- en: Introduction to Machine Learning with Scala
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala机器学习简介
- en: In this chapter, we will explain some basic concepts of **machine learning**
    (**ML**) that will be used in all subsequent chapters. We will start with a brief
    introduction to ML including basic learning workflow, ML rule of thumb, and different
    learning tasks. Then we will gradually cover most important ML tasks.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将解释一些将在所有后续章节中使用的机器学习（ML）的基本概念。我们将从对ML的简要介绍开始，包括基本学习工作流程、ML的经验法则和不同的学习任务。然后我们将逐步介绍最重要的机器学习任务。
- en: 'Also, we will discuss getting started with Scala and Scala-based ML libraries
    for getting a quick start for the next chapter. Finally, we get started with ML
    with Scala and Spark ML by solving a real-life problem. The chapter will briefly
    cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将讨论如何开始使用Scala和基于Scala的机器学习库，以便为下一章快速入门。最后，我们将通过解决一个实际问题来开始使用Scala和Spark
    ML进行机器学习。本章将简要介绍以下主题：
- en: Overview of ML
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习概述
- en: ML tasks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: Introduction to Scala
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala简介
- en: Scala ML libraries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala机器学习库
- en: Getting started with ML with Spark ML
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark ML开始机器学习
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You'll be required to have basic knowledge of Scala and Java. Since Scala is
    also a JVM-based language, make sure both Java JRE and JDK are installed and configured
    on your machine. To be more specific, you'll need Scala 2.11.x and Java 1.8.x
    version installed. Also, you need an IDE, such as Eclipse, IntelliJ IDEA, or Scala
    IDE, with the necessary plugins. However, if you're using IntelliJ IDEA, Scala
    will already be integrated.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要具备Scala和Java的基本知识。由于Scala也是一种基于JVM的语言，请确保您的机器上已安装并配置了Java JRE和JDK。更具体地说，您需要安装Scala
    2.11.x和Java 1.8.x版本。此外，您需要一个带有必要插件的IDE，例如Eclipse、IntelliJ IDEA或Scala IDE。但是，如果您使用IntelliJ
    IDEA，Scala已经集成。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter01](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter01)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter01](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter01)'
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，了解代码的实际应用：
- en: '[http://bit.ly/2V3Id08](http://bit.ly/2V3Id08)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2V3Id08](http://bit.ly/2V3Id08)'
- en: Overview of ML
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习概述
- en: ML approaches are based on a set of statistical and mathematical algorithms
    in order to carry out tasks such as classification, regression analysis, concept
    learning, predictive modeling, clustering, and mining of useful patterns. Using
    ML, we aim to improve the whole learning process automatically such that we may
    not need complete human interactions, or we can at least reduce the level of such
    interactions as much as possible.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习方法基于一系列统计和数学算法，以执行分类、回归分析、概念学习、预测建模、聚类和有用模式的挖掘等任务。使用机器学习，我们旨在自动改进整个学习过程，这样我们可能不需要完整的人类交互，或者我们至少可以尽可能减少这种交互的水平。
- en: Working principles of a learning algorithm
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习算法的工作原理
- en: 'Tom M. Mitchell explained what learning really means from a computer science
    perspective:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 托马斯·M·米切尔从计算机科学的角度解释了学习真正意味着什么：
- en: '"A computer program is said to learn from experience E with respect to some
    class of tasks T and performance measure P, if its performance at tasks in T,
    as measured by P, improves with experience E."'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: “如果一个计算机程序在任务T中，根据性能度量P，从经验E中学习，那么它的性能会随着经验E的提高而提高。”
- en: 'Based on this definition, we can conclude that a computer program or machine
    can do the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个定义，我们可以得出结论，计算机程序或机器可以执行以下操作：
- en: Learn from data and histories
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据和历史中学习
- en: Improve with experience
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随经验改进
- en: Iteratively enhance a model that can be used to predict outcomes of questions
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步提升一个可以用来预测问题结果的模型
- en: 'Since the preceding points are at the core of predictive analytics, almost
    every ML algorithm we use can be treated as an optimization problem. This is about
    finding parameters that minimize an objective function, for example, a weighted
    sum of two terms such as a cost function and regularization. Typically, an objective
    function has two components:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于前述要点是预测分析的核心，我们使用的几乎所有机器学习算法都可以被视为一个优化问题。这涉及到寻找最小化目标函数的参数，例如，两个术语（如成本函数和正则化）的加权总和。通常，目标函数有两个组成部分：
- en: A regularizer, which controls the complexity of the model
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化器，它控制着模型复杂性
- en: The loss, which measures the error of the model on the training data
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失，它衡量模型在训练数据上的误差
- en: On the other hand, the regularization parameter defines the trade-off between
    minimizing the training error and the model's complexity, in an effort to avoid
    overfitting problems. Now, if both of these components are convex, then their
    sum is also convex. So, when using an ML algorithm, the goal is to obtain the
    best hyperparameters of a function that return the minimum error when making predictions.
    Therefore, by using a convex optimization technique, we can minimize the function
    until it converges toward the minimum error.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，正则化参数定义了最小化训练误差和模型复杂度之间的权衡，旨在避免过拟合问题。现在，如果这两个组件都是凸的，那么它们的和也是凸的。因此，在使用机器学习算法时，目标是获得一个函数的最佳超参数，该函数在做出预测时返回最小误差。因此，通过使用凸优化技术，我们可以最小化函数，直到它收敛到最小误差。
- en: Given that a problem is convex, it is usually easier to analyze the asymptotic
    behavior of the algorithm, which shows how fast it converges as the model observes
    more and more training data. The task of ML is to train a model so that it can
    recognize complex patterns from the given input data and can make decisions in
    an automated way.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于问题具有凸性，通常更容易分析算法的渐近行为，这显示了随着模型观察越来越多的训练数据，其收敛速度有多快。机器学习的任务是要训练一个模型，使其能够从给定的输入数据中识别复杂的模式，并且能够以自动化的方式做出决策。
- en: 'Thus, inferencing is all about testing the model against new (that is, unobserved)
    data and evaluating the performance of the model itself. However, in the whole
    process and for making the predictive model a successful one, data acts as the
    first-class citizen in all ML tasks. In reality, the data that we feed to our
    machine learning systems must be made up of mathematical objects, such as vectors,
    so that they can consume such data. For example, in the following diagram, raw
    images are embedded into numeric values called feature vectors before feeding
    in to the learning algorithm:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，推理就是测试模型对新（即未观察到的）数据，并评估模型本身的性能。然而，在整个过程中，以及为了使预测模型成功，数据在所有机器学习任务中都是第一位的公民。实际上，我们提供给机器学习系统的数据必须由数学对象组成，例如向量，这样它们才能消费这样的数据。例如，在以下图中，原始图像被嵌入到称为特征向量的数值中，在输入到学习算法之前：
- en: '![](img/6b259b7b-104b-42f6-b03f-e6e686e14938.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6b259b7b-104b-42f6-b03f-e6e686e14938.png)'
- en: Depending on the available data and feature types, the performance of your predictive
    model can vacillate dramatically. Therefore, selecting the right features is one
    of the most important steps before the inferencing takes place. This is called
    feature engineering, where the domain knowledge about the data is used to create
    only selective or useful features that help prepare the feature vectors to be
    used so that a machine learning algorithm works.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 根据可用的数据和特征类型，你的预测模型的表现可能会发生剧烈波动。因此，在推理发生之前选择正确的特征是其中最重要的步骤之一。这被称为特征工程，其中使用关于数据的领域知识来创建仅选择性的或有用的特征，以帮助准备用于机器学习算法的特征向量。
- en: For example, comparing hotels is quite difficult unless we already have a personal
    experience of staying in multiple hotels. However, with the help of an ML model,
    which is already trained with quality features out of thousands of reviews and
    features (for example, how many stars does a hotel have, size of the room, location,
    room service, and so on), it is pretty feasible now. We'll see several examples
    throughout the chapters. However, before developing such an ML model, knowing
    some ML concepts is also important.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，除非我们已经有在多个酒店住宿的个人经验，否则比较酒店相当困难。然而，借助已经从数千条评论和特征中训练出来的机器学习模型（例如，酒店有多少颗星，房间大小，位置，客房服务等等），现在这变得相当可行了。我们将在章节中看到几个例子。然而，在开发这样的机器学习模型之前，了解一些机器学习概念也很重要。
- en: General machine learning rule of thumb
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通用机器学习经验法则
- en: 'The general machine learning rule of thumb is that the more data there is,
    the better the predictive model. However, having more features often creates a
    mess, to the extent that the performance degrades drastically, especially if the
    dataset is high-dimensional. The entire learning process requires input datasets
    that can be split into three types (or are already provided as such):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通用机器学习经验法则是，数据越多，预测模型越好。然而，拥有更多的特征往往会导致混乱，以至于性能急剧下降，尤其是在数据集是高维的情况下。整个学习过程需要可以分成三种类型（或已经以这种形式提供）的输入数据集：
- en: A **training set** is the knowledge base coming from historical or live data
    that is used to fit the parameters of the ML algorithm. During the training phase,
    the ML model utilizes the training set to find optimal weights of the network
    and reach the objective function by minimizing the training error. Here, the back-prop
    rule or an optimization algorithm is used to train the model, but all the hyperparameters
    are needed to be set before the learning process starts.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集**是从历史数据或实时数据中获取的知识库，用于拟合机器学习算法的参数。在训练阶段，机器学习模型利用训练集来找到网络的最佳权重，并通过最小化训练误差来实现目标函数。在这里，使用反向传播规则或优化算法来训练模型，但在学习过程开始之前，所有超参数都需要设置好。'
- en: A **validation set** is a set of examples used to tune the parameters of an
    ML model. It ensures that the model is trained well and generalizes toward avoiding
    overfitting. Some ML practitioners refer to it as a development set or dev set
    as well.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证集**是一组用于调整机器学习模型参数的示例。它确保模型训练良好，并泛化以避免过拟合。一些机器学习从业者也将其称为开发集或dev集。'
- en: A **test set** is used for evaluating the performance of the trained model on
    unseen data. This step is also referred to as model inferencing. After assessing
    the final model on the test set (that is, when we're fully satisfied with the
    model's performance), we do not have to tune the model any further, but the trained
    model can be deployed in a production-ready environment.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集**用于评估训练模型在未见数据上的性能。这一步骤也被称为模型推理。在测试集上评估最终模型（即当我们对模型性能完全满意时），我们不需要进一步调整模型，但训练好的模型可以部署到生产就绪环境中。'
- en: A common practice is splitting the input data (after necessary pre-processing
    and feature engineering) into 60% for training, 10% for validation, and 20% for
    testing, but it really depends on use cases. Sometimes, we also need to perform
    up-sampling or down-sampling on the data based on the availability and quality
    of the datasets.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的做法是将输入数据（在必要的预处理和特征工程之后）分为60%用于训练，10%用于验证，20%用于测试，但这实际上取决于具体用例。有时，我们还需要根据数据集的可用性和质量对数据进行上采样或下采样。
- en: This rule of thumb of learning on different types of training sets can differ
    across machine learning tasks, as we will cover in the next section. However,
    before that, let's take a quick look at a few common phenomena in machine learning.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论不同类型的训练集上的学习规则可能会有所不同。然而，在那之前，让我们快速看一下机器学习中的一些常见现象。
- en: General issues in machine learning models
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型中的通用问题
- en: 'When we use this input data for the training, validation, and testing, usually
    the learning algorithms cannot learn 100% accurately, which involves training,
    validation, and test error (or loss). There are two types of error that one can
    encounter in a machine learning model:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用这些输入数据进行训练、验证和测试时，通常学习算法无法100%准确地学习，这涉及到训练、验证和测试误差（或损失）。在机器学习模型中，可能会遇到两种类型的误差：
- en: Irreducible error
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可减少误差
- en: Reducible error
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可减少误差
- en: 'The irreducible error cannot be reduced even with the most robust and sophisticated
    model. However, the reducible error, which has two components, called bias and
    variance, can be reduced**.** Therefore, to understand the model (that is, prediction
    errors), we need to focus on bias and variance only:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最稳健和复杂的模型也无法减少不可减少误差。然而，可减少误差，它有两个组成部分，称为偏差和方差，是可以减少的**。** 因此，为了理解模型（即预测误差），我们只需要关注偏差和方差：
- en: Bias means how far the predicted value are from the actual values. Usually,
    if the average predicted values are very different from the actual values (labels),
    then the bias is higher.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏差意味着预测值与实际值之间的距离。通常，如果平均预测值与实际值（标签）非常不同，那么偏差就更高。
- en: An ML model will have a high bias because it can't model the relationship between
    input and output variables (can't capture the complexity of data well) and becomes
    very simple. Thus, a too-simple model with high variance causes underfitting of
    the data.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个机器学习模型会因为无法建模输入和输出变量之间的关系（无法很好地捕捉数据的复杂性）而具有很高的偏差，并变得非常简单。因此，一个过于简单的模型具有高方差，会导致数据欠拟合。
- en: 'The following diagram gives some high-level insights and also shows what a
    just-right fit model should look like:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表提供了一些高级见解，同时也展示了恰到好处的拟合模型应该是什么样子：
- en: '![](img/643e8299-1ebf-4072-a764-c87d8d90aab3.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/643e8299-1ebf-4072-a764-c87d8d90aab3.png)'
- en: Variance signifies the variability between the predicted values and the actual
    values (how scattered they are).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 方差表示预测值和实际值之间的可变性（它们有多分散）。
- en: '**Identifying high bias and high variance**: If the model has a high training
    error as well as the validation error or test error is the same as the training
    error, the model has high bias. On the other hand, if the model has low training
    error but has high validation or high test error, the model has a high variance.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**识别高偏差和高方差**：如果模型具有高训练误差以及验证误差或测试误差与训练误差相同，则模型具有高偏差。另一方面，如果模型具有低训练误差但具有高验证误差或高测试误差，则模型具有高方差。'
- en: 'An ML model usually performs very well on the training set but doesn''t work
    well on the test set (because of high error rates). Ultimately, it results in
    an underfit model. We can recap the overfitting and underfitting once more:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型通常在训练集上表现良好，但在测试集上表现不佳（因为误差率高）。最终，这会导致欠拟合模型。我们可以再次总结过拟合和欠拟合：
- en: '**Underfitting**: If your training and validation error are both relatively
    equal and very high, then your model is most likely underfitting your training
    data.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欠拟合**：如果你的训练误差和验证误差都相对相等且非常高，那么你的模型很可能是欠拟合了训练数据。'
- en: '**Overfitting**: If your training error is low and your validation error is
    high, then your model is most likely overfitting your training data. The just-rightfit
    model learns very well and performs better on unseen data too.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：如果你的训练误差低而验证误差高，那么你的模型很可能是过拟合了训练数据。恰到好处的模型学习得很好，并且在未见过的数据上表现也更好。'
- en: '**Bias-variance trade-off**: The high bias and high variance issue is often
    called bias-variance trade-off, because a model cannot be too complex or too simple
    at the same time. Ideally, we would strive for the best model that has both low
    bias and low variance.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏差-方差权衡**：高偏差和高方差问题通常被称为偏差-方差权衡，因为一个模型不能同时过于复杂或过于简单。理想情况下，我们应该努力寻找具有低偏差和低方差的最佳模型。'
- en: Now we know the basic working principle of an ML algorithm. However, based on
    problem type and the method used to solve a problem, ML tasks can be different,
    for example, supervised learning, unsupervised learning, and reinforcement learning.
    We'll discuss these learning tasks in more detail in the next section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了机器学习算法的基本工作原理。然而，基于问题类型和解决问题的方法，机器学习任务可能会有所不同，例如，监督学习、无监督学习和强化学习。我们将在下一节中更详细地讨论这些学习任务。
- en: ML tasks
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: Although every ML problem is more or less an optimization problem, the way they
    are solved can vary. In fact, learning tasks can be categorized into three types: supervised
    learning, unsupervised learning, and reinforcement learning.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管每个机器学习问题或多或少都是一个优化问题，但解决它们的方式可能会有所不同。实际上，学习任务可以分为三种类型：监督学习、无监督学习和强化学习。
- en: Supervised learning
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习
- en: 'Supervised learning is the simplest and most well-known automatic learning
    task. It is based on a number of predefined examples, in which the category to
    which each of the inputs should belong is already known, as shown in the following
    diagram:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是最简单且最著名的自动学习任务。它基于一系列预定义的示例，其中每个输入应属于哪个类别已经已知，如下面的图所示：
- en: '![](img/a5c163b5-9617-43ef-916f-edd20c1a9bc1.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a5c163b5-9617-43ef-916f-edd20c1a9bc1.png)'
- en: The preceding diagram shows a typical workflow of supervised learning. An actor
    (for example, a data scientist or data engineer) performs **Extraction Transformation
    Load** (**ETL**) and the necessary feature engineering (including feature extraction,
    selection, and so on) to get the appropriate data with features and labels so
    that they can be fed in to the model. Then he would split the data into training,
    development, and test sets. The training set is used to train an ML model, the
    validation set is used to validate the training against the overfitting problem
    and regularization, and then the actor would evaluate the model's performance
    on the test set (that is, unseen data).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图显示了监督学习的典型工作流程。一个演员（例如，数据科学家或数据工程师）执行**提取、转换、加载**（**ETL**）和必要的特征工程（包括特征提取、选择等），以获取具有特征和标签的适当数据，以便它们可以被输入到模型中。然后他会将数据分为训练集、开发集和测试集。训练集用于训练机器学习模型，验证集用于验证训练以防止过拟合和正则化，然后演员会在测试集（即未见过的数据）上评估模型的表现。
- en: 'However, if the performance is not satisfactory, he can perform additional
    tuning to get the best model based on hyperparameter optimization. Finally, he
    would deploy the best model in a production-ready environment. The following diagram
    summarizes these steps in a nutshell:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果性能不满意，他可以通过额外的调整来根据超参数优化获得最佳模型。最后，他将在一个生产就绪的环境中部署最佳模型。以下图表简要总结了这些步骤：
- en: '![](img/dfa111da-e783-452e-a17f-32ccb53902de.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![无监督学习任务工作流程](img/dfa111da-e783-452e-a17f-32ccb53902de.png)'
- en: In the overall life cycle, there might be many actors involved (for example,
    a data engineer, data scientist, or an ML engineer) to perform each step independently
    or collaboratively. The supervised learning context includes classification and
    regression tasks; classification is used to predict which class a data point is
    a part of (discrete value). It is also used for predicting the label of the class
    attribute. On the other hand, regression is used for predicting continuous values
    and making a numeric prediction of the class attribute.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个生命周期中，可能会有许多参与者（例如，数据工程师、数据科学家或机器学习工程师）独立或协作地执行每个步骤。监督学习环境包括分类和回归任务；分类用于预测数据点属于哪个类别（离散值）。它也用于预测类属性的标签。另一方面，回归用于预测连续值并对类属性进行数值预测。
- en: In the context of supervised learning, the learning process required for the
    input dataset is split randomly into three sets, for example, 60% for the training
    set, 10% for the validation set, and the remaining 30% for the testing set.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习的情况下，对输入数据集的学习过程被随机分为三个集合，例如，60%用于训练集，10%用于验证集，剩余的30%用于测试集。
- en: Unsupervised learning
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习
- en: 'How would you summarize and group a dataset if the labels were not given? Probably,
    you''ll try to answer this question by finding the underlying structure of a dataset
    and measuring the statistical properties such as frequency distribution, mean,
    standard deviation, and so on. If the question is *how would you effectively represent
    data in a compressed format?* You''ll probably reply saying that you''ll use some
    software for doing the compression, although you might have no idea how that software
    would do it. The following diagram shows the typical workflow of an unsupervised
    learning task:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有给出标签，你将如何总结和分组一个数据集？你可能试图通过寻找数据集的潜在结构并测量统计属性，如频率分布、均值、标准差等来回答这个问题。如果问题是“你将如何有效地以压缩格式表示数据？”你可能会回答说你会使用一些软件来进行压缩，尽管你可能不知道该软件是如何做到这一点的。以下图表显示了无监督学习任务的典型工作流程：
- en: '![](img/69e15120-3013-419e-ac6d-66248ab3c9a9.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![无监督学习示例](img/69e15120-3013-419e-ac6d-66248ab3c9a9.png)'
- en: 'These are exactly two of the main goals of unsupervised learning, which is
    largely a data-driven process. We call this type of learning *unsupervised* because
    you will have to deal with unlabeled data. The following quote comes from Yann
    LeCun, director of AI research (source: Predictive Learning, NIPS 2016, Yann LeCun,
    Facebook Research):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这些正是无监督学习的两个主要目标，它基本上是一个数据驱动的过程。我们称这种学习为“无监督”学习，因为您将不得不处理未标记的数据。以下引言来自Yann LeCun，AI研究总监（来源：预测学习，NIPS
    2016，Yann LeCun，Facebook Research）：
- en: '*"Most of human and animal learning is unsupervised learning. If intelligence
    was a cake, unsupervised learning would be the cake, supervised learning would
    be the icing on the cake, and reinforcement learning would be the cherry on the
    cake. We know how to make the icing and the cherry, but we don''t know how to
    make the cake. We need to solve the unsupervised learning problem before we can
    even think of getting to true AI".*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: “人类和动物的大多数学习都是无监督学习。如果智能是一块蛋糕，无监督学习就是蛋糕本身，监督学习就是蛋糕上的糖霜，强化学习就是蛋糕上的樱桃。我们知道如何制作糖霜和樱桃，但我们不知道如何制作蛋糕。在我们甚至考虑达到真正的AI之前，我们需要解决无监督学习问题。”
- en: 'The two most widely used unsupervised learning tasks include the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 两个最广泛使用的无监督学习任务包括以下内容：
- en: '**Clustering**: Grouping data points based on similarity (or statistical properties).
    For example, a company such as Airbnb often groups its apartments and houses into
    neighborhoods so that customers can navigate the listed ones more easily.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：根据相似性（或统计属性）对数据点进行分组。例如，像Airbnb这样的公司经常将它的公寓和房屋分组到社区中，以便客户可以更容易地浏览列表。'
- en: '**Dimensionality** **reduction**: Compressing the data with the structure and
    statistical properties preserved as much as possible. For example, often the number
    of dimensions of the dataset needs to be reduced for the modeling and visualization.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维**：尽可能多地保留结构和统计属性地压缩数据。例如，通常需要减少数据集的维度以进行建模和可视化。'
- en: '**Anomaly detection**: Useful in several applications such as identification
    of credit card fraud detection, identifying faulty pieces of hardware in an industrial engineering
    process, and identifying outliers in large-scale datasets.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**：在多个应用中很有用，例如在信用卡欺诈检测中识别，在工业工程过程中识别有缺陷的硬件，以及在大型数据集中识别异常值。'
- en: '**Association rule mining**: Often used in market basket analysis, for example,
    asking which items are brought together and frequently.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联规则挖掘**：常用于市场篮子分析，例如询问哪些商品经常一起购买。'
- en: Reinforcement learning
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: 'Reinforcement learning is an artificial intelligence approach that focuses
    on the learning of the system through its interactions with the environment. In
    reinforcement learning, the system''s parameters are adapted based on the feedback
    obtained from the environment, which in turn provides feedback on the decisions
    made by the system. The following diagram shows a person making decisions in order
    to arrive at their destination. Let''s take an example of the route you take from
    home to work:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是一种人工智能方法，它侧重于通过系统与环境交互来学习。在强化学习中，系统的参数根据从环境中获得的反馈进行调整，反过来，环境又对系统的决策提供反馈。以下图表显示一个人在做出决策以到达目的地。让我们以从家到工作的路线为例：
- en: '![](img/529a2d39-87ec-450b-8fb1-23e795d276f0.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/529a2d39-87ec-450b-8fb1-23e795d276f0.png)'
- en: In this case, you take the same route to work every day. However, out of the
    blue, one day you get curious and decide to try a different route with a view
    to finding the shortest path. Similarly, based on your experience and the time
    taken with the different route, you'd decide whether you should take a specific
    route more often. We can take a look at one more example in terms of a system
    modeling a chess player. In order to improve its performance, the system utilizes
    the result of its previous moves; such a system is said to be a system learning
    with reinforcement.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你每天走相同的路线去上班。然而，有一天你突然好奇，决定尝试一条不同的路线，以寻找最短路径。同样，根据你的经验和不同路线所花费的时间，你会决定是否应该更频繁地选择特定的路线。我们可以再举一个系统模拟棋手的例子。为了提高其性能，系统利用其先前移动的结果；这样的系统被称为具有强化学习的系统。
- en: So far, we have learned the basic working principles of ML and different learning
    tasks. However, a summarized view of each learning task with some example use
    cases is a mandate, which we will see in the next subsection.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了机器学习的基本工作原理和不同的学习任务。然而，对每个学习任务进行总结并给出一些示例用例是必要的，我们将在下一小节中看到这一点。
- en: Summarizing learning types with applications
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结学习类型及其应用
- en: 'We have seen the basic working principles of ML algorithms. Then we have seen
    what the basic ML tasks are and how they formulate domain-specific problems. However,
    each of these learning tasks can be solved using different algorithms. The following
    diagram provides a glimpse into this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了机器学习算法的基本工作原理。然后我们看到了基本机器学习任务是什么以及它们如何构建特定领域的问题。然而，每个学习任务都可以使用不同的算法来解决。以下图表提供了一个概览：
- en: '![](img/69724fda-a4e8-4d3f-b8ac-522d883c906f.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/69724fda-a4e8-4d3f-b8ac-522d883c906f.png)'
- en: Types of learning and related problems
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 学习类型和相关问题
- en: 'The following diagram summarizes the previously mentioned ML tasks and some
    applications:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了之前提到的机器学习任务和一些应用：
- en: '![](img/8a2cf2df-a148-4609-8eb0-af0f975bdda8.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a2cf2df-a148-4609-8eb0-af0f975bdda8.png)'
- en: ML tasks and some use cases from different application domains
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 来自不同应用领域的机器学习任务和一些用例
- en: However, the preceding diagram lists only a few use cases and applications using
    different ML tasks. In practice, ML is used in numerous use cases and applications.
    We will try to cover a few of those throughout this book.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，前面的图表只列出了几个使用不同机器学习任务的用例和应用。在实践中，机器学习被用于无数的用例和应用。我们将尝试在本书中涵盖其中的一些。
- en: Overview of Scala
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala概述
- en: Scala is a scalable, functional, and object-oriented programming language that
    is most closely related to Java. However, Scala is designed to be more concise
    and have features of functional programming languages. For example, Apache Spark,
    which is written in Scala, is a fast and general engine for large-scale data processing.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Scala是一种可扩展的、函数式和面向对象的编程语言，与Java最为紧密相关。然而，Scala被设计得更加简洁，并具有函数式编程语言的特征。例如，用Scala编写的Apache
    Spark是一个快速且通用的用于大规模数据处理的引擎。
- en: 'Scala''s success is due to many factors: it has many tools that enable succinct
    expression, it is very concise because you need less typing, and it therefore
    requires less reading, and it offers very good performance as well. This is why
    Spark has more support for Scala in the sense that more APIs are available that
    are written in Scala compared to R, Python, and Java. Scala''s symbolic operators
    are easy to read and, compared to Java, most of the Scala codes are comparatively
    concise and easy to read; Java is too verbose. Functional programming concepts
    such as pattern matching and higher-order functions are also available in Scala.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Scala的成功归因于许多因素：它有许多工具能够实现简洁的表达，它非常简洁，因为你需要输入更少的代码，因此需要阅读的也较少，并且它还提供了非常好的性能。这就是为什么Spark对Scala的支持更多，与R、Python和Java相比，有更多的API是用Scala编写的。Scala的符号运算符易于阅读，与Java相比，大多数Scala代码相对简洁且易于阅读；Java则过于冗长。模式匹配和高级函数等函数式编程概念也存在于Scala中。
- en: The best way to get started with Scala is either using Scala through the **Scala
    build tool** (**SBT**) or to use Scala through an **integrated development environment**
    (**IDE**). Either way, the first important step is downloading, installing, and
    configuring Scala. However, since Scala runs on **Java Virtual Machine** (**JVM**),
    having Java installed and configured on your machine is a prerequisite. Therefore,
    I'm not going to cover how to do that. Instead, I will provide some useful links
    ([https://en.wikipedia.org/wiki/Integrated_development_environment](https://en.wikipedia.org/wiki/Integrated_development_environment)).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用Scala的最佳方式是使用Scala通过**Scala构建工具**（**SBT**）或通过**集成开发环境**（**IDE**）使用Scala。无论哪种方式，第一步都是下载、安装和配置Scala。然而，由于Scala运行在**Java虚拟机**（**JVM**）上，因此需要在您的机器上安装和配置Java。因此，我不会介绍如何进行这一步骤。相反，我将提供一些有用的链接（[https://en.wikipedia.org/wiki/Integrated_development_environment](https://en.wikipedia.org/wiki/Integrated_development_environment)）。
- en: Just follow the instructions on how to set up both Java and an IDE (for example,
    IntelliJ IDEA) or build tool (for example, SBT) at [https://www.scala-lang.org/download/](https://www.scala-lang.org/download/).
    If you're using Windows (for example, Windows 10) or Linux (for example, Ubuntu),
    visit [https://www.journaldev.com/7456/download-install-scala-linux-unix-windows](https://www.journaldev.com/7456/download-install-scala-linux-unix-windows).
    Finally, here are some macOS instructions: [http://sourabhbajaj.com/mac-setup/Scala/README.html](http://sourabhbajaj.com/mac-setup/Scala/README.html).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 请遵循如何在[https://www.scala-lang.org/download/](https://www.scala-lang.org/download/)上设置Java和IDE（例如，IntelliJ
    IDEA）或构建工具（例如，SBT）的说明。如果您使用的是Windows（例如，Windows 10）或Linux（例如，Ubuntu），请访问[https://www.journaldev.com/7456/download-install-scala-linux-unix-windows](https://www.journaldev.com/7456/download-install-scala-linux-unix-windows)。最后，这里有一些macOS的说明：[http://sourabhbajaj.com/mac-setup/Scala/README.html](http://sourabhbajaj.com/mac-setup/Scala/README.html)。
- en: 'Java programmers normally prefer Scala when they need to add some functional
    programming flavor to their codes as Scala runs on JVM. There are various other
    options when it comes to editors. The following are some options to choose from:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Java程序员通常在需要为代码添加一些函数式编程风格时更喜欢Scala，因为Scala运行在JVM上。在编辑器方面，有各种其他选择。以下是一些可供选择的选择：
- en: Scala IDE
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala IDE
- en: Scala plugin for Eclipse
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eclipse的Scala插件
- en: IntelliJ IDEA
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IntelliJ IDEA
- en: Emacs
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Emacs
- en: Vim
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vim
- en: Eclipse has several advantages using numerous beta plugins and local, remote,
    and high-level debugging facilities with semantic highlighting and code completion
    for Scala.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Eclipse使用众多beta插件和本地、远程以及高级调试设施，具有语义高亮和代码补全功能，因此在Scala方面具有多个优势。
- en: ML libraries in Scala
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala中的ML库
- en: Although Scala is a relatively new programming language compared to Java and
    Python, the question will arise as to why we need to consider learning it while
    we have Python and R. Well, Python and R are two leading programming languages
    for rapid prototyping and data analytics including building, exploring, and manipulating
    powerful models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然与Java和Python相比，Scala是一种相对较新的编程语言，但当我们已经有Python和R时，为什么还需要考虑学习它的问题将会出现。嗯，Python和R是两种领先的快速原型设计和数据分析编程语言，包括构建、探索和操作强大的模型。
- en: But Scala is becoming the key language too in the development of functional
    products, which are well suited for big data analytics. Big data applications
    often require stability, flexibility, high speed, scalability, and concurrency.
    All of these requirements can be fulfilled with Scala because Scala is not only
    a general-purpose language but also a powerful choice for data science (for example,
    Spark MLlib/ML). I've been using Scala for the last couple of years and I found
    that more and more Scala ML libraries are in development. Up next, we will discuss
    available and widely used Scala libraries that can be used for developing ML applications.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 但Scala也正在成为功能产品开发的关键语言，这些产品非常适合大数据分析。大数据应用通常需要稳定性、灵活性、高速、可扩展性和并发性。所有这些需求都可以通过Scala来实现，因为Scala不仅是一种通用语言，而且也是数据科学（例如，Spark
    MLlib/ML）的一个强大选择。我过去几年一直在使用Scala，我发现越来越多的Scala ML库正在开发中。接下来，我们将讨论可用于开发ML应用的可用和广泛使用的Scala库。
- en: 'Interested readers can take a quick look at this, which lists the 15 most popular
    Scala libraries for ML and data science:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 感兴趣的读者可以快速查看这个列表，它列出了15个最受欢迎的Scala ML和数据科学库：
- en: '[https://www.datasciencecentral.com/profiles/blogs/top-15-scala-libraries-for-data-science-in-2018-1](https://www.datasciencecentral.com/profiles/blogs/top-15-scala-libraries-for-data-science-in-2018-1)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.datasciencecentral.com/profiles/blogs/top-15-scala-libraries-for-data-science-in-2018-1](https://www.datasciencecentral.com/profiles/blogs/top-15-scala-libraries-for-data-science-in-2018-1)'
- en: Spark MLlib and ML
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark MLlib 和 ML
- en: MLlib is a library that provides user-friendly ML algorithms that are implemented
    using Scala. The same API is then exposed to provide support for other languages
    such as Java, Python, and R. Spark MLlib provides support for local vectors and
    matrix data types stored on a single machine, as well as distributed matrices
    backed by one or multiple **resilient distributed datasets** (**RDDs**).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib是一个库，它提供了使用Scala实现的用户友好的ML算法。然后，相同的API被公开以提供对Java、Python和R等其他语言的支持。Spark
    MLlib为存储在单台机器上的本地向量和矩阵数据类型以及由一个或多个**弹性分布式数据集**（**RDDs**）支持的分布式矩阵提供支持。
- en: RDD is the primary data abstraction of Apache Spark, often called Spark Core,
    that represents an immutable, partitioned collection of elements that can be operated
    on in parallel. The resiliency makes RDD fault-tolerant (based on RDD lineage
    graph). RDD can help in distributed computing even when data is stored on multiple
    nodes in a Spark cluster. Also, RDD can be converted into a dataset as a collection
    of partitioned data with primitive values such as tuples or other objects.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: RDD是Apache Spark的主要数据抽象，通常称为Spark Core，它表示一个不可变、分区元素集合，可以在并行操作上操作。其容错性使得RDD具有容错性（基于RDD血缘图）。即使在Spark集群的多个节点上存储数据时，RDD也可以帮助进行分布式计算。此外，RDD可以转换为数据集，作为具有元组或其他对象等原始值的分区数据集合。
- en: Spark ML is a new set of ML APIs that allows users to quickly assemble and configure
    practical machine learning pipelines on top of datasets, which makes it easier
    to combine multiple algorithms into a single pipeline. For example, an ML algorithm
    (called estimator) and a set of transformers (for example, a `StringIndexer`,
    a `StandardScalar`, and a `VectorAssembler`) can be chained together to perform
    the ML task as stages without needing to run them sequentially.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML是一组新的ML API，它允许用户在数据集之上快速组装和配置实用的机器学习管道，这使得将多个算法组合成一个单一管道变得更加容易。例如，一个ML算法（称为estimator）和一组转换器（例如，一个`StringIndexer`，一个`StandardScalar`和一个`VectorAssembler`）可以连接在一起，作为阶段执行ML任务，而无需按顺序运行它们。
- en: Interested readers can take a look at the Spark MLlib and ML guide at [https://spark.apache.org/docs/latest/ml-guide.html](https://spark.apache.org/docs/latest/ml-guide.html).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 感兴趣的读者可以查看Spark MLlib和ML指南：[https://spark.apache.org/docs/latest/ml-guide.html](https://spark.apache.org/docs/latest/ml-guide.html)。
- en: At this point, I have to inform you of something very useful. Since we will
    be using Spark MLlib and ML APIs in upcoming chapters too. Therefore, it would
    be worth fixing some issues in advance. If you're a Windows user, then let me
    tell you about a very weird issue that you will experience while working with
    Spark. The thing is that Spark works on Windows, macOS, and Linux. While using
    Eclipse or IntelliJ IDEA to develop your Spark applications on Windows, you might
    face an I/O exception error and, consequently, your application might not compile
    successfully or may be interrupted.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我必须告诉你一些非常有用的信息。由于我们将在接下来的章节中继续使用 Spark MLlib 和 ML API，因此提前解决一些问题将是有益的。如果你是
    Windows 用户，那么让我告诉你一个你在使用 Spark 时可能会遇到的一个非常奇怪的问题。问题是 Spark 在 Windows、macOS 和 Linux
    上都可以运行。当你在 Windows 上使用 Eclipse 或 IntelliJ IDEA 开发 Spark 应用程序时，你可能会遇到 I/O 异常错误，从而导致你的应用程序可能无法成功编译或可能中断。
- en: 'Spark needs a runtime environment for Hadoop on Windows too. Unfortunately,
    the binary distribution of Spark (v2.4.0, for example) does not contain Windows-native
    components such as `winutils.exe` or `hadoop.dll`. However, these are required
    (not optional) to run Hadoop on Windows if you cannot ensure the runtime environment,
    an I/O exception saying the following will appear:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 在 Windows 上也需要 Hadoop 的运行环境。不幸的是，Spark 的二进制分发版（例如 v2.4.0）不包含 Windows 原生组件，如
    `winutils.exe` 或 `hadoop.dll`。然而，如果你不能确保运行环境，那么在 Windows 上运行 Hadoop 是必需的（不是可选的），否则会出现以下
    I/O 异常：
- en: '[PRE0]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'There are two ways to tackle this issue on Windows and from IDEs such as Eclipse
    and IntelliJ IDEA:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 和像 Eclipse 和 IntelliJ IDEA 这样的 IDE 中处理此问题的有两种方法：
- en: Download `winutls.exe` from [https://github.com/steveloughran/ winutils/tree/
    master/hadoop-2\. 7\. 1/bin/](https://github.com/steveloughran/winutils/tree/master/hadoop-2.7.1/bin/).
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [https://github.com/steveloughran/winutils/tree/master/hadoop-2.7.1/bin/](https://github.com/steveloughran/winutils/tree/master/hadoop-2.7.1/bin/)
    下载 `winutls.exe`。
- en: Download and copy it inside the `bin` folder in the Spark distribution—for example,
    `spark-2.2.0-bin-hadoop2.7/bin/`.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并将其复制到 Spark 分发版中的 `bin` 文件夹内——例如，`spark-2.2.0-bin-hadoop2.7/bin/`。
- en: Select Project | Run Configurations... | Environment | New | and create a variable
    named `HADOOP_HOME`, then put the path in the Value field. Here is an example: `c:/spark-2.2.0-bin-hadoop2.7/bin/`
    | OK | Apply | Run.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“项目”|“运行配置...”|“环境”|“新建”|创建一个名为 `HADOOP_HOME` 的变量，然后将路径放入“值”字段。以下是一个示例：`c:/spark-2.2.0-bin-hadoop2.7/bin/`
    | 确定 | 应用 | 运行。
- en: ScalNet and DynaML
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ScalNet 和 DynaML
- en: 'ScalNet is a wrapper around Deeplearning4J intended to emulate a Keras-like
    API for developing deep learning applications. If you''re already familiar with
    neural network architectures and are coming from a JVM background, it would be
    worth exploring the Scala-based ScalNet library:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ScalNet 是围绕 Deeplearning4J 的包装器，旨在模拟 Keras 类型的 API 以开发深度学习应用程序。如果你已经熟悉神经网络架构并且来自
    JVM 背景，那么探索基于 Scala 的 ScalNet 库将是有价值的：
- en: GitHub ([https://github.com/deeplear…/deeplearning4j/…/master/scalnet](https://github.com/deeplearning4j/deeplearning4j/tree/master/scalnet?fbclid=IwAR01enpe_dySCpU1aPkMorznm6k31cDmQ49wE52_jAGQzcr-3CZs9NNSVas))
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub ([https://github.com/deeplearning4j/deeplearning4j/tree/master/scalnet](https://github.com/deeplearning4j/deeplearning4j/tree/master/scalnet?fbclid=IwAR01enpe_dySCpU1aPkMorznm6k31cDmQ49wE52_jAGQzcr-3CZs9NNSVas))
- en: Example ([https://github.com/…/sc…/org/deeplearning4j/scalnet/examples](https://github.com/deeplearning4j/ScalNet/tree/master/src/test/scala/org/deeplearning4j/scalnet/examples?fbclid=IwAR2uMjTESm9KHAIZ_mZCHckZhRuZJByhmAbQDoUAn1vCVC1SoE0KmKDmQ9M))
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例 ([https://github.com/deeplearning4j/ScalNet/tree/master/src/test/scala/org/deeplearning4j/scalnet/examples](https://github.com/deeplearning4j/ScalNet/tree/master/src/test/scala/org/deeplearning4j/scalnet/examples?fbclid=IwAR2uMjTESm9KHAIZ_mZCHckZhRuZJByhmAbQDoUAn1vCVC1SoE0KmKDmQ9M))
- en: DynaML is a Scala and JVM ML toolbox for research, education, and industry.
    This library provides an interactive, end-to-end, and enterprise-friendly way
    of developing ML applications. If you're interested, see more at [https://transcendent-ai-labs.github.io/DynaML/](https://transcendent-ai-labs.github.io/DynaML/).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: DynaML 是一个用于研究、教育和行业的 Scala 和 JVM 机器学习工具箱。这个库提供了一种交互式、端到端且企业友好的方式来开发机器学习应用程序。如果你感兴趣，可以查看更多信息：[https://transcendent-ai-labs.github.io/DynaML/](https://transcendent-ai-labs.github.io/DynaML/)。
- en: ScalaNLP, Vegas, and Breeze
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ScalaNLP、Vegas 和 Breeze
- en: Breeze is one of the primary scientific computing libraries for Scala, which
    provides a fast and efficient way of data manipulation operations such as matrix
    and vector operations for creating, transposing, filling with numbers, conducting
    element-wise operations, and calculating determinants.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Breeze 是 Scala 的主要科学计算库之一，它提供了一种快速高效的数据操作方法，例如矩阵和向量操作，用于创建、转置、填充数字、执行元素级操作和计算行列式。
- en: Breeze enables basic operations based on the `netlib-java` library, which enables
    extremely fast algebraic computations. In addition, Breeze provides a way to perform
    signal-processing operations**,** necessary for working with digital signals.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Breeze基于`netlib-java`库提供基本操作，该库能够实现极快的代数计算。此外，Breeze提供了一种执行信号处理操作的方法，这对于处理数字信号是必要的。
- en: 'The following are the GitHub links:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为GitHub链接：
- en: Breeze ([https://github.com/scalanlp/breeze/](https://github.com/scalanlp/breeze/))
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Breeze ([https://github.com/scalanlp/breeze/](https://github.com/scalanlp/breeze/))
- en: Breeze examples ([https://github.com/scalanlp/breeze-examples](https://github.com/scalanlp/breeze-examples))
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Breeze示例 ([https://github.com/scalanlp/breeze-examples](https://github.com/scalanlp/breeze-examples))
- en: Breeze quickstart ([https://github.com/scalanlp/breeze/wiki/Quickstart](https://github.com/scalanlp/breeze/wiki/Quickstart))
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Breeze快速入门 ([https://github.com/scalanlp/breeze/wiki/Quickstart](https://github.com/scalanlp/breeze/wiki/Quickstart))
- en: On the other hand, ScalaNLP is a suite of scientific computing, ML, and natural
    language processing, which also acts as an umbrella project for several libraries,
    including Breeze and Epic. Vegas is another Scala library for data visualization,
    which allows plotting specifications such as filtering, transformations, and aggregations.
    Vegas is more functional than the other numerical processing library, Breeze.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，ScalaNLP是一个科学计算、机器学习和自然语言处理套件，它还充当包括Breeze和Epic在内的几个库的母项目。Vegas是另一个Scala数据可视化库，它允许绘制过滤、转换和聚合等规范。Vegas比其他数值处理库Breeze更具有函数式。
- en: 'For more information and examples of using Vegas and Breeze, refer to GitHub:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息和Vegas和Breeze的使用示例，请参阅GitHub：
- en: Vegas ([https://github.com/vegas-viz/Vegas](https://github.com/vegas-viz/Vegas))
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vegas ([https://github.com/vegas-viz/Vegas](https://github.com/vegas-viz/Vegas))
- en: Breeze ([https://github.com/scalanlp/breeze](https://github.com/scalanlp/breeze))
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Breeze ([https://github.com/scalanlp/breeze](https://github.com/scalanlp/breeze))
- en: Whereas the visualization library of Breeze is backed by Breeze and JFreeChart,
    Vegas can be considered a missing Matplotlib for Scala and Spark, because it provides
    several options for rendering plots through and within interactive notebook environments,
    such as Jupyter and Zeppelin.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Breeze的可视化库由Breeze和JFreeChart支持，而Vegas可以被视为Scala和Spark的Matplotlib的缺失库，因为它提供了通过和交互式笔记本环境（如Jupyter和Zeppelin）渲染图表的多种选项。
- en: Refer to Zeppelin notebook solutions of each chapter in the GitHub repository
    of this book.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 参考本书GitHub仓库中每个章节的Zeppelin笔记本解决方案。
- en: Getting started learning
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始学习
- en: In this section, we'll see a real-life example of a classification problem.
    The idea is to develop a classifier that, given the values for sex, age, time,
    number of warts, type, and area, will predict whether a patient has to go through
    the cryotherapy.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到一个真实生活中的分类问题示例。想法是开发一个分类器，给定性别、年龄、时间、疣的数量、类型和面积等值，将预测患者是否需要进行冷冻疗法。
- en: Description of the dataset
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集描述
- en: We will use a recently added cryotherapy dataset from the UCI machine learning
    repository. The dataset can be downloaded from [http://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+#](http://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+#).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自UCI机器学习仓库最近添加的冷冻疗法数据集。数据集可以从[http://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+#](http://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+#)下载。
- en: This dataset contains information about wart treatment results of 90 patients
    using cryotherapy. In case you don't know, a wart is a kind of skin problem caused
    by infection with a type of human papillomavirus. Warts are typically small, rough,
    and hard growths that are similar in color to the rest of the skin.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含90名患者使用冷冻疗法治疗疣的结果信息。如果你不知道，疣是由人乳头瘤病毒感染引起的一种皮肤问题。疣通常是小而粗糙、质地坚硬的生长物，颜色与周围皮肤相似。
- en: 'There are two available treatments for this problem:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题有两种可行的治疗方法：
- en: '**Salicylic acid**: A type of gel containing salicylic acid used in medicated
    band-aids.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水杨酸**：一种含有水杨酸的凝胶，用于治疗性创可贴。'
- en: '**Cryotherapy**: A freezing liquid (usually nitrogen) is sprayed onto the wart.
    It will destroy the cells in the affected area. After the cryotherapy, usually,
    a blister develops, which eventually turns into a scab and falls off after a week
    or so.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冷冻疗法**：将一种冷冻液体（通常是氮气）喷洒在疣上。这将破坏受影响区域的细胞。冷冻疗法后，通常会出现水泡，最终形成硬痂，大约一周后脱落。'
- en: 'There are 90 samples or instances that were either recommended to go through
    cryotherapy or be discharged without cryotherapy. There are seven attributes in
    the dataset:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有 90 个样本或实例，这些样本或实例被建议进行冷冻疗法或无需冷冻疗法出院。数据集有七个属性：
- en: '`sex`: Patient gender, characterized by `1` (male) or `0` (female).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sex`：患者性别，由 `1`（男性）或 `0`（女性）表示。'
- en: '`age`: Patient age.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age`：患者年龄。'
- en: '`Time`: Observation and treatment time in hours.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Time`：观察和治疗时间（以小时计）。'
- en: '`Number_of_Warts`: Number of warts.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Number_of_Warts`：疣的数量。'
- en: '`Type`: Types of warts.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Type`：疣的类型。'
- en: '`Area`: The amount of affected area.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Area`：受影响区域的数量。'
- en: '`Result_of_Treatment`: The recommended result of the treatment, characterized
    by either `1` (yes) or `0` (no). It is also the target column.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Result_of_Treatment`：治疗建议的结果，由 `1`（是）或 `0`（否）表示。它也是目标列。'
- en: As you can understand, it is a classification problem because we will have to
    predict discrete labels. More specifically, it is a binary classification problem.
    Since this is a small dataset with only six features, we can start with a very
    basic classification algorithm called logistic regression, where the logistic
    function is applied to the regression to get the probabilities of it belonging
    in either class. We will learn more details about logistic regression and other
    classification algorithms in [Chapter 3](51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml),
    *Scala for Learning Classification*. For this, we use the Spark ML-based implementation
    of logistic regression in Scala.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所理解的，这是一个分类问题，因为我们将不得不预测离散标签。更具体地说，这是一个二元分类问题。由于这是一个只有六个特征的较小数据集，我们可以从一个非常基本的分类算法开始，称为逻辑回归，其中逻辑函数应用于回归以获得它属于任一类的概率。我们将在
    [第 3 章](51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml) 中学习更多关于逻辑回归和其他分类算法的细节，*Scala
    for Learning Classification*。为此，我们使用 Scala 中基于 Spark ML 的逻辑回归实现。
- en: Configuring the programming environment
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置编程环境
- en: 'I am assuming that Java is already installed on your machine and `JAVA_HOME`
    is set too. Also, I''m assuming that your IDE has the Maven plugin installed.
    If so, then just create a Maven project and add the project properties as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我假设 Java 已经安装到您的机器上，并且已经设置了 `JAVA_HOME`。此外，我假设您的 IDE 已经安装了 Maven 插件。如果是这样，那么只需创建一个
    Maven 项目，并按以下方式添加项目属性：
- en: '[PRE1]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding `properties` tag, I specified the Spark version (that is,
    `2.3.0`), but you can adjust it. Then add the following dependencies in the `pom.xml`
    file:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的 `properties` 标签中，我指定了 Spark 版本（即 `2.3.0`），但您可以进行调整。然后在 `pom.xml` 文件中添加以下依赖项：
- en: '[PRE2]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then, if everything goes smoothly, all the JAR files will be downloaded in the
    project home as Maven dependencies. Alright! Then we can start writing the code.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果一切顺利，所有 JAR 文件都将作为 Maven 依赖项下载到项目主目录中。好的！然后我们可以开始编写代码。
- en: Getting started with Apache Spark
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark 入门
- en: Since you're here to learn how to solve a real-life problem in Scala, exploring
    available Scala libraries would be worthwhile. Unfortunately, we don't have many
    options except for the Spark MLlib and ML, which can be used for the regression
    analysis very easily and comfortably. Importantly, it has every regression analysis
    algorithm implemented as high-level interfaces. I assume that Scala, Java, and
    your favorite IDE such as Eclipse or IntelliJ IDEA are already configured on your
    machine. We will introduce some concepts of Spark without providing much detail,
    but we will continue learning in upcoming chapters too.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您来到这里是为了学习如何在 Scala 中解决现实生活中的问题，因此探索可用的 Scala 库将是有价值的。不幸的是，我们除了 Spark MLlib
    和 ML 以外没有太多选择，它们可以非常轻松和舒适地用于回归分析。重要的是，它实现了所有回归分析算法的高级接口。我假设 Scala、Java 以及您喜欢的
    IDE，如 Eclipse 或 IntelliJ IDEA 已经配置在您的机器上。我们将介绍一些 Spark 的概念，但不会提供太多细节，我们将在接下来的章节中继续学习。
- en: 'First, I''ll introduce `SparkSession`, which is a unified entry point of a
    Spark application introduced from Spark 2.0\. Technically, `SparkSession` is the
    gateway to interact with some of Spark''s functionality with a few constructs
    such as `SparkContext`, `HiveContext`, and `SQLContext`, which are all encapsulated
    in a `SparkSession`. Previously, you have seen how to create such a session, probably
    without knowing it. Well, a `SparkSession` can be created as a builder pattern
    as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我将介绍 `SparkSession`，这是从 Spark 2.0 引入的 Spark 应用程序的统一入口点。技术上，`SparkSession`
    是通过一些结构（如 `SparkContext`、`HiveContext` 和 `SQLContext`）与 Spark 的一些功能交互的网关，这些结构都被封装在
    `SparkSession` 中。之前，您可能已经看到了如何创建这样的会话，可能并不知道。嗯，`SparkSession` 可以像以下这样作为构建者模式创建：
- en: '[PRE3]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The preceding builder will try to get an existing `SparkSession` or create a
    new one. Then the newly created `SparkSession` will be assigned as the global
    default.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的构建器将尝试获取现有的 `SparkSession` 或创建一个新的，然后新创建的 `SparkSession` 将被分配为全局默认。
- en: By the way, when using `spark-shell`, you don't need to create a `SparkSession`
    explicitly, because it's already created and accessible with the `spark` variable.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，当使用 `spark-shell` 时，你不需要显式创建 `SparkSession`，因为它已经创建并且可以通过 `spark` 变量访问。
- en: 'Creating a DataFrame is probably the most important task in every data analytics
    task. Spark provides a `read()` method that can be used to read data from numerous
    sources in various formats such as CSV, JSON, Avro, and JDBC. For example, the
    following code snippet shows how to read a CSV file and create a Spark DataFrame:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 DataFrame 可能是每个数据分析任务中最重要的任务。Spark 提供了一个 `read()` 方法，可以用于从各种格式的多种来源读取数据，如
    CSV、JSON、Avro 和 JDBC。例如，以下代码片段显示了如何读取 CSV 文件并创建 Spark DataFrame：
- en: '[PRE4]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once a DataFrame is created, we can see a few samples (that is, rows) by invoking
    the `show()` method, as well as print the schema using the `printSchema()` method.
    Invoking `describe().show()` will show the statistics about the DataFrame:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了一个 DataFrame，我们就可以通过调用 `show()` 方法查看一些样本（即行），以及使用 `printSchema()` 方法打印模式。调用
    `describe().show()` 将显示 DataFrame 的统计信息：
- en: '[PRE5]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In many cases, we have to use the `spark.implicits._` package*,* which is one
    of the most useful imports. It is handy, with a lot of implicit methods for converting
    Scala objects to datasets and vice versa. Once we have created a DataFrame, we
    can create a view (temporary or global) for performing SQL using either the `ceateOrReplaceTempView()` method
    or the `createGlobalTempView()` method, respectively:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们必须使用 `spark.implicits._` 包*，这是最有用的导入之一。它很方便，提供了许多隐式方法，可以将 Scala 对象转换为数据集，反之亦然。一旦我们创建了一个
    DataFrame，我们就可以创建一个视图（临时或全局），以便使用 `createOrReplaceTempView()` 方法或 `createGlobalTempView()`
    方法执行 SQL：
- en: '[PRE6]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now a SQL query can be issued to see the data in tabular format:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以发出一个 SQL 查询来查看表格格式的数据：
- en: '[PRE7]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To drop these views, `spark.catalog.dropTempView("myTempDataFrame")` or `spark.catalog.dropGlobalTempView("myGloDataFrame")`,
    respectively, can be invoked. By the way, once you're done simply invoking the `spark.stop()`
    method, it will destroy the `SparkSession` and all the resources allocated by
    the Spark application. Interested readers can read detailed API documentation
    at [https://](https://spark.apache.org/)[spark.apache.org/](https://spark.apache.org/)
    to get more information.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除这些视图，分别可以调用 `spark.catalog.dropTempView("myTempDataFrame")` 或 `spark.catalog.dropGlobalTempView("myGloDataFrame")`。顺便说一句，一旦你调用了
    `spark.stop()` 方法，它将销毁 `SparkSession` 以及 Spark 应用程序分配的所有资源。感兴趣的读者可以阅读详细的 API 文档，请访问
    [https://](https://spark.apache.org/)[spark.apache.org/](https://spark.apache.org/)
    获取更多信息。
- en: Reading the training dataset
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取训练数据集
- en: 'There is a `Cryotherapy.xlsx` Excel file, which contains data as well as data
    usage agreement texts. So, I just copied the data and saved it in a CSV file named
    `Cryotherapy.csv`. Let''s start by creating `SparkSession`—the gateway to access
    Spark:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个名为 `Cryotherapy.xlsx` 的 Excel 文件，其中包含数据以及数据使用协议文本。因此，我只是复制了数据并将其保存到一个名为 `Cryotherapy.csv`
    的 CSV 文件中。让我们先创建 `SparkSession`——访问 Spark 的门户：
- en: '[PRE8]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then let''s read the training set and see a glimpse of it:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们读取训练集并看看它的一瞥：
- en: '[PRE9]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s take a look to see if the preceding CSV reader managed to read the data
    properly, including header and types:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看之前的 CSV 读取器是否成功正确地读取了数据，包括标题和数据类型：
- en: '[PRE10]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As seen from the following screenshot, the schema of the Spark DataFrame has
    been correctly identified. Also, as expected, all the features of my ML algorithms
    are numeric (in other words, in integer or double format):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下截图所示，Spark DataFrame 的模式已被正确识别。此外，正如预期的那样，我的机器学习算法的所有特征都是数值的（换句话说，是整数或双精度格式）：
- en: '![](img/6a21026d-dda3-4de9-b779-610209849628.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6a21026d-dda3-4de9-b779-610209849628.png)'
- en: 'A snapshot of the dataset can be seen using the `show()` method. We can limit
    the number of rows; here, let''s say `5`:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `show()` 方法查看数据集的快照。我们可以限制行数；这里，让我们说 `5`：
- en: '[PRE11]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output of the preceding line of code shows the first five samples of the
    DataFrame:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行代码的输出显示了 DataFrame 的前五个样本：
- en: '![](img/ca5ade58-f80c-4354-b9ad-a630145e1087.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca5ade58-f80c-4354-b9ad-a630145e1087.png)'
- en: Preprocessing and feature engineering
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理和特征工程
- en: 'As per the dataset description on the UCI machine learning repository, there
    are no null values. Also, the Spark ML-based classifiers expect numeric values
    to model them. The good thing is that, as seen in the schema, all the required
    fields are numeric (that is, either integers or floating point values). Also, the
    Spark ML algorithms expect a `label` column, which in our case is `Result_of_Treatment`.
    Let''s rename it to `label` using the Spark-provided `withColumnRenamed()` method:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 根据UCI机器学习仓库中的数据集描述，没有空值。此外，基于Spark ML的分类器期望模型化时使用数值。好事是，如方案所示，所有必需的字段都是数值（即整数或浮点值）。此外，Spark
    ML算法期望有一个`label`列，在我们的案例中是`Result_of_Treatment`。让我们使用Spark提供的`withColumnRenamed()`方法将其重命名为`label`：
- en: '[PRE12]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'All the Spark ML-based classifiers expect training data containing two objects
    called `label` (which we already have) and `features`. We have seen that we have
    six features. However, those features have to be assembled to create a feature
    vector. This can be done using the `VectorAssembler()` method. It is one kind
    of transformer from the Spark ML library. But first we need to select all the
    columns except the `label` column:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 所有基于Spark ML的分类器都期望包含两个对象的训练数据，称为`label`（我们已经有）和`features`。我们已经看到我们有六个特征。然而，这些特征必须被组装成特征向量。这可以通过使用`VectorAssembler()`方法来完成。它是Spark
    ML库中的一种转换器。但首先我们需要选择除了`label`列之外的所有列：
- en: '[PRE13]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then we instantiate a `VectorAssembler()` transformer and transform as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们实例化一个`VectorAssembler()`转换器，并按以下方式转换：
- en: '[PRE14]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As expected, the last line of the preceding code segment shows the assembled
    DataFrame having `label` and `features`, which are needed to train an ML algorithm:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，前面代码段的最后一行显示了组装好的DataFrame，其中包含`label`和`features`，这是训练ML算法所需的：
- en: '![](img/144b0868-c2b9-4a88-b5f4-9f29ed0b43ed.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/144b0868-c2b9-4a88-b5f4-9f29ed0b43ed.png)'
- en: Preparing training data and training a classifier
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备训练数据和训练分类器
- en: 'Next, we separate the training set and test sets. Let''s say that 80% of the
    training set will be used for the training and the other 20% will be used to evaluate
    the trained model:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将训练集和测试集分开。假设80%的训练集将用于训练，其余的20%将用于评估训练好的模型：
- en: '[PRE15]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Instantiate a decision tree classifier by specifying impurity, max bins, and
    the max depth of the trees. Additionally, we set the `label` and `feature` columns:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定不纯度、最大分箱数和树的深度来实例化一个决策树分类器。此外，我们设置了`label`和`feature`列：
- en: '[PRE16]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now that the data and the classifier are ready, we can perform the training:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据和分类器都准备好了，我们可以进行训练：
- en: '[PRE17]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Evaluating the model
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'Since it''s a binary classification problem, we need the `BinaryClassificationEvaluator()`
    estimator to evaluate the model''s performance on the test set:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个二元分类问题，我们需要`BinaryClassificationEvaluator()`估计器来评估模型在测试集上的性能：
- en: '[PRE18]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now that the training is completed and we have a trained decision tree model,
    we can evaluate the trained model on the test set:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练已完成，我们有一个训练好的决策树模型，我们可以在测试集上评估训练好的模型：
- en: '[PRE19]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, we compute the classification accuracy:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算分类准确率：
- en: '[PRE20]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You should experience about 96% classification accuracy:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该体验到大约96%的分类准确率：
- en: '[PRE21]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, we stop the `SparkSession` by invoking the `stop()` method:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过调用`stop()`方法来停止`SparkSession`：
- en: '[PRE22]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We have managed to achieve about 96% accuracy with minimum effort. However,
    there are other performance metrics such as precision, recall, and F1 measure.
    We will discuss them in upcoming chapters. Also, if you're a newbie to ML and
    haven't understood all the steps in this example, don't worry. We'll recap all
    of these steps in other chapters with various other examples.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过最少的努力实现了大约96%的准确率。然而，还有其他性能指标，如精确度、召回率和F1度量。我们将在接下来的章节中讨论它们。此外，如果您是机器学习的新手，并且没有完全理解这个示例中的所有步骤，请不要担心。我们将在其他章节中通过各种其他示例回顾所有这些步骤。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned some basic concepts of ML, which is used to
    solve a real-life problem. We started with a brief introduction to ML including
    a basic learning workflow, the ML rule of thumb, and different learning tasks,
    and then we gradually covered important ML tasks such as supervised learning,
    unsupervised learning, and reinforcement learning. Additionally, we discussed
    Scala-based ML libraries. Finally, we have seen how to get started with machine
    learning with Scala and Spark ML by solving a simple classification problem.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了一些机器学习（ML）的基本概念，这些概念用于解决现实生活中的问题。我们从一个对ML的简要介绍开始，包括基本的学习工作流程、ML的经验法则以及不同的学习任务，然后我们逐步涵盖了重要的ML任务，如监督学习、无监督学习和强化学习。此外，我们还讨论了基于Scala的ML库。最后，我们看到了如何通过解决一个简单的分类问题来开始使用Scala和Spark
    ML进行机器学习。
- en: Now that we know basic ML and Scala-based ML libraries, we can start learning
    in a more structured way. In the next chapter, we will learn about regression
    analysis techniques. Then we will develop a predictive analytics application for
    predicting slowness in traffic using linear regression and generalized linear
    regression algorithms.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了基本的ML和基于Scala的ML库，我们可以以更结构化的方式进行学习。在下一章中，我们将学习关于回归分析的技术。然后我们将开发一个预测分析应用程序，使用线性回归和广义线性回归算法来预测交通拥堵。
