- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Machine Learning and the Need for Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习和数据需求
- en: '**Machine learning** (**ML**) is the crown jewel of **artificial intelligence**
    (**AI**) and has changed our lives forever. We cannot imagine our daily lives
    without ML tools and services such as Siri, Tesla, and others.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）是**人工智能**（**AI**）的瑰宝，它永远地改变了我们的生活。我们无法想象没有ML工具和服务（如Siri、Tesla等）的日常生活。'
- en: In this chapter, you will be introduced to ML. You will understand the main
    differences between non-learning and learning-based solutions. Then, you will
    see why **deep learning** (**DL**) models often achieve state-of-the-art results.
    Following this, you will get a brief introduction to how the training process
    is done and why large-scale training data is needed in ML.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解机器学习（ML）。您将理解非学习型解决方案与基于学习型解决方案之间的主要区别。然后，您将了解到为什么**深度学习**（**DL**）模型通常能取得最先进的结果。在此之后，您将简要了解训练过程是如何进行的，以及为什么在机器学习中需要大规模的训练数据。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: AI, ML, and DL
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能、机器学习和深度学习
- en: Why are ML and DL so powerful?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么机器学习和深度学习如此强大？
- en: Training ML models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练机器学习模型
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Any code used in this chapter will be available in the corresponding chapter
    folder in this book’s GitHub repository: [https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning](https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的任何代码都将可在本书GitHub仓库的相应章节文件夹中找到：[https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning](https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning)。
- en: We will be using **PyTorch**, which is a powerful ML framework developed by
    Meta AI.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**PyTorch**，这是一个由Meta AI开发的强大机器学习框架。
- en: Artificial intelligence, machine learning, and deep learning
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能、机器学习和深度学习
- en: In this section, we learn what exactly ML is. We will learn to differentiate
    between learning and non-learning AI. However, before that, we’ll introduce ourselves
    to AI, ML, and DL.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习机器学习究竟是什么。我们将学习区分学习和非学习人工智能。然而，在那之前，我们将先介绍人工智能、机器学习和深度学习。
- en: Artificial intelligence (AI)
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能（AI）
- en: 'There are different definitions of AI. However, one of the best is John McCarthy’s
    definition. McCarthy was the first to coin the term *artificial intelligence*
    in one of his proposals for the 1956 Dartmouth Conference. He defined the outlines
    of this field by many major contributions such as the Lisp programming language,
    utility computing, and timesharing. According to the father of AI in *What is
    Artificial* *Intelligence?* ([https://www-formal.stanford.edu/jmc/whatisai.pdf](https://www-formal.stanford.edu/jmc/whatisai.pdf)):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能有各种各样的定义。然而，其中最好的一个是约翰·麦卡锡的定义。麦卡锡是第一个在1956年达特茅斯会议上的一项提案中提出“人工智能”这一术语的人。他通过诸如Lisp编程语言、效用计算和分时等许多重大贡献来勾勒出这一领域的轮廓。根据人工智能之父在《什么是人工智能？》([https://www-formal.stanford.edu/jmc/whatisai.pdf](https://www-formal.stanford.edu/jmc/whatisai.pdf))中的说法：
- en: It is the science and engineering of making intelligent machines, especially
    intelligent computer programs. It is related to the similar task of using computers
    to understand human intelligence, but AI does not have to confine itself to methods
    that are biologically observable.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 它是制造智能机器的科学和工程，特别是智能计算机程序。它与使用计算机理解人类智能的类似任务相关，但人工智能不必局限于生物可观察的方法。
- en: AI is about making computers, programs, machines, or others mimic or imitate
    human intelligence. As humans, we perceive the world, which is a very complex
    task, and we reason, generalize, plan, and interact with our surroundings. Although
    it is fascinating to master these tasks within just a few years of our childhood,
    the most interesting aspect of our intelligence is the ability to improve the
    learning process and optimize performance through experience!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能是关于使计算机、程序、机器或其他事物模仿或模拟人类智能的学科。作为人类，我们感知世界，这是一个非常复杂的任务，我们推理、归纳、规划和与周围环境互动。尽管在童年几年内掌握这些任务令人着迷，但我们的智能最有趣的一面是能够通过经验改进学习过程并优化性能！
- en: Unfortunately, we still barely scratch the surface of knowing about our own
    brains, intelligence, and other associated functionalities such as vision and
    reasoning. Thus, the trek of creating “intelligent” machines has just started
    relatively recently in civilization and written history. One of the most flourishing
    directions of AI has been learning-based AI.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们对自己大脑、智能以及其他相关功能（如视觉和推理）的了解仍然非常有限。因此，在文明和书写历史中，创建“智能”机器的旅程才刚刚开始。人工智能最繁荣的方向之一就是基于学习的AI。
- en: 'AI can be seen as an umbrella that covers two types of intelligence: learning
    and non-learning AI. It is important to distinguish between AI that improves with
    experience and one that does not!'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AI可以被视为一个涵盖两种智能的伞状概念：学习和非学习AI。区分随着经验提高的AI和不提高的AI非常重要！
- en: 'For example, let’s say you want to use AI to improve the accuracy of a physician
    identifying a certain disease, given a set of symptoms. You can create a simple
    recommendation system based on some generic cases by asking domain experts (senior
    physicians). The pseudocode for such a system is shown in the following code block:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你想使用AI来提高医生识别某种疾病准确性的能力，给定一组症状。你可以通过询问领域专家（资深医生）来创建一个基于一些通用案例的简单推荐系统。以下代码块展示了这样一个系统的伪代码：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This program mimics how a physician may reason for a similar scenario. Using
    simple `if-else` statements with few lines of code, we can bring “intelligence”
    to our program.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序模拟了医生可能对类似场景进行推理的方式。通过使用简单的`if-else`语句和几行代码，我们可以给我们的程序带来“智能”。
- en: Important note
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This is an example of non-learning-based AI. As you may expect, the program
    will not evolve with experience. In other words, the logic will not improve with
    more patients, though the program still represents a clear form of AI.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非学习型AI的例子。正如你所预期的那样，程序不会随着经验的积累而进化。换句话说，逻辑不会因为更多的患者而提高，尽管程序仍然代表了一种清晰的AI形式。
- en: In this section, we learned about AI and explored how to distinguish between
    learning and non-learning-based AI. In the next section, we will look at ML.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了AI，并探讨了如何区分基于学习和非学习型AI。在下一节中，我们将探讨ML。
- en: Machine learning (ML)
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习（ML）
- en: ML is a subset of AI. The key idea of ML is to enable computer programs to learn
    from experience. The aim is to allow programs to learn without the need to dictate
    the rules by humans. In the example of the AI doctor we saw in the previous section,
    the main issue is creating the rules. This process is extremely difficult, time-consuming,
    and error-prone. For the program to work properly, you would need to ask experienced/senior
    physicians to express the logic they usually use to handle similar patients. In
    other scenarios, we do not know exactly what the rules are and what mechanisms
    are involved in the process, such as object recognition and object tracking.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ML是AI的一个子集。ML的关键思想是使计算机程序能够从经验中学习。目标是让程序能够在不依赖人类制定规则的情况下学习。在前一节中我们看到的AI医生例子中，主要问题是创建规则。这个过程非常困难、耗时且容易出错。为了让程序正常工作，你需要让经验丰富的/资深医生表达他们通常用来处理类似患者的逻辑。在其他情况下，我们并不知道确切的规则以及涉及的过程机制，例如物体识别和物体跟踪。
- en: 'ML comes as a solution to learning the rules that control the process by exploring
    special training data collected for this task (see *Figure 1**.1*):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ML通过探索为这项任务收集的特殊训练数据来学习控制过程的规则（参见*图1**.1*）：
- en: '![Figure 1.1 – ML learns implicit rules from data](img/B18494_01_001.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – ML从数据中学习隐含规则](img/B18494_01_001.jpg)'
- en: Figure 1.1 – ML learns implicit rules from data
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – ML从数据中学习隐含规则
- en: 'ML has three major types: **supervised**, **unsupervised**, and **reinforcement
    learning**. The main difference between them comes from the nature of the training
    data used and the learning process itself. This is usually related to the problem
    and the available training data.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ML有三种主要类型：**监督学习**、**无监督学习**和**强化学习**。它们之间的主要区别来自于所使用的训练数据的性质和学习过程本身。这通常与问题和可用的训练数据有关。
- en: Deep learning (DL)
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习（DL）
- en: 'DL is a subset of ML, and it can be seen as the heart of ML (see *Figure 1**.2*).
    Most of the amazing applications of ML are possible because of DL. DL learns and
    discovers complex patterns and structures in the training data that are usually
    hard to do using other ML approaches, such as **decision trees**. DL learns by
    using **artificial neural networks** (**ANNs**) composed of multiple layers or
    too many layers (an order of 10 or more), inspired by the human brain; hence the
    *neural* in the name. It has three types of layers: input, output, and hidden.
    The input layer receives the input, while the output layer gives the prediction
    of the ANN. The hidden layers are responsible for discovering the hidden patterns
    in the training data. Generally, each layer (from the input to the output layers)
    learns a more abstract representation of the data, given the output of the previous
    layer. The more hidden layers your ANN has, the more complex and non-linear the
    ANN will be. Thus, ANNs will have more freedom to better approximate the relationship
    between the input and output or to learn your training data. For example, AlexNet
    is composed of 8 layers, VGGNet is composed of 16 to 19 layers, and ResNet-50
    is composed of 50 layers:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子集，它可以被视为机器学习的核心（见图1.2）。大多数机器学习的惊人应用都是由于深度学习才成为可能的。深度学习通过使用由多层或太多层（10层或更多）组成的**人工神经网络（ANNs**）来学习并发现训练数据中的复杂模式和结构，这些模式和结构通常难以使用其他机器学习方法（如**决策树**）来完成。深度学习通过模仿人脑的灵感，使用**人工神经网络**（ANNs）进行学习；因此，名字中的“神经”。它有三种类型的层：输入层、输出层和隐藏层。输入层接收输入，而输出层给出ANN的预测。隐藏层负责发现训练数据中的隐藏模式。一般来说，每一层（从输入层到输出层）都会学习数据的一个更抽象的表示，前提是前一层给出了输出。你的ANN有越多的隐藏层，ANN就越复杂和非线性。因此，ANN将有更多的自由度来更好地逼近输入和输出之间的关系，或者学习你的训练数据。例如，AlexNet由8层组成，VGGNet由16到19层组成，ResNet-50由50层组成：
- en: '![Figure 1.2 – How DL, ML, and AI are related](img/B18494_01_002.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 – 深度学习、机器学习和人工智能之间的关系](img/B18494_01_002.jpg)'
- en: Figure 1.2 – How DL, ML, and AI are related
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 深度学习、机器学习和人工智能之间的关系
- en: The main issue with DL is that it requires a large-scale training dataset to
    converge because we usually have a tremendous number of parameters (weights) to
    tweak to minimize the loss. In ML, loss is a way to penalize wrong predictions.
    At the same time, it is an indication of how well the model is learning the training
    data. Collecting and annotating such large datasets is extremely hard and expensive.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的主要问题是它需要一个大规模的训练数据集才能收敛，因为我们通常有大量的参数（权重）需要调整以最小化损失。在机器学习中，损失是一种惩罚错误预测的方法。同时，它也是模型学习训练数据的良好指示。收集和注释如此大规模的数据集非常困难且成本高昂。
- en: Nowadays, using synthetic data as an alternative or complementary to real data
    is a hot topic. It is a trending topic in research and industry. Many companies
    such as Google (Google’s Waymo utilizes synthetic data to train autonomous cars)
    and Microsoft (they use synthetic data to handle privacy issues with sensitive
    data) started recently to invest in using synthetic data to train next-generation
    ML models.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用合成数据作为真实数据的替代品或补充是一个热门话题。它在研究和行业中都是一个趋势话题。像谷歌（谷歌的Waymo利用合成数据来训练自动驾驶汽车）和微软（他们使用合成数据来处理敏感数据的隐私问题）这样的许多公司最近开始投资使用合成数据来训练下一代机器学习模型。
- en: Why are ML and DL so powerful?
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么机器学习和深度学习如此强大？
- en: Although most AI fields are flourishing and gaining more attention recently,
    ML and DL have been the most influential fields of AI. This is because of several
    factors that make them distinctly a better solution in terms of accuracy, performance,
    and applicability. In this section, we are going to look at some of these essential
    factors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最近大多数人工智能领域都在蓬勃发展并受到更多关注，但机器学习（ML）和深度学习（DL）一直是人工智能中最有影响力的领域。这是因为几个因素使它们在准确性、性能和适用性方面明显优于其他解决方案。在本节中，我们将探讨这些基本因素之一。
- en: Feature engineering
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: In traditional AI, it is compulsory to design the features *manually* for the
    task. This process is extremely difficult, time-consuming, and task/problem-dependent.
    If you want to write a program, say to recognize car wheels, you probably need
    to use some filters to extract edges and corners. Then, you need to utilize these
    extracted features to identify the target object. As you may anticipate, it is
    not always easy to know what features to select or ignore. Imagine developing
    an AI-based solution to predict if a patient has COVID-19 based on a set of symptoms
    at the early beginning of the pandemic. At that time, human experts did not know
    how to answer such questions. ML and DL can solve such problems.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统人工智能中，必须手动为任务设计特征。这个过程非常困难、耗时且与任务/问题相关。如果你想编写一个程序，比如识别汽车轮胎，你可能需要使用一些过滤器来提取边缘和角落。然后，你需要利用这些提取的特征来识别目标对象。正如你可能预料的，知道选择或忽略哪些特征并不总是容易。想象一下，在疫情初期，基于一组症状来预测患者是否患有COVID-19的基于人工智能的解决方案。当时，人类专家不知道如何回答这样的问题。机器学习和深度学习可以解决这样的问题。
- en: DL models learn to *automatically* extract useful features by learning hidden
    patterns, structures, and associations in the training data. A **loss** is used
    to guide the learning process and help the model achieve the objectives of the
    training process. However, for the model to converge, it needs to be exposed to
    sufficiently diverse training data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型通过学习训练数据中的隐藏模式、结构和关联来*自动*提取有用的特征。**损失**用于指导学习过程并帮助模型实现训练过程的目标。然而，为了使模型收敛，它需要接触到足够多样化的训练数据。
- en: Transfer across tasks
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务迁移
- en: 'One strong advantage of DL is that it’s more task-independent compared to traditional
    ML approaches. Transfer learning is an amazing and powerful feature of DL. Instead
    of training the model from scratch, you can start the training process using a
    different model trained on a similar task. This is very common in fields such
    as computer vision and natural language processing. Usually, you have a small
    dataset of your own target task, and your model would not converge using only
    this small dataset. Thus, training the model on a dataset close to the domain
    (or the task) but that’s sufficiently more diverse and larger and then fine-tuning
    on your task-specific dataset gives better results. This idea allows your model
    to transfer the learning between tasks and domains:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的一个显著优势是，与传统的机器学习方法相比，它更独立于任务。迁移学习是深度学习的一个神奇而强大的特性。你不需要从头开始训练模型，而是可以使用在类似任务上训练的不同模型开始训练过程。这在计算机视觉和自然语言处理等领域非常常见。通常，你有一个自己目标任务的小数据集，如果你的模型只使用这个小的数据集，那么它可能不会收敛。因此，在接近领域（或任务）但更加多样化、更大的数据集上训练模型，然后在特定任务的数据集上进行微调，可以得到更好的结果。这个想法允许你的模型在任务和领域之间迁移学习：
- en: '![Figure 1.3 – Advantages of ML and DL](img/B18494_01_003.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3 – 机器学习和深度学习的优势](img/B18494_01_003.jpg)'
- en: Figure 1.3 – Advantages of ML and DL
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 机器学习和深度学习的优势
- en: Important note
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If the problem is simple or a mathematical solution is available, then you probably
    do not need to use ML! Unfortunately, it is common to see some ML-based solutions
    proposed for problems where a clear explicit mathematical solution is already
    available! At the same time, it is not recommended to use ML if a simple rule-based
    solution works fine for your problem.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果问题简单或者有明确的数学解决方案，那么你可能不需要使用机器学习！不幸的是，对于已经有明确数学解决方案的问题，提出基于机器学习的解决方案是很常见的！同时，如果简单基于规则的解决方案已经足够解决你的问题，那么不建议使用机器学习。
- en: Training ML models
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练机器学习模型
- en: 'Developing an ML model usually requires performing the following essential
    steps:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 开发机器学习模型通常需要执行以下基本步骤：
- en: Collecting data.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集数据。
- en: Annotating data.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标注数据。
- en: Designing an ML model.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计机器学习模型。
- en: Training the model.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。
- en: Testing the model.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试模型。
- en: 'These steps are depicted in the following diagram:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤在以下图中展示：
- en: '![Figure 1.4 – Developing an ML model process](img/B18494_01_004.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4 – 开发机器学习模型过程](img/B18494_01_004.jpg)'
- en: Figure 1.4 – Developing an ML model process
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 开发机器学习模型过程
- en: Now, let’s look at each of the steps in more detail to better understand how
    we can develop an ML model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们更详细地看看每个步骤，以便更好地理解我们如何开发机器学习模型。
- en: Collecting and annotating data
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集和标注数据
- en: 'The first step in the process of developing an ML model is collecting the needed
    training data. You need to decide what training data is needed:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 开发机器学习模型的过程中的第一步是收集所需的训练数据。你需要决定需要哪些训练数据：
- en: '**Train using an existing dataset**: In this case, there’s no need to collect
    training data. Thus, you can skip collecting and annotating data. However, you
    should make sure that your target task or domain is quite similar to the available
    dataset(s) you are planning to deploy. Otherwise, your model may train well on
    this dataset, but it will not perform well when tested on the new task or domain.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用现有数据集进行训练**：在这种情况下，不需要收集训练数据。因此，你可以跳过收集和标注数据。然而，你应该确保你的目标任务或领域与计划部署的可用数据集非常相似。否则，你的模型可能在数据集上训练得很好，但在测试新任务或领域时表现不佳。'
- en: '**Train on an existing dataset and fine-tune on a new dataset**: This is the
    most popular case in today’s ML. You can pre-train your model on a large existing
    dataset and then fine-tune it on the new dataset. Regarding the new dataset, it
    does not need to be very large as you are already leveraging other existing dataset(s).
    For the dataset to be collected, you need to identify what the model needs to
    learn and how you are planning to implement this. After collecting the training
    data, you will begin the annotation process.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在现有数据集上训练并在新数据集上微调**：这是当今机器学习中最常见的情况。你可以在一个大的现有数据集上预训练你的模型，然后在新数据集上对其进行微调。关于新数据集，它不需要非常大，因为你已经在利用其他现有的数据集。对于要收集的数据集，你需要确定模型需要学习什么，以及你计划如何实现这一点。在收集训练数据后，你将开始标注过程。'
- en: '**Train from scratch on new data**: In some contexts, your task or domain may
    be far from any available datasets. Thus, you will need to collect large-scale
    data. Collecting large-scale datasets is not simple. To do this, you need to identify
    what the model will learn and how you want it to do that. Making any modifications
    to the plan later may require you to recollect more data or even start the data
    collection process again from scratch. Following this, you need to decide what
    ground truth to extract, the budget, and the quality you want.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在新数据上从头开始训练**：在某些情况下，你的任务或领域可能远离任何可用的数据集。因此，你需要收集大规模数据。收集大规模数据集并不简单。为此，你需要确定模型将学习什么，以及你希望它如何做到这一点。对计划进行任何修改可能需要你重新收集更多数据，甚至可能需要从头开始重新开始数据收集过程。随后，你需要决定提取哪些真实值、预算以及你希望的质量。'
- en: Next, we’ll explore the most essential element of an ML model development process.
    So, let’s learn how to design and train a typical ML model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨机器学习模型开发过程中最基本的一个要素。那么，让我们学习如何设计和训练一个典型的机器学习模型。
- en: Designing and training an ML model
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计和训练机器学习模型
- en: Selecting a suitable ML model for the problem a hand is dependent on the problem
    itself, any constraints, and the ML engineer. Sometimes, the same problem can
    be solved by different ML algorithms but in other scenarios, it is compulsory
    to use a specific ML model. Based on the problem and ML model, data should be
    collected and annotated.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为手头的问题选择合适的机器学习模型取决于问题本身、任何约束以及机器学习工程师。有时，同一个问题可以通过不同的机器学习算法来解决，但在其他情况下，使用特定的机器学习模型是强制性的。基于问题和机器学习模型，应该收集和标注数据。
- en: Each ML algorithm will have a different set of hyperparameters, various designs,
    and a set of decisions to be made throughout the process. It is recommended that
    you perform pilot or preliminary experiments to identify the best approach for
    your problem.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 每个机器学习算法都将有一组不同的超参数、各种设计和在整个过程中需要做出的决策。建议你进行试点或初步实验，以确定针对你问题的最佳方法。
- en: 'When the design process is finalized, the training process can start. For some
    ML models, the training process could take minutes, while for others, it could
    take weeks, months, or more! You may need to perform different training experiments
    to decide which training hyperparameters you are going to continue with – for
    example, the number of epochs or optimization techniques. Usually, the loss will
    be a helpful indication of how well the training process is going. In DL, two
    losses are used: training and validation loss. The first tells us how well the
    model is learning the training data, while the latter describes the ability of
    the model to generalize to new data.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当设计过程最终确定后，训练过程就可以开始了。对于某些机器学习模型，训练过程可能只需要几分钟，而对于其他模型，可能需要几周、几个月甚至更长时间！你可能需要执行不同的训练实验来决定你将继续使用哪些训练超参数——例如，训练轮数或优化技术。通常，损失函数将是一个有助于判断训练过程进行得如何的有用指标。在深度学习中，使用了两种损失函数：训练损失和验证损失。前者告诉我们模型学习训练数据的效果如何，而后者描述了模型泛化到新数据的能力。
- en: Validating and testing an ML model
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证和测试机器学习模型
- en: 'In ML, we should differentiate between three different datasets/partitions/sets:
    training, validation, and testing. The *training* set is used to teach the model
    about the task and assess how well the model is performing in the training process.
    The *validation* set is a proxy of the test set and is used to tell us the expected
    performance of our model on new data. However, the *test* set is the proxy of
    the actual world – that is, where our model will be tested. This dataset should
    only be deployed so that we know how the model will perform in practice. Using
    this dataset to change a hyperparameter or design option is considered cheating
    because it gives a deceptive understanding of how your model will be performing
    or generalizing in the real world. In the real world, once your model has been
    deployed, say for example in industry, you will not be able to tune the model’s
    parameters based on its performance!'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，我们应该区分三个不同的数据集/分区/集合：训练集、验证集和测试集。*训练集*用于教授模型关于任务的知识并评估模型在训练过程中的表现。*验证集*是测试集的代理，用于告诉我们模型在新数据上的预期性能。然而，*测试集*是实际世界的代理——也就是说，我们的模型将在那里接受测试。这个数据集应该仅用于部署，以便我们知道模型在实际应用中的表现。使用这个数据集来改变超参数或设计选项被认为是作弊，因为它会误导你对模型在现实世界中的表现或泛化能力的理解。在现实世界中，一旦你的模型被部署，比如在工业界，你将无法根据其性能调整模型的参数！
- en: Iterations in the ML development process
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习开发过程中的迭代
- en: In practice, developing an ML model will require many iterations between validation
    and testing and the other stages of the process. It could be that validation or
    testing results are unsatisfactory and you decide to change some aspects of the
    data collection, annotation, designing, or training.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，开发一个机器学习模型将需要在验证、测试以及其他流程阶段之间进行多次迭代。可能验证或测试结果不尽如人意，你决定改变数据收集、标注、设计或训练的一些方面。
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the terms AI, ML, and DL. We uncovered some advantages
    of ML and DL. At the same time, we learned the basic steps for developing and
    training ML models. Finally, we learned why we need large-scale training data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了人工智能（AI）、机器学习（ML）和深度学习（DL）等术语。我们揭示了机器学习和深度学习的一些优势。同时，我们学习了开发和管理机器学习模型的基本步骤。最后，我们学习了为什么我们需要大规模的训练数据。
- en: In the next chapter, we will discover the main issues with annotating large-scale
    datasets. This will give us a good understanding of why synthetic data is the
    future of ML!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨标注大规模数据集时遇到的主要问题。这将使我们更好地理解为什么合成数据是机器学习（ML）的未来！
