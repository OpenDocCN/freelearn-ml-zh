- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Deep Learning for Time-Series
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列的深度学习
- en: Deep learning is a subfield of machine learning concerned with algorithms relating
    to neural networks. Neural networks, or, more precisely, **artificial neural networks**
    (**ANNs**) got their name because of the loose association with biological neural
    networks in the human brain.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子领域，关注与神经网络相关的算法。神经网络，或者更准确地说，**人工神经网络**（**ANNs**），得名于它们与人类大脑中生物神经网络的松散关联。
- en: In recent years, deep learning has been enhancing the state of the art across
    the bench in many application domains. This is true for unstructured datasets
    such as text, images, video, and audio; however, tabular datasets and time-series
    have so far shown themselves to be less amenable to deep learning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习在多个应用领域推动了技术的进步。对于非结构化数据集，如文本、图像、视频和音频，这一点尤为明显；然而，表格数据集和时间序列迄今为止对深度学习的适应性较差。
- en: Deep learning brings a very high level of flexibility and can offer advantages
    of both online learning, as discussed in *Chapter 8*, *Online Learning for Time-Series*,
    and probabilistic approaches, as discussed in *Chapter 9*, *Probabilistic Models
    for Time-Series*. However, with its highly parameterized models, finding the right
    model can be a challenge.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习提供了非常高的灵活性，并且能够结合*第8章*中讨论的在线学习（*时间序列的在线学习*）和*第9章*中讨论的概率方法（*时间序列的概率模型*）的优势。然而，由于其高度参数化的模型，找到合适的模型可能会是一个挑战。
- en: Among the contributions deep learning has been able to bring to time-series
    are data augmentation, transfer learning, long sequence time-series forecasts,
    and data generation with **generative adversarial networks** (**GANs**). However,
    it's only very recently that deep learning approaches have become competitive
    in relation to forecasting, classification, and regression tasks.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习为时间序列带来的贡献包括数据增强、迁移学习、长时间序列的预测、以及使用**生成对抗网络**（**GANs**）的数据生成。然而，直到最近，深度学习方法在预测、分类和回归任务中才变得具有竞争力。
- en: In this chapter, we'll discuss deep learning applied to time-series, looking,
    in particular, at algorithms and approaches designed for time-series. We'll get
    into current challenges, promising avenues of research, and competitive approaches
    that bring deep learning to time-series. We'll go into detail about a lot of the
    recent innovations in deep learning for time-series.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将讨论应用于时间序列的深度学习，特别是针对时间序列设计的算法和方法。我们将探讨当前的挑战、前景广阔的研究方向以及将深度学习引入时间序列的竞争性方法。我们将详细介绍深度学习在时间序列领域的最新创新。
- en: 'We''re going to cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Introduction to deep learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习简介
- en: Deep learning for time-series
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列的深度学习
- en: Autoencoders
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自编码器
- en: InceptionTime
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: InceptionTime
- en: DeepAR
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeepAR
- en: N-BEATS
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: N-BEATS
- en: Recurrent neural networks
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: ConvNets
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络（ConvNets）
- en: Transformer architectures
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Transformer架构
- en: Informer
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Informer
- en: Python practice
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python实践
- en: Fully connected network
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全连接网络
- en: Recurrent neural network
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: Dilated causal convolutional neural network
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 膨胀因果卷积神经网络
- en: Let's start with an introduction to deep learning and the core concepts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从深度学习及其核心概念的介绍开始。
- en: Introduction to deep learning
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习简介
- en: Deep learning is based on fundamental concepts that find their roots early in
    the 20^(th) century – the wiring between neurons. Neurons communicate chemically
    and electrically through so-called neurites.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习基于一些早在20世纪初就出现的基础概念——神经元之间的连接。神经元通过所谓的神经突起在化学和电气方面进行交流。
- en: This wiring was first described and drawn by Santiago Ramón y Cajal, a Spanish
    neuroscientist. He charted the anatomy of the brain and the structure of neural
    networks in the brain. He received the Nobel Prize in Physiology or Medicine in
    1906, which he shared with Camillo Golgi, who invented the stains for neurons
    based on potassium dichromate and silver nitrate that Ramón y Cajal applied in
    his microscopy studies.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这种神经网络的连接图首次由西班牙神经科学家圣地亚哥·拉蒙·卡哈尔（Santiago Ramón y Cajal）描述和绘制。他绘制了大脑的解剖图以及大脑神经网络的结构。他因在生理学或医学领域的贡献，于1906年获得诺贝尔奖，与卡米洛·戈尔吉（Camillo
    Golgi）共享该奖项，戈尔吉发明了用于神经元染色的钾二铬酸盐和硝酸银染色法，而拉蒙·卡哈尔在显微镜研究中应用了这些染色方法。
- en: 'The chart below is just one of his elaborate drawings of the arborization of
    neural connections (called neurites – dendrites and axons) between neurons in
    the brain (source Wikimedia Commons):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表仅仅是他精心绘制的神经元之间神经连接的树突状分支（称为神经突起——树突和轴突）图（来源：Wikimedia Commons）：
- en: '![ile:Debuixos Santiago Ramón y Cajal.jpg](img/B17577_10_01.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![ile:Debuixos Santiago Ramón y Cajal.jpg](img/B17577_10_01.png)'
- en: 'Figure 10.1: Ramon y Cajal''s drawing of networks of neurons in the brain'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：Ramon y Cajal绘制的大脑中神经元网络图
- en: In the schematic, you can appreciate neurons as gray dots in layers of the brain.
    Between neurons are dendrites and axons, the wiring of the brain. Each neuron
    takes up what amounts to information about the environment through gate stations
    to neurites that are called synapses.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在示意图中，您可以看到神经元作为大脑各层中的灰色点。在神经元之间是树突和轴突，大脑的“线路”。每个神经元通过门控站接收环境信息，然后将其传递到称为突触的神经突起。
- en: Ramón y Cajal and his pupils brought to life *cable theory*, where the electric
    current passing through neurites is modeled by mathematical models. The voltage
    arriving at neural sites through the dendrites that receive synaptic inputs at
    different sites and times was recognized as sensory and other information was
    transmitted between cells. This is the foundation of today's detailed neuron models
    employed in research to model synaptic and neural responses.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Ramón y Cajal及其学生们提出了*电缆理论*，其中神经突起上通过电流传递的电流被数学模型建模。通过树突接收到来自不同部位和时间的突触输入的电压被认定为感觉和其他信息在细胞之间传递。这为今天在研究中使用的详细神经元模型奠定了基础，用于模拟突触和神经反应。
- en: The basic function of neurons was formalized by Frank Rosenblatt in 1958 as
    the perceptron – a model that contains the essentials of most modern deep learning
    concepts.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元的基本功能由Frank Rosenblatt于1958年正式化为感知机——一个包含现代大多数深度学习概念精髓的模型。
- en: '![../perceptron.png](img/B17577_10_02.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![../perceptron.png](img/B17577_10_02.png)'
- en: 'Figure 10.2: The perceptron model'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：感知机模型
- en: In the perceptron model, a neuron – illustrated by the oval in the middle –
    receives input from other neurons. In a model, these inputs could represent text,
    images, sounds, or any other type of information. These get integrated by summing
    them up. In this sum, each input from a neuron, *i*, comes with its weight, *w*[i],
    that marks its importance. This integrated input can then lead to a neural activation
    as given by the neuron's activation function, *g*.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在感知机模型中，一个神经元——图中间的椭圆——接收来自其他神经元的输入。在模型中，这些输入可以代表文本、图像、声音或任何其他类型的信息。这些输入通过求和的方式进行整合。在这个和中，每个来自神经元*i*的输入都有一个权重*w*[i]，表示它的重要性。这个整合后的输入可以通过神经元的激活函数*g*来引发神经激活。
- en: In the simplest case, the activation function could just be a threshold function
    so that the neuron gets activated if the weighted sum of the inputs exceeds a
    certain value. In modern neural networks, the activation functions are non-linear
    functions, such as sigmoid functions or the rectified linear function where the
    output is linear above a threshold and cropped below.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在最简单的情况下，激活函数可以只是一个阈值函数，当输入的加权和超过某个值时，神经元会被激活。在现代神经网络中，激活函数是非线性函数，例如sigmoid函数或修正线性函数，其中输出在阈值以上是线性的，而阈值以下被裁剪。
- en: When the network is stimulated by data, input neurons are activated and feed
    second-order neurons, which then feed other neurons in turn until the output layers
    are activated. This is called *feedforward propagation*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络受到数据刺激时，输入神经元被激活，并将信号传递给二级神经元，随后再传递给其他神经元，直到激活输出层。这被称为*前向传播*。
- en: The perceptron consisted of a single layer of integrating neurons that sum input
    over their incoming connections. It was demonstrated by Marvin Minsky and Seymour
    Pappert in their book *Perceptrons* (1969) that these neurons, similar to a simple
    linear model, cannot approximate complex functions that are relevant in the real
    world.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机由一层集成神经元组成，这些神经元通过它们的输入连接对输入进行求和。Marvin Minsky和Seymour Pappert在他们的著作《感知机》（1969）中证明，这些神经元类似于简单的线性模型，无法逼近现实世界中复杂的函数。
- en: Multilayer neural networks can overcome this limitation, however, and this is
    where we slowly enter into the realm of deep learning. These networks can be trained
    through an algorithm called *backpropagation* – often credited to Paul Werbos
    (1975). In backpropagation, outputs can be compared to targets and the error derivative
    can be fed back through the network to calculate adjustments to the weights in
    the connections.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，多层神经网络可以克服这一限制，这也正是我们逐步进入深度学习领域的地方。这些网络可以通过一种称为*反向传播*的算法进行训练——通常归功于Paul Werbos（1975）。在反向传播中，可以将输出与目标进行比较，并将误差导数反馈到网络中，以计算连接中权重的调整。
- en: 'Another innovation in neural networks again comes from neuroscience. In the
    1950s and 1960s, David Hubel and Torsten Wiesel found that neurons in the cat
    visual cortex (V1) respond to small regions of the visual field. This region they
    termed the receptive field (1959, "Receptive fields of single neurons in the cat''s
    striate cortex"). They distinguished between two basic cell types:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的另一个创新再次来源于神经科学。在1950年代和1960年代，David Hubel和Torsten Wiesel发现，猫视觉皮层（V1）中的神经元对视觉场的局部区域做出反应。他们称这一区域为感受野（1959年，“猫条纹皮层中单个神经元的感受野”）。他们区分了两种基本细胞类型：
- en: Simple cells – these cells can be characterized largely by a summation over
    the inputs
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单细胞——这些细胞的特征主要是对输入的求和
- en: Complex cells – cells that respond to a variety of stimuli across different
    locations
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂细胞——对不同位置的多种刺激做出反应的细胞
- en: Complex cells have inspired computational layers in neural networks that employ
    convolutions, first by Kunihiko Fukushima in 1980\. We've discussed convolutions
    in *Chapter 3*, *Preprocessing Time-Series*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂细胞启发了神经网络中采用卷积的计算层，最早由Kunihiko Fukushima于1980年提出。我们在*第3章*《时间序列预处理》中讨论了卷积。
- en: Neural networks with convolutional layers are the predominant type of model
    for applications such as image processing, classification, and segmentation. Yann
    LeCun and colleagues introduced the LeNet architecture (1989), where convolution
    kernels are learned through backpropagation for the classification of images of
    hand-written numbers.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 具有卷积层的神经网络是图像处理、分类和分割等应用中主要的模型类型。Yann LeCun及其同事在1989年提出了LeNet架构，其中通过反向传播学习卷积核，用于手写数字图像的分类。
- en: Deep learning networks often come not just with layers, where inputs get propagated
    from one layer to the next (feedforward). The connections can also be recurrent,
    where they connect to the neurons of the same layer or even back to the same neuron.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习网络通常不仅仅由层构成，输入从一层传播到下一层（前馈）。这些连接也可以是递归的，连接到同一层的神经元，甚至回到同一神经元。
- en: A recurrent neural network framework, **long short-term memory** (**LSTM**)
    was proposed by Jürgen Schmidhuber and Sepp Hochreiter in 1997\. LSTMs can retrieve
    and learn information for a longer period of time compared to previous models.
    This model architecture was, for some time, powering industry models such as speech
    recognition software for Android smartphones, but has since been mostly replaced
    by convolutional models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一种递归神经网络框架，**长短期记忆**（**LSTM**）由Jürgen Schmidhuber和Sepp Hochreiter于1997年提出。与之前的模型相比，LSTM能够在更长时间内检索和学习信息。该模型架构曾一度驱动着行业模型，如Android智能手机的语音识别软件，但后来大多被卷积模型取代。
- en: In 2012, AlexNet, created by Alex Krizhevsky in collaboration with Ilya Sutskever
    and Geoffrey Hinton, made a breakthrough in the ImageNet Large Scale Visual Recognition
    Challenge (short ImageNet), where millions of images are to be categorized between
    20,000 categories. AlexNet brought down the top-5 error rate from around 25% to
    about 15%. The model, utilizing massively parallel hardware powered by **Graphics
    Processing Units** (**GPUs**), combined fully connected layers with convolutions
    and pooling layers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 2012年，AlexNet由Alex Krizhevsky与Ilya Sutskever和Geoffrey Hinton合作创建，在ImageNet大规模视觉识别挑战赛（简称ImageNet）中取得突破，在该比赛中，数百万张图像需要被归类到20,000个类别中。AlexNet将Top-5错误率从大约25%降至约15%。该模型利用由**图形处理单元**（**GPU**）驱动的大规模并行硬件，将全连接层与卷积层和池化层结合起来。
- en: This was only the beginning of a radical performance improvement on different
    tasks, including images. The AlexNet performance was beaten the following year
    by ResNet.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是对不同任务（包括图像）的性能极大提升的开始。AlexNet的性能在第二年被ResNet超越。
- en: Since the ResNet paper is highly influential, it's worth taking a short detour
    to explain how it works. ResNets were introduced by Kaiming He and others at Microsoft
    Research in 2015 ("*Deep Residual Learning for Image Recognition*"). A common
    problem with deep neuron networks is that their performance can saturate and degrade
    with more layers added partly because of the vanishing gradient problem, where
    the error gradient calculated in the optimization will become too small to be
    useful.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于ResNet论文具有重要影响力，值得稍作绕道来解释它是如何工作的。ResNet由Kaiming He和微软研究院的其他人于2015年提出（“*深度残差学习用于图像识别*”）。深度神经网络的一个常见问题是，随着更多层的添加，其性能可能会饱和并退化，部分原因是梯度消失问题，在该问题中，优化中计算的误差梯度变得太小，无法发挥作用。
- en: 'Inspired by pyramidal cells in the brain, residual neural networks employ so-called
    *skip connections*, essentially shortcuts to jump intermediate layers. A ResNet
    is a network that contains blocks with skip connections (residual blocks), as
    indicated in this schema:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 受到大脑金字塔细胞的启发，残差神经网络采用了所谓的*跳跃连接*，基本上是跳过中间层的捷径。ResNet是包含跳跃连接（残差块）的网络，如下图所示：
- en: '![../resnet%20(2).png](img/B17577_10_03.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![../resnet%20(2).png](img/B17577_10_03.png)'
- en: 'Figure 10.3: Residual block with skip connections'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：带跳跃连接的残差块
- en: 'In the residual block illustrated, the output of layer 2 is as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在所示的残差块中，第二层的输出如下：
- en: '![](img/B17577_10_001.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_10_001.png)'
- en: where ![](img/B17577_10_002.png) and ![](img/B17577_10_003.png) are the activation
    functions in layer 2 and the skip connections, respectively. ![](img/B17577_10_004.png)
    is often the identify function, where activations of layer 1 are unchanged. If
    the dimensionality between layer 1 and layer 2 outputs don't match, either padding
    or convolutions are used.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/B17577_10_002.png) 和 ![](img/B17577_10_003.png) 分别是第二层的激活函数和跳跃连接。![](img/B17577_10_004.png)
    通常是恒等函数，其中第一层的激活值保持不变。如果第一层和第二层的输出维度不匹配，则会使用填充或卷积。
- en: 'With these skip connections, Kaiming He and others successfully trained networks
    with as many as 1,000 layers. The original ResNet from 2015 was very successful
    on images. Among other accolades it collected was winning several top competitions
    for image classification and object detection: ILSVRC 2015, ILSVRC 2015, COCO
    2015 competition in ImageNet Detection, ImageNet localization, Coco detection,
    and Coco segmentation.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些跳跃连接，何凯明等人成功训练了包含多达1000层的网络。2015年发布的原始ResNet在图像处理方面非常成功。它赢得了多个图像分类和目标检测的顶级竞赛奖项：ILSVRC
    2015，ILSVRC 2015，COCO 2015竞赛中的ImageNet检测，ImageNet定位，Coco检测和Coco分割等。
- en: 'I''ve summarized the early history of ANNs and deep learning in the timeline
    here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里总结了人工神经网络和深度学习的早期历史：
- en: '![../timeline%20of%20deep%20learning%20(2).png](img/B17577_10_04.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![../timeline%20of%20deep%20learning%20(2).png](img/B17577_10_04.png)'
- en: 'Figure 10.4: Timeline of artificial neural networks and deep learning'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4：人工神经网络与深度学习的时间轴
- en: Please note that this is highly simplified, leaving out many important milestones.
    I've ended in 2015, when ResNet was presented.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这只是一个高度简化的版本，省略了许多重要的里程碑。我将时间轴结束于2015年，当时ResNet首次发布。
- en: 'There are a host of architectures and approaches in deep learning, and this
    chart displays a typology of these methodologies:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中有许多架构和方法，本图展示了这些方法的类型学：
- en: '![deep%20learning%20models.png](img/B17577_10_05.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![deep%20learning%20models.png](img/B17577_10_05.png)'
- en: 'Figure 10.5: Typology of deep learning approaches'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：深度学习方法的类型学
- en: We've mentioned a few of these approaches in this section, and we'll explain
    a few of these methods in more detail in the next sections as they are relevant
    to time-series.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中提到了一些方法，接下来的章节将更详细地解释其中的一些方法，因为它们与时间序列相关。
- en: The computational complexity of techniques based on deep neural networks is
    driven in the first instance by the dimension of the input data and depends on
    the number of hidden layers trained using backpropagation. High-dimensional data
    tend to require more hidden layers to ensure a higher hierarchy of feature learning,
    where each layer derives higher-level features based on the previous level. The
    training time and complexity increase with the number of neurons – the number
    of hyperparameters can sometimes reach the millions or billions.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度神经网络的技术的计算复杂性，首先由输入数据的维度驱动，并且取决于通过反向传播训练的隐藏层数量。高维数据往往需要更多的隐藏层，以确保更高层次的特征学习，每一层基于上一层提取更高层次的特征。随着神经元数量的增加，训练时间和复杂性也会增加—有时超参数的数量可达到数百万或数十亿。
- en: The representational power of deep learning that constructs a stack of derived
    features as part of the learning allows modelers to get away from hand-crafted
    features. Further advantages of using deep learning models include their flexibility
    in terms of choosing architecture, hyperparameters such as activation functions,
    regularization, layer sizes, and loss objectives, but this is traded off against
    their complexity in terms of the number of parameters, and the difficulty of interrogating
    their inner workings.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的表示能力通过构建一系列派生特征作为学习的一部分，使模型能够摆脱手工制作的特征。使用深度学习模型的进一步优势包括其在选择架构、超参数（如激活函数、正则化、层大小和损失目标）方面的灵活性，但这与其参数数量的复杂性以及难以探查其内部工作原理之间的权衡。
- en: Deep learning methods offer better representation and, in consequence, prediction
    on a multitude of time-series datasets compared to other machine learning approaches;
    however, they haven't found the impact so far that they had in other areas.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他机器学习方法相比，深度学习方法在多个时间序列数据集上提供了更好的表示和预测；然而，到目前为止，它们尚未在其他领域取得的影响。
- en: Deep learning for time-series
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列的深度学习
- en: Recent years have seen a proliferation of deep neural networks, with unprecedented
    improvements across various application domains, in particular images, natural
    language processing, and sound. The potential advantage of deep learning models
    is that they can be much more accurate than other types of models, thereby pushing
    the envelope in domains such as vision, sound, and **natural language processing**
    (**NLP**).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度神经网络得到了广泛应用，在各个应用领域取得了前所未有的改进，特别是在图像、自然语言处理和声音领域。深度学习模型的潜在优势在于，它们比其他类型的模型更准确，从而推动了视觉、声音和**自然语言处理**（**NLP**）等领域的进展。
- en: In forecasting, especially demand forecasting, data is often highly erratic,
    discontinuous, or bursty, which violates the core assumptions of classical techniques,
    such as Gaussian errors, stationarity, or homoscedasticity, as discussed in *Chapter
    5*, *Forecasting of Time-Series*. Deep learning techniques applied to forecasting,
    classification, or regression tasks could overcome many of the challenges faced
    by classical approaches, and, most importantly, they could provide a way to model
    non-linear dynamics usually neglected by traditional methods such as Box-Jenkins,
    Exponential Smoothing (ES), or state-space models.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测中，特别是需求预测，数据通常是高度不稳定、不连续或突发的，这违反了经典技术的核心假设，如高斯误差、平稳性或同方差性，正如*第5章*中所讨论的《时间序列预测》。应用于预测、分类或回归任务的深度学习技术可以克服经典方法面临的许多挑战，最重要的是，它们可以提供一种建模非线性动态的方法，而这些动态通常被传统方法（如Box-Jenkins、指数平滑（ES）或状态空间模型）忽视。
- en: Many deep learning algorithms have been applied more recently to time-series,
    both with univariate and multivariate time-series. The model architectures encompass
    recurrent neural networks (RNNs), most prominently long short-term memory (LSTM)
    models, and transformer and convolutional models, or different types of autoencoders.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，许多深度学习算法被应用于时间序列，包括单变量和多变量时间序列。模型架构包括递归神经网络（RNN），最显著的是长短期记忆（LSTM）模型，以及变换器和卷积模型，或不同类型的自编码器。
- en: As regards their application to time-series, however, they haven't been able
    to challenge the top models in the field. For instance, as pointed out by Spyros
    Makridakis and others (2020), in the M4 competition, arguably the most important
    benchmark for univariate time-series forecasting, the best-ranking methods were
    ensembles of widely used classical statistical techniques rather than pure machine
    learning methods.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关于它们在时间序列中的应用，它们还未能挑战该领域的顶级模型。例如，正如Spyros Makridakis等人（2020）所指出的，在M4竞赛中，作为单变量时间序列预测的最重要基准，排名最高的方法是广泛使用的经典统计技术的集成，而不是纯粹的机器学习方法。
- en: This could have been at least partly due to the nature of the competition. As
    pointed out by Slawek Smyl, de-seasonalization of seasonal series was very important
    in the M4 competition, given that the series were provided as scalar vectors without
    timestamps, so there was no way to incorporate calendar features such as the day
    of the week or the month number.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这至少部分可能与竞争的性质有关。正如Slawek Smyl所指出的，季节性系列的去季节化在M4竞赛中非常重要，因为这些系列以标量向量的形式提供，没有时间戳，因此无法加入日历特征，如星期几或月份。
- en: 'In the M4 competition, out of 60 competition entries, the first machine learning
    method ranked at place 23\. However, interestingly, the winner of the M4 competition
    was a hybrid between a dilated LSTM with attention and a Holt-Winters statistical
    model. Another top contender, developed by the research group around Rob Hyndman,
    applied a gradient boosted tree ensemble to outputs from traditional models (*FFORMA:
    Feature-based Forecast Model Averaging*, 2020).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在M4竞赛中，在60个参赛作品中，排名第23的机器学习方法为首。然而，值得注意的是，M4竞赛的获胜者是一个基于扩展LSTM和注意力机制与Holt-Winters统计模型的混合模型。另一个竞争者，由Rob
    Hyndman团队开发，使用了基于梯度提升树的集成方法，将传统模型的输出作为输入（*FFORMA：基于特征的预测模型平均*，2020）。
- en: These rankings led Spyros Makridakis and others to conclude that hybrids or
    mixtures of classical and machine learning methods are the way forward. The search
    is ongoing for a deep learning architecture that could provide an inflection point
    in research and applications similar to that of AlexNet or Inception for the image
    domain.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这些排名让Spyros Makridakis等人得出结论，混合或结合传统与机器学习方法是未来的方向。目前正在寻找一种深度学习架构，能够为研究和应用带来类似AlexNet或Inception在图像领域的转折点。
- en: In *Chapter 4*, *Introduction to Machine Learning with Time-Series*, we discussed
    first how difficult it is to beat baseline approaches such as Nearest Neighbor
    with **Dynamic Time Warping** (**DTW**) and then state-of-the-art approaches.
    The most competitive model in terms of performance is **HIVE-COTE** (**Hierarchical
    Vote Collective of Transformation-Based Ensembles**), which consists of ensembles
    of machine learning models – very expensive in terms of resources, owing to the
    number of computations and the long runtime.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第4章*，*时间序列机器学习导论*中，我们首先讨论了击败基准方法（如最近邻算法结合**动态时间规整**（**DTW**））的难度，然后是最先进的方法。从性能角度来看，最具竞争力的模型是**HIVE-COTE**（**基于变换集成的层次投票集合**），它由多个机器学习模型的集成组成——由于计算量大且运行时间长，资源消耗非常高。
- en: The sardonic reader might comment that this sounds like deep learning already
    and ask whether deep learning hasn't already taken over as the state-of-the-art
    method. Generally speaking, the complexity of deep learning models is much higher
    than that of traditional models or other machine learning techniques. The case
    can be made that this is one of the biggest distinguishing characteristics of
    deep learning models.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 挖苦的读者可能会评论说，这听起来已经像深度学习了，并质疑深度学习是否已经取代了作为最先进方法的地位。一般来说，深度学习模型的复杂度远高于传统模型或其他机器学习技术。这可以说是深度学习模型最大的特点之一。
- en: Is there a deep learning model architecture of similar or lower complexity than
    HIVE that can achieve competitive results?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 是否存在比HIVE更简单或相似复杂度的深度学习模型架构，能够达到竞争力的结果？
- en: 'I''ve summarized a few libraries that implement algorithms with deep learning
    for time-series in this table:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我已将一些实现时间序列深度学习算法的库汇总在此表中：
- en: '| Library | Maintainer | Algorithms | Framework |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 库 | 维护者 | 算法 | 框架 |'
- en: '| dl-4-tsc | Hassan Ismail Fawaz | **Multi-Layer Perceptron** (**MLP**), **Fully
    Connected Network** (**FCN**), ResNet, Encoder (based on CNN), **Multi-Scale Convolutional
    Neural Network** (**MCNN**), **Time Le-Net** (**t-LeNet**), **Multi-Channel Deep
    Convolutional Neural Network** (**MCDCNN**), Time-CNN, **Time Warping Invariant
    Echo State Network** (**TWIESN**), InceptionTime | TensorFlow/Keras |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| dl-4-tsc | Hassan Ismail Fawaz | **多层感知机**（**MLP**），**全连接网络**（**FCN**），ResNet，编码器（基于CNN），**多尺度卷积神经网络**（**MCNN**），**时间Le-Net**（**t-LeNet**），**多通道深度卷积神经网络**（**MCDCNN**），时间CNN，**时间规整不变回声状态网络**（**TWIESN**），InceptionTime
    | TensorFlow/Keras |'
- en: '| Sktime-DL | Students and staff at the University of East Anglia around Tony
    Bagnell | ResNet, CNN, InceptionTime (through an interface with another library)
    | TensorFlow/Keras |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Sktime-DL | 英国东安格利亚大学的Tony Bagnell团队 | ResNet，CNN，InceptionTime（通过与其他库的接口）
    | TensorFlow/Keras |'
- en: '| Gluon-TS | Amazon Web Services – Labs | Gluon-TS specializes in probabilistic
    neural network models such as these: **Convolutional Neural Network** (**CNN**),
    DeepAR, **Recurrent Neural Network** (**RNN**), **Multi-Layer Perceptron** (**MLP**)
    | MXNET |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| Gluon-TS | 亚马逊网络服务实验室 | Gluon-TS专注于概率神经网络模型，如：**卷积神经网络**（**CNN**），DeepAR，**循环神经网络**（**RNN**），**多层感知机**（**MLP**）
    | MXNET |'
- en: '| Pytorch Forecasting | Daniel Hoyos and others | Recurrent Networks (GRU,
    LSTM), Temporal Fusion Transformers, N-Beats, Multilayer Perceptron, DeepAR |
    PyTorch Lightning |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Pytorch Forecasting | Daniel Hoyos 等人 | 循环网络（GRU，LSTM）、时序融合变换器、N-Beats、多层感知器、DeepAR
    | PyTorch Lightning |'
- en: 'Figure 10.6: Overview of several deep learning libraries for time-series'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6：几个深度学习库在时间序列中的概览
- en: Sktime-DL is an extension to sktime, maintained by the same research group.
    As of August 2021, this library is undergoing a rewrite.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Sktime-DL 是 sktime 的扩展，由同一研究小组维护。到 2021 年 8 月，该库正在重写中。
- en: Gluon-TS is based on the MXNET deep learning modeling framework, and – apart
    from the network architectures noted in the table – includes many other features,
    such as kernels for **Support Vector Machines** (**SVMs**) and **Gaussian Process**
    (**GP**), and distributions for probabilistic network models.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Gluon-TS 基于 MXNET 深度学习建模框架，除了表格中列出的网络架构外，还包含许多其他功能，如**支持向量机**（**SVMs**）和**高斯过程**（**GP**）的内核，以及用于概率网络模型的分布。
- en: '*dl-4-tsc* is the GitHub companion repository for a review paper of many time-series
    deep learning algorithms, prepared by Hassan Ismail Fawaz and others (2019). It
    includes implementations in TensorFlow/Keras of their implementations. It is not
    a library *per se*, as it isn''t installed like a library and the models run with
    datasets; however, since the algorithms are implemented in TensorFlow and Keras,
    anyone with a knowledge of these will feel at home.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*dl-4-tsc* 是 Hassan Ismail Fawaz 等人（2019）为多种时间序列深度学习算法的综述论文准备的 GitHub 伴随库。它包括了他们实现的
    TensorFlow/Keras 实现。它不是一个库*本身*，因为它不像一个库那样安装，模型在数据集上运行；然而，由于这些算法已在 TensorFlow 和
    Keras 中实现，任何熟悉这些框架的人都会觉得很亲切。'
- en: Pytorch-forecasting, sktime-DL, and Gluon-TS come with their own abstractions
    of datasets that help with the automation of common tasks. While Sktime-DL builds
    on the sktime abstractions, Pytorch-Forecasting and Gluon-TS have batteries built-in
    for deep learning with utilities for common tasks such as the scaling and encoding
    of variables, normalizing the target variable, and downsampling. These abstractions
    come at the cost of a learning curve, however, and I should caution the impatient
    reader that it can take time to get up to speed with this, which is why I am omitting
    them from the practice part.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch-forecasting、sktime-DL 和 Gluon-TS 都有自己的数据集抽象，帮助自动化常见任务。虽然 Sktime-DL 构建于
    sktime 抽象之上，Pytorch-Forecasting 和 Gluon-TS 则内置了用于深度学习的工具，处理常见任务，如变量的缩放和编码、目标变量的归一化和下采样。然而，这些抽象带来了学习曲线，我要提醒那些急于求成的读者，这可能需要一些时间才能掌握，这也是我在实践部分中省略它们的原因。
- en: 'I''ve omitted repositories from this table that only implement a single algorithm.
    In the next visualization, I have included some of these, such as the repositories
    for the Informer model or the neural prophet. In the following diagram, you can
    see the popularity of a few repositories for time-series deep learning:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我已从此表中省略了仅实现单一算法的库。在接下来的可视化中，我包含了一些这样的库，如Informer模型或神经先知的库。在下图中，您可以看到几个时间序列深度学习库的受欢迎程度：
- en: '![deep_learning-star_history.png](img/B17577_10_06.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![deep_learning-star_history.png](img/B17577_10_06.png)'
- en: 'Figure 10.7: Popularity of deep learning libraries for time-series'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7：时间序列深度学习库的受欢迎程度
- en: As always, I've tried to choose the most popular repositories – and repositories
    that have been updated recently. You can see that Gluon-TS is the most popular
    repository. Of the repositories implementing several algorithms, Pytorch Forecasting
    comes closest and has been making inroads recently in terms of popularity.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我尽量选择最受欢迎的库——以及最近有更新的库。可以看出，Gluon-TS 是最受欢迎的库。在实现多个算法的库中，Pytorch Forecasting
    紧随其后，最近在受欢迎程度上有所突破。
- en: 'In the next sections, we''ll concentrate on recent and competitive approaches
    with deep learning on time-series. We''ll go through a few of the most prominent
    algorithms in more detail: Autoencoders, InceptionTime, DeepAR, N-BEATS, RNNs
    (most prominently LSTMs), ConvNets, and Transformers (including the Informer).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将重点介绍时间序列深度学习中的一些最新和具有竞争力的方法。我们将详细介绍一些最突出的算法：自动编码器、InceptionTime、DeepAR、N-BEATS、RNN（尤其是
    LSTM）、卷积神经网络（ConvNets）和变换器（包括 Informer）。
- en: Autoencoders
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动编码器
- en: '**Autoencoders** (**AEs**) are artificial neural networks that learn to efficiently
    compress and encode data and are trained on reconstruction errors. A basic linear
    AE is essentially functionally equivalent to a **Principal Component Analysis**
    (**PCA**), although, in practice, AEs are often regularized.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**自编码器**（**AEs**）是人工神经网络，能够学习高效地压缩和编码数据，并通过重建误差进行训练。一个基本的线性自编码器本质上在功能上等同于**主成分分析**（**PCA**），尽管在实际应用中，自编码器通常会进行正则化处理。'
- en: 'AEs consist of two parts, the encoder and the decoder, as illustrated below
    (source: Wikipedia):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器由两部分组成，编码器和解码器，如下所示（来源：维基百科）：
- en: '![https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Autoencoder_schema.png/220px-Autoencoder_schema.png](img/B17577_10_07.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Autoencoder_schema.png/220px-Autoencoder_schema.png](img/B17577_10_07.png)'
- en: 'Figure 10.8: Autoencoder architecture'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8：自编码器架构
- en: Encoders and decoders are often both of the same architecture, which depends
    on the domain. For example, as regards images, they often contain convolutions
    like `LeNet`. For modeling time dependence, they can include causal convolutions
    or recurrent layers as a way of modeling time dependence.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器和解码器通常具有相同的架构，这取决于具体领域。例如，在图像处理中，它们通常包含像`LeNet`这样的卷积层。在建模时间依赖性时，它们可以包括因果卷积或递归层，用来建模时间依赖性。
- en: AEs are a natural way of reducing noise. They are often employed for anomaly
    detection in time-series.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是减少噪声的自然方式。它们常用于时间序列中的异常检测。
- en: InceptionTime
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: InceptionTime
- en: 'In a massive test that took about a month to complete on a cluster of 60 GPUs,
    Hassan Ismail Fawaz and others at the Université de Haute Alsace ran deep learning
    algorithms on the univariate UCR/UEA time-series classification archive (85 time-series)
    and the 13 datasets of the **Multivariate Time-Series** (**MTS**) classification
    archive. They presented this work in their paper "*Deep learning for time-series
    classification: a review*" in 2019.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在一次大规模的测试中，哈桑·伊斯梅尔·法瓦兹（Hassan Ismail Fawaz）和其他人在60个GPU的集群上运行了深度学习算法，测试了单变量UCR/UEA时间序列分类档案（85个时间序列）和13个**多变量时间序列**（**MTS**）分类档案中的数据集。他们在2019年的论文“*时间序列分类中的深度学习：综述*”中展示了这项工作。
- en: They conducted a systematic evaluation of 11 models, including LeNet, **Fully
    Connected Networks** (**FCNs**), Time-CNN, and ResNet. Only 9 of the algorithms
    completed all the tests. Compared to deep learning algorithms on the univariate
    datasets (UCR/UEA), ResNet won on 50 problems out of 85, and it was statistically
    better than the next best algorithm, the **fully convolutional neural network**
    (**FCNN**). At the same time, it was not statistically worse than HIVE-COTE, the
    top model in time-series classification. On the multivariate benchmark, the FCNN
    won, although they couldn't find any statistically significant differences between
    networks.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 他们对11个模型进行了系统评估，包括LeNet、**全连接网络**（**FCNs**）、Time-CNN和ResNet。仅有9个算法完成了所有测试。与单变量数据集（UCR/UEA）上的深度学习算法相比，ResNet在85个问题中赢得了50个，并且在统计上优于下一个最佳算法**全卷积神经网络**（**FCNN**）。同时，它在统计上与HIVE-COTE（时间序列分类中的顶级模型）并无显著差异。在多变量基准测试中，FCNN获胜，尽管他们没有发现网络之间有任何统计显著差异。
- en: 'In another paper, "*InceptionTime: Finding AlexNet for Time-Series Classification,*"
    Hassan Ismail Fawaz and an extended group of researchers, including Geoff Webb
    and others from Monash University (who we encountered in *Chapter 3*, *Preprocessing
    Time-Series*), presented a new model that they called InceptionTime.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一篇论文中，哈桑·伊斯梅尔·法瓦兹（Hassan Ismail Fawaz）和一个扩展的研究小组，包括来自莫纳什大学的Geoff Webb等人（我们在*第3章*，“*时间序列预处理*”中曾遇到过他们），提出了一个新模型，称为InceptionTime。
- en: 'The name *InceptionTime* makes reference to the Inception model ("*Going Deeper
    with Convolutions*", 2014), a network presented by researchers at Google, and
    the universities of North Carolina and Michigan. The Inception architecture consists
    of feedforward and convolutional layers, similar to LeNet, which we mentioned
    earlier in this chapter. A 22-layer variant was therefore also called GoogleLetNet
    (alternatively: Inception model version 1). Roughly speaking, the inception model
    consists of modules ("inception modules") that concatenate convolutions of different
    sizes together.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*InceptionTime*这个名字参考了Inception模型（“*Going Deeper with Convolutions*”，2014），这是由谷歌的研究人员和北卡罗来纳大学及密歇根大学的研究人员提出的一个网络。Inception架构由前馈层和卷积层组成，类似于我们在本章早些时候提到的LeNet。一个22层的变种因此也被称为GoogleLetNet（或者：Inception模型版本1）。粗略来说，Inception模型由多个模块（“Inception模块”）组成，这些模块将不同大小的卷积连接在一起。'
- en: InceptionTime takes ensembles of inception-type models with different hyperparameters
    (filters of varying lengths). They experimented with the number of networks in
    the ensemble and the filter sizes and finally showed that their model significantly
    outperformed ResNet on the 85 datasets of the UCR archive, while being statistically
    on a par with HIVE-COTE – with a much-reduced training time compared to HIVE-COTE.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: InceptionTime采用不同超参数（不同长度的滤波器）的Inception类型模型的集成。它们对集成中的网络数量和滤波器大小进行了实验，最终证明它们的模型在UCR档案的85个数据集上显著超越了ResNet，并且在统计上与HIVE-COTE相当，同时训练时间相比HIVE-COTE大幅减少。
- en: DeepAR
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeepAR
- en: 'DeepAR is a probabilistic forecasting method coming out of Amazon Research
    Germany. It is based on training an auto-regressive recurrent network model. In
    their article "*DeepAR: Probabilistic forecasting with autoregressive recurrent
    networks*" (2019), David Salinas, Valentin Flunkert, and Jan Gasthaus demonstrated
    through extensive empirical evaluation on several real-world forecasting datasets
    (parts, electricity, traffic, ec-sub, and ec) accuracy improvements of around
    15% compared to state-of-the-art methods.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 'DeepAR是亚马逊德国研究院提出的一种概率预测方法。它基于训练一个自回归循环网络模型。在他们的文章"*DeepAR: Probabilistic forecasting
    with autoregressive recurrent networks*"（2019年）中，David Salinas、Valentin Flunkert和Jan
    Gasthaus通过在多个真实世界预测数据集（如零部件、电力、交通、ec-sub和ec）上的广泛实证评估，展示了相比于最先进方法，准确性提高了约15%。'
- en: DeepAR was designed for demand forecasting and consists of an RNN architecture
    and incorporates a negative binomial likelihood for unbounded count data that
    can stretch across several orders of magnitude. Monte Carlo sampling is used to
    compute quantile estimates for all sub-ranges in the prediction horizon. For the
    case when the magnitudes of the time-series vary widely, they also introduced
    a scaling of the mean and variance parameters of the negative binomial likelihood
    by factors that depend on the mean of the time-series and the output of the network.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR是为需求预测而设计的，采用RNN架构，并结合了负二项分布似然，用于无界计数数据，这些数据可以跨越几个数量级。蒙特卡洛采样被用于计算预测区间内所有子区间的分位数估计。当时间序列的幅度变化较大时，它们还通过依赖于时间序列均值和网络输出的因子，对负二项似然的均值和方差参数进行了缩放。
- en: N-BEATS
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: N-BEATS
- en: This is a model architecture for univariate times series point forecasting based
    on backward and forward residual links and a very deep multilayer network of fully
    connected ReLU neurons. N-BEATS uses deep learning primitives such as residual
    blocks instead of any time-series-specific components and is the first architecture
    to demonstrate that deep learning using no time-series-specific components can
    outperform well-established statistical approaches.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于单变量时间序列点预测的模型架构，基于前向和后向残差连接，以及一个非常深的全连接ReLU神经元的多层网络。N-BEATS使用深度学习原语，如残差块，而不是任何时间序列特定的组件，是第一个展示不使用任何时间序列特定组件的深度学习架构，能够超越成熟统计方法的架构。
- en: 'Published in 2019 by a group around Yoshua Bengio ("*N-BEATS: Neural basis
    expansion analysis for interpretable time-series forecasting*"), this network
    reached state-of-the-art performance for two configurations and outperformed all
    other methods, including ensembles of traditional statistical methods in benchmarks
    over the M3, M4, and TOURISM competition datasets.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '该网络由Yoshua Bengio团队于2019年发布（"*N-BEATS: Neural basis expansion analysis for
    interpretable time-series forecasting*"），在两种配置下达到了最先进的性能，并在M3、M4和旅游竞赛数据集的基准测试中超越了所有其他方法，包括传统统计方法的集成方法。'
- en: A common criticism of deep learning is the opaque nature of the learning or
    – inversely – a lack of transparency in terms of what the network does. N-BEATS
    can be made interpretable with few changes without losing significant accuracy.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的一个常见批评是其学习过程的黑箱性，或者反过来说，就是网络的行为缺乏透明度。N-BEATS可以通过少量改动实现可解释性，而不会显著降低准确性。
- en: Recurrent neural networks
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: RNNs, most prominently LSTMs, have been applied a lot to multivariate electricity
    consumption forecasting. Electricity forecasting is a long sequence time-series,
    where it's necessary to precisely capture the long-range correlation coupling
    between items of a sequence over time.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: RNN，特别是LSTM，已广泛应用于多变量电力消费预测。电力预测是一个长序列时间序列，需要精确捕捉序列中各项之间随时间变化的长程相关性。
- en: Earlier works explored combinations of LSTMs with dilation, residual connections,
    and attention. These served as a basis for the winner of the M4 competition (Slawek
    Smyl, 2020).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的研究探讨了LSTM与膨胀、残差连接和注意力机制的结合。这些为M4竞赛的获胜者（Slawek Smyl，2020）提供了基础。
- en: Smyl introduced a mixture of a standard **Exponential Smoothing** (**ES**) model
    with LSTM networks. The ES equations enable the method to effectively capture
    the main components of the individual series, such as seasonality and baseline
    level, while the LSTM networks can model the nonlinear trend.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Smyl提出了一种将标准**指数平滑**（**ES**）模型与LSTM网络相结合的方法。ES方程使得该方法能够有效捕捉个别系列的主要组成部分，如季节性和基线水平，而LSTM网络则能够建模非线性趋势。
- en: A problem with RNNs, including LSTMs, is that they cannot be parallelized easily
    at the cost of training time and computing resources. It has also been argued
    that LSTMs cannot capture long-range dependencies since they struggle with sequences
    longer than about 100 time steps. RNNs encode past hidden states to capture dependencies
    with previous items, and they show a decrease in performance due to long dependencies.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: RNN，包括LSTM，的一个问题是它们无法轻松地进行并行化，这会导致训练时间和计算资源的浪费。也有人认为，LSTM无法捕捉长距离依赖关系，因为它们在处理超过大约100时间步的序列时表现不佳。RNN通过编码过去的隐藏状态来捕捉与之前项目的依赖关系，而由于长依赖关系，它们的性能会下降。
- en: In the next section, we'll look at the transformer architecture, which has been
    taking over from LSTM models both in terms of performance and, more recently,
    in popularity.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将介绍transformer架构，它在性能和最近的流行度方面，正在取代LSTM模型。
- en: It has been shown that convolutional architectures can outperform recurrent
    networks on tasks such as audio processing and machine translation, and they have
    been applied to time-series tasks as well.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 已经证明，卷积架构在音频处理和机器翻译等任务中可以优于递归网络，并且它们也已应用于时间序列任务。
- en: ConvNets
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积神经网络（ConvNets）
- en: Researchers from Carnegie Mellon University and Intel Labs ("*An Empirical Evaluation
    of Generic Convolutional and Recurrent Networks for Sequence Modeling*" 2018)
    compared generic convolutional and recurrent networks such as LSTM/GRU for sequence
    modeling across a broad range of tasks. These were large textual datasets and
    posed sequence problems, such as the problem of addition, the copying of memory
    tasks, or polyphonic music. Problems and datasets such as these are commonly used
    to benchmark recurrent networks.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 卡内基梅隆大学和英特尔实验室的研究人员（"*An Empirical Evaluation of Generic Convolutional and Recurrent
    Networks for Sequence Modeling*" 2018）比较了用于序列建模的通用卷积网络和递归网络（如LSTM/GRU），并在广泛的任务中进行了测试。这些任务使用了大型文本数据集，并涉及序列问题，如加法问题、记忆任务的复制或多音音乐。像这些问题和数据集通常用于对递归网络进行基准测试。
- en: They found that a simple convolutional architecture, the **Temporal Convolutional
    Network** (**TCN**), performs better than RNNs on a vast range of tasks' canonical
    recurrent networks (such as LSTMs) while demonstrating a longer effective memory.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 他们发现，一种简单的卷积架构——**时间卷积网络**（**TCN**），在许多任务中比经典的递归网络（如LSTM）表现更好，并且展示了更长的有效记忆。
- en: 'The important characteristic of the convolutions in the TCNs is that they are
    causal. A convolution is causal if its output is the result of only current and
    past inputs. This is illustrated here (source: keras-tcn, GitHub):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: TCN中卷积的重要特征是它们是因果的。如果卷积的输出仅由当前和过去的输入决定，那么它就是因果的。以下是一个示例（来源：keras-tcn，GitHub）：
- en: '![https://github.com/philipperemy/keras-tcn/raw/master/misc/Dilated_Conv.png](img/B17577_10_08.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![https://github.com/philipperemy/keras-tcn/raw/master/misc/Dilated_Conv.png](img/B17577_10_08.png)'
- en: 'Figure 10.9: A time-causal convolution'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9：时间因果卷积
- en: An output at time t is convolved only with elements from time t and earlier.
    This means that information from the future cannot leak to the past. A disadvantage
    of this basic design is that in order to achieve a long effective history size,
    we need an extremely deep network or very large filters.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间t的输出仅与时间t及之前的元素进行卷积。这意味着未来的信息不能泄露到过去。这种基本设计的一个缺点是，为了实现长的有效历史大小，我们需要一个极其深的网络或非常大的滤波器。
- en: Some advantages of convolutions over RNNs are parallelism, the flexible receptive
    field size (specifying how far the model can see), and stable gradients – backpropagation
    through time comes with the vanishing gradient problem.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积相较于RNN的优势包括并行性、灵活的感受野大小（指定模型可以看到的范围）和稳定的梯度——反向传播过程中，RNN会面临梯度消失问题。
- en: The transformer also addresses the perceived shortcomings of RNNs.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer还解决了RNNs被认为存在的不足之处。
- en: Transformer architectures
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Transformer架构
- en: Transformers, introduced in the article "*Attention is all you need*" (2017)
    by researchers at Google Brain and the University of Toronto, were designed to
    avoid recursion in order to allow parallel computation.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer是由Google Brain和多伦多大学的研究人员在2017年发布的文章《*Attention is all you need*》中提出的，旨在避免递归，以便支持并行计算。
- en: Transformers introduced two building blocks – multi-head attention and positional
    embeddings. Rather than working sequentially, sequences are processed as a whole
    rather than item by item. They employ self-attention, where similarity scores
    between items in a sentence are stored.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer引入了两个核心构件——多头注意力和位置嵌入。与按顺序处理不同，序列被作为整体处理，而不是逐项处理。它们采用自注意力机制，存储句子中各个元素之间的相似度分数。
- en: Transformers were introduced originally for machine translation, where they
    were shown to outperform Google's Neural Machine Translation models. The central
    piece is therefore the alignment of two sequences. Instead of recurrence, positional
    embeddings were introduced where weights encode information related to a specific
    position of a token in a sequence.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer最初是为机器翻译而提出的，研究表明它们在翻译性能上超越了Google的神经机器翻译模型。因此，Transformer的核心是两个序列的对齐。与递归不同，Transformer引入了位置嵌入，权重编码了与序列中某个特定位置相关的信息。
- en: Transformers consist of stacked modules, first encoder and then decoder modules.
    Encoder modules each consist of a self-attention layer and a feed-forward layer,
    while decoder modules consist of self-attention, encoder-decoder attention, and
    a feed-forward layer. These modules can be stacked, thereby creating very large
    models that can learn massive datasets.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer由堆叠的模块组成，首先是编码器模块，然后是解码器模块。每个编码器模块由一个自注意力层和一个前馈层组成，而解码器模块则包括自注意力层、编码器-解码器注意力层和前馈层。这些模块可以堆叠起来，从而创建非常大的模型，能够学习海量数据集。
- en: Transformers have pushed the envelope in NLP, especially in translation and
    language understanding. Furthermore, OpenAI's powerful GPT-3 model for language
    generation is a transformer as well, as is DeepMind's AlphaFold 2, a model that
    predicts protein structure from their genetic sequences.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer在自然语言处理（NLP）领域推动了新一轮的创新，尤其是在翻译和语言理解方面。此外，OpenAI强大的GPT-3语言生成模型也是基于Transformer架构，DeepMind的AlphaFold
    2模型也采用了Transformer架构，该模型通过基因序列预测蛋白质结构。
- en: Transformers have been able to maintain performance across longer sequences.
    However, they can capture only dependencies within the fixed input size used to
    train them. To work with even longer sentences beyond the fixed input width, architectures
    such as Transformer-XL reintroduce recursion by storing hidden states of already
    encoded sentences to leverage them in the subsequent encoding of the next sentences.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer能够在更长的序列中保持性能。然而，它们只能捕捉到训练时使用的固定输入大小内的依赖关系。为了处理超过固定输入宽度的更长句子，像Transformer-XL这样的架构重新引入了递归机制，通过存储已编码句子的隐藏状态，在后续编码下一个句子时加以利用。
- en: In the article "*Temporal Fusion Transformers for Interpretable Multi-horizon
    Time-Series Forecasting,*" researchers from the University of Oxford and Google
    Cloud AI introduced an attention-based architecture, which they called a **Temporal
    Fusion Transformer** (**TFT**). To learn temporal relationships at different scales,
    TFT uses recurrent layers for local processing and interpretable self-attention
    layers for long-term dependencies. Furthermore, a series of gating layers suppress
    unnecessary components.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在文章《*Temporal Fusion Transformers for Interpretable Multi-horizon Time-Series
    Forecasting*》中，来自牛津大学和Google Cloud AI的研究人员提出了一种基于注意力的架构，他们称之为**时间融合Transformer**（**TFT**）。为了在不同尺度上学习时间关系，TFT使用了递归层进行局部处理，并采用可解释的自注意力层来捕捉长期依赖关系。此外，一系列门控层可以抑制不必要的成分。
- en: On a variety of real-world datasets, they demonstrated significant performance
    improvements of their architecture over a broad benchmark set. Among other improvements,
    they outperformed Amazon's DeepAR by between 36 and 69%.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种真实世界的数据集上，它们展示了其架构在广泛基准测试中的显著性能提升。除此之外，它们还在多个方面超过了亚马逊的DeepAR，性能提升幅度在36%到69%之间。
- en: Informer
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Informer
- en: 'A problem with transformers is the quadratic time complexity and memory usage,
    along with the limitations of the encoder-decoder architecture. This complicates
    predictions over longer time periods, for example, 510 time steps of hourly electricity
    consumption. To address these issues, researchers from Beihang University, UC
    Berkeley, Rutgers, and SEDD Company designed an efficient transformer-based model
    for long sequence time-series forecasting, named Informer – "*Informer: Beyond
    Efficient Transformer for Long Sequence Time-Series Forecasting*". The paper obtained
    the Outstanding Paper Award at the AAAI conference in 2021.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 'Transformer 的问题在于二次时间复杂度和内存使用，以及编码器-解码器架构的局限性。这使得对长时间段（例如，510个小时的电力消耗数据）进行预测变得复杂。为了解决这些问题，来自北航大学、加州大学伯克利分校、罗格斯大学和
    SEDD 公司的研究人员设计了一种高效的基于 Transformer 的长序列时间序列预测模型，命名为 Informer —— “*Informer: Beyond
    Efficient Transformer for Long Sequence Time-Series Forecasting*”。该论文在 2021 年的
    AAAI 会议上获得了杰出论文奖。'
- en: The generative decoder alleviates the time complexity of the encoder-decoder
    by predicting long time-series sequences in one forward operation rather than
    step-by-step. They replaced the positional embeddings with a new self-attention
    mechanism called ProbSparse Self-Attention, which achieves ![](img/B17577_10_005.png),
    where *L* is the length of the sequence, instead of quadratic time complexity
    and memory usage, ![](img/B17577_10_006.png), while maintaining a comparable performance
    on sequence alignment.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式解码器通过在一次前向操作中预测长时间序列序列，而不是逐步预测，从而减轻了编码器-解码器的时间复杂度。他们用一种新的自注意力机制——ProbSparse
    自注意力——替代了位置嵌入，它实现了 ![](img/B17577_10_005.png)，其中 *L* 是序列的长度，而不是二次时间复杂度和内存使用，![](img/B17577_10_006.png)，同时在序列对齐上的表现保持相当。
- en: Finally, the self-attention distillation halves the cascading layer input, and
    efficiently handles extreme long input sequences. This reduces the complexity
    from ![](img/B17577_10_007.png), where J is the number of transformer layers,
    to ![](img/B17577_10_008.png).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，自注意力蒸馏将级联层的输入减半，并有效处理极长的输入序列。这将复杂度从 ![](img/B17577_10_007.png) 降低到 ![](img/B17577_10_008.png)，其中
    J 是 Transformer 层的数量。
- en: 'The Informer architecture is illustrated in this schema (from the official
    Informer repository):'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Informer 架构在这个框架图中进行了说明（来自官方 Informer 仓库）：
- en: '![https://github.com/zhouhaoyi/Informer2020/raw/main/img/informer.png](img/B17577_10_09.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![https://github.com/zhouhaoyi/Informer2020/raw/main/img/informer.png](img/B17577_10_09.png)'
- en: 'Figure 10.10: The Informer architecture'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10：Informer 架构
- en: This diagram shows that the Informer significantly outperforms existing methods
    on datasets of long time-series forecasting such as Electricity Transformer Temperature
    (ETT), Electricity Consuming Load (ECL), and Weather.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表显示，Informer 在长期时间序列预测数据集上明显优于现有方法，例如电力变压器温度（ETT）、电力消耗负载（ECL）和天气数据。
- en: 'On univariate datasets, they achieved superior performance compared with all
    competitors, except for two cases, where DeepAR was slightly better, as shown
    here (source: Informer GitHub repository):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在单变量数据集上，除了两个案例外，它们相比所有竞争者表现更好，其中 DeepAR 略微优于其他方法，如下所示（来源：Informer GitHub 仓库）：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_WVOQFx/Screenshot
    2021-08-01 at 22.05.06.png](img/B17577_10_10.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_WVOQFx/Screenshot
    2021-08-01 at 22.05.06.png](img/B17577_10_10.png)'
- en: 'Figure 10.11: Univariate long sequence time-series forecasting performance'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11：单变量长序列时间序列预测性能
- en: Most significantly, they beat competitors such as ARIMA, prophet, LSTMs, and
    other transformer-based architectures.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，它们击败了包括 ARIMA、prophet、LSTM 和其他基于 Transformer 的架构在内的竞争者。
- en: On a multivariate benchmark, they also beat competitors including other transformer-based
    models and LSTMs.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在多变量基准测试中，它们也超过了包括其他基于 Transformer 的模型和 LSTM 在内的竞争者。
- en: We'll put some of this into practice now.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将把其中的一些内容付诸实践。
- en: Python practice
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 实践
- en: Let's model airplane passengers. We'll forecast the monthly number of passengers.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们建模飞机乘客数据。我们将预测每月的乘客数量。
- en: 'This dataset is considered one of the classic time-series, published by George
    E.P. Box and Gwilym Jenkins alongside the book "Time-Series Analysis: Forecasting
    and Control" (1976). I have provided a copy of this dataset in the `chapter10`
    folder of the book''s GitHub repository. You can download it from there or use
    the URL directly in `pd.read_csv()`.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集被认为是经典的时间序列之一，由George E.P. Box和Gwilym Jenkins与《时间序列分析：预测与控制》一书（1976年）一起发布。我已将该数据集的副本提供在书籍GitHub仓库的`chapter10`文件夹中。你可以从那里下载，或者直接在`pd.read_csv()`中使用URL。
- en: We'll first start with a simple FCN and then we'll apply a recurrent network,
    and finally, we'll apply a very recent architecture, a Dilated Causal Convolutional
    Neural Network.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先从一个简单的FCN开始，然后应用递归网络，最后应用一种非常新的架构：膨胀因果卷积神经网络。
- en: The FCN is first.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: FCN是首选。
- en: Fully connected network
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全连接网络
- en: 'In this first practice session, we''ll use TensorFlow libraries, which we can
    quickly install from the terminal (or similarly from the anaconda navigator):'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第一次练习中，我们将使用TensorFlow库，可以通过终端快速安装（或者通过Anaconda Navigator以类似的方式）：
- en: '[PRE0]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We'll execute the commands from the Python (or IPython) terminal, but equally,
    we could execute them from a Jupyter notebook (or a different environment).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在Python（或IPython）终端中执行这些命令，但同样，我们也可以在Jupyter Notebook（或其他环境）中执行它们。
- en: The installation could take a while – the TensorFlow library is about 200 MB
    in size and comes with a few dependencies.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 安装可能需要一段时间——TensorFlow库的大小约为200MB，并且附带一些依赖项。
- en: 'Let''s load the dataset. Here, I am assuming that you''ve downloaded it onto
    your computer:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载数据集。这里假设你已经将它下载到你的计算机上：
- en: '[PRE1]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let's try naively to just use an FCN, also known as an MLP.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简单地尝试使用FCN，也叫做MLP。
- en: 'Let''s set some imports and set a couple of global constants:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设置一些导入并设置几个全局常量：
- en: '[PRE2]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We will use these constants for our model architecture.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这些常量来构建我们的模型架构。
- en: 'Dropout (or: Dilution) is a regularization technique that can help reducing
    overfitting. Dropout means that during training, a fraction of the connections
    (in our case 20%) is randomly removed.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout（或称：稀疏化）是一种正则化技术，有助于减少过拟合。Dropout意味着在训练过程中，一部分连接（在我们这个案例中是20%）会被随机移除。
- en: Early stopping is another form of regularization, where the training stops as
    defined by certain conditions. In our case, we've stated it should stop if our
    loss doesn't improve three times in a row. If the model stops improving, there's
    no point in continuing to train it, although we may be trapped in a local minimum
    of the error that we might be able to escape. One of the big advantages of early
    stopping is that it can help us quickly see whether a model is working.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 提前停止是另一种正则化形式，其中训练会在某些条件下停止。在我们的案例中，我们已设定若损失连续三次没有改进，训练就应该停止。如果模型停止改进，就没有继续训练的意义，尽管我们可能被困在一个局部最小值中，但我们仍然可能逃脱。提前停止的一个大优点是它可以帮助我们快速看到模型是否有效。
- en: 'We can define our model in this function:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这个函数中定义我们的模型：
- en: '[PRE3]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With the Keras functional API, we've defined a two-layer neural network, where
    the hidden layer of `HIDDEN_NEURONS` neurons is activated by the Rectified Linear
    Unit (ReLU) function.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Keras功能API，我们定义了一个两层神经网络，其中隐藏层有`HIDDEN_NEURONS`个神经元，并且使用整流线性单元（ReLU）激活函数。
- en: 'Let''s split our dataset into training and test sets. We will predict the number
    of passengers based on passengers in the previous time period (previous month):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将数据集划分为训练集和测试集。我们将根据上一个时间段（上个月）的乘客数来预测乘客数：
- en: '[PRE4]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We'll learn based on the first 75% of the dataset – this is the default value
    for the `test_size` parameter in the `train_test_split` function.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基于数据集的前75%进行学习——这是`train_test_split`函数中`test_size`参数的默认值。
- en: 'We can now train our naïve FCN:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以训练我们的简单FCN：
- en: '[PRE5]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We should get an output of the loss and the metrics at each epoch as they finish:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该在每个epoch结束时获得损失和度量的输出：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_zCMSbK/Screenshot
    2021-08-06 at 22.50.40.png](img/B17577_10_11.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_zCMSbK/Screenshot
    2021-08-06 at 22.50.40.png](img/B17577_10_11.png)'
- en: 'Figure 10.12: Model training'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12：模型训练
- en: Ideally, we would see the error (loss) going down, and we'd see a low error
    at the end. I haven't included any code to fix the random number generator (`tf.random.set_seed`),
    so your output might differ.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们会看到误差（损失）在下降，并且在最后看到较低的误差。我没有包含任何修复随机数生成器的代码（`tf.random.set_seed`），因此你的输出可能会有所不同。
- en: 'We can then get the predictions for the test set like this:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以像这样获取测试集的预测：
- en: '[PRE6]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, it would be good to visualize passenger predictions against the actual
    passenger values.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将乘客预测与实际乘客值进行可视化会很好。
- en: 'We can use this function:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个函数：
- en: '[PRE7]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let's visualize our predictions then!
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们可视化我们的预测！
- en: '[PRE8]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here''s the graph:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图表：
- en: '![fcn_naive.png](img/B17577_10_12.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![fcn_naive.png](img/B17577_10_12.png)'
- en: 'Figure 10.13: Predicted against actual airplane passengers: Naïve fully connected
    network'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13：预测与实际飞机乘客对比：天真的全连接网络
- en: We can see that the model has learned some of the monthly variability. However,
    it is systematically under-predicting – it has learned the baseline from the years
    1949-1958 of the training set, when far fewer passengers were traveling.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到模型已经学会了部分月度变化。然而，它在系统性低估 - 它已经从训练集1949-1958年的基线学到了一些东西，当时乘客数量较少。
- en: Let's make this a bit more sophisticated and better.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把这个变得更加复杂和更好一些。
- en: This first model was trained only on the immediate previous number of travelers.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这第一个模型仅在上一个旅客数上进行了训练。
- en: As a first step, we'll include the year and the month as predictor variables.
    The year can be used to model the trend, while the month is coupled to the monthly
    variability – so this seems a natural step.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们将包括年份和月份作为预测变量。年份可以用来模拟趋势，而月份则与月度变化密切相关 - 这似乎是一个自然的步骤。
- en: 'This will add month and year columns to the DataFrame based on the DateTimeIndex:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这将基于DateTimeIndex将月份和年份列添加到DataFrame中：
- en: '[PRE9]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we can redefine our model – we need to add more input columns:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以重新定义我们的模型 - 我们需要增加更多的输入列：
- en: '[PRE10]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And we are ready for another training round:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好进行另一轮训练：
- en: '[PRE11]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s see how well the model predictions match the test data:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模型预测与测试数据的匹配情况：
- en: '![fcn_with_year_month.png](img/B17577_10_13.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![fcn_with_year_month.png](img/B17577_10_13.png)'
- en: 'Figure 10.14: Predicted against actual airplane passengers; Fully connected
    network with the year and month'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14：预测与实际飞机乘客对比；带年份和月份的全连接网络
- en: Please note that, because of the high number of parameters, and the randomness
    involved in the learning process, the outcome might differ significantly between
    runs. This is indeed one of the problems associated with deep learning.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于参数数量多，并且学习过程中涉及随机性，结果可能在不同运行中有显著差异。这确实是深度学习所涉及的问题之一。
- en: This already looks much better. The year feature helped our model learn the
    baseline. The model has learned something about the monthly variability, but it's
    not enough to really approximate it.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来已经好多了。年份特征帮助我们的模型学习了基线。模型已经学会了一些关于月度变化的东西，但还不足以真正逼近它。
- en: 'Let''s create a less naïve version. We will change a few things in this model:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个不那么天真的版本。我们将在这个模型中做一些改动：
- en: We'll add an embedding of the month feature
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将添加一个月份特征的嵌入
- en: We'll treat the year as a linear predictor
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将年份视为线性预测器
- en: We'll add the previous month's passengers to our predictions
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将前一个月的乘客添加到我们的预测中
- en: Finally, we'll scale our predictions based on the standard deviation in the
    training dataset
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们将根据训练数据集中的标准差来缩放我们的预测。
- en: That was quite a mouthful. Let's go through these a bit more slowly.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这是相当复杂的。让我们更慢地过一遍这些。
- en: We fed the months as values from 1 to 12 into our previous model. However, we
    could intuitively guess that January (1) and December (12) are perhaps more similar
    than November (11) and December. We know that there are lots of travelers in both
    December and January, but perhaps a much lower volume in November. We can capture
    these relationships based on the data.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将月份作为从1到12的值输入到我们的先前模型中。然而，我们可以直觉地猜测1月（1）和12月（12）可能比11月（11）和12月更相似。我们知道12月和1月都有很多旅行者，但11月的体积可能较低。我们可以根据数据捕捉这些关系。
- en: This can be done in an embedding layer. An embedding layer is a mapping of distinct
    categories to real numbers. This mapping is updated as part of the network optimization.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以在嵌入层中完成。嵌入层是将不同类别映射到实数的映射。此映射将作为网络优化的一部分进行更新。
- en: The year is closely related to the overall trend. Each year, the number of airline
    passengers increases. We can model this relationship non-linearly or linearly.
    Here, I've decided to just model a linear relationship between the year feature
    and the outcome.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 年份与整体趋势密切相关。每年航空旅客人数都在增加。我们可以用非线性或线性模型来建模这种关系。在这里，我决定只建立年份特征和结果之间的线性关系。
- en: The relationship between the previous month's passenger numbers and those in
    this month is again assumed to be linear.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 假设上个月的乘客人数与本月乘客人数之间的关系仍然是线性的。
- en: 'Finally, we can scale our predictions, similar to the inverse transformation
    of the standard transformation. You should remember the standard normalization
    from *Chapter 3**, Preprocessing Time-Series*, as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以对预测结果进行缩放，类似于标准变换的逆变换。你应该记得来自*第3章*《时间序列预处理》中的标准归一化方法，如下所示：
- en: '![](img/B17577_10_009.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_10_009.png)'
- en: where ![](img/B17577_10_010.png) is the population mean and ![](img/B17577_10_011.png)
    is the population standard deviation.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/B17577_10_010.png) 是总体均值，![](img/B17577_10_011.png) 是总体标准差。
- en: 'The inverse of this is as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 其逆操作如下：
- en: '![](img/B17577_10_012.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_10_012.png)'
- en: 'Our formula is as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的公式如下：
- en: '![](img/B17577_10_013.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_10_013.png)'
- en: where ![](img/B17577_10_014.png) are the airline passengers at time t and ![](img/B17577_10_015.png)
    is the prediction based on the embedded month and the year.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/B17577_10_014.png) 是时间点 t 的航空公司乘客人数，![](img/B17577_10_015.png) 是基于嵌入的月份和年份的预测结果。
- en: We assume the network will learn to baseline, but might not learn the scale
    perfectly – so we'll help out.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设网络会学习到基准线，但可能无法完美学习到比例——因此我们将提供帮助。
- en: 'An illustration might help (from TensorBoard, TensorFlow''s visualization toolkit):'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 一张插图可能会有所帮助（来自 TensorBoard，TensorFlow 的可视化工具包）：
- en: '![../../Desktop/Screenshot%202021-08-06%20at%2022.08.12.pn](img/B17577_10_14.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![../../Desktop/Screenshot%202021-08-06%20at%2022.08.12.pn](img/B17577_10_14.png)'
- en: 'Figure 10.15: Model architecture: Fully connected network with embedding, scaling,
    and baseline'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15：模型架构：带嵌入、缩放和基准线的全连接网络
- en: We can see the three inputs, one of them (the months) going through an embedding
    layer, and another one through a (linear) projection. They all come together (concatenate)
    and go through a dense layer, where another math operation is performed on top.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到三个输入，其中一个（月份）经过嵌入层处理，另一个经过（线性）投影处理。它们都聚合（连接）起来并经过一个全连接层，在此层上执行其他数学运算。
- en: 'We''ll need a few more imports first:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要导入一些内容：
- en: '[PRE12]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we redefine our network as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们重新定义我们的网络如下：
- en: '[PRE13]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We reinitialize our model:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重新初始化我们的模型：
- en: '[PRE14]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'During training and for prediction purposes, we need to feed the three types
    of input separately like this:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和预测过程中，我们需要像这样分别输入三种类型的数据：
- en: '[PRE15]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You might notice that the training carries on for much longer in this configuration.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，在这种配置下，训练时间明显更长。
- en: 'This chart illustrates the fit we are achieving with our new network:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图展示了我们通过新网络所取得的拟合效果：
- en: '![fcn_more_sophisticated.png](img/B17577_10_15.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![fcn_more_sophisticated.png](img/B17577_10_15.png)'
- en: 'Figure 10.16: Predicted against actual airplane passenger numbers: Fully connected
    network with embedding, scaling, and baseline'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.16：预测与实际航空乘客人数对比：带嵌入、缩放和基准线的全连接网络
- en: This again looks much better than the previous network. We leave it as an exercise
    to the reader to try to improve this network further.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这比之前的网络好得多。我们把进一步改进这个网络的任务留给读者来做。
- en: We'll set up an RNN next.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将设置一个 RNN。
- en: Recurrent neural network
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: We discussed in the theory section that recurrent neural networks can be very
    good at modeling long-term relationships between points in a time-series. Let's
    set up an RNN.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在理论部分讨论过，循环神经网络非常擅长建模时间序列中点之间的长期关系。让我们设置一个 RNN。
- en: We'll use the same dataset as before – the univariate values of airline passengers.
    In this case, our network is going to need a sequence of points for each training
    sample. At each training step, the RNN is going to be trained on points (passengers)
    leading up to the next passenger number.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与之前相同的数据集——航空公司乘客的单变量值。在这种情况下，我们的网络需要为每个训练样本提供一系列数据点。在每个训练步骤中，RNN 将在接下来的乘客数量之前，训练基于一系列（乘客）点。
- en: Please note that we can use TensorFlow (or even statsmodels' `lagmat()`) utility
    functions for this purpose (and we will use them in *Chapter 12*, *Case Studies*),
    but in this instance, we'll write this quickly ourselves.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们可以使用 TensorFlow（甚至是 statsmodels 的 `lagmat()`）工具函数来完成这个任务（我们将在*第12章*《案例研究》中使用它们），但在这个例子中，我们将快速自己编写这个代码。
- en: 'We''ll need to resample our passenger numbers thus:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要按如下方式重新采样乘客数据：
- en: '[PRE16]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This function does the job. It goes over all the points in the dataset and takes
    a sequence leading up to it. The number of points in the new sequence is defined
    by the parameter `lookback`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数完成了任务。它遍历数据集中的所有点，并提取到该点的序列。新序列中的点数由参数`lookback`定义。
- en: 'Let''s put it to use:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始使用它：
- en: '[PRE17]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We are using a lookback of 10\. I've deliberately chosen a value that is not
    optimal. I'm leaving it as an exercise to the reader to choose one that's better
    and try it out.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个回溯窗口为10。我故意选择了一个并非最优的值。我把选择一个更好的值并尝试的任务留给读者。
- en: The last line in the code above joins the targets (lookahead 1) together with
    the sequences.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 上面代码中的最后一行将目标（前瞻1）与序列连接在一起。
- en: 'We are ready to define our network, but let''s get the imports out of the way:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备好定义我们的网络了，但先处理一下导入模块：
- en: '[PRE18]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The network is defined by this function:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 网络由这个函数定义：
- en: '[PRE19]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: It's a bidirectional LSTM network. The result of the last layer is projected
    linearly as our output. I've set the activation function of the LSTM to `tanh`
    in case you want to run this on a GPU runtime, so it will benefit from NVIDIA's
    GPU-accelerated library cuDNN. We are extracting the same metrics as in the previous
    practice.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个双向LSTM网络。最后一层的输出经过线性投影，作为我们的输出。我将LSTM的激活函数设置为`tanh`，以便你在GPU环境中运行时，可以利用NVIDIA的GPU加速库cuDNN。我们提取了与之前练习中相同的指标。
- en: 'A few more preliminaries that you should be familiar with from the previous
    section are as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些你应该在上一节中已经熟悉的预备知识：
- en: '[PRE20]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s train it:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始训练：
- en: '[PRE21]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The result looks quite good already – even though we made a few sub-optimal
    choices:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来已经相当不错——尽管我们做了一些次优的选择：
- en: '![rnn_passengers.png](img/B17577_10_16.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![rnn_passengers.png](img/B17577_10_16.png)'
- en: 'Figure 10.17: Recurrent neural network for passenger forecasts'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17：乘客预测的递归神经网络
- en: Given how easy this was to set up, this already looks very promising.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这个设置非常简单，这看起来已经非常有前景。
- en: Let's now try a causal ConvNet!
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们试试因果卷积神经网络！
- en: Dilated causal convolutional neural network
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 膨胀因果卷积神经网络
- en: This example is based on Krist Papadopoulos's SeriesNet implementation of the
    paper "*Conditional Time-Series Forecasting with Convolutional Neural Networks*,"
    by Anastasia Borovykh and others.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子基于Krist Papadopoulos的SeriesNet实现，参考了Anastasia Borovykh等人的论文《*使用卷积神经网络进行条件时间序列预测*》。
- en: We'll implement this model together and we'll apply it to two datasets to see
    how it does out of the box. I won't be going through tweaking the data and architecture
    in this example.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一起实现这个模型，并将其应用于两个数据集，看看它的表现如何。我在这个例子中不会讨论如何调整数据和架构。
- en: 'First, the imports:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是导入模块：
- en: '[PRE22]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: What is perhaps surprising is how easy it is to do a causal convolution in TensorFlow.
    Conv1D comes with a parameter, `padding`, which can be specified as `'causal'`.
    This simply pads the layer's input with zeros according to the causal nature,
    where output at time t only depends on the previous time steps, <t. Please refer
    to the discussion in the ConvNets section in this chapter.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 也许令人惊讶的是，在TensorFlow中实现因果卷积是如此简单。Conv1D带有一个参数`padding`，可以设置为`'causal'`。这会根据因果特性将层的输入用零填充，其中时间t的输出仅依赖于之前的时间步，<t。请参考本章ConvNets部分的讨论。
- en: This means that we can predict the values of early time steps in the frame.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以预测帧中早期时间步的值。
- en: 'The main idea of this network is a residual block with causal convolutions.
    This code segment constructs the corresponding network architecture:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这个网络的主要思想是一个带有因果卷积的残差块。这个代码段构建了相应的网络架构：
- en: '[PRE23]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: I've simplified this a bit to make it easier to read.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我简化了这个部分，使它更容易阅读。
- en: 'The network itself just stacks these layers as a SkipNet follows up with a
    convolution:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 网络本身仅仅堆叠这些层，作为一个SkipNet，后续使用卷积：
- en: '[PRE24]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This is for a univariate time-series. For a multivariate time-series, some changes
    are necessary, which we won't cover here.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这是针对单变量时间序列的。对于多变量时间序列，需要进行一些修改，这部分我们在这里不讨论。
- en: 'Let''s forecast passenger numbers again. We''ll load the DataFrame as in the
    previous practice sections:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次预测乘客数量。我们将像之前的练习部分那样加载DataFrame：
- en: '[PRE25]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We''ll split this again into test and training sets:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次将数据拆分为测试集和训练集：
- en: '[PRE26]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We''ll train the model with this function:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个函数来训练模型：
- en: '[PRE27]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This function will do the forecast for us:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将为我们做预测：
- en: '[PRE28]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The forecast is created by predicting the immediate next future value based
    on the previous predictions. The parameter `horizon` is the forecast horizon.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这个预测是通过基于前面的预测来预测紧接着的下一个未来值而产生的。参数 `horizon` 是预测的时间跨度。
- en: 'We''ll put this together as a single function for convenience:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们将把这一切整理成一个单一函数：
- en: '[PRE29]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now we are ready for training. We''ll run everything like this:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好进行训练了。我们将按照如下方式运行一切：
- en: '[PRE30]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The model is very deep, but is not that big in terms of parameters because of
    the convolutions. We'll see that there are 865 trainable parameters.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型非常深，但由于卷积的原因，在参数数量上并不算很大。我们会看到它有 865 个可训练的参数。
- en: 'The model fit is not that good though, neither in MSE nor does that graph look
    very impressive either:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，模型的拟合效果并不好，无论是 MSE 还是图表看起来都不太令人印象深刻：
- en: '![convnet_passengers.png](img/B17577_10_17.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![convnet_passengers.png](img/B17577_10_17.png)'
- en: 'Figure 10.18: ConvNet prediction of passenger numbers'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.18：ConvNet 预测乘客数量
- en: This graph can be produced by running `show_result(y_test[:HORIZON], predictions[:HORIZON],
    "Passengers")`.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表可以通过运行`show_result(y_test[:HORIZON], predictions[:HORIZON], "Passengers")`生成。
- en: This highlights the fact that each model has its strengths and weaknesses and
    that without adapting a model to our dataset and careful preprocessing, we won't
    be able to get a good performance. It's left as an exercise to the reader to try
    and tweak this model.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这突出了每个模型都有其优缺点的事实，并且如果不根据我们的数据集调整模型以及进行仔细的预处理，我们将无法获得良好的性能。让读者尝试调整这个模型作为练习。
- en: Summary
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, I've introduced many deep learning concepts relevant to time-series,
    and we've discussed many architectures and algorithms, such as autoencoders, InceptionTime,
    DeepAR, N-BEATS, ConvNets, and a few transformer architectures. Deep learning
    algorithms are indeed coming very close to the state of the art in time-series,
    and it's an exciting area of research and application.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我介绍了许多与时间序列相关的深度学习概念，我们讨论了许多架构和算法，如自编码器、InceptionTime、DeepAR、N-BEATS、ConvNets
    和一些 transformer 架构。深度学习算法确实接近时间序列领域的最新技术，它是一个令人兴奋的研究和应用领域。
- en: In the practice section, I implemented a fully connected feedforward network
    and then an RNN before taking a causal ConvNet for a ride.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践部分，我实现了一个全连接前馈网络，然后是一个 RNN，最后使用一个因果 ConvNet 进行了实验。
- en: In *Chapter 12*, *Multivariate Forecasting*, we'll do some more deep learning,
    including a Transformer model and an LSTM.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第12章*，*多元预测*中，我们将进行更多深度学习的探讨，包括一个 Transformer 模型和一个 LSTM。
