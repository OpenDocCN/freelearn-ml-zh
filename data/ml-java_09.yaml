- en: Activity Recognition with Mobile Phone Sensors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用移动电话传感器进行活动识别
- en: While the previous chapter focused on pattern recognition in images, this chapter
    is all about recognizing patterns in sensor data, which, in contrast to images,
    has temporal dependencies. We will discuss how to recognize granular daily activities
    such as walking, sitting, and running using mobile phone inertial sensors. The
    chapter also provides references to related research and emphasizes best practices
    in the activity recognition community.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然上一章侧重于图像中的模式识别，但本章全部关于在传感器数据中识别模式，这与图像不同，具有时间依赖性。我们将讨论如何使用移动电话惯性传感器识别细粒度的日常活动，如行走、坐着和跑步。本章还提供了相关研究的参考文献，并强调了活动识别社区中的最佳实践。
- en: 'The topics covered in this chapter will include the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introducing activity recognition, covering mobile phone sensors and the activity
    recognition pipeline
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍活动识别，涵盖移动电话传感器和活动识别流程
- en: Collecting sensor data from mobile devices
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从移动设备收集传感器数据
- en: Discussing activity classification and model evaluation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论活动分类和模型评估
- en: Deploying an activity recognition model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署活动识别模型
- en: Introducing activity recognition
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍活动识别
- en: Activity recognition is an underpinning step in behavior analysis, addressing
    healthy lifestyles, fitness tracking, remote assistance, security applications,
    elderly care, and so on. Activity recognition transforms low-level sensor data
    from sensors, such as an accelerometer, gyroscope, pressure sensor, and GPS location,
    to a higher-level description of behavior primitives.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 活动识别是行为分析的基础步骤，涉及健康生活方式、健身追踪、远程协助、安全应用、老年护理等。活动识别将来自加速度计、陀螺仪、压力传感器和GPS位置等传感器的低级传感器数据转换为对行为原语的高级描述。
- en: 'In most cases, these are basic activities, for example, walking, sitting, lying,
    jumping, and so on, as shown in the following diagram, or they could be more complex
    behaviors, such as going to work, preparing breakfast, and shopping:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，这些是基本活动，例如以下图中所示的行走、坐着、躺着、跳跃等，或者它们可能是更复杂的行为，如去上班、准备早餐和购物等：
- en: '![](img/d4d199bf-5cb5-4eb0-a589-d09e8154e63f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d4d199bf-5cb5-4eb0-a589-d09e8154e63f.png)'
- en: In this chapter, we will discuss how to add the activity recognition functionality
    into a mobile application. We will first look at what an activity recognition
    problem looks like, what kind of data we need to collect, what the main challenges
    are, and how to address them.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何将活动识别功能添加到移动应用程序中。我们首先将探讨活动识别问题是什么样的，我们需要收集哪些类型的数据，主要挑战是什么，以及如何解决这些问题。
- en: Later, we will follow an example to see how to actually implement activity recognition
    in an Android application, including data collection, data transformation, and
    building a classifier.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将通过一个示例来了解如何在Android应用程序中实际实现活动识别，包括数据收集、数据转换和构建分类器。
- en: Let's start!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Mobile phone sensors
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移动电话传感器
- en: Let's first review what kind of mobile phone sensors there are and what they
    report. Most smart devices are now equipped with several built-in sensors that
    measure the motion, position, orientation, and conditions of the ambient environment.
    As sensors provide measurements with high precision, frequency, and accuracy,
    it is possible to reconstruct complex user motions, gestures, and movements. Sensors
    are often incorporated in various applications; for example, gyroscope readings
    are used to steer an object in a game, GPS data is used to locate the user, and
    accelerometer data is used to infer the activity that the user is performing,
    for example, cycling, running, or walking.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先回顾一下有哪些类型的移动电话传感器以及它们报告的内容。现在大多数智能设备都配备了几个内置传感器，这些传感器可以测量运动、位置、朝向和环境条件。由于传感器提供高精度、频率和准确性的测量，因此可以重建复杂用户运动、手势和动作。传感器常被集成到各种应用中；例如，陀螺仪读数用于在游戏中控制物体，GPS数据用于定位用户，加速度计数据用于推断用户正在执行的活动，例如骑自行车、跑步或行走。
- en: 'The following diagram shows a couple of examples of what kinds of interactions
    the sensors are able to detect:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了传感器能够检测到的几种交互类型示例：
- en: '![](img/6527115b-62c1-444e-a989-6ee81830bc25.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6527115b-62c1-444e-a989-6ee81830bc25.png)'
- en: 'Mobile phone sensors can be classified into the following three broad categories:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 移动电话传感器可以分为以下三个广泛的类别：
- en: '**Motion sensors:** This sensor measures acceleration and rotational forces
    along the three perpendicular axes. Examples of sensors in this category include
    accelerometers, gravity sensors, and gyroscopes.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运动传感器**：此传感器测量沿三个垂直轴的加速度和旋转力。此类传感器包括加速度计、重力传感器和陀螺仪。'
- en: '**Environmental sensors:** This sensor measures a variety of environmental
    parameters, such as illumination, air temperature, pressure, and humidity. This
    category includes barometers, photometers, and thermometers.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境传感器**：此传感器测量各种环境参数，如光照、空气温度、压力和湿度。此类包括气压计、光度计和温度计。'
- en: '**Position sensors:** This sensor measure the physical position of a device.
    This category includes orientation sensors and magnetometers.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**位置传感器**：此传感器测量设备的物理位置。此类包括方向传感器和磁力计。'
- en: 'More detailed descriptions for different mobile platforms are available at
    the following links:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 不同移动平台的更详细描述可在以下链接中找到：
- en: '**Android sensors framework**: [http://developer.android.com/guide/topics/sensors/sensors_overview.html](http://developer.android.com/guide/topics/sensors/sensors_overview.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Android传感器框架**：[http://developer.android.com/guide/topics/sensors/sensors_overview.html](http://developer.android.com/guide/topics/sensors/sensors_overview.html)'
- en: '**iOS Core Motion framework**: [https://developer.apple.com/library/ios/documentation/CoreMotion/Reference/CoreMotion_Reference/](https://developer.apple.com/library/ios/documentation/CoreMotion/Reference/CoreMotion_Reference/)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**iOS Core Motion框架**：[https://developer.apple.com/library/ios/documentation/CoreMotion/Reference/CoreMotion_Reference/](https://developer.apple.com/library/ios/documentation/CoreMotion/Reference/CoreMotion_Reference/)'
- en: '**Windows phone**: [https://msdn.microsoft.com/en-us/library/windows/apps/hh202968(v=vs.105).aspx](https://msdn.microsoft.com/en-us/library/windows/apps/hh202968(v=vs.105).aspx)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Windows phone**：[https://msdn.microsoft.com/en-us/library/windows/apps/hh202968(v=vs.105).aspx](https://msdn.microsoft.com/en-us/library/windows/apps/hh202968(v=vs.105).aspx)'
- en: In this chapter, we will work only with Android's sensors framework.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将仅使用Android的传感器框架。
- en: Activity recognition pipeline
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 活动识别流程
- en: Classifying multidimensional time series sensor data is inherently more complex
    than classifying traditional nominal data, as we saw in the previous chapters.
    First, each observation is temporally connected to the previous and following
    observations, making it very difficult to apply a straightforward classification
    of a single set of observations only. Second, the data obtained by sensors at
    different time points is stochastic, that is, unpredictable due to the influence
    of sensor noise, environmental disturbances, and many other factors. Moreover,
    an activity can consist of various sub-activities executed in a different manner
    and each person performs the activity a bit differently, which results in high
    intraclass differences. Finally, all these reasons make an activity recognition
    model imprecise, resulting in new data often being misclassified. One of the highly
    desirable properties of an activity recognition classifier is to ensure continuity
    and consistency in the recognized activity sequence.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在前几章中看到的不同，对多维时间序列传感器数据进行分类本质上比分类传统名义数据更复杂。首先，每个观测值在时间上都与前一个和后一个观测值相关联，这使得仅对一组观测值进行直接分类变得非常困难。其次，传感器在不同时间点获得的数据是随机的，即由于传感器噪声、环境干扰等因素的影响，是不可预测的。此外，一项活动可以由以不同方式执行的各种子活动组成，每个人执行活动的方式也略有不同，这导致类内差异很大。最后，所有这些原因使得活动识别模型不够精确，导致新数据经常被错误分类。活动识别分类器的一个高度期望的特性是确保识别的活动序列的连续性和一致性。
- en: 'To deal with these challenges, activity recognition is applied to a pipeline,
    as shown in the following diagram:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，活动识别被应用于以下流程，如图所示：
- en: '![](img/5b904185-1b46-41ac-b1fa-73ebb843c034.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5b904185-1b46-41ac-b1fa-73ebb843c034.png)'
- en: In the first step, we attenuate as much noise as we can, for example, by reducing
    the sensor sampling rate, removing outliers, applying high-or low-pass filters,
    and so on. In the next phase, we construct a feature vector. For instance, we
    convert sensor data from time domain to frequency domain by applying a **discrete
    Fourier transform** (**DFT**). DFT is a method that takes a list of samples as
    an input and returns a list of sinusoid coefficients ordered by their frequencies.
    They represent a combination of frequencies that are present in the original list
    of samples.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步，我们尽可能地减少噪声，例如，通过降低传感器采样率、移除异常值、应用高通或低通滤波器等。在下一阶段，我们构建一个特征向量。例如，我们通过应用**离散傅里叶变换**（**DFT**）将传感器数据从时域转换为频域。DFT
    是一种将一系列样本作为输入并返回按频率顺序排列的正弦系数列表的方法。它们代表了原始样本列表中存在的频率组合。
- en: A gentle introduction to the Fourier transform was written by Pete Bevelacqua
    at [http://www.thefouriertransform.com/](http://www.thefouriertransform.com/).
    If you want to get a more technical and theoretical background on the Fourier
    transform, take a look at the eighth and ninth lectures in the class by Robert
    Gallager and Lizhong Zheng at this MIT open course: [http://theopenacademy.com/content/principles-digital-communication](http://theopenacademy.com/content/principles-digital-communication).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Pete Bevelacqua 在 [http://www.thefouriertransform.com/](http://www.thefouriertransform.com/)
    写了一篇关于傅里叶变换的温和介绍。如果你想要获取关于傅里叶变换的更技术性和理论性的背景知识，可以查看罗伯特·加勒格尔和郑丽中在麻省理工学院开放课程中的第八和第九讲：[http://theopenacademy.com/content/principles-digital-communication](http://theopenacademy.com/content/principles-digital-communication)。
- en: Next, based on the feature vector and set of training data, we can build an
    activity recognition model that assigns an atomic action to each observation.
    Therefore, for each new sensor reading, the model will output the most probable
    activity label. However, models make mistakes. Hence, the last phase smooths the
    transitions between activities by removing transitions that cannot occur in reality;
    for example, it is not physically feasible that the transition between the activities
    lying-standing-lying occur in less than half a second, hence such a transition
    between activities is smoothed as lying-lying-lying.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，基于特征向量和训练数据集，我们可以构建一个活动识别模型，将原子动作分配给每个观察结果。因此，对于每个新的传感器读数，模型将输出最可能的动作标签。然而，模型会犯错误。因此，最后一个阶段通过移除在现实中不可能发生的转换来平滑活动之间的过渡；例如，活动从躺到站再到躺的转换在不到半秒内发生在物理上是不可能的，因此这种活动之间的转换被平滑为躺-躺-躺。
- en: The activity recognition model is constructed with a supervised learning approach,
    which consists of training and classification steps. In the training step, a set
    of labeled data is provided to train the model. The second step is used to assign
    a label to the new unseen data by the trained model. The data in both phases must
    be preprocessed with the same set of tools, such as filtering and feature vector
    computation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 活动识别模型是通过监督学习方法构建的，包括训练和分类步骤。在训练步骤中，提供一组标记数据来训练模型。第二步是使用训练好的模型为新未见数据分配标签。两个阶段中的数据都必须使用相同的工具进行预处理，例如过滤和特征向量计算。
- en: The post processing phase, that is, spurious activity removal, can also be a
    model itself and hence also requires a learning step. In this case, the preprocessing
    step also includes activity recognition, which makes such arrangement of classifiers
    into a meta-learning problem. To avoid overfitting, it is important that the dataset
    used for training the post processing phase is not the same as the one used for
    training the activity recognition model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理阶段，即虚假活动的移除，也可以是一个模型本身，因此也需要一个学习步骤。在这种情况下，预处理步骤也包括活动识别，这使得这样的分类器排列成为一个元学习问题。为了避免过拟合，重要的是用于训练后处理阶段的训练数据集不能与用于训练活动识别模型的训练数据集相同。
- en: The plan
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计划
- en: 'The plan consists of a training phase and a deployment phase. The training
    phase boils down to the following steps:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 计划包括一个训练阶段和一个部署阶段。训练阶段可以归结为以下步骤：
- en: Install Android Studio and import `MyRunsDataCollector.zip`.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Android Studio 并导入 `MyRunsDataCollector.zip`。
- en: Load the application on your Android phone.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的 Android 手机上加载应用程序。
- en: Collect your data, for example, standing, walking, and running, and transform
    the data to a feature vector consisting of FFTs. Don't panic; low-level signal
    processing functions such as FFTs will not be written from scratch as we will
    use existing code to do that. The data will be saved on your phone in a file called
    `features.arff`.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集您的数据，例如站立、行走和跑步，并将数据转换为包含 FFT 的特征向量。不要慌张；我们不会从头开始编写低级信号处理函数，如 FFT，我们将使用现有的代码来完成这项工作。数据将被保存在您的手机上，文件名为
    `features.arff`。
- en: Create and evaluate an activity recognition classifier using exported data and
    implement a filter for spurious activity transition removal.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用导出的数据创建并评估一个活动识别分类器，并实现一个用于去除虚假活动转换的过滤器。
- en: Plug the classifier back into the mobile application.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分类器重新连接到移动应用程序。
- en: If you don't have an Android phone, or if you want to skip all the steps related
    to the mobile application, just grab the collected dataset located in `data/features.arff`
    and jump directly to the *Building a classifier* section.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有 Android 手机，或者想跳过所有与移动应用程序相关的步骤，只需获取位于 `data/features.arff` 中的收集数据集，然后直接跳转到“构建分类器”部分。
- en: Collecting data from a mobile phone
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从手机收集数据
- en: This section describes the first three steps from the plan. If you want to directly
    work with the data, you can just skip this section and continue to the *Building
    a classifier* section. The application implements the essentials to collect sensor
    data for different activity classes, for example, standing, walking, running,
    and others.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了计划中的前三个步骤。如果您想直接处理数据，可以跳过本节，继续到“构建分类器”部分。该应用程序实现了收集不同活动类（例如站立、行走、跑步等）传感器数据的必要功能。
- en: Let's start by preparing the Android development environment. If you have already
    installed it, jump to the *Loading the data collector* section.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从准备 Android 开发环境开始。如果您已经安装了它，请跳转到“加载数据收集器”部分。
- en: Installing Android Studio
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Android Studio
- en: Android Studio is a development environment for the Android platform. We will
    quickly review the installation steps and basic configurations required to start
    the app on a mobile phone. For a more detailed introduction to Android development,
    I would recommend an introductory book, *Android 5 Programming by Example* by
    Kyle Mew, Packt Publishing.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Android Studio 是 Android 平台的开发环境。我们将快速回顾启动手机上应用程序所需的安装步骤和基本配置。如果您想了解更多关于 Android
    开发的信息，我推荐阅读 Kyle Mew 编著的 Packt Publishing 出版的入门书籍《Android 5 编程实例》。
- en: Grab the latest Android Studio for developers at [https://developer.android.com/studio/](https://developer.android.com/studio/) and
    follow the installation instructions at [http://developer.android.com/sdk/installing/index.html?pkg=studio](http://developer.android.com/sdk/installing/index.html?pkg=studio).
    The installation will take around 10 minutes, occupying approximately 0.5 GB of
    space.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [https://developer.android.com/studio/](https://developer.android.com/studio/)
    为开发者获取最新的 Android Studio，并按照 [http://developer.android.com/sdk/installing/index.html?pkg=studio](http://developer.android.com/sdk/installing/index.html?pkg=studio)
    中的安装说明进行操作。安装大约需要 10 分钟，大约占用 0.5 GB 的空间。
- en: 'Follow the instructions and select your preferred options for installation,
    and finally click on Finish to start the installation, as shown in the following
    screenshot:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 按照说明操作，选择您想要的安装选项，最后点击完成以开始安装，如下面的截图所示：
- en: '![](img/5b8f52fb-fe94-46e3-9211-02479536c078.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5b8f52fb-fe94-46e3-9211-02479536c078.png)'
- en: Loading the data collector
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据收集器
- en: 'First, grab the source code of `MyRunsDataCollector` from GitHub. Once Android
    Studio is installed, choose the Open an existing Android Studio project option, as
    shown in the following screenshot, and select the `MyRunsDataCollector` folder.
    This will import the project to Android Studio:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从 GitHub 获取 `MyRunsDataCollector` 的源代码。一旦安装了 Android Studio，选择“打开现有的 Android
    Studio 项目”选项，如下面的截图所示，并选择 `MyRunsDataCollector` 文件夹。这将把项目导入到 Android Studio 中：
- en: '![](img/01b5d01c-a503-4b36-a0d3-fba9979da67d.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/01b5d01c-a503-4b36-a0d3-fba9979da67d.png)'
- en: 'After the project import is completed, you should be able to see the project
    file structure, as shown in the following screenshot. The collector consists of
    `CollectorActivity.java`, `Globals.java`, and `SensorsService.java`. The project
    also shows `FFT.java` implementing low-level signal processing:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 项目导入完成后，您应该能够看到项目文件结构，如下面的截图所示。收集器包括 `CollectorActivity.java`、`Globals.java`
    和 `SensorsService.java`。项目还显示了实现低级信号处理的 `FFT.java`：
- en: '![](img/a4f1dc26-7697-465a-b268-a5dfcd0a3284.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a4f1dc26-7697-465a-b268-a5dfcd0a3284.png)'
- en: 'The main `myrunscollector` package contains the following classes:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`myrunscollector`主包包含以下类：'
- en: '`Globals.java`: This defines global constants, such as activity labels and
    IDs, and data filenames.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Globals.java`：这个类定义了全局常量，例如活动标签和ID，以及数据文件名。'
- en: '`CollectorActivity.java`: This implements user interface actions, that is,
    what happens when a specific button is pressed.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CollectorActivity.java`：这个类实现了用户界面动作，即当按下特定按钮时会发生什么。'
- en: '`SensorsService.java`: This implements a service that collects data, calculates
    the feature vector, as we will discuss in the following sections, and stores the
    data into a file on the phone.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SensorsService.java`：这个类实现了一个收集数据、计算特征向量（我们将在以下章节中讨论）并将数据存储到手机上的文件中的服务。'
- en: The next question that we will address is how to design features.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要解决的问题是如何设计特征。
- en: Feature extraction
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取
- en: Finding an appropriate representation of a person's activities is probably the
    most challenging part of activity recognition. The behavior needs to be represented
    with simple and general features so that the model using these features will also
    be general and work well on behaviors different from those in the learning set.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 找到一个人活动适当的表现形式可能是活动识别中最具挑战性的部分。行为需要用简单和通用的特征来表示，这样使用这些特征的模型也将是通用的，并且在不同行为上也能很好地工作。
- en: 'In fact, it is not difficult to design features specific to the captured observations
    in a training set; such features would work well on them. However, as the training
    set captures only a part of the whole range of human behavior, overly specific
    features would likely fail on general behavior:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，设计针对训练集中捕获的观察特定特征并不困难；这些特征在它们身上会工作得很好。然而，由于训练集仅捕获人类行为范围的一部分，过于特定的特征可能在一般行为上失败：
- en: '![](img/33155cd1-f586-4674-a049-7ceb1c018cf9.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/33155cd1-f586-4674-a049-7ceb1c018cf9.png)'
- en: Let's see how this is implemented in `MyRunsDataCollector`. When the application
    is started, a method called `onSensorChanged()` gets a triple of accelerometer
    sensor readings (**x**, **y**, and **z**) with a specific timestamp and calculates
    the magnitude from the sensor readings. The methods buffers up to 64 consecutive
    magnitudes marked before computing the FFT coefficients.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这在`MyRunsDataCollector`中的实现方式。当应用程序启动时，一个名为`onSensorChanged()`的方法会获取一个包含加速度计传感器读数的三元组（**x**、**y**和**z**）以及特定的时戳，并从传感器读数中计算振幅。方法会缓冲最多64个连续的振幅，在计算FFT系数之前标记它们。
- en: Now, let's move on to the actual data collection.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续实际数据收集。
- en: Collecting training data
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集训练数据
- en: We can now use the collector to collect training data for activity recognition.
    The collector supports three activities by default, standing, walking, and running,
    as shown in the following screenshot.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用收集器来收集活动识别的训练数据。收集器默认支持三种活动：站立、行走和跑步，如下面的截图所示。
- en: You can select an activity, that is, target class value, and start recording
    the data by clicking the START COLLECTING button. Make sure that each activity
    is recorded for at least three minutes; for example, if the Walking activity is
    selected, press START COLLECTING and walk around for at least three minutes. At
    the end of the activity, press Stop collecting. Repeat this for each of the activities.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择一个活动，即目标类值，然后通过点击“开始收集”按钮开始记录数据。确保每个活动至少记录三分钟；例如，如果选择了行走活动，请按“开始收集”并至少行走三分钟。活动结束后，请按“停止收集”。对每个活动重复此操作。
- en: You could also collect different scenarios involving these activities, for example,
    walking in the kitchen, walking outside, walking in a line, and so on. By doing
    so, you will have more data for each activity class and a better classifier. Makes
    sense, right? The more data, the less confused the classifier will be. If you
    only have a little data, overfitting will occur and the classifier will confuse
    classes—standing with walking, walking with running, and so on. However, the more
    data, the less they get confused. You might collect less than three minutes per
    class when you are debugging, but for your final polished product, the more data,
    the better it is. Multiple recording instances will simply be accumulated in the
    same file.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以收集涉及这些活动的不同场景，例如，在厨房里走动、在外面走动、成列行走等。通过这样做，你将为每个活动类别拥有更多数据，并且分类器会更好。有道理，对吧？数据越多，分类器就越不会困惑。如果你只有少量数据，就会发生过拟合，分类器会混淆类别——站立与行走、行走与跑步等。然而，数据越多，它们就越不容易混淆。在调试时，你可能每个类别收集不到三分钟的数据，但对你最终的产品来说，数据越多越好。多个录制实例将简单地累积在同一个文件中。
- en: 'Note, the Delete Data button removes the data that is stored in a file on the
    phone. If you want to start over again, hit Delete Data before starting; otherwise,
    the new collected data will be appended at the end of the file:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，删除数据按钮会删除存储在手机文件上的数据。如果你想重新开始，请在开始之前点击删除数据；否则，新收集的数据将被附加到文件末尾：
- en: '![](img/c2686cb4-6318-41ff-a9fb-7477b78b3d24.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c2686cb4-6318-41ff-a9fb-7477b78b3d24.png)'
- en: 'The collector implements the diagram discussed in the previous sections: it
    collects accelerometer samples, computes the magnitudes, uses the `FFT.java` class
    to compute the coefficients, and produces the feature vectors. The data is then
    stored in a Weka-formatted `features.arff` file. The number of feature vectors
    will vary based on the amount of data you collect. The longer you collect the
    data, the more feature vectors are accumulated.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 收集器实现了前几节中讨论的图：它收集加速度计样本，计算幅度，使用`FFT.java`类计算系数，并生成特征向量。然后，数据存储在Weka格式的`features.arff`文件中。特征向量的数量将根据你收集的数据量而变化。你收集数据的时间越长，累积的特征向量就越多。
- en: 'Once you stop collecting the training data using the collector tool, we need
    to grab the data to carry on the workflow. We can use the file explorer in Android
    Device Monitor to upload the `features.arff` file from the phone and to store
    it on the computer. You can access your Android Device Monitor by clicking on
    the Android robot icon, as shown in the following screenshot:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你停止使用收集工具收集训练数据，我们需要抓取数据以继续工作流程。我们可以使用Android设备监控器中的文件浏览器上传手机上的`features.arff`文件并将其存储在计算机上。你可以通过点击以下截图中的Android机器人图标来访问你的Android设备监控器：
- en: '![](img/740619dc-a878-409f-80b4-853062f94596.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/740619dc-a878-409f-80b4-853062f94596.png)'
- en: 'By selecting your device on the left, your phone storage content will be shown
    on the right-hand side. Navigate through `mnt/shell/emulated/Android/data/edu.dartmouth.cs.myrunscollector/files/features.arff`,
    as shown in the following screenshot:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在左侧选择你的设备，你可以在右侧看到你的手机存储内容。导航到`mnt/shell/emulated/Android/data/edu.dartmouth.cs.myrunscollector/files/features.arff`，如下截图所示：
- en: '![](img/ff6dd849-fe2b-42f2-bb3b-a50b03814875.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ff6dd849-fe2b-42f2-bb3b-a50b03814875.png)'
- en: To upload this file to your computer, you need to select the file (it is highlighted)
    and click on Upload.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此文件上传到你的计算机，你需要选择文件（它被突出显示）并点击上传。
- en: Now, we are ready to build a classifier.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备构建一个分类器。
- en: Building a classifier
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建分类器
- en: Once sensor samples are represented as feature vectors and have the class assigned,
    it is possible to apply standard techniques for supervised classification, including
    feature selection, feature discretization, model learning, k-fold cross-validation,
    and so on. The chapter will not delve into the details of the machine learning
    algorithms. Any algorithm that supports numerical features can be applied, including
    SVMs, random forest, AdaBoost, decision trees, neural networks, multilayer perceptrons,
    and others.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦将传感器样本表示为特征向量并分配了类别，就可以应用标准的有监督分类技术，包括特征选择、特征离散化、模型学习、k-折交叉验证等。本章不会深入探讨机器学习算法的细节。任何支持数值特征的算法都可以应用，包括SVMs、随机森林、AdaBoost、决策树、神经网络、多层感知器等。
- en: 'Therefore, let''s start with a basic one: decision trees. Here, we will load
    the dataset, build the set class attribute, build a decision tree model, and output
    the model:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们从一个基本的开始：决策树。在这里，我们将加载数据集，构建类属性集，构建决策树模型，并输出模型：
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The algorithm first outputs the model, as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 算法首先输出模型，如下所示：
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The tree is quite simplistic and seemingly accurate, as majority class distributions
    in the terminal nodes are quite high. Let''s run a basic classifier evaluation
    to validate the results, as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 树的结构相当简单且看似准确，因为终端节点中的多数类分布相当高。让我们运行一个基本的分类器评估来验证结果，如下所示：
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This outputs the following model performance:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下模型性能：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The classification accuracy scores very high, `92.62%`, which is an amazing
    result. One important reason why the result is so good lies in our evaluation
    design. What I mean here is the following: sequential instances are very similar
    to each other, so if we split them randomly during a 10-fold cross-validation,
    there is a high chance that we use almost identical instances for both training
    and testing; hence, straightforward k-fold cross-validation produces an optimistic
    estimate of model performance.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 分类准确率得分非常高，`92.62%`，这是一个惊人的结果。结果之所以如此之好，一个重要原因在于我们的评估设计。我的意思是以下内容：序列实例彼此非常相似，因此如果我们在一个10折交叉验证过程中随机分割它们，那么我们使用几乎相同的实例进行训练和测试的可能性很高；因此，直接的k折交叉验证会产生对模型性能的乐观估计。
- en: A better approach is to use folds that correspond to different sets of measurements
    or even different people. For example, we can use the application to collect learning
    data from five people. Then, it makes sense to run k-person cross-validation,
    where the model is trained on four people and tested on the fifth person. The
    procedure is repeated for each person and the results are averaged. This will
    give us a much more realistic estimate of the model performance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的方法是使用与不同测量集或甚至不同人员相对应的折数。例如，我们可以使用该应用程序从五个人那里收集学习数据。然后，进行k个人交叉验证是有意义的，其中模型在四个人身上训练，在第五个人身上测试。对于每个人重复此过程，并将结果平均。这将给我们提供一个更现实的模型性能估计。
- en: Leaving evaluation comments aside, let's look at how to deal with classifier
    errors.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 不考虑评估注释，让我们看看如何处理分类错误。
- en: Reducing spurious transitions
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减少虚假转换
- en: At the end of the activity recognition pipeline, we want to make sure that the
    classifications are not too volatile, that is, we don't want activities to change
    every millisecond. A basic approach is to design a filter that ignores quick changes
    in the activity sequence.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在活动识别管道的末尾，我们想要确保分类不是太波动，也就是说，我们不希望活动每毫秒都改变。一个基本的方法是设计一个过滤器，它忽略活动序列中的快速变化。
- en: We build a filter that remembers the last window activities and returns the
    most frequent one. If there are multiple activities with the same score, it returns
    the most recent one.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建一个过滤器，它记住最后一个窗口活动并返回最频繁的一个。如果有多个活动具有相同的分数，它返回最近的一个。
- en: 'First, we create a new `SpuriousActivityRemoval` class, which will hold a list
    of activities and the `window` parameter:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个新的`SpuriousActivityRemoval`类，它将包含活动列表和`window`参数：
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we create the `Object filter(Object)` method, which will take an activity
    and return a filtered activity. The method first checks whether we have enough
    observations. If not, it simply stores the observation and returns the same value,
    as shown in the following code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建`Object filter(Object)`方法，该方法将接受一个活动并返回一个过滤后的活动。该方法首先检查我们是否有足够的观察结果。如果没有，它简单地存储观察结果并返回相同的值，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we already collected `window` observations, we simply return the most frequent
    observation, remove the oldest observation, and insert the new observation:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们已收集了`window`观察结果，我们只需返回最频繁的观察结果，删除最老的观察结果，并插入新的观察结果：
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'What is missing here is a function that returns the most frequent element from
    a list of objects. We implement this with a hash map, as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里缺少的是一个从对象列表中返回最频繁元素的函数。我们使用哈希映射来实现这一点，如下所示：
- en: '[PRE7]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we iterate over all the elements in the list, insert each unique element
    into a hash map, or update its counter if it is already in the hash map. At the
    end of the loop, we store the most frequent element that we found so far, as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们遍历列表中的所有元素，将每个唯一元素插入到哈希映射中，或者如果它已经在哈希映射中，则更新其计数器。循环结束时，我们存储迄今为止找到的最频繁元素，如下所示：
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s run a simple example:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行一个简单的例子：
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The example outputs the following activities:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 示例输出了以下活动：
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The result is a continuous sequence of activities, that is, we do not have quick
    changes. This adds some delay, but unless this is absolutely critical for the
    application, it is acceptable.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个连续的活动序列，也就是说，我们没有快速的变化。这增加了一些延迟，但除非这对应用程序至关重要，否则是可以接受的。
- en: 'Activity recognition may be enhanced by appending *n* previous activities,
    as recognized by the classifier, to the feature vector. The danger of appending
    previous activities is that the machine learning algorithm may learn that the
    current activity is always the same as the previous one, as this will often be
    the case. The problem may be solved by having two classifiers, A and B: classifier
    B''s attribute vector contains *n* previous activities as recognized by classifier
    A. Classifier A''s attribute vector does not contain any previous activities.
    This way, even if B gives a lot of weight to the previous activities, the previous
    activities as recognized by A will change as A is not burdened with B''s inertia.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将分类器识别的前*n*个活动附加到特征向量中，可以增强活动识别。将先前活动附加的危险是，机器学习算法可能会学习到当前活动总是与先前活动相同，因为这种情况通常会发生。可以通过拥有两个分类器A和B来解决这个问题：分类器B的属性向量包含由分类器A识别的*n*个先前活动。分类器A的属性向量不包含任何先前活动。这样，即使B对先前活动给予了很大的权重，由A识别的先前活动也会随着A不受B惯性的影响而改变。
- en: All that remains to do is to embed the classifier and filter it into our mobile
    application.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的工作是将分类器和过滤器嵌入到我们的移动应用程序中。
- en: Plugging the classifier into a mobile app
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将分类器插入到移动应用中
- en: 'There are two ways to incorporate a classifier into a mobile application. The
    first one involves exporting a model in the Weka format, using the Weka library
    as a dependency in our mobile application, loading the model, and so on. The procedure
    is identical to the example we saw in [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml),
    *Basic Algorithms–Classification, Regression, and Clustering*. The second approach
    is more lightweight: we export the model as source code, for example, we create
    a class implementing the decision tree classifier. Then, we can simply copy and
    paste the source code into our mobile app, without even importing any Weka dependencies.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以将分类器集成到移动应用程序中。第一种方法涉及使用Weka库将模型导出为Weka格式，将Weka库作为我们的移动应用程序的依赖项，加载模型等。该过程与我们在第3章中看到的示例相同，即*基本算法-分类、回归和聚类*。第二种方法更轻量级：我们将模型导出为源代码，例如，我们创建一个实现决策树分类器的类。然后，我们可以简单地复制并粘贴源代码到我们的移动应用中，甚至不需要导入任何Weka依赖项。
- en: 'Fortunately, some Weka models can be easily exported to source code by the
    `toSource(String)` function:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，一些Weka模型可以通过`toSource(String)`函数轻松导出为源代码：
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This outputs an `ActivityRecognitionEngine` class that corresponds to our model.
    Now, let''s take a closer look at the output code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出一个与我们的模型相对应的`ActivityRecognitionEngine`类。现在，让我们更仔细地看看输出代码：
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The outputted `ActivityRecognitionEngine` class implements the decision tree
    that we discussed earlier. The machine-generated function names, such as `N17a7cec20(Object
    [])`, correspond to decision tree nodes. The classifier can be called by the `classify(Object[])`
    method, where we should pass a feature vector obtained by the same procedure as
    we discussed in the previous sections. As usual, it returns a `double`, indicating
    a class label index.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的`ActivityRecognitionEngine`类实现了我们之前讨论的决策树。机器生成的函数名，如`N17a7cec20(Object [])`，对应于决策树节点。可以通过`classify(Object[])`方法调用分类器，其中我们应该传递通过与之前章节中讨论的相同程序获得的特征向量。像往常一样，它返回一个`double`值，表示类标签索引。
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed how to implement an activity recognition model
    for mobile applications. We looked into the completed process, including data
    collection, feature extraction, model building, evaluation, and model deployment.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何为移动应用程序实现活动识别模型。我们探讨了整个流程，包括数据收集、特征提取、模型构建、评估和模型部署。
- en: 'In the next chapter, we will move on to another Java library targeted at text
    analysis: Mallet.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将继续介绍另一个针对文本分析的Java库：Mallet。
