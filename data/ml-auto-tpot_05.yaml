- en: '*Chapter 3*: Exploring Regression with TPOT'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：使用TPOT探索回归'
- en: In this chapter, you'll get hands-on experience with automated regression modeling
    through three datasets. You will learn how to handle regression tasks with TPOT
    in an automated manner with tons of practical examples, tips, and advice.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将通过三个数据集获得自动回归建模的实践经验。您将学习如何以自动化的方式使用TPOT处理回归任务，并通过大量的实际示例、技巧和建议来掌握这一点。
- en: We will go through essential topics such as dataset loading, exploratory data
    analysis, and basic data preparation first. Then, we'll get our hands dirty with
    TPOT. You will learn how to train models in an automated way and how to evaluate
    those models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍一些基本主题，如数据集加载、探索性数据分析和基本数据准备。然后，我们将使用TPOT进行实践。您将学习如何以自动化的方式训练模型以及如何评估这些模型。
- en: Before training models automatically, we will see how good performance can be
    obtained with basic models, such as linear regression. These models will serve
    as a baseline that TPOT needs to outperform.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动训练模型之前，我们将看看如何通过基本模型（如线性回归）获得良好的性能。这些模型将作为TPOT需要超越的基准。
- en: 'This chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Applying automated regression modeling to the fish market dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自动回归建模应用于鱼市场数据集
- en: Applying automated regression modeling to the insurance dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自动回归建模应用于保险数据集
- en: Applying automated regression modeling to the vehicle dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自动回归建模应用于车辆数据集
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To complete this chapter, you will need a computer with Python and TPOT installed.
    The previous chapter demonstrated how to set up the environment from scratch for
    both standalone Python installation and installation through Anaconda. Refer to
    [*Chapter 2*](B16954_02_Final_SK_ePub.xhtml#_idTextAnchor036), *Deep Dive into
    TPOT*, for detailed instructions on environment setup.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成本章，您需要一个安装了Python和TPOT的计算机。上一章演示了如何从头开始设置环境，无论是独立的Python安装还是通过Anaconda安装。请参阅[*第2章*](B16954_02_Final_SK_ePub.xhtml#_idTextAnchor036)，*深入TPOT*，以获取环境设置的详细说明。
- en: 'You can download the source code and datasets for this chapter here: [https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter03](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter03)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处下载本章的源代码和数据集：[https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter03](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter03)
- en: Applying automated regression modeling to the fish market dataset
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将自动回归建模应用于鱼市场数据集
- en: 'This section demonstrates how to apply machine learning automation with TPOT
    to a regression dataset. The section uses the fish market dataset ([https://www.kaggle.com/aungpyaeap/fish-market](https://www.kaggle.com/aungpyaeap/fish-market))
    for exploration and regression modeling. The goal is to predict the weight of
    a fish. You will learn how to load the dataset, visualize it, adequately prepare
    it, and how to find the best machine learning pipeline with TPOT:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本节演示了如何使用TPOT将机器学习自动化应用于回归数据集。本节使用鱼市场数据集（[https://www.kaggle.com/aungpyaeap/fish-market](https://www.kaggle.com/aungpyaeap/fish-market)）进行探索和回归建模。目标是预测鱼的重量。您将学习如何加载数据集、可视化它、充分准备它，以及如何使用TPOT找到最佳的机器学习流程：
- en: 'The first thing to do is to load in the required libraries and load in the
    dataset. With regards to the libraries, you''ll need `numpy`, `pandas`, `m``atplotlib`,
    and `seaborn`. Additionally, the `rcParams` module is imported with `matplotlib`
    to tweak the plot stylings a bit. You can find the code for this step in the following
    block:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先要做的事情是加载所需的库和数据集。关于库，您需要`numpy`、`pandas`、`matplotlib`和`seaborn`。此外，使用`matplotlib`导入`rcParams`模块以稍微调整绘图样式。您可以在以下代码块中找到此步骤的代码：
- en: '[PRE0]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here''s how the first couple of rows look (the result from calling the `head()`
    method):'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是如何查看前几行（调用`head()`方法的结果）：
- en: '![Figure 3.1 – First five rows of the fish market dataset'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.1 – 鱼市场数据集的前五行'
- en: '](img/B16954_03_001.jpg)'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_001.jpg)'
- en: Figure 3.1 – First five rows of the fish market dataset
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.1 – 鱼市场数据集的前五行
- en: 'Exploratory data analysis comes in next. It''s not a hard requirement for using
    TPOT, but you should always be aware of how your data looks. The first thing of
    interest is missing values. Here''s how to check for them:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 探索性数据分析将在下一部分介绍。这不是使用TPOT的硬性要求，但您应该始终了解您的数据看起来如何。最感兴趣的第一件事是缺失值。以下是检查它们的方法：
- en: '[PRE1]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And here''s the corresponding output:'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是相应的输出：
- en: '![Figure 3.2 – Count of missing values per column'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.2 – 每列缺失值的计数'
- en: '](img/B16954_03_002.jpg)'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_002.jpg)'
- en: Figure 3.2 – Count of missing values per column
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.2 – 每列缺失值的计数
- en: As you can see, there are no missing values. This makes the data preparation
    process much easier and shorter.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，没有缺失值。这使得数据准备过程更加容易和快捷。
- en: 'The next step is to check how the target variable is distributed. For this
    dataset, we are trying to predict `Weight`. Here''s the code for drawing a simple
    histogram:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是检查目标变量的分布情况。对于这个数据集，我们试图预测`Weight`。以下是绘制简单直方图的代码：
- en: '[PRE2]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And here''s how the histogram looks:'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是直方图的样子：
- en: '![Figure 3.3 – Histogram of the target variable (Weight)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.3 – 目标变量（重量）的直方图'
- en: '](img/B16954_03_003.jpg)'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_003.jpg)'
- en: Figure 3.3 – Histogram of the target variable (Weight)
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.3 – 目标变量（重量）的直方图
- en: Most of the fish are light, but there are a couple of heavy ones present. Let's
    explore species further to get a better grasp.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数鱼都很轻，但也有一些重的。让我们进一步探索物种，以获得更好的了解。
- en: The following code prints how many instances of a specific species there are
    (the number and percentage of the total), and also prints average and standard
    deviation for every attribute. To be more precise, a subset of the original dataset
    is kept where the species equals the specified species. Afterward, the number
    of records, total percentage, mean, and standard deviation are printed for every
    column in the subset.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码打印了特定物种的实例数量（总数和百分比），并且还打印了每个属性的均值和标准差。为了更精确，我们保留了原始数据集中物种等于指定物种的子集。之后，为子集中的每一列打印了记录数、总百分比、均值和标准差。
- en: 'This function is then called for every unique species:'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后这个函数被调用以针对每个独特的物种：
- en: '[PRE3]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here''s the corresponding output:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是相应的输出：
- en: '![Figure 3.4 – Feature exploration for every fish species'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.4 – 每种鱼的特征探索'
- en: '](img/B16954_03_004.jpg)'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_004.jpg)'
- en: Figure 3.4 – Feature exploration for every fish species
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.4 – 每种鱼的特征探索
- en: 'Finally, let''s check for correlation between attributes. Correlation can be
    calculated only for numerical attributes. The following snippet shows you how
    to visualize a correlation matrix with the `seaborn` library:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们检查属性之间的相关性。相关性只能计算数值属性。以下代码片段展示了如何使用`seaborn`库可视化相关矩阵：
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here''s the correlation matrix:'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是相关矩阵：
- en: '![Figure 3.5 – Correlation matrix of features'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.5 – 特征的相关矩阵'
- en: '](img/B16954_03_005.jpg)'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_005.jpg)'
- en: Figure 3.5 – Correlation matrix of features
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.5 – 特征的相关矩阵
- en: You can do more in the exploratory data analysis process, but we'll stop here.
    This book shows you how to build automated models with TPOT, so we should spend
    most of the time there.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在探索性数据分析过程中，你可以做更多的事情，但我们将在这里停止。这本书展示了如何使用TPOT构建自动化模型，因此我们应该在那里花大部分时间。
- en: 'There''s one step left to do before modeling, and that is data preparation.
    We can''t pass non-numerical attributes to the pipeline optimizer. We''ll convert
    them to dummy variables for simplicity''s sake and merge them with the original
    data afterward. Here''s the code for doing so:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在建模之前，我们还有一步要做，那就是数据准备。我们不能将非数值属性传递给管道优化器。我们将它们转换为虚拟变量以简化问题，并在之后将它们与原始数据合并。以下是执行此操作的代码：
- en: '[PRE5]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And here''s how the dataset looks now:'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是数据集现在的样子：
- en: '![Figure 3.6 – First five rows of the fish market dataset after data preparation'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.6 – 数据准备后的鱼市场数据集的前五行'
- en: '](img/B16954_03_006.jpg)'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_006.jpg)'
- en: Figure 3.6 – First five rows of the fish market dataset after data preparation
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.6 – 数据准备后的鱼市场数据集的前五行
- en: As you can see, we deleted the `Species` column because it's not needed anymore.
    Let's begin with the modeling next.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，我们删除了`Species`列，因为它不再需要。让我们接下来开始建模。
- en: 'To start, we need to make a couple of imports and decide on the scoring strategy.
    TPOT comes with a couple of regression scoring metrics. The default one is `neg_mean_squared_error`.
    We can''t escape the negative metric, but we can at least make it be in the same
    units as the target variable is. It makes no sense to predict weight and keep
    track of errors in weight squared. That''s where **Root Mean Squared Error** (**RMSE**)
    comes into play. It is a simple metric that calculates the square root of the
    previously discussed mean squared error. Due to the square root operations, we''re
    tracking errors in the original units (weight) instead of squared units (weight
    squared). We will define it with the help of lambda functions:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要做一些导入并决定评分策略。TPOT自带一些回归评分指标。默认的是`neg_mean_squared_error`。我们无法避免负指标，但至少可以使其与目标变量的单位相同。预测重量并跟踪重量平方的错误是没有意义的。这就是**均方根误差**（**RMSE**）发挥作用的地方。这是一个简单的指标，它计算先前讨论的均方误差的平方根。由于平方根运算，我们跟踪的是原始单位（重量）中的错误，而不是平方单位（重量平方）。我们将使用lambda函数来定义它：
- en: '[PRE6]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next on the requirement list is the train test split. We will keep 75% of the
    data for training and evaluate on the rest:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来在需求列表上是训练测试集分割。我们将保留75%的数据用于训练，并在剩余的数据上进行评估：
- en: '[PRE7]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here''s how many instances are in the train and test sets, respectively:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是训练集和测试集中实例的数量：
- en: '![Figure 3.7 – Number of instances in the training and test sets'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.7 – 训练集和测试集中的实例数量](img/B16954_03_007.jpg)'
- en: '](img/B16954_03_007.jpg)'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_007.jpg](img/B16954_03_007.jpg)'
- en: Figure 3.7 – Number of instances in the training and test sets
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.7 – 训练集和测试集中的实例数量
- en: 'Next, let''s make a model with the linear regression algorithm. This model
    is just a baseline that TPOT needs to outperform:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们使用线性回归算法创建一个模型。这个模型只是TPOT需要超越的基线：
- en: '[PRE8]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here''s the corresponding RMSE value for linear regression on the test set:'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是测试集上线性回归的相应RMSE值：
- en: '![Figure 3.8 – RMSE score for the linear regression model (baseline)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.8 – 线性回归模型的RMSE评分（基线）](img/B16954_03_008.jpg)'
- en: '](img/B16954_03_008.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_008.jpg](img/B16954_03_008.jpg)'
- en: Figure 3.8 – RMSE score for the linear regression model (baseline)
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.8 – 线性回归模型的RMSE评分（基线）
- en: The baseline model is wrong by 82 units of weight on average. Not bad, considering
    we have weights up to 1,500\.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基线模型平均错误为82个权重单位。考虑到我们的权重高达1,500，这还不错。
- en: 'Next, let''s fit a TPOT pipeline optimization model. We will use our RMSE scorer
    and perform the optimization for 10 minutes. You can optimize for more time, but
    10 minutes should outperform the baseline model:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们拟合一个TPOT管道优化模型。我们将使用我们的RMSE评分器，并进行10分钟的优化。你可以优化更长的时间，但10分钟应该优于基线模型：
- en: '[PRE9]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After the optimization has finished, here''s the output that''s shown in the
    console:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 优化完成后，控制台显示的输出如下：
- en: '![Figure 3.9 – TPOT regressor output'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.9 – TPOT回归器输出](img/B16954_03_010.jpg)'
- en: '](img/B16954_03_009.jpg)'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_009.jpg](img/B16954_03_009.jpg)'
- en: Figure 3.9 – TPOT regressor output
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.9 – TPOT回归器输出
- en: 'Here''s how to obtain the RMSE score:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是获取RMSE评分的方法：
- en: '[PRE10]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And here is the corresponding output:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是相应的输出：
- en: '![Figure 3.10 – RMSE score for TPOT optimized pipeline model'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.10 – TPOT优化管道模型的RMSE评分](img/B16954_03_010.jpg)'
- en: '](img/B16954_03_010.jpg)'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_010.jpg](img/B16954_03_010.jpg)'
- en: Figure 3.10 – RMSE score for TPOT optimized pipeline model
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.10 – TPOT优化管道模型的RMSE评分
- en: 'Don''t worry about the minus sign before the number. The actual RMSE is 73.35
    units of weight. The TPOT model outperformed the baseline one. That''s all you
    need to know. TPOT gives us access to the best pipeline through the `fitted_pipeline_`
    attribute. Here''s how it looks:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要担心数字前面的负号。实际的RMSE是73.35个重量单位。TPOT模型优于基线模型。这就是你需要知道的一切。TPOT通过`fitted_pipeline_`属性给我们提供了访问最佳管道的途径。以下是它的样子：
- en: '![Figure 3.11 – Full TPOT pipeline'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.11 – 完整的TPOT管道](img/B16954_03_011.jpg)'
- en: '](img/B16954_03_011.jpg)'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_011.jpg](img/B16954_03_011.jpg)'
- en: Figure 3.11 – Full TPOT pipeline
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.11 – 完整的TPOT管道
- en: 'As a final step, we can export the pipeline to a Python file. Here''s how:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为最后一步，我们可以将管道导出到Python文件中。以下是方法：
- en: '[PRE11]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here''s what the file looks like:'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文件看起来是这样的：
- en: '![Figure 3.12 – Source code of the TPOT pipeline'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12 – TPOT管道的源代码](img/B16954_03_012.jpg)'
- en: '](img/B16954_03_012.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16954_03_012.jpg](img/B16954_03_012.jpg)'
- en: Figure 3.12 – Source code of the TPOT pipeline
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – TPOT管道的源代码
- en: You can now use this file to make predictions on new, unseen data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以使用这个文件对新数据做出预测。
- en: In this section, you've built your first automated machine learning pipeline
    with TPOT on a simple dataset. Most of the time, in practice, the steps you take
    will look similar. It's the data cleaning and preparation where things differ.
    Always make sure to prepare your dataset adequately before passing it to TPOT.
    Sure, TPOT does many things for you, but it can't turn garbage data into a usable
    model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您已经在简单数据集上使用TPOT构建了您的第一个自动机器学习流程。在实践中，大多数情况下，您所采取的步骤看起来会很相似。数据清洗和准备是其中有所不同之处。始终确保在将数据集传递给TPOT之前充分准备您的数据集。当然，TPOT为您做了很多事情，但它不能将垃圾数据转化为可用的模型。
- en: In the next section, you'll see how to apply TPOT to the medical insurance dataset.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将看到如何将TPOT应用于医疗保险数据集。
- en: Applying automated regression modeling to the insurance dataset
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将自动回归建模应用于保险数据集
- en: 'This section demonstrates how to apply an automated machine learning solution
    to a slightly more complicated dataset. You will use the medical insurance cost
    dataset ([https://www.kaggle.com/mirichoi0218/insurance](https://www.kaggle.com/mirichoi0218/insurance))
    to predict how much insurance will cost based on a couple of predictor variables.
    You will learn how to load the dataset, perform exploratory data analysis, how
    to prepare it, and how to find the best machine learning pipeline with TPOT:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本节演示了如何将自动机器学习解决方案应用于一个稍微复杂一些的数据集。您将使用医疗保险成本数据集（[https://www.kaggle.com/mirichoi0218/insurance](https://www.kaggle.com/mirichoi0218/insurance)）来预测基于几个预测变量保险费用将花费多少。您将学习如何加载数据集，进行数据探索性分析，如何准备数据，以及如何使用TPOT找到最佳的机器学习流程：
- en: 'As with the previous example, the first step is to load in the libraries and
    the dataset. We''ll need `numpy`, `pandas`, `m``atplotlib`, and `seaborn` to start
    with the analysis. Here''s how to import the libraries and load the dataset:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与前面的例子一样，第一步是加载库和数据集。我们需要`numpy`、`pandas`、`matplotlib`和`seaborn`来开始分析。以下是导入库和加载数据集的方法：
- en: '[PRE12]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The first five rows are shown in the following figure:'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图中显示了前五行：
- en: '![Figure 3.13 – First five rows of the insurance dataset'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![Figure 3.13 – First five rows of the insurance dataset'
- en: '](img/B16954_03_013.jpg)'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_013.jpg](img/B16954_03_013.jpg)'
- en: Figure 3.13 – First five rows of the insurance dataset
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.13 – 医疗保险数据集的前五行
- en: 'We''ll continue with the exploratory data analysis. As with the previous example,
    we''ll first check for the number of missing values. Here''s the code for doing
    so:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将继续进行数据探索性分析。与前面的例子一样，我们首先将检查缺失值的数量。以下是执行此操作的代码：
- en: '[PRE13]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following figure shows counts of missing values per column:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图显示了每列的缺失值计数：
- en: '![Figure 3.14 – Missing value counts per column for the insurance dataset'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![Figure 3.14 – Missing value counts per column for the insurance dataset'
- en: '](img/B16954_03_014.jpg)'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_014.jpg](img/B16954_03_014.jpg)'
- en: Figure 3.14 – Missing value counts per column for the insurance dataset
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.14 – 医疗保险数据集每列的缺失值计数
- en: As you can see, there are no missing values.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，没有缺失值。
- en: 'We''re trying to predict the `charges` column with this dataset, so let''s
    quickly check what type of values we can expect there. A histogram seems like
    an easy enough option. Here''s the code needed for drawing one:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们试图使用这个数据集预测`charges`列，所以让我们快速检查我们可以在那里期望什么类型的值。直方图似乎是一个足够简单的选项。以下是绘制直方图所需的代码：
- en: '[PRE14]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And here''s the resulting histogram:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是相应的直方图：
- en: '![Figure 3.15 – Distribution of the target variable'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![Figure 3.15 – Distribution of the target variable'
- en: '](img/B16954_03_015.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16954_03_015.jpg](img/B16954_03_015.jpg)'
- en: Figure 3.15 – Distribution of the target variable
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.15 – 目标变量的分布
- en: So, values even go above $60,000.00\. Most of them are lower, so it will be
    interesting to see how the model will handle it.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，值甚至超过了$60,000.00。大多数值都较低，所以将很有趣地看到模型将如何处理它。
- en: Let's dive deeper into the analysis and explore other variables. The goal is
    to see the average insurance costs for every categorical variable segment. We'll
    use the median as an average value, as it's less prone to outliers.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们深入分析并探索其他变量。目标是查看每个分类变量段的平均保险费用。我们将使用中位数作为平均值，因为它对异常值不太敏感。
- en: 'The easiest way to approach this analysis is to make a function that makes
    a bar chart for the specified column. The following function will come in handy
    for this example and many others in the future. It calculates a median from a
    grouped dataset and visualizes a bar chart with a title, labels, a legend, and
    text on top of the bars. You can use this function in general to visualize medians
    of some variable after a grouping operation is performed. It''s best suited for
    categorical variables:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接近这种分析的最简单方法是创建一个函数，该函数为指定的列生成条形图。以下函数对于这个例子以及未来的许多其他例子都很有用。它从一个分组数据集中计算中位数，并使用标题、标签、图例和条形图顶部的文本来可视化条形图。您可以在一般情况下使用此函数来可视化分组操作后某些变量的中位数。它最适合分类变量：
- en: '[PRE15]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s now use this function to visualize the median insurance cost for smokers
    and non-smokers. Here''s the code:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们使用这个函数来可视化吸烟者和非吸烟者的平均保险费用。以下是代码：
- en: '[PRE16]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'And here''s the corresponding visualization:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是相应的可视化：
- en: '![Figure 3.16 – Median insurance charges for smokers and non-smokers'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.16 – 吸烟者和非吸烟者的平均保险费用'
- en: '](img/B16954_03_016.jpg)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_016.jpg)'
- en: Figure 3.16 – Median insurance charges for smokers and non-smokers
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.16 – 吸烟者和非吸烟者的平均保险费用
- en: As you can see, smokers pay an insurance fee several times higher than non-smokers.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，吸烟者支付的保险费是非吸烟者的几倍。
- en: 'Let''s make a similar-looking visualization for comparing median insurance
    costs between genders:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们制作一个类似的可视化来比较男性和女性的平均保险费用：
- en: '[PRE17]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You can see the visualization here:'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以在这里看到可视化：
- en: '![Figure 3.17 – Median insurance charges between genders'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.17 – 性别之间的平均保险费用'
- en: '](img/B16954_03_017.jpg)'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_017.jpg)'
- en: Figure 3.17 – Median insurance charges between genders
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.17 – 性别之间的平均保险费用
- en: Not much of a difference here.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里没有太大的差异。
- en: 'But what will happen if we compare median insurance costs by the number of
    children? The following code snippet does just that:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 但如果我们按孩子的数量比较平均保险费用会发生什么？以下代码片段正是这样做的：
- en: '[PRE18]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here''s how the costs are distributed:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 成本分布如下：
- en: '![Figure 3.18 – Median insurance charges by number of children'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.18 – 按孩子数量划分的平均保险费用'
- en: '](img/B16954_03_018.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_018.jpg)'
- en: Figure 3.18 – Median insurance charges by number of children
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.18 – 按孩子数量划分的平均保险费用
- en: The insurance costs seem to go up until the fifth child. Maybe there aren't
    that many families with five children. Can you confirm that on your own?
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 保险费用似乎会随着第五个孩子的出生而增加。可能没有那么多有五个孩子的家庭。你能自己确认一下吗？
- en: 'What about the region? Here''s the code for visualizing median insurance costs
    by region:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那么，地区呢？以下是按地区可视化平均保险费用的代码：
- en: '[PRE19]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The cost distribution per region is shown in the following figure:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面这张图显示了每个地区的成本分布：
- en: '![Figure 3.19 – Median insurance charges by region'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.19 – 按地区划分的平均保险费用'
- en: '](img/B16954_03_019.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_019.jpg)'
- en: Figure 3.19 – Median insurance charges by region
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.19 – 按地区划分的平均保险费用
- en: The values don't differ that much.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 值之间没有太大的差异。
- en: We've made a decent amount of visualizations and explored the dataset. It's
    now time to prepare it and apply machine learning models.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们已经制作了大量可视化并探索了数据集。现在是时候准备它并应用机器学习模型了。
- en: There are a couple of things we need to do for this dataset to be machine learning
    ready. First, we'll have to remap string values to integers for the columns `sex`
    and `smoker`. Then, we'll need to create dummy variables for the `region` column.
    This step is necessary because TPOT can't understand raw textual data.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使这个数据集准备好进行机器学习，我们需要做一些事情。首先，我们必须将`sex`和`smoker`列中的字符串值重映射为整数。然后，我们需要为`region`列创建虚拟变量。这一步是必要的，因为TPOT无法理解原始文本数据。
- en: 'Here''s the code snippet that does the necessary preparation:'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是进行必要准备工作的代码片段：
- en: '[PRE20]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Calling the `head()` function results in the dataset shown in the following
    figure:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调用`head()`函数会得到以下图所示的数据集：
- en: '![Figure 3.20 – Insurance dataset after preparation'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.20 – 准备后的保险数据集'
- en: '](img/B16954_03_020.jpg)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_020.jpg)'
- en: Figure 3.20 – Insurance dataset after preparation
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.20 – 准备后的保险数据集
- en: 'The dataset is now ready for predictive modeling. Before we do so, let''s check
    for variable correlations with the target variable. The following snippet draws
    the correlation matrix with annotations:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集现在已准备好进行预测建模。在我们这样做之前，让我们检查变量与目标变量之间的相关性。以下代码片段绘制了带有注释的相关矩阵：
- en: '[PRE21]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The corresponding correlation matrix is shown in the following figure:'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面这张图显示了相应的相关矩阵：
- en: '![Figure 3.21 – Insurance dataset correlation matrix'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.21 – 保险数据集的相关矩阵'
- en: '](img/B16954_03_021.jpg)'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_021.jpg)'
- en: Figure 3.21 – Insurance dataset correlation matrix
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.21 – 保险数据集的相关矩阵
- en: Next stop – predictive modeling.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下一个目标 – 预测建模。
- en: 'As before, the first step is to make a train/test split. The following code
    snippet shows you how to do that:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，第一步是进行训练/测试分割。以下代码片段展示了如何进行：
- en: '[PRE22]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The number of training and testing instances is shown in the following figure:'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练集和测试集中的实例数量显示在以下图中：
- en: '![Figure 3.22 – Number of instances in train and test sets'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.22 – 训练集和测试集中的实例数量'
- en: '](img/B16954_03_022.jpg)'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_022.jpg)'
- en: Figure 3.22 – Number of instances in train and test sets
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.22 – 训练集和测试集中的实例数量
- en: 'We''ll first make a baseline model with a linear regression algorithm. It will
    serve as something TPOT must outperform. You''ll find a code snippet for training
    a baseline model here:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先使用线性回归算法创建一个基线模型。这将作为TPOT必须超越的目标。你可以在这里找到训练基线模型的代码片段：
- en: '[PRE23]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Coefficient of determination (R2) and root mean squared error (RMSE) values
    are shown in the following figure:'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 决定系数（R2）和均方根误差（RMSE）值显示在以下图中：
- en: '![Figure 3.23 – R2 and RMSE for the linear regression model'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.23 – 线性回归模型的R2和RMSE'
- en: '](img/B16954_03_023.jpg)'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_023.jpg)'
- en: Figure 3.23 – R2 and RMSE for the linear regression model
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.23 – 线性回归模型的R2和RMSE
- en: On average, a simple linear regression model is wrong by $5,926.02\. This simple
    model captures 77% of the variance in the dataset.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均而言，一个简单的线性回归模型错误为$5,926.02$。这个简单的模型捕捉了数据集中77%的方差。
- en: We can further explore the linear regression model's feature importance by examining
    the assigned weights (coefficients).
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过检查分配的权重（系数）来进一步探索线性回归模型的特征重要性。
- en: 'The following code snippet prints the variable name and its corresponding coefficient:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段打印变量名称及其对应的系数：
- en: '[PRE24]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is shown in the following figure:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示在以下图中：
- en: '![Figure 3.24 – Coefficients of a linear regression model'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.24 – 线性回归模型的系数'
- en: '](img/B16954_03_024.jpg)'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_024.jpg)'
- en: Figure 3.24 – Coefficients of a linear regression model
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.24 – 线性回归模型的系数
- en: As you can see, the column with the largest coefficient is `smoker`. That makes
    sense, as it confirms our visualization made in the exploratory data analysis
    phase.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，具有最大系数的列是`smoker`。这很合理，因为它证实了我们探索性数据分析阶段所做的可视化。
- en: It's now time to bring in the big guns. We'll use the TPOT library to produce
    an automated machine learning pipeline. We'll optimize the pipeline for R2 score
    this time, but feel free to stick with RMSE or any other metric.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是时候动用重武器了。我们将使用TPOT库来生成一个自动化的机器学习流程。这次我们将优化流程以R2分数为目标，但如果你愿意，也可以坚持使用RMSE或其他任何指标。
- en: 'The following code snippet imports the TPOT library, instantiates it, and fits
    the pipeline:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段导入TPOT库，实例化它，并拟合流程：
- en: '[PRE25]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'After 10 minutes, you should see the following output in your notebook:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 10分钟后，你应该在你的笔记本中看到以下输出：
- en: '![Figure 3.25 – TPOT score per generation'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.25 – 每一代的TPOT分数'
- en: '](img/B16954_03_025.jpg)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_025.jpg)'
- en: Figure 3.25 – TPOT score per generation
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.25 – 每一代的TPOT分数
- en: The score on the training set started to increase in the last couple of generations.
    You'd likely get a slightly better model if you gave TPOT more time to train.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在最近几代中，训练集上的分数开始上升。如果你给TPOT更多时间来训练，你可能会得到一个稍微更好的模型。
- en: 'The R2 score on the test set can be obtained with the following code:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试集上的R2分数可以通过以下代码获取：
- en: '[PRE26]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The score is shown in the following figure:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分数显示在以下图中：
- en: '![Figure 3.26 – TPOT R2 score on the test set'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.26 – 测试集上的TPOT R2分数'
- en: '](img/B16954_03_026.jpg)'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_026.jpg)'
- en: Figure 3.26 – TPOT R2 score on the test set
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.26 – 测试集上的TPOT R2分数
- en: 'You can obtain R2 and RMSE values for the test set manually. The following
    code snippet shows you how:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以手动获取测试集的R2和RMSE值。以下代码片段展示了如何操作：
- en: '[PRE27]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The corresponding scores are shown here:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相应的分数如下所示：
- en: '![Figure 3.27 – TPOT R2 and RMSE scores on the test set'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.27 – 测试集上的TPOT R2和RMSE分数'
- en: '](img/B16954_03_027.jpg)'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_027.jpg)'
- en: Figure 3.27 – TPOT R2 and RMSE scores on the test set
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.27 – 测试集上的TPOT R2和RMSE分数
- en: 'As the last step, we''ll export the optimized pipeline to a Python file. The
    following code snippet does it:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为最后一步，我们将优化流程导出到一个Python文件中。以下代码片段展示了如何操作：
- en: '[PRE28]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The Python code for the optimized pipeline is shown here:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 优化流程的Python代码如下所示：
- en: '![Figure 3.28 – TPOT optimized pipeline for the insurance dataset'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.28 – 保险数据集的TPOT优化管道'
- en: '](img/B16954_03_028.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_028.jpg)'
- en: Figure 3.28 – TPOT optimized pipeline for the insurance dataset
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.28 – 保险数据集的TPOT优化管道
- en: You can now use this file to make predictions on new, unseen data. It would
    be best to leave the pipeline to perform the optimization for as long as needed,
    but even 10 minutes was enough to produce good-quality models.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以使用此文件对新数据做出预测。最好让管道根据需要执行优化，但即使10分钟也足以产生高质量的模型。
- en: This section showed you how to build automated pipelines optimized for different
    metrics and with a bit more verbose output printed to the console. As you can
    see, the code for optimization is more or less identical. It's the data preparation
    that changes drastically from project to project, and that's where you'll spend
    most of your time.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 本节向您展示了如何构建针对不同指标优化的自动化管道，并在控制台上打印出更多详细输出。如您所见，优化代码大致相同。数据准备从项目到项目变化很大，这也是您将花费大部分时间的地方。
- en: In the next section, you'll see how to apply TPOT to the vehicle dataset.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将看到如何将TPOT应用于车辆数据集。
- en: Applying automated regression modeling to the vehicle dataset
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将自动回归建模应用于车辆数据集
- en: This section shows how to develop an automated machine learning model on the
    most complex dataset thus far. You will use the vehicle dataset ([https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho](https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho)),
    so download it if you haven't already. The goal is to predict the selling price
    based on the various predictors, such as year made and kilometers driven.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了如何开发一个针对迄今为止最复杂的数据集的自动化机器学习模型。您将使用车辆数据集（[https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho](https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho)），如果您还没有下载，请下载。目标是根据各种预测因子（如制造年份和行驶公里数）预测销售价格。
- en: 'This time, we won''t focus on exploratory data analysis. You can do that on
    your own if you''ve followed the last two examples. Instead, we''ll concentrate
    on dataset preparation and model training. There''s a lot of work required to
    transform this dataset into something ready for machine learning, so let''s get
    started right away:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们不会专注于探索性数据分析。如果您已经跟随了最后两个示例，您可以自己完成这项工作。相反，我们将专注于数据集准备和模型训练。将此数据集转换为机器学习准备需要做大量的工作，所以让我们立即开始：
- en: 'Once again, the first step is to load in the libraries and the dataset. The
    requirements are the same as with previous examples. You''ll need `numpy`, `p``andas`,
    `matplotlib`, and `seaborn`. Here''s how to import the libraries and load the
    dataset:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次强调，第一步是加载库和数据集。要求与前面的示例相同。您需要`numpy`、`pandas`、`matplotlib`和`seaborn`。以下是导入库和加载数据集的方法：
- en: '[PRE29]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Calling the `head()` function displays the first five rows. You can see how
    they look in the following figure:'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调用`head()`函数显示前五行。您可以在以下图中看到它们的样式：
- en: '![Figure 3.29 – First five rows of the vehicle dataset'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.29 – 车辆数据集的前五行'
- en: '](img/B16954_03_029.jpg)'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_029.jpg)'
- en: Figure 3.29 – First five rows of the vehicle dataset
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.29 – 车辆数据集的前五行
- en: 'The dataset has a lot of columns, and not all of them are shown in *Figure
    3.29*. The next step in the data preparation phase is to check for missing values.
    The following code snippet does that:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集有很多列，*图3.29* 中并没有显示所有列。数据准备阶段的下一步是检查缺失值。以下代码片段就是做这件事的：
- en: '[PRE30]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The results are shown in the following figure:'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 3.30 – Count of missing values for the vehicle dataset'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.30 – 车辆数据集中缺失值的计数'
- en: '](img/B16954_03_030.jpg)'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_03_030.jpg)'
- en: Figure 3.30 – Count of missing values for the vehicle dataset
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.30 – 车辆数据集中缺失值的计数
- en: Some of the values are missing, and we'll address this issue with the simplest
    approach – by removing them.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一些值缺失，我们将通过最简单的方法解决这个问题——通过删除它们。
- en: Removing missing values might not always be the best option. You should always
    investigate why the values are missing and if they can (or should) be somehow
    filled. This book focuses on machine learning automation, so we won't do that
    here.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除缺失值可能并不总是最佳选择。您应该始终调查为什么值会缺失，以及它们是否可以（或应该）以某种方式填充。本书侧重于机器学习自动化，所以我们在这里不会这么做。
- en: 'Here''s how you can drop the missing values:'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是删除缺失值的方法：
- en: '[PRE31]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Executing the preceding code results in the following count:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 执行前面的代码会产生以下计数：
- en: '![Figure 3.31 – Removing missing values from the vehicle dataset'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.31 – 从车辆数据集中移除缺失值'
- en: '](img/B16954_03_031.jpg)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_031.jpg)'
- en: Figure 3.31 – Removing missing values from the vehicle dataset
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.31 – 从车辆数据集中移除缺失值
- en: 'There are no missing values now, but that doesn''t mean we''re done with data
    preparation. Here''s the list of steps required to make this dataset suitable
    for machine learning:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在没有任何缺失值了，但这并不意味着我们已经完成了数据准备。以下是使此数据集适合机器学习所需的步骤列表：
- en: Convert the `transmission` column to an integer – 1 if *manual*, 0 otherwise.
    Also, rename the column to `is_manual`.
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`transmission`列转换为整数 - 如果是手动，则为 1，否则为 0。同时，将列重命名为`is_manual`。
- en: Remap the `owner` column to integers. Check the `remap_owner()` function for
    further clarifications.
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`owner`列重映射为整数。查看`remap_owner()`函数以获取更多说明。
- en: Extract car brand, mileage, engine, and max power from the corresponding attributes.
    The value of interest for all of the mentioned attributes is everything before
    the first space.
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从相应的属性中提取汽车品牌、里程、引擎和最大马力。所有提到的属性中感兴趣的价值是第一个空格之前的内容。
- en: Create dummy variables from the attributes `name`, `fuel`, and `seller_type`.
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从属性`name`、`fuel`和`seller_type`创建虚拟变量。
- en: Concatenate the original dataset with dummy variables and drop unnecessary attributes.
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将原始数据集与虚拟变量连接，并删除不必要的属性。
- en: 'Here is the code for the `remap_owner()` function:'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是`remap_owner()`函数的代码：
- en: '[PRE32]'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'And here is the code for performing all of the mentioned transformations:'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是执行所有提到的转换的代码：
- en: '[PRE33]'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'After applying the transformations, the dataset looks like this:'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应用转换后，数据集看起来是这样的：
- en: '![Figure 3.32 – Prepared vehicle dataset'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.32 – 准备好的车辆数据集'
- en: '](img/B16954_03_032.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_03_032.jpg)'
- en: Figure 3.32 – Prepared vehicle dataset
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.32 – 准备好的车辆数据集
- en: Data in this format can be passed to a machine learning algorithm. Let's do
    that next.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 此格式的数据可以传递给机器学习算法。我们接下来就做这件事。
- en: 'As always, we''ll start with the train test split. The following code snippet
    shows you how to perform it on this dataset:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和往常一样，我们将从训练/测试集分割开始。以下代码片段显示了如何在数据集上执行此操作：
- en: '[PRE34]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You can see how many instances are in both sets in *Figure 3.33*:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在*图 3.33*中看到两个集合中的实例数量：
- en: '![Figure 3.33 – Number of instances in train and test sets'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.33 – 训练集和测试集中的实例数量'
- en: '](img/B16954_03_033.jpg)'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_033.jpg)'
- en: Figure 3.33 – Number of instances in train and test sets
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.33 – 训练集和测试集中的实例数量
- en: As you can see, this is a much larger dataset than we had before.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，这是一个比我们之前拥有的更大的数据集。
- en: 'We won''t use your standard metrics for evaluating regression models (R2 and
    RMSE) this time. We''ll use `scikit-learn` library, so we''ll have to implement
    it manually. Here''s how:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这次我们不会使用评估回归模型的常规指标（R2 和 RMSE）。我们将使用`scikit-learn`库，因此我们需要手动实现它。以下是实现方法：
- en: '[PRE35]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'And now it''s time to make a baseline model. Once again, it will be a linear
    regression model, evaluated on the test set with R2 and MAPE metrics. Here''s
    the code for implementing the baseline model:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是时候建立一个基线模型了。再次强调，它将是一个线性回归模型，使用测试集的 R2 和 MAPE 指标进行评估。以下是实现基线模型的代码：
- en: '[PRE36]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The corresponding results are shown in the following figure:'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相应的结果显示在下图中：
- en: '![Figure 3.34 – R2 and MAPE for the baseline model'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.34 – 基线模型的 R2 和 MAPE'
- en: '](img/B16954_03_034.jpg)'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_034.jpg)'
- en: Figure 3.34 – R2 and MAPE for the baseline model
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.34 – 基线模型的 R2 和 MAPE
- en: On average, the baseline model is wrong by 43%. It's a lot, but we have to start
    somewhere.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均而言，基线模型错误率为 43%。这很多，但我们不得不从某处开始。
- en: 'Let''s take a look at the linear regression model coefficient to determine
    which features are important. Here''s the code for obtaining coefficients:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看一下线性回归模型的系数，以确定哪些特征是重要的。以下是获取系数的代码：
- en: '[PRE37]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'And here are the coefficients:'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是系数：
- en: '![Figure 3.35 – Baseline model coefficients'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.35 – 基线模型系数'
- en: '](img/B16954_03_035.jpg)'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_035.jpg)'
- en: Figure 3.35 – Baseline model coefficients
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.35 – 基线模型系数
- en: Just take a moment to appreciate how interpretable this is. The higher the year,
    the newer the car is, which results in a higher price. The more kilometers the
    vehicle has driven, the more the price decreases. It also looks like cars with
    automatic transmissions cost more. You get the point. Interpretability is something
    that linear regression offers. But it lacks accuracy. That's what TPOT will improve.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请花点时间来欣赏一下这种可解释性。年份越高，汽车越新，这导致价格越高。车辆行驶的公里数越多，价格就越低。看起来自动挡汽车的售价也更高。你明白了。可解释性是线性回归提供的东西。但它缺乏准确性。这正是TPOT要改进的地方。
- en: 'Let''s fit a TPOT model next and optimize it for MAPE score. We''ll train the
    model for 10 minutes on every available CPU core (indicated by `n_jobs=-1`):'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将拟合一个TPOT模型，并针对MAPE分数进行优化。我们将在每个可用的CPU核心上（由`n_jobs=-1`指示）训练模型10分钟：
- en: '[PRE38]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output you''ll see after 10 minutes is shown in the following figure:'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 10分钟后的输出显示在以下图中：
- en: '![Figure 3.36 – Output of a TPOT optimization process'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.36 – TPOT优化过程的输出'
- en: '](img/B16954_03_036.jpg)'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_036.jpg)'
- en: Figure 3.36 – Output of a TPOT optimization process
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.36 – TPOT优化过程的输出
- en: It looks like 10 minutes wasn't nearly enough for TPOT to give its best.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看起来10分钟的时间对TPOT来说远远不够以发挥其最佳性能。
- en: 'The resulting pipeline is shown in the following figure:'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果的管道显示在以下图中：
- en: '![Figure 3.37 – Best fitted pipeline after 10 minutes'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.37 – 10分钟后的最佳拟合管道'
- en: '](img/B16954_03_037.jpg)'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_03_037.jpg)'
- en: Figure 3.37 – Best fitted pipeline after 10 minutes
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.37 – 10分钟后的最佳拟合管道
- en: 'And now the moment of truth – did the MAPE decrease? Here''s the code to find
    out:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是真相大白的时候了——MAPE是否有所下降？以下是查找代码：
- en: '[PRE39]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is shown in the following figure:'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示在以下图中：
- en: '![Figure 3.38 – R2 and MAPE for the TPOT optimized model'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.38 – TPOT优化模型的R2和MAPE'
- en: '](img/B16954_03_038.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_03_038.jpg)'
- en: Figure 3.38 – R2 and MAPE for the TPOT optimized model
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.38 – TPOT优化模型的R2和MAPE
- en: As you can see, TPOT decreased the error significantly and increased the goodness
    of fit (R2) simultaneously. Just as expected.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，TPOT显著降低了错误并同时提高了拟合优度（R2）。正如预期的那样。
- en: The final code-along section showed you how easy it is to train automated models
    on a more complex dataset. The procedure is more or less identical, depending
    on the metric you're optimizing for, but it's the data preparation phase that
    makes all the difference.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的代码示例部分向您展示了如何在更复杂的数据集上训练自动化模型是多么容易。根据你优化的指标，程序大致相同，但数据准备阶段才是所有差异的来源。
- en: If you spend more time preparing and analyzing the data, and maybe removing
    some noisy data, you will get better results, guaranteed! That's mainly the case
    when a lot of columns contain text data. A lot of features can be extracted from
    there.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你花更多的时间准备和分析数据，也许还会移除一些噪声数据，你将获得更好的结果，这是有保证的！尤其是在有很多列包含文本数据的情况下。可以从那里提取出很多特征。
- en: Summary
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This was the first purely hands-on chapter in the book. You've connected the
    theory from the previous chapters with practice. You've built not one, but three
    fully automated machine learning models. Without any kind of doubt, you should
    now be able to use TPOT to solve any type of regression problem.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书的第一个完全实践性的章节。您已经将前几章的理论与实践相结合。您不仅构建了一个，而是构建了三个完全自动化的机器学习模型。毫无疑问，您现在应该能够使用TPOT来解决任何类型的回归问题。
- en: As with most things in data science and machine learning, 90% of the work boils
    down to data preparation. TPOT can make this percentage even higher because less
    time is spent designing and tweaking the models. Use this extra time wisely, and
    get yourself fully acquainted with the dataset. There's no way around it.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 就像数据科学和机器学习中的大多数事情一样，90%的工作归结为数据准备。TPOT可以使这个比例更高，因为花在设计和调整模型上的时间更少。明智地利用这额外的时间，并让自己完全熟悉数据集。这是不可避免的。
- en: In the next chapter, you'll see how to build automated machine learning models
    for classification datasets. That chapter will also be entirely hands-on. Later,
    in [*Chapter 5*](B16954_05_Final_SK_ePub.xhtml#_idTextAnchor065), *Parallel Training
    with TPOT and Dask*, we'll combine both theory and practice.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将看到如何为分类数据集构建自动化机器学习模型。那一章也将完全是实践性的。稍后，在第5章[*并行训练TPOT和Dask*](B16954_05_Final_SK_ePub.xhtml#_idTextAnchor065)中，我们将结合理论与实践。
- en: Q&A
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Q&A
- en: Which type of data visualization lets you explore the distribution of a continuous
    variable?
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种类型的数据可视化可以让你探索连续变量的分布？
- en: Explain R2, RMSE, and MAPE metrics.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释R2、RMSE和MAPE指标。
- en: Can you use a custom scoring function with TPOT? If yes, how?
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用TPOT的自定义评分函数吗？如果可以，如何使用？
- en: Why is it essential to build baseline models first? Which algorithm is considered
    as a "baseline" for regression tasks?
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么首先构建基线模型是必要的？哪种算法被认为是回归任务的“基线”？
- en: What do the coefficients of a linear regression model tell you?
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性回归模型的系数能告诉你什么？
- en: How do you use all CPU cores when training TPOT models?
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练TPOT模型时，如何使用所有CPU核心？
- en: Can you use TPOT to obtain the Python code of the best pipeline?
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用TPOT获取最佳管道的Python代码吗？
