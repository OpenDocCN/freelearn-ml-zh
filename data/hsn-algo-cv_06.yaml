- en: Video Analysis &#x2013; Motion Detection and Tracking
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视频分析——运动检测和跟踪
- en: As a computer vision developer, there is absolutely no way you can avoid dealing
    with video feeds from stored video files or cameras and other such sources. Treating
    video frames as individual images is one way to process videos, which surprisingly
    doesn't require much more effort or knowledge of the algorithms than what you
    have learned so far. For instance, you can apply a smoothening filter on a video,
    or in other words, a set of video frames, the same way as you would when you apply
    it on an individual image. The only trick here is that you must extract each frame
    from a video, as described in [Chapter 2](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4),
    *Getting Started with OpenCV*. However, in computer vision, there are certain
    algorithms that are meant to work with consecutive video frames and the result
    on their operation depends not just on an individual image but also on the result
    of the same operation on the previous frames. Both of the algorithm types we just
    mentioned will be the main topics covered in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名计算机视觉开发者，你绝对无法避免处理来自存储的视频文件或摄像头以及其他类似来源的视频流。将视频帧视为单独的图像是处理视频的一种方法，令人惊讶的是，这并不需要比你所学到的更多的努力或算法知识。例如，你可以对视频应用平滑滤波器，或者说，对一组视频帧应用，就像你在对单个图像应用时一样。这里的唯一技巧是，你必须按照[第2章](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4)“OpenCV入门”中描述的方法从视频中提取每一帧。然而，在计算机视觉中，有一些算法旨在与连续的视频帧一起工作，并且它们操作的结果不仅取决于单个图像，还取决于对前一个帧进行相同操作的结果。我们刚才提到的两种算法类型将是本章的主要内容。
- en: After learning about histograms and back-projection images in the previous chapter,
    we are ready to take on computer vision algorithms that are used to detect and
    track objects in real-time. These algorithms highly rely on a firm understanding
    on all the topics we learned in [Chapter 5](part0102.html#318PC0-15c05657f8254d318ea883ef10fc67f4),
    *Back-Projection and Histograms*. Based on this, we'll start this chapter with
    a couple of simple examples about how to use the computer vision algorithms we've
    learned so far, to process frames from a video file or camera, and then we'll
    move on to learn about two of the most famous object detection and tracking algorithms,
    the Mean Shift and CAM Shift algorithms. Then, we'll learn how to use the Kalman
    filter to correct the result of our object detection and tracking algorithms and
    how to remove noise from the results to get a better tracking result. We'll end
    this chapter by learning about motion analysis and background/foreground extraction.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章学习了直方图和反向投影图像之后，我们已准备好去应对用于实时检测和跟踪物体的计算机视觉算法。这些算法高度依赖于我们对[第5章](part0102.html#318PC0-15c05657f8254d318ea883ef10fc67f4)“反向投影和直方图”中所有主题的牢固理解。基于此，我们将从几个简单的例子开始本章，这些例子展示了如何使用我们迄今为止学到的计算机视觉算法来处理视频文件或摄像头捕获的帧，然后我们将继续学习关于两种最著名的对象检测和跟踪算法——均值漂移和CAM漂移算法。接着，我们将学习如何使用卡尔曼滤波器来校正我们的对象检测和跟踪算法的结果，以及如何去除结果中的噪声以获得更好的跟踪结果。本章的结尾，我们将学习运动分析和背景/前景提取。
- en: 'In this chapter, we''ll cover the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: How to apply filters and perform such operations on videos
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在视频上应用过滤器并执行此类操作
- en: Using the Mean Shift algorithm to detect and track objects
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用均值漂移算法检测和跟踪对象
- en: Using the CAM Shift algorithm to detect and track objects
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CAM漂移算法检测和跟踪对象
- en: Using the Kalman filter to improve tracking results and remove noise
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卡尔曼滤波器提高跟踪结果并去除噪声
- en: Using the background and foreground extraction algorithms
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用背景和前景提取算法
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: IDE to develop C++ or Python applications
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于开发C++或Python应用程序的IDE
- en: OpenCV library
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV库
- en: Refer to [Chapter 2](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4),
    *Getting Started with OpenCV*, for more information about how to set up a personal
    computer and make it ready for developing computer vision applications using the
    OpenCV library.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何设置个人计算机并使其准备好使用OpenCV库开发计算机视觉应用程序的更多信息，请参阅[第2章](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4)“OpenCV入门”。
- en: You can use the following URL to download the source codes and examples for
    this chapter: [https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter06](https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter06).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下URL下载本章的源代码和示例：[https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter06](https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter06)。
- en: Processing videos
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理视频
- en: 'To be able to use any of the algorithms that we''ve learned so far on videos,
    we need to be able to read video frames and store them in `Mat` objects. We have
    already learned about how to deal with video files, cameras, and RTSP feeds in
    the initial chapters of this book. So, extending that, using what we learned in
    the previous chapters, we can use a code similar to the following, in order to
    apply colormaps to the video feed from the default camera on a computer:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够在视频上使用我们迄今为止学到的任何算法，我们需要能够读取视频帧并将它们存储在`Mat`对象中。本书的前几章我们已经学习了如何处理视频文件、摄像头和RTSP流。因此，在此基础上，利用我们之前章节中学到的知识，我们可以使用以下类似的代码，以便将颜色图应用于计算机默认摄像头的视频流：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Just as we learned in [Chapter 2](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4),
    *Getting Started with OpenCV*, we simply need to create a `VideoCapture` object
    and read the video frames from the default camera (which has an index of zero).
    In the preceding example, we have added a single line of code that is responsible
    for applying a colormap on the extracted video frames. Try the preceding example
    code and you'll see the `COLORMAP_JET` colormap applied to every frame of the
    camera, much like what we learned in [Chapter 4](part0085.html#2H1VQ0-15c05657f8254d318ea883ef10fc67f4),
    *Drawing, Filtering, and Transformation*, and finally the results are displayed
    in real-time. Pressing the spacebar should stop the video processing altogether.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第2章](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4)“使用OpenCV入门”中学到的，我们只需创建一个`VideoCapture`对象，并从默认摄像头（索引为零）读取视频帧。在前面的示例中，我们添加了一行代码，用于在提取的视频帧上应用颜色图。尝试前面的示例代码，你会看到`COLORMAP_JET`颜色图被应用于摄像头的每一帧，就像我们在[第4章](part0085.html#2H1VQ0-15c05657f8254d318ea883ef10fc67f4)“绘制、过滤和变换”中学到的那样，最终结果实时显示。按下空格键将停止视频处理。
- en: 'Similarly, we can perform different video-processing algorithms in real-time,
    based on a specific key being pressed. Here''s an example, replacing only the
    `for` loop in the preceding code, which results in the original video being displayed
    unless either the *J* or *H* key is pressed:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以根据按下的特定键实时执行不同的视频处理算法。以下是一个示例，只需替换前面代码中的`for`循环，除非按下*J*或*H*键，否则将显示原始视频：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The original output video of the camera will be displayed unless any of the
    mentioned keys are pressed. Pressing *J* will trigger `COLORMAP_JET`, while pressing
    *H* will trigger the `COLORMAP_HOT` colormap being applied to the camera frames.
    Similar to the previous example, pressing the spacebar key will stop the process.
    Also, pressing any keys other than space, *J*, or *H* will result in the original
    video being displayed.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除非按下提到的任何键，否则将显示摄像头的原始输出视频。按下*J*键将触发`COLORMAP_JET`，而按下*H*键将触发`COLORMAP_HOT`颜色图应用于摄像头帧。与前面的示例类似，按下空格键将停止过程。此外，按下除空格、*J*或*H*以外的任何键将导致显示原始视频。
- en: The `applyColorMap` function in the preceding examples is just a random algorithm
    that is used to describe the technique used to process videos in real-time. You
    can use any of the algorithms you have learned in this book that perform on a
    single image. You can, for instance, write a program that performs a smoothening
    filter on the video, or Fourier transformation, or even a program that displays
    the Hue channel histogram in real-time. The use cases are infinite, however the
    method used is almost identical for all algorithms that perform a single complete
    operation on any individual image.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 前面示例中的`applyColorMap`函数只是一个随机算法，用于描述实时处理视频所使用的技巧。你可以使用本书中学到的任何在单个图像上执行的算法。例如，你可以编写一个程序对视频执行平滑滤波，或傅里叶变换，甚至编写一个实时显示色调通道直方图的程序。用例无限，然而，用于所有在单个图像上执行单个完整操作算法的方法几乎相同。
- en: Besides performing an operation on individual video frames, one can also perform
    operations that depend on any number of consecutive frames. Let's see how this
    is done using a very simple, but extremely important, use case.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对单个视频帧执行操作外，还可以执行依赖于任意数量连续帧的操作。让我们看看如何使用一个非常简单但极其重要的用例来完成这项操作。
- en: 'Let''s assume we want to find the average brightness of the last 60 frames
    read from a camera at any given moment. Such a value is quite useful when we want
    to automatically adjust the brightness of the video when the content of the frames
    is extremely dark or extremely bright. In fact, a similar operation is usually
    performed by the internal processor of most digital cameras, and even the smartphone
    in your pocket. You can give it a try by turning on the camera on your smartphone
    and pointing it toward a light, or the sun, or by entering a very dark environment.
    The following code demonstrates how the average of the brightness of the last
    `60` frames is calculated and displayed in the corner of the video:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要找到在任何给定时刻从摄像机读取的最后60帧的平均亮度。当帧的内容非常暗或非常亮时，这个值在自动调整视频亮度时非常有用。实际上，大多数数码相机的内部处理器以及您口袋里的智能手机通常会执行类似的操作。您可以尝试打开智能手机上的相机，将其对准光源，或太阳，或者进入一个非常黑暗的环境。以下代码演示了如何计算最后60帧的平均亮度并将其显示在视频的角落：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For the most part, this example code is quite similar to the examples we saw
    earlier in this chapter. The main difference here is that we are storing the average
    of the last `60` frames that are calculated using the OpenCV mean function in
    a `vector` of `Scalar` objects, and then we calculate the average of all averages.
    The calculated value is then drawn on the input frame using the `putText` function.
    The following image depicts a single frame that is displayed when the preceding
    example code is executed:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数情况，这个示例代码与我们本章前面看到的示例非常相似。这里的主要区别在于，我们将使用OpenCV的均值函数计算的最后60帧的平均值存储在一个`Scalar`对象的`vector`中，然后我们计算所有平均值的总平均值。然后使用`putText`函数将计算出的值绘制在输入帧上。以下图像显示了执行前面的示例代码时显示的单个帧：
- en: '![](img/00069.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00069.jpeg)'
- en: Notice the value displayed in the bottom-left corner of the image, which will
    start to decrease when the content of the video frames becomes darker and increase
    when they become brighter. Based on this result, you can, for instance, change
    the brightness value or warn the user of your application that the content is
    too dark or bright, and so on.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意图像左下角显示的值，当视频帧的内容变暗时，该值将开始减小，当内容变亮时，该值将增加。基于这个结果，您可以，例如，改变亮度值或警告您的应用程序用户内容太暗或太亮，等等。
- en: The examples in this initial section of the chapter were meant to teach you
    the idea of processing individual frames using the algorithms you've learned in
    the previous chapters, and a few simple programming techniques used to calculate
    a value based on consecutive frames. In the following sections of this chapter,
    we'll be learning about some of the most important video-processing algorithms,
    namely object detection and tracking algorithms, which depend on the concepts
    and techniques we learned in this section and the previous chapters of this book.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本章初始部分的例子旨在教会您如何使用在前几章中学到的算法处理单个帧，以及一些简单的编程技术，这些技术用于根据连续帧计算一个值。在本章接下来的部分，我们将学习一些最重要的视频处理算法，特别是目标检测和跟踪算法，这些算法依赖于我们在本节以及本书前几章中学到的概念和技术。
- en: Understanding the Mean Shift algorithm
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解均值漂移算法
- en: 'The Mean Shift algorithm is an iterative algorithm that can be used to find
    the maxima of a density function. A very rough translation of the preceding sentence
    to computer vision terminology would be the following—the Mean Shift algorithm
    can be used to find an object in an image using a back-projection image. But how
    is it achieved in practice? Let''s walk through this step by step. Here are the
    individual operations that are performed to find an object using the Mean Shift
    algorithm, in order:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移算法是一个迭代算法，可以用来找到密度函数的最大值。将前面的句子粗略地翻译成计算机视觉术语，可以表达为以下内容——均值漂移算法可以使用反向投影图像在图像中找到对象。但它是如何在实际中实现的呢？让我们一步一步地来探讨。以下是使用均值漂移算法找到对象的单个操作步骤，按顺序如下：
- en: The back-projection of an image is created using a modified histogram to find
    the pixels that are most likely to contain our object of interest. (It is also
    common to filter the back-projection image to get rid of unwanted noise, but this
    is an optional operation to improve the results.)
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像的后投影是通过使用修改后的直方图来创建的，以找到最有可能包含我们的目标对象的像素。（过滤后投影图像以去除不想要的噪声也是常见的操作，但这是一种可选操作，用于提高结果。）
- en: 'An initial search window is needed. This search window will contain our object
    of interest after a number of iterations, which we''ll get to in the next step.
    After each iteration, the search window is updated by the algorithm. The updating
    of the search window happens by calculating the mass center of the search window
    in the back-projection image, and then shifting the current center point of the
    search window to the mass center of the window. The following picture demonstrates
    the concept of the mass center in a search window and how the shifting happens:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要一个初始搜索窗口。这个搜索窗口在经过多次迭代后，将包含我们的目标对象，这一点我们将在下一步说明。每次迭代后，搜索窗口都会通过算法进行更新。搜索窗口的更新是通过在后投影图像中计算搜索窗口的质量中心，然后将当前搜索窗口的中心点移动到窗口的质量中心来实现的。以下图片展示了搜索窗口中质量中心的概念以及移动过程：
- en: '![](img/00070.gif)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00070.gif)'
- en: The two points at the two ends of the arrow in the preceding picture correspond
    to the search-window center and mass center.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前一张图中箭头两端的两个点对应于搜索窗口中心和质量中心。
- en: Just like any iterative algorithm, some termination criteria are required by
    the Mean Shift algorithm to stop the algorithm when the results are as expected
    or when reaching an accepted result does not happen as fast as needed. So, the
    number of iterations and an epsilon value are used as termination criteria. Either
    by reaching the number of iterations in the algorithm or by finding a shift distance
    that is smaller than the given epsilon value (convergence), the algorithm will
    stop.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如任何迭代算法一样，均值漂移算法需要一些终止条件来在结果符合预期或达到一个可接受的结果时停止算法。因此，迭代次数和 epsilon 值被用作终止条件。无论是达到算法中的迭代次数，还是找到一个小于给定
    epsilon 值的位移距离（收敛），算法都将停止。
- en: 'Now, let''s see a hands-on example of how this algorithm is used in practice
    by using the OpenCV library. The `meanShift` function in OpenCV implements the
    Mean Shift algorithm almost exactly as it was described in the preceding steps.
    This function requires a back-projection image, a search window, and the termination
    criteria, and it is used as seen in the following example:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过使用 OpenCV 库来实际看看这个算法是如何应用的。OpenCV 中的 `meanShift` 函数几乎完全按照前面步骤中描述的那样实现了均值漂移算法。这个函数需要一个后投影图像、一个搜索窗口和终止条件，并在以下示例中展示了其用法：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`srchWnd` is a `Rect` object, which is simply a rectangle that must contain
    an initial value that is used and then updated by the `meanShift` function. `backProjection`
    must contain a proper back-projection image that is calculated with any of the
    methods that we learned in [Chapter 5](part0102.html#318PC0-15c05657f8254d318ea883ef10fc67f4),
    *Back-Projection and Histograms*. The `TermCriteria` class is an OpenCV class
    that is used by iterative algorithms that require similar termination criteria.
    The first parameter defines the type of the termination criteria, which can be
    `MAX_ITER` (same as `COUNT`), `EPS`, or both. In the preceding example, we have
    used the termination criteria of `20` iterations and an epsilon value of `1.0`,
    which of course can be changed depending on the environment and application. The
    most important thing to note here is that a higher number of iterations and a
    lower epsilon can yield more accurate results, but it can also lead to slower
    performance, and vice versa.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`srchWnd` 是一个 `Rect` 对象，它只是一个必须包含初始值并随后由 `meanShift` 函数更新和使用的矩形。`backProjection`
    必须包含一个适当的后投影图像，该图像可以通过我们在第 5 章[5.3 后投影和直方图](part0102.html#318PC0-15c05657f8254d318ea883ef10fc67f4)中学习到的任何方法计算得出。`TermCriteria`
    类是 OpenCV 中的一个类，它被需要类似终止条件的迭代算法使用。第一个参数定义了终止条件的类型，可以是 `MAX_ITER`（与 `COUNT` 相同）、`EPS`
    或两者兼具。在前面的例子中，我们使用了 `20` 次迭代的终止条件和 `1.0` 的 epsilon 值，当然，这个值可以根据环境和应用进行更改。这里需要注意的最重要的一点是，更多的迭代次数和更低的
    epsilon 值可以产生更准确的结果，但这也可能导致性能变慢，反之亦然。'
- en: 'The preceding example is just a demonstration of how the `meanShift` function
    is called. Now, let''s walk through a complete hands-on example to learn our first
    real-time object-tracking algorithm:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例只是展示了如何调用`meanShift`函数。现在，让我们通过一个完整的动手实践示例来学习我们的第一个实时目标跟踪算法：
- en: 'The structure of the tracking example we''ll create is quite similar to the
    previous examples in this chapter. We need to open a video, or a camera, on the
    computer using the `VideoCapture` class and then start reading the frames, as
    seen here:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将要创建的跟踪示例结构与本章之前的示例非常相似。我们需要使用`VideoCapture`类在计算机上打开一个视频或摄像头，然后开始读取帧，如下所示：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Again, we have used the `waitKey` function to stop the loop if the spacebar
    key is pressed.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们使用了`waitKey`函数来停止循环，如果按下空格键。
- en: 'We''re going to assume that our object of interest has a green color. So, we''re
    going to form a hue histogram that contains only the green colors, as seen here:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将假设我们的目标对象是绿色的。因此，我们将形成一个只包含绿色色调的色调直方图，如下所示：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This needs to happen before entering the process loop, since our histogram is
    going to stay constant throughout the whole process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要在进入过程循环之前完成，因为我们的直方图将在整个过程中保持不变。
- en: 'One last thing to take care of before entering the actual process loop and
    the tracking code is the termination criteria, which will stay constant throughout
    the whole process. Here''s how we''ll create the required termination criteria:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进入实际过程循环和跟踪代码之前，还有一件事需要注意，那就是终止条件，它将在整个过程中保持不变。以下是创建所需终止条件的步骤：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The initial value of the search window is quite important when using the Mean
    Shift algorithm to track objects, since this algorithm always makes an assumption
    about the initial position of the object to be tracked. This is an obvious downside
    of the Mean Shift algorithm, which we'll learn how to deal with later on in this
    chapter when we discuss the CAM Shift algorithm and its implementation in the
    OpenCV library.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Mean Shift算法跟踪对象时，搜索窗口的初始值非常重要，因为这个算法总是对要跟踪的对象的初始位置做出假设。这是Mean Shift算法的一个明显缺点，我们将在本章后面讨论CAM
    Shift算法及其在OpenCV库中的实现时学习如何处理它。
- en: 'After each frame is read in the `while` loop we''re using for the tracking
    code, we must calculate the back-projection image of the input frame using the
    green hue histogram that we created. Here''s how it''s done:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们用于跟踪代码的`while`循环中读取每一帧之后，我们必须使用我们创建的绿色色调直方图来计算输入帧的后投影图像。以下是操作步骤：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can refer to [Chapter 5](part0102.html#318PC0-15c05657f8254d318ea883ef10fc67f4),
    *Back-Projection and Histograms*, for more detailed instructions about calculating
    the back-projection image.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考[第5章](part0102.html#318PC0-15c05657f8254d318ea883ef10fc67f4)，*后投影和直方图*，以获取更多关于计算后投影图像的详细说明。
- en: 'Call the `meanShift` function to update the search window using the back-projection
    image and provided termination criteria, as seen here:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`meanShift`函数，使用后投影图像和提供的终止条件来更新搜索窗口，如下所示：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To visualize the search window, or in other words the tracked object, we need
    to draw the search-window rectangle on the input frame. Here''s how you can do
    this by using the rectangle function:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了可视化搜索窗口，或者说跟踪对象，我们需要在输入帧上绘制搜索窗口矩形。以下是使用矩形函数进行此操作的方法：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can do the same on back-projection image result, however, first we need
    to convert the back-projection image to BGR color space. Remember that the result
    of the back-projection image contained a single channel image with the same depth
    as the input image. Here''s how we can draw a red rectangle at the search-window
    position on the back-projection image:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以对后投影图像结果做同样的事情，然而，首先我们需要将后投影图像转换为BGR颜色空间。请记住，后投影图像的结果包含了一个与输入图像深度相同的单通道图像。以下是我们在后投影图像上搜索窗口位置绘制红色矩形的步骤：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Add the means to switch between the back-projection and original video frame
    using the *B* and *V* keys. Here''s how it''s done:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*B*和*V*键在背投影和原始视频帧之间切换。以下是操作步骤：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s give our program a try and see how it performs when executed in a slightly
    controlled environment. The following picture demonstrates the initial position
    of the search window and our green object of interest, both in the original frame
    view and the back-projection view:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试运行我们的程序，看看它在稍微受控的环境中执行时表现如何。以下图片展示了搜索窗口的初始位置和我们的绿色目标对象，在原始帧视图和后投影视图中：
- en: '![](img/00071.jpeg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00071.jpeg)'
- en: 'Moving the object around will cause the `meanShift` function to update the
    search window and consequently track the object. Here''s another result, depicting
    the object tracked to the bottom-right corner of the view:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 移动物体将导致`meanShift`函数更新搜索窗口，从而跟踪物体。以下是另一个结果，展示了物体被跟踪到视图的右下角：
- en: '![](img/00072.jpeg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00072.jpeg)'
- en: Notice the small amount of noise that can be seen in the corner, which would
    be taken care of by the `meanShift` function since the mass center is not affected
    too much by it. However, as mentioned previously, it is a good idea to perform
    some sort of filtering on the back-projection image to get rid of noise. For instance,
    and in case of noise similar to what we have in the back-projection image, we
    can use the `GaussianBlur` function, or even better, the `erode` function, to
    get rid of unwanted pixels in the back-projection image. For more information
    on how to use filtering functions, you can refer to [Chapter 4](part0085.html#2H1VQ0-15c05657f8254d318ea883ef10fc67f4),
    *Drawing, Filtering, and Transformation*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到角落处可以看到的一小部分噪声，这将被`meanShift`函数处理，因为质量中心不太受其影响。然而，如前所述，对后投影图像进行某种类型的过滤以去除噪声是个好主意。例如，在噪声类似于我们在后投影图像中看到的情况下，我们可以使用`GaussianBlur`函数，或者更好的是`erode`函数，以去除后投影图像中的不需要的像素。有关如何使用过滤函数的更多信息，您可以参考[第4章](part0085.html#2H1VQ0-15c05657f8254d318ea883ef10fc67f4)，*绘图、过滤和转换*。
- en: 'In such tracking applications, we usually need to observe, record, or in any
    way process the route that the object of interest has taken before any given moment
    and for a desired period of time. This can be simply achieved by using the center
    point of the search window, as seen in the following example:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在此类跟踪应用中，我们通常需要观察、记录或以任何方式处理在任意给定时刻之前以及所需时间段内感兴趣对象所走过的路线。这可以通过使用搜索窗口的中心点简单地实现，如下面的示例所示：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Obviously, the `route` is a `vector` of `Point` objects. `route` needs to be
    updated after the `meanShift` function call, and then we can use the following
    call to the `polylines` function in order to draw the `route` over the original
    video frame:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，`route`是一个`Point`对象的`vector`。在调用`meanShift`函数后，需要更新`route`，然后我们可以使用以下对`polylines`函数的调用，以便在原始视频帧上绘制`route`：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following picture depicts the result of displaying the tracking route (for
    the last 60 frames) on the original video frames read from the camera:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片展示了在从相机读取的原始视频帧上显示跟踪路线（最后60帧）的结果：
- en: '![](img/00073.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00073.jpeg)'
- en: Now, let's address some issues that we observed while working with the `meanShift`
    function. First of all, it is not convenient to create the hue histogram manually.
    A flexible program should allow the user to choose the object they want to track,
    or at least allow the user to choose the color of the object of interest conveniently.
    The same can be said about the search window size and its initial position. There
    are a number of ways to deal with such issues and we're going to address them
    with a hands-on example.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们解决我们在使用`meanShift`函数时观察到的一些问题。首先，手动创建色调直方图并不方便。一个灵活的程序应该允许用户选择他们想要跟踪的对象，或者至少允许用户方便地选择感兴趣对象的颜色。同样，关于搜索窗口的大小及其初始位置也是如此。有几种方法可以处理这些问题，我们将通过一个实际示例来解决这个问题。
- en: When using the OpenCV library, you can use the `setMouseCallback` function to
    customize the behavior of mouse clicks on an output window. This can be used in
    combination with a few simple methods, such as `bitwise_not` to mimic an easy-to-use
    object selection for the users. `setMouseCallback`, as it can be guessed from
    its name, sets a callback function to handle the mouse clicks on a given window.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用OpenCV库时，您可以使用`setMouseCallback`函数来自定义输出窗口上鼠标点击的行为。这可以与一些简单的方法结合使用，例如`bitwise_not`，以模拟用户易于使用的对象选择。从其名称可以猜出，`setMouseCallback`设置一个回调函数来处理给定窗口上的鼠标点击。
- en: 'The following callback function in conjunction with the variables defined here
    can be used to create a convenient object selector:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下回调函数与在此定义的变量结合使用，可以创建一个方便的对象选择器：
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `event` contains an entry from the `MouseEventTypes` enum, which describes
    whether a mouse button was pressed or released. Based on such a simple event,
    we can decide when the user is actually selecting an object that''s visible on
    the screen. This is depicted as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`event`包含来自`MouseEventTypes`枚举的一个条目，它描述了是否按下了鼠标按钮或释放了鼠标按钮。基于这样一个简单的事件，我们可以决定用户何时实际上在屏幕上选择一个可见的对象。这如下所示：'
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This allows a huge amount of flexibility for our applications, and the code
    is bound to work with objects of any color. Make sure to check out the example
    codes for this chapter from the online Git repository for a complete example project
    that uses all the topics we've learned so far in this chapter.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们应用提供了巨大的灵活性，代码也必定能够与任何颜色的对象一起工作。请确保查看在线Git仓库中本章的示例代码，以获取一个完整的项目示例，该项目使用了本章迄今为止我们学到的所有主题。
- en: Another method of selecting an object or a region on an image is by using the `selectROI`
    and `selectROIs` functions in the OpenCV library. These functions allow the user
    to select a rectangle (or rectangles) on an image using simple mouse clicks and
    drags. Note that the `selectROI` and `selectROIs` functions are easier to use
    than handling mouse clicks using callback functions, however they do not offer
    the same amount of power, flexibility, and customization.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV库中，选择图像上的对象或区域的一种方法是使用`selectROI`和`selectROIs`函数。这些函数允许用户通过简单的鼠标点击和拖动在图像上选择矩形（或多个矩形）。请注意，`selectROI`和`selectROIs`函数比使用回调函数处理鼠标点击更容易使用，但它们提供的功能、灵活性和定制程度并不相同。
- en: Before moving on to the next section, let's recall that `meanShift` does not
    handle an increase or decrease in the size of the object that is being tracked,
    nor does it take care of the orientation of the object. These are probably the
    main issues that have led to the development of a more sophisticated version of
    the Mean Shift algorithm, which is the next topic we're going to learn about in
    this chapter.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一节之前，让我们回顾一下`meanShift`不处理被跟踪对象大小的增加或减少，也不关心对象的方向。这些问题可能是导致开发更复杂版本的均值漂移算法的主要原因，这是我们将在本章接下来学习的内容。
- en: Using the Continuously Adaptive Mean (CAM) Shift
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用连续自适应均值（CAM）Shift
- en: To overcome the limitations of the Mean Shift algorithm, we can use an improved
    version of it, which is called the **Continuously Adaptive Mean** Shift, or simply
    the **CAM** Shift algorithm. OpenCV contains the implementation for the CAM Shift
    algorithm in a function named `CamShift`, which is used almost in an identical
    manner to the `meanShift` function. The input parameters of the `CamShift` function
    are the same as `meanShift`, since it also uses a back-projection image to update
    a search window using a given set of termination criteria. In addition, `CamShift`
    also returns a `RotatedRect` object, which contains both the search window and
    its angle.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服均值漂移算法的局限性，我们可以使用其改进版本，这被称为**连续自适应均值**，或简称**CAM**算法。OpenCV在名为`CamShift`的函数中实现了CAM算法，其使用方式几乎与`meanShift`函数相同。`CamShift`函数的输入参数与`meanShift`相同，因为它也使用一个反向投影图像来根据给定的终止条件更新搜索窗口。此外，`CamShift`还返回一个`RotatedRect`对象，它包含搜索窗口及其角度。
- en: 'Without using the returned `RotatedRect` object, you can simply replace any
    call to the `meanShift` function with `CamShift`, and the only difference would
    be that the results will be scale-invariant, meaning the search window will become
    bigger if the object is nearer (or bigger) and vice versa. For instance, we can
    replace the call to the `meanShift` function in the preceding example code for
    the Mean Shift algorithm with the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 不使用返回的`RotatedRect`对象，你可以简单地用`CamShift`替换任何对`meanShift`函数的调用，唯一的区别是结果将是尺度不变的，这意味着如果对象更近（或更大），搜索窗口会变大，反之亦然。例如，我们可以将先前的均值漂移算法示例代码中对`meanShift`函数的调用替换为以下内容：
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The following images depict the result of replacing the `meanShift` function
    with `CamShift` in the example from the previous section:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了在上一节示例中将`meanShift`函数替换为`CamShift`的结果：
- en: '![](img/00074.jpeg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00074.jpeg)'
- en: 'Notice that the results are now scale-invariant, even though we didn''t change
    anything except replace the mentioned function. As the object moves farther away
    from the camera, or becomes smaller, the same Mean Shift algorithm is used to
    calculate its position, however, this time the search window is resized to fit
    the exact size of the object, and the rotation is calculated, which we didn''t
    use. To be able to use the rotation value of the object, we need to store the
    result of the `CamShift` function in a `RotatedRect` object first, as seen in
    the following example:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在结果具有尺度不变性，尽管我们除了替换提到的函数外没有做任何改变。当对象远离相机或变得较小时，我们仍然使用相同的Mean Shift算法来计算其位置，然而，这次搜索窗口被调整大小以适应对象的精确大小，并计算了旋转，这是我们之前没有使用的。为了能够使用对象的旋转值，我们首先需要将`CamShift`函数的结果存储在`RotatedRect`对象中，如下面的示例所示：
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To draw a `RotatedRect` object, or in other words a rotated rectangle, you
    must use the `points` method of `RotatedRect` to extract the consisting `4` points
    of the rotated rectangle first, and then draw them all using the line function,
    as seen in the following example:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制`RotatedRect`对象，换句话说，是一个旋转矩形，你必须使用`RotatedRect`的`points`方法首先提取旋转矩形的`4`个组成点，然后使用线函数将它们全部绘制出来，如下面的示例所示：
- en: '[PRE18]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You can also use a `RotatedRect` object to draw a rotated ellipse that is covered
    by the rotated rectangle. Here''s how:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用`RotatedRect`对象来绘制一个被旋转矩形覆盖的旋转椭圆。以下是方法：
- en: '[PRE19]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following image displays the result of using the `RotatedRect` object to
    draw a rotated rectangle and ellipse at the same time, over the tracked object:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了使用`RotatedRect`对象同时绘制旋转矩形和椭圆的结果，覆盖在跟踪对象上：
- en: '![](img/00075.jpeg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00075.jpeg)'
- en: In the preceding image, the red rectangle is the search window, the blue rectangle
    is the resulting rotated rectangle, and the green ellipse is drawn by using the
    resulting rotated rectangle.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，红色矩形是搜索窗口，蓝色矩形是结果旋转矩形，绿色椭圆是通过使用结果旋转矩形绘制的。
- en: To summarize, we can say that `CamShift` is far better suited to dealing with
    objects of varying size and rotation than `meanShift`, however, there are still
    a couple of possible enhancements that can be done when using the `CamShift` algorithm.
    First things first, the initial window size still needs to be set, but since `CamShift`
    is taking care of the size changes, then we can simply set the initial window
    size to be the same as the whole image size. This would help us avoid having to
    deal with the initial position and size of the search window. If we can also create
    the histogram of the object of interest using a previously saved file on disk
    or any similar method, then we will have an object detector and tracker that works
    out of the box, at least for all the cases where our object of interest has a
    visibly different color than the environment.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们可以认为`CamShift`在处理大小和旋转各不相同的目标方面比`meanShift`更适合，然而，在使用`CamShift`算法时，仍然有一些可能的改进可以实施。首先，初始窗口大小仍然需要设置，但由于`CamShift`负责处理大小变化，因此我们可以直接将初始窗口大小设置为整个图像的大小。这将帮助我们避免处理搜索窗口的初始位置和大小。如果我们还能使用磁盘上预先保存的文件或任何类似的方法来创建感兴趣对象的直方图，那么我们将拥有一个即插即用的对象检测器和跟踪器，至少对于我们的感兴趣对象与周围环境颜色明显不同的所有情况来说是这样的。
- en: 'Another huge improvement to such a color-based detection and tracking algorithm
    can be achieved by using the `inRange` function to enforce a threshold on the
    S and V channels of the HSV image that we are using to calculate the histogram.
    The reason is that in our example, we simply used the **hue** (or the **H**, or
    the first) channel, and we didn''t take into account the high possibility of having
    extremely dark or bright pixels that might have the same hue as our object of
    interest. This can be done by using the following code when calculating the histogram
    of the object to be tracked:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`inRange`函数对用于计算直方图的HSV图像的S和V通道施加阈值，可以实现对基于颜色的检测和跟踪算法的一个巨大改进。原因是，在我们的例子中，我们只是简单地使用了**色调**（或**H**，或第一个）通道，并且没有考虑到可能具有与我们的感兴趣对象相同色调的非常暗或非常亮的像素的高可能性。这可以通过在计算要跟踪的对象的直方图时使用以下代码来完成：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In the preceding example code, the variables starting with `lb` and `hb` refer
    to the lower bound and higher bound of the values that are allowed to pass the
    `inRange` function. `objImgHsv` is obviously a `Mat` object containing our object
    of interest, or a ROI that contains our object of interest. `objImgHue` is the
    first channel of `objImgHsv`, which is extracted using a previous call to the `split`
    function. The rest of the parameters are nothing new, and you've already used
    them in previous calls to the functions used in this example.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例代码中，以`lb`和`hb`开头的变量指的是允许通过`inRange`函数的值的下限和上限。`objImgHsv`显然是一个包含我们感兴趣的对象或包含我们感兴趣对象的ROI的`Mat`对象。`objImgHue`是`objImgHsv`的第一个通道，它是通过之前的`split`函数调用来提取的。其余的参数没有什么新东西，你已经在之前的函数调用中使用过它们了。
- en: Combining all of the algorithms and techniques described in this section can
    help you create an object-detector, or even a face-detector and tracker that can
    work in realtime and with stunning speed. However, you might still need to account
    for the noise that will interfere, especially with the tracking, which is almost
    inevitable because of the nature of color-based or histogram-based trackers. One
    of the most widely used solutions to these issues is the subject of the next section
    in this chapter.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 结合本节中描述的所有算法和技术可以帮助你创建一个对象检测器，甚至是一个可以实时工作且速度惊人的面部检测器和跟踪器。然而，你可能仍然需要考虑会干扰的噪声，尤其是在跟踪过程中，由于基于颜色或直方图跟踪器的本质，跟踪几乎是不可避免的。解决这些问题的最广泛使用的方法是本章下一节的主题。
- en: Using the Kalman filter for tracking and noise reduction
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卡尔曼滤波进行跟踪和噪声降低
- en: The Kalman filter is a popular algorithm that is used for reducing the noise
    of a signal, such as the result of the tracking algorithm that we used in the
    preceding section. To be precise, the Kalman filter is an estimation algorithm
    that is used to predict the next state of a signal based on previous observations.
    Digging deep into the definition and details of the Kalman filter would require
    a chapter of its own, but we'll try to walk through this simple, yet extremely
    powerful, algorithm with a couple of hands-on examples to learn how it is used
    in practice.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波是一种流行的算法，用于降低信号的噪声，例如我们前面章节中使用的跟踪算法的结果。为了更精确，卡尔曼滤波是一种估计算法，用于根据之前的观察预测信号的下一个状态。深入探讨卡尔曼滤波的定义和细节需要单独的一章，但我们将尝试通过几个实际操作的例子来了解这个简单而极其强大的算法是如何在实际中应用的。
- en: For the first example, we're going to write a program that tracks the mouse
    cursor while it is moved on a canvas, or the OpenCV window. The Kalman filter
    is implemented using the `KalmanFilter` class in OpenCV and it includes all (and
    many more) of the Kalman filter implementation details, which we'll discuss in
    this section.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个例子，我们将编写一个程序来跟踪鼠标光标在画布上移动，或者OpenCV窗口中的移动。卡尔曼滤波是通过OpenCV中的`KalmanFilter`类实现的，它包括了所有（以及更多）的卡尔曼滤波实现细节，我们将在本节中讨论这些细节。
- en: 'First of all, `KalmanFilter` must be initialized with a number of dynamic parameters,
    measurement parameters, and control parameters, in addition to the type of the
    underlying data used in the Kalman filter itself. We''re going to ignore control
    parameters, since they are outside the scope of our examples, so we''ll set them
    simply to zero. As for the data type, we''ll go for the default 32-bit float,
    or `CV_32F` in terms of OpenCV types. Dynamic parameters in a 2D movement, which
    is the case with our example, correspond to the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`KalmanFilter`必须使用一定数量的动态参数、测量参数和控制参数进行初始化，以及卡尔曼滤波本身所使用的基础数据类型。我们将忽略控制参数，因为它们超出了我们示例的范围，所以我们将它们简单地设置为零。至于数据类型，我们将使用默认的32位浮点数，或者用OpenCV类型表示为`CV_32F`。在二维运动中，例如我们的例子，动态参数对应于以下内容：
- en: '*X*, or position in *x* direction'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X*，或x方向的位置'
- en: '*Y*, or position in *y* direction'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y*，或y方向的位置'
- en: '*X*'', or velocity in *x* direction'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X*''，或x方向的速度'
- en: '*Y*'', or velocity in *y* direction'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y*''，或y方向的速度'
- en: A higher dimensionality of the parameters can also be used, which would then
    cause the preceding list to be followed by *X*'' (acceleration in *x* direction)
    and so on.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 参数的高维性也可以被使用，这会导致前面的列表后面跟着 *X*''（x方向上的加速度）等等。
- en: 'As for the measurement parameters, we''ll simply have *X* and *Y*, which correspond
    to the mouse position in our first example. Keeping in mind what was said about
    dynamic and measurement parameters, here''s how we can initialize a `KalmanFilter`
    class instance (object) that fits for tracking a point on a 2D space:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 关于测量参数，我们只需有 *X* 和 *Y*，它们对应于我们第一个例子中的鼠标位置。牢记关于动态和测量参数的讨论，以下是初始化一个适合在二维空间跟踪点的
    `KalmanFilter` 类实例（对象）的方法：
- en: '[PRE21]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Note that in this example, control parameters and type parameters are simply
    ignored and set to their default values, otherwise we could have written the same
    code as seen here:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个例子中，控制参数和类型参数被简单地忽略，并设置为它们的默认值，否则我们就可以像下面这样编写相同的代码：
- en: '[PRE22]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `KalmanFilter` class requires a transition matrix to be set before it is
    correctly usable. This transition matrix is used for calculating (and updating)
    the estimated, or next, state of the parameters. We''ll be using the following
    transition matrix in our example for tracking the mouse position:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`KalmanFilter` 类在使用之前需要设置一个转换矩阵才能正确使用。这个转换矩阵用于计算（并更新）参数的估计或下一个状态。在我们的例子中，我们将使用以下转换矩阵来跟踪鼠标位置：'
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After completing the steps required for this example, it would be wise to return
    here and update the values in the transition matrix and observe the behavior of
    the Kalman filter. For instance, try to update the matrix row that corresponds
    to the estimated *Y* (marked as `next y` in the comments) and you'll notice that
    the tracked position *Y* value is affected by it. Try experimenting with all of
    the values in the transition matrix for a better understanding of its effect.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这个例子所需的步骤后，明智的做法是返回这里并更新转换矩阵中的值，并观察卡尔曼滤波器的行为。例如，尝试更新对应于估计的 *Y*（在注释中标记为 `next
    y`）的矩阵行，你会注意到跟踪的位置 *Y* 值会受到它的影响。尝试通过实验所有转换矩阵中的值来更好地理解其影响。
- en: 'Besides the transition matrix, we also need to take care of the initialization
    of the dynamic parameters'' state and measurements, which are the initial mouse
    positions in our example. Here''s how we initialize the mentioned values:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 除了转换矩阵之外，我们还需要注意动态参数状态和测量的初始化，这些在我们的例子中是初始鼠标位置。以下是初始化这些值的方法：
- en: '[PRE24]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As you''ll see later on, the `KalmanFilter` class requires a vector instead
    of a `Point` object, since it is designed to work with higher dimensionalities
    too. For this reason, we''ll update the `pos` vector in the preceding code snippet
    with the last mouse positions before performing any calculations. Other than the
    initializations that we just mentioned, we also need to initialize the measurement
    matrix of the Kalman filter. This is done as seen here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 你稍后会看到，`KalmanFilter` 类需要一个向量而不是 `Point` 对象，因为它也设计用于处理更高维度。因此，在执行任何计算之前，我们将更新前面代码片段中的
    `pos` 向量，以包含最后一个鼠标位置。除了我们刚才提到的初始化之外，我们还需要初始化卡尔曼滤波器的测量矩阵。这就像下面这样完成：
- en: '[PRE25]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `setIdentity` function in OpenCV is simply used to initialize matrices with
    a scaled identity matrix. If only a single matrix is provided as a parameter to
    the `setIdentity` function, it will set to the identity matrix, however if a second
    `Scalar` is provided in addition, then all elements of the identity matrix will
    be multiplied (or scaled) using the given `Scalar` value.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 中的 `setIdentity` 函数简单地用于使用缩放后的单位矩阵初始化矩阵。如果只向 `setIdentity` 函数提供一个参数作为矩阵，它将被设置为单位矩阵；然而，如果还提供了一个额外的
    `Scalar`，则单位矩阵的所有元素都将乘以（或缩放）给定的 `Scalar` 值。
- en: 'One last initialization is the process noise covariance. We''ll use a very
    small value for this, which causes a tracking with a natural-movement feeling,
    although with a little bit of overshoot when tracking. Here''s how we initialize
    the process-noise covariance matrix:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个初始化是过程噪声协方差。我们将为此使用一个非常小的值，这会导致跟踪具有自然运动感觉，尽管在跟踪时会有一点过冲。以下是初始化过程噪声协方差矩阵的方法：
- en: '[PRE26]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'It is also common to initialize the following matrices before using the `KalmanFilter`
    class:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 `KalmanFilter` 类之前，初始化以下矩阵也是常见的做法：
- en: '`controlMatrix` (not used if the control parameter count is zero)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`controlMatrix`（如果控制参数计数为零则不使用）'
- en: '`errorCovPost`'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`errorCovPost`'
- en: '`errorCovPre`'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`errorCovPre`'
- en: '`gain`'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gain`'
- en: '`measurementNoiseCov`'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`measurementNoiseCov`'
- en: Using all of the matrices mentioned in the preceding list will provide a huge
    amount of customization to the `KalmanFilter` class, but it also requires a great
    amount of knowledge about the type of noise-filtering and tracking that is needed
    and the environment that the filter will be implemented in. These matrices and
    their usage have deep roots in control theory, and control science in general,
    which is a topic for another book. Note that in our example, we'll simply use
    the default values of the mentioned matrices, thus we have ignored them altogether.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面提到的所有矩阵将为 `KalmanFilter` 类提供大量的定制，但也需要大量关于所需噪声滤波和跟踪类型以及滤波器将实现的环境的知识。这些矩阵及其使用在控制理论和控制科学中有着深厚的根源，这是一个另一个书籍的主题。请注意，在我们的示例中，我们将简单地使用提到的矩阵的默认值，因此我们完全忽略了它们。
- en: 'The next thing we need in our tracking example using the Kalman filter is to
    set up a window on which we can track mouse movements. We are assuming that the
    position of the mouse on the window is the position of a detected and tracked
    object and we''ll use our `KalmanFilter` object to predict and de-noise these
    detections, or in Kalman-filter-algorithm terminology, we are going to correct
    these measurements. We can use the `namedWindow` function to create a window using
    OpenCV. Consequently, the `setMouseCallback` function can be used to assign a
    callback function for mouse interactions with that specific window. Here''s how
    we can do it:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的使用卡尔曼滤波器的跟踪示例中，接下来我们需要的是设置一个窗口，我们可以在这个窗口上跟踪鼠标移动。我们假设鼠标在窗口上的位置是检测和跟踪的对象的位置，我们将使用我们的
    `KalmanFilter` 对象来预测和去噪这些检测，或者用卡尔曼滤波算法的术语来说，我们将纠正这些测量。我们可以使用 `namedWindow` 函数使用
    OpenCV 创建一个窗口。因此，可以使用 `setMouseCallback` 函数为与该特定窗口的鼠标交互分配回调函数。以下是我们可以这样做的方法：
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We''ve used the word `Canvas` for the window, but obviously you can use any
    other name you like. `onMouse` is the callback function that will be assigned
    to react on mouse interactions with this window. It is defined like this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将“Canvas”这个词用于窗口，但显然你可以使用你喜欢的任何其他名字。`onMouse` 是将被分配以响应与该窗口的鼠标交互的回调函数。它被定义如下：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, for the actual tracking, or to use the more correct terminology, correcting
    the measurements that contain noise, we need to use the following code, which
    is followed by the required explanations:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，对于实际的跟踪，或者使用更准确的术语，纠正包含噪声的测量值，我们需要使用以下代码，后面将跟随必要的解释：
- en: '[PRE30]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the preceding code, we are using the `trackRoute` vector to record the estimations
    over the last `100` frames. Pressing any key will cause the `while` loop, and
    consequently the program, to return. Inside the loop, and where we actually use
    the `KalmanFilter` class, we simply perform the following operations in order:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用 `trackRoute` 向量记录过去 `100` 帧的估计值。按下任何键将导致 `while` 循环，从而程序返回。在循环内部，以及我们实际使用
    `KalmanFilter` 类的地方，我们简单地按以下顺序执行以下操作：
- en: Create an empty `Mat` object to be used as a canvas to draw, and for the content
    of the window on which the tracking will happen
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个空的 `Mat` 对象，用作绘制画布，以及跟踪将发生的窗口的内容
- en: Read the `objectPos`, which contains the last position of the mouse on the window
    and store it in the `pos` vector, which is usable with the `KalmanFilter` class
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取 `objectPos`，它包含鼠标在窗口上的最后位置，并将其存储在 `pos` 向量中，该向量可用于 `KalmanFilter` 类
- en: Read an estimation using the correct method of the `KalmanFilter` class
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `KalmanFilter` 类的正确方法读取估计值
- en: Convert the result of the estimation back to a `Point` object that can be used
    for drawing
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将估计结果转换回可用于绘制的 `Point` 对象
- en: Store the estimated point (or the tracked point) in the `trackRoute` vector,
    and make sure the number of items in the `trackRoute` vector doesn't exceed `100`,
    since that is the number of frames for which we want to keep a record of estimated
    points
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将估计点（或跟踪点）存储在 `trackRoute` 向量中，并确保 `trackRoute` 向量中的项目数量不超过 `100`，因为这是我们想要记录估计点的帧数
- en: Use the polylines function to draw the route, stored as `Point` objects in `trackRoute`
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用多段线函数绘制路线，将路线存储为 `Point` 对象在 `trackRoute` 中
- en: Display the results using the `imshow` function
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `imshow` 函数显示结果
- en: Update the internal matrices of the `KalmanFilter` class using the predict function
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用预测函数更新 `KalmanFilter` 类的内部矩阵
- en: 'Try executing the tracking program and move your mouse cursor around the window
    that is shown. You''ll notice a smooth tracking result, which is drawn using the
    thick red line that''s visible in the following screenshot:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试执行跟踪程序并在显示的窗口中移动鼠标光标。你会注意到一个平滑的跟踪结果，它使用以下截图中的粗红色线条绘制：
- en: '![](img/00076.gif)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00076.gif)'
- en: 'Note that the position of the mouse cursor is ahead of the tracking, and the
    noise in mouse movement is almost completely removed. It is a good idea to try
    to visualize the mouse movement for a better comparison between the `KalmanFilter`
    results and actual measurements. Simply add the following code to the loop after
    the point where `trackRoute` was drawn in the preceding code:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到鼠标光标的位置在跟踪之前，鼠标移动的噪声几乎被完全消除。尝试可视化鼠标移动以更好地比较`KalmanFilter`结果和实际测量结果是个好主意。只需在前面代码中`trackRoute`绘制点之后添加以下代码：
- en: '[PRE31]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And obviously, you need to define the `mouseRoute` vector before entering the
    `while` loop, as seen here:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在进入`while`循环之前，你需要定义`mouseRoute`向量，如下所示：
- en: '[PRE32]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let''s try the same application with this minor update and see how the results
    compare to each other. Here''s another screenshot depicting the results of actual
    mouse movements and corrected movements (or tracked, or filtered, depending on
    the terminology) drawn in the same window:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用这个小的更新来运行相同的应用程序，并看看结果如何相互比较。以下是另一个截图，展示了实际鼠标移动和校正后的移动（或跟踪，或滤波，具体取决于术语）在同一窗口中的结果：
- en: '![](img/00077.jpeg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00077.jpeg)'
- en: 'In the preceding result, the arrow is simply used to depict the overall direction
    of an extremely noisy measurement (mouse movement or detected object position,
    depending on the application), which is drawn using a thin black color, and the
    corrected results using the Kalman filter algorithm, which are drawn with a thick
    red line in the image. Try moving you mouse around and comparing the results visually.
    Remember what we mentioned about the `KalmanFilter` internal matrices and how
    you need to set their values according to the use case and application? For instance,
    a bigger process-noise covariance would have resulted in less de-noising and consequently
    less filtering. Let''s try setting the process noise covariance value to `0.001`,
    instead of the previous 0.000001 value, try the same program once again, and compare
    the results. Here''s how you can set the process-noise covariance:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的结果中，箭头只是用来表示一个极其嘈杂的测量（鼠标移动或检测到的对象位置，具体取决于应用）的整体方向，它用细黑色线条绘制，而使用卡尔曼滤波算法校正的结果，在图像中用粗红色线条绘制。尝试移动鼠标并直观地比较结果。还记得我们提到的`KalmanFilter`内部矩阵以及你需要根据用例和应用设置它们的值吗？例如，更大的过程噪声协方差会导致去噪更少，从而滤波更少。让我们尝试将过程噪声协方差值设置为`0.001`，而不是之前的`0.000001`值，再次运行相同的程序，并比较结果。以下是设置过程噪声协方差的方法：
- en: '[PRE33]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, try running the program once again and you can easily notice that less
    de-noising is happening as you move the mouse cursor around the window:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，再次运行程序，你可以很容易地注意到，当你将鼠标光标在窗口周围移动时，去噪现象减少：
- en: '![](img/00078.gif)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00078.gif)'
- en: By now, you can probably guess that the result of setting an extremely high
    value for process-noise covariance would be almost the same as using no filter
    at all. This is the reason why setting correct values for the Kalman filter algorithm
    is extremely important and also the reason why it depends so much on the application.
    However, there are methods for setting most of those parameters programmatically,
    and even dynamically while the tracking is being done to achieve the best results.
    For instance, using a function that is able to determine the possible amount of
    noise at any given moment, we can dynamically set the process noise covariance
    to high or low values for less and more de-noising of the measurements.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能已经猜到，将过程噪声协方差设置得极高，其结果几乎与完全不使用滤波器相同。这就是为什么设置卡尔曼滤波算法的正确值极其重要，也是它如此依赖于应用的原因。然而，有方法可以通过编程设置大多数这些参数，甚至在跟踪过程中动态地调整以实现最佳结果。例如，使用一个能够确定任何给定时刻可能噪声量的函数，我们可以动态地将过程噪声协方差设置为高或低值，以实现更少或更多的去噪。
- en: 'Now, let''s use `KalmanFilter` to perform a real-life tracking correction on
    objects using the `CamShift` function, instead of mouse movements. It''s important
    to note that the applied logic is exactly the same. We need to initialize a `KalmanFilter`
    object and set its parameters according to the amount of noise and so on. For
    simplicity, you can start off with the exact same set of parameters that we set
    for tracking the mouse cursor in the previous example, and then try to adjust
    them. We need to start by creating the same tracking program that we wrote in
    the previous sections. However, right after calling `CamShift` (or `meanShift`
    function) to update the search window, instead of displaying the results, we''ll
    perform a correction using the `KalmanFilter` class to de-noise the results. Here''s
    how it is done with a similar example code:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`KalmanFilter`来执行一个现实生活中的跟踪校正，使用`CamShift`函数对物体进行跟踪，而不是鼠标移动。需要注意的是，应用的逻辑完全相同。我们需要初始化一个`KalmanFilter`对象，并根据噪声量等设置其参数。为了简单起见，你可以从与之前示例中设置跟踪鼠标光标相同的参数集开始，然后尝试调整它们。我们需要从创建与之前章节中编写的相同跟踪程序开始。然而，在调用`CamShift`（或`meanShift`函数）来更新搜索窗口后，而不是显示结果，我们将使用`KalmanFilter`类进行校正以去噪结果。以下是使用类似示例代码的执行方式：
- en: '[PRE34]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: You can refer to the online source code repository of this chapter for the complete
    example project containing the preceding code, which is almost identical to what
    you saw in the previous sections, except for the simple fact that `KalmanFilter`
    is used to correct the detected and tracked object position. As you can see, `objectPos`,
    which was previously read from the mouse movement position, is now set to the
    central point of the search window. After that, the `correct` function is called
    to perform an estimation and the results are displayed by drawing a green cross
    mark for the corrected tracking result. Besides the main advantage of using the
    Kalman filter algorithm, which is useful for getting rid of noise in detection
    and tracking results, it can also help with cases where detection is momentarily
    lost or impossible. Although losing detection is, technically speaking, an extreme
    case of noise, we're trying to point out the difference in terms of computer vision.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考本章在线源代码仓库中的完整示例项目，其中包含前面的代码，它与之前章节中看到的内容几乎相同，只是简单的事实是使用了`KalmanFilter`来校正检测和跟踪到的物体位置。正如你所看到的，`objectPos`，之前是从鼠标移动位置读取的，现在被设置为搜索窗口的中心点。之后，调用`correct`函数进行估计，并通过绘制绿色十字标记显示校正后的跟踪结果。除了使用卡尔曼滤波器算法的主要优势，即有助于去除检测和跟踪结果中的噪声外，它还可以帮助处理检测暂时丢失或不可能的情况。虽然从技术上讲，检测丢失是噪声的极端情况，但我们试图从计算机视觉的角度指出这种差异。
- en: By going through a few examples and also experimenting with your own projects
    where the Kalman filter can be of help and trying different set of parameters
    for it, you'll instantly understand its long-standing popularity for whenever
    a practical algorithm for correcting a measurement (that contains noise) is required.
    What we learned in this section was a fairly simple case of how the Kalman filter
    is used (which was enough for our use case), but it is important to note that
    the same algorithm can be used to de-noise measurements of higher dimensionalities
    and with much more complexity.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析几个示例，并在自己的项目中尝试使用卡尔曼滤波器来帮助解决问题，并为其尝试不同的参数集，你将立即理解它在需要纠正测量（包含噪声）的实用算法时的长期受欢迎。在本节中我们学到的关于卡尔曼滤波器的使用是一个相当简单的情况（这对于我们的用例已经足够了），但重要的是要注意，相同的算法可以用于去噪更高维度的测量，以及具有更多复杂性的情况。
- en: How to extract the background/foreground
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何提取背景/前景
- en: The segmentation of background and foreground content in images is one of the
    most important video and motion analysis topics, and there has been a huge amount
    of research done in this area to provide some very practical and easy-to-use algorithms,
    which we're going to learn in the final section of this chapter. Current versions
    of OpenCV include the implementation of two background segmentation algorithms.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像中分割背景和前景内容是视频和运动分析中最重要的话题之一，在这个领域已经进行了大量的研究，以提供一些非常实用且易于使用的算法，我们将在本章的最后部分学习这些算法。当前版本的OpenCV包括两种背景分割算法的实现。
- en: To use a terminology that is shorter, clearer, and more compatible with OpenCV
    functions and classes, we'll refer to background/foreground extraction and background/foreground
    segmentation simply as background segmentation.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用更简短、更清晰且与OpenCV函数和类更兼容的术语，我们将背景/前景提取和背景/前景分割简单地称为背景分割。
- en: 'The following two algorithms are available by default to be used for background
    segmentation using OpenCV:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV默认提供了以下两个算法用于背景分割：
- en: '`BackgroundSubtractorKNN`'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BackgroundSubtractorKNN`'
- en: '`BackgroundSubtractorMOG2`'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BackgroundSubtractorMOG2`'
- en: Both of these classes are subclasses of `BackgroundSubtractor`, which contains
    all of the required interfaces that one can expect from a proper background segmentation
    algorithm, which we'll get to later on. This simply allows us to use polymorphism
    to switch between algorithms that produce the same results and can be used in
    a very similar fashion for the exact same reason. The `BackgroundSubtractorKNN`
    class implements the K-nearest neighbors background segmentation algorithm, which
    is used in the case of a low foreground pixel count. `BackgroundSubtractorMOG2`,
    on the other hand, implements the Gaussian mixture-based background-segmentation
    algorithm. You can refer to the OpenCV online documentation for detailed information
    about the internal behavior and implementation of these algorithms. It's also
    a good idea to go through the referred articles for both of these algorithms,
    especially if you are looking for a custom background segmentation algorithm of
    your own.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个类都是`BackgroundSubtractor`的子类，它包含了一个合适的背景分割算法所必需的所有接口，我们将在稍后讨论。这仅仅允许我们使用多态性在产生相同结果且用法非常相似的算法之间切换。`BackgroundSubtractorKNN`类实现了K最近邻背景分割算法，适用于前景像素计数较低的情况。另一方面，`BackgroundSubtractorMOG2`实现了基于高斯混合的背景分割算法。你可以参考OpenCV在线文档以获取有关这些算法内部行为和实现的详细信息。阅读这些算法的相关文章也是一个好主意，特别是如果你正在寻找自己的自定义背景分割算法的话。
- en: Besides the algorithms we already mentioned, there are many more algorithms
    that can be used for background segmentation using OpenCV, which are included
    in the extra module, `bgsegm`. We'll omit those algorithms, since their usage
    is quite similar to the algorithms we'll be talking about in this section, and
    also because they do not exist in OpenCV by default.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们之前提到的算法外，还有许多其他算法可以使用OpenCV进行背景分割，这些算法包含在额外的模块`bgsegm`中。我们将省略这些算法，因为它们的用法与我们将在本节中讨论的算法非常相似，而且它们在OpenCV中默认不存在。
- en: An example of background segmentation
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景分割的一个示例
- en: 'Let''s start with the `BackgroundSubtractorKNN` class and a hands-on example
    to see how background segmentation algorithms are used. You can use the `createBackgroundSubtractorKNN` function
    to create an object of the `BackgroundSubtractorKNN` type. Here''s how:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`BackgroundSubtractorKNN`类和一个实际操作示例开始，看看背景分割算法是如何使用的。你可以使用`createBackgroundSubtractorKNN`函数创建一个`BackgroundSubtractorKNN`类型的对象。以下是方法：
- en: '[PRE35]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: To understand the parameters used in the `BackgroundSubtractorKNN` class, it
    is important to first note that this algorithm uses a sampling technique over
    the history of pixels to create a sampled background image. With that being said,
    the `history` parameter is used to define the number of previous frames that are
    used for sampling the background image, and the `dist2Threshold` parameter is
    the threshold of squared distance between a pixel's current value and its corresponding
    pixel value in the sampled background image. `detectShadows` is a self-explanatory
    parameter that is used to determine whether the shadows are going to be detected
    during background segmentation or not.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解`BackgroundSubtractorKNN`类中使用的参数，首先需要注意的是，此算法使用像素历史记录中的采样技术来创建一个采样背景图像。换句话说，`history`参数用于定义用于采样背景图像的先前帧数，而`dist2Threshold`参数是像素当前值与其在采样背景图像中对应像素值的平方距离的阈值。"detectShadows"是一个自解释的参数，用于确定在背景分割过程中是否检测阴影。
- en: 'Now, we can simply use `bgs` to extract foreground masks from a video and use
    it to detect movements or an object entering the scene. Here''s how:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以简单地使用`bgs`从视频中提取前景掩码，并使用它来检测运动或物体进入场景。以下是方法：
- en: '[PRE36]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let''s quickly review the parts of the previous code that are new and maybe
    not that obvious. First things first, we use the `apply` function of the `BackgroundSubtractorKNN`
    class to perform a background/foreground segmentation operation. This function
    also updates the internal sampled background image for us. After that, we use
    the `bitwise_and` function with the foreground mask to extract the foreground
    image''s content. To retrieve the sampled background image itself, we simply use
    the `getBackgroundImage` function. Finally, we display all of the results. Here
    are some example results that depict a scene (top-left), the extracted background
    image (top-right), the foreground mask (bottom-left), and the foreground image
    (bottom-right):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速回顾一下之前代码中新的、可能不是那么明显的一部分。首先，我们使用 `BackgroundSubtractorKNN` 类的 `apply` 函数执行背景/前景分割操作。此函数还为我们更新了内部采样背景图像。之后，我们使用
    `bitwise_and` 函数与前景掩码结合来提取前景图像的内容。要检索采样背景图像本身，我们只需使用 `getBackgroundImage` 函数。最后，我们显示所有结果。以下是一些示例结果，描述了一个场景（左上角），提取的背景图像（右上角），前景掩码（左下角），以及前景图像（右下角）：
- en: '![](img/00079.jpeg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00079.jpeg)'
- en: 'Notice that the shadow of the hand that moved into the scene is also captured
    by the background segmentation algorithm. In our example, we omitted the `learningRate`
    parameter when using the `apply` function. This parameter can be used to set the
    rate at which the learned background model is updated. A value of `0` means the
    model will not be updated at all, which can be quite useful if you are sure that
    the background will stay the same for any known period. A value of 1.0 means an
    extremely quick update of the model. As in the case of our example, we skipped
    this parameter, which causes it to use -1.0, and it means that the algorithm itself
    will decide on the learning rate. Another important thing to note is that the
    result of the apply function can yield an extremely noisy mask, which can be smoothed
    out by using a simple blur function, such as `medianBlur`, as seen here:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，进入场景的手的阴影也被背景分割算法捕获。在我们的示例中，我们使用 `apply` 函数时省略了 `learningRate` 参数。此参数可以用来设置学习背景模型更新的速率。值为
    `0` 表示模型将完全不会更新，这在背景在已知时间段内保持不变的情况下非常有用。值为 1.0 表示模型会非常快地更新。正如我们的示例中那样，我们跳过了此参数，导致它使用
    -1.0，这意味着算法本身将决定学习率。另一个需要注意的重要事项是，`apply` 函数的结果可能会产生一个非常嘈杂的掩码，这可以通过使用简单的模糊函数，如
    `medianBlur`，来平滑，如下所示：
- en: '[PRE37]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Using the `BackgroundSubtractorMOG2` class is quite similar to `BackgroundSubtractorKNN`.
    Here''s an example:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `BackgroundSubtractorMOG2` 类与 `BackgroundSubtractorKNN` 类非常相似。以下是一个示例：
- en: '[PRE38]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Note that the `createBackgroundSubtractorMOG2` function is used quite similarly
    to what we saw before to create an instance of the `BackgroundSubtractorMOG2`
    class. The only parameter that differs here is `varThreshold`, which corresponds
    to the variance threshold used for matching the pixels value and the background
    model. Using the `apply` and `getBackgroundImage` functions is identical in both
    background segmentation classes. Try modifying the threshold values in both algorithms
    to learn more about the visual effects of the parameters.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`createBackgroundSubtractorMOG2` 函数的使用方式与我们之前看到的使用方式非常相似，用于创建 `BackgroundSubtractorMOG2`
    类的实例。这里唯一的区别是 `varThreshold` 参数，它对应于用于匹配像素值和背景模型的方差阈值。使用 `apply` 和 `getBackgroundImage`
    函数在这两个背景分割类中是相同的。尝试修改这两个算法中的阈值值，以了解更多关于参数视觉效果的细节。
- en: Background-segmentation algorithms have great potential for video editing software
    or even detecting and tracking objects in an environment with backgrounds that
    do not change too much. Try to use them in conjunction with the algorithms that
    you learned previously in this chapter to build tracking algorithms that make
    use of multiple algorithms to improve the results.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 背景分割算法在视频编辑软件中具有很大的潜力，甚至可以在背景变化不大的环境中检测和跟踪对象。尝试将它们与本章之前学到的算法结合使用，构建利用多个算法以提高结果跟踪算法。
- en: Summary
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The video analysis module in OpenCV is a collection of extremely powerful algorithms,
    functions, and classes that we have learned about in this chapter. Starting from
    the whole idea of video processing and simple calculations based on the content
    of consecutive video frames, we moved on to learn about the Mean Shift algorithm
    and how it is used to track objects with known colors and specifications using
    a back-projection image. We also learned about the more sophisticated version
    of the Mean Shift algorithm, which is called the Continuously Adaptive Mean Shift,
    or simply CAM Shift. We learned that this algorithm is also capable of handling
    objects of different sizes and determining their orientation. Moving on with the
    tracking algorithms, we learned about the powerful Kalman filter and how it is
    used for de-noising and correcting the tracking results. We used the Kalman filter
    to track mouse movements and to correct the tracking results of the Mean Shift
    and CAM Shift algorithms. Finally, we learned about OpenCV classes that implement
    background-segmentation algorithms. We wrote a simple program to use background-segmentation
    algorithms and output the calculated background and foreground images. By now,
    we are familiar with some of the most popular and widely used computer vision
    algorithms that allow real-time detection and tracking of objects.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV中的视频分析模块是一系列极其强大的算法、函数和类的集合，我们在本章中已经了解到了它们。从视频处理的整体概念和基于连续视频帧内容的简单计算开始，我们继续学习了均值漂移算法及其如何通过后投影图像跟踪已知颜色和规格的对象。我们还学习了均值漂移算法的更复杂版本，称为连续自适应均值漂移，或简称CAM
    Shift。我们了解到这个算法也能够处理不同尺寸的对象并确定它们的朝向。在跟踪算法的学习过程中，我们了解了强大的卡尔曼滤波器及其在去噪和校正跟踪结果中的应用。我们使用卡尔曼滤波器来跟踪鼠标移动并校正均值漂移和CAM
    Shift算法的跟踪结果。最后，我们学习了实现背景分割算法的OpenCV类。我们编写了一个简单的程序来使用背景分割算法并输出计算出的背景和前景图像。到目前为止，我们已经熟悉了一些最流行和最广泛使用的计算机视觉算法，这些算法允许实时检测和跟踪对象。
- en: In the next chapter, we'll be learning about many feature extraction algorithms,
    functions, and classes, and how to use features to detect objects or extract useful
    information from images based on their key points and descriptors.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习许多特征提取算法、函数和类，以及如何使用特征根据图像的关键点和描述符检测对象或从中提取有用的信息。
- en: Questions
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: All the examples in this chapter that deal with cameras return when there is
    a single failed or corrupted frame that leads to the detection of an empty frame.
    What type of modification is needed to allow a predefined number of retries before
    stopping the process?
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章中所有涉及摄像头的示例在出现单个失败或损坏的帧导致检测到空帧时都会返回。需要什么样的修改才能在停止过程之前允许预定义的尝试次数？
- en: How can we call the `meanShift` function to perform the Mean Shift algorithm
    with 10 iterations and an epsilon value of 0.5?
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何调用`meanShift`函数以10次迭代和0.5的epsilon值执行均值漂移算法？
- en: How can we visualize the hue histogram of the tracked object? Assume `CamShift`
    is used for tracking.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何可视化跟踪对象的色调直方图？假设使用`CamShift`进行跟踪。
- en: Set the process-noise covariance in the `KalmanFilter` class so that the filtered
    and measured values overlap. Assume only the process-noise covariance is set,
    of all the available matrices for `KalmanFilter` class-behavior control.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`KalmanFilter`类中设置过程噪声协方差，以便滤波值和测量值重叠。假设只设置了过程噪声协方差，在所有可用的`KalmanFilter`类行为控制矩阵中。
- en: Let's assume that the *Y* position of the mouse on a window is used to describe
    the height of a filled rectangle that starts from the top-left corner of the window
    and has a width that equals the window width. Write a Kalman filter that can be
    used to correct the height of the rectangle (single value) and remove noise in
    the mouse movement that will cause a visually smooth resizing of the filled rectangle.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设窗口中鼠标的*Y*位置用于描述从窗口左上角开始的填充矩形的长度，该矩形的宽度等于窗口宽度。编写一个卡尔曼滤波器，可以用来校正矩形的长度（单个值）并去除鼠标移动中的噪声，这将导致填充矩形的视觉平滑缩放。
- en: Create a `BackgroundSubtractorMOG2` object to extract the foreground image contents
    while avoiding shadow changes.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`BackgroundSubtractorMOG2`对象来提取前景图像内容，同时避免阴影变化。
- en: Write a program to display the *current* (as opposed to sampled) background
    image using a background-segmentation algorithm.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个程序，使用背景分割算法显示*当前*（而不是采样）的背景图像。
