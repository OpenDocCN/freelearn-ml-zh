- en: Image Captioning with TensorFlow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow进行图像标题生成
- en: Primarily, this chapter will provide a brief overview of creating a detailed
    English language description of an image. Using the image captioning model based
    on TensorFlow, we will be able to replace a single word or compound words/phrases
    with detailed captions that perfectly describe the image. We will first use a
    pre-trained model for image captioning and then retrain the model from scratch
    to run on a set of images.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，本章将简要概述创建详细英语图像描述的过程。使用基于TensorFlow的图像标题生成模型，我们将能够用详细且完美描述图像的标题替换单个单词或复合词/短语。我们首先将使用预训练的图像标题生成模型，然后从头开始重新训练模型以在一系列图像上运行。
- en: 'In this chapter, we will cover the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Image captioning introduction
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像标题生成简介
- en: Google Brain im2txt captioning model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Brain im2txt标题生成模型
- en: Running our captioning code in Jupyter
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Jupyter中运行我们的标题生成代码
- en: Retraining the model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新训练模型
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Along with knowledge of Python, the basics of image processing, and computer
    vision, we will need the following Python libraries:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Python知识、图像处理和计算机视觉的基础知识外，我们还需要以下Python库：
- en: NumPy
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy
- en: Matplotlib
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib
- en: 'The codes used in the chapter have been added to the following GitHub repository:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的代码已添加到以下GitHub仓库中：
- en: '[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3)'
- en: Introduction to image captioning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像标题生成简介
- en: Image captioning is a process in which textual description is generated based
    on an image. To better understand image captioning, we need to first differentiate
    it from image classification.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图像标题生成是一个基于图像生成文本描述的过程。为了更好地理解图像标题生成，我们首先需要将它与图像分类区分开来。
- en: Difference between image classification and image captioning
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类与图像标题生成的区别
- en: Image classification is a relatively simple process that only tells us what
    is in an image. For example, if there is a boy on a bike, image classification
    will not give us a description; it will just provide the result as **boy **or
    **bike**. Image classification can tell us whether there is a woman or a dog in
    the image, or an action, such as snowboarding. This is not a desirable result
    as there is no description of what exactly is going on in the image.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是一个相对简单的过程，它只能告诉我们图像中有什么。例如，如果有一个骑自行车的男孩，图像分类不会给我们一个描述；它只会提供结果作为**男孩**或**自行车**。图像分类可以告诉我们图像中是否有女人或狗，或者是否有动作，如滑雪。这不是一个理想的结果，因为图像中并没有描述具体发生了什么。
- en: 'The following is the result we get using image classification:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用图像分类得到的结果：
- en: '![](img/3f7f3a53-c971-43ed-9e6b-52e3f449daee.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f7f3a53-c971-43ed-9e6b-52e3f449daee.png)'
- en: Comparatively, image captioning will provide a result with a description. For
    the preceding example, the result of image captioning would be **a boy riding
    on a bike** or **a man is snowboarding**. This could be useful for generating
    content for a book or maybe helping the hearing or visually impaired.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，图像标题生成将提供一个带有描述的结果。对于前面的例子，图像标题生成的结果将是**一个男孩骑在自行车上**或**一个男人在滑雪**。这可能有助于为书籍生成内容，或者可能有助于帮助听力或视觉障碍者。
- en: 'The following is the result we get using image captioning:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用图像标题生成得到的结果：
- en: '![](img/f449b9bd-d21a-4c25-9193-9507bade3c26.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f449b9bd-d21a-4c25-9193-9507bade3c26.png)'
- en: However, this is considerably more challenging as conventional neural networks
    are powerful, but they're not very compatible with sequential data. Sequential
    data is where we have data that's coming in an order and that order actually matters.
    In audio or video, we have words coming in a sequential order; jumbling the words
    might change the meaning of the sentence or just make it complete gibberish.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这要困难得多，因为传统的神经网络虽然强大，但它们与序列数据不太兼容。序列数据是指按顺序到来的数据，而这个顺序实际上很重要。在音频或视频中，我们有按顺序到来的单词；打乱单词可能会改变句子的含义，或者只是使其成为完全的胡言乱语。
- en: Recurrent neural networks with long short-term memory
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有长短期记忆的循环神经网络
- en: As powerful as **convolutional neural networks** (**CNNs**) are, they don't
    handle sequential data so well; however, they are great for non-sequential tasks,
    such as image classification.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管卷积神经网络（CNNs）非常强大，但它们并不擅长处理序列数据；然而，它们非常适合非序列任务，如图像分类。
- en: 'How CNNs work is shown in the following diagram:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: CNN是如何工作的，以下图所示：
- en: '![](img/a8176ff9-a902-4bdf-b868-6fae3abe7c5e.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a8176ff9-a902-4bdf-b868-6fae3abe7c5e.png)'
- en: '**Recurrent neural networks** (**RNNs**), which really are state of the art,
    can handle sequential tasks. An RNN consists of CNNs where data is received in
    a sequence.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**循环神经网络**（**RNNs**），实际上确实是当前最先进的技术，可以处理序列任务。一个RNN由一系列接收数据的CNN组成。'
- en: 'How RNNs work is shown in the following diagram:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs是如何工作的，以下图所示：
- en: '![](img/be749fa7-8b9b-4378-a461-f83bed83e489.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be749fa7-8b9b-4378-a461-f83bed83e489.png)'
- en: Data coming in a sequence (**x[i]**) goes through the neural network and we
    get an output (**y[i]**). The output is then fed through to another iteration
    and forms a loop. This helps us remember the data coming from before and is helpful
    for sequential data tasks such as audio and speech recognition, language translation,
    video identification, and text generation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 按序列进入的数据（**x[i]**）通过神经网络，我们得到输出（**y[i]**）。然后输出被送入另一个迭代，形成一个循环。这有助于我们记住之前来的数据，对于音频和语音识别、语言翻译、视频识别和文本生成等序列数据任务非常有帮助。
- en: Another concept that has been around for a while and is very helpful is **long
    short-term memory** (**LSTM**) with RNNs. It is a way to handle long-term memory
    and avoid just passing data from one iteration to the next. It handles the data
    from the iterations in a robust way and it allows us to effectively train RNNs.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个存在已久且非常有用的概念是与RNNs结合的**长短期记忆**（**LSTM**）。这是一种处理长期记忆并避免仅仅将数据从一次迭代传递到下一次迭代的方法。它以稳健的方式处理迭代中的数据，并使我们能够有效地训练RNNs。
- en: Google Brain im2txt captioning model
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Brain im2txt字幕模型
- en: Google Brain im2txt was used by Google in a paper *2015 MSCOCO Image Captioning
    Challenge,* and will form the foundation of the image captioning code that we
    will implement in our project.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Google Brain im2txt被Google用于论文《2015 MSCOCO图像字幕挑战》，并将成为我们将在项目中实现的图像字幕代码的基础。
- en: The Google's GitHub TensorFlow page can be found at [https://github.com/tensorflow/models/tree/master/research/im2txt](https://github.com/tensorflow/models/tree/master/research/im2txt)[.](https://github.com/tensorflow/models/tree/master/research/im2txt)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Google的GitHub TensorFlow页面可以在[https://github.com/tensorflow/models/tree/master/research/im2txt](https://github.com/tensorflow/models/tree/master/research/im2txt)找到[.](https://github.com/tensorflow/models/tree/master/research/im2txt)
- en: In the research directory, we will find the `im2txt` file, which was used by
    Google in the paper, *2015 MSCOCO Image Captioning Challenge*, which is available
    for free at [https://arxiv.org/abs/1609.06647](https://arxiv.org/abs/1609.06647).
    It covers RNNs, LSTM, and fundamental algorithms in detail.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究目录中，我们将找到Google在论文《2015 MSCOCO图像字幕挑战》中使用的`im2txt`文件，该文件可在[https://arxiv.org/abs/1609.06647](https://arxiv.org/abs/1609.06647)免费获取。它详细介绍了RNNs、LSTM和基本算法。
- en: We can check how CNNs are used for image classification and also learn how to
    use the LSTM RNNs for actually generating sequential caption outputs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查CNN是如何用于图像分类的，也可以学习如何使用LSTM RNNs来实际生成序列字幕输出。
- en: We can download the code from the GitHub link; however, it has not been set
    up to run easily as it does not include a pre-trained model, so we may face some
    challenges. We have provided you with a pre-trained model to avoid training an
    image classifier from scratch, since it is a time-consuming process. There have
    been some modifications made to the code that will make the code easy to run on
    a Jupyter Notebook or to incorporate in your own projects. The pre-trained model
    is very quick to learn using just a CPU. The same code without a pre-trained model
    might actually take weeks to learn, even on a good GPU.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从GitHub链接下载代码；然而，它尚未设置得易于运行，因为它不包含预训练模型，所以我们可能会遇到一些挑战。我们已经为您提供了预训练模型，以避免从头开始训练图像分类器，因为这是一个耗时的过程。我们对代码进行了一些修改，使得代码在Jupyter
    Notebook上运行或集成到您自己的项目中变得容易。使用CPU，预训练模型学习非常快。没有预训练模型的相同代码实际上可能需要几周时间才能学习，即使在好的GPU上也是如此。
- en: Running the captioning code on Jupyter
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Jupyter上运行字幕代码
- en: Let's now run our own version of the code on a Jupyter Notebook. We can start
    up own own Jupyter Notebook and load the `Section_1-Tensorflow_Image_Captioning.ipynb` file
    from the GitHub repository ([https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb)).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将在Jupyter Notebook上运行我们自己的代码版本。我们可以启动自己的Jupyter Notebook，并从GitHub仓库加载`Section_1-Tensorflow_Image_Captioning.ipynb`文件（[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb)）。
- en: 'Once we load the file on a Jupyter Notebook, it will look something like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在Jupyter Notebook中加载了文件，它看起来会像这样：
- en: '![](img/7cf6b337-2a16-48f8-9c27-327a28fb278f.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7cf6b337-2a16-48f8-9c27-327a28fb278f.png)'
- en: In the first part, we are going to load some essential libraries, including `math`, `os`,
    and `tensorflow`. We will also use our handy utility function, `%pylab inline`,
    to easily read and display images within the Notebook.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分，我们将加载一些基本库，包括`math`、`os`和`tensorflow`。我们还将使用我们方便的实用函数`%pylab inline`，以便在Notebook中轻松读取和显示图像。
- en: 'Select the first code block:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 选择第一个代码块：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we hit *Ctrl* + *Enter* to execute the code in the cell, we will get the
    following output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们按下*Ctrl* + *Enter*来执行单元格中的代码时，我们将得到以下输出：
- en: '![](img/5279fc38-3cc4-4768-9c74-05fc8cbbb101.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5279fc38-3cc4-4768-9c74-05fc8cbbb101.png)'
- en: We need to now load the TensorFlow/Google Brain base code, which we can get
    from [https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要加载TensorFlow/Google Brain的基础代码，我们可以从[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3)获取。
- en: 'There are multiple utility functions, but we will be using and executing only
    a few of them in our example:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个实用函数，但在我们的示例中，我们只会使用和执行其中的一些：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We need to tell our function where to find the trained model and vocabulary:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要告诉我们的函数在哪里可以找到训练模型和词汇表：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The code for the trained model and vocabulary have been added in the GitHub
    repository, and you can access it from this link:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型和词汇表的代码已添加到GitHub仓库中，您可以通过此链接访问：[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3)
- en: '[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3)'
- en: The folder contains `checkpoint`, `word_counts.txt`, and the pre-trained model.
    We need to make sure that we use these files and avoid using other outdated files
    that might not be compatible with the latest version of TensorFlow. The `word_counts.txt`
    file contains a vocabulary list with the number of counts from our trained model,
    which our image caption generator is going to need.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 文件夹包含`checkpoint`、`word_counts.txt`和预训练模型。我们需要确保我们使用这些文件，并避免使用可能不与TensorFlow最新版本兼容的其他过时文件。`word_counts.txt`文件包含一个词汇表，其中包含我们从训练模型中得到的计数，这是我们的图像标题生成器所需要的。
- en: Once these steps have been completed, we can look at our `main` function, which
    will generate the captions for us. The function can take an input as a string
    of input files (comma separated) or could be just one file that we want to process.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这些步骤完成，我们就可以查看我们的`main`函数，它将为我们生成标题。该函数可以接受一个字符串形式的输入文件（以逗号分隔）或仅一个我们想要处理的文件。
- en: 'The verbosity is set to `tf.logging.FATAL` out of the different logging levels
    available, as it will tell us whether something has gone really wrong:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将冗余度设置为`tf.logging.FATAL`，这是可用的不同日志级别之一，因为它会告诉我们是否真的出了问题：
- en: '![](img/30533d4c-b33a-4aa2-b3fb-062758390569.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/30533d4c-b33a-4aa2-b3fb-062758390569.png)'
- en: 'In the initial part of the main code, we perform the following steps:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在主代码的初始部分，我们执行以下步骤：
- en: Set the verbosity level to `tf.logging.FATAL`.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将冗余度设置为`tf.logging.FATAL`。
- en: Load our pre-trained model.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载我们的预训练模型。
- en: Load the inference wrapper from our utility file provided by Google.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Google提供的实用文件中加载推理包装器。
- en: Load our pre-trained model from the `checkpoint` path that we established in
    the previous cell.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从之前单元格中建立的`checkpoint`路径加载我们的预训练模型。
- en: 'Run the `finalize` function:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`finalize`函数：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Load the vocabulary file again from the cell that we previously ran:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次从之前运行的单元格中加载词汇表文件：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Pre-process the filenames:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理文件名：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Perform the `Glob` action:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行`Glob`操作：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create a list of filenames so you can know on which file the image caption
    generator is running:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个文件名列表，这样你可以知道图像标题生成器正在哪个文件上运行：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create a session. We need to use the `restore` function since we are using
    a pre-trained model:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个会话。由于我们正在使用预训练的模型，我们需要使用`restore`函数：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The code for these steps is included here:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤的代码包含在此处：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We now move to the second half of the main code. Once the session has been
    restored, we perform the following steps:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在转向主代码的第二部分。一旦会话已恢复，我们执行以下步骤：
- en: 'Load `caption_generator` from our model and the vocabulary stored in an object
    called `generator`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们的模型和存储在名为`generator`的对象中的词汇中加载`caption_generator`：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Make a caption list:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作标题列表：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Iterate the files and load them in the generator called `beam_search` to analyze
    the image:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历文件并将它们加载到名为`beam_search`的生成器中，以分析图像：
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Print the captions:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印标题：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Iterate to create multiple captions with the iteration already set for the
    model:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代以创建多个标题，迭代已为模型设置：
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Return `captionlist`:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回`captionlist`：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Run the code to generate the function.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码以生成函数。
- en: 'See the following code block for the complete code:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下代码块中的完整代码：
- en: '[PRE16]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In the next code block, we will execute the code on sample stock photos from
    a `test` folder. The code will create a figure, show it, and then run the caption
    generator. We can then display the output using the `print` statement.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个代码块中，我们将对来自`test`文件夹的样本股票照片执行代码。代码将创建一个图形，显示它，然后运行标题生成器。然后我们可以使用`print`语句显示输出。
- en: 'The following is the code we use to select the image for computation:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们用来选择用于计算的图像的代码：
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'When we run our first test image, `dog.jpeg`, we get the following output:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行我们的第一个测试图像，`dog.jpeg`，我们得到以下输出：
- en: '![](img/b760c014-a429-4f3d-8387-50867828e243.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b760c014-a429-4f3d-8387-50867828e243.png)'
- en: The result, `a woman and a dog are standing on the grass`, is a good caption
    for the image. Since all the three results are pretty similar, we can say that
    our model is working pretty well.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，“一位女士和一只狗站在草地上”，是对图像的一个很好的描述。由于所有三个结果都很相似，我们可以说我们的模型工作得相当好。
- en: Analyzing the result captions
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析结果标题
- en: 'Let''s take a few examples to check our model. When we execute `football.jpeg`,
    we get the following output:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们拿几个例子来检查我们的模型。当我们执行`football.jpeg`时，我们得到以下输出：
- en: '![](img/d9aaa6e6-3abc-4202-936d-33952a1612a8.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d9aaa6e6-3abc-4202-936d-33952a1612a8.png)'
- en: Here we clearly have American football going on in the image, and `a couple
    of men playing a game of football` is a very good result. However, the first result, `a
    couple of men playing a game of frisbee`, is not the desired output, nor is `a
    couple of men playing a game of soccer`. So, in this case, the second caption
    is generally going to be the best, but it is not always going to be perfect, depending
    on the log probability.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们清楚地看到图像中正在进行美式足球比赛，而“一对男子在踢足球”是一个非常好的结果。然而，第一个结果，“一对男子在玩飞盘”，并不是我们想要的结果，也不是“一对男子在踢足球”。因此，在这种情况下，第二个标题通常会是最好的，但并不总是完美的，这取决于对数概率。
- en: 'Let''s try one more example, `giraffes.jpeg`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再试一个例子，`giraffes.jpeg`：
- en: '![](img/edfbad17-b3e0-4342-9c32-190f28865bec.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/edfbad17-b3e0-4342-9c32-190f28865bec.png)'
- en: Clearly, we have an image of giraffes, and the first caption, `a group of giraffe
    standing next to each other`, seems to be correct, except for the grammar issue.
    The other two results are `a group of giraffes are standing in a field` and `a
    group of giraffe standing next to each other on a field`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，我们有一张长颈鹿的图片，第一个标题，“一排长颈鹿并排站立”，看起来似乎是正确的，除了语法问题。其他两个结果是“一排长颈鹿站在田野中”和“一排长颈鹿在田野中并排站立”。
- en: 'Let''s take a look at one more example, `headphones.jpeg`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个例子，`headphones.jpeg`：
- en: '![](img/589ac694-b233-4dac-b54c-c5d32e45a5a5.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/589ac694-b233-4dac-b54c-c5d32e45a5a5.png)'
- en: Here we selected `headphones.jpeg`, but the results did not include headphones
    as an output. The result was `a woman holding a cell phone in her hand`, which
    is a good result. The second result, `a woman holding a cell phone up to her ear`, is
    technically incorrect, but these are some good captions overall.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们选择了`headphones.jpeg`，但结果中没有包含耳机。结果是“一位女士手里拿着一部手机”，这是一个很好的结果。第二个结果，“一位女士把手机举到耳边”，技术上是不正确的，但总体上是一些好的标题。
- en: 'Let''s take one last example, `ballons.jpeg`. When we run the image, we get
    the following output:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再举一个例子，`ballons.jpeg`。当我们运行图像时，我们得到以下输出：
- en: '![](img/c60032d5-a1ea-45a8-9d20-fd35908a06b6.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c60032d5-a1ea-45a8-9d20-fd35908a06b6.png)'
- en: The results we get for this image are `a woman standing on a beach flying a
    kite`, `a woman is flying a kite on the beach`, and `a young girl flying a kite
    on a beach`. So, the model got the `woman` or a `young girl`, but it got a `kite` instead
    of the balloon, even though "balloon" is in the vocabulary. So, we can infer that
    the model is not perfect, but it is impressive and can be included in your own
    application.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这张图像，我们得到的结果是“一个站在海滩上放风筝的妇女”、“一个在海滩上放风筝的妇女”，以及“一个在海滩上放风筝的年轻女孩”。所以，模型得到了“妇女”或“年轻女孩”，但它得到了“风筝”而不是气球，尽管“气球”在词汇表中。因此，我们可以推断出模型并不完美，但它很令人印象深刻，可以包含在你的应用程序中。
- en: Running the captioning code on Jupyter for multiple images
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Jupyter 上运行多图像的标题代码
- en: Multiple images can also be added as an input string by separating the image
    path of the different images using commas. The execution time of a string of images
    will be greater than the times we've seen thus far.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过使用逗号分隔不同图像的图像路径，将多个图像作为输入字符串添加。字符串图像的执行时间将大于我们之前看到的任何时间。
- en: 'The following is an example of multiple input files:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个多个输入文件的示例：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We will not be displaying the images, so the output will include only the results.
    We can see that some of the results are better than others:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不会显示图像，所以输出将只包括结果。我们可以看到，一些结果比其他结果要好：
- en: '![](img/c759ff9d-66fb-4db3-b062-de2575419d27.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c759ff9d-66fb-4db3-b062-de2575419d27.png)'
- en: This wraps up running the pre-trained image captioning model. We will now cover
    training our model from scratch and running it on captioned images.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了预训练图像标题模型的运行。我们现在将介绍从头开始训练模型并在标题图像上运行它。
- en: Retraining the captioning model
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新训练标题模型
- en: So, now that we have seen image captioning code in action, we are going to retrain
    the image captioner on our own desired data. However, we need to know that it
    will be very time consuming and will need over 100 GB of hard drive space for
    computations if we want it to process in a reasonable time. Even with a good GPU,
    it may take a few days or a week to complete the computation. Since we are inclined
    toward implementing it and have the resources, let's start retraining the model.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，既然我们已经看到了图像标题代码的实际应用，我们接下来将在我们自己的数据上重新训练图像标题器。然而，我们需要知道，如果想要在合理的时间内处理，这将非常耗时，并且需要超过
    100 GB 的硬盘空间。即使有好的 GPU，完成计算可能也需要几天或一周的时间。既然我们有意愿实施并且有资源，让我们开始重新训练模型。
- en: 'In the Notebook, the first step is to download the pre-trained Inception model.
    The `webbrowser` module will make it easy to open the URL and to download the
    file:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中，第一步是下载预训练的 Inception 模型。`webbrowser` 模块将使打开 URL 并下载文件变得容易：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following will be the output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下将是输出：
- en: '![](img/726b3308-e90e-4581-ac71-9b977bd35bef.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/726b3308-e90e-4581-ac71-9b977bd35bef.png)'
- en: When we select the code block and execute it, we might not be able to view the
    content on the web page, but we can click save on the dialog box to download the
    file. Unzip the file to get the inception v3 checkpoint file. We can use any of
    the unzipping utility available, but it is preferable to use 7-zip to get the
    Inception v3 checkpoint file and store it in `im2txt/data` in the project directory.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们选择代码块并执行它时，我们可能无法在网页上查看内容，但我们可以点击对话框中的“保存”来下载文件。解压文件以获取 Inception v3 检查点文件。我们可以使用任何可用的解压工具，但最好是使用
    7-zip 来获取 Inception v3 检查点文件，并将其存储在项目目录的 `im2txt/data` 中。
- en: The `cd` command is used to navigate to the `im2txt/data` directory, where all
    our files are present. The `run_build_mscoco_data.py` Python script will grab
    and process all the image data and the pre-made caption data. This process might
    take over 100 GB of space and take over an hour to complete its execution.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`cd` 命令用于导航到 `im2txt/data` 目录，那里存放着所有我们的文件。`run_build_mscoco_data.py` Python
    脚本将抓取并处理所有图像数据和预制的标题数据。这个过程可能需要超过 100 GB 的空间，并且需要超过一个小时来完成执行。'
- en: 'Once the computation is complete, we will see the three ZIP files in our project''s
    directory. We can unzip these files to get the following directories:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算完成，我们将在项目目录中看到三个 ZIP 文件。我们可以解压这些文件以获取以下目录：
- en: '![](img/ec271f43-3ccd-485b-83a0-1d7bf5354776.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ec271f43-3ccd-485b-83a0-1d7bf5354776.png)'
- en: The training and validation JSON files are present in the `annotations` folder.
    The other directories have image training and validation data. Under the `train2014`
    directory, we will find a bunch of JPEG images corresponding to the training data.
    Similarly, the resources corresponding to the validation data will be present
    in the `val2014` folder. We can substitute our own images as well and edit the
    corresponding JSON file in the `annotations` folder. We will need many examples,
    as a handful examples will not provide effective results. There are over 80,000
    images in the `train2014` directory and processing them will require intensive
    resources.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和验证的JSON文件位于`annotations`文件夹中。其他目录包含图像训练和验证数据。在`train2014`目录下，我们将找到与训练数据对应的JPEG图像。同样，与验证数据对应的资源将存在于`val2014`文件夹中。我们也可以替换自己的图像，并编辑`annotations`文件夹中相应的JSON文件。我们需要很多示例，因为少量的示例不会提供有效的结果。`train2014`目录中有超过80,000张图像，处理它们将需要大量的资源。
- en: 'Once we execute the `run_build_mscoco_data.py` command, we need to load the
    required modules:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`run_build_mscoco_data.py`命令后，我们需要加载所需的模块：
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We need to load `configuration` and `show_and_tell_model` in the `im2txt` folder
    along with TensorFlow. We can run the `cd ..` command to be in the right directory.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在`im2txt`文件夹中加载`configuration`和`show_and_tell_model`，以及TensorFlow。我们可以运行`cd
    ..`命令以进入正确的目录。
- en: 'Now, we will be defining the following variables:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将定义以下变量：
- en: '`input_file_pattern`: Defines the files pointing to the pre-trained Inception
    checkpoint, which will be generated from our model'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_file_pattern`：定义指向预训练Inception检查点的文件，这些文件将来自我们的模型'
- en: '`train_dir`: Contains the path where the training data was stored after we
    downloaded and unzipped it'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_dir`：包含下载并解压后存储训练数据的路径'
- en: '`train_inception`: Set to `false` since we will not be training our Inception
    model for the initial run'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_inception`：设置为`false`，因为我们不会在初始运行时训练Inception模型'
- en: '`number_of_steps`: One million steps for our function'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`number_of_steps`：我们的函数为一百万步'
- en: '`log_every_n_steps`: Set `1` for our function'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_every_n_steps`：将我们的函数设置为`1`'
- en: 'Here is the code:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码：
- en: '[PRE21]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now let''s define our `train` function. The steps performed in the `train`
    function are as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义我们的`train`函数。`train`函数中执行的步骤如下：
- en: Create the `train` directory
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`train`目录
- en: Create the graph file
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建图文件
- en: Load the essential files
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载必要的文件
- en: Add the required variables for TensorFlow to start training the model to get
    the learning rate with the number of batches per epoch delay step
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加TensorFlow开始训练模型所需的变量，以获得每批次的延迟步数的学习率
- en: Set up the layers
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置层
- en: Set up the saver for saving and restoring the model checkpoint
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置用于保存和恢复模型检查点的保存器
- en: Call TensorFlow and do the training
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用TensorFlow进行训练
- en: 'The following is our `train` function:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们`train`函数的内容：
- en: 'Define (but don''t run yet) our captioning training function:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义（但尚未运行）我们的字幕训练函数：
- en: '[PRE22]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Create the training directory:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练目录：
- en: '[PRE23]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Build the TensorFlow graph:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建TensorFlow图：
- en: '[PRE24]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Build the model:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建模型：
- en: '[PRE25]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Set up the learning rate:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置学习率：
- en: '[PRE26]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Set up the training ops:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置训练操作：
- en: '[PRE27]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Set up the `Saver` for saving and restoring model checkpoints:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置用于保存和恢复模型检查点的`Saver`：
- en: '[PRE28]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Hit *Ctrl* + *Enter* for this code cell, since we can execute this now. After
    that, we need to call the `train` function:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 按*Ctrl* + *Enter*执行此代码单元格，因为我们现在可以执行它。之后，我们需要调用`train`函数：
- en: '[PRE29]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This will take a long time to process, even on a good GPU, but if we have the
    resources and still want to refine the model, run the following code to fine-tuning
    our `inception` model:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这将需要很长时间来处理，即使在好的GPU上也是如此，但如果我们有资源并且仍然想改进模型，请运行以下代码以微调我们的`inception`模型：
- en: '[PRE30]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The model will run for three million steps. It actually continues from where
    the initial training completed its process and generate new checkpoints and refined
    models, before running the `train` function again. This will take even more time
    to process and provide a good result. We can do this in our Jupyter Notebook by
    correctly pointing our `checkpoint` path and the path for the vocabulary file:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型将运行三百万步。它实际上是从初始训练完成的地方继续，生成新的检查点和改进的模型，然后再运行`train`函数。这将需要更多的时间来处理并提供良好的结果。我们可以在Jupyter
    Notebook中通过正确指定我们的`checkpoint`路径和词汇文件路径来完成这项工作：
- en: '[PRE31]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: After that, we can rerun code block 4 from the Jupyter Notebook file at [https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb) to
    find `gen_caption`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以重新运行Jupyter Notebook文件中的代码块4，该文件位于[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/blob/master/Chapter01/Section_1-Tensorflow_Image_Captioning.ipynb)，以找到`gen_caption`。
- en: 'The last step is to run the following code, as we did before in the *Running
    the captioning code on Jupyter* section:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是运行以下代码，就像我们在“在Jupyter上运行标题代码”部分所做的那样：
- en: '[PRE32]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Once the computation has been completed, we should get some good results. This
    wraps up image captioning with TensorFlow.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算完成，我们应该得到一些不错的结果。这标志着使用TensorFlow的图像标题的结束。
- en: Summary
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we were introduced to different image captioning methods. We
    learned about the Google Brain im2txt captioning model. While working on the project,
    we were able to run our pre-trained model on a Jupyter Notebook and analyze the
    model based on the results. In the last section of the chapter, we retrained our
    image captioning model from scratch.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了不同的图像标题方法。我们学习了谷歌大脑的im2txt标题模型。在项目工作中，我们能够在Jupyter Notebook上运行我们的预训练模型，并根据结果分析模型。在章节的最后部分，我们从零开始重新训练了我们的图像标题模型。
- en: In the next chapter, we will cover reading license plates with OpenCV.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍使用OpenCV读取车牌。
