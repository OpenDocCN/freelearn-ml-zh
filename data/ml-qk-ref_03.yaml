- en: Performance in Ensemble Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成学习中的性能
- en: So far, we have learned that no two models will give the same result. In other
    words, different combinations of data or algorithms will result in a different
    outcome. This outcome can be good for a particular combination and not so good
    for another combination. What if we have a model that tries to take these combinations
    into account and comes up with a generalized and better result? This is called
    an **ensemble model**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解到没有两个模型会给出相同的结果。换句话说，不同的数据或算法组合会导致不同的结果。这种结果可能对某个组合有利，而对另一个组合则不然。如果我们有一个模型试图考虑这些组合，并得出一个普遍和更好的结果会怎样？这被称为**集成模型**。
- en: 'In this chapter, we will be learning about a number of concepts in regard to
    ensemble modeling, which are as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习关于集成建模的多个概念，如下所示：
- en: Bagging
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bagging
- en: Random forest
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Boosting
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boosting
- en: Gradient boosting
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升
- en: Optimization of parameters
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数优化
- en: What is ensemble learning?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是集成学习？
- en: Sometimes, one machine learning model is not good enough for a certain scenario
    or use case as it might not give you the desired accuracy, recall, and precision.
    Hence, multiple learning models—or an ensemble of models captures the pattern
    of the data and gives better output.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，一个机器学习模型可能不足以应对某个场景或用例，因为它可能无法提供所需的准确率、召回率和精确度。因此，多个学习模型——或者说是模型的集成——捕捉数据的模式，并给出更好的输出。
- en: 'As an example, let''s say we are trying to decide on a place where we would
    like to go in the summer. Typically, if we are planning for a trip, the suggestions
    for the place pours in from all corners. That is, these suggestions might come
    from our family, websites, friends, and travel agencies, and then we have to decide
    on the basis of a good experience that we had in the past:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们正在尝试决定夏天想去的地方。通常情况下，如果我们计划旅行，关于地点的建议会从各个角落涌来。也就是说，这些建议可能来自我们的家人、网站、朋友和旅行社，然后我们必须基于过去的好体验来做出决定：
- en: '**Family**: Let''s say that whenever we have consulted a family member and
    listened to them, there has been a 60% chance that they were proven right and
    we ended up having a good experience on the trip.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**家庭**：假设每次我们咨询家庭成员并听取他们的意见时，有60%的可能性他们是对的，我们最终在旅行中获得了愉快的体验。'
- en: '**Friends**: Similarly, if we listen to our friends, they suggest places where
    we might have a good experience. In these instances, a good experience occurred
    in 50% of cases.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朋友**：同样，如果我们听取朋友的意见，他们会建议我们去可能有好体验的地方。在这些情况下，有50%的情况发生了好体验。'
- en: '**Travel websites**: Travel websites are another source where we can get loads
    of information regarding where to visit. If we choose to take their advice, there''s
    a 35% chance that they were right and we had a good experience.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旅游网站**：旅游网站是另一个我们可以获取大量关于去哪里游玩的信息的来源。如果我们选择接受他们的建议，有35%的可能性他们是正确的，我们有了愉快的体验。'
- en: '**Travel agencies**: Another piece of advice and information might flow from
    travel agencies if we go and check with them first. Based on our past experiences,
    we saw that they were right in 45% of cases.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旅行社**：如果我们首先向旅行社咨询，可能会得到更多建议和信息。根据我们的以往经验，我们发现他们在45%的情况下是正确的。'
- en: 'However, we have to accumulate all of the preceding inputs and make a decision
    since no source has been 100% correct so far. If we combine these results, the
    accuracy scenario will be as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们必须积累所有前面的输入并做出决定，因为到目前为止，没有任何来源是100%正确的。如果我们结合这些结果，准确率场景将如下所示：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: From this, we are able to see the impact of ensemble modeling.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们能够看到集成建模的影响。
- en: Ensemble methods
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成方法
- en: 'Primarily, there are three methods of building an ensemble model, that is,
    **Bagging**, **Boosting**, and **Stacking**:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有三种构建集成模型的方法，即**Bagging**、**Boosting**和**Stacking**：
- en: '![](img/f2ec24a4-2d97-43aa-8d0a-71c5a58a59ff.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f2ec24a4-2d97-43aa-8d0a-71c5a58a59ff.png)'
- en: We will discuss each method one by one. However, before we get into this, we
    need to understand what bootstrapping is, which sets the basis for **Bagging**
    and **Boosting**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐一讨论每种方法。然而，在我们深入探讨之前，我们需要了解什么是自助法，这为**Bagging**和**Boosting**奠定了基础。
- en: Bootstrapping
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bootstrapping
- en: 'Bootstrapping is a statistical technique that''s used to draw an inference
    about the parameters of population based on the samples drawn from it with replacement
    and averaging these results out. In the event of sampling with replacement, samples
    are drawn one after another, and once one sample is drawn from the population,
    the population is replenished with the sampled data:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 自助法是一种统计技术，用于根据从总体中抽取的有放回样本进行推断，并平均这些结果。在有放回抽样的情况下，样本一个接一个地抽取，一旦从总体中抽取了一个样本，总体就用抽取的数据补充：
- en: '![](img/bd6e63b8-5481-4f46-8fe6-c3ecc23016dd.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd6e63b8-5481-4f46-8fe6-c3ecc23016dd.png)'
- en: In the preceding diagram, there is a dataset that has got multiples components
    (**A**, **B**, **C**, **D**, **E**, **F**, **G**, **H**, and **I**). To start,
    we need to draw three samples of the same size. Let's draw **Sample 1** randomly
    and say that the first element turned out to be **A**. However, before we draw
    the second element of **Sample 1**, **A** is returned to the dataset. A similar
    process takes place for the entire draw. This is called **Sampling with Replacement**.
    Hence, we have a chance of selecting the same item multiple times in a set. By
    following this process, we have drawn three samples, that is, **Sample 1**, **Sample
    2**, and **Sample 3**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，有一个包含多个组件（**A**, **B**, **C**, **D**, **E**, **F**, **G**, **H**, 和 **I**）的数据集。首先，我们需要绘制三个相同大小的样本。让我们随机绘制**样本
    1**，并假设第一个元素是**A**。然而，在我们绘制**样本 1**的第二个元素之前，**A**被返回到数据集中。整个过程都是如此。这被称为**有放回抽样**。因此，我们在一个集合中多次选择相同的项目。通过遵循这个过程，我们绘制了三个样本，即**样本
    1**、**样本 2**和**样本 3**。
- en: 'When we take a step further down, which is determining the statistics (various
    metrics) on **Sample 1**, **Sample 2**, and **Sample 3**, we find out a mean or
    an average of all the statistics to infer something about the dataset (population).
    This entire process is called **bootstrapping** and the drawn samples are termed
    bootstrapped samples. This can be defined with the following equation:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进一步确定**样本 1**、**样本 2**和**样本 3**的统计量（各种指标）时，我们发现所有统计量的平均值，以推断有关数据集（总体）的信息。这个过程被称为**自助法**，绘制的样本被称为自助样本。这可以用以下方程定义：
- en: '*Inference about the Dataset(Population) = Average(sample 1,sample 2,............,sample
    N)*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*关于数据集（总体）的推断 = 样本 1、样本 2、……、样本 N 的平均值*'
- en: 'If you look at the preceding diagram carefully, there might be a scenario wherein
    a few elements of the dataset haven''t been picked or are not part of those three
    samples:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仔细观察前面的图，可能会出现一些数据集的元素没有被选中或不是这三个样本的一部分的情况：
- en: '**Sample 1**: (**A**, **E**, **H**, **C**)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本 1**：(**A**, **E**, **H**, **C**)'
- en: '**Sample 2**: (**F**, **G**, **A**, **C**)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本 2**：(**F**, **G**, **A**, **C**)'
- en: '**Sample 3**: (**E**, **H**, **G**, **F**)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本 3**：(**E**, **H**, **G**, **F**)'
- en: Therefore, the elements that haven't been picked are **B**, **D**, and **I**.
    The samples that were not part of the drawn samples are called **out-of-bag**
    (**OOB**) samples.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，未被选中的元素是**B**、**D**和**I**。那些不是绘制样本一部分的样本被称为**袋外样本**（**OOB**）。
- en: 'Let''s do a simple coding exercise to see how this can be done in Python:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个简单的编码练习，看看如何在 Python 中实现：
- en: 'Here, we will be using the `sklearn` and `resample` functions. Let''s import
    the necessary libraries:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里，我们将使用`sklearn`和`resample`函数。让我们导入必要的库：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, create a dataset that we will need to sample:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个我们需要采样的数据集：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we will extract a bootstrap sample with the help of the `resample` function:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用`resample`函数提取一个自助样本：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will use list comprehension to extract an OOB sample:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用列表推导来提取OOB样本：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, let''s print it:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们打印它：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We get the following output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can see that there is a repetition of 60 in the sampling. This is due to
    sampling with replacement.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到采样中存在60的重复。这是由于有放回抽样造成的。
- en: 'Next, we need to print the following code:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要打印以下代码：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We get the following output:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'By this end of this, we want to have a result that''s as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们希望得到以下结果：
- en: '*OOB = Dataset - Boot_Sample *'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*OOB = 数据集 - Boot_Sample*'
- en: '*=[10,20,30,40,50,60,70,80,90,100] - [60,90,100,60,10]*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*=[10,20,30,40,50,60,70,80,90,100] - [60,90,100,60,10]*'
- en: '*=[20,30,40,50,70,80]*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*=[20,30,40,50,70,80]*'
- en: This is the same result we have got from the code.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码得到的结果。
- en: Bagging
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 装袋法
- en: 'Bagging stands for bootstrap **aggregation**. Hence, it''s clear that the bagging
    concept stems from bootstrapping. It implies that bagging has got the elements
    of bootstrapping. It is a bootstrap ensemble method wherein multiple classifiers
    (typically from the same algorithm) are trained on the samples that are drawn
    randomly with replacements (bootstrap samples) from the training set/population.
    Aggregation of all the classifiers takes place in the form of average or by voting.
    It tries to reduce the affect of the overfitting issue in the model as shown in
    the following diagram:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 带包装法代表的是**重抽样聚合（bootstrap aggregation）**。因此，很明显，带包装法的概念源于重抽样。它意味着带包装法具有重抽样的元素。它是一种重抽样集成方法，其中多个分类器（通常是同一算法）在从训练集/总体中随机抽取带有替换的样本（重抽样样本）上训练。所有分类器的聚合以平均或投票的形式进行。它试图减少模型中过度拟合问题的影响，如下面的图所示：
- en: '![](img/a942be0b-22b5-45c0-9fbf-007ec88a7e7e.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a942be0b-22b5-45c0-9fbf-007ec88a7e7e.png)'
- en: 'There are three stages of bagging:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 带包装法有三个阶段：
- en: '**Bootstrapping**:This is a statistical technique that''s used to generate
    random samples or bootstrap samples with replacement.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重抽样（Bootstrapping）**：这是一种统计技术，用于生成带有替换的随机样本或重抽样样本。'
- en: '**Model fitting**:In this stage, we build models on bootstrap samples. Typically,
    the same algorithm is used for building the models. However, there is no restriction
    on using different algorithms.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型拟合**：在这个阶段，我们在重抽样样本上建立模型。通常，用于建立模型的算法是相同的。然而，没有限制使用不同的算法。'
- en: '**Combining models**:This step involves combining all the models and taking
    an average. For example, if we have applied a decision tree classifier, then the
    probability that''s coming out of every classifier is averaged.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型组合**：这一步骤涉及组合所有模型并取平均值。例如，如果我们应用了决策树分类器，那么每个分类器输出的概率会被平均。'
- en: Decision tree
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: A decision tree is a supervised learning technique that works on the divide-and-conquer
    approach. It can be used to address both classification and regression. The population
    undergoes a split into two or more homogeneous samples based on the most significant
    feature.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种基于分而治之方法的监督学习技术。它可以用于解决分类和回归问题。总体根据最重要的特征被分割成两个或更多同质化的样本。
- en: For example, let's say we have got a sample of people who applied for a loan
    from the bank. For this example, we will take the count as 50\. Here, we have
    got three attributes, that is, gender, income, and the number of other loans held
    by the person, to predict whether to give them a loan or not.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们得到了一组从银行申请贷款的人的样本。在这个例子中，我们将计数设为50。在这里，我们有三个属性，即性别、收入和该人持有的其他贷款数量，以预测是否给他们贷款。
- en: We need to segment the people based on gender, income, and the number of other
    loans they hold and find out the most significant factor. This tends to create
    the most homogeneous set.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要根据性别、收入和其他贷款数量来细分人群，并找出最重要的因素。这往往会产生最同质化的群体。
- en: 'Let''s take income first and try to create the segment based on it. The total
    number of people who applied for the loan is 50\. Out of 50, the loan was awarded
    to 20 people. However, if we break this up by income, we can see that the breakup
    has been done by income <100,000 and >=100,000\. This doesn''t generate a homogeneous
    group. We can see that 40% of applicants (20) have been given a loan. Of the people
    whose income was less than 100,000, 30% of them managed to get the loan. Similarly,
    46.67 % of people whose income was greater than or equal to 100,000 managed to
    get the loan. The following diagram shows the tree splitting on the basis of income:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从收入开始，尝试根据它创建细分。申请贷款的总人数为50人。在50人中，有20人获得了贷款。然而，如果我们按收入划分，我们可以看到划分是根据收入<100,000和>=100,000进行的。这并没有生成一个同质化的群体。我们可以看到40%的申请人（20人）获得了贷款。在收入低于100,000的人群中，有30%的人设法获得了贷款。同样，46.67%的收入高于或等于100,000的人群设法获得了贷款。以下图显示了基于收入的树分割：
- en: '![](img/92c46e1e-2cb7-4b7e-8f24-a15ef8a9a299.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/92c46e1e-2cb7-4b7e-8f24-a15ef8a9a299.png)'
- en: 'Let''s take up the number of loans now. Even this time around, we are not able
    to see the creation of a homogeneous group. The following diagram shows the tree
    splitting on the basis of the number of loans:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再来看贷款数量。即使这次，我们也没有看到同质化群体的形成。以下图显示了基于贷款数量的树分割：
- en: '![](img/6d36994c-4d82-4617-a5d3-4e8c4f27e2fc.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d36994c-4d82-4617-a5d3-4e8c4f27e2fc.png)'
- en: 'Let''s get on with gender and see how it fares in terms of creating a homogeneous
    group. This turns out to be the homogeneous group. There were 15 who were female,
    out of which 53.3% got the loan. 34.3% of male also ended up getting the loan.
    The following diagram shows the tree splitting based on gender:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看性别，看看它在创建同质群体方面的表现。这实际上是一个同质群体。有15名女性，其中53.3%获得了贷款。34.3%的男性也最终获得了贷款。以下图表显示了基于性别的树分割：
- en: '![](img/48b51511-931c-4a3f-a32a-9be7d3edf359.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/48b51511-931c-4a3f-a32a-9be7d3edf359.png)'
- en: With the help of this, the most significant variable has been found. Now, we
    will dwell on how significant the variables are.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在此帮助下，已经找到了最重要的变量。现在，我们将探讨变量的重要性。
- en: 'Before we do that, it''s imperative for us to understand the terminology and
    nomenclature associated with the decision tree:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这样做之前，了解与决策树相关的术语和命名法至关重要：
- en: '**Root Node**: This stands for the whole population or dataset that undergoes
    a split into two or more homogeneous groups'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**根节点**：这代表整个总体或数据集，它被分割成两个或更多同质群体。'
- en: '**Decision Node**: This is created when a node is divided into further subnodes'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策节点**：当一个节点被进一步分割成子节点时，就会创建决策节点。'
- en: '**Leaf Node**: When there is no possibility of nodes splitting any further,
    that node is termed a leaf node or terminal node'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**叶节点**：当一个节点没有进一步分割的可能性时，该节点被称为叶节点或终端节点。'
- en: '**Branch**: A subsection of the entire tree is called a **branch** or a **Sub-tree**:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分支**：整个树的一个子部分被称为**分支**或**子树**：'
- en: '![](img/83181071-c958-46b3-86ae-372d6b81f921.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/83181071-c958-46b3-86ae-372d6b81f921.png)'
- en: Tree splitting
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树分割
- en: 'There are various algorithms that help when it comes to tree splitting, all
    of which take us to the leaf node. The decision tree takes all of the features
    (variables) that are available into account and selects the feature that would
    result in the most pure or most homogeneous split. The algorithm that''s used
    to split the tree also depends on the target variable. Let''s go through this,
    step by step:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种算法有助于树分割，所有这些算法都将我们带到叶节点。决策树考虑了所有可用的特征（变量），并选择会导致最纯净或最均匀分割的特征。用于分割树的算法也取决于目标变量。让我们一步一步地来探讨这个问题：
- en: '**Gini index**: This says that if we select two items at random from a population,
    they must be from the same class. The probability for this event would turn out
    to be 1 if the population is totally pure. It only performs binary splits. **Classification
    and regression trees** (**CARTs**) make use of this kind of split.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**基尼指数**：这表示如果我们从总体中随机选择两个项目，它们必须来自同一类别。如果总体完全纯净，这个事件发生的概率将是1。它只执行二分分割。**分类和回归树（CARTs**）就是利用这种分割。'
- en: 'The following formula is how you calculate the Gini index:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下公式是计算基尼指数的方法：
- en: '![](img/adcdc6ab-e709-4f65-a616-2d00813d3e13.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/adcdc6ab-e709-4f65-a616-2d00813d3e13.png)'
- en: Here, *p(t)* is the proportion of observations with a target variable with a
    value of *t.*
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*p(t)*是具有目标变量值为*t*的观测值的比例。
- en: 'For the binary target variable, *t=1*, the max Gini index value is as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二进制目标变量，*t=1*，最大的基尼指数值如下：
- en: '*= 1 — (1/2)^2— (1/2)^2*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 1 — (1/2)^2— (1/2)^2*'
- en: '*= 1–2*(1/2)^2*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 1–2*(1/2)^2*'
- en: '*= 1- 2*(1/4)*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 1- 2*(1/4)*'
- en: '*= 1–0.5*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 1–0.5*'
- en: '*= 0.5*'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.5*'
- en: A Gini score gives an idea of how good a split is by how mixed the classes are
    in the two groups that were created the by the split. A perfect separation results
    in a Gini score of 0, whereas the worst case split results in 50/50 classes.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基尼分数通过分割所创建的两个组中类别的混合程度来给出一个关于分割好坏的判断。完美的分离会导致基尼分数为0，而最坏的情况分割会导致50/50的类别。
- en: For a nominal variable with *k* level, the maximum value of the Gini index is *(1-
    1/k).*
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有*k*个级别的名义变量，基尼指数的最大值是*(1- 1/k)*。
- en: '**Information gain**: Let''s delve into this and find out what it is. If we
    happened to have three scenarios, as shown in the following diagram, which can
    be described easily?'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**信息增益**：让我们深入了解它，看看它是什么。如果我们碰巧有三个场景，如下所示，它们很容易描述？'
- en: '![](img/2ecceb2f-c502-4b47-9276-be973ecc1baf.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2ecceb2f-c502-4b47-9276-be973ecc1baf.png)'
- en: 'Since **Z** seem to be quite homogeneous and all of the values of it are similar,
    it is called a **pure set**. Hence, it requires less effort to explain it. However,
    **Y** would need more information to explain as it''s not pure. **X** turns out
    to be the impurest of them all. What it tries to convey is that randomness and
    disorganization adds to complexity and so it needs more information to explain.
    This degree of randomness is known as **entropy**. If the sample is completely
    homogeneous, then the entropy is *0*. If the sample is equally divided, its entropy
    will be *1*:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 **Z** 看起来相当均匀，并且它的所有值都相似，因此它被称为 **纯集**。因此，解释它需要更少的努力。然而，**Y** 需要更多的信息来解释，因为它不是纯的。**X**
    似乎是其中最不纯的。它试图传达的是，随机性和无序增加了复杂性，因此需要更多的信息来解释。这种随机性的程度被称为 **熵**。如果样本完全均匀，则熵为 *0*。如果样本均匀分割，其熵将为
    *1*：
- en: '*Entropy = -p log[2]p - q log[2]q*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*熵 = -p log[2]p - q log[2]q*'
- en: Here, *p* means the probability of success and *q* means the probability of
    failure.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*p* 表示成功的概率，而 *q* 表示失败的概率。
- en: Entropy is also used with a categorical target variable. It picks the split
    that has the lowest entropy compared to the parent node.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当目标变量是分类的，也会使用熵。它选择与父节点相比熵最低的分割点。
- en: Here, we must calculate the entropy of parent node first. Then, we need to calculate
    entropy of each individual node that's been split and post that, including the
    weighted average of all subnodes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先必须计算父节点的熵。然后，我们需要计算每个已分割的单独节点的熵，然后包括所有子节点的加权平均值。
- en: '**Reduction in variance**: When it comes to the continuous target variable,
    reduction in variance is used. Here, we are using variance to decide the best
    split. The split with the lowest variance is picked as the criteria to split:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**方差减少**：当涉及到连续的目标变量时，使用方差减少。在这里，我们使用方差来决定最佳的分割点。选择具有最低方差的分割点作为分割的标准：'
- en: Variance = ![](img/b83a3621-9aeb-480a-9a06-8df93b13d3d0.png)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 方差 = ![](img/b83a3621-9aeb-480a-9a06-8df93b13d3d0.png)
- en: Here, ![](img/41238de0-7910-4753-b06d-e0aa03b19ed2.png) is the mean of all the
    values, *X,* is the real values, and *n* is the number of values.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/41238de0-7910-4753-b06d-e0aa03b19ed2.png) 是所有值的平均值，*X* 是真实值，而 *n*
    是值的数量。
- en: The calculation of variance for each node is done first and then the weighted
    average of each node's variance makes us select the best node.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 首先计算每个节点的方差，然后计算每个节点方差的加权平均值，这使我们选择最佳的节点。
- en: Parameters of tree splitting
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树分割的参数
- en: 'There are a number of parameters that we need to tune or be aware of:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多参数我们需要调整或注意：
- en: '`Max_depth`: One of the most important parameters is `max_depth`. It captures
    the essence of how deep the tree can get. More depth in the tree means that it
    is able to extract more information from the features. However, sometimes, excessive
    depth might be a cause of worry as it tends to bring along overfitting as well.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Max_depth`: 最重要的参数之一是 `max_depth`。它捕捉了树可以延伸多深的核心。树的深度越大，意味着它能够从特征中提取更多信息。然而，有时过深的深度可能会引起担忧，因为它往往会带来过拟合的问题。'
- en: '`min_samples_split`: This represents the minimum number of samples required
    to split an internal node. This can vary between considering at least one sample
    at each node to considering all of the samples at each node. When we increase
    this parameter, the tree becomes more constrained as it has to consider more samples
    at each node. An increase in the value of `min_samples_split` tends to be underfitted.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_split`: 这表示分割内部节点所需的最小样本数。这可以在考虑每个节点至少一个样本到考虑每个节点的所有样本之间变化。当我们增加此参数时，树变得更加受约束，因为它必须在每个节点考虑更多的样本。`min_samples_split`
    值的增加往往会引起欠拟合。'
- en: '`min_samples_leaf`: This is the minimum number of samples required to be at
    a leaf node. Increasing this value to the maximum might cause underfitting.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_leaf`: 这是达到叶节点所需的最小样本数。将此值增加到最大可能会引起欠拟合。'
- en: '`max_features`: This is maximum number of features to be considered for the
    best split. It might cause overfitting when there is an increase in the max number
    of features.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_features`: 这是考虑最佳分割时可以使用的最大特征数。当增加最大特征数时，可能会引起过拟合。'
- en: Now, we are well equipped to understand the random forest algorithm. We're going
    to talk about that next.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经充分了解了随机森林算法。我们将在下一节讨论这一点。
- en: Random forest algorithm
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林算法
- en: 'The random forest algorithm works with the bagging technique. The number of
    trees are planted and grown in the following manner:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林算法使用袋装技术。树木以以下方式种植和生长：
- en: There are *N *observations in the training set. Samples out of *N* observations
    are taken at random and with replacement. These samples will act as a training
    set for different trees.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集中有*N*个观测值。从*N*个观测值中随机抽取样本，并替换。这些样本将作为不同树的训练集。
- en: If there are *M* input features (variables), *m* features are drawn as a subset
    out of *M* and of course *m < M*. What this does is select *m* features at random
    at each node of the tree.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有*M*个输入特征（变量），则从*M*个特征中抽取*m*个特征作为子集，当然*m < M*。这样做是在树的每个节点随机选择*m*个特征。
- en: Every tree is grown to the largest extent possible.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每棵树都尽可能地生长。
- en: 'Prediction takes place based on the aggregation of the results coming out of
    all the trees. In the case of classification, the method of aggregation is voting,
    whereas it is an average of all the results in the case of regression:'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测是基于所有树木输出的结果聚合。在分类的情况下，聚合方法是投票，而在回归的情况下，则是所有结果的平均值：
- en: '![](img/09fecda6-8be8-4b47-9b9c-51591cbcf909.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/09fecda6-8be8-4b47-9b9c-51591cbcf909.png)'
- en: Let's work on a case study, since that will help us understand this concept
    more in detail. Let's work on breast cancer data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个案例研究来深入了解这个概念。让我们研究乳腺癌数据。
- en: Case study
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究
- en: 'The data that is given in this case study is about patients who were detected
    with two kinds of breast cancer:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例研究中的数据是关于被检测出两种乳腺癌的患者的：
- en: Malignant
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恶性
- en: Benign
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 良性
- en: 'A number of features are given here that have characteristics in regard to
    the cell nuclei that have been computed from the **fine-needle aspiration** (**FNA**)
    of a breast mass. Based on these features, we need to predict whether the cancer
    is malignant or benign. Follow these steps to get started:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里给出了一些具有细胞核特征的特性，这些特性是从乳腺肿块**细针穿刺**（**FNA**）中计算出来的。基于这些特征，我们需要预测癌症是恶性还是良性。按照以下步骤开始：
- en: 'Import all the required libraries:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必需的库：
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Load the breast cancer data:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载乳腺癌数据：
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s understand the data:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们了解数据：
- en: '[PRE12]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We get the following output:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/f9e6557f-a0cb-4eaa-9312-442ffb09c069.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f9e6557f-a0cb-4eaa-9312-442ffb09c069.png)'
- en: 'Let''s consider `data.head()` here:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们考虑`data.head()`这里：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'From this, we get the following output:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个结果中，我们得到以下输出：
- en: '![](img/819947a5-3c40-47d5-8342-71e05f58cd5f.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/819947a5-3c40-47d5-8342-71e05f58cd5f.png)'
- en: 'We get the data diagnosis from the following code:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从以下代码中得到数据诊断：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following is the output for the preceding code:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为前面代码的输出：
- en: '![](img/7e288080-bf9d-41ea-b5bc-b43963d466ed.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7e288080-bf9d-41ea-b5bc-b43963d466ed.png)'
- en: 'The data is described as follows:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据描述如下：
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We get this output from the preceding code:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从前面的代码中得到以下输出：
- en: '![](img/b619a949-107e-455d-840b-3027dbbf095e.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b619a949-107e-455d-840b-3027dbbf095e.png)'
- en: '[PRE16]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](img/4bd0bc77-162c-441f-b7cd-428b83e5e6f4.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4bd0bc77-162c-441f-b7cd-428b83e5e6f4.png)'
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/83f6dc50-a460-45af-a92d-2b8ffc6995c3.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/83f6dc50-a460-45af-a92d-2b8ffc6995c3.png)'
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The preceding input gives us the following output:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输入给出了以下输出：
- en: '![](img/6d121f10-24e4-49d3-8832-e24d16f80548.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6d121f10-24e4-49d3-8832-e24d16f80548.png)'
- en: '[PRE19]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/f63c06af-363d-4a1b-9699-bd534ae987c2.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f63c06af-363d-4a1b-9699-bd534ae987c2.png)'
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](img/a1c90824-2c4a-4261-85a7-1fc5076b3613.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a1c90824-2c4a-4261-85a7-1fc5076b3613.png)'
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](img/d7aa01a1-4ef0-4fe8-8c92-90eed38bba16.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d7aa01a1-4ef0-4fe8-8c92-90eed38bba16.png)'
- en: '[PRE22]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'From this, we can see that the performance accuracy on the testing data is
    `95.0`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个结果中，我们可以看到测试数据的性能准确率为`95.0`：
- en: '[PRE23]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here, the total predictions is `114`:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，总预测数为`114`：
- en: '[PRE24]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/e256f6d9-d551-4096-a773-babd33156f3a.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e256f6d9-d551-4096-a773-babd33156f3a.png)'
- en: '[PRE25]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'From this, we can see that the 10 k-fold cross validation mean score is `94.9661835749`:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个结果中，我们可以看到10折交叉验证的平均分数为`94.9661835749`：
- en: '[PRE26]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here, we can see that the classification accuracy is `95.0`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到分类准确率为`95.0`：
- en: '[PRE27]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](img/df04808f-0b0b-4ae4-ae11-5eaaea1d3c6f.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/df04808f-0b0b-4ae4-ae11-5eaaea1d3c6f.png)'
- en: '[PRE28]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](img/ab332a99-7d5f-4df2-9ed3-4d8a540728df.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ab332a99-7d5f-4df2-9ed3-4d8a540728df.png)'
- en: '[PRE29]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](img/959ed7fc-e995-4594-8772-215c3369f34e.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/959ed7fc-e995-4594-8772-215c3369f34e.png)'
- en: The preceding graph is a **receiver operating characteristic** (**ROC**) metric,
    which is used to evaluate classifier output quality using cross-validation.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表是**接收者操作特征**（**ROC**）指标，用于通过交叉验证评估分类器输出的质量。
- en: The preceding plot shows the ROC response to our chosen features (`['compactness_mean',
    'perimeter_mean', 'radius_mean', 'texture_mean', 'concavity_mean', 'smoothness_mean']`)
    and the diagnosis-dependent variable that was created from k-fold cross-validation.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示了ROC对所选特征（`['compactness_mean', 'perimeter_mean', 'radius_mean', 'texture_mean',
    'concavity_mean', 'smoothness_mean']`）和由k折交叉验证创建的诊断相关变量的响应。
- en: A ROC area of `0.99` is quite good.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ROC面积为`0.99`相当不错。
- en: Boosting
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升法
- en: 'When it comes to bagging, it can be applied to both classification and regression.
    However, there is another technique that is also part of the ensemble family:
    boosting. However, the underlying principle of these two are quite different.
    In bagging, each of the models runs independently and then the results are aggregated
    at the end. This is a parallel operation. Boosting acts in a different way, since
    it flows sequentially. Each model here runs and passes on the significant features
    to another model:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 当提到袋装法时，它可以应用于分类和回归。然而，还有一种技术也是集成家族的一部分：提升。然而，这两种技术的底层原理相当不同。在袋装法中，每个模型都是独立运行的，然后在最后汇总结果。这是一个并行操作。提升以不同的方式运作，因为它按顺序流动。这里的每个模型运行并将显著特征传递给另一个模型：
- en: '![](img/d4f677a3-842b-47dc-be84-527d26d94f49.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d4f677a3-842b-47dc-be84-527d26d94f49.png)'
- en: Gradient boosting
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升
- en: 'To explain gradient boosting, we will take the route of Ben Gorman, a great
    data scientist. He has been able to explain it in a mathematical yet simple way.
    Let''s say that we have got nine training examples wherein we are required to
    predict the age of a person based on three features, such as whether they like
    gardening, playing video games, or surfing the internet. The data for this is
    as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释梯度提升，我们将采取本·戈尔曼的路线，他是一位伟大的数据科学家。他能够用一种数学而简单的方式解释它。让我们假设我们有九个训练示例，其中我们需要根据三个特征预测一个人的年龄，例如他们是否喜欢园艺、玩视频游戏或上网冲浪。这些数据如下：
- en: '![](img/0bf3e5de-9aff-46ba-aaf6-830f589b6200.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0bf3e5de-9aff-46ba-aaf6-830f589b6200.png)'
- en: To build this model, the objective is to minimize the mean squared error.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 要建立这个模型，目标是使均方误差最小化。
- en: 'Now, we will build the model with a regression tree. To start with, if we want
    to have at least three samples at the training nodes, the first split of the tree
    might look like this:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用回归树建立模型。首先，如果我们想在训练节点至少有三个样本，树的第一次分割可能看起来像这样：
- en: '![](img/928c8ffa-6ef3-4e38-8c74-2e1a1fbde65f.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/928c8ffa-6ef3-4e38-8c74-2e1a1fbde65f.png)'
- en: This seems to be fine, but it's not including information such as whether they
    play video games or browse the internet. What if we plan to have two samples at
    the training nodes?
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来似乎不错，但它没有包括他们是否玩视频游戏或浏览互联网等信息。如果我们计划在训练节点有两个样本会怎样？
- en: '![](img/a16df436-cb99-466d-a364-c33c32f41c14.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a16df436-cb99-466d-a364-c33c32f41c14.png)'
- en: 'Through the preceding tree, we are able to get certain information from features,
    such as **SurfInternet** and **PlaysVideoGames**. Let''s figure out how residuals/errors
    come along:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 通过前面的树形图，我们可以从特征中获取某些信息，例如**SurfInternet**和**PlaysVideoGames**。让我们弄清楚残差/误差是如何产生的：
- en: '![](img/53f43655-8f92-48e9-9912-97466e94b504.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/53f43655-8f92-48e9-9912-97466e94b504.png)'
- en: 'Now, we will work on the residuals of the first model:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将处理第一个模型的残差：
- en: '![](img/aa17a869-d555-461e-be73-e76c2dc09eaf.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/aa17a869-d555-461e-be73-e76c2dc09eaf.png)'
- en: 'Once we have built the model on residuals, we have to combine the previous
    model with the current one, as shown in the following table:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在残差上建立了模型，我们必须将先前的模型与当前模型相结合，如下表所示：
- en: '![](img/948cc81a-328c-4744-9dde-1a5ba19ab78f.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/948cc81a-328c-4744-9dde-1a5ba19ab78f.png)'
- en: We can see that the residuals have come down and that the model is getting better.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到残差已经下降，模型正在变得更好。
- en: 'Let''s try to formulate what we have done up until this point:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试将到目前为止我们所做的工作公式化：
- en: First, we built a model on the data *f[1](x) = y.*
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们在数据 *f[1](x) = y.* 上建立了一个模型。
- en: 'The next thing we did was calculate the residuals and build the model on residuals:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来做的事情是计算残差并在残差上建立模型：
- en: '*h [1](x)=y- f[1](x)*'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '*h [1](x)=y- f[1](x)*'
- en: The next step is to combine the model, that is, *f[2](x)= f[1](x) + h [1](x).*
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是组合模型，即 *f[2](x)= f[1](x) + h [1](x).*
- en: 'Adding more models can correct the errors of the previous models. The preceding
    equation will turn out to be as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 添加更多模型可以纠正先前模型的错误。前面的方程将变成如下：
- en: '*f3(x)= f2(x) + h2(x) *'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '*f3(x)= f2(x) + h2(x) *'
- en: 'The equation will finally look as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 方程最终将如下所示：
- en: '*f[m](x)= f[m][-1](x) + h[m][-1](x)*'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*f[m](x)= f[m][-1](x) + h[m][-1](x)*'
- en: 'Alternatively, we can write the following:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以写成以下形式：
- en: '* h[m](x)= y- f[m](x)*'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '* h[m](x)= y- f[m](x)*'
- en: 'Since our task is to minimize the squared error, *f* will be initialized with
    the mean of the training target values:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的任务是使平方误差最小化，因此 *f* 将初始化为训练目标值的平均值：
- en: '![](img/fa749feb-9490-4a4c-9790-fac085bc18f0.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fa749feb-9490-4a4c-9790-fac085bc18f0.png)'
- en: 'Then, we can find out *f*[*m+1*, ]just like before:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以像之前一样找到 *f*[*m+1*, ]：
- en: '*f[m](x)= f[m][-1](x) + h[m][-1](x)*'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*f[m](x)= f[m][-1](x) + h[m][-1](x)*'
- en: Now, we can use gradient descent for our gradient boosting model. The objective
    function we want to minimize is *L*. Our starting point is *f[o](x)*. For iteration
    *m=1*, we compute the gradient of* L* with respect to* f[o](x)*. Then, we fit
    a weak learner to the gradient components. In the case of a regression tree, leaf
    nodes produce an **average gradient** among samples with similar features. For
    each leaf, we step in the direction of the average gradient. The result is *f[1]*and
    this can be repeated until we have *f[m]*.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用梯度下降来优化我们的梯度提升模型。我们想要最小化的目标函数是 *L*。我们的起点是 *f[o](x)*。对于迭代 *m=1*，我们计算
    *L* 对 *f[o](x)* 的梯度。然后，我们将弱学习器拟合到梯度分量。在回归树的情况下，叶子节点会在具有相似特征的样本中产生一个**平均梯度**。对于每个叶子节点，我们朝着平均梯度的方向前进。结果是
    *f[1]*，这可以重复进行，直到我们得到 *f[m]*。
- en: We modified our gradient boosting algorithm so that it works with any differentiable
    loss function. Let's clean up the preceding ideas and reformulate our gradient
    boosting model once again.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们修改了我们的梯度提升算法，使其能够与任何可微分的损失函数一起工作。让我们清理前面的想法，并再次重新表述我们的梯度提升模型。
- en: Parameters of gradient boosting
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升参数
- en: 'There are different parameters to consider before applying gradient boosting
    for the breast cancer use case:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用梯度提升进行乳腺癌用例之前，需要考虑不同的参数：
- en: '`Min_samples_split`: The minimum number of samples required in a node to be
    considered for splitting is termed `min_samples_split`.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Min_samples_split`: 节点中需要考虑分割的最小样本数被称为 `min_samples_split`。'
- en: '`Min_samples_leaf`: The minimum number of samples required at the terminal
    or leaf node is termed `min_samples_leaf`.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Min_samples_leaf`: 在终端或叶子节点中需要的最小样本数被称为 `min_samples_leaf`。'
- en: '`Max_depth`: This is the maximum number of nodes allowed from the root to the
    farthest leaf of a tree. Deeper trees can model more complex relationships, however,
    causing the model to overfit.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Max_depth`: 这是指从根节点到最远叶子节点的最大节点数。更深层次的树可以模拟更复杂的关系，然而，这也可能导致模型过拟合。'
- en: '`Max_leaf_nodes`: The maximum number of nodes at the leaves in a tree. Since
    binary trees are created, a depth of `n` would produce a maximum of *2^(n )* leaves.
    Hence, either `max_depth` or `max_leaf_nodes` can be defined.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Max_leaf_nodes`: 树中叶子节点的最大节点数。由于创建了二叉树，深度为 `n` 将产生最大为 *2^(n )* 的叶子节点。因此，可以定义
    `max_depth` 或 `max_leaf_nodes`。'
- en: 'Now, we will apply gradient boosting for the breast cancer use case. Here,
    we are loading the libraries that are required to build the model:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将为乳腺癌用例应用梯度提升。在这里，我们正在加载构建模型所需的库：
- en: '[PRE30]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We are now done with the various steps of data cleaning and exploration while
    performing random forest. Now, we will jump right into building the model.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行随机森林的过程中，我们已经完成了数据清洗和探索的各个步骤。现在，我们将直接进入模型的构建。
- en: 'Here, we will perform a grid search to find out the optimal parameters for
    the gradient boosting algorithm:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将执行网格搜索以找到梯度提升算法的最优参数：
- en: '[PRE31]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We get the following output:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/f0781efe-1af7-400d-8397-3a9e5d860876.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f0781efe-1af7-400d-8397-3a9e5d860876.png)'
- en: 'Now, let''s find out the optimal parameters:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们找出最优参数：
- en: '[PRE32]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output can be seen as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![](img/588de5cb-de5b-4e24-ba89-04eb0c654304.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/588de5cb-de5b-4e24-ba89-04eb0c654304.png)'
- en: 'Now, we will build the model:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将构建模型：
- en: '[PRE33]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The performance accuracy on the testing data is `96.0`:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据上的性能准确率是 `96.0`：
- en: '[PRE34]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The total number of predictions is `114`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的总数是 `114`：
- en: '[PRE35]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![](img/ee427abe-70f1-4061-95f2-045ab887cb9e.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ee427abe-70f1-4061-95f2-045ab887cb9e.png)'
- en: 'Let''s perform cross-validation:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行交叉验证：
- en: '[PRE36]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The 10 k-fold cross-validation mean score is `94.9420289855`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 10 k-fold 交叉验证的平均分数是 `94.9420289855`：
- en: '[PRE37]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The classification accuracy is `96.0`:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 分类准确率是 `96.0`：
- en: '[PRE38]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'By looking at the confusion matrix, we can see that this model is better than
    the previous one:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看混淆矩阵，我们可以看到这个模型比之前的模型更好：
- en: '![](img/3bc63967-fbe6-41e9-b577-ad52bb8bcdf9.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3bc63967-fbe6-41e9-b577-ad52bb8bcdf9.png)'
- en: Summary
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we studied ensemble learning and its different methods, namely
    bagging, boosting, and stacking. We even saw what is bootstrapping which is the
    root for ensemble learning methods such as bagging and boosting. We also learned
    about decision trees and its approach of divide and rule with example of people
    applying for loan. Then we covered tree splitting and the parameters to split
    a decision tree, moving on to the random forest algorithm. We worked on a case
    study of breast cancer using the concepts covered. We also discovered the difference
    between bagging and boosting and gradient boosting. We also discussed on parameters
    of gradient boosting to use it our example of breast cancer.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了集成学习及其不同方法，即bagging、boosting和stacking。我们还了解了什么是bootstrapping，它是bagging和boosting等集成学习方法的根源。我们还学习了决策树及其通过例子（如申请贷款的人）进行划分和规则的方法。然后我们讨论了树分裂以及分裂决策树的参数，接着转向随机森林算法。我们使用所涵盖的概念进行了一个乳腺癌案例研究。我们还发现了bagging和boosting以及梯度提升之间的差异。我们还讨论了梯度提升的参数，以便在我们的乳腺癌例子中使用。
- en: In the next chapter, we will learn about training neural networks.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习关于训练神经网络的内容。
