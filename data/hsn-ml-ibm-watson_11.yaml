- en: Creating a Facial Expression Platform on IBM Cloud
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在IBM云上创建面部表情平台
- en: In this chapter, we will cover a complete IBM Cloud-based expression classification
    solution that will use deep learning machine learning techniques on the IBM Cloud
    platform. The solution will implement a simple, yet efficient, ML model using
    TensorFlow and the ML services available with IBM Watson Studio. The goal is to
    illustrate an end-to-end solution for a complex ML task.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一个基于IBM Cloud的完整表达式分类解决方案，该解决方案将在IBM Cloud平台上使用深度学习机器学习技术。该解决方案将使用TensorFlow和IBM
    Watson Studio提供的ML服务实现一个简单而高效的ML模型。目标是展示一个复杂ML任务的端到端解决方案。
- en: 'We will divide this chapter into the following areas:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将本章分为以下区域：
- en: Understanding facial expression classification
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解面部表情分类
- en: Exploring expression databases
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索表情数据库
- en: Preprocessing faces
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部预处理
- en: Learning the expression classifier
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习表达式分类器
- en: Evaluating the expression classifier
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估表达式分类器
- en: Understanding facial expression classification
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解面部表情分类
- en: Let's start with a brief discussion leading up to just what we mean when we
    say *facial expression classification*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从简短讨论开始，讨论当我们说**面部表情分类**时我们究竟指的是什么。
- en: In [Chapter 7](99762d15-664d-4987-82cf-74440dedabb3.xhtml), *Deep Learning Using
    TensorFlow on the IBM Cloud*, we used IBM Watson Studio to perform *object detection*
    within random images. In that use case, we asked our project's model to find or
    detect common or known objects that might be pictured within an image. For example,
    we submitted an image of an animal and the solution correctly detected and identified
    a pinto horse, although no further information about the detected object was produced,
    such as whether the horse was angry or frightened.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](99762d15-664d-4987-82cf-74440dedabb3.xhtml)《在IBM云上使用TensorFlow进行深度学习》中，我们使用了IBM
    Watson Studio在随机图像中执行**目标检测**。在那个用例中，我们要求我们的项目模型找到或检测图像中可能出现的常见或已知对象。例如，我们提交了一张动物的图片，解决方案正确地检测并识别出了一匹斑马，尽管没有提供关于检测到的对象的更多信息，例如马是否生气或害怕。
- en: Face detection
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部检测
- en: Perhaps the next step on this journey (after object detection within an image)
    is face detection. Face detection is a computer technology being applied in a
    variety of applications that strive to identify human faces within digital images.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 可能的下一步（在图像中的目标检测之后）是面部检测。面部检测是一种计算机技术，被应用于各种应用中，旨在识别数字图像中的人类面部。
- en: Facial recognition is a way of detecting and identifying a human face through
    the use of technology. A facial recognition solution utilizes the logic of biometrics
    to map facial features from a photograph (or even video) and then compares the
    information with a database of known faces, looking for a match.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 面部识别是通过使用技术来检测和识别人类面部的一种方式。面部识别解决方案利用生物识别逻辑将照片（甚至视频）中的面部特征进行映射，然后将其与已知面部数据库中的信息进行比较，寻找匹配项。
- en: Biometrics is the measurement and statistical examination of people's unique
    physical and behavioral characteristics, based upon the principle that each and
    every individual can be accurately identified by his or her intrinsic physical
    or behavioral traits.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 生物识别是基于每个人独特的生理和行为特征进行测量和统计分析的科学，基于的原则是每个个体都可以通过其固有的生理或行为特征被准确识别。
- en: Facial expression analysis
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部表情分析
- en: 'Now we can get to the point: *facial expression analysis*.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进入正题：**面部表情分析**。
- en: This concept commonly classifies all facial expressions as relating to one of
    the six universal emotions—joy (happiness), surprise, disgust, sadness, anger,
    and fear as well as neutral.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念通常将所有面部表情归类为与六种普遍情感之一相关——快乐（幸福）、惊讶、厌恶、悲伤、愤怒和恐惧，以及中性。
- en: Emotions are one element that makes us human and (believe it or not) they are
    difficult to hide, since all emotions, suppressed or not, are likely to have a
    noticeable physical effect that can be of value if we can automate the process
    of detecting and then interpreting the physical effects.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 情感是我们作为人类的一个元素，而且（信不信由你）它们很难隐藏，因为所有情感，无论是否被抑制，都可能产生明显的生理效应，如果我们能够自动化检测和解释这些生理效应的过程，这些效应将是有价值的。
- en: Once detected, the interpretation (of facial expressions) process is (perhaps)
    just another classification exercise. In practice, you'll find that facial expression
    classification will be based upon what is known as **TBM** or the **transferable
    belief model** framework.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦检测到，对（面部表情）的解释过程（或许）仅仅是另一个分类练习。在实践中，你会发现面部表情分类将基于所谓的**TBM**或**可迁移信念模型**框架。
- en: TBM
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TBM
- en: 'TBM offers an interesting premise. Without intending to provide a comprehensive
    explanation of the TBM framework, a key point is that it introduces degrees of
    belief and transfer (giving rise to the name of the method: the transferable belief
    model), which allows the model to make the necessary assumptions required to perform
    adequate classification (of the expressions). Basically, this means it scores
    its assumptions, that is, the assumption that the expression is a happy expression
    is determined to have a *n* percentage chance of being correct (we''ll see this
    in action later in this chapter when we review the results of our project).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: TBM提供了一个有趣的假设。无意提供对TBM框架的全面解释，一个关键点是它引入了信念和转移的程度（从而产生了该方法的名字：可迁移信念模型），这允许模型做出执行适当分类（表情）所需的必要假设。基本上，这意味着它对其假设进行评分，即确定表情是快乐的表情的假设有*n*百分比的正确性（我们将在本章后面回顾我们项目的结果时看到这一点）。
- en: Further (and I'm oversimplifying), TBM looks to use quantified beliefs to make
    its classification decisions. Something perhaps more easily understood is that
    facial expression analysis extracts an expression skeleton of facial features
    (the mouth, eyes and eyebrows) and then derives simple distance coefficients from
    facial images. These characteristic distances are then fed to a rule-based decision
    system that relies on TBM in order to assign a facial expression to the face image.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步（并且我在简化），TBM试图使用量化的信念来做出其分类决策。也许更容易理解的是，面部表情分析从面部特征（嘴巴、眼睛和眉毛）中提取表情骨骼，然后从面部图像中推导出简单的距离系数。这些特征距离随后被输入到一个基于规则的决策系统中，该系统依赖于TBM来将面部表情分配给面部图像。
- en: Again, the goal is not to define the theory behind TBM, or even the intimate
    details of a facial expression analysis solution, but more to show a working example
    of such; therefore, we will go on to the next section and our use case example
    and leave to the reader the further work of researching this topic.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，目标不是定义TBM背后的理论，甚至不是面部表情分析解决方案的详细细节，而是更多地展示一个实际的工作示例；因此，我们将继续到下一节和我们的用例示例，并将进一步研究这个主题的工作留给读者。
- en: Exploring expression databases
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索表情数据库
- en: At the core of all facial expression analysis solutions is an expression database.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所有面部表情分析解决方案的核心是一个表情数据库。
- en: A (**facial**) **expression database** is a collection of images showing the
    specific facial expressions of a range of emotions. These images must be well
    annotated or emotion-tagged if they are to be useful to expression recognition
    systems and their related algorithms.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个（面部）**表情数据库**是展示一系列情感的具体面部表情的图像集合。如果这些图像要用于表情识别系统和相关算法，它们必须被很好地注释或情感标记。
- en: A major hindrance to new developments in the area of **automatic human behavior
    analysis** is the lack of suitable databases with displays of behavior and affect.
    There have been directed advances in this area, as in the **MMI Facial Expression
    Database** project, which aims to deliver large volumes of **visual data of facial
    expressions** to the facial expression analysis community.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 自动人类行为分析领域新发展的一个主要障碍是缺乏展示行为和情感的合适数据库。在这个领域已经有一些有针对性的进展，例如**MMI面部表情数据库**项目，该项目旨在向面部表情分析社区提供大量**面部表情视觉数据**。
- en: The MMI Facial Expression Database was initially created in 2002 as a resource
    for building and evaluating facial expression recognition algorithms. One significance
    of this database is that others databases focus on the expressions of the six
    basic emotions (which we mentioned earlier), whereas this database contains both
    these prototypical expressions as well as expressions with a single **Facial Action
    Coding System** (**FACS**) or **Action Unit** (**AU**) activated, for all existing
    AUs and many other **Action Descriptors** (**AD**). Recently recordings of naturalistic
    expressions have been added too.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MMI 面部表情数据库最初于 2002 年创建，作为构建和评估面部表情识别算法的资源。该数据库的一个显著特点是，其他数据库专注于六种基本情绪（我们之前提到过）的表情，而此数据库包含这些典型表情以及仅激活单个**面部动作编码系统（FACS**）或**动作单元（AU**）的表情，对于所有现有的
    AU 和许多其他**动作描述符（AD**）。最近还增加了自然表情的记录。
- en: The database is freely available to the scientific community. Find out more
    about the database online at [https://mmifacedb.eu](https://mmifacedb.eu).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据库对科学界免费开放。有关数据库的更多信息，请在网上查看[https://mmifacedb.eu](https://mmifacedb.eu)。
- en: In other example projects, we've been able to create our own test data or alter
    existing datasets to use within a project. However, with **expression analysis**
    projects, it is really not realistic to create a reasonably sized database (stating
    with nothing), which would require the collection and processing of literally
    thousands of images, all appropriately documented.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他示例项目中，我们能够创建自己的测试数据或修改现有数据集以在项目中使用。然而，对于**表情分析**项目来说，创建一个合理规模的数据库（从零开始），这需要收集和处理成千上万张图像，所有这些图像都需要适当的文档记录，实际上并不现实。
- en: After collection, each (facial) image needs to be reviewed and categorized based
    on the emotion shown into one of seven categories (angry, disgust, fear, happy,
    sad, surprise, and neutral). To further complicate this work, images may not be
    aligned and properly proportioned.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 收集后，每个（面部）图像都需要根据所显示的情绪进行审查和分类，分为七个类别之一（愤怒、厌恶、恐惧、快乐、悲伤、惊讶和中性）。为了进一步复杂化这项工作，图像可能没有对齐和适当的比例。
- en: The bottom line is that, even if you have a large number of images, if the images
    are not correctly labeled or simply do not contain detectable facial images, the
    performance of the expression analysis and detection process will be compromised
    (it will perform poorly).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，即使你有大量的图像，如果图像没有正确标记，或者根本不包含可检测的面部图像，表情分析和检测过程的性能将会受到影响（表现不佳）。
- en: These types of challenges make the classification process more difficult because
    the model is forced to generalize.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的挑战使得分类过程更加困难，因为模型被迫进行泛化。
- en: Training with the Watson Visual Recognition service
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Watson 视觉识别服务进行训练
- en: Considering the above mentioned challenges, IBM Watson Studio helps us to get
    started anyway by offering (right out of the box) the **Watson Visual Recognition**
    service.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到上述挑战，IBM Watson Studio 通过提供（开箱即用的）**Watson 视觉识别**服务，帮助我们开始使用。
- en: This valuable service helps with the process of accurately analyzing, classifying,
    and training images using machine learning logic (although, to be sure, it still
    requires reasonable amounts of relevant training data to begin with, but more
    on that in a bit).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个有价值的服务有助于使用机器学习逻辑准确分析、分类和训练图像的过程（尽管，诚然，一开始仍然需要合理数量的相关训练数据，关于这一点稍后还会详细说明）。
- en: 'Thankfully, there is a set of built-in models that is available to us to provide
    highly accurate results without endless training. The models are as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一组内置模型可供我们使用，无需无限期地训练就能提供高度准确的结果。这些模型如下：
- en: '**General model**: General classifier categories'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用模型**：通用分类类别'
- en: '**Face model:** Locate faces within an image, gender, and age'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面部模型**：在图像中定位面部、性别和年龄'
- en: '**Explicit model**: Whether an image is inappropriate for general use'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显式模型**：图像是否适合通用'
- en: '**b model**: Specifically for images of food items'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**b 模型**：专门用于食品图像'
- en: In this chapter's project, we will show how to use the Visual Recognition Service
    and the Face model to build an end-to-end working solution that can look at an
    image of a human face, perform expression analysis and simple classification,
    and ultimately, determine whether the individual is feeling happy or sad.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的项目中，我们将展示如何使用视觉识别服务和面部模型构建一个端到端的工作解决方案，该解决方案可以查看人脸图像，执行表情分析和简单分类，并最终确定个人是感到快乐还是悲伤。
- en: Preprocessing faces
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理面部
- en: 'We have just mentioned that building a suitable expression database is a lot
    of work. To be able to build an end-to-end working expression analysis solution
    (and fit it all into a single chapter of this book), we will take some liberties
    with our project:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚提到，构建一个合适的表情数据库是一项大量工作。为了能够构建一个端到端的工作表情分析解决方案（并将其全部放入本书的单章中），我们将在我们的项目中采取一些自由：
- en: We will limit our model's ability to detect and classify only two emotions—happiness
    and sadness
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将限制我们模型检测和分类的能力，仅限于两种情绪——快乐和悲伤
- en: We will supply only a limited amount of expression data to train our model
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将只提供有限的表达数据来训练我们的模型
- en: Obviously, in the real world, our second assumption is a risky one; as in any
    ML model, less training data typically produces a less valuable result.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在现实世界中，我们的第二个假设是风险性的；在任何机器学习模型中，训练数据越少，通常产生的结果就越没有价值。
- en: Preparing the training data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备训练数据
- en: Again, if we have decided to satisfy only the minimal requirements for using
    the face model and the Visual Recognition service, we can get away with collecting
    only 10 images for each class which we intend our model to train on (10 happy
    faces, 10 sad faces, and 10 negative faces).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，如果我们决定仅满足使用面部模型和视觉识别服务的最低要求，我们可以只收集每个类别（我们打算让模型训练的类别）的10张图片（10个笑脸，10个哭脸和10个负面表情）。
- en: 'These individual training files will need to be the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些单个训练文件需要满足以下条件：
- en: Either JPEG (`.jpg`) and PNG (`.png`) formatted
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 格式为JPEG（`.jpg`）和PNG（`.png`）
- en: At least 32*32 pixels in size
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少32*32像素大小
- en: Compressed as a group into class ZIP files, that is, 10 happy faces in a `happy.zip`
    file and 10 sad faces in a `sad.zip` file
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一组图片压缩成ZIP文件，即一个`happy.zip`文件包含10个笑脸，一个`sad.zip`文件包含10个哭脸
- en: 'A sampling of our initial happy model training data is shown in the following
    screenshot:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是初始快乐模型训练数据的抽样截图：
- en: '![](img/e66f972a-ec25-4ac9-a6aa-3c4865f06efb.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e66f972a-ec25-4ac9-a6aa-3c4865f06efb.png)'
- en: The preceding images are of 10 faces showing what we think can be labeled as
    being representative of happy facial expressions. Notice that the individual files
    have all been added to a compressed (ZIP) file named `happy.zip`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图像是10个面部表情，我们认为可以标记为快乐面部表情的代表。请注意，所有单个文件都已添加到名为`happy.zip`的压缩（ZIP）文件中。
- en: 'A sampling of our initial sadmodel training data is shown in the following
    screenshot:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是初始悲伤模型训练数据的抽样截图：
- en: '![](img/f50f2a2d-d146-4d66-849b-9f761a3f7b29.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f50f2a2d-d146-4d66-849b-9f761a3f7b29.png)'
- en: And clearly, as the former group displayed happiness, the later images are of
    faces showing what we think can be labeled as being representative of sad expressions
    (individual files and the zipped file, `sad.zip`).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，前一组展示了快乐，后一组图像是面部表情，我们认为可以标记为悲伤表情的代表（单个文件和压缩文件`sad.zip`）。
- en: Negative or non-positive classing
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负面或非正面分类
- en: For the face model to work correctly, negative images are also required, not
    to be used to create a class (we will cover this in an upcoming section) within
    the created classifier, but to define what the updated classifier is not. Negative
    example files should not contain images that have the subject of any of the positive
    classes (happy and sad). In essence, the face images in this group should be perhaps
    considered to be neutral. You only need to specify one negative example file.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使面部模型正常工作，也需要负面图像，这些图像不会被用于创建分类（我们将在下一节中介绍）在创建的分类器中，而是用来定义更新的分类器不是什么。负面示例文件不应包含任何正面类别（快乐和悲伤）的主题图像。本质上，这个组中的面部图像可能被认为是中性的。你只需要指定一个负面示例文件。
- en: Because you want to give the model examples of what not to look for, you must
    provide the negative class. Providing a ML model with all positive images would
    mean that it would just assume that everything is positive and produce a risky
    result.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你想给模型提供不应该寻找的例子，你必须提供负面类别。向机器学习模型提供所有正面图像意味着它只会假设一切都是正面的，并产生风险性的结果。
- en: 'So finally, our initial negative model training data is shown in the following
    screenshot:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最终，我们的初始负面模型训练数据如下截图所示：
- en: '![](img/37ef7b79-dd09-413b-a9a1-72864e84c0a9.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/37ef7b79-dd09-413b-a9a1-72864e84c0a9.png)'
- en: Preparing the environment
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备环境
- en: Let's now get moving along with the project model development.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在继续进行项目模型开发。
- en: The next step (assuming you have already created a new IBM Watson Studio project)
    is to associate the Watson Visual Recognition Service to the project. We covered
    how to do this in [Chapter 7](99762d15-664d-4987-82cf-74440dedabb3.xhtml)*, Deep
    Learning Using TensorFlow on the IBM Cloud*, so we will assume you have already
    added the service to this new project. If not, review [Chapter 7](99762d15-664d-4987-82cf-74440dedabb3.xhtml)*,
    Deep Learning Using TensorFlow on the IBM Cloud*, or the online Watson Studio
    documentation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步（假设您已经创建了一个新的 IBM Watson Studio 项目）是将 Watson 视觉识别服务关联到项目。我们在[第 7 章](99762d15-664d-4987-82cf-74440dedabb3.xhtml)*使用
    TensorFlow 在 IBM Cloud 上进行深度学习*中介绍了如何进行此操作，因此我们假设您已经将服务添加到这个新项目中。如果没有，请参阅[第 7
    章](99762d15-664d-4987-82cf-74440dedabb3.xhtml)*使用 TensorFlow 在 IBM Cloud 上进行深度学习*或在线
    Watson Studio 文档。
- en: Project assets
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目资产
- en: In this chapter's project, our assets will primarily be the training images
    we have collected and, indirectly perhaps, classified. These image assets are
    added in a way similar to the process we used to add data assets to Watson Studio
    projects in earlier chapters, but there are a few differences, which we will soon
    see.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的项目中，我们的主要资产将是我们所收集的培训图像，也许间接地，还包括分类。这些图像资产以类似于我们在前几章中向 Watson Studio 项目添加数据资产的过程添加，但也有一些不同之处，我们很快就会看到。
- en: 'For now, we will perform the following steps:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将执行以下步骤：
- en: 'Go to the Assets tab and, under Models, click on New Visual Recognition model:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往“资产”标签页，在“模型”下点击“新建视觉识别模型”：
- en: '![](img/d5b40a59-b895-4128-a930-6e5d8f5b74ad.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![截图](img/d5b40a59-b895-4128-a930-6e5d8f5b74ad.png)'
- en: 'Once the model is created (it should take only a few moments), you can browse
    to or drag and drop the training (`.zip`) files we collected in the earlier section
    of this chapter to add them to our new project. This will upload the image files
    to **Cloud Object Storage** (**COO**), making them available to be used in our
    project:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型创建完成（这应该只需要几分钟），您可以将我们在本章早期部分收集的培训（`.zip`）文件浏览到或拖放到新项目中以添加它们。这将上传图像文件到**云对象存储**（**COO**），使它们可用于我们的项目：
- en: '![](img/1f296ff0-2fc6-4adc-ae50-92703f30f9ee.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![截图](img/1f296ff0-2fc6-4adc-ae50-92703f30f9ee.png)'
- en: You do not have to load each image file independently, just the three zipped
    files (`happy.zip`, `sad.zip`, and `negative.zip`). The ZIP files should then
    be listed as shown in the preceding screenshot.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您不需要单独加载每个图像文件，只需加载三个压缩文件（`happy.zip`、`sad.zip`和`negative.zip`）。ZIP 文件应列在先前的截图所示。
- en: Although you can upload the ZIP files, Watson will not allow those ZIP files
    to use the Preview feature on the Data Assets page. This is not a problem though,
    as you can still preview the images from the Model page, as we will see shortly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以上传 ZIP 文件，但 Watson 不会允许这些 ZIP 文件在数据资产页面使用预览功能。但这并不是问题，因为您仍然可以从模型页面预览图像，正如我们很快就会看到的。
- en: Creating classes for our model
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为我们的模型创建类别
- en: 'Now, from the Default Custom Model page, we need to create two classes. Perform
    the following steps to create the class for the model:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从默认自定义模型页面，我们需要创建两个类别。按照以下步骤创建模型类别：
- en: Click on Create a class.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“创建类别”。
- en: Enter a class name for it.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为其输入一个类别名称。
- en: 'Click the blue Create button:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击蓝色的“创建”按钮：
- en: '![](img/f960a915-1d9e-477a-8647-387adc7af744.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![截图](img/f960a915-1d9e-477a-8647-387adc7af744.png)'
- en: 'We actually only need to create two classes for this project: happy and sad,
    since Watson has already created the negative class for us. There is only one
    negative class per model, but you can have as many other classes as required for
    your project''s objectives.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们只需要为这个项目创建两个类别：快乐和悲伤，因为 Watson 已经为我们创建了负面类别。每个模型只有一个负面类别，但您可以根据项目目标需要创建尽可能多的其他类别。
- en: 'Once the classes are created, you then need to simply drag and drop the `.zip`
    files into the corresponding classes as shown in the following screenshot:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了类别，您只需将 `.zip` 文件拖放到相应的类别中，如下面的截图所示：
- en: '![](img/4fea40c0-94fa-4332-9571-87ac1e30bf53.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![截图](img/4fea40c0-94fa-4332-9571-87ac1e30bf53.png)'
- en: As you can see, we dropped each of the three ZIP files onto their corresponding
    class panes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们将每个三个 ZIP 文件都拖放到相应的类别面板中。
- en: 'As we stated earlier in this chapter, Watson preview doesn''t work with zipped
    image file assets; however, from the Default Custom Model page (shown in the following
    screenshot) we can click on All Images and scroll through what was loaded to see
    the filename, label, and content:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章前面所述，Watson预览不支持zip图像文件资产；然而，从以下截图所示的默认自定义模型页面，我们可以点击所有图片并滚动查看已加载的文件名、标签和内容：
- en: '![](img/39206f6e-f778-4a52-973a-a95f1fc87364.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/39206f6e-f778-4a52-973a-a95f1fc87364.png)'
- en: Automatic labeling
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动标注
- en: 'Earlier in this chapter, we pointed out that, after collecting images to be
    used for expression analysis and recognition, each individual image must be annotated
    or labelled as to which emotion group it belongs to. This can be a daunting task.
    Fortunately, when using IBM Watson Studio, you can simply include the appropriate
    images in a ZIP file and drop the ZIP file onto a class and Watson will automatically
    label the image file. For example, in the following screenshot, you can see that
    we can correctly identify those images to include within our **happy** class (shown
    outlined in green) while a single image, `sad05` (shown outlined in red), does
    not belong to and should be excluded from our ZIP file:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面，我们指出，在收集用于表情分析和识别的图像后，每个单独的图像都必须被标注或标记为属于哪个情感组。这可能是一项艰巨的任务。幸运的是，当使用IBM
    Watson Studio时，你只需将适当的图像包含在一个ZIP文件中，并将ZIP文件拖放到一个类别上，Watson就会自动标记图像文件。例如，在以下截图中，你可以看到我们可以正确识别那些属于我们**快乐**类别的图像（用绿色轮廓表示），而单个图像`sad05`（用红色轮廓表示）不属于，应该从我们的ZIP文件中排除：
- en: '![](img/eba475d9-828e-47e1-956b-5db9bc63cc7c.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/eba475d9-828e-47e1-956b-5db9bc63cc7c.png)'
- en: This is a pretty easy process, but it could invite errors. Since it is easy
    and quick, you may mistakenly include images that will dilute the training sample.
    Keep in mind that, even if the image files are named intuitively, such as happy
    or sad, Watson doesn't care about the names, it simply labels all of the images
    in the file as *positive* or *matching* to the class.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当简单的过程，但它可能会引起错误。由于它简单快捷，你可能会错误地包含会稀释训练样本的图像。记住，即使图像文件命名直观，如快乐或悲伤，Watson并不关心这些名称，它只是将文件中的所有图像标记为*正面*或*匹配*到类别。
- en: Finally, there's one more note about the training data. Once you go to the trouble
    of collecting and uploading data as an IBM Watson Studio asset, that data is available
    to any of your projects and, if you want to, you can share it with any other Watson
    Studio user! This promotes the development of assets across projects and users
    and increases the return on your investment.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有关于训练数据的另一个注意事项。一旦你费心收集和上传数据作为IBM Watson Studio资产，这些数据将可用于任何你的项目，如果你愿意，你可以与任何其他Watson
    Studio用户共享！这促进了跨项目和用户之间的资产开发，并增加了你的投资回报率。
- en: Learning the expression classifier
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习表情分类器
- en: 'Once you notice that the model status (indicated at the upper-right of the
    Default Custom Model page) has changed to Model is ready to train, you can then
    click on the Train Model button to start training the Face model on the training
    images we provided:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你注意到模型状态（在默认自定义模型页面的右上角指示）已更改为“模型准备训练”，然后你可以点击“训练模型”按钮开始在我们提供的训练图像上训练Face模型：
- en: '![](img/3b5eb50d-742a-4330-96e3-285cd285fddc.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3b5eb50d-742a-4330-96e3-285cd285fddc.png)'
- en: Since we provided only roughly 30 training images, the training process should
    take less than 5 or 10 minutes. During the training, you will not be able to make
    any changes to the model or classes.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只提供了大约30个训练图像，训练过程应该不到5或10分钟。在训练过程中，你将无法对模型或类别进行任何更改。
- en: Evaluating the expression classifier
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估表情分类器
- en: 'Once the model training is complete, you should see the following Training
    successful message:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，你应该会看到以下训练成功的消息：
- en: '![](img/65975056-898f-47e1-9b9d-47653ea42fc0.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/65975056-898f-47e1-9b9d-47653ea42fc0.png)'
- en: From this point, you can click on the here hyperlink in the popup to view and
    test the model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个点开始，你可以点击弹出窗口中的此处超链接来查看和测试模型。
- en: Viewing the model training results
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看模型训练结果
- en: 'After successfully training the model, you will be redirected to a page where
    you can see an overview or Summary (Model ID, Status, and other metadata) of the
    model build (take a note of the Model ID as that will be required during the implementation
    stage):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功训练模型后，你将被重定向到一个页面，你可以看到模型构建的概述或摘要（模型ID、状态和其他元数据）：
- en: '![](img/8b28522a-9f8c-461e-be40-3e5b4a1eede1.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8b28522a-9f8c-461e-be40-3e5b4a1eede1.png)'
- en: 'We can also see our model''s Classes information:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看我们模型的类别信息：
- en: '![](img/d150d8ec-dac7-4f83-b0ec-0876f0f455cb.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d150d8ec-dac7-4f83-b0ec-0876f0f455cb.png)'
- en: Testing the model
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试模型
- en: To test and understand how our model performs (or whether it even works!), you
    can upload images in the Test tab of the previous page view. Let's try it!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试和了解我们的模型表现如何（或者它是否真的工作！），您可以在上一页视图的测试标签页上传图像。让我们试试！
- en: 'To test with images, click on Test:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用图像进行测试，请点击测试：
- en: '![](img/937da7de-c674-410d-99d8-7869e96140e8.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/937da7de-c674-410d-99d8-7869e96140e8.png)'
- en: 'Like we did to collect our happy and sad images, we can identify several random
    images (without regard to the expression shown in the image) to test our models
    ability to detect expression:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们收集快乐和悲伤图像一样，我们可以识别出一些随机图像（不考虑图像中显示的表情）来测试模型检测表情的能力：
- en: '![](img/48473fd5-e379-4919-a66a-fe5496c5d244.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/48473fd5-e379-4919-a66a-fe5496c5d244.png)'
- en: Test scores
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试分数
- en: The idea is for our model to interpret the preceding images, perform some expression
    analysis, and then classify each image as either happy or sad facial expressions.
    In addition, the model should generate and display a score for each of the defined
    classes (except for the negative class).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型旨在解释前面的图像，进行一些表情分析，然后根据图像是快乐表情还是悲伤表情进行分类。此外，模型应为每个定义的类别（除了负类别）生成并显示一个分数。
- en: 'As you have seen in our model, we defined just two classes to be classified—happy
    and sad. The model should, for each test image, display a percentage score showing
    the percentage of whether the detected expression is happy or sad. For example,
    the following score indicates that there is approximately 90 percent chance that
    the expression identified is happy:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在我们模型中看到的那样，我们定义了两个要分类的类别——快乐和悲伤。对于每个测试图像，模型应显示一个百分比分数，显示检测到的表情是快乐还是悲伤的百分比。例如，以下分数表明有大约90%的可能性，所识别的表情是快乐的：
- en: '![](img/c86b5570-4744-41c9-ad04-b9fbb17b7f75.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c86b5570-4744-41c9-ad04-b9fbb17b7f75.png)'
- en: Test the model
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试模型
- en: 'To test the model with the following images, we can simply drag and drop the
    image files onto the preceding page to let the classifier analyze them:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用以下图像测试模型，我们可以简单地将图像文件拖放到前面的页面上，让分类器分析它们：
- en: '![](img/6d1caeb0-f9a4-499b-bfa1-b248955c13e9.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6d1caeb0-f9a4-499b-bfa1-b248955c13e9.png)'
- en: 'Take a look at the following screenshot as well:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 还请查看以下截图：
- en: '![](img/e944204a-4135-4146-8942-516dfbbe06c0.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e944204a-4135-4146-8942-516dfbbe06c0.png)'
- en: Success! It appears that all four of our random faces have been evaluated and
    scored by our Face model correctly. We can see that, in the first two images,
    the model indicates 11 and 90 percent that the individuals are happy and sad,
    respectively.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 成功！看起来我们的四个随机面孔都被我们的面部模型正确评估和评分了。我们可以看到，在前两张图像中，模型表示有11%和90%的可能性认为个体是快乐的和悲伤的。
- en: Improving the model
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进模型
- en: Even though it appears that our little solution is working correctly, we still
    have to keep in mind that the model has been trained on a very small amount of
    data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的解决方案看起来运行正确，但我们仍需记住，模型是在非常少量的数据上训练的。
- en: 'To improve the model, from the Default Custom Model page, you can click on
    the blue button labeled Edit and Retrain:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要改进模型，从默认自定义模型页面，您可以点击标有“编辑和重新训练”的蓝色按钮：
- en: '![](img/9c4fd313-60c5-456b-a5a7-51edef621695.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9c4fd313-60c5-456b-a5a7-51edef621695.png)'
- en: This will make our project editable.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们的项目可编辑。
- en: More training data
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多训练数据
- en: 'Some improvements to our solution would include adding additional images to
    the happy and sad groups. To do this, you can create a new ZIP file with new and
    additional images and upload it to IBM Watson Studio (in the same fashion as we
    did earlier in this chapter), upload the file, and drop the new ZIP file into
    the respective class. Watson will add the new images (and not overwrite what''s
    already been defined):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们的解决方案的一些改进包括向快乐和悲伤组添加更多图像。为此，您可以创建一个新的ZIP文件，包含新的和额外的图像，并将其上传到IBM Watson Studio（与本章前面所做的方式相同），上传文件，并将新的ZIP文件拖放到相应的类别中。Watson将添加新的图像（而不会覆盖已定义的内容）：
- en: '![](img/d9978cb0-9da4-40f7-85cd-e7cf8b0f8f04.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d9978cb0-9da4-40f7-85cd-e7cf8b0f8f04.png)'
- en: Adding more classes
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加更多类别
- en: 'Another great improvement for our solution would be to add additional classes.
    This is to allow our model to support the detection of, perhaps, a third emotion
    or expression other than happy and sad. Let''s try to add anger as our third (not
    counting negative) class:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决方案的另一个重大改进是添加额外的类别。这是为了让我们的模型能够支持检测除了快乐和悲伤之外的第三种情感或表情。让我们尝试添加愤怒作为我们的第三个（不计负面）类别：
- en: 'The first step, of course, is to collect and compress (zip up) our angry images
    training data:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当然，第一步是收集和压缩（zip文件）我们的愤怒图像训练数据：
- en: '![](img/b9d06d43-eb94-4e57-a5a5-e24e389a3b18.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b9d06d43-eb94-4e57-a5a5-e24e389a3b18.png)'
- en: Remember that it is not important what the individual image files are named,
    but it is important that they all represent the same emotion, *anger*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，单个图像文件的名字并不重要，重要的是它们都代表相同的情感，*愤怒*。
- en: 'After we upload the `angry.zip` file (as another data asset available to our
    project), we can then go ahead and click on Create a class, enter `angry` for
    the class name, and then click on Create:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们上传了`angry.zip`文件（作为我们项目可用的另一个数据资产）之后，我们就可以继续点击创建一个类别，输入`angry`作为类别名称，然后点击创建：
- en: '![](img/300d414b-72c5-4892-939d-f02cc5d135d9.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/300d414b-72c5-4892-939d-f02cc5d135d9.png)'
- en: 'After a moment or two, our new `angry` class is ready:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 片刻之后，我们新的`angry`类别就准备好了：
- en: '![](img/8afbac0c-9176-4595-b1b6-2424ad008523.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8afbac0c-9176-4595-b1b6-2424ad008523.png)'
- en: 'Now we can once more click on the Train Model button to start retraining the
    Face model on the training images we provided, along with our new angry class.
    After a few moments, we should see the Model Trained message again:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以再次点击训练模型按钮，开始使用我们提供的训练图像以及我们新的愤怒类别重新训练面部模型。片刻之后，我们应该再次看到模型已训练的消息：
- en: '![](img/cf224e13-b4d5-47ef-a5fa-d053b03d6814.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cf224e13-b4d5-47ef-a5fa-d053b03d6814.png)'
- en: Results
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: 'Once again, we can go to the Default Custom Model page, click on the Test tab,
    and drop some new test images for the model to evaluate and classify:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以前往默认自定义模型页面，点击测试选项卡，并投放一些新的测试图像供模型评估和分类：
- en: '![](img/8a4801df-ec7f-4ac1-a3eb-aaaddd42ac7b.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8a4801df-ec7f-4ac1-a3eb-aaaddd42ac7b.png)'
- en: You can see that the model has correctly classified the first image as 0.77
    angry. We also retested a previous image as a bit of a regression test and the
    model again correctly classified it (as 0.66 happy).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到模型已经正确地将第一张图像分类为0.77愤怒。我们还对一张之前的图像进行了回归测试，模型再次正确地将其分类（为0.66快乐）。
- en: 'Notice that now our model provides three scores for each test image: angry,
    happy, and sad, corresponding to each of our model''s defined classes:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在我们的模型为每个测试图像提供了三个分数：愤怒、快乐和悲伤，对应于我们模型定义的每个类别：
- en: '![](img/780287b9-88da-4316-9564-9ee67aa16bfd.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/780287b9-88da-4316-9564-9ee67aa16bfd.png)'
- en: Summary
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the concepts behind expression analysis and detection
    and used IBM Watson Studio, the Watson Visual Recognition service, and the default
    face model to build, train, and test an end-to-end, working visual expression
    classification solution with almost zero programming!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了表情分析和检测背后的概念，并使用IBM Watson Studio、Watson视觉识别服务和默认的面部模型构建、训练和测试了一个几乎零编程的端到端、可工作的视觉表情分类解决方案！
- en: In the next chapter, we will discover automated classification of lithofacies
    formation using ML on the IBM Cloud platform.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将发现使用IBM云平台上的机器学习自动分类岩相形成。
