- en: Basic Facial Detection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本面部检测
- en: The previous chapters can best be described as trying to read an image. This
    is a subfield in machine learning called **computer vision** (**CV**). With convolutional
    neural networks ([Chapter 7](4c71e400-fde5-467f-a1ee-52300e326504.xhtml), *Convolutional
    Neural Networks – MNIST Handwriting Recognition*), we found that the convolutional
    layers learned how to filter an image.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章可以最好地描述为尝试读取图像。这是机器学习中的一个子领域，称为**计算机视觉（CV**）。通过卷积神经网络（[第7章](4c71e400-fde5-467f-a1ee-52300e326504.xhtml)，*卷积神经网络
    – MNIST手写识别*），我们发现卷积层学会了如何过滤图像。
- en: There is a common misconception that any **machine learning** (**ML**) worth
    doing has to come from neural networks and deep learning. This is decidedly not
    the case. Instead, one should view deep learning as a technique to get to one's
    goals; deep learning is not the end-all. The purpose of this chapter is to expose
    readers to some of the insights into making ML algorithms work better in production.
    The code for this chapter is exceedingly simple. The topic is trivial and widely
    considered by many to be solved. However, the insights are not trivial. It is
    my hope that this chapter propels the reader to think more deeply about the problems
    that they face.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种普遍的误解，认为任何值得做的**机器学习（ML**）都必须来自神经网络和深度学习。这显然不是事实。相反，应该将深度学习视为实现目标的一种技术；深度学习不是终点。本章的目的是让读者了解一些关于使机器学习算法在生产环境中更好地工作的见解。本章的代码非常简单。这个主题是微不足道的，许多人认为它已经被解决了。然而，这些见解并不简单。我希望本章能促使读者更深入地思考他们面临的问题。
- en: To that end, the algorithms that will be introduced in this chapter began their
    life in academia. However, the invention of these algorithms was driven by a highly
    practical requirement, and one can learn quite a lot by analyzing how these algorithms
    were invented.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本章将要介绍的一些算法最初起源于学术界。然而，这些算法的发明是由一个高度实际的需求驱动的，通过分析这些算法是如何被发明的，我们可以学到很多东西。
- en: In this chapter, we're going to further improve our knowledge about what can
    be done with computer vision, by building multiple facial detection systems in
    Go. We will be using `GoCV` and `Pigo`. What we will be building is a program
    that detects faces from a live webcam. However, this chapter will be different
    from the previous ones, in that we will be comparing two kinds of algorithms.
    The purpose is to allow the reader to think more about the actual problems faced,
    rather than just copy-pasting code.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过在Go语言中构建多个面部检测系统，进一步加深我们对计算机视觉可以做什么的了解。我们将使用`GoCV`和`Pigo`。我们将构建的程序能够从实时网络摄像头中检测人脸。然而，本章将与前几章有所不同，因为我们将比较两种算法。目的是让读者更多地思考实际面临的问题，而不仅仅是复制粘贴代码。
- en: What is a face?
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是人脸？
- en: In order to detect faces, we need to understand what a face is, specifically
    what a human face is. Think about a typical human face. A typical human face has
    two eyes, a nose, and a mouth. But having these features isn't enough to define
    a human face. Dogs also have two eyes, a nose, and a mouth. We are, after all,
    products of mammalian evolution.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测人脸，我们需要了解什么是人脸，特别是什么是人类人脸。想想一个典型的人类人脸。一个典型的人类人脸有两只眼睛、一个鼻子和一个嘴巴。但是拥有这些特征并不足以定义一个人脸。狗也有两只眼睛、一个鼻子和一个嘴巴。毕竟，我们是哺乳动物进化的产物。
- en: I encourage the reader to think more carefully about what makes a human face.
    We instinctively know what a face is, but to really quantify exactly what constitutes
    a face takes work. Often, it may lead to philosophical ruminations about essentialism.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励读者更仔细地思考是什么构成了人脸。我们本能地知道什么是人脸，但要真正量化构成人脸的确切要素需要工作。通常，这可能会导致关于本质主义的哲学沉思。
- en: If you watch terrible procedural TV shows, you might see faces being drawn with
    dots and lines when the detectives on TV are doing facial recognition across a
    database. These dots and lines are primarily due to the work of Woodrow Bledsoe,
    Helen Chan, and Charles Bisson in the 1960s. They were among the first people
    to study automated facial detection. One of the first things noticed is that the
    standard features of the face—hairline, browlines, gauntness of eyes, height of
    nose bridge, and so on—are all dynamically definable; that is to say that these
    features are measured relative to one another. This made automatically detecting
    features a little bit more challenging than expected.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看过糟糕的程序化电视剧，可能会看到当电视上的侦探在数据库中进行面部识别时，人脸是用点和线描绘出来的。这些点和线主要归功于伍德罗·布莱索、海伦·陈和查尔斯·比松在20世纪60年代的工作。他们是第一批研究自动面部检测的人之一。首先注意到的是，面部标准特征——发际线、眉毛、眼睛的凹陷程度、鼻梁的高度等等，都是可以动态定义的；也就是说，这些特征是相对于彼此来测量的。这使得自动检测特征比预期的要更具挑战性。
- en: 'Their solution was novel: using a device that is an ancestor to today''s drawing
    tablets, annotate the location of eyes, nose, mouth, and other facial features.
    The distances between these annotations are then used as features for facial recognition.
    The process today is no different, except a lot more automatic. The works of Bledsoe,
    Chan, and gang led to an immense effort to quantify how pixels would co-occur
    to form facial features.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的解决方案是新颖的：使用一种类似于今天绘图板的设备，标注眼睛、鼻子、嘴巴和其他面部特征的位置。然后，这些标注之间的距离被用作面部识别的特征。今天的过程与此不同，只是自动化程度更高。布莱索、陈及其团队的工作导致了大量努力，以量化像素如何共同出现以形成面部特征。
- en: 'In order to understand the features that make up a face, abstract. What is
    the minimum possible number of dots and lines required to depict a face? It is
    instructive to note abstractions in the use of kaomoji. Consider the following
    kaomoji:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解构成人脸的特征，我们需要进行抽象。描绘人脸所需的最小点数和线数是多少？观察kaomoji的使用可以提供有益的启示。考虑以下kaomoji：
- en: '![](img/ad935efb-80ae-4768-9ae2-3835a66890e0.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad935efb-80ae-4768-9ae2-3835a66890e0.png)'
- en: 'It''s quite easy to see that these depict faces. Contrast them with kaomojis
    that depict other things (fish, spider, gun, and bomb respectively):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出这些描绘的是人脸。将它们与描绘其他事物（鱼、蜘蛛、枪和炸弹）的kaomoji进行对比：
- en: '![](img/6f6fb6b1-cf8f-4b9b-a16c-f0a3a5e8c0be.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f6fb6b1-cf8f-4b9b-a16c-f0a3a5e8c0be.png)'
- en: The process of abstraction—the act of removing details until only the ones that
    matter remain—allows one to think more clearly about a subject matter. This is
    true in art, as it is in mathematics. It is equally true of software engineering,
    though careful implementation of the abstractions needs to be made. Going back
    to the kaomojis, note that, even in their highly abstract form, they are capable
    of displaying emotions. In order of display, the kaomojis show happiness, indifference,
    love, dissatisfaction, and anger. These abstract depictions offer us a path to
    think about the facial features in pictures. To determine whether a face exists,
    we simply determine if those lines are there. The question now becomes how do
    we take a photo and draw lines?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象的过程——即移除细节直到只剩下重要的部分——有助于人们更清晰地思考一个主题。这在艺术和数学中都是如此。在软件工程中也是如此，尽管需要对抽象进行仔细的实现。回到kaomoji，请注意，即使在其高度抽象的形式中，它们也能够表达情感。按照显示顺序，kaomoji展示了快乐、冷漠、爱、不满和愤怒。这些抽象描绘为我们提供了思考图片中面部特征的方法。为了确定是否存在人脸，我们只需确定那些线条是否存在。现在的问题变成了如何从照片中绘制线条？
- en: Start with the facial structure and assume an evenly-lit room. Barring diseases
    such as Graves which cause proptosis, eyes are generally sunken. This causes the
    area of the eyes to be shadowed by the brow ridge of the face, as well as cheekbones.
    In pictures of an evenly-lit face, eyes would appear in shadow. Noses, on the
    other hand, would appear more brightly lit, because noses are raised compared
    with the rest of the face. Likewise, lips have a dark area and a bright area,
    separated by a dark line. These are all useful features to consider when thinking
    about detecting faces.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从面部结构开始，假设在一个均匀照明的房间里。除了像格雷夫斯病这样的疾病会导致眼球突出外，眼睛通常是凹进去的。这导致眼睛区域被面部眉毛和颧骨的阴影所覆盖。在均匀照明的面部照片中，眼睛会显得在阴影中。另一方面，鼻子会显得更明亮，因为鼻子相对于面部其他部分是凸起的。同样，嘴唇有一个暗区和亮区，由一条暗线分开。这些都是在考虑检测人脸时有用的特征。
- en: Viola-Jones
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Viola-Jones
- en: Fast forward to the early 2000s. Facial detection methodologies leaped forwards
    with Viola and Jones introducing a very fast method of detecting objects. The
    `Viola-Jones` method, while generic enough for the detection of any object, was
    primarily geared to detecting faces. The key genius to the Viola-Jones method
    is that it used many small classifiers to classify a region of an image, in a
    staged fashion. This is called the **cascade classifier**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 快进到2000年代初。随着Viola和Jones引入了一种非常快速的对象检测方法，面部检测方法取得了飞跃。`Viola-Jones`方法虽然足够通用，可以检测任何对象，但主要是为了检测面部。Viola-Jones方法的关键天才之处在于它使用了多个小分类器以分阶段的方式对图像区域进行分类。这被称为**级联分类器**。
- en: To make the explanation clearer, whenever *classifier* is used in the context
    of the Viola-Jones method, I mean the small classifiers in the cascade classifier.
    When referring to the cascade classifier, it will be explicitly mentioned as such.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使解释更清晰，每当在Viola-Jones方法中提到*分类器*时，我指的是级联分类器中的小分类器。当提到级联分类器时，将明确指出这一点。
- en: A cascade classifier is made up of many small classifiers. Each classifier is
    made up of multiple filters. For a brief introduction to filters, see the previous
    chapter (How Instagram filters work). To detect faces, first start with a small
    section (called a **window**) of the image. Run the classifiers one by one. If
    the sum of the result of applying all the filters in the classifier exceeds a
    predefined threshold for the classifier, then it's considered to be part of a
    face. Then, the cascade classifier moves on to the next classifier. This is the
    *cascading* part of the cascading classifier. Once all the classifiers are done,
    the window slides to the next pixel, and the process begins anew. Should a classifier
    in the cascade classifier fail to identify something as part of the face, the
    entire region is rejected and the sliding window slides on.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 级联分类器由许多小分类器组成。每个分类器由多个过滤器组成。关于过滤器的简要介绍，请参阅上一章（Instagram滤镜是如何工作的）。为了检测面部，首先从图像的一个小部分（称为**窗口**）开始。依次运行分类器。如果将分类器中所有过滤器应用的结果之和超过分类器的预定义阈值，则认为它是面部的一部分。然后，级联分类器继续到下一个分类器。这是级联分类器的*级联*部分。一旦所有分类器都完成，窗口滑动到下一个像素，过程重新开始。如果级联分类器中的某个分类器未能识别出面部的一部分，则整个区域被拒绝，滑动窗口继续滑动。
- en: 'The filters work by detecting the aforementioned light and dark areas of the
    face. Take, for example, the fact that the areas around the eyes are typically
    sunken and therefore shadowed. If we are to apply a filter to an area, we would
    highlight only the eyes:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤器通过检测面部上提到的明暗区域来工作。例如，眼睛周围区域通常是凹的，因此有阴影。如果我们要在某个区域应用过滤器，我们只会突出眼睛：
- en: '![](img/0e8d31e7-0b40-4472-ba28-1944360cc496.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0e8d31e7-0b40-4472-ba28-1944360cc496.png)'
- en: 'A classifier for eyes would have multiple filters, configured to test against
    the possible configurations of eyes. A classifier for the nose would have multiple
    filters specific to the nose. In a cascading classifier, we could arrange the
    importance; perhaps we define the eyes as the most important part of the face
    (they are after all windows to the soul). We could arrange it so that the cascade
    classifier first classifies a region for eyes. If there are eyes, we then look
    for the nose, then the mouth. Otherwise, the sliding window should slide on:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 用于眼睛的分类器会有多个过滤器，配置为测试眼睛的可能配置。用于鼻子的分类器会有多个针对鼻子的特定过滤器。在级联分类器中，我们可以安排重要性；也许我们将眼睛定义为面部最重要的部分（毕竟，它们是灵魂之窗）。我们可以这样安排，使得级联分类器首先对眼睛区域进行分类。如果有眼睛，我们接着寻找鼻子，然后是嘴巴。如果没有，滑动窗口应该继续滑动：
- en: '![](img/7c046b65-f1ce-4af1-937f-852c6459bd41.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7c046b65-f1ce-4af1-937f-852c6459bd41.png)'
- en: Another point of innovation with Viola-Jones is that the method was designed
    to work on an image pyramid. What is an image pyramid? Imagine you have yourself
    a large 1024 x 768 image. This image has two faces of multiple scales. There is
    one person standing very close to the camera, and one person standing far away.
    Anyone with any familiarity with the optics of cameras would instantly realize
    that the person standing close to the camera will have a much larger face in the
    image compared to the person standing far away from the camera. The question is,
    how would we be able to detect both faces at different scales?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Viola-Jones的另一个创新点是该方法被设计用于在图像金字塔上工作。什么是图像金字塔？想象一下你有一个大型的1024 x 768像素的图像。这个图像具有多个不同尺度的两个面。有一个人站在相机非常近的位置，另一个人站在较远的位置。任何对相机光学有所了解的人都会立刻意识到，站在相机近处的人的脸在图像中会比站在远处的人的脸大得多。问题是，我们如何能够检测到不同尺度的两个脸？
- en: 'One possible answer is to design multiple filters, one for each possible scale.
    But that leaves a lot of room for error. Instead of designing multiple filters,
    the same filters can be reused, if the image is resized multiple times:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可能的答案是设计多个过滤器，每个可能的尺度一个。但这留下了很多错误的空间。而不是设计多个过滤器，如果图像被多次调整大小，相同的过滤器可以被重复使用：
- en: '![](img/5d447976-f901-4f10-89ed-324b22650208.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5d447976-f901-4f10-89ed-324b22650208.png)'
- en: The face that is very close to the camera wouldn't be detected by a filter designed
    to detect a small face. Instead, in the original resolution, the classifier will
    detect the smaller face. Then, the image is resized so that the resolution is
    now smaller, say 640 x 480\. The big face is now small, and the small faces are
    now single dots. The classifier will now be able to detect the large face and
    not the small faces. But in total, the classifier would have detected all the
    faces in the image. Because the images are directly resized, coordinates in the
    smaller image can be easily translated into coordinates in the original image.
    This allows for detection in the smaller scale to be directly translated into
    detections in the original scale.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 非常靠近相机的脸不会被设计用于检测小脸的过滤器检测到。相反，在原始分辨率下，分类器会检测到较小的脸。然后，图像被调整大小，使得分辨率现在更小，比如说640
    x 480像素。大脸现在变成了小脸，小脸现在变成了单独的点。分类器现在能够检测到大脸而不是小脸。但总的来说，分类器已经检测到了图像中的所有脸。因为图像是直接调整大小的，所以在较小图像中的坐标可以很容易地转换成原始图像中的坐标。这允许在较小尺度上的检测直接转换成原始尺度上的检测。
- en: At this point, if you have read the previous chapter, this starts to feel somewhat
    familiar. **Convolutional Neural Networks** (**CNNs**) work in a remarkably similar
    way. In a CNN, multiple filters are applied to a sub-region, producing a filtered
    image. The filtered image is then passed through a reduction layer (max-pooling,
    or some other reduction method). The key in CNNs is to learn what the filters
    would be. In fact, the first layer of each CNN learns filters that are extremely
    similar to the filters used in the Viola-Jones method.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，如果你已经阅读了上一章，这开始感觉有些熟悉。**卷积神经网络**（**CNNs**）以非常相似的方式工作。在CNN中，多个过滤器被应用于子区域，生成一个过滤后的图像。然后，过滤后的图像通过一个减少层（最大池化或其他减少方法）。CNN中的关键是学习过滤器会是什么样子。实际上，每个CNN的第一层学习到的过滤器与Viola-Jones方法中使用的过滤器非常相似。
- en: 'The primary similarities are that Viola-Jones essentially amounts to having
    a sliding window and applying filters to the section of the image. This is comparable
    to convolutions in a CNN. Where CNNs have an advantage is that they are capable
    of learning those filters, whereas in the Viola-Jones method the filters are manually
    created. The Viola-Jones method on the other hand has the benefit of cascading:
    it may terminate searching a section for faces early if one of the classifiers
    fails. This saves a lot of computation. Indeed, such was the influence of the
    Viola-Jones method that it inspired the *Joint Face Detection and Alignment Using
    Multitask Cascaded Convolutional Networks* by Zhang et al. in 2016, which used
    three neural networks in cascading fashion to recognize faces.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的相似之处在于Viola-Jones基本上相当于有一个滑动窗口并将过滤器应用于图像的某个部分。这类似于CNN中的卷积。CNN的优势在于它们能够学习这些过滤器，而Viola-Jones方法中的过滤器是手动创建的。另一方面，Viola-Jones方法的好处是级联：如果其中一个分类器失败，它可能会提前终止搜索某个区域的搜索。这节省了很多计算。事实上，Viola-Jones方法的影响如此之大，以至于它启发了2016年由Zhang等人撰写的*使用多任务级联卷积网络的联合人脸检测与对齐*，该方法使用了三个神经网络以级联方式识别人脸。
- en: It would be tempting to equate the image pyramid with what the pooling layers
    do in a CNN. This wouldn't be correct. Multi-scale detection in the Viola-Jones
    method is a neat trick, while pooling layers in a CNN lead to the learning of
    higher order features. CNNs learn higher order features such as eyes, noses, and
    mouths, whereas the Viola Jones method doesn't.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易将图像金字塔与CNN中的池化层所做的工作等同起来。这并不正确。Viola-Jones方法中的多尺度检测是一个巧妙的方法，而CNN中的池化层则导致学习到更高阶的特征。CNN学习到更高阶的特征，如眼睛、鼻子和嘴巴，而Viola-Jones方法则没有。
- en: In light of this, one may wonder if CNNs may be better. They do detect faces
    the way humans do—by identifying eyes, noses, and mouths as features, as opposed
    to filtering patterns on pixels. There are still reasons to use Viola-Jones today.
    At this point in time, the Viola-Jones method is well understood and well optimized
    in libraries. It comes built into GoCV, which is what we'll use. The method is
    also faster than deep learning-based models, at some expense of flexibility. Most
    Viola-Jones models only detect faces if those faces are front-facing. Additionally,
    the Viola-Jones method may not detect rotated faces (terrible if you want to detect
    the face of a head-turning demon as proof to give an exorcist).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，人们可能会想知道CNN是否可能更好。它们确实以人类的方式检测人脸——通过识别眼睛、鼻子和嘴巴作为特征，而不是过滤像素上的模式。仍然有理由在今天使用Viola-Jones。到目前为止，Viola-Jones方法在库中得到了很好的理解和优化。它内置在GoCV中，这是我们将会使用的。该方法也比基于深度学习的模型更快，但牺牲了一些灵活性。大多数Viola-Jones模型只检测正面的人脸。此外，Viola-Jones方法可能无法检测旋转的人脸（如果你想要检测一个转头恶魔的脸作为驱魔者的证据，那就太糟糕了）。
- en: Depending on use cases, one might not need deep learning-based systems to perform
    facial detection at all!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据用例，可能根本不需要基于深度学习的系统来执行人脸检测！
- en: PICO
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PICO
- en: Another technique we'll be using is **Pixel Intensity Comparison-based Object
    detection** (**PICO**), originally developed by Markus, Frljak, et al. in 2014\.
    It uses the same broad principles as the Viola-Jones method, in that there is
    a cascade classifier. It differs in two ways. First, a sliding window is not used.
    This is due to the latter differences. Second, the classifiers of the cascade
    classifier are different from that of Viola-Jones. In Viola-Jones, a method of
    applying filters repeatedly and then summing the result is used as a classifier.
    By contrast, in PICO, decision trees are used.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的一种另一种技术是**基于像素强度比较的对象检测**（**PICO**），它最初由Markus、Frljak等人于2014年开发。它使用与Viola-Jones方法相同的广泛原则，即存在级联分类器。它有两个不同之处。首先，不使用滑动窗口。这是由于后者的差异。其次，级联分类器的分类器与Viola-Jones的不同。在Viola-Jones中，使用重复应用滤波器然后求和的结果作为分类器的方法。相比之下，在PICO中，使用决策树。
- en: A decision tree is a tree where each node is a feature, and the branching of
    the feature is defined by a threshold. In the case of PICO, the decision tree
    applies for each pixel in the photo. For each pixel considered, the intensity
    is compared against the intensity of another pixel at another location. These
    locations are generated from a uniform distribution, obviating the need for a
    sliding window.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种树，其中每个节点都是一个特征，特征的分支由一个阈值定义。在PICO的情况下，决策树应用于照片中的每个像素。对于每个考虑到的像素，其强度将与另一个位置另一个像素的强度进行比较。这些位置由均匀分布生成，从而消除了滑动窗口的需要。
- en: The PICO method also does away with needing image pyramids and integral images.
    The classifiers are capable of detecting faces straight away from an image. This
    makes it very fast.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: PICO方法也消除了需要图像金字塔和积分图像的需求。分类器能够直接从图像中检测人脸。这使得它非常快。
- en: Nonetheless, the legacy of Viola-Jones is evident. The classifiers are applied
    in stages. First, the simpler classifiers are used. This would eliminate areas
    where the probability of faces existing is low. Next, more complex classifiers
    are used on the reduced search areas. This is repeated until the last stage is
    reached. The results of each classifier are retained for later use.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，Viola-Jones的遗产是显而易见的。分类器是分阶段应用的。首先，使用简单的分类器。这将消除存在人脸概率较低的区域。接下来，在减少的搜索区域上使用更复杂的分类器。这会重复进行，直到达到最后阶段。每个分类器的结果都会保留以供后续使用。
- en: 'The reader might come to realize that areas in a picture that definitely has
    a face will be searched by more classifiers. It is with this intuition that the
    authors introduced a final clustering step in the PICO classifier. The rule is
    simple: if there is an overlap of areas searched by the classifier, and the overlap
    percentage is greater than 30%, it''s considered to be part of the same cluster.
    Thus, the final result is robust to small changes.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 读者可能会意识到，在图片中肯定有脸的区域将被更多的分类器搜索。正是基于这种直觉，作者在PICO分类器中引入了一个最终的聚类步骤。规则很简单：如果分类器搜索的区域有重叠，并且重叠百分比大于30%，则认为它们是同一个簇的一部分。因此，最终结果对小的变化具有鲁棒性。
- en: A note on learning
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于学习的笔记
- en: You may have noted that in describing the algorithms previously, I have neglected
    to mention the training procedures for how these models learn. This omission is
    rather deliberate. As we will not be training any models, how the Viola-Jones
    method and the PICO method are trained to produce models will be left as an exercise
    for the reader.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在之前描述算法时，我故意没有提到这些模型的训练过程。这种省略是有意为之的。因为我们不会训练任何模型，所以Viola-Jones方法和PICO方法是如何训练以产生模型的，将留给读者作为练习。
- en: Instead, in this chapter we wish to use already created models. These models
    are commonly used in practice. We will then compare and contrast the methods to
    find out their pros and cons.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在本章中，我们希望使用已经创建的模型。这些模型在实践中被广泛使用。然后我们将比较和对比这些方法，以找出它们的优缺点。
- en: GoCV
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GoCV
- en: In this chapter, we will be using GoCV. GoCV is a binding for OpenCV and comes
    with a suite of features from OpenCV that can be used. One of the features from
    OpenCV is the Viola-Jones classifier, which we will use to our advantage.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用GoCV。GoCV是OpenCV的一个绑定，并附带了一组可以从OpenCV使用的功能。OpenCV的一个功能是Viola-Jones分类器，我们将利用这个分类器。
- en: 'Installing GoCV is a little tricky, however. It requires OpenCV to be installed
    beforehand. At the time of writing, the version supported by GoCV is OpenCV 3.4.2\.
    Installing OpenCV can be quite a painful experience. Perhaps the best place to
    find out *how* to install OpenCV is a website called **Learn OpenCV**. They have
    great guides on installing OpenCV on all platforms:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 安装GoCV有点棘手，然而。它需要先安装OpenCV。在撰写本文时，GoCV支持的版本是OpenCV 3.4.2。安装OpenCV可能是一个相当痛苦的过程。也许最好的地方去了解**如何**安装OpenCV是一个叫做**Learn
    OpenCV**的网站。他们提供了关于在所有平台上安装OpenCV的出色指南：
- en: 'Installing OpenCV on Ubuntu: [https://www.learnopencv.com/install-opencv3-on-ubuntu/](https://www.learnopencv.com/install-opencv3-on-ubuntu/)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在Ubuntu上安装OpenCV: [https://www.learnopencv.com/install-opencv3-on-ubuntu/](https://www.learnopencv.com/install-opencv3-on-ubuntu/)'
- en: 'Installing OpenCV on Windows: [https://www.learnopencv.com/install-opencv3-on-windows/](https://www.learnopencv.com/install-opencv3-on-windows/)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在Windows上安装OpenCV: [https://www.learnopencv.com/install-opencv3-on-windows/](https://www.learnopencv.com/install-opencv3-on-windows/)'
- en: 'Installing OpenCV on MacOS: [https://www.learnopencv.com/install-opencv3-on-macos/](https://www.learnopencv.com/install-opencv3-on-macos/)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在MacOS上安装OpenCV: [https://www.learnopencv.com/install-opencv3-on-macos/](https://www.learnopencv.com/install-opencv3-on-macos/)'
- en: After the daunting process of installing OpenCV is done, installing GoCV is
    a piece of cake. Simply run `go get -u gocv.io.x.gocv`, and Bob's your uncle.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成令人敬畏的OpenCV安装过程之后，安装GoCV就像小菜一碟。只需运行`go get -u gocv.io.x.gocv`，然后Bob就是你的叔叔。
- en: API
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: API
- en: The API of GoCV matches the API of OpenCV quite well. A particularly good API
    to showcase is the display window. With the display window, one is able to display
    the image the webcam is receiving live. It's also a very useful tool for debugging,
    in cases where one might want to write a new classifier.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: GoCV的API与OpenCV的API非常匹配。一个特别好的API展示是显示窗口。有了显示窗口，人们能够显示摄像头实时接收到的图像。它也是一个非常有用的调试工具，在可能需要编写新分类器的情况下。
- en: I have developed programs for many years. It's fair to say I've seen many design
    patterns and packages. Among the prickliest problems to have for almost all programming
    languages is the foreign function interface, when a program has to call a library
    written in another language. Not many are well done. Most are shoddily done, as
    if something is plastered over the underlying **foreign function interface** (**FFI**).
    In Go, FFI is handled by cgo.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经开发了多年的程序。可以说，我见过很多设计模式和包。对于几乎所有编程语言来说，最棘手的问题之一就是外函数接口（FFI），当程序需要调用用另一种语言编写的库时。做得好的不多。大多数都做得粗糙，好像是在底层的**外函数接口**（**FFI**）上贴了些东西。在Go语言中，FFI是通过cgo来处理的。
- en: Very often, library authors (myself included) get too smart, and attempt to
    manage resources on behalf of the users. While at first blush this may seem to
    be good UX, good customer service even, this ultimately leads to much pain. At
    the time of writing, Gorgonia itself had just undergone a series of refactors
    to make the resource metaphors more clear, specifically with regards to CUDA usage.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 很常见，库的作者（包括我自己）会变得过于聪明，并试图代表用户管理资源。虽然乍一看这似乎是好的用户体验，甚至是好的客户服务，但最终这会导致很多痛苦。在撰写本文时，Gorgonia
    本身刚刚经历了一系列重构，以使资源隐喻更加清晰，特别是关于 CUDA 的使用。
- en: With all this said, GoCV is probably one of the most consistent Go libraries
    with regards to its cgo usage. The part where GoCV is consistent is in its treatment
    of foreign objects. Everything is treated as a resource; hence, most types have
    a `.Close()` method. There are certainly other beauties of GoCV, including the
    `customenv` build tags, which allow library users to define where OpenCV is installed,
    but the chief compliment I have for GoCV is in its consistency with regards to
    treating OpenCV objects as an external resource.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 说了这么多，GoCV 可能是关于 cgo 使用方面最一致的 Go 库之一。GoCV 一致的部分在于其对外部对象的处理。一切都被视为资源；因此，大多数类型都有
    `.Close()` 方法。GoCV 确实还有其他优点，包括 `customenv` 构建标签，它允许库用户定义 OpenCV 的安装位置，但我对 GoCV
    的主要赞扬在于其在将 OpenCV 对象视为外部资源方面的连贯性。
- en: The treatment of objects with the resource metaphor guides us in our use of
    the GoCV API. All objects must be closed after use,which is a  simple rule to
    abide by.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用资源隐喻处理对象指导我们在 GoCV API 中的使用。所有对象在使用后都必须关闭，这是一个简单的规则要遵守。
- en: Pigo
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pigo
- en: Pigo is a Go library for detecting faces by using the PICO algorithm. Compared
    to the Viola-Jones method, PICO is fast. Naturally, PIGO is fast too. Add this
    to the fact that GoCV uses cgo, which adds a penalty for speed, and PIGO may seem
    to be a better option overall. However, it must be noted that the PICO algorithm
    is more prone to false positives than the original Viola-Jones method.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Pigo 是一个使用 PICO 算法检测人脸的 Go 库。与 Viola-Jones 方法相比，PICO 很快。自然地，PIGO 也很快。考虑到 GoCV
    使用 cgo，这会带来速度上的惩罚，PIGO 可能看起来是一个更好的整体选择。然而，必须注意的是，PICO 算法比原始的 Viola-Jones 方法更容易产生误报。
- en: Using the PIGO library is simple. The provided documentation is clear. However,
    PIGO was designed to run within the author's workflow. Differing from that workflow
    will require some tiny amount of extra work. Specifically, the author draws images
    using external helpers such as `github.com/fogleman/gg`. We shan't. However, the
    work isn't much.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PIGO 库很简单。提供的文档很清晰。然而，PIGO 是设计在作者的工作流程中运行的。与该工作流程不同将需要一些额外的工作。具体来说，作者使用外部助手如
    `github.com/fogleman/gg` 绘制图像。我们不会这样做。但是，工作量并不大。
- en: To install `pigo`, simply run `go get -u github.com/esimov/pigo/...`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 `pigo`，只需运行 `go get -u github.com/esimov/pigo/...`。
- en: Face detection program
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测程序
- en: What we want to do is build a program that reads an image from a webcam, passes
    the image into a face detector and then draws rectangles in the image. Finally,
    we want to display the image with the rectangles drawn on.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要做的是编写一个程序，从摄像头读取图像，将图像传递给人脸检测器，然后在图像上绘制矩形。最后，我们想要显示带有绘制矩形的图像。
- en: Grabbing an image from the webcam
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从摄像头捕获图像
- en: 'First, we''ll open a connection to the webcam:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将打开与摄像头的连接：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: func main() {
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: func main() {
- en: // open webcam
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: // 打开摄像头
- en: webcam, err := gocv.VideoCaptureDevice(0)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: webcam, err := gocv.VideoCaptureDevice(0)
- en: if err != nil {
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: if err != nil {
- en: log.Fatal(err)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: log.Fatal(err)
- en: '}'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: defer webcam.Close()
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: defer webcam.Close()
- en: '}'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, I used `VideoCaptureDevice(0)` because, on my computer, which runs Ubuntu,
    the webcam is device `0`. Your webcam may differ in device numbering. Also, do
    note `defer webcam.Close()`. This is the aforementioned resource metaphor that
    GoCV sticks very strongly to. A webcam (specifically, a `VideoCaptureDevice`)
    is a resource, much like a file. In fact in Linux, this is true; the webcam on
    my computer is mounted in the `/dev/video0` directory and I can access raw bytes
    from it by just using a variant of `cat`. But I digress. The point is that `.Close()`
    has to be called on resources to free up usage.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我使用了 `VideoCaptureDevice(0)`，因为在我的电脑上，它运行的是 Ubuntu 系统，摄像头是设备 `0`。您的摄像头可能在不同设备编号上。另外，请注意
    `defer webcam.Close()`。这是 GoCV 非常坚持的资源隐喻。摄像头（特别是 `VideoCaptureDevice`）是一种资源，就像文件一样。实际上，在
    Linux 中，这是真的；我的电脑上的摄像头挂载在 `/dev/video0` 目录下，我可以通过使用 `cat` 的变体来访问它的原始字节。但我不打算深入。重点是，必须在资源上调用
    `.Close()` 以释放使用。
- en: The talk about closing resources to free up usage naturally raises a question,
    given we program in Go. Is a channel a resource? The answer is no. `close(ch)`
    of a channel  merely informs every sender that this channel is no longer receiving
    data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 关于关闭资源以释放使用的讨论自然引发了一个问题，鉴于我们是用 Go 编程。通道是一个资源吗？答案是，不是。通道的 `close(ch)` 只会通知每个发送者这个通道不再接收数据。
- en: 'Having access to the webcam is nice and all, but we also want to be able to
    grab images off it. I had mentioned one can read raw streams off the file of a
    webcam. We can do the same with GoCV as well:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 能够访问摄像头很棒，但我们还希望能够从它那里抓取图像。我提到过可以从摄像头的文件中读取原始流。我们也可以用 GoCV 做同样的事情：
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: img := gocv.NewMat()
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: img := gocv.NewMat()
- en: defer img.Close()
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: defer img.Close()
- en: width := int(webcam.Get(gocv.VideoCaptureFrameWidth))
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: width := int(webcam.Get(gocv.VideoCaptureFrameWidth))
- en: height := int(webcam.Get(gocv.VideoCaptureFrameHeight))
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: height := int(webcam.Get(gocv.VideoCaptureFrameHeight))
- en: 'fmt.Printf("Webcam resolution: %v, %v", width, height)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 'fmt.Printf("Webcam resolution: %v, %v", width, height)'
- en: if ok := webcam.Read(&amp;img); !ok {
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: if ok := webcam.Read(&amp;img); !ok {
- en: log.Fatal("cannot read device 0")
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: log.Fatal("cannot read device 0")
- en: '}'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First, we create a new matrix, representing an image. Again, the matrix is treated
    like a resource, because it is owned by the foreign function interface. Thus,
    `defer img.Close()` is written. Next, we query the webcam for information about
    the resolution. This is not as important right now, but it will be later. Nonetheless,
    it's quite nice to know what resolution a webcam runs at. Last, we read the webcam's
    image into the matrix.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个新的矩阵，代表一个图像。同样，矩阵被当作一个资源来处理，因为它是由外部函数接口拥有的。因此，我们写下了 `defer img.Close()`。接下来，我们查询摄像头的分辨率信息。现在这并不那么重要，但以后会很重要。尽管如此，知道摄像头运行在什么分辨率上还是相当不错的。最后，我们将摄像头的图像读入矩阵。
- en: At this point, if you are already familiar with Gorgonia's tensor libraries,
    this pattern may seem familiar, and yet feels funny. `img := gocv.NewMat()` does
    not define a size. How does GoCV know how much space to allocate for the matrix?
    Well, the answer is that the magic happens in `webcam.Read`. The underlying matrix
    will be resized as necessary by OpenCV. In this way, the Go part of the program
    does no real memory allocation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，如果你已经熟悉 Gorgonia 的张量库，这个模式可能看起来很熟悉，但感觉有点奇怪。`img := gocv.NewMat()` 并没有定义一个大小。GoCV
    是如何知道为矩阵分配多少空间的呢？答案是，这个魔法发生在 `webcam.Read` 中。底层的矩阵将由 OpenCV 根据需要调整大小。这样，程序的 Go
    部分实际上并没有进行真正的内存分配。
- en: Displaying the image
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示图像
- en: So, the image has been magically read into the matrix. How do we get anything
    out of it?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，图像已经神奇地读入矩阵。我们如何从中获取任何内容呢？
- en: 'The answer is that we have to copy the data from the data structure controlled
    by OpenCV into a Go-native data structure. Fortunately, GoCV handles that as well.
    Here, we write it out to a file:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是我们必须将 OpenCV 控制的从数据结构中的数据复制到一个 Go 原生数据结构中。幸运的是，GoCV 也处理了这一点。在这里，我们将它写入文件：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: First, the matrix has to be converted to `image.Image`. To do that, `img.ToImage()`
    is called. Then, it is encoded as a PNG by using `png.Encode`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，矩阵必须转换为 `image.Image`。为此，调用 `img.ToImage()`。然后，使用 `png.Encode` 将其编码为 PNG
    格式。
- en: 'And you will have a test image. This was mine:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到一个测试图像。这是我用的：
- en: '![](img/617e5f17-6a1f-4b93-9b32-2144890f51c9.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/617e5f17-6a1f-4b93-9b32-2144890f51c9.png)'
- en: In the picture, I'm holding a box with a photo of Ralph Waldo Emerson, famed
    American author. Readers who are familiar with writing instruments may note that
    it's actually a brand of inks I use for my writing.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在图片中，我拿着一个装着拉尔夫·瓦尔多·爱默生照片的盒子，他是著名的美国作家。熟悉书写工具的读者可能会注意到，这实际上是我写作时使用的墨水品牌。
- en: So, now we have the basic pipeline of getting an image from the webcam and writing
    out the image to a file. A webcam continuously captures images, but we're only
    reading a single image to a matrix, and then writing the matrix into a file. If
    we put this in a loop, we would have the ability to continuously read images from
    a webcam and write to file.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在我们已经有了从摄像头获取图像并将其写入文件的基本流程。摄像头持续捕捉图像，但我们只将一个图像读入矩阵，然后将矩阵写入文件。如果我们将其放入循环中，我们就有能力连续从摄像头读取图像并将其写入文件。
- en: Analogously to having a file, we could write it to the screen instead. The GoCV
    integration with OpenCV is so complete that this is trivial. Instead of writing
    to a file, we can display a window instead.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于有一个文件，我们可以将其写入屏幕。GoCV 与 OpenCV 的集成如此完整，以至于这很简单。我们不是写入文件，而是显示一个窗口。
- en: 'To do so, we need to first create a window object, with the title `Face Detection
    Window`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们首先需要创建一个窗口对象，标题为 `Face Detection Window`：
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, to show the image in the window, simply replace the parts where we write
    out to a file with this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，要显示图像在窗口中，只需替换我们写入文件的代码部分为以下内容：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When the program is run, a window will pop up, showing you the image captured
    by the webcam.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序运行时，将弹出一个窗口，显示由网络摄像头捕获的图像。
- en: Doodling on images
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在图像上涂鸦
- en: At some point, we would also like to draw on an image, preferably before we
    output it, either to the display or a file. GoCV handles that admirably. For our
    purposes in this chapter, we'll just be drawing rectangles to denote where a face
    might be. GoCV interfaces well with the standard library's `Rectangle` type.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时候，我们可能还想在图像上绘制，最好是在输出到显示或文件之前。GoCV 在这方面表现得非常好。在本章的用途中，我们只需绘制矩形来表示可能存在面部的地方。GoCV
    与标准库的 `Rectangle` 类型配合良好。
- en: 'To draw a rectangle on an image with GoCV, we first define a rectangle:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 GoCV 在图像上绘制矩形，我们首先定义一个矩形：
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, I defined a rectangle that starts at location (`50, 50`) and is 100 pixels
    wide and 100 pixels tall.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我定义了一个从位置（`50, 50`）开始，宽度为 100 像素，高度为 100 像素的矩形。
- en: 'Then, a color needs to be defined. Again, GoCV plays very nicely with `image`/`color`,
    found in the standard library. So, here''s the definition of the color `blue`:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，需要定义一个颜色。同样，GoCV 与标准库中的 `image`/`color` 结合得非常好。所以，这是颜色 `blue` 的定义：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And now, onward to draw the rectangle on the image!:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续在图像上绘制矩形！：
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This draws a blue rectangle with the top left of the rectangle at (50, 50) in
    the image.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在图像中绘制一个以矩形左上角为（50, 50）的蓝色矩形。
- en: 'At this point, we have the components necessary to build two different pipelines.
    One writes an image to a file. One creates a window to display the image. There
    are two ways the input from the webcam may be processed: one-off or continuously.
    And, we are also able to modify the image matrix before outputting. This gives
    us a lot of flexibility as scaffolding in the process of building the program.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经有了构建两个不同管道所需的组件。一个将图像写入文件。另一个创建一个窗口来显示图像。处理来自网络摄像头的输入有两种方式：一次性或持续进行。此外，我们还可以在输出之前修改图像矩阵。这为我们提供了在构建程序过程中的大量灵活性。
- en: Face detection 1
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部检测 1
- en: The first face detection algorithm we want to use is the Viola-Jones method.
    It comes built into GoCV, so we can just use that. The consistency of GoCV gives
    us a hint as to what to do next. We need a classifier object (and remember to
    close it!)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要使用的第一个面部检测算法是 Viola-Jones 方法。这个方法内置在 GoCV 中，因此我们可以直接使用它。GoCV 的一致性给我们提供了下一步要做什么的提示。我们需要一个分类器对象（并且记得要关闭它！）
- en: 'This is how to create a classifier object:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是创建分类器对象的方法：
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: classifier := gocv.NewCascadeClassifier()
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: classifier := gocv.NewCascadeClassifier()
- en: if !classifier.Load(haarCascadeFile) {
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: if !classifier.Load(haarCascadeFile) {
- en: 'log.Fatalf("Error reading cascade file: %v\n", haarCascadeFile)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 'log.Fatalf("Error reading cascade file: %v\n", haarCascadeFile)'
- en: '}'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: defer classifier.Close()
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: defer classifier.Close()
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note that at this point, it is not enough to just create a classifier. We need
    to load it with the model to use. The model used is very well established. It
    was first created by Rainer Lienhart in the early 2000s. Like most products of
    the 2000s, the model is serialized as an XML file.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个阶段，仅仅创建一个分类器是不够的。我们需要用模型来加载它。所使用的模型非常成熟。它最初由 Rainer Lienhart 在 2000 年代初创建。像大多数
    2000 年代的产品一样，该模型被序列化为 XML 文件。
- en: 'The file can be downloaded from the GoCV GitHub repository: [https://github.com/hybridgroup/gocv/blob/master/data/haarcascade_frontalface_default.xml](https://github.com/hybridgroup/gocv/blob/master/data/haarcascade_frontalface_default.xml)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件可以从 GoCV GitHub 仓库下载：[https://github.com/hybridgroup/gocv/blob/master/data/haarcascade_frontalface_default.xml](https://github.com/hybridgroup/gocv/blob/master/data/haarcascade_frontalface_default.xml)
- en: In the preceding code, `haarCascadeFile` is a string denoting the path to the
    file. GoCV handles the rest.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`haarCascadeFile` 是一个表示文件路径的字符串。GoCV 处理其余部分。
- en: 'To detect faces, it is a simple one-liner:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要检测面部，这是一个简单的单行代码：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: rects := classifier.DetectMultiScale(img)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: rects := classifier.DetectMultiScale(img)
- en: '[PRE13]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this single line of code, we are telling OpenCV to use Viola-Jones' multiscale
    detection to detect faces. Internally, OpenCV builds an image pyramid of integral
    images, and runs the classifiers on the image pyramids. At each stage, rectangles
    representing where the algorithm thinks the faces are, produced. These rectangles
    are what is returned. They can then be drawn on the image before being output
    to a file or window.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一行代码中，我们告诉OpenCV使用Viola-Jones的多尺度检测来检测人脸。内部，OpenCV构建了一个积分图像的图像金字塔，并在图像金字塔上运行分类器。在每一阶段，算法认为人脸所在位置的矩形被生成。这些矩形就是返回的内容。它们可以在输出到文件或窗口之前绘制到图像上。
- en: 'Here''s what a full windowed pipeline looks like:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了一个完整的窗口化管道的示例：
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: var haarCascadeFile = "Path/To/CascadeFile.xml"
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: var haarCascadeFile = "Path/To/CascadeFile.xml"
- en: var blue = color.RGBA{0, 0, 255, 0}
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: var blue = color.RGBA{0, 0, 255, 0}
- en: func main() {
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: func main() {
- en: // open webcam
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: // 打开摄像头
- en: webcam, err := gocv.VideoCaptureDevice(0)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: webcam, err := gocv.VideoCaptureDevice(0)
- en: if err != nil {
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: if err != nil {
- en: log.Fatal(err)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: log.Fatal(err)
- en: '}'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: defer webcam.Close()
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: defer webcam.Close()
- en: var err error
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: var err error
- en: // open display window
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: // 打开显示窗口
- en: window := gocv.NewWindow("Face Detect")
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: window := gocv.NewWindow("人脸检测")
- en: defer window.Close()
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: defer window.Close()
- en: // prepare image matrix
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: // 准备图像矩阵
- en: img := gocv.NewMat()
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: img := gocv.NewMat()
- en: defer img.Close()
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: defer img.Close()
- en: // color for the rect when faces detected
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: // 当检测到人脸时的人脸矩形颜色
- en: // load classifier to recognize faces
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: // 加载分类器以识别人脸
- en: classifier := gocv.NewCascadeClassifier()
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: classifier := gocv.NewCascadeClassifier()
- en: if !classifier.Load(haarCascadeFile) {
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: if !classifier.Load(haarCascadeFile) {
- en: 'log.Fatalf("Error reading cascade file: %v\n", haarCascadeFile)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 'log.Fatalf("读取级联文件时出错: %v\n", haarCascadeFile)'
- en: '}'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: defer classifier.Close()
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: defer classifier.Close()
- en: for {
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: for {
- en: if ok := webcam.Read(&amp;img); !ok {
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: if ok := webcam.Read(&img); !ok {
- en: fmt.Printf("cannot read device %d\n", deviceID)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: fmt.Printf("无法读取设备 %d\n", deviceID)
- en: return
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: return
- en: '}'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: if img.Empty() {
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: if img.Empty() {
- en: continue
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: continue
- en: '}'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: rects := classifier.DetectMultiScale(img)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: rects := classifier.DetectMultiScale(img)
- en: for _, r := range rects {
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: for _, r := range rects {
- en: gocv.Rectangle(&amp;img, r, blue, 3)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: gocv.Rectangle(&img, r, blue, 3)
- en: '}'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: window.IMShow(img)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: window.IMShow(img)
- en: if window.WaitKey(1) &gt;= 0 {
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: if window.WaitKey(1) >= 0 {
- en: break
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: break
- en: '}'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '}'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '}'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE15]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The program is now able to get an image from the webcam, detect faces, draw
    rectangles around the faces, and then display the image. You may note that it
    is quite quick at doing that.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在能够从摄像头获取图像，检测人脸，在人脸周围绘制矩形，然后显示图像。你可能注意到，它在这方面做得相当快。
- en: Face detection 2
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测 2
- en: In one fell swoop, GoCV has provided us with everything necessary to do real-time
    face detection. But is it easy to use with other face detection algorithms? The
    answer is yes, but some work is required.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 一举一动，GoCV为我们提供了进行实时人脸检测所需的一切。但是，它与其他人脸检测算法一起使用容易吗？答案是肯定的，但需要一些工作。
- en: The algorithm we want to use is the PICO algorithm. Recall that images in GoCV
    are in the `gocv.Mat` type. In order for PIGO to use that, we would need to convert
    that into a format readable by PICO. Incidentally, such a shared format is the
    `image.Image` of the standard library.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要使用的算法是PICO算法。回想一下，GoCV中的图像是`gocv.Mat`类型。为了使PIGO能够使用它，我们需要将其转换为PICO可读的格式。顺便说一句，这种共享格式是标准库中的`image.Image`。
- en: Recall once again that the `gocv.Mat` type has a method `.ToImage()`, which
    returns an `image.Image`. That's our bridge!
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，`gocv.Mat`类型有一个`.ToImage()`方法，它返回一个`image.Image`。这就是我们的桥梁！
- en: 'Before crossing it, let''s look at how to create a PIGO classifier. Here''s
    a function to do so:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在穿过它之前，让我们看看如何创建一个PIGO分类器。这里有一个创建它的函数：
- en: '[PRE16]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: func pigoSetup(width, height int) (*image.NRGBA, []uint8, *pigo.Pigo,
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: func pigoSetup(width, height int) (*image.NRGBA, []uint8, *pigo.Pigo,
- en: pigo.CascadeParams, pigo.ImageParams) {
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: pigo.CascadeParams, pigo.ImageParams) {
- en: goImg := image.NewNRGBA(image.Rect(0, 0, width, height))
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: goImg := image.NewNRGBA(image.Rect(0, 0, width, height))
- en: grayGoImg := make([]uint8, width*height)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: grayGoImg := make([]uint8, width*height)
- en: cParams := pigo.CascadeParams{
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: cParams := pigo.CascadeParams{
- en: 'MinSize: 20,'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'MinSize: 20,'
- en: 'MaxSize: 1000,'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'MaxSize: 1000,'
- en: 'ShiftFactor: 0.1,'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'ShiftFactor: 0.1,'
- en: 'ScaleFactor: 1.1,'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'ScaleFactor: 1.1,'
- en: '}'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: imgParams := pigo.ImageParams{
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: imgParams := pigo.ImageParams{
- en: 'Pixels: grayGoImg,'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Pixels: grayGoImg,'
- en: 'Rows: height,'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Rows: height,'
- en: 'Cols: width,'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Cols: width,'
- en: 'Dim: width,'
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Dim: width,'
- en: '}'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: classifier := pigo.NewPigo()
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: classifier := pigo.NewPigo()
- en: var err error
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: var err error
- en: if classifier, err = classifier.Unpack(pigoCascadeFile); err != nil {
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: if classifier, err = classifier.Unpack(pigoCascadeFile); err != nil {
- en: 'log.Fatalf("Error reading the cascade file: %s", err)'
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'log.Fatalf("读取级联文件时出错: %s", err)'
- en: '}'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: return goImg, grayGoImg, classifier, cParams, imgParams
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: return goImg, grayGoImg, classifier, cParams, imgParams
- en: '}'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE17]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This function is quite dense. Let's unpack it. We'll do it in a logical fashion
    as opposed to in a top-down linear fashion.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数相当密集。让我们来分解它。我们将以逻辑方式而不是自顶向下的线性方式来执行。
- en: First, a `pigo.Pigo` is created with `classifier := pigo.NewPigo()`. This creates
    a new classifier. Like the Viola-Jones method, a model is required to be supplied.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用 `classifier := pigo.NewPigo()` 创建一个 `pigo.Pigo` 对象。这创建了一个新的分类器。与 Viola-Jones
    方法一样，需要一个模型来提供。
- en: 'Unlike in GoCV, the model is in a binary format which needs to be unpacked.
    Additionally, `classifier.Unpack` takes a `[]byte`, instead of a string denoting
    the path to the file. The provided model can be acquired on GitHub: `https://github.com/esimov/pigo/blob/master/data/facefinder`.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 与 GoCV 不同，模型是二进制格式，需要解包。此外，`classifier.Unpack` 接受一个 `[]byte`，而不是表示文件路径的字符串。提供的模型可以在
    GitHub 上获取：`https://github.com/esimov/pigo/blob/master/data/facefinder`。
- en: 'Once the file has been acquired, it needs to be read as `[]byte`, as shown
    in the snippet below (which is wrapped in an `init` function):'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获取了文件，就需要像下面片段所示的那样以 `[]byte` 格式读取它（该片段被 `init` 函数包裹）：
- en: '[PRE18]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: pigoCascadeFile, err = ioutil.ReadFile("path/to/facefinder")
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: pigoCascadeFile, err = ioutil.ReadFile("path/to/facefinder")
- en: if err != nil {
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: if err != nil {
- en: 'log.Fatalf("Error reading the cascade file: %v", err)'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'log.Fatalf("Error reading the cascade file: %v", err)'
- en: '}'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE19]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Once the `pigoCascadeFile` is available, we can now unpack it into the classifier
    by using `classifier.Unpack(pigoCascadeFile)`. Usual error handling applies.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 `pigoCascadeFile` 可用，我们可以使用 `classifier.Unpack(pigoCascadeFile)` 将其解包到分类器中。通常的错误处理适用。
- en: But what of the earlier parts of the section? Why is this necessary?
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 但这一节前面的部分呢？为什么这是必要的？
- en: 'To understand this, let''s look at how PIGO does its classification. It looks
    roughly like this:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，让我们看看 PIGO 是如何进行分类的。它大致如下：
- en: '[PRE20]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'When PIGO runs the classifier, it takes two parameters which determine its
    behavior: the `ImageParam` and the `CascadeParams`. In particular, the details
    `ImageParam` is illuminating our process. It''s defined thus:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当 PIGO 运行分类器时，它接受两个参数，这些参数决定了其行为：`ImageParam` 和 `CascadeParams`。特别是，`ImageParam`
    的细节对我们理解过程很有启发。它被定义为：
- en: '[PRE21]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: It is with this in mind that the `pigoSetup` function has the extra functionalities.
    The `goImg` is not strictly required, but it's useful when considering our bridge
    between GoCV and PIGO.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`pigoSetup` 函数具有额外的功能。`goImg` 不是严格必需的，但在考虑 GoCV 和 PIGO 之间的桥梁时很有用。
- en: 'PIGO requires images to be in `[]uint8`, representing a grayscale image. GoCV
    reads a webcam image into a `gocv.Mat`, which has a `.ToImage()` method. The method
    returns a `image.Image`. Most webcams capture color images. These are the steps
    required in order to make GoCV and PIGO play nicely together:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: PIGO 需要图像以 `[]uint8` 格式存在，表示灰度图像。GoCV 将网络摄像头图像读取到 `gocv.Mat` 中，该对象具有 `.ToImage()`
    方法。该方法返回一个 `image.Image` 对象。大多数网络摄像头捕获的是彩色图像。以下是将 GoCV 和 PIGO 结合使用的步骤：
- en: Capture an image from the webcam.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从网络摄像头捕获图像。
- en: Convert the image into an `image.Image`.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为 `image.Image`。
- en: Convert that image into a gray scale image.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将该图像转换为灰度图像。
- en: Extract the `[]uint8` from the gray scale image.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从灰度图像中提取 `[]uint8`。
- en: Perform face detection on the `[]uint8`.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `[]uint8` 上执行人脸检测。
- en: For our preceding pipeline, the image parameters and the cascade parameters
    are more or less static. Processing of the image is done in a linear fashion.
    A frame from the webcam doesn't get captured until the face detection is done,
    and the rectangles drawn, and the final image displayed in the window.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们前面的管道，图像参数和级联参数基本上是静态的。图像处理以线性方式进行。直到完成人脸检测、绘制矩形和最终在窗口中显示图像之前，网络摄像头的帧不会捕获。
- en: Hence, it would be perfectly all right to allocate an image once, and then overwrite
    the image in each loop. The `.ToImage()` method allocates a new image every time
    it's called. Rather, we can have a naughty version, where an already-allocated
    image is reused.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一次分配一个图像，然后在每个循环中覆盖图像是完全正确的。`.ToImage()` 方法每次调用时都会分配一个新的图像。相反，我们可以有一个“顽皮”版本，其中已分配的图像被重复使用。
- en: 'Here''s how to do it:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何做到这一点：
- en: '[PRE22]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This function allows one to reuse an existing image. We simply loop through
    the bytes of the `gocv.Mat` and overwrite the underlying bytes of the image.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数允许用户重用现有的图像。我们只需遍历 `gocv.Mat` 的字节，并覆盖图像的底层字节。
- en: 'With the same logic, we can also create a naughty version of a function that
    converts the image into gray scale:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的逻辑，我们还可以创建一个将图像转换为灰度的“顽皮”版本的函数：
- en: '[PRE23]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The differences in function signature are stylistic. The latter signature is
    better—it''s better to return the type. This allows for error correction as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 函数签名之间的差异是风格上的。后者签名更好——最好返回类型。这允许进行错误纠正，如下所示：
- en: '[PRE24]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'And so our pipeline looks like this:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的流程看起来像这样：
- en: '[PRE25]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: There are some things to note here. If you follow the logic, you will note that
    the only things that really changed are the data in `imgParams.Pixels`. The rest
    of the things didn't really change as much.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些需要注意的事情。如果你遵循逻辑，你会注意到真正改变的是 `imgParams.Pixels` 中的数据。其余的东西并没有真正改变很多。
- en: 'Recall from the earlier explanation of the PICO algorithm—that there may be
    overlaps in detection''s. A final clustering step is required for final detections.
    This explains the following two lines:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下之前对 PICO 算法的解释——检测中可能存在重叠。需要最终聚类步骤来完成最终检测。这解释了以下两行代码：
- en: '[PRE26]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `0.3` value is chosen based on the original paper. In the documentation
    of PIGO, the value `0.2` is recommended.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`0.3` 这个值是基于原始论文选择的。在 PIGO 的文档中，建议的值是 `0.2`。'
- en: 'Another thing that is different is that PIGO does not return rectangles as
    detections. Instead, it returns its own `pigo.Detection` type. To translate from
    these to standard `image.Rectangle` is simply done with these lines:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个不同之处在于，PIGO 不返回矩形作为检测结果。相反，它返回自己的 `pigo.Detection` 类型。将这些转换为标准的 `image.Rectangle`
    只需以下几行代码：
- en: '[PRE27]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Running the program yields a window showing the webcam image, with green rectangles
    around faces.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序会弹出一个窗口，显示带有脸部周围绿色矩形的网络摄像头图像。
- en: Putting it all together
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有这些放在一起
- en: Now we have two different uses of two different algorithms to detect faces.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了两种不同的算法来检测人脸的不同应用。
- en: 'Here are some observations:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些观察结果：
- en: The images using PIGO are smoother—there are fewer jumps and lags.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PIGO 的图像更平滑——跳跃和延迟更少。
- en: The PIGO algorithm jitters a little more than the standard Viola-Jones method.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PIGO 算法比标准的 Viola-Jones 方法抖动得更多。
- en: The PIGO algorithm is more robust to rotations—I could tilt my head more and
    still have my face detected compared to the standard Viola-Jones method.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PIGO 算法对旋转更鲁棒——我可以倾斜我的头部更多，仍然能够检测到我的脸部，与标准的 Viola-Jones 方法相比。
- en: 'We can of course put both of them together:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以将它们放在一起：
- en: '[PRE28]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here we see PIGO and GoCV both managed to detect them rather accurately, and
    that they agree with each other quite a lot.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到 PIGO 和 GoCV 都能够相当准确地检测到它们，并且它们之间相当一致。
- en: Additionally we can see that there is now a fairly noticeable lag between actions
    and when the actions are displayed on screen. This is because there is more work
    to be done.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以看到现在动作和动作在屏幕上显示之间有一个相当明显的延迟。这是因为还有更多的工作要做。
- en: Evaluating algorithms
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估算法
- en: There are many dimensions upon which we can evaluate the algorithms. This section
    explores how to evaluate algorithms.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从很多维度来评估算法。本节探讨了如何评估算法。
- en: Assuming we want to have fast face detection—which algorithm would be better?
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要快速的人脸检测——哪个算法会更好？
- en: The only way to understand the performance of an algorithm is to measure it.
    Thankfully Go comes with benchmarking built in. That is what we are about to do.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 理解算法性能的唯一方法就是测量它。幸运的是，Go 内置了基准测试功能。这正是我们即将要做的事情。
- en: To build benchmarks we must be very careful about what we're benchmarking. In
    this case, we want to benchmark the performance of the detection algorithm. This
    means comparing  `classifier.DetectMultiScale` versus, `pigoClass.RunCascade`
    and `pigoClass.ClusterDetections`.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建基准测试，我们必须非常小心我们正在测试的内容。在这种情况下，我们想要测试检测算法的性能。这意味着比较 `classifier.DetectMultiScale`
    与 `pigoClass.RunCascade` 和 `pigoClass.ClusterDetections`。
- en: 'Also, we have to compare apples to apples—it would be unfair if we compare
    one algorithm with a 3840 x 2160 image and the other algorithm with a 640 x 480
    image. There are simply more pixels in the former compared to the latter:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们必须比较苹果和苹果——如果我们用一个 3840 x 2160 的图像和一个 640 x 480 的图像来比较一个算法，而另一个算法，这将是不公平的。前者比后者有更多的像素：
- en: '[PRE29]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: There are a few things to note—the set up is made early on in the function.
    Then `b.ResetTimer()` is called. This resets the timer so that setups are not
    counted towards the benchmark. The second thing to note is that the classifier
    is set to detect faces on the same image over and over again. This is so that
    we can get an accurate idea of how well the algorithm performs. The last thing
    to note is the rather weird `_ = rects` line at the end. This is done to prevent
    Go from optimizing away the calls. Technically, it is not needed, as I am quite
    certain that the `DetectMultiScale` function is complicated enough as to never
    have been optimized away, but that line is just there for insurance.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 有几点需要注意——设置是在函数的早期完成的。然后调用`b.ResetTimer()`。这样做是为了重置计时器，使得设置不被计入基准测试。第二点需要注意的是，分类器被设置为在相同的图像上反复检测人脸。这样做是为了我们可以准确地了解算法的性能。最后一点需要注意的是结尾的相当奇怪的`_
    = rects`行。这样做是为了防止Go优化掉这些调用。从技术上讲，这并不是必需的，因为我相当确信`DetectMultiScale`函数已经复杂到从未被优化掉，但那行只是为了保险。
- en: 'A similar set up can be done for PIGO:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PIGO也可以进行类似的设置：
- en: '[PRE30]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This time the set up is more involved than the GoCV benchmark. It may seem that
    these two functions are benchmarking different things—the GoCV benchmark takes
    a `gocv.Mat` while the PIGO benchmark takes a `[]uint8`. But remember that we're
    interested in the performance of the algorithms on an image.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这次设置比GoCV基准测试更复杂。可能会觉得这两个函数正在基准测试不同的事情——GoCV基准测试使用`gocv.Mat`，而PIGO基准测试使用`[]uint8`。但记住，我们感兴趣的是算法在图像上的性能。
- en: The main reason why the gray scaling is also added into the benchmark is because,
    although GoCV takes a color image, the actual Viola-Jones method uses a gray scale
    image. Internally, OpenCV converts the image into a gray scale before detection.
    Because we're unable to separate the detection part by itself, the only alternative
    is to consider conversion to gray scale as part of the detection process.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 将灰度化也添加到基准测试中的主要原因是因为，尽管GoCV接受彩色图像，但实际的Viola-Jones方法使用的是灰度图像。在内部，OpenCV在检测之前将图像转换为灰度。因为我们无法单独分离检测部分，唯一的替代方案是将转换为灰度作为检测过程的一部分来考虑。
- en: 'To run the benchmark, both functions are added into `algorithms_test.go`. Then
    `go test -run=^$ -bench=. -benchmem` is run. The result is as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行基准测试，需要将这两个函数添加到`algorithms_test.go`中。然后运行`go test -run=^$ -bench=. -benchmem`。结果如下：
- en: '[PRE31]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here we can see that GoCV is about 1/3 slower than PIGO. A key reason for this
    is due to the cgo calls made in order to interface with OpenCV. However, it should
    also be noted that the PICO algorithm is faster than the original Viola-Jones
    algorithm. That PIGO can exceed the performance of a highly tuned and optimized
    Viola-Jones algorithm found in OpenCV, is rather impressive.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到GoCV比PIGO慢大约1/3。这其中的一个关键原因是由于与OpenCV接口而进行的cgo调用。然而，也应该注意的是，PICO算法比原始的Viola-Jones算法更快。PIGO能够超越OpenCV中找到的经过高度调整和优化的Viola-Jones算法的性能，这相当令人印象深刻。
- en: 'However, speed is not the only thing that matters. There are other dimensions
    that matter. The following are things that matter when considering face detection
    algorithms. Tests for them are suggested but left as an exercise for the reader:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，速度并不是唯一需要考虑的因素。还有其他维度也很重要。以下是在考虑人脸检测算法时需要注意的事项。对这些事项的测试被建议，但留作读者的练习：
- en: '[PRE32]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The last one is of particular interest. For many years, ML algorithms have not
    served people of color well. I myself had some issues when using a Viola-Jones
    model (a different model from the one in the repository) to detect eyes. In a
    facial feature detection project I did about five years ago, I was trying to detect
    eyes on a face.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个特别有趣。多年来，机器学习算法并没有很好地服务于有色人种。我自己在使用Viola-Jones模型（与存储库中的模型不同）检测眼睛时遇到了一些问题。在大约五年前的一个面部特征检测项目中，我试图在脸上检测眼睛。
- en: The so-called **Asian** eyes are composed of two major features—an upward slant
    away from the nose to the outside of the face; and eyes that have epicanthic folds,
    giving the illusion of a *single* eyelid—that is, an eyelid without crease. The
    model I was working on couldn't detect where my eyes were on occasion because
    the filter looked for the crease of the eyelid, and the creases on my eyelids
    are not that obvious.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 所说的**亚洲**眼睛由两个主要特征组成——从鼻子向外侧的脸上有一个向上的斜坡；以及有内眦褶的眼睑，给人一种**单层**眼睑的错觉——也就是说，没有褶皱的眼睑。我正在工作的模型有时无法检测到我的眼睛位置，因为过滤器寻找的是眼睑的褶皱，而我眼睑上的褶皱并不明显。
- en: On that front, some algorithms and models may appear accidentally exclusionary.
    To be clear, I am NOT saying that the creators of such algorithms and models are
    racist. However there are some assumptions that were made in the design of the
    algorithms that did not include considerations of all the possible cases—nor could
    they ever. For example, any contrast-based detection of facial landmarks will
    fare poorly with people who have darker skin tones. On the flipside, contrast-based
    detection systems are usually very fast, because there is a minimal amount of
    calculation required. Here, there is a tradeoff to be made—do you need to detect
    everyone, or do you need to be fast?
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，一些算法和模型可能意外地具有排他性。为了明确，我并不是说这些算法和模型的创造者是种族主义者。然而，在设计这些算法时，确实存在一些假设，它们没有考虑所有可能的情况——而且永远也不能。例如，任何基于对比度的面部特征检测在肤色较深的人身上表现都会很差。另一方面，基于对比度的检测系统通常非常快，因为所需的计算量最小。在这里，我们需要做出权衡——你需要检测每个人，还是你需要速度快？
- en: This chapter aims to encourage readers to think more about use cases of machine
    learning algorithms and the tradeoffs required in using the algorithms. This book
    has mostly been about thinking about the tradeoffs. I highly encourage the reader
    to think deeply about the use cases of the machine learning algorithms. Understand
    all the tradeoffs required. Once the appropriate tradeoffs are understood, implementation
    is usually a piece of cake.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在鼓励读者更多地思考机器学习算法的应用场景以及使用算法所需的权衡。这本书主要关于权衡的思考。我强烈建议读者深入思考机器学习算法的应用场景。理解所有所需的权衡。一旦理解了适当的权衡，实现通常就是小菜一碟。
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about using GoCV and PIGO, and built a program that
    detects faces from a live webcam. At the end of the chapter, we implemented a
    usable facial recognition system, got familiar with notions of hashing of facial
    features, and saw how to make fast inferences using the Gorgonia suite of libraries
    as well as GoCV, which is a binding for OpenCV.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了使用GoCV和PIGO，并构建了一个从实时网络摄像头检测人脸的程序。在本章结束时，我们实现了一个可用的面部识别系统，熟悉了面部特征哈希的概念，并了解了如何使用Gorgonia库系列以及GoCV（OpenCV的绑定）来快速进行推理。
- en: In saying that, in the next chapter, we'll look at some of the implications
    of not having built your algorithm by yourself.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，在下一章中，我们将探讨没有自己构建算法的一些影响。
