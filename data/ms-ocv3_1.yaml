- en: Cartoonifier and Skin Changer for Raspberry Pi
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树莓派的卡通化器和皮肤转换器
- en: 'This chapter will show how to write some image processing filters for desktop
    and for small embedded systems such as Raspberry Pi. First, we develop it for
    the desktop (in C/C++) and then port the project to Raspberry Pi, since this is
    the recommended scenario when developing for embedded devices. This chapter will
    cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将展示如何为桌面和如树莓派等小型嵌入式系统编写一些图像处理过滤器。首先，我们为桌面（使用C/C++）开发它，然后将项目移植到树莓派上，因为这是为嵌入式设备开发时推荐的场景。本章将涵盖以下主题：
- en: How to convert a real-life image to a sketch drawing
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将现实生活中的图像转换为素描草图
- en: How to convert to a painting and overlay the sketch to produce a cartoon
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将图像转换为绘画并在其上叠加草图以产生卡通效果
- en: A scary evil mode to create bad characters instead of good characters
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个恐怖的邪恶模式，用于创建反派角色而不是正面角色
- en: A basic skin detector and skin color changer, to give someone green alien skin
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个基本的皮肤检测器和皮肤颜色转换器，可以给某人绿色的外星皮肤
- en: Finally, how to create an embedded system based on our desktop application
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，如何基于我们的桌面应用程序创建嵌入式系统
- en: 'Note that an **embedded system** is basically a computer motherboard placed
    inside a product or device, designed to perform specific tasks, and **Raspberry
    Pi** is a very low-cost and popular motherboard for building an embedded system:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一个**嵌入式系统**基本上是将计算机主板放置在产品或设备内部，用于执行特定任务，而**树莓派**是构建嵌入式系统的一个非常低廉且流行的主板：
- en: '![](img/image_01_001.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_001.png)'
- en: 'The preceding picture shows what you could make after this chapter: a battery-powered
    Raspberry Pi + screen you could wear to Comic Con, turning everyone into a cartoon!'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张图片展示了本章完成后你可以制作的内容：一个可穿戴的电池供电的树莓派加屏幕，可以将每个人变成卡通人物！
- en: We want to make the real-world camera frames automatically look like they are
    from a cartoon. The basic idea is to fill the flat parts with some color and then
    draw thick lines on the strong edges. In other words, the flat areas should become
    much more flat and the edges should become much more distinct. We will detect
    edges, smooth the flat areas, and draw enhanced edges back on top, to produce
    a cartoon or comic-book effect.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望使现实世界的相机帧自动看起来像是从卡通中来的。基本思路是填充平面部分一些颜色，然后在强边缘上画粗线。换句话说，平面区域应该变得更加平坦，边缘应该变得更加明显。我们将检测边缘，平滑平面区域，并在其上重新绘制增强的边缘，以产生卡通或漫画效果。
- en: When developing an embedded computer vision system, it is a good idea to build
    a fully working desktop version first before porting it to an embedded system,
    since it is much easier to develop and debug a desktop program than an embedded
    system! So this chapter will begin with a complete Cartoonifier desktop program
    that you can create using your favorite IDE (for example, Visual Studio, XCode,
    Eclipse, QtCreator). After it is working properly on your desktop, the last section
    shows how to create an embedded system based on the desktop version. Many embedded
    projects require some custom code for the embedded system, such as to use different
    inputs and outputs or use some platform-specific code optimizations. However,
    for this chapter, we will actually be running identical code on the embedded system
    and the desktop, so we only need to create one project.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发嵌入式计算机视觉系统时，在将其移植到嵌入式系统之前先构建一个完全工作的桌面版本是一个好主意，因为与嵌入式系统相比，开发桌面程序和调试要容易得多！因此，本章将从完整的卡通化器桌面程序开始，你可以使用你喜欢的IDE（例如，Visual
    Studio、XCode、Eclipse、QtCreator）创建它。在桌面上运行正常后，最后一节将展示如何基于桌面版本创建嵌入式系统。许多嵌入式项目需要为嵌入式系统编写一些自定义代码，例如使用不同的输入和输出或使用一些平台特定的代码优化。然而，对于本章，我们实际上将在嵌入式系统和桌面系统上运行相同的代码，所以我们只需要创建一个项目。
- en: The application uses an **OpenCV** GUI window, initializes the camera, and with
    each camera frame it calls the function `cartoonifyImage()`, containing most of
    the code in this chapter. It then displays the processed image on the GUI window.
    This chapter will explain how to create the desktop application from scratch using
    a USB webcam, and the embedded system-based on the desktop application using a
    Raspberry Pi Camera Module. So first you would create a desktop project in your
    favorite IDE, with a `main.cpp` file to hold the GUI code given in the following
    sections such as the main loop, webcam functionality, and keyboard input, and
    you would create a `cartoon.cpp` file with the image processing operations with
    most of this chapter's code in a function called `cartoonifyImage()`.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序使用**OpenCV** GUI窗口，初始化摄像头，并且对于每一帧摄像头图像，它都会调用`cartoonifyImage()`函数，其中包含本章的大部分代码。然后，它在GUI窗口上显示处理后的图像。本章将解释如何从头开始使用USB摄像头创建桌面应用程序，以及使用树莓派摄像头模块的基于桌面应用程序的嵌入式系统。因此，首先你会在你喜欢的IDE中创建一个桌面项目，创建一个`main.cpp`文件来保存以下章节中给出的GUI代码，例如主循环、摄像头功能、键盘输入，并且你会创建一个`cartoon.cpp`文件，其中包含图像处理操作，大部分本章的代码都在一个名为`cartoonifyImage()`的函数中。
- en: The full source code of this book is available at [http://github.com/MasteringOpenCV/code](http://github.com/MasteringOpenCV/code).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的全源代码可在[http://github.com/MasteringOpenCV/code](http://github.com/MasteringOpenCV/code)找到。
- en: Accessing the webcam
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问摄像头
- en: To access a computer's webcam or camera device, you can simply call the `open()`
    function on a `cv::VideoCapture` object (OpenCV's method of accessing your camera
    device), and pass 0 as the default camera ID number. Some computers have multiple
    cameras attached, or they do not work as default camera 0, so it is common practice
    to allow the user to pass the desired camera number as a command-line argument,
    in case they want to try camera 1, 2, or -1, for example. We will also try to
    set the camera resolution to 640x480 using `cv::VideoCapture::set()` to run faster
    on high-resolution cameras.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问计算机的摄像头或相机设备，你可以简单地在`cv::VideoCapture`对象上调用`open()`函数（OpenCV访问你的相机设备的方法），并将0作为默认的摄像头ID号传递。一些计算机连接了多个摄像头，或者它们不是作为默认的摄像头0工作，因此允许用户将所需的摄像头编号作为命令行参数传递是一种常见的做法，例如，他们可能想尝试摄像头1、2或-1。我们还将尝试使用`cv::VideoCapture::set()`将摄像头分辨率设置为640x480，以便在高清摄像头上运行更快。
- en: Depending on your camera model, driver, or system, OpenCV might not change the
    properties of your camera. It is not important for this project, so don't worry
    if it does not work with your webcam.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的摄像头型号、驱动程序或系统，OpenCV可能不会更改你摄像头的属性。对于这个项目来说并不重要，所以如果你发现它不能与你的摄像头一起工作，请不要担心。
- en: 'You can put this code in the `main()` function of your `main.cpp` file:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将此代码放在`main.cpp`文件的`main()`函数中：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After the webcam has been initialized, you can grab the current camera image
    as a `cv::Mat` object (OpenCV's image container). You can grab each camera frame
    by using the C++ streaming operator from your `cv::VideoCapture` object into a
    `cv::Mat` object, just like if you were getting input from a console.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在摄像头初始化之后，你可以将当前摄像头图像作为`cv::Mat`对象（OpenCV的图像容器）捕获。你可以通过使用C++流操作符从你的`cv::VideoCapture`对象到`cv::Mat`对象来捕获每一帧摄像头图像，就像你从控制台获取输入一样。
- en: OpenCV makes it very easy to capture frames from a video file (such as an AVI
    or MP4 file) or network stream instead of a webcam. Instead of passing an integer
    such as `camera.open(0)`, pass a string such as `camera.open("my_video.avi")`
    and then grab frames just like it was a webcam. The source code provided with
    this book has an `initCamera()` function that opens a webcam, video file, or network
    stream.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV使得从视频文件（如AVI或MP4文件）或网络流中捕获帧变得非常容易，而不是从摄像头中捕获。你不需要传递整数，如`camera.open(0)`，而是传递一个字符串，如`camera.open("my_video.avi")`，然后像处理摄像头一样捕获帧。本书提供的源代码中有一个`initCamera()`函数，它可以打开摄像头、视频文件或网络流。
- en: Main camera processing loop for a desktop app
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 桌面应用程序的主摄像头处理循环
- en: If you want to display a GUI window on the screen using OpenCV, you call the
    `cv::namedWindow()` function and then `cv::imshow()`function for each image, but
    you must also call `cv::waitKey()` once per frame, otherwise your windows will
    not update at all! Calling `cv::waitKey(0)` waits forever until the user hits
    a key in the window, but a positive number such as `waitKey(20)` or higher will
    wait for at least that many milliseconds.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想使用OpenCV在屏幕上显示GUI窗口，您需要调用`cv::namedWindow()`函数，然后对每个图像调用`cv::imshow()`函数，但您还必须对每个帧调用一次`cv::waitKey()`，否则您的窗口将完全不会更新！调用`cv::waitKey(0)`将无限期等待，直到用户在窗口中按下一个键，但一个正数，例如`waitKey(20)`或更高，将至少等待那么多的毫秒。
- en: 'Put this main loop in the `main.cpp` file, as the base of your real-time camera
    app:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将此主循环放入`main.cpp`文件中，作为您实时相机应用程序的基础：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Generating a black and white sketch
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成黑白素描
- en: To obtain a sketch (black and white drawing) of the camera frame, we will use
    an edge detection filter, whereas to obtain a color painting, we will use an edge
    preserving filter (Bilateral filter) to further smoothen the flat regions while
    keeping edges intact. By overlaying the sketch drawing on top of the color painting,
    we obtain a cartoon effect, as shown earlier in the screenshot of the final app.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得相机帧的素描（黑白绘图），我们将使用边缘检测滤波器，而要获得彩色绘画，我们将使用边缘保持滤波器（双边滤波器）来进一步平滑平坦区域，同时保持边缘完整。通过将素描绘制叠加在彩色绘画之上，我们获得卡通效果，如之前截图中的最终应用程序所示。
- en: There are many different edge detection filters, such as Sobel, Scharr, Laplacian
    filters, or a Canny edge detector. We will use a Laplacian edge filter since it
    produces edges that look most similar to hand sketches compared to Sobel or Scharr,
    and are quite consistent compared to a Canny edge detector, which produces very
    clean line drawings but is affected more by random noise in the camera frames
    and therefore the line drawings would often change drastically between frames.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的边缘检测滤波器，例如Sobel、Scharr、拉普拉斯滤波器或Canny边缘检测器。我们将使用拉普拉斯边缘滤波器，因为它产生的边缘与手绘草图相比最为相似，与Sobel或Scharr相比相当一致，与Canny边缘检测器相比则相当干净，但更容易受到相机帧中随机噪声的影响，因此线图在帧之间往往会发生剧烈变化。
- en: 'Nevertheless, we still need to reduce the noise in the image before we use
    a Laplacian edge filter. We will use a Median filter because it is good at removing
    noise while keeping edges sharp, but is not as slow as a Bilateral filter. Since
    Laplacian filters use grayscale images, we must convert from OpenCV''s default
    BGR format to grayscale. In your empty `cartoon.cpp` file, put this code on the
    top so you can access OpenCV and STD C++ templates without typing `cv::` and `std::` everywhere:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们仍然需要在使用拉普拉斯边缘滤波器之前减少图像中的噪声。我们将使用中值滤波器，因为它擅长去除噪声同时保持边缘锐利，但比双边滤波器慢。由于拉普拉斯滤波器使用灰度图像，我们必须将OpenCV的默认BGR格式转换为灰度。在您的空`cartoon.cpp`文件中，将此代码放在顶部，这样您就可以在不输入`cv::`和`std::`的情况下访问OpenCV和STD
    C++模板：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Put this and all remaining code in a `cartoonifyImage()` function in your `cartoon.cpp`
    file:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将此代码和所有剩余代码放入您的`cartoon.cpp`文件中的`cartoonifyImage()`函数中：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The Laplacian filter produces edges with varying brightness, so to make the
    edges look more like a sketch, we apply a binary threshold to make the edges either
    white or black:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 拉普拉斯滤波器产生的边缘亮度各异，因此为了使边缘看起来更像素描，我们应用二值阈值使边缘要么是白色要么是黑色：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the following figure, you see the original image (to the left) and the generated
    edge mask (to the right) that looks similar to a sketch drawing. After we generate
    a color painting (explained later), we also put this edge mask on top to have
    black line drawings:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，您可以看到原始图像（左侧）和生成的类似素描的边缘掩码（右侧）。在我们生成彩色绘画（稍后解释）之后，我们也将此边缘掩码放在顶部，以获得黑色线图：
- en: '![](img/image_01_002.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_01_002.png)'
- en: Generating a color painting and a cartoon
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成彩色绘画和卡通
- en: 'A strong Bilateral filter smoothens flat regions while keeping edges sharp;
    and therefore, is great as an automatic cartoonifier or painting filter, except
    that it is extremely slow (that is, measured in seconds or even minutes, rather
    than milliseconds!). Therefore, we will use some tricks to obtain a nice cartoonifier,
    while still running in acceptable speed. The most important trick we can use is
    that we can perform Bilateral filtering at a lower resolution and it will still
    have a similar effect as a full resolution, but run much faster. Lets reduce the
    total number of pixels by four (for example, half width and half height):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 强大的双边滤波器可以平滑平坦区域，同时保持边缘锐利；因此，它非常适合作为自动卡通化或绘画滤镜，除了它极其缓慢（即以秒或甚至分钟计算，而不是毫秒！）之外。因此，我们将使用一些技巧来获得一个不错的卡通化效果，同时仍然以可接受的速度运行。我们可以使用的一个最重要的技巧是，我们可以在较低的分辨率下执行双边滤波，它仍然会产生与全分辨率相似的效果，但运行得更快。让我们将总像素数减少四分之一（例如，宽度和高度各减半）：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Rather than applying a large Bilateral filter, we will apply many small Bilateral
    filters, to produce a strong cartoon effect in less time. We will truncate the
    filter (see the following figure) so that instead of performing a whole filter
    (for example, a filter size of 21x21, when the bell curve is 21 pixels wide),
    it just uses the minimum filter size needed for a convincing result (for example,
    with a filter size of just 9x9 even if the bell curve is 21 pixels wide). This
    truncated filter will apply the major part of the filter (gray area) without wasting
    time on the minor part of the filter (white area under the curve), so it will
    run several times faster:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会应用一个大的双边滤波器，而是会应用许多小的双边滤波器，以在更短的时间内产生强烈的卡通效果。我们将截断滤波器（见下图），这样它就只使用达到令人信服结果所需的最小滤波器尺寸（例如，即使钟形曲线宽度为21像素，也只使用9x9的滤波器尺寸）。这个截断滤波器将应用滤波器的大部分（灰色区域），而不会在滤波器的次要部分（曲线下的白色区域）上浪费时间，因此它将运行得快几倍：
- en: '![](img/image_01_003.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_003.png)'
- en: 'Therefore, we have four parameters that control the Bilateral filter: color
    strength, positional strength, size, and repetition count. We need a temp `Mat`
    since the `bilateralFilter()`function can''t overwrite its input (referred to
    as *in-place processing*), but we can apply one filter storing a temp `Mat` and
    another filter storing back the input:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有四个参数控制双边滤波器：颜色强度、位置强度、大小和重复计数。我们需要一个临时的`Mat`，因为`bilateralFilter()`函数不能覆盖其输入（称为*就地处理*），但我们可以应用一个存储临时`Mat`的滤波器，然后应用另一个存储输入的滤波器：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Remember that this was applied to the shrunken image, so we need to expand
    the image back to the original size. Then we can overlay the edge mask that we
    found earlier. To overlay the edge mask *sketch* onto the Bilateral filter *painting*
    (left side of the following figure), we can start with a black background and
    copy the *painting* pixels that aren''t edges in the *sketch* mask:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这是应用于缩小后的图像，因此我们需要将图像扩展回原始大小。然后我们可以叠加之前找到的边缘蒙版。要将边缘蒙版*草图*叠加到双边滤波器*绘画*（下图的左侧），我们可以从黑色背景开始，并复制*草图*蒙版中不是边缘的*绘画*像素：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result is a cartoon version of the original photo, as shown on the right
    side of the following figure, where the *sketch* mask is overlaid on the painting:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是原始照片的卡通版本，如图中右侧所示，其中在绘画上叠加了*草图*蒙版：
- en: '![](img/image_01_004.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_004.png)'
- en: Generating an evil mode using edge filters
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用边缘滤镜生成邪恶模式
- en: Cartoons and comics always have both good and bad characters. With the right
    combination of edge filters, a scary image can be generated from the most innocent
    looking people! The trick is to use a small-edge filter that will find many edges
    all over the image, then merge the edges using a small Median filter.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 卡通和漫画总是有好的和坏的角色。通过合适的边缘滤镜组合，可以从看起来最无辜的人那里生成一个令人恐惧的图像！技巧是使用一个小边缘滤镜，它将在整个图像中找到许多边缘，然后使用一个小中值滤波器合并这些边缘。
- en: 'We will perform this on a grayscale image with some noise reduction, so the
    preceding code for converting the original image to grayscale and applying a 7x7
    Median filter should still be used (the first image in the following figure shows
    the output of the grayscale Median blur). Instead of following it with a Laplacian
    filter and Binary threshold, we can get a more scary look if we apply a 3x3 Scharr
    gradient filter along *x* and *y* (second image in the figure), then a binary
    threshold with a very low cutoff (third image in the figure),and a 3x3 Median
    blur, producing the final *evil* mask (fourth image in the figure):'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在一个带有一些噪声减少的灰度图像上执行此操作，因此之前将原始图像转换为灰度并应用7x7中值滤波器的代码仍然应该使用（以下图中第一幅图像显示了灰度中值模糊的输出）。我们不需要跟随拉普拉斯滤波器和二值阈值，如果我们沿着*x*和*y*应用3x3
    Scharr梯度滤波器（图中第二幅图像），然后使用一个非常低的截止值的二值阈值（图中第三幅图像），以及3x3中值模糊，就可以得到最终的**邪恶**蒙版（图中第四幅图像）：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](img/image_01_005.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_005.png)'
- en: 'Now that we have an *evil* mask, we can overlay this mask onto the *cartoonified*
    painting image like we did with the regular *sketch* edge mask. The final result
    is shown on the right side of the following figure:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了**邪恶**蒙版，我们可以像处理常规的**草图**边缘蒙版一样将此蒙版叠加到**卡通化**的绘画图像上。最终结果显示在以下图的右侧：
- en: '![](img/image_01_006.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_006.png)'
- en: Generating an alien mode using skin detection
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用皮肤检测生成外星人模式
- en: 'Now that we have a *sketch* mode, a *cartoon* mode (*painting* + *sketch* mask),
    and an *evil* mode (*painting* + *evil* mask), for fun, let''s try something more
    complex: an *alien* mode, by detecting the skin regions of the face and then changing
    the skin color to green.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了**草图**模式、**卡通**模式（**绘画**+**草图**蒙版）和**邪恶**模式（**绘画**+**邪恶**蒙版），为了好玩，让我们尝试更复杂的东西：一个**外星人**模式，通过检测面部皮肤区域，然后将皮肤颜色变为绿色。
- en: Skin detection algorithm
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 皮肤检测算法
- en: There are many different techniques used for detecting skin regions, from simple
    color thresholds using **RGB (Red-Green-Blue)**, **HSV (Hue-Saturation-Brightness)**
    values, or color histogram calculation and re-projection, to complex machine-learning
    algorithms of mixture models that need camera calibration in the **CIELab** color-space
    and offline training with many sample faces, and so on. But even the complex methods
    don't necessarily work robustly across various camera and lighting conditions
    and skin types. Since we want our skin detection to run on an embedded device,
    without any calibration or training, and we are just using skin detection for
    a fun image filter, it is sufficient for us to use a simple skin detection method.
    However, the color responses from the tiny camera sensor in the Raspberry Pi Camera
    Module tend to vary significantly, and we want to support skin detection for people
    of any skin color but without any calibration, so we need something more robust
    than simple color thresholds.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测皮肤区域方面，有许多不同的技术被使用，从简单的使用**RGB（红-绿-蓝）**、**HSV（色调-饱和度-亮度）**值或颜色直方图计算和重新投影的颜色阈值，到复杂的混合模型机器学习算法，这些算法需要在**CIELab**颜色空间中进行相机校准，并使用许多样本面部进行离线训练，等等。但是，即使是复杂的方法也不一定在各种相机、照明条件和皮肤类型下都能稳健地工作。由于我们希望我们的皮肤检测在嵌入式设备上运行，无需任何校准或训练，而我们只是使用皮肤检测作为有趣的图像过滤器，因此对我们来说，使用简单的皮肤检测方法就足够了。然而，树莓派相机模块中的微型相机传感器的颜色响应往往会显著变化，我们希望支持任何肤色的人的皮肤检测，但无需任何校准，因此我们需要比简单的颜色阈值更稳健的方法。
- en: For example, a simple HSV skin detector can treat any pixel as skin if its hue
    color is fairly red, and saturation is fairly high but not extremely high, and
    its brightness is not too dark or extremely bright. But cameras in mobile phones
    or Raspberry Pi Camera Modules often have bad white balancing, therefore a person's
    skin might look slightly blue instead of red, and so on, and this would be a major
    problem for simple HSV thresholding.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个简单的HSV皮肤检测器可以将其色调颜色相当红色、饱和度相当高但不是极高、亮度不是太暗或极度明亮的任何像素视为皮肤。但是，手机或树莓派相机模块中的相机通常有很差的白平衡，因此一个人的皮肤可能看起来是略带蓝色而不是红色，等等，这将是简单HSV阈值的一个主要问题。
- en: A more robust solution is to perform face detection with a Haar or LBP cascade
    classifier (shown in [Chapter 6](0db61fe2-672f-4d4f-9e20-a20035ea8314.xhtml),
    *Face Recognition using Eigenfaces or Fisherfaces*), then look at the range of
    colors for the pixels in the middle of the detected face, since you know that
    those pixels should be skin pixels of the actual person. You could then scan the
    whole image or nearby region for pixels of a similar color as the center of the
    face. This has the advantage that it is very likely to find at least some of the
    true skin region of any detected person, no matter what their skin color is or
    even if their skin appears somewhat blueish or redish in the camera image.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更稳健的解决方案是使用Haar或LBP级联分类器进行人脸检测（见[第6章](0db61fe2-672f-4d4f-9e20-a20035ea8314.xhtml)，*使用特征脸或费舍尔脸进行人脸识别*)，然后查看检测到的脸部中间像素的颜色范围，因为你知道那些像素应该是实际人的皮肤像素。然后你可以在整个图像或附近区域扫描与脸部中心颜色相似的像素。这个方法的优势是，无论检测到的人的皮肤颜色如何，甚至如果他们的皮肤在相机图像中看起来有些蓝色或红色，都极有可能找到至少一些真正的皮肤区域。
- en: Unfortunately, face detection using cascade classifiers is quite slow on current
    embedded devices, so that method might be less ideal for some real-time embedded
    applications. On the other hand, we can take advantage of the fact that for mobile
    apps and some embedded systems, it can be expected that the user will be facing
    the camera directly from a very close distance, so it can be reasonable to ask
    the user to place their face at a specific location and distance, rather than
    try to detect the location and size of their face. This is the basis of many mobile
    phone apps, where the app asks the user to place their face at a certain position
    or perhaps to manually drag points on the screen to show where the corners of
    their face are in a photo. So let's simply draw the outline of a face in the center
    of the screen, and ask the user to move their face to the shown position and size.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，使用级联分类器进行人脸检测在当前的嵌入式设备上相当慢，因此这种方法可能对某些实时嵌入式应用来说不太理想。另一方面，我们可以利用这样一个事实，对于移动应用和一些嵌入式系统，可以预期用户将直接从非常近的距离面对相机，因此要求用户将脸部放置在特定的位置和距离是合理的，而不是试图检测他们脸部的位置和大小。这是许多手机应用的基础，应用会要求用户将脸部放置在某个位置，或者手动在屏幕上拖动点来显示照片中脸部角的位置。所以让我们简单地绘制屏幕中央的脸部轮廓，并要求用户将脸部移动到显示的位置和大小。
- en: Showing the user where to put their face
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向用户展示他们应该将脸部放在哪里
- en: 'When the *alien* mode is first started, we will draw the face outline on top
    of the camera frame so the user knows where to put their face. We will draw a
    big ellipse covering 70% of the image height, with a fixed aspect ratio of 0.72,
    so that the face will not become too skinny or fat depending on the aspect ratio
    of the camera:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当第一次启动*外星人*模式时，我们将在相机帧上绘制脸部轮廓，以便用户知道他们的脸部应该放在哪里。我们将绘制一个覆盖70%图像高度的椭圆，具有固定的宽高比0.72，这样脸部就不会因为相机的宽高比而变得太瘦或太胖：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To make it more obvious that it is a face, let''s also draw two eye outlines.
    Rather than drawing an eye as an ellipse, we can give it a bit more realism (see
    the following figure) by drawing a truncated ellipse for the top of the eye and
    a truncated ellipse for the bottom of the eye, because we can specify the start
    and end angles when drawing with the `ellipse()` function:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更明显地表明这是一个脸部，我们还可以绘制两个眼睛轮廓。而不是将眼睛画成椭圆，我们可以通过绘制眼睛顶部和底部的截断椭圆来给它增加一点现实感（见以下图示），因为我们可以在使用`ellipse()`函数绘制时指定起始和结束角度：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can do the same to draw the bottom lip of the mouth:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用同样的方法来绘制嘴巴的底部：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To make it even more obvious that the user should put their face where shown,
    let's write a message on the screen!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让用户更清楚地知道应该将脸部放在显示的位置，让我们在屏幕上写一条信息！
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we have the face outline drawn, we can overlay it onto the displayed
    image by using alpha blending, to combine the cartoonified image with this drawn
    outline:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经画出了脸部轮廓，我们可以通过使用透明度混合将其叠加到显示的图像上，以将卡通化图像与绘制的轮廓结合：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This results in the outline in the following figure, showing the user where
    to put their face, so we don''t have to detect the face location:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下图中的轮廓，显示了用户应该将脸部放在哪里，因此我们不需要检测脸部位置：
- en: '![](img/image_01_007.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_007.jpg)'
- en: Implementation of the skin color changer
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 肌肤颜色改变器的实现
- en: Rather than detecting the skin color and then the region with that skin color,
    we can use OpenCV's `floodFill()` function, which is similar to the bucket fill
    tool in many image editing software. We know that the regions in the middle of
    the screen should be skin pixels (since we asked the user to put their face in
    the middle), so to change the whole face to have green skin, we can just apply
    a green flood fill on the center pixel, which will always color some parts of
    the face green. In reality, the color, saturation, and brightness is likely to
    be different in different parts of the face, so a floodfill will rarely cover
    all the skin pixels of a face unless the threshold is so low that it also covers
    unwanted pixels outside of the face. So instead of applying a single flood fill
    in the center of the image, let's apply a flood fill on six different points around
    the face that should be skin pixels.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是先检测肤色然后检测具有该肤色的区域，我们可以使用OpenCV的`floodFill()`函数，这个函数在很多图像编辑软件中的桶填充工具类似。我们知道屏幕中间的区域应该是皮肤像素（因为我们要求用户将脸部放在中间），所以要将整个脸部变成绿色皮肤，我们只需在中心像素上应用绿色填充，这将始终使脸部的一些部分变成绿色。实际上，颜色、饱和度和亮度在脸的不同部分可能不同，所以除非阈值非常低，否则填充通常不会覆盖脸部所有的皮肤像素。因此，我们不是在图像的中心应用单个填充，而是在脸部周围六个不同的点应用填充，这些点应该是皮肤像素。
- en: A nice feature of OpenCV's `floodFill()` is that it can draw the floodfill into
    an external image rather than modify the input image. So this feature can give
    us a mask image for adjusting the color of the skin pixels without necessarily
    changing the brightness or saturation, producing a more realistic image than if
    all the skin pixels became an identical green pixel(losing significant face detail).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV的`floodFill()`的一个不错的特点是它可以将填充绘制到外部图像中，而不是修改输入图像。因此，这个功能可以给我们一个掩码图像，用于调整皮肤像素的颜色，而无需改变亮度或饱和度，产生比所有皮肤像素都变成相同的绿色像素（丢失显著的面部细节）更逼真的图像。
- en: Skin color changing does not work so well in the RGB color-space, because you
    want to allow brightness to vary in the face but not allow skin color to vary
    much, and RGB does not separate brightness from color. One solution is to use
    the HSV color-space, since it separates brightness from the color (Hue) as well
    as the corlorful-ness (Saturation). Unfortunately, HSV wraps the Hue value around
    red, and since skin is mostly red, it means that you need to work both with *Hue
    < 10%* and *Hue > 90%*, since these are both red. So, instead we will use the
    **Y'CrCb** color-space (the variant of YUV that is in OpenCV), since it separates
    brightness from color, and only has a single range of values for typical skin
    color rather than two. Note that most cameras, images, and videos actually use
    some type of YUV as their color-space before conversion to RGB, so in many cases
    you can get a YUV image free without converting it yourself.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在RGB颜色空间中，肤色改变的效果并不好，因为你希望脸部亮度可以变化，但肤色变化不大，而RGB没有将亮度与颜色分开。一个解决方案是使用HSV颜色空间，因为它将亮度从颜色（色调）以及色彩的鲜艳程度（饱和度）中分离出来。不幸的是，HSV将色调值围绕红色进行循环，由于皮肤主要是红色，这意味着你需要同时处理*色调
    < 10%*和*色调 > 90%，因为这两个都是红色。因此，我们将使用**Y'CrCb**颜色空间（OpenCV中YUV的变体），因为它将亮度与颜色分开，并且对于典型的皮肤颜色只有一个值范围，而不是两个。请注意，大多数相机、图像和视频在转换为RGB之前实际上使用某种类型的YUV作为它们的颜色空间，所以在许多情况下，你可以免费获得YUV图像，而无需自己转换。
- en: 'Since we want our alien mode to look like a cartoon, we will apply the *alien*
    filter after the image has already been cartoonified. In other words, we have
    access to the shrunken color image produced by the Bilateral filter, and access
    to the full-sized edge mask. Skin detection often works better at low resolutions,
    since it is the equivalent of analyzing the average value of each high-resolution
    pixel''s neighbors (or the low-frequency signal instead of the high-frequency
    noisy signal). So let''s work at the same shrunk scale as the Bilateral filter
    (half-width and half-height). Let''s convert the painting image to YUV:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望我们的外星模式看起来像卡通，我们将在图像已经被卡通化之后应用*外星*滤镜。换句话说，我们有权访问双边滤波器产生的缩小颜色图像，以及完整的边缘掩码。皮肤检测在低分辨率下通常效果更好，因为它相当于分析每个高分辨率像素邻居的平均值（或低频信号而不是高频噪声信号）。所以让我们以双边滤波器相同的缩小比例工作（半宽度和半高度）。让我们将绘画图像转换为YUV：
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We also need to shrink the edge mask so it is at the same scale as the painting
    image. There is a complication with OpenCV''s `floodFill()` function, when storing
    to a separate mask image, in that the mask should have a 1 pixel border around
    the whole image, so if the input image is *WxH* pixels in size then the separate
    mask image should be *(W+2) x (H+2)* pixels in size. But the `floodFill()` function
    also allows us to initialize the mask with edges, that the flood fill algorithm
    will ensure it does not cross. Let''s use this feature, in the hope that it helps
    prevent the flood fill from extending outside of the face. So we need to provide
    two mask images: one is the edge mask of *WxH* in size, and the other image is
    the exact same edge mask but *(W+2)x(H+2)* in size because it should include a
    border around the image. It is possible to have multiple `cv::Mat` objects (or
    headers) referencing the same data, or even to have a `cv::Mat` object that references
    a sub-region of another `cv::Mat` image. So, instead of allocating two separate
    images and copying the edge mask pixels across, let''s allocate a single mask
    image including the border, and create an extra `cv::Mat` header of *WxH* (that
    just references the region-of-interest in the flood fill mask without the border).
    In other words, there is just one array of pixels of size *(W+2)x(H+2)* but two
    `cv::Mat` objects, where one is referencing the whole *(W+2)x(H+2)* image and
    the other is referencing the *WxH* region in the middle of that image:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要缩小边缘掩码，使其与绘画图像具有相同的比例。在使用OpenCV的`floodFill()`函数时存在一个复杂问题，当存储到单独的掩码图像中时，掩码应围绕整个图像有1像素的边界，因此如果输入图像大小为*WxH*像素，则单独的掩码图像大小应为*(W+2)
    x (H+2)*像素。但是`floodFill()`函数也允许我们使用边缘初始化掩码，这样洪水填充算法将确保它不会交叉。让我们利用这个特性，希望它能帮助防止洪水填充扩展到面部之外。因此，我们需要提供两个掩码图像：一个是*WxH*大小的边缘掩码，另一个图像是大小完全相同的边缘掩码，但为*(W+2)x(H+2)*，因为它应包括图像周围的边界。可能存在多个`cv::Mat`对象（或头文件）引用相同的数据，或者甚至有一个`cv::Mat`对象引用另一个`cv::Mat`图像的子区域。因此，我们不是分配两个单独的图像并将边缘掩码像素复制过来，而是分配一个包含边界的单个掩码图像，并创建一个额外的*WxH*大小的`cv::Mat`头文件（它仅引用洪水填充掩码中的感兴趣区域，不包括边界）。换句话说，只有一个大小为*(W+2)x(H+2)*的像素数组，但有两个`cv::Mat`对象，其中一个是引用整个*(W+2)x(H+2)*图像，另一个是引用该图像中间的*WxH*区域：
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The edge mask (shown on the left of the following figure) is full of both strong
    and weak edges, but we only want strong edges, so we will apply a binary threshold
    (resulting in the middle image in the following figure). To join some gaps between
    edges, we will then combine the morphological operators `dilate()` and `erode()`
    to remove some gaps (also referred to as the close operator), resulting in the
    right of the figure:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘掩码（如图中左侧所示）充满了强和弱边缘，但我们只想保留强边缘，因此我们将应用二值阈值（结果如图中中间图像所示）。为了连接边缘之间的某些间隙，我们将结合形态学算子`dilate()`和`erode()`来消除一些间隙（也称为闭合算子），结果如图中右侧所示：
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](img/image_01_008.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_01_008.png)'
- en: 'As mentioned earlier, we want to apply flood fills in numerous points around
    the face, to make sure we include the various colors and shades of the whole face.
    Let''s choose six points around the nose, cheeks, and forehead, as shown on the
    left-hand side of the following figure. Note that these values are dependent on
    the face outline drawn earlier:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们想在面部周围多个点应用洪水填充，以确保包括整个面部的各种颜色和阴影。让我们选择六个点，围绕鼻子、面颊和额头，如图中左侧所示。请注意，这些值取决于之前绘制的面部轮廓：
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now we just need to find some good lower and upper bounds for the flood fill.
    Remember that this is being performed in *Y''CrCb* color-space, so we basically
    decide how much the brightness can vary, how much the red component can vary,
    and how much the blue component can vary. We want to allow the brightness to vary
    a lot, to include shadows as well as highlights and reflections, but we don''t
    want the colors to vary much at all:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需要找到洪水填充的一些良好的上下限。记住，这是在*Y'CrCb*颜色空间中进行的，所以我们基本上决定亮度可以变化多少，红色分量可以变化多少，以及蓝色分量可以变化多少。我们希望亮度变化很大，包括阴影、高光和反射，但我们不希望颜色变化很大：
- en: '[PRE18]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We will use the `floodFill()` function with its default flags, except that
    we want to store to an external mask, so we must specify `FLOODFILL_MASK_ONLY`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用带有默认标志的`floodFill()`函数，除了我们希望将其存储到外部掩码中，因此必须指定`FLOODFILL_MASK_ONLY`：
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following figure on the left-side shows the six flood fill locations (shown
    as circles), and the right-side of the figure shows the external mask that is
    generated, where skin is shown as gray and edges are shown as white. Note that
    the right-side image was modified for this book so that skin pixels (of value
    1) are clearly visible:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 下图左侧显示了六个洪水填充位置（以圆圈表示），图例右侧显示了生成的外部掩码，其中皮肤以灰色显示，边缘以白色显示。请注意，右侧图像已被修改以供本书使用，以便皮肤像素（值为1）清晰可见：
- en: '![](img/image_01_009.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_009.png)'
- en: 'The `mask` image (shown on the right side of the previous figure) now contains
    the following:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个图例右侧显示的`mask`图像现在包含以下内容：
- en: Pixels of value 255 for the edge pixels
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘像素的值为255
- en: Pixels of value 1 for the skin regions
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 皮肤区域的像素值为1
- en: Pixels of value 0 for the rest
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其余像素的值为0
- en: 'Meanwhile, `edgeMask` just contains edge pixels (as value 255). So to get just
    the skin pixels, we can remove the edges from it:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，`edgeMask`仅包含边缘像素（值为255）。因此，要仅获取皮肤像素，我们可以从其中移除边缘：
- en: '[PRE20]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The `mask` variable now just contains 1''s for skin pixels and 0''s for non-skin
    pixels. To change the skin color and brightness of the original image, we can
    use the `cv::add()`function with the skin mask, to increase the green component
    in the original BGR image:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`mask`变量现在仅包含皮肤像素的1和非皮肤像素的0。要更改原始图像的皮肤颜色和亮度，我们可以使用`cv::add()`函数与皮肤掩码一起使用，以增加原始BGR图像中的绿色分量：'
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The following figure shows the original image on the left, and the final alien
    cartoon image on the right, where at least six parts of the face will now be green!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了左侧的原始图像和右侧的最终外星人卡通图像，其中现在至少有六个面部部分将变为绿色！
- en: '![](img/image_01_010.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_010.png)'
- en: Notice that we have made the skin look green but also brighter (to look like
    an alien that glows in the dark). If you want to just change the skin color without
    making it brighter, you can use other color changing methods, such as adding 70
    to green while subtracting 70 from red and blue, or convert to HSV color space
    using `cvtColor(src, dst, "CV_BGR2HSV_FULL")`, and adjust the hue and saturation.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已经使皮肤看起来更绿也更亮（看起来像在黑暗中发光的外星人）。如果您只想改变皮肤颜色而不使其变亮，可以使用其他颜色变换方法，例如在绿色上添加70，同时从红色和蓝色中减去70，或者使用`cvtColor(src,
    dst, "CV_BGR2HSV_FULL")`转换为HSV颜色空间，并调整色调和饱和度。
- en: Reducing the random pepper noise from the sketch image
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少草图图像中的随机胡椒噪声
- en: Most of the tiny cameras in smartphones, RPi Camera Modules, and some webcams
    have significant image noise. This is normally acceptable, but it has a large
    effect on our 5x5 Laplacian edge filter. The edge mask (shown as the sketch mode)
    will often have thousands of small blobs of black pixels called **pepper noise**,
    made of several black pixels next to each other in a white background. We are
    already using a Median filter, which is usually strong enough to remove pepper
    noise, but in our case it may not be strong enough. Our edge mask is mostly a
    pure white background (value of 255) with some black edges (value of 0) and the
    dots of noise (also values of 0). We could use a standard closing morphological
    operator but it will remove a lot of edges. So instead, we will apply a custom
    filter that removes small black regions that are surrounded completely by white
    pixels. This will remove a lot of noise while having little effect on actual edges.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 智能手机中的大多数小型摄像头、RPi摄像头模块和一些网络摄像头都有明显的图像噪声。这通常是可接受的，但它对我们的5x5拉普拉斯边缘过滤器有很大的影响。边缘掩码（如图所示为草图模式）通常会有成千上万的黑色像素小团块，称为**胡椒噪声**，由几个相邻的黑色像素在白色背景中组成。我们已经在使用中值滤波器，这通常足以去除胡椒噪声，但在此情况下可能不够强大。我们的边缘掩码主要是纯白色背景（值为255）和一些黑色边缘（值为0）以及噪声点（也是值为0）。我们可以使用标准的闭合形态学算子，但它将去除很多边缘。因此，我们将应用一个自定义过滤器，该过滤器移除完全被白色像素包围的小黑色区域。这将去除很多噪声，同时对实际边缘的影响很小。
- en: We will scan the image for black pixels, and at each black pixel, we'll check
    the border of the 5x5 square around it to see if all the 5x5 border pixels are
    white. If they are all white then we know we have a small island of black noise,
    so then we fill the whole block with white pixels to remove the black island.
    For simplicity in our 5x5 filter, we will ignore the two border pixels around
    the image and leave them as they are.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将扫描图像中的黑色像素，并在每个黑色像素周围检查5x5平方区域的边界，看是否所有5x5边界像素都是白色。如果它们都是白色，那么我们知道我们有一个小的黑色噪声岛，因此我们将整个块填充为白色像素以去除黑色岛屿。为了简化我们的5x5过滤器，我们将忽略图像周围的两个边界像素，并保持它们不变。
- en: 'The following figure shows the original image from an Android tablet on the
    left-side, with a sketch mode in the center, showing small black dots of pepper
    noise, and the result of our pepper-noise removal shown on the right-side, where
    the skin looks cleaner:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了左侧的Android平板电脑上的原始图像，中间是草图模式，显示了中间的小黑点椒噪声，右侧显示了我们的椒噪声去除结果，皮肤看起来更干净：
- en: '![](img/image_01_011.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_01_011.png)'
- en: 'The following code can be named the `removePepperNoise()`function to edit the
    image in-place for simplicity:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可以命名为`removePepperNoise()`函数，以简化图像的编辑：
- en: '[PRE22]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: That's all! Run the app in the different modes until you are ready to port it
    to embedded!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！在不同的模式下运行应用程序，直到你准备好将其迁移到嵌入式系统！
- en: Porting from desktop to embedded
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从桌面迁移到嵌入式系统
- en: Now that the program works on desktop, we can make an embedded system from it.
    The details given here are specific to Raspberry Pi, but similar steps apply when
    developing for other embedded Linux systems such as BeagleBone, ODROID, Olimex,
    Jetson, and so on.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在程序在桌面上运行良好，我们可以从它制作一个嵌入式系统。这里给出的细节是针对Raspberry Pi的，但类似的步骤也适用于为其他嵌入式Linux系统开发，如BeagleBone、ODROID、Olimex、Jetson等。
- en: There are several different options for running our code on an embedded system,
    each with some advantages and disadvantages in different scenarios.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在嵌入式系统上运行我们的代码有几种不同的选择，每种选择在不同场景下都有一些优缺点。
- en: 'There are two common methods for compiling the code for an embedded device:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 编译嵌入式设备代码有两种常见方法：
- en: Copy the source code from the desktop onto the device and compile it directly
    onboard the device. This is often referred to as **native compilation**, since
    we are compiling our code natively on the same system that it will eventually
    run on.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源代码从桌面复制到设备上，并在设备上直接编译。这通常被称为**原生编译**，因为我们是在最终运行代码的同一系统上本地编译代码。
- en: Compile all the code on the desktop but using special methods to generate code
    for the device, and then you copy the final executable program onto the device.
    This is often referred to as **cross-compilation** since you need a special compiler
    that knows how to generate code for other types of CPUs.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在桌面上编译所有代码，但使用特殊方法生成设备的代码，然后将最终的可执行程序复制到设备上。这通常被称为**交叉编译**，因为你需要一个特殊的编译器，它知道如何为其他类型的CPU生成代码。
- en: Cross-compilation is often significantly harder to configure than native compilation,
    especially if you are using many shared libraries, but since your desktop is usually
    a lot faster than your embedded device, cross-compilation is often much faster
    at compiling large projects. If you expect to be compiling your project hundreds
    of times so as to work on it for months, and your device is quite slow compared
    to your desktop, such as the Raspberry Pi 1 or Raspberry Pi Zero that are very
    slow compared to a desktop, then cross-compilation is a good idea. But in most
    cases, especially for small simple projects, you should just stick with native
    compilation since it is easier.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与原生编译相比，交叉编译通常配置起来要困难得多，尤其是如果你使用了多个共享库。但是，由于你的桌面通常比你的嵌入式设备快得多，交叉编译在编译大型项目时通常要快得多。如果你预计要编译你的项目数百次，以便在几个月内对其进行工作，并且你的设备与桌面相比相当慢，比如与桌面相比非常慢的Raspberry
    Pi 1或Raspberry Pi Zero，那么交叉编译是一个好主意。但在大多数情况下，特别是对于小型简单项目，你应该坚持使用原生编译，因为它更容易。
- en: Note that all the libraries used by your project will also need to be compiled
    for the device, so you will need to compile OpenCV for your device. Natively compiling
    OpenCV on a Raspberry Pi 1 can take hours, whereas, cross-compiling OpenCV on
    a desktop might take just 15 minutes. But you usually only need to compile OpenCV
    once and then you'll have it for all your projects, so it is still worth sticking
    with native compilation of your project (including native compilation of OpenCV)
    in most cases.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你项目中使用的所有库也需要为设备编译，因此你需要为你的设备编译OpenCV。在Raspberry Pi 1上本地编译OpenCV可能需要数小时，而桌面交叉编译OpenCV可能只需15分钟。但通常你只需要编译一次OpenCV，然后你就可以为所有项目使用它，所以大多数情况下，坚持使用项目的原生编译（包括OpenCV的原生编译）仍然是值得的。
- en: 'There are also several options for how to run the code on an embedded system:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在嵌入式系统上运行代码也有几种选择：
- en: Use the same input and output methods you used on desktop, such as the same
    video files or USB webcam or keyboard as input, and display text or graphics to
    an HDMI monitor in the same way you were doing on desktop.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用与桌面相同的输入和输出方法，例如相同的视频文件或 USB 摄像头或键盘作为输入，并以与桌面相同的方式将文本或图形显示到 HDMI 显示器上。
- en: Use special devices for input and output. For example, instead of sitting at
    a desk using a USB webcam and keyboard as input and displaying the output to a
    desktop monitor, you could use the special Raspberry Pi Camera Module for video
    input, use custom GPIO push-buttons or sensors for input, and use a 7-inch MIPI
    DSI screen or GPIO LED lights as the output, and then by powering it all with
    a common **portable USB charger**, you can be wearing the whole computer platform
    in your backpack or attach it on your bicycle!
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用特殊的输入和输出设备。例如，你不必坐在桌前使用 USB 摄像头和键盘作为输入，并将输出显示到桌面显示器上，你可以使用特殊的树莓派摄像头模块作为视频输入，使用定制的
    GPIO 推按钮或传感器作为输入，并使用 7 英寸 MIPI DSI 屏幕或 GPIO LED 灯作为输出，然后通过一个通用的**便携式 USB 充电器**为所有设备供电，你就可以将整个计算机平台背在背包里，或者将其固定在自行车上！
- en: Another option is to stream data in or out of the embedded device to other computers,
    or even use one device to stream out the camera data and one device to use that
    data. For example, you can use the Gstreamer framework to configure the Raspberry
    Pi to stream H.264 compressed video from its Camera Module onto the Ethernet network
    or through Wi-Fi, so that a powerful PC or server rack on the local network or
    Amazon AWS cloud-computing services can process the video stream somewhere else.
    This method allows a small and cheap camera device to be used in a complex project
    requiring large processing resources located somewhere else.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个选择是将数据流进或流出嵌入式设备到其他计算机，或者甚至使用一个设备来输出摄像头数据，另一个设备来使用这些数据。例如，你可以使用 Gstreamer
    框架来配置树莓派，从其摄像头模块流式传输 H.264 压缩视频到以太网网络或通过 Wi-Fi，这样局域网中的强大 PC 或服务器机架或亚马逊 AWS 云计算服务就可以在其他地方处理视频流。这种方法允许使用一个小巧廉价的摄像头设备，在需要位于其他地方的大量处理资源的复杂项目中使用。
- en: If you do wish to perform computer vision onboard the device, beware that some
    low-cost embedded devices such as Raspberry Pi 1, Raspberry Pi Zero, and BeagleBone
    Black have significantly slower computing power than desktops or even cheap netbooks
    or smartphones, perhaps 10-50 times slower than your desktop, so depending on
    your application you might need a powerful embedded device or to stream video
    to a separate computer as mentioned previously. If you don't need much computing
    power (for example, you only need to process one frame every 2 seconds, or you
    only need to use 160x120 image resolution), then a Raspberry Pi Zero running some
    Computer Vision onboard might be fast enough for your requirements. But many Computer
    Vision systems need far more computing power, and so if you want to perform Computer
    Vision onboard the device, you will often want to use a much faster device with
    a CPU in the range of 2 GHz, such as a Raspberry Pi 3, ODROID-XU4, or Jetson TK1.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实希望在设备上执行计算机视觉，请注意，一些低成本嵌入式设备，如树莓派 1、树莓派 Zero 和 BeagleBone Black，其计算能力比桌面或甚至廉价的上网本或智能手机慢得多，可能比你的桌面慢
    10-50 倍，因此根据你的应用，你可能需要一个功能强大的嵌入式设备，或者像之前提到的那样将视频流到另一台计算机。如果你不需要太多的计算能力（例如，你只需要每
    2 秒处理一帧，或者你只需要使用 160x120 的图像分辨率），那么运行一些计算机视觉的树莓派 Zero 可能足够快以满足你的需求。但许多计算机视觉系统需要更多的计算能力，因此如果你想在设备上执行计算机视觉，你通常会想要使用一个速度更快的设备，其
    CPU 在 2 GHz 范围内，例如树莓派 3、ODROID-XU4 或 Jetson TK1。
- en: Equipment setup to develop code for an embedded device
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为开发嵌入式设备代码的设备设置
- en: Let's begin by keeping it as simple as possible, by using a USB keyboard and
    mouse and a HDMI monitor just like our desktop system, compiling the code natively
    on the device, and running our code on the device. Our first step will be to copy
    the code onto the device, install the build tools, and compile OpenCV and our
    source code on the embedded system.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从尽可能简单开始，使用 USB 键盘和鼠标以及 HDMI 显示器，就像我们的桌面系统一样，在设备上本地编译代码，并在设备上运行我们的代码。我们的第一步将是将代码复制到设备上，安装构建工具，并在嵌入式系统上编译
    OpenCV 和我们的源代码。
- en: Many embedded devices such as Raspberry Pi have an HDMI port and at least one
    USB port. Therefore, the easiest way to start using an embedded device is to plug
    in a HDMI monitor and USB keyboard and mouse for the device, to configure settings
    and see output, while doing the code development and testing using your desktop
    machine. If you have a spare HDMI monitor, plug that into the device, but if you
    don't have a spare HDMI monitor, you might consider buying a small HDMI screen
    just for your embedded device.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 许多嵌入式设备，如 Raspberry Pi，都有一个 HDMI 端口和至少一个 USB 端口。因此，开始使用嵌入式设备的最简单方法是连接一个 HDMI
    显示器和 USB 键盘和鼠标，以配置设置并查看输出，同时在您的桌面机器上开发代码并进行测试。如果您有一个备用的 HDMI 显示器，可以将其连接到设备上，但如果您没有备用的
    HDMI 显示器，您可能需要考虑购买一个小型 HDMI 屏幕专门用于您的嵌入式设备。
- en: Also, if you don't have a spare USB keyboard and mouse, you might consider buying
    a wireless keyboard and mouse that has a single USB wireless dongle, so you only
    use up a single USB port for both the keyboard and mouse. Many embedded devices
    use a 5V power supply, but they usually need more power (electrical current) than
    a desktop or laptop will provide in its USB port. So you should obtain either
    a separate 5V USB charger (atleast 1.5 Amps, *ideally 2.5 Amps*), or a portable
    USB battery charger that can provide atleast 1.5 Amps of output current. Your
    device might only use 0.5 Amps most of the time, but there will be occasional
    times when it needs over 1 Amps, so it's important to use a power supply that
    is rated for at least 1.5 Amps or more, otherwise your device will occasionally
    reboot or some hardware could behave strangely at important times or the filesystem
    could become corrupt and you lose your files! A 1 Amp supply might be good enough
    if you don't use cameras or accessories, but 2.0-2.5 Amps is safer.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果您没有备用的 USB 键盘和鼠标，您可能需要考虑购买一个带有单个 USB 无线接收器的无线键盘和鼠标，这样您只需为键盘和鼠标使用一个 USB
    端口。许多嵌入式设备使用 5V 电源，但它们通常需要的电力（电流）比桌面或笔记本电脑的 USB 端口提供的要多。因此，您应该获得一个单独的 5V USB 充电器（至少
    1.5 安培，*理想情况下 2.5 安培*），或者一个可携带的 USB 电池充电器，可以提供至少 1.5 安培的输出电流。您的设备可能大多数时候只需要 0.5
    安培的电流，但偶尔它可能需要超过 1 安培的电流，因此使用至少 1.5 安培或更高额定功率的电源很重要，否则您的设备可能会偶尔重新启动，或者某些硬件在关键时刻可能会出现异常行为，或者文件系统可能会损坏，您会丢失文件！如果您不使用摄像头或配件，1
    安培的电源可能足够好，但 2.0-2.5 安培更安全。
- en: 'For example, the following photographs show a convenient setup containing a
    Raspberry Pi 3, a good quality 8 GB micro-SD card for $10 ([http://ebay.to/2ayp6Bo](http://ebay.to/2ayp6Bo)),
    a 5-inch HDMI resistive-touchscreen for $30-$45 ([http://bit.ly/2aHQO2G](http://bit.ly/2aHQO2G)),
    a wireless USB keyboard and mouse for $30 ([http://ebay.to/2aN2oXi](http://ebay.to/2aN2oXi)),
    a **5V 2.5A** power supply for $5 ([http://ebay.to/2aCBLVK](http://ebay.to/2aCBLVK)),
    a USB webcam such as the very fast **PS3 Eye** for just $5 ([http://ebay.to/2aVWCUS](http://ebay.to/2aVWCUS)),
    a Raspberry Pi Camera Module v1 or v2 for $15-$30 ([http://bit.ly/2aF9PxD](http://bit.ly/2aF9PxD)),
    and an Ethernet cable for $2 ([http://ebay.to/2aznnjd](http://ebay.to/2aznnjd)),connecting
    the Raspberry Pi into the same LAN network as your development PC or laptop. Notice
    that this HDMI screen is designed specifically for the Raspberry Pi, since the
    screen plugs directly into the Raspberry Pi below it, and has a HDMI male-to-male
    adapter (shown in the right-hand side photo) for the Raspberry Pi so you don''t
    need an HDMI cable, whereas other screens may require an HDMI cable ([http://ebay.to/2aW4Fko](http://ebay.to/2aW4Fko))
    or MIPI DSI or SPI cable. Also note that some screens and touch panels need configuration
    before they will work, whereas most HDMI screens should work without any configuration:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下照片展示了一个方便的设置，包括一个 Raspberry Pi 3，一张质量良好的 8 GB micro-SD 卡，售价 10 美元 ([http://ebay.to/2ayp6Bo](http://ebay.to/2ayp6Bo))，一个
    5 英寸 HDMI 触摸屏，售价 30-45 美元 ([http://bit.ly/2aHQO2G](http://bit.ly/2aHQO2G))，一个无线
    USB 键盘和鼠标，售价 30 美元 ([http://ebay.to/2aN2oXi](http://ebay.to/2aN2oXi))，一个 **5V
    2.5A** 电源，售价 5 美元 ([http://ebay.to/2aCBLVK](http://ebay.to/2aCBLVK))，一个 USB 摄像头，例如非常快速的
    **PS3 Eye**，只需 5 美元 ([http://ebay.to/2aVWCUS](http://ebay.to/2aVWCUS))，一个 Raspberry
    Pi Camera Module v1 或 v2，售价 15-30 美元 ([http://bit.ly/2aF9PxD](http://bit.ly/2aF9PxD))，以及一根网线，售价
    2 美元 ([http://ebay.to/2aznnjd](http://ebay.to/2aznnjd))，将 Raspberry Pi 连接到与您的开发
    PC 或笔记本电脑相同的局域网。请注意，这个 HDMI 屏幕是专门为 Raspberry Pi 设计的，因为屏幕直接插在下面的 Raspberry Pi 上，并有一个
    HDMI 公对公适配器（如右手边照片所示）供 Raspberry Pi 使用，因此您不需要 HDMI 线，而其他屏幕可能需要 HDMI 线 ([http://ebay.to/2aW4Fko](http://ebay.to/2aW4Fko))
    或 MIPI DSI 或 SPI 线。另外，请注意，一些屏幕和触摸屏在它们工作之前需要配置，而大多数 HDMI 屏幕则无需配置即可工作：
- en: '![](img/image_01_012.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_01_012.png)'
- en: Notice the black USB webcam (on the far left of the LCD), the Raspberry Pi Camera
    Module (green and black board sitting on the top-left corner of the LCD), Raspberry
    Pi board (underneath the LCD), HDMI adapter (connecting the LCD to the Raspberry
    Pi below it), a blue Ethernet cable (plugged into a router), a small USB wireless
    keyboard and mouse dongle, and a micro-USB power cable (plugged into a **5V 2.5A**
    power supply).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意黑色USB摄像头（位于LCD最左侧），Raspberry Pi摄像头模块（绿色和黑色的板子位于LCD的左上角），Raspberry Pi板（位于LCD下方），HDMI适配器（连接LCD和下方的Raspberry
    Pi），蓝色以太网线（插入路由器），小型USB无线键盘和鼠标适配器，以及微型USB电源线（插入**5V 2.5A**电源供应）。
- en: Configuring a new Raspberry Pi
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置新的Raspberry Pi
- en: 'The following steps are specific to Raspberry Pi (also referred to as an **RPi**),
    so if you are using a different embedded device or you want a different type of
    setup, search the Web about how to setup your board. To setup an RPi 1, 2, or
    3 (including their variants such as RPi Zero, RPi2B, 3B, and so on, and RPi 1A+
    if you plug in a USB Ethernet dongle):'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤仅适用于Raspberry Pi（也称为**RPi**），如果您使用的是不同的嵌入式设备或您想要不同的设置类型，请在网络上搜索如何设置您的板子。要设置RPi
    1、2或3（包括其变体，如RPi Zero、RPi2B、3B等，以及如果您插入USB以太网适配器，RPi 1A+），请按照以下步骤操作：
- en: Get a fairly new, *good-quality micro-SD card* of at least 8 GB. If you use
    a cheap micro-SD card or an old micro-SD card that you already used many times
    before and it has degraded in quality, it might not be reliable enough to boot
    the RPi, so if you have trouble booting the RPi, you should try a good quality
    Class 10 micro-SD card (such as SanDisk Ultra or better) that says it handles
    at least 45 MB/s or can handle 4K video.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取一张至少8 GB的较新、*高质量的小型SD卡*。如果您使用的是廉价的微型SD卡或已经多次使用且质量下降的旧微型SD卡，它可能不足以可靠地启动RPi，因此如果您在启动RPi时遇到问题，应尝试使用高质量Class
    10微型SD卡（例如SanDisk Ultra或更好），这种卡声称至少可以处理45 MB/s或可以处理4K视频。
- en: Download and burn the latest **Raspbian IMG** (not NOOBS) to the micro-SD card.
    Note that *burning an IMG is different to simply copying the file to SD*. Visit
    [https://www.raspberrypi.org/documentation/installation/installing-images/](https://www.raspberrypi.org/documentation/installation/installing-images/)
    and follow the instructions for your desktop's OS, to burn Raspbian to a micro-SD
    card. Be aware that you will lose any files that were previously on the card.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并将最新的**Raspbian IMG**（不是NOOBS）烧录到微型SD卡上。请注意，*烧录IMG与简单地将文件复制到SD卡不同*。访问[https://www.raspberrypi.org/documentation/installation/installing-images/](https://www.raspberrypi.org/documentation/installation/installing-images/)，按照您桌面操作系统的说明将Raspbian烧录到微型SD卡。请注意，您将丢失卡上之前存在的任何文件。
- en: Plug a USB keyboard and mouse and HDMI display into the RPi, so you can easily
    run some commands and see the output.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将USB键盘、鼠标和HDMI显示器插入RPi，这样您就可以轻松运行一些命令并查看输出。
- en: Plug the RPi into a 5V USB power supply with atleast 1.5A, ideally 2.5A or higher.
    Computer USB ports aren't powerful enough.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将RPi插入至少1.5A、理想情况下2.5A或更高电压的5V USB电源。计算机USB端口不够强大。
- en: You should see many pages of text scrolling while it is booting up Raspbian
    Linux, then it should be ready after 1 or 2 minutes.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在启动Raspbian Linux时，您应该会看到许多页面文本滚动，然后大约1到2分钟后应该就绪。
- en: If, after booting, it's just showing a black console screen with some text (such
    as if you downloaded **Raspbian Lite**), you are at the text-only login prompt.
    Log in by typing `pi` as the username and then hit *Enter*. Then type `raspberry`
    as the password and hit *Enter* again.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果启动后只显示一个带有一些文本（如下载了**Raspbian Lite**）的黑屏控制台，您处于纯文本登录提示符。通过输入用户名`pi`并按*Enter*键登录。然后输入密码`raspberry`并再次按*Enter*键。
- en: Or if it booted to the graphical display, click on the black Terminal icon at
    the top to open a shell (Command Prompt).
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 或者，如果它启动到图形显示，请点击顶部的黑色终端图标以打开shell（命令提示符）。
- en: 'Initialize some settings in your RPi:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的RPi中初始化一些设置：
- en: Type `sudo raspi-config` and hit *Enter* (see the following screenshot).
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入`sudo raspi-config`并按*Enter*键（见以下截图）。
- en: First, run **Expand Filesystem** and then finish and reboot your device, so
    the Raspberry Pi can use the whole micro-SD card.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，运行**扩展文件系统**，然后完成并重新启动您的设备，这样Raspberry Pi就可以使用整个微型SD卡。
- en: If you use a normal (US) keyboard, not a British keyboard, in Internationalization
    Options, change to Generic 104-key keyboard, Other, English (US), and then for
    the `AltGr` and similar questions just hit *Enter* unless you are use a special
    keyboard.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您使用的是普通（美国）键盘，而不是英国键盘，在国际化选项中，将其更改为通用104键键盘，其他，英语（美国），然后对于`AltGr`和类似的问题，只需按*Enter*键，除非您使用的是特殊键盘。
- en: In Enable Camera, enable the RPi Camera Module.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在启用摄像头中，启用RPi摄像头模块。
- en: In Overclock Options, set to RPi2 or similar so the device runs faster (but
    generates more heat).
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在超频选项中，设置为RPi2或类似型号，以便设备运行更快（但会产生更多热量）。
- en: In Advanced Options, enable SSH server.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在高级选项中，启用SSH服务器。
- en: In Advanced Options, if you are using Raspberry Pi 2 or 3, **change Memory Split
    to 256MB** so the GPU has plenty of RAM for video processing. For Raspberry Pi
    1 or Zero, use 64 MB or the default.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在高级选项中，如果您使用的是Raspberry Pi 2或3，**将内存分割更改为256MB**，以便GPU有足够的RAM进行视频处理。对于Raspberry
    Pi 1或Zero，使用64MB或默认值。
- en: Finish then Reboot the device.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成后重启设备。
- en: '(Optional) Delete Wolfram, to save 600 MB of space on your SD card:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）删除Wolfram，以在您的SD卡上节省600MB的空间：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: It can be installed back using `sudo apt-get install wolfram-engine`
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`sudo apt-get install wolfram-engine`重新安装。
- en: To see the remaining space on your SD card, run `df -h | head -2`
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看SD卡上的剩余空间，运行`df -h | head -2`
- en: '![](img/image_01_013.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_01_013.png)'
- en: 'Assuming you plugged the RPi into your Internet router, it should already have
    Internet access. So update your RPi to the latest RPi firmware, software locations,
    OS, and software. **Warning**: Many Raspberry Pi tutorials say you should run
    `sudo rpi-update`; however, in recent years it''s no longer a good idea to run
    `rpi-update` since it can give you an unstable system or firmware. The following
    instructions will update your Raspberry Pi to have stable software and firmware
    (note that these commands might take up to 1 hour):'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设您已将RPi连接到您的互联网路由器，它应该已经具有互联网访问权限。因此，将您的RPi更新到最新的RPi固件、软件位置、操作系统和软件。**警告**：许多Raspberry
    Pi教程建议您运行`sudo rpi-update`；然而，近年来运行`rpi-update`已不再是一个好主意，因为它可能会给您带来不稳定的系统或固件。以下说明将更新您的Raspberry
    Pi，使其具有稳定的软件和固件（请注意，这些命令可能需要1小时左右）：
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Find the IP address of the device:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找设备的IP地址：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Try accessing the device from your desktop.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试从您的桌面访问设备。
- en: For example, assuming the device's IP address is `192.168.2.101`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设设备的IP地址是`192.168.2.101`。
- en: 'On a Linux desktop:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux桌面上：
- en: '[PRE26]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Or on a Windows desktop:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 或者在一个Windows桌面上：
- en: Download, install, and run PuTTY
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载、安装并运行PuTTY
- en: Then in PuTTY, connect to the IP address (192.168.2.101),
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后在PuTTY中，连接到IP地址（192.168.2.101），
- en: As user `pi` with password `raspberry`
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用用户`pi`和密码`raspberry`
- en: '(Optional) If you want your Command Prompt to be a different color than the
    commands and show the error value after each command:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）如果您希望您的命令提示符与命令颜色不同，并在每个命令后显示错误值：
- en: '[PRE27]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Add this line to the bottom:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 将此行添加到末尾：
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Save the file (hit *Ctrl* + *X*, then hit *Y*, and then hit *Enter*).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 保存文件（按*Ctrl* + *X*，然后按*Y*，然后按*Enter*）。
- en: 'Start using the new settings:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用新设置：
- en: '[PRE29]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To disable the screensaver/screen blank power saving feature in Raspbian from
    turning off your screen on idle:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要禁用Raspbian中的屏幕保护程序/屏幕空白省电功能，以防止在空闲时关闭屏幕：
- en: '[PRE30]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Look for the line that says `#xserver-command=X` (jump to line 87 by pressing
    *Alt* + *G* and then typing `87` and hitting *Enter*).
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找说`#xserver-command=X`的行（通过按*Alt* + *G*跳转到行87，然后输入`87`并按*Enter*）。
- en: Change it to: `**xserver-command=X -s 0 dpms**`
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改为：`**xserver-command=X -s 0 dpms**`
- en: Save the file (hit *Ctrl* + *X* then hit *Y* then hit *Enter*).
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存文件（按*Ctrl* + *X*然后按*Y*然后按*Enter*）。
- en: '[PRE31]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: You should be ready to start developing on the device now!
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在应该准备好开始在设备上开发了！
- en: Installing OpenCV on an embedded device
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在嵌入式设备上安装OpenCV
- en: 'There is a very easy way to install OpenCV and all its dependencies on a Debian-based
    embedded device such as Raspberry Pi:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于Debian的嵌入式设备（如Raspberry Pi）上安装OpenCV及其所有依赖项有一个非常简单的方法：
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: However, that might install an old version of OpenCV from 1 or 2 years ago.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这可能会安装来自1或2年前的旧版OpenCV。
- en: 'To install the latest version of OpenCV on an embedded device such as Raspberry
    Pi, we need to build OpenCV from the source code. First we install a compiler
    and build system, then libraries for OpenCV to use, and finally OpenCV itself.
    Note that the steps for compiling OpenCV from source on Linux is the same whether
    you are compiling for desktop or for embedded. A Linux script `install_opencv_from_source.sh`
    is provided with this book; it is recommended you copy the file onto your Raspberry
    Pi (for example, with a USB flash stick) and run the script to download, build,
    and install OpenCV including potential multi-core CPU and **ARM NEON SIMD** optimizations
    (depending on hardware support):'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Raspberry Pi这样的嵌入式设备上安装OpenCV的最新版本，我们需要从源代码构建OpenCV。首先，我们安装一个编译器和构建系统，然后安装OpenCV所需的库，最后安装OpenCV本身。请注意，在Linux上从源代码编译OpenCV的步骤，无论是为桌面还是为嵌入式编译都是相同的。本书提供了一个名为`install_opencv_from_source.sh`的Linux脚本；建议您将文件复制到Raspberry
    Pi上（例如，使用USB闪存驱动器）并运行脚本以下载、构建和安装OpenCV，包括潜在的CPU多核和**ARM NEON SIMD**优化（取决于硬件支持）：
- en: '[PRE33]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The script will stop if there is any error; for example, if you don't have Internet
    access, or a dependency package conflicts with something else you already installed.
    If the script stops with an error, try using info on the Web to solve that error,
    then run the script again. The script will quickly check all the previous steps
    and then continue from where it finished last time. Note that it will take between
    20 minutes to 12 hours depending on your hardware and software!
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有任何错误，脚本将停止；例如，如果您没有互联网访问，或者依赖包与您已经安装的其他东西冲突。如果脚本因错误而停止，请尝试使用网络上的信息来解决该错误，然后再次运行脚本。脚本将快速检查所有之前的步骤，然后从上次停止的地方继续。请注意，根据您的硬件和软件，这可能需要20分钟到12小时不等！
- en: It's highly recommended to build and run a few OpenCV samples every time you've
    installed OpenCV, so when you have problems building your own code, at least you
    will know whether the problem is the OpenCV installation or a problem with your
    code.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 高度推荐每次安装OpenCV后都构建和运行几个OpenCV示例，这样当您构建自己的代码时遇到问题时，至少您会知道问题是不是OpenCV安装的问题，或者是不是代码本身的问题。
- en: 'Let''s try to build the simple *edge* sample program. If we try the same Linux
    command to build it from OpenCV 2, we get a build error:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试构建简单的*edge*示例程序。如果我们尝试使用相同的Linux命令从OpenCV 2构建它，我们会得到一个构建错误：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The second to last line of that error message tells us that a library was missing
    from the command line, so we simply need to add `-lopencv_imgcodecs` in our command
    next to the other OpenCV libraries we linked to. Now you know how to fix the problem
    anytime you are compiling an OpenCV 3 program and you see that error message.
    So let''s do it correctly:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 那个错误信息的倒数第二行告诉我们命令行中缺少了一个库，所以我们只需要在链接到其他OpenCV库的命令旁边添加`-lopencv_imgcodecs`。现在您知道如何修复在编译OpenCV
    3程序时遇到该错误信息的问题。所以让我们正确地做：
- en: '[PRE35]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'It worked! So now you can run the program:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 成功了！所以现在您可以运行程序：
- en: '[PRE36]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Hit *Ctrl* + *C* on your keyboard to quit the program. Note that the *edge*
    program might crash if you try running the command in an SSH terminal and you
    don''t redirect the window to display on the device''s LCD screen. So if you are
    using SSH to remotely run the program, add *DISPLAY=:0* before your command:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在键盘上按*Ctrl* + *C*来退出程序。请注意，如果尝试在SSH终端中运行命令而没有将窗口重定向到设备的LCD屏幕上，*edge*程序可能会崩溃。所以如果您使用SSH远程运行程序，请在命令前添加*DISPLAY=:0*：
- en: '[PRE37]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You should also plug a USB webcam into the device and test that it works:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应该将USB摄像头插入设备并测试它是否工作：
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Note: If you don''t have a USB webcam, you can test using a video file:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您没有USB摄像头，可以使用视频文件进行测试：
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now that OpenCV is successfully installed on your device, you can run the Cartoonifier
    applications we developed earlier. Copy the `Cartoonifier` folder onto the device
    (for example, by using a USB flash stick, or using `scp` to copy files over the
    network). Then build the code just like you did for desktop:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在OpenCV已成功安装在您的设备上，您可以运行我们之前开发的Cartoonifier应用程序。将`Cartoonifier`文件夹复制到设备上（例如，使用USB闪存驱动器或使用`scp`通过网络复制文件）。然后像为桌面一样构建代码：
- en: '[PRE40]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'And run it:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行它：
- en: '[PRE41]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![](img/image_01_014.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_01_014.png)'
- en: Using the Raspberry Pi Camera Module
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Raspberry Pi摄像头模块
- en: While using a USB webcam on Raspberry Pi has the convenience of supporting identical
    behavior and code on desktop as on embedded device, you might consider using one
    of the official Raspberry Pi Camera Modules (referred to as the **RPi Cams**).
    They have some advantages and disadvantages over USB webcams.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在Raspberry Pi上使用USB摄像头可以方便地支持在桌面和嵌入式设备上具有相同的行为和代码，但你可能考虑使用官方的Raspberry Pi摄像头模块（简称**RPi
    Cams**）。它们与USB摄像头相比，有一些优缺点。
- en: The RPi Cams use the special MIPI CSI camera format, designed for smartphone
    cameras to use less power. They have smaller physical size, faster bandwidth,
    higher resolutions, higher frame rates, and reduced latency, compared to USB.
    Most USB 2.0 webcams can only deliver 640x480 or 1280x720 30 FPS video, since
    USB 2.0 is too slow for anything higher (except for some expensive USB webcams
    that perform onboard video compression) and USB 3.0 is still too expensive. Whereas,
    smartphone cameras (including the RPi Cams) can often deliver 1920x1080 30 FPS
    or even Ultra HD/4K resolutions. The RPi Cam v1 can in fact deliver upto 2592x1944
    15 FPS or 1920x1080 30 FPS video even on a $5 Raspberry Pi Zero, thanks to the
    use of MIPI CSI for the camera and a compatible video processing ISP and GPU hardware
    inside the Raspberry Pi. The RPi Cams also support 640x480 in 90 FPS mode (such
    as for slow-motion capture), and this is quite useful for real-time computer vision
    so you can see very small movements in each frame, rather than large movements
    that are harder to analyze.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: RPi摄像头使用特殊的MIPI CSI摄像头格式，专为智能手机摄像头设计，以减少功耗。与USB相比，它们具有更小的物理尺寸、更快的带宽、更高的分辨率、更高的帧率和更低的延迟。大多数USB
    2.0摄像头只能提供640x480或1280x720 30 FPS的视频，因为USB 2.0对于任何更高的速度都太慢（除非是一些昂贵的USB摄像头，它们在板上进行视频压缩），而USB
    3.0仍然太贵。而智能手机摄像头（包括RPi摄像头）通常可以提供1920x1080 30 FPS或甚至超高清/4K分辨率。实际上，RPi Cam v1可以在$5的Raspberry
    Pi Zero上提供高达2592x1944 15 FPS或1920x1080 30 FPS的视频，这得益于使用了MIPI CSI摄像头和Raspberry
    Pi内部兼容的视频处理ISP和GPU硬件。RPi摄像头还支持在90 FPS模式下使用640x480（例如用于慢动作捕捉），这对于实时计算机视觉非常有用，因为你可以看到每一帧中的非常小的运动，而不是难以分析的大运动。
- en: However, the RPi Cam is a plain circuit board that is *highly sensitive* to
    electrical interference, static electricity, or physical damage (simply touching
    the small orange flat cable with your finger can cause video interference or even
    permanently damage your camera!). The big flat white cable is far less sensitive
    but it is still very sensitive to electrical noise or physical damage. The RPi
    Cam comes with a very short 15 cm cable. It's possible to buy third-party cables
    on eBay with lengths between 5 cm to 1 m, but cables 50cm or longer are less reliable,
    whereas USB webcams can use 2 m to 5 m cables and can be plugged into USB hubs
    or active extension cables for longer distances.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RPi摄像头是一个简单的电路板，对电气干扰、静电或物理损伤非常敏感（只需用手指轻轻触摸那根小橙色的扁平电缆，就可能导致视频干扰，甚至永久损坏你的摄像头！）大扁平白色电缆的敏感性较低，但它对电气噪声或物理损伤仍然非常敏感。RPi摄像头附带一根非常短的15厘米电缆。你可以在eBay上购买第三方电缆，长度在5厘米到1米之间，但50厘米或更长的电缆可靠性较低，而USB摄像头可以使用2米到5米的电缆，并且可以插入USB集线器或主动延长线以实现更长的距离。
- en: 'There are currently several different RPi Cam models, notably the NoIR version
    that doesn''t have an internal infrared filter; therefore, a NoIR camera can easily
    see in the dark (if you have an invisible infrared light source), or see infrared
    lasers or signals far clearer than regular cameras that includes an infrared filter
    inside them. There are also two different versions of RPi Cam: RPi Cam v1.3 and
    RPi Cam v2.1, where the v2.1 uses a wider angle lens with a Sony 8 Mega-Pixel
    sensor instead of a 5 Mega-Pixel **OmniVision** sensor, and has better support
    for motion in low lighting conditions, and adds support for 3240x2464 video at
    15 FPS and potentially upto 120 FPS video at 720p. However, USB webcams come in
    thousands of different shapes and versions, making it easy to find specialized
    webcams such as waterproof or industrial-grade webcams, rather than requiring
    you to create your own custom housing for an RPi Cam.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有几种不同的RPi Cam型号，特别是没有内部红外滤光片的NoIR版本；因此，NoIR相机可以轻易地在黑暗中看到（如果你有一个不可见红外光源），或者比包含内部红外滤光片的普通相机更清晰地看到红外激光或信号。RPi
    Cam也有两种不同的版本：RPi Cam v1.3和RPi Cam v2.1，其中v2.1使用更宽的视角镜头和索尼8百万像素传感器，而不是5百万像素的**OmniVision**传感器，并且在低光照条件下有更好的运动支持，并增加了3240x2464视频在15
    FPS的支持，以及可能在720p下高达120 FPS的视频。然而，USB网络摄像头有数千种不同的形状和版本，这使得找到专门的网络摄像头（如防水或工业级网络摄像头）变得容易，而不是需要你为RPi
    Cam创建自己的定制外壳。
- en: IP cameras are also another option for a camera interface that can allow 1080p
    or higher resolution videos with Raspberry Pi, and IP cameras support not just
    very long cables, but potentially even work anywhere in the world using the Internet.
    But IP cameras aren't quite as easy to interface with OpenCV as USB webcams or
    the RPi Cam.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: IP相机也是另一个可以选择的相机接口，它可以允许使用Raspberry Pi进行1080p或更高分辨率的视频，并且IP相机不仅支持非常长的电缆，而且有可能通过互联网在世界上的任何地方工作。但是，与USB网络摄像头或RPi
    Cam相比，IP相机与OpenCV的接口并不那么简单。
- en: In the past, RPi Cams and the official drivers weren't directly compatible with
    OpenCV; you often used custom drivers and modified your code in order to grab
    frames from RPi Cams, but it's now possible to access an RPi Cam in OpenCVin the
    exact same way as a USB webcam! Thanks to recent improvements in the v4l2 drivers,
    once you load the v4l2 driver the RPi Cam will appear as a `/dev/video0` or `/dev/video1`
    file like a regular USB webcam. So traditional OpenCV webcam code such as `cv::VideoCapture(0)`
    will be able to use it just like a webcam.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，RPi Cams和官方驱动程序与OpenCV不直接兼容；你通常需要使用自定义驱动程序并修改你的代码，以便从RPi Cams捕获帧，但现在你可以以与USB网络摄像头完全相同的方式在OpenCV中访问RPi
    Cam！多亏了v4l2驱动程序的最近改进，一旦加载了v4l2驱动程序，RPi Cam将像普通USB网络摄像头一样出现在`/dev/video0`或`/dev/video1`文件中。因此，传统的OpenCV网络摄像头代码，如`cv::VideoCapture(0)`，将能够像网络摄像头一样使用它。
- en: Installing the Raspberry Pi Camera Module driver
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安装Raspberry Pi Camera Module驱动程序
- en: 'First let''s temporarily load the v4l2 driver for the RPi Cam to make sure
    our camera is plugged in correctly:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们暂时加载RPi Cam的v4l2驱动程序，以确保我们的相机已经正确连接：
- en: '[PRE42]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: If the command failed (if it printed an error message to the console, or it
    froze, or the command returned a number besides 0), then perhaps your camera is
    not plugged in correctly. Shutdown and then unplug power from your RPi and try
    attaching the flat white cable again, looking at photos on the Web to make sure
    it's plugged in the correct way around. If it is the correct way around, it's
    possible the cable wasn't fully inserted before you closed the locking tab on
    the RPi. Also check whether you forgot to click Enable Camera when configuring
    your Raspberry Pi earlier, using the `sudoraspi-config` command.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果命令失败（如果它在控制台打印了错误消息，或者它冻结了，或者命令返回了除了0以外的数字），那么可能你的相机没有正确连接。关闭并从你的RPi上拔掉电源，然后再次尝试连接扁平的白色电缆，查看网络上的照片以确保它以正确的方式连接。如果是以正确的方式连接的，那么可能在你关闭RPi上的锁定标签之前，电缆没有完全插入。还要检查你是否在之前配置Raspberry
    Pi时忘记了点击启用相机，使用`sudoraspi-config`命令。
- en: 'If the command worked (if the command returned 0 and no error was printed to
    the console), then we can make sure the v4l2 driver for the RPi Cam is always
    loaded on bootup, by adding it to the bottom of the `/etc/modules` file:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果命令成功（如果命令返回了0并且没有错误打印到控制台），那么我们可以通过将其添加到`/etc/modules`文件的底部，确保RPi Cam的v4l2驱动程序在启动时始终加载：
- en: '[PRE43]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: After you save the file and reboot your RPi, you should be able to run `ls /dev/video*`
    to see a list of cameras available on your RPi. If the RPi Cam is the only camera
    plugged into your board, you should see it as the default camera (`/dev/video0`),
    or if you also have a USB webcam plugged in then it will be either `/dev/video0`
    or `/dev/video1`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 保存文件并重启你的RPi后，你应该能够运行`ls /dev/video*`来查看你的RPi上可用的摄像头列表。如果RPi摄像头是你板上唯一连接的摄像头，你应该看到它是默认摄像头（`/dev/video0`），或者如果你还连接了一个USB摄像头，它将是`/dev/video0`或`/dev/video1`。
- en: 'Let''s test the RPi Cam using the `starter_video` sample program we compiled
    earlier:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用我们之前编译的`starter_video`示例程序来测试RPi摄像头：
- en: '[PRE44]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: If it's showing the wrong camera, try `DISPLAY=:0 ./starter_video 1`.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果显示错误的摄像头，尝试`DISPLAY=:0 ./starter_video 1`。
- en: 'Now that we know the RPi Cam is working in OpenCV, let''s try Cartoonifier:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道RPi摄像头在OpenCV中工作正常，让我们尝试运行卡通化器：
- en: '[PRE45]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Or `DISPLAY=:0 ./Cartoonifier 1` for the other camera.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 或者`DISPLAY=:0 ./Cartoonifier 1`用于其他摄像头。
- en: Making Cartoonifier to run full screen
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使卡通化器全屏运行
- en: 'In embedded systems, you often want your application to be full screen and
    hide the Linux GUI and menu. OpenCV offers an easy method to set the full screen
    window property, but make sure you created the window using the `NORMAL` flag:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在嵌入式系统中，你通常希望你的应用程序全屏显示，并隐藏Linux GUI和菜单。OpenCV提供了一个简单的方法来设置全屏窗口属性，但请确保你使用`NORMAL`标志创建了窗口：
- en: '[PRE46]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Hiding the mouse cursor
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐藏鼠标光标
- en: 'You might notice the mouse cursor is shown on top of your window even though
    you don''t want to use a mouse in your embedded system. To hide the mouse cursor,
    you can use the `xdotool` command to move it to the bottom-right corner pixel,
    so it''s not noticeable, but is still available if you want to occasionally plug
    in your mouse to debug the device. Install `xdotool` and create a short Linux
    script to run it with Cartoonifier:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，即使你不想在嵌入式系统中使用鼠标，鼠标光标仍然显示在你的窗口上方。要隐藏鼠标光标，你可以使用`xdotool`命令将其移动到右下角像素，这样它就不那么显眼了，但如果你偶尔需要将鼠标插入进行设备调试，它仍然可用。安装`xdotool`并创建一个简短的Linux脚本来与卡通化器一起运行：
- en: '[PRE47]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Finally, make your script executable:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使你的脚本可执行：
- en: '[PRE48]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Try running your script, to make sure it works:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试运行你的脚本，以确保它工作：
- en: '[PRE49]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Running Cartoonifier automatically after bootup
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动后自动运行卡通化器
- en: 'Often when you build an embedded device, you want your application to be executed
    automatically after the device has booted up, rather than requiring the user to
    manually run your application. To automatically run our application after the
    device has fully booted up and logged into the graphical desktop, create an `autostart`
    folder with a file in it with certain contents including the full path to your
    script or application:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在构建嵌入式设备时，你希望设备启动后自动执行你的应用程序，而不是要求用户手动运行。为了在设备完全启动并登录到图形桌面后自动运行我们的应用程序，创建一个包含特定内容的`autostart`文件夹，其中包含脚本或应用程序的完整路径：
- en: '[PRE50]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Now, whenever you turn the device on or reboot it, Cartoonifier will begin running!
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，无论何时你开启设备或重启它，卡通化器都将开始运行！
- en: Speed comparison of Cartoonifier on Desktop versus Embedded
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 桌面与嵌入式系统上卡通化器的速度比较
- en: You will notice that the code runs much slower on Raspberry Pi than on your
    desktop! By far the two easiest ways to run it faster are to use a faster device
    or use a smaller camera resolution. The following table shows some frame rates,
    **Frames per Seconds** (**FPS**) for both the *Sketch* and *Paint* modes of Cartoonifier
    on a desktop, RPi 1, RPi 2, RPi 3, and Jetson TK1\. Note that the speeds don't
    have any custom optimizations and only run on a single CPU core, and the timings
    include the time for rendering images to the screen. The USB webcam used is the
    fast PS3 Eye webcam running at 640x480 since it is the fastest low-cost webcam
    on the market.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到代码在Raspberry Pi上的运行速度比在桌面上的运行速度慢得多！到目前为止，让它运行得更快的最简单两种方法是用更快的设备或使用更小的摄像头分辨率。以下表格显示了桌面、RPi
    1、RPi 2、RPi 3和Jetson TK1上卡通化器的*草图*和*绘画*模式的某些帧率，**每秒帧数**（**FPS**）。请注意，这些速度没有进行任何自定义优化，并且只在单个CPU核心上运行，时间包括将图像渲染到屏幕上的时间。所使用的USB摄像头是运行在640x480的快速PS3
    Eye摄像头，因为它是目前市场上速度最快且价格低廉的摄像头。
- en: 'It''s worth mentioning that Cartoonifier is only using a single CPU core, but
    all the devices listed have four CPU cores except for RPi 1 which has a single
    core, and many x86 computers have hyperthreading to give roughly eight CPU cores.
    So if you wrote your code to efficiently make use of multiple CPU cores (or GPU),
    the speeds might be 1.5 to 3 times faster than the single-threaded figures shown:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，Cartoonifier只使用单个CPU核心，但列出的所有设备都有四个CPU核心，除了RPi 1只有一个核心，许多x86计算机有超线程技术，可以提供大约八个CPU核心。所以如果你编写的代码能够高效地利用多个CPU核心（或GPU），速度可能会比单线程的数值快1.5到3倍：
- en: '| **Computer** | **Sketch mode** | **Paint mode** |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| **Computer** | **Sketch mode** | **Paint mode** |'
- en: '| Intel Core i7 PC | 20 FPS | 2.7 FPS |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| Intel Core i7 PC | 20 FPS | 2.7 FPS |'
- en: '| Jetson TK1ARM CPU | 16 FPS | 2.3 FPS |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| Jetson TK1ARM CPU | 16 FPS | 2.3 FPS |'
- en: '| Raspberry Pi 3 | 4.3 FPS | 0.32 FPS (3 seconds/frame) |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 3 | 4.3 FPS | 0.32 FPS (3 seconds/frame) |'
- en: '| Raspberry Pi 2 | 3.2 FPS | 0.28 FPS (4 seconds/frame) |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 2 | 3.2 FPS | 0.28 FPS (4 seconds/frame) |'
- en: '| Raspberry Pi Zero | 2.5 FPS | 0.21 FPS (5 seconds/frame) |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi Zero | 2.5 FPS | 0.21 FPS (5 seconds/frame) |'
- en: '| Raspberry Pi 1 | 1.9 FPS | 0.12 FPS (8 seconds/frame) |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 1 | 1.9 FPS | 0.12 FPS (8 seconds/frame) |'
- en: Notice that Raspberry Pi is extremely slow at running the code, especially the
    *Paint* mode, so we will try simply changing the camera and the resolution of
    the camera.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到Raspberry Pi在运行代码时非常慢，尤其是*Paint*模式，因此我们将尝试简单地更改相机和相机的分辨率。
- en: Changing the camera and camera resolution
  id: totrans-251
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更改相机和相机分辨率
- en: 'The following table shows how the speed of the *Sketch* mode compares on Raspberry
    Pi 2 using different types of cameras and different camera resolutions:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了在Raspberry Pi 2上使用不同类型的相机和不同相机分辨率时*Sketch*模式的速度对比：
- en: '| **Hardware** | **640x480 resolution** | **320x240 resolution** |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| **Hardware** | **640x480 resolution** | **320x240 resolution** |'
- en: '| RPi 2 with RPi Cam | 3.8 FPS | 12.9 FPS |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| RPi 2 with RPi Cam | 3.8 FPS | 12.9 FPS |'
- en: '| RPi 2 with PS3 Eye webcam | 3.2 FPS | 11.7 FPS |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| RPi 2 with PS3 Eye webcam | 3.2 FPS | 11.7 FPS |'
- en: '| RPi 2 with unbranded webcam | 1.8 FPS | 7.4 FPS |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| RPi 2 with unbranded webcam | 1.8 FPS | 7.4 FPS |'
- en: As you can see, when using the RPi Cam in 320x240, it seems we have a good enough
    solution to have some fun, even if it's not in the 20-30 FPS range that we would
    prefer.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，当使用RPi Cam在320x240分辨率下时，似乎我们已经有一个足够好的解决方案来享受一些乐趣，即使它不在我们更希望的20-30 FPS范围内。
- en: Power draw of Cartoonifier running on desktop versus embedded system
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在台式机和嵌入式系统上运行Cartoonifier的功耗对比
- en: We've seen that various embedded devices are slower than desktop, from the RPi
    1 being roughly 20 times slower than a desktop, up to Jetson TK1 being roughly
    1.5 times slower than a desktop. But for some tasks, low speed is acceptable if
    it means there will also be significantly lower battery draw, allowing for small
    batteries or low year-round electricity costs for a server or low heat generated.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，各种嵌入式设备比台式机慢，从RPi 1大约比台式机慢20倍，到Jetson TK1大约比台式机慢1.5倍。但对于某些任务来说，如果这意味着电池消耗也会显著降低，允许使用小电池或降低服务器全年电费成本，低速度是可以接受的。
- en: 'Raspberry Pi has different models even for the same processor, such as Raspberry
    Pi 1B, Zero, and 1A+ that all run at similar speeds but have significantly different
    power draw. MIPI CSI cameras such as the RPi Cam also use less electricity than
    webcams. The following table shows how much electrical power is used by different
    hardware running the same Cartoonifier code. Power measurements of Raspberry Pi
    were performed as shown in the following photo using a simple USB current monitor
    (for example, J7-T Safety Tester--[h t t p ://b i t . l y /2a S Z a 6H](http://bit.ly/2aSZa6H)--for
    $5), and a DMM multimeter for the other devices:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Raspberry Pi即使对于相同的处理器也有不同的型号，例如Raspberry Pi 1B、Zero和1A+，它们的运行速度相似，但功耗差异很大。MIPI
    CSI相机，如RPi Cam，也比网络摄像头耗电少。以下表格显示了运行相同Cartoonifier代码的不同硬件所消耗的电能。Raspberry Pi的功耗测量方法如下所示的照片，使用简单的USB电流监控器（例如，J7-T
    Safety Tester--[h t t p ://b i t . l y /2aS Z a 6H](http://bit.ly/2aSZa6H)--售价5美元），以及一个DMM万用表来测量其他设备：
- en: '![](img/image_01_015.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_01_015.png)'
- en: '**Idle Power** measures power when the computer is running but no major applications
    are being used, whereas **Cartoonifier Power** measures power when Cartoonifier
    is running. **Efficiency** is Cartoonifier Power / Cartoonifier Speed in a 640x480
    *Sketch* mode.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '**Idle Power**测量的是计算机运行但未使用任何主要应用程序时的功耗，而**Cartoonifier Power**测量的是Cartoonifier运行时的功耗。**效率**是指640x480
    *Sketch*模式下Cartoonifier Power与Cartoonifier Speed的比值。'
- en: '| **Hardware** | **Idle Power** | **Cartoonifier Power** | **Efficiency** |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| **Hardware** | **Idle Power** | **Cartoonifier Power** | **Efficiency** |'
- en: '| RPi Zero with PS3 Eye | 1.2 Watts | 1.8 Watts | 1.4 Frames per Watt |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| RPi Zero与PS3 Eye | 1.2瓦 | 1.8瓦 | 1.4帧每瓦 |'
- en: '| RPi 1A+ with PS3 Eye | **1.1 Watts** | **1.5 Watts** | 1.1 Frames per Watt
    |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| RPi 1A+与PS3 Eye | **1.1瓦** | **1.5瓦** | 1.1帧每瓦 |'
- en: '| RPi 1B with PS3 Eye | 2.4 Watts | 3.2 Watts | 0.5 Frames per Watt |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| RPi 1B与PS3 Eye | 2.4瓦 | 3.2瓦 | 0.5帧每瓦 |'
- en: '| RPi 2B with PS3 Eye | 1.8 Watts | 2.2 Watts | 1.4 Frames per Watt |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| RPi 2B与PS3 Eye | 1.8瓦 | 2.2瓦 | 1.4帧每瓦 |'
- en: '| RPi 3B with PS3 Eye | 2.0 Watts | 2.5 Watts | 1.7 Frames per Watt |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| RPi 3B与PS3 Eye | 2.0瓦 | 2.5瓦 | 1.7帧每瓦 |'
- en: '| Jetson TK1 with PS3 Eye | 2.8 Watts | 4.3 Watts | **3.7 Frames per Watt**
    |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| Jetson TK1与PS3 Eye | 2.8瓦 | 4.3瓦 | **3.7帧每瓦** |'
- en: '| Core i7 laptop with PS3 Eye | 14.0 Watts | 39.0 Watts | 0.5 Frames per Watt
    |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 配备PS3 Eye的Core i7笔记本电脑 | 14.0瓦 | 39.0瓦 | 0.5帧每瓦 |'
- en: We can see that RPi 1A+ uses the least power, but the most power-efficient options
    are Jetson TK1 and Raspberry Pi 3B. Interestingly, the original Raspberry Pi (RPi1B)
    has roughly the same efficiency as an x86 laptop. All later Raspberry Pis are
    significantly more power-efficient than the original (RPi 1B).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到RPi 1A+使用的功率最少，但最节能的选项是Jetson TK1和Raspberry Pi 3B。有趣的是，原始的Raspberry Pi（RPi1B）的效率与x86笔记本电脑大致相同。所有后续的Raspberry
    Pi都比原始的（RPi 1B）节能得多。
- en: '**Disclaimer:** The author is a former employee of NVIDIA that produced the
    Jetson TK1, but the results and conclusions are believed to be authentic.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '**免责声明**：作者曾是NVIDIA的前员工，该公司生产了Jetson TK1，但相信结果和结论是真实的。'
- en: 'Lets also look at the power draw of different cameras that work with Raspberry
    Pi:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也看看与Raspberry Pi兼容的不同摄像头的功耗：
- en: '| **Hardware** | **Idle Power** | **Cartoonifier Power** | **Efficiency** |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| **硬件** | **空闲功耗** | **卡通化器功耗** | **效率** |'
- en: '| RPi Zero with PS3 Eye | 1.2 Watts | 1.8 Watts | 1.4 Frames per Watt |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| RPi Zero与PS3 Eye | 1.2瓦 | 1.8瓦 | 1.4帧每瓦 |'
- en: '| RPi Zero with RPi Cam v1.3 | 0.6 Watts | 1.5 Watts | 2.1 Frames per Watt
    |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| RPi Zero与RPi Cam v1.3 | 0.6瓦 | 1.5瓦 | 2.1帧每瓦 |'
- en: '| RPi Zero with RPi Cam v2.1 | **0.55 Watts** | **1.3 Watts** | **2.4 Frames
    per Watt** |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| RPi Zero与RPi Cam v2.1 | **0.55瓦** | **1.3瓦** | **2.4帧每瓦** |'
- en: We see that RPi Cam v2.1 is slightly more power-efficient than RPi Cam v1.3,
    and significantly more power-efficient than a USB webcam.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到RPi Cam v2.1比RPi Cam v1.3略节能，但比USB摄像头节能得多。
- en: Streaming video from Raspberry Pi to a powerful computer
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从Raspberry Pi向高性能计算机传输视频流
- en: Thanks to the hardware-accelerated video encoders in all modern ARM devices
    including Raspberry Pi, a valid alternative to performing Computer Vision onboard
    an embedded device is to use the device to just capture video and stream it across
    a network in realtime to a PC or server rack. All Raspberry Pi models contain
    the same video encoder hardware, so an RPi 1A+ or RPi Zero with a Pi Cam is quite
    a good option for a low-cost, low-power portable video streaming server. Raspberry
    Pi 3 adds Wi-Fi for additional portable functionality.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢所有现代ARM设备（包括Raspberry Pi）中的硬件加速视频编码器，这些设备可以作为在嵌入式设备上执行计算机视觉的有效替代方案，即使用该设备仅捕获视频，并通过网络实时传输到PC或服务器机架。所有Raspberry
    Pi型号都包含相同的视频编码器硬件，因此带有Pi Cam的RPi 1A+或RPi Zero是一个很好的低成本、低功耗便携式视频流媒体服务器选项。Raspberry
    Pi 3增加了Wi-Fi，以提供额外的便携式功能。
- en: 'There are numerous ways live camera video can be streamed from a Raspberry
    Pi, such as using the official RPi V4L2 camera driver to allow the RPi Cam to
    appear like a webcam, then use Gstreamer, liveMedia, netcat, or VLC to stream
    the video across a network. However, these methods often introduce 1 or 2 seconds
    of latency and often require customizing the OpenCV client code or learning how
    to use Gstreamer efficiently. So instead, the following section will show how
    to perform both the camera capture and network streaming using an alternative
    camera driver named **UV4L**:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以从Raspberry Pi传输实时摄像头视频，例如使用官方的RPi V4L2摄像头驱动程序，使RPi Cam看起来像是一个网络摄像头，然后使用Gstreamer、liveMedia、netcat或VLC在网络中传输视频。然而，这些方法通常引入1到2秒的延迟，并且通常需要自定义OpenCV客户端代码或学习如何高效地使用Gstreamer。因此，以下部分将展示如何使用名为**UV4L**的替代摄像头驱动程序同时执行摄像头捕获和网络流：
- en: 'Install UV4L on the Raspberry Pi by following [h t t p ://w w w . l i n u x
    - p r o j e c t s . o r g /u v 4l /i n s t a l l a t i o n /](http://www.linux-projects.org/uv4l/installation/):'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '按照以下链接在Raspberry Pi上安装UV4L：[http://www.linux-projects.org/uv4l/installation/](http://www.linux-projects.org/uv4l/installation/):'
- en: '[PRE51]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Run the UV4L streaming server manually (on the RPi) to check that it works:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动运行UV4L流媒体服务器（在RPi上）以检查其是否工作：
- en: '[PRE52]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Test the camera''s network stream from your desktop:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从您的桌面测试摄像头的网络流：
- en: Install VLC Media Player.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装VLC媒体播放器。
- en: File | Open Network Stream | visit [h t t p ://192\. 168\. 2\. 111:8080/s t
    r e a m /v i d e o . m j p e g](http://192.168.2.111:8080/stream/video.mjpeg).
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件 | 打开网络流 | 访问[h t t p ://192\. 168\. 2\. 111:8080/s t r e a m /v i d e o .
    m j p e g](http://192.168.2.111:8080/stream/video.mjpeg)。
- en: Adjust the URL to the IP address of your Raspberry Pi. Run `hostname -I` on
    RPi to find its IP address.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将URL调整为您的树莓派的IP地址。在RPi上运行`hostname -I`以找到其IP地址。
- en: 'Now get the UV4L server to run automatically on bootup:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让UV4L服务器在启动时自动运行：
- en: '[PRE53]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Edit any UV4L server settings you want in `uv4l-raspicam.conf` such as resolution
    and frame rate:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`uv4l-raspicam.conf`中编辑您想要的任何UV4L服务器设置，例如分辨率和帧率：
- en: '[PRE54]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Now we can tell OpenCV to use our network stream as if it was a webcam. As
    long as your installation of OpenCV can use FFMPEG internally, OpenCV will be
    able to grab frames from an MJPEG network stream just like a webcam:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以告诉OpenCV将其作为网络流使用，就像它是网络摄像头一样。只要您的OpenCV安装可以内部使用FFMPEG，OpenCV就能像网络摄像头一样从MJPEG网络流中抓取帧：
- en: '[PRE55]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Your Raspberry Pi is now using UV4L to stream the live 640x480 24 FPS video
    to a PC that is running Cartoonifier in *Sketch* mode, achieving roughly 19 FPS
    (with 0.4 seconds of latency). Notice this is almost the same speed as using the
    PS3 Eye webcam directly on the PC (20 FPS)!
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 您的树莓派现在正在使用UV4L将640x480分辨率的24 FPS实时视频流传输到运行在*Sketch*模式的Cartoonifier的PC上，大约达到19
    FPS（延迟0.4秒）。注意，这几乎与直接在PC上使用PS3 Eye网络摄像头（20 FPS）的速度相同！
- en: Note that when you are streaming the video to OpenCV, it won't be able to set
    the camera resolution; you need to adjust the UV4L server settings to change the
    camera resolution. Also note that instead of streaming MJPEG, we could have streamed
    H.264 video that uses lower bandwidth, but some computer vision algorithms don't
    handle video compression such as H.264 very well, so MJPEG will cause less algorithm
    problems than H.264.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当您将视频流到OpenCV时，它将无法设置摄像头分辨率；您需要调整UV4L服务器设置以更改摄像头分辨率。另外请注意，我们本可以流式传输H.264视频，它使用较低的带宽，但某些计算机视觉算法处理不了H.264这样的视频压缩，所以MJPEG比H.264引起的问题要少。
- en: If you have both the official RPi V4L2 driver and the UV4L driver installed,
    they will both be available as cameras 0 and 1 (devices `/dev/video0` and `/dev/video1`),
    but you can only use one camera driver at a time.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已安装了官方的RPi V4L2驱动程序和UV4L驱动程序，它们都将作为摄像头0和1（设备`/dev/video0`和`/dev/video1`）可用，但您一次只能使用一个摄像头驱动程序。
- en: Customizing your embedded system!
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定制您的嵌入式系统！
- en: Now that you have created a whole embedded Cartoonifier system, and you know
    the basics of how it works and which parts do what, you should customize it! Make
    the video full screen, change the GUI, or change the application behavior and
    workflow, or change the Cartoonifier filter constants, or the skin detector algorithm,
    or replace the Cartoonifier code with your own project ideas. Or stream the video
    to the cloud and process it there!
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经创建了一个完整的嵌入式Cartoonifier系统，并且您知道它的工作原理以及各个部分的作用，您应该对其进行定制！使视频全屏，更改GUI，或更改应用程序的行为和工作流程，或更改Cartoonifier的过滤器常数，或皮肤检测算法，或用您自己的项目想法替换Cartoonifier代码。或者将视频流到云端进行处理！
- en: You can improve the skin detection algorithm in many ways, such as a more complex
    skin detection algorithm (for example, using trained Gaussian models from many
    recent CVPR or ICCV conference papers at [http://www.cvpapers.com](http://www.cvpapers.com/)),
    or add face detection (see the *Face detection* section of [Chapter 6](0db61fe2-672f-4d4f-9e20-a20035ea8314.xhtml),
    *Face Recognition using Eigenfaces and Fisherfaces*) to the skin detector, so
    it detects where the user's face is, rather than asking the user to put their
    face in the center of the screen. Beware that face detection may take many seconds
    on some devices or high-resolution cameras, so they may be limited in their current
    real-time uses. But embedded system platforms are getting faster every year, so
    this may be less of a problem over time.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过多种方式改进皮肤检测算法，例如使用更复杂的皮肤检测算法（例如，使用来自许多最近CVPR或ICCV会议论文的经过训练的高斯模型[http://www.cvpapers.com](http://www.cvpapers.com/)），或者向皮肤检测器添加人脸检测（参见第6章的*Face
    detection*部分，*Face Recognition using Eigenfaces and Fisherfaces*），以便检测用户的面部位置，而不是要求用户将面部置于屏幕中央。请注意，在某些设备或高分辨率摄像头上进行人脸检测可能需要几秒钟，因此它们在当前的实时应用中可能受到限制。但是，嵌入式系统平台每年都在变快，所以这可能会随着时间的推移而变得不那么成问题。
- en: The most significant way to speed up embedded computer vision applications is
    to reduce the camera resolution absolutely as much as possible (for example, 0.5
    mega pixel instead of 5 megapixels), allocate and free images as rarely as possible,
    and do image format conversions as rarely as possible. In some cases, there might
    be some optimized image processing or math libraries, or optimized version of
    OpenCV from the CPU vendor of your device (for example, Broadcom, NVIDIA Tegra,
    Texas Instruments OMAP, Samsung Exynos), or for your CPU family (for example,
    ARM Cortex-A9).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 加速嵌入式计算机视觉应用最显著的方法是尽可能降低相机分辨率（例如，0.5百万像素而不是5百万像素），尽可能少地分配和释放图像，尽可能少地进行图像格式转换。在某些情况下，可能存在一些优化的图像处理或数学库，或者来自您设备CPU供应商的OpenCV优化版本（例如，Broadcom、NVIDIA
    Tegra、Texas Instruments OMAP、Samsung Exynos），或者针对您的CPU系列（例如，ARM Cortex-A9）。
- en: 'To make customizing embedded and desktop image processing code easier, this
    book comes with the files, `ImageUtils.cpp` and `ImageUtils.h`, to help you experiment.
    They include functions such as `printMatInfo()` that prints a lot of info about
    a `cv::Mat` object, making debugging OpenCV much easier. There are also timing
    macros to easily add detailed timing statistics to your C/C++ code. For example:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使定制嵌入式和桌面图像处理代码更容易，这本书附带`ImageUtils.cpp`和`ImageUtils.h`文件，以帮助您进行实验。它们包括`printMatInfo()`等函数，该函数会打印有关`cv::Mat`对象的大量信息，使调试OpenCV变得更容易。还有计时宏，可以轻松地将详细的计时统计信息添加到您的C/C++代码中。例如：
- en: '[PRE56]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'You would then see something like the following printed to your console:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在控制台看到如下类似的内容：
- en: '[PRE57]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This is useful when your OpenCV code is not working as expected, particularly
    for embedded development where it is often difficult to use an IDE debugger.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这在您的OpenCV代码未按预期工作时很有用，尤其是在嵌入式开发中，通常很难使用IDE调试器。
- en: Summary
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has shown several different types of image processing filters that
    can be used to generate various cartoon effects, from a plain sketch mode that
    looks like a pencil drawing, a paint mode that looks like a color painting, to
    a cartoon mode that overlays the *Sketch* mode on top of the paint mode to appear
    like a cartoon. It also shown that other fun effects can be obtained, such as
    the evil mode that greatly enhanced noisy edges, and the alien mode that changed
    the skin of a face to appear bright green.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了多种不同类型的图像处理滤镜，可用于生成各种卡通效果，从类似铅笔素描的普通草图模式，到类似彩色绘画的绘画模式，再到在绘画模式之上叠加*草图*模式以呈现卡通效果。它还展示了可以获得其他有趣的效果，例如大大增强噪边界的邪恶模式，以及将人脸皮肤变为明亮的绿色的外星人模式。
- en: There are many commercial smartphone apps that perform similar fun effects on
    the user's face, such as cartoon filters and skin color changers. There are also
    professional tools using similar concepts, such as skin-smoothing video post-processing
    tools that attempt to beautify women's faces by smoothing their skin while keeping
    the edges and non-skin regions sharp, in order to make their faces appear younger.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多商业智能手机应用程序可以对用户的脸部执行类似有趣的特效，例如卡通滤镜和肤色改变器。还有使用类似概念的专业工具，例如皮肤平滑视频后期处理工具，它试图通过平滑皮肤来美化女性的脸部，同时保持边缘和非皮肤区域的清晰，以便使她们的脸看起来更年轻。
- en: This chapter shows how to port the application from a desktop to an embedded
    system, by following the recommended guidelines of developing a working desktop
    version first, and then porting it to embedded, and creating a user interface
    that is suitable for the embedded application. The image processing code is shared
    between the two projects, so that the reader can modify the cartoon filters for
    the desktop application, and easily see those modifications in the embedded system
    as well.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何通过遵循首先开发一个可工作的桌面版本的建议指南，然后将应用程序移植到嵌入式系统，并创建一个适合嵌入式应用程序的用户界面。图像处理代码在这两个项目之间共享，以便读者可以修改桌面应用程序的卡通滤镜，并轻松地在嵌入式系统中看到这些修改。
- en: Remember that this book includes an OpenCV installation script for Linux and
    full source code for all projects discussed.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这本书包括Linux的OpenCV安装脚本以及所有讨论项目的完整源代码。
