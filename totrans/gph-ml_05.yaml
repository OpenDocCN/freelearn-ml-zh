- en: 'Chapter 3: Unsupervised Graph Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章：无监督图学习
- en: Unsupervised machine learning refers to the subset of machine learning algorithms
    that do not exploit any target information during training. Instead, they work
    on their own to find clusters, discover patterns, detect anomalies, and solve
    many other problems for which there is no teacher and no correct answer known
    *a priori*.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督机器学习指的是机器学习算法的一个子集，在训练过程中不利用任何目标信息。相反，它们独立工作以找到聚类、发现模式、检测异常，并解决许多其他问题，对于这些问题没有教师和事先已知的正确答案。
- en: As per many other machine learning algorithms, unsupervised models have found
    large applications in the graph representation learning domain. Indeed, they represent
    an extremely useful tool for solving various downstream tasks, such as node classification
    and community detection, among others.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如许多其他机器学习算法一样，无监督模型在图表示学习领域得到了广泛的应用。事实上，它们是解决各种下游任务（如节点分类和社区检测等）的极其有用的工具。
- en: In this chapter, an overview of recent unsupervised graph embedding methods
    will be provided. Given a graph, the goal of these techniques is to automatically
    learn a latent representation of it, in which the key structural components are
    somehow preserved.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将提供最近无监督图嵌入方法的概述。给定一个图，这些技术的目标是自动学习其潜在表示，其中关键的结构组件以某种方式得到保留。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The unsupervised graph embedding roadmap
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督图嵌入路线图
- en: Shallow embedding methods
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浅层嵌入方法
- en: Autoencoders
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动编码器
- en: Graph neural networks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图神经网络
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will be using Jupyter notebooks with Python 3.9 for all of our exercises.
    The following is a list of the Python libraries that need to be installed for
    this chapter using `pip`. For example, run `pip install networkx==2.5` on the
    command line, and so on:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Python 3.9 的 Jupyter 笔记本来进行所有练习。以下是需要使用 `pip` 安装此章节所需的 Python 库的列表。例如，在命令行中运行
    `pip install networkx==2.5`，等等：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the rest of this book, if not clearly stated, we will refer to the Python
    commands `import networkx` as `nx`.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的其余部分，除非明确说明，否则我们将引用 Python 命令 `import networkx` 作为 `nx`。
- en: All the code files relevant to this chapter are available at [https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter03](https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter03).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所有与本章相关的代码文件均可在[https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter03](https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter03)找到。
- en: The unsupervised graph embedding roadmap
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督图嵌入路线图
- en: 'Graphs are complex mathematical structures defined in a non-Euclidean space.
    Roughly speaking, this means that it is not always easy to define what is close
    to what; it might also be hard to say what *close* even means. Imagine a social
    network graph: two users can be respectively connected and yet share very different
    features—one might be interested in fashion and clothes, while the other might
    be interested in sports and videogames. Can we consider them as "close"?'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图是非欧几里得空间中定义的复杂数学结构。粗略地说，这意味着并不总是容易定义什么是接近什么；甚至可能很难说“接近”这个词究竟是什么意思。想象一下社交网络图：两个用户可能分别连接，但共享非常不同的特征——一个可能对时尚和服装感兴趣，而另一个可能对体育和电子游戏感兴趣。我们能认为他们是“接近”的吗？
- en: For this reason, unsupervised machine learning algorithms have found large applications
    in graph analysis. Unsupervised machine learning is the class of machine learning
    algorithms that can be trained without the need for manually annotated data. Most
    of those models indeed make use of only information in the adjacency matrix and
    the node features, without any knowledge of the downstream machine learning task.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，无监督机器学习算法在图分析中得到了广泛的应用。无监督机器学习是机器学习算法的一个类别，可以在没有手动标注数据的情况下进行训练。这些模型中的大多数实际上只使用邻接矩阵和节点特征中的信息，而不了解下游机器学习任务。
- en: 'How is this possible? One of the most used solutions is to learn embeddings
    that preserve the graph structure. The learned representation is usually optimized
    so that it can be used to reconstruct the pair-wise node similarity, for example,
    the **adjacency matrix**. These techniques bring an important feature: the learned
    representation can encode latent relationships among nodes or graphs, allowing
    us to discover hidden and complex novel patterns.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这怎么可能呢？最常用的解决方案之一是学习保留图结构的嵌入。学习到的表示通常被优化，以便它可以用来重建成对节点相似度，例如，**邻接矩阵**。这些技术带来一个重要特性：学习到的表示可以编码节点或图之间的潜在关系，使我们能够发现隐藏和复杂的新的模式。
- en: 'Many algorithms have been developed in relation to unsupervised graph machine
    learning techniques. However, as previously reported by different scientific papers
    ([https://arxiv.org/abs/2005.03675](https://arxiv.org/abs/2005.03675)), those
    algorithms can be grouped into macro-groups: shallow embedding methods, autoencoders,
    and **Graph Neural Networks** (**GNNs**), as graphically described in the following
    chart:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 与无监督图机器学习技术相关联的许多算法已经被开发出来。然而，如不同科学论文先前所报告的（[https://arxiv.org/abs/2005.03675](https://arxiv.org/abs/2005.03675)），这些算法可以被分为几个宏观组：浅层嵌入方法、自动编码器和**图神经网络**（**GNNs**），如下面的图表所示：
- en: '![Figure 3.1 – The hierarchical structure of the different unsupervised embedding
    algorithms described in this book](img/B16069_03_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – 本书所述的不同无监督嵌入算法的层次结构](img/B16069_03_01.jpg)'
- en: Figure 3.1 – The hierarchical structure of the different unsupervised embedding
    algorithms described in this book
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 本书所述的不同无监督嵌入算法的层次结构
- en: In the following sections, you will learn the main principles behind each group
    of algorithms. We will try to provide the idea behind the most well-known algorithms
    in the field as well as how they can be used for solving real problems.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将了解每组算法背后的主要原理。我们将尝试提供该领域最著名算法背后的想法以及它们如何用于解决实际问题。
- en: Shallow embedding methods
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 浅层嵌入方法
- en: As already introduced in [*Chapter 2*](B16069_02_Final_JM_ePub.xhtml#_idTextAnchor035),
    *Graph Machine Learning*, with shallow embedding methods, we identify a set of
    algorithms that are able to learn and return only the embedding values for the
    learned input data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如已在[*第二章*](B16069_02_Final_JM_ePub.xhtml#_idTextAnchor035)中介绍，*图机器学习*，使用浅层嵌入方法，我们识别出一组能够学习和仅返回学习输入数据的嵌入值的算法。
- en: 'In this section, we will explain in detail some of those algorithms. Moreover,
    we will enrich the descriptions by providing several examples of how to use those
    algorithms in Python. For all the algorithms described in this section, we will
    use the implementation provided in the following libraries: **Graph Embedding
    Methods** (**GEM**), **Node to Vector** (**Node2Vec**), and Karate Club.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细解释其中的一些算法。此外，我们将通过提供几个如何在Python中使用这些算法的示例来丰富描述。本节中描述的所有算法，我们将使用以下库中提供的实现：**图嵌入方法**（**GEM**）、**节点到向量**（**Node2Vec**）和Karate
    Club。
- en: Matrix factorization
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: Matrix factorization is a general decomposition technique widely used in different
    domains. A consistent number of graph embedding algorithms use this technique
    in order to compute the node embedding of a graph.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵分解是一种在多个领域广泛使用的通用分解技术。许多图嵌入算法使用这种技术来计算图的节点嵌入。
- en: We will start by providing a general introduction to the matrix factorization
    problem. After the introduction of the basic principles, we will describe two
    algorithms, namely **Graph Factorization** (**GF**) and **Higher-Order Proximity
    Preserved Embedding** (**HOPE**), which use matrix factorization to build the
    node embedding of a graph.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先提供一个关于矩阵分解问题的通用介绍。在介绍基本原理之后，我们将描述两个算法，即**图分解**（**GF**）和**高阶邻近保持嵌入**（**HOPE**），它们使用矩阵分解来构建图的节点嵌入。
- en: Let ![](img/B16069_03_001.png) be the input data. Matrix factorization decomposes
    ![](img/B16069_03_002.png) with ![](img/B16069_03_003.png) and ![](img/B16069_03_004.png)
    called the **source** and **abundance** matrix, respectively, and ![](img/B16069_03_005.png)
    is the number of dimensions of the generated embedding space. The matrix factorization
    algorithm learns the *V* and *H* matrices by minimizing a loss function that can
    change according to the specific problem we want to solve. In its general formulation,
    the loss function is defined by computing the reconstruction error using the Frobenius
    norm as ![](img/B16069_03_006.png).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 设![](img/B16069_03_001.png)为输入数据。矩阵分解将![](img/B16069_03_002.png)分解为![](img/B16069_03_003.png)和![](img/B16069_03_004.png)，分别称为**源**和**丰度**矩阵，而![](img/B16069_03_005.png)是生成的嵌入空间的维度数。矩阵分解算法通过最小化一个损失函数来学习*V*和*H*矩阵，该损失函数可以根据我们想要解决的问题的具体情况而变化。在其一般公式中，损失函数通过计算使用Frobenius范数（![](img/B16069_03_006.png)）的重构误差来定义。
- en: Generally speaking, all the unsupervised embedding algorithms based on matrix
    factorization use the same principle. They all factorize an input graph expressed
    as a matrix in different components. The main difference between each method lies
    in the loss function used during the optimization process. Indeed, different loss
    functions allow creating an embedding space that emphasizes specific properties
    of the input graph.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，所有基于矩阵分解的无监督嵌入算法都使用相同的原则。它们都将表示为矩阵的输入图分解为不同的组件。每种方法之间的主要区别在于优化过程中使用的损失函数。确实，不同的损失函数允许创建一个嵌入空间，该空间强调输入图的具体属性。
- en: Graph factorization
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图分解
- en: The GF algorithm was one of the first models to reach good computational performance
    in order to perform the node embedding of a given graph. By following the principle
    of matrix factorization that we previously described, the GF algorithm factorizes
    the adjacency matrix of a given graph.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: GF算法是第一个在执行给定图的节点嵌入时达到良好计算性能的模型之一。通过遵循我们之前描述的矩阵分解原理，GF算法分解给定图的邻接矩阵。
- en: 'Formally, let ![](img/B16069_03_007.png) be the graph we want to compute the
    node embedding with and let ![](img/B16069_03_008.png) be its adjacency matrix.
    The loss function (*L*) used in this matrix factorization problem is as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，设![](img/B16069_03_007.png)为我们想要计算节点嵌入的图，设![](img/B16069_03_008.png)为其邻接矩阵。在此矩阵分解问题中使用的损失函数（*L*）如下：
- en: '![](img/B16069_03_009.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B16069_03_009.jpg)'
- en: In the preceding equation, ![](img/B16069_03_010.png) represents one of the
    edges in *G* while ![](img/B16069_03_011.png) is the matrix containing the *d*-dimensional
    embedding. Each row of the matrix represents the embedding of a given node. Moreover,
    a regularization term (![](img/B16069_03_012.png)) of the embedding matrix is
    used to ensure that the problem remains well-posed even in the absence of sufficient
    data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，![](img/B16069_03_010.png)代表*G*中的一条边，而![](img/B16069_03_011.png)是包含*d*-维嵌入的矩阵。矩阵的每一行代表一个给定节点的嵌入。此外，嵌入矩阵的正则化项（![](img/B16069_03_012.png)）用于确保即使在缺乏足够数据的情况下，问题仍然是有良好定义的。
- en: The loss function used in this method was mainly designed to improve GF performances
    and scalability. Indeed, the solution generated by this method could be noisy.
    Moreover, it should be noted, by looking at its matrix factorization formulation,
    that GF performs a strong symmetric factorization. This property is particularly
    suitable for undirected graphs, where the adjacency matrix is symmetric, but could
    be a potential limitation for undirected graphs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法中使用的损失函数主要是为了提高GF的性能和可扩展性。实际上，此方法生成的解决方案可能会有噪声。此外，需要注意的是，通过观察其矩阵分解公式，GF执行了强对称分解。这一特性特别适合无向图，其中邻接矩阵是对称的，但可能对无向图构成潜在的限制。
- en: 'In the following code, we will show how to perform the node embedding of a
    given `networkx` graph using Python and the GEM library:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们将展示如何使用Python和GEM库对给定的`networkx`图执行节点嵌入：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding example, the following have been done:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，以下操作已经完成：
- en: '`networkx` is used to generate a **barbell graph** (*G*) used as input for
    the GF factorization algorithm.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`networkx`用于生成一个**双环图**（*G*），作为GF分解算法的输入。'
- en: The `GraphFactorization` class is used to generate a `d=2`-dimensional embedding
    space.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`GraphFactorization`类生成一个`d=2`维度的嵌入空间。
- en: The computation of the node embeddings of the input graph is performed using
    `gf.learn_embedding(G)`.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `gf.learn_embedding(G)` 执行输入图的节点嵌入计算。
- en: The computed embeddings are extracted by calling the `gf.get_embedding()` method.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`gf.get_embedding()`方法提取计算出的嵌入。
- en: 'The results of the previous code are shown in the following graph:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码的结果显示在以下图中：
- en: '![Figure 3.2 – Application of the GF algorithm to a graph (left) to generate
    the embedding vector of its nodes (right)](img/B16069_03_02.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2 – 将 GF 算法应用于图（左）以生成其节点嵌入向量（右）](img/B16069_03_02.jpg)'
- en: Figure 3.2 – Application of the GF algorithm to a graph (left) to generate the
    embedding vector of its nodes (right)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 将 GF 算法应用于图（左）以生成其节点嵌入向量（右）
- en: From *Figure 3.2*, it is possible to see how nodes belonging to groups 1 and
    3 are mapped together in the same region of space. Those points are separated
    by the nodes belonging to group 2\. This mapping allows us to well separate groups
    1 and 3 from group 2\. Unfortunately, there is no clear separation between groups
    1 and 3.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从 *图 3.2* 中，我们可以看到属于组 1 和 3 的节点如何在同一空间区域中映射在一起。这些点被属于组 2 的节点所分隔。这种映射使我们能够很好地将组
    1 和 3 与组 2 分离。不幸的是，组 1 和 3 之间没有明显的分离。
- en: Higher-order proximity preserved embedding
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高阶邻近保持嵌入
- en: 'HOPE is another graph embedding technique based on the matrix factorization
    principle. This method allows preserving higher-order proximity and does not force
    its embeddings to have any symmetric properties. Before starting to describe the
    method, let''s understand what first-order proximity and high-order proximity
    mean:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: HOPE 是另一种基于矩阵分解原理的图嵌入技术。这种方法允许保持高阶邻近，并且不强制其嵌入具有任何对称性质。在开始描述该方法之前，让我们了解一阶邻近和高阶邻近的含义：
- en: '**First-order proximity**: Given a graph, ![](img/B16069_03_013.png), where
    the edges have a weight, ![](img/B16069_03_014.png), for each vertex pair ![](img/B16069_03_015.png),
    we say they have a first-order proximity equal to ![](img/B16069_03_016.png) if
    the edge ![](img/B16069_03_017.png). Otherwise, the first-order proximity between
    the two nodes is 0.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一阶邻近**：给定一个图 ![img/B16069_03_013.png](img/B16069_03_013.png)，其中边具有权重 ![img/B16069_03_014.png](img/B16069_03_014.png)，对于每个顶点对
    ![img/B16069_03_015.png](img/B16069_03_015.png)，如果边 ![img/B16069_03_017.png](img/B16069_03_017.png)，则我们说它们具有等于
    ![img/B16069_03_016.png](img/B16069_03_016.png) 的一阶邻近。否则，两个节点之间的一阶邻近为 0。'
- en: '**Second- and high-order proximity**: With the second-order proximity, we can
    capture the two-step relations between each pair of vertices. For each vertex
    pair ![](img/B16069_03_018.png), we can see the second-order proximity as a two-step
    transition from ![](img/B16069_03_019.png) to ![](img/B16069_03_020.png). High-order
    proximity generalizes this concept and allows us to capture a more global structure.
    As a consequence, high-order proximity can be viewed as a k-step (*k* ≥ 3) transition
    from ![](img/B16069_03_021.png) to ![](img/B16069_03_022.png).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二阶及高阶邻近**：使用二阶邻近，我们可以捕捉每对顶点之间的两步关系。对于每个顶点对 ![img/B16069_03_018.png](img/B16069_03_018.png)，我们可以将二阶邻近视为从
    ![img/B16069_03_019.png](img/B16069_03_019.png) 到 ![img/B16069_03_020.png](img/B16069_03_020.png)
    的两步转换。高阶邻近泛化了这个概念，并允许我们捕捉更全局的结构。因此，高阶邻近可以被视为从 ![img/B16069_03_021.png](img/B16069_03_021.png)
    到 ![img/B16069_03_022.png](img/B16069_03_022.png) 的 k 步（*k* ≥ 3）转换。'
- en: 'Given the definition of proximity, we can now describe the HOPE method. Formally,
    let ![](img/B16069_03_023.png) be the graph we want to compute the embedding for
    and let ![](img/B16069_03_024.png) be its adjacency matrix. The loss function
    (*L*) used by this problem is as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 给定邻近的定义，我们现在可以描述 HOPE 方法。形式上，设 ![img/B16069_03_023.png](img/B16069_03_023.png)
    为我们想要计算嵌入的图，设 ![img/B16069_03_024.png](img/B16069_03_024.png) 为其邻接矩阵。此问题使用的损失函数（*L*）如下：
- en: '![](img/B16069_03_025.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![img/B16069_03_025.jpg](img/B16069_03_025.jpg)'
- en: In the preceding equation, ![](img/B16069_03_026.png) is a similarity matrix
    generated from graph ![](img/B16069_03_027.png) and ![](img/B16069_03_028.png)
    and ![](img/B16069_03_029.png) are two embedding matrices representing a *d*-dimensional
    embedding space. In more detail, ![](img/B16069_03_030.png) represents the source
    embedding and ![](img/B16069_03_031.png) represents the target embedding.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，![img/B16069_03_026.png](img/B16069_03_026.png) 是由图 ![img/B16069_03_027.png](img/B16069_03_027.png)
    和 ![img/B16069_03_028.png](img/B16069_03_028.png) 以及 ![img/B16069_03_029.png](img/B16069_03_029.png)
    生成的相似性矩阵。更详细地说，![img/B16069_03_030.png](img/B16069_03_030.png) 代表源嵌入，而 ![img/B16069_03_031.png](img/B16069_03_031.png)
    代表目标嵌入。
- en: HOPE uses those two matrices in order to capture asymmetric proximity in directed
    networks where the direction from a source node and a target node is present.
    The final embedding matrix, ![](img/B16069_03_032.png), is obtained by simply
    concatenating, column-wise, the ![](img/B16069_03_033.png) and ![](img/B16069_03_034.png)
    matrices. Due to this operation, the final embedding space generated by HOPE will
    have ![](img/B16069_03_035.png) dimensions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: HOPE使用这两个矩阵来捕捉有向网络中的非对称邻近性，其中存在从源节点到目标节点的方向。最终的嵌入矩阵，![](img/B16069_03_032.png)，通过简单地按列连接![](img/B16069_03_033.png)和![](img/B16069_03_034.png)矩阵获得。由于这个操作，由HOPE生成的最终嵌入空间将具有![](img/B16069_03_035.png)维。
- en: As we already stated, the ![](img/B16069_03_036.png) matrix is a similarity
    matrix obtained from the original graph, *G*. The goal of ![](img/B16069_03_037.png)
    is to obtain high-order proximity information. Formally, it is computed as ![](img/B16069_03_038.png),
    where ![](img/B16069_03_039.png) and ![](img/B16069_03_040.png) are both polynomials
    of matrices.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所述，![](img/B16069_03_036.png)矩阵是从原始图*G*中获得的相似度矩阵。![](img/B16069_03_037.png)的目标是获得高阶邻近信息。形式上，它被计算为![](img/B16069_03_038.png)，其中![](img/B16069_03_039.png)和![](img/B16069_03_040.png)都是矩阵的多项式。
- en: In its original formulation, the authors of HOPE suggested different ways to
    compute ![](img/B16069_03_041.png) and ![](img/B16069_03_042.png). Here we report
    a common and easy method to compute those matrices, **Adamic-Adar** (**AA**).
    In this formulation, ![](img/B16069_03_043.png)(the identity matrix) while ![](img/B16069_03_044.png),
    where ![](img/B16069_03_045.png) is a diagonal matrix computed as ![](img/B16069_03_046.png).
    Other formulations to compute ![](img/B16069_03_047.png)and ![](img/B16069_03_048.png)
    are the **Katz Index**, **Rooted PageRank** (**RPR**), and **Common Neighbors**
    (**CN**).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在其原始公式中，HOPE的作者建议了不同的方法来计算![](img/B16069_03_041.png)和![](img/B16069_03_042.png)。在这里，我们报告了一种常见且简单的方法来计算这些矩阵，**Adamic-Adar**（**AA**）。在这个公式中，![](img/B16069_03_043.png)（单位矩阵）而![](img/B16069_03_044.png)，其中![](img/B16069_03_045.png)是一个对角矩阵，其计算方式为![](img/B16069_03_046.png)。计算![](img/B16069_03_047.png)和![](img/B16069_03_048.png)的其他公式包括**Katz指数**、**根PageRank**（**RPR**）和**共同邻居**（**CN**）。
- en: 'In the following code, we will show how to perform the node embedding of a
    given `networkx` graph using Python and the GEM library:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将展示如何使用Python和GEM库对给定的`networkx`图执行节点嵌入：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The preceding code is similar to the one used for GF. The only difference is
    in the class initialization since here we use `HOPE`. According to the implementation
    provided by GEM, the `d` parameter, representing the dimension of the embedding
    space, will define the number of columns of the final embedding matrix, ![](img/B16069_03_049.png),
    obtained after the column-wise concatenation of ![](img/B16069_03_050.png) and
    ![](img/B16069_03_051.png).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码与用于GF的代码类似。唯一的区别在于类初始化，因为在这里我们使用`HOPE`。根据GEM提供的实现，`d`参数，表示嵌入空间的维度，将定义最终嵌入矩阵![](img/B16069_03_049.png)的列数，该矩阵是在按列连接![](img/B16069_03_050.png)和![](img/B16069_03_051.png)之后获得的。
- en: 'As a consequence, the number of columns of ![](img/B16069_03_052.png) and ![](img/B16069_03_053.png)
    is defined by the floor division (the `//` operator in Python) of the value assigned
    to `d`. The results of the code are shown in the following graph:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，![](img/B16069_03_052.png)和![](img/B16069_03_053.png)的列数由`d`分配的值的整数除法（Python中的`//`运算符）定义。代码的结果在以下图表中显示：
- en: '![Figure 3.3 – Application of the HOPE algorithm to a graph (left) to generate
    the embedding vector of its nodes (right)](img/B16069_03_03.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – 将HOPE算法应用于图（左）以生成其节点的嵌入向量（右）](img/B16069_03_03.jpg)'
- en: Figure 3.3 – Application of the HOPE algorithm to a graph (left) to generate
    the embedding vector of its nodes (right)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 将HOPE算法应用于图（左）以生成其节点的嵌入向量（右）
- en: In this case, the graph is undirected and thus there is no difference between
    the source and target nodes. *Figure 3.3* shows the first two dimensions of the
    `embeddings` matrix representing ![](img/B16069_03_054.png). It is possible to
    see how the embedding space generated by HOPE provides, in this case, a better
    separation of the different nodes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，图是无向的，因此源节点和目标节点之间没有区别。*图3.3*显示了表示![](img/B16069_03_054.png)的`embeddings`矩阵的前两个维度。可以看到，HOPE生成的嵌入空间在这种情况下提供了不同节点之间更好的分离。
- en: Graph representation with global structure information
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带有全局结构信息的图表示
- en: 'Graph representation with global structure information (GraphRep), such as
    HOPE, allows us to preserve higher-order proximity without forcing its embeddings
    to have symmetric properties. Formally, let ![](img/B16069_03_055.png) be the
    graph we want to compute the node embeddings for and let ![](img/B16069_03_056.png)
    be its adjacency matrix. The loss function (*L*) used by this problem is as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 具有全局结构信息的图表示（GraphRep），如HOPE，允许我们保留高阶邻近度，而不强迫其嵌入具有对称属性。形式上，设![](img/B16069_03_055.png)为我们想要计算节点嵌入的图，设![](img/B16069_03_056.png)为其邻接矩阵。此问题使用的损失函数（*L*）如下：
- en: '![](img/B16069_03_057.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16069_03_057.jpg)'
- en: In the preceding equation, ![](img/B16069_03_058.png) is a matrix generated
    from graph *G* in order to get the *k*th order of proximity between nodes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个方程中，![](img/B16069_03_058.png)是从图*G*生成的矩阵，用于获取节点之间的*k*阶邻近度。
- en: '![](img/B16069_03_059.png) and ![](img/B16069_03_060.png) are two embedding
    matrices representing a *d*-dimensional embedding space of the *k*th order of
    proximity for the source and target nodes, respectively.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B16069_03_059.png)和![](img/B16069_03_060.png)是两个嵌入矩阵，分别表示源节点和目标节点的*k*阶邻近度的*d*-维嵌入空间。'
- en: 'The ![](img/B16069_03_061.png) matrix is computed according to the following
    equation: ![](img/B16069_03_062.png). Here, ![](img/B16069_03_063.png) is a diagonal
    matrix known as the **degree matrix** computed using the following equation:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以下方程计算![](img/B16069_03_061.png)矩阵：![](img/B16069_03_062.png)。在这里，![](img/B16069_03_063.png)是使用以下方程计算出的称为**度矩阵**的对角矩阵：
- en: '![](img/B16069_03_064.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – 将GraphRep算法应用于图（顶部）以生成其节点嵌入向量（底部）的不同k值](img/B16069_03_064.jpg)'
- en: '![](img/B16069_03_065.png) represents the (one-step) probability transition
    matrix, where ![](img/B16069_03_066.png) is the probability of a transition from
    ![](img/B16069_03_067.png)to vertex ![](img/B16069_03_068.png) within one step.
    In general, for a generic value of *k*, ![](img/B16069_03_069.png) represents
    the probability of a transition from ![](img/B16069_03_070.png)to vertex ![](img/B16069_03_071.png)
    within *k* steps.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B16069_03_065.png)代表（一步）概率转移矩阵，其中![](img/B16069_03_066.png)是在一步内从![](img/B16069_03_067.png)到顶点![](img/B16069_03_068.png)的转移概率。一般来说，对于通用的*k*值，![](img/B16069_03_069.png)代表在*k*步内从![](img/B16069_03_070.png)到顶点![](img/B16069_03_071.png)的转移概率。'
- en: For each order of proximity, *k*, an independent optimization problem is fitted.
    All the *k* embedding matrices generated are then column-wise concatenated to
    get the final source embedding matrices.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个邻近度阶数*k*，拟合一个独立的优化问题。然后，所有生成的*k*嵌入矩阵按列连接，以获得最终的源嵌入矩阵。
- en: 'In the following code, we will show how to perform the node embedding of a
    given `networkx` graph using Python and the `karateclub` library:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将展示如何使用Python和`karateclub`库对给定的`networkx`图执行节点嵌入：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We initialize the `GraRep` class from the `karateclub` library. In this implementation,
    the `dimension` parameter represents the dimension of the embedding space, while
    the `order` parameter defines the maximum number of orders of proximity between
    nodes. The number of columns of the final embedding matrix (stored, in the example,
    in the `embeddings` variable) is `dimension*order`, since, as we said, for each
    proximity order an embedding is computed and concatenated in the final embedding
    matrix.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`karateclub`库初始化`GraRep`类。在这个实现中，`dimension`参数表示嵌入空间的维度，而`order`参数定义了节点之间最大邻近度阶数。最终嵌入矩阵的列数（例如，在示例中存储在`embeddings`变量中）是`dimension*order`，因为，正如我们所说的，对于每个邻近度阶数，都会计算并连接到最终的嵌入矩阵中。
- en: 'To specify, since two dimensions are computed in the example, `embeddings[:,:2]`
    represents the embedding obtained for *k*=1, `embeddings[:,2:4]` for *k*=2, and
    `embeddings[:,4:]` for *k*=3\. The results of the code are shown in the following
    graph:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，由于示例中计算了两个维度，`embeddings[:,:2]`表示对于*k*=1获得的嵌入，`embeddings[:,2:4]`表示*k*=2，而`embeddings[:,4:]`表示*k*=3。代码的结果如下所示：
- en: .f
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: .f
- en: '![Figure 3.4 – Application of the GraphRep algorithm to a graph (top) to generate
    the embedding vector of its nodes (bottom) for different values of k](img/B16069_03_04.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – 将GraphRep算法应用于图（顶部）以生成其节点嵌入向量（底部）的不同k值](img/B16069_03_04.jpg)'
- en: Figure 3.4 – Application of the GraphRep algorithm to a graph (top) to generate
    the embedding vector of its nodes (bottom) for different values of k
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 将GraphRep算法应用于图（顶部）以生成其节点嵌入向量（底部）的不同k值
- en: From the preceding graph, it is easy to see how different orders of proximity
    allow us to get different embeddings. Since the input graph is quite simple, in
    this case, already with *k*=1, a well-separated embedding space is obtained. To
    specify, the nodes belonging to groups 1 and 3 in all the proximity orders have
    the same embedding values (they are overlapping in the scatter plot).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中，很容易看出不同的邻近顺序如何使我们得到不同的嵌入。由于输入图相当简单，在这种情况下，即使*k*=1，也能获得一个很好地分离的嵌入空间。具体来说，所有邻近顺序中属于第1组和第3组的节点具有相同的嵌入值（它们在散点图中是重叠的）。
- en: In this section, we described some matrix factorization methods for unsupervised
    graph embedding. In the next section, we will introduce a different way to perform
    unsupervised graph embedding using skip-gram models.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了一些无监督图嵌入的矩阵分解方法。在下一节中，我们将介绍使用跳字图模型进行无监督图嵌入的不同方法。
- en: Skip-gram
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跳字图
- en: In this section, we will provide a quick description of the skip-gram model.
    Since it is widely used by different embedding algorithms, a high-level description
    is needed to better understand the different methods. Before going deep into a
    detailed description, we will first give a brief overview.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要描述跳字图模型。由于它在不同的嵌入算法中广泛使用，因此需要一个高级描述来更好地理解不同的方法。在深入详细描述之前，我们首先给出一个简要概述。
- en: 'The skip-gram model is a simple neural network with one hidden layer trained
    in order to predict the probability of a given word being present when an input
    word is present. The neural network is trained by building the training data using
    a text corpus as a reference. This process is described in the following chart:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 跳字图模型是一个简单的神经网络，包含一个隐藏层，用于在输入词存在时预测给定词出现的概率。该神经网络通过使用文本语料库作为参考来构建训练数据来训练。这个过程在以下图表中描述：
- en: '![Figure 3.5 – Example of the generation of training data from a given corpus.
    In the filled boxes, the target word. In the dash boxes, the context words identified
    by a window size of length 2](img/B16069_03_05.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – 从给定语料库生成训练数据的例子。在填充的框中是目标词。在虚线框中，是长度为2的窗口大小识别出的上下文词](img/B16069_03_05.jpg)'
- en: Figure 3.5 – Example of the generation of training data from a given corpus.
    In the filled boxes, the target word. In the dash boxes, the context words identified
    by a window size of length 2
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 从给定语料库生成训练数据的例子。在填充的框中是目标词。在虚线框中，是长度为2的窗口大小识别出的上下文词
- en: The example described in *Figure 3.5* shows how the algorithm to generate the
    training data works. A *target* word is selected and a rolling window of fixed
    size *w* is built around that word. The words inside the rolling windows are known
    as *context* words. Multiple pairs of *(target word, context word)* are then built
    according to the words inside the rolling window.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.5*中描述的例子展示了生成训练数据的算法是如何工作的。选择一个*目标词*，并围绕该词构建一个固定大小的滚动窗口*w*。滚动窗口内的词被称为*上下文词*。然后根据滚动窗口内的词构建多个*(目标词，上下文词)*对。'
- en: Once the training data is generated from the whole corpus, the skip-gram model
    is trained to predict the probability of a word being a context word for the given
    target. During its training, the neural network learns a compact representation
    of the input words. This is why the skip-gram model is also known as **Word to
    Vector** (**Word2Vec**).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦从整个语料库中生成了训练数据，跳字图模型就被训练来预测给定目标词的上下文词的概率。在其训练过程中，神经网络学习输入词的紧凑表示。这就是为什么跳字图模型也被称为**词到向量**（**Word2Vec**）。
- en: 'The structure of the neural network representing the skip-gram model is described
    in the following chart:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 跳字图模型表示的神经网络结构在以下图表中描述：
- en: '![Figure 3.6 – Structure of the neural network of the skip-gram model. The
    number of d neurons in the hidden layer represents the final size of the embedding
    space](img/B16069_03_06.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6 – 跳字图模型的神经网络结构。隐藏层中d神经元的数量表示嵌入空间的最终大小](img/B16069_03_06.jpg)'
- en: Figure 3.6 – Structure of the neural network of the skip-gram model. The number
    of d neurons in the hidden layer represents the final size of the embedding space
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – 跳字图模型的神经网络结构。隐藏层中d神经元的数量表示嵌入空间的最终大小
- en: The input of the neural network is a binary vector of size *m*. Each element
    of the vector represents a word in the dictionary of the language we want to embed
    the words in. When, during the training process, a *(target word, context word)*
    pair is given, the input array will have 0 in all its entries with the exception
    of the entry representing the "target" word, which will be equal to 1\. The hidden
    layer has *d* neurons. The hidden layer will learn the embedding representation
    of each word, creating a *d*-dimensional embedding space.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的输入是一个大小为 *m* 的二进制向量。向量的每个元素代表我们想要嵌入的单词语言字典中的一个单词。当在训练过程中给出一个 *(目标词，上下文词)*
    对时，输入数组在其所有条目中都将为0，除了表示“目标”词的条目，它将等于1。隐藏层有 *d* 个神经元。隐藏层将学习每个单词的嵌入表示，创建一个 *d*-维嵌入空间。
- en: Finally, the output layer of the neural network is a dense layer of *m* neurons
    (the same size as the input vector) with a *softmax* activation function. Each
    neuron represents a word of the dictionary. The value assigned by the neuron corresponds
    to the probability of that word being "related" to the input word. Since softmax
    can be hard to compute when the size of *m* increases, a *hierarchical softmax*
    approach is always used.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，神经网络的输出层是一个包含 *m* 个神经元（与输入向量大小相同）的密集层，并使用 *softmax* 激活函数。每个神经元代表字典中的一个单词。神经元分配的值对应于该单词与输入单词“相关”的概率。由于当
    *m* 的大小增加时softmax可能难以计算，因此通常使用**层次softmax**方法。
- en: 'The final goal of the skip-gram model is not to actually learn the task we
    previously described but to build a compact *d*-dimensional representation of
    the input words. Thanks to this representation, it is possible to easily extract
    an embedding space for the words using the weight of the hidden layer. Another
    common approach to creating a skip-gram model, which will be not described here,
    is *context-based*: **Continuous Bag-of-Words** (**CBOW**).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: skip-gram模型最终的目标不是真正学习我们之前描述的任务，而是构建输入单词的紧凑 *d*-维表示。得益于这种表示，可以很容易地使用隐藏层的权重提取单词的嵌入空间。另一种常见的创建skip-gram模型的方法（这里将不描述），是基于**连续词袋**（**CBOW**）。
- en: Since the basic concepts behind the skip-gram model have been introduced, we
    can start to describe a series of unsupervised graph embedding algorithms built
    upon this model. Generally speaking, all the unsupervised embedding algorithms
    based on the skip-gram model use the same principle.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍了skip-gram模型背后的基本概念之后，我们可以开始描述一系列基于此模型构建的无监督图嵌入算法。一般来说，所有基于skip-gram模型的无监督嵌入算法都使用相同的原理。
- en: Starting from an input graph, they extract from it a set of walks. Those walks
    can be seen as a text corpus where each node represents a word. Two words (representing
    nodes) are near each other in the text if they are connected by an edge in a walk.
    The main difference between each method lies in the way those walks are computed.
    Indeed, as we will see, different walk generation algorithms can emphasize particular
    local or global structures of the graph.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个输入图开始，他们从中提取出一组路径。这些路径可以看作是一个文本语料库，其中每个节点代表一个单词。在路径中通过边连接的两个单词（代表节点）在文本中彼此靠近。每种方法之间的主要区别在于计算这些路径的方式。实际上，正如我们将看到的，不同的路径生成算法可以强调图的特殊局部或全局结构。
- en: DeepWalk
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DeepWalk
- en: The DeepWalk algorithm generates the node embedding of a given graph using the
    skip-gram model. In order to provide a better explanation of this model, we need
    to introduce the concept of **random walks**.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: DeepWalk算法使用skip-gram模型生成给定图的节点嵌入。为了更好地解释这个模型，我们需要介绍**随机游走**的概念。
- en: Formally, let ![](img/B16069_03_072.png) be a graph and let ![](img/B16069_03_073.png)
    be a vertex selected as the starting point. We select a neighbor of ![](img/B16069_03_074.png)
    at random and we move toward it. From this point, we randomly select another point
    to move. This process is repeated ![](img/B16069_03_075.png) times. The random
    sequence of ![](img/B16069_03_076.png) vertices selected in this way is a random
    walk of length ![](img/B16069_03_077.png). It is worth mentioning that the algorithm
    used to generate the random walks does not impose any constraint on how they are
    built. As a consequence, there is no guarantee that the local neighborhood of
    the node is well preserved.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，设![](img/B16069_03_072.png)为一个图，设![](img/B16069_03_073.png)为一个选定的起始点。我们随机选择![](img/B16069_03_074.png)的一个邻居并向其移动。从这个点开始，我们随机选择另一个点进行移动。这个过程重复![](img/B16069_03_075.png)次。以这种方式选出的![](img/B16069_03_076.png)个顶点的随机序列是一个长度为![](img/B16069_03_077.png)的随机游走。值得一提的是，用于生成随机游走的算法不对它们的构建方式施加任何约束。因此，不能保证节点的局部邻域得到很好的保留。
- en: 'Using the notion of random walk, the DeepWalk algorithm generates a random
    walk of a size of at most *t* for each node. Those random walks will be given
    as input to the skip-gram model. The embedding generated using skip-gram will
    be used as the final node embedding. In the following figure (*Figure 3.7*), we
    can see a step-by-step graphical representation of the algorithm:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用随机游走的概念，DeepWalk算法为每个节点生成一个最大长度为*t*的随机游走。这些随机游走将被作为skip-gram模型的输入。使用skip-gram生成的嵌入将被用作最终的节点嵌入。在下面的图（*图3.7*）中，我们可以看到算法的逐步图形表示：
- en: '![Figure 3.7 – All the steps used by the DeepWalk algorithm to generate the
    node embedding of a given graph](img/B16069_03_07.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图3.7 – DeepWalk算法生成给定图节点嵌入的所有步骤](img/B16069_03_07.jpg)'
- en: Figure 3.7 – All the steps used by the DeepWalk algorithm to generate the node
    embedding of a given graph
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – DeepWalk算法生成给定图节点嵌入的所有步骤
- en: 'Here is a step-by-step explanation of the algorithm graphically described in
    the preceding chart:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是对前面图表中图形描述的算法的逐步解释：
- en: '**Random Walk Generation**: For each node of input graph *G*, a set of ![](img/B16069_03_078.png)random
    walks with a fixed maximum length (*t*) is computed. It should be noted that the
    length *t* is an upper bound. There are no constraints forcing all the paths to
    have the same length.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**随机游走生成**：对于输入图*G*的每个节点，计算一组具有固定最大长度(*t*)的随机游走。需要注意的是，长度*t*是一个上限。没有约束强制所有路径具有相同的长度。'
- en: '**Skip-Gram Training**: Using all the random walks generated in the previous
    step, a skip-gram model is trained. As we described earlier, the skip-gram model
    works on words and sentences. When a graph is given as input to the skip-gram
    model, as visible in *Figure 3.7*, a graph can be seen as an input text corpus,
    while a single node of the graph can be seen as a word of the corpus.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Skip-Gram训练**：使用之前步骤中生成的所有随机游走，训练一个skip-gram模型。正如我们之前所描述的，skip-gram模型在单词和句子上工作。当将一个图作为skip-gram模型的输入时，如*图3.7*所示，一个图可以看作是一个输入文本语料库，而图中的单个节点可以看作是语料库中的一个单词。'
- en: A random walk can be seen as a sequence of words (a sentence). The skip-gram
    is then trained using the "fake" sentences generated by the nodes in the random
    walk. The parameters for the skip-gram model previously described (window size,
    *w*, and embed size, *d*) are used in this step.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随机游走可以看作是一系列单词（一个句子）。然后使用随机游走中节点生成的“假”句子来训练skip-gram。在此步骤中使用了之前描述的skip-gram模型的参数（窗口大小，*w*，和嵌入大小，*d*）。
- en: '**Embedding Generation**: The information contained in the hidden layers of
    the trained skip-gram model is used in order to extract the embedding of each
    node.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入生成**：使用训练好的skip-gram模型的隐藏层中的信息来提取每个节点的嵌入。'
- en: 'In the following code, we will show how to perform the node embedding of a
    given `networkx` graph using Python and the `karateclub` library:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们将展示如何使用Python和`karateclub`库对给定的`networkx`图执行节点嵌入：
- en: '[PRE4]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The code is quite simple. We initialize the `DeepWalk` class from the `karateclub`
    library. In this implementation, the `dimensions` parameter represents the dimension
    of the embedding space. Other parameters worth mentioning that the `DeepWalk`
    class accepts are as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相当简单。我们从`karateclub`库初始化`DeepWalk`类。在这个实现中，`dimensions`参数表示嵌入空间的维度。`DeepWalk`类接受的其它值得注意的参数如下：
- en: '`walk_number`: The number of random walks to generate for each node'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`walk_number`：为每个节点生成随机游走的数量'
- en: '`walk_length`: The length of the generated random walks'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`walk_length`：生成的随机游走的长度'
- en: '`window_size`: The window size parameter of the skip-gram model'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`window_size`：跳字模型的窗口大小参数'
- en: Finally, the model is fitted on graph *G* using `dw.fit(G)` and the embeddings
    are extracted using `dw.get_embedding()`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用`dw.fit(G)`在图*G*上拟合模型，并使用`dw.get_embedding()`提取嵌入。
- en: 'The results of the code are shown in the following figure:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了代码的结果：
- en: '![Figure 3.8 – Application of the DeepWalk algorithm to a graph (left) to generate
    the embedding vector of its nodes (right)](img/B16069_03_08.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图3.8 – 将DeepWalk算法应用于图（左）以生成其节点的嵌入向量（右）](img/B16069_03_08.jpg)'
- en: Figure 3.8 – Application of the DeepWalk algorithm to a graph (left) to generate
    the embedding vector of its nodes (right)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 – 将DeepWalk算法应用于图（左）以生成其节点的嵌入向量（右）
- en: From the previous graph, we can see how DeepWalk is able to separate region
    1 from region 3\. Those two groups are contaminated by the nodes belonging to
    region 2\. Indeed, for those nodes, a clear distinction is not visible in the
    embedding space.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中，我们可以看到DeepWalk如何将区域1和区域3分开。这两个组受到属于区域2的节点的影响。确实，对于这些节点，在嵌入空间中无法看到明显的区分。
- en: Node2Vec
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Node2Vec
- en: The **Node2Vec** algorithm can be seen as an extension of DeepWalk. Indeed,
    as with DeepWalk, Node2Vec also generates a set of random walks used as input
    to a skip-gram model. Once trained, the hidden layers of the skip-gram model are
    used to generate the embedding of the node in the graph. The main difference between
    the two algorithms lies in the way the random walks are generated.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**Node2Vec**算法可以看作是DeepWalk的扩展。确实，与DeepWalk一样，Node2Vec也生成一组随机游走，作为跳字模型的输入。一旦训练完成，跳字模型的隐藏层被用来生成图中节点的嵌入。这两个算法之间的主要区别在于随机游走的生成方式。'
- en: Indeed, if DeepWalk generates random walks without using any bias, in Node2Vec
    a new technique to generate biased random walks on the graph is introduced. The
    algorithm to generate the random walks combines graph exploration by merging **Breadth-First
    Search** (**BFS**) and **Depth-First Search** (**DFS**). The way those two algorithms
    are combined in the random walk's generation is regularized by two parameters,
    ![](img/B16069_03_079.png) and ![](img/B16069_03_080.png). ![](img/B16069_03_081.png)
    defines the probability of a random walk getting back to the previous node, while
    ![](img/B16069_03_082.png) defines the probability that a random walk can pass
    through a previously unseen part of the graph.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果DeepWalk在不使用任何偏差的情况下生成随机游走，那么在Node2Vec中引入了一种生成有偏随机游走的新技术。生成随机游走的算法通过合并**广度优先搜索**（**BFS**）和**深度优先搜索**（**DFS**）来进行图探索。这两种算法在随机游走生成中的结合方式由两个参数进行正则化，![](img/B16069_03_079.png)和![](img/B16069_03_080.png)。![](img/B16069_03_081.png)定义了随机游走返回前一个节点的概率，而![](img/B16069_03_082.png)定义了随机游走通过之前未见过的图部分的概率。
- en: Due to this combination, Node2Vec can preserve high-order proximities by preserving
    local structures in the graph as well as global community structures. This new
    method of random walk generation allows solving the limitation of DeepWalk preserving
    the local neighborhood properties of the node.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种组合，Node2Vec可以通过保留图中的局部结构和全局社区结构来保留高阶邻近性。这种新的随机游走生成方法允许解决DeepWalk保留节点局部邻域属性的限制。
- en: 'In the following code, we will show how to perform the node embedding of a
    given `networkx` graph using Python and the `node2vec` library:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将展示如何使用Python和`node2vec`库对给定的`networkx`图进行节点嵌入：
- en: '[PRE5]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Also, for Node2Vec, the code is straightforward. We initialize the `Node2Vec`
    class from the `node2vec` library. In this implementation, the `dimensions` parameter
    represents the dimension of the embedding space. The model is then fitted using
    `node2vec.fit(window=10)`. Finally, the embeddings are obtained using `model.wv`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于Node2Vec，代码非常直接。我们从`node2vec`库中初始化`Node2Vec`类。在这个实现中，`dimensions`参数表示嵌入空间的维度。然后使用`node2vec.fit(window=10)`进行模型拟合。最后，使用`model.wv`获取嵌入。
- en: 'It should be noted that `model.wv` is an object of the `Word2VecKeyedVectors`
    class. In order to get the embedding vector of a specific node with `nodeid` as
    the ID, we can use the trained model, as follows: `model.wv[str(nodeId)]`. Other
    parameters worth mentioning that the `Node2Vec` class accepts are as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 应注意，`model.wv` 是 `Word2VecKeyedVectors` 类的对象。为了获取具有 `nodeid` 作为 ID 的特定节点的嵌入向量，我们可以使用训练好的模型，如下所示：`model.wv[str(nodeId)]`。`Node2Vec`
    类接受的其它参数也值得提及，如下：
- en: '`num_walks`: The number of random walks to generate for each node'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_walks`: 为每个节点生成的随机游走的数量'
- en: '`walk_length`: The length of the generated random walks'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`walk_length`: 生成的随机游走的长度'
- en: '`p, q`: The *p* and *q* parameters of the random walk''s generation algorithm'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p, q`: 随机游走生成算法的 *p* 和 *q* 参数'
- en: 'The results of the code are shown in *Figure 3.9*:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的结果显示在 *图 3.9* 中：
- en: '![Figure 3.9 – Application of the Node2Vec algorithm to a graph (left) to generate
    the embedding vector of its nodes (right)](img/B16069_03_09.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.9 – 将 Node2Vec 算法应用于图（左）以生成其节点的嵌入向量（右）](img/B16069_03_09.jpg)'
- en: Figure 3.9 – Application of the Node2Vec algorithm to a graph (left) to generate
    the embedding vector of its nodes (right)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9 – 将 Node2Vec 算法应用于图（左）以生成其节点的嵌入向量（右）
- en: As is visible from *Figure 3.9*, Node2Vec allows us to obtain a better separation
    between nodes in the embedding space compared to DeepWalk. To specify, regions
    1 and 3 are well clustered in two regions of space. Region 2 instead is well placed
    in the middle of the two groups without any overlap.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 3.9* 所示，Node2Vec 允许我们在嵌入空间中获得比 DeepWalk 更好的节点分离。具体来说，区域 1 和 3 在空间中的两个区域中很好地聚集。而区域
    2 则位于两组中间，没有任何重叠。
- en: Edge2Vec
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Edge2Vec
- en: Contrary to the other embedding function, the **Edge to Vector** (**Edge2Vec**)
    algorithm generates the embedding space on edges, instead of nodes. This algorithm
    is a simple side effect of the embedding generated by using Node2Vec. The main
    idea is to use the node embedding of two adjacent nodes to perform some basic
    mathematical operations in order to extract the embedding of the edge connecting
    them.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他嵌入函数不同，**边到向量**（**Edge2Vec**）算法在边而不是节点上生成嵌入空间。该算法是使用 Node2Vec 生成的嵌入的简单副作用。主要思想是使用两个相邻节点的节点嵌入来执行一些基本的数学运算，以提取连接它们的边的嵌入。
- en: 'Formally, let ![](img/B16069_03_083.png) and ![](img/B16069_03_084.png) be
    two adjacent nodes and let ![](img/B16069_03_085.png) and ![](img/B16069_03_086.png)
    be their embeddings computed with Node2Vec. The operators described in *Table
    3.1* can be used in order to compute the embedding of their edge:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，令 ![](img/B16069_03_083.png) 和 ![](img/B16069_03_084.png) 为两个相邻节点，令 ![](img/B16069_03_085.png)
    和 ![](img/B16069_03_086.png) 为它们使用 Node2Vec 计算的嵌入。*表 3.1* 中描述的算子可以用来计算它们的边的嵌入：
- en: '![Table 3.1 – Edge embedding operators with their equation and class name in
    the Node2Vec library](img/B16069_03_Table_01.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![表 3.1 – Node2Vec 库中的边嵌入算子及其方程和类名](img/B16069_03_Table_01.jpg)'
- en: Table 3.1 – Edge embedding operators with their equation and class name in the
    Node2Vec library
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.1 – Node2Vec 库中的边嵌入算子及其方程和类名
- en: 'In the following code, we will show how to perform the node embedding of a
    given `networkx` graph using Python and the Node2Vec library:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将展示如何使用 Python 和 Node2Vec 库对给定的 `networkx` 图执行节点嵌入：
- en: '[PRE6]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The code is quite simple. The `HadamardEmbedder` class is instantiated with
    only the `keyed_vectors` parameter. The value of this parameter is the embedding
    model generated by Node2Vec. In order to use other techniques to generate the
    edge embedding, we just need to change the class and select one from the ones
    listed in *Table 3.1*. An example of the application of this algorithm is shown
    in the following figure:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相当简单。`HadamardEmbedder` 类仅使用 `keyed_vectors` 参数实例化。此参数的值是 Node2Vec 生成的嵌入模型。为了使用其他技术生成边嵌入，我们只需更改类并从
    *表 3.1* 中选择一个即可。以下图示展示了该算法的应用示例：
- en: '![Figure 3.11 – Application of the Edge2Vec algorithm to a graph (top) to generate
    the embedding vector of its nodes (bottom) using different methods](img/B16069_03_11.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.11 – 将 Edge2Vec 算法应用于图（顶部）以生成其节点的嵌入向量（底部）的不同方法](img/B16069_03_11.jpg)'
- en: Figure 3.11 – Application of the Edge2Vec algorithm to a graph (top) to generate
    the embedding vector of its nodes (bottom) using different methods
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11 – 将 Edge2Vec 算法应用于图（顶部）以生成其节点的嵌入向量（底部）的不同方法
- en: From *Figure 3.11*, we can see how different embedding methods generate completely
    different embedding spaces. `AverageEmbedder` and `HadamardEmbedder`, in this
    example, generate well-separated embeddings for regions 1, 2, and 3\.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 从[*图3.11*]中，我们可以看到不同的嵌入方法如何生成完全不同的嵌入空间。在本例中，`AverageEmbedder`和`HadamardEmbedder`为区域1、2和3生成了良好的分离嵌入。
- en: For `WeightedL1Embedder` and `WeightedL2Embedder`, however, the embedding space
    is not well separated since the edge embeddings are concentrated in a single region
    without showing clear clusters.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于`WeightedL1Embedder`和`WeightedL2Embedder`，由于边嵌入集中在单个区域而没有显示出清晰的聚类，因此嵌入空间没有很好地分离。
- en: Graph2Vec
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Graph2Vec
- en: The methods we previously described generated the embedding space for each node
    or edge on a given graph. **Graph to Vector** (**Graph2Vec**) generalizes this
    concept and generates embeddings for the whole graph.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前描述的方法为给定图上的每个节点或边生成了嵌入空间。**图到向量**（**Graph2Vec**）泛化了这个概念，并为整个图生成嵌入。
- en: 'To specify, given a set of graphs, the Graph2Vec algorithms generate an embedding
    space where each point represents a graph. This algorithm generates its embedding
    using an evolution of the Word2Vec skip-gram model known as **Document to Vector**
    (**Doc2Vec**). We can graphically see a simplification of this model in *Figure
    3.12*:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，给定一组图，Graph2Vec算法生成一个嵌入空间，其中每个点代表一个图。该算法使用Word2Vec skip-gram模型的演变来生成其嵌入，这种演变被称为**文档到向量**（**Doc2Vec**）。我们可以在[*图3.12*]中直观地看到该模型的简化：
- en: '![Figure 3.12 – Simplified graphical representation of the Doc2Vec skip-gram
    model. The number of d neurons in the hidden layer represents the final size of
    the embedding space](img/B16069_03_12.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图3.12 – Doc2Vec skip-gram模型的简化图形表示。隐藏层中d神经元的数量表示嵌入空间的最终大小](img/B16069_03_12.jpg)'
- en: Figure 3.12 – Simplified graphical representation of the Doc2Vec skip-gram model.
    The number of d neurons in the hidden layer represents the final size of the embedding
    space
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – Doc2Vec skip-gram模型的简化图形表示。隐藏层中d神经元的数量表示嵌入空间的最终大小
- en: Compared to the simple Word2Vec, Doc2Vec also accepts another binary array representing
    the document containing the input word. Given a "target" document and a "target"
    word, the model then tries to predict the most probable "context" word with respect
    to the input "target" word and document.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 与简单的Word2Vec相比，Doc2Vec还接受表示包含输入单词的文档的另一个二进制数组。给定一个“目标”文档和一个“目标”单词，该模型随后尝试预测与输入“目标”单词和文档相关的最可能的“上下文”单词。
- en: With the introduction of the Doc2Vec model, we can now describe the Graph2Vec
    algorithm. The main idea behind this method is to view an entire graph as a document
    and each of its subgraphs, generated as an ego graph (see [*Chapter 1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014),
    *Getting Started with Graphs*) of each node, as words that comprise the document.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Doc2Vec模型的引入，我们现在可以描述Graph2Vec算法。这种方法背后的主要思想是将整个图视为一个文档，并将每个节点生成的作为ego图（参见[*第1章*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014)，*Graphs入门*）的每个子图，视为构成文档的单词。
- en: 'In other words, a graph is composed of subgraphs as a document is composed
    of sentences. According to this description, the algorithm can be summarized into
    the following steps:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，图由子图组成，就像文档由句子组成一样。根据这种描述，算法可以总结为以下步骤：
- en: '**Subgraph generation**: A set of rooted subgraphs is generated around every
    node.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**子图生成**：围绕每个节点生成一组根子图。'
- en: '**Doc2Vec training**: The Doc2Vec skip-gram is trained using the subgraphs
    generated by the previous step.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Doc2Vec训练**：使用前一步骤生成的子图对Doc2Vec skip-gram进行训练。'
- en: '**Embedding generation**: The information contained in the hidden layers of
    the trained Doc2Vec model is used in order to extract the embedding of each node.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入生成**：使用训练好的Doc2Vec模型的隐藏层中的信息来提取每个节点的嵌入。'
- en: 'In the following code, as we already did in [*Chapter 2*](B16069_02_Final_JM_ePub.xhtml#_idTextAnchor035),
    *Graph Machine Learning*, we will show how to perform the node embedding of a
    set of `networkx` graphs using Python and the `karateclub` library:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，正如我们在[*第2章*](B16069_02_Final_JM_ePub.xhtml#_idTextAnchor035)，*Graph Machine
    Learning*中所做的那样，我们将展示如何使用Python和`karateclub`库对一组`networkx`图执行节点嵌入：
- en: '[PRE7]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this example, the following have been done:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，以下工作已经完成：
- en: 20 Watts-Strogatz graphs have been generated with random parameters.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 已生成20个具有随机参数的Watts-Strogatz图。
- en: We then initialize the `Graph2Vec` class from the `karateclub` library with
    two dimensions. In this implementation, the `dimensions` parameter represents
    the dimension of the embedding space.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用 `karateclub` 库中的 `Graph2Vec` 类初始化两个维度。在这个实现中，`dimensions` 参数表示嵌入空间的维度。
- en: The model is then fitted on the input data using `model.fit(Gs)`.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用 `model.fit(Gs)` 在输入数据上拟合模型。
- en: The vector containing the embeddings is extracted using `model.get_embedding()`.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `model.get_embedding()` 提取包含嵌入的向量。
- en: 'The results of the code are shown in the following figure:'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码的结果显示在下图中：
- en: '![Figure 3.13 – Application of the Graph2Vec algorithm to a graph (left) to
    generate the embedding vector of its nodes (right) using different methods](img/B16069_03_13.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.13 – 将 Graph2Vec 算法应用于图（左）以生成其节点的嵌入向量（右）的不同方法](img/B16069_03_13.jpg)'
- en: Figure 3.13 – Application of the Graph2Vec algorithm to a graph (left) to generate
    the embedding vector of its nodes (right) using different methods
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13 – 将 Graph2Vec 算法应用于图（左）以生成其节点的嵌入向量（右）的不同方法
- en: From *Figure 3.13*, it is possible to see the embedding space generated for
    the different graphs.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 从 *图 3.13* 中，可以看到为不同图生成的嵌入空间。
- en: 'In this section, we described different shallow embedding methods based on
    matrix factorization and the skip-gram model. However, in the scientific literature,
    a lot of unsupervised embedding algorithms exist, such as Laplacian methods. We
    refer those of you who are interested in exploring those methods to look at the
    paper *Machine Learning on Graphs: A Model and Comprehensive Taxonomy* available
    at [https://arxiv.org/pdf/2005.03675.pdf](https://arxiv.org/pdf/2005.03675.pdf).'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们描述了基于矩阵分解和 skip-gram 模型的不同浅层嵌入方法。然而，在科学文献中，存在许多无监督嵌入算法，如拉普拉斯方法。我们建议对那些感兴趣探索这些方法的读者查阅可用的论文
    *Machine Learning on Graphs: A Model and Comprehensive Taxonomy*，链接为 [https://arxiv.org/pdf/2005.03675.pdf](https://arxiv.org/pdf/2005.03675.pdf)。'
- en: We will continue our description of the unsupervised graph embedding method
    in the next sections. We will describe more complex graph embedding algorithms
    based on autoencoders.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节继续描述无监督图嵌入方法。我们将描述基于自动编码器的更复杂的图嵌入算法。
- en: Autoencoders
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动编码器
- en: 'Autoencoders are an extremely powerful tool that can effectively help data
    scientists to deal with high-dimensional datasets. Although first presented around
    30 years ago, in recent years, autoencoders have become more and more widespread
    in conjunction with the general rise of neural network-based algorithms. Besides
    allowing us to compact sparse representations, they can also be at the base of
    generative models, representing the first inception of the famous **Generative
    Adversarial Network** (**GAN**), which is, using the words of Geoffrey Hinton:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器是一种极其强大的工具，可以有效帮助数据科学家处理高维数据集。尽管它最初是在大约 30 年前提出的，但在最近几年，随着基于神经网络的算法的普遍兴起，自动编码器变得越来越普及。除了允许我们进行紧凑的稀疏表示外，它们还可以作为生成模型的基础，代表着著名的**生成对抗网络**（**GAN**）的首次出现，正如杰弗里·辛顿所说：
- en: '*"The most interesting idea in the last 10 years in machine learning"*'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*"过去 10 年中最有趣的机器学习思想"*'
- en: An autoencoder is a neural network where the inputs and outputs are basically
    the same, but that is characterized by a small number of units in the hidden layer.
    Loosely speaking, it is a neural network that is trained to reconstruct its inputs
    using a significantly lower number of variables and/or degree of freedom.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器是一种神经网络，其中输入和输出基本上是相同的，但特征在于隐藏层中的单元数量很少。简单来说，它是一种经过训练以使用显著较少的变量和/或自由度来重建其输入的神经网络。
- en: 'Since an autoencoder does not need a labeled dataset, it can be seen as an
    example of unsupervised learning and a dimensionality-reduction technique. However,
    different from other techniques such as **Principal Component Analysis** (**PCA**)
    and matrix factorization, autoencoders can learn non-linear transformation thanks
    to the non-linear activation functions of their neurons:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 由于自动编码器不需要标记的数据集，它可以被视为无监督学习的一个例子和降维技术。然而，与**主成分分析**（**PCA**）和矩阵分解等其他技术不同，自动编码器可以通过其神经元的非线性激活函数学习非线性变换：
- en: '![Figure 3.14 – Diagram of the autoencoder structure. The colors in the input
    and output layers represent the fact that the values should be as similar as possible.
    In fact, the training of the network is done in order to match these values and
    minimize the reconstruction error ](img/B16069_03_14.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图3.14 – 自动编码器结构图。输入层和输出层中的颜色表示值应该尽可能相似。实际上，网络的训练是为了匹配这些值并最小化重建误差](img/B16069_03_14.jpg)'
- en: Figure 3.14 – Diagram of the autoencoder structure. The colors in the input
    and output layers represent the fact that the values should be as similar as possible.
    In fact, the training of the network is done in order to match these values and
    minimize the reconstruction error
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 – 自动编码器结构图。输入层和输出层中的颜色表示值应该尽可能相似。实际上，网络的训练是为了匹配这些值并最小化重建误差
- en: '*Figure 3.14* shows a simple example of an autoencoder. You can see how the
    autoencoder can generally be seen as composed of two parts:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.14*展示了自动编码器的一个简单示例。您可以看到自动编码器通常可以看作由两部分组成：'
- en: An encoder network that processes the input through one or more units and maps
    it into an encoded representation that reduces the dimension of the inputs (under-complete
    autoencoders) and/or constrains its sparsity (over-complete regularized autoencoders)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个编码器网络，它通过一个或多个单元处理输入，并将其映射到一个编码表示，该表示减少了输入的维度（欠完备自动编码器）和/或约束其稀疏性（过完备正则化自动编码器）
- en: A decoder network that reconstructs the input signal from the encoded representation
    of the middle layer
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个解码器网络，它从中间层的编码表示中重建输入信号
- en: The encoder-decoder structure is then trained to minimize the ability of the
    full network to reconstruct the input. In order to completely specify an autoencoder,
    we need a loss function. The error between the inputs and the outputs can be computed
    using different metrics and indeed the choice of the correct form for the "reconstruction"
    error is a critical point when building an autoencoder.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 然后训练编码器-解码器结构以最小化整个网络重建输入的能力。为了完全指定一个自动编码器，我们需要一个损失函数。输入和输出之间的误差可以使用不同的度量标准来计算，并且确实，选择“重建”误差的正确形式是构建自动编码器时的一个关键点。
- en: Some common choices for the loss functions that measure the reconstruction error
    are **mean square error**, **mean absolute error**, **cross-entropy**, and **KL
    divergence**.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 用于衡量重建误差的一些常见损失函数选择是**均方误差**、**平均绝对误差**、**交叉熵**和**KL散度**。
- en: 'In the following sections, we will show you how to build an autoencoder starting
    with some basic concepts and then applying those concepts to graph structures.
    But before diving in, we feel compelled to give you a very brief introduction
    to the frameworks that will allow us to do this: TensorFlow and Keras.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将向您展示如何从一些基本概念开始构建自动编码器，然后将这些概念应用于图结构。但在深入之前，我们感到有必要给您一个非常简短的介绍，这些框架将使我们能够做到这一点：TensorFlow和Keras。
- en: TensorFlow and Keras – a powerful combination
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow和Keras – 强力组合
- en: Released as open source by Google in 2017, TensorFlow is now the standard, de
    facto framework that allows symbolic computations and differential programming.
    It basically allows you to build a symbolic structure that describes how inputs
    are combined in order to produce the outputs, defining what is generally called
    a **computational graph** or a **stateful dataflow graph**. In this graph, nodes
    are the variable (scalar, arrays, tensors) and edges represent operations connecting
    the inputs (edge source) to the output (edge target) of a single operation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Google于2017年开源的TensorFlow现在已成为标准、事实上的框架，允许符号计算和微分编程。它基本上允许您构建一个符号结构，描述输入如何组合以产生输出，定义通常称为**计算图**或**有状态数据流图**的内容。在这个图中，节点是变量（标量、数组、张量），边代表连接输入（边源）到单个操作的输出（边目标）的操作。
- en: 'In TensorFlow, such a graph is static (this is indeed one of the main differences
    with respect to another very popular framework in this context: `torch`) and can
    be executed by feeding data into it, as inputs, clearing the "dataflow" attribute
    mentioned previously.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中，这样的图是静态的（这确实是与这个环境中另一个非常流行的框架相比的一个主要区别：`torch`），可以通过向其中输入数据作为输入，清除之前提到的“数据流”属性来执行。
- en: 'By abstracting the computation, TensorFlow is a very general tool that can
    run on multiple backends: on machines powered by CPUs, GPUs, or even ad hoc, specifically
    designed processing units such as TPUs. Besides, TensorFlow-powered applications
    can also be deployed on different devices, ranging from single and distributed
    servers to mobile devices.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通过抽象计算，TensorFlow是一个非常通用的工具，可以在多个后端上运行：在由CPU、GPU或甚至专门设计的处理单元（如TPU）驱动的机器上。此外，由TensorFlow驱动的应用程序也可以部署在不同的设备上，从单机和分布式服务器到移动设备。
- en: Besides abstracting computation, TensorFlow also allows you to symbolically
    differentiate your computational graph with respect to any of its variables, resulting
    in a new computational graph that can also be differentiated to produce higher-order
    derivatives. This approach is generally referred to as symbol-to-symbol derivative
    and it is indeed extremely powerful, especially in the context of the optimization
    of the generic loss function, which requires gradient estimations (such as gradient
    descent techniques).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 除了抽象计算之外，TensorFlow还允许你针对其任何变量符号化地微分你的计算图，从而生成一个新的计算图，该图也可以微分以产生高阶导数。这种方法通常被称为符号到符号的导数，它确实非常强大，尤其是在通用损失函数优化的背景下，这需要梯度估计（例如梯度下降技术）。
- en: As you might know, the problem of optimizing a loss function with respect to
    many parameters is central in the training of any neural network via backpropagation.
    This is surely the main reason why TensorFlow has become very popular in the past
    few years and why it was designed and produced in the first place by Google.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，相对于许多参数优化损失函数的问题，是任何神经网络通过反向传播训练的核心。这无疑是TensorFlow在过去几年中变得非常流行的主要原因，也是它最初由谷歌设计和生产的原因。
- en: Diving in depth into the usage of TensorFlow is beyond the scope of this book
    and indeed you can find out more through the description given in dedicated books.
    In the following sections, we will use some of its main functionalities and provide
    you with the basic tools for building neural networks.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 深入探讨TensorFlow的使用超出了本书的范围，实际上你可以通过在专门的书籍中的描述了解更多信息。在接下来的章节中，我们将使用其一些主要功能，并为你提供构建神经网络的基本工具。
- en: 'Since its last major release, 2.x, the standard way of building a model with
    TensorFlow is using the Keras API. Keras was natively a side external project
    with respect to TensorFlow, aimed at providing a common and simple API to use
    several differential programming frameworks, such as TensorFlow, Teano, and CNTK,
    for implementing a neural network model. It generally abstracts the low-level
    implementation of the computation graph and provides you with the most common
    layers used when building neural networks (although custom layers can also be
    easily implemented), such as the following:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 自从其上一个主要版本2.x以来，使用TensorFlow构建模型的标准方式是使用Keras API。Keras最初是TensorFlow的一个外部项目，旨在提供一个通用且简单的API来使用几个微分编程框架，例如TensorFlow、Teano和CNTK，以实现神经网络模型。它通常抽象了计算图的底层实现，并为你提供了构建神经网络时最常用的层（尽管也可以轻松实现自定义层），如下所示：
- en: Convolutional layers
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层
- en: Recurrent layers
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环层
- en: Regularization layers
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化层
- en: Loss functions
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失函数
- en: Keras also exposes APIs that are very similar to scikit-learn, the most popular
    library for machine learning in the Python ecosystem, making it very easy for
    data scientists to build, train, and integrate neural network-based models in
    their applications.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Keras还公开了与scikit-learn非常相似的API，scikit-learn是Python生态系统中最受欢迎的机器学习库，这使得数据科学家在他们的应用程序中构建、训练和集成基于神经网络的模型变得非常容易。
- en: In the next section, we will show you how to build and train an autoencoder
    using Keras. We'll start applying these techniques to images in order to progressively
    apply the key concepts to graph structures.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将向您展示如何使用Keras构建和训练自动编码器。我们将开始将这些技术应用于图像，以便逐步将关键概念应用于图结构。
- en: Our first autoencoder
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的第一种自动编码器
- en: We'll start by implementing an autoencoder in its simplest form, that is, a
    simple feed-forward network trained to reconstruct its input. We'll apply this
    to the Fashion-MNIST dataset, which is a dataset similar to the famous MNIST dataset
    that features hand-written numbers on a black and white image.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从实现最简单的自动编码器开始，即一个简单的前馈网络，该网络被训练以重建其输入。我们将将其应用于Fashion-MNIST数据集，这是一个类似于著名MNIST数据集的数据集，它包含黑白图像上的手写数字。
- en: MNIST has 10 categories and consists of 60k + 10k (train dataset + test dataset)
    28x28 pixel grayscale images that represent a piece of clothing (`T-shirt`, `Trouser`,
    `Pullover`, `Dress`, `Coat`, `Sandal`, `Shirt`, `Sneaker`, `Bag`, and `Ankle boot`).
    The Fashion-MNIST dataset is a harder task than the original MNIST dataset and
    it is generally used for benchmarking algorithms.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 有 10 个类别，由 60k + 10k（训练数据集 + 测试数据集）28x28 像素的灰度图像组成，代表一件服装（`T-shirt`、`Trouser`、`Pullover`、`Dress`、`Coat`、`Sandal`、`Shirt`、`Sneaker`、`Bag`
    和 `Ankle boot`）。Fashion-MNIST 数据集比原始 MNIST 数据集更具挑战性，通常用于算法的基准测试。
- en: 'The dataset is already integrated in the Keras library and can be easily imported
    using the following code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集已经集成在 Keras 库中，可以使用以下代码轻松导入：
- en: '[PRE8]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'It is usually good practice to rescale the inputs with an order of magnitude
    of around 1 (for which activation functions are most efficient) and make sure
    that the numerical data is in single-precision (32 bits) instead of double-precision
    (64 bits). This is due to the fact that it is generally desirable to promote speed
    rather than precision when training a neural network, which is a computationally
    expensive process. In certain cases, the precision could even be lowered to half-precision
    (16 bits). We transform the input with the following:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，将输入按数量级约 1（对于激活函数来说效率最高）进行缩放，并确保数值数据以单精度（32 位）而不是双精度（64 位）的形式存在。这是因为当训练神经网络时，通常更希望提高速度而不是精度，这是一个计算密集型的过程。在某些情况下，精度甚至可以降低到半精度（16
    位）。我们使用以下方式转换输入：
- en: '[PRE9]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can grasp the type of inputs we are dealing with by plotting some of the
    samples from the training set using the following code:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用以下代码绘制训练集中的某些样本来了解我们正在处理哪种类型的输入：
- en: '[PRE10]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the preceding code, `classes` represents the mapping between integers and
    class names, for example, `T-shirt`, `Trouser`, `Pullover`, `Dress`, `Coat`, `Sandal`,
    `Shirt`, `Sneaker`, `Bag`, and `Ankle boot`:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`classes` 表示整数和类名之间的映射，例如，`T-shirt`、`Trouser`、`Pullover`、`Dress`、`Coat`、`Sandal`、`Shirt`、`Sneaker`、`Bag`
    和 `Ankle boot`：
- en: '![Figure 3.15 – Some samples taken from the training set of the Fashion-MNIST
    dataset](img/B16069_03_15.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.15 – 从 Fashion-MNIST 数据集的训练集中取出的某些样本](img/B16069_03_15.jpg)'
- en: Figure 3.15 – Some samples taken from the training set of the Fashion-MNIST
    dataset
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.15 – 从 Fashion-MNIST 数据集的训练集中取出的某些样本
- en: 'Now that we have imported the inputs, we can build our autoencoder network
    by creating the encoder and the decoder. We will be doing this using the Keras
    functional API, which provides more generality and flexibility compared to the
    so-called Sequential API. We start by defining the encoder network:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经导入了输入，我们可以通过创建编码器和解码器来构建我们的自动编码器网络。我们将使用 Keras 功能 API 来完成这项工作，与所谓的顺序 API
    相比，它提供了更多的通用性和灵活性。我们首先定义编码器网络：
- en: '[PRE11]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Our network is composed of a stack of three levels of the same pattern composed
    of the same two-layer building block:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网络由三个相同模式的堆叠组成，每个模式由相同的两层构建块组成：
- en: '`Conv2D`, a two-dimensional convolutional kernel that is applied to the input
    and effectively corresponds to having weights shared across all the input neurons.
    After applying the convolutional kernel, the output is transformed using the ReLU
    activation function. This structure is replicated for *n* hidden planes, with
    *n* being 16 in the first stacked layer and 8 in the second and third stacked
    layers.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Conv2D` 是一个二维卷积核，应用于输入，并且实际上对应于在整个输入神经元之间共享权重。在应用卷积核后，使用 ReLU 激活函数转换输出。这种结构在
    *n* 个隐藏平面中重复，其中 *n* 在第一个堆叠层中为 16，在第二个和第三个堆叠层中为 8。'
- en: '`MaxPooling2D`, which down-samples the inputs by taking the maximum value over
    the specified window (2x2 in this case).'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MaxPooling2D` 通过在指定的窗口（在这种情况下为 2x2）上取最大值来对输入进行下采样。'
- en: 'Using the Keras API, we can also have an overview of how the layers transformed
    the inputs using the `Model` class, which converts the tensors into a user-friendly
    model ready to be used and explored:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Keras API，我们还可以使用 `Model` 类来概述层如何转换输入，该类将张量转换为用户友好的模型，以便使用和探索：
- en: '[PRE12]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This provides a summary of the encoder network visible in *Figure 3.16*:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了 *图 3.16* 中可见的编码器网络的概览：
- en: '![Figure 3.16 – Overview of the encoder network'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.16 – 编码器网络概览'
- en: '](img/B16069_03_16.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16069_03_16.jpg)'
- en: Figure 3.16 – Overview of the encoder network
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.16 – 编码器网络概览
- en: 'As can be seen, at the end of the encoding phase, we have a (4, 4, 8) tensor,
    which is more than six times smaller than our original initial inputs (28x28).
    We can now build the decoder network. Note that the encoder and decoder do not
    need to have the same structure and/or shared weights:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如所示，在编码阶段结束时，我们得到了一个(4, 4, 8)的张量，这比我们原始的初始输入(28x28)小六倍以上。我们现在可以构建解码器网络。请注意，编码器和解码器不需要具有相同的结构以及/或共享权重：
- en: '[PRE13]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this case, the decoder network resembles the encoder structure where the
    down-sampling of the input achieved using the `MaxPooling2D` layer has been replaced
    by the `UpSampling2D` layer, which basically repeats the input over a specified
    window (2x2 in this case, effectively doubling the tensor in each direction).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，解码器网络类似于编码器结构，其中使用`MaxPooling2D`层实现的输入下采样已被`UpSampling2D`层替换，该层基本上在指定的窗口（在这种情况下为2x2）上重复输入，从而在每个方向上有效地将张量加倍。
- en: 'We have now fully defined the network structure with the encoder and decoder
    layers. In order to completely specify our autoencoder, we also need to specify
    a loss function. Moreover, to build the computational graph, Keras also needs
    to know which algorithms should be used in order to optimize the network weights.
    Both bits of information, the loss function and optimizer to be used, are generally
    provided to Keras when *compiling* the model:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完全定义了网络结构，包括编码器和解码器层。为了完全指定我们的自动编码器，我们还需要指定一个损失函数。此外，为了构建计算图，Keras还需要知道应该使用哪些算法来优化网络权重。这两项信息，即损失函数和要使用的优化器，通常在*编译*模型时提供给Keras：
- en: '[PRE14]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can now finally train our autoencoder. Keras `Model` classes provide APIs
    that are similar to scikit-learn, with a `fit` method to be used to train the
    neural network. Note that, owing to the nature of the autoencoder, we are using
    the same information as the input and output of our network:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以最终训练我们的自动编码器。Keras `Model`类提供了与scikit-learn类似的API，使用`fit`方法来训练神经网络。请注意，由于自动编码器的性质，我们正在使用与网络输入和输出相同的信息：
- en: '[PRE15]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Once the training is finished, we can examine the ability of the network to
    reconstruct the inputs by comparing input images with their reconstructed version,
    which can be easily computed using the `predict` method of the Keras `Model` class
    as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，我们可以通过比较输入图像与其重建版本来检验网络重建输入的能力。这可以通过使用Keras `Model`类的`predict`方法轻松计算，如下所示：
- en: '[PRE16]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In *Figure 3.17*, we show the reconstructed images. As you can see, the network
    is quite good at reconstructing unseen images, especially when considering the
    large-scale features. Details might have been lost in the compression (see, for
    instance, the logo on the t-shirts) but the overall relevant information has indeed
    been captured by our network:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3.17*中，我们展示了重建的图像。如您所见，网络在重建未见过的图像方面相当出色，尤其是在考虑大规模特征时。在压缩过程中可能会丢失细节（例如，T恤上的标志），但网络确实捕捉到了整体的相关信息：
- en: '![Figure 3.17 – Examples of the reconstruction done on the test set by the
    trained autoencoder'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.17 – 训练的自动编码器在测试集上完成的重建示例'
- en: '](img/B16069_03_17.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16069_03_17.jpg](img/B16069_03_17.jpg)'
- en: Figure 3.17 – Examples of the reconstruction done on the test set by the trained
    autoencoder
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 3.17 – 训练的自动编码器在测试集上完成的重建示例
- en: 'It can also be very interesting to represent the encoded version of the images
    in a two-dimensional plane using T-SNE:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 使用T-SNE在二维平面上表示图像的编码版本也非常有趣：
- en: '[PRE17]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The coordinates provided by T-SNE are shown in *Figure 3.18*, colored by the
    class the sample belongs to. The clustering of the different clothing can clearly
    be seen, particularly for some classes that are very well separated from the rest:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: T-SNE提供的坐标显示在*图3.18*中，根据样本所属的类别进行着色。不同服装的聚类可以清楚地看到，尤其是对于一些与其他类别非常分离的类别：
- en: '![Figure 3.18 – T-SNE transformation of the embeddings extracted from the test
    set, colored by the class that the sample belongs to](img/B16069_03_18.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.18 – 从测试集中提取的嵌入的T-SNE转换，根据样本所属的类别着色](img/B16069_03_18.jpg)'
- en: Figure 3.18 – T-SNE transformation of the embeddings extracted from the test
    set, colored by the class that the sample belongs to
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 – 从测试集中提取的嵌入的T-SNE转换，根据样本所属的类别着色
- en: Autoencoders are, however, rather prone to overfitting, as they tend to re-create
    exactly the images of the training and not generalize well. In the following subsection,
    we will see how overfitting can be prevented in order to build more robust and
    reliable dense representations.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，自动编码器很容易过拟合，因为它们倾向于精确地重新创建训练图像，而不是很好地泛化。在下一小节中，我们将看到如何防止过拟合，以构建更稳健和可靠的密集表示。
- en: Denoising autoencoders
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 去噪自动编码器
- en: Besides allowing us to compress a sparse representation into a denser vector,
    autoencoders are also widely used to process a signal in order to filter out noise
    and extract only a relevant (characteristic) signal. This can be very useful in
    many applications, especially when identifying anomalies and outliers.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 除了允许我们将稀疏表示压缩到更密集的向量中，自动编码器还被广泛用于处理信号，以过滤噪声并提取仅相关的（特征）信号。这在许多应用中非常有用，尤其是在识别异常值和离群值时。
- en: 'Denoising autoencoders are a small variation of what has been implemented.
    As described in the previous section, basic autoencoders are trained using the
    same image as input and output. Denoising autoencoders corrupt the input using
    some noise of various intensity, while keeping the same noise-free target. This
    could be achieved by simply adding some Gaussian noise to the inputs:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪自动编码器是对之前实现的小幅修改。如前所述，基本自动编码器使用相同的图像作为输入和输出进行训练。去噪自动编码器使用各种强度的噪声来损坏输入，同时保持相同的无噪声目标。这可以通过简单地向输入添加一些高斯噪声来实现：
- en: '[PRE18]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The network can then be trained using the corrupted input, while for the output
    the noise-free image is used:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 网络可以使用损坏的输入进行训练，而对于输出，则使用无噪声图像：
- en: '[PRE19]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Such an approach is generally valid when datasets are large and when the risk
    of overfitting the noise is rather limited. When datasets are smaller, an alternative
    to avoid the network "learning" the noise as well (thus learning the mapping between
    a static noisy image to its noise-free version) is to add training stochastic
    noise using a `GaussianNoise` layer.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集较大且过拟合噪声的风险相对较小时，这种方法通常是有效的。当数据集较小时，为了避免网络“学习”噪声（从而学习从静态噪声图像到其无噪声版本的映射），可以通过添加一个
    `GaussianNoise` 层来使用训练随机噪声作为替代。
- en: 'Note that in this way, the noise may change between epochs and prevent the
    network from learning a static corruption superimposed to our training set. In
    order to do so, we change the first layers of our network in the following way:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这样，噪声可能在各个时期之间变化，从而防止网络学习叠加到我们的训练集上的静态损坏。为了做到这一点，我们以下列方式更改我们网络的顶层：
- en: '[PRE20]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The difference is that instead of having statically corrupted samples (that
    do not change in time), the noisy inputs now keep changing between epochs, thus
    avoiding the network learning the noise as well.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 差别在于，不是静态损坏的样本（随时间不变），噪声输入现在在各个时期之间不断变化，从而避免网络学习噪声。
- en: The `GaussianNoise` layer is an example of a regularization layer, that is,
    a layer that helps reduce overfitting of a neural network by inserting a random
    part in the network. `GaussianNoise` layers make models more robust and able to
    generalize better, avoiding autoencoders learning the identity function.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`GaussianNoise` 层是正则化层的一个例子，即一个通过在网络中插入随机部分来帮助减少神经网络过拟合的层。`GaussianNoise` 层使模型更稳健，能够更好地泛化，避免自动编码器学习恒等函数。'
- en: Another common example of a regularization layer is the dropout layers that
    effectively set to 0 some of the inputs (at random with a probability, ![](img/B16069_03_087.png))
    and rescale the other inputs by a ![](img/B16069_03_088.png) factor in order to
    (statistically) keep the sum over all the units constant, with and without dropout.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的正则化层示例是 dropout 层，它有效地将某些输入（以概率随机）设置为 0，并通过一个 ![](img/B16069_03_088.png)
    因子重新缩放其他输入，以（统计上）保持所有单元的总和恒定，无论是带有还是不带 dropout。
- en: Dropout corresponds to randomly killing some of the connections between layers
    in order to reduce output dependence to specific neurons. You need to keep in
    mind that regularization layers are only active at training, while at test time
    they simply correspond to identity layers.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout 对应于随机杀死层之间的一些连接，以减少输出对特定神经元的依赖。你需要记住，正则化层仅在训练时活跃，而在测试时它们仅仅对应于恒等层。
- en: 'In *Figure 3.19*, we compare the network reconstruction of a noisy input (input)
    for the previous unregularized trained network and the network with a `GaussianNoise`
    layer. As can be seen (compare, for instance, the images of trousers), the model
    with regularization tends to develop stronger robustness and reconstructs the
    noise-free outputs:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3.19*中，我们比较了先前未正则化训练的网络和具有`GaussianNoise`层的网络的噪声输入（输入）的网络重建。如图所示（例如，比较裤子图像），具有正则化的模型倾向于发展更强的鲁棒性，并重建无噪声的输出：
- en: '![Figure 3.19 – Comparison with reconstruction for noisy samples. Top row:
    noisy input; middle row: reconstructed output using a vanilla autoencoder; bottom
    row: reconstructed output using a denoising autoencoder](img/B16069_03_19.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图3.19 – 与噪声样本重建的比较。第一行：噪声输入；第二行：使用普通自编码器重建的输出；第三行：使用降噪自编码器重建的输出](img/B16069_03_19.jpg)'
- en: 'Figure 3.19 – Comparison with reconstruction for noisy samples. Top row: noisy
    input; middle row: reconstructed output using a vanilla autoencoder; bottom row:
    reconstructed output using a denoising autoencoder'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19 – 与噪声样本重建的比较。第一行：噪声输入；第二行：使用普通自编码器重建的输出；第三行：使用降噪自编码器重建的输出
- en: Regularization layers are often used when dealing with deep neural networks
    that tend to overfit and are able to learn identity functions for autoencoders.
    Often, dropout or `GaussianNoise` layers are introduced, repeating a similar pattern
    composed of regularization and learnable layers that we usually refer to as **stacked
    denoising layers**.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理容易过拟合的深度神经网络，并且能够为自编码器学习身份函数时，通常会使用正则化层。通常，会引入dropout或`GaussianNoise`层，重复一个由正则化和可学习层组成的类似模式，我们通常将其称为**堆叠降噪层**。
- en: Graph autoencoders
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图自编码器
- en: Once the basic concepts of autoencoders are understood, we can now turn to apply
    this framework to graph structures. If on one hand the network structure, decomposed
    into an encoder-decoder structure with a low-dimensional representation in between,
    still applies, the definition of the loss function to be optimized needs a bit
    of caution when dealing with networks. First, we need to adapt the reconstruction
    error to a meaningful formulation that can adapt to the peculiarities of graph
    structures. But to do so, let's first introduce the concepts of first- and higher-order
    proximity.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦理解了自编码器的基本概念，我们现在可以转向将这个框架应用于图结构。一方面，网络结构，分解为一个编码器-解码器结构，其中间有一个低维表示，仍然适用，但在处理网络时，需要优化损失函数的定义时需要小心。首先，我们需要将重建误差适应到一个有意义的公式，使其能够适应图结构的特殊性。但要做到这一点，让我们首先介绍一阶和更高阶邻近度的概念。
- en: 'When applying autoencoders to graph structures, the input and output of the
    network should be a graph representation, as, for instance, the adjacency matrix.
    The reconstruction loss could then be defined as the Frobenius norm of the difference
    between the input and output matrices. However, when applying autoencoders to
    such graph structures and adjacency matrices, two critical issues arise:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 当将自编码器应用于图结构时，网络的输入和输出应该是一个图表示，例如邻接矩阵。然后，重建损失可以定义为输入和输出矩阵之间的Frobenius范数的差。然而，当将自编码器应用于此类图结构和邻接矩阵时，会出现两个关键问题：
- en: Whereas the presence of links indicates a relation or similarity between two
    vertices, their absence does not generally indicate a dissimilarity between vertices.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然链接的存在表明两个顶点之间存在关系或相似性，但它们的缺失通常并不表明顶点之间存在不相似性。
- en: The adjacency matrix is extremely sparse and therefore the model will naturally
    tend to predict a 0 rather than a positive value.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邻接矩阵非常稀疏，因此模型自然会倾向于预测0而不是正值。
- en: 'To address such peculiarities of graph structures, when defining the reconstruction
    loss, we need to penalize more errors done for the non-zero elements rather than
    that for zero elements. This can be done using the following loss function:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决图结构的这种特殊性，在定义重建损失时，我们需要对非零元素所做的错误进行惩罚，而不是对零元素进行惩罚。这可以通过以下损失函数来实现：
- en: '![](img/B16069_03_089.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16069_03_089.jpg)'
- en: Here, ![](img/B16069_03_090.png) is the Hadamard element-wise product, where
    ![](img/B16069_03_091.png) if there is an edge between nodes ![](img/B16069_03_092.png)
    and ![](img/B16069_03_093.png), and 0 otherwise. The preceding loss guarantees
    that vertices that share a neighborhood (that is, their adjacency vectors are
    similar) will also be close in the embedding space. Thus, the preceding formulation
    will naturally preserve second-order proximity for the reconstructed graph.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![哈达玛逐元素乘积](img/B16069_03_090.png)是哈达玛逐元素乘积，其中![存在边](img/B16069_03_091.png)如果节点![节点1](img/B16069_03_092.png)和![节点2](img/B16069_03_093.png)之间存在边，否则为0。前面的损失保证了共享邻域（即它们的邻接向量相似）的顶点在嵌入空间中也会很接近。因此，前面的公式将自然地保留重建图的二阶邻近性。
- en: 'On the other hand, you can also promote first-order proximity in the reconstructed
    graph, thus enforcing connected nodes to be close in the embedding space. This
    condition can be enforced by using the following loss:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，你还可以在重建图中促进第一阶邻近性，从而强制连接的节点在嵌入空间中靠近。可以通过以下损失来实现这一条件：
- en: '![](img/B16069_03_094.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![损失函数](img/B16069_03_094.jpg)'
- en: 'Here, ![](img/B16069_03_095.png) and ![](img/B16069_03_096.png) are the two
    representation of nodes ![](img/B16069_03_097.png) and ![](img/B16069_03_098.png)
    in the embedding space. This loss function forces neighboring nodes to be close
    in the embedding space. In fact, if two nodes are tightly connected, ![](img/B16069_03_099.png)
    will be large. As a consequence, their difference in the embedding space, ![](img/B16069_03_100.png),
    should be limited (indicating the two nodes are close in the embedding space)
    to keep the loss function small. The two losses can also be combined into a single
    loss function, where, in order to prevent overfitting, a regularization loss can
    be added that is proportional to the norm of the weight coefficients:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![节点表示1](img/B16069_03_095.png)和![节点表示2](img/B16069_03_096.png)是嵌入空间中![节点1](img/B16069_03_097.png)和![节点2](img/B16069_03_098.png)的两个表示。这个损失函数强制相邻节点在嵌入空间中靠近。实际上，如果两个节点紧密连接，![连接强度](img/B16069_03_099.png)将很大。因此，它们在嵌入空间中的差异![差异值](img/B16069_03_100.png)，应该受到限制（表示两个节点在嵌入空间中靠近），以保持损失函数较小。这两个损失也可以组合成一个单一的损失函数，其中，为了防止过拟合，可以添加一个正比于权重系数范数的正则化损失：
- en: '![](img/B16069_03_101.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B16069_03_101.jpg)'
- en: In the preceding equation, *W* represents all the weights used across the network.
    The preceding formulation was proposed in 2016 by Wang et al., and it is now known
    as **Structural Deep Network Embedding** (**SDNE**).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，*W*代表网络中使用的所有权重。前面的公式由Wang等人于2016年提出，现在被称为**结构深度网络嵌入**（**SDNE**）。
- en: 'Although the preceding loss could also be directly implemented with TensorFlow
    and Keras, you can already find this network integrated in the GEM package we
    referred to previously. As before, extracting the node embedding can be done similarly
    in a few lines of code, as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的损失也可以直接使用TensorFlow和Keras实现，但你已经可以在我们之前提到的GEM包中找到这个网络集成。和之前一样，提取节点嵌入可以通过几行代码完成，如下所示：
- en: '[PRE21]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Although very powerful, these graph autoencoders encounter some issues when
    dealing with large graphs. For these cases, the input of our autoencoder is one
    row of the adjacency matrix that has as many elements as the nodes in the network.
    In large networks, this size can easily be of the order of millions or tens of
    millions.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管非常强大，但这些图自动编码器在处理大型图时遇到一些问题。对于这些情况，我们的自动编码器的输入是邻接矩阵的一行，其元素数量与网络中的节点数量相同。在大网络中，这个大小可以很容易地达到数百万或数千万。
- en: In the next section, we describe a different strategy for encoding the network
    information that in some cases may iteratively aggregate embeddings only over
    local neighborhoods, making it scalable to large graphs.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们描述了一种不同的编码网络信息策略，在某些情况下，它可能仅迭代地聚合局部邻域的嵌入，使其可扩展到大型图。
- en: Graph neural networks
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图神经网络
- en: '**GNNs** are deep learning methods that work on graph-structured data. This
    family of methods is also known as **geometric deep learning** and is gaining
    increasing interest in a variety of applications, including social network analysis
    and computer graphics.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '**GNNs**是针对图结构数据工作的深度学习方法。这个方法族也被称为**几何深度学习**，在包括社交网络分析和计算机图形学在内的各种应用中越来越受到关注。'
- en: According to the taxonomy defined in [*Chapter 2*](B16069_02_Final_JM_ePub.xhtml#_idTextAnchor035),
    *Graph Machine Learning*, the encoder part takes as input both the graph structure
    and the node features. Those algorithms can be trained either with or without
    supervision. In this chapter, we will focus on unsupervised training, while the
    supervised setting will be explored in [*Chapter 4*](B16069_04_Final_JM_ePub.xhtml#_idTextAnchor064),
    *Supervised Graph Learning*.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 根据在[*第2章*](B16069_02_Final_JM_ePub.xhtml#_idTextAnchor035)中定义的分类法，*图机器学习*，编码器部分将图结构和节点特征作为输入。这些算法可以带监督或不带监督地进行训练。在本章中，我们将关注无监督训练，而监督设置将在[*第4章*](B16069_04_Final_JM_ePub.xhtml#_idTextAnchor064)的*监督图学习*中探讨。
- en: If you are familiar with the concept of a **Convolutional Neural Network** (**CNN**),
    you might already know that they are able to achieve impressive results when dealing
    with regular Euclidean spaces, such as text (one-dimensional), images (two-dimensional),
    and videos (three-dimensional). A classic CNN consists of a sequence of layers
    and each layer extracts multi-scale localized spatial features. Those features
    are exploited by deeper layers to construct more complex and highly expressive
    representations.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉**卷积神经网络**（**CNN**）的概念，你可能已经知道，当处理规则欧几里得空间（如文本（一维）、图像（二维）和视频（三维））时，它们能够取得令人印象深刻的成果。一个经典的CNN由一系列层组成，每一层提取多尺度局部化的空间特征。这些特征被深层层利用，以构建更复杂和高度表达性的表示。
- en: 'In recent years, it has been observed that concepts such as multi-layer and
    locality are also useful for processing graph-structured data. However, graphs
    are defined over a *non-Euclidean space*, and finding a generalization of a CNN
    for graphs is not straightforward, as described in *Figure 3.20*:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，观察到多层和局部性等概念也适用于处理图结构数据。然而，图是在一个*非欧几里得空间*上定义的，正如*图3.20*中所述，找到一个适用于图的CNN泛化并不简单：
- en: '![Figure 3.20 – Visual difference between Euclidean and non-Euclidean neighborhoods'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.20 – 欧几里得和非欧几里得邻域之间的视觉差异'
- en: '](img/B16069_03_20.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16069_03_20.jpg)'
- en: Figure 3.20 – Visual difference between Euclidean and non-Euclidean neighborhoods
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.20 – 欧几里得和非欧几里得邻域之间的视觉差异
- en: The original formulation of GNN was proposed by Scarselli et al. back in 2009\.
    It relies on the fact that each node can be described by its features and its
    neighborhood. Information coming from the neighborhood (which represents the concept
    of locality in the graph domain) can be aggregated and used to compute more complex
    and high-level features. Let's understand in more detail how it can be done.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: GNN的原始公式由Scarselli等人于2009年提出。它依赖于每个节点可以通过其特征和其邻域来描述的事实。来自邻域的信息（在图域中代表局部性概念）可以被聚合并用于计算更复杂和高级的特征。让我们更详细地了解它是如何实现的。
- en: 'At the beginning, each node, ![](img/B16069_03_102.png), is associated with
    a state. Let''s start with a random embedding, ![](img/B16069_03_103.png) (ignoring
    node attributes for simplicity). At each iteration of the algorithm, nodes accumulate
    input from their neighbors using a simple neural network layer:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始时，每个节点，![](img/B16069_03_102.png)，都与一个状态相关联。让我们从一个随机的嵌入开始，![](img/B16069_03_103.png)（为了简单起见，忽略节点属性）。在算法的每次迭代中，节点通过一个简单的神经网络层从其邻居那里积累输入：
- en: '![](img/B16069_03_104.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16069_03_104.jpg)'
- en: Here, ![](img/B16069_03_105.png) and ![](img/B16069_03_106.png) are trainable
    parameters (where *d* is the dimension of the embedding), ![](img/B16069_03_107.png)
    is a non-linear function, and *t* represents the *t*th iteration of the algorithm.
    The equation is applied recursively until a particular objective is reached. Notice
    that, at each iteration, the *previous state* (the state computed at the previous
    iteration) is exploited in order to compute that the new state has happened with
    *recurrent neural networks*.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B16069_03_105.png)和![](img/B16069_03_106.png)是可训练的参数（其中*d*是嵌入的维度），![](img/B16069_03_107.png)是一个非线性函数，*t*代表算法的第*t*次迭代。该方程递归应用，直到达到特定的目标。请注意，在每次迭代中，*前一个状态*（前一次迭代计算的状态）被利用，以便通过*循环神经网络*计算新的状态是否发生。
- en: Variants of GNNs
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GNN的变体
- en: Starting from this first idea, several attempts have been made in recent years
    to re-address the problem of learning from graph data. In particular, variants
    of the previously described GNN have been proposed, with the aim of improving
    its representation learning capability. Some of them are specifically designed
    to process specific types of graphs (direct, indirect, weighted, unweighted, static,
    dynamic, and so on).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个最初的想法出发，近年来已经尝试了多种方法来重新审视从图数据中学习的问题。特别是，提出了之前描述的GNN的变体，目的是提高其表示学习能力。其中一些是专门设计来处理特定类型的图（直接、间接、加权、无权、静态、动态等）。
- en: Also, several modifications have been proposed for the propagation step (convolution,
    gate mechanisms, attention mechanisms, and skip connections, among others), with
    the aim of improving representation at different levels. Also, different training
    methods have been proposed to improve learning.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还提出了几种对传播步骤（卷积、门机制、注意力机制和跳跃连接等）的修改，目的是在不同层次上提高表示能力。同时，还提出了不同的训练方法来提高学习效果。
- en: 'When dealing with unsupervised representation learning, one of the most common
    approaches is to use an encoder to embed the graph (the encoder is formulated
    as one of the GNN variants) and then use a simple decoder to reconstruct the adjacency
    matrix. The loss function is usually formulated as the similarity between the
    original adjacency matrix and the reconstructed one. Formally, it can be defined
    as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理无监督表示学习时，最常见的方法之一是使用编码器将图嵌入（编码器被表述为GNN的一种变体）然后使用一个简单的解码器来重建邻接矩阵。损失函数通常被表述为原始邻接矩阵与重建矩阵之间的相似度。形式上，它可以定义为以下：
- en: '![](img/B16069_03_108.jpg)![](img/B16069_03_109.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![图](img/B16069_03_108.jpg)![图](img/B16069_03_109.jpg)'
- en: Here, ![](img/B16069_03_110.png) is the adjacency matrix representation and
    ![](img/B16069_03_111.png) is the matrix of node attributes. Another common variant
    of this approach, especially used when dealing with graph classification/representation
    learning, is to train against a *target distance*. The idea is to embed two pairs
    of graphs simultaneously obtaining a combined representation. The model is then
    trained such that this representation matches the distance. A similar strategy
    can be also adopted when dealing with node classification/representation learning
    by using a node similarity function.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![图](img/B16069_03_110.png)是邻接矩阵表示，![节点属性矩阵](img/B16069_03_111.png)是节点属性矩阵。这种方法的一种常见变体，尤其是在处理图分类/表示学习时，是对**目标距离**进行训练。其思路是同时嵌入两对图以获得一个组合表示。然后，模型被训练以使这种表示与距离相匹配。在处理节点分类/表示学习时，也可以采用类似的策略，通过使用节点相似度函数。
- en: '**Graph Convolutional Neural Network** (**GCN**)-based encoders are one of
    the most diffused variants of GNN for unsupervised learning. GCNs are GNN models
    inspired by many of the basic ideas behind CNN. Filter parameters are typically
    shared over all locations in the graph and several layers are concatenated to
    form a deep network.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于图卷积神经网络**（**GCN**）的编码器是用于无监督学习中最广泛使用的GNN变体之一。GCN是受到许多CNN基本思想启发的GNN模型。滤波参数通常在图的所有位置共享，并且通过连接多层形成一个深度网络。'
- en: There are essentially two types of convolutional operations for graph data,
    namely **spectral approaches** and **non-spectral** (**spatial**) approaches.
    The first, as the name suggests, defines convolution in the spectral domain (that
    is, decomposing graphs in a combination of simpler elements). Spatial convolution
    formulates the convolution as aggregating feature information from neighbors.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图数据，本质上存在两种类型的卷积操作，即**光谱方法**和**非光谱**（**空间**）方法。第一种，正如其名所示，在频谱域中定义卷积（即将图分解为更简单的元素组合）。空间卷积将卷积表述为从邻居聚合特征信息。
- en: Spectral graph convolution
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 光谱图卷积
- en: Spectral approaches are related to spectral graph theory, the study of the characteristics
    of a graph in relation to the characteristic polynomial, eigenvalues, and eigenvectors
    of the matrices associated with the graph. The convolution operation is defined
    as the multiplication of a signal (node features) by a kernel. In more detail,
    it is defined in the Fourier domain by determining the *eigendecomposition of
    the graph Laplacian* (think about the graph Laplacian as an adjacency matrix normalized
    in a special way).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: While this definition of spectral convolution has a strong mathematical foundation,
    the operation is computationally expensive. For this reason, several works have
    been done to approximate it in an efficient way. ChebNet by Defferrard et al.,
    for instance, is one of the first seminal works on spectral graph convolution.
    Here, the operation is approximated by using the concept of the Chebyshev polynomial
    of order *K* (a special kind of polynomial used to efficiently approximate functions).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Here, *K* is a very useful parameter because it determines the locality of the
    filter. Intuitively, for *K*=1, only the node features are fed into the network.
    With *K*=2, we average over two-hop neighbors (neighbors of neighbors) and so
    on.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'Let ![](img/B16069_03_112.png) be the matrix of node features. In classical
    neural network processing, this signal would be composed of layers of the following
    form:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_03_113.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B16069_03_114.png) is the layer weights and ![](img/B16069_03_115.png)
    represents some non-linear activation function. The drawback of this operation
    is that it processes each node signal independently without taking into account
    connections between nodes. To overcome this limitation, a simple (yet effective)
    modification can be done, as follows:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_03_116.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
- en: By introducing the adjacency matrix, ![](img/B16069_03_117.png), a new linear
    combination between each node and its corresponding neighbors is added. This way,
    the information depends only on the neighborhood and parameters are applied on
    all the nodes, simultaneously.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that this operation can be repeated in sequence several times,
    thus creating a deep network. At each layer, the node descriptors, *X*, will be
    replaced with the output of the previous layer, ![](img/B16069_03_118.png).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: The preceding presented equation, however, has some limitations and cannot be
    applied as it stands. The first limitation is that by multiplying by *A*, we consider
    all the neighbors of the node but not the node itself. This problem can be easily
    overcome by adding self-loops in the graph, that is, adding the ![](img/B16069_03_119.png)
    identity matrix.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: The second limitation is related to the adjacency matrix itself. Since it is
    typically not normalized, we will observe large values in the feature representation
    of high-degree nodes and small values in the feature representation of low-degree
    nodes. This will lead to several problems during training since optimization algorithms
    are often sensitive to feature scale. Several methods have been proposed for normalizing
    *A*.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个限制与邻接矩阵本身有关。由于它通常没有归一化，我们将在高度节点的特征表示中观察到较大的值，在低度节点的特征表示中观察到较小的值。这将在训练期间导致几个问题，因为优化算法通常对特征尺度敏感。已经提出了几种用于归一化
    *A* 的方法。
- en: 'In Kipf and Welling, 2017 (one of the well-known GCN models), for example,
    the normalization is performed by multiplying *A* by the *diagonal node degree
    matrix* *D*, such that all the rows sum to 1: ![](img/B16069_03_120.png). More
    specifically, they used symmetric normalization ![](img/B16069_03_121.png), such
    that the proposed propagation rule becomes as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在 Kipf 和 Welling，2017 年（一个著名的 GCN 模型）中，归一化是通过将 *A* 乘以 *对角节点度矩阵* *D* 来实现的，使得所有行的和为
    1：![img/B16069_03_120.png](img/B16069_03_120.png)。更具体地说，他们使用了对称归一化 ![img/B16069_03_121.png](img/B16069_03_121.png)，使得提出的传播规则如下：
- en: '![](img/B16069_03_122.jpg)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![img/B16069_03_122.jpg](img/B16069_03_122.jpg)'
- en: Here, ![](img/B16069_03_123.png) is the diagonal node degree matrix of ![](img/B16069_03_124.png).
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![img/B16069_03_123.png](img/B16069_03_123.png) 是 ![img/B16069_03_124.png](img/B16069_03_124.png)
    的对角节点度矩阵。
- en: 'In the following example, we will create a GCN as defined in Kipf and Welling
    and we will apply this propagation rule for embedding a well-known network: a
    Zachary''s karate club graph:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的例子中，我们将创建一个如 Kipf 和 Welling 所定义的 GCN，并将应用此传播规则来嵌入一个著名的网络：Zachary 的空手道俱乐部图：
- en: 'To begin, it is necessary to import all the Python modules. We will use `networkx`
    to load the *barbell graph*:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，有必要导入所有 Python 模块。我们将使用 `networkx` 来加载 *barbell 图*：
- en: '[PRE22]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To implement the GC propagation rule, we need an adjacency matrix representing
    `G`. Since this network does not have node features, we will use the ![](img/B16069_03_125.png)
    identity matrix as the node descriptor:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要实现 GC 传播规则，我们需要一个表示 `G` 的邻接矩阵。由于这个网络没有节点特征，我们将使用 ![img/B16069_03_125.png](img/B16069_03_125.png)
    单位矩阵作为节点描述符：
- en: '[PRE23]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We now add the self-loop and prepare the diagonal node degree matrix:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在添加自环并准备对角节点度矩阵：
- en: '[PRE24]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Our GCN will be composed of two layers. Let''s define the layers'' weights
    and the propagation rule. Layer weights, *W*, will be initialized using *Glorot
    uniform initialization* (even if other initialization methods can be also used,
    for example, by sampling from a Gaussian or uniform distribution):'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的 GCN 将由两层组成。让我们定义层的权重和传播规则。层权重，*W*，将使用 *Glorot 均匀初始化* 来初始化（即使也可以使用其他初始化方法，例如，从高斯或均匀分布中采样）：
- en: '[PRE25]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, let''s create our network and compute the forward pass, that is, propagate
    the signal through the network:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们创建我们的网络并计算前向传递，即通过网络传播信号：
- en: '[PRE26]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`H3` now contains the embedding computed using the GCN propagation rule. Notice
    that we chose `2` as the number of outputs, meaning that the embedding is bi-dimensional
    and can be easily visualized. In *Figure 3.21*, you can see the output:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '`H3` 现在包含了使用 GCN 传播规则计算出的嵌入。注意，我们选择了 `2` 作为输出数量，这意味着嵌入是二维的，可以很容易地可视化。在 *图 3.21*
    中，你可以看到输出：'
- en: '![Figure 3.21 – Application of the graph convolutional layer to a graph (left)
    to generate the embedding vector of its nodes (right)](img/B16069_03_21.jpg)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.21 – 应用图卷积层到图（左）以生成其节点的嵌入向量（右）](img/B16069_03_21.jpg)'
- en: Figure 3.21 – Application of the graph convolutional layer to a graph (left)
    to generate the embedding vector of its nodes (right)
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.21 – 应用图卷积层到图（左）以生成其节点的嵌入向量（右）
- en: You can observe the presence of two quite well-separated communities. This is
    a nice result, considering that we have not trained the network yet!
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以观察到存在两个相当分离的社区。考虑到我们还没有训练网络，这是一个很好的结果！
- en: 'Spectral graph convolution methods have achieved noteworthy results in many
    domains. However, they present some drawbacks. Consider, for example, a very big
    graph with billions of nodes: a spectral approach requires the graph to be processed
    simultaneously, which can be impractical from a computational point of view.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 谱图卷积方法在许多领域都取得了显著成果。然而，它们也有一些缺点。例如，考虑一个非常大的图，包含数十亿个节点：谱方法需要同时处理整个图，这在计算上可能是不切实际的。
- en: Furthermore, spectral convolution often assumes a fixed graph, leading to poor
    generalization capabilities on new, different graphs. To overcome these issues,
    spatial graph convolution represents an interesting alternative.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，频谱卷积通常假设一个固定的图，导致在新、不同的图上泛化能力较差。为了克服这些问题，空间图卷积代表了一个有趣的替代方案。
- en: Spatial graph convolution
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 空间图卷积
- en: 'Spatial graph convolutional networks perform the operations directly on the
    graph by aggregating information from spatially close neighbors. Spatial convolution
    has many advantages: weights can be easily shared across a different location
    of the graph, leading to a good generalization capability on different graphs.
    Furthermore, the computation can be done by considering subsets of nodes instead
    of the entire graph, potentially improving computational efficiency.'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 空间图卷积网络通过直接在图上操作，并聚合空间上接近的邻居的信息来执行操作。空间卷积有许多优点：权重可以轻松地在图的不同位置共享，从而在不同图上具有良好的泛化能力。此外，可以通过考虑节点子集而不是整个图来进行计算，这可能会提高计算效率。
- en: 'GraphSAGE is one of the algorithms that implement spatial convolution. One
    of the main characteristics is its ability to scale over various types of networks.
    We can think of GraphSAGE as composed of three steps:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: GraphSAGE是实现空间卷积的算法之一。其主要特点之一是它能够扩展到各种类型的网络。我们可以将GraphSAGE视为由三个步骤组成：
- en: '**Neighborhood sampling**: For each node in a graph, the first step is to find
    its k-neighborhood, where *k* is defined by the user for determining how many
    hops to consider (neighbors of neighbors).'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**邻域采样**：对于图中的每个节点，第一步是找到其k-邻域，其中*k*由用户定义，以确定要考虑多少跳（邻居的邻居）。'
- en: '**Aggregation**: The second step is to aggregate, for each node, the node features
    describing the respective neighborhood. Various types of aggregation can be performed,
    including average, pooling (for example, taking the best feature according to
    certain criteria), or an even more complicated operation, such as using recurrent
    units (such as LSTM).'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚合**：第二步是为每个节点聚合描述相应邻域的节点特征。可以执行各种类型的聚合，包括平均、池化（例如，根据某些标准选择最佳特征）或更复杂的操作，例如使用循环单元（如LSTM）。'
- en: '**Prediction**: Each node is equipped with a simple neural network that learns
    how to perform predictions based on the aggregated features from the neighbors.'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测**：每个节点都配备了一个简单的神经网络，该网络学习如何根据邻居的聚合特征进行预测。'
- en: GraphSAGE is often used in supervised settings, as we will see in [*Chapter
    4*](B16069_04_Final_JM_ePub.xhtml#_idTextAnchor064), *Supervised Graph Learning*.
    However, by adopting strategies such as using a similarity function as the target
    distance, it can also be effective for learning embedding without explicitly supervising
    the task.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: GraphSAGE通常用于监督学习场景，正如我们将在[*第4章*](B16069_04_Final_JM_ePub.xhtml#_idTextAnchor064)“监督图学习”中看到的。然而，通过采用诸如使用相似度函数作为目标距离等策略，它也可以在没有明确监督任务的情况下进行嵌入学习。
- en: Graph convolution in practice
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际中的图卷积
- en: In practice, GNNs have been implemented in many machine learning and deep learning
    frameworks, including TensorFlow, Keras, and PyTorch. For the next example, we
    will be using StellarGraph, the Python library for machine learning on graphs.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，GNNs已经在许多机器学习和深度学习框架中得到实现，包括TensorFlow、Keras和PyTorch。在下一个例子中，我们将使用StellarGraph，这是一个用于图上机器学习的Python库。
- en: 'In the following example, we will learn about embedding vectors in an unsupervised
    manner, without a target variable. The method is inspired by Bai et al. 2019 and
    is based on the simultaneous embedding of pairs of graphs. This embedding should
    match a ground-truth distance between graphs:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将以无监督的方式了解嵌入向量，没有目标变量。该方法受Bai等人2019年的启发，并基于图对的同步嵌入。这种嵌入应匹配图之间的真实距离：
- en: 'First, let''s load the required Python modules:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们加载所需的Python模块：
- en: '[PRE27]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We will be using the `PROTEINS` dataset for this example, which is available
    in StellarGraph and consists of 1,114 graphs with 39 nodes and 73 edges on average
    for each graph. Each node is described by four attributes and belongs to one of
    two classes:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`PROTEINS`数据集进行此示例，该数据集在StellarGraph中可用，包含1,114个图，每个图平均有39个节点和73条边。每个节点由四个属性描述，并属于两个类别之一：
- en: '[PRE28]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The next step is to create the model. It will be composed of two GC layers
    with 64 and 32 output dimensions followed by ReLU activation, respectively. The
    output will be computed as the Euclidean distance of the two embeddings:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是创建模型。它将由两个具有64和32个输出维度的GC层组成，随后是ReLU激活，分别。输出将被计算为两个嵌入之间的欧几里得距离：
- en: '[PRE29]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'It is now time to prepare the dataset for training. To each pair of input graphs,
    we will assign a similarity score. Notice that any notion of graph similarity
    can be used in this case, including graph edit distances. For simplicity, we will
    be using the distance between the spectrum of the Laplacian of the graphs:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候准备用于训练的数据集了。对于每一对输入图，我们将分配一个相似度分数。请注意，在这种情况下可以使用任何图相似度的概念，包括图编辑距离。为了简单起见，我们将使用图的拉普拉斯谱之间的距离：
- en: '[PRE30]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Finally, let''s compile and train the model. We will be using an adaptive moment
    estimation optimizer (Adam) with the learning rate parameter set to `1e-2`. The
    loss function we will be using is defined as the minimum squared error between
    the prediction and the ground-truth distance computed as previously. The model
    will be trained for 500 epochs:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们编译和训练模型。我们将使用自适应矩估计优化器（Adam），学习率参数设置为`1e-2`。我们将使用的损失函数定义为预测与先前计算的真实距离之间的最小平方误差。模型将训练500个周期：
- en: '[PRE31]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After training, we are now ready to inspect and visualize the learned representation.
    Since the output is 32-dimensional, we need a way to qualitatively evaluate the
    embeddings, for example, by plotting them in a bi-dimensional space. We will use
    T-SNE for this purpose:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练完成后，我们现在可以检查和可视化学习到的表示。由于输出是32维的，我们需要一种方法来定性评估嵌入，例如，通过在二维空间中绘制它们。我们将为此目的使用T-SNE：
- en: '[PRE32]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let''s plot the embeddings. In the plot, each point (embedded graph) is colored
    according to the corresponding label (blue=0, red=1). The results are visible
    in *Figure 3.22*:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制嵌入。在图中，每个点（嵌入图）的颜色根据相应的标签（蓝色=0，红色=1）进行着色。结果在*图3.22*中可见：
- en: '![Figure 3.22 – The PROTEINS dataset embedding using GCNs'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.22 – 使用GCNs的PROTEINS数据集嵌入]'
- en: '](img/B16069_03_22.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16069_03_22.jpg](img/B16069_03_22.jpg)'
- en: Figure 3.22 – The PROTEINS dataset embedding using GCNs
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22 – 使用GCNs的PROTEINS数据集嵌入
- en: This is just one of the possible methods for learning embeddings for graphs.
    More advanced solutions can be experimented with to better fit the problem of
    interest.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是学习图嵌入的可能方法之一。可以尝试更高级的解决方案，以更好地适应感兴趣的问题。
- en: Summary
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned how unsupervised machine learning can be effectively
    applied to graphs to solve real problems, such as node and graph representation
    learning.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何将无监督机器学习有效地应用于图来解决实际问题，例如节点和图表示学习。
- en: In particular, we first analyzed shallow embedding methods, a set of algorithms
    that are able to learn and return only the embedding values for the learned input
    data.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是首先分析了浅层嵌入方法，这是一组能够学习并仅返回学习输入数据的嵌入值的算法。
- en: We then learned how autoencoder algorithms can be used to encode the input by
    preserving important information in a lower-dimensional space. We have also seen
    how this idea can be adapted to graphs, by learning about embeddings that allow
    us to reconstruct the pair-wise node/graph similarity.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们学习了如何使用自动编码器算法通过在低维空间中保留重要信息来编码输入。我们还看到了如何通过学习允许我们重建成对节点/图相似度的嵌入来将这个想法应用于图。
- en: Finally, we introduced the main concepts behind GNNs. We have seen how well-known
    concepts, such as convolution, can be applied to graphs.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍了GNN背后的主要概念。我们看到了如何将诸如卷积等众所周知的概念应用于图。
- en: In the next chapter, we will revise these concepts in a supervised setting.
    There, a target label is provided and the objective is to learn a mapping between
    the input and the output.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将以监督设置修订这些概念。在那里，将提供一个目标标签，目标是学习输入和输出之间的映射。
