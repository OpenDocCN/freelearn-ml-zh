["```py\nimport cv2\nimport numpy as np\n\ndef is_inside(o, i):\n    ox, oy, ow, oh = o\n    ix, iy, iw, ih = i\n    return ox > ix and oy > iy and ox + ow < ix + iw and oy + oh < iy + ih\n\ndef draw_person(image, person):\n  x, y, w, h = person\n  cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 2)\n\nimg = cv2.imread(\"../images/people.jpg\")\nhog = cv2.HOGDescriptor()\nhog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n\nfound, w = hog.detectMultiScale(img)\n\nfound_filtered = []\nfor ri, r in enumerate(found):\n    for qi, q in enumerate(found):\n        if ri != qi and is_inside(r, q):\n            break\n    else:\n        found_filtered.append(r)\n\nfor person in found_filtered:\n  draw_person(img, person)\n\ncv2.imshow(\"people detection\", img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```", "```py\ncv2.HOGDescriptor()\n```", "```py\n{\n    I: 4,\n    like: 4,\n    OpenCV: 2,\n    and: 2,\n    Python: 2,\n    C++: 1,\n    dont: 1,\n    artichokes: 1\n}\n```", "```py\n[2, 2, 1, 1, 1, 0, 0, 0]\n[1, 1, 0, 1, 1, 1, 0, 0]\n[1, 1, 0, 0, 0, 0, 1, 1]\n```", "```py\nimport cv2\nimport numpy as np\nfrom os.path import join\n\ndatapath = \"/home/d3athmast3r/dev/python/CarData/TrainImages/\"\ndef path(cls,i):\n  return \"%s/%s%d.pgm\"  % (datapath,cls,i+1)\n\npos, neg = \"pos-\", \"neg-\"\n\ndetect = cv2.xfeatures2d.SIFT_create()\nextract = cv2.xfeatures2d.SIFT_create()\n\nflann_params = dict(algorithm = 1, trees = 5)flann = cv2.FlannBasedMatcher(flann_params, {})\n\nbow_kmeans_trainer = cv2.BOWKMeansTrainer(40)\nextract_bow = cv2.BOWImgDescriptorExtractor(extract, flann)\n\ndef extract_sift(fn):\n  im = cv2.imread(fn,0)\n  return extract.compute(im, detect.detect(im))[1]\n\nfor i in range(8):\n  bow_kmeans_trainer.add(extract_sift(path(pos,i)))\n  bow_kmeans_trainer.add(extract_sift(path(neg,i)))\n\nvoc = bow_kmeans_trainer.cluster()\nextract_bow.setVocabulary( voc )\n\ndef bow_features(fn):\n  im = cv2.imread(fn,0)\n  return extract_bow.compute(im, detect.detect(im))\n\ntraindata, trainlabels = [],[]\nfor i in range(20):\n  traindata.extend(bow_features(path(pos, i))); trainlabels.append(1)\n  traindata.extend(bow_features(path(neg, i))); trainlabels.append(-1)\n\nsvm = cv2.ml.SVM_create()\nsvm.train(np.array(traindata), cv2.ml.ROW_SAMPLE, np.array(trainlabels))\n\ndef predict(fn):\n  f = bow_features(fn);  \n  p = svm.predict(f)\n  print fn, \"\\t\", p[1][0][0]\n  return p\n\ncar, notcar = \"/home/d3athmast3r/dev/python/study/images/car.jpg\", \"/home/d3athmast3r/dev/python/study/images/bb.jpg\"\ncar_img = cv2.imread(car)\nnotcar_img = cv2.imread(notcar)\ncar_predict = predict(car)\nnot_car_predict = predict(notcar)\n\nfont = cv2.FONT_HERSHEY_SIMPLEX\n\nif (car_predict[1][0][0] == 1.0):\n  cv2.putText(car_img,'Car Detected',(10,30), font, 1,(0,255,0),2,cv2.LINE_AA)\n\nif (not_car_predict[1][0][0] == -1.0):\n  cv2.putText(notcar_img,'Car Not Detected',(10,30), font, 1,(0,0, 255),2,cv2.LINE_AA)\n\ncv2.imshow('BOW + SVM Success', car_img)\ncv2.imshow('BOW + SVM Failure', notcar_img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```", "```py\n    def path(cls,i):\n      return \"%s/%s%d.pgm\"  % (datapath,cls,i+1)\n\n    pos, neg = \"pos-\", \"neg-\"\n    ```", "```py\n    detect = cv2.xfeatures2d.SIFT_create()\n    extract = cv2.xfeatures2d.SIFT_create()\n    ```", "```py\n    flann_params = dict(algorithm = 1, trees = 5)flann = cv2.FlannBasedMatcher(flann_params, {})\n    ```", "```py\n    bow_kmeans_trainer = cv2.BOWKMeansTrainer(40)\n    ```", "```py\n    extract_bow = cv2.BOWImgDescriptorExtractor(extract, flann)\n    ```", "```py\n    def extract_sift(fn):\n      im = cv2.imread(fn,0)\n      return extract.compute(im, detect.detect(im))[1]\n    ```", "```py\n    for i in range(8):\n      bow_kmeans_trainer.add(extract_sift(path(pos,i)))\n      bow_kmeans_trainer.add(extract_sift(path(neg,i)))\n    ```", "```py\n    vocabulary = bow_kmeans_trainer.cluster()\n    extract_bow.setVocabulary(vocabulary)\n    ```", "```py\n    def bow_features(fn):\n      im = cv2.imread(fn,0)\n      return extract_bow.compute(im, detect.detect(im))\n    ```", "```py\n    traindata, trainlabels = [],[]\n    for i in range(20):\n      traindata.extend(bow_features(path(pos, i))); trainlabels.append(1)\n      traindata.extend(bow_features(path(neg, i))); trainlabels.append(-1)\n    ```", "```py\n    svm = cv2.ml.SVM_create()\n    ```", "```py\n    svm.train(np.array(traindata), cv2.ml.ROW_SAMPLE, np.array(trainlabels))\n    ```", "```py\n    def predict(fn):\n      f = bow_features(fn);  \n      p = svm.predict(f)\n      print fn, \"\\t\", p[1][0][0]\n      return p\n    ```", "```py\n    car, notcar = \"/home/d3athmast3r/dev/python/study/images/car.jpg\", \"/home/d3athmast3r/dev/python/study/images/bb.jpg\"\n    car_img = cv2.imread(car)\n    notcar_img = cv2.imread(notcar)\n    ```", "```py\n    car_predict = predict(car)\n    not_car_predict = predict(notcar)\n    ```", "```py\n    font = cv2.FONT_HERSHEY_SIMPLEX\n\n    if (car_predict[1][0][0] == 1.0):\n      cv2.putText(car_img,'Car Detected',(10,30), font, 1,(0,255,0),2,cv2.LINE_AA)\n\n    if (not_car_predict[1][0][0] == -1.0):\n      cv2.putText(notcar_img,'Car Not Detected',(10,30), font, 1,(0,0, 255),2,cv2.LINE_AA)\n\n    cv2.imshow('BOW + SVM Success', car_img)\n    cv2.imshow('BOW + SVM Failure', notcar_img)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n    ```", "```py\n├── car_detector\n│   ├── detector.py\n│   ├── __init__.py\n│   ├── non_maximum.py\n│   ├── pyramid.py\n│   └── sliding_w112661222.indow.py\n└── car_sliding_windows.py\n```", "```py\nimport cv2\n\ndef resize(img, scaleFactor):\n  return cv2.resize(img, (int(img.shape[1] * (1 / scaleFactor)), int(img.shape[0] * (1 / scaleFactor))), interpolation=cv2.INTER_AREA)\n\ndef pyramid(image, scale=1.5, minSize=(200, 80)):\n  yield image\n\n  while True:\n    image = resize(image, scale)\n    if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n      break\n\n    yield image\n```", "```py\ndef sliding_window(image, stepSize, windowSize):\n  for y in xrange(0, image.shape[0], stepSize):\n    for x in xrange(0, image.shape[1], stepSize):\n      yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n```", "```py\ndef non_max_suppression_fast(boxes, overlapThresh):\n\n  # if there are no boxes, return an empty list\n\n  if len(boxes) == 0:\n\n    return []\n\n  # if the bounding boxes integers, convert them to floats --\n\n  # this is important since we'll be doing a bunch of divisions\n\n  if boxes.dtype.kind == \"i\":\n\n    boxes = boxes.astype(\"float\")\n\n  # initialize the list of picked indexes \n\n  pick = []\n\n  # grab the coordinates of the bounding boxes\n\n  x1 = boxes[:,0]\n\n  y1 = boxes[:,1]\n\n  x2 = boxes[:,2]\n\n  y2 = boxes[:,3]\n\n  scores = boxes[:,4]\n\n  # compute the area of the bounding boxes and sort the bounding\n\n  # boxes by the score/probability of the bounding box\n\n  area = (x2 - x1 + 1) * (y2 - y1 + 1)\n\n  idxs = np.argsort(scores)[::-1]\n\n  # keep looping while some indexes still remain in the indexes\n\n  # list\n\n  while len(idxs) > 0:\n\n    # grab the last index in the indexes list and add the\n\n    # index value to the list of picked indexes\n\n    last = len(idxs) - 1\n\n    i = idxs[last]\n\n    pick.append(i)\n\n    # find the largest (x, y) coordinates for the start of\n\n    # the bounding box and the smallest (x, y) coordinates\n\n    # for the end of the bounding box\n\n    xx1 = np.maximum(x1[i], x1[idxs[:last]])\n\n    yy1 = np.maximum(y1[i], y1[idxs[:last]])\n\n    xx2 = np.minimum(x2[i], x2[idxs[:last]])\n\n    yy2 = np.minimum(y2[i], y2[idxs[:last]])\n\n    # compute the width and height of the bounding box\n\n    w = np.maximum(0, xx2 - xx1 + 1)\n\n    h = np.maximum(0, yy2 - yy1 + 1)\n\n    # compute the ratio of overlap\n\n    overlap = (w * h) / area[idxs[:last]]\n\n    # delete all indexes from the index list that have\n\n    idxs = np.delete(idxs, np.concatenate(([last],\n\n      np.where(overlap > overlapThresh)[0])))\n\n  # return only the bounding boxes that were picked using the\n\n  # integer data type\n\n  return boxes[pick].astype(\"int\")\n```", "```py\nimport cv2\nimport numpy as np\n\ndatapath = \"/path/to/CarData/TrainImages/\"\nSAMPLES = 400\n\ndef path(cls,i):\n    return \"%s/%s%d.pgm\"  % (datapath,cls,i+1)\n\ndef get_flann_matcher():\n  flann_params = dict(algorithm = 1, trees = 5)\n  return cv2.FlannBasedMatcher(flann_params, {})\n\ndef get_bow_extractor(extract, flann):\n  return cv2.BOWImgDescriptorExtractor(extract, flann)\n\ndef get_extract_detect():\n  return cv2.xfeatures2d.SIFT_create(), cv2.xfeatures2d.SIFT_create()\n\ndef extract_sift(fn, extractor, detector):\n  im = cv2.imread(fn,0)\n  return extractor.compute(im, detector.detect(im))[1]\n\ndef bow_features(img, extractor_bow, detector):\n  return extractor_bow.compute(img, detector.detect(img))\n\ndef car_detector():\n  pos, neg = \"pos-\", \"neg-\"\n  detect, extract = get_extract_detect()\n  matcher = get_flann_matcher()\n  print \"building BOWKMeansTrainer...\"\n  bow_kmeans_trainer = cv2.BOWKMeansTrainer(1000)\n  extract_bow = cv2.BOWImgDescriptorExtractor(extract, flann)\n\n  print \"adding features to trainer\"\n  for i in range(SAMPLES):\n    print i\n    bow_kmeans_trainer.add(extract_sift(path(pos,i), extract, detect))\n    bow_kmeans_trainer.add(extract_sift(path(neg,i), extract, detect))\n\n  voc = bow_kmeans_trainer.cluster()\n  extract_bow.setVocabulary( voc )\n\n  traindata, trainlabels = [],[]\n  print \"adding to train data\"\n  for i in range(SAMPLES):\n    print i\n    traindata.extend(bow_features(cv2.imread(path(pos, i), 0), extract_bow, detect))\n    trainlabels.append(1)\n    traindata.extend(bow_features(cv2.imread(path(neg, i), 0), extract_bow, detect))\n    trainlabels.append(-1)\n\n  svm = cv2.ml.SVM_create()\n  svm.setType(cv2.ml.SVM_C_SVC)\n  svm.setGamma(0.5)\n  svm.setC(30)\n  svm.setKernel(cv2.ml.SVM_RBF)\n\n  svm.train(np.array(traindata), cv2.ml.ROW_SAMPLE, np.array(trainlabels))\n  return svm, extract_bow\n```", "```py\ndef path(cls,i):\n    return \"%s/%s%d.pgm\"  % (datapath,cls,i+1)\n```", "```py\ndef get_flann_matcher():\n  flann_params = dict(algorithm = 1, trees = 5)\n  return cv2.FlannBasedMatcher(flann_params, {})\n```", "```py\ndef get_bow_extractor(extract, flann):\n  return cv2.BOWImgDescriptorExtractor(extract, flann)\n\ndef get_extract_detect():\n  return cv2.xfeatures2d.SIFT_create(), cv2.xfeatures2d.SIFT_create()\n```", "```py\ndef extract_sift(fn, extractor, detector):\n  im = cv2.imread(fn,0)\n  return extractor.compute(im, detector.detect(im))[1]\n```", "```py\ndef bow_features(img, extractor_bow, detector):\n  return extractor_bow.compute(img, detector.detect(img))\n```", "```py\n  pos, neg = \"pos-\", \"neg-\"\n  detect, extract = get_extract_detect()\n  matcher = get_flann_matcher()\n  bow_kmeans_trainer = cv2.BOWKMeansTrainer(1000)\n  extract_bow = cv2.BOWImgDescriptorExtractor(extract, flann)\n```", "```py\n  print \"adding features to trainer\"\n  for i in range(SAMPLES):\n    print i\n    bow_kmeans_trainer.add(extract_sift(path(pos,i), extract, detect))\n```", "```py\nvocabulary = bow_kmeans_trainer.cluster()\n extract_bow.setVocabulary(vocabulary)\n```", "```py\ntraindata, trainlabels = [], []  \n  print \"adding to train data\"\n  for i in range(SAMPLES):\n    print i\n    traindata.extend(bow_features(cv2.imread(path(pos, i), 0), extract_bow, detect))\n    trainlabels.append(1)\n    traindata.extend(bow_features(cv2.imread(path(neg, i), 0), extract_bow, detect))\n    trainlabels.append(-1)\n```", "```py\n  traindata, trainlabels = [], []\n  print \"adding to train data\"\n  for i in range(SAMPLES):\n    print i\n    traindata.extend(bow_features(cv2.imread(path(class1, i), 0), extract_bow, detect))\n    trainlabels.append(1)\n    traindata.extend(bow_features(cv2.imread(path(class2, i), 0), extract_bow, detect))\n    trainlabels.append(2)\n    traindata.extend(bow_features(cv2.imread(path(class3, i), 0), extract_bow, detect))\n    trainlabels.append(3)\n```", "```py\n  svm = cv2.ml.SVM_create()\n  svm.setType(cv2.ml.SVM_C_SVC)\n  svm.setGamma(0.5)\n  svm.setC(30)\n  svm.setKernel(cv2.ml.SVM_RBF)\n\n  svm.train(np.array(traindata), cv2.ml.ROW_SAMPLE, np.array(trainlabels))\n  return svm, extract_bow\n```", "```py\nimport cv2\nimport numpy as np\nfrom car_detector.detector import car_detector, bow_features\nfrom car_detector.pyramid import pyramid\nfrom car_detector.non_maximum import non_max_suppression_fast as nms\nfrom car_detector.sliding_window import sliding_window\n\ndef in_range(number, test, thresh=0.2):\n  return abs(number - test) < thresh\n\ntest_image = \"/path/to/cars.jpg\"\n\nsvm, extractor = car_detector()\ndetect = cv2.xfeatures2d.SIFT_create()\n\nw, h = 100, 40\nimg = cv2.imread(test_img)\n\nrectangles = []\ncounter = 1\nscaleFactor = 1.25\nscale = 1\nfont = cv2.FONT_HERSHEY_PLAIN\n\nfor resized in pyramid(img, scaleFactor):  \n  scale = float(img.shape[1]) / float(resized.shape[1])\n  for (x, y, roi) in sliding_window(resized, 20, (w, h)):\n\n    if roi.shape[1] != w or roi.shape[0] != h:\n      continue\n\n    try:\n      bf = bow_features(roi, extractor, detect)\n      _, result = svm.predict(bf)\n      a, res = svm.predict(bf, flags=cv2.ml.STAT_MODEL_RAW_OUTPUT)\n      print \"Class: %d, Score: %f\" % (result[0][0], res[0][0])\n      score = res[0][0]\n      if result[0][0] == 1:\n        if score < -1.0:\n          rx, ry, rx2, ry2 = int(x * scale), int(y * scale), int((x+w) * scale), int((y+h) * scale)\n          rectangles.append([rx, ry, rx2, ry2, abs(score)])\n    except:\n      pass\n\n    counter += 1\n\nwindows = np.array(rectangles)\nboxes = nms(windows, 0.25)\n\nfor (x, y, x2, y2, score) in boxes:\n  print x, y, x2, y2, score\n  cv2.rectangle(img, (int(x),int(y)),(int(x2), int(y2)),(0, 255, 0), 1)\n  cv2.putText(img, \"%f\" % score, (int(x),int(y)), font, 1, (0, 255, 0))\n\ncv2.imshow(\"img\", img)\ncv2.waitKey(0)\n```", "```py\n      bf = bow_features(roi, extractor, detect)\n      _, result = svm.predict(bf)\n      a, res = svm.predict(bf, flags=cv2.ml.STAT_MODEL_RAW_OUTPUT)\n      print \"Class: %d, Score: %f\" % (result[0][0], res[0][0])\n      score = res[0][0]\n      if result[0][0] == 1:\n        if score < -1.0:\n          rx, ry, rx2, ry2 = int(x * scale), int(y * scale), int((x+w) * scale), int((y+h) * scale)\n          rectangles.append([rx, ry, rx2, ry2, abs(score)])\n```", "```py\nwindows = np.array(rectangles)\nboxes = nms(windows, 0.25)\n```", "```py\nsvm.save('/path/to/serialized/svmxml')\n```"]