["```py\nJupyter==1.0.0\nnetworkx==2.5\nmatplotlib==3.2.2\nkarateclub==1.0.19\nnode2vec==0.3.3\ntensorflow==2.4.0\nscikit-learn==0.24.0\ngit+https://github.com/palash1992/GEM.git\ngit+https://github.com/stellargraph/stellargraph.git\n```", "```py\nimport networkx as nx\nfrom gem.embedding.gf import GraphFactorization\nG = nx.barbell_graph(m1=10, m2=4)\ngf = GraphFactorization(d=2, data_set=None, max_iter=10000, eta=1*10**-4, regu=1.0)\ngf.learn_embedding(G)\nembeddings = gf.get_embedding()\n```", "```py\nimport networkx as nx\nfrom gem.embedding.hope import HOPE\nG = nx.barbell_graph(m1=10, m2=4)\ngf = HOPE(d=4, beta=0.01)\ngf.learn_embedding(G)\nembeddings = gf.get_embedding()\n```", "```py\nimport networkx as nx\nfrom karateclub.node_embedding.neighbourhood.grarep import GraRep\nG = nx.barbell_graph(m1=10, m2=4)\ngr = GraRep(dimensions=2, order=3)\ngr.fit(G)\nembeddings = gr.get_embedding()\n```", "```py\nimport networkx as nx\nfrom karateclub.node_embedding.neighbourhood.deepwalk import DeepWalk\nG = nx.barbell_graph(m1=10, m2=4)\ndw = DeepWalk(dimensions=2)\ndw.fit(G)\nembeddings = dw.get_embedding()\n```", "```py\nimport networkx as nx\nfrom node2vec import Node2Vec\nG = nx.barbell_graph(m1=10, m2=4)\ndraw_graph(G)\nnode2vec = Node2Vec(G, dimensions=2)\nmodel = node2vec.fit(window=10)\nembeddings = model.wv\n```", "```py\nfrom node2vec.edges import HadamardEmbedder\nembedding = HadamardEmbedder(keyed_vectors=model.wv)\n```", "```py\nimport matplotlib.pyplot as plt\nfrom karateclub import Graph2Vec\nn_graphs = 20\ndef generate_random():\n    n = random.randint(5, 20)\n    k = random.randint(5, n)\n    p = random.uniform(0, 1)\n    return nx.watts_strogatz_graph(n,k,p)\nGs = [generate_random() for x in range(n_graphs)]\nmodel = Graph2Vec(dimensions=2)\nmodel.fit(Gs)\nembeddings = model.get_embedding()\n```", "```py\nfrom tensorflow.keras.datasets import fashion_mnist\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() \n```", "```py\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n```", "```py\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    ax = plt.subplot(1, n, i + 1)\n    plt.imshow(x_train[i])\n    plt.title(classes[y_train[i]])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n```", "```py\nfrom tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, UpSampling2D, Input\ninput_img = Input(shape=(28, 28, 1))\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n```", "```py\nModel(input_img, encoded).summary()\n```", "```py\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x) \n```", "```py\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n```", "```py\nautoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test, x_test))\n```", "```py\ndecoded_imgs = autoencoder.predict(x_test)\n```", "```py\nfrom tensorflow.keras.layers import Flatten\nembed_layer = Flatten()(encoded)\nembeddings = Model(input_img, embed_layer).predict(x_test)\ntsne = TSNE(n_components=2)\nemb2d = tsne.fit_transform(embeddings)\nx, y = np.squeeze(emb2d[:, 0]), np.squeeze(emb2d[:, 1])\n```", "```py\nnoise_factor = 0.1\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n```", "```py\nnoisy_autoencoder.fit(x_train_noisy, x_train,\n                epochs=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test_noisy, x_test))\n```", "```py\ninput_img = Input(shape=(28, 28, 1))\nnoisy_input = GaussianNoise(0.1)(input_img)\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(noisy_input)\n```", "```py\nG=nx.karate_club_graph()\nsdne=SDNE(d=2, beta=5, alpha=1e-5, nu1=1e-6, nu2=1e-6,\n          K=3,n_units=[50, 15,], rho=0.3, n_iter=10, \n          xeta=0.01,n_batch=100,\n          modelfile=['enc_model.json','dec_model.json'],\n          weightfile=['enc_weights.hdf5','dec_weights.hdf5'])\nsdne.learn_embedding(G)\nembeddings = m1.get_embedding()\n```", "```py\n    import networkx as nx\n    import numpy as np\n    G = nx.barbell_graph(m1=10,m2=4)\n    ```", "```py\n    A = nx.to_numpy_matrix(G)\n     I = np.eye(G.number_of_nodes())\n    ```", "```py\n    from scipy.linalg import sqrtm\n    A_hat = A + I\n    D_hat = np.array(np.sum(A_hat, axis=0))[0]\n     D_hat = np.array(np.diag(D_hat))\n     D_hat = np.linalg.inv(sqrtm(D_hat))\n     A_norm = D_hat @ A_hat @ D_hat\n    ```", "```py\n    def glorot_init(nin, nout):\n         sd = np.sqrt(6.0 / (nin + nout))\n         return np.random.uniform(-sd, sd, size=(nin, nout))\n    class GCNLayer():\n      def __init__(self, n_inputs, n_outputs):\n          self.n_inputs = n_inputs\n          self.n_outputs = n_outputs\n          self.W = glorot_init(self.n_outputs, self.n_inputs)\n          self.activation = np.tanh\n      def forward(self, A, X):\n          self._X = (A @ X).T\n          H = self.W @ self._X \n          H = self.activation(H)\n          return H.T # (n_outputs, N)\n    ```", "```py\n    gcn1 = GCNLayer(G.number_of_nodes(), 8)\n     gcn2 = GCNLayer(8, 4)\n     gcn3 = GCNLayer(4, 2)\n    H1 = gcn1.forward(A_norm, I)\n     H2 = gcn2.forward(A_norm, H1)\n    H3 = gcn3.forward(A_norm, H2)\n    ```", "```py\n    import numpy as np\n    import stellargraph as sg\n    from stellargraph.mapper import FullBatchNodeGenerator\n    from stellargraph.layer import GCN\n    import tensorflow as tf\n    from tensorflow.keras import layers, optimizers, losses, metrics, Model\n    ```", "```py\n    dataset = sg.datasets.PROTEINS()\n    graphs, graph_labels = dataset.load()\n    ```", "```py\n    generator = sg.mapper.PaddedGraphGenerator(graphs)\n\n    # define a GCN model containing 2 layers of size 64 and 32, respectively. \n    # ReLU activation function is used to add non-linearity between layers\n    gc_model = sg.layer.GCNSupervisedGraphClassification(\n     [64, 32], [\"relu\", \"relu\"], generator, pool_all_layers=True)\n    # retrieve the input and the output tensor of the GC layer such that they can be connected to the next layer\n    inp1, out1 = gc_model.in_out_tensors()\n    inp2, out2 = gc_model.in_out_tensors()\n    vec_distance = tf.norm(out1 - out2, axis=1)\n\n    # create the model. It is also useful to create a specular model in order to easily retrieve the embeddings\n    pair_model = Model(inp1 + inp2, vec_distance)\n     embedding_model = Model(inp1, out1)\n    ```", "```py\n    def graph_distance(graph1, graph2):\n       spec1 = nx.laplacian_spectrum(graph1.to_networkx(feature_attr=None))\n       spec2 = nx.laplacian_spectrum(graph2.to_networkx(feature_attr=None))\n       k = min(len(spec1), len(spec2))\n       return np.linalg.norm(spec1[:k] - spec2[:k])\n    graph_idx = np.random.RandomState(0).randint(len(graphs), size=(100, 2))\n    targets = [graph_distance(graphs[left], graphs[right]) for left, right in graph_idx]\n    train_gen = generator.flow(graph_idx, batch_size=10, targets=targets)\n    ```", "```py\n    pair_model.compile(optimizers.Adam(1e-2), loss=\"mse\")\n    pair_model.fit(train_gen, epochs=500, verbose=0)\n    ```", "```py\n    # retrieve the embeddings\n    embeddings = embedding_model.predict(generator.flow(graphs))\n    # TSNE is used for dimensionality reduction\n    from sklearn.manifold import TSNE\n    tsne = TSNE(2)\n     two_d = tsne.fit_transform(embeddings)\n    ```"]