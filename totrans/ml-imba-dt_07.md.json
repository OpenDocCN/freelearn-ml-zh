["```py\nimg_transform = torchvision.transforms.ToTensor()\ntrainset = torchvision.datasets.MNIST(\\\n    root='/tmp/mnist', train=True,\\\n    download=True, transform=img_transform)\ntestset = torchvision.datasets.MNIST(root='/tmp/mnist',\\\n    train=False, transform=img_transform)\n```", "```py\ntrain_loader = torch.utils.data.DataLoader(trainset,\\\n    batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=testset,\\\n    batch_size=500)\n```", "```py\nimport torch.nn as nn\nimport torch.optim as optim\n```", "```py\ninput_size = 28 * 28 # 784\nnum_classes = 10\nnum_epochs = 20\nlearning_rate = 0.01\n```", "```py\ndef train(trainloader):\n    model = nn.Linear(input_size, num_classes)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), learning_rate)\n    for epoch in range(num_epochs):\n        run_epoch(trainloader, model, criterion, optimizer, \\\n            total_step, epoch)\n    return model\n```", "```py\ndef run_epoch(\n    trainloader, model, criterion, optimizer, total_step, epoch\n):\n    for i, (images, labels) in enumerate(trainloader):\n        # Reshape images to (batch_size, input_size)\n        images = images.reshape(-1, input_size)\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, torch.tensor(labels))\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n```", "```py\nmodel = train(imbalanced_train_loader)\n```", "```py\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = torch.nn.Dropout2d()\n        self.fc1 = torch.nn.Linear(320, 50)\n        self.fc2 = torch.nn.Linear(50, 10)\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(\n            self.conv2_drop(self.conv2(x)),2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n```", "```py\nX=torch.stack(tuple(imbalanced_train_loader.dataset.data))\ny=torch.tensor(imbalanced_train_loader.dataset.targets)\n```", "```py\nreshaped_X = X.reshape(X.shape[0],-1)\n```", "```py\nfrom imblearn.over_sampling import RandomOverSampler\noversampler = RandomOverSampler()\noversampled_X, oversampled_y = oversampler.fit_resample(reshaped_X, y)\n```", "```py\noversampled_X = oversampled_X.reshape(-1,28,28)\n```", "```py\nbalanced_train_dataset = copy.deepcopy(imbalanced_train_dataset)\nbalanced_train_dataset.targets = torch.from_numpy(oversampled_y)\nbalanced_train_dataset.data = torch.from_numpy(oversampled_X)\nbalanced_train_loader = torch.utils.data.DataLoader( \\\n    balanced_train_dataset, batch_size=100, shuffle=True)\n```", "```py\nbalanced_data_model = train(balanced_train_loader)\n```", "```py\nclass_counts = pd.Series(\\\n    imbalanced_train_loader.dataset.targets.numpy()).value_counts()\nclass_weights = 1.0/class_counts\n```", "```py\nweightedRandomSampler = \\\n    WeightedRandomSampler(weights=class_weights, \\\n    num_samples=len(imbalanced_train_dataset), \\\n    replacement=True)\nweightedRandomSampler_dataloader = \\\n    torch.utils.data.DataLoader(imbalanced_train_dataset,\\\n    sampler=weightedRandomSampler, batch_size=64)\n```", "```py\npadded_imgs = [torchvision.transforms.Pad(padding=90)(orig_img)]\nplot(padded_imgs)\n```", "```py\n(top_left, top_right, bottom_left, bottom_right, center) =\\\n    torchvision.transforms.FiveCrop(size=(100,100))(orig_img)\nplot([top_left, top_right, bottom_left, bottom_right, center])\n```", "```py\njitter = torchvision.transforms.ColorJitter(brightness=.7, hue=.5)\njitted_imgs = [jitter(orig_img) for _ in range(3)]\nplot(jitted_imgs)\n```", "```py\ngaussian_blurrer = \\\n    torchvision.transforms.GaussianBlur(kernel_size=(9,\\\n    11), sigma=(0.1, 5))\nblurred_imgs = [gaussian_blurrer(orig_img) for _ in \\\n    range(4)]\nplot(blurred_imgs)\n```", "```py\nrotater = torchvision.transforms.RandomRotation(degrees=(0, 50))\nrotated_imgs = [rotater(orig_img) for _ in range(4)]\nplot(rotated_imgs)\n```", "```py\ndef mixup(data, target, alpha):\n    indices = torch.randperm(data.size(0))\n    shuffled_data = data[indices]\n    shuffled_target = target[indices]\n    lamda = np.random.beta(alpha, alpha)\n    data = lamda * data + (1 - lamda) * shuffled_data\n    target = lamda * target + (1 - lamda) * shuffled_target\n    return data, target\n```", "```py\nfrom torchvision.transforms import transforms\ndef simple_augmix(image):\n    # Our box of magic tricks\n    magic_tricks = [\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomAffine(degrees=30)\n        # other transforms here\n    ]\n    # Pick a random number of tricks to use\n    num_tricks = np.random.randint(0, len(magic_tricks) + 1)\n    # Create a new picture by mixing transformed ones\n    new_picture = torch.zeros_like(image)\n    # Let's use 4 mixed images for our example\n    for _ in range(4):\n        transformed_picture = image.clone()\n        for _ in range(num_tricks):\n            trick = np.random.choice(magic_tricks)\n            transformed_picture = trick(transformed_picture)\n            # Add the transformed picture to our new picture\n            new_picture += (1/4) * transformed_picture\n    return new_picture\n```", "```py\ndef remix_data(inputs, labels, class_counts, alpha=1.0):\n    lambda_x = np.random.beta(alpha, alpha) if alpha > 0 else 1\n    # Constants for controlling the remixing conditions.\n    K = 3\n    tau = 0.5\n    # Shuffle the indices randomly.\n    random_indices = torch.randperm(inputs.size()[0])\n    # Determine lambda_y values based on class counts and lambda_x.\n    lambda_y_values = []\n    for i, j in enumerate(random_indices):\n        class_count_ratio = (\n            class_counts[labels[i]] / class_counts[labels[j]]\n        )\n        if class_count_ratio >= K and lambda_x < tau:\n            lambda_y_values.append(0)\n        else:\n            lambda_y_values.append(lambda_x)\n    lambda_y = torch.tensor(lambda_y_values)\n    # Mix inputs, labels based on lambda_x, lambda_y, and shuffled indices.\n    mixed_inputs = (\n        lambda_x * inputs + (1 - lambda_x) * inputs[random_indices, :]\n    )\n    mixed_labels = (\n        lambda_y * labels + (1 - lambda_y) * labels[random_indices]\n    )\n    return mixed_inputs, mixed_labels\n```", "```py\n               precision     recall     f1-score     support\nham               0.97        1.00        0.98        1216\nspam              0.97        0.80        0.88         177\naccuracy                                  0.97        1393\nmacro avg         0.97        0.90        0.93        1393\nweighted avg      0.97        0.97        0.97        1393\n```", "```py\n               precision     recall     f1-score     support\nham               0.99        0.99        0.99        1216\nspam              0.93        0.91        0.92         177\naccuracy                                  0.98        1393\nmacro avg         0.96        0.95        0.95        1393\nweighted avg      0.98        0.98        0.98        1393\n```", "```py\n               precision     recall     f1-score     support\nham               0.98        1.00        0.99        1216\nspam              0.96        0.86        0.91         177\naccuracy                                  0.98        1393\nmacro avg         0.97        0.93        0.95        1393\nweighted avg      0.98        0.98        0.98        1393\n```", "```py\n               precision     recall      f1-score    support\nham               0.98        0.99        0.99        1216\nspam              0.96        0.88        0.91         177\naccuracy                                  0.98        1393\nmacro avg         0.97        0.93        0.95        1393\nweighted avg      0.98        0.98        0.98        1393\n```"]