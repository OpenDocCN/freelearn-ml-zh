- en: Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After the previous [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machine Learn*, you now know
    how to make machines learn from observations and data points so that they can
    find out interesting patterns, trends, and make predictions. In this chapter,
    we will be dealing with one of the complex problems faced by retailers, stores,
    and e-commerce marketplaces today. With the advent of modern technology and innovations,
    shopping has become a relatively pleasant and enjoyable experience which we can
    enjoy from the comfort of our home, without even venturing to an actual store,
    using the web or dedicated apps which provide shopping facilities. With a humongous
    number of retailers, stores, marketplaces, and sellers, competition is pretty
    stiff, and to attract customers, they have to use all the data they can gather
    from consumers about their personal traits and shopping patterns, and use machine
    learning techniques to try and make shopping experiences as personalized as possible
    based on each customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might be wondering how machine learning can help in making shopping experiences
    personalized for each user! The answer lies in two things: data and algorithms.
    Using a combination of both of these, retailers are able to figure out what are
    the most trending items that the consumers buy, the likes and dislikes of the
    customers, the peak times when the sales go up and come down, the trending combination
    of products which people tend to buy, and the product reviews and prices which
    are being offered by other retailers for the same products. Retailers have their
    own data science teams which aggregate this data and apply various machine learning
    algorithms which are used to analyze the trending products and build recommender
    engines which predict what the customers are most likely to buy, and give recommendations
    to the customers based on their interests and shopping history.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be focusing on product based recommendations where
    the algorithms focus on customer shopping transactional data, where we observe
    common patterns of product combinations bought by the customers, to detect and
    predict what products customers are most likely to buy and what they have bought
    in the past. The main techniques we will be focusing on in this chapter are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Product contingency matrix evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequent itemsets generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Association rule mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trend analysis using association rules and pattern mining however have their
    own limitations. They do not provide a more personalized shopping experience for
    each customer based on attributes like their interests, products they have bought
    and rated. We will be looking at that in the subsequent chapter where we focus
    on algorithms such as user-based collaborative filtering, which takes into account
    both product based and user based features when building recommender engines.
  prefs: []
  type: TYPE_NORMAL
- en: What is most interesting is that all the retailers and e-commerce marketplaces,
    such as Staples, Macy's, Target, Amazon, Flipkart, Alibaba, Rakuten, Lazada, and
    many many others, have their own data science teams, which solve a wide variety
    of problems including the one we discussed earlier. They make use of all the data
    generated from customer shopping transactions, product stocks, deliveries, SLAs,
    reviews, advertisements, click-through rates, bounce rates, pricing data, and
    many other sources. They process this data and feed it into their machine learning
    algorithm based engines to generate data driven insights to increase sales and
    profits for the business. Now this is definitely one domain which is hot in the
    market right now. Let's now look further into some of the machine learning techniques
    and algorithms which help them in making such great data driven decisions!
  prefs: []
  type: TYPE_NORMAL
- en: Detecting and predicting trends
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will talk about what exactly we mean by trends and how the
    retailers detect and predict these trends. Basically, a trend in the retail context
    can be defined as a specific pattern or behavior which occurs over a period of
    time. This may involve a product or a combination of products being sold out in
    a very short period of time or even the reverse. A simple example would be a best-selling
    smartphone being prebooked and out of stock before even hitting the shelves on
    any e-commerce marketplace, or a combination of products like the classic beer
    and diapers combination which is frequently found in shopping baskets or carts
    of customers!
  prefs: []
  type: TYPE_NORMAL
- en: How can we even start analyzing shopping carts or start to detect and predict
    shopping trends. Like I mentioned earlier, we can achieve this with a combination
    of the right data and algorithms. Let's assume that we are heading a large retail
    chain. First we will have to keep track of each and every transaction which is
    taking place from our stores and website. We will need to gather data points relevant
    to the items being purchased, stockouts, combinations of items purchased together,
    and customer transactions to begin with.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have this data, we can start processing, normalizing, and aggregating
    this data to machine readable formats, which can be easily operated on and fed
    to machine learning algorithms for product recommendations based on the shopping
    trends. We can achieve this by using the right data structures and constructs
    which we learned back in [Chapter 1](part0014_split_000.html#DB7S2-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 1. Getting Started with R and Machine Learning"), *Getting Started with
    R and Machine Learning*. There are several machine learning algorithms which help
    us in analyzing the shopping transactional data and recommending products based
    on the shopping trends. The main paradigm under which these algorithms fall is
    popularly known as **market basket analysis**. Interestingly, these algorithms
    use statistical and machine learning concepts such as probability, support, confidence,
    lift, pattern detection, and many more to determine what are the items being bought
    together frequently, which helps us in analyzing shopping transactions and detecting
    and predicting trends. This ultimately helps us in making product recommendations
    for the customers and also making business decisions wisely, if we were running
    a retail chain! Do note that the only data we will be using in both these algorithms
    is pure shopping transactions based data.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start diving into building algorithms to analyze the shopping carts
    and transactions, let us first see what market basket analysis actually means
    and the concepts associated with it. This will come in handy later on, when we
    implement machine learning algorithms using some of these concepts to solve real
    world problems.
  prefs: []
  type: TYPE_NORMAL
- en: Market basket analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Market basket analysis consists of some modeling techniques which are typically
    used by retailers and e-commerce marketplaces to analyze shopping carts and transactions
    to find out what customers buy the most, what kind of items they buy, what the
    peak season is for specific items to be sold the most, and so on. We will be focusing
    on item based transactional patterns in this chapter for detecting and predicting
    what items people are buying and are most likely to buy. Let us first look at
    the formal definition of market basket analysis and then we will look at core
    concepts, metrics, and techniques tied to it. Finally, we will conclude with how
    to actually use these results to make data driven decisions.
  prefs: []
  type: TYPE_NORMAL
- en: What does market basket analysis actually mean?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Market basket analysis typically encompasses several modeling techniques based
    upon the simple principle that while shopping if you buy a certain group of items
    (also known as an itemset in machine learning lingo), you are likely to buy an
    other specific item or items along with that itemset. We analyze human shopping
    patterns and apply statistical techniques to generate frequent itemsets. These
    itemsets contain combination of items that people are most likely to buy together,
    based on past shopping history.
  prefs: []
  type: TYPE_NORMAL
- en: A simple example of an itemset would be people buying beer and diapers frequently
    at the market. The itemset can be depicted as `{ beer, diapers }`. A frequent
    itemset is indicated by an itemset which occurs more frequently than usual and
    is specified by a metric known as support, which we will be talking about later
    on. Hence, from the preceding example you can say that if I buy beer, I am also
    most likely to buy `diapers`, and recommend that product to me. We can also build
    item association rules on top of these itemsets by analyzing shopping purchases.
    An example association rule can be denoted by using itemsets using the notation,
    `{ beer, diapers } -> { milk }` which would indicate that if I am buying beer
    and diapers together, I am most likely to also purchase milk along with that!
  prefs: []
  type: TYPE_NORMAL
- en: Core concepts and definitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you know what market basket analysis actually does, let us look at
    some definitions and concepts which are widely used in the algorithms and techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transactional datasets** indicate databases or datasets where the customer''s
    shopping transactions are recorded daily/weekly and consist of various items bought
    together by the customers. We will take an example transactional dataset which
    we will also be using later on in the chapter for our algorithms. Consider the
    following dataset, which you can also get from the `shopping_transaction_log.csv`
    file for this chapter. The data is represented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts and definitions](img/00078.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Each cell in the preceding dataset is also defined as an item. Items are also
    denoted by the symbol In where `n` denotes the `n-th` item number, and examples
    are enclosed in curly braces in formal definitions and when building algorithm
    pseudocode or doing some computations by hand. For example, cell combination `(1,
    A)` indicates item `I1` whose value is depicted as `{ beer }`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Itemsets** are defined as sets or groups of items which were bought together
    in any shopping transaction. Hence, these items are said to co-occur based on
    the transactions. We will denote itemsets as `ISn` where *n* denotes the `n-th`
    itemset number. The itemset values will will be enclosed in curly braces. Each
    row in the preceding dataset denotes a particular transaction and the combination
    of items form the itemsets. The itemset `IS1` is depicted by `{ beer, diapers,
    bread }`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Association** **rules** or just rules are statements which have a **left-hand
    side** (**LHS**) and a **right-hand side** (**RHS**), and indicate that if we
    have the items on the LHS for purchase, we are likely to be interested in purchasing
    the RHS items too. This signifies that the itemsets are associated with each other.
    They are denoted as `ISx → ISy`, which means that if I have itemset `x` in my
    shopping cart, I will also be interested in purchasing itemset `y` along with
    it. An example rule can be `{ beer } → { diapers }` which indicates that if I
    have beer in my cart, there is a chance I will buy diapers too! We will now see
    some metrics which determine how to measure frequent itemsets and the strength
    of the association rules.'
  prefs: []
  type: TYPE_NORMAL
- en: The **frequency** of an itemset is basically the number of times a particular
    itemset occurs in the list of all transactions. Do note that the itemset can be
    a subset of a larger itemset in the transactions and still be counted because
    the subset denotes that the itemset containing the specific set of items was bought
    along with some other products. We can denote it as `f(ISn)`, where `ISn` is a
    particular itemset and function `f( )` gives us the frequency of that itemset
    in the whole transactional based dataset. Taking our previous dataset, `f(IS{beer,
    diapers})` is six, which indicates `IS{beer, diapers}` has been purchased six
    times in total out of all the transactional data in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The **support** of an itemset is defined as the fraction of transactions in
    our transactional dataset which consists of that particular itemset. Basically,
    it means the number of times that itemset was purchased divided by the total number
    of transactions in the dataset. It can be denoted as ![Core concepts and definitions](img/00079.jpeg),
    where `S( )` denotes the support of the itemset `ISn`. Taking our preceding example,
    `S(IS{beer, diapers})` is ![Core concepts and definitions](img/00080.jpeg) which
    gives us `66.67%`. The support for an association rule is similar and can be depicted
    as ![Core concepts and definitions](img/00081.jpeg), where we use the intersection
    operator to see the frequency of both the itemsets occurring together in the transactional
    dataset. The support for the rule we defined earlier, `S(IS{beer} → IS{diapers})`,
    is once again ![Core concepts and definitions](img/00080.jpeg) or `66.67%` because
    the itemset combining beer and diapers occurs six times in total, as we saw earlier.
    When evaluating results from association rules or frequent itemsets, the higher
    the support, the better it is. Support is more about measuring the quality of
    rules detecting what has already happened from the past transactions.
  prefs: []
  type: TYPE_NORMAL
- en: The **confidence** of an association rule is defined as the probability or likelihood
    that, for a new transaction containing itemset in the LHS of the rule, the transaction
    also contains the itemset on the RHS of the rule. The confidence for a rule can
    be depicted as ![Core concepts and definitions](img/00082.jpeg), where `C( )`
    denotes the confidence of the rule. Do note that since calculation of support
    involves dividing itemset frequency by the total number of transactions in the
    denominator, the RHS of the preceding equation ultimately reduces to getting the
    frequency of the itemsets for both the numerator and denominator. Thus we get
    ![Core concepts and definitions](img/00083.jpeg) as the reduced formula for getting
    confidence. The confidence for our earlier rule `C(IS{beer} → IS{diapers})` is
    ![Core concepts and definitions](img/00084.jpeg) or `100%`, which means the probability
    of buying diapers, if I have beer in my shopping basket, is a hundred percent!
    That is pretty high and if you go back to the dataset, you can see that it is
    true because for every transaction involving beer, we can see diapers associated
    with it. Thus, you can see that making predictions and recommendations is not
    rocket science but just simple applied math and statistical methods on top of
    data. Remember that confidence is more about detecting the quality of rules predicting
    what can happen in the future based on the past transactional data.
  prefs: []
  type: TYPE_NORMAL
- en: The **lift** of an association rule is defined as the ratio of the support of
    the combination of two itemsets on the LHS and RHS together divided by the product
    of the support of each of the itemsets. The lift for a rule can be depicted as
    ![Core concepts and definitions](img/00085.jpeg), where `L( )` denotes the lift
    of the rule. For our example rule, `L(IS{beer} → IS{diapers})` is, ![Core concepts
    and definitions](img/00086.jpeg) which evaluates to ![Core concepts and definitions](img/00087.jpeg)
    giving us the value of `1.125` which is pretty decent! The lift of a rule in general
    is another metric to evaluate the quality of the rule. If the lift is `> 1` then
    it indicates that the presence of the itemset in the LHS is responsible for the
    increase in probability that the customer is also going to buy the itemset on
    the RHS. This is another very important way to determine itemset associations
    and which items influence people to buy other items, because if the lift has a
    value `= 1`, it means that the itemsets on the LHS and RHS are independent and
    buying one itemset will not affect the customer to buy the other itemset. If the
    lift is `< 1`, it indicates that if the customer has an itemset on the LHS then
    the probability of buying the itemset on the RHS is relatively low.
  prefs: []
  type: TYPE_NORMAL
- en: Techniques used for analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have been overwhelmed by all the mathematical information in the previous
    section, just relax and take a deep breath! You do not need to remember everything
    because most of the time, the algorithms will compute everything for you! The
    thing where you need to be good at is using these techniques and algorithms in
    the right way and interpreting the results to filter out what is necessary and
    useful. The earlier mentioned concepts will help you when you start implementing
    and applying the techniques later on, which we will briefly describe in this section.
    We will mainly be talking about three techniques which we will be exploring in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation of a product contingency matrix is the simplest approach to start
    with, which is more of a global trend capturing mechanism and shows the top most
    products that are being bought together in a contingency matrix. The R package
    `arules`, which we will be using later on, has a nice function called **crossTable**
    which helps in cross-tabulating the joint occurrences across pairs of items into
    a contingency matrix. We will use this matrix to predict which products the customers
    would most likely buy with some other product from the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Frequent itemset generation takes off from where product contingency matrix
    stops, because it has a severe limitation of not being able to deal with pairs
    of products at any point in time. Hence, to get into itemsets which can have any
    number of products and detect patterns from there, we will be building our own
    frequent itemset generator using machine learning! Using this, we will be able
    to get frequent itemsets with specific support values indicating the sets of items
    likely to be purchased together, and hence forming the basis of recommending products
    to the customers.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will be implementing association rule mining using the wonderful
    Apriori algorithm which uses frequent itemsets as a part of its rule generation
    process. You have already seen a demo of this in the [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*. However,
    this time we will be using its full-fledged capabilities to view the association
    rules between product itemsets, evaluating the quality of the rules using the
    metrics we discussed earlier, and also using these rules to make trend predictions
    and recommendations for products in shopping transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Making data driven decisions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You now know what market basket analysis is, what techniques are used for it,
    and what results they give us. Remember that the output of market basket analysis
    is a set of items or products which co-occur frequently in transactions. Now this
    can happen because of strong support, confidence, and lift which boost its association
    and the customers tend to buy them, or it could also be because the retailer has
    placed the items together or side by side in the store or website. However, do
    remember that strong associations do not always happen just by chance and that
    is what the retailers are always trying to find out using the techniques we talked
    about earlier to boost sales.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some crucial data driven decisions which the retailers usually
    tend to take based on the results obtained from market basket analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: Frequent itemsets containing pairs of products such as diapers and beer should
    be typically placed side by side in the store, which would give customers easy
    access and they would tend to buy them more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequent itemsets which have a large number of distinct items or product counts
    should be placed in a specific category or theme for the itemset, such as special
    grocery combos or baby products. Discounts offered on the whole itemset attracts
    more customers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Association rules having a long list of items in the itemset or products obtained
    from frequent itemsets or contingency matrices can be shown as product suggestions
    and recommendations to the customers, in specific product pages associated with
    the itemsets, when they browse the shopping or e-commerce website. Care should
    be taken that the lift of these rules be greater than 1 at least, like we discussed
    earlier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation systems, targeted advertising, and marketing everything can be
    built upon the results obtained from market basket analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These decisions if made at the right place and right time can help the retailers
    immensely in boosting their sales and making good profits.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a solid grasp of what market basket analysis actually does
    and how it works, we will start by building a simple algorithm for our first technique,
    where we make product recommendations using a product contingency matrix based
    on top trending products purchased in a supermarket, and then move on to building
    more sophisticated analyzers and recommenders using powerful machine learning
    capabilities of the R language.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating a product contingency matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be doing a couple of things here. First, we will analyze a small toy
    dataset belonging to a supermarket, by using a product contingency matrix of product
    pair purchases based on their frequency. Then we will move on to contingency matrices
    based on other metrics such as support, lift, and so on by using another dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data for our first matrix consists of the six most popular products sold
    at the supermarket and also the number of times each product was sold by itself
    and in combination with the other products. We have the data in the form of a
    data table captured in a `csv` file, as you can see in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluating a product contingency matrix](img/00088.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: To analyze this data, we first need to understand what it depicts. Basically,
    each cell value denotes the number of times that product combination was sold.
    Thus, the cell combination `(1, A)` denotes the product combination `(milk, milk)`,
    which is basically the number of times milk was bought. Another example is the
    cell combination `(4, C)` which is analogous to cell combination `(3, D)` which
    indicates the number of times bread was bought along with butter. This is also
    often known as a contingency matrix and in our case it is a product contingency
    matrix since it deals with product data. Let us follow our standard machine learning
    pipeline of getting the data, analyzing it, running it on our algorithm, and getting
    the intended results.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting the data](img/00089.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Analyzing and visualizing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we will do some exploratory analysis of the dataset to see what kind
    of story the data tells us. For that, we will first look at the transactions related
    to buying milk and bread in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Thus, you can see that just by sorting the data columns we are able to see the
    top products which were bought in combination with bread or with milk. When recommending
    top products to buy from the matrix, we will remove the product from the recommendation
    list if that product is in the shopping cart already, because, if I buy bread,
    it makes no sense to recommend bread to me. Now, we will visualize the complete
    dataset using a mosaic plot. Do note that the product combinations which were
    bought very frequently will have high frequency values and will be indicated by
    a significant area in the mosaic plot.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The code generates the following mosaic plot where we apply a gradient using
    the color parameter and specify that axis labels be at right angles to the axis
    using the `las` parameter to make a cleaner plot.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing and visualizing the data](img/00090.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding plot you can note that it is now very easy to see which products
    were bought a large number of times in combination with another product. Ignoring
    the same product row and column values, we can easily deduce that product combinations
    such as beer and diapers were bought very frequently!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The background story about our beer – diapers combination was actually discovered
    by Walmart sometime back when they analyzed customer transactional data to find
    that, on Fridays, young American dads tend to buy beer and diapers together. They
    would celebrate the weekend with their friends but, having fathered an offspring,
    they also carried out essential duties of taking care of their children's needs.
    In fact, Walmart placed beer and diapers side by side in stores and their sales
    went up significantly! This is the power of analytics and machine learning which
    enables us to find out unknown and unexpected patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Global recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we will recommend products based on the product chosen by a customer in
    his shopping cart. Do note that we mention this as global recommendations because
    these product recommendations are neither based on association rules or frequent
    itemsets that we will be exploring after this. They are purely based on the global
    product contingency matrix of product pair purchase counts. The following code
    snippet enables us to recommend the top two suggested products for each item from
    the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Thus you can see that, based on the product pair purchases from the contingency
    matrix, we get the top two products which people would tend to buy, based on the
    global trends captured in that matrix. Now we will look at some more ways to generate
    more advanced contingency matrices based on some other metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced contingency matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Until now we have just used product contingency matrices based on product purchase
    frequencies. We will now look at creating some more contingency matrices using
    metrics such as support and lift, which we talked about earlier, since they are
    better indicators for items which have a probability of being purchased together
    by customers when shopping. For this we will be using the package `arules` available
    in the **Comprehensive R Archive Network** (**CRAN**) repositories. You can download
    it if not present using the `install.packages('arules')` command. Once it is installed,
    we will look at a standard grocery based transactional log database and build
    the contingency matrices using the standard machine learning methodology that
    we used in the previous chapters to work on any dataset or problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will start by loading the required package and the data into our
    workspace and looking at what the transactional data looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Each preceding transaction is a set of products which were purchased together,
    just as we had discussed in the previous sections. We will now build several contingency
    matrices on different matrices and view the top five product pairs which customers
    would be interested in buying together. The following code snippet shows us a
    count based product contingency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Advanced contingency matrices](img/00091.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here we see a similar matrix to what we had worked with earlier. Now we will
    create a support based product contingency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Advanced contingency matrices](img/00092.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Finally, we look at another matrix based on the metric lift which we discussed
    earlier. If you remember, the higher the value of lift, if greater than 1, the
    stronger the chance of both products being bought together by customers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Advanced contingency matrices](img/00093.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding matrix, you can get such insights as that people tend to
    buy yoghurt and whole milk together, or that soda and whole milk do not really
    go together since it has a lift value less than `1`. These kinds of insights help
    in planning product placement in stores and shopping websites for better sales
    and recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, some of the main issues with this model are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: High number of products leads to a huge matrix which is difficult to work with
    since it needs more time and space to process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can detect pairs of items in frequent itemsets only for recommendations. It
    is possible to find out combinations of more than two items from this model but
    that needs additional logic related to set theory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Faces the cold start problem, typically known in recommender engines, which
    happens when a new product is launched and we cannot predict recommendations or
    how it will sell in the market since our historical data does not have any information
    associated with it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequent itemset generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now look at a better technique to find patterns and detect frequently
    bought products. For this, we will be using the frequent itemset generation technique.
    We will be implementing this algorithm from scratch because, even though when
    we solve any machine learning or optimization problem we usually use readymade
    machine learning algorithms out of the box which are optimized and available in
    various R packages, one of the main objectives of this book is to make sure we
    understand what exactly goes on behind the scenes of a machine learning algorithm.
    Thus, we will see how we can build some of these algorithms ourselves using the
    principles of mathematics, statistics, and logic.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data we will be using for this is the `shopping_transaction_log.csv` dataset
    which we used to explain the concepts of market basket analysis at the beginning
    of the chapter. The code we will be using for this section is available in the
    `ch3_frequent` itemset `generation.R` file. We will first go through all the functions
    and then define the main function which utilizes all the helper functions to define
    a workflow for frequent itemset generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by loading some library dependencies and utility functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Data retrieval and transformation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we will define the functions for getting the data and transforming it
    into the required format of a data frame consisting of products and purchase frequency.
    We also have a function to prune this data frame if we want to remove products
    below a certain purchase frequency threshold.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Building an itemset association matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we will implement three functions to help us build the itemset association
    matrix. We start with building the first function, which returns us different
    unique itemset combinations from the list of items in our transactional dataset
    based on the number of items in each itemset passed as a parameter. This helps
    us in getting itemsets of a particular count.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The following function builds a frequency contingency table showing the occurrence
    of each itemset in each transaction from the dataset. This forms the basis of
    getting the data for building our frequent itemsets. The itemset association matrix
    shows on a high level the occurrence of the different unique itemsets generated
    in the previous function per transaction in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the itemset association matrix, we use it in the following function,
    to sum up these individual itemset occurrences to get the total occurrence of
    each itemset in the whole dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Creating a frequent itemsets generation workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we will define the function which will utilize all the previous functions
    to create a workflow for generating the frequent itemsets. The main parameters
    we will be taking here include `data.file.path` which contains the location of
    the dataset, `itemset.combination.nums` which denotes the number of items which
    should be in each itemset, `item.min.freq` which denotes the minimum purchase
    count threshold of each item, and `minsup` which tells us the minimum support
    for the generated frequent itemsets.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Detecting shopping trends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now it's time to test our algorithm! We will first generate all the frequent
    itemsets that have two items where each item has been purchased at least three
    times in the overall dataset and have a minimum support of at least 20%. To do
    this, you will have to fire up the following function in the R console. Do remember
    to load all the previous functions in memory first.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We get the following itemset contingency matrix, which is used to generate the
    frequent itemsets. The left side rows indicate the transactions and each column
    represents an itemset.
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting shopping trends](img/00094.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The final frequent itemsets will be shown both in the console and in the plot
    section in the form of a pretty table, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting shopping trends](img/00095.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Thus, you can clearly see that the itemset `{beer, diapers}` is our most frequent
    itemset with a support of approximately `67%`, which has occurred six times in
    total in our dataset, and the association matrix shows you the exact transactions
    where it has occurred. Thus, this function detects a trend of people buying beer
    and diapers or diapers and milk more frequently, and thus we can recommend people
    the same when they are shopping. We will also take a look at the frequent itemsets
    containing three items next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following table showing the frequent itemsets with their
    necessary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting shopping trends](img/00096.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Thus we see that we get two frequent itemsets with support greater than 20%.
    Of course remember that this is a small dataset and the bigger the dataset you
    have containing purchase transactions, the more patterns you will get with stronger
    support.
  prefs: []
  type: TYPE_NORMAL
- en: We have successfully built an algorithm for generating frequent itemsets! You
    can use this same algorithm on new datasets to generate more and more frequent
    itemsets and then we can start recommending products for people to purchase as
    soon as we see them buying one or more items from any of the frequent itemsets.
    A simple example would be if we see people buying beer, we can recommend diapers
    and milk to them since that shopping trend was detected by our algorithm in the
    frequent itemsets earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Association rule mining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now be implementing the final technique in market basket analysis for
    finding out association rules between itemsets to detect and predict product purchase
    patterns which can be used for product recommendations and suggestions. We will
    be notably using the Apriori algorithm from the `arules` package which uses an
    implementation for generating frequent itemsets first, which we discussed earlier.
    Once it has the frequent itemsets, the algorithm generates necessary rules based
    on parameters such as support, confidence, and lift. We will also show how you
    can visualize and interact with these rules using the `arulesViz` package. The
    code for this implementation is in the `ch3_association` rule `mining.R` file
    which you can directly load and follow the book.
  prefs: []
  type: TYPE_NORMAL
- en: Loading dependencies and data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will first load the necessary package and data dependencies. Do note that
    we will be using the `Groceries` dataset which we discussed earlier in the section
    dealing with advanced contingency matrices.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Exploratory analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will do some basic exploratory analysis on our dataset here, to see what
    kind of data we are dealing with and what products are the most popular among
    the customers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploratory analysis](img/00097.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![Exploratory analysis](img/00098.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Detecting and predicting shopping trends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will be generating association rules now using the Apriori algorithm, which
    we talked about earlier, to detect shopping trends so that we can predict what
    customers might buy in the future and even recommend it to them. We will start
    off with a normal workflow for generating association rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting and predicting shopping trends](img/00099.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The way to interpret these rules is that you observe the items on the LHS and
    the items on the RHS, and conclude that if a customer has the item(s) from the
    LHS in his shopping cart, there is a chance of him also buying the item(s) on
    the RHS. This chance can be quantified using the metrics which are present in
    the remaining columns. We have discussed the significance of these metrics in
    the concepts of market basket analysis. From the previous rules, we can say that
    there is a 73.3% confidence that if a customer buys honey, he will also buy whole
    milk. From the previous rules, we see a trend that items such as honey, cocoa,
    pudding, and cooking chocolate all need milk as an essential ingredient, which
    might explain why people tend to buy that together with these products and we
    can recommend that to the customers. Feel free to tune the parameters for lift,
    support, and confidence to extract more rules from the dataset to get more and
    more patterns!
  prefs: []
  type: TYPE_NORMAL
- en: 'Often the rules generated by the Apriori algorithm have duplicate association
    rules which need to be removed before we examine the set of rules. You can do
    the same using the following utility function on the generated rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: There are also ways to sort rules by specific metrics to see the rules with
    the best quality. We will look at the best rules using the previous metric parameter
    values sorted by the best confidence values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting and predicting shopping trends](img/00100.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We see itemsets in the previous rules like `{ rice, sugar }`, which have a
    strong tendency to be purchased along with `{ whole milk }`. The confidence values
    are pretty high (and they should be since we sorted them!) of 100% and the lift
    is also greater than 1, indicating a positive association between the itemsets.
    Do note that in large datasets, the support values may not be very high and that
    is perfectly normal because we are searching some specific patterns in the whole
    transaction dataset which may not even cover 1% of the total transactions present
    due to the varied type of transactions. However, it is extremely important for
    us to detect these patterns to make informed decisions about predicting what products
    might get sold together and recommending them to the customers. We will next look
    at another example of showing the best quality rules sorted by lift:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting and predicting shopping trends](img/00101.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We see that these rules have really high lift and good confidence too making
    them items which customers would tend to buy together the most!
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now look at detecting specific shopping patterns which we discussed
    earlier. One way to do this is to target specific items and generate association
    rules containing those items explicitly. The first way is to predict what items
    the customers might have in their shopping cart if they have bought an item on
    the RHS of association rules. We do this by specifying the item explicitly as
    shown next and analyze the transactional dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting and predicting shopping trends](img/00102.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It is interesting to note that people tend to buy beverages together, such as
    coffee, water, beer, and other miscellaneous beverages along with soda from the
    previous rules. Thus you can see that it is quite easy to predict when the users
    might buy soda using these rules and take action accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also predict what items the users are going to buy if they have already
    put some specific items in their shopping cart, by explicitly setting specific
    itemset values on the LHS of the association rules using the following technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting and predicting shopping trends](img/00103.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: You can clearly see from the previous rules that people tend to buy milk if
    they have yogurt and sugar in their shopping cart together or individually. Thus,
    by targeting specific itemsets, you can offer specific product based recommendations
    to the customers.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing association rules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is an excellent package, `arulesViz` which provides an interactive way
    to visualize the association rules and interact with them. Following is a sample
    visualization for the preceding association rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This visualization generated by `arulesViz` is completely interactive and you
    can play around with the vertices and edges, and place the itemsets according
    to your desire to find more and more trends and patterns from various rules.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our discussion on the main techniques which are being used in
    market basket analysis to detect and predict trends from shopping transaction
    logs and take actions accordingly from the derived insights.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered a lot of ground! We started with a discussion about
    how trends are detected and predicted in the retail vertical. Then we dived into
    what market basket analysis really means and the core concepts, mathematical formulae
    underlying the algorithms, and the critical metrics which are used to evaluate
    the results obtained from the algorithms, notably, support, confidence, and lift.
    We also discussed the most popular techniques used for analysis, including contingency
    matrix evaluation, frequent itemset generation, and association rule mining. Next,
    we talked about how to make data driven decisions using market basket analysis.
    Finally, we implemented our own algorithms and also used some of the popular libraries
    in R, such as `arules`, to apply these techniques to some real world transactional
    data for detecting, predicting, and visualizing trends. Do note that these machine
    learning techniques only talk about product based recommendations purely based
    on purchase and transactional logs. The human element is missing here since we
    don't take into account the likes and dislikes based on user purchase or ratings.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be tackling some of these very problems and building
    robust recommendation engines for recommending products taking into account products
    as well as user interests.
  prefs: []
  type: TYPE_NORMAL
