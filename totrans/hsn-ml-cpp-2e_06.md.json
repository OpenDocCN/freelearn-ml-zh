["```py\nvoid PCAReduction(const std::vector<Matrix> &data, double target_dim) {\n  // instantiante the PCA algorithm object.\n  Dlib::vector_normalizer_pca<Matrix> pca;\n  // train the PCA algorithm\n  pca.train(data, target_dim / data[0].nr());\n  // apply trained algorithm to the new data\n  std::vector<Matrix> new_data;\n  new_data.reserve(data.size());\n  for (size_t i = 0; i < data.size(); ++i) {\n    new_data.emplace_back(pca(data[i]));\n  }\n  // example how to get transformed values\n  for (size_t r = 0; r < new_data.size(); ++r) {\n    Matrix vec = new_data[r];\n    double x = vec(0, 0);\n    double y = vec(1, 0);\n  }\n```", "```py\nvoid PCACompression(const std::string& image_file, long target_dim) {\n  array2d<Dlib::rgb_pixel> img;\n  load_image(img, image_file);\n  array2d<unsigned char> img_gray;\n  assign_image(img_gray, img);\n  save_png(img_gray, \"original.png\");\n  array2d<DataType> tmp;\n  assign_image(tmp, img_gray);\n  Matrix img_mat = Dlib::mat(tmp);\n  img_mat /= 255.;  // scale\n  std::cout << \"Original data size \" << img_mat.size() <<\n  std::endl;\n```", "```py\nstd::vector<Matrix> data;\nint patch_size = 8;\nfor (long r = 0; r < img_mat.nr(); r += patch_size) {\n  for (long c = 0; c < img_mat.nc(); c += patch_size) {\n    auto sm =\n      Dlib::subm(img_mat, r, c, patch_size, patch_size);\n      data.emplace_back(Dlib::reshape_to_column_vector(sm));\n  }\n}\n```", "```py\n// normalize data\nauto data_mat = mat(data);\nMatrix m = mean(data_mat);\nMatrix sd = reciprocal(sqrt(variance(data_mat)));\nmatrix<decltype(data_mat)::type, 0, 1,\n       decltype(data_mat)::mem_manager_type>\n    x(data_mat);\nfor (long r = 0; r < x.size(); ++r)\n    x(r) = pointwise_multiply(x(r) - m, sd);\n```", "```py\nMatrix temp, eigen, pca;\n// Compute the svd of the covariance matrix\nDlib::svd(covariance(x), temp, eigen, pca);\nMatrix eigenvalues = diag(eigen);\nrsort_columns(pca, eigenvalues);\n// leave only required number of principal components\npca = trans(colm(pca, range(0, target_dim)));\n```", "```py\n// dimensionality reduction\nstd::vector<Matrix> new_data;\nsize_t new_size = 0;\nnew_data.reserve(data.size());\nfor (size_t i = 0; i < data.size(); ++i) {\n  new_data.emplace_back(pca * data[i]);\n  new_size += static_cast<size_t>(new_data.back().size());\n}\nstd::cout << \"New data size \"\n          << new_size + static_cast<size_t>(pca.size())\n          << std::endl;\n```", "```py\nauto pca_matrix_t = Dlib::trans(pca);\nMatrix isd = Dlib::reciprocal(sd);\nfor (size_t i = 0; i < new_data.size(); ++i) {\n    Matrix sample = pca_matrix_t * new_data[i];\n    new_data[i] = Dlib::pointwise_multiply(sample, isd) + m;\n}\n```", "```py\nsize_t i = 0;\n    for (long r = 0; r < img_mat.nr(); r += patch_size) {\n        for (long c = 0; c < img_mat.nc(); c += patch_size)\n        {\n            auto sm = Dlib::reshape(new_data[i],\n                patch_size, patch_size);\n                Dlib::set_subm(img_mat, r, c, patch_size,\n                    patch_size) = sm;\n                    ++i;\n        }\n    }\n    img_mat *= 255.0;\n    assign_image(img_gray, img_mat);\n    equalize_histogram(img_gray);\n    save_png(img_gray, \"compressed.png\");\n}\n```", "```py\nvoid LDAReduction(const Matrix &data,\n                  const std::vector<unsigned long> &labels,\n                  unsigned long target_dim) {\n  Dlib::matrix<DataType, 0, 1> mean;\n  Matrix transform = data;\n  // Apply LDA on input data,\n  // result with will be in the \"transform object\"\n  Dlib::compute_lda_transform(transform, mean, labels,\n                              target_dim);\n  // Apply LDA \"transform\" to the input \"data\"\n  for (long r = 0; r < data.nr(); ++r) {\n    Matrix row =\n        transform * Dlib::trans(Dlib::rowm(data, r)) - mean;\n    double x = row(0, 0);\n    double y = row(1, 0);\n  }\n}x`\n```", "```py\ntransform * Dlib::trans(Dlib::rowm(data, r))\n```", "```py\nvoid SammonReduction(const std::vector<Matrix> &data, long target_dim) {\n  Dlib::sammon_projection sp;\n  auto new_data = sp(data, target_dim);\n  for (size_t r = 0; r < new_data.size(); ++r) {\n    Matrix vec = new_data[r];\n    double x = vec(0, 0);\n    double y = vec(1, 0);\n  }\n}\n```", "```py\nvoid Reduction(tapkee::ParametersSet parameters,\n               bool with_kernel,\n               const tapkee::DenseMatrix& features,\n               const tapkee::DenseMatrix& lables,\n               const std::string& img_file) {\n  using namespace tapkee;\n  // define the kernel callback object,\n  // that will be applied to the input \"features\"\n  gaussian_kernel_callback kcb(features, 2.0);\n  // define distance callback object,\n  // that will be applied to the input \"features\"\n  eigen_distance_callback dcb(features);\n  // define the feature access callback object\n  eigen_features_callback fcb(features);\n  // save the initial features indices order\n  auto n = features.cols();\n  std::vector<int> indices(n);\n  for (int i = 0; i < n; ++i) indices[i] = i;\n  TapkeeOutput result;\n  if (with_kernel) {\n    // apply feature transformation with kernel function\n    result =\n        initialize()\n            .withParameters(parameters)\n            .withKernel(kcb)\n            .withFeatures(fcb)\n            .withDistance(dcb)\n            .embedRange(indices.begin(), indices.end());\n  } else {\n    // apply features transformation without kernel\n    // //function\n    result =\n        initialize()\n            .withParameters(parameters)\n            .withFeatures(fcb)\n            .withDistance(dcb)\n            .embedRange(indices.begin(), indices.end());\n  }\n  // create helper object for transformed data\n  // //visualization result\n  Clusters clusters;\n  for (index_t i = 0; i < result.embedding.rows(); ++i) {\n    // get a transformed feature\n    auto new_vector = result.embedding.row(i);\n    // populate visualization helper structure\n    auto label = static_cast<int>(lables(i));\n    clusters[label].first.push_back(new_vector[0]);\n    clusters[label].second.push_back(new_vector[1]);\n  }\n  // Visualize dimensionality reduction result\n  PlotClusters(clusters,\n               get_method_name(parameters[method]),\n               img_ file);\n}\n```", "```py\ninitialize().\nwithParameters(parameters).\nwithKernel(kcb).\nwithFeatures(fcb).\nwithDistance(dcb).\nembedRange(indices.begin(), indices.end());\n```", "```py\nbool with_kernel = false;\nReduction((method = PCA, target_dimension = target_dim),\n          with_kernel, input_data, labels_data,\n          \"pca-tapkee.png\");\n```", "```py\nstruct gaussian_kernel_callback {\n  gaussian_kernel_callback(\n      const tapkee::DenseMatrix& matrix,\n      tapkee::ScalarType gamma)\n      : feature_ matrix(matrix), gamma(gamma){};\n  inline tapkee::ScalarType kernel(\n      tapkee::IndexType a, tapkee::IndexType b) const {\n    auto distance =\n        (feature_matrix.col(a) – feature_matrix.col(b))\n            .norm();\n    return exp(-(distance * distance) * gamma);\n  }\n  inline tapkee::ScalarType operator()(\n      tapkee::IndexType a, tapkee::IndexType b) const {\n    return kernel(a, b);\n  }\n  const tapkee::DenseMatrix& feature_matrix;\n  tapkee::ScalarType gamma{1};\n}\n```", "```py\nbool with_kernel = true;\nReduction((method = KernelPCA, target_dimension = target_dim), \n                      with_kernel, input_data, labels_data,\n                      \"kernel-pca-tapkee.png\");\n```", "```py\nReduction((method = MultidimensionalScaling,\n                    target_dimension = target_dim),\n           false, input_data, labels_data, \"mds-tapkee.png\";\n```", "```py\nReduction((method = Isomap, target_dimension = target_dim,\n                            num_neighbors =100),\n           false, input_data, labels_data, \"isomap-tapkee.png\");\n```", "```py\nReduction((method = FactorAnalysis,\n           target_dimension = target_dim,\n           fa_epsilon = 10e-5, max_iteration = 100),\n          false, input_data, labels_data,\n          \"isomap-tapkee.png\");\n```", "```py\nReduction((method = tDistributedStochasticNeighborEmbedding,\n           target_dimension = target_dim,\n           sne_perplexity = 30),\n          false, input_data, labels_data,\n          \"tsne-tapkee.png\");\n```"]