- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hypothesis Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will begin discussing drawing statistical conclusions from
    data, putting together sampling and experiment design from [*Chapter 1*](B18945_01.xhtml#_idTextAnchor015)*,
    Sampling and Generalization* and distributions from [*Chapter 2*](B18945_02.xhtml#_idTextAnchor029)*,
    Distributions of Data*. Our primary use of statistical modeling is to answer questions
    of interest from data. Hypothesis testing provides a formal framework for answering
    questions of interest with measures of uncertainty. First, we will cover the goals
    and structure of hypothesis testing. Then, we will talk about the errors that
    can occur from hypothesis tests and define the expected error rate. Then, we will
    walk through the hypothesis test process utilizing the z-test. Finally, we will
    discuss statistical power analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The goal of hypothesis testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type I and type II errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basics of the z-test – the z-score, z-statistic, critical values, and p-values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One-sample and two-sample z-tests for means and proportions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting error rate and power analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the power analysis to the z-test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The goal of hypothesis testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Put simply, the goal of hypothesis testing is to decide whether the data we
    have is sufficient to support a particular hypothesis. The hypothesis test provides
    a *formal* framework for testing a hypothesis based on our data rather than attempting
    to decide based on visual inspection. In this section, we will discuss the process
    of hypothesis testing. In the next section, *Basics of the z-test – the z-score,
    z-statistic, critical values, and p-values*, we will put the process to work by
    walking through an example in detail with the z-test.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of a hypothesis test for the mean
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the hypothesis testing process, let’s start with a simple example.
    Suppose we have a factory with machines that produce widgets, and we expect our
    machines to produce widgets at a certain rate (30 widgets per hour). We start
    by constructing two hypotheses, the **null hypothesis** and the **alternative
    hypothesis**. The null hypothesis and alternative hypothesis are given the following
    symbols, respectively: H 0 and H a. To create the null hypothesis, we will start
    by assuming what we want to test is true. In our example, the null hypothesis
    would be that *the machines output a mean of 30 widgets per hour*. Once we have
    determined the null hypothesis, we then create the alternative hypothesis, which
    is just the contradiction of the null hypothesis. In our example, the alternative
    hypothesis is that *the machines do not output a mean of 30 widgets per hour*.
    Notice that our hypotheses do not indicate any directionality, that is, the alternative
    hypothesis contains values both less than and greater than the expected value.
    This is called a **two-sided test**, meaning there are two alternatives to the
    null hypothesis. We also have **one-sided tests**. For example, if we had said
    the null hypothesis was that *the machines output more than a mean of 30 widgets
    per hour*, the alternative would be that *the machines output less than a mean
    of 30 widgets per hour*. This set of hypotheses would be a one-sided test.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The two-sided null hypothesis and alternative hypothesis from our example can
    be stated mathematically as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 :  _ x  = 30'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a :  _ x  ≠ 30'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have the null and alternative hypotheses and the data, we will run
    the test with software. Let’s set the implementation details of the test aside
    for now (these will be covered in detail in the next section). There are two possible
    outcomes of a statistical test: reject the null hypothesis or fail to reject the
    null hypothesis. If the mean output of our machines is statistically different
    from the stated value in the null hypothesis, then we will *reject the null hypothesis*.
    This means that, given the data, the value stated in the null hypothesis is not
    a *plausible* value for the mean. However, if the mean output of our machines
    is not statistically different from the value listed in the null hypothesis, we
    *fail to reject the null hypothesis*. This means that, given the data, the value
    stated in the null hypothesis is a *plausible* value for the mean. After running
    the test for the null hypothesis and determining the conclusion, we will provide
    a confidence interval (discussed in the next section) and determine the scope
    of inference.'
  prefs: []
  type: TYPE_NORMAL
- en: Scope of inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The scope of inference is determined by the sampling design discussed in [*Chapter
    1*](B18945_01.xhtml#_idTextAnchor015). There are two questions to consider – *what
    is the population, and how was the sample selected from the population?* In this
    example, let’s assume that we are testing the mean output of machines from a large
    factory (possibly hundreds of machines). The population is then the machines in
    the factory. If we take a random sample of machines, then our conclusion can be
    extrapolated to the entire population.
  prefs: []
  type: TYPE_NORMAL
- en: While our current example is realistic, it is rather simple. In other scenarios,
    there may be additional considerations. For example, the machines in the factory
    may have different models and different ages, which may impact output. In that
    case, we could use stratified random sampling and make inferences for each stratum.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis test steps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section provides an overview of hypothesis testing from creating a hypothesis
    to drawing a conclusion. As we continue through this chapter, keep the following
    key hypothesis test steps in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: State the null hypothesis and alternative hypothesis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform the statistical test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Determine the conclusion: reject or fail to reject the null hypothesis'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide a statistical conclusion, a confidence interval, and a scope of inference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These steps are applicable to any statistical test, and we will continue to
    follow this series of steps for hypothesis tests. In the next section, we will
    discuss the types of errors that can result from hypothesis tests.
  prefs: []
  type: TYPE_NORMAL
- en: Type I and Type II errors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While data can give us a good idea of the characteristics of a distribution,
    it is possible for a hypothesis test to result in an error. Errors can occur because
    we are taking a random sample from a population. While randomization makes it
    less likely that a sample contains sampling bias, *there is no guarantee that
    a random sample will be representative of the population*. There are two possible
    errors that could occur as a result of a hypothesis test:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Type I error**: Rejecting the null hypothesis when it is actually true'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Type II error**: Failure to reject the null hypothesis when it is actually
    false'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type I errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A type I error occurs when a hypothesis test results in *rejecting the null
    hypothesis, but the null hypothesis is actually true*. For example, say we have
    a distribution of data with a population mean of 30\. We state our null hypothesis
    as H 0 :  _ x  = 30\. We take a random sample for our test, but the random values
    in the sample happen to be on the higher side of the distribution. Thus, the test
    result suggests that we should reject the null hypothesis. In this case, we have
    made a type I error. This type of error is also called a **false positive**.'
  prefs: []
  type: TYPE_NORMAL
- en: When we make statistical tests, it is always possible that we will come to an
    incorrect conclusion due to the data sampled from the target population. The *probability
    of making a type one error is specified by* α. Said another way, α represents
    how often we expect to make an error (the expected error rate). This is a free
    parameter we can select for our test (α is also called the *level of significance*).
    It is common to use 0.05 for α, but there is no evidential basis for using 0.05;
    different values may be appropriate in other contexts. Later in the chapter, we
    will discuss selecting the type I error rate.
  prefs: []
  type: TYPE_NORMAL
- en: Type II errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The other type of error we can make is called a type II error. In this case,
    *we fail to reject the null hypothesis when it is actually false*. Let’s consider
    another example. Say we have a distribution of data and we want to test whether
    the mean of the distribution is 30 or not. We take a random sample for the test
    and the test suggests that we should not reject the null hypothesis. However,
    the true population mean is 35\. In this case, we have made a type II error. This
    type of error is also called a **false negative**.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, it is always possible that a statistical test could
    lead to an erroneous conclusion. Thus, we want to control the probability of making
    an error. However, unlike α, the Type II error rate β is not simply a free parameter
    that we can select. To understand the likeliness of making a type II error, we
    generally will conduct a power analysis, which will show how various factors,
    such as sample size, will impact the type II error rate. In the next section,
    we will discuss selecting the error rate and power analysis.
  prefs: []
  type: TYPE_NORMAL
- en: We can summarize the possible results of a hypothesis test with the help of
    the table in *Figure 3**.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | Null Hypothesis is: |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | True | False |'
  prefs: []
  type: TYPE_TB
- en: '| Decision about Null Hypothesis | Don’t Reject | Correct Inference(1- α) |
    Type II Error(β) |'
  prefs: []
  type: TYPE_TB
- en: '| Reject | Type I Error(α) | Correct Inference(1-β) |'
  prefs: []
  type: TYPE_TB
- en: Figure 3.1 – Results of the hypothesis test
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have discussed the types of errors that can occur when drawing
    conclusions from statistical tests. In the next section, we will walk through
    an example of hypothesis testing with the z-test and later in the chapter, we
    will discuss how to select an error rate and how to analyze statistical power
    and related factors.
  prefs: []
  type: TYPE_NORMAL
- en: Basics of the z-test – the z-score, z-statistic, critical values, and p-values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will discuss a type of hypothesis test called the z-test.
    It is a statistical procedure using sample data assumed to be normally distributed
    to determine whether a statistical statement related to the value of a population
    parameter should be rejected or not. The test can be performed on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: One sample (a left-tailed z-test, right-tailed z-test, or two-tailed z-test)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two samples (a two-sample z-test)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proportions (a one-proportion z-test or two-proportion z-test)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test assumes that the standard deviation is known and the sample size is
    large enough. In practice, a sample size that is larger than 30 should be considered.
  prefs: []
  type: TYPE_NORMAL
- en: Before going into different types of z-tests, we will discuss the z-score and
    z-statistic.
  prefs: []
  type: TYPE_NORMAL
- en: The z-score and z-statistic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To measure how far a particular value from a mean is, we could use the z-score
    or the z-statistic as statistical techniques together with the mean and the standard
    deviation to determine the relative location.
  prefs: []
  type: TYPE_NORMAL
- en: 'A z-score is computed with the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: z i =  x i −  _ x  _ σ
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, z i is the z-score for x i,  _ x  is the sample mean, and σ is the sample
    standard deviation. The z-score is also known as the z-value, standardized value,
    or standard score. Let’s consider a few examples. The standard deviation tells
    us how far a sample is from the mean of the distribution. If z i = 1.8, that point
    is 1.8 standard deviations away from the mean. Similarly if z i = − 1.5, then
    that point is 1.5 standard deviations away from the mean. The sign of the determines
    whether it is greater or less than the sample mean. A z i of -1.5 is less than
    the mean and a z i of 1.8 is greater than the mean. Now let us go through an example.
    In a high school in Dallas (in the US), we ask students to take anonymous IQ tests
    for some statistical research. The data collected from that school is normally
    distributed with an IQ score population mean μ = 98 and a population standard
    deviation σ = 12\. A particular student took an IQ test and his score is 110\.
    He has an IQ score greater than the score mean but he wants to know whether he
    is in the top 5%. First, we will use the z-score formula to calculate it:'
  prefs: []
  type: TYPE_NORMAL
- en: z student = 110 − 98 _ 12  = 12 _ 12 = 1.
  prefs: []
  type: TYPE_NORMAL
- en: The student can check a z-table (*Figure 3**.2*), for example, from the website
    [http://www.z-table.com](http://www.z-table.com), and get the value of 0.8413\.
    He is in the top 1-0.8413 = 0.1587 or 15.87% of his school IQ scores.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – z-table](img/B18945_03_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – z-table
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, we can use the **cumulative distribution function** (**CDF**) to
    calculate it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We also get the same value in Python as in the z-table check; it is 0.8413 for
    the z-score = 1 in this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example here is a simple random sample of 10 scores taken from the
    IQ survey:'
  prefs: []
  type: TYPE_NORMAL
- en: 90, 78, 110, 110, 99, 115, 130, 100, 95, 93
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute the z-score for each IQ score in the sample, we need to calculate
    the mean and the standard deviation of this sample and then apply the z-score
    formula. Fortunately, we can use the `scipy` library again as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We created an array of IQ scores called `IQ` and used `z-score` from `scipy.stats`
    to compute `z_score`. Finally, we created the following output DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Output DataFrame](img/B18945_03_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – Output DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: 'Before discussing the z-statistic, we will introduce the notion of sampling
    distributions. Going back to the last example, as a rule of thumb, we perform
    the process of selecting a simple random sample of 35 IQ scores from the pool
    of IQ scores of the high school repeatedly, as many times as needed for the study.
    We then compute the mean score of each sample, called  _ x . Because we have various
    samples selected, we also have various possible values of  _ x . The expected
    value of  _ x  is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: E( _ x ) = μ
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, μ is the population mean. σ  _ x  denotes the standard distribution of
     _ x . Practically, in many sampling situations, a population is relatively large
    compared to small sample sizes. Then, the standard deviation of  _ x  can be given
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: σ  _ x  =  σ _ √ _ n
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, σ is the population standard deviation and n is the sample size for finite
    or infinite populations such that the population is large and the sample size
    is small, relatively. Note that σ  _ x  is also called the standard error of the
    mean to help us determine how far the sample mean is from the population mean.
    Note that E( _ x ) = μ, independent of the sample size. Sample size and standard
    error are inversely correlated: when the sample size is increased, the standard
    error decreases. Since the sampling distribution of  _ x  is assumed to be normally
    distributed, the sample distribution is given by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: z  _ x  =  ‾ x  − μ _ σ  ‾ x  ￼
  prefs: []
  type: TYPE_NORMAL
- en: 'In hypothesis tests about a population mean, we use test statistics where its
    formula is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: z = z  _ x  =   _ x  − μ _ σ/ √ _ n
  prefs: []
  type: TYPE_NORMAL
- en: Here,  _ x  is the sample mean, μ is the population mean, σ is the population
    standard deviation, and n is the sample size.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the IQ test example again. The IQ score data has a mean μ = 98 and
    a standard deviation σ = 12\. Suppose the data is normally distributed. Let x
    be the score taken randomly from the IQ data. What is the probability that x is
    between 95 and 104? We will compute the z-scores when x = 95 and x = 104 as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: z 95 =  95 − 98 _ 12  = − 0.25,
  prefs: []
  type: TYPE_NORMAL
- en: z 100 =  104 − 98 _ 12  = 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the probability that the taken score is between 95 and 104 is:'
  prefs: []
  type: TYPE_NORMAL
- en: P(95 < x < 104) = P(− 0.25 < z < 0.5) = 0.6915 − 0.4013 = 0.2902.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the probability is about 29.02% that an IQ score taken at random from
    the data is between 95 and 104\. We also can get the values from a z-table as
    follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – z-table](img/B18945_03_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – z-table
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – z-table](img/B18945_03_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – z-table
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, we can implement the code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Another question raised is what is the probability that the mean score  _ x 
    of four scores taken randomly is between 95 and 104? To solve this question, we
    use the notion of the z-statistic. We assume the mean of  _ x  is also 98 and
     _ x  has a normal distribution. Then, the standard error of  _ x  is:'
  prefs: []
  type: TYPE_NORMAL
- en: σ  _ x  =  σ _ √ _ n   =  12 _ √ _ 4   = 6,
  prefs: []
  type: TYPE_NORMAL
- en: 'then:'
  prefs: []
  type: TYPE_NORMAL
- en: z =   _ x  − μ  _ x  _ σ  _ x   =   _ x  − 98 _ 6 .
  prefs: []
  type: TYPE_NORMAL
- en: 'It is easy to calculate z 95 = − 0.5 and z 104 = 1\. By using the z-table,
    we can get the probability that the mean score  _ x  of six scores taken randomly
    is between 95 and 104 as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 0.8413 – 0.3085 = 0.5328
  prefs: []
  type: TYPE_NORMAL
- en: 'Or, about 53.28%. To use this idea, we can implement the code in Python as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that in the preceding code, we also need the library called `math` for
    calculating the square root function, `math.sqrt()`.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will discuss a z-test for means.
  prefs: []
  type: TYPE_NORMAL
- en: A z-test for means
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this part, one-sample and two-sample z-tests related to a population mean
    or means of two populations respectively are considered.
  prefs: []
  type: TYPE_NORMAL
- en: A one-sample z-test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A selected sample for research from a population should be normally distributed.
    The population standard deviation is supposed to be known, at least for practical
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: This test is still applicable in cases where the population cannot be assumed
    to be normally distributed but the sample size needs to be considered large enough
    by a rule of thumb, based on the experiences of researchers involved in the study.
    To perform the hypothesis testing, we need to develop the null and alternative
    hypotheses. The following figure illustrates three null and alternative hypotheses
    corresponding to left-tailed, right-tailed, and two-tailed z-tests.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Left-tailed, right-tailed, and two-tailed hypothesis tests](img/B18945_03_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – Left-tailed, right-tailed, and two-tailed hypothesis tests
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 : μ ≥ μ 0 H 0 : μ ≤ μ 0 H 0 : μ = μ 0'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a : μ < μ 0 H a : μ > μ 0 H a : μ ≠ μ 0'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to specify the level of significance, α, the probability of rejecting
    the null hypothesis when it is true. In other words, it is the probability of
    a type I error, aswe discussed in the last section. Then, we calculate the value
    of the test statistic. There are two approaches using a p-value or a critical
    value for the hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the p-value approach, we use the value of the test statistic to calculate
    a probability, denoted by the p-value, which takes on values as extreme as or
    more extreme than the test statistic derived from the sample. The smaller the
    p-value is, the more it indicates evidence against the null hypothesis, or in
    other words, the probability used to determine whether H 0 should be rejected.
    The rejection rule (reject H 0) is the p-value being less than or equal to the
    specified level of significance α in the research. In order to find the p-value
    based on the value of the test statistic in Python, we use the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `x` is the z-score. For example, we want to find the p-value associated
    with a z-score of -2.67 in a left-tailed test. The Python implementation is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be 0.0038\. Similar Python code is used in the case of a right-tailed
    test. For a two-tailed test, we need to multiply the value by 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The following figure illustrates the idea of how the p-value is computed in
    each type of test.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – p-values in hypothesis testing](img/B18945_03_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – p-values in hypothesis testing
  prefs: []
  type: TYPE_NORMAL
- en: The last step is to interpret the statistical conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, in the critical value approach, we will need to compute a
    critical value for the test statistic by using the level of significance. Critical
    values are the boundaries of the critical region where we can reject the null
    hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – Critical regions in hypothesis testing](img/B18945_03_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – Critical regions in hypothesis testing
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute the critical value in Python, we use the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `alpha` is the level of significance to be used. The following is the
    implementation of the code in Python for left-tailed, right-tailed, and two-tailed
    tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`The critical value` `is -1.6448536269514729`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The critical value` `is 1.6448536269514722`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The critical values are -1.959963984540054` `and 1.959963984540054`'
  prefs: []
  type: TYPE_NORMAL
- en: At the level of significance α = 0.05 for the left-tailed test, the critical
    value is about -1.64485\. Since this is a left-tailed test, if the test statistic
    is less than or equal to this critical value, we reject the null hypothesis. Similarly,
    for the right-tailed test, if the test statistic is greater than or equal to 1.64485,
    we reject the null hypothesis. For the two-tailed test, we reject the null hypothesis
    if the test statistic is greater than or equal to 1.95996 or less than or equal
    to -1.95996.
  prefs: []
  type: TYPE_NORMAL
- en: After determining whether to reject the null hypothesis, we interpret the statistical
    conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us discuss the IQ test scores again in the high school in Dallas. The IQ
    score data has a mean of μ = 98 and a standard deviation of σ = 12\. A researcher
    wants to know whether IQ scores will be affected by some IQ training. He recruits
    30 students and trains them to answer IQ questions 2 hours per day for 30 days
    and records their IQ levels after finishing the training period. The IQ scores
    of 30 students after the training section are 95, 110, 105, 120, 125, 110, 98,
    90, 99, 100,110, 112, 106, 92, 108, 97, 95, 99, 100, 100,103, 125, 122, 110, 112,
    102, 92, 97, 89, and 102\. Their average score is 104.17\. We can easily implement
    the calculation in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We define the null hypothesis and the alternative hypothesis:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 : μ after = μ = 98'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a : μ after > μ = 98'
  prefs: []
  type: TYPE_NORMAL
- en: 'We choose the level of significance α=0.05\. Previously, the critical value
    for the right-tailed test was 1.64485\. We now calculate the test statistic on
    the problem:'
  prefs: []
  type: TYPE_NORMAL
- en: z =   _ x  − μ _ σ/ √ _ n   =  104.17 − 98  _ 12/ √ _ 30   = 2.8162
  prefs: []
  type: TYPE_NORMAL
- en: 'It is implemented in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Since the test statistic value is 2.8162 > 1.64485, we reject the null hypothesis.
    This means that the training does affect the IQ levels of these students and helps
    them improve their IQ scores.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also can use the `ztest()` function from the `statsmodels` package (*Seabold,
    Skipper, and Josef Perktold, “statsmodels: Econometric and statistical modeling
    with python.” Proceedings of the 9th Python in Science Conference. 2010*) to perform
    one- or two-sample z-tests (which we will discuss in the next part). The syntax
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`x1`: The first of the two independent samples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x2`: The second of the two independent samples (if performing a two-sample
    z-test)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value`: In the one -sample case, `value` is the mean of `x1` under the null
    hypothesis. In the two-sample case, `value` is the difference between the mean
    of `x1` and the mean of `x2` under the null hypothesis. The test statistic is
    `x1_mean - x2_mean -` `value`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alternative`: The alternative hypothesis:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''two-sided''`: Two-sided test'
  prefs: []
  type: TYPE_NORMAL
- en: '`''larger''`: Right-tailed test'
  prefs: []
  type: TYPE_NORMAL
- en: '`''smaller''` : Left-tailed test'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Python code shows how we perform a one-sample z-test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The test statistic is 3.3975 and the p-value = 0.00034 < 0.05, where 0.05 is
    the level of significance. Therefore, we have enough evidence to reject the null
    hypothesis. This means that the training does affect the IQ levels of these students.
  prefs: []
  type: TYPE_NORMAL
- en: Two-sample z-test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We consider two normally distributed and independent populations. Let Ω be
    the hypothesized difference between two population means, μ 1 and μ 2\. Similarly,
    as in the case of the one-sample z-test, we have three forms for the null and
    alternative hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 : μ 1 − μ 2 ≥ Ω H 0 : μ 1 − μ 2 ≤ Ω H 0 : μ 1 − μ 2 = Ω'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a : μ 1 − μ 2 < Ω H a : μ 1 − μ 2 > Ω H a : μ 1 − μ 2 ≠ Ω'
  prefs: []
  type: TYPE_NORMAL
- en: 'In many problems, Ω = 0\. That means that for the case of the two-tailed test,
    the null hypothesis is zero, or in other words, μ 1 and μ 2 are equal. The test
    statistic for hypothesis tests is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: z =  (‾ x 1 − ‾ x 2) − Ω  ___________  √ _ σ 1 2 _ n 1  + σ 2 2 _ n 2
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, _ x 1 and _ x 2 are the sample means with the sample sizes n 1and n 2randomly
    taken from the two populations with the means μ 1 and μ 2, respectively. σ 1 and
    σ 2 are the standard deviations for these two populations. With two independent
    simple random samples, the point estimator _ x 1 − _ x 2 has a standard error
    given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: σ ‾ x 1−‾ x 2 = √ _  σ 1 2 _ n 1  +  σ 2 2 _ n 2
  prefs: []
  type: TYPE_NORMAL
- en: The distribution of _ x 1 − _ x 2 can be considered a normal distribution when
    the sample sizes are large enough. The step-by-step approach to the two-sample
    z-test hypothesis test is similar to that of the one-sample z-test.
  prefs: []
  type: TYPE_NORMAL
- en: Let us now consider an example. We study the IQ scores of students from two
    schools, named A and B, in Dallas, and we want to know whether the mean IQ levels
    for these two schools are different. A simple random sample of 30 students from
    each school is recorded.
  prefs: []
  type: TYPE_NORMAL
- en: A= [95,110, 105, 120, 125, 110, 98, 90, 99, 100,110, 112, 106, 92, 108, 97,
    95, 99, 100, 100, 103, 125, 122, 110, 112, 102, 92, 97, 89, 102]
  prefs: []
  type: TYPE_NORMAL
- en: B = [98, 90, 100, 93, 91, 79, 90, 100, 121, 89, 101, 98, 75, 90, 95, 99, 100,
    120, 121, 95,
  prefs: []
  type: TYPE_NORMAL
- en: 96, 89, 115, 99, 95, 121, 122, 98, 97, 97]
  prefs: []
  type: TYPE_NORMAL
- en: 'The null and alternative hypotheses are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 : μ 1 − μ 2 = 0'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a : μ 1 − μ 2 ≠ 0'
  prefs: []
  type: TYPE_NORMAL
- en: 'We choose the level of significance α=0.05\. In Python, by using the `ztest()`
    function of the `statsmodels` package, we perform the following calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we chose `alternative = 'two-sided'` related to the null
    and alternative hypotheses for the study. The test statistic and the p-value produced
    by the Python code are 1.757 and 0.079, respectively. Using a level of significance
    of 0.05, since the p-value > 0.05, we fail to reject the null hypothesis. In other
    words, we do not have enough evidence to show that the IQ mean scores between
    the students from the two schools are different.
  prefs: []
  type: TYPE_NORMAL
- en: z-test for proportions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can also test for differences in proportions. Let’s take a look at how to
    perform the z-test for proportions.
  prefs: []
  type: TYPE_NORMAL
- en: A one-proportion z-test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One-proportion z-tests are used to compare the difference between a sample
    proportion  _ p  and a hypothesized proportion p0\. Similarly, as in a z-test
    for means, we have three forms for the null and alternative hypotheses – left-tailed,
    right-tailed, and two-tailed tests:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 :  _ p  ≥ p 0 H 0 :  _ p  ≤ p 0 H 0 :  _ p  = p 0'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a :  _ p  < p 0 H a :  _ p  > p 0 H a :  _ p  ≠ p 0'
  prefs: []
  type: TYPE_NORMAL
- en: 'The test statistic is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: z =   _ p  − p 0 _____________  √ ___________ p 0(1 − p 0) _ n
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, *n* is the sample size. Let us consider an example. In a community college
    in Houston, a researcher wants to know whether students support some changes equal
    to 80%. He will use a one-proportion z-test at the level of significance α = 0.05\.
    To implement the code in Python, he can use `proportions_ztest` from the `statsmodel`
    library. The syntax is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`count`: The number of successes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nobs`: The number of trials or observations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value`: This is the value of the null hypothesis, equal to the proportion
    in the case of a one-sample test. In the case of a two-sample test, the null hypothesis
    is `prop[0] - prop[1] = value`, where `prop` is the proportion in the two samples.
    If not provided, `value` = 0, and the null hypothesis is `prop[0] = prop[1]`.`alternative`:
    The alternative hypothesis:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''two-sided''`: Two-sided test'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''larger''`: Right-tailed test'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''smaller''`: Left-tailed test'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The researcher gathers a sample of data with an observed sample proportion
    p = 0.84, the hypothesized population proportion p 0 = 0.8, and the sample size
    n = 500\. The null and alternative hypotheses are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 :  _ p  = p 0,'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a :  _ p  ≠ p 0.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will implement a one-proportion two-tailed z-test in Python to calculate
    the test statistic and p-value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The test statistic is -2.236067977499786 and the corresponding p-value is 0.0253473186774685\.
    Since the p-value < 0.05 (the level of significance), we reject the null hypothesis.
    There is enough evidence to suggest the proportion of students who support the
    changes is different from 0.8.
  prefs: []
  type: TYPE_NORMAL
- en: A two-proportion z-test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This test is used to test the difference between two population proportions.
    There are also three forms of the null and alternative hypotheses. The test statistic
    is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: z =  ‾ p 1 − ‾ p 2  ____________  √ _____________   _ p (1 −  _ p )( 1 _ n 1
    +  1 _ n 2)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, _ p 1 is a sample proportion for a simple random sample from population
    1 and _ p 2 is a sample proportion for a simple random sample from population
    2, n 1 and n 2 are the sample sizes, and  _ p  is the total pooled proportion,
    calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: _ p  =  n 1‾ p 1 + n 2‾ p 2 _ n 1 + n 2 .
  prefs: []
  type: TYPE_NORMAL
- en: 'We consider a similar example if there is a difference in the proportion of
    students from school A who support the changes compared to the proportion of students
    from school B. Here, n 1 = 100, n 2 = 100, _ p 1 = 0.8, and _ p 2 = 0.7\. You
    can use `proportions_ztest` from the `statsmodels` library (*Seabold, Skipper,
    and Josef Perktold, “statsmodels: Econometric and statistical modeling with python.”
    Proceedings of the 9th Python in Science Conference. 2010*) to perform the hypothesis
    test. Here, we will compute the p-value directly using the test statistic. The
    null and alternative hypotheses are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H 0 : _ p 1 = _ p 2 (The two population proportions are equal)'
  prefs: []
  type: TYPE_NORMAL
- en: 'H a : _ p 1 ≠ _ p 2 (The two population proportions are different)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we specify that the level of significance for the two-tailed test is
    α = 0.05\. We then calculate the test statistic and p-value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The test statistic is 1.633 and the p-value for a two-tailed test is 0.10\.
    Because the p-value is greater than the specified level of significance, 0.05,
    we fail to reject the null hypothesis. There is enough evidence to say that the
    proportion of students who support the changes is different between school A and
    school B.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the implemented Python code for the preceding calculation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we went through different important statistical notions such
    as the z-score, z-statistics, critical values, p-value, and z-test for means and
    proportions. We will discuss selecting the error rate and power analysis in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the error rate and power analysis
  prefs: []
  type: TYPE_NORMAL
- en: Statistics generalizes approximations around which to form acceptable conclusions
    from behaviors in data. Therefore, errors in statistics are unavoidable. The significance
    of findings from statistical models is essentially determined by the error rate.
    One method that can be used to minimize errors in modeling, especially with lower
    sample volumes, is the power test. Statistical power is the probability of correctly
    rejecting a null hypothesis, thus minimizing type II errors. Where alpha (*α*)
    is a type I error and beta (*β*) is a type II error, power’s formulation is *1
    – β*. To refresh, a type I error is the probability of incorrectly rejecting the
    null hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: As noted, power is more important with smaller samples because the law of large
    numbers typically helps minimize errors as the sample size increases if an appropriate
    sampling method is chosen. Power is also important when the differences being
    compared are relatively small. One scenario in which power analysis may be particularly
    useful is when sampling is expensive, for example, with human studies. Power analyses
    can be used to find an appropriate minimum sample size given the desired power,
    type I error rate, and effect size. The relationship between these parameters
    can be explored as needed. Effect size is the difference or similarity of the
    data being compared in the hypothesis test, such as a standardized difference
    of means or correlation. As a common level of significance (type I error) in hypothesis
    testing is anywhere between 0.01 and 0.1, a common level of power is anywhere
    between 0.8 and 0.9, although these measures are case-dependent (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7745163/#:~:text=The%20ideal%20power%20of%20a,high%20as%200.8%20or%200.9).
  prefs: []
  type: TYPE_NORMAL
- en: 'A few notable properties of power are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: There must be sufficient power to detect a meaningful difference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Power increases with sample size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Power increases with the effect size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standard deviation (as well as variance and standard error) decreases as power
    increases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following plot, we can see that type I error (α) is where we may falsely
    assume the null hypothesis and conclude there is no statistically significant
    difference when, in fact, the data points don’t belong to data source 2 (the null
    hypothesis), but to data source 1\. Type II error (β) is where we might make the
    mistake of assuming the data in that region belongs to data source 1 (the alternate
    hypothesis) when, in fact, it belongs to data source 2.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 – Visualizing error in a left-tailed two-population z-test](img/B18945_03_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – Visualizing error in a left-tailed two-population z-test
  prefs: []
  type: TYPE_NORMAL
- en: 'As illustrated in the preceding plot, we see a left-tailed t-test comparing
    the null distribution on the right to the alternate distribution on the left.
    In this plot, we can see two prominent concepts at hand:'
  prefs: []
  type: TYPE_NORMAL
- en: As *α* becomes smaller, the critical value slides left, moving more toward distributional
    outliers, *β* becomes larger, and vice versa
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical power is the area of data source 2 to the right of *β*, as *power
    = (**1-β)*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A type I error is determined based on a pre-selected threshold; a researcher
    may feel most comfortable with a 90, 95, or 99% level of confidence. However,
    a type II error is based on parameterization (standard deviation, effect size,
    sample size, and so on). Therefore, we can use a power analysis to identify the
    sample size, and vice versa. The implementation of power analysis for various
    hypothesis tests will be implemented in the following two chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Power analysis for a two-population pooled z-test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us look at a dataset of salaries for professors of two different disciplines,
    discipline A and discipline B. We want to know whether there is a statistically
    significant difference between them based on the data we have. First, we need
    to perform a power analysis to know whether we have enough samples to trust the
    results of the z-test we may perform to test this hypothesis. The components of
    a power analysis we need for this include effect size, the type I error rate,
    a desired type II error rate, the direction of the alternate hypothesis (group
    2 is expected to be larger than, smaller than, or could be either larger or smaller
    than group 1), and the ratio of observations in the larger sample relative to
    that of the smaller. Discipline A has 181 salaries and discipline B has 216\.
    Therefore, 216 will be our numerator corresponding to what we will consider as
    *group 1* (discipline A will be *group 2*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us suppose we are not sure whether one group will be larger or smaller
    than the other; we will consider this a two-sided hypothesis test. The effect
    size for this z-test is the difference between the two groups. We will use **Cohen’s
    d**. To calculate that, we need to divide the difference between the means of
    the two groups by the pooled standard deviation. Calculated here, the pooled standard
    deviation is the number of samples in group 1 multiplied by the variance of group
    1, plus the same for group 2, all divided by the combined sample size for the
    two groups. The following is the equation for the pooled standard deviation:'
  prefs: []
  type: TYPE_NORMAL
- en: √ _____________   n 1 σ 1 2 + n 2 σ 2 2  _ n 1 + n 2
  prefs: []
  type: TYPE_NORMAL
- en: 'For effect size, we need to divide the difference of means by the effect size
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|μ 1 − μ 2| ______________  √ ___________  n 1 σ 1 2 + n 2 σ 2 2  _ n 1 + n 2'
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the equation for effect size, we take the absolute value of the
    difference of means. That is because, for Cohen’s d, we always need a positive
    difference of means for this test.
  prefs: []
  type: TYPE_NORMAL
- en: 'As calculated here, if we want a power of 80% (the type II error rate is 20%)
    and a type I error rate (a level of significance) of 0.05, we will need 172 samples
    in group 1 and 145 samples in group 2\. However, if we wanted a power of 90% and
    a level of significance of 0.01 (99% confidence), we would need 325 samples in
    group 1 and 274 samples in group 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from this code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Sample Size Required in Sample` `1: 325.346`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Sample Size Required in Sample` `2: 273.400`'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we introduced the concept of a hypothesis test. We started
    with a basic outline of a hypothesis test with the four key steps:'
  prefs: []
  type: TYPE_NORMAL
- en: State the hypothesis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform the test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine whether to reject or fail to reject the null hypothesis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Draw a statistical conclusion with a scope of inference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we talked about potential errors that can occur and false positives and
    false negatives and defined the expected error rate (alpha) of a test and the
    power (beta) of a test.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed the statistical procedure called the z-test. This is a type
    of hypothesis test using sample data assumed to be normally distributed. The z-score
    and z-statistic were also introduced in the section on different types of z-tests,
    such as one-sample or two-sample z-tests for means or proportions.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed the concept and motivation behind the power analysis,
    which can be used to identify the probability of incorrectly rejecting the null
    hypothesis and selecting the sample size. We also explored the parameters of the
    analysis for a two-population pooled z-test. Here, we briefly examined effect
    size, which is the value of impact (the effect of a treatment) we search for when
    performing the hypothesis test. We will discuss power analysis in the next two
    chapters as we iterate over different applications of hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss more parametric hypothesis tests. While
    these tests will still require distribution assumptions, the assumptions will
    be less strict than the assumptions of the z-test.
  prefs: []
  type: TYPE_NORMAL
