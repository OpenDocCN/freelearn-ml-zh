<html><head></head><body>
<div id="sbo-rt-content" class="calibre1"><div id="_idContainer083" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-84"><a id="_idTextAnchor146" class="calibre6 pcalibre pcalibre1"/>4</h1>
<h1 id="_idParaDest-85" class="calibre5"><a id="_idTextAnchor147" class="calibre6 pcalibre pcalibre1"/>Utilizing Google Cloud’s High-Level AI Services</h1>
<p class="calibre3">Now that you have been equipped with an arsenal of information regarding AI/ML and Google Cloud, you are ready to start diving in and implementing AI/ML workloads in the cloud – that’s exactly what we will do in this chapter! You’re going to start by using Google Cloud’s high-level AI/ML APIs, such as the Natural Language API and the Vision API, which enable you to implement AI/ML functionality using models that are trained and maintained by Google. Then, you’ll use Vertex AI AutoML to train your own ML model, all without the need for any <span>AI/ML expertise.</span></p>
<p class="calibre3">This chapter will cover the <span>following topics:</span></p>
<ul class="calibre16">
<li class="calibre8">Using Document AI to extract information <span>from documents</span></li>
<li class="calibre8">Using the Google Cloud Natural Language API to to get sentiment analysis insights from <span>textual inputs</span></li>
<li class="calibre8">Using Vertex <span>AI AutoML</span></li>
</ul>
<h1 id="_idParaDest-86" class="calibre5"><a id="_idTextAnchor148" class="calibre6 pcalibre pcalibre1"/>Prerequisites for this chapter</h1>
<p class="calibre3">First, we need to perform some setup steps to lay the foundations for the activities we will be performing in <span>this chapter.</span></p>
<h2 id="_idParaDest-87" class="calibre9"><a id="_idTextAnchor149" class="calibre6 pcalibre pcalibre1"/>Cloning this book’s GitHub repository to your local machine</h2>
<p class="calibre3">Throughout the rest of this book, we will perform a lot of hands-on activities that require the use of resources such as code, data, and other files. Many of these resources are stored in the GitHub repository associated with this book, so the easiest way to access them would be to clone the repository to your local machine (that is, your laptop/PC). The exact way to do this will differ based on the operating system you use, but the process is generally to open a command terminal on your system, navigate to a directory of your choice, and run the <span>following commands:</span></p>
<pre class="console">
git init
git clone https://github.com/PacktPublishing/Google-Machine-Learning-for-Solutions-Architects</pre> <h2 id="_idParaDest-88" class="calibre9"><a id="_idTextAnchor150" class="calibre6 pcalibre pcalibre1"/>The Google Cloud console</h2>
<p class="calibre3">In the Prerequisites <a id="_idIndexMarker429" class="calibre6 pcalibre pcalibre1"/>for using <em class="italic">Google Cloud tools and services</em> section of <a href="B18143_03.xhtml#_idTextAnchor059" class="calibre6 pcalibre pcalibre1"><span><em class="italic">Chapter 3</em></span></a>, we discussed that you would need to create a Google Cloud account to interact with most Google Cloud services. We will use the Google Cloud console to perform many of the activities in this chapter. Once you have created a Google Cloud account, you can log into the console by navigating <span>to </span><a href="https://console.cloud.google.com" class="calibre6 pcalibre pcalibre1"><span>https://console.cloud.google.com</span></a><span>.</span></p>
<p class="calibre3">Throughout this book, you will need to navigate to different services within the Google Cloud console. Whenever you need to do this, you can click on the symbol with three horizontal lines next to the Google Cloud logo in the top-left corner of the screen to view the menu of Google Cloud services or products (in this context, we’ll use the terms “services” and “products” interchangeably throughout this book). See <span><em class="italic">Figure 4</em></span><em class="italic">.1</em> <span>for reference:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer064">
<img alt="Figure 4.1: Accessing the Google Cloud services menu" src="image/B18143_04_1.jpg" class="calibre68"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.1: Accessing the Google Cloud services menu</p>
<p class="calibre3">You can then scroll through the list of services and select the relevant one. Some of the menu items have sub-menus nested under them, as shown in <span><em class="italic">Figure 4</em></span><span><em class="italic">.2</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer065">
<img alt="Figure 4.2: Google Cloud services sub-menus" src="image/B18143_04_2.jpg" class="calibre69"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.2: Google Cloud services sub-menus</p>
<p class="calibre3">Throughout this book, we will sometimes use shorthand notation to represent the navigation path through the services menus and sub-menus. For example, to navigate to the <strong class="bold">Credentials</strong> sub-menu item, we will represent this as the <strong class="bold">Google Cloud services</strong> menu → <strong class="bold">APIs &amp; Services</strong> → <span><strong class="bold">Credentials</strong></span><span>.</span></p>
<p class="calibre3">Now that we’ve<a id="_idIndexMarker430" class="calibre6 pcalibre pcalibre1"/> looked at how to access the Google Cloud console, let’s ensure that we have a Google Cloud project to use for the activities in <span>this book.</span></p>
<h2 id="_idParaDest-89" class="calibre9"><a id="_idTextAnchor151" class="calibre6 pcalibre pcalibre1"/>Google Cloud project</h2>
<p class="calibre3">A Google Cloud <a id="_idIndexMarker431" class="calibre6 pcalibre pcalibre1"/>project is an environment that contains all of your resources in Google Cloud. Resources include things such as virtual machines, network configurations, databases, storage buckets, identity and access controls, and pretty much everything that you create on <span>Google Cloud.</span></p>
<p class="calibre3">By default, when you create your Google Cloud account and log into the console for the first time, Google Cloud automatically creates your first project for you, with the name <strong class="bold">My First Project</strong>. If, for any reason, this has not happened, you will need to create one by following <span>these steps:</span></p>
<ol class="calibre7">
<li class="calibre8">In the Google Cloud console, navigate to the <strong class="bold">Google Cloud services</strong> menu → <strong class="bold">IAM &amp; Admin</strong> → <strong class="bold">Create </strong><span><strong class="bold">a Project</strong></span><span>.</span></li>
<li class="calibre8">Type a name for your project in the <strong class="bold">Project Name</strong> <span>text box.</span><p class="calibre3">You could also edit the <strong class="bold">Project ID</strong> value if you’d like, but it’s more common to leave this at the generated value unless you have a specific naming convention that you’d like to implement. Note that this cannot be changed after the project <span>is created.</span></p></li>
<li class="calibre8">In the <strong class="bold">Location</strong> field, click <strong class="bold">Browse</strong> to display potential locations for your project. Then, <span>click </span><span><strong class="bold">Select</strong></span><span>.</span></li>
<li class="calibre8">Click <strong class="bold">Create</strong>. The console will navigate to the <strong class="bold">Dashboard</strong> page and your project will be created within a <span>few minutes.</span></li>
</ol>
<p class="calibre3">Now that we have our<a id="_idIndexMarker432" class="calibre6 pcalibre pcalibre1"/> Google Cloud project in place, let’s ensure that our billing details are set up for using <span>Google Cloud.</span></p>
<h2 id="_idParaDest-90" class="calibre9"><a id="_idTextAnchor152" class="calibre6 pcalibre pcalibre1"/>Google Cloud Billing</h2>
<p class="calibre3">A Google Cloud <a id="_idIndexMarker433" class="calibre6 pcalibre pcalibre1"/>Billing account contains all of the details that enable Google Cloud to bill you for using <span>their services.</span></p>
<p class="calibre3">If you don’t already have a Google Cloud Billing account, then you will need to create one by following <span>these steps:</span></p>
<ol class="calibre7">
<li class="calibre8">In the Google Cloud console, navigate to the <strong class="bold">Google Cloud services</strong> menu<strong class="bold"> </strong>→ <span><strong class="bold">Billing</strong></span><span>.</span></li>
<li class="calibre8">On the page that appears, select <strong class="bold">Manage Billing Accounts</strong>, then <strong class="bold">Add </strong><span><strong class="bold">billing account</strong></span><span>.</span></li>
<li class="calibre8">Click <span><strong class="bold">Create account</strong></span><span>.</span></li>
<li class="calibre8">Enter a name for the Cloud <span>Billing account.</span></li>
<li class="calibre8">Depending on your configuration, you will also need to select one of <span>the following:</span><ul class="calibre70"><li class="calibre8"><strong class="bold">Organization</strong>: If you see an <strong class="bold">Organization</strong> dropdown, then you must select an organization before you <span>can continue</span></li><li class="calibre8"><strong class="bold">Country</strong>: If you are prompted to select a <strong class="bold">country</strong>, select the country that corresponds with your billing <span>mailing address</span></li></ul></li>
<li class="calibre8"><span>Click </span><span><strong class="bold">Continue</strong></span><span>.</span></li>
<li class="calibre8">You will then need to fill in all of your <span>billing details.</span></li>
<li class="calibre8">When you have entered all of your details, click <strong class="bold">Submit and enable billing</strong>. To learn more about Google Cloud Billing accounts and concepts, <span>visit </span><a href="https://cloud.google.com/billing/docs/how-to/create-billing-account" class="calibre6 pcalibre pcalibre1"><span>https://cloud.google.com/billing/docs/how-to/create-billing-account</span></a><span>.</span></li>
</ol>
<p class="calibre3">Now that our Google <a id="_idIndexMarker434" class="calibre6 pcalibre pcalibre1"/>Cloud project and Billing account have been set up, we’re ready to start using Google Cloud products in <span>our project.</span></p>
<h2 id="_idParaDest-91" class="calibre9"><a id="_idTextAnchor153" class="calibre6 pcalibre pcalibre1"/>Google Cloud Shell</h2>
<p class="calibre3">We will use Google <a id="_idIndexMarker435" class="calibre6 pcalibre pcalibre1"/>Cloud Shell to perform some of the activities in <span>this chapter.</span></p>
<p class="calibre3">Open Cloud Shell, as described in the <em class="italic">Interacting with Google Cloud services</em> section of <a href="B18143_03.xhtml#_idTextAnchor059" class="calibre6 pcalibre pcalibre1"><span><em class="italic">Chapter 3</em></span></a>. As a reminder, you can access it by clicking the <strong class="bold">Cloud Shell</strong> symbol in the top-right corner of the screen, as shown in <span><em class="italic">Figure 4</em></span><span><em class="italic">.3</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer066">
<img alt="Figure 4.3: Cloud Shell symbol" src="image/B18143_04_3.jpg" class="calibre71"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.3: Cloud Shell symbol</p>
<p class="calibre3">Now that we’ve opened Cloud Shell, we’ll perform some basic setup steps to prepare our Cloud <span>Shell environment.</span></p>
<h2 id="_idParaDest-92" class="calibre9"><a id="_idTextAnchor154" class="calibre6 pcalibre pcalibre1"/>Authentication</h2>
<p class="calibre3">When a Google <a id="_idIndexMarker436" class="calibre6 pcalibre pcalibre1"/>Cloud service is invoked in some way, it usually wants to know who or what (identity) is invoking it. This is for many reasons, such as billing and checking whether the invoker is allowed to perform the action that is being requested. This process of identification is called “authentication.” There are numerous different ways to authenticate with a Google Cloud API. For example, when you log into the Google Cloud console, you are authenticating with the console. Then, as you navigate and perform actions in the console, your authentication details are used to control what kinds of actions you are allowed to perform. One of the simplest authentication mechanisms is referred to as <strong class="bold">API keys</strong>. We’ll explore <span>this next.</span></p>
<h3 class="calibre11">Google Cloud API keys</h3>
<p class="calibre3">API keys are a <a id="_idIndexMarker437" class="calibre6 pcalibre pcalibre1"/>very basic type of authentication supported by some Google Cloud APIs. An API key does not provide any identification or authorization information to the called API; they are only generally used for billing purposes (by linking to a Google Cloud project) or to track usage against Google <span>Cloud quotas.</span></p>
<p class="calibre3">In this chapter, we will use them to access the Google Cloud Natural <span>Language API.</span></p>
<h4 class="calibre20">Creating an API key</h4>
<p class="calibre3">Although we will use<a id="_idIndexMarker438" class="calibre6 pcalibre pcalibre1"/> Cloud Shell to perform many of the steps in this chapter, Google Cloud currently only supports creating API keys in the Google Cloud console. To create our API key, perform the <span>following steps:</span></p>
<ol class="calibre7">
<li class="calibre8">In the Google Cloud console, navigate to the <strong class="bold">Google Cloud services</strong> menu → <strong class="bold">APIs &amp; Services</strong> → <span><strong class="bold">Credentials</strong></span><span>.</span></li>
<li class="calibre8">Select <strong class="bold">Create credentials</strong>, then <span><strong class="bold">API key</strong></span><span>.</span></li>
<li class="calibre8">Copy the generated API key and <span>click </span><span><strong class="bold">Close</strong></span><span>.</span></li>
<li class="calibre8">You will need to paste this API key in a later step. If you need to view or copy the key again, you can select <strong class="bold">Show key</strong> in the <strong class="bold">API Keys</strong> section of the console (that is, the section you are <span>currently in).</span></li>
<li class="calibre8">With that, we <a id="_idIndexMarker439" class="calibre6 pcalibre pcalibre1"/>have created an API key that we can use in later activities in <span>this chapter.</span></li>
</ol>
<h2 id="_idParaDest-93" class="calibre9"><a id="_idTextAnchor155" class="calibre6 pcalibre pcalibre1"/>Enabling the relevant Google Cloud APIs</h2>
<p class="calibre3">As we discussed in <a href="B18143_03.xhtml#_idTextAnchor059" class="calibre6 pcalibre pcalibre1"><span><em class="italic">Chapter 3</em></span></a>, before<a id="_idIndexMarker440" class="calibre6 pcalibre pcalibre1"/> you can use a Google Cloud service API, you need to enable it. Since we are already logged into Cloud Shell, we can easily do that directly from here by using the <strong class="source-inline">gcloud</strong> command. We will enable the Google Cloud Natural Language API, the Vision API, the Document AI API, and the Google Cloud Storage API as we will be using all of them in this chapter. To do this, run the following commands in <span>Cloud Shell:</span></p>
<pre class="console">
gcloud services enable language.googleapis.com
gcloud services enable vision.googleapis.com
gcloud services enable documentai.googleapis.com
gcloud services enable storage.googleapis.com</pre> <p class="calibre3">The responses should be similar to <span>the following:</span></p>
<pre class="console">
Operation "operations/..." finished successfully.</pre> <p class="calibre3">With the required APIs now enabled, we just have a few more steps to complete before we can start <span>using them.</span></p>
<h2 id="_idParaDest-94" class="calibre9"><a id="_idTextAnchor156" class="calibre6 pcalibre pcalibre1"/>Storing authentication credentials in environment variables</h2>
<p class="calibre3">We will reference<a id="_idIndexMarker441" class="calibre6 pcalibre pcalibre1"/> our authentication credentials – that is, the API key that we created earlier – in many commands in this chapter. To make it easier to reference the credentials, we will store them in Linux environment variables in <span>Cloud Shell.</span></p>
<p class="calibre3">To store the API key, run the following command, but replace <strong class="source-inline">&lt;YOUR_API_KEY&gt;</strong> with the API key you created and <span>copied earlier:</span></p>
<pre class="source-code">
export API_KEY=&lt;YOUR_API_KEY&gt;</pre> <p class="calibre3">We’re almost finished with the environment setup steps now. Next, we will clone our GitHub repository, after which we’ll be ready to start using Google Cloud’s high-level <span>AI services.</span></p>
<h2 id="_idParaDest-95" class="calibre9"><a id="_idTextAnchor157" class="calibre6 pcalibre pcalibre1"/>Creating a directory and cloning our GitHub repository</h2>
<p class="calibre3">You already<a id="_idIndexMarker442" class="calibre6 pcalibre pcalibre1"/> cloned our repository to <a id="_idIndexMarker443" class="calibre6 pcalibre pcalibre1"/>your local machine. In<a id="_idIndexMarker444" class="calibre6 pcalibre pcalibre1"/> this section, you will also clone it to your Cloud Shell environment. To do this, perform the following steps in <span>Cloud Shell:</span></p>
<ol class="calibre7">
<li class="calibre8">Create <span>a directory:</span><pre class="source-code">
mkdir packt-ml-sa</pre></li> <li class="calibre8">Change location to <span>that directory:</span><pre class="source-code">
cd packt-ml-sa</pre></li> <li class="calibre8">Initiate the directory as a local <span><strong class="source-inline">git</strong></span><span> repository:</span><pre class="source-code">
git init</pre></li> <li class="calibre8">Clone the <strong class="source-inline">git</strong> repository that contains the code we will use in the Document AI section of <span>this chapter:</span><pre class="source-code">
git clone https://github.com/PacktPublishing/Google-Machine-Learning-for-Solutions-Architects</pre></li> </ol>
<p class="calibre3">Now that we have all of the required code copied to our Cloud Shell environment, it’s time to start <span>executing it!</span></p>
<h1 id="_idParaDest-96" class="calibre5"><a id="_idTextAnchor158" class="calibre6 pcalibre pcalibre1"/>Detecting text in images with the Cloud Vision API</h1>
<p class="calibre3">We’re going <a id="_idIndexMarker445" class="calibre6 pcalibre pcalibre1"/>to begin with a very simple<a id="_idIndexMarker446" class="calibre6 pcalibre pcalibre1"/> example to show you just how easy it is to start using AI/ML services on Google Cloud. In just a few short steps, you will be able to extract text and associated metadata from an image and save that text in a file. This process is<a id="_idIndexMarker447" class="calibre6 pcalibre pcalibre1"/> called <strong class="bold">optical character </strong><span><strong class="bold">recognition</strong></span><span> (</span><span><strong class="bold">OCR</strong></span><span>).</span></p>
<p class="calibre3">To begin this process, download the following image to your computer (the image can also be found in the <strong class="source-inline">Chapter</strong><strong class="source-inline">0</strong><strong class="source-inline">4/images</strong> folder in the git repository you created <span>above): </span><a href="https://github.com/PacktPublishing/Google-Machine-Learning-for-Solutions-Architects/blob/main/Chapter-04/images/poem.png" class="calibre6 pcalibre pcalibre1"><span>https://github.com/PacktPublishing/Google-Machine-Learning-for-Solutions-Architects/blob/main/Chapter-04/images/poem.png</span></a><span>.</span></p>
<p class="calibre3">The image is shown in <span><em class="italic">Figure 4</em></span><span><em class="italic">.4</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer067">
<img alt="Figure 4.4: Sign to be used for OCR" src="image/B18143_04_4.jpg" class="calibre72"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.4: Sign to be used for OCR</p>
<p class="calibre3">Continue with the <a id="_idIndexMarker448" class="calibre6 pcalibre pcalibre1"/>remaining<a id="_idIndexMarker449" class="calibre6 pcalibre pcalibre1"/> steps to upload this image to your Cloud <span>Shell environment:</span></p>
<ol class="calibre7">
<li class="calibre8">Click the symbol with the three dots at the top-right corner of the Cloud Shell area (at the bottom of your Google Cloud console screen), then select <strong class="bold">Upload</strong>. See <span><em class="italic">Figure 4</em></span><em class="italic">.5</em> <span>for reference:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer068">
<img alt="Figure 4.5: Cloud Shell upload" src="image/B18143_04_5.jpg" class="calibre73"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.5: Cloud Shell upload</p>
<ol class="calibre7">
<li value="2" class="calibre8">You will be<a id="_idIndexMarker450" class="calibre6 pcalibre pcalibre1"/> presented<a id="_idIndexMarker451" class="calibre6 pcalibre pcalibre1"/> with a file upload dialogue box (see <span><em class="italic">Figure 4</em></span><em class="italic">.6</em> for reference). Select <strong class="bold">Choose files</strong> and browse for the file that you <span>previously downloaded:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer069">
<img alt="Figure 4.6: Cloud Shell upload prompt" src="image/B18143_04_6.jpg" class="calibre74"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.6: Cloud Shell upload prompt</p>
<ol class="calibre7">
<li value="3" class="calibre8">Now, invoke the Cloud Vision API to extract the text and save it in a file with the following<a id="_idIndexMarker452" class="calibre6 pcalibre pcalibre1"/> command (in<a id="_idIndexMarker453" class="calibre6 pcalibre pcalibre1"/> this case, the filename of the image we’re using is <strong class="source-inline">poem.png</strong>). The results are stored in a file <span>named </span><span><strong class="source-inline">vision-ocr.json</strong></span><span>:</span><pre class="source-code">
gcloud ml vision detect-text poem.png&gt; vision-ocr.json</pre></li> <li class="calibre8">Inspect the contents of <span>the file:</span><pre class="source-code">
cat vision-ocr.json</pre></li> </ol>
<p class="callout-heading">Note</p>
<p class="callout">The file is not conducive to being printed in a book, so we will not display <span>it here.</span></p>
<p class="calibre3">As you can see, each word that is extracted is stored with some associated metadata, such as the <em class="italic">X</em> and <em class="italic">Y</em> coordinates of the corners of the bounding boxes that contain that word in the image. This metadata helps us understand where each word appeared in the image, which can be useful information <span>for developers.</span></p>
<ol class="calibre7">
<li value="5" class="calibre8">If you just want to see the detected text, without the other metadata, you can use the <span>following command:</span><pre class="source-code">
cat vision-ocr.json | grep description</pre><p class="calibre3">You will see the entire body of detected text in the first description, and then individual words in the subsequent descriptions. The output will look similar to the<a id="_idIndexMarker454" class="calibre6 pcalibre pcalibre1"/> following (truncated <a id="_idIndexMarker455" class="calibre6 pcalibre pcalibre1"/>here <span>for brevity):</span></p><pre class="source-code">"description": "\"All the summer long I stood\nIn the silence of the wood.\nTall and tapering I grew;\nWhat might happen well I knew;\nFor one day a little bird.\nSang, and in the song I heard\nMany things quite strange to me",
          "description": "\""
          "description": "All"
          "description": "the"
          "description": "summer"
          "description": "long"
          "description": "I"
          "description": "stood"</pre></li> </ol>
<p class="calibre3">Congratulations – you have<a id="_idIndexMarker456" class="calibre6 pcalibre pcalibre1"/> just<a id="_idIndexMarker457" class="calibre6 pcalibre pcalibre1"/> implemented your first AI/ML workload on Google Cloud! It really is that simple! Next, we’ll start looking at some slightly more advanced <span>use cases.</span></p>
<h1 id="_idParaDest-97" class="calibre5"><a id="_idTextAnchor159" class="calibre6 pcalibre pcalibre1"/>Using Document AI to extract information from documents</h1>
<p class="calibre3">As you may recall, we <a id="_idIndexMarker458" class="calibre6 pcalibre pcalibre1"/>discussed Document AI at length in <a href="B18143_03.xhtml#_idTextAnchor059" class="calibre6 pcalibre pcalibre1"><span><em class="italic">Chapter 3</em></span></a>. We talked about how it goes beyond understanding the content of textual inputs and also incorporates structure. In this section, we’re going to take a look at how Document AI does this, and we’ll see it in action for some real-world use cases. We’ll start by covering some important Document <span>AI concepts.</span></p>
<h2 id="_idParaDest-98" class="calibre9"><a id="_idTextAnchor160" class="calibre6 pcalibre pcalibre1"/>Document AI concepts</h2>
<p class="calibre3">Document AI<a id="_idIndexMarker459" class="calibre6 pcalibre pcalibre1"/> uses the concept of “processors” to process documents. There are three main types of processors that you <span>can use:</span></p>
<ul class="calibre16">
<li class="calibre8"><span>General processors</span></li>
<li class="calibre8"><span>Specialized processors</span></li>
<li class="calibre8"><span>Custom processors</span></li>
</ul>
<p class="calibre3">General processors and specialized processors use models that are pre-trained by Google, so you can use them without needing to train your own models, and without any AI/ML expertise. However, to provide additional flexibility, Google Cloud gives you the ability to further train specialized processors with your data to improve their accuracy for use cases that are specific to your business. This process is referred to <span>as “uptraining.”</span></p>
<p class="calibre3">General processors include a processor for performing OCR on images of text documents and forms. While we performed OCR using the Cloud Vision API in the previous section, Document AI provides additional functionality, such as identifying structured information within the input documents. This includes understanding key-value pairs in input forms, which can be very useful for automated data entry <span>use cases.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">This is an important consideration in the Solution Architect role; there are often multiple different services that could be used to achieve similar business goals, and the Solution Architect’s job is to create or select the most suitable solution based on specific business requirements. In the case of selecting between the Cloud Vision API and Document AI for OCR use cases, bear in mind that the Cloud Vision API generally requires less initial effort to use, but it also provides fewer features than Document AI. Therefore, if you have a very simple use case that can be satisfied with the Cloud Vision API, then you can select that option, whereas more complex use cases would steer you toward using <span>Document AI.</span></p>
<p class="calibre3">Specialized processors provide models for processing specific types of documents, such as US Federal Government forms, identification documents, and invoices. The specialized processors are currently categorized into four <span>different types:</span></p>
<ul class="calibre16">
<li class="calibre8"><span>Procurement</span></li>
<li class="calibre8"><span>Identity</span></li>
<li class="calibre8"><span>Lending</span></li>
<li class="calibre8"><span>Contract</span></li>
</ul>
<p class="calibre3">At the time of writing (March 2023), Google Cloud recently announced the general availability of new functionality in Document AI, which is Document AI Workbench. Document AI <a id="_idIndexMarker460" class="calibre6 pcalibre pcalibre1"/>Workbench enables you to create completely new, custom types of processors, beyond what’s provided by Google Cloud, for your specific <span>use cases.</span></p>
<p class="calibre3">Let’s take a look at how some of the Document AI <span>processors work.</span></p>
<h2 id="_idParaDest-99" class="calibre9"><a id="_idTextAnchor161" class="calibre6 pcalibre pcalibre1"/>Performing OCR with Document AI</h2>
<p class="calibre3">We’re going to <a id="_idIndexMarker461" class="calibre6 pcalibre pcalibre1"/>use the simplest use case, OCR, for <a id="_idIndexMarker462" class="calibre6 pcalibre pcalibre1"/>demonstration purposes, which will also allow us to directly contrast this functionality against how we performed OCR with the Cloud <span>Vision API.</span></p>
<h3 class="calibre11">Creating a Document AI OCR processor</h3>
<p class="calibre3">Before we can <a id="_idIndexMarker463" class="calibre6 pcalibre pcalibre1"/>process any documents, we need to create a processor. We’re going to perform this action in the Google <span>Cloud console:</span></p>
<ol class="calibre7">
<li class="calibre8">In the Google Cloud console, navigate to the <strong class="bold">Google Cloud services</strong> menu → <strong class="bold">Document AI</strong> → <span><strong class="bold">Processor Gallery</strong></span><span>.</span></li>
<li class="calibre8">Under <strong class="bold">Document OCR</strong>, click <strong class="bold">CREATE PROCESSOR</strong>. See <span><em class="italic">Figure 4</em></span><em class="italic">.7</em> <span>for reference:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer070">
<img alt="Figure 4.7: CREATE PROCESSOR" src="image/B18143_04_7.jpg" class="calibre75"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.7: CREATE PROCESSOR</p>
<ol class="calibre7">
<li value="3" class="calibre8">Input <strong class="bold">OCR-Processor</strong> as the name, select the region nearest to you, and <span>click </span><span><strong class="bold">Create</strong></span><span>.</span></li>
</ol>
<p class="callout-heading">A note on regions and zones</p>
<p class="callout">For this book, whenever you need to select a region, we recommend selecting the same region every time since we will build resources throughout this book that may need to be used in combination with other resources created in different chapters of this book. Generally, when you need to use some cloud resources with other cloud resources, it’s often much easier if those resources are in the same region. Sometimes, it can be difficult or impossible for resources in one region to reference resources in a different region without building a customized solution to <span>do so.</span></p>
<p class="callout">In some activities in this book, you will also have the option of selecting a specific zone within a region. This decision is usually less important for the activities in this book because accessing resources across zones within a region is generally quite easy. In a production environment, you may want to keep resources in the same zone if you have specific business requirements, such as clusters of compute instances that need to work very <span>closely together.</span></p>
<p class="callout">If you don’t have such specific requirements, then the best practice is to distribute your resources across multiple zones to improve workload resilience and availability. You can learn more about Google Cloud regions and zones in the documentation at the following <span>URL: </span><a href="https://cloud.google.com/compute/docs/regions-zones" class="calibre6 pcalibre pcalibre1"><span>https://cloud.google.com/compute/docs/regions-zones</span></a><span>.</span></p>
<ol class="calibre7">
<li value="4" class="calibre8">When your <a id="_idIndexMarker464" class="calibre6 pcalibre pcalibre1"/>processor gets created, you should automatically be redirected to the <strong class="bold">PROCESSOR DETAILS</strong> page. If not, you can view the details by selecting <strong class="bold">My processors</strong> in the menu on the left-hand side of the screen and then selecting your newly created processor. The processor details are shown in <span><em class="italic">Figure 4</em></span><span><em class="italic">.8</em></span><span>:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer071">
<img alt="Figure 4.8: OCR processor details" src="image/B18143_04_8.jpg" class="calibre76"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.8: OCR processor details</p>
<p class="calibre3">Take note of your processor ID (highlighted by the red arrow in <span><em class="italic">Figure 4</em></span><em class="italic">.8</em>) as you will need to reference<a id="_idIndexMarker465" class="calibre6 pcalibre pcalibre1"/> it in the code we will use in the <span>next section.</span></p>
<h3 class="calibre11">Invoking the OCR processor</h3>
<p class="calibre3">Now that we’ve <a id="_idIndexMarker466" class="calibre6 pcalibre pcalibre1"/>created our processor, we can start using it. In this section, we will run a simple piece of Python code that uses the Document AI Python client library to process a file and extract the necessary information. We’re going to use the same file that we used with the Cloud Vision API earlier in <span>this chapter.</span></p>
<p class="calibre3">Perform the following steps in <span>Cloud Shell:</span></p>
<ol class="calibre7">
<li class="calibre8">Install the latest version of the Document AI <span>client packages:</span><pre class="source-code">
python -m venv env
source env/bin/activate 
pip install --upgrade google-cloud-documentai</pre></li> <li class="calibre8">Take note of your project ID as you will need to reference it in the Python code that will be used to interact with Document AI. You can use the following command to <span>view it:</span><pre class="source-code">
echo $DEVSHELL_PROJECT_ID</pre></li> <li class="calibre8">Ensure that you are in your <span>home directory:</span><pre class="source-code">
cd ~</pre></li> <li class="calibre8">Copy the <strong class="source-inline">docai-ocr.py</strong> file to your home directory from the <strong class="source-inline">git</strong> directory we created earlier. We’re going to edit this file outside of the branch because we won’t need to merge the updates back to the <span>main branch:</span><pre class="source-code">
cp ~/packt-ml-sa/Google-Machine-Learning-for-Solutions-Architects/Chapter-04/docai-ocr.py ~</pre></li> </ol>
<p class="calibre3">In this Python file, we’ll begin by importing the required libraries. Then, we’ll define some variables (we will need to replace the values of those variables with the values of the processor we created in the <span>previous section).</span></p>
<p class="calibre3">Then, we’ll define a function that creates a Document AI client, reads the input file, creates a request object based on the file’s contents, and sends this request to be processed by the Document <span>AI service.</span></p>
<p class="calibre3">Finally, the function will print the resulting <span>document text.</span></p>
<p class="calibre3">To perform these actions, execute the <span>following steps:</span></p>
<ol class="calibre7">
<li class="calibre8">Use <strong class="source-inline">nano</strong> to open the file <span>for editing:</span><pre class="source-code">
nano docai-ocr.py</pre></li> <li class="calibre8">Replace the variable definitions with the values you saved after creating the processor in the Google <span>Cloud console:</span><ol class="calibre77"><li class="lower-roman">Replace the <strong class="source-inline">project_id</strong> value with your project ID, which you viewed in the <strong class="source-inline">$DEVSHELL_PROJECT_ID</strong> environment <span>variable previously.</span></li><li class="lower-roman">Specify ‘<strong class="source-inline">us'</strong> or <strong class="source-inline">'eu'</strong> as the location, depending on which region <span>you used.</span></li><li class="lower-roman">Replace <a id="_idIndexMarker467" class="calibre6 pcalibre pcalibre1"/>the <strong class="source-inline">processor_id</strong> value with your processor ID, which you can view on the <strong class="bold">PROCESSOR DETAILS</strong> page in the console after creating <span>your processor.</span></li><li class="lower-roman">Replace the <strong class="source-inline">file_path</strong> value with the path to the file we want to process. The Cloud Shell upload feature that we used generally stores files in your Cloud Shell home directory, which is <span>usually </span><span><strong class="source-inline">/home/admin_.</strong></span></li><li class="lower-roman">In this case, the <strong class="source-inline">mime_type</strong> value is <strong class="source-inline">'image/</strong><strong class="source-inline">png</strong><strong class="source-inline">'</strong>. You can view the list of supported MIME types <span>at </span><a href="https://cloud.google.com/document-ai/docs/file-types" class="calibre6 pcalibre pcalibre1"><span>https://cloud.google.com/document-ai/docs/file-types</span></a><span>.</span></li></ol></li>
<li class="calibre8">When you have completed all of the edits, press <em class="italic">Ctrl</em> + <em class="italic">X</em> to exit <strong class="source-inline">nano</strong>, then <em class="italic">Y</em> to save the file, and then <em class="italic">Enter</em> to <span>confirm this.</span></li>
<li class="calibre8">Now, we’re ready to execute OCR! The following command will run our Python function and save the results in a file <span>named </span><span><strong class="source-inline">docai-ocr.txt</strong></span><span>:</span><pre class="source-code">
python docai-ocr.py &gt; docai-ocr.txt</pre></li> <li class="calibre8">Inspect the contents of <span>the file:</span><pre class="source-code">
cat docai-ocr.txt</pre><p class="calibre3">The response should look <span>like this:</span></p><pre class="source-code">All the summer long I stood
In the silence of the wood.
Tall and tapering I grew;
What might happen well I knew;
For one day a little bird.
Sang, and in the song I heard
Many things quite strange to me</pre></li> </ol>
<p class="calibre3">Note how the output is formatted differently than the results we received when we used the Cloud Vision API. This further demonstrates how we can use different services to achieve similar results. However, there are subtle differences between the services, and we need to pick the best option based on business requirements. The Cloud Vision API required much less initial effort to use, but bear in mind that Document AI has much more powerful<a id="_idIndexMarker468" class="calibre6 pcalibre pcalibre1"/> features, such as automated document processing, and customized models for specific <span>use cases.</span></p>
<p class="calibre3">Let’s take a look at some of Document AI’s <span>additional features.</span></p>
<h3 class="calibre11">Document AI’s response</h3>
<p class="calibre3">In our OCR example, we <a id="_idIndexMarker469" class="calibre6 pcalibre pcalibre1"/>focused on the <strong class="source-inline">document.txt</strong> object in the response. However, the full response that is returned contains a lot more information that we can use in various ways, such as the number of pages, paragraphs, and lines in the document, and many other types of metadata. When using form parsers or specialized processors, it can even highlight structured data types such as tables and <span>key-value pairs.</span></p>
<p class="calibre3">It should also be noted that in the preceding example, we performed an online inference request, in which we got a response in real time for a single document. Document AI also allows us to perform batch inference requests if we need to process large numbers of <a id="_idIndexMarker470" class="calibre6 pcalibre pcalibre1"/>documents at <span>a time.</span></p>
<h3 class="calibre11">Human in the loop (HITL) AI</h3>
<p class="calibre3">In the preceding<a id="_idIndexMarker471" class="calibre6 pcalibre pcalibre1"/> use case,<a id="_idIndexMarker472" class="calibre6 pcalibre pcalibre1"/> the model was able to identify all the words in the image. However, in reality, the sources of our images may not always be clearly legible. For example, we may need to read information from pictures of road signs that could be worn in places. This is something to bear in mind when thinking about how accurate you need the results to be. Document AI provides a <strong class="bold">HITL</strong>) feature to enable you to improve the accuracy of the results by having a human review and make updates <span>where necessary.</span></p>
<h1 id="_idParaDest-100" class="calibre5"><a id="_idTextAnchor162" class="calibre6 pcalibre pcalibre1"/>Using the Google Cloud Natural Language API to get sentiment analysis insights from textual inputs</h1>
<p class="calibre3"><strong class="bold">Natural language processing</strong> (<strong class="bold">NLP</strong>) and <strong class="bold">natural language understanding</strong> (<strong class="bold">NLU</strong>) are<a id="_idIndexMarker473" class="calibre6 pcalibre pcalibre1"/> becoming <a id="_idIndexMarker474" class="calibre6 pcalibre pcalibre1"/>ever more<a id="_idIndexMarker475" class="calibre6 pcalibre pcalibre1"/> prominent in our daily lives, and researchers<a id="_idIndexMarker476" class="calibre6 pcalibre pcalibre1"/> continue to find interesting new use cases almost every day. In this chapter, we’ll explore the simplest way to get powerful NLP/NLU functionality on Google Cloud by using the Google Cloud Natural Language API. In later chapters, we will build and use much more complex language <span>use cases.</span></p>
<h2 id="_idParaDest-101" class="calibre9"><a id="_idTextAnchor163" class="calibre6 pcalibre pcalibre1"/>Sentiment analysis with the Natural Language API</h2>
<p class="calibre3">Sentiment analysis<a id="_idIndexMarker477" class="calibre6 pcalibre pcalibre1"/> allows us to get<a id="_idIndexMarker478" class="calibre6 pcalibre pcalibre1"/> insights regarding the primary emotional tone of a piece of text. This is important for many business use cases, especially when it comes to connecting with, and understanding, your customers. For example, if you want to understand how customers feel about a new product you’ve released, you can analyze various customer interaction channels, such as reviews, social media reactions, and customer service center logs, to find out how people are reacting to the new product. This enables you to answer questions such as <span>the following:</span></p>
<ul class="calibre16">
<li class="calibre8">Are they happy <span>with it?</span></li>
<li class="calibre8">Is there a pattern of complaints emerging about a <span>specific feature?</span></li>
</ul>
<p class="calibre3">Doing this kind of analysis manually would not be possible if you have thousands of reviews, social media reactions, and service center logs <span>to process.</span></p>
<p class="calibre3">Fortunately, you can perform sentiment analysis on a piece of text with a simple API call to the Google Cloud Natural <span>Language API.</span></p>
<p class="calibre3">To do so, perform the following steps in <span>Cloud Shell:</span></p>
<ol class="calibre7">
<li class="calibre8">Create a JSON file that will contain the piece of text that we want to analyze. Just like when we discussed Document AI, we can use the <strong class="source-inline">nano</strong> command to do this, which<a id="_idIndexMarker479" class="calibre6 pcalibre pcalibre1"/> will <a id="_idIndexMarker480" class="calibre6 pcalibre pcalibre1"/>create and open the file <span>for editing:</span><pre class="source-code">
nano request.json</pre><p class="calibre3">Paste the following text into the <span><strong class="source-inline">request.json</strong></span><span> file:</span></p><pre class="source-code">{
  "document":{
    "type":"PLAIN_TEXT",
    "content":"This is the best soap I've ever used! It smells great, my skin feels amazing after using it, and my partner loves it too!"
  },
  "encodingType":"UTF8"
}</pre></li> <li class="calibre8">Press <em class="italic">Ctrl</em> + <em class="italic">X</em> to <span>exit </span><span><strong class="source-inline">nano</strong></span><span>.</span></li>
<li class="calibre8">Press <em class="italic">Y</em> to save <span>the file.</span></li>
<li class="calibre8">Press <em class="italic">Enter</em> to <span>confirm this.</span></li>
<li class="calibre8">Now, we can send the request to the Natural Language API’s <strong class="source-inline">analyzeSentiment</strong> endpoint. To do that, we will use the following <strong class="source-inline">curl</strong> command. Note that we are using the <strong class="source-inline">API_KEY</strong> environment variable that we created earlier in this chapter. This will be used to authenticate <span>our request:</span><pre class="source-code">
curl -X POST -s -H "Content-Type: application/json" --data-binary @request.json "https://language.googleapis.com/v1/documents:analyzeSentiment?key=${API_KEY}"</pre><p class="calibre3">Your response<a id="_idIndexMarker481" class="calibre6 pcalibre pcalibre1"/> should <a id="_idIndexMarker482" class="calibre6 pcalibre pcalibre1"/>look <span>like this:</span></p><pre class="source-code">{"documentSentiment": {
 { "magnitude": 1.9, "score": 0.9
  }, "language": "en",
  "sentences": [
    {"text": {"content": "This is the best soap I've ever used!", "beginOffset": 0},
      "sentiment": {"magnitude": 0.9,"score": 0.9 }},
    {"text": {"content": "It smells great, my skin feels amazing after using it, and my partner loves it too!", "beginOffset": 38 },
      "sentiment": {"magnitude": 0.9,"score": 0.9}
    }]}</pre></li> </ol>
<p class="calibre3">The first thing we can see in the output is the overall document score, which is the score for the entire body of text. After that, we can see the scores for the individual sentences that were detected. The score of the sentiment ranges between -1.0 (negative) and 1.0 (positive), and the magnitude indicates the overall strength of emotion (both positive and negative) within the given text. You can learn more about the response fields and scores <span>at </span><a href="https://cloud.google.com/natural-language/docs/basics#sentiment_analysis_response_fields" class="calibre6 pcalibre pcalibre1"><span>https://cloud.google.com/natural-language/docs/basics#sentiment_analysis_response_fields</span></a><span>.</span></p>
<p class="calibre3">In this case, both of the sentences constitute a positive review, so they both have high scores, and the overall document score is therefore <span>also high.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">If your scores are slightly different than those in the outputs, that’s because the models that serve these requests are constantly being updated with <span>new data.</span></p>
<p class="calibre3">Retry all of the previous steps in this section, but add the following two sentences at the end of the review: “The <a id="_idIndexMarker483" class="calibre6 pcalibre pcalibre1"/>only <a id="_idIndexMarker484" class="calibre6 pcalibre pcalibre1"/>bad thing is that it’s just too expensive, and that really sucks. <span>Very annoying!”</span></p>
<p class="calibre3">The overall review will then look <span>as follows:</span></p>
<p class="calibre3">“<em class="italic">This is the best soap I’ve ever used! It smells great, my skin feels amazing after using it, and my partner loves it too! The only bad thing is that it’s just too expensive, and that really sucks. </em><span><em class="italic">Very annoying!</em></span><span>”</span></p>
<p class="calibre3">When you submit the updated request, the response output will look <span>as follows:</span></p>
<pre class="source-code">
{ "documentSentiment": { "magnitude": 3.4,"score": 0.1
  }, "language": "en",
  "sentences": [
    {"text": {"content": "This is the best soap I've ever used!","beginOffset": 0},
      "sentiment": {"magnitude": 0.9,"score": 0.9}},
    {"text": {"content": "It smells great, my skin feels amazing after using it, and my pertner loves it too!",
        "beginOffset": 38},
      "sentiment": {"magnitude": 0.9,"score": 0.9}},
    {"text": {"content": "The only bad thing is that it's just too expensive, and that really sucks.",
        "beginOffset": 122},
      "sentiment": {"magnitude": 0.5,"score": -0.5}},
    {"text": {"content": "Very annoying!",
        "beginOffset": 197},
      "sentiment": {"magnitude": 0.8,"score": -0.8}
    }]}</pre> <p class="calibre3">In the output, notice that the negative sentences at the end have much lower scores, so this brings down the overall score for the entire review. This makes sense because the overall sentiment of the <a id="_idIndexMarker485" class="calibre6 pcalibre pcalibre1"/>review<a id="_idIndexMarker486" class="calibre6 pcalibre pcalibre1"/> is frustration, even though it starts with a <span>positive sentiment.</span></p>
<p class="calibre3">The Natural Language API also provides other types of functionality, such as <span>the following:</span></p>
<ul class="calibre16">
<li class="calibre8"><strong class="bold">Entity analysis</strong>: This<a id="_idIndexMarker487" class="calibre6 pcalibre pcalibre1"/> involves identifying what kinds of entities (for example, people, places, and so on) are present in a piece of text. The supported entities are listed <span>at </span><a href="https://cloud.google.com/natural-language/docs/reference/rest/v1/Entity#type" class="calibre6 pcalibre pcalibre1"><span>https://cloud.google.com/natural-language/docs/reference/rest/v1/Entity#type</span></a><span>.</span></li>
<li class="calibre8"><strong class="bold">Entity sentiment analysis</strong>: A combination of entity analysis and <span>sentiment analysis.</span></li>
<li class="calibre8"><strong class="bold">Syntactic analysis</strong>: This involves inspecting the linguistic structure of a given piece <span>of text.</span></li>
<li class="calibre8"><strong class="bold">Content classification</strong>: This involves categorizing the content of a document or piece <span>of text.</span></li>
</ul>
<p class="calibre3">To explore the Natural Language API in more detail, let’s take a look at one of its other features <span>content classification.</span></p>
<h2 id="_idParaDest-102" class="calibre9"><a id="_idTextAnchor164" class="calibre6 pcalibre pcalibre1"/>Classifying content with the Natural Language API</h2>
<p class="calibre3">Let’s imagine that we<a id="_idIndexMarker488" class="calibre6 pcalibre pcalibre1"/> want to build a search engine that can be used to search across large amounts of documents and content objects. One of the first things we will need to do is classify our documents and content objects into categories. Doing this manually on millions of objects would be impossible, or at least extremely laborious and error-prone. This is where the content classification feature of the Natural Language API can <span>be useful.</span></p>
<p class="calibre3">To demonstrate, we’re going to use the text that was produced by our Document AI OCR processor in the previous section of this chapter. This will also demonstrate an important concept, which is that you can combine multiple AI services to create more complex use cases to meet your business needs. In this case, not only can we classify regular text inputs, but we can detect text in images and then categorize the contents of <span>that text.</span></p>
<p class="calibre3">Perform the following steps in <span>Cloud Shell:</span></p>
<ol class="calibre7">
<li class="calibre8">Create a JSON file that we will use in our request to the API. This will contain the text from our <span>OCR processor:</span><pre class="source-code">
nano classify-request.json</pre></li> <li class="calibre8">Paste the following text into the <span><strong class="source-inline">classify-request.json</strong></span><span> file:</span><pre class="source-code">
{
  "document":{
    "type":"PLAIN_TEXT",
    "content":""All the summer long I stood
In the silence of the wood.
Tall and tapering I grew;
What might happen well I knew;
For one day a little bird.
Sang, and in the song I heard
Many things quite strange to me "
  },
  "classificationModelOptions":{
    "v2Model":{
      "contentCategoriesVersion":"V2"
    }
  }
}</pre></li> <li class="calibre8">Press <em class="italic">Ctrl</em> + <em class="italic">X</em> to <span>exit </span><span><strong class="source-inline">nano</strong></span><span>.</span></li>
<li class="calibre8">Press <em class="italic">Y</em> to save <span>the file.</span></li>
<li class="calibre8">Press <em class="italic">Enter</em> to <span>confirm this.</span></li>
<li class="calibre8">Now, we can send the request to the Natural Language API’s <strong class="source-inline">classifyText</strong> endpoint. To do that, we will use the following <strong class="source-inline">curl</strong> command. Note that we are using<a id="_idIndexMarker489" class="calibre6 pcalibre pcalibre1"/> the <strong class="source-inline">API_KEY</strong> environment variable that we created earlier in this chapter. This will be used to authenticate <span>our request:</span><pre class="source-code">
curl "https://language.googleapis.com/v1/documents:classifyText?key=${API_KEY}"   -s -X POST -H "Content-Type: application/json" --data-binary @classify-request.json</pre><p class="calibre3">Your response should look <span>like this:</span></p><pre class="source-code">{
  "categories": [
    {
      "name": "/Books &amp; Literature/Poetry",
      "confidence": 0.45689428
    },
    {
      "name": "/Arts &amp; Entertainment/Music &amp; Audio/Music Reference",
      "confidence": 0.22331826
    },
    {
      "name": "/Arts &amp; Entertainment/Music &amp; Audio/Rock Music",
      "confidence": 0.109513044
    }
  ]
}</pre></li> </ol>
<p class="calibre3">That’s more like it! Note that the response contains entries for multiple potential categories, each with different levels of confidence.. This demonstrates two important realities for the Solution <span>Architect role:</span></p>
<ul class="calibre16">
<li class="calibre8">While we want to automate everything as much as possible via AI/ML, it’s often necessary to have mechanisms for humans to review the model outputs and make corrections <span>where needed.</span></li>
<li class="calibre8">AI/ML workloads often consist <a id="_idIndexMarker490" class="calibre6 pcalibre pcalibre1"/>of several steps in which data is passed from one step to the next, and it’s important to implement data quality checks at each stage in <span>the process.</span></li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">When using HITL reviews, we wouldn’t need to have a human review every data point (that would be impractical, and would negate the benefits of AI/ML), but we should have mechanisms that define what kinds of values we expect to see in a given use case, if possible, or flag our outputs for human review if our model’s confidence levels are below specified thresholds for some <span>data points.</span></p>
<p class="calibre3">Now that we’ve explored how to use pre-trained models provided by Google, we’re going to look at the next level of complexity when it comes to implementing AI/ML workloads on <a id="_idIndexMarker491" class="calibre6 pcalibre pcalibre1"/>Google Cloud, which is to train our own models in a managed way, <span>using AutoML.</span></p>
<h1 id="_idParaDest-103" class="calibre5"><a id="_idTextAnchor165" class="calibre6 pcalibre pcalibre1"/>Using Vertex AI AutoML</h1>
<p class="calibre3">As we <a id="_idIndexMarker492" class="calibre6 pcalibre pcalibre1"/>discussed in <a href="B18143_03.xhtml#_idTextAnchor059" class="calibre6 pcalibre pcalibre1"><span><em class="italic">Chapter 3</em></span></a>, we can use AutoML to automate all of the steps in the model training and evaluation process. In this section, we’re going to build an AutoML Model with <span>Vertex AI.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Refer to the Vertex AutoML pricing at the following link before following the instructions in this <span>section: </span><a href="https://cloud.google.com/vertex-ai/pricing" class="calibre6 pcalibre pcalibre1"><span>https://cloud.google.com/vertex-ai/pricing</span></a><span>.</span></p>
<h2 id="_idParaDest-104" class="calibre9"><a id="_idTextAnchor166" class="calibre6 pcalibre pcalibre1"/>Use case – forecasting</h2>
<p class="calibre3">The use case we <a id="_idIndexMarker493" class="calibre6 pcalibre pcalibre1"/>will focus on for this workload is forecasting. After all, forecasting is one of the most fundamental business processes that almost all businesses have to perform in some form or other. For example, whether you own a global online retail company or just a single store in a small town, you will need to estimate how much of each product you should purchase each month, or perhaps each day, based on the expected customer demand for those items. And, forecasting is not just for physical goods. For example, if you owned a consulting or services company, you would need to estimate how many people you would need to hire to cater to the expected needs of your customers in the coming months. Being able to predict the future is a pretty important superpower, and in our case, we’re going to skip right the to “get-rich-quick” use case of forecasting stock <span>market performance.</span></p>
<p class="calibre3">Are you ready to train your first ML model? Let’s <span>dive in!</span></p>
<h3 class="calibre11">Preparation – creating a BigQuery dataset for our prediction outputs</h3>
<p class="calibre3">BigQuery is a useful tool for viewing and performing analytical queries on our prediction outputs. For this reason, we will create a BigQuery dataset to store the outputs from our AutoML tests. To create a dataset in BigQuery, perform the <span>following steps:</span></p>
<ol class="calibre7">
<li class="calibre8">In the Google Cloud console, navigate to the <strong class="bold">Google Cloud services</strong> menu → <span><strong class="bold">BigQuery</strong></span><span>.</span></li>
<li class="calibre8">In the top-left corner of the screen, you will see your project’s name. Click on the three vertical dots to the right of your project’s name (see <span><em class="italic">Figure 4</em></span><em class="italic">.9</em> <span>for reference):</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer072">
<img alt="Figure 4.9: BigQuery project menu" src="image/B18143_04_9.jpg" class="calibre78"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.9: BigQuery project menu</p>
<ol class="calibre7">
<li value="3" class="calibre8">In the menu that’s<a id="_idIndexMarker494" class="calibre6 pcalibre pcalibre1"/> displayed, select <span><strong class="bold">Create dataset</strong></span><span>.</span></li>
<li class="calibre8">Give your dataset a name, such as <strong class="source-inline">forecast_test_dataset</strong> (see <span><em class="italic">Figure</em></span><span> </span><span><em class="italic">4</em></span><span><em class="italic">.10</em></span><span>).</span></li>
<li class="calibre8">Select your preferred region, then select <span><strong class="bold">Create dataset</strong></span><span>:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer073">
<img alt="Figure 4.10: Creating a BigQuery dataset" src="image/B18143_04_10.jpg" class="calibre79"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.10: Creating a BigQuery dataset</p>
<ol class="calibre7">
<li value="6" class="calibre8">That’s it – we<a id="_idIndexMarker495" class="calibre6 pcalibre pcalibre1"/> don’t need to do anything else in BigQuery <span>for now.</span></li>
</ol>
<h3 class="calibre11">Creating the AutoML workload</h3>
<p class="calibre3">Now, it’s time to define the AutoML job that’s going to automate all the steps in our data science projects. As a reminder, the steps in the model life cycle are shown in <span><em class="italic">Figure 4</em></span><span><em class="italic">.11</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer074">
<img alt="Figure 4.11: ML model life cycle managed by AutoML" src="image/B18143_04_11.jpg" class="calibre80"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.11: ML model life cycle managed by AutoML</p>
<p class="calibre3">As we can see, the first step in the process is to ingest some data. We need to create a dataset for this purpose. We’re going to use a public dataset from Kaggle, which is a useful resource for practicing ML concepts. Forecasting use cases generally require <strong class="bold">time series</strong> data, which<a id="_idIndexMarker496" class="calibre6 pcalibre pcalibre1"/> is a sequence of data that is chronologically ordered according to time intervals. For this reason, our dataset will need to include a timestamp field. We will dive into how model training and deployment work later in this book, but for now, we’ll focus on how easily Vertex AI AutoML enables us to train a forecasting model, without the need for much <a id="_idIndexMarker497" class="calibre6 pcalibre pcalibre1"/>or any AI/ML expertise. Note that Vertex AI AutoML can also be used for classification and regression <span>use cases.</span></p>
<p class="calibre3">In our example, we will use a subset of the <em class="italic">DJIA 30 Stock Time Series</em> dataset, which can be found <span>at </span><a href="https://www.kaggle.com/datasets/szrlee/stock-time-series-20050101-to-20171231" class="calibre6 pcalibre pcalibre1"><span>https://www.kaggle.com/datasets/szrlee/stock-time-series-20050101-to-20171231</span></a><span>.</span></p>
<p class="calibre3">For reference, the data contains the <span>following fields:</span></p>
<ul class="calibre16">
<li class="calibre8"><strong class="source-inline">Date</strong>: In <span>yy-mm-dd format</span></li>
<li class="calibre8"><strong class="source-inline">Open</strong>: The price of the stock at market open (this is NYSE data, so it’s all <span>in USD)</span></li>
<li class="calibre8"><strong class="source-inline">High</strong>: The highest price reached in <span>the day</span></li>
<li class="calibre8"><strong class="source-inline">Low Close</strong>: The lowest price reached in <span>the day</span></li>
<li class="calibre8"><strong class="source-inline">Volume</strong>: The number of <span>shares traded</span></li>
<li class="calibre8"><strong class="source-inline">Name</strong>: The stock’s <span>ticker name</span></li>
</ul>
<p class="calibre3">In the clone of our GitHub repository that you created on your local machine earlier in this chapter, you will find a modified version of this file in a directory named <strong class="source-inline">data</strong>, which exists within the directory named <strong class="source-inline">Chapter</strong><strong class="source-inline">0</strong><strong class="source-inline">4</strong>. The name of the modified file <span>is </span><span><strong class="source-inline">automl-forecast-train-1002.csv</strong></span><span>.</span></p>
<p class="calibre3">Therefore, you should find the file at the following path on your local machine (the slashes will be reversed if you’re using Microsoft Windows): <strong class="source-inline">[Location in which you cloned our </strong><span><strong class="source-inline">GitHub repository]/</strong></span><span><strong class="source-inline">Chapter-04</strong></span><span><strong class="source-inline">/data/automl-forecast-train-1002.csv</strong></span><span>.</span></p>
<p class="calibre3">To create our dataset in Google Cloud, perform the <span>following steps:</span></p>
<ol class="calibre7">
<li class="calibre8">In the Google Cloud console, navigate to the <strong class="bold">Google Cloud services</strong> menu → <strong class="bold">Vertex AI</strong> → <span><strong class="bold">Datasets</strong></span><span>.</span></li>
<li class="calibre8">Select <strong class="bold">Create dataset</strong>. A dataset name will be generated automatically, but you can change it to something easier to remember if you wish. In our example, we’ve called <span>it </span><span><strong class="source-inline">my-forecasting-dataset</strong></span><span>.</span></li>
<li class="calibre8">You will also be asked to select a data type and objective. Select <strong class="bold">Tabular</strong>, and then select <strong class="bold">Forecasting</strong>. Your selections should look like what’s shown in <span><em class="italic">Figure 4</em></span><span><em class="italic">.12</em></span><span>.</span></li>
<li class="calibre8">Select your preferred region, then select <strong class="bold">Create</strong> (note that this must be the same region<a id="_idIndexMarker498" class="calibre6 pcalibre pcalibre1"/> in which you created the BigQuery dataset in the <span>previous section):</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer075">
<img alt="Figure 4.12: Create dataset" src="image/B18143_04_12.jpg" class="calibre81"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.12: Create dataset</p>
<ol class="calibre7">
<li value="5" class="calibre8">Next, we need to add data to the dataset. Select <strong class="bold">Upload CSV files from your computer</strong>, then click <strong class="bold">Select files</strong>. See <span><em class="italic">Figure 4</em></span><em class="italic">.13</em> <span>for reference:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer076">
<img alt="Figure 4.13: Add data to your dataset" src="image/B18143_04_13.jpg" class="calibre82"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.13: Add data to your dataset</p>
<ol class="calibre7">
<li value="6" class="calibre8">Select the file from<a id="_idIndexMarker499" class="calibre6 pcalibre pcalibre1"/> the following path on your local machine (the slashes will be reversed if you’re using <span>Microsoft Windows):</span><pre class="source-code">
[Location in which you cloned our GitHub repository]/Chapter-04/data/automl-forecast-train-1002.csv</pre></li> <li class="calibre8">In the <strong class="bold">Cloud Storage path</strong> input field, <span>select </span><span><strong class="bold">Browse</strong></span><span>.</span></li>
<li class="calibre8">We’re going to create a new Cloud Storage bucket for this use case. To do this, click on the symbol in the top-right corner that looks like a bucket with a plus <span>sign (<img alt="" role="presentation" src="image/Icon1.png" class="calibre83"/>).</span></li>
<li class="calibre8">Give the bucket a unique name and select <strong class="bold">Create</strong> (you can leave all of the bucket configuration options at their <span>default values).</span></li>
<li class="calibre8">If you are prompted to prevent public access, select <strong class="bold">Confirm</strong>. This prevents any items in your bucket from being made public, which is a best practice unless you specifically want to create publicly accessible content. In this example, we do not need to create publicly <span>accessible content.</span></li>
<li class="calibre8">When your bucket has<a id="_idIndexMarker500" class="calibre6 pcalibre pcalibre1"/> been created, click <strong class="bold">Select</strong> at the bottom of the screen. With that, your bucket is now the storage location for our training data. The resulting screen should look similar to what’s shown in <span><em class="italic">Figure 4</em></span><span><em class="italic">.14</em></span><span>:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer078">
<img alt="Figure 4.14: Add data to your dataset" src="image/B18143_04_14.jpg" class="calibre84"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.14: Add data to your dataset</p>
<ol class="calibre7">
<li value="12" class="calibre8"><span>Select </span><span><strong class="bold">Continue</strong></span><span>.</span></li>
<li class="calibre8">When the file has<a id="_idIndexMarker501" class="calibre6 pcalibre pcalibre1"/> been uploaded, you should see a message saying that the upload has been completed. Now, we’re ready to start training <span>our model!</span></li>
<li class="calibre8">In the details screen for your dataset, select the button that says <strong class="bold">Train </strong><span><strong class="bold">new model</strong></span><span>.</span></li>
<li class="calibre8">On the next screen that appears, select <span><strong class="bold">AutoML (Default)</strong></span><span>.</span></li>
<li class="calibre8">Next, enter the details for the AutoML workload, as follows (see <span><em class="italic">Figure 4</em></span><em class="italic">.15</em> for the final <span>configuration details):</span><ol class="calibre77"><li class="upper-roman">The dataset name is automatically selected as the name for the workload. You can leave it at the default value, or change the name as <span>you wish.</span></li><li class="upper-roman">We’re going to try to predict the volume of the company’s stocks that will be sold on each date, so select <strong class="bold">Volume</strong> as the <span>target column.</span></li><li class="upper-roman">The <strong class="bold">Name</strong> column is the series <span>identifier column.</span></li><li class="upper-roman">The <strong class="bold">Date</strong> column <a id="_idIndexMarker502" class="calibre6 pcalibre pcalibre1"/>contains our timestamps, so we will select this as the <span>timestamp column.</span></li><li class="upper-roman">Our <strong class="bold">Date</strong> column contains a timestamp for each day, so the data granularity <span>is </span><span><strong class="bold">Daily</strong></span><span>.</span></li><li class="upper-roman">We can leave holiday regions blank for this <span>use case.</span></li><li class="upper-roman">We’re going to set <strong class="bold">Forecast horizon</strong> and <strong class="bold">Context window</strong> to <strong class="bold">10</strong>. You can play around with these values if you’d like to see how they affect the <span>resulting outputs.</span></li><li class="upper-roman">Select <strong class="bold">Export test dataset </strong><span><strong class="bold">to BigQuery</strong></span><span>.</span></li><li class="upper-roman">In the <strong class="bold">BigQuery path</strong> input field, input the details of the BigQuery dataset we created earlier in this section. The format will be <strong class="source-inline">[project_name].[dataset_name].[table_name]</strong>, where we have <span>the following:</span><ol class="calibre77"><li class="lower-roman"><strong class="source-inline">project_name</strong> is the name of your Google Cloud project (hint: remember seeing this in the BigQuery console when you were creating the <span>BigQuery dataset).</span></li><li class="lower-roman"><strong class="source-inline">dataset_name</strong> is the name of the BigQuery dataset you created; for <span>example, </span><span><strong class="bold">forecast_test_dataset</strong></span><span>.</span></li><li class="lower-roman"><strong class="source-inline">table_name</strong> is the name of the table that will be created to store the test outputs. You can type any name here, and that name will be assigned to the table that will be created. <em class="italic">It’s important to note that this table will be created by our AutoML job, so it must NOT have been created manually in BigQuery before this point. Only the dataset must have been created; not the table within </em><span><em class="italic">that dataset.</em></span></li><li class="lower-roman">When you have entered the dataset details, click <strong class="bold">Select</strong>. The dataset path will <a id="_idIndexMarker503" class="calibre6 pcalibre pcalibre1"/>appear in the <strong class="bold">BigQuery path</strong> <span>input field:</span></li></ol></li></ol></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer079">
<img alt="Figure 4.15: Model details" src="image/B18143_04_15.jpg" class="calibre85"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.15: Model details</p>
<ol class="calibre7">
<li value="17" class="calibre8"><span>Select </span><span><strong class="bold">Continue</strong></span><span>.</span></li>
<li class="calibre8">On the <strong class="bold">Training options</strong> screen that appears, select the checkboxes next to the <strong class="bold">Close</strong>, <strong class="bold">High</strong>, <strong class="bold">Low</strong>, and <strong class="bold">Open</strong> <span>column names.</span></li>
<li class="calibre8">When you do that, four menus will appear in blue text near the top of the screen (see <span><em class="italic">Figure 4</em></span><em class="italic">.16</em> for reference). Click on the <strong class="bold">Feature type</strong> menu and select <strong class="bold">Covariate</strong>. This is a required step, and it indicates that these columns in the training dataset<a id="_idIndexMarker504" class="calibre6 pcalibre pcalibre1"/> contain values that change <span>over time:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer080">
<img alt="Figure 4.16: Training options" src="image/B18143_04_16.jpg" class="calibre86"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.16: Training options</p>
<ol class="calibre7">
<li value="20" class="calibre8"><span>Select </span><span><strong class="bold">Continue</strong></span><span>.</span></li>
<li class="calibre8">On the <strong class="bold">Compute and pricing</strong> screen that appears, we can specify the budget in terms of the maximum number of node hours for which we want to allow our AutoML job to run. A link is provided on that screen for further details on how this pricing model works. For testing purposes, we will select the minimum possible number of node hours, which is <strong class="bold">1</strong>. For this reason, enter <strong class="source-inline">1</strong> in the input field (see <span><em class="italic">Figure 4</em></span><em class="italic">.17</em> <span>for reference):</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer081">
<img alt="Figure 4.17: Compute and pricing budget" src="image/B18143_04_17.jpg" class="calibre87"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.17: Compute and pricing budget</p>
<ol class="calibre7">
<li value="22" class="calibre8">Select <span><strong class="bold">Start training</strong></span><span>.</span></li>
<li class="calibre8">To monitor our training job, we can select <strong class="bold">Training</strong> from the menu on the left-hand side of <span>the screen.</span></li>
<li class="calibre8">When the status of our job changes to <strong class="bold">Finished</strong>, our model has been trained, and we can begin using it to <span>get predictions.</span></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Due to the various steps in the AutoML process, and the concept of a “node hour,” the job may run for more than <span>1 hour.</span></p>
<p class="calibre3">Congratulations! You<a id="_idIndexMarker505" class="calibre6 pcalibre pcalibre1"/> have trained your first ML model on Google Cloud. Let’s take a look at some details regarding <span>our model.</span></p>
<h3 class="calibre11">Viewing model details</h3>
<p class="calibre3">When the status of our model training job changes to <strong class="bold">Finished</strong>, we can click on the name of the training job and see a lot of useful details regarding our model (see <span><em class="italic">Figure 4</em></span><em class="italic">.18</em> for reference). Along the top of the screen, we can see various performance metrics, such <a id="_idIndexMarker506" class="calibre6 pcalibre pcalibre1"/>as <strong class="bold">Mean Absolute Error</strong> (<strong class="bold">MAE</strong>), <strong class="bold">Mean Absolute Percentage Error</strong> (<strong class="bold">MAPE</strong>), and <a id="_idIndexMarker507" class="calibre6 pcalibre pcalibre1"/>others. You can click the question mark symbol next to each one to learn more about it. We will also discuss these metrics in more detail in later chapters in <span>this book.</span></p>
<p class="calibre3">Another useful piece of information is <strong class="bold">Feature importance</strong>, which shows us how much each input feature appears to influence the model outputs. This is very important for understanding how our <span>model works.</span></p>
<p class="calibre3">Can you think of how each of these features may influence the predicted sales volume of stocks? For example, when a stock price is low, do people buy more of that stock? If this is true, does it make sense that the <strong class="bold">Low</strong> feature – which represents the stock’s lowest price point each day – would be important in predicting how much of that stock would be sold on a <a id="_idIndexMarker508" class="calibre6 pcalibre pcalibre1"/><span>given day?</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer082">
<img alt="Figure 4.18: Model metrics" src="image/B18143_04_18.jpg" class="calibre88"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 4.18: Model metrics</p>
<p class="calibre3">In addition to our model’s performance metrics, let’s take a look at some of the predictions our model made as part of the testing process during our AutoML <span>workload execution.</span></p>
<h3 class="calibre11">Viewing model predictions</h3>
<p class="calibre3">To take a look at some of the model outputs that were generated by our AutoML job, we need to view the BigQuery table that we created to store those outputs. To do this, perform the <span>following steps:</span></p>
<ol class="calibre7">
<li class="calibre8">In the Google Cloud console, navigate to the <strong class="bold">Google Cloud services</strong> menu → <span><strong class="bold">BigQuery</strong></span><span>.</span></li>
<li class="calibre8">In the top-left corner of the screen, click on your project’s name, then click on your dataset’s name, and then click on the <span>table’s name.</span></li>
<li class="calibre8">You will see the schema of <span>the table.</span></li>
<li class="calibre8">Click on the <strong class="bold">Preview</strong> tab; a preview of the output data will <span>be displayed.</span></li>
<li class="calibre8">Scroll to the right; you will see columns named <strong class="bold">predicted_Volume.value</strong> and <strong class="bold">predicted_on_Date</strong>. These show us the prediction outputs from <span>our model.</span></li>
</ol>
<p class="calibre3">It’s important to note that we only allowed our job to run for 1 node hour, so our prediction values may not be accurate at this point. An AutoML job would usually need to run for a longer time<a id="_idIndexMarker509" class="calibre6 pcalibre pcalibre1"/> to find the best model. This is something to bear in mind from a cost perspective. If your budget allows, try running the AutoML job for longer periods, and see how it affects the <span>model’s performance.</span></p>
<h1 id="_idParaDest-105" class="calibre5"><a id="_idTextAnchor167" class="calibre6 pcalibre pcalibre1"/>Summary</h1>
<p class="calibre3">In this chapter, you learned how to use Google Cloud’s high-level AI/ML APIs to implement AI/ML functionality by using models that are trained and maintained by Google. Then, you moved on to train your own ML model using Vertex AI AutoML. All of this was performed with the help of fully managed services on Google Cloud. In the next chapter, and beyond, we’re going to dive in deeper, and you will build your own models from scratch so that you get to see how each of the steps in the model development life cycle works in much <span>more detail.</span></p>
</div>
</div></body></html>