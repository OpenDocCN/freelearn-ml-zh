- en: Chapter 7. What Is He Doing? Motion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 他正在做什么？运动
- en: In this chapter, we will show you different techniques related to motion, as
    estimated from video frames. After a short introduction and definitions, we will
    show you how to read video frames captured from a camera. Then, we will tackle
    the all-important Optical Flow technique. In the third section, we will show you
    different functions that can be used for tracking. The Motion history and Background
    subtraction techniques are explained in the fourth and fifth sections, respectively.
    Finally, image alignment with the ECC method is explained. Every example has been
    developed and tested for the latest version of OpenCV in GitHub. Most of the functions
    can work in the previous versions equally, leading to some changes that will be
    discussed. Most of the functions introduced in this chapter are in the `video`
    module.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将向您展示从视频帧中估计出的不同运动技术。在简短介绍和定义之后，我们将向您展示如何读取从摄像头捕获的视频帧。然后，我们将探讨至关重要的光流技术。在第三部分，我们将向您展示可用于跟踪的不同函数。运动历史和背景减法技术在第四和第五部分中分别解释。最后，我们将解释使用ECC方法进行图像对齐。每个示例都已针对GitHub上OpenCV的最新版本开发和测试。大多数函数在先前版本中也可以同样工作，导致了一些将被讨论的变化。本章中介绍的大多数函数都在`video`模块中。
- en: Note
  id: totrans-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To test the latest source code available in GitHub, go to [https://github.com/itseez/opencv](https://github.com/itseez/opencv)
    and download the library code as a ZIP file. Then unzip it to a local folder and
    follow the same steps described in [Chapter 1](part0014_split_000.html#page "Chapter 1. Getting
    Started"), *Getting Started*, to compile and install the library.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试GitHub上可用的最新源代码，请访问[https://github.com/itseez/opencv](https://github.com/itseez/opencv)并下载库代码作为ZIP文件。然后将其解压到本地文件夹，并按照[第1章](part0014_split_000.html#page
    "第1章. 开始")中描述的相同步骤，*开始*，来编译和安装库。
- en: Motion history
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运动历史
- en: Motion is a very important topic in Computer Vision. Once we detect and isolate
    an object or person of interest, we can extract valuable data such as positions,
    velocity, acceleration, and so on. This information can be used for action recognition,
    behavior pattern studies, video stabilization, augmented reality, and so on.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 运动是计算机视觉中的一个非常重要的话题。一旦我们检测和隔离了感兴趣的对象或人，我们就可以提取有价值的数据，如位置、速度、加速度等。这些信息可用于动作识别、行为模式研究、视频稳定、增强现实等。
- en: The Optical Flow technique is a pattern of an object's apparent motion. Surfaces
    and edges in a visual scene are caused by relative motion between an observer
    and scene or between the camera and the scene. The concept of the Optical Flow
    technique is central in Computer Vision and is associated with techniques/tasks
    such as motion detection, object segmentation, time-to-control information, focus
    of expansion calculations, luminance, motion compensated encoding, and stereo
    disparity measurement.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 光流技术是一种对象的明显运动模式。视觉场景中的表面和边缘是由观察者与场景或摄像头与场景之间的相对运动引起的。光流技术的概念在计算机视觉中至关重要，并与运动检测、对象分割、时间控制信息、扩展焦点计算、亮度、运动补偿编码和立体视差测量等技术/任务相关联。
- en: '**Video tracking** consists of locating a moving object (or multiple objects)
    over time using videos captured from a camera or file. The aim of video tracking
    is to associate target objects in consecutive video frames. It has a variety of
    uses, some of which are video editing, medical imaging, traffic control, augmented
    reality, video communication and compression, security and surveillance, and human-computer
    interaction.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**视频跟踪**是指使用从摄像头或文件捕获的视频在一段时间内定位移动对象（或多个对象）。视频跟踪的目的是将连续视频帧中的目标对象关联起来。它有多种用途，其中一些包括视频编辑、医学成像、交通控制、增强现实、视频通信和压缩、安全和监控以及人机交互。'
- en: '**Motion** templates were invented at the MIT Media Lab by Bobick and David
    in 1996\. The use of the motion templates is a simple yet robust technique that
    tracks general movement. OpenCV motion template functions only work with single
    channel images. A silhouette (or part of a silhouette) of an object is needed.
    These silhouettes can be obtained in different ways. For example, segmentation
    techniques can be used to detect the interest object and then perform tracking
    with motion templates. Another option is to use the Background subtraction technique
    to detect foreground objects and then track them. There are other techniques too,
    although, in this chapter, we will see two examples that use the Background subtraction
    technique.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**运动**模板是在 1996 年由 Bobick 和 David 在麻省理工学院媒体实验室发明的。使用运动模板是一种简单而稳健的技术，可以跟踪一般运动。OpenCV
    运动模板函数仅适用于单通道图像。需要一个物体的轮廓（或部分轮廓）。这些轮廓可以通过不同的方式获得。例如，可以使用分割技术来检测感兴趣的对象，然后使用运动模板进行跟踪。另一种选择是使用背景减法技术来检测前景对象，然后跟踪它们。还有其他技术，尽管在本章中，我们将看到两个使用背景减法技术的示例。'
- en: '**Background subtraction** is a technique by which an image foreground or region
    of interest is extracted for further processing, for example, people, cars, text,
    and so on. The Background subtraction technique is a widely used approach for
    detecting moving objects in videos captured from static cameras. The essence of
    the Background subtraction technique is to detect the moving objects from differences
    between current frames and a reference image taken without target objects present,
    which is usually called a background image.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**背景减法**是一种技术，通过它可以从图像中提取前景或感兴趣区域以进行进一步处理，例如人、汽车、文本等。背景减法技术是检测从静态摄像头捕获的视频中移动对象的一种广泛使用的方法。背景减法技术的本质是从当前帧和没有目标对象存在的参考图像之间的差异中检测移动对象，这通常被称为背景图像。'
- en: '**Image alignment** can be seen as a mapping between the coordinate systems
    of two or more images taken from different points of view. The first step is,
    therefore, the choice of an appropriate geometric transformation that adequately
    models this mapping. This algorithm can be used in a wide range of applications,
    such as image registration, object tracking, super-resolution, and visual surveillance
    by moving cameras.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**图像配准**可以看作是来自不同视角的两个或多个图像的坐标系之间的映射。因此，第一步是选择一个合适的几何变换，足以模拟这种映射。该算法可以应用于广泛的领域，例如图像配准、目标跟踪、超分辨率和移动摄像头的视觉监控。'
- en: Reading video sequences
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取视频序列
- en: To process a video sequence, we should be able to read each frame. OpenCV has
    developed an easy-to-use framework that can work with video files and camera input.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理视频序列，我们应该能够读取每一帧。OpenCV 开发了一个易于使用的框架，可以处理视频文件和摄像头输入。
- en: 'The following code is a `videoCamera` example that works with a video captured
    from a video camera. This example is a modification of an example in [Chapter
    1](part0014_split_000.html#page "Chapter 1. Getting Started"), *Getting Started*,
    and we will use it as the basic structure for other examples in this chapter:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是一个 `videoCamera` 示例，它使用从视频摄像头捕获的视频。这个示例是对 [第 1 章](part0014_split_000.html#page
    "Chapter 1. Getting Started") 中的示例的修改，*入门指南*，我们将用它作为本章其他示例的基本结构：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding code example creates a window that shows you the grayscale video's
    camera capture. To initiate the capture, an instance of the `VideoCapture` class
    has been created with the zero-based camera index. Then, we check whether the
    video capture can be successfully initiated. Each frame is then read from the
    video sequence using the `read` method. This video sequence is converted to grayscale
    using the `cvtColor` method with the `COLOR_BGR2GRAY` parameter and is displayed
    on the screen until the user presses the *Esc* key. Then, the video sequence is
    finally released. The previous frame is stored because it will be used for some
    examples that follow.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码示例创建了一个窗口，显示灰度视频的摄像头捕获。为了启动捕获，已经创建了一个 `VideoCapture` 类的实例，其摄像头索引为零。然后，我们检查视频捕获是否可以成功启动。然后使用
    `read` 方法从视频序列中读取每一帧。该视频序列使用 `cvtColor` 方法与 `COLOR_BGR2GRAY` 参数转换为灰度，并在用户按下 *Esc*
    键之前显示在屏幕上。然后，最终释放视频序列。上一帧被存储，因为它将被用于后续的一些示例。
- en: Note
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `COLOR_BGR2GRAY` parameter can be used in OpenCV 3.0\. In the previous versions,
    we also had `CV_BGR2GRAY`.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`COLOR_BGR2GRAY` 参数可以在 OpenCV 3.0 中使用。在之前的版本中，我们也有 `CV_BGR2GRAY`。'
- en: In the summary, we have shown you a simple method that works with video sequences
    using a video camera. Most importantly, we have learned how to access each video
    frame and can now make any type of frame processing.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在总结中，我们向您展示了一个使用视频相机处理视频序列的简单方法。最重要的是，我们已经学会了如何访问每个视频帧，现在可以处理任何类型的帧。
- en: Note
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: With regard to video and audio formats supported by OpenCV, more information
    can be found at the [ffmpeg.org](http://ffmpeg.org) website, which presents a
    complete open source and cross-platform solution for audio and video reading,
    recording, converting, and streaming. The OpenCV classes that work with video
    files are built on top of this library. The [Xvid.org](http://Xvid.org) website
    offers you an open source video codec library based on the MPEG-4 standard for
    video compression. This codec library has a competitor called DivX, which offers
    you proprietary but free codec and software tools.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 关于OpenCV支持的音视频格式，更多详细信息可以在[ffmpeg.org](http://ffmpeg.org)网站上找到，该网站提供了一个完整的开源跨平台解决方案，用于音频和视频的读取、录制、转换和流式传输。与视频文件一起工作的OpenCV类都是基于这个库构建的。在[Xvid.org](http://Xvid.org)网站上，你可以找到一个基于MPEG-4标准的开源视频编解码库。这个编解码库有一个竞争对手叫做DivX，它提供专有但免费的编解码器和软件工具。
- en: The Lucas-Kanade optical flow
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lucas-Kanade光流
- en: 'The **Lucas-Kanade** (**LK**) algorithm was originally proposed in 1981, and
    it has become one of the most successful methods available in Computer Vision.
    Currently, this method is typically applied to a subset of key points in the input
    image. This method assumes that optical flow is a necessary constant in a local
    neighborhood of the pixel that is under consideration and solves the basic Optical
    Flow technique equations you can see equation (1), for each pixel (x, y) on that
    neighborhood. The method also assumes that displacements between two consecutive
    frames are small and are approximately a way to get an over-constrained system
    of the considered points:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**Lucas-Kanade**（**LK**）算法最初于1981年提出，并已成为计算机视觉中最成功的方法之一。目前，这种方法通常应用于输入图像的关键点子集。该方法假设光流是考虑像素局部邻域中的一个必要常数，并为该邻域中的每个像素（x,
    y）解决基本光流技术方程（见方程（1））。该方法还假设连续帧之间的位移很小，并且是获得考虑点过度约束系统的一种方法：'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will now focus on the **Pyramidal Lucas-Kanade** method, which estimates
    the optical flow in a pyramid using the `calcOpticalFlowPyrLK()` function. This
    method first estimates the optical flow at the top of the pyramid, thus avoiding
    the problems caused by violations of our assumptions of small and coherent motion.
    The motion estimate from this first level is then used as the starting point to
    estimate motion at the next level, as shown in the pyramid in the following diagram:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将关注**金字塔Lucas-Kanade**方法，该方法使用`calcOpticalFlowPyrLK()`函数在金字塔中估计光流。这种方法首先在金字塔的顶部估计光流，从而避免了由违反我们对小而一致运动假设引起的问题。然后，从这个第一级的光流估计被用作下一个级别的运动估计的起点，如下图中金字塔所示：
- en: '![The Lucas-Kanade optical flow](img/00047.jpeg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![Lucas-Kanade光流](img/00047.jpeg)'
- en: Pyramidal Lucas-Kanade
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 金字塔Lucas-Kanade
- en: 'The following example uses the `maxMovementLK` function to implement a motion
    detector:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例使用`maxMovementLK`函数实现运动检测器：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding example shows you a window with each movement. If there is a
    large movement, a message is displayed on the screen. Firstly, we need to obtain
    a set of appropriate key points in the image on which we can estimate the optical
    flow. The `goodFeaturesToTrack()` function uses the method that was originally
    proposed by Shi and Tomasi to solve this problem in a reliable way, although you
    can also use other functions to detect important and easy-to-track features (see
    [Chapter 5](part0042_split_000.html#page "Chapter 5. Focusing on the Interesting
    2D Features"), *Focusing on the Interesting 2D Features*). `MAX_FEATURES` is set
    to `500` to limit the number of key points. The Lucas-Kanade method parameters
    are then set and `calcOpticalFlowPyrLK()` is called. When the function returns,
    the status (`status`) array is checked to see which points were successfully tracked
    and that the new set of points (`new_features`) with the estimated positions is
    used. Lines are drawn to represent the motion, and if there is a displacement
    greater than `MAX_MOVEMENT`—for example—100, a message is shown on the screen.
    We can see two screen captures, as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例展示了每次移动时窗口的显示情况。如果存在较大移动，屏幕上会显示一条消息。首先，我们需要在图像中获取一组适当的关键点，以便我们可以估计光流。`goodFeaturesToTrack()`函数使用Shi和Tomasi最初提出的方法以可靠的方式解决这个问题，尽管你也可以使用其他函数来检测重要且易于跟踪的特征（参见[第5章](part0042_split_000.html#page
    "第5章. 专注于有趣的2D特征")，*专注于有趣的2D特征*）。`MAX_FEATURES`被设置为`500`以限制关键点的数量。然后设置Lucas-Kanade方法参数并调用`calcOpticalFlowPyrLK()`。当函数返回时，检查状态(`status`)数组以查看哪些点被成功跟踪，并且使用估计位置的新点集(`new_features`)。绘制线条以表示运动，如果位移大于`MAX_MOVEMENT`——例如——100，屏幕上会显示一条消息。我们可以看到以下两个屏幕截图：
- en: '![The Lucas-Kanade optical flow](img/00048.jpeg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![Lucas-Kanade光流](img/00048.jpeg)'
- en: Output of the maxMovementLK example
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`maxMovementLK`示例的输出'
- en: 'Using the modified `videoCamera` example, we have applied the `maxMovementLK()`
    function to detect large movements:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用修改后的`videoCamera`示例，我们已将`maxMovementLK()`函数应用于检测大移动：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This method is computationally efficient because tracking is only performed
    on important or interesting points.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法计算效率高，因为跟踪仅在重要或有趣点上执行。
- en: The Gunnar-Farneback optical flow
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gunnar-Farneback光流
- en: The **Gunnar-Farneback** algorithm was developed to produce dense Optical Flow
    technique results (that is, on a dense grid of points). The first step is to approximate
    each neighborhood of both frames by quadratic polynomials. Afterwards, considering
    these quadratic polynomials, a new signal is constructed by a global displacement.
    Finally, this global displacement is calculated by equating the coefficients in
    the quadratic polynomials' yields.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**Gunnar-Farneback**算法被开发出来以产生密集的光流技术结果（即在密集的点网格上）。第一步是使用二次多项式近似两帧的每个邻域。之后，考虑到这些二次多项式，通过全局位移构建一个新的信号。最后，通过等于二次多项式产出的系数来计算这个全局位移。'
- en: 'Let''s now see the implementation of this method, which uses the `calcOpticalFlowFarneback()`function.
    The following is an example (`maxMovementFarneback`) that uses this function to
    detect the maximum movement as shown in the previous example:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看这个方法的实现，它使用了`calcOpticalFlowFarneback()`函数。以下是一个示例(`maxMovementFarneback`)，它使用此函数检测前一个示例中显示的最大移动：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This function receives two consecutive frames, estimates the optical flow with
    different parameters, and returns an array with the same size as the input frame,
    where each pixel is actually a point (`Point2f`) that represents the displacement
    for that pixel. Firstly, different parameters are set for this function. Of course,
    you can also use your own criteria to configure the performance. Then, with these
    parameters, the Optical Flow technique is performed between each two consecutive
    frames. Consequently, we obtain an array with the estimations for each pixel,
    which is `optical_flow`. Finally, the movements that are greater than `MIN_MOVEMENT`
    are displayed on the screen. If the largest movement is greater than `MAX_MOVEMENT`,
    then an `INTRUDER` message is displayed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数接收两个连续帧，使用不同的参数估计光流，并返回一个与输入帧大小相同的数组，其中每个像素实际上是一个点(`Point2f`)，代表该像素的位移。首先，为此函数设置不同的参数。当然，你也可以使用自己的标准来配置性能。然后，使用这些参数，在每两个连续帧之间执行光流技术。因此，我们获得一个包含每个像素估计的数组，即`optical_flow`。最后，显示屏幕上大于`MIN_MOVEMENT`的移动。如果最大移动大于`MAX_MOVEMENT`，则显示`INTRUDER`消息。
- en: Understandably, this method is quite slow because the Optical Flow technique
    is computed over each pixel on the frame. The output of this algorithm is similar
    to the previous method, although it's much slower.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 可以理解，这种方法相当慢，因为光流技术在每一帧的每个像素上计算。此算法的输出与先前的方法类似，尽管它要慢得多。
- en: The Mean-Shift tracker
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mean-Shift跟踪器
- en: The **Mean-Shift** method allows you to locate the maximum of a density function
    given discrete data sampled from that function. It is, therefore, useful for detecting
    the modes of this density. Mean-Shift is an iterative method, and an initial estimation
    is needed.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mean-Shift**方法允许你定位从该函数离散采样得到的密度函数的最大值。因此，它对于检测这种密度的模式非常有用。Mean-Shift是一种迭代方法，需要初始估计。'
- en: 'The algorithm can be used for visual tracking. In this case, the color histogram
    of the tracked object is used to compute the confidence map. The simplest of such
    algorithm would create a confidence map in the new image based on the object histogram
    taken from the previous image, and Mean-Shift is used to find the peak of the
    confidence map near the object''s previous position. The confidence map is a probability
    density function on the new image, assigning each pixel of the new image a probability,
    which is the probability of the pixel color occurring in the object in the previous
    image. Next, we show you an example (`trackingMeanShift`) using this function:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法可用于视觉跟踪。在这种情况下，跟踪对象的颜色直方图用于计算置信图。此类算法中最简单的一种会在新图像中基于从上一图像中获取的对象直方图创建置信图，并使用Mean-Shift在对象之前位置附近找到置信图的峰值。置信图是新图像上的概率密度函数，为每个新图像的像素分配一个概率，即该像素颜色在上一图像中的对象中出现的概率。接下来，我们通过此函数（`trackingMeanShift`）展示一个示例：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This example shows you a window with an initial centered rectangle where the
    tracking is performed. First, the criteria parameter is set. The function that
    implements the method needs three parameters: the main image, the interest area
    that we want to search, and the term criteria for different modes of tracking.
    Finally, a rectangle is obtained from `meanShift()`, and `search_window` is drawn
    on the main image.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例显示了一个初始居中的矩形窗口，其中执行跟踪。首先，设置准则参数。实现此方法的函数需要三个参数：主图像、我们想要搜索的兴趣区域以及不同跟踪模式的术语准则。最后，从`meanShift()`获得一个矩形，并在主图像上绘制`search_window`。
- en: 'Using a modified `videoCamera` example, we apply this method for tracking.
    A static window of the screen is used to search. Of course, you can manually adjust
    another window or use other functions to detect interest objects and then perform
    the tracking on them:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用修改后的`videoCamera`示例，我们将此方法应用于跟踪。使用屏幕的静态窗口进行搜索。当然，你可以手动调整另一个窗口或使用其他功能来检测感兴趣的对象，然后对它们进行跟踪：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here, we can see the following two screen captures:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们可以看到以下两个屏幕截图：
- en: '![The Mean-Shift tracker](img/00049.jpeg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![Mean-Shift跟踪器](img/00049.jpeg)'
- en: Output of the trackingMeanShift example
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: trackingMeanShift示例的输出
- en: The CamShift tracker
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CamShift跟踪器
- en: The `CamShift` (**Continuously Adaptive Mean Shift**) algorithm is an image
    segmentation method that was introduced by Gary Bradski of OpenCV fame in 1998\.
    It differs from `MeanShift` in that a search window adjusts itself in size. If
    we have a well-segmented distribution (for example, face features that stay compact),
    this method will automatically adjust itself to the face sizes as the person moves
    closer or farther from the camera.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`CamShift`（**连续自适应Mean Shift**）算法是由OpenCV的Gary Bradski在1998年提出的一种图像分割方法。它与`MeanShift`的不同之处在于搜索窗口会调整其大小。如果我们有一个很好地分割的分布（例如，保持紧凑的面部特征），当人靠近或远离相机时，此方法会自动调整到人脸大小。'
- en: Note
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We can find a `CamShift` reference at [http://docs.opencv.org/trunk/doc/py_tutorials/py_video/py_meanshift/py_meanshift.html](http://docs.opencv.org/trunk/doc/py_tutorials/py_video/py_meanshift/py_meanshift.html).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[http://docs.opencv.org/trunk/doc/py_tutorials/py_video/py_meanshift/py_meanshift.html](http://docs.opencv.org/trunk/doc/py_tutorials/py_video/py_meanshift/py_meanshift.html)找到`CamShift`的参考。
- en: 'We will now see the following example (`trackingCamShift`) using this method:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用此方法查看以下示例（`trackingCamShift`）：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This function structure is very similar to the one in the preceding section;
    the only difference is that a bounding rectangle is returned from `CamShift()`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数结构与前一个部分中的非常相似；唯一的区别是`CamShift()`返回一个边界矩形。
- en: The Motion templates
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运动模板
- en: Motion template is a technique in image processing for finding a small part
    of an image or silhouette that matches a template image. This template matcher
    is used to make comparisons with respect to similarity and to examine the likeness
    or difference. Templates might potentially require sampling of a large number
    of points. However, it is possible to reduce these numbers of points by reducing
    the resolution of the search; another technique to improve these templates is
    to use pyramid images.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 动作模板是图像处理中用于找到与模板图像匹配的图像或轮廓的小部分的技术。此模板匹配器用于进行相似性比较和检查相似或差异。模板可能需要大量点的采样。然而，通过降低搜索分辨率可以减少这些点的数量；另一种改进这些模板的技术是使用金字塔图像。
- en: In OpenCV's examples (`[opencv_source_code]/samples/c/motempl.c`), a related
    program can be found.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV的示例（`[opencv_source_code]/samples/c/motempl.c`）中可以找到一个相关的程序。
- en: The Motion history template
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动作历史模板
- en: 'We now assume that we have a good silhouette or template. New silhouettes are
    then captured and overlaid using the current time stamp as the weight. These sequentially
    fading silhouettes record the history of the previous movement and are thus referred
    to as the Motion history template. Silhouettes whose time stamp is more than a
    specified `DURATION` older than the current time stamp are set to zero. We have
    created a simple example (`motionHistory`) using the `updateMotionHistory()`OpenCV
    function on two frames as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们假设我们有一个好的轮廓或模板。然后，使用当前时间戳作为权重捕获并叠加新的轮廓。这些依次淡出的轮廓记录了之前的运动历史，因此被称为动作历史模板。时间戳比当前时间戳早于指定`DURATION`的轮廓被设置为零。我们使用`updateMotionHistory()`OpenCV函数在两个帧上创建了一个简单的示例（`motionHistory`）如下：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `THRESH_BINARY` parameter can be used on OpenCV 3.0\. In the previous versions,
    we also had `CV_THRESH_BINARY`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV 3.0中可以使用`THRESH_BINARY`参数。在之前的版本中，我们也有`CV_THRESH_BINARY`。
- en: This example shows you a window where the motion history is drawn. The first
    step is to obtain a silhouette; the Background subtraction technique is used for
    this. The difference in the absolute value is obtained from the two input frames.
    In the second step, a binary thresholding is applied to remove noise from the
    silhouette. Then, the current time is obtained. The final step is to perform the
    updating of the Motion history template using OpenCV's function.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例向您展示了一个绘制动作历史的窗口。第一步是获取轮廓；为此使用了背景减法技术。从两个输入帧中获取绝对值的差异。第二步，应用二值阈值以从轮廓中去除噪声。然后，获取当前时间。最后一步是使用OpenCV的函数更新动作历史模板。
- en: 'We have also set `DURATION` to `5`. Note that it is necessary to initialize
    `INITIAL_TIME` and `history`. Besides, we can use this function call from the
    modified `videoCamera` example as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将`DURATION`设置为`5`。请注意，初始化`INITIAL_TIME`和`history`是必要的。此外，我们可以使用修改后的`videoCamera`示例中的此函数调用如下：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To use the `clock()` function, which gets the current time, we need to include
    `<ctime>`. Some screen captures will be shown in which a person is walking in
    front of the camera.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用获取当前时间的`clock()`函数，我们需要包含`<ctime>`。以下是一些屏幕截图，显示有人在摄像机前行走。
- en: '![The Motion history template](img/00050.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![动作历史模板](img/00050.jpeg)'
- en: Output of the motionHistory example
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 动作历史示例的输出
- en: The Motion gradient
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动作梯度
- en: 'Once the Motion templates have a collection of object silhouettes overlaid
    in time, we can obtain the directions of movement by computing the gradients of
    the `history` image. The following example (`motionGradient`) computes the gradients:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦动作模板在时间上叠加了一系列物体轮廓，我们可以通过计算`历史`图像的梯度来获得运动方向。以下示例（`motionGradient`）计算了梯度：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'A screen capture is shown with a person moving his head in front of the camera
    (see the following screenshot). Each line represents the gradient for each pixel.
    Different frames also overlap at a `t` time:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 屏幕截图显示有人在摄像机前移动头部（见下述截图）。每一行代表每个像素的梯度。不同的帧在`t`时间上也有重叠：
- en: '![The Motion gradient](img/00051.jpeg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![动作梯度](img/00051.jpeg)'
- en: Output of the motionGradient example (a person is moving his head in front of
    the camera).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 动作梯度示例的输出（有人在摄像机前移动头部）。
- en: 'The preceding example shows you a window that displays the directions of movement.
    As the first step, the parameters are set (the maximum and minimum gradient value
    to be detected). The second step uses the `calcMotionGradient()` function to obtain
    a matrix of the gradient direction angles. Finally, to show the results, these
    angles are drawn on the screen using a default distance, which is `dist`. Again,
    we can use this function from the following modified `videoCamera` example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例展示了显示运动方向的窗口。作为第一步，设置参数（要检测的最大和最小梯度值）。第二步使用`calcMotionGradient()`函数获取梯度方向角度的矩阵。最后，为了显示结果，使用默认距离`dist`将这些角度绘制在屏幕上。同样，我们可以从以下修改后的`videoCamera`示例中使用此功能：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The Background subtraction technique
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景减除技术
- en: The Background subtraction technique consists of obtaining the important objects
    over a background.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 背景减除技术包括在背景上获取重要对象。
- en: 'Now, let''s see the methods available in OpenCV for the Background subtraction
    technique. Currently, the following four important techniques are required for
    this task:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看OpenCV中可用于背景减除技术的可用方法。目前，以下四种重要技术对于这项任务来说是必需的：
- en: '**MOG** (**Mixture-of-Gaussian**)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MOG**（**混合高斯**）'
- en: '**MOG2**'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MOG2**'
- en: '**GMG** (**Geometric MultiGrip**)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GMG**（**Geometric MultiGrip**）'
- en: '**KNN** (**K-Nearest Neighbors**)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**KNN**（**K-Nearest Neighbors**）'
- en: 'Next, we are going to see an example (`backgroundSubKNN`) using the KNN technique:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看到一个使用KNN技术（`backgroundSubKNN`）的示例：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `createBackgroundSubtractorKNN` method has only been included in Version
    3.0 of OpenCV.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`createBackgroundSubtractorKNN`方法仅包含在OpenCV的3.0版本中。'
- en: 'The Background subtracted frame and screen capture are shown in the following
    screenshot in which a person is walking in front of the camera:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图（其中有人在摄像机前行走）中显示了背景减除帧和屏幕截图：
- en: '![The Background subtraction technique](img/00052.jpeg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![背景减除技术](img/00052.jpeg)'
- en: Output of the backgroundSubKNN example
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: backgroundSubKNN示例的输出
- en: The preceding example shows you two windows with the subtracted background images
    and draws contours of the person found. First, parameters are set as the distance
    threshold between background and each frame to detect objects (`dist2Threshol`)
    and the disabling of the shadow detection (`detectShadows`). In the second step,
    using the `createBackgroundSubtractorKNN()` function, a background subtractor
    is created and a smart pointer construct is used (`Ptr<>`) so that we will not
    have to release it. The third step is to read each frame, if possible. Using the
    `apply()` and `getBackgroundImage()` methods, the foreground and background images
    are obtained. The fifth step is to reduce the foreground noise by applying a morphological
    closing operation (in the erosion—`erode()`—and dilation—`dilate()`—order). Then,
    contours are detected on the foreground image and then they're drawn. Finally,
    the background and current frame image are shown.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例展示了两个带有减去背景图像的窗口，并绘制了找到的人的轮廓。首先，设置参数作为背景与每一帧之间的距离阈值以检测对象（`dist2Threshol`）以及禁用阴影检测（`detectShadows`）。在第二步中，使用`createBackgroundSubtractorKNN()`函数创建一个背景减除器，并使用智能指针构造（`Ptr<>`）以确保我们不需要释放它。第三步是读取每一帧，如果可能的话。使用`apply()`和`getBackgroundImage()`方法，获取前景和背景图像。第五步是通过应用形态学闭合操作（在腐蚀—`erode()`—和膨胀—`dilate()`—顺序）来减少前景噪声。然后，在前景图像上检测轮廓，并绘制它们。最后，显示背景和当前帧图像。
- en: Image alignment
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像配准
- en: OpenCV now implements the ECC algorithm, which is only available as of Version
    3.0\. This method estimates the geometric transformation (warp) between the input
    and template frames and returns the warped input frame, which must be close to
    the first template. The estimated transformation is the one that maximizes the
    correlation coefficient between the template and the warped input frame. In the
    OpenCV examples (`[opencv_source_code]/samples/cpp/image_alignment.cpp`), a related
    program can be found.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV现在实现了ECC算法，该算法仅从版本3.0开始可用。此方法估计输入帧和模板帧之间的几何变换（扭曲），并返回扭曲后的输入帧，该帧必须接近第一个模板。估计的变换是最大化模板和扭曲后的输入帧之间相关系数的变换。在OpenCV示例（`[opencv_source_code]/samples/cpp/image_alignment.cpp`）中可以找到一个相关的程序。
- en: Note
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The ECC algorithm is based on the ECC criterion of the paper *Parametric Image
    Alignment Using Enhanced Correlation Coefficient Maximization*. You can find this
    at [http://xanthippi.ceid.upatras.gr/people/evangelidis/george_files/PAMI_2008.pdf](http://xanthippi.ceid.upatras.gr/people/evangelidis/george_files/PAMI_2008.pdf).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ECC 算法基于论文 *使用增强相关系数最大化的参数图像对齐* 的 ECC 标准。您可以在 [http://xanthippi.ceid.upatras.gr/people/evangelidis/george_files/PAMI_2008.pdf](http://xanthippi.ceid.upatras.gr/people/evangelidis/george_files/PAMI_2008.pdf)
    找到它。
- en: 'We are now going to see an example (`findCameraMovement`) that uses this ECC
    technique using the `findTransformECC()` function:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到一个示例 (`findCameraMovement`)，它使用 `findTransformECC()` 函数来应用这种 ECC 技术：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Some screen captures are shown in the following screenshot. The left-column
    frames represent the initial and template frames. The upper-right image is the
    current frame and the lower-right image is the warped frame.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了部分屏幕截图。左侧的框架表示初始和模板框架。右上角是当前帧，右下角是变形帧。
- en: '![Image alignment](img/00053.jpeg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图像对齐](img/00053.jpeg)'
- en: Output of the findCameraMovement example.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`findCameraMovement` 示例的输出。'
- en: 'The code example shows you four windows: the initial template, the initial
    frame, the current frame, and the warped frame. The first step is to set the initial
    parameters as `warp_mode` (`MOTION_HOMOGRAPHY`). The second step is to check whether
    the video camera is opened and to obtain a template, which will be calculated
    using a centered rectangle. When the *C* key is pressed, this area will be captured
    as the template. The third step is to read the next frame and convert it to a
    gray frame. The `findTransformECC()` function is applied to calculate `warp_matrix`
    with this matrix, and using `warpPerspective()`, the camera movement can be corrected
    using `warped_frame`.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 代码示例展示了四个窗口：初始模板、初始帧、当前帧和变形帧。第一步是将初始参数设置为 `warp_mode` (`MOTION_HOMOGRAPHY`)。第二步是检查视频摄像头是否已打开，并获取一个模板，该模板将使用中心矩形计算。当按下
    *C* 键时，此区域将被捕获作为模板。第三步是读取下一帧并将其转换为灰度帧。使用 `findTransformECC()` 函数应用此矩阵计算 `warp_matrix`，然后使用
    `warpPerspective()`，可以通过 `warped_frame` 来校正相机运动。
- en: Summary
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter covered an important subject in Computer Vision. Motion detection
    is an essential task, and in this chapter, we have provided the reader with the
    insight and samples that are required for the most useful methods available in
    OpenCV: working with video sequences (see the `videoCamera` example), the Optical
    Flow technique (see the `maxMovementLK` and `maxMovementFarneback` examples),
    tracking (see the `trackingMeanShift` and `trackingCamShift` examples), the Motion
    templates (see the `motionHistory` and `motionGradient` examples), the Background
    subtraction technique (see the `backgroundSubKNN` example), and image alignment
    (see the `findCameraMovement` example).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了计算机视觉中的一个重要主题。运动检测是一个基本任务，在本章中，我们为读者提供了所需的知识和示例，以便了解 OpenCV 中最实用的方法：处理视频序列（参见
    `videoCamera` 示例）、光流技术（参见 `maxMovementLK` 和 `maxMovementFarneback` 示例）、跟踪（参见 `trackingMeanShift`
    和 `trackingCamShift` 示例）、运动模板（参见 `motionHistory` 和 `motionGradient` 示例）、背景减法技术（参见
    `backgroundSubKNN` 示例）和图像对齐（参见 `findCameraMovement` 示例）。
- en: What else?
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有什么？
- en: Within the OpenCV libraries, there are other functions that deal with motion.
    Other Optical Flow technique methods are implemented, such as the Horn and Schunk
    (`cvCalcOpticalFlowHS`), block machine (`cvCalcOpticalFlowBM`), and simple flow
    (`calcOpticalFlowSF`) methods. A method to estimate the global movement is also
    available (`calcGlobalOrientation`). Finally, there are other methods to obtain
    backgrounds such as MOG (`createBackgroundSubtractorMOG`), MOG2 (`createBackgroundSubtractorMOG2`),
    and GMG (`createBackgroundSubtractorGMG`) methods.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenCV 库中，还有其他处理运动的功能。实现了其他光流技术方法，例如 Horn 和 Schunk (`cvCalcOpticalFlowHS`)、块机器
    (`cvCalcOpticalFlowBM`) 和简单流 (`calcOpticalFlowSF`) 方法。还有一个用于估计全局运动的方法 (`calcGlobalOrientation`)。最后，还有其他获取背景的方法，如
    MOG (`createBackgroundSubtractorMOG`)、MOG2 (`createBackgroundSubtractorMOG2`)
    和 GMG (`createBackgroundSubtractorGMG`) 方法。
