- en: Bag the Models with Bagging
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Bagging对模型进行打包
- en: 'In this chapter, we discuss the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论以下内容：
- en: Bootstrap aggregation
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bootstrap aggregation
- en: Ensemble meta-estimators
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成元估计器
- en: Bagging regressors
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bagging回归器
- en: Introduction
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: The combination of classifiers can help reduce misclassification errors substantially. Many
    studies have proved such ensembling methods can significantly reduce the variance
    of the prediction model. Several techniques have been proposed to achieve a variance
    reduction. For example, in many cases, bootstrap aggregating (bagging) classification
    trees have been shown to have higher accuracy than a single classification tree. Bagging
    can be applied to tree-based algorithms to enhance the accuracy of the predictions,
    although it can be used with methods other than tree-based methods as well.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的组合可以帮助显著减少误分类错误。许多研究表明，这种集成方法可以显著减少预测模型的方差。已经提出了几种技术来实现方差减少。例如，在许多情况下，bootstrap
    aggregating (bagging) 分类树已被证明比单个分类树具有更高的准确性。Bagging可以应用于基于树的算法以增强预测的准确性，尽管它也可以与基于树的算法以外的其他方法一起使用。
- en: Bootstrap aggregation
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bootstrap aggregation
- en: '**Bootstrap aggregation**, also known as **bagging**, is a powerful ensemble
    method that was proposed by Leo Breiman in 1994 to prevent overfitting. The concept
    behind bagging is to combine the predictions of several base learners to create
    a more accurate output.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**Bootstrap aggregation**，也称为**Bagging**，是一种由Leo Breiman于1994年提出的强大集成方法，用于防止过拟合。Bagging背后的概念是将多个基础学习者的预测组合起来以创建更准确的输出。'
- en: Breiman showed that bagging can successfully achieve the desired result in **unstable **learning
    algorithms where small changes to the training data can lead to large variations
    in the predictions. Breiman demonstrated that algorithms such as neural networks
    and decision trees are examples of **unstable** learning algorithms. Bootstrap
    aggregation is effective on small datasets.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Breiman表明，Bagging可以在**不稳定**的学习算法中成功实现预期结果，在这些算法中，训练数据的小幅变化可能导致预测结果的大幅变化。Breiman证明了神经网络和决策树等算法是不稳定学习算法的例子。Bootstrap
    aggregation在小型数据集上非常有效。
- en: 'The general procedure for bagging helps to reduce variance for those algorithms
    have high variance. Bagging also supports the classification and regression problem.
    The following diagram shows how the bootstrap aggregation flow works:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging的一般过程有助于降低具有高方差的算法的方差。Bagging还支持分类和回归问题。以下图表显示了Bootstrap aggregation流程的工作方式：
- en: '![](img/fa8702be-8271-4dba-9264-13e122c57947.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fa8702be-8271-4dba-9264-13e122c57947.png)'
- en: Using bootstrapping with a training dataset *X***,** we generate N bootstrap
    samples *X1*, *X2,....., XN*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练数据集**X**，我们生成N个bootstrap样本**X1**，**X2**，……，**XN**。
- en: 'For each bootstrap sample, we train a classifier, ![](img/0f7c18d2-774c-46a5-958b-e14bfac327eb.png).
    The combined classifier will average the outputs from all these individual classifiers
    as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个bootstrap样本，我们训练一个分类器，![图片](img/0f7c18d2-774c-46a5-958b-e14bfac327eb.png)。组合分类器将平均所有这些单个分类器的输出，如下所示：
- en: '![](img/9332286b-1e5f-4fb6-839f-8afe04b73931.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9332286b-1e5f-4fb6-839f-8afe04b73931.png)'
- en: In the preceding formula, *N* represents the number of samples.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的公式中，*N* 代表样本数量。
- en: 'In a bagging classifier, voting is used to make a final prediction. The pseudo-code
    for the bagging classifier proposed by Breiman is as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在Bagging分类器中，使用投票来做出最终预测。Breiman提出的Bagging分类器的伪代码如下：
- en: '![](img/542d5b93-e002-4f48-b9c6-f76f9909939b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/542d5b93-e002-4f48-b9c6-f76f9909939b.png)'
- en: 'In the case of the bagging regressor, the final prediction is the average of
    the predictions of the models that are built over each bootstrap sample. The following
    pseudo-code describes the bagging regressor:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在Bagging回归器的情况下，最终预测是构建在每个bootstrap样本上的模型预测的平均值。以下伪代码描述了Bagging回归器：
- en: '![](img/9a400a3a-8888-45de-8a81-161d00c22819.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9a400a3a-8888-45de-8a81-161d00c22819.png)'
- en: Getting ready
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We start by importing the required libraries and reading our file. We suppress
    any warnings using the `warnings.filterwarnings()` function from the `warnings`
    library:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入所需的库并读取我们的文件。我们使用`warnings.filterwarnings()`函数从`warnings`库抑制任何警告：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We have now set our working folder. Download the `autompg.csv` file from the
    GitHub and copy the file into your working folder as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已设置好工作文件夹。从GitHub下载`autompg.csv`文件，并将其复制到工作文件夹中，如下所示：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We read our data with `read_csv()` and prefix the name of the data frame with
    `df_` so that it is easier to understand:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`read_csv()`读取我们的数据，并在数据帧名称前加上`df_`前缀，以便更容易理解：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We check whether the dataset has any missing values as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查数据集是否有任何缺失值，如下所示：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We notice that the `horsepower` variable has six missing values. We can fill
    in the missing values using the median of the `horsepower` variable''s existing
    values with the following code:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到`horsepower`变量有六个缺失值。我们可以使用`horsepower`变量现有值的均值来填充这些缺失值，以下代码如下：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We notice that the `carname` variable is an identifier and is not useful in
    our model-building exercise, so we can drop it as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到`carname`变量是一个标识符，在我们的模型构建练习中并不有用，因此我们可以将其删除，如下所示：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can look at the data with the `dataframe.head()` command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`dataframe.head()`命令查看数据：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How to do it...
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In this section, we will see how to build a model using bootstrap samples:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解如何使用bootstrap样本构建模型：
- en: We start by creating the bootstrap samples. In [Chapter 3](6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml),
    *Resampling Methods*, we wrote a custom function, `create_bootstrap_oob()`, to
    create both bootstrap and **out-of-bag** (**OOB**) samples.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先创建bootstrap样本。在[第3章](6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml)“重采样方法”中，我们编写了一个自定义函数`create_bootstrap_oob()`，用于创建bootstrap和**袋外**（**OOB**）样本。
- en: 'In the following code block, we see how to create bootstrap and OOB samples:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码块中，我们看到如何创建bootstrap和OOB样本：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We build models using the bootstrap samples and average the cost function across
    all the models. We use the `SGDRegressor()` on each bootstrap sample. In the following
    code block, we reuse our previously written custom function, `create_bootstrap_oob()`,
    to create the bootstrap and OOB error samples:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用bootstrap样本构建模型，并对所有模型的成本函数进行平均。我们在每个bootstrap样本上使用`SGDRegressor()`。在以下代码块中，我们重用之前编写的自定义函数`create_bootstrap_oob()`来创建bootstrap和OOB误差样本：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We are now going to plot the MSE for each model built:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将绘制每个构建的模型的均方误差（MSE）：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The plot will look as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图表将如下所示：
- en: '![](img/f8316674-8694-4913-9562-18dde46e30a7.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f8316674-8694-4913-9562-18dde46e30a7.png)'
- en: How it works...
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In *Step 1*, we executed our custom function code to create the `create_bootstrap_oob()` function
    that creates the bootstrap and OOB samples for us. In *Step 2*, we executed the
    following steps:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*中，我们执行了自定义函数代码以创建`create_bootstrap_oob()`函数，该函数为我们创建bootstrap和OOB样本。在*步骤2*中，我们执行以下步骤：
- en: We decided to make 50 iterations, so we set the `iteration` variable to `50`.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们决定进行50次迭代，因此我们将`iteration`变量设置为`50`。
- en: The `create_bootstrap_oob()` function returned two DataFrame objects, `df_bootstrap_sample`
    and `df_OOB`, in each iteration.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每次迭代中，`create_bootstrap_oob()`函数返回两个DataFrame对象，`df_bootstrap_sample`和`df_OOB`。
- en: We used `df_bootstrap_sample` and `df_OOB` as our bootstrap and OOB samples
    respectively.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们分别使用`df_bootstrap_sample`和`df_OOB`作为我们的bootstrap和OOB样本。
- en: We split both the `df_bootstrap_sample` and the `df_OOB` samples into feature
    sets and response variables.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`df_bootstrap_sample`和`df_OOB`样本分别拆分为特征集和响应变量。
- en: We fit the `SGDRegressor()` to our bootstrap sample to build our model.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`SGDRegressor()`拟合到我们的bootstrap样本以构建我们的模型。
- en: We passed the OOB sample to the model to predict our values.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将OOB样本传递给模型以预测我们的值。
- en: We compared the predicted values against the response variable in the OOB sample.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将预测值与OOB样本中的响应变量进行比较。
- en: We calculated the MSE for each iteration.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算了每次迭代的MSE。
- en: In *Step 3*, we created a plot to show the MSE for each iteration up to the
    fiftieth iteration. This result may vary because of randomness.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤3*中，我们创建了一个图表来显示直到第五十次迭代的MSE。这个结果可能会因为随机性而有所不同。
- en: See also
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Bagging Predictors* by Leo Breiman, September 1994'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《Leo Breiman的《Bagging Predictors》》，1994年9月
- en: Ensemble meta-estimators
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成元估计器
- en: The bagging classifier and the bagging regressor are ensemble meta-estimators
    that fit the base classifier and regressor models respectively on random subsets
    of the original dataset. The predictions from each model are combined to create
    the final prediction. These kinds of meta-estimators induce randomization into
    the model-building process and aggregate the outcome. The aggregation averages
    over the iterations for a numerical target variable and performs a plurality vote
    in order to reach a categorical outcome.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging分类器和Bagging回归器是集成元估计器，分别将基础分类器和回归器模型拟合到原始数据集的随机子集。每个模型的预测被组合起来以创建最终预测。这类元估计器将随机化引入模型构建过程并汇总结果。对于数值目标变量，聚合平均迭代，以实现分类结果进行多数投票。
- en: Bagging classifiers
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bagging分类器
- en: Bagging classifiers train each classifier model on a random subset of the original
    training set and aggregate the predictions, then perform a plurality voting for
    a categorical outcome. In the following recipe, we are going to look at an implementation
    of a bagging classifier with bootstrap samples.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging分类器在每个分类器模型上训练原始训练集的随机子集，然后汇总预测，并对分类结果进行多数投票。在下面的配方中，我们将查看一个带有自助样本的Bagging分类器的实现。
- en: How to do it...
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We import `BaggingClassifier` and `DecisionTreeClassifier` from the `scikit-learn`
    library. We also import the other required libraries as follows:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从`scikit-learn`库中导入`BaggingClassifier`和`DecisionTreeClassifier`。我们还按如下方式导入其他所需的库：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we read out the data and take a look at the dimensions:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们读取数据并查看其维度：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We separate our features and the response set. We also split our data into training
    and testing subsets.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将特征和响应集分开。我们还把数据分成训练集和测试集。
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We create an instance of the `DecisionTreeClassifier` class and pass it to
    the `BaggingClassifier()`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个`DecisionTreeClassifier`类的实例，并将其传递给`BaggingClassifier()`：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that in the preceding code block, we have declared `bootstrap=True`. This
    is the default value and indicates that samples are drawn with replacement.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在先前的代码块中，我们已声明`bootstrap=True`。这是默认值，表示以替换方式抽取样本。
- en: 'We fit our model to the training data as follows:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将模型拟合到训练数据如下：
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can see the score after passing the test data to the model:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到将测试数据传递给模型后的得分：
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We use the `predict` function to predict the response variable as follows:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`predict`函数如下预测响应变量：
- en: '[PRE16]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We will now use a code to plot the confusion matrix. Note that this code has
    been taken from [scikit-learn.org](https://scikit-learn.org/stable/). We execute
    the following code to create the `plot_confusion_matrix()` function:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将使用代码来绘制混淆矩阵。请注意，此代码已从[scikit-learn.org](https://scikit-learn.org/stable/)获取。我们执行以下代码以创建`plot_confusion_matrix()`函数：
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We use the preceding `plot_confusion_matrix()` function to plot our confusion
    matrix:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用前面的`plot_confusion_matrix()`函数来绘制我们的混淆矩阵：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The confusion matrix plot looks as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵图如下所示：
- en: '![](img/a6309b5b-fc95-44fc-94d1-6d5607f77a59.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a6309b5b-fc95-44fc-94d1-6d5607f77a59.png)'
- en: How it works...
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we imported the required libraries to build our decision tree classifier
    model using the bagging classifier. In *Step 2*, we read our dataset, which was `winedata.csv`. In
    *Step 3*, we separated our feature set and the target variable. We also split
    our data into training and testing subsets. In *Step 4*, we created a decision
    tree classifier model and passed it to the `BaggingClassifier()`. In the `DecisionTreeClassifier()`,
    the default value for the `criterion` parameter was `gini`, but we changed it
    to `entropy`. We then passed our decision tree model to the `BaggingClassfier()`. In
    the `BaggingClassfier()`, we have parameters including `n_estimators` and `bootstrap`. `n_estimators` is
    the number of base estimators in the ensemble and has a default value of `10`.
    The `bootstrap` parameter indicates whether samples are drawn with replacement
    or not and is set to `True` by default.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*中，我们导入了所需的库，使用Bagging分类器构建我们的决策树分类器模型。在*步骤2*中，我们读取了我们的数据集，它是`winedata.csv`。在*步骤3*中，我们分离了特征集和目标变量。我们还把数据分成训练集和测试集。在*步骤4*中，我们创建了一个决策树分类器模型，并将其传递给`BaggingClassifier()`。在`DecisionTreeClassifier()`中，`criterion`参数的默认值是`gini`，但我们将其更改为`entropy`。然后我们将我们的决策树模型传递给`BaggingClassfier()`。在`BaggingClassfier()`中，我们有包括`n_estimators`和`bootstrap`在内的参数。`n_estimators`是集成中基础估计器的数量，默认值为`10`。`bootstrap`参数指示是否用替换方式抽取样本，默认设置为`True`。
- en: In *Step 5* and *Step **6*, we fitted our model to the training data and looked
    at the score of the test set. In *Step 7*, we called the `predict()` method and
    passed the test feature set. In *Step 8*, we added the code for the `plot_confusion_matrix()`
    from [http://scikit-learn.org](http://scikit-learn.org), which takes the confusion
    matrix as one of its input parameters and plots the confusion matrix. In *Step
    9*, we called the `plot_confusion_matrix()` function by passing the confusion
    matrix to generate the confusion matrix plot.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤5*和*步骤6*中，我们将模型拟合到训练数据，并查看测试集的分数。在*步骤7*中，我们调用了`predict()`方法并传递了测试特征集。在*步骤8*中，我们添加了来自[http://scikit-learn.org](http://scikit-learn.org)的`plot_confusion_matrix()`的代码，它将混淆矩阵作为其输入参数之一，并绘制混淆矩阵。在*步骤9*中，我们通过传递混淆矩阵来调用`plot_confusion_matrix()`函数以生成混淆矩阵图。
- en: There's more...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We can also use `GridSearchCV()` from `sklearn.model_selection` to grid search
    the best parameters and use them in the `BaggingClassifier`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用来自`sklearn.model_selection`的`GridSearchCV()`来进行网格搜索最佳参数，并在`BaggingClassifier`中使用它们：
- en: 'First, we import the required library:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入所需的库：
- en: '[PRE19]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We then set our parameter values:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们设置我们的参数值：
- en: '[PRE20]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We instantiate our `DecisionTreeClassifier` class and pass it to the `BaggingClassifier()` function.
    Note that we set the `oob_score` to `True` to evaluate the models built on the
    OOB samples:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实例化`DecisionTreeClassifier`类，并将其传递给`BaggingClassifier()`函数。请注意，我们将`oob_score`设置为`True`以评估基于OOB样本构建的模型：
- en: '[PRE21]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We use `GridSearchCV()` to determine the best parameters:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`GridSearchCV()`来确定最佳参数：
- en: '[PRE22]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code returns the optimum parameters:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码返回了最佳参数：
- en: '![](img/11224b03-0e99-4ce4-beb7-7d3cd26242fb.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/11224b03-0e99-4ce4-beb7-7d3cd26242fb.png)'
- en: 'We now take the values returned by `bc_grid.bestparams` and rebuild our decision
    tree models using the `BaggingClassfier()` function. We pass `10` for the `max_leaf_nodes`,
    `3` for the `max_depth`, and `20` for the `n_estimators`:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们取`bc_grid.bestparams`返回的值，并使用`BaggingClassfier()`函数重新构建我们的决策树模型。我们将`max_leaf_nodes`设置为`10`，`max_depth`设置为`3`，`n_estimators`设置为`20`：
- en: '[PRE23]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We set our `n_estimators` to `150` in the preceding code block. The `n_estimators`
    parameter indicates the number of trees we want to build. We fit our final model
    to our training data and make a prediction using our test feature set.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们将`n_estimators`设置为`150`。`n_estimators`参数表示我们想要构建的树的数量。我们将最终模型拟合到我们的训练数据，并使用我们的测试特征集进行预测。
- en: 'We can then look at the accuracy of our OOB samples in the following code block:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以在以下代码块中查看我们的OOB样本的准确率：
- en: '[PRE24]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'If we plot our confusion matrix, we can see that we have made an improvement
    with regard to the number of misclassifications that are made. In the earlier
    example, two instances of class 2 were wrongly predicted as class 3, but we can
    now see that the number of misclassifications has reduced to one:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制混淆矩阵，我们可以看到我们在错误分类的数量上有所改进。在早期示例中，有两个类2的实例被错误地预测为类3，但现在我们可以看到错误分类的数量减少到了一个：
- en: '![](img/2ab6bb14-572f-47c8-a678-f7331a597e13.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2ab6bb14-572f-47c8-a678-f7331a597e13.png)'
- en: See also
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考内容
- en: The scikit-learn guide to bagging classifiers: [https://bit.ly/2zaq8lS](https://bit.ly/2zaq8lS)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn关于Bagging分类器的指南：[https://bit.ly/2zaq8lS](https://bit.ly/2zaq8lS)
- en: Bagging regressors
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bagging回归器
- en: Bagging regressors are similar to bagging classifiers. They train each regressor
    model on a random subset of the original training set and aggregate the predictions.
    Then, the aggregation averages over the iterations because the target variable
    is numeric. In the following recipe, we are going to showcase the implementation
    of a bagging regressor with bootstrap samples.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging回归器与Bagging分类器类似。它们在每个回归器模型上训练原始训练集的随机子集，并汇总预测。然后，由于目标变量是数值的，因此汇总平均在迭代中。在下面的配方中，我们将展示使用自助样本实现的Bagging回归器的实现。
- en: Getting ready
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will import the required libraries, `BaggingRegressor` and `DecisionTreeRegressor`,
    from `sklearn.ensemble` and `sklearn.tree` respectively:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分别从`sklearn.ensemble`和`sklearn.tree`导入所需的库`BaggingRegressor`和`DecisionTreeRegressor`：
- en: '[PRE25]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We read our dataset, which is `bostonhousing.csv`, and look at the dimensions
    of the DataFrame:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们读取数据集，它是`bostonhousing.csv`，并查看DataFrame的维度：
- en: '[PRE26]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We now move on to creating our feature set and our target variable set.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们继续创建我们的特征集和目标变量集。
- en: How to do it...
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'We first separate our feature and response set. We will also split our data
    into training and testing subsets in the following code block:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先将特征集和响应集分开。在下面的代码块中，我们还将数据分为训练集和测试集：
- en: '[PRE27]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We will then create an instance of the `DecisionTreeClassifier` class and pass
    it to the `BaggingClassifier()` function:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将创建一个`DecisionTreeClassifier`类的实例并将其传递给`BaggingClassifier()`函数：
- en: '[PRE28]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We will fit our model to the training dataset as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将按照以下方式将我们的模型拟合到训练数据集：
- en: '[PRE29]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can see the model score in the following code block:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以在以下代码块中看到模型得分：
- en: '[PRE30]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We use the `predict()` function and pass the test dataset to predict our target
    variable as follows:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`predict()`函数并将测试数据集传递给它来预测我们的目标变量，如下所示：
- en: '[PRE31]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We plot the scatter plot of our actual values and the predicted values of our
    target variable with the following code:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用以下代码绘制了我们的实际值和目标变量的预测值的散点图：
- en: '[PRE32]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Executing the preceding code gives us the following scatter plot:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前面的代码给出了以下散点图：
- en: '![](img/efe7575b-b3c6-4059-8454-653ce7268e60.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/efe7575b-b3c6-4059-8454-653ce7268e60.png)'
- en: The `matplotlib.pyplot.tight_layout()` automatically adjusts the subplot parameters
    to create specified padding.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`matplotlib.pyplot.tight_layout()`自动调整子图参数以创建指定的填充。'
- en: 'We now change the `n_estimators` parameter to 30 in the following code and
    re-execute the steps from *Step 3* to *Step 6*:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将`n_estimators`参数更改为30，并重新执行从**步骤 3**到**步骤 6**的步骤：
- en: '[PRE33]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This gives us the following score:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下得分：
- en: '![](img/bbf118f9-2223-46e4-9f14-575e7f0f64c9.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bbf118f9-2223-46e4-9f14-575e7f0f64c9.png)'
- en: 'The plot of the actual values against the predicted values looks as follows.
    This shows us that the values are predicted more accurately than in our previous
    case when we changed the value of the `n_estimator` parameter from `5` to `30`:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实际值与预测值的图表如下。这表明，与我们将`n_estimator`参数的值从`5`改为`30`的前一个案例相比，预测值更加准确：
- en: '![](img/62df9a66-8da7-4b7d-b9e9-8389e017f331.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/62df9a66-8da7-4b7d-b9e9-8389e017f331.png)'
- en: How it works...
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we separated the features and the target variable set. We also
    split our data into training and testing subsets. In *Step 2*, we created a decision
    tree regressor model and passed it to the `BaggingRegressor()` function. Note
    that we also passed the `n_estimator=5` parameter to the `BaggingRegressor()` function.
    As mentioned earlier, `n_estimator` is the number of trees in the forest we would
    like the algorithm to build. In *Step 3*, we trained our model.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 1**中，我们将特征和目标变量集分开。我们还把我们的数据分成训练集和测试集。在**步骤 2**中，我们创建了一个决策树回归器模型并将其传递给`BaggingRegressor()`函数。请注意，我们还向`BaggingRegressor()`函数传递了`n_estimator=5`参数。如前所述，`n_estimator`是我们希望算法构建的森林中树的数量。在**步骤
    3**中，我们训练了我们的模型。
- en: In *Step 4*, we looked at the model score, which was 0.71\. In *Step 5*, we
    used the `predict()` function to predict our target variable for the test subset.
    After that, in *Step 6*, we plotted a scatterplot to explore the relationship
    between the actual target values and the predicted target values.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 4**中，我们查看了模型得分，为0.71。在**步骤 5**中，我们使用`predict()`函数预测测试子集中的目标变量。之后，在**步骤
    6**中，我们绘制了一个散点图来探索实际目标值和预测目标值之间的关系。
- en: In *Step 7*, we changed the `n_estimator` parameter's value from `5` to `30`
    and re-built our model. This time, we noticed that the model score improved to
    0.82. In *Step 8*, we plotted the actual and predicted values and saw that the
    correlation between the actual and predicted values was much better than our previous
    model, where we used `n_estimators=5`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 7**中，我们将`n_estimator`参数的值从`5`改为`30`并重新构建了我们的模型。这次，我们注意到模型得分提高到了0.82。在**步骤
    8**中，我们绘制了实际值和预测值，并发现实际值和预测值之间的相关性比我们之前使用`n_estimators=5`的模型要好得多。
- en: See also
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The scikit-learn guide to bagging regressors: [https://bit.ly/2pZFmUh](https://bit.ly/2pZFmUh)
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn关于袋回归器的指南：[https://bit.ly/2pZFmUh](https://bit.ly/2pZFmUh)
- en: Single estimator versus bagging: [https://bit.ly/2q08db6](https://bit.ly/2q08db6)
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个估计器与袋装：[https://bit.ly/2q08db6](https://bit.ly/2q08db6)
