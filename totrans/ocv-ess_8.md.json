["```py\n#include <iostream>\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/ml/ml.hpp>\n\nusing namespace std;\nusing namespace cv;\n\nint main(int argc, char *argv[]){\n\n//Create Mat for the training set and classes\n Mat classes(5, 1, CV_32FC1);\n Mat colors(5, 3, CV_32FC1);\n\n    //Training set (primary colors)\n    colors.at<float>(0,0)=0, colors.at<float>(0,1)=0, colors.at<float>(0,2)=0;\n    colors.at<float>(1,0)=255, colors.at<float>(1,1)=255, colors.at<float>(1,2)=255;\n    colors.at<float>(2,0)=255, colors.at<float>(2,1)=0, colors.at<float>(2,2)=0;\n    colors.at<float>(3,0)=0, colors.at<float>(3,1)=255, colors.at<float>(3,2)=0;\n    colors.at<float>(4,0)=0, colors.at<float>(4,1)=0, colors.at<float>(4,2)=255;\n\n    //Set classes to each training sample\n    classes.at<float>(0,0)=1;\n    classes.at<float>(1,0)=2;\n    classes.at<float>(2,0)=3;\n    classes.at<float>(3,0)=4;\n    classes.at<float>(4,0)=5;\n\n    //KNN classifier (k=1)\n CvKNearest classifier;\n classifier.train(colors,classes,Mat(),false,1,false);\n\n    //Load original image\n    Mat src=imread(\"baboon.jpg\",1);\n    imshow(\"baboon\",src);\n\n    //Create result image\n    Mat dst(src.rows , src.cols, CV_8UC3);\n\n    Mat results;\nMat newPoint(1,3,CV_32FC1);\n\n    //Response for each pixel and store the result in the result image\n    float prediction=0;\n    for(int y = 0; y < src.rows; ++y){\n      for(int x = 0; x < src.cols; ++x){\n         newPoint.at<float>(0,0)= src.at<Vec3b>(y, x)[0];\n         newPoint.at<float>(0,1) = src.at<Vec3b>(y, x)[1];\n         newPoint.at<float>(0,2) = src.at<Vec3b>(y, x)[2];\n prediction=classifier.find_nearest(newPoint,1,&results, 0, 0);\n         dst.at<Vec3b>(y, x)[0]= colors.at<float>(prediction-1,0);\n         dst.at<Vec3b>(y, x)[1]= colors.at<float>(prediction-1,1);\n         dst.at<Vec3b>(y, x)[2]= colors.at<float>(prediction-1,2);\n      }\n    }\n\n    //Show result image\n    cv::imshow(\"result KNN\",dst);\n    cv::waitKey(0);\n    return 0;\n}\n```", "```py\n//… (omitted for simplicity)\n\nint main(int argc, char *argv[]){\n\n CvMLData mlData;\n mlData.read_csv(\"iris.csv\");\n mlData.set_response_idx(4);\n    //Select 75% samples as training set and 25% as test set\n CvTrainTestSplit cvtts(0.75f, true);\n    //Split the iris dataset\n mlData.set_train_test_split(&cvtts);\n\n    //Get training set\n Mat trainsindex= mlData.get_train_sample_idx();\n    cout<<\"Number of samples in the training set:\"<<trainsindex.cols<<endl;\n    //Get test set\n Mat testindex=mlData.get_test_sample_idx();\n    cout<<\"Number of samples in the test set:\"<<testindex.cols<<endl;\n    cout<<endl;\n\n    //Random Forest parameters\n CvRTParams params = CvRTParams(3, 1, 0, false, 2, 0, false, 0, 100, 0, CV_TERMCRIT_ITER | CV_TERMCRIT_EPS);\n\n CvRTrees classifierRF;\n    //Taining phase\n classifierRF.train(&mlData,params);\n    std::vector<float> train_responses, test_responses;\n\n    //Calculate train error\n    cout<<\"Error on train samples:\"<<endl;\n    cout<<(float)classifierRF.calc_error( &mlData, CV_TRAIN_ERROR,&train_responses)<<endl;\n\n    //Print train responses\n    cout<<\"Train responses:\"<<endl;\n    for(int i=0;i<(int)train_responses.size();i++)\n        cout<<i+1<<\":\"<<(float)train_responses.at(i)<<\"  \";\n    cout<<endl<<endl;\n\n    //Calculate test error\n    cout<<\"Error on test samples:\"<<endl;\n    cout<<(float)classifierRF.calc_error( &mlData, CV_TEST_ERROR,&test_responses)<<endl;\n\n    //Print test responses\n    cout<<\"Test responses:\"<<endl;\n    for(int i=0;i<(int)test_responses.size();i++)\n        cout<<i+1<<\":\"<<(float)test_responses.at(i)<<\"  \";\n    cout<<endl<<endl;\n\n    return 0;\n}\n```", "```py\n//… (omitted for simplicity)\n#include <opencv2/features2d/features2d.hpp>\n#include <opencv2/nonfree/features2d.hpp>\n\nusing namespace std;\nusing namespace cv;\n\nint main(int argc, char *argv[]){\n\n    Mat groups;\n    Mat samples;\n    vector<KeyPoint> keypoints1;\n    //ORB feature detector with 15 interest points\n    OrbFeatureDetector detector(15, 1.2f, 2, 31,0, 2, ORB::HARRIS_SCORE, 31);\n    Mat descriptors, descriptors2;\n    //SURF feature descriptor\n    SurfDescriptorExtractor extractor;\n\n    //Training samples\n    for(int i=1; i<=56; i++){\n        stringstream nn;\n        nn <<i<<\".png\";\n        //Read the image to be trained\n        Mat img=imread(nn.str());\n        cvtColor(img, img, COLOR_BGR2GRAY);\n        //Detect interest points\n        detector.detect(img, keypoints1);\n        //Compute SURF descriptors\n        extractor.compute(img, keypoints1, descriptors);\n        //Organize and save information in one row\n        samples.push_back(descriptors.reshape(1,1));\n        keypoints1.clear();\n    }\n\n    //Set the labels of each sample\n    for(int j=1; j<=56; j++){\n        if(j<=14)  groups.push_back(1);\n        else if(j>14 && j<=28)  groups.push_back(2);\n             else if(j>28 && j<=42)  groups.push_back(3);\n                  else groups.push_back(4);\n    }\n\n    //Indicate SVM parameters\n CvSVMParams params=CvSVMParams(CvSVM::C_SVC, CvSVM::LINEAR, 0, 1, 0, 1, 0, 0, 0, cvTermCriteria(CV_TERMCRIT_ITER+CV_TERMCRIT_EPS, 100, FLT_EPSILON));\n\n    //Create SVM classifier\n CvSVM classifierSVM;\n\n    //Train classifier\n classifierSVM.train(samples, groups, Mat(), Mat(), params );\n\n    //Test samples\n    for(int i=1; i<=10; i++){\n        stringstream nn;\n        nn <<\"unknown\"<<i<<\".png\";\n        //Read the image to be tested\n        Mat unknown=imread(nn.str());\n        cvtColor(unknown, unknown, COLOR_BGR2GRAY);\n        //Detect interest points\n        detector.detect(unknown, keypoints1);\n        //Compute descriptors\n        extractor.compute(unknown, keypoints1, descriptors2);\n        //Test sample\n float result=classifierSVM.predict(descriptors2.reshape(1,1));\n        //Print result\n        cout<<nn.str()<<\": class \"<<result<<endl;\n    }\n    return 0;\n}\n```", "```py\n#include <iostream>\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/imgproc/imgproc.hpp\" \nusing namespace cv;\n\nint main(int argc, char** argv){\nif ( argc < 2 ){\n        std::cout << \"Usage: ./edgesGPU <image>\" << std::endl;\n        return -1;\n    }\n    Mat orig = imread(argv[1]);\n    Mat gray, dst;\n\n    bilateralFilter(orig,dst,-1,50,7);\n    cvtColor(dst,gray,COLOR_BGR2GRAY);\n    Canny(gray,gray,7,20);\n\n    imshow(\"Canny Filter\", gray);\n    waitKey(0);\n\n    return 0;\n}\n```", "```py\n#include <iostream>\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/gpu/gpu.hpp>\nusing namespace cv;\n\nint main( int argc, char** argv){\n  if ( argc < 2 ){\n        std::cout << \"Usage: ./edgesGPU <image>\" << std::endl;\n        return -1;\n    }\n    Mat orig = imread(argv[1]);\n gpu::GpuMat g_orig, g_gray, g_dst;\n    //Transfer the image data to the GPU\n g_orig.upload(orig);\n\n gpu::bilateralFilter(g_orig,g_dst,-1,50,7);\n gpu::cvtColor(g_dst,g_gray,COLOR_BGR2GRAY);\n gpu::Canny(g_gray,g_gray,7,20);\n\n    Mat dst;\n    //Copy the image back to the CPU memory\n g_gray.download(dst);\n    imshow(\"Canny Filter\", dst);\n    waitKey(0);\n\n    return 0;\n}\n```", "```py\n#include <iostream>\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/features2d/features2d.hpp\"\n#include \"opencv2/gpu/gpu.hpp\"\n#include \"opencv2/nonfree/gpu.hpp\"\n\nusing namespace std;\nusing namespace cv;\n\nint main( int argc, char** argv )\n{\n    Mat img_template_cpu = imread( argv[1],IMREAD_GRAYSCALE);\n    gpu::GpuMat img_template;\n    img_template.upload(img_template_cpu);\n\n    //Detect keypoints and compute descriptors of the template\n gpu::SURF_GPU surf;\n    gpu::GpuMat keypoints_template, descriptors_template;\n\n    surf(img_template,gpu::GpuMat(),keypoints_template,       descriptors_template);\n\n    //Matcher variables\n gpu::BFMatcher_GPU matcher(NORM_L2); \n\n    //VideoCapture from the webcam\n    gpu::GpuMat img_frame;\n    gpu::GpuMat img_frame_gray;\n    Mat img_frame_aux;\n    VideoCapture cap;\n    cap.open(0);\n    if (!cap.isOpened()){\n        cerr << \"cannot open camera\" << endl;\n        return -1;\n    }\n    int nFrames = 0;\n    uint64 totalTime = 0;\n    //main loop\n    for(;;){\n int64 start = getTickCount();\n        cap >> img_frame_aux;\n        if (img_frame_aux.empty())\n            break;\n        img_frame.upload(img_frame_aux);\n        cvtColor(img_frame,img_frame_gray, CV_BGR2GRAY);\n\n        //Step 1: Detect keypoints and compute descriptors\n        gpu::GpuMat keypoints_frame, descriptors_frame;\n surf(img_frame_gray,gpu::GpuMat(),keypoints_frame, descriptors_frame);\n\n        //Step 2: Match descriptors\n        vector<vector<DMatch>>matches; matcher.knnMatch(descriptors_template,descriptors_frame,matches,2);\n\n        //Step 3: Filter results\n        vector<DMatch> good_matches;\n        float ratioT = 0.7;\n        for(int i = 0; i < (int) matches.size(); i++)\n        {\n            if((matches[i][0].distance < ratioT*(matches[i][1].distance)) && ((int) matches[i].size()<=2 && (int) matches[i].size()>0))\n            {\n                good_matches.push_back(matches[i][0]);\n            }\n        }\n        // Step 4: Download results\n        vector<KeyPoint> keypoints1, keypoints2;\n        vector<float> descriptors1, descriptors2;\n surf.downloadKeypoints(keypoints_template, keypoints1);\n surf.downloadKeypoints(keypoints_frame, keypoints2);\n surf.downloadDescriptors(descriptors_template, descriptors1);\n surf.downloadDescriptors(descriptors_frame, descriptors2);\n\n        //Draw the results\n        Mat img_result_matches;\n        drawMatches(img_template_cpu, keypoints1, img_frame_aux, keypoints2, good_matches, img_result_matches);\n        imshow(\"Matching a template\", img_result_matches);\n\n int64 time_elapsed = getTickCount() - start;\n double fps = getTickFrequency() / time_elapsed;\n        totalTime += time_elapsed;\n        nFrames++;\n        cout << \"FPS : \" << fps <<endl;\n\n        int key = waitKey(30);\n        if (key == 27)\n            break;;\n    }\n double meanFps = getTickFrequency() / (totalTime / nFrames);\n    cout << \"Mean FPS: \" << meanFps << endl;\n\n    return 0;\n}\n```"]