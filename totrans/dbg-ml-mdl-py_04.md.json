["```py\nfrom sklearn.metrics import confusion_matrix as cmdef performance_from_cm(y_true, y_pred):\n    # Calculating values of confusion matrix\n    cm_values = cm(y_true, y_pred)\n    # Extracting tn, fp, fn, and tp from calculated confusion matrix\n    tn, fp, fn, tp = cm_values.ravel()\n    # Calculating specificity\n    specificity = tn/(tn+fp)\n    # Calculating precision\n    precision = tp/(tp+fp)\n    # Calculating recall\n    recall = tp/(tp+fn)\n    return specificity, precision, recall\n```", "```py\nfrom sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import balanced_accuracy_score as bacc\nfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nX, y = load_breast_cancer(return_X_y=True)\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(X, y,    test_size = 0.3, random_state=10)\nmaximum_depth = 15\ndepth_range = range(1, maximum_depth)\nbacc_train = []\nbacc_test = []\nlog_loss_train = []\nlog_loss_test = []\nfor depth_iter in depth_range:\n# initializing an fitting a decision tree model\nmodel_fit = RF(n_estimators = 5, max_depth = depth_iter,\n    random_state=10).fit(X_train, y_train)\n# generating label outputs of train and test set using the trained model\ntrain_y_labels = model_fit.predict(X_train)\ntest_y_labels = model_fit.predict(X_test)\n# generating probability outputs of train and test set using the trained model\ntrain_y_probs = model_fit.predict_proba(X_train)\ntest_y_probs = model_fit.predict_proba(X_test)\n# calculating balanced accuracy\nbacc_train.append(bacc(y_train, train_y_labels))\nbacc_test.append(bacc(y_test, test_y_labels))\n# calculating log-loss\nlog_loss_train.append(log_loss(y_train, train_y_probs))\nlog_loss_test.append(log_loss(y_test, test_y_probs))\n```", "```py\nfrom sklearn.datasets import load_breast_cancerfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\n# importing different cross-validation functions\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nmodle_random_state = 42\nX, y = load_breast_cancer(return_X_y=True)\nrf_init = RF(random_state=modle_random_state)\n```", "```py\n# validating using hold-out validationX_train, X_test, y_train, y_test = train_test_split(X, y,\n    test_size = 0.3, random_state=10)\nrf_fit = rf_init.fit(X_train, y_train)\n# validating using k-fold (k=5) cross-validation\nkfold_cv = KFold(n_splits = 5, shuffle=True,\n    random_state=10)\nscores_kfold_cv = cross_val_score(rf_init, X, y,\n    cv = kfold_cv, scoring = \"roc_auc\")\n# validating using stratified k-fold (k=5) cross-validation\nstratified_kfold_cv = StratifiedKFold(n_splits = 5,\n    shuffle=True, random_state=10)\nscores_strat_kfold_cv = cross_val_score(rf_init, X, y, cv = stratified_kfold_cv, scoring = \"roc_auc\")\n```", "```py\nfrom sklearn.datasets import load_winefrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.model_selection import KFold\nfrom collections import Counter\n# loading wine dataset and generating k-fold CV subsets\nX, y = load_wine(return_X_y=True)\n```", "```py\nkfold_cv = KFold(n_splits = 5, shuffle=True,    random_state=10)\n# initializing the random forest model\nrf_init = RF(n_estimators=3, max_depth=5, random_state=42)\n```", "```py\nmisclass_ind_list = []for fold_n, (train_idx, validation_idx) in enumerate(\n    kfold_cv.split(X, y)):\n        #get train and validation subsets for current fold\n        X_train, y_train = X[train_idx], y[train_idx]\n        X_validation, y_validation = X[validation_idx],\n            y[validation_idx]\n    rf_fit = rf_init.fit(X_train, y_train)\n    # write results\n    match_list = rf_fit.predict(\n        X_validation) != y_validation\n    wrong_pred_subset = [i for i, x in enumerate(\n        match_list) if x]\n    misclass_ind_list.extend([validation_idx[\n        iter] for iter in wrong_pred_subset])\n```", "```py\nfrom sklearn.datasets import load_breast_cancerfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom xgboost import XGBClassifier\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n    stratify=y, random_state=123)\nestimators = [\n    ('lr', make_pipeline(StandardScaler(),\n    LR(random_state=123))),\n    ('knn', make_pipeline(StandardScaler(), KNN())),\n    ('svr', make_pipeline(StandardScaler(),\n    LinearSVC(random_state=123))),\n    ('rf', RF(random_state=123)),\n    ('xgb', XGBClassifier(random_state=123))\n    ]\nstacked_model = StackingClassifier(estimators=estimators,\n    final_estimator=LR())\nstacked_model.fit(X_train, y_train).score(X_test, y_test)\nindividual_models = [estimators[iter][1].fit(X_train,\n    y_train).score(X_test, y_test) for iter in range(\n        0, len(estimators))]\n```"]