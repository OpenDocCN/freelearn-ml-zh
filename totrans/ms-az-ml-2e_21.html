<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer279">
			<h1 id="_idParaDest-270"><em class="italic"><a id="_idTextAnchor269"/>Chapter 17</em>: Preparing for a Successful ML Journey</h1>
			<p>Congratulations, you've made it – what an incredible journey you've been on! By now, you should have learned how to preprocess data in the cloud, experiment with <strong class="bold">ML</strong> models, train deep learning models and recommendation engines on auto-scaling clusters, optimize models, and deploy them wherever you want. And you should know how to add a cherry to the top of the cake by operationalizing all of these steps through <strong class="bold">MLOps</strong>.</p>
			<p>In this last chapter, we will recap some important revelations we learned during this journey. It's easy to get lost or overwhelmed by technological and algorithmic choices. You could dive deep into modeling, infrastructure, or monitoring without getting any closer to having a good predictive model.</p>
			<p>In the first section, we will remind you that ML is mostly about data. Artificial intelligence should probably be called data cleansing and labeling, but of course, this doesn't sound as good as AI. You will come to understand that your data is key to great performance, so it's what you should care about the most. Your data is all that matters!</p>
			<p>In the following section, we will show you how to start your ML projects. We will do this by providing you with some guidance and making a point about the importance of a clean base infrastructure and thoughtful monitoring.</p>
			<p>After that, we will reiterate the importance of automation and how new technologies will take us further into the world of <strong class="bold">machine learning as a service </strong>(<strong class="bold">MLaaS</strong>). It is always great to understand where technology is heading and in the case of ML, it is meta-learning and systems that already automatically suggest fitting models and stack them to achieve good predictive performance. And what is left when modeling is fully automated? Exactly – your data!</p>
			<p>Following that, we will talk about the constant change and evolution of cloud services while focusing on PaaS offerings. We will look at why PaaS solutions are built and what their foundation is. This will help you understand how best to prepare for change and why you are still betting on the right foundation, despite ever-changing services.</p>
			<p>Finally, we will talk about a topic we have mostly ignored throughout this book. We will talk about some questions you should think about before starting any ML project: Should you do it? Will the results of your model have a grave impact on people's lives? You may have guessed it: we will talk about <strong class="bold">ethics</strong> in terms of data processing. With a more and more connected world, you shouldn't misuse the personal data of others, you shouldn't build models that are extremely biased toward certain groups of people, and you shouldn't influence people's lives negatively with your deployed solution. </p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>Remembering the importance of data</li>
				<li>Starting with a thoughtful infrastructure</li>
				<li>Automating recurrent tasks</li>
				<li>Expecting constant change</li>
				<li>Thinking about your responsibility </li>
			</ul>
			<h1 id="_idParaDest-271"><a id="_idTextAnchor270"/>Remembering the importance of data</h1>
			<p>Many algorithmic<a id="_idIndexMarker1850"/> problems for predictions and model fitting are hard to model, compute, and optimize using classic optimization algorithms or complex heuristics. Supervised machine learning provides a powerful new way to solve the most complex problems using optimization and a ton of labeled training data. </p>
			<p>Some may think you just should throw a metric ton of data at a model. Imagine that you have thousands of pictures of the same bird from every possible angle. A trained model based on those pictures would probably not be very predictive for classifying different bird families.</p>
			<p class="callout-heading">Choosing the Right Data Samples for Your Model</p>
			<p class="callout">A trained model will increase<a id="_idIndexMarker1851"/> in quality when it's using highly distinct data samples and data samples that are useful in the context of what your model should predict.</p>
			<p>So, when you're working with ML algorithms, you need to remember that models are powered by the training data you provide them with, as well as their training labels. Good data is the key to good performance. </p>
			<p>Knowing this, let's reiterate the key takeaways when it comes to working with data and training ML models:</p>
			<ul>
				<li><strong class="bold">Spend most of your time wrangling the data</strong>: As we discussed at the beginning of this<a id="_idIndexMarker1852"/> book, in most ML projects, you'll spend about 80% of your time on data analysis, preprocessing, and feature engineering. Understanding your data inside and out is critical to developing a successful predictive model. Think about it this way: the only thing that makes you stand out from your competition is your data. Most likely, your competitors have access to a similar set of algorithms, optimizations, and compute infrastructure that you do. The only thing they don't have is your data and your skill to take apart this data (hopefully). Hence, this is where your secret to success lies: in interpreting, cleaning, modeling, and preparing your data for high-quality predictions.</li>
				<li><strong class="bold">Emphasize the engineering of your features</strong>: The biggest opportunity you get to increase the predictive baseline performance of any of your models is to improve your underlying dataset through better feature engineering or by adding more predictive features. Don't get lost trying to tune and stack the model. Rather, spend most of your time and resources on data preprocessing and feature engineering. Feature engineering is where you can shine and win the prediction game. Are you dealing with dates? Pull in other data sources, such as local and global holidays, and nearby events; add relative dates, such as days before a holiday, days before a weekend, and so on. Are you dealing with locations, cities, or countries? Here, you should pull in demographic data, political data, or geographic data. You get the point.</li>
				<li><strong class="bold">Do not get sidetracked with model tuning</strong>: There is only so much that your model can do. Yes, you can stack multiple models, tune and optimize them, optimize for different metrics, and so on. However, your biggest leverage is your data. A good plan for any ML model is to start with a very simple baseline model. Are you working with categorical data? If so, choose a gradient-boosted tree ensemble and stick with the default parameters. Are you predicting continuous values? If so, choose a logistic regression model. Start small and make sure you get your data right before you start to fiddle with your model.</li>
				<li><strong class="bold">Always start with a baseline model</strong>: Use a baseline model and start to build all your automation, infrastructure, and metrics around it. It's worth noting that a baseline model should perform better than a random approach. Once the pipeline has finished, you can dive into the data, add new data, perform better feature engineering, deploy again, test, and re-iterate. Reducing your model to a primitive baseline model is a difficult step, but it will help you succeed in managing your priorities during the first phase of the project. Why is the baseline model approach so important? Because it sets your mindset for an iterative project, where you constantly measure, add data, retrain, and improve your model. Your model will require retraining and you need to measure when this is the case. To retrain, you will need new training data.</li>
				<li><strong class="bold">Continuously collect new, relevant data samples</strong>: In a perfect setup, you would install a<a id="_idIndexMarker1853"/> continuous data collection pipeline that collects new training data and training labels directly from your current product. Does your model predict search relevance? Collect search queries and the clicked results. Does your model predict fraud? Collect new data and the results of manually verified fraud cases. Does your model predict hashtags? Track the predictions and let your users change them if they're not accurate. In all these examples, we continuously track relevant training data that we can use for constant retraining and fine-tuning. Having this constant stream of training data could be the competitive advantage for your business that sets you up for success. Hence, when you oversee an ML project, think about how you are going to retrain the model in the future.</li>
			</ul>
			<p>Besides following these technical rules to handle an ML project, it is of utmost importance to understand the business side of your company. Such a project typically requires an interdisciplinary team of people to succeed. Therefore, it is vital to get C-level buy-in for a complete company data strategy. Data is your fuel, and it is typically distributed throughout the company in a vast amount of data silos, controlled by different departments. As you probably need access to a lot of these sources to implement and improve ML models, it is of utmost importance to have the authority to access and use that data.</p>
			<p>This often<a id="_idIndexMarker1854"/> requires a mental shift in most companies, as data from different departments needs to be combined and analyzed to be used in predictions. Hence, data quality matters, data lineage is important so that you can understand where it came from, timeliness is important, and correctness is essential. So, make sure that data is a first-class citizen in your company that gets the support, love, and care it deserves.</p>
			<p>Now that we've reiterated these important facts about data processing, let's talk about the environment you are working with.</p>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor271"/>Starting with a thoughtful infrastructure</h1>
			<p>Successfully applied ML projects depend on an iterative approach to tackle data collection, data cleansing, feature engineering, and modeling. After a successful deployment and<a id="_idIndexMarker1855"/> rollout, you should go back to the beginning, keep an eye on your metrics, and collect more data. By now, it should be clear that you will repeat some of your development and deployment steps in the life cycle of your ML project.</p>
			<p>Getting the infrastructure and environment for your ML project right from the beginning will save you a lot of trouble down the road. One key to a successful infrastructure is automation and versioning, as we discussed in the previous chapter. So, we recommend that you take a few extra days to set up your infrastructure and automation and register your datasets, models, and environments from within Azure Machine Learning.</p>
			<p>The same can be said for monitoring. To make educated decisions about whether your model is working as intended, whether the training data is still accurate, or whether the resource utilization is high enough, you need accurate metrics. Adding metrics to a project after deployment is quite tricky. Therefore, you should be aware of what you want to measure and what you want to be alerted on beforehand. Take some extra time at the beginning of your project to think about the metrics that you are going to track.</p>
			<p>Finally, prioritizing infrastructure while working on the data and models is hard. If you can afford the luxury to split these into separate teams for ML infrastructure, modeling, and data, then this may not be at the top of your mind. However, this is often not the case. To avoid this prioritization issue, we recommend starting with a simple baseline model and defining your infrastructure<a id="_idIndexMarker1856"/> automation based on this simple model.</p>
			<p>Let's look at the steps you should perform when you're starting your ML project:</p>
			<ol>
				<li><strong class="bold">Choose a baseline model</strong>: Pick<a id="_idIndexMarker1857"/> the simplest model with default parameters for your use case, a small set of training data, and the most important engineered features.</li>
				<li><strong class="bold">Build a simple pipeline</strong>: Put all these model training steps into a pipeline that builds your model automatically and deploys it into a staging environment. The great thing about this approach is that you automatically prioritize infrastructure and always output a deployed scoring service. This will set you up for success.</li>
				<li><strong class="bold">Dive into the data</strong>: Make sure you understand the data and its quality, how to fill in missing values, and how to pre-process features. You can add additional data and work on feature engineering to turn your raw input data into interpretable data. If you pick a good baseline model, this work should greatly improve the performance of the baseline and give your colleagues a scoring service API to use with the new service.</li>
				<li><strong class="bold">Experiment with more complex models</strong>: Once you are confident that you have built a solid data pipeline, you can tackle modeling, including model selection, training, validation, optimization, and stacking. Again, you should be able to see incremental improvements that can be measured and continuously deployed to any QA environment. Once your performance is good enough, roll out the service to your customers and start collecting metrics and more training data.</li>
				<li><strong class="bold">Monitor cloud usage</strong>: When you develop using compute infrastructure in the cloud, it is easy to quickly spend a few thousand dollars for a couple of unused or underutilized virtual machines. We recommend that you regularly check the number of machines and their utilization. If something is not being used anymore, scale or shut it down. Remember that the cloud's number-one benefit is scalable infrastructure. So, please take advantage of it. </li>
			</ol>
			<p>Following this guidance will <a id="_idIndexMarker1858"/>help you set up a clean and monitored infrastructure that you can evolve along the way.</p>
			<p>Now that we've talked about the base infrastructure you should set up, let's talk about automation again.</p>
			<h1 id="_idParaDest-273"><a id="_idTextAnchor272"/>Automating recurrent tasks</h1>
			<p>Training an ML model is a <a id="_idIndexMarker1859"/>complex iterative process that includes data preparation, feature engineering, model selection, optimization, and deployment. Above all, an enterprise-grade end-to-end ML pipeline needs to be reproducible, interpretable, secure, and automated, which poses an additional challenge for most companies in terms of know-how, costs, and infrastructure requirements.</p>
			<p>In the previous chapters, we learned the ins and outs of this process, so we can confirm that there is nothing simple or easy about it. Tuning a feature engineering approach will affect model training; the missing value strategy during data cleansing will influence the optimization process.</p>
			<p>Above all, the information that's captured by your model is rarely constant, so most ML models require frequent retraining and deployments. This leads to a whole new requirement for MLOps: a DevOps pipeline for ML to ensure continuous integration and continuous deployment of your data, pipelines, and models. </p>
			<p>Automated ML helps simplify this complex iterative process by automating many of these challenges. Instead of manually tuning the input data, then selecting, optimizing, and deploying an ML model manually, an automated service just requires the input data, as well as a few business-related configurations, such as the type of prediction to train.</p>
			<p>Therefore, using tools such as Azure DevOps and Azure Machine Learning pipelines greatly reduces errors and system downtime and frees the user from performing a bunch of manual tasks. In addition, services such as Azure Automated Machine Learning allows users to optimize ML training and even stack multiple models to improve prediction performance. The biggest benefit of this is that the user can focus on the most important part of the ML process: understanding, acquiring, and cleaning the data.</p>
			<p>In many cases, automated ML services will outperform manually trained models while requiring significantly<a id="_idIndexMarker1860"/> less in terms of training and operation costs. The reason for this is that many tasks, such as choosing the correct categorical embedding, handling imbalanced data, selecting the best model, finding the best parameters, and combining multiple models to improve performance, can be systematically optimized as opposed to being chosen manually.</p>
			<p>Every major cloud provider offers mature services so that you can perform automated ML in the cloud and functionalities to deploy these models conveniently. Automated ML is a great way to save time and costs while providing your existing employees with the tools needed for training complex end-to-end ML pipelines. This makes automated ML a real service – MLaaS.</p>
			<p>Speaking about tooling, let's talk about the changes you need to keep up with when you're working with modern cloud systems.</p>
			<h1 id="_idParaDest-274"><a id="_idTextAnchor273"/>Expecting constant change</h1>
			<p>Everything is in a constant state of change. 15 years ago, only a few people ever heard about neural networks <a id="_idIndexMarker1861"/>and machine learning. Today, you have access to a vast amount of ML libraries, programs, and cloud services. Every day, new progress is made to automate ML tasks and improve ML modeling. Just think about the voice assistants you may use and what is happening with self-driving vehicles.</p>
			<p>Due to this, you are in for a whole bunch of constant changes being made to ML libraries and their tooling. This is especially true in a cloud environment, where updates can quickly be pushed out to the userbase compared to licensed software. As we learned previously, looking at the big cloud providers, their services can typically be divided into the following categories:</p>
			<ul>
				<li><strong class="bold">Infrastructure as a Service </strong>(<strong class="bold">IaaS</strong>): IaaS <a id="_idIndexMarker1862"/>services are all-infrastructure abstractions such as virtual machines (compute), disks (storage), and networking.</li>
				<li><strong class="bold">Platform as a Service</strong> (<strong class="bold">PaaS</strong>): PaaS <a id="_idIndexMarker1863"/>services are platforms built on top of these components with additional functionality that exposes a service while hiding the underlying infrastructure and operating system.</li>
				<li><strong class="bold">Software as a Service</strong> (<strong class="bold">SaaS</strong>): SaaS services, in contrast, are exposed through a UI and don't give <a id="_idIndexMarker1864"/>you any access to the underlying software and hardware stack.</li>
			</ul>
			<p>Azure Machine Learning is a <a id="_idIndexMarker1865"/>great example of a PaaS offering as it combines different infrastructure services, UIs, and SDKs to give you great new features and full access to the underlying services, such as blob storage, training clusters, and container registries while putting the operating system out of sight in most cases. On your monthly Azure bill, you will see that you spend most of your money on infrastructure services when using a PaaS solution.</p>
			<p>While the underlying infrastructure builds the foundation for all cloud services, they are not likely to change drastically over the next few years. New improvements will make their way to the market that typically concentrate on throughput levels and network security. Still, you shouldn't expect major changes to be made to the existing APIs. In addition, these offerings are not likely to be discontinued since they are the backbone of many services.</p>
			<p>The same is not true for PaaS services. They are designed to answer the requests of customers regarding an abstracted solution so that they are freed from implementing tons of boilerplate code and handling the lower-level infrastructure details of a solution. How many times have you seen a feature of Azure Machine Learning and thought, <em class="italic">Hey, I could easily implement this on my own</em>? This is certainly true, but you may want someone else to solve this simple thing so that you can concentrate on the complex problems you are trying to solve. And that's why PaaS exists in the first place.</p>
			<p>However, the downside with customer-driven needs is that those needs and usage patterns are constantly evolving. New use cases are cropping up (such as MLOps) that ask for new services or extensions to existing services to be supported. Hence, you should always expect that PaaS will change over time. </p>
			<p>If you were to look at the first version of this book, you would find that nearly half of the code and features that were shown in that version were either deprecated, replaced by something new, or merged with other parts of the Azure Machine Learning service. Depending on when you are reading this book, you may have found discrepancies between the features or APIs that we are describing here and the current APIs and features in Azure. </p>
			<p>If you were understandably confused and asked yourself how this book could already be out of date, we want to assure you that what we are presenting is the right technology to bet on. PaaS offerings in <a id="_idIndexMarker1866"/>general and MLaaS offerings specifically undergo massive changes and improvements all the time. Expect change!</p>
			<p>Let's look at some possible changes you may encounter over time:</p>
			<ul>
				<li><strong class="bold">Expect names to change</strong>: This is probably the most common change. Companies are notoriously bad at naming products, and Azure and all other cloud providers are no exception. This may look like a big change or inconvenience, but it is nothing more than changing the name of a service or component or hiding it somewhere else in the cloud platform. In the past few years, a lot of changes were made to ML regarding Azure. There was a service called <strong class="bold">Azure Machine Learning Studio (classic)</strong>, which<a id="_idIndexMarker1867"/> mostly survived as the <strong class="bold">Designer</strong> in Azure Machine Learning. There were – and still are – services called <strong class="bold">Azure Batch</strong>, <strong class="bold">Azure BatchAI</strong>, and <strong class="bold">AML Compute</strong>, which<a id="_idIndexMarker1868"/> offered mostly the same functionality as the <a id="_idIndexMarker1869"/>compute cluster for batch inference you will now find in<a id="_idIndexMarker1870"/> Azure Machine Learning. Simply put, do not let yourself get distracted by this. Expect some interesting new names to pop up for the functionality that you know and love.</li>
				<li><strong class="bold">Expect the UIs to change</strong>: This is the most visible change and is quite common in cloud offerings of late. Many services get revamped UIs, some get integrated into the Azure UI, and some get placed in a separate application. Expect some functionality to be exposed only in one UI and not another. Most often, however, a new UI means that just the same or similar functionality is accessible through a new interface. This is one of the reasons why we trained you to work so much with the Python API or the Azure CLI instead of the graphical interface.</li>
				<li><strong class="bold">Expect classes and packages to change in the SDKs</strong>: Most APIs of most cloud providers for ML solutions are constantly evolving. Azure has invested a lot of money in its ML service, so change is inevitable. A good way to prepare for this change is to abstract code into specific implementations that can be swapped out easily with new functionality. Another good practice is to be cautious with library updates, but also don't stay behind the most recent version for too long.</li>
			</ul>
			<p>Do you agree that change is the <a id="_idIndexMarker1871"/>only constant, given all these circumstances? Just keep in mind that all PaaS solutions are ultimately built on an underlying infrastructure, which provides a rock-solid foundation for your computing, storage, and networking.</p>
			<p>So, remember: despite the constant change, you are building on the right foundation!</p>
			<p>Having talked about most of the things you should consider while using a cloud platform for ML, let's talk about something far more important: data ethics.</p>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor274"/>Thinking about your responsibility</h1>
			<p>In this final section<a id="_idIndexMarker1872"/> of this book, we want to take a step back from models, deployments, and optimization to talk about a much more important topic: ethics when it comes to handling data or what is today<a id="_idIndexMarker1873"/> known as <strong class="bold">responsible AI/ML</strong>. </p>
			<p>In <a href="B17928_01_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Understanding the End-to-End Machine Learning Process</em>, we talked about <strong class="bold">bias</strong> in data, how it can <a id="_idIndexMarker1874"/>be introduced willingly or unwillingly into a dataset, and what you have to look out for. This is but one small piece of the puzzle to reflect how you are gathering data and how your trained model can negatively influence other people's lives.</p>
			<p>Imagine that you are training an ML model to suggest to a bank teller that the customer in front of him is allowed to receive a loan and what kind of interest rate the customer is allowed to have on that loan. Using an automated system to make this decision can be a blessing or a curse. If there is an inherent bias in most of the bank tellers of a company and you build a fair model, then this will probably be a blessing. However, if your model is based on the previous decisions of those bank tellers, you must be on the lookout for a lot of bias in your data. If not, you may create an even more unfair world because now, your ML system is in charge. A fair teller giving out the loan, even though they may understand that there is a bias in your ML system, is now probably not allowed to overrule it.</p>
			<p>There are far worse examples than this one, but this should give you a good idea of what we want to talk about. </p>
			<p>Generally speaking, we can group the responsibilities you have into the following categories:</p>
			<ul>
				<li><strong class="bold">Interpretability</strong>: How well can<a id="_idIndexMarker1875"/> you explain your model and the results it generates?</li>
				<li><strong class="bold">Fairness</strong>: How well can <a id="_idIndexMarker1876"/>you ensure fairness by eliminating bias in the data? </li>
				<li><strong class="bold">Privacy</strong>: How<a id="_idIndexMarker1877"/> well are the <strong class="bold">personally identifiable information</strong> (<strong class="bold">PII</strong>) of individuals being<a id="_idIndexMarker1878"/> safeguarded in your underlying data and model? Who has access to it?</li>
				<li><strong class="bold">Compliance</strong>: How well documented is <a id="_idIndexMarker1879"/>everything you work with and have access to? How do you track who is using your data or model?</li>
			</ul>
			<p>Let's have a more detailed look <a id="_idIndexMarker1880"/>at what you have to watch out for and what tooling is offered through Azure Machine Learning to accommodate you while you're doing this.</p>
			<h2 id="_idParaDest-276"><a id="_idTextAnchor275"/>Interpreting a model</h2>
			<p>Any deployed ML model is a <a id="_idIndexMarker1881"/>black box. We send input and receive output in the form of a prediction or classification through the model. Therefore, it is hard for stakeholders to understand why and why not a system makes certain decisions. To alleviate this situation, you can apply new tooling to explain your model.</p>
			<p>But before we talk about tooling and approaches to explain an ML model, let's group models into two categories:</p>
			<ul>
				<li><strong class="bold">Black-box models</strong>: Models where the <a id="_idIndexMarker1882"/>calculations are so complex that we do not know how the decision came to be.</li>
				<li><strong class="bold">Glass-box models</strong>: Models where the<a id="_idIndexMarker1883"/> result can be relatively easily explained and calculated. Think about linear regression models, for example. </li>
			</ul>
			<p>Glass-box models tend to be simpler, so the trade-off seems to be between explainability and complexity (and therefore, possibly accuracy). But if your model handles a whole bunch of personal information, you will want to know how the model comes to its conclusion.</p>
			<p>Therefore, the need for an <a id="_idIndexMarker1884"/>explainer arises that can interpret black-box<a id="_idIndexMarker1885"/> models, called the <strong class="bold">Black Box Explainer</strong>. The following are the two most well-known explainers:</p>
			<ul>
				<li><strong class="bold">Shapley Additive Explanations</strong> (<strong class="bold">SHAP</strong>): This is a game theory approach that's applied to <a id="_idIndexMarker1886"/>ML models and is used primarily for explainability. This family of methods assumes every feature in a model as a <strong class="bold">player</strong> in a game. Based on this assumption, you can use the so-called <strong class="bold">Shapley values</strong> to calculate the <a id="_idIndexMarker1887"/>average contribution of a feature value to a prediction. Simply put, this is done by adding and removing features from <strong class="bold">coalitions</strong>, which<a id="_idIndexMarker1888"/> in game theory is the group of players cooperating. SHAP can be used for any type of model, but it is well defined for linear regression, trees, ensemble trees, and deep learning with TensorFlow or Keras. Furthermore, it can explain individual predictions, not only explanations on a global scale. You can read more about SHAP in its open source release (<a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>). </li>
				<li><strong class="bold">Local Interpretable Model-agnostic Explanations</strong> (<strong class="bold">LIME</strong>): This is a method that<a id="_idIndexMarker1889"/> creates a so-called surrogate glass-box<a id="_idIndexMarker1890"/> model based on any black-box classifier model. A surrogate model tries to mimic the behavior of an underlying model while reducing its complexity. This is done by training a linear model in the vicinity of a particular instance. Users can then look at this newly created glass-box model to understand the black-box model's outputs for this neighborhood or subset of predictions. Therefore, LIME can explain individual predictions of the black-box model. You can read more about LIME in its open source release (<a href="https://github.com/marcotcr/lime">https://github.com/marcotcr/lime</a>).</li>
			</ul>
			<p>These are the techniques you can use to interpret black-box models. To alleviate the situation with glass-box models a bit, Microsoft Research is working on an ML model called <strong class="bold">Explainable Boosting Machine</strong> (<strong class="bold">EBM</strong>) that is as <a id="_idIndexMarker1891"/>accurate as gradient boosting while still being completely explainable. Their original paper can be found at <a href="https://arxiv.org/abs/2106.09680">https://arxiv.org/abs/2106.09680</a>. </p>
			<p>To try out these explainers, you can either use these packages directly in your project or you can use the <strong class="source-inline">azureml-interpret</strong> package (<a href="https://docs.microsoft.com/en-us/python/api/azureml-interpret">https://docs.microsoft.com/en-us/python/api/azureml-interpret</a>) from<a id="_idIndexMarker1892"/> the Azure ML SDK. This package gives you access to the <strong class="bold">Interpret Community SDK</strong> (<a href="https://github.com/interpretml/interpret-community">https://github.com/interpretml/interpret-community</a>). Have a read through the explainer that's available on that package. </p>
			<p>If you want to try this out, have a look at the following guide: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml</a>. When you were looking at the Azure Machine Learning studio pages throughout all the hands-on exercises in this book, you may have noticed a tab called <strong class="bold">Explanations</strong> in the<a id="_idIndexMarker1893"/> training runs and models. When you're using this package, you can add the results of the explainers to your training runs and view the visuals online afterward.</p>
			<p>For further reading, have a<a id="_idIndexMarker1894"/> look at the <strong class="bold">InterpretML</strong> project (<a href="https://interpret.ml/docs/intro.html">https://interpret.ml/docs/intro.html</a>), which provides an overview of the different types of explainers.</p>
			<p>Now that we have an idea of how to interpret the results of our models, let's look at fairness.</p>
			<h2 id="_idParaDest-277"><a id="_idTextAnchor276"/>Fairness in model training</h2>
			<p>One of the major tools for analyzing the<a id="_idIndexMarker1895"/> fairness of a model is called <strong class="bold">Fairlearn </strong>(<a href="https://fairlearn.org/">https://fairlearn.org/</a>). To <a id="_idIndexMarker1896"/>define if a model behaves fairly, the algorithms and metrics in the Fairlearn package look for two types of harm that can be done, as follows:</p>
			<ul>
				<li><strong class="bold">Allocation harm</strong>: A model or system withholds opportunities, resources, or information. This would fit our<a id="_idIndexMarker1897"/> previous example, where we discussed an ML system giving out loans to individuals.</li>
				<li><strong class="bold">Quality-of-service harm</strong>: A model or <a id="_idIndexMarker1898"/>system that does not withhold something but behaves differently toward different groups.</li>
			</ul>
			<p>To assess the fairness in a given model, two constructs are used, assessment metrics and mitigation algorithms. These can be classified as follows:</p>
			<ul>
				<li><strong class="bold">Assessment metrics</strong>: Metrics can be calculated for a single model by comparing multiple models <a id="_idIndexMarker1899"/>and for models that have been created through the mitigation algorithms. They span from simple metrics calculating the recall rate of a model up to adding grouping information to the mix to analyze the model results. Further information is available here: <a href="https://fairlearn.org/main/user_guide/assessment.html">https://fairlearn.org/main/user_guide/assessment.html</a>. </li>
				<li><strong class="bold">Reduction algorithms</strong>: These <a id="_idIndexMarker1900"/>build a new standard black-box model from a re-weighted training dataset after the assessment. Users can tweak this through different model runs to find the optimum trade-off between accuracy and fairness. Further information is available here: <a href="https://fairlearn.org/main/user_guide/mitigation.html#reductions">https://fairlearn.org/main/user_guide/mitigation.html#reductions</a>. </li>
				<li><strong class="bold">Post-processing algorithms</strong>: These algorithms take the original model and the sensitive feature to<a id="_idIndexMarker1901"/> calculate a transformation to be applied to the prediction of the model. Through this process, we avoid retraining the original model.</li>
			</ul>
			<p>Be aware that packages such as <a id="_idIndexMarker1902"/>Fairlearn are still in development. Since deciding on fairness is not a simple topic, do not only rely on such tooling. When you're thinking about the types of biases you can introduce, be reflective on what you are doing and use tools like these to get more insights. The developers of Fairlearn pointed the following out:</p>
			<p class="author-quote">"Fairness is fundamentally a sociotechnical challenge. Many aspects of fairness, such as justice and due process, are not captured by quantitative fairness metrics. Furthermore, there are many quantitative fairness metrics which cannot all be satisfied simultaneously. Our goal is to enable humans to assess different mitigation strategies and then make trade-offs appropriate to their scenario."</p>
			<p>For a guide on how to use the Fairlearn package with Azure Machine Learning and how to upload your results, go to <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml</a>. </p>
			<p>Finally, let's learn how to handle privacy and compliance with Azure Machine Learning.</p>
			<h2 id="_idParaDest-278"><a id="_idTextAnchor277"/>Handling PII data and compliance requirements</h2>
			<p>With the <a id="_idIndexMarker1903"/>dawn of legislation <a id="_idIndexMarker1904"/>such as the <strong class="bold">General Data Protection Regulation </strong>(<strong class="bold">GDPR</strong>) in Europe<a id="_idIndexMarker1905"/> and the <strong class="bold">California Consumer Privacy Act</strong> (<strong class="bold">CCPA</strong>) in California, businesses<a id="_idIndexMarker1906"/> are now in a predicament. Besides having clear instructions on how PII data can be utilized, they are also often required to store audit trails of any action that involved this data, from a user up to an employee of the company accessing this data.</p>
			<p>Therefore, it is very<a id="_idIndexMarker1907"/> important to have the tooling to support this effort. Most Azure <a id="_idIndexMarker1908"/>services have security measures in place to deal with external intruders and to build multi-tenant applications, helping customers avoid seeing the PII data of others. Still, the ones administrating the system have access to this clear text data in most organizations. And the same is true for someone building an ML model. In addition, databases on Azure can typically log any access and build an audit trail for review. But what about the ML modeling pipeline or deployment pipeline? Who can see the data in which form and at which point?</p>
			<p>All these questions need to be answered. Let's look at some of the available tooling and research that's being done in this area:</p>
			<ul>
				<li><strong class="bold">Differential privacy</strong>: This mechanism is used to add noise or randomness to data to make the data of a<a id="_idIndexMarker1909"/> person unidentifiable. In doing so, we can still build an accurate model on a slightly changed dataset. Be aware that this is not referring to obvious PII data, such as your name or email address. To give you something to think about: you can likely be identified directly by the version of the browser and the installed browser add-ons you are using. This <a id="_idIndexMarker1910"/>method was implemented in a package called <strong class="bold">SmartNoise </strong>(<a href="https://github.com/opendp/smartnoise-core">https://github.com/opendp/smartnoise-core</a>), which you can use in your ML projects. Additional information about this topic can be found here: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy">https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy</a>. </li>
				<li><strong class="bold">Homomorphic encryption</strong>: This allows computation to be done on encrypted data without <a id="_idIndexMarker1911"/>allowing access to a decryption key. Only the results of the computation need to be decrypted with a secret key. So far, even using encrypted data and decrypting it with a key was bothersome, since running encryption on TBs of data was time-consuming. Now, this technology, which has been researched by Microsoft, is<a id="_idIndexMarker1912"/> available through the <strong class="bold">Microsoft SEAL</strong> project (<a href="https://www.microsoft.com/en-us/research/project/microsoft-seal/">https://www.microsoft.com/en-us/research/project/microsoft-seal/</a>). Furthermore, you can learn how to use this method with an inferencing web service by following the guide at <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal</a>.</li>
				<li><strong class="bold">Datasheets for models</strong>: This<a id="_idIndexMarker1913"/> provides guidelines for documenting ML assets and their life cycles. To be compliant with regulations and also just to work cleanly, a guideline called <strong class="bold">ABOUT ML</strong> (<a href="https://partnershiponai.org/paper/about-ml-reference-document/">https://partnershiponai.org/paper/about-ml-reference-document/</a>) can be adapted. A<a id="_idIndexMarker1914"/> view of how to adapt this guideline in the context of Azure Machine Learning can be found here: <a href="https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb">https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb</a>. </li>
			</ul>
			<p>Keep an eye on these topics as<a id="_idIndexMarker1915"/> they develop since failure to comply with these regulations can have dire consequences.</p>
			<p>As you have seen, all the<a id="_idIndexMarker1916"/> packages we've discussed in this section are still in alpha or beta stages since the topics of interpretability, fairness, and privacy are relatively new in the context of ML. For a decade, ML was more of a research topic than a real-life production environment. Nowadays, solutions that build on ML have found their way into our daily lives. Therefore, we need to take a step back and start asking if we can let machines decide for us without questioning their validity. </p>
			<p>So, when you're running your next ML project that is bound for production, bring these topics into the discussion since they need to be handled from the beginning.</p>
			<h1 id="_idParaDest-279"><a id="_idTextAnchor278"/>Summary</h1>
			<p>In this chapter, we looked at a few things from a much higher level by covering data, infrastructure, monitoring, automation, change management, and ethics. We hope that our coverage of these topics made sense to you after reading this book.</p>
			<p>It is important to understand that your data will control and influence everything, so making data a first-class citizen in your company is the first important step. Hiring a <em class="italic">VP of Data</em> and defining standards on data quality, lineage, and discoverability are just a few of the measures you can take.</p>
			<p>Looking at automatization, we saw that Automated Machine Learning will run the world in a couple of years. The idea is quite simple: a trained meta-model will always be better at proposing, training, optimizing, and stacking models for higher predictive performance than humans. This makes total sense. It is just another parameter optimization step that also includes the model architecture. Another interesting thought is that Automated Machine Learning will offer true MLaaS to users who aren't ML-savvy. Maybe a prediction column will be provided in Excel, or an ML transformation step in Power BI, meaning regular Office users can suddenly harness the power of ML through spreadsheet applications.</p>
			<p>We also mentioned that change is inevitable when working with PaaS in the cloud. This is because PaaS solutions are designed to implement typical customer solutions and drive you toward consuming more infrastructure services. As customer needs evolve, so do these PaaS offerings. Hence, a good takeaway is to not get too attached to product names, UIs, or SDK packages.</p>
			<p>Finally, we understood the importance of ethics in data handling. We discussed the topics of building models that can be explained, assessing the fairness of our models, and how we can safeguard the personal data of individuals from ourselves and others. </p>
			<p>We hope you have enjoyed this book and learned how to master ML and Azure Machine Learning. However, the rabbit hole is far deeper than this book. So, keep on learning, as we also will. Reach out to us on social media and tell us what you've learned, what you liked, and what could be improved in this book. We would love to hear your feedback.</p>
			<p>Until then, happy machine learning!</p>
		</div>
	</div>
</div>
</body></html>