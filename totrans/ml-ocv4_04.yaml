- en: First Steps in Supervised Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the moment you've been waiting for, isn't it?
  prefs: []
  type: TYPE_NORMAL
- en: We have covered all of the bases—we have a functioning Python environment, we
    have OpenCV installed, and we know how to handle data in Python. Now, it's time
    to build our first machine learning system! And what better way to start off than
    to focus on one of the most common and successful types of machine learning: **supervised
    learning**?
  prefs: []
  type: TYPE_NORMAL
- en: From the previous chapter, we already know that supervised learning is all about
    learning regularities in training data by using the labels that come with it so
    that we can predict the labels of some new, never-seen-before test data. In this
    chapter, we want to dig a little deeper and learn how to turn our theoretical
    knowledge ...
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can refer to the code for this chapter at the following link: [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter03](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter03).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is globally a summary of software and hardware requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: You will need OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need Python version 3.6 (any Python 3.x version will be fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need Anaconda Python 3 to install Python and the required modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use any OS—macOS, Windows, and Linux-based OSes—with this book. We recommend
    you have at least 4 GB RAM in your system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You don't need to have a GPU to run the code provided with this book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have previously established that the goal of supervised learning is always
    to predict labels (or target values) for data. However, depending on the nature
    of these labels, supervised learning can come in two distinct forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification**: Supervised learning is called **classification** whenever
    we use the data to predict categories. A good example of this is when we try to
    predict whether an image contains a cat or a dog. Here, the labels of the data
    are categorical, either one or the other, but never a mixture of categories. For
    example, a picture contains either a cat or a dog, never 50% cat and 50% dog (before
    you ask, no, here we do not consider pictures of the cartoon character, CatDog),
    and our job ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having a look at supervised learning in OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just knowing how supervised learning works is not going to be of any use if
    we can't put it into practice. Thankfully, OpenCV provides a pretty straightforward
    interface for all its statistical learning models, which includes all supervised
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: In OpenCV, every machine learning model derives from the `cv::ml::StatModel` base
    class. This is fancy talk for saying that if we want to use a machine learning model in
    OpenCV, we have to provide all of the functionality that `StatModel` tells us
    to. This includes a method to train the model (called `train`) and a method to
    measure the performance of the model (called `calcError`).
  prefs: []
  type: TYPE_NORMAL
- en: In **Object-Oriented Programming** (**OOP**), we deal primarily with objects or classes.
    An object consists of several functions, called **methods**, as well as variables,
    called **members** or **attributes**. You can learn more about OOP in Python at [https://docs.python.org/3/tutorial/classes.html](https://docs.python.org/3/tutorial/classes.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to this organization of the software, setting up a machine learning
    model in OpenCV always follows the same logic, as we will see later:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialization**: We call the model by name to create an empty instance of
    the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set parameters**: If the model needs some parameters, we can set them via
    setter methods, which can be different for every model. For example, for a k-NN
    algorithm to work, we need to specify its open parameter, *k* (as we will find
    out later).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Train the model**: Every model must provide a method called `train`, used
    to fit the model to some data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predict new labels**: Every model must provide a method called `predict`,
    used to predict the labels of new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Score the model**: Every model must provide a method called `calcError`,
    used to measure performance. This calculation might be different for every model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because OpenCV is a vast and community-driven project, not every algorithm follows
    these rules to the extent that we as users might expect. For example, the k-NN
    algorithm does most of its work in a `findNearest` method, although `predict` still
    works. We will make sure to point out these discrepancies as we work through different
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: As we will make occasional use of scikit-learn to implement some machine learning
    algorithms that OpenCV does not provide, it is worth pointing out that learning
    algorithms in scikit-learn follow an almost identical logic. The most notable
    difference is that scikit-learn sets all of the required model parameters in the
    initialization step. Also, it calls the training function, `fit`, instead of `train` and
    the scoring function `score` instead of `calcError`.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring model performance with scoring functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important parts of building a machine learning system is to find a
    way to measure the quality of model predictions. In real-life scenarios, a model
    will rarely get everything right. From earlier chapters, we know that we are supposed
    to use data from the test set to evaluate our model. But how exactly does that
    work?
  prefs: []
  type: TYPE_NORMAL
- en: The short, but not very helpful, answer is that it depends on the model. People
    have come up with all sorts of scoring functions that can be used to evaluate
    the trained model in all possible scenarios. The good news is that a lot of them
    are actually part of scikit-learn's `metrics` module.
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a quick look at some of the most important scoring functions. ...
  prefs: []
  type: TYPE_NORMAL
- en: Scoring classifiers using accuracy, precision, and recall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a binary classification task where there are only two different class labels,
    there are several different ways to measure classification performance. Some common
    metrics are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`accuracy_score`: Accuracy counts the number of data points in the test set
    that have been predicted correctly and returns that number as a fraction of the
    test set size. Sticking to the example of classifying pictures as cats or dogs,
    accuracy indicates the fraction of pictures that have been correctly classified
    as containing either a cat or a dog. This is the most basic scoring function for
    classifiers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`precision_score`: Precision describes the ability of a classifier not to label
    as a cat a picture that contains a dog. In other words, out of all of the pictures
    in the test set that the classifier thinks contain a cat, precision is the fraction
    of pictures that actually contain a cat.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recall_score`: Recall (or sensitivity) describes the ability of a classifier to
    retrieve all of the pictures that contains a cat. In other words, out of all of
    the pictures of cats in the test set, recall is the fraction of pictures that
    has been correctly identified as pictures of cats.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s say, we have some `ground truth` (correct according to the dataset we
    have) class labels that are either zeros or ones. We can generate them at random
    using NumPy''s random number generator. Obviously, this means that, whenever we
    rerun our code, new data points will be generated at random. However, for the
    purpose of this book, this is not very helpful, as I want you to be able to run
    the code and always get the same result as me. A nice trick to achieve that is
    to fix the seed of the random number generator. This will make sure the generator
    is initialized the same way every time you run the script:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can fix the seed of the random number generator using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can generate five random labels that are either zeros or ones by picking
    random integers in the range,  `(0,2)`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the literature, these two classes are sometimes also called **positives** (all
    data points with the class label, `1`) and **negatives** (all other data points).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume we have a classifier that tries to predict the class labels mentioned
    earlier. For the sake of argument, let''s say the classifier is not very smart
    and always predicts the label, `1`. We can mock this behavior by hardcoding the
    prediction labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: What is the accuracy of our prediction?
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, accuracy counts the number of data points in the test
    set that have been predicted correctly and returns that number as a fraction of
    the test set size. We correctly predicted only the second data point (where the
    true label is `1`). In all other cases, the true label was `0`, yet we predicted
    `1`. Hence, our accuracy should be 1/5 or 0.2.
  prefs: []
  type: TYPE_NORMAL
- en: 'A naive implementation of an accuracy metric might sum up all occurrences where
    the predicted class label matched the true class label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'A smarter, and more convenient, implementation is provided by scikit-learn''s `metrics` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'That wasn''t too hard, was it? However, to understand precision and recall,
    we need a general understanding of type I and type II errors. Let''s recall that
    data points with the class label, `1`, are often called positives, and data points
    with the class label, `0` (or -1) are often called negatives. Then, classifying
    a specific data point can have one of four possible outcomes, as illustrated by the
    following confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Is truly positive** | **Is truly negative** |'
  prefs: []
  type: TYPE_TB
- en: '| **Predicted positive** | True Positive | False Positive |'
  prefs: []
  type: TYPE_TB
- en: '| **Predicted negative** | False Negative | True Negative |'
  prefs: []
  type: TYPE_TB
- en: Let's break this down. If a data point was truly positive, and we predicted
    a positive, we got it all right! In this case, the outcome is called a **true
    positive**. If we thought the data point was a positive, but it was really a negative,
    we falsely predicted a positive (hence the term, **false positive**). Analogously,
    if we thought the data point was negative, but it was really a positive, we falsely predicted a
    negative (false negative). Finally, if we predicted a negative and the data point
    was truly a negative, we found a true negative.
  prefs: []
  type: TYPE_NORMAL
- en: In statistical hypothesis testing, false positives are also known as **type
    I errors** and false negatives are also known as **type II errors**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s quickly calculate these four metrics on our mock-up data. We have a
    true positive, where the true label is `1` and we predicted `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, a false positive is where we predicted `1` but `ground truth` was
    really `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'I''m sure by now you''ve got the hang of it. But do we even have to do the
    math to know about predicted negatives? Our not-so-smart classifier never predicted
    `0`, so `(y_pred == 0)` should never be true:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also draw the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Is truly positive** | **Is truly negative** |'
  prefs: []
  type: TYPE_TB
- en: '| **Predicted positive** | 1 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| **Predicted negative** | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'To make sure we did everything right, let''s calculate the accuracy one more
    time. Accuracy should be the number of true positives plus the number of true
    negatives (that is, everything we got right) divided by the total number of data
    points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Success! Precision is then given as the number of true positives divided by
    the number of all true predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'It turns out that precision is no better than accuracy in our case. Let''s
    check our math with scikit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, `recall` is given as the fraction of all positives that we correctly
    classified as positives:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Perfect recall! But, going back to our mock-up data, it should be clear that
    this excellent recall score was mere luck. Since there was only a single `1` label
    in our mock-up dataset, and we happened to correctly classify it, we got a perfect
    recall score. Does that mean our classifier is perfect? Not really! But we have
    found three useful metrics that seem to measure complementary aspects of our classification
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Scoring regressors using mean squared error, explained variance, and R squared
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When it comes to regression models, our metrics, as shown earlier, don''t work
    anymore. After all, we are now predicting continuous output values, not distinct
    classification labels. Fortunately, scikit-learn provides some other useful scoring
    functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mean_squared_error`: The most commonly used error metric for regression problems
    is to measure the squared error between the predicted and the true target value
    for every data point in the training set, averaged across all of the data points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`explained_variance_score`: A more sophisticated metric is to measure to what
    degree a model can explain the variation or dispersion of the test data. Often,
    the amount of explained ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using classification models to predict class labels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With these tools in hand, we can now take on our first real classification example.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the small town of Randomville, where people are crazy about their two
    sports teams, the Randomville Reds and the Randomville Blues. The Reds had been
    around for a long time, and people loved them. But then, some out-of-town millionaire
    came along and bought the Reds' top scorer and started a new team, the Blues.
    To the discontent of most Reds fans, the top scorer would go on to win the championship
    title with the Blues. Years later, he would return to the Reds, despite some backlash
    from fans who could never forgive him for his earlier career choices. But anyway,
    you can see why fans of the Reds don't necessarily get along with fans of the
    Blues. In fact, these two fan bases are so divided that they never even live next
    to each other. I've even heard stories where the Red fans deliberately moved away
    once Blues fans moved in next door. True story!
  prefs: []
  type: TYPE_NORMAL
- en: Anyway, we are new in town and are trying to sell some Blues merchandise to
    people by going from door to door. However, every now and then we come across
    a bleeding-heart Reds fan who yells at us for selling Blues stuff and chases us
    off their lawn. Not nice! It would be much less stressful, and a better use of
    our time, to avoid these houses altogether and just visit the Blues fans instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Confident that we can learn to predict where the Reds fans live, we start keeping
    track of our encounters. If we come by a Reds fan''s house, we draw a red triangle
    on our handy town map; otherwise, we draw a blue square. After a while, we get
    a pretty good idea of where everyone lives:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ced3ad58-fea3-4305-8752-ecebfde7cc9f.png)'
  prefs: []
  type: TYPE_IMG
- en: However, now, we approach the house that is marked as a green circle in the
    preceding map. Should we knock on their door? We try to find some clue as to what
    team they prefer (perhaps a team flag hanging from the back porch), but we can't
    see any. How can we know if it is safe to knock on their door?
  prefs: []
  type: TYPE_NORMAL
- en: What this silly example illustrates is exactly the kind of problem a supervised
    learning algorithm can solve. We have a bunch of observations (houses, their locations,
    and their colors) that make up our training data. We can use this data to learn
    from experience so that, when we face the task of predicting the color of a new
    house, we can make a well-informed estimate.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned earlier, fans of the Reds are really passionate about their
    team, so they would never move next to a Blues fan. Couldn't we use this information
    and look at all of the neighboring houses, to find out what kind of fan lives
    in the new house?
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what the k-NN algorithm would do.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the k-NN algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The k-NN algorithm is arguably one of the simplest machine learning algorithms.
    The reason for this is that we basically only need to store the training dataset.
    Then, to predict a new data point, we only need to find the closest data point
    in the training dataset: its nearest neighbor.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, the k-NN algorithm argues that a data point probably belongs
    to the same class as its neighbors. Think about it: if our neighbor is a Reds
    fan, we''re probably Reds fans, too; otherwise, we would have moved away a long
    time ago. The same can be said for the Blues.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, some neighborhoods might be a little more complicated. In this case,
    we would not just consider our closest neighbor (where *k=1*), but instead ...
  prefs: []
  type: TYPE_NORMAL
- en: Implementing k-NN in OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using OpenCV, we can easily create a k-NN model via the `cv2.ml.KNearest_create()`
    function. Building the model then involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate some training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a k-NN object for a given number, *k*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the *k* nearest neighbors of a new data point that we want to classify.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign the class label of the new data point by majority vote.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first import all of the necessary modules: OpenCV for the k-NN algorithm,
    NumPy for data processing, and Matplotlib for plotting. If you are working in
    a Jupyter Notebook, don''t forget to call the `%matplotlib inline` magic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Generating the training data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first step is to generate some training data. For this, we will use NumPy''s
    random number generator. As discussed in the previous section, we will fix the
    seed of the random number generator, so that re-running the script will always
    generate the same values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Alright, now let's get to it. What should our training data look like exactly?
  prefs: []
  type: TYPE_NORMAL
- en: In the previous example, each data point is a house on the town map. Every data
    point has two features (that is, the *x* and *y* coordinates of its location on
    the town map) and a class label (that is, a blue square if a Blues fan lives there
    and a red triangle if a Reds fan lives there).
  prefs: []
  type: TYPE_NORMAL
- en: The features of a single data point can, therefore, be represented ...
  prefs: []
  type: TYPE_NORMAL
- en: Training the classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As with all other machine learning functions, the k-NN classifier is part of
    the OpenCV 3.1 `ml` module. We can create a new classifier using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In older versions of OpenCV, this function might be called `cv2.KNearest()`
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then pass our training data to the `train` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have to tell `knn` that our data is an *N x 2* array (that is, every
    row is a data point). Upon success, the function returns `True`.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the label of a new data point
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The other really helpful method that `knn` provides is called `findNearest`.
    It can be used to predict the label of a new data point based on its nearest neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to our `generate_data` function, it is actually really easy to generate
    a new data point! We can think of a new data point as a dataset of size `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Our function also returns a random label, but we are not interested in that.
    Instead, we want to predict it using our trained classifier! We can tell Python
    to ignore an output value with an underscore (`_`).
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a look at our town map again. We will plot the training set as we
    did earlier, but ...
  prefs: []
  type: TYPE_NORMAL
- en: Using regression models to predict continuous outcomes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's turn our attention to a regression problem. As I'm sure you can recite
    in your sleep by now, regression is all about predicting continuous outcomes rather
    than predicting discrete class labels.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The easiest regression model is called **linear regression**. The idea behind
    linear regression is to describe a target variable (such as Boston house pricing—recall
    the various datasets we studied in [Chapter 1](7ebeef44-67a4-4843-83e0-bd644fc19eea.xhtml),
    *A Taste of Machine Learning*) with a linear combination of features.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep things simple, let''s just focus on two features. Let''s say we want
    to predict tomorrow''s stock prices using two features: today''s stock price and
    yesterday''s stock price. We will denote today''s stock price as the first feature, *f[1]*,
    and yesterday''s stock price as *f[2]*. Then, the goal of linear regression would
    be to learn two weight coefficients, *w[1]* and *w[2]*, so that we can predict
    tomorrow''s stock price as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Here,  is the
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression in OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before trying out linear regression on a real-life dataset, let''s understand
    how we can use the `cv2.fitLine` function to fit a line to a 2D or 3D point set:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by generating some points. We will generate them by adding noise
    to the points lying on the line ![](img/25934214-92e9-4194-937c-af8f014804a7.png):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also visualize these points using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following diagram, where the red line is the true function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/93344671-1736-4539-991e-8face2c9f3a6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we will split the points into training and testing sets. Here, we will
    split the data into a 70:30 ratio, meaning, 70% of the points will be used for
    training and 30% for testing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s use `cv2.fitLine` to fit a line to this 2D point set. This function
    takes in the following arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`points`: This is the set of points to which a line has to be fit.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`distType`: This is the distance used by the M-estimator.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`param`: This is the numerical parameter (C), which is used in some types of
    distances. We will keep it at 0 so that an optimal value can be chosen.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reps`: This is the accuracy of the distance between the origin and the line.
    `0.01` is a good default value for `reps`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aeps`: This is the accuracy of the angle. `0.01` is a good default value for `aeps`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information, have a look at the [documentation](https://docs.opencv.org/4.0.0/d3/dc0/group__imgproc__shape.html#gaf849da1fdafa67ee84b1e9a23b93f91f).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what kinds of result we get using different distance type options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also use scikit-learn''s `LinearRegression` to fit the training points
    and then use the `predict` function to predict the *y*-values for them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We use `reshape(-1,1)` and `reshape(1,-1)` to convert the NumPy arrays into
    a column vector and then back into a row vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The only purpose of this preceding (and lengthy) code was to create a plot that
    could be used to compare the results obtained using different distance measures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a look at the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02196ce1-87a5-4273-b2b5-43bd4f62b56e.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can clearly see, scikit-learn's `LinearRegression` model performs much
    better than OpenCV's `fitLine` function. Now, let's use scikit-learn's API to
    predict Boston housing prices.
  prefs: []
  type: TYPE_NORMAL
- en: Using linear regression to predict Boston housing prices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get a better understanding of linear regression, we want to build a simple
    model that can be applied to one of the most famous machine learning datasets:
    the **Boston housing prices dataset**. Here, the goal is to predict the value
    of homes in several Boston neighborhoods in the 1970s, using information such
    as crime rate, property tax rate, distance to employment centers, and highway
    accessibility.'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can again thank scikit-learn for easy access to the dataset. We first import
    all of the necessary modules, as we did earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Then loading the dataset is a one-liner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The structure of the `boston` object is identical to the `iris` object, as
    discussed in the preceding command. We can get more information about the dataset
    in `''DESCR''` and find all data in `''data''`, all feature names in `''feature_names''`, the
    physical location of the Boston CSV dataset in `''filename''`, and all target
    values in `''target''`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The dataset contains a total of `506` data points, each of which has `13` features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, we have only a single target value, which is the housing price:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Training the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now let''s create a `LinearRegression` model that we will then train on the
    training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding command, we want to split the data into training and test
    sets. We are free to make the split as we see fit, but usually it is a good idea
    to reserve between 10 percent and 30 percent for testing. Here, we choose 10 percent,
    using the `test_size` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In scikit-learn, the `train` function is called `fit` but otherwise behaves
    exactly the same as in OpenCV:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Testing the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test the generalization performance of the model, we calculate the mean squared
    error on the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We note that the mean squared error is a little lower on the test set than
    the training set. This is good news, as we care mostly about the test error. However,
    from these numbers it is really hard to understand how good the model really is.
    Perhaps it''s better to plot the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c458025-ac75-4430-91a7-23f68787efb4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This makes more sense! Here, we see the `ground truth` housing prices for all
    test samples in red and our predicted housing prices in blue. It''s pretty close,
    if you ask me. It is interesting to note, though, that the model tends to be off
    the most for really high or really low housing prices, such as the peak values
    of data points **12**, **18**, and **42**. We can formalize the amount of variance
    in the data that we were able to explain by calculating R squared:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This will plot the `ground truth` prices, `y_test`, on the *x* axis and our
    predictions, `y_pred`, on the *y* axis. We also plot a diagonal line for reference
    (using a black dashed line, `''k--''`), as we will see soon. But we also want
    to display the R² score and mean squared error in a textbox:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following diagram and is a professional way of plotting
    a model fit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/139e4726-1300-4c73-aa11-c8282dba5832.png)'
  prefs: []
  type: TYPE_IMG
- en: If our model was perfect, then all data points would lie on the dashed diagonal,
    since `y_pred` would always be equal to `y_true`. Deviations from the diagonal
    indicate that the model made some errors, or that there is some variance in the
    data that the model was not able to explain. Indeed, ![](img/a15dc10c-dde6-4547-ac44-71066ff64510.png)
    indicates that we were able to explain 76% of the scatter in the data, with a
    mean squared error of 14.996\. These are some performance measures we can use
    to compare the linear regression model to some more complicated ones.
  prefs: []
  type: TYPE_NORMAL
- en: Applying Lasso and ridge regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common problem in machine learning is that an algorithm might work really
    well on the training set but, when applied to unseen data, it makes a lot of mistakes.
    You can see how this is problematic since, often, we are most interested in how
    a model generalizes to new data. Some algorithms (such as decision trees) are
    more susceptible to this phenomenon than others, but even linear regression can
    be affected.
  prefs: []
  type: TYPE_NORMAL
- en: This phenomenon is also known as **overfitting**, and we will talk about it
    extensively in [Chapter 5](5e1a6c2e-f10d-4599-993c-16e772b10a50.xhtml), *Using
    Decision Trees to Make a Medical Diagnosis*, and [Chapter 11](904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml), *Selecting
    the Right Model with Hyperparameter Tuning*.
  prefs: []
  type: TYPE_NORMAL
- en: A common technique for reducing overfitting is called **regularization**, which
    involves ...
  prefs: []
  type: TYPE_NORMAL
- en: Classifying iris species using logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another famous dataset in the world of machine learning is called the Iris dataset.
    The Iris dataset contains measurements of 150 iris flowers from three different
    species: Setosa, Versicolor, and Viriginica. These measurements include the length
    and width of the petals and the length and width of the sepals, all measured in
    centimeters.'
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to build a machine learning model that can learn the measurements
    of these iris flowers, the species of which are known, so that we can predict
    the species for a new iris flower.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we start off with this section, let me issue warning—logistic regression,
    despite its name, is actually a model for classification, specifically when you
    have two classes. It derives its name from the  logistic function (or sigmoid)
    it uses to convert any real-valued input *x* into a predicted output value *ŷ* that takes values
    between **0** and **1**, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b9b54eb8-287c-4286-a68e-d5f9496af292.png)'
  prefs: []
  type: TYPE_IMG
- en: Rounding *ŷ* to the nearest integer effectively classifies the input as belonging
    either to class **0** or **1**.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, most often, our problems have more than one input or feature value, *x*.
    For example, the Iris dataset provides a total ...
  prefs: []
  type: TYPE_NORMAL
- en: Loading the training data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Iris dataset is included with scikit-learn. We first load all of the necessary modules,
    as we did in our earlier examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Then loading the dataset is a one-liner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This function returns a dictionary we call `iris`, which contains a bunch of
    different fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, all of the data points are contained in `''data''`. There are `150` data
    points, each of which has `4` feature values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'These four features correspond to the sepal and petal dimensions mentioned
    earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'For every data point, we have a class label stored in `target`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also inspect the class labels and find that there is a total of three
    classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Making it a binary classification problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the sake of simplicity, we want to focus on a binary classification problem for
    now, where we only have two classes. The easiest way to do this is to discard
    all data points belonging to a certain class, such as class label 2, by selecting
    all of the rows that do not belong to class `2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's inspect the data.
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before you get started with setting up a model, it is always a good idea to have a
    look at the data. We did this earlier for the town map example, so let''s repeat
    it here too. Using Matplotlib, we create a **scatter plot** where the color of
    each data point corresponds to the class label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'To make plotting easier, we limit ourselves to the first two features (`iris.feature_names[0]` being
    the sepal length and `iris.feature_names[1]` being the sepal width). We can see
    a nice separation of classes in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02b2daa3-8a42-4601-b8c5-e84f87ed0cdb.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding image shows the plot for the first two features of the Iris dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting data into training and test sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We learned, in the previous chapter, that it is essential to keep training and
    test data separate. We can easily split the data using one of scikit-learn''s
    many helper functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we want to split the data into 90% training data and 10% test data, which
    we specify with `test_size=0.1`. By inspecting the return arguments, we note that
    we ended up with exactly `90` training data points and `10` test data points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Training the classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Creating a logistic regression classifier involves pretty much the same steps
    as setting up k-NN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We then have to specify the desired training method. Here, we can choose `cv2.ml.LogisticRegression_BATCH` or `cv2.ml.LogisticRegression_MINI_BATCH`.
    For now, all we need to know is that we want to update the model after every data
    point, which can be achieved with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We also want to specify the number of iterations the algorithm should run before
    it terminates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then call the `train` method of the object (in the exact same way as
    we did earlier), which will return `True` upon success:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'As we just saw, the goal of the training phase is to find a set of weights
    that best transform the feature values into an output label. A single data point
    is given by its four feature values (*f[0]*, *f[1]*, *f[2]*, and *f[3]*). Since
    we have four features, we should also get four weights, so that *x = w[0] f[0] +
    w[1] f[1] + w[2] f[2] + w[3] f[3]*, and *ŷ=σ(x)*. However, as discussed previously,
    the algorithm adds an extra weight that acts as an offset or bias, so that *x
    = w[0] f[0] + w[1] f[1] + w[2] f[2] + w[3] f[3] + w[4]*. We can retrieve these
    weights as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This means that the input to the logistic function is *x = -0.0409 f[0] - 0.0191
    f[1] - 0.163 f[2] + 0.287 f[3] + 0.119*. Then, when we feed in a new data point
    (*f[0]*, *f[1]*, *f[2]*, *f[3]*) that belongs to class 1, the output *ŷ=σ(x)* should
    be close to 1\. But how well does that actually work?
  prefs: []
  type: TYPE_NORMAL
- en: Testing the classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see for ourselves by calculating the accuracy score on the training
    set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Perfect score! However, this only means that the model was able to perfectly **memorize** the
    training dataset. This does not mean that the model would be able to classify
    a new, unseen data point. For this, we need to check the test dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Luckily, we get another perfect score! Now we can be sure that the model we
    built is truly awesome.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered quite a lot of ground, didn't we?
  prefs: []
  type: TYPE_NORMAL
- en: In short, we learned a lot about different supervised learning algorithms, how
    to apply them to real datasets, and how to implement everything in OpenCV. We
    introduced classification algorithms such as k-NN and logistic regression and
    discussed how they could be used to predict labels as two or more discrete categories.
    We introduced various variants of linear regression (such as Lasso regression
    and ridge regression) and discussed how they could be used to predict continuous
    variables. Last but not least, we got acquainted with the Iris and Boston datasets,
    two classics in the history of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, we will go into much greater depth within these topics
    and explore some more interesting examples of where these concepts can be useful.
  prefs: []
  type: TYPE_NORMAL
- en: But first, we need to talk about another essential topic in machine learning, feature
    engineering. Often, data does not come in nicely formatted datasets, and it is
    our responsibility to represent the data in a meaningful way. Therefore, the next
    chapter will talk about representing features and engineering data.
  prefs: []
  type: TYPE_NORMAL
