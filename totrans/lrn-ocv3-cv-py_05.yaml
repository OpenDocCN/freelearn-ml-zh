- en: Chapter 5. Detecting and Recognizing Faces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Among the many reasons that make computer vision a fascinating subject is the
    fact that computer vision makes very *futuristic*-sounding tasks a reality. One
    such feature is face detection. OpenCV has a built-in facility to perform face
    detection, which has virtually infinite applications in the real world in all
    sorts of contexts, from security to entertainment.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter introduces some of OpenCV's face detection functionalities, along
    with the data files that define particular types of trackable objects. Specifically,
    we look at Haar cascade classifiers, which analyze contrast between adjacent image
    regions to determine whether or not a given image or subimage matches a known
    type. We consider how to combine multiple Haar cascade classifiers in a hierarchy,
    such that one classifier identifies a parent region (for our purposes, a face)
    and other classifiers identify child regions (eyes, nose, and mouth).
  prefs: []
  type: TYPE_NORMAL
- en: We also take a detour into the humble but important subject of rectangles. By
    drawing, copying, and resizing rectangular image regions, we can perform simple
    manipulations on image regions that we are tracking.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, we will integrate face tracking and rectangle manipulations
    into Cameo. Finally, we'll have some face-to-face interaction!
  prefs: []
  type: TYPE_NORMAL
- en: Conceptualizing Haar cascades
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we talk about classifying objects and tracking their location, what exactly
    are we hoping to pinpoint? What constitutes a recognizable part of an object?
  prefs: []
  type: TYPE_NORMAL
- en: Photographic images, even from a webcam, may contain a lot of detail for our
    (human) viewing pleasure. However, image detail tends to be unstable with respect
    to variations in lighting, viewing angle, viewing distance, camera shake, and
    digital noise. Moreover, even real differences in physical detail might not interest
    us for the purpose of classification. I was taught in school that no two snowflakes
    look alike under a microscope. Fortunately, as a Canadian child, I had already
    learned how to recognize snowflakes without a microscope, as the similarities
    are more obvious in bulk.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, some means of abstracting image detail is useful in producing stable classification
    and tracking results. The abstractions are called **features**, which are said
    to be **extracted** from the image data. There should be far fewer features than
    pixels, though any pixel might influence multiple features. The level of similarity
    between two images can be evaluated based on Euclidean distances between the images'
    corresponding features.
  prefs: []
  type: TYPE_NORMAL
- en: For example, distance might be defined in terms of spatial coordinates or color
    coordinates. Haar-like features are one type of feature that is often applied
    to real-time face tracking. They were first used for this purpose in the paper,
    *Robust Real-Time Face Detection*, *Paul Viola and Michael Jones*, *Kluwer Academic
    Publishers*, *2001* (available at [http://www.vision.caltech.edu/html-files/EE148-2005-Spring/pprs/viola04ijcv.pdf](http://www.vision.caltech.edu/html-files/EE148-2005-Spring/pprs/viola04ijcv.pdf)).
    Each Haar-like feature describes the pattern of contrast among adjacent image
    regions. For example, edges, vertices, and thin lines each generate distinctive
    features.
  prefs: []
  type: TYPE_NORMAL
- en: For any given image, the features may vary depending on the region's size; this
    may be called the **window size**. Two images that differ only in scale should
    be capable of yielding similar features, albeit for different window sizes. Thus,
    it is useful to generate features for multiple window sizes. Such a collection
    of features is called a **cascade**. We may say a Haar cascade is scale-invariant
    or, in other words, robust to changes in scale. OpenCV provides a classifier and
    tracker for scale-invariant Haar cascades that it expects to be in a certain file
    format.
  prefs: []
  type: TYPE_NORMAL
- en: Haar cascades, as implemented in OpenCV, are not robust to changes in rotation.
    For example, an upside-down face is not considered similar to an upright face
    and a face viewed in profile is not considered similar to a face viewed from the
    front. A more complex and more resource-intensive implementation could improve
    Haar cascades' robustness to rotation by considering multiple transformations
    of images as well as multiple window sizes. However, we will confine ourselves
    to the implementation in OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Haar cascade data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have a copy of the source code of OpenCV 3, you will find a folder,
    `data/haarcascades`.
  prefs: []
  type: TYPE_NORMAL
- en: This folder contains all the XML files used by the OpenCV face detection engine
    to detect faces in still images, videos, and camera feeds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you find `haarcascades`, create a directory for your project; in this
    folder, create a subfolder called `cascades`, and copy the following files from
    `haarcascades` into `cascades`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As their names suggest, these cascades are for tracking faces, eyes, noses,
    and mouths. They require a frontal, upright view of the subject. We will use them
    later when building a face detector. If you are curious about how these data sets
    are generated, refer to *Appendix B*, *Generating Haar Cascades for Custom Targets*,
    *OpenCV Computer Vision with Python*. With a lot of patience and a powerful computer,
    you can make your own cascades and train them for various types of objects.
  prefs: []
  type: TYPE_NORMAL
- en: Using OpenCV to perform face detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Unlike what you may think from the outset, performing face detection on a still
    image or a video feed is an extremely similar operation. The latter is just the
    sequential version of the former: face detection on videos is simply face detection
    applied to each frame read into the program from the camera. Naturally, a whole
    host of concepts are applied to video face detection such as tracking, which does
    not apply to still images, but it''s always good to know that the underlying theory
    is the same.'
  prefs: []
  type: TYPE_NORMAL
- en: So let's go ahead and detect some faces.
  prefs: []
  type: TYPE_NORMAL
- en: Performing face detection on a still image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first and most basic way to perform face detection is to load an image and
    detect faces in it. To make the result visually meaningful, we will draw rectangles
    around faces on the original image.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have `haarcascades` included in your project, let's go ahead and
    create a basic script to perform face detection.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let's go through the code. First, we use the obligatory `cv2` import (you'll
    find that every script in this book will start like this, or almost similar).
    Secondly, we declare the `detect` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Within this function, we declare a `face_cascade` variable, which is a `CascadeClassifier`
    object for faces, and responsible for face detection.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We then load our file with `cv2.imread`, and convert it to grayscale, because
    that's the color space in which the face detection happens.
  prefs: []
  type: TYPE_NORMAL
- en: The next step (`face_cascade.detectMultiScale`) is where we operate the actual
    face detection.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The parameters passed are `scaleFactor` and `minNeighbors`, which determine
    the percentage reduction of the image at each iteration of the face detection
    process, and the minimum number of neighbors retained by each face rectangle at
    each iteration. This may all seem a little complex in the beginning but you can
    check all the options out in the official documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The value returned from the detection operation is an array of tuples that represent
    the face rectangles. The utility method, `cv2.rectangle`, allows us to draw rectangles
    at the specified coordinates (`x` and `y` represent the left and top coordinates,
    `w` and `h` represent the width and height of the face rectangle).
  prefs: []
  type: TYPE_NORMAL
- en: We will draw blue rectangles around all the faces we find by looping through
    the faces variable, making sure we use the original image for drawing, not the
    gray version.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we create a `namedWindow` instance and display the resulting processed
    image in it. To prevent the image window from closing automatically, we insert
    a call to `waitKey`, which closes the window down at the press of any key.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'And there we go, a whole set of Vikings have been detected in our image, as
    shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Performing face detection on a still image](img/image00213.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Performing face detection on a video
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now have a good foundation to understand how to perform face detection on
    a still image. As mentioned previously, we can repeat the process on the individual
    frames of a video (be it a camera feed or a video) and perform face detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'The script will perform the following tasks: it will open a camera feed, it
    will read a frame, it will examine that frame for faces, it will scan for eyes
    within the faces detected, and then it will draw blue rectangles around the faces
    and green rectangles around the eyes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a file called `face_detection.py` and start by importing the
    necessary module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After this, we declare a method, `detect()`, which will perform face detection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The first thing we need to do inside the `detect()` method is to load the Haar
    cascade files so that OpenCV can operate face detection. As we copied the cascade
    files in the local `cascades/` folder, we can use a relative path. Then, we open
    a `VideoCapture` object (the camera feed). The `VideoCapture` constructor takes
    a parameter, which indicates the camera to be used; `zero` indicates the first
    camera available.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next up, we capture a frame. The `read()` method returns two values: a Boolean
    indicating the success of the frame read operation, and the frame itself. We capture
    the frame, and then we convert it to grayscale. This is a necessary operation,
    because face detection in OpenCV happens in the grayscale color space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Much like the single still image example, we call `detectMultiScale` on the
    grayscale version of the frame.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a few additional parameters in the eye detection. Why? The method
    signature for `detectMultiScale` takes a number of optional parameters: in the
    case of detecting a face, the default options were good enough to detect faces.
    However, eyes are a smaller feature of the face, and self-casting shadows in my
    beard or my nose and random shadows in the frame were triggering **false positives**.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By limiting the search for eyes to a minimum size of 40x40 pixels, I was able
    to discard all false positives. Go ahead and test these parameters until you reach
    a point at which your application performs as you expected it to (for example,
    you can try and specify a maximum size for the feature too, or increase the scale
    factor and number of neighbors).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here we have a further step compared to the still image example: we create
    a region of interest corresponding to the face rectangle, and within this rectangle,
    we operate "eye detection". This makes sense as you wouldn''t want to go looking
    for eyes outside a face (well, for human beings at least!).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Again, we loop through the resulting eye tuples and draw green rectangles around
    them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, we show the resulting frame in the window. All being well, if any face
    is within the field of view of the camera, you will have a blue rectangle around
    their face and a green rectangle around each eye, as shown in this screenshot:![Performing
    face detection on a video](img/image00214.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Performing face recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Detecting faces is a fantastic feature of OpenCV and one that constitutes the
    basis for a more advanced operation: face recognition. What is face recognition?
    It''s the ability of a program, given an image or a video feed, to identify a
    person. One of the ways to achieve this (and the approach adopted by OpenCV) is
    to "train" the program by feeding it a set of classified pictures (a facial database),
    and operate the recognition against those pictures.'
  prefs: []
  type: TYPE_NORMAL
- en: This is the process that OpenCV and its face recognition module follow to recognize
    faces.
  prefs: []
  type: TYPE_NORMAL
- en: Another important feature of the face recognition module is that each recognition
    has a confidence score, which allows us to set thresholds in real-life applications
    to limit the amount of false reads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start from the very beginning; to operate face recognition, we need
    faces to recognize. You can do this in two ways: supply the images yourself or
    obtain freely available face databases. There are a number of face databases on
    the Internet:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Yale** **face database (Yalefaces)**: [http://vision.ucsd.edu/content/yale-face-database](http://vision.ucsd.edu/content/yale-face-database)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The** **AT&T**: [http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html](http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The** **Extended Yale or Yale B**: [http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html](http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To operate face recognition on these samples, you would then have to run face
    recognition on an image that contains the face of one of the sampled people. That
    may be an educational process, but I found it to be not as satisfying as providing
    images of my own. In fact, I probably had the same thought that many people had:
    I wonder if I could write a program that recognizes my face with a certain degree
    of confidence.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating the data for face recognition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So let''s go ahead and write a script that will generate those images for us.
    A few images containing different expressions are all that we need, but we have
    to make sure the sample images adhere to certain criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: Images will be grayscale in the `.pgm` format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Square shape
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the same size images (I used 200 x 200; most freely available sets are smaller
    than that)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s the script itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: What is quite interesting about this exercise is that we are going to generate
    sample images building on our newfound knowledge of how to detect a face in a
    video feed. Effectively, what we are doing is detecting a face, cropping that
    region of the gray-scaled frame, resizing it to be 200x200 pixels, and saving
    it with a name in a particular folder (in my case, `jm`; you can use your initials)
    in the `.pgm` format.
  prefs: []
  type: TYPE_NORMAL
- en: I inserted a variable, `count`, because we needed progressive names for the
    images. Run the script for a few seconds, change expressions a few times, and
    check the destination folder you specified in the script. You will find a number
    of images of your face, grayed, resized, and named with the format, `<count>.pgm`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now move on to try and recognize our face in a video feed. This should
    be fun!
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing faces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'OpenCV 3 comes with three main methods for recognizing faces, based on three
    different algorithms: **Eigenfaces**, **Fisherfaces**, and **Local Binary Pattern
    Histograms** (**LBPH**). It is beyond the scope of this book to get into the nitty-gritty
    of the theoretical differences between these methods, but we can give a high-level
    overview of the concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I will refer you to the following links for a detailed description of the algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Principal** **Component Analysis (PCA)**: A very intuitive introduction by
    Jonathon Shlens is available at [http://arxiv.org/pdf/1404.1100v1.pdf](http://arxiv.org/pdf/1404.1100v1.pdf).
    This algorithm was invented in 1901 by K. Pearson, and the original paper, *On
    Lines and Planes of Closest Fit to Systems of Points in Space*, is available at
    [http://stat.smmu.edu.cn/history/pearson1901.pdf](http://stat.smmu.edu.cn/history/pearson1901.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Eigenfaces**: The paper, *Eigenfaces for Recognition*, *M. Turk and A. Pentland*,
    *1991*, is available at [http://www.cs.ucsb.edu/~mturk/Papers/jcn.pdf](http://www.cs.ucsb.edu/~mturk/Papers/jcn.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fisherfaces**: The seminal paper, *THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC
    PROBLEMS*, *R.A. Fisher*, *1936*, is available at [http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/pdf](http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local** **Binary Pattern**: The first paper describing this algorithm is
    *Performance evaluation of texture measures with classification based on Kullback
    discrimination of distributions*, *T. Ojala, M. Pietikainen, D. Harwood* and is
    available at [http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=576366&searchWithin%5B%5D=%22Authors%22%3A.QT.Ojala%2C+T..QT.&newsearch=true](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=576366&searchWithin%5B%5D=%22Authors%22%3A.QT.Ojala%2C+T..QT.&newsearch=true).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First and foremost, all methods follow a similar process; they all take a set
    of classified observations (our face database, containing numerous samples per
    individual), get "trained" on it, perform an analysis of faces detected in an
    image or video, and determine two elements: whether the subject is identified,
    and a measure of the confidence of the subject really being identified, which
    is commonly known as the confidence score.'
  prefs: []
  type: TYPE_NORMAL
- en: Eigenfaces performs a so called PCA, which—of all the mathematical concepts
    you will hear mentioned in relation to computer vision—is possibly the most descriptive.
    It basically identifies principal components of a certain set of observations
    (again, your face database), calculates the **divergence** of the current observation
    (the faces being detected in an image or frame) compared to the dataset, and it
    produces a value. The smaller the value, the smaller the difference between face
    database and detected face; hence, a value of `0` is an exact match.
  prefs: []
  type: TYPE_NORMAL
- en: Fisherfaces derives from PCA and evolves the concept, applying more complex
    logic. While computationally more intensive, it tends to yield more accurate results
    than Eigenfaces.
  prefs: []
  type: TYPE_NORMAL
- en: LBPH instead roughly (again, from a very high level) divides a detected face
    into small cells and compares each cell to the corresponding cell in the model,
    producing a histogram of matching values for each area. Because of this flexible
    approach, LBPH is the only face recognition algorithm that allows the model sample
    faces and the detected faces to be of different shape and size. I personally found
    this to be the most accurate algorithm generally speaking, but each algorithm
    has its strengths and weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the training data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have our data, we need to load these sample pictures into our face
    recognition algorithms. All face recognition algorithms take two parameters in
    their `train()` method: an array of images and an array of labels. What do these
    labels represent? They are the IDs of a certain individual/face so that when face
    recognition is performed, we not only know the person was recognized but also
    who—among the many people available in our database—the person is.'
  prefs: []
  type: TYPE_NORMAL
- en: To do that, we need to create a **comma-separated value** (**CSV**) file, which
    will contain the path to a sample picture followed by the ID of that person. In
    my case, I have 20 pictures generated with the previous script, in the subfolder,
    `jm/`, of the folder, `data/at/`, which contains all the pictures of all the individuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'My CSV file therefore looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The dots are all the missing numbers. The `jm/` instance indicates the subfolder,
    and the `0` value at the end is the ID for my face.
  prefs: []
  type: TYPE_NORMAL
- en: OK, at this stage, we have everything we need to instruct OpenCV to recognize
    our face.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data and recognizing faces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next up, we need to load these two resources (the array of images and CSV file)
    into the face recognition algorithm, so it can be trained to recognize our face.
    To do this, we build a function that reads the CSV file and—for each line of the
    file—loads the image at the corresponding path into the images array and the ID
    into the labels array.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Performing an Eigenfaces recognition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We''re ready to test the face recognition algorithm. Here''s the script to
    perform it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: There are a few lines that may look a bit mysterious, so let's analyze the script.
    First of all, there's an array of names declared; those are the actual names of
    the individual people I stored in my database of faces. It's great to identify
    a person as ID `0`, but printing `'Joe'` on top of a face that's been correctly
    detected and recognized is much more dramatic.
  prefs: []
  type: TYPE_NORMAL
- en: So whenever the script recognizes an ID, we will print the corresponding name
    in the `names` array instead of an ID.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this, we load the images as described in the previous function, create
    the face recognition model with `cv2.createEigenFaceRecognizer()`, and train it
    by passing the two arrays of images and labels (IDs). Note that the Eigenface
    recognizer takes two important parameters that you can specify: the first one
    is the number of principal components you want to keep and the second is a float
    value specifying a confidence threshold.'
  prefs: []
  type: TYPE_NORMAL
- en: Next up, we repeat a similar process to the face detection operation. This time,
    though, we extend the processing of the frames by also operating face recognition
    on any face that's been detected.
  prefs: []
  type: TYPE_NORMAL
- en: 'This happens in two steps: firstly, we resize the detected face to the expected
    size (in my case, samples were 200x200 pixels), and then we call the `predict()`
    function on the resized region.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a bit of a simplified process, and it serves the purpose of enabling
    you to have a basic application running and understand the process of face recognition
    in OpenCV 3\. In reality, you will apply a few more optimizations, such as correctly
    aligning and rotating detected faces, so the accuracy of the recognition is maximized.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we obtain the results of the recognition and, just for effect, we draw
    it in the frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Performing an Eigenfaces recognition](img/image00215.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Performing face recognition with Fisherfaces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'What about Fisherfaces? The process doesn''t change much; we simply need to
    instantiate a different algorithm. So, the declaration of our model variable would
    look like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Fisherface takes the same two arguments as Eigenfaces: the Fisherfaces to keep
    and the confidence threshold. Faces with confidence above this threshold will
    be discarded.'
  prefs: []
  type: TYPE_NORMAL
- en: Performing face recognition with LBPH
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, let''s take a quick look at the LBPH algorithm. Again, the process
    is very similar. However, the parameters taken by the algorithm factory are a
    bit more complex as they indicate in order: `radius`, `neighbors`, `grid_x`, `grid_y`,
    and the confidence threshold. If you don''t specify these values, they will automatically
    be set to 1, 8, 8, 8, and 123.0\. The model declaration will look like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that with LBPH, you won't need to resize images, as the division in grids
    allows comparing patterns identified in each cell.
  prefs: []
  type: TYPE_NORMAL
- en: Discarding results with confidence score
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `predict()` method returns a two-element array: the first element is the
    label of the recognized individual and the second is the confidence score. All
    algorithms come with the option of setting a confidence score threshold, which
    measures the distance of the recognized face from the original model, therefore
    a score of 0 signifies an exact match.'
  prefs: []
  type: TYPE_NORMAL
- en: There may be cases in which you would rather retain all recognitions, and then
    apply further processing, so you can come up with your own algorithms to estimate
    the confidence score of a recognition; for example, if you are trying to identify
    people in a video, you may want to analyze the confidence score in subsequent
    frames to establish whether the recognition was successful or not. In this case,
    you can inspect the confidence score obtained by the algorithm and draw your own
    conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The confidence score value is completely different in Eigenfaces/Fisherfaces
    and LBPH. Eigenfaces and Fisherfaces will produce values (roughly) in the range
    0 to 20,000, with any score below 4-5,000 being quite a confident recognition.
  prefs: []
  type: TYPE_NORMAL
- en: LBPH works similarly; however, the reference value for a good recognition is
    below 50, and any value above 80 is considered as a low confidence score.
  prefs: []
  type: TYPE_NORMAL
- en: A normal custom approach would be to hold-off drawing a rectangle around a recognized
    face until we have a number of frames with a satisfying arbitrary confidence score,
    but you have total freedom to use OpenCV's face recognition module to tailor your
    application to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, you should have a good understanding of how face detection and face
    recognition work, and how to implement them in Python and OpenCV 3.
  prefs: []
  type: TYPE_NORMAL
- en: Face detection and face recognition are constantly evolving branches of computer
    vision, with algorithms being developed continuously, and they will evolve even
    faster in the near future with the emphasis posed on robotics and the Internet
    of things.
  prefs: []
  type: TYPE_NORMAL
- en: For now, the accuracy of detection and recognition heavily depends on the quality
    of the training data, so make sure you provide your applications with high-quality
    face databases and you will be satisfied with the results.
  prefs: []
  type: TYPE_NORMAL
