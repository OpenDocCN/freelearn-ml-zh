["```py\nset.seed(1234)\nLogisticRegression=glm(train$Default~.,data=train[,2:ncol(train)],family=binomial())\n ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```", "```py\nsummary(LogisticRegression)\n ## \n ## Call:\n ## glm(formula = train$Default ~ ., family = binomial(), data =         train[, \n ##     2:ncol(train)])\n ## \n ## Deviance Residuals: \n ##     Min       1Q   Median       3Q      Max  \n ## -3.9330  -0.0210  -0.0066  -0.0013   4.8724  \n ## \n ## Coefficients:\n ##                   Estimate     Std. Error z value Pr(>|z|)  \n ## (Intercept) -11.7599825009   6.9560247460  -1.691   0.0909 .\n ## UBPRE395     -0.0575725641   0.0561441397  -1.025   0.3052  \n ## UBPRE543      0.0014008963   0.0294470630   0.048   0.9621  \n ##         ....                             .....                           ....                            ....             ....\n ## UBPRE021     -0.0114148389   0.0057016025  -2.002   0.0453 *\n ## UBPRE023      0.4950212919   0.2459506994   2.013   0.0441 *\n ## UBPRK447     -0.0210028916   0.0192296299  -1.092   0.2747  \n ## ---\n ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n ## \n ## (Dispersion parameter for binomial family taken to be 1)\n ## \n ##     Null deviance: 2687.03  on 7090  degrees of freedom\n ## Residual deviance:  284.23  on 6982  degrees of freedom\n ## AIC: 502.23\n ## \n ## Number of Fisher Scoring iterations: 13\n```", "```py\nlibrary(h2o)\n```", "```py\nh2o.init()\n```", "```py\ntrain$Default<-as.factor(train$Default)\n\ntest$Default<-as.factor(test$Default)\n```", "```py\nas.h2o(train[,2:ncol(train)],destination_frame=\"train\")\n\nas.h2o(test[,2:ncol(test)],destination_frame=\"test\")\n```", "```py\nh2o.ls()\n\n ##     key\n ## 1  test\n ## 2 train\n```", "```py\nh2o.removeAll()\n ## [1] 0\n```", "```py\nas.h2o(train[,2:ncol(train)],destination_frame=\"train\")\nas.h2o(test[,2:ncol(test)],destination_frame=\"test\")\n```", "```py\ngrid_id <- 'glm_grid'\n```", "```py\nhyper_parameters <- list( alpha = c(0, .5, 1) )\nstopping_metric <- 'auc'\nglm_grid <- h2o.grid(\n     algorithm = \"glm\",\n     grid_id = grid_id,\n     hyper_params = hyper_parameters,\n     training_frame = training,\n     nfolds=5,\n     x=2:110,\n     y=1,\n     lambda_search = TRUE,\n     family = \"binomial\", seed=1234)\n```", "```py\nresults_glm <- h2o.getGrid(\n     grid_id = grid_id,\n     sort_by = stopping_metric,\n     decreasing = TRUE)\n```", "```py\nbest_GLM <- h2o.getModel(results_glm@model_ids[[1]])\n```", "```py\nbest_GLM@model$model_summary$regularization\n ## [1] \"Ridge ( lambda = 0.006918 )\"\n```", "```py\nperf_train<-h2o.performance(model = best_GLM,newdata = training)\nperf_train\n ## H2OBinomialMetrics: glm\n ##\n ## MSE:  0.006359316\n ## RMSE:  0.07974532\n ## LogLoss:  0.02561085\n ## Mean Per-Class Error:  0.06116986\n ## AUC:  0.9953735\n ## Gini:  0.990747\n ## R^2:  0.8579102\n ## Residual Deviance:  363.213\n ## AIC:  581.213\n ##\n ## Confusion Matrix (vertical: actual; across: predicted) for F1-              optimal threshold:\n ##           0   1    Error      Rate\n ## 0      6743  15 0.002220  =15/6758\n ## 1        40 293 0.120120   =40/333\n ## Totals 6783 308 0.007756  =55/7091\n ##\n ## Maximum Metrics: Maximum metrics at their respective thresholds\n ##                         metric threshold    value idx\n ## 1                       max f1  0.540987 0.914197 144\n ## 2                       max f2  0.157131 0.931659 206\n ## 3                 max f0point5  0.617239 0.941021 132\n ## 4                 max accuracy  0.547359 0.992244 143\n ## 5                max precision  0.999897 1.000000   0\n ## 6                   max recall  0.001351 1.000000 383\n ## 7              max specificity  0.999897 1.000000   0\n ## 8             max absolute_mcc  0.540987 0.910901 144\n ## 9   max min_per_class_accuracy  0.056411 0.972973 265\n ## 10 max mean_per_class_accuracy  0.087402 0.977216 239\n ##\n\n```", "```py\nperf_test<-h2o.performance(model = best_GLM,newdata = as.h2o(test))\nperf_test\n ## H2OBinomialMetrics: glm\n ##\n ## MSE:  0.01070733\n ## RMSE:  0.1034762\n ## LogLoss:  0.04052454\n ## Mean Per-Class Error:  0.0467923\n ## AUC:  0.9875425\n ## Gini:  0.975085\n ## R^2:  0.7612146\n ## Residual Deviance:  246.3081\n ## AIC:  464.3081\n ##\n ## Confusion Matrix (vertical: actual; across: predicted) for F1-            optimal threshold:\n ##           0   1    Error      Rate\n ## 0      2868  28 0.009669  =28/2896\n ## 1        12 131 0.083916   =12/143\n ## Totals 2880 159 0.013162  =40/3039\n ##\n ## Maximum Metrics: Maximum metrics at their respective thresholds\n ##                         metric threshold    value idx\n ## 1                       max f1  0.174545 0.867550 125\n ## 2                       max f2  0.102341 0.904826 138\n ## 3                 max f0point5  0.586261 0.885167  89\n ## 4                 max accuracy  0.309187 0.987167 107\n ## 5                max precision  0.999961 1.000000   0\n ## 6                   max recall  0.000386 1.000000 388\n ## 7              max specificity  0.999961 1.000000   0\n ## 8             max absolute_mcc  0.174545 0.861985 125\n ## 9   max min_per_class_accuracy  0.027830 0.955456 210\n ## 10 max mean_per_class_accuracy  0.102341 0.965295 138\n\n```", "```py\nhead(best_GLM@model$coefficients)\n ##    Intercept     UBPRE395     UBPRE543     UBPRE586     UBPRFB60\n ## -8.448270911 -0.004167366 -0.003376142 -0.001531582  0.027969152\n ##     UBPRE389\n ## -0.004031844\n```", "```py\nsummary_models_train<-train[,c(\"ID_RSSD\",\"Default\")]\nsummary_models_test<-test[,c(\"ID_RSSD\",\"Default\")]\n```", "```py\nsummary_models_train$GLM<-as.vector(h2o.predict(best_GLM,training)[3])\nsummary_models_test$GLM<-as.vector(h2o.predict(best_GLM,validation)[3])\n```", "```py\nperf_test@metrics$cm$table\n ## Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n ##           0   1  Error         Rate\n ## 0      2868  28 0.0097 = 28 / 2,896\n ## 1        12 131 0.0839 =   12 / 143\n ## Totals 2880 159 0.0132 = 40 / 3,039\n```", "```py\nmean(as.numeric(as.character(train$Default)))\n ## [1] 0.04696094\n```", "```py\naux<-summary_models_test\naux$pred<-ifelse(summary_models_test$GLM>0.04696094,1,0)\n```", "```py\ntable(aux$Default,aux$pred)\n ##   \n ##        0    1\n ##   0 2818   78\n ##   1    8  135\n```", "```py\nh2o.saveModel(object= best_GLM, path=getwd(), force=TRUE)\n```", "```py\nrm(list=setdiff(ls(), c(\"Model_database\",\"train\",\"test\",\"summary_models_train\",\"summary_models_test\",\"training\",\"validation\")))\n\nsave.image(\"Data13.RData\")\n```", "```py\ntraining<-as.h2o(train[,2:ncol(train)],destination_frame=“train”)\nvalidation<-as.h2o(test[,2:ncol(test)],destination_frame=“test”)\n```", "```py\ngrid_space <- list()\n grid_space$ntrees <- c(25, 50, 75)\n grid_space$max_depth <- c(4, 10, 20)\n grid_space$mtries <- c(10, 14, 20)\n grid_space$seed <- c(1234)\n\n grid <- h2o.grid(\"randomForest\", grid_id=\"RF_grid\", x=2:110,y=1,training_frame=training, nfolds=5, hyper_params=grid_space)\n\nresults_grid <- h2o.getGrid(grid_id = \"RF_grid\",\n                              sort_by = \"auc\",\n                              decreasing = TRUE)\n\nprint(results_grid)\n\n ## H2O Grid Details\n ## ================\n ## \n ## Grid ID: RF_grid \n ## Used hyper parameters: \n ##   -  max_depth \n ##   -  mtries \n ##   -  ntrees \n ##   -  seed \n ## Number of models: 27 \n ## Number of failed models: 0 \n ## \n ## Hyper-Parameter Search Summary: ordered by decreasing auc\n ##   max_depth mtries ntrees seed        model_ids                auc\n ## 1        20     20     75 1234 RF_grid_model_26 0.9928546480780869\n ## 2        10     10     75 1234 RF_grid_model_19 0.9922021014799943\n ## 3        10     10     50 1234 RF_grid_model_10 0.9921534437663471\n ## 4        10     20     75 1234 RF_grid_model_25 0.9920343545676484\n ## 5        10     20     50 1234 RF_grid_model_16 0.9919039341205663\n ## \n ## ---\n ##    max_depth mtries ntrees seed       model_ids                auc\n ## 22        20     20     25 1234 RF_grid_model_8 0.9879017816277361\n ## 23        20     10     25 1234 RF_grid_model_2 0.9876307203918924\n ## 24        10     20     25 1234 RF_grid_model_7 0.9873765449379537\n ## 25        10     14     25 1234 RF_grid_model_4  0.986949956763511\n ## 26         4     10     25 1234 RF_grid_model_0  0.984477522802471\n ## 27        20     14     25 1234 RF_grid_model_5  0.980687331308817\n```", "```py\nbest_RF <- h2o.getModel(results_grid@model_ids[[1]])\n```", "```py\nh2o.performance(model = best_RF,newdata = training)\n ## H2OBinomialMetrics: drf\n ## \n ## MSE:  0.001317125\n ## RMSE:  0.03629222\n ## LogLoss:  0.009026859\n ## Mean Per-Class Error:  0\n ## AUC:  1\n ## Gini:  1\n ## \n ## Confusion Matrix (vertical: actual; across: predicted) for F1-            optimal          threshold:\n ##           0   1    Error     Rate\n ## 0      6758   0 0.000000  =0/6758\n ## 1         0 333 0.000000   =0/333\n ## Totals 6758 333 0.000000  =0/7091\n ## \n ## Maximum Metrics: Maximum metrics at their respective thresholds\n ##                         metric threshold    value idx\n ## 1                       max f1  0.586667 1.000000  29\n ## 2                       max f2  0.586667 1.000000  29\n ## 3                 max f0point5  0.586667 1.000000  29\n ## 4                 max accuracy  0.586667 1.000000  29\n ## 5                max precision  1.000000 1.000000   0\n ## 6                   max recall  0.586667 1.000000  29\n ## 7              max specificity  1.000000 1.000000   0\n ## 8             max absolute_mcc  0.586667 1.000000  29\n ## 9   max min_per_class_accuracy  0.586667 1.000000  29\n ## 10 max mean_per_class_accuracy  0.586667 1.000000  29\n\n```", "```py\nh2o.performance(model = best_RF,newdata = validation)\n ## H2OBinomialMetrics: drf\n ## \n ## MSE:  0.00940672\n ## RMSE:  0.09698825\n ## LogLoss:  0.05488315\n ## Mean Per-Class Error:  0.06220299\n ## AUC:  0.9882138\n ## Gini:  0.9764276\n ## \n ## Confusion Matrix (vertical: actual; across: predicted) for F1-            optimal              threshold:\n ##           0   1    Error      Rate\n ## 0      2880  16 0.005525  =16/2896\n ## 1        17 126 0.118881   =17/143\n ## Totals 2897 142 0.010859  =33/3039\n ## \n ## Maximum Metrics: Maximum metrics at their respective thresholds\n ##                         metric threshold    value idx\n ## 1                       max f1  0.346667 0.884211  44\n ## 2                       max f2  0.280000 0.897790  49\n ## 3                 max f0point5  0.760000 0.897196  18\n ## 4                 max accuracy  0.346667 0.989141  44\n ## 5                max precision  1.000000 1.000000   0\n ## 6                   max recall  0.000000 1.000000  70\n ## 7              max specificity  1.000000 1.000000   0\n ## 8             max absolute_mcc  0.346667 0.878520  44\n ## 9   max min_per_class_accuracy  0.106667 0.965035  62\n ## 10 max mean_per_class_accuracy  0.106667 0.968878  62\n\n```", "```py\nvar_importance<-data.frame(best_RF@model$variable_importances)\n h2o.varimp_plot(best_RF,20)\n```", "```py\nsummary_models_train$RF<-as.vector(h2o.predict(best_RF,training)[3])\nsummary_models_test$RF<-as.vector(h2o.predict(best_RF,validation)[3])\n```", "```py\naux<-summary_models_test\n aux$pred<-ifelse(summary_models_test$RF>0.04696094,1,0)\n table(aux$Default,aux$pred)\n ##        0    1\n ##   0 2753  143\n ##   1    5  138\n```", "```py\nrm(list=setdiff(ls(), c(\"Model_database\",\"train\",\"test\",\"summary_models_train\",\"summary_models_test\",\"training\",\"validation\")))\nsave.image(\"Data14.RData\")\n```", "```py\ngrid_space <- list()\ngrid_space$ntrees <- c(25,75,100)\ngrid_space$max_depth = c(4,6,8,12,16,20)\n```", "```py\ngbm_grid <- h2o.grid(hyper_params = grid_space,\n   algorithm = \"gbm\",\n   grid_id =\"Grid1\", \n   x=2:110,\n   y=1,\n   training_frame = training,seed=1234)\n```", "```py\nresults_gbm <- h2o.getGrid(\"Grid1\", sort_by = \"AUC\", decreasing = TRUE)    \nresults_gbm\n ## H2O Grid Details\n ## ================\n ## \n ## Grid ID: Grid1 \n ## Used hyper parameters: \n ##   -  max_depth \n ##   -  ntrees \n ## Number of models: 18 \n ## Number of failed models: 0 \n ## \n ## Hyper-Parameter Search Summary: ordered by decreasing AUC\n ##    max_depth ntrees      model_ids                auc\n ## 1         16    100 Grid1_model_16                1.0\n ## 2          4    100 Grid1_model_12                1.0\n ## 3         16     25  Grid1_model_4                1.0\n ## 4         20     75 Grid1_model_11                1.0\n ## 5          6     75  Grid1_model_7                1.0\n ## 6         20    100 Grid1_model_17                1.0\n ## 7          8     75  Grid1_model_8                1.0\n ## 8         20     25  Grid1_model_5                1.0\n ## 9         12     75  Grid1_model_9                1.0\n ## 10        16     75 Grid1_model_10                1.0\n ## 11         6    100 Grid1_model_13                1.0\n ## 12        12    100 Grid1_model_15                1.0\n ## 13         8    100 Grid1_model_14                1.0\n ## 14         4     75  Grid1_model_6 0.9999986669119549\n ## 15        12     25  Grid1_model_3 0.9999986669119549\n ## 16         8     25  Grid1_model_2 0.9999922236530701\n ## 17         6     25  Grid1_model_1 0.9998680242835318\n ## 18         4     25  Grid1_model_0 0.9977795196794901\n```", "```py\nbest_GBM <- h2o.getModel(results_gbm@model_ids[[1]])\nh2o.performance(model = best_GBM,newdata = as.h2o(test))\n ## H2OBinomialMetrics: gbm\n ## \n ## MSE:  0.01053012\n ## RMSE:  0.1026164\n ## LogLoss:  0.06001792\n ## Mean Per-Class Error:  0.05905179\n ## AUC:  0.9876222\n ## Gini:  0.9752444\n ## \n ## Confusion Matrix (vertical: actual; across: predicted) for F1-            optimal          threshold:\n ##           0   1    Error      Rate\n ## 0      2878  18 0.006215  =18/2896\n ## 1        16 127 0.111888   =16/143\n ## Totals 2894 145 0.011188  =34/3039\n ## \n ## Maximum Metrics: Maximum metrics at their respective thresholds\n ##                         metric threshold    value idx\n ## 1                       max f1  0.076792 0.881944 143\n ## 2                       max f2  0.010250 0.892857 154\n ## 3                 max f0point5  0.852630 0.906902 118\n ## 4                 max accuracy  0.076792 0.988812 143\n ## 5                max precision  0.999962 1.000000   0\n ## 6                   max recall  0.000006 1.000000 392\n ## 7              max specificity  0.999962 1.000000   0\n ## 8             max absolute_mcc  0.076792 0.876096 143\n ## 9   max min_per_class_accuracy  0.000181 0.958042 246\n ## 10 max mean_per_class_accuracy  0.000816 0.963611 203\n\n```", "```py\nsummary_models_train$GBM<-as.vector(h2o.predict(best_GBM,training)[3])\nsummary_models_test$GBM<-as.vector(h2o.predict(best_GBM,validation)[3])\n```", "```py\naux<-summary_models_test\naux$pred<-ifelse(summary_models_test$GBM>0.04696094,1,0)\ntable(aux$Default,aux$pred)\n ##    \n ##        0    1\n ##   0 2876   20\n ##   1   15  128\n```", "```py\nrm(list=setdiff(ls(), c(\"Model_database\",\"train\",\"test\",\"summary_models_train\",\"summary_models_test\",\"training\",\"validation\")))\nsave.image(\"Data15.RData\")\n```", "```py\nhyper_params <- list(\n   hidden=list(c(5),c(80,80,80),c(75,75)),\n   input_dropout_ratio=c(0.05,0.1,0.15,0.2,0.25),\n   rate=c(0.01,0.02,0.10))\n```", "```py\ndeep_grid <- h2o.grid(\n   algorithm=\"deeplearning\",\n   grid_id=\"dl_grid\", \n   training_frame=training,\n   validation_frame=as.h2o(test),\n   x=2:110,\n   y=1,\n   epochs=2,\n   stopping_metric=\"AUC\",\n   stopping_tolerance=1e-2,\n   stopping_rounds=2,\n   score_duty_cycle=0.01,  \n   l1=1e-5,\n   l2=1e-5,\n   activation=c(\"Rectifier\"),\n   nfolds=5,\n   hyper_params=hyper_params,standardize=TRUE,seed=1234)\n```", "```py\nresults_deep <- h2o.getGrid(\"dl_grid\",sort_by=\"auc\",decreasing=TRUE)\nresults_deep\n ## H2O Grid Details\n ## ================\n ## \n ## Grid ID: dl_grid \n ## Used hyper parameters: \n ##   -  hidden \n ##   -  input_dropout_ratio \n ##   -  rate \n ## Number of models: 45 \n ## Number of failed models: 0 \n ## \n ## Hyper-Parameter Search Summary: ordered by decreasing auc\n ##         hidden input_dropout_ratio rate        model_ids\n ## 1     [75, 75]                0.25 0.01 dl_grid_model_14\n ## 2     [75, 75]                0.25  0.1 dl_grid_model_44\n ## 3     [75, 75]                 0.2 0.01 dl_grid_model_11\n ## 4 [80, 80, 80]                0.25 0.02 dl_grid_model_28\n ## 5     [75, 75]                 0.1 0.01  dl_grid_model_5\n ##                  auc\n ## 1 0.9844357527103902\n ## 2 0.9841366966255987\n ## 3 0.9831344365969994\n ## 4 0.9830902225101693\n ## 5 0.9830724480029008\n ## \n ## ---\n ##    hidden input_dropout_ratio rate        model_ids                auc\n ## 40    [5]                 0.1  0.1 dl_grid_model_33 0.9603608491593103\n ## 41    [5]                 0.1 0.01  dl_grid_model_3 0.9599749201702442\n ## 42    [5]                 0.2 0.01  dl_grid_model_9 0.9599749201702442\n ## 43    [5]                 0.2 0.02 dl_grid_model_24 0.9591890647676383\n ## 44    [5]                0.05 0.02 dl_grid_model_15 0.9587149297862527\n ## 45    [5]                0.15  0.1 dl_grid_model_36 0.9575646969846437\n```", "```py\nbest_deep <- h2o.getModel(results_deep@model_ids[[1]])\n```", "```py\nh2o.performance(model = best_deep,newdata = validation)\n ## H2OBinomialMetrics: deeplearning\n ## \n ## MSE:  0.02464987\n ## RMSE:  0.1570028\n ## LogLoss:  0.1674725\n ## Mean Per-Class Error:  0.1162044\n ## AUC:  0.9794568\n ## Gini:  0.9589137\n ## \n ## Confusion Matrix (vertical: actual; across: predicted) for F1-         optimal threshold:\n ##           0   1    Error      Rate\n ## 0      2871  25 0.008633  =25/2896\n ## 1        32 111 0.223776   =32/143\n ## Totals 2903 136 0.018756  =57/3039\n ## \n ## Maximum Metrics: Maximum metrics at their respective thresholds\n ##                         metric threshold    value idx\n ## 1                       max f1  0.001538 0.795699 135\n ## 2                       max f2  0.000682 0.812672 153\n ## 3                 max f0point5  0.011028 0.831904 109\n ## 4                 max accuracy  0.001538 0.981244 135\n ## 5                max precision  0.999998 1.000000   0\n ## 6                   max recall  0.000000 1.000000 398\n ## 7              max specificity  0.999998 1.000000   0\n ## 8             max absolute_mcc  0.001538 0.786148 135\n ## 9   max min_per_class_accuracy  0.000017 0.937063 285\n ## 10 max mean_per_class_accuracy  0.000009 0.943153 314\n\n```", "```py\nsummary_models_train$deep<-as.vector(h2o.predict(best_deep,training)[3])\nsummary_models_test$deep<- as.vector(h2o.predict(best_deep,validation)[3])\n```", "```py\naux<-summary_models_test\n aux$pred<-ifelse(summary_models_test$deep>0.04696094,1,0)\n table(aux$Default,aux$pred)\n ##    \n ##        0    1\n ##   0 2886   10\n ##   1   61   82\n\nrm(list=setdiff(ls(), c(\"Model_database\",\"train\",\"test\",\"summary_models_train\",\"summary_models_test\",\"training\",\"validation\")))\nsave.image(\"Data16.RData\")\n```", "```py\nlevels(train$Default)\n ## [1] \"0\" \"1\"\n```", "```py\nlevels(train$Default) <- make.names(levels(factor(train$Default)))\nlevels(train$Default)\n ## [1] \"X0\" \"X1\"\n```", "```py\ntest$Default<-as.factor(test$Default)\nlevels(test$Default) <- make.names(levels(factor(test$Default)))\n levels(test$Default)\n ## [1] \"X0\" \"X1\"\n```", "```py\nsvmGrid <- expand.grid(sigma= 2^c(-20, -15,-10, -5, 0), C= 2^c(2:5))\nprint(svmGrid)\n ##              sigma  C\n ## 1  0.0000009536743  4\n ## 2  0.0000305175781  4\n ## 3  0.0009765625000  4\n ## 4  0.0312500000000  4\n ## 5  1.0000000000000  4\n ## 6  0.0000009536743  8\n ## 7  0.0000305175781  8\n ## 8  0.0009765625000  8\n ## 9  0.0312500000000  8\n ## 10 1.0000000000000  8\n ## 11 0.0000009536743 16\n ## 12 0.0000305175781 16\n ## 13 0.0009765625000 16\n ## 14 0.0312500000000 16\n ## 15 1.0000000000000 16\n ## 16 0.0000009536743 32\n ## 17 0.0000305175781 32\n ## 18 0.0009765625000 32\n ## 19 0.0312500000000 32\n ## 20 1.0000000000000 32\n```", "```py\nlibrary(caret)\nset.seed(1234)\n\nSVM <- train(Default ~ ., data = train[,2:ncol(train)], \n method = \"svmRadial\",\n standardize=TRUE,\n tuneGrid = svmGrid,\n metric = \"ROC\",\n allowParallel=TRUE,\n trControl = trainControl(method = \"cv\", 5, classProbs = TRUE, \n summaryFunction=twoClassSummary))\n```", "```py\nprint(SVM)\n ## Support Vector Machines with Radial Basis Function Kernel \n ## \n ## 7091 samples\n ##  108 predictor\n ##    2 classes: 'X0', 'X1' \n ## \n ## No pre-processing\n ## Resampling: Cross-Validated (5 fold) \n ## Summary of sample sizes: 5674, 5673, 5672, 5672, 5673 \n ## Resampling results across tuning parameters:\n ## \n ##   sigma            C   ROC        Sens       Spec     \n ##   0.0000009536743   4  0.9879069  0.9899383  0.8710086\n ##   0.0000009536743   8  0.9879135  0.9903822  0.8710086\n ##   0.0000009536743  16  0.9879092  0.9900863  0.8710086\n ##   0.0000009536743  32  0.9880736  0.9909741  0.8679783\n ##   0.0000305175781   4  0.9894669  0.9943777  0.8380371\n ##   0.0000305175781   8  0.9903574  0.9957094  0.8439168\n ##   0.0000305175781  16  0.9903018  0.9958573  0.8499774\n ##   0.0000305175781  32  0.9903865  0.9958572  0.8619629\n ##   0.0009765625000   4  0.9917597  0.9960052  0.8739937\n ##   0.0009765625000   8  0.9913792  0.9963011  0.8590231\n ##   0.0009765625000  16  0.9900214  0.9960050  0.8379919\n ##   0.0009765625000  32  0.9883768  0.9961529  0.8410222\n ##   0.0312500000000   4  0.9824358  0.9789899  0.9159656\n ##   0.0312500000000   8  0.9824358  0.9767682  0.8735414\n ##   0.0312500000000  16  0.9824358  0.9783977  0.8622343\n ##   0.0312500000000  32  0.9824358  0.9755850  0.9189959\n ##   1.0000000000000   4  0.4348777  1.0000000  0.0000000\n ##   1.0000000000000   8  0.4336278  1.0000000  0.0000000\n ##   1.0000000000000  16  0.4273365  1.0000000  0.0000000\n ##   1.0000000000000  32  0.4325194  1.0000000  0.0000000\n ## \n ## ROC was used to select the optimal model using the largest value.\n ## The final values used for the model were sigma = 0.0009765625 and C     = 4.\n```", "```py\nSVM$bestTune\n ##          sigma C\n ## 9 0.0009765625 4\n```", "```py\nSVM$finalModel\n ## Support Vector Machine object of class \"ksvm\" \n ## \n ## SV type: C-svc  (classification) \n ##  parameter : cost C = 4 \n ## \n ## Gaussian Radial Basis kernel function. \n ##  Hyperparameter : sigma =  0.0009765625 \n ## \n ## Number of Support Vectors : 252 \n ## \n ## Objective Function Value : -619.9088 \n ## Training error : 0.007333 \n ## Probability model included.\n```", "```py\nlibrary(ROCR)\nSVM_pred<-as.numeric(unlist(predict(SVM, newdata =test, type = \"prob\")[2]))\npred2 <- prediction(SVM_pred,test$Default)\npred3 <- performance(pred2,\"tpr\",\"fpr\")\nplot(pred3, lwd=1, colorize=FALSE)\nlines(x=c(0, 1), y=c(0, 1), col=\"red\", lwd=1, lty=3);  \n```", "```py\nlibrary(Hmisc)\nprint(\"Gini indicator of SVM in the test sample is:\")\n ## [1] \"Gini indicator of SVM in the test sample is:\"\n\nprint(abs(as.numeric(2*rcorr.cens(SVM_pred,test[,'Default'])[1]-1)))\n ## [1] 0.9766884\n```", "```py\nsummary_models_train$SVM<-as.numeric(unlist(predict(SVM, newdata =train, type = \"prob\")[2]))\nsummary_models_test$SVM<- as.numeric(unlist(predict(SVM, newdata =test, type = \"prob\")[2]))\n```", "```py\naux<-summary_models_test\naux$pred<-ifelse(summary_models_test$SVM>0.04696094,1,0)\ntable(aux$Default,aux$pred)\n ##    \n ##        0    1\n ##   0 2828   68\n ##   1    8  135\n```", "```py\nrm(list=setdiff(ls(), c(\"Model_database\",\"train\",\"test\",\"summary_models_train\",\"summary_models_test\",\"train_woe\",\"test_woe\")))\nsave.image(\"~/Data17.RData\")\n```", "```py\nhead(summary_models_train)\n ##    ID_RSSD Default          GLM RF            GBM              deep\n ## 4       37       0 0.0013554364  0 0.000005755001 0.000000018217172\n ## 21     242       0 0.0006967876  0 0.000005755001 0.000000002088871\n ## 38     279       0 0.0028306028  0 0.000005240935 0.000003555978680\n ## 52     354       0 0.0013898732  0 0.000005707480 0.000000782777042\n ## 78     457       0 0.0021731695  0 0.000005755001 0.000000012535539\n ## 81     505       0 0.0011344433  0 0.000005461855 0.000000012267744\n ##             SVM\n ## 4  0.0006227083\n ## 21 0.0002813123\n ## 38 0.0010763298\n ## 52 0.0009740568\n ## 78 0.0021555739\n ## 81 0.0005557417\n```", "```py\ngini_models<-as.data.frame(names(summary_models_train[,3:ncol(summary_models_train)]))\ncolnames(gini_models)<-\"Char\"\n\nfor (i in 3:ncol(summary_models_train))\n{\n\n   gini_models$Gini_train[i-2]<-(abs(as.numeric(2*rcorr.cens(summary_models_train[,i],summary_models_train$Default)[1]-1)))\n\n   gini_models$Gini_test[i-2]<-(abs(as.numeric(2*rcorr.cens(summary_models_test[,i],summary_models_test$Default)[1]-1)))\n\n}\n```", "```py\ngini_models$var_train_test<-(gini_models$Gini_train-gini_models$Gini_test)/gini_models$Gini_train\nprint(gini_models)\n\n ##   Char Gini_train Gini_test var_train_test\n ## 1  GLM  0.9906977 0.9748967     0.01594943\n ## 2   RF  1.0000000 0.9764276     0.02357242\n ## 3  GBM  1.0000000 0.9754665     0.02453348\n ## 4 deep  0.9855324 0.9589837     0.02693848\n ## 5  SVM  0.9920815 0.9766884     0.01551595\n```", "```py\ndecisions_train <- summary_models_train\n\ndecisions_test <- summary_models_test\n```", "```py\nfor (m in 3:ncol(decisions_train))\n{\n\n   decisions_train[,m]<-ifelse(decisions_train[,m]>0.04696094,1,0)\n\n   decisions_test[,m]<-ifelse(decisions_test[,m]>0.04696094,1,0)\n\n }\n```", "```py\naccuracy_function <- function(dataframe, observed, predicted)\n{\n bads<-sum(as.numeric(as.character(dataframe[,observed])))\n  goods<-nrow(dataframe)-bads\n   y <- as.vector(table(dataframe[,predicted], dataframe[,observed]))\n   names(y) <- c(\"TN\", \"FP\", \"FN\", \"TP\")\n  return(y)\n }\n```", "```py\nprint(\"Accuracy GLM model:\")\n ## [1] \"Accuracy GLM model:\"\naccuracy_function(decisions_train,\"Default\",\"GLM\")\n ##   TN   FP   FN   TP \n ## 6584  174    9  324\n\nprint(\"Accuracy RF model:\")\n ## [1] \"Accuracy RF model:\"\naccuracy_function(decisions_train,\"Default\",\"RF\")\n ##   TN   FP   FN   TP \n ## 6608  150    0  333\n\nprint(\"Accuracy GBM model:\")\n ## [1] \"Accuracy GBM model:\"\naccuracy_function(decisions_train,\"Default\",\"GBM\")\n ##   TN   FP   FN   TP \n ## 6758    0    0  333\n\nprint(\"Accuracy deep model:\")\n ## [1] \"Accuracy deep model:\"\naccuracy_function(decisions_train,\"Default\",\"deep\")\n ##   TN   FP   FN   TP \n ## 6747   11  104  229\n\nprint(\"Accuracy SVM model:\")\n ## [1] \"Accuracy SVM model:\"\naccuracy_function(decisions_train,\"Default\",\"SVM\")\n ##   TN   FP   FN   TP \n ## 6614  144    7  326\n```", "```py\nprint(\"Accuracy GLM model:\")\n ## [1] \"Accuracy GLM model:\"\naccuracy_function(decisions_test,\"Default\",\"GLM\")\n ##   TN   FP   FN   TP\n ## 2818   78    8  135\n\nprint(\"Accuracy RF model:\")\n ## [1] \"Accuracy RF model:\"\naccuracy_function(decisions_test,\"Default\",\"RF\")\n ##   TN   FP   FN   TP\n ## 2753  143    5  138\n\nprint(\"Accuracy GBM model:\")\n ## [1] \"Accuracy GBM model:\"\naccuracy_function(decisions_test,\"Default\",\"GBM\")\n ##   TN   FP   FN   TP\n ## 2876   20   15  128\n\nprint(\"Accuracy deep model:\")\n ## [1] \"Accuracy deep model:\"\naccuracy_function(decisions_test,\"Default\",\"deep\")\n ##   TN   FP   FN   TP\n ## 2886   10   61   82\n\nprint(\"Accuracy SVM model:\")\n ## [1] \"Accuracy SVM model:\"\naccuracy_function(decisions_test,\"Default\",\"SVM\")\n ##   TN   FP   FN   TP\n ## 2828   68    8  135\n```", "```py\ncorrelations<-cor(summary_models_train[,3:ncol(summary_models_train)], use=\"pairwise\", method=\"pearson\")\n\nprint(correlations)\n ##            GLM        RF       GBM      deep       SVM\n ## GLM  1.0000000 0.9616688 0.9270350 0.8010252 0.9910695\n ## RF   0.9616688 1.0000000 0.9876728 0.7603979 0.9719735\n ## GBM  0.9270350 0.9876728 1.0000000 0.7283464 0.9457436\n ## deep 0.8010252 0.7603979 0.7283464 1.0000000 0.7879191\n ## SVM  0.9910695 0.9719735 0.9457436 0.7879191 1.0000000\n```", "```py\nsummary_models_test$avg<-(summary_models_test$GLM + summary_models_test$RF + summary_models_test$GBM + summary_models_test$deep + summary_models_test$SVM)/5\n```", "```py\nabs(as.numeric(2*rcorr.cens(summary_models_test[,\"avg\"],summary_models_test$Default)[1]-1))\n ## [1] 0.9771665\n```", "```py\naux<-summary_models_test\naux$pred<-ifelse(summary_models_test$avg>0.04696094,1,0)\ntable(aux$Default,aux$pred) \n ##        0    1\n ##   0 2834   62\n ##   1    7  136\n```", "```py\ndecisions_test$votes<-rowSums(decisions_test[,3:7])\ndecisions_test$majority_vote<-ifelse(decisions_test$votes>2,1,0) \n\ntable(decisions_test$Default,decisions_test$majority_vote)\n ##        0    1\n ##   0 2844   52\n ##   1    8  135\n```", "```py\nrm(list=setdiff(ls(), c(\"Model_database\",\"train\",\"test\",\"summary_models_train\",\"summary_models_test\",\"train_woe\",\"test_woe\",\"decisions_train\",\"decisions_test\")))\nsave.image(\"~/Data18.RData\")\nrm(list=ls())\n```", "```py\nload(\"~/Data12.RData\")\n```", "```py\nlibrary(h2o)\nh2o.init()\nh2o.removeAll()\n```", "```py\nlibrary(caret)\nfeatures <- setdiff(names(train), c(\"ID_RSSD\",\"Default\"))\n```", "```py\npre_process <- preProcess(x = train[, features], \n                method = c( \"center\", \"scale\"))\n```", "```py\n# apply to both training & test\ntrain <- cbind(train[,\"Default\"],predict(pre_process, train[, features]))\ntest <- cbind(test[,\"Default\"],predict(pre_process, test[, features]))\n\ncolnames(train)[1]<-\"Default\"\ncolnames(test)[1]<-\"Default\"\n```", "```py\ntrain <- as.h2o(train)\ntest <- as.h2o(test)\n```", "```py\ny <- \"Default\"\nx <- setdiff(names(train), y)\n```", "```py\nAML_models <- h2o.automl(y = y, x = x,\n                   training_frame = train,\n                   max_models = 10,stopping_metric =\"AUC\",\n                   seed = 1234,sort_metric =\"AUC\")\n```", "```py\nLeaderboard <- AML_models@leaderboard\nprint(Leaderboard)\n ##                                                model_id       auc\n ## 1             GBM_grid_0_AutoML_20190105_000223_model_4 0.9945125\n ## 2 StackedEnsemble_BestOfFamily_0_AutoML_20190105_000223 0.9943324\n ## 3    StackedEnsemble_AllModels_0_AutoML_20190105_000223 0.9942727\n ## 4             GLM_grid_0_AutoML_20190105_000223_model_0 0.9941941\n ## 5             GBM_grid_0_AutoML_20190105_000223_model_1 0.9930208\n ## 6             GBM_grid_0_AutoML_20190105_000223_model_5 0.9926648\n ##      logloss mean_per_class_error       rmse         mse\n ## 1 0.03801166           0.04984862 0.09966934 0.009933978\n ## 2 0.03566530           0.03747844 0.09228175 0.008515921\n ## 3 0.03589846           0.03929486 0.09251204 0.008558478\n ## 4 0.03026294           0.05200978 0.08904775 0.007929502\n ## 5 0.03664414           0.06546054 0.09659713 0.009331005\n ## 6 0.13078645           0.08500441 0.18747430 0.035146615\n ## \n ## [12 rows x 6 columns]\n```", "```py\nleader_model <- AML_models@leaderpred_test <- as.data.frame(h2o.predict(object = leader_model, newdata = test))\n```", "```py\nprint(leader_model)\n```", "```py\nhead(pred_test)\n ##   predict        p0          p1\n ## 1       0 0.9977300 0.002270014\n ## 2       0 0.9977240 0.002275971\n ## 3       0 0.9819248 0.018075249\n ## 4       0 0.9975793 0.002420683\n ## 5       0 0.9977238 0.002276235\n ## 6       0 0.9977240 0.002276009\n```", "```py\npred_test$predict<-ifelse(pred_test$p1>0.04696094,1,0)\n```", "```py\npred_test<-cbind(as.data.frame(test[,\"Default\"]),pred_test)\ntable(pred_test$Default,pred_test$predict)\n ##        0    1\n ##   0 2810   86\n ##   1    6  137\n```", "```py\nh2o.saveModel(leader_model, path = \"AML_model\")\n```"]