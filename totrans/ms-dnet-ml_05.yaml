- en: Chapter 5. Time Out – Obtaining Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to break from looking at various machine learning
    models. Instead, we are going to revisit some of the issues that I glossed over
    in [Chapter 2](part0024_split_000.html#MSDG2-a18db0be6c20485ba81f22e43ca13055
    "Chapter 2. AdventureWorks Regression"), *AdventureWorks Regression*, [Chapter
    3](part0029_split_000.html#RL0A2-a18db0be6c20485ba81f22e43ca13055 "Chapter 3. More
    AdventureWorks Regression"), *More AdventureWorks Regression*, and [Chapter 4](part0032_split_000.html#UGI01-a18db0be6c20485ba81f22e43ca13055
    "Chapter 4. Traffic Stops – Barking Up the Wrong Tree?"), *Traffic Stops – Barking
    Up the Wrong Tree?*. We are going to look at different ways in which we can obtain
    data using Visual Studio and type providers. We will then look at how type providers
    help us solve problems of missing data, how we can use parallelism to speed up
    our data extraction, and how we can use type providers on secured web services.
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the underappreciated skills that a data scientist must possess is the
    ability to gather and assimilate heterogeneous data. Heterogeneous data is data
    from different sources, structures, and formats. Heterogeneous stands in contrast
    to homogenous data which assumes that all of the data that is imported is the
    same as all of the other data that may already exist. When the data scientist
    gets heterogeneous data, one of the first things they will do is transform the
    data to a point that it can be combined with the other data. The most common shape
    of that transformation is the **data frame**—sometimes called the *rectangle*
    because the columns are attributes and the rows are the data. For example, here
    is a data frame that we have seen earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Overview](img/00070.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ideally, each frame has a unique key that allows it to be combined with other
    data frames. In this case, **ProductID** is the primary key. If you are thinking
    that this is a lot like RDBMS theory—you are right.
  prefs: []
  type: TYPE_NORMAL
- en: One of the bigger differences between a research analysts and a line of business
    developer is how they approach using data in their project. For the software engineer,
    data elements must be meticulously defined, created, and tracked. For the research
    analyst, all of that mental effort is noise that is tangential to solving the
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the power of type providers comes in. Instead of spending any
    effort on extracting data, we spend our time transforming, shaping, and analyzing
    it.
  prefs: []
  type: TYPE_NORMAL
- en: SQL Server providers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though there is lots of buzz surrounding `no-sql` databases like MongoDb
    and unstructured data stores like *data lakes* (or *data swamps*, depending on
    your point of view), a significant percentage of data that our industry works
    with is still stored in relational databases. As we have seen in prior chapters,
    the data scientist must be able to effectively communicate with relational databases
    using SQL. However, we also saw that F# offers the ability to use something called
    a type provider to access SQL Server.
  prefs: []
  type: TYPE_NORMAL
- en: Non-type provider
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's go back to the SQL that was used in [Chapter 3](part0029_split_000.html#RL0A2-a18db0be6c20485ba81f22e43ca13055
    "Chapter 3. More AdventureWorks Regression"), *More AdventureWorks Regression*,
    to bring down the Average Orders, Average Reviews, and List Price for individual
    customers and see how to do it differently. Go into Visual Studio and create an
    F# Windows Library called `TypeProviders`.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that I am using .NET Framework 4.5.2\. The framework's minor version
    does not matter, as long as it is 4.x. It is important to note that you cannot
    use type providers with **Portable Class Libraries** (**PCLs**).
  prefs: []
  type: TYPE_NORMAL
- en: '![Non-type provider](img/00071.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once Visual Studio generates the files for you, go ahead and delete `Library1.fs`
    and remove all the contents of `Script1.fsx`. Rename `Scipt1.fsx` to `SqlServerProviders.fsx`.
    Next, add a reference to `System.Transactions`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Non-type provider](img/00072.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Go into `SqlServerProviders.fsx` and add this code (you can copy it from [Chapter
    3](part0029_split_000.html#RL0A2-a18db0be6c20485ba81f22e43ca13055 "Chapter 3. More
    AdventureWorks Regression"), *More AdventureWorks Regression*, it is identical):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: There are 52 lines of total code here, 26 of which are SQL inside the string
    called `query`. This seems like a lot of work for something that appears to be
    pretty basic. Also, if we want to change our output rectangle, we would have to
    rewrite this SQL and hope we got it right. Also, we now need to know some fairly
    advanced SQL even though we don't care one whit that the data is stored in a SQL
    Server database. How can type providers help us here?
  prefs: []
  type: TYPE_NORMAL
- en: SqlProvider
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Go back into Visual Studio, open up the nugget package manager, and enter this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, go into the script file and add this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Warning**'
  prefs: []
  type: TYPE_NORMAL
- en: Type Providers are constantly changing their version number. Therefore, `SQLProvider.0.0.11`
    will fail unless you edit it. To determine the correct version, go into the packages
    folder in your solution and look at the path.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you put in the correct version of the provider, you might get a dialog
    box that looks like this (this is from the last chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: '![SqlProvider](img/00073.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on **Enable**. Heading back to the script, go ahead and enter the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the following code in the script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending that to the FSI gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a couple of things to notice here. First, we are sending a query
    (sometimes referred to as a *computational expression*) to the type provider.
    In this case, we are selecting all customers where the `storeId` is greater than
    `0`—the individual customers. The expression is everything between the `{}` symbols.
    Notice that it is LINQ-syntax, because it is LINQ. If you are not familiar, LINQ
    stands for **language Integrated Query** and is a language within a language—it
    allows for querying capabilities to be placed inside your .NET language of choice.
    The other thing to notice is that the results of the expression are piped to our
    familiar F# `Seq` type. This means we can get any result from the expression and
    use `Seq` to further shape or refine the data. To see this in action, enter this
    into the script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send it to the FSI, you should see an array of product IDs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Going back to the code, we are joining three tables from the **AdventureWorks**
    database together via their foreign keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next line, we are selecting only those customers that are in the customers''
    table that we created previously. Notice that we are using the F# `in` operator
    of `|=|`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we are selecting only the product IDs and then pulling down all of
    the values and then selecting the unique values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s keep going and see what else we can do. Enter the following into the
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this block of code, we are pulling down all the reviews. We are then grouping
    the reviews by `productId`. From there, we can sum up the ratings and the count
    of the number of reviews (using `Seq.length`). We can then divide the total ratings
    amount by the number of reviews and get the average review for each `productId`.
    Finally, we throw in a `Seq.sortBy` and pipe it to an array. All of this F# code
    should be familiar as it is very similar to how we manipulated data in [Chapter
    2](part0024_split_000.html#MSDG2-a18db0be6c20485ba81f22e43ca13055 "Chapter 2. AdventureWorks
    Regression"), *AdventureWorks Regression*, [Chapter 3](part0029_split_000.html#RL0A2-a18db0be6c20485ba81f22e43ca13055
    "Chapter 3. More AdventureWorks Regression"), *More AdventureWorks Regression*,
    and [Chapter 4](part0032_split_000.html#UGI01-a18db0be6c20485ba81f22e43ca13055
    "Chapter 4. Traffic Stops – Barking Up the Wrong Tree?"), *Traffic Stops – Barking
    Up the Wrong Tree?*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s create a data frame (sometimes called a *rectangle* of data if
    you are geometrically inclined) of prices for each product:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending that to the REPL, you should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This code does not introduce anything new. We pull down all of the products
    that are in our array, take the `productId` and `list price`, sort it, and send
    it to an array. Finally, enter the following into the script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a pretty sizable code block so it can look daunting. What we are doing
    is first pulling down all of the `SalesOrderHeaders` and `SalesOrderDetails` as
    a tuple select (`soh,sod`). We then pipe that set into a `Seq.map` that returns
    a sequence of a tuple that has three elements: `ProductId`, `OrderQty`, and `CustomerId
    |> Seq.map(fun (soh,sod) -> sod.ProductId, sod.OrderQty, soh.CustomerId)`. From
    there we pipe those tuples into a `groupBy` for the `ProductId |> Seq.groupBy(fun
    (pid,q,cid) -> pid)`. From there, we go a bit crazy. Take a look at the next line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Hopefully, you remember the discussion about `GroupBy`, so you realize that
    the input is a tuple of `ProductId` and an array of the three-item tuple of (`ProductId`,
    `OrderQty`, and `CustomerId`). We create a new three-item tuple that has `ProductId`,
    the sum of the `OrderQty`, and yet another tuple that has the `CustomerId` and
    a sequence of the distinct `customerId` items.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we pipe this to the next line, we take the length of that last tuple (`CustomerId,`
    Array of `CustomerIds`) as that is the number of unique customers that ordered
    the product. The three-item tuple is `ProductId`, `SumOfQuantityOrdered`, and
    `CountOfUniqueCustomersThatOrdered`. Since that is a bit verbose, I used the standard
    tuple notation of `(pid, q, c)`, where `q` is SumOfQuan`t`ityOrdered and `c` is
    `CountOfUniqueCustomersThatOrdered`. This tuple is then piped to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now get the average number of orders for each product. We then finish
    off with a sort and send it to an array. We now have three arrays of tuples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Ideally, we can then combine these into one array that has `ProductId`, `AverageNumberOfOrders`,
    `AverageReviews`, and `PriceOfProduct`. To do that, you might think that we can
    just zip these three arrays up. Go into the script and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send it to the FSI, you will see something disappointing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The arrays are not matching up. Apparently, some products do not have any ratings.
    What we need is a way to join these three arrays into one array and have the join
    occur on the `ProductId`. Although we could go back and play around with our `where`
    clauses in the LINQ expressions, there is an alternative way.
  prefs: []
  type: TYPE_NORMAL
- en: Deedle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Go into the script file and enter the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As we did earlier, you will have to make sure the version numbers match. When
    you send it to the REPL, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'What we have done is loaded **Deedle**. Deedle is a neat library created for
    time-series analysis. Let''s see if Deedle can help us with our unbalanced array
    issue. The first thing we want to do is to take our array of tuples and turn them
    into data frames. Enter this into the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI, you will see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s rename `Item1` and `Item2` to something that has a bit more meaning
    and make the first vector of the fame the primary key of the frame. Enter the
    following into the script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This code should be fairly self-explanatory. We are creating a function called
    `adjustFrame` that takes in two arguments: a data frame and an array of strings
    that will become the header values. We apply the headers via the first pipe, make
    the first column (`ProductId`) the `primaryKey` via the second pipe, and then
    sort the frame via the third pipe. We then apply this function to our three data
    frames: orders, prices, and reviews. Notice that we are using the tick notation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From there, we can now combine the frames based on their key. Go to the script
    file and add this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI, you should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Cool huh? Deedle is a very powerful library that you can use in a variety of
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Going back to our original task, we now have two different ways to pull data
    out from a database and transform it. When you do a side-by-side comparison of
    the ADO.NET SQL ways and the type-provider approach, there are some pretty strong
    arguments to be made to use the type provider method. First, `SqlDataProvider`
    is designed for most of the popular relational databases out there. If you moved
    your **AdventureWorks** database from MS SQL Server to MySql, all you would have
    to change is the connection string and all the code would be the same. Second,
    consider that there is no SQL in the type provider implementation. Instead, we
    are using an F# computational expression to pick what tables and what records
    we want. This means we don't have to know any SQL and we have even more portability.
    If we move our AdventureWorks database to a NoSQL database like Mongo or DocumentDb,
    we would have to swap out a type provider and then change our connection string.
    Finally, consider our approach to the data using the type provider. We do not
    have to build any classes ahead of time to put our data into, as types are automatically
    generated for us.
  prefs: []
  type: TYPE_NORMAL
- en: Also, since we are bringing down small chunks of data to the client that are
    then transformed, we can run each step of our though process independently. I
    can't emphasize how important that is; we are extracting and transforming the
    data with small viewable steps that align with our thought process. We can spend
    our mental energy and time focusing on the problem at hand and not wading through
    the syntax of a language we may or may not be comfortable with. The downside of
    the type provider method is that it may be slower than the ADO.NET approach because
    there is less opportunity to hand-adjust query optimization. In this case, we
    are doing ad hoc data exploration and analysis on a small dataset so the performance
    differences are minor. However, even if it was a large dataset, I would still
    follow the software engineering mantra of, "Make it right. Then make it fast."
  prefs: []
  type: TYPE_NORMAL
- en: MicrosoftSqlProvider
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we leave our discussion on type providers, I want to show another type
    provider that is built upon Entity Framework 7 that has a lot of promise, especially
    when you want to start using type providers as a replacement to your current ORM.
    It is called the `EntityFramework.MicrosoftSqlServer` type provider.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back to Visual Studio, open the package manager console and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, go to your script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Yes, I know that is a lot, but you only have to enter this once and you don''t
    have to bring it over to your `.fs` file. If you don''t want to copy and paste
    this code over to your script, you can just install all of Entity Framework, and
    these packages will be available. In any event, enter the following into the script
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Go back to the script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the FSI, you will see the `SalesOrderheader` Entity Framework
    type in all its glory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The implications are that anything you do with Entity Framework, you can do
    with the type provider—with no upfront code. No templates, no designers, no nothin'.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s press on and see how the type provider handles null. Go into the script
    and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the FSI, you will see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we have to use `System.Nullable<int>` in the `where` condition
    to account for the fact that `ProductSubcategoyID` is nullable on the database.
    This leads to one small *gotcha* with using the type provider. You can''t use
    the out of the box `|=|` operator to search for an array of values. For example,
    if you sent the following to the REPL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get the following back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We now need to create an array of nullable ints. Will that work?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Alas, no:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'So there are a couple of ways out of this problem. Option number 1, is that
    you can create a function. Enter the following into your script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI gives you the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: There is no new code here. We created a function.
  prefs: []
  type: TYPE_NORMAL
- en: 'But wait! There''s more! Go back to the script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: So what is this line of code?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'It is a function named `|=|` that takes in two parameters: the `id` to search
    and the array that gets searched. This function is called an *infix* operator
    because we are assigning symbols to stand in for a more descriptive name. Consider
    how the `+` operator stands in for *Add*. With that infix operator in place, we
    can go back and make our syntax more intuitive here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'There is one more option to consider: just ditching the extra function and
    inlining `Array.contains`. Go back to the script and enter this in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL gives us the expected return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: So we have three different ways to handle the problem. Do we pick the named
    function, the in-fix operator, or the in-line function? In this case, I would
    pick the in-fix operator because we are replacing an existing operator that should
    work and makes the line the most readable. Others might disagree and you have
    to be prepared as a data scientist to be able to read other people's code, so
    it is good that you are familiar with all three ways.
  prefs: []
  type: TYPE_NORMAL
- en: SQL Server type provider wrap up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I have already highlighted two SQL type providers in this chapter. There are
    actually five different type providers that you can use when accessing SQL databases
    that I know of, and there are certainly more. When you first start using F#, you
    might be confused about which one to use. For your reference, here is my basic
    run down:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FSharp.Data.TypeProviders.SqlServerProvider`: This is a part of Visual Studio
    install, is supported by Microsoft, and no new development is going on. Since
    this is the end of life, you would not want to use this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FSharp.Data.TypeProviders.EntityFrameworkProvider`: This is a part of Visual
    Studio install, is supported by Microsoft, and no new development is going on.
    It is good for vanilla databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FSharp.Data.SqlClient`: This was created by the community. It is a very stable
    way to pass SQL commands to the server. It does not support LINQ-style computational
    expressions. It is good for CRUD-based F# operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FSharp.Data.SqlProvider`: This was created by the community in pre-release,
    so there is some instability. It is very good for doing LINQ-style computation
    expressions. It supports different RDMS like Oracle, MySQL, and SQL Server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FSharp.EntityFramework.MicrosoftSqlServer`: This was created by the community.
    It is in its very early stages, but holds tons of promise to be a great replacement
    to traditional ORM coding. It is good for doing LINQ-style computation expressions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non SQL type providers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Type providers are not just for relational database management systems. In fact,
    there are JSON type providers, XML type providers, CSV type providers, the list
    goes on. Let's take a look at a couple and see how we can use them to make some
    really interesting data frames based on heterogeneous data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go into Visual Studio and add a new script file called `NonSqlTypeProviders.fsx`.
    At the top, bring in all of the references that we''ll be using and open up the
    needed libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Send it to the REPL to make sure you have all of the needed libraries. In the
    script, add the following code to bring in data from our AdventureWorks SQL Server
    database. You will notice that I am piping straight to Deedle''s dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Go back to the script and add some data that is stored in a CSV file from Yahoo
    Finance. In this case, it is the change in daily stock price for the Dow Jones
    Industrial Average:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Send it to the REPL to get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Go back to the script and add some data that is served up by an API in JSON
    format from Quandl. In this case, it is the number of sunspots recorded by the
    Royal Observatory in Belgium.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send it to the FSI, you should get something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, go back to the script and join all three data frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending that to the REPL gives:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll leave the process of creating a model to see if there is a relationship
    among the Down Jones Price Change and the number of sunspots on the amount of
    Sales by Day up to the reader. Before you get too carried away, you might want
    to consider this website about data elements that have no relation but are correlated
    ([http://tylervigen.com/spurious-correlations](http://tylervigen.com/spurious-correlations)).
    I think this is my favorite one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Non SQL type providers](img/00074.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Combining data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sometimes the data that you obtain from a source system is incomplete. Consider
    this dataset of crash locations that was obtained from the State Department of
    Transportation office:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Combining data](img/00075.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Notice that latitude and longitude are missing and that location does not use
    a normal address/city/state pattern. Rather, it is **OnRoad**, **Miles**, **FromRoad**,
    and **TowardRoad**. Unfortunately, this is fairly common when getting data from
    public entities—systems may have been built before lat/lon became mainstream and
    the system's addressing might be designed to only work inside the system. This
    means we need a way to figure out the latitude and longitude from this atypical
    addressing.
  prefs: []
  type: TYPE_NORMAL
- en: If you pull the source code down from the site, you will see a couple of script
    files. The first is called `BingGeocode`. This is a script that goes out to the
    Bing maps API and returns a geolocation for a given address. The key thing is
    that, although Bing does not recognize **OnRoad**/**FromRoad**/**TowardRoad**,
    it does recognize cross streets. Therefore, we can take a sample from the crash
    dataset of incidents that happened at or near intersections—which we can determine
    from the **OnRoad**/**FromRoad** as long as the **Miles** value is fairly low.
    In fact, 90 percent of the records are within a quarter mile of an intersection.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you inspect the code, you will see that there is nothing particularly new
    here. We use the JSON type provider to make the call to Bing, and we parse the
    results, using the `Option` type to return none or some Geolocation. If you want
    to run this on your machine, we will need to sign up for the Bing Map API developer
    program here ([https://www.bingmapsportal.com/](https://www.bingmapsportal.com/))
    and put your value into the `apiKey`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'In the solution, there is another script file that does the actual heavy lifting
    of pulling the original crash data from the database, updating it with the latitude
    and longitude, and then putting it back into the database. This script file is
    called `UpdateCrashLatLon.fsx`. If you look at the code, the first part pulls
    down crashes that happened in the same town as the traffic stops and occurred
    within a quarter mile of an intersection. It then creates an address string that
    is passed to the Bing geocode file and creates a frame with the ID and the latitude
    and longitude. We then filter that Array with only the values that returned as
    some:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'There is one new line of code in this script: `#load "BingGeocode.fsx"`. This
    adds a reference to the script file we already created, so we can go ahead and
    invoke the `getGeocode()` function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we update the database with our data, I wrote a script to write the
    data to the local disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: As the comment says, Bing throttles how many requests you can make per hour.
    The last thing you want is to have to re-query Bing because you are experimenting
    with the data and get a 401 error back because you are at your limit. Rather,
    it is much better to bring it local once and work off a local copy.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the data local, we can then pull down each record from the database that
    we want to update, update the lat/long, and write it back to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Parallelism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I want to show you one more trick that will greatly speed up your data extraction—parallelism.
    My machine has four cores, but only one core is being used in the prior example
    when making the API calls to Bing. It would be much faster if I could use all
    of the cores and make the requests in parallel. F# makes this a snap. As a demonstration,
    I re-queried Bing for the first 200 crash records and wrote the time out to the
    FSI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'When I ran it, it took 33 seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, I added this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the only change was adding a reference to `Collections.Array.Parallel`
    and then considering the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Change this line to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'When I ran it, I saw this in the FSI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: So I got a 3x speed improvement by changing one line. Because F# was built from
    the ground-up with parallelism and async in mind, it is very easy to take advantage
    of these concepts. The other languages have these features bolted on and can be
    very cumbersome to use and often can lead to race conditions or worse.
  prefs: []
  type: TYPE_NORMAL
- en: There is one more thing to note when you are pulling mass data from a web service.
    Unless you explicitly code it, you have no real way of monitoring the progress.
    I often pop open Fiddler ([http://www.telerik.com/fiddler](http://www.telerik.com/fiddler))
    and monitor the HTTP traffic to see how things are progressing.
  prefs: []
  type: TYPE_NORMAL
- en: '![Parallelism](img/00076.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: JSON type provider – authentication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The JSON type provider is a very handy tool, but there is a limitation to its
    out of the box implementation—it assumes that the web service does not have any
    authentication or the authentication token is part of the query string. Some datasets
    are not like that—in fact most web services use headers for authentication. Fortunately,
    there is a way to code around this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this open dataset—the NOAA archives ([http://www.ncdc.noaa.gov/cdo-web/webservices/v2](http://www.ncdc.noaa.gov/cdo-web/webservices/v2)).
    If you look at the solution that comes with the chapter, there is a script file
    called `GetWeatherData.fsx`. In this script, I picked a single zip code for the
    town where the traffic stops and crashes occurred and pulled down the daily precipitation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'There is one thing new here. I am using the JSON type provider but the authorization
    token needs to be in the header of the request. Since the JSON type provider does
    not allow you to set headers, you need to pull the data down via the `System.Net.WebClient`
    class (where you can set the `auth` token in the header) and then use the JSON
    type provider to parse the results. You can see that I am using `Parse()` and
    not `Load()` in the following line to accomplish that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Just like the geolocation data, I then pushed the data frame to disk because
    the number of requests are limited:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, like the data geolocation data, you can do this on your machine but you
    will need an `apiToken`. You can go to the NOAA developer website to apply for
    one. I also added the data as a table on the SQL Server so you don''t have to
    pull the data from the source code to write the remaining code in the chapter.
    Go into the active `kmeans.fsx` script file and enter this to get the data from
    the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send it to the FSI, you will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you ask a data scientist what they like least about their day, they will
    tell you meetings, building slide decks, and munging data in no particular order.
    Although F# type providers can't help you with meetings and building slide decks,
    it can decrease the amount of time spent obtaining and cleaning data. Although
    not completely frictionless, type providers can help you with relational and non-relational
    data stores and enable you to spend more time with the "fun" parts of data science.
    Speaking of which, let's jump back into the fun with KNN and Naïve Bayes modeling.
  prefs: []
  type: TYPE_NORMAL
