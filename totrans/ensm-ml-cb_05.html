<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Bag the Models with Bagging</h1>
                </header>
            
            <article>
                
<p class="CDPAlignLeft3"><span class="calibre5">In this chapter, we discuss the following recipes:</span></p>
<ul class="calibre10">
<li class="calibre11">Bootstrap aggregation </li>
<li class="calibre11">Ensemble meta-estimators</li>
<li class="calibre11">Bagging regressors</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">The combination of classifiers can help reduce misclassification errors substantially. Many studies have proved such ensembling methods can significantly reduce the variance of the prediction model. Several techniques have been proposed to achieve a variance reduction. For example, in many cases, bootstrap aggregating (bagging) classification trees have been shown to have higher accuracy than a single classification tree. Bagging can be applied to tree-based algorithms to enhance the accuracy of the predictions, although it can be used with methods other than tree-based methods as well.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bootstrap aggregation</h1>
                </header>
            
            <article>
                
<p class="calibre2"><strong class="calibre4">Bootstrap aggregation</strong>, also known as <strong class="calibre4">bagging</strong>, is a powerful ensemble method that was proposed by Leo Breiman in 1994 to prevent overfitting. The concept behind bagging is to combine the predictions of several base learners to create a more accurate output. </p>
<p class="calibre2"><span class="calibre5">Breiman showed that bagging can successfully achieve the desired result in <strong class="calibre4">unstable </strong>learning algorithms where small changes to the training data can lead to large variations in the predictions. Breiman demonstrated that algorithms such as neural networks and decision trees are examples of <strong class="calibre4">unstable</strong> learning algorithms.</span> Bootstrap aggregation is effective on small datasets.</p>
<p class="calibre2"/>
<p class="calibre2">The general procedure for bagging helps to reduce variance for those algorithms have high variance. Bagging also supports the classification and regression problem. The following diagram shows how the bootstrap aggregation flow works:</p>
<p class="CDPAlignCenter"><img class="aligncenter65" src="assets/fa8702be-8271-4dba-9264-13e122c57947.png"/></p>
<p class="calibre2">Using bootstrapping with a training dataset<span class="calibre5"> </span><em class="calibre13">X</em><strong class="calibre4">,</strong><span class="calibre5"> </span>we generate N bootstrap samples <em class="calibre13">X1</em>, <em class="calibre13">X2,....., XN</em>. </p>
<p class="calibre2">For each bootstrap sample, we train a classifier, <img class="fm-editor-equation60" src="assets/0f7c18d2-774c-46a5-958b-e14bfac327eb.png"/>. T<span class="calibre5">he combined classifier will average the outputs from all these individual classifiers as follows:</span></p>
<p class="CDPAlignCenter"><img class="fm-editor-equation61" src="assets/9332286b-1e5f-4fb6-839f-8afe04b73931.png"/></p>
<p class="calibre2">In the preceding formula, <em class="calibre13">N</em> represents the number of samples.</p>
<p class="calibre2"><span class="calibre5">In a bagging classifier, voting is used to make a final prediction. The pseudo-code for the bagging classifier proposed by Breiman is as follows:</span></p>
<p class="CDPAlignCenter"><img class="aligncenter66" src="assets/542d5b93-e002-4f48-b9c6-f76f9909939b.png"/></p>
<p class="calibre2"><span class="calibre5">In the case of the bagging regressor, the final prediction is the average of the predictions of the models that are built over each bootstrap sample. The following pseudo-code describes the bagging regressor:</span></p>
<p class="CDPAlignCenter"><img class="aligncenter67" src="assets/9a400a3a-8888-45de-8a81-161d00c22819.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="calibre2">We start by importing the required libraries and reading our file. We suppress any warnings using the <kbd class="calibre12">warnings.filterwarnings()</kbd> function from the <kbd class="calibre12">warnings</kbd> library:</p>
<pre class="calibre18">import warnings<br class="title-page-name"/>warnings.filterwarnings('ignore')<br class="title-page-name"/><br class="title-page-name"/>import os<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/><br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/>from sklearn.linear_model import SGDRegressor<br class="title-page-name"/>from sklearn.metrics import mean_squared_error, r2_score<br class="title-page-name"/>from sklearn.utils import resample<br class="title-page-name"/><br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/><br class="title-page-name"/></pre>
<p class="calibre2">We have now set our working folder. Download the <span class="calibre5"><kbd class="calibre12">autompg.csv</kbd> file from the GitHub and copy the file into your working folder as follows:</span></p>
<pre class="calibre18">os.chdir('.../.../Chapter 5')<br class="title-page-name"/>os.getcwd()</pre>
<p class="calibre2">We read our data with <kbd class="calibre12">read_csv()</kbd> and prefix the name of the data frame with <kbd class="calibre12">df_</kbd> so that it is easier to understand:</p>
<pre class="calibre18">df_autodata = pd.read_csv("autompg.csv")</pre>
<p class="calibre2">We check whether the dataset has any missing values as follows:</p>
<pre class="calibre18"># The below syntax returns the column names which has any missing value<br class="title-page-name"/>columns_with_missing_values=df_autodata.columns[df_autodata.isnull().any()]<br class="title-page-name"/><br class="title-page-name"/># We pass the column names with missing values to the dataframe to count the number<br class="title-page-name"/># of missing values<br class="title-page-name"/>df_autodata[columns_with_missing_values].isnull().sum()</pre>
<p class="calibre2">We notice that the <kbd class="calibre12">horsepower</kbd> variable has six missing values. We can fill in the missing values using the median of the <kbd class="calibre12">horsepower</kbd> variable's existing values with the following code:</p>
<pre class="calibre18">df_autodata['horsepower'].fillna(df_autodata['horsepower'].median(), inplace=True)</pre>
<p class="calibre2">We notice that the <kbd class="calibre12">carname</kbd> variable is an identifier and is not useful in our model-building exercise, so we can drop it as follows:</p>
<pre class="calibre18"><span>df_autodata.drop(['carname'], axis=1, inplace=True)</span></pre>
<p class="calibre2">We can look at the data with the <kbd class="calibre12">dataframe.head()</kbd> command:</p>
<pre class="calibre18">df_autodata.head()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">In this section, we will see how to build a model using bootstrap samples:</span></p>
<ol class="calibre14">
<li class="calibre11">We start by creating the bootstrap samples. In <a href="6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml" class="calibre9">Chapter 3</a>, <em class="calibre23">Resampling Methods</em>, we wrote a custom function, <kbd class="calibre12">create_bootstrap_oob()</kbd>, to create both bootstrap and <strong class="calibre1">out-of-bag</strong> (<strong class="calibre1">OOB</strong>) samples.</li>
</ol>
<p class="calibre20">In the following code block, we see how to create bootstrap and OOB samples:</p>
<pre class="calibre18">def create_bootstrap_oob(df):<br class="title-page-name"/>    global df_OOB<br class="title-page-name"/>    global df_bootstrap_sample <br class="title-page-name"/>    # creating the bootstrap sample<br class="title-page-name"/>    df_bootstrap_sample = resample(df, replace=True, n_samples=100)<br class="title-page-name"/>    <br class="title-page-name"/>    # creating the OOB sample <br class="title-page-name"/>    bootstrap_sample_index = tuple(df_bootstrap_sample.index)<br class="title-page-name"/>    bootstrap_df = df.index.isin(bootstrap_sample_index)<br class="title-page-name"/>    <br class="title-page-name"/>    df_OOB = df[~bootstrap_df]</pre>
<ol start="2" class="calibre14">
<li class="calibre11">We build models using the bootstrap samples and average the cost function across all the models. We use<span> the </span><kbd class="calibre12">SGDRegressor()</kbd><span> </span><span>on each bootstrap sample. In the following code block, w</span><span>e reuse our previously written custom function, </span><kbd class="calibre12">create_bootstrap_oob()</kbd><span>, to create the bootstrap and OOB error samples:</span></li>
</ol>
<pre class="calibre18">iteration=50<br class="title-page-name"/>mse_each_iterations = list()<br class="title-page-name"/>lm=SGDRegressor()<br class="title-page-name"/>total_mse=0<br class="title-page-name"/>average_mse= list()<br class="title-page-name"/><br class="title-page-name"/>for i in range(iteration):<br class="title-page-name"/>    create_bootstrap_oob(df_autodata)<br class="title-page-name"/><br class="title-page-name"/>    # Bootstrap sample features set<br class="title-page-name"/>    X_BS = df_bootstrap_sample.iloc[:,1:8] <br class="title-page-name"/><br class="title-page-name"/>    # bootstrap sample response variable<br class="title-page-name"/>    Y_BS = df_bootstrap_sample.iloc[:,0] <br class="title-page-name"/><br class="title-page-name"/>    X_OOB = df_OOB.iloc[:,1:8] #OOB sample features<br class="title-page-name"/>    Y_OOB = df_OOB.iloc[:,0] #OOB sample response variable <br class="title-page-name"/>    <br class="title-page-name"/>    # fit your model with bootstrap sample<br class="title-page-name"/>    lm=SGDRegressor()<br class="title-page-name"/>    lm.fit(X_BS, Y_BS)<br class="title-page-name"/>    <br class="title-page-name"/>    # test your model on out-of-bag sample <br class="title-page-name"/>    predictedvalues = lm.predict(X_OOB)<br class="title-page-name"/>    <br class="title-page-name"/>    # capture MSE for the predicted values against OOB actuals<br class="title-page-name"/>    mse = mean_squared_error(Y_OOB, predictedvalues)<br class="title-page-name"/>    <br class="title-page-name"/>    # create a list of mse values<br class="title-page-name"/>    mse_each_iterations.append(mse) </pre>
<ol start="3" class="calibre14">
<li class="calibre11"><span>We are now going to plot the MSE for each model built:</span></li>
</ol>
<pre class="calibre18">import matplotlib.pyplot as plt<br class="title-page-name"/>f, ax= plt.subplots(figsize=(8,6))<br class="title-page-name"/><br class="title-page-name"/>plt.plot(mse_each_iterations, 'c--', label='MSE by Iteration')<br class="title-page-name"/><br class="title-page-name"/>plt.xlabel('Iterations')<br class="title-page-name"/>plt.ylabel('Mean Squared Error')<br class="title-page-name"/>plt.legend(loc=1)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">The plot will look as follows:</p>
<p class="CDPAlignCenter"><img class="aligncenter68" src="assets/f8316674-8694-4913-9562-18dde46e30a7.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="calibre2">In <em class="calibre13">Step 1</em>, we executed our custom function code to create the <kbd class="calibre12">create_bootstrap_oob()</kbd> function that creates the bootstrap and OOB samples for us. In <em class="calibre13">Step 2</em>, we executed the following steps:</p>
<ol class="calibre14">
<li class="calibre11">We decided to make 50 iterations, so we set the <kbd class="calibre12">iteration</kbd> <span>variable </span>to <kbd class="calibre12">50</kbd>.</li>
<li class="calibre11">The <kbd class="calibre12"><span>create_bootstrap_oob()</span></kbd> function returned two DataFrame objects, <kbd class="calibre12">df_bootstrap_sample</kbd> and <kbd class="calibre12">df_OOB</kbd>, in each iteration.</li>
<li class="calibre11">We used <span><kbd class="calibre12">df_bootstrap_sample</kbd> and <kbd class="calibre12">df_OOB</kbd> as our bootstrap and OOB samples respectively.</span></li>
<li class="calibre11">We split both the <span><kbd class="calibre12">df_bootstrap_sample</kbd> and the <kbd class="calibre12">df_OOB</kbd> samples into feature sets and response variables.</span></li>
<li class="calibre11">We fit the <kbd class="calibre12">SGDRegressor()</kbd> to our bootstrap sample to build our model.</li>
<li class="calibre11">We passed the OOB sample to the model to predict our values.</li>
</ol>
<ol start="7" class="calibre14">
<li class="calibre11">We compared the predicted values against the response variable in the OOB<span> sample.</span></li>
<li class="calibre11">We calculated the MSE for each iteration.</li>
</ol>
<p class="calibre2">In <em class="calibre13">Step 3</em>, w<span class="calibre5">e created a plot to show the MSE for each iteration up to the fiftieth iteration. This result may vary because of randomness.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul class="calibre10">
<li class="calibre11"><em class="calibre23">Bagging Predictors</em> by Leo <span>Breiman, September 1994</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ensemble meta-estimators</h1>
                </header>
            
            <article>
                
<p class="calibre2">The bagging classifier and the bagging regressor<span class="calibre5"> are ensemble meta-estimators that fit the base classifier and regressor models respectively on random subsets of the original dataset. The predictions from each model are combined to create the final prediction. </span>These kinds of meta-estimators induce randomization into the model-building process and aggregate the outcome. The aggregation averages over the iterations for a numerical target variable and performs a plurality vote in order to reach a categorical outcome. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bagging classifiers</h1>
                </header>
            
            <article>
                
<p class="calibre2">Bagging classifiers <span class="calibre5">train each classifier model on a random subset of the original training set and aggregate the predictions, then perform a plurality voting for a categorical outcome. In the following recipe, we are going to look at an implementation of a bagging classifier with bootstrap samples.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol class="calibre14">
<li class="calibre11">We import <kbd class="calibre12">BaggingClassifier</kbd> and <span><kbd class="calibre12">DecisionTreeClassifier</kbd> from the <kbd class="calibre12">scikit-learn</kbd> library. We also import the other required libraries as follows:</span></li>
</ol>
<pre class="calibre18">from sklearn.ensemble import BaggingClassifier<br class="title-page-name"/>from sklearn.tree import DecisionTreeClassifier<br class="title-page-name"/>from sklearn.model_selection import train_test_split</pre>
<p class="calibre2"/>
<ol start="2" class="calibre14">
<li class="calibre11">Next, we read out the data and take a look at the dimensions:</li>
</ol>
<pre class="calibre18">df_winedata = pd.read_csv('winedata.csv')<br class="title-page-name"/>df_winedata.shape</pre>
<ol start="3" class="calibre14">
<li class="calibre11">We separate our features and the response set. We also split our data into training and testing subsets.</li>
</ol>
<pre class="calibre18">X = df_winedata.iloc[:,1:14]<br class="title-page-name"/>Y = df_winedata.iloc[:,0]<br class="title-page-name"/><br class="title-page-name"/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">We create an instance of the <kbd class="calibre12">DecisionTreeClassifier</kbd> class and pass it to the <kbd class="calibre12">BaggingClassifier()</kbd>:</li>
</ol>
<pre class="calibre18">dt_model = DecisionTreeClassifier(criterion='entropy')<br class="title-page-name"/>bag_dt_model = BaggingClassifier(dt_model, max_features=1.0, n_estimators=5, \<br class="title-page-name"/>                                 random_state=1, bootstrap=True)</pre>
<div class="packtinfobox">Note that in the preceding code block, we have declared <kbd class="calibre19">bootstrap=True</kbd>. This is the default value and indicates <span>that samples are drawn with replacement.</span></div>
<ol start="5" class="calibre14">
<li class="calibre11">We fit our model to the training data as follows:</li>
</ol>
<pre class="calibre18">bag_dt_model.fit(X_train, Y_train)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">We can see the score after passing the test data to the model:</li>
</ol>
<pre class="calibre18">bag_dt_model.score(X_test, Y_test)</pre>
<ol start="7" class="calibre14">
<li class="calibre11">We use the <kbd class="calibre12">predict</kbd> function to predict the response variable as follows:</li>
</ol>
<pre class="calibre18">predictedvalues = bag_dt_model.predict(X_test)</pre>
<ol start="8" class="calibre14">
<li class="calibre11">We will now use a code to plot the confusion matrix. Note that this code has been taken from <a href="https://scikit-learn.org/stable/" class="calibre9">scikit-learn.org</a>. We execute the following code to create the <span><kbd class="calibre12">plot_confusion_matrix()</kbd> function:</span></li>
</ol>
<pre class="calibre18"># code from <br class="title-page-name"/># http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html<br class="title-page-name"/>def plot_confusion_matrix(cm, classes,<br class="title-page-name"/>                          normalize=False,<br class="title-page-name"/>                          title='Confusion matrix',<br class="title-page-name"/>                          cmap=plt.cm.Blues):<br class="title-page-name"/>    """<br class="title-page-name"/>    This function prints and plots the confusion matrix.<br class="title-page-name"/>    """<br class="title-page-name"/>    plt.imshow(cm, interpolation='nearest', cmap=cmap)<br class="title-page-name"/>    plt.title(title)<br class="title-page-name"/>    plt.colorbar()<br class="title-page-name"/>    tick_marks = np.arange(len(classes))<br class="title-page-name"/>    plt.xticks(tick_marks, classes, rotation=45)<br class="title-page-name"/>    plt.yticks(tick_marks, classes)<br class="title-page-name"/><br class="title-page-name"/>    thresh = cm.max() / 2.<br class="title-page-name"/>    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):<br class="title-page-name"/>        plt.text(j, i, cm[i, j],<br class="title-page-name"/>                 horizontalalignment="center",<br class="title-page-name"/>                 color="white" if cm[i, j] &gt; thresh else "black")<br class="title-page-name"/><br class="title-page-name"/>    plt.tight_layout()<br class="title-page-name"/>    plt.ylabel('Actuals')<br class="title-page-name"/>    plt.xlabel('Predicted')</pre>
<ol start="9" class="calibre14">
<li class="calibre11">We use the preceding <span><kbd class="calibre12">plot_confusion_matrix()</kbd> function to plot our confusion matrix:</span></li>
</ol>
<pre class="calibre18"># This variable holds the class labels of our target variable<br class="title-page-name"/>target_names = [ '1', '2', '3']<br class="title-page-name"/><br class="title-page-name"/>import itertools<br class="title-page-name"/>from sklearn.metrics import confusion_matrix<br class="title-page-name"/><br class="title-page-name"/># Constructing the Confusion Matrix<br class="title-page-name"/>cm = confusion_matrix(Y_test, predictedvalues)<br class="title-page-name"/><br class="title-page-name"/># Plotting the confusion matrix<br class="title-page-name"/>plt.figure(figsize=(3,3))<br class="title-page-name"/>plot_confusion_matrix(cm, classes=target_names, normalize=False)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">The confusion matrix plot looks as follows:</p>
<p class="CDPAlignCenter"><img class="aligncenter69" src="assets/a6309b5b-fc95-44fc-94d1-6d5607f77a59.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="calibre2">In <em class="calibre13">Step 1</em>, we imported the required libraries to build our decision tree classifier model using the bagging classifier. In <em class="calibre13">Step 2</em>, we read our dataset, which was <kbd class="calibre12">winedata.csv</kbd>. In <em class="calibre13">Step 3</em>, we separated our feature set and the target variable. We also split our data into training and testing subsets. <span class="calibre5">In <em class="calibre13">Step 4</em>, we created a</span> d<span class="calibre5">ecision tree classifier</span> <span class="calibre5">model and passed it to the</span> <span class="calibre5"><kbd class="calibre12">BaggingClassifier()</kbd>. In the <kbd class="calibre12">DecisionTreeClassifier()</kbd>, the default value for the <kbd class="calibre12">criterion</kbd> parameter was <kbd class="calibre12">gini</kbd></span>, but we <span class="calibre5">changed it to <kbd class="calibre12">entropy</kbd>. We then passed our decision tree model to the <kbd class="calibre12">BaggingClassfier()</kbd>. </span><span class="calibre5">In the </span><span class="calibre5"><kbd class="calibre12">BaggingClassfier()</kbd>, we have parameters including <kbd class="calibre12">n_estimators</kbd> and</span> <span class="calibre5"><kbd class="calibre12">bootstrap</kbd>. <kbd class="calibre12">n_estimators</kbd> </span><span class="calibre5">is the number of base estimators in the ensemble and has a default value of <kbd class="calibre12">10</kbd>. The </span><span class="calibre5"><kbd class="calibre12">bootstrap</kbd> parameter </span><span class="calibre5">indicates whether samples are drawn with replacement or not and </span><span class="calibre5">is set to <kbd class="calibre12">True</kbd> by default.</span></p>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">In <em class="calibre13">Step 5</em> and <em class="calibre13">Step<span class="calibre5"> </span></em><em class="calibre13">6</em>, we fitted our model to the training data and looked at the score of the test set. In <em class="calibre13">Step 7</em>, we called the <kbd class="calibre12">predict()</kbd> method and passed the test feature set. In <em class="calibre13">Step 8</em>, we added the code for the <span class="calibre5"><kbd class="calibre12">plot_confusion_matrix()</kbd> from <a href="http://scikit-learn.org" class="calibre9">http://scikit-learn.org</a>, which takes the confusion matrix as one of its input parameters and plots the confusion matrix. </span>In <em class="calibre13">Step 9</em>, we called the <span class="calibre5"><kbd class="calibre12">plot_confusion_matrix()</kbd> function by passing the confusion matrix to generate the confusion matrix plot.</span></p>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p class="calibre2">We can also use <kbd class="calibre12">GridSearchCV()</kbd> from <kbd class="calibre12">sklearn.model_selection</kbd> to grid search the best parameters and use them in the <kbd class="calibre12">BaggingClassifier</kbd>:</p>
<ol class="calibre14">
<li class="calibre11">First, we import the required library:</li>
</ol>
<pre class="calibre18">from sklearn.model_selection import GridSearchCV</pre>
<ol start="2" class="calibre14">
<li class="calibre11">We then set our parameter values:</li>
</ol>
<pre class="calibre18">param_values = {'n_estimators': [10, 20, 25, 30], 'base_estimator__max_leaf_nodes':[5, 10, 15, 20], 'base_estimator__max_depth':[3, 4, 5]}</pre>
<ol start="3" class="calibre14">
<li class="calibre11">We instantiate our <kbd class="calibre12">DecisionTreeClassifier</kbd> class and pass it to the <kbd class="calibre12">BaggingClassifier()</kbd> function. Note that we set the <kbd class="calibre12">oob_score</kbd> to <kbd class="calibre12">True</kbd> to evaluate the models built on the OOB samples:</li>
</ol>
<pre class="calibre18">dt_model = DecisionTreeClassifier()<br class="title-page-name"/>bag_dt_model_grid = BaggingClassifier(base_estimator=dt_model, oob_score=True, random_state=1) </pre>
<ol start="4" class="calibre14">
<li class="calibre11">We use <kbd class="calibre12">GridSearchCV()</kbd> to determine the best parameters:</li>
</ol>
<pre class="calibre18">bc_grid = GridSearchCV(estimator=bag_dt_model_grid, param_grid=param_values, cv=20, n_jobs=-1)<br class="title-page-name"/>bc_grid.fit(X_train, Y_train)<br class="title-page-name"/>best_params = bc_grid.best_params_<br class="title-page-name"/>print(best_params)</pre>
<p class="calibre20">The preceding code returns the optimum parameters:</p>
<p class="CDPAlignCenter"><img class="aligncenter70" src="assets/11224b03-0e99-4ce4-beb7-7d3cd26242fb.png"/></p>
<ol start="5" class="calibre14">
<li class="calibre11">We now take the values returned by <kbd class="calibre12">bc_grid.bestparams</kbd> and rebuild our decision tree models using the <kbd class="calibre12">BaggingClassfier()</kbd> function. We pass <kbd class="calibre12">10</kbd> for the <kbd class="calibre12">max_leaf_nodes</kbd>, <kbd class="calibre12">3</kbd> for the <kbd class="calibre12">max_depth</kbd>, and <kbd class="calibre12">20</kbd> for the <kbd class="calibre12">n_estimators</kbd>:</li>
</ol>
<pre class="calibre18">best_dt_model = DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=10, max_depth=3) <br class="title-page-name"/>final_bag_dt_model = BaggingClassifier(base_estimator=best_dt_model, n_estimators=150, bootstrap=True, random_state=1, oob_score=True)</pre>
<p class="calibre20">We set our <kbd class="calibre12">n_estimators</kbd> to <kbd class="calibre12">150</kbd> in the preceding code block. The <kbd class="calibre12">n_estimators</kbd> <span class="calibre5">parameter </span>indicates <span class="calibre5">the number of trees we want to build</span>. We fit our final model to our training data and make a prediction using our test feature set.</p>
<ol start="6" class="calibre14">
<li class="calibre11">We can then look at the accuracy of our OOB samples in the following code block:</li>
</ol>
<pre class="calibre18">final_bag_dt_model.fit(X_train, Y_train)<br class="title-page-name"/>bag_predictedvalues = final_bag_dt_model.predict(X_test)<br class="title-page-name"/><br class="title-page-name"/># See the OOB accuracy<br class="title-page-name"/>acc_oob = final_bag_dt_model.oob_score_<br class="title-page-name"/>print(acc_oob)</pre>
<p class="calibre2">If we plot our confusion matrix, we can see that we have made an improvement with regard to the number of misclassifications that are made. In the earlier example, two instances of class 2 were wrongly predicted as class 3, but we can now see that the number of misclassifications has reduced to one:</p>
<p class="CDPAlignCenter"><img class="aligncenter71" src="assets/2ab6bb14-572f-47c8-a678-f7331a597e13.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul class="calibre10">
<li class="calibre11">The scikit-learn guide to bagging classifiers: <a href="https://bit.ly/2zaq8lS" class="calibre9">https://bit.ly/2zaq8lS</a></li>
</ul>
<p class="calibre2"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bagging regressors</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">Bagging regressors are similar to bagging classifiers. They </span><span class="calibre5">train each regressor model on a random subset of the original training set and aggregate the predictions. Then, the aggregation averages over the iterations because the target variable is numeric. In the following recipe, we are going to showcase the implementation of a bagging regressor with bootstrap samples.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">We will import the required libraries,</span> <kbd class="calibre12">BaggingRegressor</kbd> and <kbd class="calibre12">DecisionTreeRegressor</kbd>, from <kbd class="calibre12">sklearn.ensemble</kbd> and <kbd class="calibre12">sklearn.tree</kbd> respectively:</p>
<pre class="calibre15">from sklearn.ensemble import BaggingRegressor<br class="title-page-name"/>from sklearn.tree import DecisionTreeRegressor</pre>
<p class="calibre2">We read our dataset, which is <kbd class="calibre12">bostonhousing.csv</kbd>, and look at the dimensions of the DataFrame:</p>
<pre class="calibre15">df_housingdata = pd.read_csv('bostonhousing.csv')<br class="title-page-name"/>df_housingdata.shape</pre>
<p class="calibre2">We now move on to creating our feature set and our target variable set.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol start="1" class="calibre14">
<li class="calibre11">We first separate our feature and response set. We will also split our data into training and testing subsets in the following code block:</li>
</ol>
<pre class="calibre18">X = df_housingdata.iloc[:,1:14]<br class="title-page-name"/>Y = df_housingdata.iloc[:,-1]<br class="title-page-name"/><br class="title-page-name"/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)</pre>
<ol start="2" class="calibre14">
<li class="calibre11">We will then create an instance of the <kbd class="calibre12">DecisionTreeClassifier</kbd><span> </span>class and pass it to the<span> </span><kbd class="calibre12">BaggingClassifier()</kbd> function:</li>
</ol>
<pre class="calibre18">dt_model = DecisionTreeRegressor()<br class="title-page-name"/>bag_dt_model = BaggingRegressor(dt_model, max_features=1.0, n_estimators=5, bootstrap=True, random_state=1, )</pre>
<ol start="3" class="calibre14">
<li class="calibre11">We will fit our model to the training dataset as follows:</li>
</ol>
<pre class="calibre18">bag_dt_model.fit(X_train, Y_train)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">We can see the model score in the following code block:</li>
</ol>
<pre class="calibre18">bag_dt_model.score(X_test, Y_test)</pre>
<ol start="5" class="calibre14">
<li class="calibre11">We use the <kbd class="calibre12">predict()</kbd> function and pass the test dataset to predict our target variable as follows:</li>
</ol>
<pre class="calibre18">predictedvalues = bag_dt_model.predict(X_test)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">We plot the scatter plot of our actual values and the predicted values of our target variable with the following code:</li>
</ol>
<pre class="calibre18">#We can plot the actuals and the predicted values <br class="title-page-name"/>plt.figure(figsize=(4, 4))<br class="title-page-name"/>plt.scatter(Y_test, predictedvalues)<br class="title-page-name"/>plt.xlabel('Actual')<br class="title-page-name"/>plt.ylabel('Predicted')<br class="title-page-name"/>plt.tight_layout()</pre>
<p class="calibre20">Executing the preceding code gives us the following scatter plot:</p>
<p class="CDPAlignCenter"><img class="aligncenter72" src="assets/efe7575b-b3c6-4059-8454-653ce7268e60.png"/></p>
<div class="packttip"><span>The <kbd class="calibre19">matplotlib.pyplot.tight_layout()</kbd> automatically adjusts the subplot parameters to create specified padding.</span></div>
<p class="calibre2"/>
<ol start="7" class="calibre14">
<li class="calibre11">We now change the <kbd class="calibre12">n_estimators</kbd> parameter to 30 in the following code and re-execute the steps from <em class="calibre23">Step 3</em> to <em class="calibre23">Step 6</em>:</li>
</ol>
<pre class="calibre18">bag_dt_model = BaggingRegressor(dt_model, max_features=1.0, n_estimators=30, bootstrap=True, random_state=1, )</pre>
<p class="calibre20">This gives us the following score:</p>
<p class="CDPAlignCenter"><img class="aligncenter73" src="assets/bbf118f9-2223-46e4-9f14-575e7f0f64c9.png"/></p>
<ol start="8" class="calibre14">
<li class="calibre11">The plot of the actual values against the predicted values looks as follows. This shows us that the values are predicted more accurately than in our previous case when we changed the value of the <kbd class="calibre12">n_estimator</kbd> parameter from <kbd class="calibre12">5</kbd> to <kbd class="calibre12">30</kbd>:</li>
</ol>
<p class="CDPAlignCenter"><img class="aligncenter74" src="assets/62df9a66-8da7-4b7d-b9e9-8389e017f331.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="calibre2">In <em class="calibre13">Step 1</em>, we separated the features and the target variable set. We also split our data into training and testing subsets. In <em class="calibre13">Step 2</em>, <span class="calibre5">we created a decision tree regressor model and passed it to the</span> <kbd class="calibre12"><span>BaggingRegressor()</span></kbd><span class="calibre5"> function. Note that we also passed the <kbd class="calibre12">n_estimator=5</kbd> parameter to the <kbd class="calibre12">BaggingRegressor()</kbd> function. As mentioned earlier, <kbd class="calibre12">n_estimator</kbd> is the number of trees in the forest we would like the algorithm to build. </span><span class="calibre5">In <em class="calibre13">Step 3</em>, we trained our model.</span></p>
<p class="calibre2"/>
<p class="calibre2">In <em class="calibre13">Step 4</em>, we looked at the model score, which was 0.71. In <em class="calibre13">Step 5</em>, we used the <kbd class="calibre12">predict()</kbd> function to predict our target variable for the test subset. After that, in <em class="calibre13">Step 6</em>, we plotted a scatterplot to explore the relationship between the actual target values and the predicted target values. </p>
<p class="calibre2">In <em class="calibre13">Step 7</em>, we changed the <kbd class="calibre12">n_estimator</kbd> parameter's value from <kbd class="calibre12">5</kbd> to <kbd class="calibre12">30</kbd> and re-built our model. This time, we noticed that the model score improved to 0.82. In <em class="calibre13">Step 8</em>, we plotted the actual and predicted values and saw that the correlation between the actual and predicted values was much better than our previous model, where we used <kbd class="calibre12">n_estimators=5</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul class="calibre10">
<li class="calibre11">The scikit-learn guide to bagging regressors: <a href="https://bit.ly/2pZFmUh" class="calibre9">https://bit.ly/2pZFmUh</a></li>
<li class="calibre11">Single estimator versus bagging: <a href="https://bit.ly/2q08db6" class="calibre9">https://bit.ly/2q08db6</a></li>
</ul>


            </article>

            
        </section>
    </body></html>