- en: Chapter 8. Detecting Shapes and Segmenting an Image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to learn about shape analysis and image segmentation.
    We will learn how to recognize shapes and estimate the exact boundaries. We will
    discuss how to segment an image into its constituent parts using various methods.
    We will learn how to separate the foreground from the background as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will know:'
  prefs: []
  type: TYPE_NORMAL
- en: What is contour analysis and shape matching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to match shapes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is image segmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to segment an image into its constituent parts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to separate the foreground from the background
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use various techniques to segment an image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contour analysis and shape matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Contour analysis is a very useful tool in the field of computer vision. We deal
    with a lot of shapes in the real world and contour analysis helps in analyzing
    those shapes using various algorithms. When we convert an image to grayscale and
    threshold it, we are left with a bunch of lines and contours. Once we understand
    the properties of different shapes, we will be able to extract detailed information
    from an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we want to identify the boomerang shape in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Contour analysis and shape matching](img/B04554_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to do that, we first need to know what a regular boomerang looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Contour analysis and shape matching](img/B04554_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now using the above image as a reference, can we identify what shape in our
    original image corresponds to a boomerang? If you notice, we cannot use a simple
    correlation based approach because the shapes are all distorted. This means that
    an approach where we look for an exact match won''t work! We need to understand
    the properties of this shape and match the corresponding properties to identify
    the boomerang shape. OpenCV provides a nice shape matcher function that we can
    use to achieve this. The matching is based on the concept of Hu moment, which
    in turn is related to image moments. You can refer to the following paper to learn
    more about moments: [http://zoi.utia.cas.cz/files/chapter_moments_color1.pdf](http://zoi.utia.cas.cz/files/chapter_moments_color1.pdf).
    The concept of "image moments" basically refers to the weighted and power-raised
    summation of the pixels within a shape.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Contour analysis and shape matching](img/B04554_08_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the above equation, **p** refers to the pixels inside the contour, **w**
    refers to the weights, **N** refers to the number of points inside the contour,
    **k** refers to the power, and **I** refers to the moment. Depending on the values
    we choose for w and k, we can extract different characteristics from that contour.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the simplest example is to compute the area of the contour. To do this,
    we need to count the number of pixels within that region. So mathematically speaking,
    in the weighted and power raised summation form, we just need to set w to 1 and
    k to 0\. This will give us the area of the contour. Depending on how we compute
    these moments, they will help us in understanding these different shapes. This
    also gives rise to some interesting properties that help us in determining the
    shape similarity metric.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we match the shapes, you will see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Contour analysis and shape matching](img/B04554_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at the code to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Approximating a contour
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A lot of contours that we encounter in real life are noisy. This means that
    the contours don't look smooth, and hence our analysis takes a hit. So how do
    we deal with this? One way to go about this would be to get all the points on
    the contour and then approximate it with a smooth polygon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the boomerang image again. If you approximate the contours
    using various thresholds, you will see the contours changing their shapes. Let''s
    start with a factor of 0.05:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Approximating a contour](img/B04554_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you reduce this factor, the contours will get smoother. Let''s make it 0.01:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Approximating a contour](img/B04554_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you make it really small, say 0.00001, then it will look like the original
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Approximating a contour](img/B04554_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Identifying the pizza with the slice taken out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The title might be slightly misleading, because we will not be talking about
    pizza slices. But let's say you are in a situation where you have an image containing
    different types of pizzas with different shapes. Now, somebody has taken a slice
    out of one of those pizzas. How would we automatically identify this?
  prefs: []
  type: TYPE_NORMAL
- en: 'We cannot take the approach we took earlier because we don''t know what the
    shape looks like. So we don''t have any template. We are not even sure what shape
    we are looking for, so we cannot build a template based on any prior information.
    All we know is the fact that a slice has been taken from one of the pizzas. Let''s
    consider the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying the pizza with the slice taken out](img/B04554_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It's not exactly a real image, but you get the idea. You know what shape we
    are talking about. Since we don't know what we are looking for, we need to use
    some of the properties of these shapes to identify the sliced pizza. If you notice,
    all the other shapes are nicely closed. As in, you can take any two points within
    those shapes and draw a line between them, and that line will always lie within
    that shape. These kinds of shapes are called **convex shapes**.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look at the sliced pizza shape, we can choose two points such that the
    line between them goes outside the shape as shown in the figure that follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying the pizza with the slice taken out](img/B04554_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So, all we need to do is detect the non-convex shape in the image and we''ll
    be done. Let''s go ahead and do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the above code, you will see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying the pizza with the slice taken out](img/B04554_08_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Wait a minute, what happened here? It looks so cluttered. Did we do something
    wrong? As it turns out, the curves are not really smooth. If you observe closely,
    there are tiny ridges everywhere along the curves. So, if you just run your convexity
    detector, it''s not going to work. This is where contour approximation comes in
    really handy. Once we''ve detected the contours, we need to smoothen them so that
    the ridges do not affect them. Let''s go ahead and do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the preceding code, the output will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying the pizza with the slice taken out](img/B04554_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How to censor a shape?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say you are dealing with images and you want to block out a particular
    shape. Now, you might say that you will use shape matching to identify the shape
    and then just block it out, right? But the problem here is that we don''t have
    any template available. So, how do we go about doing this? Shape analysis comes
    in various forms, and we need to build our algorithm depending on the situation.
    Let''s consider the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to censor a shape?](img/B04554_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s say we want to identify all the boomerang shapes and then block them
    out without using any template images. As you can see, there are various other
    weird shapes in that image and the boomerang shapes are not really smooth. We
    need to identify the property that''s going to differentiate the boomerang shape
    from the other shapes present. Let''s consider the convex hull. If you take the
    ratio of the area of each shape to the area of the convex hull, we can see that
    this can be a distinguishing metric. This metric is called **solidity factor**
    in shape analysis. This metric will have a lower value for the boomerang shapes
    because of the empty area that will be left out, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to censor a shape?](img/B04554_08_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The black boundaries represent the convex hulls. Once we compute these values
    for all the shapes, how do separate them out? Can we just use a fixed threshold
    to detect the boomerang shapes? Not really! We cannot have a fixed threshold value
    because you never know what kind of shape you might encounter later. So, a better
    approach would be to use **K-Means clustering**. K-Means is an unsupervised learning
    technique that can be used to separate out the input data into K classes. You
    can quickly brush up on K-Means before proceeding further at [http://docs.opencv.org/master/de/d4d/tutorial_py_kmeans_understanding.html](http://docs.opencv.org/master/de/d4d/tutorial_py_kmeans_understanding.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'We know that we want to separate the shapes into two groups, that is, boomerang
    shapes and other shapes. So, we know what our *K* will be in K-Means. Once we
    use that and cluster the values, we pick the cluster with the lowest solidity
    factor and that will give us our boomerang shapes. Bear in mind that this approach
    works only in this particular case. If you are dealing with other kinds of shapes,
    then you will have to use some other metrics to make sure that the shape detection
    works. As we discussed earlier, it depends heavily on the situation. If you detect
    the shapes and block them out, it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to censor a shape?](img/B04554_08_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Following is the code to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: What is image segmentation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image segmentation is the process of separating an image into its constituent
    parts. It is an important step in many computer vision applications in the real
    world. There are many different ways of segmenting an image. When we segment an
    image, we separate the regions based on various metrics such as color, texture,
    location, and so on. All the pixels within each region have something in common,
    depending on the metric we are using. Let's take a look at some of the popular
    approaches here.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, we will be looking at a technique called **GrabCut**. It is
    an image segmentation method based on a more generic approach called **graph-cuts**.
    In the graph-cuts method, we consider the entire image to be a graph, and then
    we segment the graph based on the strength of the edges in that graph. We construct
    the graph by considering each pixel to be a node and edges are constructed between
    the nodes, where edge weight is a function of the pixel values of those two nodes.
    Whenever there is a boundary, the pixel values are higher. Hence, the edge weights
    will also be higher. This graph is then segmented by minimizing the Gibss energy
    of the graph. This is analogous to finding the maximum entropy segmentation. You
    can refer to the original paper to learn more about it at [http://cvg.ethz.ch/teaching/cvl/2012/grabcut-siggraph04.pdf](http://cvg.ethz.ch/teaching/cvl/2012/grabcut-siggraph04.pdf).
    Let''s consider the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What is image segmentation?](img/B04554_08_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s select the region of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What is image segmentation?](img/B04554_08_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the image has been segmented, it will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What is image segmentation?](img/B04554_08_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Following is the code to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: How does it work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start with the seed points specified by the user. This is the bounding box
    within which we have the object of interest. Underneath the surface, the algorithm
    estimates the color distribution of the object and the background. The algorithm
    represents the color distribution of the image as a **Gaussian Mixture Markov
    Random Field** (**GMMRF**). You can refer to the detailed paper to learn more
    about GMMRF at [http://research.microsoft.com/pubs/67898/eccv04-GMMRF.pdf](http://research.microsoft.com/pubs/67898/eccv04-GMMRF.pdf).
    We need the color distribution of both, the object and the background, because
    we will be using this knowledge to separate the object. This information is used
    to find the maximum entropy segmentation by applying the min-cut algorithm to
    the Markov Random Field. Once we have this, we use the graph cuts optimization
    method to infer the labels.
  prefs: []
  type: TYPE_NORMAL
- en: Watershed algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenCV comes with a default implementation of the watershed algorithm. It's
    pretty famous and there are a lot of implementations available out there. You
    can read more about it at [http://docs.opencv.org/master/d3/db4/tutorial_py_watershed.html](http://docs.opencv.org/master/d3/db4/tutorial_py_watershed.html).
    Since you already have access to the OpenCV source code, we will not be looking
    at the code here.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will just see what the output looks like. Consider the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Watershed algorithm](img/B04554_08_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s select the regions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Watershed algorithm](img/B04554_08_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you run the watershed algorithm on this, the output will look something
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Watershed algorithm](img/B04554_08_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about contour analysis and image segmentation. We
    learned how to match shapes based on a template. We learned about the various
    different properties of shapes and how we can use them to identify different kinds
    of shapes. We discussed image segmentation and how we can use graph-based methods
    to segment regions in an image. We briefly discussed watershed transformation
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to discuss how to track an object in a live
    video.
  prefs: []
  type: TYPE_NORMAL
