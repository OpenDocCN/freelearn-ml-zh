- en: <st c="0">3</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2">Transforming Numerical Variables</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="34">The statistical methods that are used in data analysis make certain
    assumptions about the data.</st> <st c="131">For example, in the general linear
    model, it is assumed that the values of the dependent variable (the target) are
    independent, that there is a linear relationship between the target and the independent
    (predictor) variables, and that the residuals – that is, the difference between
    the predictions and the real values of the target – are normally distributed and
    centered at</st> `<st c="507">0</st>`<st c="508">. When these assumptions are
    not met, the resulting probabilistic statements might not be accurate.</st> <st
    c="608">To correct for failure in the assumptions and thus improve the performance
    of the models, we can transform variables before</st> <st c="732">the analysis.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="745">When we transform a variable, we replace its original values with
    a function of that variable.</st> <st c="841">Transforming variables with mathematical
    functions helps reduce variable skewness, improves the value spread, and sometimes
    unmasks linear and additive relationships between predictors and the target.</st>
    <st c="1042">Commonly used mathematical transformations include the logarithm,
    reciprocal, power, and square and cube root transformations, as well as the Box-Cox
    and Yeo-Johnson transformations.</st> <st c="1225">This set of transformations</st>
    <st c="1253">is commonly referred</st> <st c="1273">to as</st> **<st c="1280">variance
    stabilizing transformations</st>**<st c="1316">. Variance stabilizing transformations
    intend to bring the distribution of the variable to a more symmetric – that is,
    Gaussian – shape.</st> <st c="1453">In this chapter, we will discuss when to use
    each transformation and then implement them using NumPy, scikit-learn,</st> <st
    c="1569">and Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1588">This chapter contains the</st> <st c="1615">following recipes:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1633">Transforming variables with the</st> <st c="1666">logarithm function</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1684">Transforming variables with the</st> <st c="1717">reciprocal function</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1736">Using the square root to</st> <st c="1762">transform variables</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1781">Using</st> <st c="1788">power transformations</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1809">Performing</st> <st c="1821">Box-Cox transformatio</st><st c="1842">ns</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1845">Performing</st> <st c="1857">Yeo-Johnson transformatio</st><st
    c="1882">ns</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="1885">Transforming variables with the logarithm function</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1936">The</st> <st c="1940">logarithm function is a</st> <st c="1964">powerful
    transformation for dealing with positive data wi</st><st c="2022">th a right-skewed
    distribution (observations accumulate at lower values of the variable).</st> <st
    c="2113">A comm</st><st c="2119">on example is the</st> `<st c="2138">income</st>`
    <st c="2144">variable, with a heavy accumulation of values toward lower salaries.</st>
    <st c="2214">The logarithm transformation has a strong effect on the shape of
    the</st> <st c="2283">variable distribution.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2305">In this</st> <st c="2314">recipe, we will perform logarithmic transformation
    using NumPy, scikit-learn, and Feature-engine.</st> <st c="2412">We will also
    create a diagnostic plot function to evaluate the effect of the transformation
    on the</st> <st c="2511">variable distributi</st><st c="2530">on.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2534">Getting ready</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="2548">To evaluate the variable distribution and understand whether a
    transformation improves value spread and stabilizes the variance, we can visually
    inspect the data w</st><st c="2712">ith histograms and</st> **<st c="2732">Quantile-Quantile</st>**
    <st c="2749">(</st>**<st c="2751">Q-Q</st>**<st c="2754">) plots.</st> <st c="2764">A
    Q-Q plot helps us determine whether two</st> <st c="2805">variables show a similar
    distribution.</st> <st c="2845">In a Q-Q plot, we plot the quantiles of one variable
    against the quantiles of the second variable.</st> <st c="2944">If we plot the
    quantiles of the variable of interest against the expected quantiles of the normal
    distribution, then we can determine whether our variable is also normally distributed.</st>
    <st c="3129">If the variable is normally distributed, the points in the Q-Q plot
    will fall along a</st> <st c="3215">45-degree diagonal.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3234">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3239">A quantile is the value below which there is a certain fraction
    of data points in the distribution.</st> <st c="3340">Thus, the 20th quantile
    is the point in the distribution at which 20% of the observations fall below and
    80% above</st> <st c="3455">that va</st><st c="3462">lue.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3467">How to do it...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="3483">Let’s b</st><st c="3491">egin</st> <st c="3496">by importing the
    libr</st><st c="3518">aries and getting the</st> <st c="3541">dataset ready:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3555">Import the required Python libraries</st> <st c="3593">and dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="3758">Let’s</st> <st c="3764">load the California housing dataset into
    a</st> <st c="3808">pandas DataFrame:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="3889">Let’s explore the distributions of all the variables in the dataset
    by plotting histograms</st> <st c="3981">with pandas:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="4038">In the following output, we can see that the</st> `<st c="4084">MedInc</st>`
    <st c="4090">variable shows</st> <st c="4106">a mild right-skewed distribution,
    var</st><st c="4143">iables such as</st> `<st c="4159">AveRooms</st>` <st c="4167">and</st>
    `<st c="4172">Population</st>` <st c="4182">are heavily right-skewed, and the</st>
    `<st c="4217">HouseAge</st>` <st c="4225">variable shows an even spread of values
    across</st> <st c="4273">its</st> <st c="4277">range:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="4283">figure 3</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Histograms with the distribution of the numerical variables](img/B22396_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="4684">Figure 3.1 – Histograms with the distribution of the numerical
    variables</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4756">To</st> <st c="4760">evaluate</st> <st c="4768">the effect of the
    transformation on the variable distribution</st><st c="4830">, we’ll create a
    f</st><st c="4848">unction that takes a DataFrame and a variable name as inputs
    and plots a histogram next to a</st> <st c="4942">Q-Q plot:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="5221">Let’s</st> <st c="5228">plot the</st> <st c="5236">distribution
    of the</st> `<st c="5257">MedInc</st>` <st c="5263">variable with the function
    from</st> *<st c="5296">step 4</st>*<st c="5302">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="5334">The following output shows that</st> `<st c="5367">MedInc</st>`
    <st c="5373">has a</st> <st c="5380">right-skewed distr</st><st c="5398">ibution:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.2 – A histogram and Q-Q plot of the MedInc variable](img/B22396_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="5547">Figure 3.2 – A histogram and Q-Q plot of the MedInc variable</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5607">Now, let’s transform the data with</st> <st c="5643">the logarithm:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5657">Firs</st><st c="5662">t, let’s mak</st><st c="5675">e a copy of
    the</st> <st c="5692">original DataFrame:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="5727">We’ve</st> <st c="5734">created a copy so that we can modify the
    values in the copy and not in the original DataFrame, which we need for the rest
    of</st> <st c="5859">this recipe.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="5871">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5876">If we execute</st> `<st c="5891">X_tf = X</st>` <st c="5899">instead
    of using pandas’</st> `<st c="5925">copy()</st>`<st c="5931">function,</st> `<st
    c="5942">X_tf</st>` <st c="5946">will not be a copy of the DataFrame; instead,
    it will be another view of the same data.</st> <st c="6035">Therefore, changes
    made in</st> `<st c="6062">X_tf</st>` <st c="6066">will be reflected in</st> `<st
    c="6088">X</st>` <st c="6089">as well.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6097">Let’s</st> <st c="6104">make a list with the variables that we
    want</st> <st c="6148">to transform:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="6219">Let’s apply the logarithmic transformation with NumPy to the variables
    from</st> *<st c="6296">step 7</st>* <st c="6302">a</st><st c="6304">nd capture
    the transformed variables in the</st> <st c="6348">new DataFrame:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="6391">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6396">Remember that the logarithm transformation can only be applied
    to strictly positive variables.</st> <st c="6492">If the variables have zero or
    negative values, sometimes, it is useful to add a constant to make those values
    positive.</st> <st c="6612">We could add a constant value of</st> `<st c="6645">1</st>`
    <st c="6647">using</st> `<st c="6653">X_tf[vars] = np.log(X[vars] +</st>` `<st
    c="6683">1)</st>`<st c="6685">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6686">Let’s check the distribution of</st> `<st c="6719">MedInc</st>`
    <st c="6725">after the transformation with the diagnostic function from</st> *<st
    c="6785">step 4</st>*<st c="6791">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="6826">In the following output, we can see that the logarithmic transformation
    returned a more evenly distributed variable that better approximates the theoretical
    normal distribution in the</st> <st c="7011">Q-Q plot:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 3.3 – A histogram and Q-Q plot of the MedInc variable after the logarithm\
    \ transformation\uFEFF](img/B22396_03_03.jpg)"
  prefs: []
  type: TYPE_IMG
- en: <st c="7187">Figure 3.3 – A histogram and Q-Q plot of the MedInc variable after
    the logarithm transformation</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7282">Go ahead</st> <st c="7292">an</st><st c="7294">d plot the other
    transformed variables to familiarize yourself with the effect of the logarithm
    transformation</st> <st c="7406">on distributions.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7423">Now, let’s</st> <st c="7435">apply the logarithmic transformation</st>
    <st c="7472">with</st> `<st c="7477">scikit-learn</st>`<st c="7489">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7490">Let’s</st> <st c="7497">import</st> `<st c="7504">FunctionTransformer()</st>`<st
    c="7525">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="7581">Before we proceed, we need to take a copy of the original dataset,
    as we did in</st> *<st c="7662">step 6</st>*<st c="7668">.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="7669">We’ll set up the transformer to apply the logarithm and to be able
    to revert the transformed variable to its</st> <st c="7779">original representation:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="7866">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7871">If we set up</st> `<st c="7885">FunctionTransformer()</st>` <st
    c="7906">with the default parameter,</st> `<st c="7935">validate=False</st>`<st
    c="7949">, we don’t need to fit the transformer before transforming the data.</st>
    <st c="8018">If we set</st> `<st c="8028">validate</st>` <st c="8036">to</st>
    `<st c="8040">True</st>`<st c="8044">, the transformer will check the data input
    to the</st> `<st c="8095">fit</st>` <st c="8098">method.</st> <st c="8107">The
    latter is useful when fitting the transformer with a DataFrame so that it learns
    and stores the</st> <st c="8207">variable n</st><st c="8217">ames.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8223">Let’s tr</st><st c="8232">ansform the positive variables from</st>
    *<st c="8269">step 7</st>*<st c="8275">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="8321">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8326">Scikit-learn transformers return NumPy arrays and transform the
    entire DataFrame by default.</st> <st c="8420">In this case, we assigned the results
    of the array directly to our existing DataFrame.</st> <st c="8507">We can change
    the returned format through the</st> `<st c="8553">set_output</st>` <st c="8563">method
    and we can restrict the variables to transform</st> <st c="8618">with</st> `<st
    c="8623">ColumnTransformer()</st>`<st c="8642">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8643">Check</st> <st c="8650">the results of the transformation</st>
    <st c="8683">with the diagnostic function from</st> *<st c="8718">step 4</st>*<st
    c="8724">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8725">Let’s now revert the transformation to the original</st> <st c="8778">variable
    representation:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="8857">If you check the distribution by executing</st> `<st c="8901">diagnostic_plots(X_tf,
    "MedInc")</st>`<st c="8933">, you should see a plot that is identical to that
    returned by</st> *<st c="8995">step 5</st>*<st c="9001">.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="9002">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="9007">To add a constant value to the variables, in case they are not
    strictly positive, use</st> `<st c="9094">transformer = FunctionTransformer(lambda
    x: np.log(x +</st>` `<st c="9149">1)</st><st c="9151">)</st>`<st c="9153">.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9154">Now, let’s apply the logarithm transformation</st> <st c="9201">with
    Feature-</st><st c="9214">engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9222">Let’s import</st> <st c="9236">the</st> `<st c="9240">LogTransformer()</st>`<st
    c="9256">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="9315">We’ll set up the transformer to transform the variables from</st>
    *<st c="9377">step 7</st>* <st c="9383">and then fit the transformer to</st> <st
    c="9416">the dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="9476">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9481">If the</st> `<st c="9489">variables</st>` <st c="9498">argument
    is left as</st> `<st c="9519">None</st>`<st c="9523">,</st> `<st c="9525">LogTransformer()</st>`
    <st c="9541">applies the logarithm to all the numerical variables found during</st>
    `<st c="9608">fit()</st>`<st c="9613">. Alternatively, we can indicate which variables
    to modify, as we did in</st> *<st c="9686">step 15</st>*<st c="9693">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9694">Finally, let’s</st> <st c="9709">transform</st> <st c="9719">the
    data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`<st c="9752">X_tf</st>` <st c="9757">is a copy of the</st> `<st c="9775">X</st>`
    <st c="9776">DataFrame, where the variables from</st> *<st c="9813">step 7</st>*
    <st c="9819">are transformed with</st> <st c="9841">the logarithm.</st>'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="9855">We can also revert</st> <st c="9875">the transformed variables
    to their</st> <st c="9910">original representation:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="9969">If you check the distribution of the variables after</st> *<st
    c="10023">step 17</st>*<st c="10030">, they should be identical to those of the</st>
    <st c="10073">original data.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="10087">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10092">Feature-engine has a dedicated transformer that adds constant
    values to the variables before the applying the logarithm transformation.</st>
    <st c="10229">Check the</st> *<st c="10239">There’s more…</st>* <st c="10252">section
    later in this recipe fo</st><st c="10284">r</st> <st c="10287">more details.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10300">How it works...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="10316">In this recipe, we applied the logarithm transformation to a subset
    of positive variables using NumPy, scikit-learn,</st> <st c="10434">and Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10453">To compare</st> <st c="10464">the effect of the transformation
    on the variable distribution, we created a diagnostic function to plot a histogram
    next to a Q-Q plot.</st> <st c="10601">To create the Q-Q plot, we used</st> `<st
    c="10633">scipy.stats.probplot()</st>`<st c="10655">, which plotted the quantiles
    of the variable of interest in the</st> *<st c="10720">y</st>* <st c="10721">axis
    versus the quantiles of a theoretical normal distribution, which we indicated
    by setting the</st> `<st c="10820">dist</st>` <st c="10824">parameter to</st>
    `<st c="10838">norm</st>` <st c="10842">in the</st> *<st c="10850">x</st>* <st
    c="10851">axis.</st> <st c="10858">We used</st> `<st c="10866">matplotlib</st>`
    <st c="10876">to display the plot by setting the</st> `<st c="10912">plot</st>`
    <st c="10916">parameter</st> <st c="10927">to</st> `<st c="10930">plt</st>`<st
    c="10933">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10934">With</st> `<st c="10940">plt.figure()</st>` <st c="10952">and</st>
    `<st c="10957">figsize</st>`<st c="10964">, we adjusted the size of the figure
    and, with</st> `<st c="11011">plt.subplot()</st>`<st c="11024">, we organized
    the two plots in</st> `<st c="11056">one</st>` <st c="11059">row with</st> `<st
    c="11069">two</st>` <st c="11072">columns – that is, one plot next to the other.</st>
    <st c="11120">The numbers within</st> `<st c="11139">plt.subplot()</st>` <st c="11152">indicated
    the number of rows, the number of columns, and the place of the plot in the figure,
    respectively.</st> <st c="11261">We placed the histogram in position 1 and the
    Q-Q plot in position 2 – that is, left and</st> <st c="11350">right, respe</st><st
    c="11362">ctively.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11371">To test the</st> <st c="11384">function, we plotted a histogram
    and a Q-Q plot for the</st> `<st c="11440">MedInc</st>` <st c="11446">variable
    before t</st><st c="11464">he transformation and observed that</st> `<st c="11501">MedInc</st>`
    <st c="11507">was not normally distributed.</st> <st c="11538">Most observations
    were at the left of the histogram and the values deviated from the 45-degree line
    in the Q-Q plot at both ends of</st> <st c="11670">the distribution.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11687">Next, using</st> `<st c="11700">np.log()</st>`<st c="11708">,
    we applied the logarithm to a slice of the DataFrame with four positive variables.</st>
    <st c="11793">To evaluate the effect of the transformation, we plotted a histogram
    and Q-Q plot of the transformed</st> `<st c="11894">MedInc</st>` <st c="11900">variable.</st>
    <st c="11911">We observed that, after the logarithm transformation, the values
    were more centered in the histogram and that, in the Q-Q plot, they only deviated
    from the 45-degree line toward the ends of</st> <st c="12101">the distribution.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12118">Next, we used the</st> `<st c="12137">FunctionTransformer()</st>`
    <st c="12158">from scikit-learn, which applies any user-defined function to a
    dataset.</st> <st c="12232">We passed</st> `<st c="12242">np.log()</st>` <st c="12250">as
    an argument to apply the logarithm transformation and NumPy’s</st> `<st c="12316">exp()</st>`
    <st c="12321">for the inverse transformation to</st> `<st c="12356">FunctionTransfomer()</st>`<st
    c="12376">. With the</st> `<st c="12387">transform()</st>` <st c="12398">method,
    we transformed a slice of the DataFrame with the positive variables by using the
    logarithm.</st> <st c="12499">With</st> `<st c="12504">inverse_transform()</st>`<st
    c="12523">, we reverted the variable values to their</st> <st c="12566">original
    representation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12590">Finally, we used Feature-engine’s</st> `<st c="12625">LogTransformer()</st>`
    <st c="12641">and specified the variables to transform in a list using the</st>
    `<st c="12703">variables</st>` <st c="12712">argument.</st> <st c="12723">With</st>
    `<st c="12728">fit()</st>`<st c="12733">, the transformer checked that the variables
    were numerical and positive, and with</st> `<st c="12816">transform()</st>`<st
    c="12827">, it applied</st> `<st c="12840">np.log()</st>` <st c="12848">under
    the hood to transform the selected variables.</st> <st c="12901">With</st> `<st
    c="12906">inverse_transform()</st>`<st c="12925">, we reverted the transformed
    variables to their</st> <st c="12974">original</st> <st c="12982">representations.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12999">There’s more…</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="13013">Feature-engine has a</st> <st c="13034">dedicated</st> <st c="13044">transformer
    for adding a constant</st> <st c="13078">value to variables that are not strictly
    positive, before applying the logarithm:</st> `<st c="13161">LogCpTransformer()</st>`<st
    c="13179">.</st> `<st c="13181">LogCpTransformer()</st>` <st c="13199">can:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13204">Add the same constant to</st> <st c="13230">all variables</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="13243">Automatically identify and add the minimum value required to make
    the</st> <st c="13314">variables positive</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="13332">Add different values defined by the user to</st> <st c="13377">different
    variables.</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="13397">You can find a code implementation of</st> `<st c="13436">LogCpTransformer()</st>`
    <st c="13454">in this book’s GitHub</st> <st c="13477">repository:</st> [<st c="13489">https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch03-variable-transformation/Recipe-1-logarithmic-t</st><st
    c="13635">ransformation.ipynb</st>](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch03-variable-transformation/Recipe-1-logarithmic-transformation.ipynb)
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13655">Transforming variables with the reciprocal function</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="13707">The reciprocal function</st> <st c="13731">is defined as 1/x</st><st
    c="13749">. It is often useful when we have rati</st><st c="13787">os – that is,
    values resulting from the division of two variables.</st> <st c="13855">Examples
    of</st> <st c="13867">this are</st> **<st c="13876">population density</st>**
    <st c="13894">– that is, people per area – and, as we will see in this recipe,</st>
    **<st c="13960">house occupancy</st>** <st c="13975">– that is, the</st> <st c="13990">number
    of occupants</st> <st c="14011">per house.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14021">The reciprocal</st> <st c="14036">transformation is not defined
    for the</st> `<st c="14075">0</st>` <st c="14076">value, and although it is defined
    for negative values, it is mainly useful for transforming</st> <st c="14169">positive
    variables.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14188">In this recipe, we will implement the reciprocal transformation
    using</st> `<st c="14259">NumPy</st>`<st c="14264">,</st> `<st c="14266">scikit-learn</st>`<st
    c="14278">, and</st> `<st c="14284">Feature-engine</st>`<st c="14298">, and compare
    its effect on variable distribution using his</st><st c="14357">tograms and a</st>
    <st c="14372">Q-Q plot</st><st c="14380">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14381">How to do it...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="14397">Let’s</st> <st c="14403">begin by</st> <st c="14413">importing
    the libraries and getting the</st> <st c="14453">dataset ready:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14467">Import the required Python libraries</st> <st c="14505">and data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="14667">Let’s load</st> <st c="14678">the California</st> <st c="14694">housing
    dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="14774">To evaluate variable distributions, we’ll create a function that
    takes a DataFrame and a variable name as inputs and plots a histogram next to
    a</st> <st c="14920">Q-Q plot:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="15199">Now, le</st><st c="15207">t’s plot the distribution of the</st>
    `<st c="15240">AveOccup</st>` <st c="15249">variable, which specifies the average
    occupancy of</st> <st c="15301">the house:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="15343">The</st> `<st c="15348">AveOccup</st>` <st c="15356">variable</st>
    <st c="15366">shows a very strong</st> <st c="15385">right-skewed distribution,
    as show</st><st c="15420">n in the</st> <st c="15430">following output:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.4 – A histogram and Q-Q plot of the AveOccup variable](img/B22396_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="15699">Figure 3.4 – A histogram and Q-Q plot of the AveOccup variable</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15761">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15766">Th</st><st c="15769">e</st> `<st c="15772">AveOccup</st>` <st
    c="15780">variable</st> <st c="15789">refers to the average number of household
    members – that is, the ratio between t</st><st c="15870">he number of people and
    the nu</st><st c="15901">mber of houses in a certain area.</st> <st c="15936">This
    is a promising variable for a reciprocal transformation.</st> <st c="15998">You
    can find more details about the variables and the dataset by executing</st> `<st
    c="16073">data = fetch_california_housing()</st>` <st c="16106">followed</st>
    <st c="16116">by</st> `<st c="16119">print(data.DESCR)</st>`<st c="16136">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16137">Now, let’s apply the reciprocal transformation</st> <st c="16185">with
    NumPy.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16196">First, let’s make a copy of the original DataFrame so that we
    can modify the values in</st> <st c="16283">the copy and not in the original one,
    which we will need for the rest of</st> <st c="16357">this recipe:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="16385">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16390">Remember that executing</st> `<st c="16415">X_tf = X</st>` <st
    c="16423">instead of using pandas’</st> `<st c="16449">copy()</st>` <st c="16455">creates
    an additional view of the same data.</st> <st c="16501">Therefore, changes that
    are made in</st> `<st c="16537">X_tf</st>` <st c="16541">will be r</st><st c="16551">eflected
    in</st> `<st c="16564">X</st>` <st c="16565">as well</st><st c="16572">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16573">Let’s</st> <st c="16579">apply the reciprocal transformation to
    the</st> `<st c="16623">AveOccup</st>` <st c="16631">variable:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="16692">Let’s check the distribution of the</st> `<st c="16729">AveOccup</st>`
    <st c="16737">variable after the transformation with the diagnostic function we
    created in</st> *<st c="16815">step 3</st>*<st c="16821">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="16858">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16863">After the transformation,</st> `<st c="16890">AveOccup</st>` <st
    c="16898">is now the ratio of the number of houses and the number of people in
    a certain area – in other words, houses</st> <st c="17008">per citizen.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17020">Here, we can see a dramatic change in the distribution of the</st>
    `<st c="17083">AveOccup</st>` <st c="17091">variable after th</st><st c="17109">e</st>
    <st c="17112">reciprocal transformation:</st>
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 3.5 – A histogram and Q-Q plot of the AveOccup variable after the\
    \ reciproc\uFEFFal transfo\uFEFFrmation](img/B22396_03_05.jpg)"
  prefs: []
  type: TYPE_IMG
- en: <st c="17309">Figure 3.5 – A histogram and Q-Q plot of the AveOccup variable
    after the reciproc</st><st c="17390">al transfo</st><st c="17401">rmation</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17409">Now, let’s apply</st> <st c="17427">the reciprocal transformation</st>
    <st c="17457">with</st> `<st c="17462">scikit-learn</st>`<st c="17474">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17475">Let’s import</st> <st c="17489">the</st> `<st c="17493">FunctionTransformer()</st>`<st
    c="17514">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="17570">Let’s set up the transformer by passing</st> `<st c="17611">np.reciprocal</st>`
    <st c="17624">as</st> <st c="17628">an argument:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="17689">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17694">By default,</st> `<st c="17707">FunctionTransformer()</st>` <st
    c="17728">does not need to be fit before tran</st><st c="17764">sforming</st>
    <st c="17774">the data.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17783">Now, let’s</st> <st c="17795">make a copy of the orig</st><st
    c="17818">inal dataset and transform</st> <st c="17846">the variable:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="17932">You can check the effect of the transformation using the function
    from</st> *<st c="18004">step 3</st>*<st c="18010">.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="18011">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18016">The inverse transformation of the reciprocal function is also
    the reciprocal function.</st> <st c="18104">Hence, if you re-apply</st> `<st c="18127">transform()</st>`
    <st c="18138">to the transformed data, you will revert it to its original representation.</st>
    <st c="18215">A better practice would be to set the</st> `<st c="18253">inverse_transform</st>`
    <st c="18270">parameter of the</st> `<st c="18288">FunctionTransformer()</st>`
    <st c="18309">to</st> `<st c="18313">np.reciprocal</st>` <st c="18326">as well.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18335">Now, let’s apply</st> <st c="18352">the reciprocal transformation</st>
    <st c="18383">with</st> `<st c="18388">feature-engine</st>`<st c="18402">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18403">Let’s import</st> <st c="18417">the</st> `<st c="18421">ReciprocalTransformer()</st>`<st
    c="18444">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="18510">Let’s set up the transformer to modify the</st> `<st c="18554">AveOccup</st>`
    <st c="18562">variable and then fit it to</st> <st c="18591">the dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="18662">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18667">If the</st> `<st c="18675">variables</st>` <st c="18684">argument
    is set to</st> `<st c="18704">None</st>`<st c="18708">, the transformer applies
    the reciprocal function to</st> *<st c="18761">all the numerical variables</st>*
    <st c="18788">in the dataset.</st> <st c="18805">If some of the variables contain
    a</st> `<st c="18840">0</st>` <st c="18841">value, the transfo</st><st c="18860">rmer
    will rais</st><st c="18875">e</st> <st c="18878">an error.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18887">Let’s</st> <st c="18893">transform the selected variable in</st>
    <st c="18929">our dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`<st c="18964">ReciprocalTransformer()</st>` <st c="18988">will return a new
    pandas DataFrame containing the original variables, where the variable indicated
    in</st> *<st c="19091">step 12</st>* <st c="19098">is transform</st><st c="19111">ed
    with the</st> <st c="19124">reciprocal function.</st>'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="19144">How it works...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="19160">In this recipe, we applied the reciprocal transformation using
    NumPy, scikit-learn,</st> <st c="19245">and Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19264">To evaluate the variable distribution, we used the function to
    plot a histogram next to a Q-Q plot that we described in the</st> *<st c="19389">How
    it works…</st>* <st c="19402">section of the</st> *<st c="19418">Transforming
    variables with the logarithm function</st>* <st c="19468">recipe earlier in</st>
    <st c="19487">this chapter.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19500">We plotted the histogram and Q-Q plot of the</st> `<st c="19546">AveOccup</st>`
    <st c="19554">variable, which showed a heavy right-skewed distribution; most of
    its values were at the left of the histogram and they deviated from the 45-degree
    line toward the right end of the distribution in the</st> <st c="19756">Q-Q plot.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19765">To carry out the</st> <st c="19783">reciprocal transformation,
    we applied</st> `<st c="19821">np.reciprocal()</st>` <st c="19836">to the variable.</st>
    <st c="19854">After the transformation,</st> `<st c="19880">AveOccup</st>`<st
    c="19888">’s va</st><st c="19894">lues were more evenly d</st><st c="19918">istributed
    across the value range and followed the theoretical quantiles of the normal distribution
    in the Q-Q plot</st> <st c="20035">more closely.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20048">Next, we used</st> `<st c="20063">np.reciprocal()</st>` <st c="20078">with
    scikit-learn’s</st> `<st c="20099">FunctionTransformer()</st>`<st c="20120">.
    The</st> `<st c="20126">transform()</st>` <st c="20137">method applied</st> `<st
    c="20153">np.reciprocal()</st>` <st c="20168">to</st> <st c="20172">the dataset.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20184">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20189">To restrict the effect of</st> `<st c="20216">FunctionTransformer()</st>`
    <st c="20237">to a group of variables, use the</st> `<st c="20271">ColumnTransformer()</st>`<st
    c="20290">. To change the output to a pandas DataFrame, set the transform output</st>
    <st c="20361">to pandas.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20371">Finally, we</st> <st c="20383">used Feature-engine’s</st> `<st
    c="20406">ReciprocalTransformer()</st>` <st c="20429">to specifically modify one
    variable.</st> <st c="20467">With</st> `<st c="20472">fit()</st>`<st c="20477">,
    the transformer checked that the variable was numerical.</st> <st c="20536">With</st>
    `<st c="20541">transform()</st>`<st c="20552">, the transformer applied</st> `<st
    c="20578">np.reciprocal()</st>` <st c="20593">under the hood to transform</st>
    <st c="20622">the variable.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20635">Feature-engine’s</st> `<st c="20653">ReciprocalTransformer()</st>`
    <st c="20676">provides functionality to revert the variable to its original representation
    out of the box via the</st> `<st c="20777">inverse_transform()</st>` <st c="20796">method.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20804">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20809">Using the transformers from scikit-learn or Feature-engine, instead
    of NumPy’s</st> `<st c="20889">reciprocal()</st>` <st c="20901">function, allows
    us to apply the reciprocal function as an additional step of a feature engineering
    pipeline within the</st> `<st c="21022">Pipeline</st>` <st c="21030">object</st>
    <st c="21038">from scikit-learn.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21056">The difference</st> <st c="21072">between</st> `<st c="21080">FunctionTransformer()</st>`
    <st c="21101">and</st> `<st c="21106">ReciprocalTransformer()</st>` <st c="21129">is
    that the first one can apply any user-specified transformation, whereas the latter
    only applies the reciprocal function.</st> <st c="21254">scikit-learn returns
    NumPy arrays by default and transforms all variables in the dataset.</st> <st
    c="21344">Feature-engine’s transformer, on the other hand, returns pandas DataFrames
    and can modif</st><st c="21432">y subsets of variables within the data</st> <st
    c="21471">without using</st> <st c="21486">additional classes.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21505">Using the square root to transform variables</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="21550">The</st> <st c="21554">square root transformation,</st> **<st
    c="21583">√x</st>**<st c="21585">, as well as its variations, the Anscombe transformation,</st>
    **<st c="21643">√(x+3/8)</st>**<st c="21651">, and the Freeman-Tukey transf</st><st
    c="21681">ormation,</st> **<st c="21692">√x + √(x+1)</st>**<st c="21703">, are
    variance stabilizing transformations that transform a variable with a P</st><st
    c="21780">oisson distribution into one with an approximately standard Gaussian
    distribution.</st> <st c="21864">The square root transformation is a form of power
    transformation where the exponent is</st> **<st c="21951">1/2</st>** <st c="21954">and
    is only defined for</st> <st c="21979">positive values.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21995">The</st> <st c="21999">Poisson distribution is a probability distribution
    that indicates the number of times an event is likely to occur.</st> <st c="22115">In
    other words, it is a count distribution.</st> <st c="22159">It is right-skewed
    and its variance equals its mean.</st> <st c="22212">Examples of variables that
    could follow a Poisson distribution are the number of financial items of a customer,
    such as the number of current accounts or credit cards, the number of passengers
    in a vehicle, and the number of occupants in</st> <st c="22450">a household.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22462">In this recipe, we will implement square root transformations
    using Num</st><st c="22534">Py, scikit-learn,</st> <st c="22553">and Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22572">How to do it...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="22588">We’ll start</st> <st c="22601">by creating a dataset with two
    variables whose values are drawn from a</st> <st c="22672">Poisson distribution:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22693">Let’s begin by importing the</st> <st c="22723">necessary libraries:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="22810">Let’s</st> <st c="22817">create a DataFrame with two variables
    drawn from a Poisson distribution with mean values of</st> `<st c="22909">2</st>`
    <st c="22910">and</st> `<st c="22915">3</st>`<st c="22916">, respectively, and</st>
    `<st c="22936">10000</st>` <st c="22941">observations:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="23079">Let’s create a function that takes a</st> <st c="23117">DataFrame
    and a variab</st><st c="23139">le name as inputs and plots a bar graph with the
    number of observations per value next to a</st> <st c="23232">Q-Q plot:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="23537">Let’s create a bar plot and a Q-Q plot for one of the variables
    in the data using the function from</st> *<st c="23638">step 3</st>*<st c="23644">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="23678">Here, we can see t</st><st c="23697">he Poisson distribution in</st>
    <st c="23725">the output:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 3.6 – The bar and Q-Q pl\uFEFFots of the counts1 variable](img/B22396_03_06.jpg)"
  prefs: []
  type: TYPE_IMG
- en: <st c="23866">Figure 3.6 – The bar and Q-Q pl</st><st c="23897">ots of the counts1
    variable</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23925">Now, let’s</st> <st c="23937">make a copy of</st> <st c="23952">the</st>
    <st c="23955">dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="23982">Let’s apply the</st> <st c="23998">square root transformation
    to</st> <st c="24029">both variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="24112">Let’s round the values to two decimals for a</st> <st c="24158">nicer
    visualization:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="24254">Let’s plot the distribution of</st> `<st c="24286">counts1</st>`
    <st c="24293">after</st> <st c="24300">the transformation:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="24354">We see a more</st> **<st c="24369">stabilized</st>** <st c="24379">variance,
    as the dots in the Q-Q plot foll</st><st c="24422">ow the 45-degree diagonal</st>
    <st c="24449">more closely:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 3.7 – The bar and Q-Q plots of the counts1 variable after th\uFEFF\
    e square root transformation](img/B22396_03_07.jpg)"
  prefs: []
  type: TYPE_IMG
- en: <st c="24667">Figure 3.7 – The bar and Q-Q plots of the counts1 variable after
    th</st><st c="24734">e square root transformation</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24763">Now, let’s</st> <st c="24775">apply the square root</st> <st c="24796">transformation</st>
    <st c="24812">with</st> `<st c="24817">scikit-learn</st>`<st c="24829">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24830">Let’s import</st> `<st c="24844">FunctionTransformer()</st>` <st
    c="24865">and set up it to perform a square</st> <st c="24900">root transformation:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="25049">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25054">If we wanted to round the values as we did in</st> *<st c="25101">step
    7</st>*<st c="25107">, we can set up the transformer using</st> `<st c="25145">transformer
    = FunctionTransformer(func=lambda x:</st>` `<st c="25194">np.round(np.sqrt(x),
    2))</st>`<st c="25218">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25219">Let’s make a copy of the data and transform</st> <st c="25264">the
    variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="25330">Go ahead and check the result of the transformation as we did
    in</st> *<st c="25396">step 8</st>*<st c="25402">.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="25403">To apply</st> <st c="25412">the square root with Feature-engine
    instead, we use the</st> `<st c="25469">PowerTransformer()</st>` <st c="25487">with
    an exponent</st> <st c="25505">of 0.5:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="25607">Next, we</st> <st c="25617">fit the transformer to</st> <st c="25640">the
    data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="25664">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25669">The transformer automatically identifies the numerical variables,
    which we can explore by</st> <st c="25760">executing</st> `<st c="25770">root_t.variables_</st>`<st
    c="25787">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25788">Finally, let’s transform</st> <st c="25814">the data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`<st c="25852">PowerTransformer()</st>` <st c="25871">returns a panda</st><st
    c="25887">s DataFrame with the</st> <st c="25909">transformed variables.</st>'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="25931">How it works…</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="25945">In this recipe, we applied the square root transformation using
    NumPy, scikit-learn,</st> <st c="26031">and Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26050">We used NumPy’s</st> `<st c="26067">sqrt()</st>` <st c="26073">function
    either directly or within scikit-learn’s</st> `<st c="26124">FunctionTrasnformer()</st>`
    <st c="26145">to determine the variables’ square root.</st> <st c="26187">Alternatively,
    we used Feature-engine’s</st> `<st c="26227">PowerTransformer()</st>`<st c="26245">,
    setting the exponent to 0.5, that of the square root function.</st> <st c="26310">NumPy
    modified the variables directly.</st> <st c="26349">The transformers of scikit-learn
    and Feature-engine modified the var</st><st c="26417">iables when calling the</st>
    `<st c="26442">transform()</st>` <st c="26453">method.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26461">Using power transformations</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="26489">Power functions</st> <st c="26506">are mathematical transformations
    that follow the</st> ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>X</mi><mi>t</mi></msub><mo>=</mo><msup><mi>X</mi><mrow><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></mrow></msup></mrow></mrow></math>](img/15.png)
    <st c="26555"><st c="26562">format, where lambda can take any value.</st> <st
    c="26603">The square and</st> <st c="26617">cube root transformations are special
    cases of power transformations where lambda is 1/2 or 1/3, respectively.</st>
    <st c="26729">The challenge resides in finding the value for the lambda parameter.</st>
    <st c="26798">The Box-Cox transformation, which</st> <st c="26831">is a generalization
    of the power transformations, finds the optimal lambda value via maximum likelihood.</st>
    <st c="26937">We will discuss the Box-Cox transformation in the following recipe.</st>
    <st c="27005">In practice, we will try different lambda values and visually inspect
    the variable distribution to determine which one offers the best transformation.</st>
    <st c="27156">In general, if the data is right-skewed – that is, if observations
    accumulate toward lower values – we use a lambda value that is smaller than 1,
    while if the data is left-skewed – that is, there are more observations around
    higher values – then we use a lambda value that is greater</st> <st c="27440">than
    1.</st></st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27447">In this recipe, we will carry out power transformations u</st><st
    c="27505">sing NumPy, scikit-learn,</st> <st c="27532">an</st><st c="27534">d
    Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27552">How to do it...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="27568">Let’s begin by importing</st> <st c="27594">the libraries and
    getting the</st> <st c="27624">dataset ready:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27638">Import the required Python libraries</st> <st c="27676">and classes:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="27894">Let’s load the California housing dataset into a</st> <st c="27944">pandas
    DataFrame:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="28026">To evaluate variable distributions, we’ll create a function that
    takes a DataFrame and a</st> <st c="28115">variable name as inputs and plots a
    histogram next to a</st> <st c="28172">Q-Q plot:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="28451">Let’s plot the distribution of the</st> `<st c="28487">Population</st>`
    <st c="28497">variable with the</st> <st c="28516">previous function:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="28568">In the plots returned by the previous command, we can see t</st><st
    c="28628">hat</st> `<st c="28633">Population</st>` <st c="28643">is heavily skewed
    to</st> <st c="28665">the right:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 3.8 – A histogram and \uFEFFQ-Q plot of the Population variable](img/B22396_03_08.jpg)"
  prefs: []
  type: TYPE_IMG
- en: <st c="28903">Figure 3.8 – A histogram and</st> <st c="28932">Q-Q plot of the
    Population variable</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28967">Now, let’s</st> <st c="28979">apply a power transformation to
    the</st> `<st c="29015">MedInc</st>` <st c="29021">and</st> `<st c="29026">Population</st>`
    <st c="29036">variables.</st> <st c="29048">As both are skewed to the right, an
    exponent smaller than</st> *<st c="29106">1</st>* <st c="29107">might return a
    better spread of the</st> <st c="29144">variable values.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29160">Let’s capture the variables to transform in</st> <st c="29205">a
    list:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="29249">Let’s make a copy of the DataFrame and then apply a power transformation
    to the variables from</st> *<st c="29345">step 5,</st>* <st c="29352">where the
    exponent</st> <st c="29372">is</st> `<st c="29375">0.3</st>`<st c="29378">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="29442">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29447">With</st> `<st c="29453">np.power()</st>`<st c="29463">, we can
    apply any power transformation by changing the value of the exponent in the second
    position of</st> <st c="29567">the function.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29580">Let’s examine the change in the distribution</st> <st c="29626">of</st>
    `<st c="29629">Population</st>`<st c="29639">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="29678">As shown in the plots returned by the previous command,</st> `<st
    c="29735">Population</st>` <st c="29745">is now more evenly distributed across
    the value range and follows the quan</st><st c="29820">tiles of the normal distribution</st>
    <st c="29854">more closely:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 3.9 – A histogram and Q-Q plot of the Populatio\uFEFFn variable after\
    \ the transformation](img/B22396_03_09.jpg)"
  prefs: []
  type: TYPE_IMG
- en: <st c="30015">Figure 3.9 – A histogram and Q-Q plot of the Populatio</st><st
    c="30069">n variable after the transformation</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30105">Now, let’s apply a</st> <st c="30124">power transformation</st>
    <st c="30146">with scikit-learn.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30164">Let’s set up</st> `<st c="30178">FunctionTransformer()</st>` <st
    c="30199">with a power transformation with an exponent</st> <st c="30245">of</st>
    `<st c="30248">0.3</st>`<st c="30251">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="30315">Let’s make a copy of the DataFrame and transform the variables
    from</st> *<st c="30384">step 5</st>*<st c="30390">:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="30462">That’s it – we can now examine the variable distribution.</st>
    <st c="30521">Finally, let’s perform an exponential transformation</st> <st c="30574">with
    Feature-engine.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="30594">Let’s set up</st> `<st c="30608">PowerTransformer()</st>` <st
    c="30626">with an exponent of</st> `<st c="30647">0.3</st>` <st c="30650">to transform
    the variables from</st> *<st c="30683">step 5</st>*<st c="30689">. Then, we’ll
    fit it to</st> <st c="30713">the data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="30794">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30799">If we don’t define the variables to transform,</st> `<st c="30847">PowerTransformer()</st>`
    <st c="30865">will select and transform all of the numerical variables in</st>
    <st c="30926">the DataFrame.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30940">Finally, let’s transform those</st> <st c="30972">two variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="31014">The transformer</st> <st c="31031">returns a DataFrame containing
    the original variables, where the two variables specified in</st> *<st c="31122">step
    5</st>* <st c="31129">are transformed with the</st> <st c="31155">po</st><st c="31157">wer
    function.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31171">How it works...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="31187">In this recipe, we applied power transformations using NumPy,
    scikit-learn,</st> <st c="31264">and Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31283">To apply power functions with NumPy, we applied the</st> `<st
    c="31336">power()</st>` <st c="31343">method to the slice of the dataset containing
    the variables to transform.</st> <st c="31418">To apply this transformation with
    scikit-learn, we set up the</st> `<st c="31480">FunctionTransformer()</st>`<st
    c="31501">with</st> `<st c="31507">np.power()</st>` <st c="31517">within a</st>
    `<st c="31527">lambda</st>` <st c="31533">function, using</st> `<st c="31550">0.</st><st
    c="31552">3</st>` <st c="31554">as the exponent.</st> <st c="31572">To apply power
    functions with Feature-engine, we set up the</st> `<st c="31632">PowerTransformer()</st>`
    <st c="31650">with a list of the variables to transform and an exponent</st> <st
    c="31709">of</st> `<st c="31712">0.3</st>`<st c="31715">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31716">scikit-learn and Feature-engine transformers applied the transformation
    when we called the</st> `<st c="31808">transform()</st>` <st c="31819">method.</st>
    <st c="31828">scikit-learn’s</st> `<st c="31843">FunctionTransformer()</st>` <st
    c="31864">modifies the entire dataset and returns NumPy arrays by default.</st>
    <st c="31930">To return pandas DataFrames, we need to set the transform output
    to pandas, and to apply the transformation to specific variables, we can use</st>
    `<st c="32072">ColumnTransformer()</st>`<st c="32091">. Feature-engine’s</st>
    `<st c="32110">PowerTransformer()</st>`<st c="32128">, on the other hand, can
    apply the transformation to a subset of variables out of</st> <st c="32210">the
    box, returning pandas DataFrames</st> <st c="32247">by default</st><st c="32257">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32258">Performing Box-Cox transformations</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="32293">The Box-Cox transformation</st> <st c="32320">is a generalization
    of the power family of transformations and is defined</st> <st c="32395">as follows:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msup><mi>y</mi><mrow><mo>(</mo><mi>λ</mi><mo>)</mo></mrow></msup><mo>=</mo><mfrac><mrow><mo>(</mo><msup><mi>y</mi><mi>λ</mi></msup><mo>−</mo><mn>1</mn><mo>)</mo></mrow><mi>λ</mi></mfrac><mi>i</mi><mi>f</mi><mi>λ</mi><mo>≠</mo><mn>0</mn></mrow></mrow></math>](img/16.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msup><mi>y</mi><mrow><mo>(</mo><mi>λ</mi><mo>)</mo></mrow></msup><mo>=</mo><mi>log</mi><mfenced
    open="(" close=")"><mi>y</mi></mfenced><mi>i</mi><mi>f</mi><mi>λ</mi><mo>=</mo><mn>0</mn></mrow></mrow></math>](img/17.png)'
  prefs: []
  type: TYPE_IMG
- en: <st c="32450">Here,</st> *<st c="32456">y</st>* <st c="32457">is the</st> <st
    c="32465">variable and</st> *<st c="32478">λ</st>* <st c="32479">is the transformation
    parameter.</st> <st c="32513">It includes important special cases of transformations,
    such as untransformed</st> *<st c="32591">(λ = 1)</st>*<st c="32598">, the logarithm</st>
    *<st c="32614">(λ = 0)</st>*<st c="32621">, the reciprocal</st> *<st c="32638">(λ
    = - 1)</st>*<st c="32647">, the square root (when</st> *<st c="32671">λ</st>*
    *<st c="32672">= 0.5</st>*<st c="32677">, it applies a scaled and shifted version
    of the square root function), and the</st> <st c="32757">cube root.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32767">The Box-Cox transformation evaluates several values of</st> *<st
    c="32823">λ</st>* <st c="32824">using the maximum likelihood and selects the</st>
    *<st c="32870">λ</st>* <st c="32871">parameter that returns the</st> <st c="32899">best
    transformation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32919">In this recipe, we will perform the Box-Cox transformation using
    scikit-learn</st> <st c="32998">a</st><st c="32999">nd Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33017">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33022">The Box-Cox transformation can only be used on positive variables.</st>
    <st c="33090">If your variables have negative values, try the Yeo-Johnson transformation,
    which is described in the next recipe,</st> *<st c="33205">Performing Yeo-Johnson
    transformation</st>*<st c="33242">. Alternatively, you can shift the variable
    distributi</st><st c="33296">on by adding a constant befo</st><st c="33325">re</st>
    <st c="33329">the transformation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33348">How to do it...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="33364">Let’s begin by importing the necessary libraries and getting the</st>
    <st c="33430">dataset ready:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33444">Import the required Python libraries</st> <st c="33482">and classes:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="33726">Let’s load the California housing dataset into a</st> <st c="33776">pandas
    DataFrame:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="33858">Let’s</st> <st c="33864">drop the</st> `<st c="33874">Latitude</st>`
    <st c="33882">and</st> `<st c="33887">Longitude</st>` <st c="33896">variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="33970">Let’s inspect the variable distributions</st> <st c="34012">with
    histograms:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="34088">In the following output, we can see that the</st> `<st c="34134">MedInc</st>`
    <st c="34140">variable shows a mild right-skewed distribution, variables such
    as</st> `<st c="34208">AveRooms</st>` <st c="34216">and</st> `<st c="34221">Population</st>`
    <st c="34231">are heavily right-skewed, and the</st> `<st c="34266">HouseAge</st>`
    <st c="34274">variabl</st><st c="34282">e shows an even spread of values across</st>
    <st c="34323">its range:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.10 – Histograms of the numerical variables](img/B22396_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="34643">Figure 3.10 – Histograms of the numerical variables</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34694">Let’s</st> <st c="34700">capture the variable names in a list
    since we will use these in the</st> <st c="34769">follo</st><st c="34774">wing
    step:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="34813">Let’s create a function that will plot Q-Q plots for all the variables
    in the data in two rows with three</st> <st c="34920">plots each:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="35231">Now, let’s display the Q-Q plots using the</st> <st c="35275">preceding
    function:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="35309">By looking</st> <st c="35321">at the following plots, we can corrobora</st><st
    c="35361">te that the variables are not</st> <st c="35392">normally distributed:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.11 – Q-Q plots of the numerical variables](img/B22396_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="35950">Figure 3.11 – Q-Q plots of the numerical variables</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36000">Next, let’s carry</st> <st c="36018">out the Box-Cox transformation</st>
    <st c="36050">using scikit-learn.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36069">Let’s set up</st> `<st c="36083">PowerTransformer()</st>` <st
    c="36101">to apply the Box-Cox transformation and fit it to the data so that it
    finds the optimal</st> *<st c="36190">λ</st>* <st c="36191">parameter:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="36323">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36328">To avoid data leakage, the</st> *<st c="36356">λ</st>* <st c="36357">parameter
    should be learned from the train set and then used to transform the train and
    test sets.</st> <st c="36457">Thus, remember to split your data into train and
    tes</st><st c="36509">t sets before</st> <st c="36524">fitting</st> `<st c="36532">PowerTransformer()</st>`<st
    c="36550">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36551">Now, let’s transform</st> <st c="36573">the dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="36617">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36622">scikit-learn’s</st> `<st c="36638">PowerTransformer()</st>` <st
    c="36656">stores the learned lambdas in its</st> `<st c="36691">lambdas_</st>`
    <st c="36699">attribute, which you can display by</st> <st c="36736">executing</st>
    `<st c="36746">transformer.lambdas_</st>`<st c="36766">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36767">Let’s inspect the distributions of the transformed data</st> <st
    c="36824">with histograms:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="36903">In the following output, we can see that the variables’</st> <st
    c="36959">values are more evenly spread across</st> <st c="36997">their ranges:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.12 – Histograms of the variables after the transformation](img/B22396_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="37302">Figure 3.12 – Histograms of the variables after the transformation</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="37368">Now, let’s return</st> <st c="37387">Q-Q plots of the</st> <st
    c="37404">transformed variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="37444">In the following output, we can see that, after the transformation,
    the variables follo</st><st c="37532">w the theoretical normal distribution</st>
    <st c="37571">more closely:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 3.13 – Q-Q plots o\uFEFFf the variables after the transformation](img/B22396_03_13.jpg)"
  prefs: []
  type: TYPE_IMG
- en: <st c="38093">Figure 3.13 – Q-Q plots o</st><st c="38118">f the variables after
    the transformation</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38159">Now, let’s</st> <st c="38170">implement the Box-Cox transformation</st>
    <st c="38208">with Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38228">Let’s set up</st> `<st c="38242">BoxCoxTransformer()</st>` <st
    c="38261">to transform all the variables in the dataset and then fit it to</st>
    <st c="38327">the data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="38373">Now, let’s go ahead and transform</st> <st c="38408">the variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="38446">The transformation returns a pandas DataFrame containing</st>
    <st c="38504">the</st> <st c="38508">modified variables.</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="38527">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="38532">PowerTransformer()</st>` <st c="38551">from scikit-learn will
    transform the entire dataset.</st> <st c="38605">On the other hand,</st> `<st
    c="38624">BoxCoxTransformer()</st>` <st c="38643">from Feature-engine can modify
    a subset of the variables, if we pass their names in a list to the</st> `<st c="38742">variables</st>`
    <st c="38751">parameter when setting up the transformer.</st> <st c="38795">If
    the</st> `<st c="38802">variables</st>` <st c="38811">parameter is set to</st>
    `<st c="38832">None</st>`<st c="38836">, the transformer will transform all numerical
    variables seen</st> <st c="38898">during</st> `<st c="38905">fit()</st>`<st c="38910">.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38911">The</st> <st c="38916">optimal lambdas for the Box-Cox transformation
    are stored in the</st> `<st c="38981">lambda_dict_</st>` <st c="38993">attribute.</st>
    <st c="39005">Let’s</st> <st c="39011">inspect them:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="39041">The output of the previous command is</st> <st c="39080">the following:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="39294">Now you know how to implement the Box-Co</st><st c="39335">x transformation
    with two different</st> <st c="39372">Python libraries.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39389">How it works...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="39405">scikit-learn’s</st> `<st c="39421">PowerTransformer()</st>` <st
    c="39439">can apply both Box-Cox and Yeo-Johnson transformations, so we specified
    the transformation when setting up the transformer by passing the b</st>`<st c="39579">ox-cox</st>`
    <st c="39586">string.</st> <st c="39595">Next, we fit the transformer to the data
    so that the transformer learned the optimal lambdas for each variable.</st> <st
    c="39707">The learned lambdas were stored in the</st> `<st c="39746">lambdas_</st>`
    <st c="39754">attribute.</st> <st c="39766">Finally, we used the</st> `<st c="39787">transform()</st>`
    <st c="39798">method to transform</st> <st c="39819">the variables.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39833">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39838">Remember that to return DataFrames instead of arrays, you need
    to specify the transform output through the</st> `<st c="39946">set_output()</st>`
    <st c="39958">method.</st> <st c="39967">You can apply the transformation to a
    subset of values by using</st> <st c="40031">the</st> `<st c="40035">ColumnTransformer()</st>`<st
    c="40054">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40055">Finally, we applied the Box-Cox transformation using Feature-engine.</st>
    <st c="40125">We initialized</st> `<st c="40140">BoxCoxTransformer()</st>`<st
    c="40159">, leaving</st> <st c="40168">the parameter</st> `<st c="40183">variables</st>`
    <st c="40192">set the</st> `<st c="40201">None</st>`<st c="40205">. Due to this,
    the transformer automatically found the numerical variables in the data during</st>
    `<st c="40299">fit()</st>`<st c="40304">. We fit the transformer to the data so
    that it learned the optimal lambdas per variable, which were stored in</st> `<st
    c="40415">lambda_dict_</st>`<st c="40427">, and transformed the variables using
    the</st> `<st c="40469">transform()</st>` <st c="40480">method.</st> <st c="40489">Feature-engine’s</st>
    `<st c="40506">BoxCoxTransformer()</st>` <st c="40525">can take the entire DataFrame
    a</st><st c="40557">s input and it yet mo</st><st c="40579">dify only the</st>
    <st c="40594">selected variables.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40613">There’s more…</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="40627">We can apply the Box-Cox transformation with the SciPy library.</st>
    <st c="40692">For a code implementation, visit this book’s GitHub</st> <st c="40744">repository:</st>
    [<st c="40756">https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch03-variabl</st><st
    c="40863">e-transformation/Recipe-5-Box-Cox-transformation.ipynb</st>](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch03-variable-transformation/Recipe-5-Box-Cox-transformation.ipynb)
  prefs: []
  type: TYPE_NORMAL
- en: <st c="40918">Performing Yeo-Johnson transformations</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="40957">The</st> <st c="40962">Yeo-Johnson transformation is an extension
    of the Box-Cox transformation that is no longer constrained to positive values.</st>
    <st c="41085">In other words, the Yeo-Johnson transformation can be used on variables
    with zero and negative values, as well as positive values.</st> <st c="41216">These
    transformations are defined</st> <st c="41250">as follows:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:math>](img/18.png)<st
    c="41261"><st c="41274">; if λ ≠ 0 and X >= 0</st></st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="41295">ln(X + 1 ); if λ = 0 and X >= 0</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>−</mo><mstyle
    scriptlevel="+1"><mfrac><mrow><msup><mrow><mo>(</mo><mo>−</mo><mi>X</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow><mrow><mn>2</mn><mo>−</mo><mi>λ</mi></mrow></msup><mo>−</mo><mn>1</mn></mrow><mrow><mn>2</mn><mo>−</mo><mi>λ</mi></mrow></mfrac></mstyle></mrow></mrow></math>](img/19.png)<st
    c="41327"><st c="41329">; if λ ≠ 2 and X < 0</st></st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="41349">-ln(-X + 1); if λ = 2 and X < 0</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="41381">When the</st> <st c="41391">variable has only positive values,
    then the Yeo-Johnson transformation is like the Box-Cox transformation of the
    variable plus one.</st> <st c="41523">If the variable has only negative values,
    then the Yeo-Johnson transformation is like the Box-Cox transformation of the
    negative of the variable plus one, at the power of</st> *<st c="41694">2- λ</st>*<st
    c="41698">. If the variable has a mix of positive and negative values, the Yeo-Johnson
    transformation applies different powers to the positive and</st> <st c="41835">negative
    values.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="41851">In this recipe, we will perform the Yeo-Johns</st><st c="41897">on
    transfo</st><st c="41908">rmation using scik</st><st c="41927">it-learn</st> <st
    c="41937">and Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="41956">How to do it...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="41972">Let’s begin</st> <st c="41984">by importing the necessary libraries
    and getting the</st> <st c="42038">dataset ready:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42052">Import the required Python libraries</st> <st c="42090">and classes:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="42338">Let’s load the California housing dataset into a pandas DataFrame
    and then drop the</st> `<st c="42423">Latitude</st>` <st c="42431">and</st> `<st
    c="42436">Longitude</st>` <st c="42445">variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="42584">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42589">We can evaluate the variable distribution with histograms and
    Q-Q plots, as we did in</st> *<st c="42676">steps 4</st>* <st c="42683">to</st>
    *<st c="42687">7</st>* <st c="42688">of the</st> *<st c="42696">Performing Box-Cox</st>*
    *<st c="42715">transformations</st>* <st c="42730">recipe.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42738">Now, let’s</st> <st c="42750">apply the Yeo-Johnson transformation</st>
    <st c="42787">with scikit-learn.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="42805">Let’s set up</st> `<st c="42819">PowerTransformer()</st>` <st
    c="42837">with the</st> `<st c="42847">yeo-johnson</st>` <st c="42858">transformation:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="42981">Let’s</st> <st c="42988">fit the transformer to</st> <st c="43011">the
    data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="43039">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="43044">The</st> *<st c="43049">λ</st>* <st c="43050">parameter should
    be learned from the train set and then used to transform the train and test sets.</st>
    <st c="43150">Thus, remember to separate your data into train and test sets before</st>
    <st c="43219">fitting</st> `<st c="43227">PowerTransformer()</st>`<st c="43245">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="43246">Now, let’s transform</st> <st c="43268">the dataset:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="43312">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="43317">PowerTransformer()</st>` <st c="43336">stores the learned parameters
    in its</st> `<st c="43374">lambda_</st>` <st c="43381">attribute, which you can
    return by</st> <st c="43417">executing</st> `<st c="43427">transformer.lambdas_</st>`<st
    c="43447">.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="43448">Let’s inspect the distributions of the transformed data</st> <st
    c="43505">with histograms:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="43584">In the following output, we can see that the variables’ values
    are more evenly spread across</st> <st c="43678">their ranges:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.14 – Histograms of the variables after the yeo-Johnson transformation](img/B22396_03_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="43883">Figure 3.14 – Histograms of the variables after the yeo-Johnson
    transformation</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="43961">Finally, let’s implement</st> <st c="43986">the Yeo-Johnson transformation</st>
    <st c="44018">with Feature-engine.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="44038">Let’</st><st c="44043">s set up</st> `<st c="44053">YeoJohnsonTransformer()</st>`
    <st c="44076">to transform all numerical variables and then fit it to</st> <st
    c="44133">the data:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="44183">Note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="44188">If the</st> `<st c="44196">variables</st>` <st c="44205">argument
    is left set to</st> `<st c="44230">None</st>`<st c="44234">, the transformer selects
    and transforms all the numerical variables in the dataset.</st> <st c="44319">Alternatively,
    we can pass the names of the variables to modify in</st> <st c="44386">a list.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="44393">Compared to</st> `<st c="44406">PowerTransformer()</st>` <st c="44424">from
    scikit-learn, Feature-engine’s transformer can take the entire DataFrame as an
    argument of the</st> `<st c="44525">fit()</st>` <st c="44530">and</st> `<st c="44535">transform()</st>`
    <st c="44546">methods, and yet it will only modify the</st> <st c="44588">selected
    variables.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="44607">Let’s transform</st> <st c="44623">the variables:</st>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`<st c="44662">YeoJohnsonTransformer()</st>` <st c="44686">stores the best
    parameters per variable in its</st> `<st c="44734">lambda_dict_</st>` <st c="44746">attribute,
    which we can display</st> <st c="44779">as follows:</st>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="44807">The previous command returns the</st> <st c="44841">following
    dictionary:</st>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <st c="45062">Now you know</st> <st c="45075">how to implement the Yeo-John</st><st
    c="45105">son transformation with two different open</st> <st c="45149">source
    libraries.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="45166">How it works...</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="45182">In this recipe, we applied the Yeo-Johnson transformation using</st>
    `<st c="45247">scikit-learn</st>` <st c="45259">and</st> `<st c="45264">Feature-engine</st>`<st
    c="45278">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="45279">scikit-learn</st>`<st c="45292">’s</st> `<st c="45296">PowerTransformer()</st>`
    <st c="45314">can apply both Box-Cox and Yeo-Johnson transformations, so we specified
    the transformation with the</st> `<st c="45415">yeo-johnson</st>` <st c="45426">string.</st>
    <st c="45435">The</st> `<st c="45439">standardize</st>` <st c="45450">argument
    allowed us to determine whether we wanted to standardize (scale) the transformed
    values.</st> <st c="45549">Next, we fit the transformer to the DataFrame so that
    it learned the optimal lambdas for each variable.</st> `<st c="45653">PowerTransformer()</st>`
    <st c="45671">stored the learned lambdas in its</st> `<st c="45706">lambdas_</st>`
    <st c="45714">attribute.</st> <st c="45726">Finally, we used the</st> `<st c="45747">transform()</st>`
    <st c="45758">method to return the transformed variables.</st> <st c="45803">We
    set the transform output to</st> `<st c="45834">pandas</st>` <st c="45840">to
    return DataFrames after</st> <st c="45868">the transformation.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: <st c="45887">After that, we</st> <st c="45903">applied the Yeo-Johnson transformation
    using Feature-engine.</st> <st c="45964">We set up</st> `<st c="45974">YeoJohnsonTransformer()</st>`
    <st c="45997">so that it transforms all numerical variables seen during</st> `<st
    c="46056">fit()</st>`<st c="46061">. We fitted the transformer to the data so
    that it learned the optimal lambdas per variable, which were stored in</st> `<st
    c="46175">lambda_dict_</st>`<st c="46187">, and finally transformed the variables
    using the</st> `<st c="46237">transform()</st>` <st c="46248">method.</st> <st
    c="46257">Feature-engine’s</st> `<st c="46274">YeoJohnnsonTransformer()</st>`
    <st c="46298">can take the entire DataFrame</st> <st c="46328">as input, yet it
    wil</st><st c="46349">l only transform the</st> <st c="46371">selected variables.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="46390">There’s more…</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="46404">We can apply the Yeo-Johnson transformation with the SciPy library.</st>
    <st c="46473">For a code implementation, visit this book’s GitHub</st> <st c="46525">repository:</st>
    [<st c="46537">https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition/blob/main/ch03-variable-transformation/Recipe-6-Yeo-Johnson-transformation.ipynb</st>](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition/blob/main/ch03-variable-transformation/Recipe-6-Yeo-Johnson-transformation.ipynb)
  prefs: []
  type: TYPE_NORMAL
