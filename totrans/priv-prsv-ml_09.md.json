["```py\nimport pandas as pd\nurl =\"PS_20174392719_1491204439457_log.csv\"\ndf_actual = pd.read_csv(url, sep=\",\")\ndf_actual\n```", "```py\ndf_transactions=df_actual.head(25000)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nprint(\"No of Fraud Transactions:\",\ndf_transactions[\"isFraud\"].value_counts()[0])\nprint(\"No of Non Fraud Transactions:\",\ndf_transactions[\"isFraud\"].value_counts()[1])\nprint('No Frauds',\nround(df_transactions['isFraud'].value_counts()[0]/len(df_t\nransactions) * 100,2), '% of the dataset')\nprint('Frauds',\nround(df_transactions['isFraud'].value_counts()[1]/len(df_t\nransactions) * 100,2), '% of the dataset')\n```", "```py\nNo of Fraud Transactions: 24917\nNo of Non Fraud Transactions: 83\nNo Frauds 99.67 % of the dataset\nFrauds 0.33 % of the dataset\n```", "```py\ndf_transactions.dtypes\n```", "```py\nstep                int64\ntype               object\namount            float64\nnameOrig           object\noldbalanceOrg     float64\nnewbalanceOrig    float64\nnameDest           object\noldbalanceDest    float64\nnewbalanceDest    float64\nisFraud             int64\nisFlaggedFraud      int64\ndtype: object\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder\nencoder = {}\nfor i in df_transactions.select_dtypes('object').columns:\n    encoder[i] = LabelEncoder()\n    df_transactions[i] = encoder[i].fit_transform(df_transactions[i])\nX = df_transactions.drop('isFraud', axis=1)\ny = df_transactions['isFraud'\nfrom typing import Tuple, Union, List\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nXY = Tuple[np.ndarray, np.ndarray]\nDataset = Tuple[XY, XY]\nLogRegParams = Union[XY, Tuple[np.ndarray]]\nXYList = List[XY]\ndef get_model_parameters(model: LogisticRegression) -> LogRegParams:\n    if model.fit_intercept:\n        params = [\n            model.coef_,\n            model.intercept_,\n        ]\n    else:\n        params = [\n            model.coef_,\n        ]\n    return params\ndef set_model_params(\n    model: LogisticRegression, params: LogRegParams\n) -> LogisticRegression:\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\ndef shuffle(X: np.ndarray, y: np.ndarray) -> XY:\n    rng = np.random.default_rng()\n    idx = rng.permutation(len(X))\n    return X[idx], y[idx]\ndef partition(X: np.ndarray, y: np.ndarray, num_partitions: int) -> XYList:\n    return list(\n        zip(np.array_split(X, num_partitions), np.array_split(y, num_partitions))\n    )\ndef set_initial_params(model: LogisticRegression):\n    n_classes = 2  # Fraud Detection has only  classes\n    n_features = 9  # Number of features in dataset\n    model.classes_ = np.array([i for i in range(n_classes)])\n    model.coef_ = np.zeros((n_classes, n_features))\n    if model.fit_intercept:\n        model.intercept_ = np.zeros((n_classes,))\nimport flwr as fl\nfrom sklearn.metrics import log_loss\nfrom sklearn.linear_model import LogisticRegression\nfrom typing import Dict\ndef fit_round(server_round: int) -> Dict:\n    \"\"\"Send round number to client.\"\"\"\n    return {\"server_round\": server_round}\ndef get_evaluate_fn(model: LogisticRegression,X_test,y_test):\n# The `evaluate` function will be called after every round\n    def evaluate(server_round, parameters: fl.common.NDArrays, config):\n        # Update model with the latest parameters\n        set_model_params(model, parameters)\n        loss = log_loss(y_test, model.predict_proba(X_test))\n        accuracy = model.score(X_test, y_test)\n        return loss, {\"accuracy\": accuracy}\n    return evaluate\n# Start Flower server for five rounds of federated learning\ndef Server():\n    model = LogisticRegression(max_iter=10000)\n    set_initial_params(model)\n    strategy = fl.server.strategy.FedAvg(\n        min_available_clients=2,\n        evaluate_fn=get_evaluate_fn(model,X_test,y_test),\n        on_fit_config_fn=fit_round,\n    )\n    fl.server.start_server(\n        server_address=\"0.0.0.0:8080\",\n        strategy=strategy,\n        config=fl.server.ServerConfig(num_rounds=5),\n    )\nServer()\n```", "```py\nimport pandas as pd\nimport torch\nurl =\"PS_20174392719_1491204439457_log.csv\"\ndf_actual = pd.read_csv(url, sep=\",\")\ndf_actual\ndf_transactions=df_actual.head(25000)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nprint(\"No of Fraud Transactions:\", df_transactions[\"isFraud\"].value_counts()[0])\nprint(\"No of Non Fraud Transactions:\", df_transactions[\"isFraud\"].value_counts()[1])\nprint('No Frauds', round(df_transactions['isFraud'].value_counts()[0]/len(df_transactions) * 100,2), '% of the dataset')\nprint('Frauds', round(df_transactions['isFraud'].value_counts()[1]/len(df_transactions) * 100,2), '% of the dataset')\n```", "```py\nNo of Fraud Transactions: 24917\nNo of Non Fraud Transactions: 83\nNo Frauds 99.67 % of the dataset\nFrauds 0.33 % of the dataset\n```", "```py\ndf_transactions.dtypes\n```", "```py\nstep                int64\ntype               object\namount            float64\nnameOrig           object\noldbalanceOrg     float64\nnewbalanceOrig    float64\nnameDest           object\noldbalanceDest    float64\nnewbalanceDest    float64\nisFraud             int64\nisFlaggedFraud      int64\ndtype: object\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder\nencoder = {}\nfor i in df_transactions.select_dtypes('object').columns:\n    encoder[i] = LabelEncoder()\n    df_transactions[i] = encoder[i].fit_transform(df_transactions[i])\nX = df_transactions.drop('isFraud', axis=1)\ny = df_transactions['isFraud']\n```", "```py\nfrom imblearn.over_sampling import SMOTE\nover_sample = SMOTE(random_state=0)\nX,y = over_sample.fit_resample(X,y)\ny.value_counts()\n```", "```py\n0    24917\n1    24917\nName: isFraud, dtype: int64\nX = df_transactions[['step', 'type', 'amount','nameOrig', 'oldbalanceOrg', 'newbalanceOrig','nameDest', 'oldbalanceDest', 'isFlaggedFraud']]\ny= df_transactions['isFraud']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\nfrom typing import Tuple, Union, List\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nXY = Tuple[np.ndarray, np.ndarray]\nDataset = Tuple[XY, XY]\nLogRegParams = Union[XY, Tuple[np.ndarray]]\nXYList = List[XY]\ndef get_model_parameters(model: LogisticRegression) -> LogRegParams:\n    if model.fit_intercept:\n        params = [\n            model.coef_,\n            model.intercept_,\n        ]\n    else:\n        params = [\n            model.coef_,\n        ]\n    return params\ndef set_model_params(\n    model: LogisticRegression, params: LogRegParams\n) -> LogisticRegression:\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\ndef shuffle(X: np.ndarray, y: np.ndarray) -> XY:\n    rng = np.random.default_rng()\n    idx = rng.permutation(len(X))\n    return X[idx], y[idx]\ndef partition(X: np.ndarray, y: np.ndarray, num_partitions: int) -> XYList:\n    return list(\n        zip(np.array_split(X, num_partitions), np.array_split(y, num_partitions))\n    )\ndef set_initial_params(model: LogisticRegression):\n    n_classes = 2  # only 2 classes  Fraud or Genuine\n    n_features = 9  # Number of features in dataset\n    model.classes_ = np.array([i for i in range(n_classes)])\n    model.coef_ = np.zeros((n_classes, n_features))\n    if model.fit_intercept:\n        model.intercept_ = np.zeros((n_classes,))\npartition_id = np.random.choice(10)\n(X_train, y_train) = partition(X_train, y_train, 10)[partition_id]\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(\n        penalty=\"l2\",\n        max_iter=1,  # local epoch\n        warm_start=True,  # prevent refreshing weights when fitting\n    )\nmodel.fit(X_train, y_train)\nclass AML_Detection_Client(fl.client.NumPyClient):\n        def get_parameters(self, config):\n            return get_model_parameters(model)\n        def fit(self, parameters, config):\n            set_model_params(model, parameters)\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\")\n                model.fit(X_train, y_train)\n            print(f\"Training finished for round {config['server_round']}\")\n            return get_model_parameters(model), len(X_train), {}\n        def evaluate(self, parameters, config):\n            set_model_params(model, parameters)\n            loss = log_loss(y_test, model.predict_proba(X_test))\n            accuracy = model.score(X_test, y_test)\n            print(loss,accuracy)\n            return loss, len(X_test), {\"accuracy\": accuracy}\nfl.client.start_numpy_client(server_address=\"0.0.0.0:8080\", client=AML_Detection_Client())\n```", "```py\nimport pandas as pd\nimport torch\nurl =\"PS_20174392719_1491204439457_log.csv\"\ndf_actual = pd.read_csv(url, sep=\",\")\ndf_actual\ndf_transactions=df_actual.head(25000)\nfrom sklearn.model_selection import train_test_split\nffrom sklearn.model_selection import StratifiedShuffleSplit\nprint(\"No of Fraud Transactions:\", df_transactions[\"isFraud\"].value_counts()[0])\nprint(\"No of Non Fraud Transactions:\", df_transactions[\"isFraud\"].value_counts()[1])\nprint('No Frauds', round(df_transactions['isFraud'].value_counts()[0]/len(df_transactions) * 100,2), '% of the dataset')\nprint('Frauds', round(df_transactions['isFraud'].value_counts()[1]/len(df_transactions) * 100,2), '% of the dataset')\n```", "```py\nNo of Fraud Transactions: 24917\nNo of Non Fraud Transactions: 83\nNo Frauds 99.67 % of the dataset\nFrauds 0.33 % of the dataset\ndf_transactions.dtypes\nstep                int64\ntype               object\namount            float64\nnameOrig           object\noldbalanceOrg     float64\nnewbalanceOrig    float64\nnameDest           object\noldbalanceDest    float64\nnewbalanceDest    float64\nisFraud             int64\nisFlaggedFraud      int64\ndtype: object\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder\nencoder = {}\nfor i in df_transactions.select_dtypes('object').columns:\n    encoder[i] = LabelEncoder()\n    df_transactions[i] = encoder[i].fit_transform(df_transactions[i])\nX = df_transactions.drop('isFraud', axis=1)\ny = df_transactions['isFraud']\ny.value_counts()\n```", "```py\n0    24392\n1      608\nName: isFraud, dtype: int64\nX = df_transactions[['step', 'type', 'amount','nameOrig', 'oldbalanceOrg', 'newbalanceOrig','nameDest', 'oldbalanceDest', 'isFlaggedFraud']]\ny= df_transactions['isFraud']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\nfrom typing import Tuple, Union, List\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nXY = Tuple[np.ndarray, np.ndarray]\nDataset = Tuple[XY, XY]\nLogRegParams = Union[XY, Tuple[np.ndarray]]\nXYList = List[XY]\ndef get_model_parameters(model: LogisticRegression) -> LogRegParams:\n    if model.fit_intercept:\n        params = [\n            model.coef_,\n            model.intercept_,\n        ]\n    else:\n        params = [\n            model.coef_,\n        ]\n    return params\ndef set_model_params(\n    model: LogisticRegression, params: LogRegParams\n) -> LogisticRegression:\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\ndef shuffle(X: np.ndarray, y: np.ndarray) -> XY:\n    rng = np.random.default_rng()\n    idx = rng.permutation(len(X))\n    return X[idx], y[idx]\ndef partition(X: np.ndarray, y: np.ndarray, num_partitions: int) -> XYList:\n    return list(\n        zip(np.array_split(X, num_partitions), np.array_split(y, num_partitions))\n    )\ndef set_initial_params(model: LogisticRegression):\n    n_classes = 2  # only 2 classes  Fraud or Geninue\n    n_features = 9  # Number of features in dataset\n    model.classes_ = np.array([i for i in range(n_classes)])\n    model.coef_ = np.zeros((n_classes, n_features))\n    if model.fit_intercept:\n        model.intercept_ = np.zeros((n_classes,))\npartition_id = np.random.choice(10)\n(X_train, y_train) = partition(X_train, y_train, 10)[partition_id]\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(\n        penalty=\"l2\",\n        max_iter=1,  # local epoch\n        warm_start=True,  # prevent refreshing weights when fitting\n    )\nmodel.fit(X_train, y_train)\nclass AML_Detection_Client(fl.client.NumPyClient):\n        def get_parameters(self, config):\n            return get_model_parameters(model)\n        def fit(self, parameters, config):\n            set_model_params(model, parameters)\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\")\n                model.fit(X_train, y_train)\n            print(f\"Training finished for round {config['server_round']}\")\n            return get_model_parameters(model), len(X_train), {}\n        def evaluate(self, parameters, config):\n            set_model_params(model, parameters)\n            loss = log_loss(y_test, model.predict_proba(X_test))\n            accuracy = model.score(X_test, y_test)\n            print(loss,accuracy)\n            return loss, len(X_test), {\"accuracy\": accuracy}\nfl.client.start_numpy_client(server_address=\"0.0.0.0:8080\", client=AML_Detection_Client())\n```", "```py\ndef DP_Fed_Server():\n    model = LogisticRegression(max_iter=10000)\n    set_initial_params(model)\n    strategy = fl.server.strategy.FedAvg(\n        min_available_clients=2,\n        evaluate_fn=get_evaluate_fn(model,X_test,y_test),\n        on_fit_config_fn=fit_round,\n    )\ndps = DPFedAvgFixed(strategy,\nnum_sampled_clients=2,\nclip_norm=0.03,\nnoise_multiplier=0.5)\nfl.server.start_server(\n        server_address=\"0.0.0.0:8080\",\n          strategy=dps,\n         config=fl.server.ServerConfig(num_rounds=5),\n    )\nDP_Fed_Server()\n```"]