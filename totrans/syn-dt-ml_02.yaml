- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Annotating Real Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fuel of the **machine learning** (**ML**) engine is data. Data is available
    in almost every part of our technology-driven world. ML models usually need to
    be trained or evaluated on annotated data, not just data! Thus, data by itself
    is not very useful for ML but annotated data is what ML models need.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn why ML models need annotated data. We will see
    why the annotation process is expensive, error-prone, and biased. At the same
    time, you will be introduced to the annotation process for a number of ML tasks,
    such as **image classification**, **semantic segmentation**, and **instance segmentation**.
    We will highlight the main annotation problems. At the same time, we will understand
    why ideal ground truth generation is impossible or extremely difficult for tasks
    such as **optical flow estimation** and **depth estimation**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The need to annotate real data for ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Issues with the annotation process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Optical flow and depth estimation: ground truth and annotation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annotating data for ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you learn why ML models need annotated data and not simply
    data! Furthermore, you will be introduced to a diverse set of annotation tools.
  prefs: []
  type: TYPE_NORMAL
- en: Learning from data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As humans, we learn differently from ML models. We just require *implicit* data
    annotation. However, ML models need *explicit* annotation of the data. For example,
    let’s say you want to train an ML model to classify cat and dog images; you cannot
    simply feed this model with many images of cats and dogs expecting the model to
    learn to differentiate between these two classes. Instead, you need to describe
    what each image is and then you can train your “cat-dog” classifier (see *Figure
    2**.1*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Training data for the cat-dog classifier](img/B18494_02_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Training data for the cat-dog classifier
  prefs: []
  type: TYPE_NORMAL
- en: 'It should be noted that the amazing capabilities of ML models are closely related
    to and highly affected by the quality and quantity of the training data and ground
    truth. Generally, we need humans to annotate data for two main reasons: training
    and testing ML models. Next, we will be looking at these in more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: Training your ML model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have four main steps for training an ML model. We will look at each of them
    next (see *Figure 2**.2*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Training process of a typical ML model](img/B18494_02_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Training process of a typical ML model
  prefs: []
  type: TYPE_NORMAL
- en: Initialization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the beginning of the training process, the model’s parameters should be initialized.
    Usually, the parameters (weights and biases) of the **deep learning** (**DL**)
    model are set to random small numbers because this is what the **stochastic optimization
    process** expects at the beginning of the optimization process. The stochastic
    optimization process is a method of finding the best solution for a mathematical
    problem where randomness and uncertainty are involved to enhance the search procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The model utilizes its past knowledge about the task and predicts the output
    given the input data. We can imagine that the model builds its own understanding
    of the problem by fitting a **hyperplane** (a decision boundary) to the training
    data in the training process, and then it projects any given input on this hyperplane
    to give us the model’s prediction for this specific input. Please remember that,
    at this step, we feed the model with *data only*, without any ground truth. If
    we go back to our “cat-dog” classifier, the model will be fed with cat and dog
    images and asked to predict the class or the label of these images.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '*Training*: The ML model develops its own comprehension of the problem by adjusting
    its parameters and evaluating its performance until it reaches a satisfactory
    understanding of the training data.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Testing*: After the training, the ML model is evaluated on new data to assess
    its performance by using various metrics, such as F1 score, precision, and accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: Error calculation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Given what the model has predicted, we now need to assess the *correctness*
    of this prediction. This is exactly where we need the ground truth or the annotations.
    At this step, we have two inputs: the model’s prediction and the ground truth.
    Going back to our “cat-dog” classifier, the model may wrongly predict the class
    of a cat image as “dog.” Now, since we have the true class of the training cat
    image, we can tell the model that its understanding of the cat-dog problem was
    wrong this time (for this training sample). Furthermore, we can calculate how
    close the model was by using the loss function, which depends on the type of the
    problem. Please note that we essentially have two types of problems in ML: **classification**
    and **regression** problems. In classification problems, the ML model learns to
    categorize training data. For example, the “cat-dog” problem is a classification
    problem, and the error could be 0 or 1 since you have two categories: cat or dog.
    On the other hand, in regression problems, the ML model learns to leverage input
    data to predict a continuous value. For example, assume you are training a model
    to predict a house’s price based on some information about the house: location,
    number of rooms, age, and other information. Assume that the model predicted the
    house’s price to be £100,000 but the actual price (from the ground truth) is £105,000\.
    Then, the error in this case is £5,000.'
  prefs: []
  type: TYPE_NORMAL
- en: The error is the essence of the learning process in ML; it provides guidance
    for training the model – for example, how much it needs to update its parameters
    and which parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is where the learning happens. Given the calculated error, we need to update
    the model’s parameters or weights based on the input and error. In other words,
    the model needs to “debug” the cause of this error in the prediction. If the error
    is small, the model will slightly update its weights or understanding of the problem.
    On the other hand, if the error is huge, the model will need to make major changes
    to the weights, thus, the understanding of the problem. Going back again to the
    “cat-dog” classifier, at the beginning of the training process, most predictions
    will be wrong, thus the model will be updating its weights drastically. In contrast,
    when the model is close to convergence (the best possible understanding of the
    training data), ideally, it starts to get most of its predictions right, thus
    making just slight updates on the weights.
  prefs: []
  type: TYPE_NORMAL
- en: Testing your ML model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To assess the performance of your ML model, you need annotated data too. Thus,
    the annotations are not just needed for training but also for testing. Usually,
    qualitative results are good for having an overall understanding of how the model
    is performing in general or in some individual interesting scenarios. However,
    quantitative results are the most important way to understand the ML model’s robustness,
    accuracy, and precision.
  prefs: []
  type: TYPE_NORMAL
- en: Using the ground truth, we can examine our trained model’s performance on a
    large number of examples. Thus, there is no need to look at predictions individually
    as the overall average, standard deviation, and other statistics will be a good
    description for that. In the next section, we will delve into common issues with
    the annotation of real data.
  prefs: []
  type: TYPE_NORMAL
- en: Issues with the annotation process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen so far, annotations are critical to both training and testing.
    Thus, any mislabeling, biased annotations, or insufficient annotated data will
    drastically impact the learning and evaluation process of your ML model. As you
    can expect, the annotation process is time-consuming, expensive, and error-prone,
    and this is what we will see in this section.
  prefs: []
  type: TYPE_NORMAL
- en: The annotation process is expensive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To train state-of-the-art computer vision or **natural language processing**
    (**NLP**) models, you need large-scale training data. For example, *BERT* ([https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805))
    was trained on BooksCorpos (800 million words) and Wikipedia (2,500 million words).
    Similarly, *ViT* ([https://arxiv.org/abs/2010.11929](https://arxiv.org/abs/2010.11929))
    was trained on ImageNet (14 million images) and JFT (303 million images). Annotating
    such huge datasets is extremely difficult and challenging. Furthermore, it is
    time-consuming and expensive. It should be noted that the time required to annotate
    a dataset depends on three main elements: the task or problem, dataset size, and
    granularity level. Next, we will be looking at each of these in more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: Task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For example, annotating a dataset for a binary classification problem is easier
    and requires less time compared to annotating a dataset for semantic segmentation.
    Thus, the nature of the task also imposes clear difficulty on the annotation process.
    Even for the same task, let’s say semantic segmentation, annotating a single image
    under standard weather conditions and normal illumination takes approximately
    90 minutes for the *Cityscapes* dataset (Marius Cordts, et al. *The cityscapes
    dataset for semantic urban scene understanding*. In Proceedings of the IEEE conference
    on computer vision and pattern recognition, pages 3213–3223, 2016). However, doing
    similar annotation for images under adverse conditions such as snow, rain, and
    fog or at low illumination such as nighttime takes up to 3 hours for the *ACDC*
    dataset (Christos Sakaridis, et al. *ACDC: The adverse conditions dataset with
    correspondences for semantic driving scene understanding*. In Proceedings of the
    IEEE/CVF International Conference on Computer Vision, pages 10765–10775, 2021.).'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset size
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As expected, the larger the dataset, the harder it is to annotate. The complexity
    comes from managing such a huge dataset and ensuring the same annotation and data
    collection protocol is being followed by a large group of annotators. These annotators
    may have different languages, backgrounds, experiences, and skills. Indeed, guiding
    such a huge, diverse team, probably in different geographical locations, is not
    simple.
  prefs: []
  type: TYPE_NORMAL
- en: Granularity level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The more detail you want your ground truth to capture, the more work for the
    annotators to perform. Let’s take **visual object tracking** as an example. Annotating
    images for single-object tracking is easier than multi-object tracking. We find
    the same thing for semantic segmentation, too. Annotating a semantic segmentation
    dataset with 3 classes is easier than 10 classes. Furthermore, the type of class
    also creates difficulty for the annotator. In other words, small objects may be
    harder to differentiate from the background and thus harder to annotate.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we look at the main reasons behind noisy ground truth issues commonly
    seen in real datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The annotation process is error-prone
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we shed light on the key reasons behind issues in manually
    annotated real data.
  prefs: []
  type: TYPE_NORMAL
- en: Human factor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most important element in the annotation process is humans. However, we
    are limited by our perceptions of the world. Humans struggle to perceive with
    the naked eye the visual content in scenarios such as low illumination, cluttered
    scenes, or when objects are far from the camera, transparent, and so on. At the
    same time, miscommunication and misunderstanding of annotation protocol is another
    major issue. For example, assume you asked a team of annotators to annotate images
    for a visual object-tracking training dataset. You aim only to consider the *person
    object* for this task. Some annotators will annotate humans without objects while
    other annotators may consider other objects carried by humans as part of the object
    of interest (see *Figure 2**.3*). Furthermore, some annotators may consider only
    the unoccluded part of the human. This will cause a major inconsistency in the
    training data and the model will struggle to learn the task and will never converge.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Samples of annotation errors due to unclear annotation protocol](img/B18494_02_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – Samples of annotation errors due to unclear annotation protocol
  prefs: []
  type: TYPE_NORMAL
- en: Recording tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the recoding camera is shaky, the captured images will be blurred and thus
    the annotators will fail to accurately identify the actual pixels of the object
    from the background. Furthermore, the intrinsic and extrinsic parameters of the
    camera drastically change how the 3D scene will be projected into a 2D image.
    The focal length of the lens, shutter speed, lens distortion, and others all introduce
    certain errors in the annotation process. In other words, the objects annotated
    by annotators may not exactly correspond to the same object in the raw image or
    even in the 3D world.
  prefs: []
  type: TYPE_NORMAL
- en: Scene attributes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Attributes such as weather conditions and time of the day all play an important
    role in the annotation process. As we have mentioned earlier, clear weather in
    the daytime may help the annotators to clearly identify objects as compared to
    adverse conditions at nighttime. In parallel to this, crowded and cluttered scenes
    are much more difficult to annotate and more subject to errors (see *Figure 2**.4*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Scene attribute: crowded scenes are more subject to annotation
    errors](img/B18494_02_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4 – Scene attribute: crowded scenes are more subject to annotation
    errors'
  prefs: []
  type: TYPE_NORMAL
- en: Annotation tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To enhance the annotation process, there are various annotation tools, such
    as Labelbox, Scale AI, Dataloop, HiveData, and LabelMe. Some of the annotation
    tools integrate AI components to optimize the annotation process by assisting
    the human annotator, such as Labelbox. While these AI-assisted methods are promising,
    they are not practical and reliable yet. In other words, the human annotator still
    needs to verify and correct the predictions. Additionally, some of these methods
    are slow and far from able to provide real-time assistance. In addition to this,
    if the problem is novel, the AI assistance will not work as expected because the
    AI model was not trained on similar scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Given the task, dataset size, and team specifications, a suitable annotation
    tool should be selected. The annotation tool should be the same for all annotators
    to ensure consistency among the annotators and the created ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: The annotation process is biased
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the world and to reason about it efficiently, our brains build
    fast decisions and judgments based on our previous experience and systems of beliefs.
    For more details, see *Decision Making: Factors that Influence Decision Making,
    Heuristics Used, and Decision Outcomes* ([http://www.inquiriesjournal.com/a?id=180](http://www.inquiriesjournal.com/a?id=180)).
    ML models learn to reason and perceive the world using the training data. We try
    to collect and annotate the data objectively. However, unintentionally, we reflect
    our biases on the data we collect and annotate. Consequently, ML models also become
    biased and unfair. We will discuss the three common factors of annotation process
    bias next.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the problem and task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The annotator may not know the problem, may not understand the data, or understand
    why the data is collected and annotated. Thus, they may make wrong assumptions
    or misinterpret data. Furthermore, given the differences between the annotators,
    they may understand the problem differently.
  prefs: []
  type: TYPE_NORMAL
- en: Background, ideology, and culture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is a critical factor behind inconsistency in the annotation process. Let’s
    imagine that you asked a group of 10 annotators to annotate a dataset for **action
    recognition**. You have only two actions: confirmation or negation. Your annotation
    team members are from the UK, Bulgaria, and India. The Bulgarian annotators will
    understand and annotate head shaking as “Yes” and nodding as “No.” The other annotators
    will do the opposite. Thus, you will have wrong training data and your model will
    not learn this task. There are also other scenarios where the bias is not clear
    and cannot be easily identified, and this is the hardest issue under this scope.'
  prefs: []
  type: TYPE_NORMAL
- en: Subjectivity and emotions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For some problems such as **text sentiment analysis**, a well-known NLP technique
    used to understand textual data, a human annotator may be biased toward certain
    political parties, football teams, genders, and ethnicities. Thus, the annotations
    will be biased to the annotator’s point of view as well.
  prefs: []
  type: TYPE_NORMAL
- en: Common issues in the annotation process
  prefs: []
  type: TYPE_NORMAL
- en: 'Always avoid the following: using the wrong labeling tool, vague annotation
    protocol, miscommunication between annotators, adding new labels after starting
    the annotation process, and modifying the annotation protocol during the process.'
  prefs: []
  type: TYPE_NORMAL
- en: Optical flow and depth estimation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look at different ML tasks and the followed procedures
    to generate their corresponding ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: Ground truth generation for computer vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Computer vision** aims at enabling computers to see using digital images.
    It is not surprising to know that vision is one of the most complex functionalities
    performed by our brain. Thus, imitating vision is not simple, and it is rather
    complex for state-of-the-art computer vision models.'
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision tasks include semantic segmentation, instance segmentation,
    optical flow estimation, depth estimation, normal map estimation, visual object
    tracking, and many more. Each task has its own unique way of generating the corresponding
    ground truth. Next, we will see samples of these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Image classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The training images for this task usually contain one object, which is the object
    of interest. The annotation for this task is simply looking at each image and
    selecting one class or more describing the object in the image.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic and instance segmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For semantic and instance segmentation, the annotator needs to assign a class
    label for each pixel in the image. In other words, the annotator is asked to partition
    the image into different segments where each segment demonstrates one class for
    semantic segmentation and one instance for instance segmentation. Please refer
    to [https://github.com/mrgloom/awesome-semantic-segmentation](https://github.com/mrgloom/awesome-semantic-segmentation)
    for an exhaustive list of semantic segmentation methods, such as *U-Net*, *DeepLab*,
    and *D2Det*. For instance segmentation, please check [https://github.com/topics/instance-segmentation](https://github.com/topics/instance-segmentation).
  prefs: []
  type: TYPE_NORMAL
- en: Object detection and tracking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In object detection and tracking, the annotator draws a bounding box around
    each object in the image. Object tracking works using video to track an initially
    selected object throughout the video. On the other hand, **object detection**
    works on images to detect objects as required by the task. Please refer to [https://github.com/topics/object-detection](https://github.com/topics/object-detection)
    for a list of well-known and state-of-the-art object detection methods and useful
    Python libraries, such as *YOLOv5*, *Mask R-CNN*, and *OpenMMLab*. For object
    tracking, please refer to [https://github.com/topics/object-tracking](https://github.com/topics/object-tracking)
    for a list of models, such as *SiamMask*, *HQTrack*, and *CFNet*.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will examine two specific tasks in computer vision that are extremely
    hard to generate ground truth for using a standard approach. This is basically
    just an example of the limitation of real data.
  prefs: []
  type: TYPE_NORMAL
- en: Optical flow estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Optical flow** is the relative apparent motion of objects from one frame
    to another. The motion could be because of objects or camera motion. Optical flow
    has many key applications in tasks, such as **structure from motion**, **video
    compression**, and **video stabilization**. Structure from motion is widely used
    in 3D construction, and navigation and manipulation tasks in robotics, augmented
    reality, and games. Video compression is essential for video streaming, storage,
    and transmission; video stabilization, on the other hand, is crucial for timelapse
    videos, and videos recorded by drones or head-mounted cameras. Thus, optical flow
    has enormous applications in practice. For a comprehensive list of optical flow
    methods such as *SKFlow*, *GMFlow*, and *RAFT*, please refer to [https://github.com/hzwer/Awesome-Optical-Flow](https://github.com/hzwer/Awesome-Optical-Flow).'
  prefs: []
  type: TYPE_NORMAL
- en: Please note that it is extremely hard to generate ground truth for optical flow.
    Some approaches apply complex procedures to achieve this under many assumptions,
    such as an indoor environment and a limited number of objects and motions.
  prefs: []
  type: TYPE_NORMAL
- en: Depth estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Depth estimation** is the task of measuring the distance of each pixel in
    the scene to the camera. It is essential for 3D vision and has many applications,
    such as 3D scene reconstruction, autonomous cars and navigation, medical imaging,
    and augmented reality. Usually, there are two major approaches for depth estimation:
    one uses monocular images and the other is based on stereo images utilizing epipolar
    geometry. Similar to optical flow, generating ground truth for depth estimation
    is extremely hard in the real world. Please refer to [https://github.com/topics/depth-estimation](https://github.com/topics/depth-estimation)
    for a list of recent depth estimation methods, such as *AdaBins*, *SC-Depth*,
    and *Monodepth2*.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For optical flow and depth estimation, most of the standard datasets used are
    synthetic datasets. For optical flow, we can recognize synthetic datasets such
    as *FlyingChairs*, *FlyingThings3D*, and *Kubric* ([https://github.com/google-research/kubric](https://github.com/google-research/kubric)).
    For depth estimation, we can mention *Virtual KITTI*, *DENSE* ([https://github.com/uzh-rpg/rpg_e2depth](https://github.com/uzh-rpg/rpg_e2depth)),
    and *DrivingStereo* ([https://drivingstereo-dataset.github.io/](https://drivingstereo-dataset.github.io/)).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned why ML models need annotated real data. At the same
    time, we explored some of the common issues in the annotation process. Our exploration
    has led us to a deeper understanding of real data collection and annotation issues,
    such as being a time-consuming process and subject to annotator errors. Additionally,
    we covered the limitations of real data for tasks such as optical flow and depth
    estimation. In the next chapter, we will look specifically at the privacy issues
    with real data.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters of the book, we will continue our exciting journey
    to understand the limitations of real data and the promising solutions of synthetic
    data.
  prefs: []
  type: TYPE_NORMAL
