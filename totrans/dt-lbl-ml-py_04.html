<html><head></head><body>
<div id="_idContainer078">
<h1 class="chapter-number" id="_idParaDest-78"><a id="_idTextAnchor081"/><span class="koboSpan" id="kobo.1.1">4</span></h1>
<h1 id="_idParaDest-79"><a id="_idTextAnchor082"/><span class="koboSpan" id="kobo.2.1">Exploring Image Data</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we will learn how to explore image data using various packages and libraries in Python. </span><span class="koboSpan" id="kobo.3.2">We will also see how to visualize images using Matplotlib and analyze image properties </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">using NumPy.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">Image data is widely used in machine learning, computer vision, and object detection across various </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">real-world applications.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">The chapter is divided into three key sections covering visualizing image data, analyzing image size and aspect ratios, and performing transformations on images. </span><span class="koboSpan" id="kobo.7.2">Each section focuses on a specific aspect of image data analysis, providing practical insights and techniques to extract </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">valuable information.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">In the first section, </span><em class="italic"><span class="koboSpan" id="kobo.10.1">Visualizing image data</span></em><span class="koboSpan" id="kobo.11.1">, we will utilize the Matplotlib, Seaborn, </span><strong class="bold"><span class="koboSpan" id="kobo.12.1">Python Imaging Library</span></strong><span class="koboSpan" id="kobo.13.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.14.1">PIL</span></strong><span class="koboSpan" id="kobo.15.1">), and </span><a id="_idIndexMarker198"/><span class="koboSpan" id="kobo.16.1">NumPy libraries and explore techniques such as plotting histograms of pixel values for grayscale images, visualizing color channels in RGB images, adding annotations to enhance image interpretation, and performing image segmentation. </span><span class="koboSpan" id="kobo.16.2">Additionally, we will dive into feature extraction using the </span><strong class="bold"><span class="koboSpan" id="kobo.17.1">Histogram of Oriented Gradients</span></strong><span class="koboSpan" id="kobo.18.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.19.1">HOG</span></strong><span class="koboSpan" id="kobo.20.1">). </span><span class="koboSpan" id="kobo.20.2">Through practical examples and hands-on </span><a id="_idIndexMarker199"/><span class="koboSpan" id="kobo.21.1">exercises, this section equips you with essential skills for visually analyzing and interpreting image data using Python libraries. </span><span class="koboSpan" id="kobo.21.2">Whether you’re a beginner or seeking to deepen your image processing expertise, this section provides valuable insights and </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">practical knowledge.</span></span></p>
<p><span class="koboSpan" id="kobo.23.1">Moving on to the second </span><em class="italic"><span class="koboSpan" id="kobo.24.1">Analyzing image size and aspect ratio</span></em><span class="koboSpan" id="kobo.25.1"> section, we delve into the importance of understanding the dimensions and proportions of images. </span><span class="koboSpan" id="kobo.25.2">We demonstrate how Python libraries such </span><a id="_idIndexMarker200"/><span class="koboSpan" id="kobo.26.1">as </span><strong class="bold"><span class="koboSpan" id="kobo.27.1">Python Imaging Library</span></strong><span class="koboSpan" id="kobo.28.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.29.1">PIL</span></strong><span class="koboSpan" id="kobo.30.1">) and OpenCV can be utilized to extract and analyze image size and aspect ratios. </span><span class="koboSpan" id="kobo.30.2">By studying these attributes, we can derive meaningful insights about the composition and structure of images, which can inform data-labeling decisions and contribute to accurate classification or object </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">detection tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">The final </span><em class="italic"><span class="koboSpan" id="kobo.33.1">Performing transformations on images</span></em><span class="koboSpan" id="kobo.34.1"> section explores the concept of data augmentation through transformations. </span><span class="koboSpan" id="kobo.34.2">We delve into how various image transformations, such as rotations, translations, and shearing, can be applied using libraries such as OpenCV and scikit-image. </span><span class="koboSpan" id="kobo.34.3">These transformations not only enhance the diversity and size of the dataset but also enable the creation of augmented images that capture different orientations, perspectives, or variations. </span><span class="koboSpan" id="kobo.34.4">We discuss how these transformed images can be leveraged for data labeling and improving </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">model performance.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">Throughout the chapter, we emphasize the practical implementation of these techniques using Python. </span><span class="koboSpan" id="kobo.36.2">By leveraging the rich ecosystem of image processing libraries and visualization tools, we empower readers to perform exploratory data analysis specifically tailored for image datasets. </span><span class="koboSpan" id="kobo.36.3">The insights gained from visualizing image data, analyzing size and aspect ratios, and performing transformations lay a strong foundation for effective data labeling and building robust machine </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">learning models.</span></span></p>
<p><span class="koboSpan" id="kobo.38.1">Whether you are an aspiring data scientist, an image processing enthusiast, or a professional looking to enhance your data labeling skills, this chapter provides valuable guidance and hands-on examples to explore, analyze, and label image data effectively </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">using Python.</span></span></p>
<p><span class="koboSpan" id="kobo.40.1">By the end of this chapter, we will have covered the </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.42.1">Visualizing </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">image data</span></span></li>
<li><span class="koboSpan" id="kobo.44.1">Analyzing image size and </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">aspect ratios</span></span></li>
<li><span class="koboSpan" id="kobo.46.1">Performing transformations </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">on images</span></span></li>
</ul>
<h1 id="_idParaDest-80"><a id="_idTextAnchor083"/><span class="koboSpan" id="kobo.48.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.49.1">In this chapter, you’ll need VS Code, Keras, CV2, and OpenCV. </span><span class="koboSpan" id="kobo.49.2">A Python notebook with the example code used in this chapter can be downloaded </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">from </span></span><a href="https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/code//Ch04"><span class="No-Break"><span class="koboSpan" id="kobo.51.1">https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/code//Ch04</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.52.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.53.1">You will find the results of all code blocks in the notebook in this GitHub repository. </span><span class="koboSpan" id="kobo.53.2">As well as this, you will need the environment setup outlined in the </span><em class="italic"><span class="koboSpan" id="kobo.54.1">Preface</span></em><span class="koboSpan" id="kobo.55.1"> of </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">the book.</span></span></p>
<h1 id="_idParaDest-81"><a id="_idTextAnchor084"/><span class="koboSpan" id="kobo.57.1">Visualizing image data using Matplotlib in Python</span></h1>
<p><span class="koboSpan" id="kobo.58.1">In this section, we explore the power of visualization tools and techniques to gain meaningful insights into the characteristics and patterns of image data. </span><span class="koboSpan" id="kobo.58.2">Using Python libraries such as Matplotlib and Seaborn, we learn how to create visualizations that showcase image distributions, class imbalances, color distributions, and other essential features. </span><span class="koboSpan" id="kobo.58.3">By visualizing the image data, we can uncover hidden patterns, detect anomalies, and make informed decisions for </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">data labeling.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.60.1">Exploratory Data Analysis</span></strong><span class="koboSpan" id="kobo.61.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.62.1">EDA</span></strong><span class="koboSpan" id="kobo.63.1">) is</span><a id="_idIndexMarker201"/><span class="koboSpan" id="kobo.64.1"> an important step in the process of building computer vision models. </span><span class="koboSpan" id="kobo.64.2">In EDA, we analyze the image data to understand its characteristics and identify patterns and relationships that can inform our </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">modeling decisions.</span></span></p>
<p><span class="koboSpan" id="kobo.66.1">Some real-world examples</span><a id="_idIndexMarker202"/><span class="koboSpan" id="kobo.67.1"> of image data analysis and AI applications</span><a id="_idIndexMarker203"/><span class="koboSpan" id="kobo.68.1"> are </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.70.1">Autonomous vehicles</span></strong><span class="koboSpan" id="kobo.71.1">: Image data plays a crucial role in enabling autonomous vehicles to perceive their surroundings. </span><span class="koboSpan" id="kobo.71.2">Cameras mounted on vehicles capture images of the road and surroundings, and machine learning algorithms analyze these images to detect and recognize objects such as pedestrians, vehicles, and </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">traffic signs.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.73.1">Medical image analysis</span></strong><span class="koboSpan" id="kobo.74.1">: In the field of medical imaging, machine learning is used for tasks such as tumor detection, organ segmentation, and disease diagnosis. </span><span class="koboSpan" id="kobo.74.2">Radiological images, such as X-rays, MRIs, and CT scans, are analyzed to identify anomalies and assist healthcare professionals in making </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">informed decisions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.76.1">Retail and e-commerce</span></strong><span class="koboSpan" id="kobo.77.1">: Object detection is employed in retail for inventory management and customer experience improvement. </span><span class="koboSpan" id="kobo.77.2">For example, automated checkout systems use computer vision to recognize and tally products in a shopping cart, enhancing the efficiency of the </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">checkout process.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.79.1">Security and surveillance</span></strong><span class="koboSpan" id="kobo.80.1">: Image data is utilized in security systems for surveillance and threat detection. </span><span class="koboSpan" id="kobo.80.2">Machine learning models can analyze video feeds to identify and alert authorities about suspicious activities, intruders, or unusual behavior in </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">public spaces.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.82.1">Facial recognition</span></strong><span class="koboSpan" id="kobo.83.1">: Facial recognition technology relies on image data to identify and verify individuals. </span><span class="koboSpan" id="kobo.83.2">This is used in various applications, including smartphone authentication, access control systems, and law enforcement for </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">criminal identification.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.85.1">Augmented Reality (AR)</span></strong><span class="koboSpan" id="kobo.86.1">: AR applications overlay digital information onto the real world. </span><span class="koboSpan" id="kobo.86.2">Image data is essential for tracking and recognizing objects and surfaces, enabling realistic and interactive </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">AR experiences.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.88.1">Quality control in manufacturing</span></strong><span class="koboSpan" id="kobo.89.1">: Computer vision is employed in manufacturing to inspect products for defects and ensure quality. </span><span class="koboSpan" id="kobo.89.2">Automated systems analyze images of products on assembly lines, identifying any deviations from the </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">desired specifications.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.91.1">Satellite image analysis</span></strong><span class="koboSpan" id="kobo.92.1">: Satellite imagery is used for various purposes, including land cover classification, environmental monitoring, and disaster response. </span><span class="koboSpan" id="kobo.92.2">Machine learning algorithms can analyze satellite images to identify changes in</span><a id="_idIndexMarker204"/><span class="koboSpan" id="kobo.93.1"> landscapes, detect deforestation, or </span><a id="_idIndexMarker205"/><span class="koboSpan" id="kobo.94.1">assess the impact of </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">natural disasters.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.96.1">These examples illustrate the diverse applications of image data in machine learning, computer vision, and object detection, showcasing its significance in solving real-world problems across </span><span class="No-Break"><span class="koboSpan" id="kobo.97.1">different domains.</span></span></p>
<p><span class="koboSpan" id="kobo.98.1">The following are some steps to follow when conducting EDA for </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">image data.</span></span></p>
<h2 id="_idParaDest-82"><a id="_idTextAnchor085"/><span class="koboSpan" id="kobo.100.1">Loading the data</span></h2>
<p><span class="koboSpan" id="kobo.101.1">The first </span><a id="_idIndexMarker206"/><span class="koboSpan" id="kobo.102.1">step in any EDA process is to load the image data into your </span><strong class="bold"><span class="koboSpan" id="kobo.103.1">Integrated Development Environment </span></strong><span class="koboSpan" id="kobo.104.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.105.1">IDE</span></strong><span class="koboSpan" id="kobo.106.1">) workspace, such as VS Code, Jupyter Notebook, or any other Python editor. </span><span class="koboSpan" id="kobo.106.2">Depending on the format of the data, you may need to use a library such as OpenCV or PIL to read in </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">the images.</span></span></p>
<h2 id="_idParaDest-83"><a id="_idTextAnchor086"/><span class="koboSpan" id="kobo.108.1">Checking the dimensions</span></h2>
<p><span class="koboSpan" id="kobo.109.1">The </span><a id="_idIndexMarker207"/><span class="koboSpan" id="kobo.110.1">next step is to check the dimensions of the images. </span><span class="koboSpan" id="kobo.110.2">Image dimensions can affect the performance of your model, as larger images require more memory and computation. </span><span class="koboSpan" id="kobo.110.3">You should also check that all the images have the same dimensions, as this is a requirement for most computer vision models. </span><span class="koboSpan" id="kobo.110.4">If the images are not of the same size, then preprocessing is required to convert them to the </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">same size.</span></span></p>
<h2 id="_idParaDest-84"><a id="_idTextAnchor087"/><span class="koboSpan" id="kobo.112.1">Visualizing the data</span></h2>
<p><span class="koboSpan" id="kobo.113.1">Visualization is a </span><a id="_idIndexMarker208"/><span class="koboSpan" id="kobo.114.1">powerful tool for understanding image data. </span><span class="koboSpan" id="kobo.114.2">You can use the Matplotlib or Seaborn libraries to visualize the data in various ways. </span><span class="koboSpan" id="kobo.114.3">You can plot histograms of pixel values to see their distributions or use scatter plots to visualize the relationship between pixel values. </span><span class="koboSpan" id="kobo.114.4">We will cover this later in </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">this chapter.</span></span></p>
<h2 id="_idParaDest-85"><a id="_idTextAnchor088"/><span class="koboSpan" id="kobo.116.1">Checking for outliers</span></h2>
<p><span class="koboSpan" id="kobo.117.1">Outliers can have a</span><a id="_idIndexMarker209"/><span class="koboSpan" id="kobo.118.1"> significant impact on your model’s performance. </span><span class="koboSpan" id="kobo.118.2">You should check for outliers in your image data by plotting boxplots and examining the distribution of pixel values. </span><span class="koboSpan" id="kobo.118.3">In the context of image data, outliers are data points (in this case, images) that significantly deviate from the expected or normal distribution of the dataset. </span><span class="koboSpan" id="kobo.118.4">Outliers in image data are images that have distinct characteristics or patterns that are different from the majority of images in the dataset. </span><span class="koboSpan" id="kobo.118.5">Images with pixel values that are much higher or lower than the typical range for the dataset can be considered outliers. </span><span class="koboSpan" id="kobo.118.6">These extreme values might be due to sensor malfunctions, data corruption, or other anomalies. </span><span class="koboSpan" id="kobo.118.7">Images with color distributions that significantly differ from the expected color distributions of the dataset can be considered outliers. </span><span class="koboSpan" id="kobo.118.8">These might be images with unusual color casts, saturation, </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">or intensity.</span></span></p>
<h2 id="_idParaDest-86"><a id="_idTextAnchor089"/><span class="koboSpan" id="kobo.120.1">Performing data preprocessing</span></h2>
<p><span class="koboSpan" id="kobo.121.1">Preprocessing is </span><a id="_idIndexMarker210"/><span class="koboSpan" id="kobo.122.1">an important step in EDA, as it can help to reduce noise and improve</span><a id="_idIndexMarker211"/><span class="koboSpan" id="kobo.123.1"> the quality of the images. </span><span class="koboSpan" id="kobo.123.2">Common preprocessing techniques include resizing, normalization, data augmentation, image segmentation, and </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">feature extraction.</span></span></p>
<p><span class="koboSpan" id="kobo.125.1">In image data, preprocessing involves </span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">several steps.</span></span></p>
<h3><span class="koboSpan" id="kobo.127.1">1. </span><span class="koboSpan" id="kobo.127.2">Image resizing</span></h3>
<p><span class="koboSpan" id="kobo.128.1">The first step in </span><a id="_idIndexMarker212"/><span class="koboSpan" id="kobo.129.1">preprocessing image data is resizing the images. </span><span class="koboSpan" id="kobo.129.2">Image resizing is essential because we </span><a id="_idIndexMarker213"/><span class="koboSpan" id="kobo.130.1">need all the images to be of the same size. </span><span class="koboSpan" id="kobo.130.2">If we do not make sure to resize the images, we may end up with images of different sizes, which can lead to issues </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">during training.</span></span></p>
<h3><span class="koboSpan" id="kobo.132.1">2. </span><span class="koboSpan" id="kobo.132.2">Image normalization</span></h3>
<p><span class="koboSpan" id="kobo.133.1">The next step in preprocessing </span><a id="_idIndexMarker214"/><span class="koboSpan" id="kobo.134.1">image data is normalization. </span><span class="koboSpan" id="kobo.134.2">Normalization is essential because</span><a id="_idIndexMarker215"/><span class="koboSpan" id="kobo.135.1"> it helps to reduce the effect of lighting and color variations on the images. </span><span class="koboSpan" id="kobo.135.2">Normalization involves scaling the pixel values of the images to a specific range. </span><span class="koboSpan" id="kobo.135.3">The most common method of normalization is to scale the pixel values to the range [0,1]. </span><span class="koboSpan" id="kobo.135.4">Scaling pixel values to the range [0, 1] during image dataset normalization has several significant advantages and implications that make it a common and effective practice in various image processing and machine learning tasks. </span><span class="koboSpan" id="kobo.135.5">Here’s why this range is significant. </span><span class="koboSpan" id="kobo.135.6">Normalizing images to a common range ensures that all pixel values across different images have the same scale. </span><span class="koboSpan" id="kobo.135.7">This makes it easier for algorithms to compare and process images, as they don’t need to deal with varying pixel value ranges. </span><span class="koboSpan" id="kobo.135.8">The range [0, 1] is well suited for numerical stability in computations. </span><span class="koboSpan" id="kobo.135.9">Many machine learning algorithms and image processing techniques work best when dealing with values that are not too large or too small. </span><span class="koboSpan" id="kobo.135.10">Scaling to [0, 1] helps prevent numerical instability and issues such as exploding gradients </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">during training.</span></span></p>
<h3><span class="koboSpan" id="kobo.137.1">3. </span><span class="koboSpan" id="kobo.137.2">Image augmentation</span></h3>
<p><span class="koboSpan" id="kobo.138.1">Image augmentation</span><a id="_idIndexMarker216"/><span class="koboSpan" id="kobo.139.1"> is a technique used to increase the size of the training dataset by</span><a id="_idIndexMarker217"/><span class="koboSpan" id="kobo.140.1"> creating additional images. </span><span class="koboSpan" id="kobo.140.2">Image augmentation involves applying various transformations to the original images, such as rotation, flipping, zooming, and shearing. </span><span class="koboSpan" id="kobo.140.3">It is used in image classification and object detection tasks. </span><span class="koboSpan" id="kobo.140.4">Image augmentation is essential because it helps to reduce overfitting and improves the generalization of the model. </span><span class="koboSpan" id="kobo.140.5">Overfitting is a common problem in machine learning and deep learning where a model learns the training data so well that it starts capturing noise and random fluctuations in the data instead of the underlying patterns. </span><span class="koboSpan" id="kobo.140.6">It helps produce robust models. </span><span class="koboSpan" id="kobo.140.7">Excessive augmentation can lead to unrealistic models or overfitting, which can result in reduced generalization ability, limiting the model’s usefulness in </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">real-world scenarios.</span></span></p>
<p><span class="koboSpan" id="kobo.142.1">Adding</span><a id="_idIndexMarker218"/><span class="koboSpan" id="kobo.143.1"> more training data is one way to help reduce overfitting. </span><span class="koboSpan" id="kobo.143.2">However, in</span><a id="_idIndexMarker219"/><span class="koboSpan" id="kobo.144.1"> many situations, collecting a large amount of new, diverse data can be impractical or expensive. </span><span class="koboSpan" id="kobo.144.2">This is where data augmentation comes in. </span><span class="koboSpan" id="kobo.144.3">Data augmentation involves applying various transformations to the existing training data to artificially increase its size and diversity. </span><span class="koboSpan" id="kobo.144.4">Here’s how data augmentation helps reduce overfitting, particularly in the context of </span><span class="No-Break"><span class="koboSpan" id="kobo.145.1">image datasets:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.146.1">Improved generalization</span></strong><span class="koboSpan" id="kobo.147.1">: Augmentation helps the model generalize better to unseen data by exposing it to a diverse range of transformations. </span><span class="koboSpan" id="kobo.147.2">This can enhance the model’s ability to handle variations in </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">object appearance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.149.1">Robustness to variations</span></strong><span class="koboSpan" id="kobo.150.1">: Models trained with augmented data are often more robust to changes in lighting, orientation, and other factors that may be present in </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">real-world scenarios.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.152.1">Data efficiency</span></strong><span class="koboSpan" id="kobo.153.1">: Augmentation allows for the creation of a larger effective training dataset without collecting additional labeled samples. </span><span class="koboSpan" id="kobo.153.2">This can be particularly beneficial when the available labeled data </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">is limited.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.155.1">Mitigating overfitting</span></strong><span class="koboSpan" id="kobo.156.1">: Augmentation introduces variability, helping to prevent overfitting. </span><span class="koboSpan" id="kobo.156.2">Models trained on augmented data are less likely to memorize specific training examples and are more likely to learn </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">generalizable features.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.158.1">Considerations</span></strong><span class="koboSpan" id="kobo.159.1">: While augmentation is generally beneficial, it’s essential to apply transformations that make sense for the specific task. </span><span class="koboSpan" id="kobo.159.2">For example, randomly flipping images horizontally makes sense for many tasks, but randomly rotating images might not be suitable for tasks with strict </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">orientation requirements.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.161.1">4. </span><span class="koboSpan" id="kobo.161.2">Image segmentation</span></h3>
<p><span class="koboSpan" id="kobo.162.1">Image segmentation</span><a id="_idIndexMarker220"/><span class="koboSpan" id="kobo.163.1"> is the process of dividing an image into multiple meaningful segments or </span><a id="_idIndexMarker221"/><span class="koboSpan" id="kobo.164.1">regions. </span><span class="koboSpan" id="kobo.164.2">Image segmentation is essential in medical image analysis, where we need to identify the different organs or tissues in the image. </span><span class="koboSpan" id="kobo.164.3">Image segmentation is also used in object detection, where we need to identify the different objects in </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">an image.</span></span></p>
<h3><span class="koboSpan" id="kobo.166.1">5. </span><span class="koboSpan" id="kobo.166.2">Feature extraction</span></h3>
<p><span class="koboSpan" id="kobo.167.1">Feature extraction</span><a id="_idIndexMarker222"/><span class="koboSpan" id="kobo.168.1"> is the process of extracting relevant features or information</span><a id="_idIndexMarker223"/><span class="koboSpan" id="kobo.169.1"> from the image data. </span><span class="koboSpan" id="kobo.169.2">Feature extraction is essential because it helps to reduce the dimensionality of the image data, which can improve the performance of machine learning algorithms. </span><span class="koboSpan" id="kobo.169.3">Feature extraction involves applying various filters to the images, such as edge detection, texture analysis, and color segmentation. </span><span class="koboSpan" id="kobo.169.4">Examples of color features are color histograms that represent the distribution of color intensities in an image. </span><span class="koboSpan" id="kobo.169.5">Similarly, shape features include the Hough transform that detects and represents shapes such as lines </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">and circles.</span></span></p>
<p><span class="koboSpan" id="kobo.171.1">To summarize, data exploration and preprocessing are essential steps in the machine learning pipeline. </span><span class="koboSpan" id="kobo.171.2">In image data, we need to resize the images, normalize the pixel values, apply image augmentation, perform image segmentation, and extract relevant features from the images. </span><span class="koboSpan" id="kobo.171.3">By following these preprocessing steps, we can improve the performance of the machine learning algorithm and achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">better results.</span></span></p>
<h2 id="_idParaDest-87"><a id="_idTextAnchor090"/><span class="koboSpan" id="kobo.173.1">Checking for class imbalance</span></h2>
<p><span class="koboSpan" id="kobo.174.1">In many image classification </span><a id="_idIndexMarker224"/><span class="koboSpan" id="kobo.175.1">problems, the classes may not be evenly represented in the dataset. </span><span class="koboSpan" id="kobo.175.2">You should check for class imbalance by counting the number of images in each class and visualizing the distribution of classes. </span><span class="koboSpan" id="kobo.175.3">If there is an imbalance, we augment the minority class data by applying transformations such as rotations, flips, crops, and color variations. </span><span class="koboSpan" id="kobo.175.4">This increases the diversity of the minority class without needing to generate entirely </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">new samples.</span></span></p>
<h2 id="_idParaDest-88"><a id="_idTextAnchor091"/><span class="koboSpan" id="kobo.177.1">Identifying patterns and relationships</span></h2>
<p><span class="koboSpan" id="kobo.178.1">The goal of EDA is</span><a id="_idIndexMarker225"/><span class="koboSpan" id="kobo.179.1"> to identify patterns and relationships in the data that can inform your modeling decisions. </span><span class="koboSpan" id="kobo.179.2">You can use techniques such as clustering to identify patterns in the data or examine the relationship between different features using scatter plots or correlation matrices. </span><span class="koboSpan" id="kobo.179.3">Clustering, in the context of image dataset analysis, is a technique used to group similar images together based on their inherent patterns and characteristics. </span><span class="koboSpan" id="kobo.179.4">It’s a data exploration method that aids in understanding the structure of image data by identifying groups or clusters of images that share similar visual traits. </span><span class="koboSpan" id="kobo.179.5">Clustering algorithms analyze the visual properties of images, such as pixel values or extracted features, to group images that are visually similar into clusters. </span><span class="koboSpan" id="kobo.179.6">Images that share common visual traits are grouped together, forming </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">distinct clusters.</span></span></p>
<h2 id="_idParaDest-89"><a id="_idTextAnchor092"/><span class="koboSpan" id="kobo.181.1">Evaluating the impact of preprocessing</span></h2>
<p><span class="koboSpan" id="kobo.182.1">Finally, you should evaluate </span><a id="_idIndexMarker226"/><span class="koboSpan" id="kobo.183.1">the impact of preprocessing on your image data. </span><span class="koboSpan" id="kobo.183.2">You can compare the performance of your model on preprocessed and unprocessed data to determine the effectiveness of your </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">preprocessing techniques.</span></span></p>
<p><span class="koboSpan" id="kobo.185.1">In summary, EDA is an important step in the process of building computer vision models. </span><span class="koboSpan" id="kobo.185.2">By visualizing the data, checking for outliers and class imbalance, identifying patterns and relationships, and evaluating the impact of preprocessing, you can gain a better understanding of your image data and make informed decisions about your </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">modeling approach.</span></span></p>
<h2 id="_idParaDest-90"><a id="_idTextAnchor093"/><span class="koboSpan" id="kobo.187.1">Practice example of visualizing data</span></h2>
<p><span class="koboSpan" id="kobo.188.1">Let’s see an example of </span><a id="_idIndexMarker227"/><span class="koboSpan" id="kobo.189.1">visualizing image data using Matplotlib. </span><span class="koboSpan" id="kobo.189.2">In the following code, we first load the image using the </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">PIL library:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.191.1">
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
# Load an image
img = Image.open('../images/roseflower.jpeg')</span></pre> <p><span class="koboSpan" id="kobo.192.1">Then we convert it to a NumPy array using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.193.1">np.array</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.194.1"> function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.195.1">
# Convert image to numpy array
img_array = np.array(img)</span></pre> <p><span class="koboSpan" id="kobo.196.1">Next, plot the result with the </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">following commands:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.198.1">
# Plot the image
plt.imshow(img_array)
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.199.1">We get the </span><a id="_idIndexMarker228"/><span class="No-Break"><span class="koboSpan" id="kobo.200.1">following result:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer066">
<span class="koboSpan" id="kobo.201.1"><img alt="Figure 4.1﻿ – Visualizing image data" src="image/B18944_04_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.202.1">Figure 4.1 – Visualizing image data</span></p>
<p><span class="koboSpan" id="kobo.203.1">We then </span><a id="_idIndexMarker229"/><span class="koboSpan" id="kobo.204.1">use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.205.1">imshow</span></strong><span class="koboSpan" id="kobo.206.1"> function from Matplotlib to plot the image. </span><span class="koboSpan" id="kobo.206.2">Converting images to NumPy arrays during EDA offers several benefits that make data manipulation, analysis, and visualization more convenient and efficient. </span><span class="koboSpan" id="kobo.206.3">NumPy is a powerful numerical computing library in Python that provides support for multi-dimensional arrays and a wide range of mathematical operations. </span><span class="koboSpan" id="kobo.206.4">Converting images to NumPy arrays is common during EDA as NumPy arrays provide direct access to individual pixels in an image, making it easier to analyze pixel values and perform pixel-level operations. </span><span class="koboSpan" id="kobo.206.5">Many data analysis and visualization libraries in Python, including Matplotlib and scikit-learn, work seamlessly with NumPy arrays. </span><span class="koboSpan" id="kobo.206.6">This allows you to take advantage of a rich ecosystem of tools and techniques for </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">image analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.208.1">There are </span><a id="_idIndexMarker230"/><span class="koboSpan" id="kobo.209.1">many different ways to visualize image data using Matplotlib. </span><span class="koboSpan" id="kobo.209.2">We’ll now review a few commonly </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">encountered examples.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.211.1">Grayscale image</span></strong><span class="koboSpan" id="kobo.212.1">: To display a grayscale image, we can simply set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.213.1">cmap</span></strong><span class="koboSpan" id="kobo.214.1"> parameter of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.215.1">imshow</span></strong><span class="koboSpan" id="kobo.216.1"> function </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.218.1">'gray'</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.220.1">
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
img_color = Image.open('../images/roseflower.jpeg')
# Convert the image to grayscale
img_gray = img_color.convert('L')
# Convert the image to a NumPy array
img_gray_array = np.array(img_gray)
# Display the image using matplotlib
plt.imshow(img_gray_array, cmap='gray')
# Show the plot
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.221.1">The following figure is the result of </span><span class="No-Break"><span class="koboSpan" id="kobo.222.1">this code:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer067">
<span class="koboSpan" id="kobo.223.1"><img alt="Figure 4.2﻿ – Gr﻿ayscale image" src="image/B18944_04_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.224.1">Figure 4.2 – Grayscale image</span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.225.1">Histogram of pixel values</span></strong><span class="koboSpan" id="kobo.226.1">: We can use a histogram to visualize the distribution of pixel values</span><a id="_idIndexMarker231"/><span class="koboSpan" id="kobo.227.1"> in an image. </span><span class="koboSpan" id="kobo.227.2">This can help us understand the overall brightness and contrast of </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">the image:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.229.1">
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
# Load an image
img_color = Image.open('../images/roseflower.jpeg')
# Convert image to numpy array
img_array = np.array(img_color)
# Plot the histogram
plt.hist(img_array.ravel(), bins=256)
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.230.1">The</span><a id="_idIndexMarker232"/><span class="koboSpan" id="kobo.231.1"> resulting graph is </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer068">
<span class="koboSpan" id="kobo.233.1"><img alt="Figure 4.3﻿ – Histogram of pixel values" src="image/B18944_04_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.234.1">Figure 4.3 – Histogram of pixel values</span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.235.1">Multiple images side by side</span></strong><span class="koboSpan" id="kobo.236.1">: We can use subplots to display multiple images side by side </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">for comparison:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.238.1">
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
# Load two images
img1 = Image.open('./images/roseflower.jpeg')
img2 = Image.open('./images/roseflower.jpeg')
# Convert images to numpy arrays
img1_array = np.array(img1)
img2_array = np.array(img2)
# Plot the images side-by-side
fig, axes = plt.subplots(nrows=1, ncols=2)
axes[0].imshow(img1_array)
axes[1].imshow(img2_array)
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.239.1">We </span><a id="_idIndexMarker233"/><span class="koboSpan" id="kobo.240.1">get the stunning result </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer069">
<span class="koboSpan" id="kobo.242.1"><img alt="Figure 4.4﻿ – Multiple images side by side" src="image/B18944_04_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.243.1">Figure 4.4 – Multiple images side by side</span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.244.1">Color channel visualization</span></strong><span class="koboSpan" id="kobo.245.1">: For color images, we can plot each color channel separately to see how they contribute to the overall image. </span><span class="koboSpan" id="kobo.245.2">In an image dataset, a color channel refers to a single component of color information in each pixel of an image. </span><span class="koboSpan" id="kobo.245.3">Color images are composed of multiple color channels, where each channel represents a specific color aspect or color space. </span><span class="koboSpan" id="kobo.245.4">The combination of these color channels creates the full-color</span><a id="_idIndexMarker234"/><span class="koboSpan" id="kobo.246.1"> representation of an</span><a id="_idIndexMarker235"/><span class="koboSpan" id="kobo.247.1"> image. </span><span class="koboSpan" id="kobo.247.2">Common color spaces</span><a id="_idIndexMarker236"/><span class="koboSpan" id="kobo.248.1"> include </span><strong class="bold"><span class="koboSpan" id="kobo.249.1">Red, Green, Blue</span></strong><span class="koboSpan" id="kobo.250.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.251.1">RGB</span></strong><span class="koboSpan" id="kobo.252.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.253.1">Hue, Saturation, Value</span></strong><span class="koboSpan" id="kobo.254.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.255.1">HSV</span></strong><span class="koboSpan" id="kobo.256.1">), and </span><strong class="bold"><span class="koboSpan" id="kobo.257.1">Cyan, Magenta, Yellow, </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.258.1">Key/Black</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.259.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.260.1">CMYK</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.262.1">In general, RGB</span><a id="_idIndexMarker237"/><span class="koboSpan" id="kobo.263.1"> color channels are visualized using the appropriate colormap to represent their respective colors. </span><span class="koboSpan" id="kobo.263.2">When visualizing individual color channels (red, green, and blue) separately, it’s common to use colormaps that highlight the specific </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">color information.</span></span></p>
<p><span class="koboSpan" id="kobo.265.1">Here are typical colormaps used for visualizing individual </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">RGB channels:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.267.1">Red channel</span></strong><span class="koboSpan" id="kobo.268.1">: The </span><strong class="source-inline"><span class="koboSpan" id="kobo.269.1">'Reds'</span></strong><span class="koboSpan" id="kobo.270.1"> colormap is often used to visualize the red channel. </span><span class="koboSpan" id="kobo.270.2">It ranges from dark to light red, with the darker values representing lower intensity and the lighter values representing </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">higher intensity.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.272.1">Green channel</span></strong><span class="koboSpan" id="kobo.273.1">: The </span><strong class="source-inline"><span class="koboSpan" id="kobo.274.1">'Greens'</span></strong><span class="koboSpan" id="kobo.275.1"> colormap is commonly used to visualize the green channel. </span><span class="koboSpan" id="kobo.275.2">Similar to </span><strong class="source-inline"><span class="koboSpan" id="kobo.276.1">'Reds'</span></strong><span class="koboSpan" id="kobo.277.1">, it ranges from dark to </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">light green.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.279.1">Blue channel</span></strong><span class="koboSpan" id="kobo.280.1">: The </span><strong class="source-inline"><span class="koboSpan" id="kobo.281.1">'Blues'</span></strong><span class="koboSpan" id="kobo.282.1"> colormap is used for visualizing the blue channel. </span><span class="koboSpan" id="kobo.282.2">It ranges from dark to </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">light blue.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.284.1">Here’s an example of how you might visualize individual RGB channels using </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">these colormaps:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.286.1">
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
# Load a color image
img = Image.open('../images/roseflower.jpeg')
# Split the image into RGB channels
r, g, b = img.split()
# Convert channels to numpy arrays
r_array = np.array(r)
g_array = np.array(g)
b_array = np.array(b)
# Plot each channel separately
fig, axes = plt.subplots(nrows=1, ncols=3)
axes[0].imshow(r_array, cmap='Reds') # Use 'Reds' colormap for the red channel
axes[1].imshow(g_array, cmap='Greens') # Use 'Greens' colormap for the green channel
axes[2].imshow(b_array, cmap='Blues') # Use 'Blues' colormap for the blue channel
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.287.1">As a result, we</span><a id="_idIndexMarker238"/><span class="koboSpan" id="kobo.288.1"> see the </span><span class="No-Break"><span class="koboSpan" id="kobo.289.1">following channels:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer070">
<span class="koboSpan" id="kobo.290.1"><img alt="Figure 4.5﻿ – Color channel visualization" src="image/B18944_04_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.291.1">Figure 4.5 – Color channel visualization</span></p>
<h2 id="_idParaDest-91"><a id="_idTextAnchor094"/><span class="koboSpan" id="kobo.292.1">Practice example for adding annotations to an image</span></h2>
<p><span class="koboSpan" id="kobo.293.1">We</span><a id="_idIndexMarker239"/><span class="koboSpan" id="kobo.294.1"> can add annotations to an image to highlight specific regions of interest, such as marking key features within an image, perhaps facial landmarks on a person’s face (eyes, nose, mouth), to emphasize important attributes for analysis or recognition. </span><span class="koboSpan" id="kobo.294.2">Annotations can also be used to highlight regions that exhibit anomalies, defects, or irregularities in industrial inspection images, medical images, and quality control processes, along with identifying and marking specific points of interest, such as landmarks on a map. </span><span class="koboSpan" id="kobo.294.3">Let’s see annotations </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">at work:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.296.1">
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
# Load an image
img = Image.open('../images/roseflower.jpeg')
# Convert image to numpy array
img_array = np.array(img)
# Plot the image with annotations
plt.imshow(img_array)
plt.scatter(100, 200, c='r', s=50)
plt.annotate("Example annotation", (50, 50), fontsize=12, color='w')
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.297.1">We get the following result </span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">as output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer071">
<span class="koboSpan" id="kobo.299.1"><img alt="Figure 4.6﻿ – Image annotation" src="image/B18944_04_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.300.1">Figure 4.6 – Image annotation</span></p>
<p><span class="koboSpan" id="kobo.301.1">These are </span><a id="_idIndexMarker240"/><span class="koboSpan" id="kobo.302.1">just a few examples of the many ways that we can use Matplotlib to visualize image data. </span><span class="koboSpan" id="kobo.302.2">With some creativity and experimentation, we can create a wide variety of visualizations to help us understand our image </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">data better.</span></span></p>
<h2 id="_idParaDest-92"><a id="_idTextAnchor095"/><span class="koboSpan" id="kobo.304.1">Practice example of image segmentation</span></h2>
<p><span class="koboSpan" id="kobo.305.1">The</span><a id="_idIndexMarker241"/><span class="koboSpan" id="kobo.306.1"> following simple code snippet demonstrates how to perform basic image segmentation using the CIFAR-10 dataset and a simple </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">thresholding technique:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.308.1">
import numpy as np
import matplotlib.pyplot as plt
from keras.datasets import cifar10
# Load the CIFAR-10 dataset
(x_train, _), (_, _) = cifar10.load_data()
# Select a sample image for segmentation
sample_image = x_train[0]  # You can choose any index here
# Convert the image to grayscale (optional)
gray_image = np.mean(sample_image, axis=2)
# Apply a simple thresholding for segmentation
threshold = 100
segmented_image = np.where(\
    gray_image &gt; threshold, 255, 0).astype(np.uint8)
# Plot the original and segmented images
plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(sample_image)
plt.title('Original Image')
plt.subplot(1, 2, 2)
plt.imshow(segmented_image, cmap='gray')
plt.title('Segmented Image')
plt.tight_layout()
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.309.1">The result is </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer072">
<span class="koboSpan" id="kobo.311.1"><img alt="Figure 4.7﻿ – Image segmentation" src="image/B18944_04_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.312.1">Figure 4.7 – Image segmentation</span></p>
<p><span class="koboSpan" id="kobo.313.1">This </span><a id="_idIndexMarker242"/><span class="koboSpan" id="kobo.314.1">example uses a basic thresholding technique to segment the image based on pixel </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">intensity values.</span></span></p>
<h2 id="_idParaDest-93"><a id="_idTextAnchor096"/><span class="koboSpan" id="kobo.316.1">Practice example for feature extraction</span></h2>
<p><span class="koboSpan" id="kobo.317.1">Feature</span><a id="_idIndexMarker243"/><span class="koboSpan" id="kobo.318.1"> extraction from an image dataset such as CIFAR-10 involves transforming raw image data into a set of relevant features that can be used as input for machine learning models. </span><span class="koboSpan" id="kobo.318.2">Here’s a simple example using the </span><strong class="bold"><span class="koboSpan" id="kobo.319.1">Histogram of Oriented Gradients </span></strong><span class="koboSpan" id="kobo.320.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.321.1">HOG</span></strong><span class="koboSpan" id="kobo.322.1">) feature</span><a id="_idIndexMarker244"/> <span class="No-Break"><span class="koboSpan" id="kobo.323.1">extraction technique:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.324.1">
import numpy as np
import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import exposure
from keras.datasets import cifar10
# Load the CIFAR-10 dataset
(x_train, _), (_, _) = cifar10.load_data()
# Select a sample image for feature extraction
sample_image = x_train[0]  # You can choose any index here
# Convert the image to grayscale (optional)
gray_image = np.mean(sample_image, axis=2)
# Apply Histogram of Oriented Gradients (HOG) feature extraction
hog_features, hog_image = hog( \
    gray_image,pixels_per_cell=(8, 8),\
    cells_per_block=(2, 2), visualize=True)
# Plot the original image and its HOG representation
plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title('Original Grayscale Image')
plt.subplot(1, 2, 2)
plt.imshow(hog_image, cmap='gray')
plt.title('HOG Feature Extraction')
plt.tight_layout()
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.325.1">We </span><a id="_idIndexMarker245"/><span class="koboSpan" id="kobo.326.1">get the </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">following output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer073">
<span class="koboSpan" id="kobo.328.1"><img alt="Figure 4.8﻿ – HOG feature extraction" src="image/B18944_04_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.329.1">Figure 4.8 – HOG feature extraction</span></p>
<p><span class="koboSpan" id="kobo.330.1">Imagine you have a picture, and you want to understand what’s in the picture by looking at the patterns of</span><a id="_idIndexMarker246"/><span class="koboSpan" id="kobo.331.1"> lines and edges. </span><span class="koboSpan" id="kobo.331.2">HOG is a way to do that by focusing on the directions of lines and edges in </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">an image.</span></span></p>
<p><span class="koboSpan" id="kobo.333.1">In the preceding code block, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.334.1">hog</span></strong><span class="koboSpan" id="kobo.335.1"> function internally performs the following four steps to generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">HOG image:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.337.1">Divide the image into small cells</span></strong><span class="koboSpan" id="kobo.338.1">: First, the function takes the image and divide it into small boxes called cells. </span><span class="koboSpan" id="kobo.338.2">Think of these like little squares placed over </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">the image.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.340.1">Calculate gradients</span></strong><span class="koboSpan" id="kobo.341.1">: Inside each cell, we look at how the colors change. </span><span class="koboSpan" id="kobo.341.2">If the colors change significantly, it means there’s probably an edge or a line. </span><span class="koboSpan" id="kobo.341.3">We figure out the direction of this color change, and this is called a gradient. </span><span class="koboSpan" id="kobo.341.4">Imagine drawing little arrows to show the directions of these </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">color changes.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.343.1">Group arrows into directions</span></strong><span class="koboSpan" id="kobo.344.1">: Now, we group these little arrows with similar directions together. </span><span class="koboSpan" id="kobo.344.2">This is like saying, “Hey, there are a lot of edges going this way, and a lot of edges going </span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">that way.”</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.346.1">Make a histogram of the directions</span></strong><span class="koboSpan" id="kobo.347.1">: A histogram is like a chart that shows how many times something happens. </span><span class="koboSpan" id="kobo.347.2">Here, we make a histogram that shows how many arrows are pointing in each direction. </span><span class="koboSpan" id="kobo.347.3">This tells us which directions of edges and </span><a id="_idIndexMarker247"/><span class="koboSpan" id="kobo.348.1">lines are more common in </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">that cell.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.350.1">In this section, we have seen how to visualize the image data and plot various features including color pixel histograms, grayscale images, RGB color channels, image segmentation, and annotations </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">on images.</span></span></p>
<p><span class="koboSpan" id="kobo.352.1">In the next section, we will examine the importance of image size and aspect ratio distribution in image </span><span class="No-Break"><span class="koboSpan" id="kobo.353.1">data models.</span></span></p>
<h1 id="_idParaDest-94"><a id="_idTextAnchor097"/><span class="koboSpan" id="kobo.354.1">Analyzing image size and aspect ratio</span></h1>
<p><span class="koboSpan" id="kobo.355.1">It is very important to</span><a id="_idIndexMarker248"/><span class="koboSpan" id="kobo.356.1"> understand the distribution of image sizes and aspect ratios in image </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">data models.</span></span></p>
<p><span class="koboSpan" id="kobo.358.1">Aspect ratio, in the context of image dataset EDA, refers to the proportional relationship between the width and height of an image. </span><span class="koboSpan" id="kobo.358.2">It’s a numerical representation that helps describe the shape of an image. </span><span class="koboSpan" id="kobo.358.3">Aspect ratio is especially important when working with images, as it provides insights into how elongated or compressed an image appears visually. </span><span class="koboSpan" id="kobo.358.4">Mathematically, the aspect ratio is calculated by dividing the width of the image by its height. </span><span class="koboSpan" id="kobo.358.5">It’s typically expressed as a ratio or a decimal value. </span><span class="koboSpan" id="kobo.358.6">A square image has an aspect ratio of 1:1, while a rectangular image would have an aspect ratio different </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">from 1:1.</span></span></p>
<h2 id="_idParaDest-95"><a id="_idTextAnchor098"/><span class="koboSpan" id="kobo.360.1">Impact of aspect ratios on model performance</span></h2>
<p><span class="koboSpan" id="kobo.361.1">Let’s understand the impact of </span><a id="_idIndexMarker249"/><span class="koboSpan" id="kobo.362.1">aspect ratios on the model performance using the </span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">following points:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.364.1">Object recognition</span></strong><span class="koboSpan" id="kobo.365.1">: In object recognition</span><a id="_idIndexMarker250"/><span class="koboSpan" id="kobo.366.1"> tasks, maintaining the correct aspect ratio is essential for accurate detection. </span><span class="koboSpan" id="kobo.366.2">If the aspect ratio is distorted during preprocessing or augmentation, it may lead to misinterpretation of object shapes by </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">the model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.368.1">Training stability</span></strong><span class="koboSpan" id="kobo.369.1">: Ensuring consistent aspect ratios across the training dataset can contribute to training stability. </span><span class="koboSpan" id="kobo.369.2">Models may struggle if they encounter variations in aspect ratios that were not present in the </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">training data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.371.1">Bounding-box accuracy</span></strong><span class="koboSpan" id="kobo.372.1">: In object detection, bounding boxes</span><a id="_idIndexMarker251"/><span class="koboSpan" id="kobo.373.1"> are often defined by aspect ratios. </span><span class="koboSpan" id="kobo.373.2">Deviations from the expected aspect ratios can impact the accuracy of bounding </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">box predictions.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.375.1">Let’s consider a scenario where we have an image represented by a matrix with dimensions </span><em class="italic"><span class="koboSpan" id="kobo.376.1">M×N</span></em><span class="koboSpan" id="kobo.377.1">, where </span><em class="italic"><span class="koboSpan" id="kobo.378.1">M</span></em><span class="koboSpan" id="kobo.379.1"> is the number of rows (height) and </span><em class="italic"><span class="koboSpan" id="kobo.380.1">N</span></em><span class="koboSpan" id="kobo.381.1"> is the number of columns (width). </span><span class="koboSpan" id="kobo.381.2">The image size, aspect ratio, and pixel aspect ratio can be calculated </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.383.1">Image size</span></strong><span class="koboSpan" id="kobo.384.1">: Image size</span><a id="_idIndexMarker252"/><span class="koboSpan" id="kobo.385.1"> is the total number of pixels in the image and is calculated by multiplying the number of rows (</span><em class="italic"><span class="koboSpan" id="kobo.386.1">M</span></em><span class="koboSpan" id="kobo.387.1">) by the number of </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">columns (</span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.389.1">N</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">).</span></span><p class="list-inset"><em class="italic"><span class="koboSpan" id="kobo.391.1">Image size = </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.392.1">M×N</span></em></span></p><p class="list-inset"><span class="koboSpan" id="kobo.393.1">Example: If we have an image with dimensions </span><strong class="source-inline"><span class="koboSpan" id="kobo.394.1">300×200</span></strong><span class="koboSpan" id="kobo.395.1">, the image size would be </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.396.1">300×200=60,000</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.397.1"> pixels.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.398.1">Aspect ratio</span></strong><span class="koboSpan" id="kobo.399.1">: The aspect ratio</span><a id="_idIndexMarker253"/><span class="koboSpan" id="kobo.400.1"> is the ratio of the width to the height of the image and is calculated by dividing the number of columns (</span><em class="italic"><span class="koboSpan" id="kobo.401.1">N</span></em><span class="koboSpan" id="kobo.402.1">) by the number of </span><span class="No-Break"><span class="koboSpan" id="kobo.403.1">rows (</span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.404.1">M</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">).</span></span><p class="list-inset"><span class="koboSpan" id="kobo.406.1">Aspect ratio = </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.407.1">N</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">/</span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.409.1">M</span></em></span></p><p class="list-inset"><span class="koboSpan" id="kobo.410.1">Example: For an image</span><a id="_idIndexMarker254"/><span class="koboSpan" id="kobo.411.1"> with dimensions </span><strong class="source-inline"><span class="koboSpan" id="kobo.412.1">300×200</span></strong><span class="koboSpan" id="kobo.413.1">, the aspect ratio would be 200/300, which simplifies </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">to 2/3.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.415.1">Pixel Aspect Ratio (PAR)</span></strong><span class="koboSpan" id="kobo.416.1">: It is the ratio of the width of a pixel to its height. </span><span class="koboSpan" id="kobo.416.2">This is </span><a id="_idIndexMarker255"/><span class="koboSpan" id="kobo.417.1">especially relevant when dealing with </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">non-square pixels.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.419.1">PAR = </span><em class="italic"><span class="koboSpan" id="kobo.420.1">Height of pixel</span></em><span class="koboSpan" id="kobo.421.1">/</span><em class="italic"><span class="koboSpan" id="kobo.422.1">Width </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.423.1">of pixel</span></em></span></p><p class="list-inset"><span class="koboSpan" id="kobo.424.1">Example: If the pixel aspect ratio is 3/4, it means that the width of a pixel is three-quarters of </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">its height.</span></span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.426.1">These mathematical examples provide a basic understanding of how image size, aspect ratio, and pixel aspect ratio can be calculated using </span><span class="No-Break"><span class="koboSpan" id="kobo.427.1">simple formulas.</span></span></p>
<p><span class="koboSpan" id="kobo.428.1">Now, let’s delve into the concepts of padding, cropping, and aspect ratio evaluation metrics in the context of image data analysis in </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1">machine learning:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.430.1">Padding</span></strong><span class="koboSpan" id="kobo.431.1"> involves adding</span><a id="_idIndexMarker256"/><span class="koboSpan" id="kobo.432.1"> extra pixels around the edges of an image. </span><span class="koboSpan" id="kobo.432.2">This is often done to ensure that the spatial dimensions of the input images remain consistent, especially when applying convolutional operations in neural networks. </span><span class="koboSpan" id="kobo.432.3">Padding can be applied symmetrically, adding pixels equally on all sides, or asymmetrically, depending on the requirements of </span><span class="No-Break"><span class="koboSpan" id="kobo.433.1">the model.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.434.1">Example: Suppose you have an image of size </span><strong class="source-inline"><span class="koboSpan" id="kobo.435.1">200×200</span></strong><span class="koboSpan" id="kobo.436.1"> pixels, and you want to apply a </span><strong class="source-inline"><span class="koboSpan" id="kobo.437.1">3×3</span></strong><span class="koboSpan" id="kobo.438.1"> convolutional filter. </span><span class="koboSpan" id="kobo.438.2">Without padding, the output size would be </span><strong class="source-inline"><span class="koboSpan" id="kobo.439.1">198×198</span></strong><span class="koboSpan" id="kobo.440.1">. </span><span class="koboSpan" id="kobo.440.2">To maintain the spatial size, you can add a border of one pixel around the image, resulting in a </span><strong class="source-inline"><span class="koboSpan" id="kobo.441.1">202×202</span></strong><span class="koboSpan" id="kobo.442.1"> image </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">after padding.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.444.1">Cropping</span></strong><span class="koboSpan" id="kobo.445.1"> involves removing portions of an image, typically from the borders. </span><span class="koboSpan" id="kobo.445.2">This is often done to focus on specific regions of interest or to resize the image. </span><span class="koboSpan" id="kobo.445.3">Cropping</span><a id="_idIndexMarker257"/><span class="koboSpan" id="kobo.446.1"> can help eliminate irrelevant information and reduce the </span><span class="No-Break"><span class="koboSpan" id="kobo.447.1">computational load.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.448.1">Example: If you have an image of size </span><strong class="source-inline"><span class="koboSpan" id="kobo.449.1">300×300</span></strong><span class="koboSpan" id="kobo.450.1"> pixels and you decide to crop the central region, you might end up with a </span><strong class="source-inline"><span class="koboSpan" id="kobo.451.1">200×200</span></strong><span class="koboSpan" id="kobo.452.1"> pixel image by removing </span><strong class="source-inline"><span class="koboSpan" id="kobo.453.1">50</span></strong><span class="koboSpan" id="kobo.454.1"> pixels from </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">each side.</span></span></p></li>
<li><span class="koboSpan" id="kobo.456.1">Aspect ratio evaluation</span><a id="_idIndexMarker258"/><span class="koboSpan" id="kobo.457.1"> metrics are measures used to assess the similarity between the aspect ratio of predicted bounding boxes and the ground truth bounding boxes in object detection tasks. </span><span class="koboSpan" id="kobo.457.2">Common metrics include </span><strong class="bold"><span class="koboSpan" id="kobo.458.1">Intersection over Union</span></strong><span class="koboSpan" id="kobo.459.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.460.1">IoU</span></strong><span class="koboSpan" id="kobo.461.1">) and </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">F1 score.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.463.1">In image classification, aspect ratio evaluation metrics play a crucial role in gauging the accuracy of predicted bounding boxes compared to the ground truth bounding boxes in object detection tasks. </span><span class="koboSpan" id="kobo.463.2">One widely employed metric is IoU, calculated </span><a id="_idIndexMarker259"/><span class="koboSpan" id="kobo.464.1">by dividing the area of overlap between the predicted and ground truth bounding boxes by the total area covered by both. </span><span class="koboSpan" id="kobo.464.2">The resulting IoU score ranges from </span><strong class="source-inline"><span class="koboSpan" id="kobo.465.1">0</span></strong><span class="koboSpan" id="kobo.466.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.467.1">1</span></strong><span class="koboSpan" id="kobo.468.1">, where a score of </span><strong class="source-inline"><span class="koboSpan" id="kobo.469.1">0</span></strong><span class="koboSpan" id="kobo.470.1"> indicates no overlap, and a score of </span><strong class="source-inline"><span class="koboSpan" id="kobo.471.1">1</span></strong><span class="koboSpan" id="kobo.472.1"> signifies perfect alignment. </span><span class="koboSpan" id="kobo.472.2">Additionally, the F1 score, another common metric, combines precision and recall, providing a balanced assessment of the model’s performance in maintaining accurate aspect ratios across predicted and true bounding boxes. </span><span class="koboSpan" id="kobo.472.3">These metrics collectively offer valuable insights into the effectiveness of object detection models in preserving the spatial relationships of objects within </span><span class="No-Break"><span class="koboSpan" id="kobo.473.1">an image.</span></span></p>
<p><span class="koboSpan" id="kobo.474.1">Example: Let’s say that in an object detection task, you have a ground-truth bounding box with an aspect ratio of </span><strong class="source-inline"><span class="koboSpan" id="kobo.475.1">2:1</span></strong><span class="koboSpan" id="kobo.476.1"> for a specific object. </span><span class="koboSpan" id="kobo.476.2">If your model predicts a bounding box with an aspect ratio of </span><strong class="source-inline"><span class="koboSpan" id="kobo.477.1">1.5:1</span></strong><span class="koboSpan" id="kobo.478.1">, you can use IoU to measure how well the predicted box aligns with the ground truth. </span><span class="koboSpan" id="kobo.478.2">If the IoU metric is high, it indicates good alignment; if it’s low, there may be a mismatch in </span><span class="No-Break"><span class="koboSpan" id="kobo.479.1">aspect ratios.</span></span></p>
<p><span class="koboSpan" id="kobo.480.1">Understanding and effectively applying padding, cropping, and aspect ratio evaluation metrics are crucial aspects of preprocessing and evaluating image data in machine learning models, particularly in tasks such as object detection where accurate bounding box predictions </span><span class="No-Break"><span class="koboSpan" id="kobo.481.1">are essential.</span></span></p>
<h2 id="_idParaDest-96"><a id="_idTextAnchor099"/><span class="koboSpan" id="kobo.482.1">Image resizing</span></h2>
<p><span class="koboSpan" id="kobo.483.1">Image resizing</span><a id="_idIndexMarker260"/><span class="koboSpan" id="kobo.484.1"> is the process of changing the dimensions of an image while preserving its aspect ratio. </span><span class="koboSpan" id="kobo.484.2">It is a common preprocessing step in computer vision applications, including object detection, image classification, and </span><span class="No-Break"><span class="koboSpan" id="kobo.485.1">image segmentation.</span></span></p>
<p><span class="koboSpan" id="kobo.486.1">The primary reasons for</span><a id="_idIndexMarker261"/><span class="koboSpan" id="kobo.487.1"> resizing images are </span><span class="No-Break"><span class="koboSpan" id="kobo.488.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.489.1">To fit the image into a specific display size or aspect ratio, such as for web pages or </span><span class="No-Break"><span class="koboSpan" id="kobo.490.1">mobile applications.</span></span></li>
<li><span class="koboSpan" id="kobo.491.1">To reduce the computational complexity of processing the image, such as for real-time computer vision applications or when the image size is too large to fit </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">into memory.</span></span></li>
<li><span class="koboSpan" id="kobo.493.1">When resizing an image, we need to decide on a new size for the image. </span><span class="koboSpan" id="kobo.493.2">The new size can be specified in terms of pixels or as a scaling factor. </span><span class="koboSpan" id="kobo.493.3">In the latter case, we multiply the original image dimensions by a scaling factor to obtain the </span><span class="No-Break"><span class="koboSpan" id="kobo.494.1">new dimensions.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.495.1">There are two primary methods for resizing an image: interpolation </span><span class="No-Break"><span class="koboSpan" id="kobo.496.1">and resampling:</span></span></p>
<p><span class="koboSpan" id="kobo.497.1">Interpolation </span><a id="_idIndexMarker262"/><span class="koboSpan" id="kobo.498.1">is a technique for estimating the </span><a id="_idIndexMarker263"/><span class="koboSpan" id="kobo.499.1">pixel values in the resized image. </span><span class="koboSpan" id="kobo.499.2">It involves computing a weighted average of the pixel values in the original image surrounding the target pixel location. </span><span class="koboSpan" id="kobo.499.3">There are several interpolation methods available, including nearest neighbor, bilinear, bicubic, and </span><span class="No-Break"><span class="koboSpan" id="kobo.500.1">Lanczos resampling.</span></span></p>
<p><span class="koboSpan" id="kobo.501.1">Lanczos resampling</span><a id="_idIndexMarker264"/><span class="koboSpan" id="kobo.502.1"> is a method used in digital image processing for resizing or resampling images. </span><span class="koboSpan" id="kobo.502.2">It is a type of interpolation algorithm that aims to produce high-quality results, particularly when downscaling images. </span><span class="koboSpan" id="kobo.502.3">The Lanczos algorithm is named after Cornelius Lanczos, a Hungarian mathematician and physicist. </span><span class="koboSpan" id="kobo.502.4">The Lanczos resampling algorithm involves applying a sinc function (a type of mathematical function) to the pixel values in the original image to calculate the values of pixels in the resized image. </span><span class="koboSpan" id="kobo.502.5">This process is more complex than simple interpolation methods such as bilinear or bicubic, but it tends to produce better results, especially when reducing the size of </span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">an image.</span></span></p>
<p><span class="koboSpan" id="kobo.504.1">The</span><a id="_idIndexMarker265"/><span class="koboSpan" id="kobo.505.1"> following is a simple example in Python using the Pillow library (a fork of PIL) to demonstrate nearest neighbor, bilinear, bicubic, and Lanczos </span><span class="No-Break"><span class="koboSpan" id="kobo.506.1">resampling methods</span></span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.508.1">
from PIL import Image
# Open an example image
image_path = "../images/roseflower.jpeg"
image = Image.open(image_path)
# Resize the image using different interpolation methods
nearest_neighbor_resized = image.resize((100, 100), \
    resample=Image.NEAREST)
bilinear_resized = image.resize((100, 100), \
    resample=Image.BILINEAR)
bicubic_resized = image.resize((100, 100), \
    resample=Image.BICUBIC)
lanczos_resized = image.resize((100, 100), \
    resample=Image.LANCZOS)
# Save the resized images
nearest_neighbor_resized.save("nearest_neighbor_resized.jpg")
bilinear_resized.save("bilinear_resized.jpg")
bicubic_resized.save("bicubic_resized.jpg")
lanczos_resized.save("lanczos_resized.jpg")</span></pre> <p><span class="koboSpan" id="kobo.509.1">We get the </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1">following output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer074">
<span class="koboSpan" id="kobo.511.1"><img alt="Figure 4.9﻿ – ﻿The results of each interpolation method" src="image/B18944_04_X_Merged_images.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.512.1">Figure 4.9 – The results of each interpolation method</span></p>
<p><span class="koboSpan" id="kobo.513.1">Let’s delve into the details of</span><a id="_idIndexMarker266"/><span class="koboSpan" id="kobo.514.1"> each </span><span class="No-Break"><span class="koboSpan" id="kobo.515.1">interpolation method:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.516.1">Nearest neighbor method</span></strong><span class="koboSpan" id="kobo.517.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.518.1">Image.NEAREST</span></strong><span class="koboSpan" id="kobo.519.1">): This method chooses the nearest pixel value to</span><a id="_idIndexMarker267"/><span class="koboSpan" id="kobo.520.1"> the </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">interpolated point:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.522.1">Usage</span></strong><span class="koboSpan" id="kobo.523.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.524.1">resample=Image.NEAREST</span></strong><span class="koboSpan" id="kobo.525.1">): Simple and fast. </span><span class="koboSpan" id="kobo.525.2">Often used for upscaling pixel </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">art images.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.527.1">Visual effect</span></strong><span class="koboSpan" id="kobo.528.1">: Results in blocky or pixelated images, especially noticeable </span><span class="No-Break"><span class="koboSpan" id="kobo.529.1">during upscaling.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.530.1">Bilinear method</span></strong><span class="koboSpan" id="kobo.531.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.532.1">Image.BILINEAR</span></strong><span class="koboSpan" id="kobo.533.1">): Uses a</span><a id="_idIndexMarker268"/><span class="koboSpan" id="kobo.534.1"> linear interpolation between the four </span><span class="No-Break"><span class="koboSpan" id="kobo.535.1">nearest pixels:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.536.1">Usage</span></strong><span class="koboSpan" id="kobo.537.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.538.1">resample=Image.BILINEAR</span></strong><span class="koboSpan" id="kobo.539.1">): Commonly used for general </span><span class="No-Break"><span class="koboSpan" id="kobo.540.1">image resizing</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.541.1">Visual effect</span></strong><span class="koboSpan" id="kobo.542.1">: Smoother than nearest neighbor but may result in some loss </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">of sharpness</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.544.1">Bicubic method</span></strong><span class="koboSpan" id="kobo.545.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.546.1">Image.BICUBIC</span></strong><span class="koboSpan" id="kobo.547.1">): Employs a</span><a id="_idIndexMarker269"/><span class="koboSpan" id="kobo.548.1"> cubic polynomial </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">for interpolation:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.550.1">Usage</span></strong><span class="koboSpan" id="kobo.551.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.552.1">resample=Image.BICUBIC</span></strong><span class="koboSpan" id="kobo.553.1">): Typically used for </span><span class="No-Break"><span class="koboSpan" id="kobo.554.1">high-quality downsampling</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.555.1">Visual effect</span></strong><span class="koboSpan" id="kobo.556.1">: Smoother than bilinear; often used for photographic images, but can introduce </span><span class="No-Break"><span class="koboSpan" id="kobo.557.1">slight blurring</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.558.1">Lanczos method</span></strong><span class="koboSpan" id="kobo.559.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.560.1">Image.LANCZOS</span></strong><span class="koboSpan" id="kobo.561.1">): Applies a </span><strong class="source-inline"><span class="koboSpan" id="kobo.562.1">sinc</span></strong><span class="koboSpan" id="kobo.563.1"> function as the </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">interpolation </span></span><span class="No-Break"><a id="_idIndexMarker270"/></span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">kernel:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.566.1">Usage</span></strong><span class="koboSpan" id="kobo.567.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.568.1">resample=Image.LANCZOS</span></strong><span class="koboSpan" id="kobo.569.1">): Preferred for downscaling images and </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">maintaining quality.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.571.1">Visual effect</span></strong><span class="koboSpan" id="kobo.572.1">: Generally produces the highest quality, especially noticeable in downscaling scenarios. </span><span class="koboSpan" id="kobo.572.2">May take longer </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">to compute.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.574.1">Choosing the </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.575.1">right method</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.576.1">:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.577.1">Quality versus speed</span></strong><span class="koboSpan" id="kobo.578.1">: Nearest neighbor is the fastest but may result in visible artifacts. </span><span class="koboSpan" id="kobo.578.2">Bicubic and Lanczos are often preferred for quality, sacrificing a bit </span><span class="No-Break"><span class="koboSpan" id="kobo.579.1">of speed.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.580.1">Downscaling versus upscaling</span></strong><span class="koboSpan" id="kobo.581.1">: Bicubic</span><a id="_idIndexMarker271"/><span class="koboSpan" id="kobo.582.1"> and Lanczos are commonly used for downscaling, while bilinear might be sufficient </span><span class="No-Break"><span class="koboSpan" id="kobo.583.1">for upscaling.</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.584.1">If the images do</span><a id="_idIndexMarker272"/><span class="koboSpan" id="kobo.585.1"> not show noticeable differences, it could be due to factors such as the original image’s characteristics, the magnitude of resizing, or the viewer’s display capabilities. </span><span class="koboSpan" id="kobo.585.2">Generally, for high-quality resizing, especially downscaling, Lanczos</span><a id="_idIndexMarker273"/><span class="koboSpan" id="kobo.586.1"> interpolation tends to provide superior results. </span><span class="koboSpan" id="kobo.586.2">If the images are small or the differences subtle, the choice of method may have </span><span class="No-Break"><span class="koboSpan" id="kobo.587.1">less impact.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.588.1">Resampling</span></strong><span class="koboSpan" id="kobo.589.1">: Resampling</span><a id="_idIndexMarker274"/><span class="koboSpan" id="kobo.590.1"> is the process of selecting a subset of the pixels from the original image to create the resized image. </span><span class="koboSpan" id="kobo.590.2">This method can result in</span><a id="_idIndexMarker275"/><span class="koboSpan" id="kobo.591.1"> loss of information or artifacts in the image due to the removal </span><span class="No-Break"><span class="koboSpan" id="kobo.592.1">of pixels.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.593.1">In Python, we can use the Pillow library for image resizing. </span><span class="koboSpan" id="kobo.593.2">Here is some example code for resizing an image using the </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1">Pillow library:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.595.1">
 #resizing Image
from PIL import Image
# Open image
img = Image.open('../images/roseflower.jpeg')
# Resize image
new_size = (200, 200)
resized_img = img.resize(new_size)
resized_img.save("resized_image.jpg")</span></pre> <p><span class="koboSpan" id="kobo.596.1">We get the </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1">following result:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<span class="koboSpan" id="kobo.598.1"><img alt="Figure 4.﻿10 – Resized image (200*200)" src="image/B18944_04_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.599.1">Figure 4.10 – Resized image (200*200)</span></p>
<p><span class="koboSpan" id="kobo.600.1">In the preceding</span><a id="_idIndexMarker276"/><span class="koboSpan" id="kobo.601.1"> code, we first open an image using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.602.1">Image.open()</span></strong><span class="koboSpan" id="kobo.603.1"> function from the Pillow library. </span><span class="koboSpan" id="kobo.603.2">We then define the new size of the image as a tuple </span><strong class="source-inline"><span class="koboSpan" id="kobo.604.1">(500, 500)</span></strong><span class="koboSpan" id="kobo.605.1">. </span><span class="koboSpan" id="kobo.605.2">Finally, we call the </span><strong class="source-inline"><span class="koboSpan" id="kobo.606.1">resize()</span></strong><span class="koboSpan" id="kobo.607.1"> method on the image object with the new size tuple as an argument, which returns a new resized image object. </span><span class="koboSpan" id="kobo.607.2">We then save the resized image using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.608.1">save()</span></strong><span class="koboSpan" id="kobo.609.1"> method with the </span><span class="No-Break"><span class="koboSpan" id="kobo.610.1">new filename.</span></span></p>
<p><span class="koboSpan" id="kobo.611.1">Let’s see one more example of resizing images using Python. </span><span class="koboSpan" id="kobo.611.2">We first import the necessary libraries: </span><strong class="source-inline"><span class="koboSpan" id="kobo.612.1">os</span></strong><span class="koboSpan" id="kobo.613.1"> for file and directory operations and </span><strong class="source-inline"><span class="koboSpan" id="kobo.614.1">cv2</span></strong><span class="koboSpan" id="kobo.615.1"> for image loading </span><span class="No-Break"><span class="koboSpan" id="kobo.616.1">and manipulation:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.617.1">
import os
import cv2</span></pre> <p><span class="koboSpan" id="kobo.618.1">We define the path to the image directory and get a list of all image filenames in the directory using a </span><span class="No-Break"><span class="koboSpan" id="kobo.619.1">list comprehension:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.620.1">
# Define the path to the image directory
img_dir = '../Images/resize_images'
# Get a list of all image filenames in the directory
img_files = [os.path.join(img_dir, f) \
    for f in os.listdir(img_dir) \
    if os.path.isfile(os.path.join(img_dir, f))]</span></pre> <p><span class="koboSpan" id="kobo.621.1">We define the new size of the images using a tuple </span><strong class="source-inline"><span class="koboSpan" id="kobo.622.1">(224, 224)</span></strong><span class="koboSpan" id="kobo.623.1"> in this example. </span><span class="koboSpan" id="kobo.623.2">You can change the tuple to any other size </span><span class="No-Break"><span class="koboSpan" id="kobo.624.1">you want:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.625.1">
# Define the new size of the images
new_size = (224, 224)</span></pre> <p><span class="koboSpan" id="kobo.626.1">We then</span><a id="_idIndexMarker277"/><span class="koboSpan" id="kobo.627.1"> resize the image </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.629.1">
# Loop through all the image files
for img_file in img_files:
    # Load the image using OpenCV
    img = cv2.imread(img_file)
    # Resize the image
    resized_img = cv2.resize(img, new_size)
    # Save the resized image with the same filename
    cv2.imwrite(img_file, resized_img)</span></pre> <p><span class="koboSpan" id="kobo.630.1">Here’s the output of the resized images in the </span><span class="No-Break"><span class="koboSpan" id="kobo.631.1">relevant directory:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer076">
<span class="koboSpan" id="kobo.632.1"><img alt="Figure 4.1﻿1 – Resized images in the directory" src="image/B18944_04_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.633.1">Figure 4.11 – Resized images in the directory</span></p>
<p><span class="koboSpan" id="kobo.634.1">We loop through all the image files using a </span><strong class="source-inline"><span class="koboSpan" id="kobo.635.1">for</span></strong><span class="koboSpan" id="kobo.636.1"> loop. </span><span class="koboSpan" id="kobo.636.2">For each image file, we load the image using OpenCV (</span><strong class="source-inline"><span class="koboSpan" id="kobo.637.1">cv2.imread()</span></strong><span class="koboSpan" id="kobo.638.1">), resize the image using </span><strong class="source-inline"><span class="koboSpan" id="kobo.639.1">cv2.resize()</span></strong><span class="koboSpan" id="kobo.640.1">, and save the resized image with the same filename </span><span class="No-Break"><span class="koboSpan" id="kobo.641.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.642.1">cv2.imwrite()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.643.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.644.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.645.1">cv2.resize()</span></strong><span class="koboSpan" id="kobo.646.1"> function takes three parameters: the image to resize, the new size of the image as a tuple </span><strong class="source-inline"><span class="koboSpan" id="kobo.647.1">(width, height)</span></strong><span class="koboSpan" id="kobo.648.1">, and an interpolation method. </span><span class="koboSpan" id="kobo.648.2">The default interpolation method is </span><strong class="source-inline"><span class="koboSpan" id="kobo.649.1">cv2.INTER_LINEAR</span></strong><span class="koboSpan" id="kobo.650.1">, which produces good results in </span><span class="No-Break"><span class="koboSpan" id="kobo.651.1">most cases.</span></span></p>
<p><span class="koboSpan" id="kobo.652.1">Resizing </span><a id="_idIndexMarker278"/><span class="koboSpan" id="kobo.653.1">an image is a common preprocessing step in image classification and object detection tasks. </span><span class="koboSpan" id="kobo.653.2">It is often necessary to resize images to a fixed size to ensure that all images have the same size and aspect ratio, which makes it easier to train machine learning models on the images. </span><span class="koboSpan" id="kobo.653.3">Resizing can also help to reduce the computational cost of processing images, as smaller images require less memory and computing resources than </span><span class="No-Break"><span class="koboSpan" id="kobo.654.1">larger images.</span></span></p>
<p><span class="koboSpan" id="kobo.655.1">In summary, image resizing is the process of changing the dimensions of an image while preserving its aspect ratio. </span><span class="koboSpan" id="kobo.655.2">It is a common preprocessing step in computer vision applications and can be performed using interpolation or resampling techniques. </span><span class="koboSpan" id="kobo.655.3">In Python, we can use the Pillow library for </span><span class="No-Break"><span class="koboSpan" id="kobo.656.1">image resizing.</span></span></p>
<h2 id="_idParaDest-97"><a id="_idTextAnchor100"/><span class="koboSpan" id="kobo.657.1">Image normalization</span></h2>
<p><span class="koboSpan" id="kobo.658.1">Image normalization is </span><a id="_idIndexMarker279"/><span class="koboSpan" id="kobo.659.1">a preprocessing technique that is commonly used in computer vision applications. </span><span class="koboSpan" id="kobo.659.2">The goal of image normalization is to transform the pixel values of an image that are within a certain range or have certain statistical properties. </span><span class="koboSpan" id="kobo.659.3">Normalization is used to reduce the impact of variations in lighting conditions or to standardize the color or brightness </span><span class="No-Break"><span class="koboSpan" id="kobo.660.1">of images.</span></span></p>
<p><span class="koboSpan" id="kobo.661.1">Normalization techniques typically involve scaling the pixel values of an image to fall within a certain range or modifying the distribution of pixel values to have certain statistical properties. </span><span class="koboSpan" id="kobo.661.2">There are many different techniques for image normalization, and the choice of technique depends on the specific application and the characteristics of the </span><span class="No-Break"><span class="koboSpan" id="kobo.662.1">image data.</span></span></p>
<p><span class="koboSpan" id="kobo.663.1">Here are some common techniques for </span><span class="No-Break"><span class="koboSpan" id="kobo.664.1">image normalization.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.665.1">Min-max normalization</span></strong><span class="koboSpan" id="kobo.666.1">: This</span><a id="_idIndexMarker280"/><span class="koboSpan" id="kobo.667.1"> technique scales the pixel values of an image so that they</span><a id="_idIndexMarker281"/><span class="koboSpan" id="kobo.668.1"> fall within a specified range, typically </span><strong class="source-inline"><span class="koboSpan" id="kobo.669.1">[0, 1]</span></strong><span class="koboSpan" id="kobo.670.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.671.1">[-1, 1]</span></strong><span class="koboSpan" id="kobo.672.1">. </span><span class="koboSpan" id="kobo.672.2">This can be done using the </span><span class="No-Break"><span class="koboSpan" id="kobo.673.1">following formula:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.674.1">
normalized_image = (image - min_value) / (max_value - min_value)</span></pre> <p><span class="koboSpan" id="kobo.675.1">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.676.1">min_value</span></strong><span class="koboSpan" id="kobo.677.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.678.1">max_value</span></strong><span class="koboSpan" id="kobo.679.1"> are the minimum and maximum pixel values in the </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">image, respectively.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.681.1">Z-score normalization</span></strong><span class="koboSpan" id="kobo.682.1">: This </span><a id="_idIndexMarker282"/><span class="koboSpan" id="kobo.683.1">technique modifies the distribution of pixel values in an</span><a id="_idIndexMarker283"/><span class="koboSpan" id="kobo.684.1"> image to have a mean of 0 and a standard deviation of 1. </span><span class="koboSpan" id="kobo.684.2">This can be done using the </span><span class="No-Break"><span class="koboSpan" id="kobo.685.1">following formula:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.686.1">
normalized_image = (image - mean_value) / std_value</span></pre> <p><span class="koboSpan" id="kobo.687.1">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.688.1">mean_value</span></strong><span class="koboSpan" id="kobo.689.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.690.1">std_value</span></strong><span class="koboSpan" id="kobo.691.1"> are the mean and standard deviation of the pixel values in the </span><span class="No-Break"><span class="koboSpan" id="kobo.692.1">image, respectively.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.693.1">Histogram equalization</span></strong><span class="koboSpan" id="kobo.694.1">: This </span><a id="_idIndexMarker284"/><span class="koboSpan" id="kobo.695.1">technique modifies the distribution of pixel values in an</span><a id="_idIndexMarker285"/><span class="koboSpan" id="kobo.696.1"> image to be more uniform. </span><span class="koboSpan" id="kobo.696.2">This can be done by computing the </span><strong class="bold"><span class="koboSpan" id="kobo.697.1">cumulative distribution function</span></strong><span class="koboSpan" id="kobo.698.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.699.1">CDF</span></strong><span class="koboSpan" id="kobo.700.1">) of the pixel values and mapping the pixel values to new values based </span><a id="_idIndexMarker286"/><span class="koboSpan" id="kobo.701.1">on </span><span class="No-Break"><span class="koboSpan" id="kobo.702.1">the CDF:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.703.1">
import cv2
# Load image
img = cv2.imread("image.jpg", 0)
# Apply histogram equalization
equalized_img = cv2.equalizeHist(img)</span></pre> <p><span class="koboSpan" id="kobo.704.1">In the preceding</span><a id="_idIndexMarker287"/><span class="koboSpan" id="kobo.705.1"> code, we first load an image using the OpenCV library. </span><span class="koboSpan" id="kobo.705.2">We then apply histogram equalization using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.706.1">equalizeHist()</span></strong><span class="koboSpan" id="kobo.707.1"> function, which returns a new image with a more uniform distribution of pixel values. </span><span class="koboSpan" id="kobo.707.2">OpenCV is a powerful and widely used open source library that plays a crucial role in image recognition and computer vision tasks. </span><span class="koboSpan" id="kobo.707.3">Its importance stems from its comprehensive collection of tools, functions, and algorithms designed to handle various aspects of image processing, analysis, </span><span class="No-Break"><span class="koboSpan" id="kobo.708.1">and recognition.</span></span></p>
<p><span class="koboSpan" id="kobo.709.1">Let’s see an example of image normalization using Python. </span><span class="koboSpan" id="kobo.709.2">We first import the necessary libraries: </span><strong class="source-inline"><span class="koboSpan" id="kobo.710.1">os</span></strong><span class="koboSpan" id="kobo.711.1"> for file and directory operations, </span><strong class="source-inline"><span class="koboSpan" id="kobo.712.1">cv2</span></strong><span class="koboSpan" id="kobo.713.1"> for image loading and manipulation, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.714.1">numpy</span></strong><span class="koboSpan" id="kobo.715.1"> for </span><span class="No-Break"><span class="koboSpan" id="kobo.716.1">mathematical operations:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.717.1">
import os
import cv2
import numpy as np</span></pre> <p><span class="koboSpan" id="kobo.718.1">We define the path to the image directory and get a list of all image filenames in the directory using a </span><span class="No-Break"><span class="koboSpan" id="kobo.719.1">list comprehension:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.720.1">
# Define the path to the image directory
img_dir = 'path/to/image/directory'
# Get a list of all image filenames in the directory
img_files = [os.path.join(img_dir, f) \
    for f in os.listdir(img_dir) \
    if os.path.isfile(os.path.join(img_dir, f))]</span></pre> <p><span class="koboSpan" id="kobo.721.1">We loop through all the image files using a </span><strong class="source-inline"><span class="koboSpan" id="kobo.722.1">for</span></strong><span class="koboSpan" id="kobo.723.1"> loop. </span><span class="koboSpan" id="kobo.723.2">For each image file, we load the image using </span><span class="No-Break"><span class="koboSpan" id="kobo.724.1">OpenCV (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.725.1">cv2.imread()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.726.1">):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.727.1">
# Loop through all the image files
for img_file in img_files:
    # Load the image using OpenCV
    img = cv2.imread(img_file)</span></pre> <p><span class="koboSpan" id="kobo.728.1">We convert the image to </span><strong class="source-inline"><span class="koboSpan" id="kobo.729.1">float32</span></strong><span class="koboSpan" id="kobo.730.1"> data type using </span><strong class="source-inline"><span class="koboSpan" id="kobo.731.1">astype(np.float32)</span></strong><span class="koboSpan" id="kobo.732.1">. </span><span class="koboSpan" id="kobo.732.2">This is necessary for the next step </span><span class="No-Break"><span class="koboSpan" id="kobo.733.1">of normalization:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.734.1">
    # Convert the image to float32 data type
    img = img.astype(np.float32)</span></pre> <p><span class="koboSpan" id="kobo.735.1">We normalize</span><a id="_idIndexMarker288"/><span class="koboSpan" id="kobo.736.1"> the image pixels to have zero mean and unit variance using the following formula: </span><strong class="source-inline"><span class="koboSpan" id="kobo.737.1">img -= np.mean(img); img /= np.std(img)</span></strong><span class="koboSpan" id="kobo.738.1">. </span><span class="koboSpan" id="kobo.738.2">This is also known as standardization or z-score normalization. </span><span class="koboSpan" id="kobo.738.3">This step is important for machine learning models that are sensitive to the scale of input features, as it ensures that the pixel values have a similar scale across </span><span class="No-Break"><span class="koboSpan" id="kobo.739.1">all images:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.740.1">
    # Normalize the image pixels to have zero mean and unit variance
    img -= np.mean(img)
    img /= np.std(img)</span></pre> <p><span class="koboSpan" id="kobo.741.1">Finally, we save the normalized image with the same filename </span><span class="No-Break"><span class="koboSpan" id="kobo.742.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.743.1">cv2.imwrite()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.744.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.745.1">
    # Save the normalized image with the same filename
    cv2.imwrite(img_file, img)</span></pre> <p><span class="koboSpan" id="kobo.746.1">Image normalization </span><a id="_idIndexMarker289"/><span class="koboSpan" id="kobo.747.1">is a critical step in many computer vision applications, as it can help to reduce the impact of variations in lighting conditions and standardize the color and brightness of images. </span><span class="koboSpan" id="kobo.747.2">By transforming the pixel values of an image, we can make it easier for machine learning algorithms to learn from the image data and improve the accuracy of </span><span class="No-Break"><span class="koboSpan" id="kobo.748.1">our models.</span></span></p>
<h1 id="_idParaDest-98"><a id="_idTextAnchor101"/><span class="koboSpan" id="kobo.749.1">Performing transformations on images – image augmentation</span></h1>
<p><span class="koboSpan" id="kobo.750.1">In the realm of image</span><a id="_idIndexMarker290"/><span class="koboSpan" id="kobo.751.1"> processing and deep learning, the ability to effectively work with image data is paramount. </span><span class="koboSpan" id="kobo.751.2">However, acquiring a diverse and extensive dataset can be a challenge. </span><span class="koboSpan" id="kobo.751.3">This is where the concept of image augmentation comes into play. </span><span class="koboSpan" id="kobo.751.4">Image augmentation is a transformative technique that holds the power to enhance the richness of a dataset without the need to amass additional images manually. </span><span class="koboSpan" id="kobo.751.5">This section delves into the intricacies of image augmentation – an indispensable tool for improving model performance, enhancing generalization capabilities, and mitigating </span><span class="No-Break"><span class="koboSpan" id="kobo.752.1">overfitting concerns.</span></span></p>
<p><a id="_idTextAnchor102"/><span class="koboSpan" id="kobo.753.1">Image augmentation</span><a id="_idIndexMarker291"/><span class="koboSpan" id="kobo.754.1"> is a technique for artificially increasing the size of a dataset by generating new training examples from existing ones. </span><span class="koboSpan" id="kobo.754.2">It is commonly used in deep learning applications to prevent overfitting and improve </span><span class="No-Break"><span class="koboSpan" id="kobo.755.1">generalization performance.</span></span></p>
<p><span class="koboSpan" id="kobo.756.1">The idea behind image augmentation is to apply a variety of transformations to existing images to create new, slightly modified versions of the original images. </span><span class="koboSpan" id="kobo.756.2">By doing so, we can effectively increase the size of our dataset without having to collect and label new images manually. </span><span class="koboSpan" id="kobo.756.3">For example, in medical image analysis, acquiring a large number of high-quality medical images with accurate annotations is often difficult due to patient privacy concerns and the expertise required for labeling. </span><span class="koboSpan" id="kobo.756.4">Image augmentation techniques can help to generate diverse training examples to train accurate diagnostic models. </span><span class="koboSpan" id="kobo.756.5">Another scenario is when dealing with rare events or anomalies, such as defects in manufacturing or diseases in agriculture, where collecting a sufficient number of real-world instances can be challenging. </span><span class="koboSpan" id="kobo.756.6">Image augmentation allows the generation of various scenarios of these rare events, improving the model’s ability to </span><span class="No-Break"><span class="koboSpan" id="kobo.757.1">detect them.</span></span></p>
<p><span class="koboSpan" id="kobo.758.1">There are several types of </span><a id="_idIndexMarker292"/><span class="koboSpan" id="kobo.759.1">image augmentation techniques that can be used. </span><span class="koboSpan" id="kobo.759.2">The most commonly used techniques include </span><span class="No-Break"><span class="koboSpan" id="kobo.760.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.761.1">Rotation</span></strong><span class="koboSpan" id="kobo.762.1">: Rotating</span><a id="_idIndexMarker293"/><span class="koboSpan" id="kobo.763.1"> the image</span><a id="_idIndexMarker294"/><span class="koboSpan" id="kobo.764.1"> by a specified angle </span><span class="No-Break"><span class="koboSpan" id="kobo.765.1">in degrees</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.766.1">Flipping</span></strong><span class="koboSpan" id="kobo.767.1">: Flipping </span><a id="_idIndexMarker295"/><span class="koboSpan" id="kobo.768.1">the image</span><a id="_idIndexMarker296"/><span class="koboSpan" id="kobo.769.1"> horizontally </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">or vertically</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.771.1">Zooming</span></strong><span class="koboSpan" id="kobo.772.1">: Zooming in</span><a id="_idIndexMarker297"/><span class="koboSpan" id="kobo.773.1"> or out on</span><a id="_idIndexMarker298"/><span class="koboSpan" id="kobo.774.1"> the image by a </span><span class="No-Break"><span class="koboSpan" id="kobo.775.1">specified factor</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.776.1">Shearing</span></strong><span class="koboSpan" id="kobo.777.1">: Shearing </span><a id="_idIndexMarker299"/><span class="koboSpan" id="kobo.778.1">the image in </span><a id="_idIndexMarker300"/><span class="koboSpan" id="kobo.779.1">the </span><em class="italic"><span class="koboSpan" id="kobo.780.1">x</span></em><span class="koboSpan" id="kobo.781.1"> or </span><em class="italic"><span class="koboSpan" id="kobo.782.1">y</span></em><span class="koboSpan" id="kobo.783.1"> direction by a </span><span class="No-Break"><span class="koboSpan" id="kobo.784.1">specified factor</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.785.1">Shifting</span></strong><span class="koboSpan" id="kobo.786.1">: Shifting</span><a id="_idIndexMarker301"/><span class="koboSpan" id="kobo.787.1"> the image</span><a id="_idIndexMarker302"/><span class="koboSpan" id="kobo.788.1"> horizontally or vertically by a specified number </span><span class="No-Break"><span class="koboSpan" id="kobo.789.1">of pixels</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.790.1">These techniques can be applied in various combinations to generate a large number of new images from a small set of original images. </span><span class="koboSpan" id="kobo.790.2">For example, we can rotate an image by 45 degrees, flip it horizontally, and shift it vertically, resulting in a new image that is quite different from the original but still retains some of </span><span class="No-Break"><span class="koboSpan" id="kobo.791.1">its features.</span></span></p>
<p><span class="koboSpan" id="kobo.792.1">One important consideration when using image augmentation is to ensure that the generated images are still representative of the underlying dataset. </span><span class="koboSpan" id="kobo.792.2">For example, if we are training a model to recognize handwritten digits, we should ensure that the generated images are still recognizable as digits and not some </span><span class="No-Break"><span class="koboSpan" id="kobo.793.1">random patterns.</span></span></p>
<p><span class="koboSpan" id="kobo.794.1">Overall, image augmentation is a powerful technique that can be used to increase the size of a dataset and improve the performance of deep learning models. </span><span class="koboSpan" id="kobo.794.2">The Keras library provides a convenient way to apply various image augmentation techniques to a dataset, as we will see in the following </span><span class="No-Break"><span class="koboSpan" id="kobo.795.1">code example.</span></span></p>
<p><span class="koboSpan" id="kobo.796.1">Let us see some example Python code for image augmentation. </span><span class="koboSpan" id="kobo.796.2">We first import the necessary libraries: </span><strong class="source-inline"><span class="koboSpan" id="kobo.797.1">keras.preprocessing.image</span></strong><span class="koboSpan" id="kobo.798.1"> for image augmentation and </span><strong class="source-inline"><span class="koboSpan" id="kobo.799.1">os</span></strong><span class="koboSpan" id="kobo.800.1"> for file and </span><span class="No-Break"><span class="koboSpan" id="kobo.801.1">directory operations:</span></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.802.1">Step 1: Import the necessary libraries for </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.803.1">image augmentation</span></em></span></p>
<p><span class="koboSpan" id="kobo.804.1">The following code snippet</span><a id="_idIndexMarker303"/><span class="koboSpan" id="kobo.805.1"> shows how to import </span><span class="No-Break"><span class="koboSpan" id="kobo.806.1">the libraries:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.807.1">
# import the necessary libraries
from keras.preprocessing.image import ImageDataGenerator
import os</span></pre> <p><span class="koboSpan" id="kobo.808.1">We define the path to the image directory </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.810.1">
# Define the path to the image directory
img_dir = 'path/to/image/directory'</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.811.1">Step 2: Create an instance </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.812.1">of ImageDataGenerator</span></em></span></p>
<p><span class="koboSpan" id="kobo.813.1">We create an instance of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.814.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.815.1"> class, which allows us to define various types of image augmentation techniques. </span><span class="koboSpan" id="kobo.815.2">In this example, we use rotation, horizontal and vertical shifts, shear, zoom, and </span><span class="No-Break"><span class="koboSpan" id="kobo.816.1">horizontal flipping:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.817.1">
# Create an instance of the ImageDataGenerator class
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.818.1">Step 3: Load each image from the directory and convert the image to </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.819.1">an array</span></em></span></p>
<p><span class="koboSpan" id="kobo.820.1">We get a list of all image filenames in the directory using a list comprehension. </span><span class="koboSpan" id="kobo.820.2">We then loop through all the image files using a </span><strong class="source-inline"><span class="koboSpan" id="kobo.821.1">for</span></strong><span class="koboSpan" id="kobo.822.1"> loop. </span><span class="koboSpan" id="kobo.822.2">For each image file, we load the image using Keras’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.823.1">load_img</span></strong><span class="koboSpan" id="kobo.824.1"> function and convert it to an array using Keras’ </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.825.1">img_to_array</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.826.1"> function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.827.1">
# Get a list of all image filenames in the directory
img_files = [os.path.join(img_dir, f) \
    for f in os.listdir(img_dir) \
    if os.path.isfile(os.path.join(img_dir, f))]
# Loop through all the image files
for img_file in img_files:
    # Load the image using Keras' load_img function
    img = load_img(img_file)
    # Convert the image to an array using Keras' img_to_array function
    img_arr = img_to_array(img)</span></pre> <p><span class="koboSpan" id="kobo.828.1">We reshape the array to have a batch dimension of </span><strong class="source-inline"><span class="koboSpan" id="kobo.829.1">1</span></strong><span class="koboSpan" id="kobo.830.1">, which is required by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.831.1">flow</span></strong><span class="koboSpan" id="kobo.832.1"> method of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.833.1">ImageDataGenerator</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.834.1"> class:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.835.1">
    # Reshape the array to have a batch dimension of 1
    img_arr = img_arr.reshape((1,) + img_arr.shape)</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.836.1">Step 4: Regenerate five augmented images for each </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.837.1">input image</span></em></span></p>
<p><span class="koboSpan" id="kobo.838.1">We then regenerate our</span><a id="_idIndexMarker304"/><span class="koboSpan" id="kobo.839.1"> augmented images </span><span class="No-Break"><span class="koboSpan" id="kobo.840.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.841.1">
    # Generate 5 augmented images for each input image
    i = 0
    for batch in datagen.flow( \
        img_arr, batch_size=1, save_to_dir=img_dir, \
        save_prefix='aug_', save_format='jpg' \
    ):
        i += 1
        if i == 5:
            break</span></pre> <p><span class="koboSpan" id="kobo.842.1">You can see five augmented</span><a id="_idIndexMarker305"/><span class="koboSpan" id="kobo.843.1"> images generated for the flow in the GitHub repository in the directory </span><span class="No-Break"><span class="koboSpan" id="kobo.844.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer077">
<span class="koboSpan" id="kobo.845.1"><img alt="Figure 4.1﻿2 – Augmented images" src="image/B18944_04_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.846.1">Figure 4.12 – Augmented images</span></p>
<p><span class="koboSpan" id="kobo.847.1">We use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.848.1">flow</span></strong><span class="koboSpan" id="kobo.849.1"> method to </span><a id="_idIndexMarker306"/><span class="koboSpan" id="kobo.850.1">generate five augmented images for each input image. </span><span class="koboSpan" id="kobo.850.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.851.1">flow</span></strong><span class="koboSpan" id="kobo.852.1"> method takes the array of input images, a batch size of 1, and various parameters defined in </span><em class="italic"><span class="koboSpan" id="kobo.853.1">step 3</span></em><span class="koboSpan" id="kobo.854.1">. </span><span class="koboSpan" id="kobo.854.2">It returns a generator that generates augmented images on the fly. </span><span class="koboSpan" id="kobo.854.3">We save each augmented image with a filename prefix of </span><strong class="source-inline"><span class="koboSpan" id="kobo.855.1">aug_</span></strong><span class="koboSpan" id="kobo.856.1"> using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.857.1">save_to_dir</span></strong><span class="koboSpan" id="kobo.858.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.859.1">save_prefix</span></strong><span class="koboSpan" id="kobo.860.1">, and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.861.1">save_format</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.862.1"> parameters.</span></span></p>
<p><span class="koboSpan" id="kobo.863.1">In this section, we learned how to transform a dataset using data augmentation and saw some commonly used data augmentation techniques for generating additional data </span><span class="No-Break"><span class="koboSpan" id="kobo.864.1">for training.</span></span></p>
<h1 id="_idParaDest-99"><a id="_idTextAnchor103"/><span class="koboSpan" id="kobo.865.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.866.1">In this chapter, we learned how to review images after loading an image dataset and explore them using a tool called Matplotlib in Python. </span><span class="koboSpan" id="kobo.866.2">We also found out how to change the size of pictures using two handy tools called PIL and OpenCV. </span><span class="koboSpan" id="kobo.866.3">And just when things were getting interesting, we discovered a cool trick called data augmentation that helps us make our dataset bigger and teaches our computer how to understand different versions of the </span><span class="No-Break"><span class="koboSpan" id="kobo.867.1">same picture.</span></span></p>
<p><span class="koboSpan" id="kobo.868.1">But wait, there’s more to come! </span><span class="koboSpan" id="kobo.868.2">In the next chapter, we are going to see how to label our image data using Snorkel based on rules and heuristics. </span><span class="koboSpan" id="kobo.868.3">Get ready for some more fun as we dive into the world of </span><span class="No-Break"><span class="koboSpan" id="kobo.869.1">labeling images!</span></span></p>
</div>
</body></html>