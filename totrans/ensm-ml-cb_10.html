<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Heterogeneous Ensemble Classifiers Using H2O</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this chapter, we will cover the following recipe:</p>
<ul class="calibre10">
<li class="calibre11">Predicting credit card defaulters using heterogeneous ensemble classifiers</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction </h1>
                </header>
            
            <article>
                
<p class="calibre2">In this chapter, we'll showcase how to build heterogeneous ensemble classifier using H2O, which is an<span class="calibre5"> open source, distributed, in-memory, machine learning platform. There are a host of supervised and unsupervised algorithms available in H2O.</span></p>
<p class="calibre2">Among the supervised algorithms, H2O provides us with neural networks, random forest (RF), generalized linear models, a Gradient-Boosting Machine, a naive Bayes classifier, and XGBoost.</p>
<p class="calibre2">H2O also provides us with a stacked ensemble method that aims to find the optimal combination of a collection of predictive algorithms using the stacking process. H2O's stacked ensemble supports both regression and classification.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predicting credit card defaulters using heterogeneous ensemble classifiers</h1>
                </header>
            
            <article>
                
<p class="calibre2">We will use Taiwan's credit card payment defaulters data as an example. This is the same dataset we used earlier, in <a href="6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml" class="calibre9">Chapter 3</a>, <em class="calibre13">Resampling Methods</em>, to build a logistic regression model. In this recipe, we'll build multiple models using different algorithms, and finally, build a stacked ensemble model.</p>
<p class="calibre2"><span class="calibre5">This dataset contains information about credit card clients in Taiwan. This includes information to do with payment defaulters, customers' demographic factors, their credit data, and their payment history. The dataset is provided in GitHub. It is also available from its main source, the UCI ML Repository:<a href="https://bit.ly/2EZX6IC" class="calibre9"> https://bit.ly/2EZX6IC</a>.</span></p>
<p class="calibre2"><span class="calibre5"/>In our example, we'll use the following supervised algorithms from H2O to build our models:</p>
<ul class="calibre10">
<li class="calibre11">Generalized linear model</li>
<li class="calibre11">Distributed random forest </li>
<li class="calibre11">Gradient-boosting machine </li>
<li class="calibre11">Stacked ensemble</li>
</ul>
<p class="calibre2">We'll see how to use these algorithms in Python and learn <span class="calibre5">how </span>to set some of the hyperparameters for each of the algorithms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="calibre2">We'll use Google Colab to build our model. In <a href="0d0517ac-d372-478f-ba6a-4ad4828b81a0.xhtml" class="calibre9">Chapter 10</a>, <em class="calibre13">Heterogeneous Ensemble Classifiers Using H2O</em><span class="calibre5"><span class="calibre5"><em class="calibre13">,</em> w</span></span>e explained how to use Google Colaboratory in the <em class="calibre13">There's more</em> section.</p>
<p class="calibre2">We'll start by installing H2O in Google Colab as follows:</p>
<pre class="calibre15"><strong class="calibre1">! pip install h2o</strong></pre>
<p class="calibre2">Executing the preceding command will show you a few instructions, with the final line showing the following message (the version number of H2O will be different depending on the latest version available):</p>
<pre class="calibre15"><strong class="calibre1"><span>Successfully installed colorama-0.4.1 h2o-3.22.1.2</span></strong></pre>
<p class="calibre2">We import all the required libraries, as follows:</p>
<pre class="calibre15">import pandas as pd<br class="title-page-name"/>import numpy as np<br class="title-page-name"/><br class="title-page-name"/>from sklearn.model_selection import train_test_split<br class="title-page-name"/>from sklearn.metrics import confusion_matrix, roc_curve, auc<br class="title-page-name"/>from sklearn import tree<br class="title-page-name"/><br class="title-page-name"/>import h2o<br class="title-page-name"/>from h2o.estimators.glm import H2OGeneralizedLinearEstimator<br class="title-page-name"/>from h2o.estimators.random_forest import H2ORandomForestEstimator<br class="title-page-name"/>from h2o.estimators.gbm import H2OGradientBoostingEstimator<br class="title-page-name"/>from h2o.grid.grid_search import H2OGridSearch<br class="title-page-name"/>from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/>import seaborn as sns<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>%matplotlib inline</pre>
<p class="calibre2"><span class="calibre5">We'll then initialize H2O:</span></p>
<pre class="calibre15"># Initialize H2o<br class="title-page-name"/>h2o.init()</pre>
<p class="calibre2">Upon successful initialization, we'll see the information shown in the <span class="calibre5">following screenshot</span>. This information might be different, depending on the environment:</p>
<p class="CDPAlignCenter"><img class="aligncenter93" src="assets/882ed571-c8ba-4490-a404-f16e26aabade.png"/></p>
<p class="calibre2">We'll read our dataset from Google Drive. In order to do this, we first need to mount the drive:</p>
<pre class="calibre15">from google.colab import drive<br class="title-page-name"/>drive.mount('/content/drive')</pre>
<p class="calibre2">It will instruct you to go to a URL to get the authorization code. You'll need to click on the URL, copy the authorization code, and paste it. Upon successful mounting, you can read your file from the respective folder in Google Drive:</p>
<pre class="calibre15"># Reading dataset from Google drive<br class="title-page-name"/>df_creditcarddata = h2o.import_file("/content/drive/My Drive/Colab Notebooks/UCI_Credit_Card.csv")</pre>
<p class="calibre2">Note that with <kbd class="calibre12">h2o.import_file</kbd>, we create <span class="calibre5"><kbd class="calibre12">h2o.frame.H2OFrame</kbd>. This is similar to a <kbd class="calibre12">pandas</kbd> DataFrame. However, in the case of a <kbd class="calibre12">pandas</kbd> DataFrame, the data is held in the memory, while in this case, the data is located on an H2O cluster.</span></p>
<p class="calibre2">You can run similar methods on an H2O DataFrame as you can on pandas. For example, in order to see the first 10 observations in the DataFrame, you can use the following command:</p>
<pre class="calibre15">df_creditcarddata.head()</pre>
<p class="calibre2">To check the dimensions of the <span class="calibre5">DataFrame</span>, we use the following command:</p>
<pre class="calibre15">df_creditcarddata.shape</pre>
<p class="calibre2">In order to see all the column names, we run the following syntax:</p>
<pre class="calibre15">df_creditcarddata.columns</pre>
<p class="calibre2">In the <kbd class="calibre12">pandas</kbd> <span class="calibre5">DataFrame</span>, we used <kbd class="calibre12">dtypes</kbd> to see the datatypes of each column. In the H2o DataFrame, we would use the following:</p>
<pre class="calibre15">df_creditcarddata.types</pre>
<p class="calibre2">This gives us the following output. Note that the categorical variables appear as <kbd class="calibre12">'enum'</kbd>:</p>
<p class="CDPAlignCenter"><img class="aligncenter94" src="assets/937331c5-ec80-4367-add7-ab7fd1c2be27.png"/></p>
<p class="calibre2">We have our target variable, <kbd class="calibre12">default.payment.next.month</kbd>, in the dataset. This tells us which customers have and have not defaulted on their payments. We want to see the distribution of the defaulters and non-defaulters:</p>
<pre class="calibre15">df_creditcarddata['default.payment.next.month'].table()</pre>
<p class="calibre2">This gives us the count of each class in the <kbd class="calibre12"><span>default.payment.next.month</span></kbd> variable:</p>
<p class="CDPAlignCenter"><img class="aligncenter95" src="assets/4a2cdc5f-076e-4b13-bf8e-c0ef7bc4b80d.png"/></p>
<p class="calibre2">We don't need the <kbd class="calibre12">ID</kbd> column for predictive modeling, so we remove it from our <span class="calibre5">DataFrame</span>:</p>
<pre class="calibre15">df_creditcarddata = df_creditcarddata.drop(["ID"], axis = 1) </pre>
<p class="calibre2">We can see the distribution of the numeric variables using the <kbd class="calibre12">hist()</kbd> method:</p>
<pre class="calibre15">import pylab as pl<br class="title-page-name"/>df_creditcarddata[['AGE','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6', 'LIMIT_BAL']].as_data_frame().hist(figsize=(20,20))<br class="title-page-name"/>pl.show()</pre>
<p class="calibre2">The following screenshot shows us the <span class="calibre5">plotted</span> variables . This can help us in our analysis of each of the variables:</p>
<p class="CDPAlignCenter"><img class="aligncenter96" src="assets/23b6773e-bf76-460b-9529-95a123315127.png"/></p>
<p class="calibre2">To extend our analysis, we can see the distribution of defaulters and non-defaulters by gender, education, and marital status:</p>
<pre class="calibre15"># Defaulters by Gender<br class="title-page-name"/>columns = ["default.payment.next.month","SEX"]<br class="title-page-name"/>default_by_gender = df_creditcarddata.group_by(by=columns).count(na ="all")<br class="title-page-name"/>print(default_by_gender.get_frame())<br class="title-page-name"/><br class="title-page-name"/># Defaulters by education<br class="title-page-name"/>columns = ["default.payment.next.month","EDUCATION"]<br class="title-page-name"/>default_by_education = df_creditcarddata.group_by(by=columns).count(na ="all")<br class="title-page-name"/>print(default_by_education.get_frame())<br class="title-page-name"/><br class="title-page-name"/># Defaulters by MARRIAGE<br class="title-page-name"/>columns = ["default.payment.next.month","MARRIAGE"]<br class="title-page-name"/>default_by_marriage = df_creditcarddata.group_by(by=columns).count(na ="all")<br class="title-page-name"/>print(default_by_marriage.get_frame())</pre>
<p class="calibre2">In the following screenshot, we get to see the distribution of defaulters by different categories:</p>
<p class="CDPAlignCenter"><img class="aligncenter97" src="assets/6bae3882-f108-4d74-8219-38c232dbe93f.png"/></p>
<p class="calibre2">We'll now convert the categorical variables into factors:</p>
<pre class="calibre15"><strong class="calibre1"># Convert the categorical variables into factors</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['SEX'] = df_creditcarddata['SEX'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['EDUCATION'] = df_creditcarddata['EDUCATION'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['MARRIAGE'] = df_creditcarddata['MARRIAGE'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_0'] = df_creditcarddata['PAY_0'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_2'] = df_creditcarddata['PAY_2'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_3'] = df_creditcarddata['PAY_3'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_4'] = df_creditcarddata['PAY_4'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_5'] = df_creditcarddata['PAY_5'].asfactor()</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['PAY_6'] = df_creditcarddata['PAY_6'].asfactor()</strong></pre>
<p class="calibre2">We also encode the dichotomous target variable, <kbd class="calibre12">default.payment.next.month</kbd>, as a factor variable. After the conversion, we check the classes of the target variable with the <kbd class="calibre12">levels()</kbd> method:</p>
<pre class="calibre15"><strong class="calibre1"># Also, encode the binary response variable as a factor</strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['default.payment.next.month'] = df_creditcarddata['default.payment.next.month'].asfactor() </strong><br class="title-page-name"/><strong class="calibre1">df_creditcarddata['default.payment.next.month'].levels()</strong></pre>
<p class="calibre2">We'll then define our predictor and target variables:</p>
<pre class="calibre15"><strong class="calibre1"># Define predictors manually</strong><br class="title-page-name"/><strong class="calibre1">predictors = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3',\</strong><br class="title-page-name"/><strong class="calibre1"> 'PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4',\</strong><br class="title-page-name"/><strong class="calibre1"> 'BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">target = 'default.payment.next.month'</strong></pre>
<p class="calibre2">We then split our DataFrame using the <kbd class="calibre12">split_frame()</kbd> method:</p>
<pre class="calibre15"><strong class="calibre1">splits = df_creditcarddata.split_frame(ratios=[0.7], seed=1)</strong> </pre>
<p class="calibre2">The following code gives us two split output:</p>
<pre class="calibre15"><strong class="calibre1">splits</strong></pre>
<p class="calibre2">In the following screenshot, we get to see the following two splits:</p>
<p class="CDPAlignCenter"><img class="aligncenter98" src="assets/0c3138ad-28b8-46f5-b7d6-9d1ef46803f4.png"/></p>
<p class="calibre2">We separate the splits into train and test subsets:</p>
<pre class="calibre15">train = splits[0]<br class="title-page-name"/>test = splits[1] </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">Let's move on to training our models using the algorithms we mentioned earlier in this chapter. </span>We'll start by training our <span class="calibre5"><strong class="calibre4">generalized linear model</strong> (<strong class="calibre4">GLM</strong>) models. We'll build three GLM models:</span></p>
<ul class="calibre10">
<li class="calibre11">A GLM model with default values for the parameters</li>
<li class="calibre11">A GLM model with Lambda search (regularization)</li>
<li class="calibre11">A GLM model with grid search</li>
</ul>
<p class="calibre2">Now we will start with training our models in the following section.</p>
<ol class="calibre14">
<li class="calibre11">Let's train our first model:</li>
</ol>
<pre class="calibre18">GLM_default_settings = H2OGeneralizedLinearEstimator(family='binomial', \<br class="title-page-name"/>                                            model_id='GLM_default',nfolds = 10, \<br class="title-page-name"/>                                            fold_assignment = "Modulo", \<br class="title-page-name"/>                                            keep_cross_validation_predictions = True)</pre>
<p class="calibre20"><kbd class="calibre12">H2OGeneralizedLinearEstimator</kbd> fits a <span class="calibre5">generalized linear model. It takes in a response variable and a set of predictor variables. </span></p>
<p class="calibre20"><kbd class="calibre12">H2OGeneralizedLinearEstimator</kbd> <span class="calibre5">can handle both regression and classification tasks. In the case of a regression problem, it returns an <kbd class="calibre12">H2ORegressionModel</kbd> subclass, while for classification, it returns an <kbd class="calibre12">H2OBinomialModel</kbd> subclass. </span></p>
<ol start="2" class="calibre14">
<li class="calibre11">We created predictor and target variables in the <em class="calibre23">Getting ready</em> section. Pass the predictor and target variables to the model:</li>
</ol>
<pre class="calibre18">GLM_default_settings.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="3" class="calibre14">
<li class="calibre11">Train the GLM model using the <kbd class="calibre12">lambda_search</kbd> parameter:</li>
</ol>
<pre class="calibre18">GLM_regularized = H2OGeneralizedLinearEstimator(family='binomial', model_id='GLM', \<br class="title-page-name"/>                                                lambda_search=True, nfolds = 10, \<br class="title-page-name"/>                                                fold_assignment = "Modulo", \<br class="title-page-name"/>                                                keep_cross_validation_predictions = True)<br class="title-page-name"/><br class="title-page-name"/>GLM_regularized.train(x = predictors, y = target, training_frame = train)</pre>
<p class="calibre20"><kbd class="calibre12">lambda_search</kbd> helps the GLM to find an optimal regularization parameter, <span class="calibre5">λ. </span>The <kbd class="calibre12">lambda_search</kbd> parameter takes in a Boolean value. When set to <kbd class="calibre12">True</kbd>, the <span class="calibre5">GLM will first fit a model with the highest lambda value, which is known as <strong class="calibre4">maximum regularization</strong>. It then decreases this at each step until it reaches the minimum lambda. The resulting optimum model is based on the best lambda value.</span></p>
<ol start="4" class="calibre14">
<li class="calibre11">Train the model using the GLM with a grid search:</li>
</ol>
<pre class="calibre18">hyper_parameters = { 'alpha': [0.001, 0.01, 0.05, 0.1, 1.0],<br class="title-page-name"/>                     'lambda': [0.001, 0.01, 0.1, 1] }<br class="title-page-name"/>search_criteria = { 'strategy': "RandomDiscrete", 'seed': 1,<br class="title-page-name"/>                    'stopping_metric': "AUTO",<br class="title-page-name"/>                    'stopping_rounds': 5 }<br class="title-page-name"/><br class="title-page-name"/>GLM_grid_search = H2OGridSearch(H2OGeneralizedLinearEstimator(family='binomial', \<br class="title-page-name"/>                  nfolds = 10, fold_assignment = "Modulo", \<br class="title-page-name"/>                  keep_cross_validation_predictions = True),\<br class="title-page-name"/>                  hyper_parameters, grid_id="GLM_grid", search_criteria=search_criteria)<br class="title-page-name"/><br class="title-page-name"/>GLM_grid_search.train(x= predictors,y= target, training_frame=train)</pre>
<ol start="5" class="calibre14">
<li class="calibre11">We get the grid result sorted by the <kbd class="calibre12"><span>auc</span></kbd> value with the <kbd class="calibre12">get_grid()</kbd> method:</li>
</ol>
<pre class="calibre18"># Get the grid results, sorted by validation AUC<br class="title-page-name"/>GLM_grid_sorted = GLM_grid_search.get_grid(sort_by='auc', decreasing=True)<br class="title-page-name"/>GLM_grid_sorted</pre>
<p class="calibre20">In the following screenshot, we can see the <kbd class="calibre12">auc</kbd> score for each model, which consists of different combinations of the <kbd class="calibre12">alpha</kbd> and <kbd class="calibre12">lambda</kbd> parameters:</p>
<p class="CDPAlignCenter"><img class="aligncenter99" src="assets/f4209530-ce0e-440d-ab7a-85f54f11e2e6.png"/></p>
<ol start="6" class="calibre14">
<li class="calibre11">We can see the model metrics on our train data and our cross-validation data:</li>
</ol>
<pre class="calibre18"># Extract the best model from random grid search<br class="title-page-name"/>Best_GLM_model_from_Grid = GLM_grid_sorted.model_ids[0]<br class="title-page-name"/><br class="title-page-name"/># model performance<br class="title-page-name"/>Best_GLM_model_from_Grid = h2o.get_model(Best_GLM_model_from_Grid)<br class="title-page-name"/>print(Best_GLM_model_from_Grid)</pre>
<p class="calibre20">From the preceding code block, you can evaluate the model metrics, which include <kbd class="calibre12">MSE</kbd>, <kbd class="calibre12">RMSE</kbd>, <kbd class="calibre12">Null</kbd> and <kbd class="calibre12">Residual Deviance</kbd>, <kbd class="calibre12">AUC</kbd>, and <kbd class="calibre12">Gini</kbd>, along with the <kbd class="calibre12">Confusion Matrix</kbd>. At a later stage, we will use the best model from the grid search for our stacked ensemble.</p>
<p class="calibre20">Let us look at the following image and evaluate the model metrics:</p>
<p class="CDPAlignCenter"><img class="aligncenter100" src="assets/f2e1b50c-c083-4d8c-a17b-37ff57893a35.png"/></p>
<ol start="7" class="calibre14">
<li class="calibre11">Train the model using random forest. The code for random forest using default settings looks as follows:</li>
</ol>
<pre class="calibre18"># Build a RF model with default settings<br class="title-page-name"/>RF_default_settings = H2ORandomForestEstimator(model_id = 'RF_D',\<br class="title-page-name"/>                                nfolds = 10, fold_assignment = "Modulo", \<br class="title-page-name"/>                                keep_cross_validation_predictions = True)<br class="title-page-name"/><br class="title-page-name"/># Use train() to build the model<br class="title-page-name"/>RF_default_settings.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="8" class="calibre14">
<li class="calibre11">To get the summary output of the model, use the following code:</li>
</ol>
<pre class="calibre18">RF_default_settings.summary()</pre>
<ol start="9" class="calibre14">
<li class="calibre11">Train the random forest model using a grid search. Set the hyperparameters as shown in the following code block:</li>
</ol>
<pre class="calibre18">hyper_params = {'sample_rate':[0.7, 0.9],<br class="title-page-name"/>                'col_sample_rate_per_tree': [0.8, 0.9],<br class="title-page-name"/>                'max_depth': [3, 5, 9],<br class="title-page-name"/>                'ntrees': [200, 300, 400]<br class="title-page-name"/>               }</pre>
<ol start="10" class="calibre14">
<li class="calibre11">Use the hyperparameters on <kbd class="calibre12">H2OGridSearch()</kbd> to train the <kbd class="calibre12">RF</kbd> model using <kbd class="calibre12">gridsearch</kbd>:</li>
</ol>
<pre class="calibre18">RF_grid_search = H2OGridSearch(H2ORandomForestEstimator(nfolds = 10, \<br class="title-page-name"/>                             fold_assignment = "Modulo", \<br class="title-page-name"/>                             keep_cross_validation_predictions = True, \<br class="title-page-name"/>                             stopping_metric = 'AUC',stopping_rounds = 5), \<br class="title-page-name"/>                             hyper_params = hyper_params, \<br class="title-page-name"/>                             grid_id= 'RF_gridsearch')<br class="title-page-name"/><br class="title-page-name"/># Use train() to start the grid search<br class="title-page-name"/>RF_grid_search.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="11" class="calibre14">
<li class="calibre11">Sort the results by AUC score to see which model performs best:</li>
</ol>
<pre class="calibre18"># Sort the grid models<br class="title-page-name"/>RF_grid_sorted = RF_grid_search.get_grid(sort_by='auc', decreasing=True)<br class="title-page-name"/>print(RF_grid_sorted)</pre>
<ol start="12" class="calibre14">
<li class="calibre11">Extract the best model from the grid search result:</li>
</ol>
<pre class="calibre18">Best_RF_model_from_Grid = RF_grid_sorted.model_ids[0]<br class="title-page-name"/><br class="title-page-name"/># Model performance<br class="title-page-name"/>Best_RF_model_from_Grid = h2o.get_model(Best_RF_model_from_Grid) <br class="title-page-name"/>print(Best_RF_model_from_Grid)</pre>
<p class="calibre20">In the following screenshot, we see the model metrics for the grid model on the train data and the cross-validation data:</p>
<p class="CDPAlignCenter"><img class="aligncenter101" src="assets/960c92f8-db18-427d-a08a-ee1a3750b8d7.png"/></p>
<ol start="13" class="calibre14">
<li class="calibre11">Train the model using GBM. Here's how to train a GBM with the default settings:</li>
</ol>
<pre class="calibre18">GBM_default_settings = H2OGradientBoostingEstimator(model_id = 'GBM_default', \<br class="title-page-name"/>                       nfolds = 10, \<br class="title-page-name"/>                       fold_assignment = "Modulo", \<br class="title-page-name"/>                       keep_cross_validation_predictions = True)<br class="title-page-name"/><br class="title-page-name"/># Use train() to build the model<br class="title-page-name"/>GBM_default_settings.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="14" class="calibre14">
<li class="calibre11">
<p class="calibre2">Use a grid search on the GBM. To perform a grid search, set the hyperparameters as follows:</p>
</li>
</ol>
<pre class="calibre18">hyper_params = {'learn_rate': [0.001,0.01, 0.1],<br class="title-page-name"/>                'sample_rate': [0.8, 0.9],<br class="title-page-name"/>                'col_sample_rate': [0.2, 0.5, 1],<br class="title-page-name"/>                'max_depth': [3, 5, 9]}</pre>
<ol start="15" class="calibre14">
<li class="calibre11">Use the hyperparameters on<span> </span><kbd class="calibre12">H2OGridSearch()</kbd><span> </span>to train the GBM model using grid search:</li>
</ol>
<pre class="calibre18">GBM_grid_search = H2OGridSearch(H2OGradientBoostingEstimator(nfolds = 10, \<br class="title-page-name"/>                        fold_assignment = "Modulo", \<br class="title-page-name"/>                        keep_cross_validation_predictions = True,\<br class="title-page-name"/>                        stopping_metric = 'AUC', stopping_rounds = 5),<br class="title-page-name"/>                        hyper_params = hyper_params, grid_id= 'GBM_Grid')<br class="title-page-name"/><br class="title-page-name"/># Use train() to start the grid search<br class="title-page-name"/>GBM_grid_search.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="16" class="calibre14">
<li class="calibre11">As with the earlier models, we can view the results sorted by AUC:</li>
</ol>
<pre class="calibre18"># Sort and show the grid search results<br class="title-page-name"/>GBM_grid_sorted = GBM_grid_search.get_grid(sort_by='auc', decreasing=True)<br class="title-page-name"/>print(GBM_grid_sorted)</pre>
<ol start="17" class="calibre14">
<li class="calibre11">Extract the best model from the grid search:</li>
</ol>
<pre class="calibre18">Best_GBM_model_from_Grid = GBM_grid_sorted.model_ids[0]<br class="title-page-name"/><br class="title-page-name"/>Best_GBM_model_from_Grid = h2o.get_model(Best_GBM_model_from_Grid) <br class="title-page-name"/>print(Best_GBM_model_from_Grid)</pre>
<p class="calibre20">We can use <span class="calibre5"><kbd class="calibre12">H2OStackedEnsembleEstimator</kbd> to build a stacked ensemble ML model that can use the models we have built using H2O algorithms to improve the predictive performance. <span class="calibre5"><kbd class="calibre12">H2OStackedEnsembleEstimator</kbd> helps us find the optimal combination of a collection of predictive algorithms. </span></span></p>
<ol start="18" class="calibre14">
<li class="calibre11">Create a list of the best models from the earlier models that we built using grid search:</li>
</ol>
<pre class="calibre18"># list the best models from each grid<br class="title-page-name"/>all_models = [Best_GLM_model_from_Grid, Best_RF_model_from_Grid, Best_GBM_model_from_Grid]</pre>
<ol start="19" class="calibre14">
<li class="calibre11">Set up a stacked ensemble model using <span><kbd class="calibre12">H2OStackedEnsembleEstimator</kbd></span>:</li>
</ol>
<pre class="calibre18"># Set up Stacked Ensemble<br class="title-page-name"/>ensemble = H2OStackedEnsembleEstimator(model_id = "ensemble", base_models = all_models, metalearner_algorithm = "deeplearning")<br class="title-page-name"/><br class="title-page-name"/># uses GLM as the default metalearner<br class="title-page-name"/>ensemble.train(y = target, training_frame = train)</pre>
<ol start="20" class="calibre14">
<li class="calibre11">Evaluate the ensemble performance on the test data:</li>
</ol>
<pre class="calibre18"><span># Eval ensemble performance on the test data</span>
<span>Ens_model</span> <span>=</span> <span>ensemble</span><span>.</span><span>model_performance</span><span>(</span><span>test</span><span>)<br class="title-page-name"/></span>Ens_AUC<span> </span><span>=</span><span> </span><span>Ens_model</span><span>.</span><span>auc</span><span>()</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<ol start="21" class="calibre14">
<li class="calibre11">Compare the performance of the base learners on the <kbd class="calibre12">test</kbd> data. The following code tests the model performance of all the GLM models we've built:</li>
</ol>
</div>
</div>
<pre class="calibre18"># Checking the model performance for all GLM models built<br class="title-page-name"/>model_perf_GLM_default = GLM_default_settings.model_performance(test)<br class="title-page-name"/>model_perf_GLM_regularized = GLM_regularized.model_performance(test)<br class="title-page-name"/>model_perf_Best_GLM_model_from_Grid = Best_GLM_model_from_Grid.model_performance(test)</pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre20">The following code tests the model performance of all the random forest models we've built:</p>
<pre class="calibre18"># Checking the model performance for all RF models built<br class="title-page-name"/>model_perf_RF_default_settings = RF_default_settings.model_performance(test)<br class="title-page-name"/>model_perf_Best_RF_model_from_Grid = Best_RF_model_from_Grid.model_performance(test)</pre></div>
</div>
</div>
<p class="calibre20">The following code tests the model performance of all the GBM models we've built:</p>
<pre class="calibre18"># Checking the model performance for all GBM models built<br class="title-page-name"/>model_perf_GBM_default_settings = GBM_default_settings.model_performance(test)<br class="title-page-name"/>model_perf_Best_GBM_model_from_Grid = Best_GBM_model_from_Grid.model_performance(test)</pre>
<div class="title-page-name">
<ol start="22" class="calibre14">
<li class="calibre11">To get the best AUC from the base learners, execute the following commands:</li>
</ol>
<pre class="calibre18"># Best AUC from the base learner models<br class="title-page-name"/>best_auc = max(model_perf_GLM_default.auc(), model_perf_GLM_regularized.auc(), \<br class="title-page-name"/> model_perf_Best_GLM_model_from_Grid.auc(), \<br class="title-page-name"/> model_perf_RF_default_settings.auc(), \<br class="title-page-name"/> model_perf_Best_RF_model_from_Grid.auc(), \<br class="title-page-name"/> model_perf_GBM_default_settings.auc(), \<br class="title-page-name"/> model_perf_Best_GBM_model_from_Grid.auc())<br class="title-page-name"/><br class="title-page-name"/>print("Best AUC out of all the models performed: ", format(best_auc))</pre>
<ol start="23" class="calibre14">
<li class="calibre11">The following commands show the AUC from the stacked ensemble model:</li>
</ol>
<pre class="calibre18"># Eval ensemble performance on the test data<br class="title-page-name"/>Ensemble_model = ensemble.model_performance(test)<br class="title-page-name"/>Ensemble_model = Ensemble_model.auc()</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="calibre2">We used Google Colab to train our models. After we installed H2O in Google Colab, we initialized the H2O instance. We also imported the required libraries.</p>
<p class="calibre2">In order to use the H2O libraries, we imported <span class="calibre5"><kbd class="calibre12">H2OGeneralizedLinearEstimator</kbd>, <kbd class="calibre12">H2ORandomForestEstimator</kbd>, and <kbd class="calibre12">H2OGradientBoostingEstimator</kbd> from <kbd class="calibre12">h2o.estimators</kbd>. We also imported <kbd class="calibre12">H2OStackedEnsembleEstimator</kbd> to train our model using a stacked ensemble.</span></p>
<p class="calibre2">We mounted Google Drive and read our dataset using <kbd class="calibre12">h2o.import_file()</kbd>. This created an H2O DataFrame, which is very similar to a <kbd class="calibre12">pandas</kbd> <span class="calibre5">DataFrame</span>. Instead of holding it in the memory, however, the data is located in one of the remote H2O clusters.</p>
<p class="calibre2">We then performed basic operations on the H2O DataFrame to analyze our data. We took a look at the dimensions, the top few rows, and the data types of each column. The <kbd class="calibre12">shape</kbd> attribute returned a tuple with the number of rows and columns. The <kbd class="calibre12">head()</kbd> method returned the top 10 observations. The <kbd class="calibre12">types</kbd> attribute returned the data types of each column.</p>
<div class="packtinfobox">Note that a categorical variable in an H2O DataFrame is marked as an <kbd class="calibre19">enum</kbd>.</div>
<p class="calibre2">Our target variable was <kbd class="calibre12">default.payment.next.month</kbd>. With the <kbd class="calibre12">table()</kbd> method, we saw the distribution of both classes of our target variable. The <kbd class="calibre12">table()</kbd> method returned the count for classes <kbd class="calibre12">1</kbd> and <kbd class="calibre12">0</kbd> in this case.</p>
<p class="calibre2">We didn't need the <kbd class="calibre12">ID</kbd> column, so we removed it using the <kbd class="calibre12">drop()</kbd> method with <kbd class="calibre12">axis=1</kbd> as a parameter. With <kbd class="calibre12">axis=1</kbd>, it dropped the columns. Otherwise, the default value of <kbd class="calibre12">axis=0</kbd> would have dropped the labels from the index.</p>
<p class="calibre2">We analyzed the distribution of the numeric variables. There's no limit to how far you can explore your data. We also saw the distribution of both of the classes of our target variable by various categories, such as gender, education, and marriage.</p>
<p class="calibre2">We then converted the categorical variables to factor type with the <kbd class="calibre12">asfactor()</kbd> method. This was done for the target variable as well.</p>
<p class="calibre2">We created a list of predictor variables and target variables. We split our DataFrame into the train and test subsets with the <kbd class="calibre12">split_frame()</kbd> method. </p>
<div class="packtinfobox">We passed ratios to the <kbd class="calibre19">split_frame()</kbd> method. In our case, we split the dataset into 70% and 30%. However, note that this didn't give an exact split of 70%-30%. H2O uses a probabilistic splitting method instead of using the exact ratios to split the dataset. This is to make the split more efficient on big data.</div>
<p class="calibre2">After we split our datasets into train and test subsets, we moved onto training our models. We used GLM, random forest, a <strong class="calibre4">gradient-boosting machine</strong> (<strong class="calibre4">GBM</strong>), and stacked ensembles to train the stacking model.</p>
<p class="calibre2">In the <em class="calibre13">How to do it...</em> section, in <em class="calibre13">Step 1</em> and <em class="calibre13">Step<span class="calibre5"> </span>2</em>, we showcased the code to train a GLM model with the default settings. We used cross-validation to train our model. </p>
<p class="calibre2">In <em class="calibre13">Step 3</em>, we trained a GLM model with <kbd class="calibre12">lambda_search</kbd>, which helps to find the optimal regularization parameter.</p>
<p class="calibre2">In <em class="calibre13">Step 4</em>, we used grid-search parameters to train our GLM model. We set our hyper-parameters and provided these to the <kbd class="calibre12">H2OGridSearch()</kbd> method. This helps us search for the optimum parameters across models. In the <span class="calibre5"><kbd class="calibre12">H2OGridSearch()</kbd> method, we used the </span><span class="calibre5"><kbd class="calibre12"><span>RandomDiscrete</span></kbd></span> <span class="calibre5">search-criteria strategy</span><span class="calibre5">. </span></p>
<div class="packtinfobox">The default search-criteria strategy is Cartesian, which covers the entire space of hyperparameter combinations. The random discrete strategy carries out a random search of all the combinations of the hyperparameters provided.</div>
<p class="calibre2"><span class="calibre5">In <em class="calibre13">Step 5</em>, with the <kbd class="calibre12">get_grid()</kbd> method, we looked at the AUC score of each model built with different combinations of the parameters provided. In <em class="calibre13">Step 6</em>, we extracted the <kbd class="calibre12">best</kbd> model from the random grid search. We can also use the <kbd class="calibre12">print()</kbd> method on the best model to see the model performance metrics on both the train data and the cross-validation data.</span></p>
<p class="calibre2">In <em class="calibre13"><span class="calibre5">Step </span>7</em>, we trained a random forest model with default settings and looked at the summary of the resulting model in step 8. In <em class="calibre13"><span class="calibre5">Step </span>9</em> and <em class="calibre13"><span class="calibre5">Step </span>10</em>, we showcased the code to train a random forest model using grid-search. We set multiple values for various acceptable hyper-parameters, such as <kbd class="calibre12">sample_rate</kbd>, <kbd class="calibre12">col_sample_rate_per_tree</kbd>, <kbd class="calibre12">max_depth</kbd>, and <kbd class="calibre12">ntrees</kbd>. <span class="calibre5"><kbd class="calibre12">sample_rate</kbd> refers to row sampling without replacement. It takes a value between <kbd class="calibre12">0</kbd> and <kbd class="calibre12">1</kbd>, indicating the sampling percentage of the data. <kbd class="calibre12">col_sample_rate_per_tree</kbd> is the column sampling for each tree without replacement. <kbd class="calibre12">max_depth</kbd> is set to specify the maximum depth to which each tree should be built. Deeper trees may perform better on the training data but will take more computing time and may overfit and fail to generalize on unseen data. </span>The <kbd class="calibre12">ntrees</kbd> parameter is used for tree-based algorithms to specify the number of trees to build on the model.</p>
<p class="calibre2">In <em class="calibre13">Step 11</em> and <em class="calibre13"><span class="calibre5">Step </span>12</em>, we printed the AUC score of each model generated by the grid-search and extracted the best model from it.</p>
<p class="calibre2">We also trained GBM models to fit our data. In <em class="calibre13">Step 13</em>, we built the GBM using the default settings. In <em class="calibre13">Step 14</em>, we set the hyperparameter space for the grid search. We used this in <em class="calibre13">Step 15</em>, where we trained our GBM. In the GBM, we set values for hyperparameters, such as <kbd class="calibre12">learn_rate</kbd>, <kbd class="calibre12">sample_rate</kbd>, <kbd class="calibre12">col_sample_rate</kbd>, <kbd class="calibre12">max_depth</kbd>, and <kbd class="calibre12">ntrees</kbd>. The <kbd class="calibre12">learn_rate</kbd> parameter is used to specify the rate at which the GBM algorithm trains the model. A lower value for the <kbd class="calibre12">learn_rate</kbd> parameter is better and can help in avoiding overfitting, but can be costly in terms of computing time.</p>
<div class="packtinfobox">In H2O, <kbd class="calibre19">learn_rate</kbd> is available in GBM and XGBoost.</div>
<p class="calibre2"><em class="calibre13">Step 16</em> showed us the AUC score of each resulting model from the grid search. We extracted the best grid-searched GBM in <em class="calibre13">Step 17</em>.</p>
<p class="calibre2">In <em class="calibre13">Step 18</em> through to <em class="calibre13">Step 20</em>, we trained our stacked ensemble model using <kbd class="calibre12">H2OStackedEnsembleEstimator</kbd> from H2O. We evaluated the performance of the resulting model on the test data.</p>
<p class="calibre2">In S<em class="calibre13">tep 21</em>, we evaluated all the GLM models we built on our test data. We did the same with all the models we trained using RF and GBM. <em class="calibre13">Step 22</em> gave us the model with the maximum AUC score. In <em class="calibre13">Step 23</em>, we evaluated the AUC score of the stacked ensemble model on the test data in order to compare the performance of the stacked ensemble model with the individual base learners.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p class="calibre2">Note that we used cross-validation to train all our models. We used the <kbd class="calibre12">nfolds</kbd> option to set the number of folds to use for cross-validation. In our example, we used <kbd class="calibre12">nfolds=5</kbd>, but we can also set it to higher numbers.</p>
<div class="packttip">The number of folds needs to be the same across every models you build.</div>
<p class="calibre2">With a value for <kbd class="calibre12">nfolds</kbd> specified, we can also provide a value for the <kbd class="calibre12">fold_assignment</kbd> parameters. <kbd class="calibre12">fold_assignment</kbd> takes values such as <kbd class="calibre12">auto</kbd>, <kbd class="calibre12">random</kbd>, <kbd class="calibre12">modulo</kbd>, and <kbd class="calibre12">stratified</kbd>. If we set it to <kbd class="calibre12">Auto</kbd>, the algorithm automatically chooses an option; currently, it chooses <kbd class="calibre12">Random</kbd>. With <kbd class="calibre12">fold_assignment</kbd> set to <kbd class="calibre12">Random</kbd>, it will enable a random split of the data into <kbd class="calibre12">nfolds</kbd> sets. When<span class="calibre5"> <kbd class="calibre12">fold_assignment</kbd> is set to <kbd class="calibre12">Modulo</kbd>, it uses a deterministic method to evenly split the data into <kbd class="calibre12">nfolds</kbd></span> that don't depend on the <span class="calibre5"><kbd class="calibre12">seed</kbd> parameter. </span></p>
<div class="packttip">When we use cross-validation method to build models, ensure that you specify a <kbd class="calibre19">seed</kbd> value for all models or use <kbd class="calibre19">fold_assignment="Modulo"</kbd>.</div>
<p class="calibre2">In grid search, we used two parameters: <kbd class="calibre12">stopping_metric</kbd> and <kbd class="calibre12">stopping_rounds</kbd>. These parameters are available for GBM and random forest algorithms, but they aren't available for GLM. <span class="calibre5"><kbd class="calibre12">stopping_metric</kbd> </span><span class="calibre5">specifies the metric to consider when early stopping is specified, which can be done by setting <kbd class="calibre12">stopping_rounds</kbd> to a value greater than zero.</span></p>
<p class="calibre2"><span class="calibre5">In our examples, we set <kbd class="calibre12">stopping_metric</kbd></span> to AUC and <kbd class="calibre12">stopping_rounds</kbd> to five. This means that the algorithm will measure the AUC before it stops training any further if the AUC doesn't improve in the specified number of rounds, which is five in our case.</p>
<div class="packtinfobox">If <kbd class="calibre19">stopping_metric</kbd> is specified, <kbd class="calibre19">stopping_rounds</kbd> must be set as well. When <kbd class="calibre19">stopping_tolerance</kbd> is also set, the model will stop training after reaching the number of rounds mentioned in <kbd class="calibre19">stopping_rounds</kbd> if the model's <kbd class="calibre19">stopping_metric</kbd> doesn't improve by the <kbd class="calibre19">stopping_tolerance</kbd> value. </div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p class="calibre2">The H2O documentation is available at <a href="http://docs.h2o.ai/" class="calibre9">http://docs.h2o.ai/</a>.</p>


            </article>

            
        </section>
    </body></html>