- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Intermediate Data Processing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 中间数据处理
- en: The previous chapter covered a suite of commonly used functions offered by `dplyr`
    for data processing. For example, when characterizing and extracting the statistics
    of a dataset, we can follow the split-apply-combine procedure using `group_by()`
    and `summarize()`. This chapter continues from the previous one and focuses on
    intermediate data processing techniques, including transforming categorical and
    numeric variables and reshaping DataFrames. Besides that, we will also introduce
    string manipulation techniques for working with textual data, whose format is
    fundamentally different from the neatly shaped tables we have been working with
    so far.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了`dplyr`提供的用于数据处理的常用函数集。例如，在描述和提取数据集的统计信息时，我们可以使用`group_by()`和`summarize()`函数遵循拆分-应用-组合程序。本章从上一章继续，重点关注中间数据处理技术，包括转换分类和数值变量以及重塑数据框。除此之外，我们还将介绍用于处理文本数据的字符串操作技术，其格式与我们迄今为止所使用的整洁表格格式根本不同。
- en: By the end of this chapter, you will be able to perform more advanced data manipulation
    and extend your data massaging skills to string-based texts, which are fundamental
    to the field of natural language processing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够执行更高级的数据操作，并将你的数据处理技能扩展到基于字符串的文本，这对于自然语言处理领域是基本的。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Transforming categorical and numeric variables
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换分类和数值变量
- en: Reshaping the DataFrame
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重塑数据框
- en: Manipulating string data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作字符串数据
- en: Working with `stringr`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`stringr`
- en: Introducing regular expressions
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍正则表达式
- en: Working with tidy text mining
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用整洁文本挖掘
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete the exercises in this chapter, you will need to have the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章的练习，你需要具备以下条件：
- en: The latest version of the `rebus` package, which is 0.1-3 at the time of writing
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写本文时，`rebus`包的最新版本是0.1-3
- en: The latest version of the `tidytext` package, which is 0.3.2 at the time of
    writing
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写本文时，`tidytext`包的最新版本是0.3.2
- en: The latest version of the `tm` package, which is 0.7-8 at the time of writing
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写本文时，`tm`包的最新版本是0.7-8
- en: All the code and data for this chapter is available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/tree/main/Chapter_3](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/tree/main/Chapter_3).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码和数据都可在以下链接找到：[https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/tree/main/Chapter_3](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/tree/main/Chapter_3)。
- en: Transforming categorical and numeric variables
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换分类和数值变量
- en: As covered in the previous chapter, we can use the `mutate()` function from
    `dplyr` to transform existing variables and create new ones. The specific transformation
    depends on the type of the variable and the resulting shape we would like it to
    be. For example, we may want to change the value of a categorical variable according
    to a mapping dictionary, create a new variable based on a combination of filtering
    conditions of existing variables, or group a numeric variable into different ranges
    in a new variable. Let us look at these scenarios in turn.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，我们可以使用`dplyr`中的`mutate()`函数来转换现有变量并创建新变量。具体的转换取决于变量的类型和我们希望其具有的形状。例如，我们可能希望根据映射字典更改分类变量的值，基于现有变量的过滤条件组合创建新变量，或者将数值变量分组到新的变量中的不同范围。让我们依次查看这些场景。
- en: Recoding categorical variables
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新编码分类变量
- en: There are many cases when you would want to recode the values of a variable,
    such as mapping countries’ short names to the corresponding full names. Let’s
    create a dummy `tibble` dataset to illustrate this.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你可能需要重新编码变量的值，例如将国家的简称映射到相应的全称。让我们创建一个模拟的`tibble`数据集来展示这一点。
- en: 'In the following code, we have created a `students` variable that stores information
    on age, country, gender, and height. This is a small dummy dataset but it’s good
    enough for demonstration purposes:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们创建了一个`students`变量，用于存储有关年龄、国家、性别和身高的信息。这是一个小型模拟数据集，但对于演示目的来说已经足够好了：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, let’s go through an example of converting the values of the `country` variable
    into their full names.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一个将`country`变量的值转换为全称的示例来了解这个过程。
- en: Exercise 3.1 – converting the country variable values into their full names
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习3.1 – 将国家变量值转换为全称
- en: 'This exercise will use the `recode()` function from the `dplyr` package to
    map the existing short country names to the corresponding full names:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习将使用 `dplyr` 包中的 `recode()` 函数将现有的短国家名称映射到相应的全称：
- en: 'Add a new column that converts the short country names into the corresponding
    full names by providing a mapping table using `recode()`:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用 `recode()` 函数并提供映射表来添加一个新列，将短国家名称转换为相应的全称：
- en: '[PRE1]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, we provided a mapping dictionary as an argument in the `recode()` function,
    which searches for the keys in the left column and assigns the corresponding values
    in the right column to `country_fullname`. Note that the newly created column
    assumes a character type.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们提供了映射字典作为 `recode()` 函数的参数，该函数在左侧列中搜索键，并将右侧列中对应的值分配给 `country_fullname`。请注意，新创建的列假定是字符类型。
- en: 'Perform the same conversion and store the result as a `factor` type:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行相同的转换，并将结果存储为 `factor` 类型：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can see that the resulting variable, `country_fullname2`, is a factor by
    using `recode_factor()`.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到，使用 `recode_factor()` 后，生成的变量 `country_fullname2` 是一个因子。
- en: When the new column we want to create depends on a complex combination of existing
    ones, we can resort to the `case_when()` function, as introduced in the following
    section.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要创建的新列依赖于现有列的复杂组合时，我们可以求助于下一节中介绍的 `case_when()` 函数。
- en: Creating variables using case_when()
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 case_when() 创建变量
- en: The `case_when()` function provides a convenient way to set multiple `if-else`
    conditions when creating a new variable. It takes a sequence of two-sided formulas,
    where the left-hand side contains the filtering conditions and the right-hand
    side provides the replacement value that matches the preceding conditions. The
    syntax inside the function follows a `logical condition(s) ~ replacement value`
    pattern that gets evaluated sequentially, where multiple variables can be used
    inside the logical conditioning. At the end of the sequence is a `TRUE ~ default
    value` case that gets assigned to the variable if all preceding conditions evaluate
    to `FALSE`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`case_when()` 函数提供了一个在创建新变量时设置多个 `if-else` 条件的便捷方式。它接受一系列双向公式，其中左侧包含筛选条件，右侧提供与先前条件匹配的替换值。函数内部的语法遵循
    `逻辑条件(们) ~ 替换值` 的模式，这些条件按顺序进行评估，其中可以在逻辑条件中使用多个变量。序列的末尾是一个 `TRUE ~ 默认值` 的情况，如果所有先前条件评估为
    `FALSE`，则将该值分配给变量。'
- en: Let’s go through an exercise to create a new variable based on multiple `if-else`
    conditions involving multiple columns.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个练习来创建一个基于多个 `if-else` 条件的新变量，这些条件涉及多个列。
- en: Exercise 3.2 – creating a new variable using multiple conditions and columns
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.2 – 使用多个条件和列创建新变量
- en: In this exercise, we will create a new variable that indicates the age and region
    of the students.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将创建一个新变量，该变量指示学生的年龄和地区。
- en: 'Create a new variable type to identify whether the students come from Asia
    and are in their 20s or 30s by assuming `asia_20+` and `asia_30+` as values, respectively.
    Set the value to `others` if there is no match:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新变量类型，用于识别学生是否来自亚洲，以及他们是否在20多岁或30多岁，分别假设 `asia_20+` 和 `asia_30+` 作为值。如果没有匹配项，将值设置为
    `others`：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, we used the `&` sign to combine multiple `AND` conditions that evaluate
    `age` and `country`. When neither of the preceding conditions in the sequence
    evaluate to `TRUE`, the function will fall into the all-encompassing `TRUE` case
    and assign `others` as the default value.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了 `&` 符号来组合多个评估 `年龄` 和 `国家` 的 `AND` 条件。当序列中的前一个条件都不评估为 `TRUE` 时，函数将落入包含所有条件的
    `TRUE` 情况，并将 `others` 作为默认值分配。
- en: Next, we will look at converting a numeric column into different bins/categories.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看将数值列转换为不同的箱/类别。
- en: Binning numeric variables using cut()
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 cut() 对数值变量进行分箱
- en: A numeric column can be partitioned into different categories using the `cut()`
    function. For a numeric column, it assigns the value to the corresponding predefined
    intervals and codes the value based on the assigned interval. The resulting column
    of intervals assumes an ordered factor type.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `cut()` 函数将数值列划分为不同的类别。对于数值列，它将值分配给相应的预定义区间，并根据分配的区间对值进行编码。生成的区间列假定是一个有序因子类型。
- en: 'The `cut()` function has three key arguments: `x` to accept a numeric vector
    to be binned, `breaks` to accept a numeric vector of cut points, which could include
    negative infinity, `–Inf`, and positive infinity, `Inf`, and `labels` to indicate
    the labels of the resulting intervals.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`cut()`函数有三个关键参数：`x`用于接受要分组的数值向量，`breaks`用于接受一个数值向量作为切割点，这可能包括负无穷大`-Inf`和正无穷大`Inf`，以及`labels`用于指示结果区间的标签。'
- en: Let’s go through an exercise using `cut()` to convert the `age` column into
    different age groups.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用`cut()`将`age`列转换为不同的年龄组进行一次练习。
- en: Exercise 3.3 – binning the age column into three groups
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习3.3 – 将年龄列分为三个组
- en: 'In this exercise, we will use the `cut()` function to assign the value of the
    `age` column to one of the following ranges: `(-infinity, 25)`, `[26, 30]`, or
    `[``31, infinity]`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用`cut()`函数将`age`列的值分配到以下范围之一：`(-infinity, 25)`、`[26, 30]`或`[31, infinity]`：
- en: 'Segment the `age` column into three intervals with breakpoints at `25` and
    `30` (inclusive on the right) and store them in a new column named `age_group`:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`age`列分为三个区间，断点为`25`和`30`（右侧包含），并将它们存储在一个名为`age_group`的新列中：
- en: '[PRE4]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we can see that `age_group` is an ordered factor with three levels.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们可以看到`age_group`是一个有序因子，有三个层级。
- en: A few cutting functions perform automatic binning when we do not have a specific
    cutoff point in mind. For example, `cut_interval()` cuts the original vector into
    a specified number of groups with equal intervals, while `cut_number()` converts
    the input vector into a specific number of groups, where each group has approximately
    the same number of observations. The `tidyverse` package provides both functions.
    Let’s try them out.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 几个切割函数在没有特定截止点的情况下执行自动分组。例如，`cut_interval()`将原始向量切割成指定数量的等间隔组，而`cut_number()`将输入向量转换为指定数量的组，其中每个组大约有相同数量的观测值。`tidyverse`包提供了这两个函数。让我们尝试一下。
- en: 'Group the `age` column into three bins of equal length using `cut_interval()`:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cut_interval()`将`age`列分为三个等长的组：
- en: '[PRE5]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `age_group` column now consists of three levels that represent equal-length
    intervals. Let’s check out the counts of each level using the `summary()` function:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`age_group`列现在由三个代表等长区间的层级组成。让我们使用`summary()`函数检查每个层级的计数：'
- en: '[PRE6]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Group the `age` column into three bins of an equal number of observations using
    `cut_interval()`:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cut_interval()`将`age`列分为具有相等观测数的三个组：
- en: '[PRE7]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The cutoff points are now assuming decimal points to make the resulting count
    of observations approximately equal, as verified in the following code:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 截止点现在假设为小数点，以使观测值的计数大约相等，如下面的代码所验证：
- en: '[PRE8]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: So far, we have looked at different ways to transform an existing categorical
    or numeric variable and create a new variable based on specific conditions. Next,
    we will look at how to transform and reshape the whole DataFrame to facilitate
    our analysis.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了不同的方法来转换现有的分类或数值变量，并基于特定条件创建新变量。接下来，我们将探讨如何转换和重塑整个DataFrame，以方便我们的分析。
- en: Reshaping the DataFrame
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重塑DataFrame
- en: A DataFrame that consists of a combination of categorical and numeric columns
    can be expressed in both wide and long formats. For example, the `students` DataFrame
    is considered a long format since all countries are stored in the `country` column.
    Depending on the specific purpose of processing, we may want to create a separate
    column for each unique country in the dataset, which adds more columns to the
    DataFrame and converts it into a wide format.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由分类和数值列组合而成的DataFrame可以用宽格式和长格式表示。例如，`students`DataFrame被认为是长格式，因为所有国家都存储在`country`列中。根据处理的具体目的，我们可能希望为数据集中的每个唯一国家创建一个单独的列，这会增加DataFrame的列数，并将其转换为宽格式。
- en: Converting between wide and long formats can be achieved via the `spread()`
    and `gather()` functions, both of which are provided by the `tidyr` package from
    the `tidyverse` ecosystem. Let’s see how it works in practice.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`spread()`和`gather()`函数可以在宽格式和长格式之间进行转换，这两个函数都由`tidyr`包提供，属于`tidyverse`生态系统。让我们看看它在实际中的应用。
- en: Converting from long format into wide format using spread()
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`spread()`将长格式转换为宽格式
- en: There will be times when we’ll want to turn a long-formatted DataFrame into
    a wide format. The `spread()` function can be used to convert a categorical column
    with multiple categories into multiple columns, as specified by the `key` argument,
    with each category added to the DataFrame as a separate column. The column names
    will be the unique values of the categorical column. The `value` argument specifies
    the contents to be spread and filled in these additional columns upon calling
    the `spread()` function. Let’s go through an exercise on this.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会需要将长格式 DataFrame 转换为宽格式。`spread()` 函数可以将具有多个类别的分类列转换为由 `key` 参数指定的多个列，每个类别作为
    DataFrame 中的单独列添加。列名将是分类列的唯一值。`value` 参数指定在调用 `spread()` 函数时要在这些附加列中展开和填充的内容。让我们通过一个练习来了解。
- en: Exercise 3.4 – converting from long format into wide format
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.4 – 将长格式转换为宽格式
- en: 'In this exercise, we will convert the `students` DataFrame into a wide format
    using `spread()`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用 `spread()` 将 `students` DataFrame 转换为宽格式：
- en: 'Use `country` as the `key` argument and `height` as the `value` argument to
    convert students into a wide format using `spread()`. Store the resulting DataFrame
    in `students_wide`:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `country` 作为 `key` 参数，`height` 作为 `value` 参数，使用 `spread()` 将学生转换为宽格式。将结果
    DataFrame 存储在 `students_wide` 中：
- en: '[PRE9]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can see that the original `height` column disappears, and four additional
    columns are added. These four columns correspond to the unique countries, and
    the values of these columns are filled in by the heights. If the corresponding
    height for a particular country is not available, `NA` is used to fill in the
    missing combination.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到原始的 `height` 列消失了，并增加了四个附加列。这四个列对应于唯一的各国，这些列的值由身高填充。如果特定国家的对应身高不可用，则使用
    `NA` 填充缺失的组合。
- en: If we want to specify a default value for these `NA` values, we can set the
    `fill` argument in `spread()`.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们想为这些 `NA` 值指定默认值，我们可以在 `spread()` 中设置 `fill` 参数。
- en: 'Use the rounded average height to fill the `NA` values in the resulting wide
    format. Store the resulting DataFrame in `students_wide2`:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用四舍五入的平均身高来填充结果宽格式中的 `NA` 值。将结果 DataFrame 存储在 `students_wide2` 中：
- en: '[PRE10]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Converting from long into wide could be helpful from an analysis and presentational
    perspective since we can visually compare the heights across all countries for
    a specific combination of age and gender. However, this comes with additional
    storage costs, as shown by the multiple `NA` values earlier.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从长格式转换为宽格式在分析和展示方面可能很有帮助，因为我们可以直观地比较特定年龄和性别组合下所有国家的身高。然而，这会带来额外的存储成本，如之前显示的多个
    `NA` 值所示。
- en: Now, let’s learn how to convert a wide-formatted DataFrame into a long format.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习如何将宽格式 DataFrame 转换为长格式。
- en: Converting from wide format into long format using gather()
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 `gather()` 函数将宽格式转换为长格式
- en: When we are in the opposite situation, where the given data is in a wide format,
    we can use the `gather()` function to convert it into a long format for more convenient
    follow-up processing. For example, by compressing the four country columns into
    the `key` variable and storing all heights under the `value` variable specified
    in `gather()`, we can continue with the usual split-apply-combine treatments we
    introduced earlier based on just two columns instead of four or more.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处于相反的情况，即给定的数据是宽格式时，我们可以使用 `gather()` 函数将其转换为长格式，以便进行更方便的后续处理。例如，通过将四个国家列压缩到
    `key` 变量中，并将所有身高存储在 `gather()` 中指定的 `value` 变量下，我们可以继续使用我们之前介绍过的基于两列（而不是四列或更多）的常规分割-应用-组合处理。
- en: The `gather()` function also uses the `key` and `value` arguments to specify
    the name of the resulting `key` and `value` columns in the long-formatted table.
    Besides, we need to specify the columns whose names are used to fill in the `key`
    column and the values in the `value` column. When there are many adjacent columns
    to specify, we can use the `:` operator by passing the starting and ending column
    names to select all columns in between. Let’s go through a practice exercise.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`gather()` 函数也使用 `key` 和 `value` 参数来指定长格式表中结果的 `key` 和 `value` 列的名称。此外，我们还需要指定用于填充
    `key` 列的列名和 `value` 列中的值。当需要指定许多相邻的列时，我们可以通过传递起始和结束列名来使用 `:` 运算符选择所有中间的列。让我们通过一个练习来了解。'
- en: Exercise 3.5 – converting from wide format into long format
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.5 – 将宽格式转换为长格式
- en: 'This exercise will convert the wide-formatted `students_wide` DataFrame back
    into its original long format:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习将宽格式化的`students_wide` DataFrame转换回其原始的长格式：
- en: 'Convert `students_wide` into a long format by specifying the `key` column as
    `country` and the `value` column as `height`, and using the values of the `CN`,
    `IN`, `SG`, and `UK` columns to fill in the `key` and `value` columns, respectively:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过指定`key`列为`country`和`value`列为`height`，并将`CN`、`IN`、`SG`和`UK`列的值分别用于填充`key`和`value`列，将`students_wide`转换为长格式：
- en: '[PRE11]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can see that several rows with missing values in the `height` column have
    been added to `students_long`. This is because of their original presence in `students_wide`.
    Let’s remove them using the `drop_na()` function from `dplyr`.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到，由于`students_wide`中原本就存在缺失值，`height`列中添加了几行缺失值。让我们使用`dplyr`中的`drop_na()`函数来删除它们。
- en: 'Remove the rows with `NA` values in the `height` column:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除`height`列中的`NA`值行：
- en: '[PRE12]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With that, we have obtained the long-formatted DataFrame. Now, let’s verify
    whether it is the same as the original `students` DataFrame.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过这样，我们已经获得了长格式的DataFrame。现在，让我们验证它是否与原始的`students` DataFrame相同。
- en: 'Verify whether `students_long` is the same as `students` using `all_equal()`:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`all_equal()`验证`students_long`是否与`students`相同：
- en: '[PRE13]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `all_equal()` function from `dplyr` compares two datasets and checks whether
    they are identical. It provides a flexible way to carry out an equality comparison
    and supports ignoring the ordering of rows and/or columns. The result shows that
    we have successfully converted back into the original dataset.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`dplyr`中的`all_equal()`函数比较两个数据集并检查它们是否相同。它提供了一种灵活的方法来进行等价比较，并支持忽略行和/或列的顺序。结果显示，我们已经成功转换回原始数据集。'
- en: With that, we have looked at different ways to reshape the DataFrame. Next,
    we will cover how to deal with string data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经探讨了不同的方法来重塑DataFrame。接下来，我们将介绍如何处理字符串数据。
- en: Manipulating string data
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作字符串数据
- en: Character-typed strings are standard in real-life data, such as name and address.
    Analyzing string data requires properly cleaning the raw characters and converting
    the information embedded in a blob of textual data into a quantifiable numeric
    summary. For example, we may want to find the matching names of all students that
    follow a specific pattern.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串类型在现实生活中的数据中很常见，例如姓名和地址。分析字符串数据需要正确清理原始字符，并将文本数据块中嵌入的信息转换为可量化的数值摘要。例如，我们可能想要找到所有遵循特定模式的学生的匹配姓名。
- en: This section will cover different ways to define patterns via regular expressions
    to detect, split, and extract string data. Let’s start with the basics of strings.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍通过正则表达式定义不同模式的方法，以检测、分割和提取字符串数据。让我们从字符串的基础知识开始。
- en: Creating strings
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建字符串
- en: A `""`). Sometimes, a single quote (`'`) is also used to denote a string, although
    it is generally recommended to use double quotes unless the characters themselves
    include double quotes.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，单个引号（`'`）也被用来表示字符串，尽管通常建议除非字符本身包含双引号，否则使用双引号。
- en: There are multiple ways to create a string. The following exercise introduces
    a few different ways to initialize a character-typed string.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 创建字符串有多种方式。以下练习介绍了初始化字符类型字符串的几种不同方法。
- en: Exercise 3.6 – expressing strings in R
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习3.6 – 在R中表达字符串
- en: 'In this exercise, we will look at creating strings in R:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将探讨如何在R中创建字符串：
- en: 'Try to type out the following strings in the R console:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试在R控制台中键入以下字符串：
- en: '[PRE14]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The strings are printed without error. Let’s see what happens if we wrap `statistics`
    with double quotes to highlight this word.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 字符串被正确打印出来。让我们看看如果我们用双引号包裹`statistics`会发生什么。
- en: 'Add double quotes to `statistics` in the string:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在字符串中给`statistics`添加双引号：
- en: '[PRE15]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This time, an error pops up because R takes the second double quote as the ending
    quote of the string. This error can be avoided by switching to using single quotes
    for the outside quotes when double quotes are used in a string.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次，出现了一个错误，因为R将第二个双引号视为字符串的结束引号。可以通过在字符串中使用双引号时，将外部引号切换为单引号来避免这个错误。
- en: 'Wrap the previous string with single quotes:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用单引号包裹前面的字符串：
- en: '[PRE16]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now, R interprets the string correctly and considers all content within the
    pair of single quotes as a whole string. Note that the resulting string is still
    printed with double quotes in the console. The two double quotes within the string
    are also preceded by a backward slash (`\`). This is called an escape sequence
    and is used to indicate the literal interpretation of the double quotes as characters
    instead of the start of a string. The escape sequence is a useful way to include
    special characters in a string.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，R正确解释了字符串，并将单引号对内的所有内容视为一个整体字符串。请注意，结果字符串在控制台中仍然用双引号打印。字符串内的两个双引号前面也有一个反斜杠（`\`）。这被称为转义序列，用于指示双引号作为字符的原始解释，而不是字符串的开始。转义序列是在字符串中包含特殊字符的有用方式。
- en: We can also manually add the escape character inside the string to enforce the
    correct interpretation, which will print out the same result as before.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们也可以在字符串内部手动添加转义字符，以强制正确解释，这将打印出与之前相同的结果。
- en: 'Add the escape sequence before the double quotes inside the string:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在字符串内部双引号之前添加转义序列：
- en: '[PRE17]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Printing out the string sequence with a backslash is not convenient for reading.
    To beautify the output, we can pass the exact string to the `writeLines()` function.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用反斜杠打印字符串序列不方便阅读。为了美化输出，我们可以将确切字符串传递给`writeLines()`函数。
- en: 'Print the same string using `writeLines()`:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`writeLines()`打印相同的字符串：
- en: '[PRE18]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Next, we will look at how to turn numbers into strings for better interpretation.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何将数字转换为字符串以进行更好的解释。
- en: Converting numbers into strings
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数字转换为字符串
- en: As we learned earlier, numbers can be converted into strings via the `as.character()`
    function. However, it would be inconvenient to directly read and report a big
    number such as `123000`. We would usually express it in a more readable manner
    such as 123,000 or a more concise way such as 1.23e+05, where the latter follows
    the scientific representation with e+05 equal to 105\. Additionally, we may want
    to display a limited number of digits after the decimal point for a floating number.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所学，数字可以通过`as.character()`函数转换为字符串。然而，直接读取和报告像`123000`这样的大数字会很不方便。我们通常会以更易读的方式表达，例如123,000，或者以更简洁的方式，例如1.23e+05，后者遵循科学表示法，其中e+05等于105。此外，我们可能还想显示浮点数小数点后有限位数的数字。
- en: All of these can be achieved via the `format()` function, which is useful when
    converting and printing numbers as strings while following different formats.
    Let’s see how this is done in practice.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都可以通过`format()`函数实现，这在将数字作为字符串转换和打印时遵循不同格式时非常有用。让我们看看在实践中是如何做到这一点的。
- en: Exercise 3.7 – converting numbers into strings using format()
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习3.7 – 使用`format()`将数字转换为字符串
- en: 'This exercise will use `format()` to convert numbers into pretty and easily
    readable strings:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习将使用`format()`将数字转换为漂亮且易于阅读的字符串：
- en: 'Add a comma as a thousands separator to `123000` by specifying the `big.mark`
    argument in `format()`:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在`format()`函数中指定`big.mark`参数，将逗号作为千位分隔符添加到`123000`：
- en: '[PRE19]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Notice that the result is now a character-type string with a comma added.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，现在结果是带有逗号的字符类型字符串。
- en: 'Convert `123000` into scientific format:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`123000`转换为科学格式：
- en: '[PRE20]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Using scientific format is a concise way to represent large numbers. We can
    also shorten a long floating number by specifying the number of digits to display.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用科学格式是表示大数字的简洁方式。我们还可以通过指定显示的数字位数来缩短一个长的浮点数。
- en: 'Display only three digits of `1.256` by specifying the `digits` argument:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过指定`digits`参数，仅显示`1.256`的三个数字：
- en: '[PRE21]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The result is rounded and converted into a string, displaying only three digits
    as specified. We can also achieve the same rounding effect using `round()`.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果被四舍五入并转换为字符串，显示指定数量的三个数字。我们也可以使用`round()`函数达到相同的四舍五入效果。
- en: 'Round `1.256` to two decimal points:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`1.256`四舍五入到两位小数：
- en: '[PRE22]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This time, the result is still numeric since `round()` does not involve type
    conversion.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次，结果仍然是数值型，因为`round()`不涉及类型转换。
- en: In the next section, we will look at connecting multiple strings.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨连接多个字符串。
- en: Connecting strings
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接字符串
- en: When there are multiple strings, we can use `paste()` to connect and join them
    into a single string. This becomes important if we want to print long and customized
    messages in our program instead of relying on manually typing them out.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当有多个字符串时，我们可以使用`paste()`将它们连接并合并成一个字符串。如果我们想在程序中打印长而定制的消息而不是手动输入，这变得很重要。
- en: The `paste()` function takes an arbitrary number of string inputs as arguments
    and combines them into one. Let’s see how it works.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`paste()` 函数接受任意数量的字符串输入作为参数，并将它们组合成一个。让我们看看它是如何工作的。'
- en: Exercise 3.8 – combining strings using paste()
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.8 – 使用 paste() 组合字符串
- en: 'In this exercise, we will look at different ways to combine multiple string
    inputs:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将探讨不同的方法来组合多个字符串输入：
- en: 'Connect the `statistics` and `workshop` strings to generate `statistics workshop`:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `statistics` 和 `workshop` 字符串连接起来生成 `statistics workshop`：
- en: '[PRE23]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, we can see that a space is automatically added between the two strings.
    This is controlled by the `sep` argument, which specifies the filling content
    between strings and assumes a default value of a space. We can choose to override
    the default behavior by passing a separating character to this argument.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到两个字符串之间自动添加了一个空格。这是由 `sep` 参数控制的，它指定了字符串之间的填充内容，并假定默认值为空格。我们可以选择通过传递一个分隔字符来覆盖默认行为。
- en: 'Remove the space in between and generate `statisticsworkshop`:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除中间的空格并生成 `statisticsworkshop`：
- en: '[PRE24]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Connect a vector of `statistics` and `workshop` with `course`:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `statistics` 和 `workshop` 向量与 `course` 连接：
- en: '[PRE25]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The result shows that `course` is added to each element in the vector. This
    is completed via the recycling operation under the hood, where `course` is recycled
    so that it can be combined with each string in the vector. This is similar to
    the broadcasting mechanism in Python.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示 `course` 被添加到向量的每个元素中。这是通过底层的回收操作完成的，其中 `course` 被回收以便可以与向量中的每个字符串组合。这类似于
    Python 中的广播机制。
- en: We can also remove the vector structure and combine all elements into a single
    string by specifying the `collapse` argument.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们也可以通过指定 `collapse` 参数来移除向量结构并将所有元素组合成一个字符串。
- en: 'Compress the previous output into a single string separated by `+`:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将之前的输出压缩成一个由 `+` 分隔的单个字符串：
- en: '[PRE26]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: After plugging in all the components of the combined vector and separating them
    by the specified argument, the result is a single collapsed string.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在将组合向量的所有组件插入并按指定参数分隔后，结果是单个折叠的字符串。
- en: So far, we have learned the basics when it comes to working with string data.
    The `stringr` package provided by the `tidyverse` ecosystem provides many handy
    functions if we want to have more flexible control of our strings. This will be
    covered in the following section.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了处理字符串数据的基本知识。`tidyverse` 生态系统提供的 `stringr` 包提供了许多方便的函数，如果我们想要对字符串有更灵活的控制，这将在本节中介绍。
- en: Working with stringr
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 stringr 处理字符串
- en: The `stringr` package provides a cohesive set of functions that all start with
    `str_` and are designed to make working with strings as easy as possible.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`stringr` 包提供了一套连贯的函数，所有这些函数都以 `str_` 开头，旨在使字符串处理尽可能容易。'
- en: Let’s start with the basic functions of `stringr` by replicating the same results
    from the previous exercise.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 `stringr` 的基本函数开始，通过复制上一个练习中的相同结果。
- en: Basics of stringr
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: stringr 的基础知识
- en: The `str_c()` function from the `stringr` package can concatenate multiple strings
    with similar functionalities as in `paste()`. Let’s see its use in action.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`stringr` 包中的 `str_c()` 函数可以像 `paste()` 一样连接多个字符串，具有类似的功能。让我们看看它的实际应用。'
- en: Exercise 3.9 – combining strings using paste()
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.9 – 使用 paste() 组合字符串
- en: 'In this exercise, we will reproduce the same as what we did in *Exercise 3.8*
    using `str_c()`:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用 `str_c()` 重复 *练习 3.8* 中的相同操作：
- en: 'Concatenate `statistics` with `workshop` with a separating space in between:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `statistics` 和 `workshop` 之间添加一个分隔空格来连接：
- en: '[PRE27]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We can use the `sep` argument to specify the separator between strings.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以使用 `sep` 参数来指定字符串之间的分隔符。
- en: 'Combine a vector of `statistics` and `workshop` with `course`:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `statistics` 和 `workshop` 向量与 `course` 结合：
- en: '[PRE28]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The same recycling behavior also appears here.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相同的回收行为也出现在这里。
- en: 'Compress the preceding output into a single string separated by `+`:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前面的输出压缩成一个由 `+` 分隔的单个字符串：
- en: '[PRE29]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'There are two other common `stringr` functions: `str_length()`, which returns
    the length of the string, and `str_sub()`, which subtracts parts of the string:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个其他常见的 `stringr` 函数：`str_length()`，它返回字符串的长度，和 `str_sub()`，它从字符串中减去部分内容：
- en: For example, we can get the length of each string in a vector, as shown in the
    following code snippet.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，我们可以得到向量中每个字符串的长度，如下面的代码片段所示。
- en: '[PRE30]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Alternatively, we can use the `nchar()` function from base R to achieve the
    same result, as shown here:'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者，我们可以使用来自基础 R 的 `nchar()` 函数来达到相同的结果，如下所示：
- en: '[PRE31]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can also use `str_sub()` to extract parts of the string by providing a starting
    and ending index:'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还可以使用 `str_sub()` 通过提供起始和结束索引来提取字符串的一部分：
- en: '[PRE32]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Extracting parts of a string is one way to look for patterns in the string.
    In the next section, we will cover a more advanced approach for pattern matching
    beyond positional indexing.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 提取字符串的一部分是查找字符串中模式的一种方式。在下一节中，我们将介绍一种比位置索引更高级的字符串匹配方法。
- en: Pattern matching in a string
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 字符串中的模式匹配
- en: Matching patterns in a string is a common way to extract intelligence from textual
    data. When a match is found, we could split or replace the string based on the
    match, add additional data such as the number of matches, or perform other text-based
    analyses. Let’s go through a few exercises to get familiar with string matches.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在字符串中匹配模式是提取文本数据中的信息的一种常见方式。当找到匹配时，我们可以根据匹配拆分或替换字符串，添加如匹配次数等额外数据，或执行其他基于文本的分析。让我们通过几个练习来熟悉字符串匹配。
- en: Exercise 3.10 – locating matches in a string
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.10 – 在字符串中定位匹配
- en: 'In this exercise, we will cover three functions that are commonly used in locating
    a match in a string, including detecting a match using `str_detect()`, selecting
    the strings of a vector that have a match using `str_subset()`, and counting the
    number of matches in a string using `str_count()`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将介绍三个在字符串中定位匹配时常用的函数，包括使用 `str_detect()` 检测匹配、使用 `str_subset()` 选择具有匹配的向量字符串，以及使用
    `str_count()` 在字符串中计算匹配次数：
- en: 'Detect the occurrence of `stat` in a vector of strings containing `statistics`
    and `workshop`:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在包含 `statistics` 和 `workshop` 的字符串向量中检测 `stat` 的出现：
- en: '[PRE33]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `str_detect()` function looks for a specified pattern in the input strings
    and returns a logical vector of the same length as the input vector, with `TRUE`
    indicating a match and `FALSE` otherwise.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`str_detect()` 函数在输入字符串中查找指定的模式，并返回一个与输入向量长度相同的逻辑向量，其中 `TRUE` 表示匹配，否则为 `FALSE`。'
- en: 'Subset the string that contains `stat`:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择包含 `stat` 的字符串子集：
- en: '[PRE34]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `str_subset()` function completes detection and selection in one shot. It
    will return only the strings that match the specified pattern.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`str_subset()` 函数一次完成检测和选择。它将仅返回与指定模式匹配的字符串。'
- en: 'Count the occurrence of `t` in each string of the previous vector:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算前一个向量中每个字符串中 `t` 的出现次数：
- en: '[PRE35]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `str_count()` function returns an integer vector of the same length as the
    input vector and shows each string’s frequency of a particular match.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`str_count()` 函数返回一个与输入向量长度相同的整数向量，显示每个字符串中特定匹配的频率。'
- en: Next, we will look at how to split a string based on a particular match.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何根据特定的匹配来拆分字符串。
- en: Splitting a string
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆分字符串
- en: Splitting a string based on a specific pattern can be achieved via the `str_split()`
    function, which assumes a similar naming and argument setting as in previous functions.
    The original string could then be decomposed into smaller pieces to support a
    more refined analysis. Let’s see how it can be used.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 根据特定模式拆分字符串可以通过 `str_split()` 函数实现，该函数假设与之前函数具有相似的命名和参数设置。然后原始字符串可以被分解成更小的部分以支持更精细的分析。让我们看看它是如何使用的。
- en: Exercise 3.11 – splitting a string using str_split()
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.11 – 使用 str_split() 拆分字符串
- en: 'This exercise will use `str_split()` to decompose a string into smaller pieces
    based on a specific matching condition:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习将使用 `str_split()` 根据特定的匹配条件将字符串分解成更小的部分：
- en: 'Separate the `statistics & machine learning workshop` string at the `&` sign:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `&` 符号处拆分 `statistics & machine learning workshop` 字符串：
- en: '[PRE36]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The result is a single-entry list that contains a vector of two elements in
    the first entry. Note that both the resulting substrings have a space inside,
    showing that the an exact pattern match is used to split the string. We could
    then include the space in the matching pattern to remove the spaces in the resulting
    substrings.
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果是一个包含两个元素的向量列表，位于第一个条目中。请注意，结果子字符串中都有空格，这表明使用了精确的模式匹配来拆分字符串。然后我们可以将空格包含在匹配模式中，以移除结果子字符串中的空格。
- en: 'Include preceding and trailing spaces in the matching pattern:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在匹配模式中包含前导和尾随空格：
- en: '[PRE37]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: With that, the spaces in the substrings have been removed. As shown in the following
    code snippet, since the result is wrapped in a list, we can follow the list indexing
    rule to access the corresponding element.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过这种方式，子字符串中的空格已经被移除。如下面的代码片段所示，由于结果被包裹在一个列表中，我们可以遵循列表索引规则来访问相应的元素。
- en: 'Access the second element from the previous result:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从上一个结果中访问第二个元素：
- en: '[PRE38]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Next, we will look at replacing a matched pattern in a string.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看如何在字符串中替换匹配的模式。
- en: Replacing a string
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替换字符串
- en: The `str_replace()` and `str_replace_all()` functions replace the matches with
    new text specified by the `replacement` argument. The difference is that `str_replace()`
    only replaces the first match, while `str_replace_all()` replaces all matches
    as its name suggests.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`str_replace()` 和 `str_replace_all()` 函数使用 `replacement` 参数指定的新文本替换匹配项。区别在于
    `str_replace()` 只替换第一个匹配项，而 `str_replace_all()` 如其名称所示替换所有匹配项。'
- en: 'Let’s try replacing the `&` sign with `and` using both functions:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用两个函数将 `&` 符号替换为 `and`：
- en: '[PRE39]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can see that all `&` signs are replaced by `and` in the second string. Again,
    replacing a particular match involves a two-step process: locating the match,
    if any, and performing the replacement. The `str_replace()` and `str_replace_all()`
    functions complete both steps in one shot.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，第二个字符串中的所有 `&` 符号都被替换为 `and`。再次强调，替换特定匹配项涉及两个步骤：定位匹配项（如果有的话），然后执行替换。`str_replace()`
    和 `str_replace_all()` 函数一次完成这两个步骤。
- en: In the next section, we will go through a bit of a challenge that requires combining
    these `stringr` functions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将遇到一个需要结合这些 `stringr` 函数的挑战。
- en: Putting it together
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 整合起来
- en: Often, a particular string processing task involves using more than one `stringr`
    function. Together, these functions could deliver useful transformations to the
    textual data. Let’s go through an exercise that puts together what we have covered
    so far.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，一个特定的字符串处理任务会涉及使用多个 `stringr` 函数。这些函数结合在一起可以对文本数据进行有用的转换。让我们通过一个练习来整合到目前为止我们所学的知识。
- en: Exercise 3.12 – converting strings using multiple functions
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.12 – 使用多个函数转换字符串
- en: 'In this exercise, we will use different string-based functions to convert `statistics
    and machine leaning workshop` into `stats & ml workshop`. First, we will replace
    `and` with the `&` sign, split the string, and work with the individual pieces.
    Let’s see how this can be achieved:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用不同的基于字符串的函数将 `statistics and machine leaning workshop` 转换为 `stats
    & ml workshop`。首先，我们将 `and` 替换为 `&` 符号，分割字符串，并处理各个部分。让我们看看如何实现这一点：
- en: 'Create a `title` variable to hold the string and replace `and` with `&`:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `title` 变量来存储字符串，并将 `and` 替换为 `&`：
- en: '[PRE40]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Here, we used `str_replace()` to replace `and` with `&`.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用 `str_replace()` 将 `and` 替换为 `&`。
- en: 'Split `title` into substrings using `&`:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `&` 将 `title` 分割成子字符串：
- en: '[PRE41]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Here, we used `str_split()` to split the original string into smaller substrings.
    Note that additional spaces are added to the matching pattern as well. We will
    work with these individual pieces now.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用 `str_split()` 将原始字符串分割成更小的子字符串。注意，匹配模式中也添加了额外的空格。我们现在将处理这些单个部分。
- en: 'Convert `statistics` into `stats`:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `statistics` 转换为 `stats`：
- en: '[PRE42]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Here, we extracted the first four characters, namely `stat`, and the last character,
    `s`, using `str_sub()`, then concatenated them using `str_c()`. Note that `-1`
    indicates the last positional indexing of a string.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用 `str_sub()` 提取了前四个字符，即 `stat`，以及最后一个字符 `s`，然后使用 `str_c()` 将它们连接起来。注意
    `-1` 表示字符串的最后一个位置索引。
- en: Now, we can start to work on the second part.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以开始处理第二部分。
- en: 'Split the second element of the `a` variable with a space:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用空格分割 `a` 变量的第二个元素：
- en: '[PRE43]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Here, we used `str_split()` to split the `machine leaning workshop` string with
    a space and converted the result from a list into a vector using `unlist()`. We
    did this conversion to save some typing in the follow-up referencing since there
    is only one entry in the returned list.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用 `str_split()` 使用空格分割 `machine leaning workshop` 字符串，并使用 `unlist()`
    将结果从列表转换为向量。我们这样做是为了在后续引用中节省一些打字，因为返回的列表中只有一个条目。
- en: Now, we can repeat a similar step by extracting the first characters of `machine`
    and `learning` and combining them to form `ml`.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以通过提取 `machine` 和 `learning` 的第一个字符并将它们组合起来形成 `ml` 来重复类似的步骤。
- en: 'Form `ml` based on the previous outputs:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据前面的输出形成 `ml`：
- en: '[PRE44]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Now, we can combine all the worked components into one string.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以将所有处理过的组件组合成一个字符串。
- en: 'Use the previous outputs to form the final expected string:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面的输出形成最终的预期字符串：
- en: '[PRE45]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: In the next section, we will learn about more advanced pattern matching techniques
    that use regular expressions.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习更多使用正则表达式的先进模式匹配技术。
- en: Introducing regular expressions
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则表达式介绍
- en: A `rebus` package. It is a good companion to `stringr` and provides utility
    functions that facilitate string manipulation and make building regular expressions
    much easier. Remember to install this package via `install.package("rebus")` when
    you use it for the first time.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`rebus`包。它是`stringr`的一个好伴侣，提供了便于字符串操作和使构建正则表达式更加容易的实用函数。记住，当你第一次使用它时，通过`install.package("rebus")`安装此包。
- en: 'The `rebus` package has a special operator called `%R%` that’s used to concatenate
    matching conditions. For example, to detect whether a string starts with a particular
    character, such as `s`, we could specify the pattern as `START %R% "s"` and pass
    it to the pattern argument of the `str_detect()` function, where `START` is a
    special keyword that’s used to indicate the start of a string. Similarly, the
    `END` keyword indicates the end of a string. Together, they are called anchors
    in the `rebus` library. Let’s look at the following example:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`rebus`包有一个特殊的操作符`%R%`，用于连接匹配条件。例如，为了检测一个字符串是否以特定的字符开始，比如`s`，我们可以指定模式为`START
    %R% "s"`并将其传递给`str_detect()`函数的模式参数，其中`START`是一个特殊关键字，用于指示字符串的开始。同样，`END`关键字表示字符串的结束。它们一起在`rebus`库中被称为锚点。让我们看看以下示例：'
- en: '[PRE46]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We can also type `START` in the console. The result, which is a carat sign,
    is exactly the character used in vanilla regression expressions to indicate the
    start of a string:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以在控制台中输入`START`。结果是箭头符号，这正是vanilla正则表达式中用来指示字符串开始的字符：
- en: '[PRE47]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'In addition, `str_view()` is another useful function that visualizes the matched
    parts of a string. Running the following command will bring up an HTML viewer
    panel with the matched parts highlighted:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`str_view()`是另一个有用的函数，它可视化字符串的匹配部分。运行以下命令将弹出一个带有高亮显示匹配部分的HTML查看器面板：
- en: '[PRE48]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This is shown in *Figure 3**.1*:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这在*图3.1*中显示：
- en: '![Figure 3.1 – Visualizing the matching result in the viewer pane using str_view()](img/B18680_03_001.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – 使用str_view()在查看器面板中可视化匹配结果](img/B18680_03_001.jpg)'
- en: Figure 3.1 – Visualizing the matching result in the viewer pane using str_view()
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 使用str_view()在查看器面板中可视化匹配结果
- en: Let’s go through an exercise to learn more about the various pattern matching
    functions in rebus.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个练习来了解rebus中各种模式匹配函数的更多内容。
- en: Exercise 3.13 – applying regular expressions using rebus
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习3.13 – 使用rebus应用正则表达式
- en: 'In this exercise, we will apply different regular expressions to match the
    expected pattern in the strings:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将应用不同的正则表达式来匹配字符串中的预期模式：
- en: 'Run the following command to create a vector of strings. Note that the strings
    are designed to be simple but good enough to demonstrate the purpose of the matching
    functions we will introduce here:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令来创建一个字符串向量。注意，这些字符串设计得简单但足以展示我们将要介绍的匹配函数的目的：
- en: '[PRE49]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Search for a string from the vector that ends with `learning`:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索以`learning`结尾的向量中的字符串：
- en: '[PRE50]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Here, we used the `END` keyword in the `pattern` argument to indicate that the
    string should end with `learning`.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们在`pattern`参数中使用了`END`关键字来指示字符串应以`learning`结尾。
- en: 'Search for a string that contains any character followed by `101`:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索包含任何字符后跟`101`的字符串：
- en: '[PRE51]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Note that `ANY_CHAR` is a special keyword, a wildcard that indicates any single
    character and corresponds to a dot in normal regression expressions, as shown
    in the following code:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意`ANY_CHAR`是一个特殊关键字，是一个通配符，表示任何单个字符，在正常正则表达式中对应于点（.），如下面的代码所示：
- en: '[PRE52]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Since the pattern says any character followed by `101`, two strings have been
    selected due to the presence of `101`. `101 R workshop` has not been selected
    since there is no character before `101`.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于模式表示任何字符后跟`101`，因此由于存在`101`，选出了两个字符串。`101 R workshop`没有被选中，因为没有字符在`101`之前。
- en: 'Search for a string whose third character is `a`:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索第三个字符为`a`的字符串：
- en: '[PRE53]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Here, we specified the third character to be `a` by passing in two wildcard
    keywords at the beginning.
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们通过传递两个通配符关键字在开头来指定第三个字符为`a`。
- en: 'Search for a string that starts with `stats` or `R`:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索以`stats`或`R`开头的字符串：
- en: '[PRE54]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The `or()` function is useful when specifying more than one matching condition.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`or()`函数在指定多个匹配条件时很有用。'
- en: 'Search for a string that contains one or more `a` or `A` characters:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索包含一个或多个`a`或`A`字符的字符串：
- en: '[PRE55]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Two new functions were used here. The `char_class()` function enforces matching
    one and only one of the allowable characters specified in the input argument,
    while the `one_or_more()` function says that the pattern wrapped within the parentheses
    could be repeated more than once.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里使用了两个新函数。`char_class()` 函数强制匹配输入参数中指定的允许字符之一，而 `one_or_more()` 函数表示括号内包含的模式可以重复一次或多次。
- en: Next, we will cover the `tidytext` package, which allows us to conveniently
    work with unstructured textual data and the `tidyverse` ecosystem.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍 `tidytext` 包，它允许我们方便地处理非结构化文本数据和 `tidyverse` 生态系统。
- en: Working with tidy text mining
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用整洁文本进行挖掘
- en: The `tidytext` package handles unstructured text by following the tidy data
    principle, which mandates that data is represented as a structured, rectangular-shaped,
    and tibble-like object. In the case of text mining, this requires converting a
    piece of text in a single cell into one token per row in the DataFrame.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '`tidytext` 包通过遵循整洁数据原则来处理非结构化文本，该原则规定数据应以结构化、矩形形状和类似 tibble 的对象表示。在文本挖掘的情况下，这需要将单个单元格中的文本转换为
    DataFrame 中的每行一个标记。'
- en: Another commonly used representation for a collection of texts (called a **corpus**)
    is the **document-term matrix**, where each row represents one document (this
    could be a short sentence or a lengthy article) and each column represents one
    term (a unique word in the whole corpus, for example). Each cell in the matrix
    usually contains a representative statistic, such as frequency of occurrence,
    to indicate the number of times the term appears in the document.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一组文本（称为**语料库**）的另一种常用表示是**文档-词矩阵**，其中每一行代表一个文档（这可能是一句简短的句子或一篇长篇文章），每一列代表一个术语（整个语料库中唯一的单词，例如）。矩阵中的每个单元格通常包含一个代表性统计量，例如出现频率，以指示术语在文档中出现的次数。
- en: We will dive into both representations and look at how to convert between a
    document-term matrix and a tidy data format for text mining in the following sections.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将深入了解这两种表示，并探讨如何将文档-词矩阵转换为整洁数据格式以进行文本挖掘。
- en: Converting text into tidy data using unnest_tokens()
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 unnest_tokens() 将文本转换为整洁数据
- en: 'Let’s create a slightly different dummy dataset, as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个稍微不同的虚拟数据集，如下所示：
- en: '[PRE56]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The `texts` column in this dataset contains text of arbitrary length. Although
    it is stored as a tibble object, it is not quite suitable for tidy text analysis.
    For example, each row consists of multiple words in the `texts` column, making
    it challenging to derive statistical summaries such as the frequency of words.
    It would be much easier to get these statistics when each row corresponds to a
    single word for all the text.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集中，`texts` 列包含任意长度的文本。尽管它存储为 tibble 对象，但它并不非常适合整洁文本分析。例如，`texts` 列中的每一行都包含多个单词，这使得推导出诸如单词频率之类的统计总结变得具有挑战性。当每一行对应于所有文本的单个单词时，获取这些统计量会容易得多。
- en: Note that looking at word-level information is common in text mining, although
    we could extend to other variations such as pairs of words or even sentences.
    The unit of analysis used for text mining is called a `unnest_tokens()` function
    from the `tidytext` package. Remember to install and load this package if you
    have not done so.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在文本挖掘中查看单词级信息是常见的，尽管我们也可以扩展到其他变化，如单词对或甚至句子。用于文本挖掘的分析单位称为 `tidytext` 包中的 `unnest_tokens()`
    函数。如果你还没有这样做，请记住安装并加载此包。
- en: 'The `unnest_tokens()` function takes two inputs: the column used to host the
    resulting tokens from text, and the column whose text will be decomposed into
    tokens. There are also other aspects that the `unnest_tokens()` function takes
    care of when converting into a tidy text DataFrame. Let’s go through an exercise
    to learn more about this.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '`unnest_tokens()` 函数接受两个输入：用于存储结果标记的列，以及将文本分解为标记的列。此外，`unnest_tokens()` 函数在将数据转换为整洁文本
    DataFrame 时还处理其他方面。让我们通过一个练习来了解更多关于这个函数的信息。'
- en: Exercise 3.14 – building tidy text using unnest_tokens()
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.14 – 使用 unnest_tokens() 构建整洁文本
- en: 'In this exercise, we will use `unnest_tokens()` to build tidy text and extract
    word frequency:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用 `unnest_tokens()` 函数来构建整洁的文本并提取词频：
- en: 'Convert `texts_df` into tidy text format using `unnest_tokens()` and name the
    token-holding column `unit_token`. Store the result in `tidy_df`:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `unnest_tokens()` 将 `texts_df` 转换为整洁文本格式，并将包含标记的列命名为 `unit_token`。将结果存储在
    `tidy_df` 中：
- en: '[PRE57]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note that `unnest_tokens()` uses word-level tokenization by default; thus, the
    `unit_token` column contains all the word tokens extracted from respective texts,
    and each word occupies one row. Note that the `&` sign is removed from the result
    since `unnest_tokens()` removes all punctuation by default and converts all words
    into lowercase. The rest of the columns, such as `id`, are retained and duplicated
    for each word in the raw text string.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，`unnest_tokens()` 默认使用单词级别的标记化；因此，`unit_token` 列包含从相应文本中提取的所有单词标记，每个单词占一行。注意，由于
    `unnest_tokens()` 默认移除所有标点符号并将所有单词转换为小写，`&` 符号已从结果中移除。其余的列，如 `id`，被保留并复制为原始文本字符串中的每个单词。
- en: 'We can also use `texts_df` into tidy data using a bigram representation by
    specifying the token and *n* arguments:'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还可以通过指定 `token` 和 *n* 参数，使用双词（bigram）表示将 `texts_df` 转换为整洁数据：
- en: '[PRE58]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: We can see that the resulting tokens consist of each consecutive pair of words
    in the original text. Again, punctuation removal and lowercase conversion are
    performed under the hood.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到，生成的标记由原始文本中的每个连续单词对组成。同样，在底层执行了标点符号的移除和转换为小写。
- en: We can easily derive the word frequency distribution with the tidy data available.
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以轻松地从可用的整洁数据中推导出单词频率分布。
- en: 'Derive the word counts from `tidy_df`:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `tidy_df` 中推导单词计数：
- en: '[PRE59]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Here, we used the `count()` function to count the frequency of each unique
    word. We can also overlay this analysis with other `dplyr` operations, such as
    removing stop words (for example, `the` and `a`) from the word counts. Stop words
    are common words that do not convey additional meaning in text mining and are
    often removed from the corpus. We can inspect the list of English stop words using
    the `get_stopwords()` function, as follows:'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用了 `count()` 函数来计算每个唯一单词的频率。我们还可以通过其他 `dplyr` 操作来叠加此分析，例如从单词计数中移除停用词（例如，`the`
    和 `a`）。停用词是文本挖掘中不传达额外意义的常见单词，通常从语料库中移除。我们可以使用 `get_stopwords()` 函数检查英语停用词列表，如下所示：
- en: '[PRE60]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Derive the word frequency after removing the stop words. Store the result in
    `tidy_df2`:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除停用词后，推导单词频率。将结果存储在 `tidy_df2` 中：
- en: '[PRE61]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: We can see that `and` and `with` have been removed from the result.
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到，结果中已经移除了 `and` 和 `with`。
- en: Next, we will work with text in the form of a document-term matrix, which is
    the most commonly used format when building machine learning models using textual
    data.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将以文档-词矩阵的形式处理文本，这是在构建使用文本数据的机器学习模型时最常用的格式。
- en: Working with a document-term matrix
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理文档-词矩阵
- en: We can convert the tidy DataFrame from earlier to and from a document-term matrix.
    Since we used unigram (single-word) representation in the previous exercise, we
    will continue working with unigram word frequency and look at how to transform
    between tidy data and a document-term matrix, as shown in the following exercise.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将之前的整洁 DataFrame 转换为文档-词矩阵，也可以从文档-词矩阵转换回来。由于在前一个练习中我们使用了单词（unigram）表示，我们将继续使用单词频率，并查看如何在前面的练习中在整洁数据和文档-词矩阵之间进行转换。
- en: A commonly used package for text mining is `tm`. Remember to install and load
    this package before you continue with the following exercise.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的文本挖掘包是 `tm`。在继续进行以下练习之前，请记住安装并加载此包。
- en: Exercise 3.15 – converting to and from a document-term matrix
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3.15 – 转换为和从文档-词矩阵
- en: 'In this exercise, we will get the word frequency table in a tidy format, followed
    by converting the table into a sparse document-term matrix. A sparse matrix is
    a special data structure that contains the same amount of information but occupies
    much less memory space than a typical DataFrame. Lastly, we will look at converting
    a document-term matrix back into tidy format:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将以整洁格式获取单词频率表，然后将其转换为稀疏文档-词矩阵。稀疏矩阵是一种特殊的数据结构，它包含相同数量的信息，但比典型的 DataFrame
    占用更少的内存空间。最后，我们将查看如何将文档-词矩阵转换回整洁格式：
- en: 'Derive the word frequency count for each document and word token using `tidy_df`
    from the previous exercise. Save the result in `count_df`:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前一个练习中的 `tidy_df` 从每个文档和单词标记推导单词频率计数，并将结果保存到 `count_df` 中：
- en: '[PRE62]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Here, `r` appears twice in the fourth document, and all other words appear once.
    We will convert it into a document-term matrix format.
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，第四个文档中 `r` 出现了两次，其他所有单词都只出现一次。我们将将其转换为文档-词矩阵格式。
- en: 'Convert `count_df` into a document-term matrix by using the `cast_dtm()` function
    from the `tm` package and store the result in `dtm`:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tm` 包中的 `cast_dtm()` 函数将 `count_df` 转换为文档-词矩阵，并将结果存储在 `dtm` 中：
- en: '[PRE63]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: The result shows that we have a total of four documents and 10 terms. The sparsity
    is as high as 70% since most words appear only in their respective document. Also,
    the statistic used to represent a word in a document is the term frequency.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示，我们总共有四篇文档和10个术语。稀疏度高达70%，因为大多数单词只出现在各自的文档中。此外，表示文档中单词的统计量是词频。
- en: 'We can also look at the whole table by specifically converting it into a normal
    matrix:'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还可以通过将其特别转换为普通矩阵来查看整个表格：
- en: '[PRE64]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now, we have the canonical document-term matrix. Note that we can use other
    statistics, such as `tf-idf`, to represent each cell in the matrix, or even use
    a vector of multiple numeric values to represent each word in a document. The
    latter is referred to as `dtm` back into tidy format:'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们有了标准的文档-词矩阵。请注意，我们可以使用其他统计方法，例如`tf-idf`，来表示矩阵中的每个单元格，或者甚至使用多个数值的向量来表示文档中的每个单词。后者被称为将`dtm`转换回整洁格式：
- en: '[PRE65]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Now, we have the same tidy data as before.
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们拥有与之前相同的数据整洁格式。
- en: Summary
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we touched upon several intermediate data processing techniques,
    ranging from structured tabular data to unstructured textual data. First, we covered
    how to transform categorical and numeric variables, including recoding categorical
    variables using `recode()`, creating new variables using `case_when()`, and binning
    numeric variables using `cut()`. Next, we looked at reshaping a DataFrame, including
    converting a long-format DataFrame into a wide format using `spread()` and back
    again using `gather()`. We also delved into working with strings, including how
    to create, convert, and format string data.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了几种中间数据处理技术，从结构化表格数据到非结构化文本数据。首先，我们介绍了如何转换分类和数值变量，包括使用`recode()`重新编码分类变量，使用`case_when()`创建新变量，以及使用`cut()`对数值变量进行分箱。接下来，我们探讨了如何重塑DataFrame，包括使用`spread()`将长格式DataFrame转换为宽格式，以及使用`gather()`反向转换。我们还深入探讨了字符串的处理，包括如何创建、转换和格式化字符串数据。
- en: In addition, we covered some essential knowledge regarding the `stringr` package,
    which provides many helpful utility functions to ease string processing tasks.
    Common functions include `str_c()`, `str_sub()`, `str_subset()`, `str_detect()`,
    `str_split()`, `str_count()`, and `str_replace()`. These functions can be combined
    to create a powerful and easy-to-understand string processing pipeline.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还介绍了有关`stringr`包的一些基本知识，该包提供了许多有用的实用函数，以简化字符串处理任务。常见的函数包括`str_c()`、`str_sub()`、`str_subset()`、`str_detect()`、`str_split()`、`str_count()`和`str_replace()`。这些函数可以组合起来创建一个强大且易于理解的字符串处理管道。
- en: Then, we introduced regular expressions using the `rebus` package, which provides
    convenient pattern matching functionalities that work well with `stringr`. Its
    functions and keywords are easy to read, and they include `START`, `END`, `ANY_CHAR`,
    `or()`, `one_or_more()`, and others.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们介绍了使用`rebus`包的正则表达式，该包提供了与`stringr`配合良好的便利模式匹配功能。其函数和关键字易于阅读，包括`START`、`END`、`ANY_CHAR`、`or()`、`one_or_more()`等。
- en: Lastly, we covered working with tidy text data using the `tidytext` package.
    Converting a set of textual data into a tidy format makes it easy to leverage
    the many utility functions from the `tidyverse` ecosystem. The `unnest_tokens()`
    function is often used to tidy up raw texts, and the tidy output can also be converted
    to and from a document-term matrix, the standard data structure used to develop
    machine learning models.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍了使用`tidytext`包处理整洁文本数据。将一组文本数据转换为整洁格式，可以轻松利用`tidyverse`生态系统中的许多实用函数。`unnest_tokens()`函数通常用于整理原始文本，整洁的输出也可以转换为文档-词矩阵，这是开发机器学习模型的标准数据结构。
- en: Text mining is a big topic, and we only covered the very basics in this chapter.
    Hopefully, the basic flavors presented here will encourage you to further explore
    the potential functionalities provided by the `tidyverse` ecosystem.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 文本挖掘是一个很大的主题，我们在这章中只介绍了最基本的内容。希望这里展示的基本内容能够鼓励你进一步探索`tidyverse`生态系统提供的潜在功能。
- en: In the next chapter, we will switch gears and cover data visualization, taking
    what we have processed and converting them into visual and actionable insights.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将转换方向，介绍数据可视化，将我们处理过的数据转换为可视和可操作的见解。
