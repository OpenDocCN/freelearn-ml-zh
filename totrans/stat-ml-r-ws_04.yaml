- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Intermediate Data Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter covered a suite of commonly used functions offered by `dplyr`
    for data processing. For example, when characterizing and extracting the statistics
    of a dataset, we can follow the split-apply-combine procedure using `group_by()`
    and `summarize()`. This chapter continues from the previous one and focuses on
    intermediate data processing techniques, including transforming categorical and
    numeric variables and reshaping DataFrames. Besides that, we will also introduce
    string manipulation techniques for working with textual data, whose format is
    fundamentally different from the neatly shaped tables we have been working with
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to perform more advanced data manipulation
    and extend your data massaging skills to string-based texts, which are fundamental
    to the field of natural language processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Transforming categorical and numeric variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reshaping the DataFrame
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating string data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with `stringr`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing regular expressions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with tidy text mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete the exercises in this chapter, you will need to have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of the `rebus` package, which is 0.1-3 at the time of writing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of the `tidytext` package, which is 0.3.2 at the time of
    writing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of the `tm` package, which is 0.7-8 at the time of writing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code and data for this chapter is available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/tree/main/Chapter_3](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/tree/main/Chapter_3).
  prefs: []
  type: TYPE_NORMAL
- en: Transforming categorical and numeric variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As covered in the previous chapter, we can use the `mutate()` function from
    `dplyr` to transform existing variables and create new ones. The specific transformation
    depends on the type of the variable and the resulting shape we would like it to
    be. For example, we may want to change the value of a categorical variable according
    to a mapping dictionary, create a new variable based on a combination of filtering
    conditions of existing variables, or group a numeric variable into different ranges
    in a new variable. Let us look at these scenarios in turn.
  prefs: []
  type: TYPE_NORMAL
- en: Recoding categorical variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many cases when you would want to recode the values of a variable,
    such as mapping countries’ short names to the corresponding full names. Let’s
    create a dummy `tibble` dataset to illustrate this.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we have created a `students` variable that stores information
    on age, country, gender, and height. This is a small dummy dataset but it’s good
    enough for demonstration purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s go through an example of converting the values of the `country` variable
    into their full names.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.1 – converting the country variable values into their full names
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This exercise will use the `recode()` function from the `dplyr` package to
    map the existing short country names to the corresponding full names:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a new column that converts the short country names into the corresponding
    full names by providing a mapping table using `recode()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we provided a mapping dictionary as an argument in the `recode()` function,
    which searches for the keys in the left column and assigns the corresponding values
    in the right column to `country_fullname`. Note that the newly created column
    assumes a character type.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform the same conversion and store the result as a `factor` type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that the resulting variable, `country_fullname2`, is a factor by
    using `recode_factor()`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When the new column we want to create depends on a complex combination of existing
    ones, we can resort to the `case_when()` function, as introduced in the following
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating variables using case_when()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `case_when()` function provides a convenient way to set multiple `if-else`
    conditions when creating a new variable. It takes a sequence of two-sided formulas,
    where the left-hand side contains the filtering conditions and the right-hand
    side provides the replacement value that matches the preceding conditions. The
    syntax inside the function follows a `logical condition(s) ~ replacement value`
    pattern that gets evaluated sequentially, where multiple variables can be used
    inside the logical conditioning. At the end of the sequence is a `TRUE ~ default
    value` case that gets assigned to the variable if all preceding conditions evaluate
    to `FALSE`.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go through an exercise to create a new variable based on multiple `if-else`
    conditions involving multiple columns.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.2 – creating a new variable using multiple conditions and columns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will create a new variable that indicates the age and region
    of the students.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new variable type to identify whether the students come from Asia
    and are in their 20s or 30s by assuming `asia_20+` and `asia_30+` as values, respectively.
    Set the value to `others` if there is no match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, we used the `&` sign to combine multiple `AND` conditions that evaluate
    `age` and `country`. When neither of the preceding conditions in the sequence
    evaluate to `TRUE`, the function will fall into the all-encompassing `TRUE` case
    and assign `others` as the default value.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at converting a numeric column into different bins/categories.
  prefs: []
  type: TYPE_NORMAL
- en: Binning numeric variables using cut()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A numeric column can be partitioned into different categories using the `cut()`
    function. For a numeric column, it assigns the value to the corresponding predefined
    intervals and codes the value based on the assigned interval. The resulting column
    of intervals assumes an ordered factor type.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cut()` function has three key arguments: `x` to accept a numeric vector
    to be binned, `breaks` to accept a numeric vector of cut points, which could include
    negative infinity, `–Inf`, and positive infinity, `Inf`, and `labels` to indicate
    the labels of the resulting intervals.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go through an exercise using `cut()` to convert the `age` column into
    different age groups.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.3 – binning the age column into three groups
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `cut()` function to assign the value of the
    `age` column to one of the following ranges: `(-infinity, 25)`, `[26, 30]`, or
    `[``31, infinity]`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Segment the `age` column into three intervals with breakpoints at `25` and
    `30` (inclusive on the right) and store them in a new column named `age_group`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we can see that `age_group` is an ordered factor with three levels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A few cutting functions perform automatic binning when we do not have a specific
    cutoff point in mind. For example, `cut_interval()` cuts the original vector into
    a specified number of groups with equal intervals, while `cut_number()` converts
    the input vector into a specific number of groups, where each group has approximately
    the same number of observations. The `tidyverse` package provides both functions.
    Let’s try them out.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Group the `age` column into three bins of equal length using `cut_interval()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `age_group` column now consists of three levels that represent equal-length
    intervals. Let’s check out the counts of each level using the `summary()` function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Group the `age` column into three bins of an equal number of observations using
    `cut_interval()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The cutoff points are now assuming decimal points to make the resulting count
    of observations approximately equal, as verified in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So far, we have looked at different ways to transform an existing categorical
    or numeric variable and create a new variable based on specific conditions. Next,
    we will look at how to transform and reshape the whole DataFrame to facilitate
    our analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Reshaping the DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A DataFrame that consists of a combination of categorical and numeric columns
    can be expressed in both wide and long formats. For example, the `students` DataFrame
    is considered a long format since all countries are stored in the `country` column.
    Depending on the specific purpose of processing, we may want to create a separate
    column for each unique country in the dataset, which adds more columns to the
    DataFrame and converts it into a wide format.
  prefs: []
  type: TYPE_NORMAL
- en: Converting between wide and long formats can be achieved via the `spread()`
    and `gather()` functions, both of which are provided by the `tidyr` package from
    the `tidyverse` ecosystem. Let’s see how it works in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Converting from long format into wide format using spread()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There will be times when we’ll want to turn a long-formatted DataFrame into
    a wide format. The `spread()` function can be used to convert a categorical column
    with multiple categories into multiple columns, as specified by the `key` argument,
    with each category added to the DataFrame as a separate column. The column names
    will be the unique values of the categorical column. The `value` argument specifies
    the contents to be spread and filled in these additional columns upon calling
    the `spread()` function. Let’s go through an exercise on this.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.4 – converting from long format into wide format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will convert the `students` DataFrame into a wide format
    using `spread()`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `country` as the `key` argument and `height` as the `value` argument to
    convert students into a wide format using `spread()`. Store the resulting DataFrame
    in `students_wide`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that the original `height` column disappears, and four additional
    columns are added. These four columns correspond to the unique countries, and
    the values of these columns are filled in by the heights. If the corresponding
    height for a particular country is not available, `NA` is used to fill in the
    missing combination.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If we want to specify a default value for these `NA` values, we can set the
    `fill` argument in `spread()`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the rounded average height to fill the `NA` values in the resulting wide
    format. Store the resulting DataFrame in `students_wide2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Converting from long into wide could be helpful from an analysis and presentational
    perspective since we can visually compare the heights across all countries for
    a specific combination of age and gender. However, this comes with additional
    storage costs, as shown by the multiple `NA` values earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s learn how to convert a wide-formatted DataFrame into a long format.
  prefs: []
  type: TYPE_NORMAL
- en: Converting from wide format into long format using gather()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we are in the opposite situation, where the given data is in a wide format,
    we can use the `gather()` function to convert it into a long format for more convenient
    follow-up processing. For example, by compressing the four country columns into
    the `key` variable and storing all heights under the `value` variable specified
    in `gather()`, we can continue with the usual split-apply-combine treatments we
    introduced earlier based on just two columns instead of four or more.
  prefs: []
  type: TYPE_NORMAL
- en: The `gather()` function also uses the `key` and `value` arguments to specify
    the name of the resulting `key` and `value` columns in the long-formatted table.
    Besides, we need to specify the columns whose names are used to fill in the `key`
    column and the values in the `value` column. When there are many adjacent columns
    to specify, we can use the `:` operator by passing the starting and ending column
    names to select all columns in between. Let’s go through a practice exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.5 – converting from wide format into long format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This exercise will convert the wide-formatted `students_wide` DataFrame back
    into its original long format:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert `students_wide` into a long format by specifying the `key` column as
    `country` and the `value` column as `height`, and using the values of the `CN`,
    `IN`, `SG`, and `UK` columns to fill in the `key` and `value` columns, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that several rows with missing values in the `height` column have
    been added to `students_long`. This is because of their original presence in `students_wide`.
    Let’s remove them using the `drop_na()` function from `dplyr`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Remove the rows with `NA` values in the `height` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With that, we have obtained the long-formatted DataFrame. Now, let’s verify
    whether it is the same as the original `students` DataFrame.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify whether `students_long` is the same as `students` using `all_equal()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `all_equal()` function from `dplyr` compares two datasets and checks whether
    they are identical. It provides a flexible way to carry out an equality comparison
    and supports ignoring the ordering of rows and/or columns. The result shows that
    we have successfully converted back into the original dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With that, we have looked at different ways to reshape the DataFrame. Next,
    we will cover how to deal with string data.
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating string data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Character-typed strings are standard in real-life data, such as name and address.
    Analyzing string data requires properly cleaning the raw characters and converting
    the information embedded in a blob of textual data into a quantifiable numeric
    summary. For example, we may want to find the matching names of all students that
    follow a specific pattern.
  prefs: []
  type: TYPE_NORMAL
- en: This section will cover different ways to define patterns via regular expressions
    to detect, split, and extract string data. Let’s start with the basics of strings.
  prefs: []
  type: TYPE_NORMAL
- en: Creating strings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A `""`). Sometimes, a single quote (`'`) is also used to denote a string, although
    it is generally recommended to use double quotes unless the characters themselves
    include double quotes.
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to create a string. The following exercise introduces
    a few different ways to initialize a character-typed string.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.6 – expressing strings in R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will look at creating strings in R:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Try to type out the following strings in the R console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The strings are printed without error. Let’s see what happens if we wrap `statistics`
    with double quotes to highlight this word.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add double quotes to `statistics` in the string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This time, an error pops up because R takes the second double quote as the ending
    quote of the string. This error can be avoided by switching to using single quotes
    for the outside quotes when double quotes are used in a string.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Wrap the previous string with single quotes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, R interprets the string correctly and considers all content within the
    pair of single quotes as a whole string. Note that the resulting string is still
    printed with double quotes in the console. The two double quotes within the string
    are also preceded by a backward slash (`\`). This is called an escape sequence
    and is used to indicate the literal interpretation of the double quotes as characters
    instead of the start of a string. The escape sequence is a useful way to include
    special characters in a string.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also manually add the escape character inside the string to enforce the
    correct interpretation, which will print out the same result as before.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add the escape sequence before the double quotes inside the string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Printing out the string sequence with a backslash is not convenient for reading.
    To beautify the output, we can pass the exact string to the `writeLines()` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the same string using `writeLines()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we will look at how to turn numbers into strings for better interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: Converting numbers into strings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we learned earlier, numbers can be converted into strings via the `as.character()`
    function. However, it would be inconvenient to directly read and report a big
    number such as `123000`. We would usually express it in a more readable manner
    such as 123,000 or a more concise way such as 1.23e+05, where the latter follows
    the scientific representation with e+05 equal to 105\. Additionally, we may want
    to display a limited number of digits after the decimal point for a floating number.
  prefs: []
  type: TYPE_NORMAL
- en: All of these can be achieved via the `format()` function, which is useful when
    converting and printing numbers as strings while following different formats.
    Let’s see how this is done in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.7 – converting numbers into strings using format()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This exercise will use `format()` to convert numbers into pretty and easily
    readable strings:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a comma as a thousands separator to `123000` by specifying the `big.mark`
    argument in `format()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that the result is now a character-type string with a comma added.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Convert `123000` into scientific format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using scientific format is a concise way to represent large numbers. We can
    also shorten a long floating number by specifying the number of digits to display.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Display only three digits of `1.256` by specifying the `digits` argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result is rounded and converted into a string, displaying only three digits
    as specified. We can also achieve the same rounding effect using `round()`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Round `1.256` to two decimal points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This time, the result is still numeric since `round()` does not involve type
    conversion.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the next section, we will look at connecting multiple strings.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting strings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When there are multiple strings, we can use `paste()` to connect and join them
    into a single string. This becomes important if we want to print long and customized
    messages in our program instead of relying on manually typing them out.
  prefs: []
  type: TYPE_NORMAL
- en: The `paste()` function takes an arbitrary number of string inputs as arguments
    and combines them into one. Let’s see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.8 – combining strings using paste()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will look at different ways to combine multiple string
    inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect the `statistics` and `workshop` strings to generate `statistics workshop`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we can see that a space is automatically added between the two strings.
    This is controlled by the `sep` argument, which specifies the filling content
    between strings and assumes a default value of a space. We can choose to override
    the default behavior by passing a separating character to this argument.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Remove the space in between and generate `statisticsworkshop`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Connect a vector of `statistics` and `workshop` with `course`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result shows that `course` is added to each element in the vector. This
    is completed via the recycling operation under the hood, where `course` is recycled
    so that it can be combined with each string in the vector. This is similar to
    the broadcasting mechanism in Python.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also remove the vector structure and combine all elements into a single
    string by specifying the `collapse` argument.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compress the previous output into a single string separated by `+`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After plugging in all the components of the combined vector and separating them
    by the specified argument, the result is a single collapsed string.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So far, we have learned the basics when it comes to working with string data.
    The `stringr` package provided by the `tidyverse` ecosystem provides many handy
    functions if we want to have more flexible control of our strings. This will be
    covered in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Working with stringr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `stringr` package provides a cohesive set of functions that all start with
    `str_` and are designed to make working with strings as easy as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with the basic functions of `stringr` by replicating the same results
    from the previous exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Basics of stringr
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `str_c()` function from the `stringr` package can concatenate multiple strings
    with similar functionalities as in `paste()`. Let’s see its use in action.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.9 – combining strings using paste()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will reproduce the same as what we did in *Exercise 3.8*
    using `str_c()`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Concatenate `statistics` with `workshop` with a separating space in between:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can use the `sep` argument to specify the separator between strings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Combine a vector of `statistics` and `workshop` with `course`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The same recycling behavior also appears here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compress the preceding output into a single string separated by `+`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There are two other common `stringr` functions: `str_length()`, which returns
    the length of the string, and `str_sub()`, which subtracts parts of the string:'
  prefs: []
  type: TYPE_NORMAL
- en: For example, we can get the length of each string in a vector, as shown in the
    following code snippet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Alternatively, we can use the `nchar()` function from base R to achieve the
    same result, as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also use `str_sub()` to extract parts of the string by providing a starting
    and ending index:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Extracting parts of a string is one way to look for patterns in the string.
    In the next section, we will cover a more advanced approach for pattern matching
    beyond positional indexing.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern matching in a string
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Matching patterns in a string is a common way to extract intelligence from textual
    data. When a match is found, we could split or replace the string based on the
    match, add additional data such as the number of matches, or perform other text-based
    analyses. Let’s go through a few exercises to get familiar with string matches.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.10 – locating matches in a string
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will cover three functions that are commonly used in locating
    a match in a string, including detecting a match using `str_detect()`, selecting
    the strings of a vector that have a match using `str_subset()`, and counting the
    number of matches in a string using `str_count()`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Detect the occurrence of `stat` in a vector of strings containing `statistics`
    and `workshop`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `str_detect()` function looks for a specified pattern in the input strings
    and returns a logical vector of the same length as the input vector, with `TRUE`
    indicating a match and `FALSE` otherwise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Subset the string that contains `stat`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `str_subset()` function completes detection and selection in one shot. It
    will return only the strings that match the specified pattern.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Count the occurrence of `t` in each string of the previous vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `str_count()` function returns an integer vector of the same length as the
    input vector and shows each string’s frequency of a particular match.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, we will look at how to split a string based on a particular match.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting a string
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Splitting a string based on a specific pattern can be achieved via the `str_split()`
    function, which assumes a similar naming and argument setting as in previous functions.
    The original string could then be decomposed into smaller pieces to support a
    more refined analysis. Let’s see how it can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.11 – splitting a string using str_split()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This exercise will use `str_split()` to decompose a string into smaller pieces
    based on a specific matching condition:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Separate the `statistics & machine learning workshop` string at the `&` sign:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result is a single-entry list that contains a vector of two elements in
    the first entry. Note that both the resulting substrings have a space inside,
    showing that the an exact pattern match is used to split the string. We could
    then include the space in the matching pattern to remove the spaces in the resulting
    substrings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Include preceding and trailing spaces in the matching pattern:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With that, the spaces in the substrings have been removed. As shown in the following
    code snippet, since the result is wrapped in a list, we can follow the list indexing
    rule to access the corresponding element.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Access the second element from the previous result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we will look at replacing a matched pattern in a string.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing a string
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `str_replace()` and `str_replace_all()` functions replace the matches with
    new text specified by the `replacement` argument. The difference is that `str_replace()`
    only replaces the first match, while `str_replace_all()` replaces all matches
    as its name suggests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try replacing the `&` sign with `and` using both functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that all `&` signs are replaced by `and` in the second string. Again,
    replacing a particular match involves a two-step process: locating the match,
    if any, and performing the replacement. The `str_replace()` and `str_replace_all()`
    functions complete both steps in one shot.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will go through a bit of a challenge that requires combining
    these `stringr` functions.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Often, a particular string processing task involves using more than one `stringr`
    function. Together, these functions could deliver useful transformations to the
    textual data. Let’s go through an exercise that puts together what we have covered
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.12 – converting strings using multiple functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use different string-based functions to convert `statistics
    and machine leaning workshop` into `stats & ml workshop`. First, we will replace
    `and` with the `&` sign, split the string, and work with the individual pieces.
    Let’s see how this can be achieved:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `title` variable to hold the string and replace `and` with `&`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used `str_replace()` to replace `and` with `&`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Split `title` into substrings using `&`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used `str_split()` to split the original string into smaller substrings.
    Note that additional spaces are added to the matching pattern as well. We will
    work with these individual pieces now.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Convert `statistics` into `stats`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we extracted the first four characters, namely `stat`, and the last character,
    `s`, using `str_sub()`, then concatenated them using `str_c()`. Note that `-1`
    indicates the last positional indexing of a string.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, we can start to work on the second part.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Split the second element of the `a` variable with a space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used `str_split()` to split the `machine leaning workshop` string with
    a space and converted the result from a list into a vector using `unlist()`. We
    did this conversion to save some typing in the follow-up referencing since there
    is only one entry in the returned list.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, we can repeat a similar step by extracting the first characters of `machine`
    and `learning` and combining them to form `ml`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Form `ml` based on the previous outputs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we can combine all the worked components into one string.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the previous outputs to form the final expected string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the next section, we will learn about more advanced pattern matching techniques
    that use regular expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing regular expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A `rebus` package. It is a good companion to `stringr` and provides utility
    functions that facilitate string manipulation and make building regular expressions
    much easier. Remember to install this package via `install.package("rebus")` when
    you use it for the first time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `rebus` package has a special operator called `%R%` that’s used to concatenate
    matching conditions. For example, to detect whether a string starts with a particular
    character, such as `s`, we could specify the pattern as `START %R% "s"` and pass
    it to the pattern argument of the `str_detect()` function, where `START` is a
    special keyword that’s used to indicate the start of a string. Similarly, the
    `END` keyword indicates the end of a string. Together, they are called anchors
    in the `rebus` library. Let’s look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also type `START` in the console. The result, which is a carat sign,
    is exactly the character used in vanilla regression expressions to indicate the
    start of a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, `str_view()` is another useful function that visualizes the matched
    parts of a string. Running the following command will bring up an HTML viewer
    panel with the matched parts highlighted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This is shown in *Figure 3**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Visualizing the matching result in the viewer pane using str_view()](img/B18680_03_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – Visualizing the matching result in the viewer pane using str_view()
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go through an exercise to learn more about the various pattern matching
    functions in rebus.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.13 – applying regular expressions using rebus
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will apply different regular expressions to match the
    expected pattern in the strings:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to create a vector of strings. Note that the strings
    are designed to be simple but good enough to demonstrate the purpose of the matching
    functions we will introduce here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Search for a string from the vector that ends with `learning`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used the `END` keyword in the `pattern` argument to indicate that the
    string should end with `learning`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Search for a string that contains any character followed by `101`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Note that `ANY_CHAR` is a special keyword, a wildcard that indicates any single
    character and corresponds to a dot in normal regression expressions, as shown
    in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Since the pattern says any character followed by `101`, two strings have been
    selected due to the presence of `101`. `101 R workshop` has not been selected
    since there is no character before `101`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Search for a string whose third character is `a`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we specified the third character to be `a` by passing in two wildcard
    keywords at the beginning.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Search for a string that starts with `stats` or `R`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `or()` function is useful when specifying more than one matching condition.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Search for a string that contains one or more `a` or `A` characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Two new functions were used here. The `char_class()` function enforces matching
    one and only one of the allowable characters specified in the input argument,
    while the `one_or_more()` function says that the pattern wrapped within the parentheses
    could be repeated more than once.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, we will cover the `tidytext` package, which allows us to conveniently
    work with unstructured textual data and the `tidyverse` ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Working with tidy text mining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `tidytext` package handles unstructured text by following the tidy data
    principle, which mandates that data is represented as a structured, rectangular-shaped,
    and tibble-like object. In the case of text mining, this requires converting a
    piece of text in a single cell into one token per row in the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Another commonly used representation for a collection of texts (called a **corpus**)
    is the **document-term matrix**, where each row represents one document (this
    could be a short sentence or a lengthy article) and each column represents one
    term (a unique word in the whole corpus, for example). Each cell in the matrix
    usually contains a representative statistic, such as frequency of occurrence,
    to indicate the number of times the term appears in the document.
  prefs: []
  type: TYPE_NORMAL
- en: We will dive into both representations and look at how to convert between a
    document-term matrix and a tidy data format for text mining in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Converting text into tidy data using unnest_tokens()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s create a slightly different dummy dataset, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The `texts` column in this dataset contains text of arbitrary length. Although
    it is stored as a tibble object, it is not quite suitable for tidy text analysis.
    For example, each row consists of multiple words in the `texts` column, making
    it challenging to derive statistical summaries such as the frequency of words.
    It would be much easier to get these statistics when each row corresponds to a
    single word for all the text.
  prefs: []
  type: TYPE_NORMAL
- en: Note that looking at word-level information is common in text mining, although
    we could extend to other variations such as pairs of words or even sentences.
    The unit of analysis used for text mining is called a `unnest_tokens()` function
    from the `tidytext` package. Remember to install and load this package if you
    have not done so.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `unnest_tokens()` function takes two inputs: the column used to host the
    resulting tokens from text, and the column whose text will be decomposed into
    tokens. There are also other aspects that the `unnest_tokens()` function takes
    care of when converting into a tidy text DataFrame. Let’s go through an exercise
    to learn more about this.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.14 – building tidy text using unnest_tokens()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use `unnest_tokens()` to build tidy text and extract
    word frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert `texts_df` into tidy text format using `unnest_tokens()` and name the
    token-holding column `unit_token`. Store the result in `tidy_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that `unnest_tokens()` uses word-level tokenization by default; thus, the
    `unit_token` column contains all the word tokens extracted from respective texts,
    and each word occupies one row. Note that the `&` sign is removed from the result
    since `unnest_tokens()` removes all punctuation by default and converts all words
    into lowercase. The rest of the columns, such as `id`, are retained and duplicated
    for each word in the raw text string.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can also use `texts_df` into tidy data using a bigram representation by
    specifying the token and *n* arguments:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that the resulting tokens consist of each consecutive pair of words
    in the original text. Again, punctuation removal and lowercase conversion are
    performed under the hood.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can easily derive the word frequency distribution with the tidy data available.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Derive the word counts from `tidy_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we used the `count()` function to count the frequency of each unique
    word. We can also overlay this analysis with other `dplyr` operations, such as
    removing stop words (for example, `the` and `a`) from the word counts. Stop words
    are common words that do not convey additional meaning in text mining and are
    often removed from the corpus. We can inspect the list of English stop words using
    the `get_stopwords()` function, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Derive the word frequency after removing the stop words. Store the result in
    `tidy_df2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that `and` and `with` have been removed from the result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, we will work with text in the form of a document-term matrix, which is
    the most commonly used format when building machine learning models using textual
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Working with a document-term matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can convert the tidy DataFrame from earlier to and from a document-term matrix.
    Since we used unigram (single-word) representation in the previous exercise, we
    will continue working with unigram word frequency and look at how to transform
    between tidy data and a document-term matrix, as shown in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: A commonly used package for text mining is `tm`. Remember to install and load
    this package before you continue with the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.15 – converting to and from a document-term matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will get the word frequency table in a tidy format, followed
    by converting the table into a sparse document-term matrix. A sparse matrix is
    a special data structure that contains the same amount of information but occupies
    much less memory space than a typical DataFrame. Lastly, we will look at converting
    a document-term matrix back into tidy format:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Derive the word frequency count for each document and word token using `tidy_df`
    from the previous exercise. Save the result in `count_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, `r` appears twice in the fourth document, and all other words appear once.
    We will convert it into a document-term matrix format.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Convert `count_df` into a document-term matrix by using the `cast_dtm()` function
    from the `tm` package and store the result in `dtm`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result shows that we have a total of four documents and 10 terms. The sparsity
    is as high as 70% since most words appear only in their respective document. Also,
    the statistic used to represent a word in a document is the term frequency.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can also look at the whole table by specifically converting it into a normal
    matrix:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we have the canonical document-term matrix. Note that we can use other
    statistics, such as `tf-idf`, to represent each cell in the matrix, or even use
    a vector of multiple numeric values to represent each word in a document. The
    latter is referred to as `dtm` back into tidy format:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we have the same tidy data as before.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we touched upon several intermediate data processing techniques,
    ranging from structured tabular data to unstructured textual data. First, we covered
    how to transform categorical and numeric variables, including recoding categorical
    variables using `recode()`, creating new variables using `case_when()`, and binning
    numeric variables using `cut()`. Next, we looked at reshaping a DataFrame, including
    converting a long-format DataFrame into a wide format using `spread()` and back
    again using `gather()`. We also delved into working with strings, including how
    to create, convert, and format string data.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we covered some essential knowledge regarding the `stringr` package,
    which provides many helpful utility functions to ease string processing tasks.
    Common functions include `str_c()`, `str_sub()`, `str_subset()`, `str_detect()`,
    `str_split()`, `str_count()`, and `str_replace()`. These functions can be combined
    to create a powerful and easy-to-understand string processing pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we introduced regular expressions using the `rebus` package, which provides
    convenient pattern matching functionalities that work well with `stringr`. Its
    functions and keywords are easy to read, and they include `START`, `END`, `ANY_CHAR`,
    `or()`, `one_or_more()`, and others.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we covered working with tidy text data using the `tidytext` package.
    Converting a set of textual data into a tidy format makes it easy to leverage
    the many utility functions from the `tidyverse` ecosystem. The `unnest_tokens()`
    function is often used to tidy up raw texts, and the tidy output can also be converted
    to and from a document-term matrix, the standard data structure used to develop
    machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Text mining is a big topic, and we only covered the very basics in this chapter.
    Hopefully, the basic flavors presented here will encourage you to further explore
    the potential functionalities provided by the `tidyverse` ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will switch gears and cover data visualization, taking
    what we have processed and converting them into visual and actionable insights.
  prefs: []
  type: TYPE_NORMAL
