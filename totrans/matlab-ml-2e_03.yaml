- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Prediction Using Classification and Regression
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用分类和回归进行预测
- en: Classification algorithms return accurate predictions based on our observations.
    Starting from a set of predefined class labels, the classifier assigns each piece
    of input data a class label according to the training model. Classification algorithms
    learn linear or non-linear associations between independent and categorical dependent
    variables. For example, a classification algorithm may learn to predict the weather
    as clear sky, gentle showers or heavy rain, and so on. Regression relates a set
    of independent variables to a dependent variable, numeric or continuous, for example,
    predicting rainfall in units of millimeters. Through this technique, it is possible
    to understand how the value of the dependent variable changes as the independent
    variable varies. This chapter shows us how to classify an object using nearest
    neighbors and how to perform an accurate regression analysis in a MATLAB environment.
    The aim of this chapter is to provide you with an introduction, background information,
    and a basic knowledge of classification and regression techniques and how to perform
    them in MATLAB.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 分类算法基于我们的观察返回准确的预测。从一组预定义的类别标签开始，分类器根据训练模型将每个输入数据分配一个类别标签。分类算法学习独立变量和分类依赖变量之间的线性或非线性关联。例如，一个分类算法可能学会预测天气为晴朗的天空、轻柔的阵雨或大雨等。回归将一组独立变量与一个依赖变量（数值或连续）相关联，例如，预测降雨量（以毫米为单位）。通过这种技术，我们可以了解依赖变量的值如何随着独立变量的变化而变化。本章将向我们展示如何使用最近邻方法对对象进行分类，以及如何在MATLAB环境中进行准确的回归分析。本章的目标是为你提供分类和回归技术的基本介绍、背景信息以及如何在MATLAB中执行这些技术的基本知识。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Introducing classification methods using MATLAB
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MATLAB介绍分类方法
- en: Building an effective and accurate classifier
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个有效且准确的分类器
- en: Exploring different types of regression
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索不同的回归类型
- en: Making predictions with regression analysis in MATLAB
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在MATLAB中使用回归分析进行预测
- en: Evaluating model performance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: Using advanced techniques for model evaluation and selection in MATLAB
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在MATLAB中使用高级技术进行模型评估和选择
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will introduce basic concepts relating to machine learning.
    To understand these topics, a basic knowledge of algebra and mathematical modeling
    is needed. A working knowledge of the MATLAB environment is also required.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍与机器学习相关的基本概念。为了理解这些主题，需要具备代数和数学建模的基本知识。同时，也需要对MATLAB环境有实际操作的了解。
- en: 'To work with the MATLAB code in this chapter, you need the following files
    (available on GitHub at [https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用本章中的MATLAB代码，你需要以下文件（可在GitHub上找到，网址为[https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)）：
- en: '`datatraining.txt`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datatraining.txt`'
- en: '`VehiclesItaly.xlsx`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VehiclesItaly.xlsx`'
- en: '`Employees.xlsx`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Employees.xlsx`'
- en: '`AirfoilSelfNoise.xlsx`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AirfoilSelfNoise.xlsx`'
- en: Introducing classification methods using MATLAB
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MATLAB介绍分类方法
- en: '**Classification** methods are an essential component of machine learning and
    data analysis. These methods allow us to categorize data into predefined classes
    or groups based on specific characteristics or attributes. By utilizing classification
    algorithms, we can train models to make predictions or assign labels to new, unseen
    data points. Classification plays a vital role in various domains, including image
    recognition, spam filtering, sentiment analysis, fraud detection, and medical
    diagnosis. It enables us to make informed decisions, identify patterns, and gain
    insights from data.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类**方法是机器学习和数据分析的一个基本组成部分。这些方法允许我们根据特定的特征或属性将数据分类到预定义的类别或组中。通过利用分类算法，我们可以训练模型来对新数据点进行预测或分配标签。分类在各个领域都发挥着至关重要的作用，包括图像识别、垃圾邮件过滤、情感分析、欺诈检测和医疗诊断。它使我们能够做出明智的决策，识别模式，并从数据中获得洞察。'
- en: 'There are numerous classification algorithms available, each with its own strengths,
    assumptions, and applications. Some common classification methods include decision
    trees, **support vector machines** (**SVMs**), random forests, logistic regression,
    and naive Bayes classifiers. SVM has two variations: SVC for classification and
    SVR for regression. To effectively employ classification methods, we need to understand
    the underlying concepts, techniques, and evaluation metrics associated with them.
    Additionally, data preparation and feature engineering play crucial roles in ensuring
    accurate and reliable classification results.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的分类算法众多，每种算法都有其自身的优势、假设和应用。一些常见的分类方法包括决策树、**支持向量机**（**SVMs**）、随机森林、逻辑回归和朴素贝叶斯分类器。SVM有两种变体：SVC用于分类和SVR用于回归。为了有效地应用分类方法，我们需要了解与之相关的潜在概念、技术和评估指标。此外，数据准备和特征工程在确保准确和可靠的分类结果方面发挥着至关重要的作用。
- en: Throughout our learning journey, we will explore various classification methods,
    learn how to implement them in the MATLAB environment, and understand the necessary
    steps for data preparation and model evaluation. By the end, you will be equipped
    with the knowledge and skills to apply classification techniques to your own datasets
    and extract valuable insights. Let’s start by exploring decision trees.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的学习旅程中，我们将探索各种分类方法，学习如何在MATLAB环境中实现它们，并了解数据准备和模型评估的必要步骤。到结束时，你将具备将分类技术应用于自己的数据集并提取有价值见解的知识和技能。让我们从探索决策树开始。
- en: Decision trees for decision-making
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策树用于决策
- en: A **decision tree** serves as a visual representation of a choice or decision
    being made. It captures the complexity of decision-making processes where the
    most interesting option may not always be the most useful, and situations may
    not always offer clear-cut choices. Often, decisions are determined by a series
    of conditional factors that need to be evaluated. Representing this concept solely
    through tables and numbers can be challenging, as the justification behind the
    decision is not immediately apparent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树**是做出选择或决策的视觉表示。它捕捉了决策过程的复杂性，其中最有趣的选项可能并不总是最有用的，情况可能并不总是提供明确的选项。通常，决策是由一系列需要评估的条件因素决定的。仅通过表格和数字来表示这一概念可能具有挑战性，因为决策背后的理由并不立即明显。'
- en: A decision tree structure helps us convey the same information with enhanced
    readability by emphasizing the specific branches that lead to the decision or
    evaluation. The technology of decision trees is valuable in identifying strategies
    or achieving goals by creating models with probable outcomes. The graphical representation
    of a decision tree immediately guides readers to comprehend the result. A visual
    representation is much more effective than a table filled with numbers. The human
    mind prefers to see the solution first and then trace back to understand the reasoning
    behind it, rather than being presented with a series of algebraic descriptions,
    percentages, and data to describe a result.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树结构有助于我们通过强调导致决策或评估的具体分支来以增强的可读性传达相同的信息。决策树技术通过创建具有可能结果的模型来识别策略或实现目标非常有价值。决策树的图形表示立即引导读者理解结果。与充满数字的表格相比，视觉表示更有效。人类大脑更喜欢先看到解决方案，然后再追溯理解其背后的推理，而不是被一系列代数描述、百分比和数据所描述的结果。
- en: 'A decision tree is composed of the following elements:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树由以下元素组成：
- en: '**Nodes**: These contain the names of independent variables or factors involved
    in the decision-making process.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点**：这些包含决策过程中涉及的独立变量或因素的名称。'
- en: '**Branches**: These are labeled with the possible values of the independent
    variables, representing different pathways or choices.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分支**：这些被标记为独立变量的可能值，代表不同的路径或选择。'
- en: '**Leaf nodes**: These represent the classes or outcomes, where observations
    are grouped based on the values of an independent variable. Leaf nodes are connected
    to the nodes through the branches.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**叶节点**：这些代表类别或结果，观察结果根据独立变量的值进行分组。叶节点通过分支与节点相连。'
- en: Using these tools, we assign labels to data and classes to represent the confidence
    level of the classification itself. The decision tree provides the probability
    or likelihood of belonging to a specific class, reflecting the level of confidence
    in the classification.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些工具，我们为数据分配标签，为类别分配标签以表示分类本身的置信水平。决策树提供了属于特定类别的概率或可能性，反映了分类的置信水平。
- en: The process of classification begins with a set of pre-classified data known
    as the training set. The goal is to define rules that characterize different classes
    based on this data. Once the model is built, it is tested using a separate test
    set. The resulting descriptions or classes are then generalized through inference
    or induction. These generalized descriptions are then used to classify records
    whose membership class is unknown.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 分类过程从一组已知为预分类数据（训练集）开始。目标是定义基于这些数据的规则，以表征不同的类别。一旦构建了模型，就使用单独的测试集对其进行测试。然后通过推理或归纳将这些结果描述或类别推广。然后使用这些推广的描述来分类成员类别未知的数据记录。
- en: Decision trees offer a straightforward approach to classifying objects into
    a finite number of classes. They are constructed by recursively dividing the records
    into homogeneous subsets based on a target attribute, which must be categorical.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树为将对象分类到有限数量的类别提供了一种直接的方法。它们通过递归地将记录根据目标属性划分为同质子集来构建，该目标属性必须是分类的。
- en: 'There are two types of classification rules: univariate and multivariate. **Univariate
    rules** consider a single predictor or target attribute at a time, while **multivariate
    algorithms** represent the predictor as a linear combination of variables. The
    process of subdivision results in a hierarchical tree structure, where subsets
    are referred to as nodes, and the final nodes are called leaf nodes. Nodes are
    labeled with the attribute name, branches are labeled with possible attribute
    values, and leaf nodes are labeled with different values representing the membership
    classes.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种分类规则：单变量和多变量。**单变量规则**一次考虑一个预测器或目标属性，而**多变量算法**将预测器表示为变量的线性组合。细分过程产生一个层次树结构，其中子集被称为节点，最终节点被称为叶节点。节点用属性名称标记，分支用可能的属性值标记，叶节点用表示成员类别的不同值标记。
- en: 'To classify an object using a decision tree, we use the following steps:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用决策树对对象进行分类，我们遵循以下步骤：
- en: Begin at the root of the tree.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从树的根节点开始。
- en: Select the instance attribute associated with the current node.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择与当前节点关联的实例属性。
- en: Follow the branch corresponding to the attribute value assigned to the instance.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 沿着与分配给实例的属性值对应的分支前进。
- en: If a leaf node is reached, return the label associated with that leaf. Otherwise,
    repeat from *step 2*, starting from the current node.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果达到叶节点，则返回与该叶节点关联的标签。否则，从*步骤 2*开始重复，从当前节点开始。
- en: By traversing the decision tree, the path taken represents the classification
    rules or production rules. The branches represent the values assumed by different
    attributes, and the leaves represent the classification outcomes. Each rule is
    written along the tree, from the node to the corresponding leaf. All possible
    paths in the tree represent the different classification rules.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遍历决策树，所采取的路径代表分类规则或生产规则。分支代表不同属性所假设的值，叶节点代表分类结果。每个规则沿着树从节点到相应的叶节点书写。树中的所有可能路径代表不同的分类规则。
- en: In summary, when classifying an instance using a decision tree, the process
    involves starting from the root, selecting the appropriate attribute at each node,
    following the corresponding branch based on the attribute value, and repeating
    these steps until a leaf node is reached, and then returning the associated label.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在使用决策树对实例进行分类时，过程涉及从根节点开始，在每个节点选择适当的属性，根据属性值跟随相应的分支，重复这些步骤直到达到叶节点，然后返回与该叶节点关联的标签。
- en: Exploring decision trees in MATLAB
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 MATLAB 中探索决策树
- en: In the MATLAB environment, the Statistics and Machine Learning Toolbox provides
    the necessary tools for constructing a classification tree from raw data. In this
    section, we will delve into a well-known example featured in many machine learning
    books—the iris flower dataset. Let’s explore how to handle this within the MATLAB
    environment. We already used this dataset in [*Chapter 2*](B21156_02.xhtml#_idTextAnchor040),
    *Working with Data* *in MATLAB.*
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MATLAB 环境中，Statistics and Machine Learning Toolbox 提供了从原始数据构建分类树所需的工具。在本节中，我们将深入研究许多机器学习书籍中介绍的一个著名示例——鸢尾花数据集。让我们探索如何在
    MATLAB 环境中处理这个问题。我们已经在 [*第 2 章*](B21156_02.xhtml#_idTextAnchor040)，*在 MATLAB 中处理数据*
    中使用了这个数据集。
- en: 'Within this dataset, there are 50 samples belonging to each of three iris species:
    Iris setosa, Iris virginica, and Iris versicolor. Each sample consists of four
    measured features—sepal length, sepal width, petal length, and petal width—all
    measured in centimeters. The dataset includes the following variables:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集中，有三个鸢尾物种（Iris setosa、Iris virginica 和 Iris versicolor）各有 50 个样本。每个样本包含四个测量特征——花瓣长度、花瓣宽度、萼片长度和萼片宽度，所有这些都是在厘米中测量的。数据集包括以下变量：
- en: Sepal length in cm
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 萼片长度（厘米）
- en: Sepal width in cm
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 萼片宽度（厘米）
- en: Petal length in cm
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣长度（厘米）
- en: Petal width in cm
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣宽度（厘米）
- en: 'Class: `setosa`, `versicolour`, `virginica`'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别：`setosa`、`versicolour`、`virginica`
- en: 'Our goal is to create a classification tree that can accurately classify flower
    species based on the size of their sepals and petals. Fortunately, there is no
    need to connect to the previously mentioned external archive to upload data to
    MATLAB’s workspace. MATLAB already includes a file containing the necessary data
    within its software distribution:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目的是创建一个分类树，能够根据花瓣和萼片的大小准确地对花卉物种进行分类。幸运的是，无需连接到之前提到的外部存档来将数据上传到 MATLAB 的工作空间。MATLAB
    已经在其软件发行版中包含了一个包含必要数据的文件：
- en: 'To import this data, simply execute the following command:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要导入此数据，只需执行以下命令：
- en: '[PRE0]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In MATLAB, two variables, namely `meas` and `species`, have been successfully
    imported. `meas` contains the measurements for sepal and petal length and width,
    forming a 150x4 double matrix. On the other hand, `species` represents the classification
    information and is structured as a 150x1 cell array. Now, let’s examine the distribution
    of the three species within the `species` variable:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 MATLAB 中，已成功导入两个变量，即 `meas` 和 `species`。`meas` 包含萼片和花瓣长度和宽度的测量值，形成一个 150x4
    的双精度矩阵。另一方面，`species` 代表分类信息，其结构为一个 150x1 的单元数组。现在，让我们检查 `species` 变量中三种物种的分布情况：
- en: '[PRE1]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After careful analysis, it has been determined that the sample is evenly distributed
    among the three species. To gain an overview of the listed floral species’ features,
    we can utilize a scatter plot matrix. This showcases the scatter plots of the
    species’ features in a convenient matrix format.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经过仔细分析，已经确定样本在三个物种中均匀分布。为了概述列出的花卉物种的特征，我们可以利用散点图矩阵。这以方便的矩阵格式展示了物种特征的散点图。
- en: 'To effectively display the characteristics of the species in pairs and distinguish
    observations within their respective groups, we can leverage the `gplotmatrix()`
    function. This function is specifically designed to create a matrix of scatter
    plots:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了有效地显示物种成对的特征并区分各自组内的观察结果，我们可以利用 `gplotmatrix()` 函数。此函数专门设计用于创建散点图矩阵：
- en: '[PRE2]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The variables we want to compare in pairs are contained in the `meas` variable,
    while the groups are contained in the species variable. Each set of axes in the
    resulting figure contains a scatter plot of a column of `meas` against a column
    of `meas`. All graphs are grouped to describe bivariate relationships between
    combinations of variables.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们想要成对比较的变量包含在 `meas` 变量中，而组包含在 `species` 变量中。结果图中的每一组坐标轴都包含一个 `meas` 列对 `meas`
    列的散点图。所有图表都分组以描述变量组合的双变量关系。
- en: '*Figure 3**.1* depicts the scatter plot of the floral features for the three
    iris species.'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*图 3.1* 描述了三种鸢尾物种的花卉特征的散点图。'
- en: '![Figure 3.1 – Matrix of scatter plots grouped by species](img/B21156_03_01.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1 – 按物种分组的散点图矩阵](img/B21156_03_01.jpg)'
- en: Figure 3.1 – Matrix of scatter plots grouped by species
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 按物种分组的散点图矩阵
- en: Upon a preliminary analysis of *Figure 3**.1*, it becomes evident that the `setosa`
    species' values are distinctly separated from the other two species, because the
    markers are located at various distances from the others. Conversely, the values
    of the other two species exhibit overlapping patterns across all plots.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在对*图3.1*进行初步分析后，很明显，`setosa`物种的值与其他两种物种明显分开，因为标记位于与其他物种不同的距离上。相反，其他两种物种的值在所有图中都表现出重叠的模式。
- en: 'Now, let’s focus on investigating the variations in petal measurements across
    different species. To achieve this, we can utilize the two columns containing
    petal measurements, specifically the third and fourth columns. To visually represent
    the distribution of these measurements by species, we can employ a modified version
    of the scatter plot that we have used previously. This can be achieved using the
    `gscatter()` function, which generates a scatter plot grouped by a specified grouping
    variable. The function requires two vectors of the same size as arguments. The
    grouping variable must be provided in the form of a categorical variable, vector,
    character array, or cell array of character vectors:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们专注于调查不同物种间花瓣尺寸的变化。为了实现这一点，我们可以利用包含花瓣尺寸的两个列，特别是第三列和第四列。为了通过物种来直观地表示这些尺寸的分布，我们可以使用之前使用过的散点图的修改版。这可以通过使用`gscatter()`函数实现，该函数通过一个指定的分组变量生成分组散点图。该函数需要两个大小相同的向量作为参数。分组变量必须以分类变量、向量、字符数组或字符向量的单元格数组的形式提供：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*Figure 3**.2* distinctly illustrates the distribution of the three floral
    species, each occupying distinct regions within the plot.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.2* 明确展示了三种花卉物种的分布，每个物种在图中占据不同的区域。'
- en: '![Figure 3.2 – Scatter plot grouped by species](img/B21156_03_02.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – 按物种分组的散点图](img/B21156_03_02.jpg)'
- en: Figure 3.2 – Scatter plot grouped by species
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 按物种分组的散点图
- en: These observations indicate that it is feasible to perform classification based
    on petal characteristics.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些观察结果表明，基于花瓣特征进行分类是可行的。
- en: 'To create a classification tree, we can utilize the `fitctree()` function.
    This function generates a fitted binary decision tree by considering the input
    and output variables provided as inputs:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建分类树，我们可以使用`fitctree()`函数。该函数通过考虑作为输入提供的输入和输出变量生成拟合的二叉决策树：
- en: '[PRE4]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following results are printed:'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下结果被打印出来：
- en: '[PRE5]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*Figure 3**.3* presents a graphical representation of the tree, depicting its
    branches and leaf nodes. Each node includes the conditions that must be met to
    traverse a particular branch.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*图3.3* 展示了树的图形表示，描绘了其分支和叶节点。每个节点都包括必须满足的条件才能遍历特定的分支。'
- en: '![Figure 3.3 – Graphical description of the tree](img/B21156_03_03.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – 树的图形描述](img/B21156_03_03.jpg)'
- en: Figure 3.3 – Graphical description of the tree
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 树的图形描述
- en: '*Figure 3**.3* offers valuable insights into the classification of the three
    floral species, providing immediate information. In many cases, decision tree
    construction is primarily focused on predicting class labels or responses. Once
    a tree is constructed, it becomes straightforward to predict responses for new
    data.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.3* 为三种花卉物种的分类提供了宝贵的见解，提供了即时信息。在许多情况下，决策树构建主要关注预测类标签或响应。一旦构建了树，预测新数据的响应就变得简单直接。'
- en: Let’s consider a scenario where a new combination of four data points, representing
    the length and width of the sepal and petal for a specific class of floral species,
    has been identified. We can use this data to predict the iris species.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个场景，其中已经确定了一个新的四个数据点的组合，代表特定花卉物种的萼片和花瓣的长度和宽度。我们可以使用这些数据来预测鸢尾花物种。
- en: 'To predict the classification for new data based on the previously created
    and trained decision tree named `ClassTree`, use the following command:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要根据先前创建和训练的名为`ClassTree`的决策树预测新数据的分类，请使用以下命令：
- en: '[PRE6]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `predict()` function returns a vector comprising the predicted class labels
    for the predictor data, which can be in the form of a table or matrix. These predictions
    are based on the trained classification tree. In the given case, only one prediction
    is made because the input variable contains a single record. If a data matrix
    with multiple observations were used, the function would produce a series of results
    equivalent to the number of rows in the data matrix.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`predict()`函数返回一个向量，包含预测的预测数据类别标签，这些数据可以是表或矩阵的形式。这些预测基于训练好的分类树。在给定的情况下，只进行了一次预测，因为输入变量包含单个记录。如果使用包含多个观测值的数据矩阵，该函数将产生一系列结果，相当于数据矩阵中的行数。'
- en: Having built a classification tree from our data, the next step is to assess
    the model’s performance in predicting new observations. Various tools are available
    to measure the quality of the tree. A commonly used method is **resubstitution
    error**, which calculates the difference between the predicted responses and the
    actual responses in the training data. It serves as an initial estimate of the
    model’s performance but only provides insight in one direction. A high resubstitution
    error suggests that the tree’s predictions may not be accurate.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从我们的数据中构建了分类树之后，下一步是评估模型在预测新观测值方面的性能。有多种工具可以衡量树的质量。常用的方法之一是**重采样误差**，它计算预测响应与训练数据中实际响应之间的差异。它作为模型性能的初始估计，但只提供单向的洞察。高重采样误差表明树的预测可能不准确。
- en: 'To calculate the resubstitution error, you can use the following command:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要计算重采样误差，你可以使用以下命令：
- en: '[PRE7]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The low value obtained indicates that the classification tree accurately classifies
    a significant portion of the data. However, to enhance the assessment of the tree’s
    predictive accuracy, we can perform `crossval()` and `kfoldLoss()` for performing
    cross-validation.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获得的低值表明分类树准确地分类了数据的一个显著部分。然而，为了增强对树预测准确性的评估，我们可以执行`crossval()`和`kfoldLoss()`来进行交叉验证。
- en: During cross-validation, the training data is divided randomly by default into
    10 parts. Subsequently, 10 new trees are trained, with each tree utilizing 9 parts
    of the data for training. The predictive accuracy of each new tree is then evaluated
    on the remaining data that was not used for training that particular tree. Unlike
    the resubstitution error, this approach provides a reliable estimate of the predictive
    accuracy of the resulting tree since it tests the new trees on fresh, unseen data.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在交叉验证期间，默认情况下，训练数据被随机分为10部分。随后，训练了10棵新树，每棵树使用数据中的9部分进行训练。然后，评估每棵新树的预测准确性，这些新树是在未用于训练特定树的剩余数据上进行的。与重采样误差不同，这种方法提供了一个可靠的预测准确性的估计，因为它在新鲜、未见的数据上测试了新树。
- en: 'Performing cross-validation helps gauge the tree’s generalizability and offers
    a more robust measure of its predictive performance:'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 进行交叉验证有助于评估树的泛化能力，并提供对其预测性能的更稳健的度量：
- en: '[PRE8]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We used the `crossval()` function, which performs a loss estimate using cross-validation.
    A cross-validated classification model is returned. A number of properties are
    now available in MATLAB’s workspace.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用了`crossval()`函数，该函数使用交叉验证进行损失估计。返回一个交叉验证的分类模型。现在MATLAB工作空间中可用了一些属性。
- en: 'To calculate the cross-validation loss, you can utilize the `kfoldLoss()` function
    in the following manner:'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要计算交叉验证损失，你可以以下这种方式使用`kfoldLoss()`函数：
- en: '[PRE9]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, we calculated the classification loss for observations not used for training
    by using the `kfoldLoss()` function. The low calculated value confirms that the
    model works well.
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用`kfoldLoss()`函数计算了未用于训练的观测值的分类损失。计算出的低值确认了模型运行良好。
- en: The `kfoldLoss()` function calculates the average loss across all folds during
    cross-validation. It provides a measure of the predictive accuracy of the classification
    tree on unseen data. By default, `kfoldLoss()` employs 10-fold cross-validation,
    where the data is randomly divided into 10 parts. Each part is then used as a
    testing set while the remaining data is used for training the tree.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`kfoldLoss()` 函数计算交叉验证期间所有折叠的平均损失。它提供了对分类树在未见数据上的预测准确性的度量。默认情况下，`kfoldLoss()`
    使用10折交叉验证，将数据随机分为10部分。然后，每一部分被用作测试集，而剩余的数据用于训练树。'
- en: Using `kfoldLoss()` enables us to obtain a more reliable estimate of the tree’s
    predictive accuracy as it assesses the model’s performance on new and unseen data,
    rather than the training data itself.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用`kfoldLoss()`函数可以使我们获得更可靠的树预测准确度估计，因为它评估的是模型在新和未见过的数据上的性能，而不是训练数据本身。
- en: At the start of this section, we listed several classification methods. In the
    following section, we will address SVM techniques and discriminant analysis for
    classification.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的开头，我们列出了几种分类方法。在下一节中，我们将讨论SVM技术和分类的判别分析。
- en: Building an effective and accurate classifier
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个有效且准确的分类器
- en: Classification in machine learning is a supervised learning task that involves
    categorizing or classifying data into predefined classes or categories. It is
    one of the fundamental and widely used techniques in machine learning and data
    mining. The goal of classification is to develop a model or classifier that can
    accurately assign new, unseen instances to the correct class based on their features
    or attributes. The classifier learns patterns and relationships from a labeled
    training dataset, where each instance is associated with a known class label.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的分类是一个监督学习任务，它涉及将数据分类或归类到预定义的类别或类别中。这是机器学习和数据挖掘中最基本且广泛使用的技术之一。分类的目标是开发一个模型或分类器，能够根据其特征或属性，准确地将新的、未见过的实例分配到正确的类别。分类器从标记的训练数据集中学习模式和关系，其中每个实例都与一个已知的类别标签相关联。
- en: We will first discuss **SVMs**.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先讨论**SVMs**。
- en: SVMs explained
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SVMs explained
- en: SVMs are powerful supervised machine learning algorithms used for classification
    and regression tasks. They are particularly effective in solving complex problems
    with a clear margin of separation between classes. SVMs can handle both linearly
    separable and non-linearly separable data by transforming the input space into
    a higher-dimensional feature space. The main idea behind SVMs is to find the best
    possible decision boundary, known as the *hyperplane*, that maximally separates
    the classes while minimizing classification errors. The hyperplane is determined
    by a subset of training examples called support vectors, which are the closest
    points to the decision boundary. SVMs employ a kernel function to map the input
    data into a higher-dimensional space, where linear separation is more feasible.
    This allows SVMs to solve non-linear problems by finding non-linear decision boundaries
    in the transformed feature space.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs是强大的监督机器学习算法，用于分类和回归任务。它们在解决具有清晰类别分离边界的复杂问题方面特别有效。SVMs可以通过将输入空间转换到更高维的特征空间来处理线性可分和非线性可分的数据。SVMs背后的主要思想是找到最佳可能的决策边界，即*超平面*，它最大限度地分离类别同时最小化分类错误。超平面由称为支持向量的训练示例的子集确定，它们是决策边界最近的点。SVMs使用核函数将输入数据映射到更高维的空间，在那里线性分离更加可行。这使得SVMs能够通过在转换后的特征空间中找到非线性决策边界来解决非线性问题。
- en: SVMs excel in tackling intricate problems where there exists a discernible gap
    between different categories. They possess the capacity to handle datasets that
    can be separated both linearly and non-linearly through a process involving the
    transformation of the initial input space into a higher-dimensional feature space.
    The fundamental concept underpinning SVMs revolves around the quest for the optimal
    decision boundary, known as the hyperplane. SVMs leverage a kernel function to
    project the input data into this higher-dimensional space, where achieving linear
    separation becomes more attainable. This distinctive capability empowers SVMs
    to address non-linear problems by identifying non-linear decision boundaries within
    the transformed feature space.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs在处理存在不同类别之间明显差距的复杂问题时表现出色。它们能够通过将初始输入空间转换到更高维的特征空间的过程，处理可以线性或非线性分离的数据集。SVMs的基本概念是寻找最优决策边界，即超平面。SVMs利用核函数将输入数据投影到这个更高维的空间，在那里实现线性分离变得更加可行。这种独特的功能使SVMs能够通过在转换后的特征空间中识别非线性决策边界来解决非线性问题。
- en: The training of an SVM involves optimizing a cost function that penalizes misclassified
    examples and maximizes the margin between the support vectors and the decision
    boundary. There are different variations of SVMs, such as **C-support vector machine**(**C-SVM**)
    for classification tasks and **epsilon-SVM** for regression tasks. SVMs are widely
    used in various domains, including image classification, text categorization,
    bioinformatics, and finance. They are known for their ability to handle high-dimensional
    data, handle outliers well, and generalize effectively to unseen data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: SVM的训练涉及优化一个成本函数，该函数惩罚错误分类的示例并最大化支持向量与决策边界之间的边缘。SVM有不同变体，如用于分类任务的**C-支持向量机**（**C-SVM**）和用于回归任务的**epsilon-SVM**。SVM在各种领域得到广泛应用，包括图像分类、文本分类、生物信息学和金融。它们因其处理高维数据的能力、处理异常值的能力以及有效地泛化到未见数据的能力而闻名。
- en: 'An SVM-based classification technique enables the classification of both linear
    and non-linear datasets. In SVMs, the training data instances are represented
    on a plane with dimensions equal to the number of attributes in each instance.
    For instance, a three-dimensional plane is used to represent instances with three
    attributes. The three main components of an SVM classifier are as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 基于支持向量机（SVM）的分类技术能够对线性和非线性数据集进行分类。在SVM中，训练数据实例在平面上表示，其维度等于每个实例中属性的数目。例如，一个三维平面用于表示具有三个属性的实例。SVM分类器的三个主要组成部分如下：
- en: Lines or hyperplanes, which act as boundaries to classify instances into different
    classes
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线或超平面，它们作为将实例分类到不同类别的边界
- en: Margins, which are the distances between the closest instances of different
    classes
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘，即不同类别最近实例之间的距离
- en: Support vectors, which are the instances within the hyperplane boundaries that
    are challenging to classify
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量，它们是位于超平面边界内难以分类的实例
- en: SVMs separate data by finding an optimal hyperplane in a higher-dimensional
    feature space that maximizes the margin between different classes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: SVM通过在更高维度的特征空间中找到一个最优超平面来分离数据，从而最大化不同类别之间的边缘。
- en: SVMs can handle linearly separable datasets, where instances can be separated
    by straight lines on the plane, as well as non-linearly separable datasets. In
    the case of linearly separable instances, the goal is to find the lines or hyperplanes
    that maximize the margin value. This selection minimizes the classification error.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: SVM可以处理线性可分的数据集，其中实例可以通过平面上的直线进行分离，以及非线性可分的数据集。在线性可分实例的情况下，目标是找到最大化边缘值的线或超平面。这种选择最小化了分类误差。
- en: For non-linearly separable datasets, the classification process is more complex.
    It involves two phases that build upon the previous approach.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非线性可分的数据集，分类过程更为复杂。它涉及两个阶段，这两个阶段建立在先前方法的基础上。
- en: In the first phase, instances are mapped to a higher-dimensional space to achieve
    linear separability. In the second phase, the previous approach is used to find
    a line or hyperplane that maximizes the margin, taking advantage of the now linearly
    separable instances.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一阶段，实例被映射到更高维的空间以实现线性可分性。在第二阶段，使用先前的方法找到一个最大化边缘的线或超平面，利用现在线性可分的实例。
- en: To handle datasets that require non-linear functions for separation, **feature
    spaces** are used in SVMs. This technique involves mapping the initial data to
    a higher-dimensional space. If the initial data has *m* dimensions and the feature
    space has *n* dimensions, with *m > n*, a mapping function is applied. Suppose
    we have an input denoted with *x* and *y*. The concept of kernel spaces is particularly
    useful for algorithms that rely on training data solely through scalar products.
    In this case, instead of explicitly finding *f(x)* and *f(y)* in the *m*-dimensional
    space, we only need to calculate their scalar product, denoted as *f(x) ·* *f(y)*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理需要非线性函数进行分离的数据集，SVM中使用**特征空间**。这种技术涉及将初始数据映射到更高维的空间。如果初始数据有*m*维，特征空间有*n*维，且*m
    > n*，则应用映射函数。假设我们有一个用*x*和*y*表示的输入。核空间的概念对于仅通过标量积依赖训练数据的算法特别有用。在这种情况下，我们不需要在*m*-维空间中显式地找到*f(x)*和*f(y)*，我们只需要计算它们的标量积，表示为*f(x)
    · f(y)*。
- en: The function *f* is employed to map the input from the original *n*-dimensional
    space to a higher-dimensional *m*-space. To simplify this computation, especially
    in large spaces, a kernel function is utilized. The kernel function directly provides
    the scalar product of the images, eliminating the need for explicit mapping and
    making the calculation more efficient.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 *f* 被用来将输入从原始 *n*-维空间映射到更高维的 *m*-空间。为了简化这种计算，特别是在大空间中，使用核函数。核函数直接提供图像的标量积，消除了显式映射的需要，使计算更高效。
- en: K(x, y) = f(x) · f(y)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: K(x, y) = f(x) · f(y)
- en: 'Here, we have the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们有以下内容：
- en: '*x* and *y* are input vectors'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x* 和 *y* 是输入向量'
- en: '*f* is a transformation function'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f* 是一个转换函数'
- en: The dot product operation, denoted by *f(x) · f(y)*, calculates the dot product
    of the transformed input vectors. It allows us to efficiently compute the scalar
    product of the mapped input vectors without explicitly calculating the mapping
    function, *f(x)* and *f(y)*. This dot product operation is an essential component
    in various algorithms that utilize kernel methods for classification and regression
    tasks.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 点积运算，表示为 *f(x) · f(y)*，计算了转换后的输入向量的点积。它允许我们高效地计算映射输入向量的标量积，而无需显式计算映射函数，*f(x)*
    和 *f(y)*。这种点积运算是各种利用核方法进行分类和回归任务算法的一个基本组成部分。
- en: The purpose of the **kernel function** is to transform the input data into a
    suitable form, particularly when it is not feasible to determine a linearly separable
    hyperplane, which is often the case. There are several commonly used kernels,
    including **linear**, **polynomial**, **radial basis function** (**RBF**), and
    **sigmoid**.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**核函数**的目的是将输入数据转换成合适的形式，尤其是在无法确定线性可分超平面时，这种情况很常见。常用的核函数包括**线性**、**多项式**、**径向基函数**（**RBF**）和**Sigmoid**。'
- en: In this methodology, the training phase and the subsequent error evaluation
    activity play a crucial role. To accomplish this, the data is split into two subsets,
    named training and testing. The **training set** is utilized for algorithm training
    and comprises labeled inputs and outputs for supervised learning. Typically, it
    consists of approximately 80% of the total data. The **testing set**, on the other
    hand, is used to evaluate the accuracy of the SVM. It contains 20% of the remaining
    data that was not used in training, and it helps measure the prediction error.
    This phase also serves to test the algorithm in real-world scenarios, simulating
    the actual usage of the trained model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方法中，训练阶段和随后的错误评估活动起着至关重要的作用。为此，数据被分成两个子集，分别命名为训练集和测试集。**训练集**用于算法训练，包含用于监督学习的标记输入和输出。通常，它占全部数据的约80%。另一方面，**测试集**用于评估SVM的精度。它包含未用于训练的剩余数据的20%，有助于衡量预测误差。这一阶段还用于在现实世界场景中测试算法，模拟训练模型的实际使用。
- en: One notable advantage of SVM-based classifiers is their capability to handle
    complex and non-linear classification problems while ensuring a high level of
    accuracy. However, for simpler problems, the accuracy may be comparable to that
    of decision tree-based classification techniques. Some drawbacks of SVMs include
    the relatively longer time required for model creation, although it is still faster
    compared to neural networks. The other drawback is the lack of interpretability
    of the model’s inner workings.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 基于SVM的分类器的一个显著优点是它们能够处理复杂和非线性分类问题，同时确保高精度。然而，对于简单问题，精度可能与基于决策树的分类技术相当。SVM的一些缺点包括模型创建所需的时间相对较长，尽管与神经网络相比仍然更快。另一个缺点是模型内部工作的不可解释性。
- en: Supervised classification using SVM
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SVM的监督分类
- en: Supervised classification is a machine learning technique used to classify or
    categorize data into predefined classes or categories. Supervised classification
    relies on labeled training data, in which data points are linked to a specific
    class. The objective of supervised classification is to construct a model capable
    of making precise predictions regarding the class of previously unseen or fresh
    data points, utilizing their inherent features as guidance.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 监督分类是一种机器学习技术，用于将数据分类或归类到预定义的类别或类别中。监督分类依赖于标记的训练数据，其中数据点与特定类别相关联。监督分类的目的是构建一个模型，能够根据数据点的固有特征，对先前未见或新数据点的类别做出精确预测。
- en: To understand how to implement the SVM algorithm in MATLAB, we will use a dataset
    for binary classification. **Binary classification** is a specific type of supervised
    classification where the goal is to classify data into one of two mutually exclusive
    classes or categories. The two classes are often referred to as the positive class
    and the negative class, or class 1 and class 0\. In binary classification, the
    labeled training data consists of examples where each data point is associated
    with one of the two classes. The machine learning algorithm is then trained on
    this labeled data to learn a model that can accurately predict the class of unseen
    data points.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何在MATLAB中实现SVM算法，我们将使用用于二进制分类的数据集。**二进制分类**是一种特定的监督分类，其目标是将数据分类为两个互斥的类别或类别之一。这两个类别通常被称为正类和负类，或类别1和类别0。在二进制分类中，标记的训练数据包括每个数据点与两个类别之一相关联的示例。然后，机器学习算法在此标记数据上训练，以学习一个可以准确预测未见数据点类别的模型。
- en: The dataset consists of features such as `Temperature`, `Humidity`, `Light`,
    and `CO2`, and the target variable is room occupancy. The ground-truth occupancy
    information was obtained by capturing time-stamped pictures every minute.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包括诸如`温度`、`湿度`、`光照`和`CO2`等特征，目标变量是房间占用情况。通过每分钟捕捉带时间戳的图片，获得了真实占用信息。
- en: The goal of this experiment is to train a binary classification model that can
    predict whether the room is occupied or unoccupied based on the given sensor data.
    The features (`Temperature`, `Humidity`, `Light`, `CO2`, and `Humidity Ratio`)
    are used as input to the model, and the corresponding occupancy status (`occupied`
    or `unoccupied`) serves as the target variable for training and evaluation.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本实验的目的是训练一个二进制分类模型，可以根据给定的传感器数据预测房间是被占用还是未被占用。特征（`温度`、`湿度`、`光照`、`CO2`和`湿度比`）作为模型的输入，相应的占用状态（`占用`或`未占用`）作为训练和评估的目标变量。
- en: Important note
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'To download the dataset and a short summary of the variables contained within
    it, please refer to UCI Machine Learning Repository at the following link: [https://doi.org/10.24432/C5X01N](https://doi.org/10.24432/C5X01N).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载数据集及其包含的变量简要概述，请参阅以下链接的UCI机器学习仓库：[https://doi.org/10.24432/C5X01N](https://doi.org/10.24432/C5X01N)。
- en: By analyzing the relationship between the sensor data and the ground-truth occupancy,
    the model aims to learn patterns and make accurate predictions on unseen data.
    The training process involves feeding the labeled data into a binary classification
    algorithm, using SVM. The algorithm learns from the features and their corresponding
    occupancy labels to create a model that can classify new instances.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析传感器数据与真实占用情况之间的关系，模型旨在学习模式并对未见数据做出准确预测。训练过程涉及将标记数据输入到使用SVM的二进制分类算法中。该算法从特征及其对应的占用标签中学习，以创建一个可以对新实例进行分类的模型。
- en: 'Take the following steps:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 按以下步骤操作：
- en: 'We start by importing the data into the MATLAB environment. To do that, we
    will use the `readtable()` function, as we learned in [*Chapter 2*](B21156_02.xhtml#_idTextAnchor040),
    *Working with Data in MATLAB*, in the *Importing data into MATLAB* section. We
    need to use the `datatraining.txt` file, containing eight variables (`Num`, `date`,
    `Temperature`, `Humidity`, `Light`, `CO2`, `HumidityRatio`, and `Occupancy`).
    But for our purpose, only six variables are needed, that is, the last six. So,
    we have to set some options to use in the function call, as follows:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先将数据导入MATLAB环境。为此，我们将使用`readtable()`函数，正如我们在[*第2章*](B21156_02.xhtml#_idTextAnchor040)中学习的，在*导入数据到MATLAB*部分。我们需要使用包含八个变量（`Num`、`date`、`Temperature`、`Humidity`、`Light`、`CO2`、`HumidityRatio`和`Occupancy`）的`datatraining.txt`文件。但出于我们的目的，只需要六个变量，即最后六个。因此，我们必须设置一些选项来在函数调用中使用，如下所示：
- en: '[PRE10]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Only the last six variables have been selected.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 只选择了最后六个变量。
- en: 'Now we are ready to import the dataset:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经准备好导入数据集：
- en: '[PRE11]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can see, in the MATLAB workspace, a new variable named `DataMatrix` as a
    table of size 814x6\. This table contains the five predictors (`Temperature`,
    `Humidity`, `Light`, `CO2`, and `HumidityRatio`) and one dichotomic response (`Occupancy`).
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在MATLAB工作区中看到一个名为`DataMatrix`的新变量，它是一个814x6大小的表格。这个表格包含五个预测变量（`温度`、`湿度`、`光照`、`CO2`和`湿度比`）和一个二分响应变量（`占用`）。
- en: 'To train an SVM classifier for binary classification problems, we can use the
    `fitcsvm()` function as follows:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要为二进制分类问题训练SVM分类器，我们可以使用`fitcsvm()`函数，如下所示：
- en: '[PRE12]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `DataMatrix(:,1:5)` parameter represents the predictor data, which is an
    8,143-by-5 matrix, where 8,143 is the matrix’s dimension consisting of the number
    of observations, denoting data points, and 5 signifies the count of predictor
    variables, or features. Each row within this matrix represents a distinct observation,
    while each column pertains to an individual predictor variable. The `DataMatrix(:,6)`
    parameter represents the response data, which is an 8,143-by-1 vector. For binary
    classification, this vector should be a binary vector of 0s and 1s, where 0 represents
    the negative class and 1 represents the positive class.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`DataMatrix(:,1:5)` 参数表示预测数据，它是一个 8,143 行 5 列的矩阵，其中 8,143 是矩阵的维度，由观测值数量组成，表示数据点，而
    5 表示预测变量或特征的数量。这个矩阵中的每一行代表一个独特的观测值，而每一列则对应一个单独的预测变量。`DataMatrix(:,6)` 参数表示响应数据，它是一个
    8,143 行 1 列的向量。对于二元分类，这个向量应该是一个由 0 和 1 组成的二进制向量，其中 0 代表负类，1 代表正类。'
- en: 'The function returns an `SVMClassifier` object, which represents the trained
    SVM classifier. This object contains information about the trained model, such
    as support vectors, coefficients, and kernel parameters. We can print some of
    this information simply by typing the name of the model into the MATLAB command
    prompt:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 函数返回一个 `SVMClassifier` 对象，它代表训练好的 SVM 分类器。该对象包含有关训练模型的信息，例如支持向量、系数和核参数。我们只需在
    MATLAB 命令提示符中输入模型名称，就可以简单地打印出一些这些信息：
- en: '[PRE13]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `fitcsvm()` function applies the linear kernel by default. It’s possible
    to set a different kernel using the `KernelFunction` parameter. The supported
    kernels are the following:'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`fitcsvm()` 函数默认应用线性核。可以使用 `KernelFunction` 参数设置不同的核。支持的核如下：'
- en: '**Linear**: This is a commonly used kernel function. It assumes that the data
    can be separated by a linear decision boundary or hyperplane. The linear kernel
    computes the dot product between the input feature vectors, which effectively
    measures the similarity between the samples in the original feature space.'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性**：这是一个常用的核函数。它假设数据可以通过线性决策边界或超平面分离。线性核计算输入特征向量之间的点积，这实际上测量了原始特征空间中样本之间的相似性。'
- en: '**Polynomial**: This can be used to handle non-linearly separable data. It
    maps the input feature vectors into a higher-dimensional space using polynomial
    functions, which allows for the learning of non-linear decision boundaries. This
    kernel requires setting the degree of the polynomial and the scale factor.'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式**：这可以用来处理非线性可分数据。它使用多项式函数将输入特征向量映射到更高维的空间，这允许学习非线性决策边界。这个核需要设置多项式的次数和尺度因子。'
- en: '**Gaussian or RBF**: This can handle non-linearly separable data by mapping
    the input feature vectors into an infinite-dimensional feature space. The RBF
    kernel is particularly effective when the decision boundary is complex or not
    well defined. This kernel requires setting the kernel scale or gamma parameter,
    which determines the influence of each training example.'
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高斯或径向基函数（RBF）**：这可以通过将输入特征向量映射到无限维特征空间来处理非线性可分数据。当决策边界复杂或定义不明确时，RBF 核特别有效。这个核需要设置核尺度或伽马参数，它决定了每个训练样本的影响。'
- en: 'Calculating the resubstitution error helps us gauge the performance of the
    method employed. As mentioned earlier, this error is determined by measuring the
    disparity between the predicted and actual responses in the training data. While
    it offers an initial estimate of the model’s performance, it only provides insights
    in one direction. A high resubstitution error implies that the predictions made
    by the tree model may not be accurate:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算重采样误差有助于我们评估所采用方法的性能。如前所述，这个误差是通过测量训练数据中预测值和实际响应之间的差异来确定的。虽然它提供了模型性能的初步估计，但它只提供了一个方向上的见解。高重采样误差意味着树模型做出的预测可能不准确：
- en: '[PRE14]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Based on our analysis, we have encountered an error of at least 15%. This suggests
    that there is room for improvement in the performance of the classifier. It is
    likely that the data cannot be effectively separated using a linear plane, indicating
    the need to modify the kernel function.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据我们的分析，我们遇到了至少 15% 的错误。这表明在分类器的性能方面还有改进的空间。很可能是数据无法使用线性平面有效地分离，这表明需要修改核函数。
- en: 'To improve the performance of the model, we can choose an SVM classifier based
    on the RBF kernel:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了提高模型的性能，我们可以选择基于 RBF 核的 SVM 分类器：
- en: '[PRE15]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We initially had an error rate of 15%, but we have successfully reduced it to
    0.61%. This significant improvement indicates that the model is robust in handling
    non-linearity in the data.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们最初有15%的错误率，但已成功将其降低到0.61%。这种显著的改进表明模型在处理数据中的非线性方面具有鲁棒性。
- en: Now that we have introduced classification, it is time to explore the world
    of regression, which allows us to work with continuous numerical values.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了分类，是时候探索回归的世界了，它允许我们处理连续的数值。
- en: Exploring different types of regression
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索不同类型的回归
- en: '**Regression analysis** is a statistical method used to examine the connection
    between a group of independent variables (also known as explanatory variables)
    and a dependent variable (referred to as the response variable). By employing
    this technique, it becomes possible to comprehend how the value of the response
    variable fluctuates when the explanatory variable is altered.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归分析**是一种统计方法，用于研究一组自变量（也称为解释变量）与因变量（称为响应变量）之间的联系。通过采用这种方法，我们可以理解当解释变量改变时，响应变量的值是如何波动的。'
- en: 'Regression analysis serves a dual purpose: explanatory and predictive. The
    **explanatory** role helps us understand and assess the impact of independent
    variables on the dependent variable based on a specific theoretical model. It
    allows us to quantify the relationship and determine the magnitude and significance
    of the effects. In the **predictive** role, regression analysis aims to identify
    the optimal linear combination of independent variables to predict the value of
    the dependent variable accurately. By utilizing this technique, we can make predictions
    based on the observed relationships between variables.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析具有双重目的：解释性和预测性。**解释性**的作用帮助我们根据特定的理论模型理解和评估自变量对因变量的影响。它使我们能够量化关系并确定效应的大小和显著性。在**预测性**方面，回归分析旨在确定自变量的最佳线性组合，以准确预测因变量的值。通过利用这种技术，我们可以根据变量之间的观察关系进行预测。
- en: Introducing linear regression
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍线性回归
- en: To characterize the relationship between variables, we can employ a mathematical
    function that captures the observed behavior, interpolates the data, and represents
    its underlying trend while retaining its key information. Linear regression is
    a method that specifically aims to identify a line that can effectively represent
    the distribution of points in a two-dimensional plane. When the observed points
    closely align with the line, it indicates that the chosen model accurately describes
    the relationship between the variables.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了描述变量之间的关系，我们可以使用一个数学函数来捕捉观察到的行为，插值数据，并保留其关键信息的同时表示其潜在趋势。线性回归是一种旨在识别一条能够有效表示二维平面上点分布的线的特定方法。当观察到的点与线紧密一致时，这表明所选模型准确地描述了变量之间的关系。
- en: 'While there are theoretically infinite lines that can interpolate the observations,
    in practice, only one mathematical model can optimize the data representation.
    In the case of a linear mathematical relationship, the observations of the variable
    *y* can be derived from a linear function of the observations of the variable
    *x*. For each observation, this relationship can be expressed as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从理论上讲有无限多条线可以插值观察值，但在实践中，只有一个数学模型可以优化数据表示。在线性数学关系的情况下，变量*y*的观察值可以由变量*x*的线性函数推导出来。对于每个观察值，这种关系可以表示如下：
- en: y = α * x+ β
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: y = α * x + β
- en: In the given formula, *x* represents the explanatory variable, and *y* represents
    the response variable. The parameters *α* and *β* correspond to the slope of the
    line and the intercept with the *y* axis, respectively. These parameters need
    to be estimated using the collected observations for both variables included in
    the model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定的公式中，*x*代表解释变量，*y*代表响应变量。参数*α*和*β*分别对应于线的斜率和与*y*轴的截距。这些参数需要使用模型中包含的两个变量的收集到的观察值进行估计。
- en: Of particular interest is the slope *α*, which signifies the change in the average
    response for each unit increase in the explanatory variable. What happens when
    this coefficient changes? If the slope is positive, the regression line ascends
    from left to right, indicating that the response increases as the explanatory
    variable increases. Conversely, if the slope is negative, the line descends from
    left to right, suggesting that the response decreases with an increase in the
    explanatory variable. When the slope is 0, it implies that the explanatory variable
    has no effect on the response value.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 特别值得注意的是斜率 *α*，它表示解释变量每增加一个单位时平均响应的变化。当这个系数发生变化时会发生什么？如果斜率是正的，回归线从左到右上升，表明响应变量随着解释变量的增加而增加。相反，如果斜率是负的，线从左到右下降，表明响应变量随着解释变量的增加而减少。当斜率为
    0 时，表示解释变量对响应值没有影响。
- en: However, the significance of the relationship between the variables is not solely
    determined by the sign of *α*; its value is also crucial. In the case of a positive
    slope, the average response is higher when the explanatory variable is higher.
    Conversely, for a negative slope, the average response is lower when the explanatory
    variable is higher. The magnitude of the slope plays a vital role in understanding
    the strength and nature of the relationship between the variables.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，变量之间关系的显著性并不仅仅由 *α* 的符号决定；其值同样至关重要。在正斜率的情况下，当解释变量较高时，平均响应也较高。相反，对于负斜率，当解释变量较高时，平均响应较低。斜率的大小在理解变量之间关系的强度和性质方面起着至关重要的作用。
- en: In MATLAB, you can perform simple linear regression using the built-in functions
    and tools available in the Statistics and Machine Learning Toolbox. Another approach
    to perform simple linear regression in MATLAB is by using the `polyfit()` and
    `polyval()` functions. These functions allow you to fit data to a pattern that
    is linear in the coefficients.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MATLAB 中，您可以使用 Statistics 和 Machine Learning Toolbox 中提供的内置函数和工具执行简单线性回归。在
    MATLAB 中执行简单线性回归的另一种方法是使用 `polyfit()` 和 `polyval()` 函数。这些函数允许您将数据拟合到系数线性的模式。
- en: Linear regression model in MATLAB
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MATLAB 中的线性回归模型
- en: A convenient method to construct a linear regression model in MATLAB is by employing
    the `fitlm()` function, which is a part of the Statistics and Machine Learning
    Toolbox. This function offers a straightforward approach to creating and analyzing
    linear regression models.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MATLAB 中构建线性回归模型的一个便捷方法是使用 `fitlm()` 函数，它是 Statistics 和 Machine Learning Toolbox
    的一部分。此函数提供了一种创建和分析线性回归模型的方法。
- en: The `fitlm()` function generates a `LinearModel` object in MATLAB. This object
    contains various properties that can be easily examined by simply selecting it.
    Additionally, the `LinearModel` object offers several methods, such as `plot`,
    `plotResiduals`, and `plotDiagnostics`, which facilitate creating plots and conducting
    diagnostic analysis.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`fitlm()` 函数在 MATLAB 中生成一个 `LinearModel` 对象。此对象包含各种属性，可以通过简单地选择它来轻松检查。此外，`LinearModel`
    对象提供了一些方法，如 `plot`、`plotResiduals` 和 `plotDiagnostics`，这些方法有助于创建图表和进行诊断分析。'
- en: A `LinearModel` object encapsulates training data, model description, diagnostic
    information, and fitted coefficients for a linear regression. By default, when
    using the `fitlm()` function, the last variable in a table or dataset array is
    considered the response variable. Alternatively, you can specify the predictors
    and response variables explicitly using a formula. Moreover, you have the flexibility
    to designate a specific column as the response variable by utilizing the `ResponseVar`
    name-value pair argument. To define a set of columns as predictors, you can employ
    the `PredictorVars` name-value pair argument. The predictor variables can be numeric
    or of any grouping variable type, such as logical or categorical. However, the
    response variable must be numeric or logical in nature.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `LinearModel` 对象封装了线性回归的训练数据、模型描述、诊断信息和拟合系数。默认情况下，当使用 `fitlm()` 函数时，表格或数据集数组中的最后一个变量被视为响应变量。或者，您可以使用公式明确指定预测变量和响应变量。此外，您可以通过使用
    `ResponseVar` 名称-值对参数来指定一个特定列作为响应变量。要定义一组列作为预测变量，您可以使用 `PredictorVars` 名称-值对参数。预测变量可以是数值型或任何分组变量类型，例如逻辑型或分类型。然而，响应变量必须是数值型或逻辑型。
- en: 'To gain insight into the functionality of the `fitlm()` function, let’s consider
    a dataset that includes information on the number of vehicles registered in Italy
    and the population of various regions. The dataset includes the following fields:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了了解`fitlm()`函数的功能，让我们考虑一个包括意大利注册车辆数量和各地区人口信息的数据集。该数据集包括以下字段：
- en: Names of Italian regions (`Region`)
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 意大利地区名称（`Region`）
- en: Vehicle registrations for each region (`Registrations`)
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个地区的车辆注册（`Registrations`）
- en: Resident population in each region (`Population`)
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个地区的居民人口（`Population`）
- en: 'Let’s start by importing the data into a table:'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们先从将数据导入表格开始：
- en: '[PRE16]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To fit a linear regression model with the `Registrations` variable as the response
    and `Population` as the explanatory variable (predictor), we can use the `fitlm()`
    function as follows:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要拟合以`Registrations`变量为响应变量、`Population`为解释变量（预测变量）的线性回归模型，我们可以使用`fitlm()`函数，如下所示：
- en: '[PRE17]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following information is printed:'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打印以下信息：
- en: '[PRE18]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The results of the linear regression model include the model formula and estimated
    coefficients. Each term in the model is represented by a row, and the following
    columns provide additional information:'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 线性回归模型的结果包括模型公式和估计系数。模型中的每个项都由一行表示，以下列提供了额外的信息：
- en: '`Estimate`: The estimated coefficient value for each corresponding term in
    the model.'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Estimate`：模型中对应项的估计系数值。'
- en: '`SE`: The standard error of the estimate.'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SE`：估计的标准误差。'
- en: '`tStat`: The t-statistic for each coefficient, which tests the null hypothesis
    that the coefficient is 0 against the alternative that it is different from 0,
    given the other predictors in the model.'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tStat`：每个系数的t统计量，该统计量检验系数是否为0的零假设，以及它是否不同于0的备择假设，给定模型中的其他预测变量。'
- en: '`pValue`: The p-value for the F-statistic of the hypothesis test that the coefficient
    is equal to 0\. In our example, a p-value lower than 0.05 indicates that the term
    is significant at the 5% significance level, given the other terms in the model.'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pValue`：假设检验中系数等于0的F统计量的p值。在我们的例子中，低于0.05的p值表明，在模型的其他项中，该项在5%的显著性水平上是显著的。'
- en: Interpretation of the intercept adds more meaning to the problem statement,
    as an average 70,549 registrations are happening in the city.
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释截距增加了问题陈述的意义，因为该城市平均有70,549个注册。
- en: We can also explain the slope (0.59212) as with every 1,000-person increase
    in population, registrations increase by 592, with approximately 6 out of every
    10 people having vehicles.
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们也可以将斜率（0.59212）解释为，随着人口每增加1000人，注册数量增加592，大约每10个人中有6个人有车辆。
- en: The `Registrations` response variable.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Registrations`响应变量。'
- en: '**Adjusted R-squared**: A modified version of R-squared that takes into account
    the number of predictors in the model.'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**调整后的R-squared**：考虑模型中预测变量数量的R-squared的修改版本。'
- en: '**F-statistic versus constant model**: The test statistic for the F-test on
    the regression model, which tests for a significant linear regression relationship
    between the response variable and the predictor variables.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**F统计量与常量模型**：回归模型中F检验的检验统计量，该统计量检验响应变量与预测变量之间的显著线性回归关系。'
- en: '**p-value**: The p-value for the F-test on the model. In our example, the model
    is significant with a very low p-value of 1.03e-21.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**p-value**：模型中F检验的p值。在我们的例子中，模型具有显著性，p值非常低，为1.03e-21。'
- en: 'Let’s examine the results of the last MATLAB command. Two values stand out
    among the others: R-squared and p-value. The calculated R-squared value is very
    high, equal to 0.994\. This indicates that a substantial variation in the response
    variable can be explained by the predictor variable. On the other hand, the p-value
    is very small, but understanding its significance requires further exploration.
    During a statistical significance test, we start by assuming the **null hypothesis**,
    which states that there is no difference between the groups with respect to the
    parameters being considered. Under the null hypothesis, any observed differences
    are attributed to chance.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查最后一个MATLAB命令的结果。在其他的值中，有两个值突出：R-squared和p-value。计算出的R-squared值非常高，等于0.994。这表明响应变量的显著变化可以由预测变量解释。另一方面，p值非常小，但理解其意义需要进一步探索。在统计显著性检验中，我们首先假设**零假设**，即所考虑的组之间在参数上没有差异。在零假设下，任何观察到的差异都归因于偶然。
- en: Now we must make a decision, whether to accept or reject the null hypothesis.
    To make this determination, we analyze our data using a significance test. If
    the test *suggests* rejecting the null hypothesis, we declare the observed difference
    as statistically significant. Conversely, if the test *advises* accepting the
    null hypothesis, the difference is deemed statistically not significant. The results
    of a statistical test always come with a certain level of uncertainty and probability.
    Thus, a decision to reject the null hypothesis is likely correct but may also
    be incorrect. Assessing the risk of making an error is known as the **significance
    level** of the test.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须做出决定，是接受还是拒绝零假设。为了做出这个决定，我们使用显著性测试来分析我们的数据。如果测试*建议*拒绝零假设，我们宣布观察到的差异在统计上是有意义的。相反，如果测试*建议*接受零假设，则认为差异在统计上不显著。统计测试的结果总是伴随着一定的不确定性和概率。因此，拒绝零假设的决定可能是正确的，但也可能是错误的。评估犯错误的概率被称为测试的**显著性水平**。
- en: This significance level, also known as the p-value, provides a quantitative
    estimate of the probability that the observed differences are due to chance. The
    **p-value** is a probability and can only assume values between 0 and 1\. A p-value
    approaching 0 indicates a low probability that the observed difference is due
    to chance. Researchers typically choose a significance level of 0.05 (5%) or 0.01
    (1%). In our case, we calculated a p-value of 1.03e-21, which is far below the
    chosen significance level. This suggests that the observed difference is statistically
    significant and not likely due to chance.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这个显著性水平，也称为p值，提供了观察到的差异是由于偶然性的概率的定量估计。**p值**是一个概率，只能取0到1之间的值。接近0的p值表示观察到的差异是由于偶然性的低概率。研究人员通常选择显著性水平为0.05（5%）或0.01（1%）。在我们的案例中，我们计算出的p值为1.03e-21，远低于所选的显著性水平。这表明观察到的差异在统计上是有意义的，并且不太可能是偶然的。
- en: After having seen the first example of linear regression that deals with continuous
    predictors, it is necessary to see how to deal with the case in which the type
    of predictors is different.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到了处理连续预测因子的第一个线性回归例子之后，有必要了解如何处理预测因子类型不同的情况。
- en: Making predictions with regression analysis in MATLAB
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MATLAB进行回归分析进行预测
- en: Having explored numerous instances of linear regression, we can confidently
    assert that we comprehend the underlying mechanisms of this statistical method.
    Non-linear regression is used to model the relationship between a dependent variable
    and one or more independent variables when the relationship is not linear. In
    contrast to linear regression, where the relationship is assumed to be a straight
    line, non-linear regression allows for more complex and flexible relationships
    between variables.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了众多线性回归实例之后，我们可以自信地断言我们已经理解了这种统计方法的内在机制。非线性回归用于在因变量和至少一个自变量之间的关系不是线性的情况下建模。与线性回归不同，线性回归假设关系是一条直线，而非线性回归允许变量之间有更复杂和灵活的关系。
- en: Up until now, we have exclusively employed continuous variables as predictors.
    However, what transpires when the predictors are categorical variables? No need
    to fret, as the fundamental principles of regression techniques remain unchanged.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直只使用连续变量作为预测因子。然而，当预测因子是分类变量时会发生什么呢？无需担心，因为回归技术的根本原则保持不变。
- en: Multiple linear regression with categorical predictor
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有分类预测因子的多元线性回归
- en: Categorical variables differ from numerical ones as they do not stem from measurement
    operations but rather from classification and comparison operations. Categorical
    variables can be categorized into nominal, dichotomous, or ordinal groups.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量与数值变量不同，因为它们不是来自测量操作，而是来自分类和比较操作。分类变量可以分为名义、二分或有序组。
- en: 'Now, let’s delve into a real-life scenario. Within a company, we have diligently
    gathered information on employee salaries, which are determined by their years
    of experience. Our objective is to construct a model that enables us to track
    the progression of an employee’s salary over time. We have categorized the employees
    into three types: Management, Technical Staff, and General Staff.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入一个现实生活中的场景。在一家公司中，我们已勤勉地收集了有关员工工资的信息，这些工资由他们的工作经验决定。我们的目标是构建一个模型，使我们能够跟踪员工工资随时间的变化。我们将员工分为三类：管理层、技术人员和一般员工。
- en: 'Let''s now see practically how to process the MATLAB code:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下如何实际处理 MATLAB 代码：
- en: 'To begin our analysis, we will import the relevant data from an Excel worksheet
    named `employees.xlsx` into MATLAB:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了开始我们的分析，我们将从名为`employees.xlsx`的 Excel 工作表中导入相关数据到 MATLAB：
- en: '[PRE19]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following results are printed:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下结果被打印出来：
- en: '[PRE20]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now we can check the type of the variable:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们可以检查变量的类型：
- en: '[PRE21]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: So, the variable is corrected and recognized by MATLAB.
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，变量已修正并被 MATLAB 识别。
- en: Now, it is time to create the regression model by applying the `fitlm()` function
    using `Salary` as the dependent variable, and `YearsExperience` and `LevelOfEmployee`
    as the independent variables. Given that `LevelOfEmployee` is a categorical variable
    with three levels (`Management`, `TechnicalStaff`, and `GeneralStaff`), it is
    represented in the model as two indicator variables. In MATLAB, categorical predictors
    are typically included as dummy indicator variables. An indicator variable takes
    on values of 0 or 1\. For a categorical variable with *n* categories, it can be
    represented by *n – 1* indicator variables.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候通过使用`fitlm()`函数，以`Salary`作为因变量，以`YearsExperience`和`LevelOfEmployee`作为自变量来创建回归模型了。鉴于`LevelOfEmployee`是一个有三个级别（`Management`、`TechnicalStaff`和`GeneralStaff`）的分类变量，它在模型中以两个指示变量表示。在
    MATLAB 中，分类预测通常作为虚拟指示变量包括。指示变量取值为 0 或 1。对于一个有 *n* 个类别的分类变量，它可以由 *n – 1* 个指示变量表示。
- en: 'To account for the distinctions between the different employee types, we can
    incorporate interaction terms between `YearsExperience` and `LevelOfEmployee`.
    This allows us to capture the interaction effects between years of experience
    and the specific employee category:'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了考虑不同员工类型之间的区别，我们可以在`YearsExperience`和`LevelOfEmployee`之间加入交互项。这使我们能够捕捉到工作经验和特定员工类别之间的交互效应：
- en: '[PRE22]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let’s see the characteristics of the model:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们看看模型的特点：
- en: '![Figure 3.4 – Regression model summary](img/B21156_03_04.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.4 – 回归模型摘要](img/B21156_03_04.jpg)'
- en: Figure 3.4 – Regression model summary
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – 回归模型摘要
- en: 'Based on the results, the model equation is as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 根据结果，模型方程如下：
- en: '[PRE23]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this equation, the term `LevelOfEmployee(GeneralStaff)` is not included because
    the first level, by default, serves as the reference group. However, the first-order
    terms for `YearsExperience` and `LevelOfEmployee`, along with all the interactions,
    are present.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，`LevelOfEmployee(GeneralStaff)`这一项没有包括，因为默认情况下，第一级作为参考组。然而，`YearsExperience`和`LevelOfEmployee`的一阶项以及所有交互项都是存在的。
- en: 'It is apparent that a single equation for the entire system is insufficient
    to obtain accurate wage estimates. To address this, we need to differentiate between
    the three categories of employees and create separate models for each. Consequently,
    we obtain the following three equations to capture the wage dynamics for each
    employee category:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，一个适用于整个系统的单一方程式不足以获得准确的工资估计。为了解决这个问题，我们需要区分三种员工类别，并为每个类别创建单独的模型。因此，我们得到以下三个方程式来捕捉每个员工类别的工资动态：
- en: '[PRE24]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: From a simple comparison between the three equations we have just seen, we can
    see that the intercept progressively increases with the category of employees
    (`20.2;20.2 + 10.4; 20.2 + 30.2`); this shifts the regression line upward. Similarly,
    the slope also progressively increases with the employee category (`0.25 ; 0.25
    + 0.24; 0.25 + 0.49`), leading to a greater increase in salary as the number of
    years of experience increases.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们刚刚看到的三个方程式的简单比较中，我们可以看出，截距随着员工类别（`20.2;20.2 + 10.4; 20.2 + 30.2`）的增加而逐渐增加；这使回归线向上移动。同样，斜率也随着员工类别的增加而逐渐增加（`0.25
    ; 0.25 + 0.24; 0.25 + 0.49`），随着工作经验年数的增加，工资的增长也更大。
- en: 'To enhance our understanding of the progress made thus far, let’s incorporate
    the following lines into the scatter plot of the data:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了增强我们对迄今为止所取得进展的理解，让我们将以下行添加到数据的散点图中：
- en: '[PRE25]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The results are shown in *Figure 3**.5*.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示在*图 3.5*中。
- en: In the previously suggested code, we first created a linearly spaced vector
    between the minimum and maximum values of the `YearsExperience` variable using
    the `linspace()` function. Subsequently, we generated a scatter plot depicting
    the relationship between employee salaries (`Salary`) and years of experience
    (`YearsExperience`), with the data points grouped by the level of employee (`LevelOfEmployee`).
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在之前建议的代码中，我们首先使用`linspace()`函数在`YearsExperience`变量的最小值和最大值之间创建一个线性间隔的向量。随后，我们生成一个散点图，展示了员工工资（`Salary`）与工作经验年数（`YearsExperience`）之间的关系，数据点按员工级别（`LevelOfEmployee`）分组。
- en: '![Figure 3.5 – Scatter plot with the three straight lines that fit three data
    groups](img/B21156_03_05.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – 适合三个数据组的散点图，包含三条直线](img/B21156_03_05.jpg)'
- en: Figure 3.5 – Scatter plot with the three straight lines that fit three data
    groups
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 适合三个数据组的散点图，包含三条直线
- en: Finally, we added the three lines representing the respective trends for each
    employee category. This was accomplished by utilizing the `feval()` function to
    evaluate the model at the specified points in the `Xvalues` variable. It is now
    evident that the three straight lines, corresponding to the three equations, are
    distinguished by both their intercepts and slopes.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们添加了代表每个员工类别相应趋势的三条线。这是通过利用`feval()`函数在`Xvalues`变量中指定的点来评估模型实现的。现在很明显，对应于三个方程的三条直线，它们在截距和斜率上都有所区别。
- en: After having analyzed two regression examples in detail, we can see how to evaluate
    the performance of the models created so far.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细分析了两个回归示例之后，我们可以看到如何评估迄今为止创建的模型的表现。
- en: Evaluating model performance
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: '**Model performance** refers to how well a model fits the given data and accurately
    predicts outcomes. It is important to evaluate model performance to assess its
    reliability and effectiveness in making predictions or in capturing the underlying
    patterns in the data. One commonly used metric to evaluate model performance is
    the R-squared value, also known as the coefficient of determination. R-squared
    measures the proportion of the variance in the dependent variable that can be
    explained by the independent variables in the model. A higher R-squared value
    indicates a better fit, as it means a larger proportion of the variability in
    the data is accounted for by the model.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型性能**指的是模型与给定数据的拟合程度以及准确预测结果的能力。评估模型性能对于评估其预测的可靠性和有效性至关重要。评估模型性能的一个常用指标是R-squared值，也称为确定系数。R-squared衡量了模型中自变量可以解释的因变量变差的比例。R-squared值越高，表示拟合度越好，因为它意味着数据变异性中有更大比例被模型解释。'
- en: However, R-squared alone may not provide a complete picture of model performance.
    Other metrics, such as **mean squared error** (**MSE**) or **mean absolute error**
    (**MAE**), can be used to assess the average prediction error of the model. Lower
    values of MSE or MAE indicate better predictive performance. Furthermore, it is
    important to consider the context and specific requirements of the problem at
    hand. For example, if the residuals (the differences between the predicted and
    actual values) exhibit certain patterns or non-random behavior, it may indicate
    that the model is missing important factors or violating assumptions.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅R-squared可能无法提供模型性能的完整图景。其他指标，如**均方误差**（**MSE**）或**平均绝对误差**（**MAE**），可以用来评估模型的平均预测误差。MSE或MAE的值越低，表示预测性能越好。此外，考虑问题的具体背景和需求也很重要。例如，如果残差（预测值与实际值之间的差异）表现出某些模式或非随机行为，这可能表明模型遗漏了重要因素或违反了假设。
- en: Additionally, cross-validation techniques can be used to further evaluate the
    model’s performance by assessing its ability to generalize to new, unseen data.
    This helps to ensure that the model is not overfitting the training data and can
    make accurate predictions on new observations. In summary, model performance is
    assessed through various metrics, including R-squared, MSE, MAE, and consideration
    of the residuals and cross-validation results. Evaluating these aspects provides
    a comprehensive understanding of how well the model performs and its suitability
    for the given task.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，可以通过交叉验证技术进一步评估模型性能，通过评估其对新、未见数据的泛化能力。这有助于确保模型没有过度拟合训练数据，并且可以在新的观测上做出准确的预测。总之，模型性能通过各种指标进行评估，包括
    R 平方、MSE、MAE，以及残差和交叉验证结果。评估这些方面提供了对模型性能及其对给定任务适用性的全面理解。
- en: In the next example, we will exploit the evaluation metrics to improve the performance
    of the model by identifying the outliers.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，我们将利用评估指标通过识别异常值来提高模型的性能。
- en: Reducing outlier effects
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少异常值的影响
- en: As mentioned earlier, the `fitlm()` function generates a `LinearModel` object
    that contains valuable information about the linear regression, including training
    data, model description, diagnostic details, and estimated coefficients. Now,
    we can utilize some of these properties to gain additional insights from the model.
    The least-squares method is commonly employed when we have sufficient knowledge
    about the model’s shape and aim to determine its parameters. It is also useful
    for model exploration.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`fitlm()` 函数生成一个包含有关线性回归的宝贵信息的 `LinearModel` 对象，包括训练数据、模型描述、诊断细节和估计系数。现在，我们可以利用这些属性从模型中获得更多见解。当我们对模型的形状有足够的了解并旨在确定其参数时，通常采用最小二乘法。它也适用于模型探索。
- en: 'However, this method requires manual inspection of the data to identify and
    handle outliers. Therefore, we will now examine whether there are any outliers
    in the data that should be excluded from the fitting process. Residual plots can
    aid us in this analysis. The most used plots include the default histogram plot,
    which displays the range and frequencies of the residuals, and the probability
    plot, which compares the distribution of the residuals to a normal distribution
    with a similar variance:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法需要手动检查数据以识别和处理异常值。因此，我们现在将检查数据中是否存在任何应该从拟合过程中排除的异常值。残差图可以帮助我们进行这种分析。最常用的图包括默认的直方图，它显示残差的范围和频率，以及概率图，它将残差的分布与具有相似方差的正态分布进行比较：
- en: 'We start as usual by importing the data:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们像往常一样开始导入数据：
- en: '[PRE26]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Now, we can work on the evaluation of the model.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以开始对模型进行评估。
- en: 'To start, we extract some different evaluation metrics of the model:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们提取模型的一些不同评估指标：
- en: '[PRE27]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The following results are returned:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下结果将被返回：
- en: '[PRE28]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: MSE quantifies the mean squared disparity between the model’s predicted values
    and the actual observed values. The MSE is calculated by taking the average of
    the squared differences between the predicted values and the true values over
    the entire dataset.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MSE 量化了模型预测值与实际观测值之间平均平方差异。MSE 通过在整个数据集上取预测值与真实值之间平方差的平均值来计算。
- en: The R-squared and MSE values obtained will be used to compare the performance
    of the different models.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 获得的 R 平方和 MSE 值将被用来比较不同模型的性能。
- en: 'To show how residual plots are useful for identifying outliers, we will refer
    to the example used in the *Linear regression model in MATLAB* section. We will
    use the same model (`LRModel`). To visualize the residuals, we will utilize a
    specific property of the `LinearModel` object:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了说明残差图如何有助于识别异常值，我们将参考 *MATLAB 中的线性回归模型* 部分中使用的示例。我们将使用相同的模型 (`LRModel`)。为了可视化残差，我们将利用
    `LinearModel` 对象的特定属性：
- en: '[PRE29]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Upon analyzing the histogram obtained, a distinct asymmetry is evident in the
    negative values. Specifically, the observations near `-2 *105` appear to be potential
    outliers. To achieve a more accurate fit, we will construct a probability plot.
    As previously mentioned, the plot in *Figure 3**.6* demonstrates the comparison
    between the distribution of residuals and a normal distribution with similar variance.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在分析获得的直方图时，负值中存在明显的非对称性。具体来说，接近 `-2 *105` 的观测值似乎是有潜在异常值的。为了实现更准确的拟合，我们将构建一个概率图。如前所述，*图
    3**.6* 中的图显示了残差分布与具有相似方差的正态分布的比较。
- en: The probability plot of residuals also reveals potential outliers, particularly
    in the lower left region. We can observe three values that significantly deviate
    from the dotted line. On the other hand, the probability plot appears reasonably
    linear for the remaining residual values, indicating a reasonable fit to normally
    distributed residuals.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 残差的概率图也揭示了潜在的异常值，尤其是在左下区域。我们可以观察到三个显著偏离虚线的值。另一方面，对于剩余的残差值，概率图看起来合理线性，表明对正态分布残差的拟合是合理的。
- en: '![Figure 3.6 – Histogram of residuals and probability plot of residuals for
    the linear regression model](img/B21156_03_06.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.6 – 线性回归模型的残差直方图和残差概率图](img/B21156_03_06.jpg)'
- en: Figure 3.6 – Histogram of residuals and probability plot of residuals for the
    linear regression model
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 – 线性回归模型的残差直方图和残差概率图
- en: 'We can identify these outliers and proceed to remove them from the dataset.
    To locate them, we can utilize the `find()` function, examining values to the
    left of the abscissa equal to `-1.5*105`:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以识别这些异常值，并继续从数据集中移除它们。为了定位它们，我们可以利用 `find()` 函数，检查等于 `-1.5*105` 的横坐标左侧的值：
- en: '[PRE30]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The following results are returned:'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下结果被返回：
- en: '[PRE31]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Currently, we have the outliers detected in the data.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前，我们已经检测到数据中的异常值。
- en: 'Now, at this stage, we can proceed to create the model once again, this time
    excluding the aforementioned outlier values:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在这个阶段，我们可以再次创建模型，这次排除上述异常值：
- en: '[PRE32]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following values are printed:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下值将被打印：
- en: '[PRE33]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The model’s performance has noticeably improved, as indicated by the increased
    R-squared value of `0.997` compared to the previous model’s R-squared value of
    `0.994`. This improvement suggests that the new model provides a better fit to
    the data. Now we will extract the MSE:'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型的性能明显提高，这从与先前模型相比增加的 R 平方值 `0.997` 可以看出，先前模型的 R 平方值为 `0.994`。这种改进表明新模型更好地拟合了数据。现在我们将提取
    MSE：
- en: '[PRE34]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: From a comparison, we can see an improvement; the MSE decreased from `1.3407e+10`
    to `6.8047e+09`.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过比较，我们可以看到有所改进；均方误差（MSE）从 `1.3407e+10` 降低到 `6.8047e+09`。
- en: To further evaluate the model’s performance, we can assess other metrics, such
    as the MSE or MAE. Additionally, conducting cross-validation or assessing the
    residuals’ distribution and patterns can provide further insights into the model’s
    effectiveness.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步评估模型的性能，我们可以评估其他指标，如 MSE 或 MAE。此外，进行交叉验证或评估残差的分布和模式可以进一步了解模型的有效性。
- en: Having discussed the utilization of evaluation metrics to enhance model performance,
    it is now opportune to delve into these methodologies and strive toward constructing
    increasingly effective models. By employing these techniques, we aim to improve
    the overall performance and predictive capabilities of our models.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论了使用评估指标来提高模型性能之后，现在是深入探讨这些方法并努力构建越来越有效的模型的好时机。通过采用这些技术，我们旨在提高我们模型的总体性能和预测能力。
- en: Using advanced techniques for model evaluation and selection in MATLAB
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MATLAB 中的高级模型评估和选择技术
- en: Model evaluation and selection are crucial steps in machine learning to ensure
    the chosen model performs well on unseen data and generalizes effectively. When
    it comes to advanced techniques for model evaluation and selection in MATLAB,
    there are several approaches you can consider.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估和选择是机器学习中的关键步骤，以确保所选模型在未见过的数据上表现良好，并且能够有效泛化。当涉及到 MATLAB 中的高级模型评估和选择技术时，有几种方法可以考虑。
- en: In the subsequent sub-section, we will take a look at the most important techniques
    for model evaluation and selection.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的子节中，我们将探讨模型评估和选择的最重要技术。
- en: Understanding k-fold cross-validation
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 k 折交叉验证
- en: '**K-fold cross-validation** is a widely used technique for model evaluation
    and selection. It involves partitioning the dataset into *k* equally sized subsets
    or folds. The model undergoes training and assessment in *k* iterations, with
    each iteration employing a distinct fold as the validation set while using the
    remaining folds as the training set. The outcomes of each iteration are then averaged
    to derive a comprehensive performance estimation. This is the essence of how k-fold
    cross-validation operates:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '**K 折交叉验证**是一种广泛使用的模型评估和选择技术。它涉及将数据集划分为 *k* 个大小相等的子集或折。模型在 *k* 次迭代中进行训练和评估，每次迭代使用一个不同的折作为验证集，而使用剩余的折作为训练集。然后，将每次迭代的结果平均，以得出全面的性能估计。这就是
    k 折交叉验证运作的本质：'
- en: '**Splitting the dataset**: Partition the dataset into *k* non-overlapping folds.
    Generally, the value of *k* falls within the range of 5 to 10, although it can
    be adjusted based on factors such as dataset size and complexity.'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分割数据集**：将数据集划分为*k*个非重叠折。通常，*k*的值在5到10之间，尽管可以根据数据集大小和复杂度等因素进行调整。'
- en: '**Training and evaluating the model**: This entails a repetitive process repeated
    *k* times. Within each iteration, the model is trained using *k – 1* folds and
    subsequently assessed for its performance on the remaining fold.'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练和评估模型**：这涉及重复进行的过程，重复*k*次。在每次迭代中，使用*k – 1*个折来训练模型，然后评估其在剩余折上的性能。'
- en: '**Performance metric aggregation**: Calculate the performance metric of interest
    for each iteration. The metrics from all iterations are then averaged to obtain
    a robust estimation of the model’s performance.'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**性能指标聚合**：计算每个迭代中感兴趣的性能指标。然后对所有迭代的指标进行平均，以获得对模型性能的稳健估计。'
- en: '**Model selection**: Use the average performance metric to compare and select
    the best model among different algorithms or hyperparameter configurations.'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型选择**：使用平均性能指标来比较和选择不同算法或超参数配置中表现最好的模型。'
- en: K-fold cross-validation helps address the limitations of single train-test splits
    by providing a more reliable estimate of a model’s performance. It helps assess
    how well the model generalizes to unseen data and reduces the risk of overfitting
    or underfitting. MATLAB provides built-in functions, such as `crossval()` and
    `cvpartition()`, to facilitate k-fold cross-validation. These functions automate
    the process and allow for easy implementation and evaluation of models using k-fold
    cross-validation.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: K折交叉验证有助于解决单次训练-测试分割的局限性，通过提供对模型性能的更可靠估计。它有助于评估模型对未见数据的泛化能力，并降低过拟合或欠拟合的风险。MATLAB提供了内置函数，如`crossval()`和`cvpartition()`，以简化k折交叉验证的过程。这些函数自动化了过程，并允许使用k折交叉验证轻松实现和评估模型。
- en: 'Let''s see how we can practically approach a k-fold cross-validation:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何实际进行k折交叉验证：
- en: 'To understand the use of cross-validation, we employ a NASA dataset derived
    from a sequence of aerodynamic and acoustic experiments conducted in an anechoic
    wind tunnel. The dataset comprises several fields, including the following:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了理解交叉验证的使用，我们使用了一个NASA数据集，该数据集来自一系列在消声风洞中进行的空气动力学和声学实验。该数据集包括以下几个字段：
- en: Frequency, in Hertz (named `FreqH`).
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率，以赫兹为单位（命名为`FreqH`）。
- en: Angle of attack, in degrees (named `AngleD`).
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻角，以度为单位（命名为`AngleD`）。
- en: Chord length, in meters (named `ChLenM`).
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弦长，以米为单位（命名为`ChLenM`）。
- en: Free-stream velocity, in meters per second (named `FStVelMs`).
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自由流速度，以米每秒为单位（命名为`FStVelMs`）。
- en: Suction side displacement thickness, in meters (named `SucSDTM`).
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吸入侧位移厚度，以米为单位（命名为`SucSDTM`）。
- en: Scaled sound pressure level, in decibels (named `SPLdB`).
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较声压级，以分贝为单位（命名为`SPLdB`）。
- en: 'As usual, we start importing the dataset into the MATLAB environment:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如往常一样，我们开始将数据集导入MATLAB环境：
- en: '[PRE35]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: So, data is now available in the MATLAB workspace. To apply cross-validation
    in our model, we can use the apps available in the MATLAB environment, for example,
    the Regression Learner app. This app facilitates a streamlined and efficient process
    for conducting step-by-step regression analysis. With this app, importing and
    exploring data, selecting features, defining validation schemes, training models,
    and evaluating results becomes remarkably straightforward and swift. The app offers
    automated training functionality, enabling the search for the optimal regression
    model type. It includes options such as linear regression models, regression trees,
    Gaussian process regression models, support vector regression, and an ensemble
    of regression trees. Additionally, the trained model can be exported to the workspace
    for reuse with new data or to generate MATLAB code for programmatic regression.
    By leveraging the Regression Learner app, users can save time and effort in performing
    regression analysis, benefiting from its intuitive interface and powerful features.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，数据现在已可在 MATLAB 工作空间中。要在我们的模型中应用交叉验证，我们可以使用 MATLAB 环境中可用的应用程序，例如回归学习器应用程序。此应用程序简化并提高了逐步回归分析的过程。使用此应用程序，导入和探索数据、选择特征、定义验证方案、训练模型和评估结果变得非常简单快捷。应用程序提供自动训练功能，能够搜索最佳回归模型类型。它包括线性回归模型、回归树、高斯过程回归模型、支持向量回归以及回归树的集成。此外，训练好的模型可以导出到工作空间，以便与新数据一起重用或生成用于程序化回归的
    MATLAB 代码。通过利用回归学习器应用程序，用户可以在执行回归分析时节省时间和精力，并从其直观界面和强大功能中受益。
- en: 'To open the app, select the **APPS** tab on the MATLAB toolstrip, and click
    on the **Regression Learner** icon. The Regression Learner app window will open,
    as shown in the following figure:'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要打开应用程序，请在 MATLAB 工具栏中选择 **APPS** 选项卡，然后单击 **回归学习器** 图标。回归学习器应用程序窗口将打开，如图所示：
- en: '![Figure 3.7 – Regression Learner app window](img/B21156_03_07.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.7 – 回归学习器应用程序窗口](img/B21156_03_07.jpg)'
- en: Figure 3.7 – Regression Learner app window
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7 – 回归学习器应用程序窗口
- en: 'To import data from the MATLAB workspace into the Regression Learner app, follow
    these steps:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据从 MATLAB 工作空间导入到回归学习器应用程序中，请按照以下步骤操作：
- en: Open the Regression Learner app by clicking on the **New Session** button located
    in the **File** section of the **Regression** **Learner** tab.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过单击位于 **回归学习器** 选项卡 **文件** 部分的 **新会话** 按钮来打开回归学习器应用程序。
- en: 'The **New Session** dialog box will appear, containing three sections:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将出现 **新会话** 对话框，包含三个部分：
- en: '*Step 1*: Select a table or matrix. In this section, choose the source of your
    data. You can select a table or a matrix containing the data you want to analyze.'
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*步骤 1*：选择一个表格或矩阵。在本节中，选择数据来源。您可以选择包含要分析数据的表格或矩阵。'
- en: '*Step 2*: Select predictors and a response. In this section, specify the variables
    that will serve as predictors and the variable that will be the response variable.
    This allows you to define the type of variables involved in the analysis. In this
    case, we can select **SPLdB** as the response and the other variables as predictors.'
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*步骤 2*：选择预测变量和响应变量。在本节中，指定将作为预测变量的变量以及作为响应变量的变量。这允许您定义分析中涉及的变量类型。在这种情况下，我们可以选择
    **SPLdB** 作为响应变量，其他变量作为预测变量。'
- en: '*Step 3*: Define a validation method. In this section, you can choose the type
    of validation method to evaluate the predictive accuracy of the fitted models.
    Different validation methods, such as cross-validation or holdout validation,
    can be selected to estimate model performance on new data.'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*步骤 3*：定义验证方法。在本节中，您可以选择用于评估拟合模型预测准确性的验证方法类型。可以选择不同的验证方法，如交叉验证或保留验证，以估计模型在新数据上的性能。'
- en: Validation methods play a crucial role in assessing how well the fitted models
    can make accurate predictions on unseen data. The Regression Learner app provides
    tools to evaluate and compare models based on their estimated performance, enabling
    the selection of the best model for the given data.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 验证方法在评估拟合模型在未见数据上做出准确预测的能力方面发挥着至关重要的作用。回归学习器应用程序提供工具来评估和比较模型，基于它们的估计性能，以便为给定数据选择最佳模型。
- en: We will choose `5` by default), then we can press the **Start** **Session**
    button.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将默认选择 `5`（然后我们可以按下 **开始会话** 按钮）。
- en: 'To select the desired model type in the Regression Learner app, follow these
    steps:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在回归学习器应用程序中选择所需的模型类型，请按照以下步骤操作：
- en: Expand the **Model Type** section by clicking on the arrow icon present in the
    app.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击应用中存在的箭头图标来展开**模型类型**部分。
- en: 'A list of available regression models will be displayed, including the following:'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将显示可用的回归模型列表，包括以下内容：
- en: '**Linear** **regression models**'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性** **回归模型**'
- en: '**Regression trees**'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归树**'
- en: '**SVMs**'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVMs**）'
- en: '**Gaussian process** **regression models**'
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高斯过程** **回归模型**'
- en: '**Ensembles** **of trees**'
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成** **树**'
- en: To get started, select the **All Quick-To-Train** option. This option allows
    you to select all the models available for this type of problem, so it will be
    possible to train the models using default settings quickly.
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始，请选择**全部快速训练**选项。此选项允许您选择适用于此类问题的所有模型，因此可以快速使用默认设置训练模型。
- en: Click on the **Train** icon to initiate the training process. The app will start
    training the selected models, and a selection of model types will appear in the
    **History** section.
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**训练**图标以启动训练过程。应用将开始训练所选模型，并在**历史记录**部分显示所选模型类型。
- en: Once the models finish training, the best RMSE score will be highlighted in
    a box. This score indicates the model’s performance.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练完成后，最佳RMSE分数将在一个框中突出显示。这个分数表示模型的性能。
- en: To further improve the model’s performance, you can try training with all available
    algorithms. Click on **All** and then click **Train**.
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了进一步提高模型性能，您可以尝试使用所有可用的算法进行训练。点击**全部**，然后点击**训练**。
- en: By comparing the results in the **History** section, you can observe the RMSE
    scores for each model. The lower RMSE score represents better performance. In
    the example provided, the Gaussian process regression model achieved the *lowest
    RMSE score (RMSE = 1.49)*, while the boosted trees model obtained the *highest
    RMSE score (RMSE =* *6.18)*.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过比较**历史记录**部分的结果，您可以观察到每个模型的RMSE分数。较低的RMSE分数表示更好的性能。在提供的示例中，高斯过程回归模型实现了*最低的RMSE分数（RMSE
    = 1.49*），而提升树模型获得了*最高的RMSE分数（RMSE = 6.18*）。
- en: To assess the improvements obtained, you can compare the predicted versus actual
    plots for the extreme models. In the model with the lowest RMSE, the data points
    should closely align with the reference line, indicating a close match between
    the predicted and actual data.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了评估获得的改进，您可以比较极端模型的预测值与实际值的对比图。在RMSE最低的模型中，数据点应与参考线紧密对齐，表明预测数据和实际数据之间的匹配非常接近。
- en: Overall, the Regression Learner app provides a visual representation of the
    results, allowing you to easily compare and analyze the performance of different
    models. Let’s see another way to select the data.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，回归学习器应用提供了结果的视觉表示，使您能够轻松比较和分析不同模型的性能。让我们看看另一种选择数据的方法。
- en: Exploring leave-one-out cross-validation
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索留一法交叉验证
- en: '**Leave-one-out cross-validation** (**LOOCV**) is a specific type of cross-validation
    technique used for model evaluation. In LOOCV, each data point is sequentially
    held out as the validation set while the rest of the data is used for training
    the model. This process is repeated for all data points, and the performance of
    the model is evaluated by averaging the results across all iterations. The LOOCV
    technique works in the following way:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**留一法交叉验证**（**LOOCV**）是一种用于模型评估的特定交叉验证技术。在LOOCV中，每个数据点依次被排除作为验证集，其余数据用于训练模型。这个过程对所有数据点重复进行，通过平均所有迭代的成果来评估模型的性能。LOOCV技术的工作方式如下：'
- en: 'For each data point in the dataset, do the following:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于数据集中的每个数据点，执行以下操作：
- en: Remove the data point from the training set
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从训练集中移除数据点
- en: Train the model using the remaining data points
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用剩余的数据点训练模型
- en: Use the trained model to predict the removed data point
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练好的模型来预测移除的数据点
- en: Evaluate the performance of the model by comparing the predicted value with
    the actual value of the removed data point
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过比较预测值与移除数据点的实际值来评估模型的性能
- en: Calculate the performance metric (such as MSE or accuracy) for each iteration.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个迭代的性能指标（如均方误差或准确率）。
- en: Compute the average performance metric across all iterations to obtain an overall
    estimation of the model’s performance.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有迭代的平均性能指标，以获得模型性能的整体估计。
- en: LOOCV is particularly useful when the dataset is small or when there is a limited
    amount of data available. Since each data point serves as a validation set once,
    LOOCV provides a more reliable estimate of the model’s performance compared to
    other cross-validation techniques. It is worth mentioning that this technique
    is good for small datasets, as it is difficult to judge its variance error as
    the data points are almost the same for each fold; it just means one new record
    in each fold.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: LOOCV（留一法交叉验证）在数据集较小或可用数据有限时特别有用。由于每个数据点都作为一次验证集，因此LOOCV比其他交叉验证技术提供了对模型性能的更可靠估计。值得注意的是，这种方法适用于小数据集，因为很难判断其方差误差，因为每个折叠中的数据点几乎相同；这只意味着每个折叠中有一个新的记录。
- en: In MATLAB, you can use the `cvpartition()` function with the `LeaveOut` option
    to generate indices for performing LOOCV. These indices can then be used to partition
    the data for training and validation purposes in a loop.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在MATLAB中，您可以使用带有`LeaveOut`选项的`cvpartition()`函数来生成执行LOOCV的索引。然后，可以使用这些索引在循环中用于训练和验证目的的数据分区。
- en: Now, we will introduce the bootstrap method.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将介绍自助方法。
- en: Introducing the bootstrap method
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍自助方法
- en: The bootstrap method is a resampling technique used for estimating the sampling
    distribution of a statistic. This process entails generating multiple bootstrap
    samples by randomly selecting data points from the original dataset with replacement,
    from which estimates of the statistic can be obtained. This method allows us to
    assess the variability and uncertainty associated with the statistic of interest.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 自助方法是用于估计统计量抽样分布的重新抽样技术。这个过程涉及通过有放回地从原始数据集中随机选择数据点来生成多个自助样本，从而可以获得统计量的估计。这种方法使我们能够评估与所关注的统计量相关的变异性和不稳定性。
- en: 'The bootstrap algorithm provides the following steps:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 自助算法包括以下步骤：
- en: Start with an original dataset of size *N*.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从大小为*N*的原始数据集开始。
- en: Randomly sample *N* data points from the original dataset with replacement to
    create a bootstrap sample. This means that each data point in the bootstrap sample
    is selected independently, and it is possible to select the same data point multiple
    times.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从原始数据集中随机抽取*N*个数据点进行有放回抽样以创建自助样本。这意味着自助样本中的每个数据点都是独立选择的，并且可能多次选择相同的数据点。
- en: Compute the desired statistic on the bootstrap sample. This could be the mean,
    median, standard deviation, or any other statistic of interest.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在自助样本上计算所需的统计量。这可能包括均值、中位数、标准差或其他感兴趣的任何统计量。
- en: Repeat *steps 2* and *3* a number of times equal to *B*, where *B* is the number
    of bootstrap iterations desired.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2和步骤3，次数等于*B*，其中*B*是所需的自助迭代次数。
- en: Collect the computed statistics from each bootstrap sample to create the bootstrap
    distribution.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每个自助样本中收集计算出的统计数据以创建自助分布。
- en: Calculate the desired confidence intervals or standard errors based on the bootstrap
    distribution to quantify the uncertainty around the statistic.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据自助分布计算所需的置信区间或标准误差，以量化统计量周围的不确定性。
- en: The bootstrap method provides a robust approach for estimating the sampling
    distribution when the underlying distribution of the data is unknown or when analytical
    methods are not readily available. It can be used for various purposes, such as
    hypothesis testing, constructing confidence intervals, and assessing model stability.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据的基础分布未知或分析方法不易获得时，自助方法为估计抽样分布提供了一种稳健的方法。它可以用于各种目的，例如假设检验、构建置信区间和评估模型稳定性。
- en: The bootstrap method holds significance as it enables the estimation of a model’s
    performance attributes, encompassing measures such as central tendency and uncertainty,
    all without requiring stringent assumptions about the underlying data distribution.
    This method enhances the reliability and robustness of assessing a model’s performance,
    particularly in scenarios where data is scarce or the data distribution remains
    poorly defined.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 自助方法的重要性在于它能够估计模型性能属性，包括诸如集中趋势和不确定性等度量，而无需对底层数据分布做出严格假设。这种方法增强了评估模型性能的可靠性和鲁棒性，尤其是在数据稀缺或数据分布定义不明确的情况下。
- en: Summary
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have gained valuable insights into performing accurate classification
    tasks within the MATLAB environment. We began by delving into the realm of decision
    tree methods, where we familiarized ourselves with key concepts such as nodes,
    branches, and leaf nodes. By repeatedly dividing records into homogeneous subsets
    based on the target attribute, we learned how to classify objects into distinct
    classes effectively. Moreover, we explored the prediction aspect of SVMs, which
    are particularly effective in solving complex problems with a clear margin of
    separation between classes. SVMs can handle both linearly separable and non-linearly
    separable data by transforming the input space into a higher-dimensional feature
    space.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们获得了在MATLAB环境中执行准确分类任务的有价值见解。我们首先深入决策树方法的领域，熟悉了诸如节点、分支和叶节点等关键概念。通过根据目标属性反复将记录划分为同质子集，我们学会了如何有效地将对象分类到不同的类别中。此外，我们还探讨了SVMs的预测方面，SVMs在解决具有清晰类别分离边界的复杂问题时特别有效。SVMs可以通过将输入空间转换到更高维的特征空间来处理线性可分和非线性可分的数据。
- en: In the subsequent section, our focus shifted toward conducting precise regression
    analysis within the MATLAB environment. We commenced by delving into simple linear
    regression, gaining an understanding of its definition and the process of obtaining
    ordinary least squares estimation. Additionally, we explored multiple techniques
    for quantifying the intercept and slope of the linear relationship.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的部分，我们的重点转向了在MATLAB环境中进行精确回归分析。我们首先深入简单线性回归，了解了其定义和获得普通最小二乘估计的过程。此外，我们还探索了量化线性关系截距和斜率的多种技术。
- en: Subsequently, we unearthed the linear regression model builder, a valuable tool
    for constructing an object encompassing training data, model description, diagnostic
    information, and fitted coefficients necessary for linear regression. Furthermore,
    we familiarized ourselves with the correct interpretation of simulation results
    and grasped the techniques to mitigate the influence of outliers through robust
    regression.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们发现了线性回归模型构建器，这是一个构建包含训练数据、模型描述、诊断信息和线性回归所需的拟合系数的对象的有价值工具。此外，我们熟悉了正确解释模拟结果，并掌握了通过稳健回归减轻异常值影响的技术。
- en: Then, we understood how to use the tools available in MATLAB to perform an accurate
    evaluation of the model trained. Finally, we discovered the cross-validation methods
    to increase the performance of the model, finding the best-performing model.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们了解了如何使用MATLAB中可用的工具对训练好的模型进行准确评估。最后，我们发现交叉验证方法可以提升模型的性能，找到表现最佳的模型。
- en: In the next chapter, we will explore the clustering methodology to find hidden
    patterns or groupings in a dataset.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨聚类方法，以在数据集中找到隐藏的模式或分组。
