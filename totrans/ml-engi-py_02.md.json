["```py\nconda env create –f mlewp-chapter02.yml \n```", "```py\nconda env --name mleng python=3.10 \n```", "```py\nsource activate mleng \n```", "```py\nconda export env > environment.yml \n```", "```py\nconda env create --file environment.yml \n```", "```py\nconda install <package-name> \n```", "```py\npip install <package-name> \n```", "```py\n    pip install poetry \n    ```", "```py\n    poetry new mleng-with-python \n    ```", "```py\n    [tool.poetry.dependencies]\n    scikit-learn = \"*\" \n    ```", "```py\n    poetry install \n    ```", "```py\n    from sklearn import datasets\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LogisticRegression \n    ```", "```py\n    git clone <repo-name> \n    ```", "```py\n    git add README.md\n    git commit -m \"I've made a nice change …\" \n    ```", "```py\n    git push origin main \n    ```", "```py\n    git pull origin main \n    ```", "```py\ngit checkout -b pipeline1spark \n```", "```py\n# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(),\n                      outputCol=\"features\")\nlr = LogisticRegression(maxIter=10, regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr]) \n```", "```py\ngit push origin pipeline1spark \n```", "```py\ngit pull origin pipeline1spark\ngit checkout pipeline1spark\ngit checkout -b pipeline \n```", "```py\nlr = LogisticRegression(maxIter=model_config[\"maxIter\"], \n                        regParam=model_config[\"regParam\"]) \n```", "```py\ngit push origin pipeline \n```", "```py\nmain\npipeline1spark\npipeline \n```", "```py\n# Branch pipeline1spark - Commit 1 (Engineer A)\nlr = LogisticRegression(maxIter=10, regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n# Branch pipeline - Commit 2 (Engineer B)\nlr = LogisticRegression(maxIter=model_config[\"maxIter\"], \n                        regParam=model_config[\"regParam\"])\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr]) \n```", "```py\n<<<<<<< HEAD\nlr = LogisticRegression(maxIter=10, regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n=======\nlr = LogisticRegression(maxIter=model_config[\"maxIter\"], \n                        regParam=model_config[\"regParam\"])\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n>>>>>>> pipeline \n```", "```py\npip install mlflow \n```", "```py\n    import pandas as pd\n    from fbprophet import Prophet\n    from fbprophet.diagnostics import cross_validation\n    from fbprophet.diagnostics import performance_metrics\n    import mlflow\n    import mlflow.pyfunc \n    ```", "```py\n    class FbProphetWrapper(mlflow.pyfunc.PythonModel):\n        def __init__(self, model):\n            self.model = model\n            super().__init__()\n        def load_context(self, context):\n            from fbprophet import Prophet\n            return\n        def predict(self, context, model_input):\n            future = self.model.make_future_dataframe(\n                periods=model_input[\"periods\"][0])\n            return self.model.predict(future) \n    ```", "```py\n    with mlflow.start_run():\n        # Experiment code and mlflow logging goes in here \n    ```", "```py\n    # create Prophet model\n    model = Prophet(\n        yearly_seasonality=seasonality_params['yearly'],\n        weekly_seasonality=seasonality_params['weekly'],\n        daily_seasonality=seasonality_params['daily']\n    )\n    # train and predict\n    model.fit(df_train) \n    ```", "```py\n    # Evaluate Metrics\n    df_cv = cross_validation(model, initial=\"730 days\", \n                             period=\"180 days\", horizon=\"365 days\")\n    df_p = performance_metrics(df_cv) \n    ```", "```py\n    # Log parameter, metrics, and model to MLflow\n    mlflow.log_metric(\"rmse\", df_p.loc[0, \"rmse\"]) \n    ```", "```py\n    mlflow.pyfunc.log_model(\"model\", python_model=FbProphetWrapper(model))\n    print(\n        \"Logged model with URI: runs:/{run_id}/model\".format(\n            run_id=mlflow.active_run().info.run_id\n        )\n    ) \n    ```", "```py\ngit checkout –b feature/actions \n```", "```py\n    name: Python package\n    on: [push] \n    ```", "```py\n    jobs:\n      build:\n        runs-on: ubuntu-latest\n        strategy:\n          matrix:\n            python-version: [3.9, 3.10] \n    ```", "```py\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Python ${{ matrix.python-version }}\n    uses: actions/setup-python@v4\n    with:\n      python-version: ${{ matrix.python-version }} \n    ```", "```py\n    - name: Install dependencies\n    run: |\n      python -m pip install --upgrade pip\n      pip install flake8 pytest\n      if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n    - name: Lint with flake8 \n    ```", "```py\n    - name: Lint with flake8\n    run: |\n      # stop the build if there are Python syntax errors or undefined \n      names\n      flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n      # exit-zero treats all errors as warnings. The GitHub editor is \n      127 chars wide\n      flake8 . --count --exit-zero --max-complexity=10 --max-line-\n      length=127 --statistics \n    ```", "```py\n    - name: Test with pytest\n    run: pytest\n    working-directory: Chapter02 \n    ```", "```py\ngit add .github/workflows/github-actions-basic.yml\ngit commit –m \"Basic CI run with dummy test\"\ngit push origin feature/actions \n```", "```py\n@pytest.fixture\ndef test_dataset() -> Union[np.array, np.array]:\n    # Load the dataset\n    X, y = load_wine(return_X_y=True)\n    # create an array of True for 2 and False otherwise\n    y = y == 2\n    # Train and test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                        random_state=42)\n    return X_test, y_test \n```", "```py\n@pytest.fixture\ndef model() -> sklearn.ensemble._forest.RandomForestClassifier:\n    REPO_ID = \"electricweegie/mlewp-sklearn-wine\"\n    FILENAME = \"rfc.joblib\"\n    model = joblib.load(hf_hub_download(REPO_ID, FILENAME))\n    return model \n```", "```py\ndef test_model_inference_types(model, test_dataset):\n    assert isinstance(model.predict(test_dataset[0]), np.ndarray)\n    assert isinstance(test_dataset[0], np.ndarray)\n    assert isinstance(test_dataset[1], np.ndarray) \n```", "```py\ndef test_model_performance(model, test_dataset):\n    metrics = classification_report(y_true=test_dataset[1], \n                                    y_pred=model.predict(test_dataset[0]),\n                                    output_dict=True)\n    assert metrics['False']['f1-score'] > 0.95\n    assert metrics['False']['precision'] > 0.9\n    assert metrics['True']['f1-score'] > 0.8\n    assert metrics['True']['precision'] > 0.8 \n```", "```py\nname: Continous Training Example\non: [pull_request] \n```", "```py\njobs:\n  deploy-trainer \n    runs-on: [ubuntu-latest]\n    steps:\n    - name: Checkout       uses: actions/checkout@v3\n    - name: Configure AWS Credentials\n      uses: aws-actions/configure-aws-credentials@v2\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n        aws-region: us-east-2\n        role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}\n        role-external-id: ${{ secrets.AWS_ROLE_EXTERNAL_ID }}\n        role-duration-seconds: 1200\n        role-session-name: TrainingSession \n```", "```py\n - name: Copy files to target destination\n    run: aws s3 sync . s3://<S3-BUCKET-NAME> \n```", "```py\n - name: Run training job\n       run: |\n        # Your bespoke run commands go in here using the tools of your choice! \n```"]