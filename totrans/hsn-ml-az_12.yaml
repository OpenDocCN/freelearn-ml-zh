- en: End-to-End Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn about the new capabilities that were launched
    with the Azure Machine Learning service that can help data scientists and AI developers
    with **end-to-end** (**E2E**) machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: When developing AI applications, we can use cognitive services, as described
    in [Chapter 3](89299379-0f5e-4602-ad78-9d3d46a0710e.xhtml), *Cognitive Services*.
    Alternatively, we can create custom machine learning models with our own data,
    because cognitive services won't work in every possible scenario. In cases such
    as these, we have to train our own machine learning algorithms. The Azure Machine
    Learning service has an SDK, CLI, and APIs that can help you to create these custom
    models.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to learn how to use the Azure Machine Learning
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Using the Azure Machine Learning SDK for E2E machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As shown in the following diagram, the first step in E2E machine learning is **data
    preparation**, which includes cleaning the data and featurization. Then, we have
    to create and train a machine learning model in the  **m****odel training **step.
    After that, we have **m****odel deployment**, which means deploying the model
    as a web service to perform predictions. The final step is **m****onitoring**, which
    includes analyzing how the model is performing and then triggering the retraining
    of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9fe50b26-c95f-4730-aac1-617edb56ca73.png)'
  prefs: []
  type: TYPE_IMG
- en: The Azure ML SDK enables professional data scientists and DevOps engineers to
    carry out E2E machine learning. It allows us to seamlessly use the power of the
    cloud to train and deploy our model. We can start using the Azure ML SDK easily
    by installing it using `pip` in any Python environment. We can scale the compute
    for training by using a cluster of CPUs or GPUs. We can also easily track the
    run history of all experiments with the SDK. This run history is stored in a shareable
    workspace, which allows teams to share the resources and experiment results. Another
    advantage of the SDK is that it allows us to find the best model from multiple
    runs of our experiment, based on a metric that we specify, such as, for example,
    the highest accuracy rate or the lowest rate of errors.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have a machine learning model that meets our needs, we can put it into
    operation using the Azure ML service. We can create a web service from the model
    that can be deployed in the Azure-managed computer or IoT device. The SDK can
    be installed in any IDE, so you can even deploy the model using VS Code or PyCharm
    if you do not use Jupyter Notebooks or Databricks. For development testing scenarios,
    we can deploy the web service to the **Azure Container Instance** (**ACI)**. To deploy
    the model in production, we can use **Azure Kubernetes Service** (**AKS)**. After
    the web service is deployed to AKS, we can enable monitoring and see how the web
    service is performing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following sample code shows how to use the SDK for E2E machine learning.
    Start by creating a workspace for your machine learning project. This will be
    created in your Azure subscription and can be shared with different users in your
    organization. This workspace logically groups the computes, experiments, datastores,
    models, images, and deployments that we will need for E2E machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b57e9787-ddf2-4673-9b30-53c819842c43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This workspace can be accessed either via code or in the Azure portal within
    our subscription. We can manage all logical components of the workspace and we
    can also manage user permissions. The following screenshot shows the components
    of a workspace as seen in the portal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f628e88a-5de1-4185-a024-5e7256a2ec9f.png)'
  prefs: []
  type: TYPE_IMG
- en: Once we have created a workspace, we can create a training compute that can
    scale automatically based on our training requirements. This compute can use either
    CPU or GPU, and we can use whichever framework we like. We can perform classical
    machine learning with scikit-learn, for example, or deep learning with TensorFlow.
    Any framework or library can be installed using `pip` and used with the SDK. We
    can submit experiment runs to this compute and we will see the results both in
    our environment and in the Azure portal. We can also log metrics as part of our
    training script. Here are some sample screenshots of how experiments run, and
    how corresponding metrics may appear in the Azure portal. We can also access these
    metrics using code with the SDK.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the number of experiments and the duration it
    took to run each experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b1c89f9-6643-4ca6-b1c6-ea70f39d213e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This screenshot shows the metrics that are being monitored within a particular
    run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/533e4f22-57a0-4a85-b136-31eae588077c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As mentioned, we can find the best run based on a particular metric of interest.
    An example of a code snippet used to find the best run is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bef39db5-adb8-42b5-aa26-51bf84a3265d.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we have found the best run, we can deploy the model as a web service,
    either to ACI or AKS. To do this, we need to provide a scoring script and an environment
    configuration, in addition to the model that we want to deploy. Here is an example
    of code that can be used to deploy models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4231a365-173d-4dcf-9d54-381308fe24b8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When a model is deployed in production to AKS and monitoring is enabled, we
    can view insights on how our web service is performing. We can also add custom
    monitoring for our model. The following screenshot shows how the web service has
    performed over a few days:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5fe13434-0bf9-41c6-baea-8b9db00c35b3.png)'
  prefs: []
  type: TYPE_IMG
- en: You can get more details about the Azure Machine Learning service at the following
    website: [https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml](https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml).
  prefs: []
  type: TYPE_NORMAL
- en: You can also get sample notebooks to get started with the Azure Machine Learning
    SDK at the following website: [https://github.com/Azure/MachineLearningNotebooks](https://github.com/Azure/MachineLearningNotebooks).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about the new capabilities of the Azure Machine
    Learning service, which makes it easy to perform E2E machine learning. We have
    also learned how professional data scientists and DevOps engineers can benefit
    from the experimentation and model management capabilities of the Azure Machine
    Learning SDK.
  prefs: []
  type: TYPE_NORMAL
