<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;4.&#xA0;Building a Product Recommendation System" id="UGI01-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04" class="calibre1"/>Chapter 4. Building a Product Recommendation System</h1></div></div></div><p class="calibre8">The digital world has made everything available at the click of a button. With everything going the online way, online shopping or e-commerce has become a big thing. From groceries to electronics to even cars, everything is available at the Amazon, Flipkart, and eBay of the world. This ever expanding digital market is just the right place for data science to show its magic.</p><p class="calibre8">The online revolution of e-commerce has not only empowered the customers, it has also overwhelmed them with too many choices. Choices are not only in terms of products or categories but also between different e-commerce platforms. Being an ecommerce company in this highly competitive market can be really difficult. Standing out is a challenge and that is where data yet again comes to the rescue.</p><p class="calibre8">As we saw in <a class="calibre1" title="Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis" href="part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8">Chapter 3</a>, <span class="strong"><em class="calibre10">Predicting Customer Shopping Trends with Market Basket Analysis</em></span>, purchase patterns can provide a lot of insights about shopping behaviors. We utilized such data to find association rules to not only help the customers quickly find the right products but also help the retailers increase revenues (see <a class="calibre1" title="Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis" href="part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8">Chapter 3</a>, <span class="strong"><em class="calibre10">Predicting Customer Shopping Trends with Market Basket Analysis</em></span>). For association rules, the granularity lies at the transaction level. They use transactions as a central entity and hence do not provide user specific insights.</p><p class="calibre8">In this chapter as well, we will continue our project work in the e-commerce domain. Here we will tackle the problem of personalization. We will use machine learning algorithms to provide user specific recommendations.</p><p class="calibre8">Through this chapter we will learn about:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Recommendation systems and their types</li><li class="listitem">Issues with recommendation systems</li><li class="listitem">Collaborative filters</li><li class="listitem">Building a recommendation system from scratch based on matrix factorization</li><li class="listitem">Utilizing highly optimized R packages to build a production ready recommendation engine and evaluate its recommendations</li></ul></div><p class="calibre8">Throughout this chapter we will use the terms <span class="strong"><strong class="calibre9">recommender engines</strong></span> and <span class="strong"><strong class="calibre9">recommendation systems</strong></span> interchangeably.</p></div>

<div class="book" title="Chapter&#xA0;4.&#xA0;Building a Product Recommendation System" id="UGI01-973e731d75c2419489ee73e3a0cf4be8">
<div class="book" title="Understanding recommendation systems"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch04lvl1sec26" class="calibre1"/>Understanding recommendation systems</h1></div></div></div><p class="calibre8"><span class="strong"><em class="calibre10">Every individual in unique</em></span>, the way we do things is what defines us uniquely. We eat, walk, talk, and even shop in a very unique way. Since the focus of this chapter is e-commerce, we will focus mostly on our shopping behaviors. We will utilize each customer's unique behavior to provide a personalized shopping experience.</p><p class="calibre8">To accomplish the task of providing a personalized shopping experience, we need a system to understand and model our customers. Recommendation engines are the systems which learn about customer preferences, choices, and so on, to recommend new products which are closer to what the user might have purchased themselves, thus providing a personalized experience. The options presented by such systems would have a high probability of the customer purchasing them.</p><p class="calibre8">Let us try to formally define a recommendation system.</p><p class="calibre8"><span class="strong"><strong class="calibre9">Recommendation systems</strong></span> (or <span class="strong"><strong class="calibre9">recommender engines</strong></span>) are a class of information filtering systems which analyze the input data to predict preferences of a user as they might have done for themselves.</p><p class="calibre8">Unlike information filtering systems which remove or filter information, recommender engines add or re-arrange the information flowing towards the user, which is more relevant to the current context.</p><p class="calibre8">Recommender engines are not a new concept. They have existed long before the internet was there. They existed in the form of our friends and family who used to recommend us things to buy because they understood our choices. These were and still are a sort of <span class="strong"><strong class="calibre9">offline-recommender engines</strong></span>. The web is full of <span class="strong"><strong class="calibre9">online-recommender engines</strong></span>. From recommendation <a id="id200" class="calibre1"/>related to <span class="strong"><strong class="calibre9">Who to follow</strong></span> <a id="id201" class="calibre1"/>on Twitter to <span class="strong"><strong class="calibre9">Other movies you might enjoy</strong></span> on Netflix to <span class="strong"><strong class="calibre9">Jobs you may be interested in</strong></span> on LinkedIn, recommender engines are everywhere and not just on e-commerce platforms.</p><p class="calibre8">Now that we have <a id="id202" class="calibre1"/>understood what a recommendation engine is, let us look at their different types:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">User-based recommender engines</strong></span>: As the name suggests, these systems have the <a id="id203" class="calibre1"/>user as the central entity. The activities, preferences, or behavior of the users are analyzed to predict what they might like depending upon their similarity <a id="id204" class="calibre1"/>with other such users. They are also termed as User Based Collaborative Filters in general due to extensive use of collaborative filters specifically for such recommender engines.</li><li class="listitem"><span class="strong"><strong class="calibre9">Content-based recommender engines</strong></span>: As the name suggests, these engines have the <a id="id205" class="calibre1"/>content or the items as the central entities. These items are analyzed to extract features; also the user profiles are built to map user preferences to the type of items. The engines then use this information to predict <a id="id206" class="calibre1"/>items which are similar to the ones the users have liked in the past. Such recommender engines are also known as <a id="id207" class="calibre1"/><span class="strong"><strong class="calibre9">item-based collaborative filters</strong></span> and have their roots in information retrieval theory.</li><li class="listitem"><span class="strong"><strong class="calibre9">Hybrid recommender engines</strong></span>: These systems take the best of both worlds to improve <a id="id208" class="calibre1"/>upon the prediction results. The two pure types can be used simultaneously and then their results can be combined; they can be used by adding collaborative filtering capabilities to content based systems or even by unifying both <a id="id209" class="calibre1"/>the approaches into a single model. Multiple studies have been conducted to demonstrate that hybrid approaches are better than the simple ones. Hybrid recommendation engines are also better at tackling the problems which haunt recommender engines in general.</li></ul></div><p class="calibre8">Before we dive deep into the intricacies of these algorithms, let us see the issues that affect the recommender systems.</p></div></div>
<div class="book" title="Issues with recommendation systems" id="VF2I1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec27" class="calibre1"/>Issues with recommendation systems</h1></div></div></div><p class="calibre8">Recommender <a id="id210" class="calibre1"/>engines are affected mainly by the following two issues:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">The sparsity problem</strong></span>: Recommender engines work upon user preferences (or ratings for <a id="id211" class="calibre1"/>different items, depending upon the application) to predict or recommend products. Usually the ratings are given on some chosen scale but the user may choose not to rate certain items which he/she hasn't bought or looked at. For such cases, the rating is blank or zero. Hence, the ratings matrix R has elements of the form:<p class="calibre20"><span class="strong"><img src="../images/00105.jpeg" alt="Issues with recommendation systems" class="calibre16"/></span></p><p class="calibre20">For any real world application, such as an e-commerce platform, the size of such a ratings matrix is huge due to the large number of users and items available on the platform. Even though a lot of user related information is gathered on such a platform, the ratings matrix itself might still be pretty sparse, that is the matrix might have a many elements as blanks (or zeroes). This problem in general is termed the <span class="strong"><strong class="calibre9">sparsity </strong></span><a id="id212" class="calibre1"/>
<span class="strong"><strong class="calibre9">problem</strong></span>. The sparsity problem renders the recommender engine's predictions ineffective as the algorithms are not able to infer the correlations correctly due to blanks or missing ratings. In the worst cases, the algorithm may term two users as un-correlated when actually they have highly similar preferences. The sparsity problem usually affects collaborative filtering algorithms.</p></li><li class="listitem"><span class="strong"><strong class="calibre9">The cold start problem</strong></span>: A special case of the sparsity problem is the cold start issue. As mentioned previously, when the ratings matrix contains sparsely populated elements (or ratings), the recommender engine fails to return valid recommendations. The cold start problem occurs in two particular <a id="id213" class="calibre1"/>cases. Firstly, assume a user has newly been added to the system. In this case, the row representing the user would <a id="id214" class="calibre1"/>contain zeroes (mostly). Recommending items to such a user is virtually impossible due to unavailability of information related to his/her preferences. The second scenario is when an item is newly added to the system. Since the newly added item will not have any ratings by the users, recommending such an item would be difficult for the recommender system. Hence, these two scenarios represent what is termed the cold start problem. Very much like the sparsity problem, the cold start problem also plagues collaborative filters.</li></ul></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Collaborative filters"><div class="book" id="10DJ42-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec28" class="calibre1"/>Collaborative filters</h1></div></div></div><p class="calibre8">Recommendation <a id="id215" class="calibre1"/>systems and collaborative filters share a long history. From the early days of primitive recommender engines which utilized specific categorizations with hard-coded results, to current sophisticated recommender engines on various e-commerce platforms, recommender engines have made use of collaborative filters throughout. They are not only easy to understand but are equally simple to implement. Let us take this opportunity to learn more about collaborative filters before we dive into implementation details.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note10" class="calibre1"/>Note</h3><p class="calibre8"><span class="strong"><strong class="calibre9">Fun Fact</strong></span></p><p class="calibre8">Recommender engines surely outdate any known e-commerce platform! Grundy, a virtual librarian, was developed in 1979. It was a system for recommending <a id="id216" class="calibre1"/>books to users. It modeled the users based upon certain pre-defined stereotypes and recommended books from a known list for each such category.</p></div></div>

<div class="book" title="Collaborative filters">
<div class="book" title="Core concepts and definitions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec49" class="calibre1"/>Core concepts and definitions</h2></div></div></div><p class="calibre8"><span class="strong"><strong class="calibre9">Collaborative filters</strong></span> (denoted as <span class="strong"><strong class="calibre9">CF</strong></span> henceforth) and recommender engines in general use certain terms and <a id="id217" class="calibre1"/>definitions to formally define and tackle the problem.</p><p class="calibre8">The problem domain of recommender engines revolves around the users and the items they are interested in. A <a id="id218" class="calibre1"/>
<span class="strong"><strong class="calibre9">user</strong></span> is anybody who interacts with the system and <a id="id219" class="calibre1"/>performs certain actions on the <span class="strong"><strong class="calibre9">item</strong></span> (say purchases or views it). Similarly, a <span class="strong"><strong class="calibre9">rating</strong></span> defines a user's preference for an item in consideration. Generally, this <a id="id220" class="calibre1"/>trio is represented as a <code class="email">(user, item, rating)</code> tuple. Since the ratings quantify a user's preference, the ratings can themselves be defined in different ways depending upon the application. Applications define ratings as integer-valued scales ranging from say <span class="strong"><em class="calibre10">0-5</em></span>, while others may define a real-valued scale. Some applications might use binary scales with values such as <span class="strong"><em class="calibre10">Like/Dislike</em></span> or <span class="strong"><em class="calibre10">Purchased/Not-Purchased</em></span>. Thus, each application makes use of a rating scale to suit its user's preferences.</p><p class="calibre8">Now that we know the key players involved, the next step is the representation of these core-concepts mathematically. A tuple of <code class="email">(user, item, rating)</code> is usually represented in the form of a sparse <a id="id221" class="calibre1"/>matrix called a <span class="strong"><strong class="calibre9">ratings matrix</strong></span>. Each <a id="id222" class="calibre1"/>user is represented by a row while the columns denote the items. Each element of this ratings matrix refers to the rating or preference of the user <a id="id223" class="calibre1"/>for an item. The ratings matrix is a <span class="strong"><strong class="calibre9">sparse matrix</strong></span> <a id="id224" class="calibre1"/>since not all the items would be rated by every user and hence such unrated items would contain nulls or blank values. A ratings matrix using a 0-5 scale (unrated/missing ratings are denoted by <code class="email">?</code>) looks like the following matrix showing the preference of three users for different laptop models:</p><div class="mediaobject"><img src="../images/00106.jpeg" alt="Core concepts and definitions" class="calibre11"/><div class="caption"><p class="calibre18">A sample ratings matrix</p></div></div><p class="calibre12"> </p><p class="calibre8">A recommender engine is tasked to perform two main operations: <span class="strong"><strong class="calibre9">predict</strong></span> and <span class="strong"><strong class="calibre9">recommend</strong></span>. The prediction <a id="id225" class="calibre1"/>operation works upon a given user and item to <a id="id226" class="calibre1"/>determine the user's likely preference for the item in consideration. For the ratings matrix (like the one shown earlier), prediction is like identification of the <a id="id227" class="calibre1"/>missing values (represented by <code class="email">?</code> in the previous example).</p><p class="calibre8">The recommendation operation comes after the predictions have been done. Given a user, the recommendation operation generates a list of top <span class="strong"><em class="calibre10">N</em></span> items based on the user's preferences.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note11" class="calibre1"/>Note</h3><p class="calibre8">Note that the user in consideration for the predict and recommend tasks is termed the <span class="strong"><strong class="calibre9">active-user</strong></span> in the context of recommender engines.</p></div></div></div>

<div class="book" title="Collaborative filters">
<div class="book" title="The collaborative filtering algorithm"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec50" class="calibre1"/>The collaborative filtering algorithm</h2></div></div></div><p class="calibre8">Collaborative filters <a id="id228" class="calibre1"/>are a popular set of algorithms heavily used across applications. As we know, collaborative filters utilize the behaviour of similar users to predict and recommend items for the active user. These algorithms work on a simple assumption that similar users showcase similar behaviours. More formally, the algorithm assumes that the preferences or ratings of the other users in the system can be utilized to provide reasonable predictions for the active user.</p><p class="calibre8"><span class="strong"><strong class="calibre9">Neighbour-based </strong></span><a id="id229" class="calibre1"/>
<span class="strong"><strong class="calibre9">collaborative filtering</strong></span>, also known <a id="id230" class="calibre1"/>as <span class="strong"><strong class="calibre9">user-user collaborative filtering</strong></span> or <span class="strong"><strong class="calibre9">kNN collaborative filtering</strong></span>, is one of the earliest and most widely used algorithms from the <a id="id231" class="calibre1"/>family of collaborative filters. The kNN collaborative filter is based on the core assumption of similar behaviour amongst users with similar preferences. This algorithm makes use of similarity measures (discussed in <a class="calibre1" title="Chapter 2. Let's Help Machines Learn" href="part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8">Chapter 2</a>, <span class="strong"><em class="calibre10">Let's Help Machines Learn</em></span>) to predict and recommend items for the active user. The algorithm follows a two-step approach of first computing the predictions followed by the recommendations. The three main components of this algorithm are discussed next.</p><div class="book" title="Predictions"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch04lvl3sec17" class="calibre1"/>Predictions</h3></div></div></div><p class="calibre8">The first step of kNN CF <a id="id232" class="calibre1"/>is to make use of the ratings matrix (usually denoted as <code class="email">R</code>) to calculate predictions. Since we are concerned about user-user CF, the neighbourhood of active user (the user in consideration), denoted as <code class="email">u</code>, is to be taken into account.</p><p class="calibre8">Let <code class="email">U</code> be the set of all available users in the system and <code class="email">N</code> denote the required neighbourhood where <span class="strong"><img src="../images/00107.jpeg" alt="Predictions" class="calibre16"/></span>. The algorithm then uses a similarity measure, say <code class="email">s</code>, to compute the neighbours of <code class="email">u</code>. Once <code class="email">N </code>(the neighborhood of<code class="email"> u</code>) has been identified, the ratings of the neighbouring users are aggregated to compute <code class="email">u</code>'s preference for the current item. The most common <a id="id233" class="calibre1"/>measure to aggregate preferences is to use the <span class="strong"><strong class="calibre9">weighted average</strong></span> of <code class="email">N</code> neighboring users.</p><p class="calibre8">Mathematically, the <a id="id234" class="calibre1"/>active user <code class="email">u</code>'s predicted preference for item <code class="email">i</code>, denoted as <code class="email">p<sub class="calibre19">ui</sub></code> is given as:</p><div class="mediaobject"><img src="../images/00108.jpeg" alt="Predictions" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Where:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><img src="../images/00109.jpeg" alt="Predictions" class="calibre16"/></span> is the active user <code class="email">u's</code> mean rating
</li><li class="listitem"><span class="strong"><img src="../images/00110.jpeg" alt="Predictions" class="calibre16"/></span> is the similarity measure between the active user u and the neighbouring user <span class="strong"><img src="../images/00111.jpeg" alt="Predictions" class="calibre16"/></span></li></ul></div><p class="calibre8">In the preceding equation, we subtract the mean of the active user's rating <span class="strong"><img src="../images/00109.jpeg" alt="Predictions" class="calibre16"/></span> from the neighbouring user's mean rating to remove the rating bias of the users (some users give extremely high or low ratings and thus they may bias the overall predicted rating). A biased recommender engine might prevent better user-product matches in favour of popular or against not so popular ones. We can further improve the predictions by normalizing the user's ratings by using standard deviation to control the rating spread across the mean. To keep things simple, we will use the equation as mentioned previously. The following image depicts the nearest neighbours for an active user:</p><div class="mediaobject"><img src="../images/00112.jpeg" alt="Predictions" class="calibre11"/><div class="caption"><p class="calibre18">Nearest neighbors (<span class="strong"><em class="calibre10">K=3</em></span>)</p></div></div><p class="calibre12"> </p><p class="calibre8">The question now arises that why only weighted average was used to predict the ratings and what the optimal number of neighbours (<code class="email">N</code>) is. The reason behind using weighted average is that it is one of the measures which helps in generating consistent results. Different systems over the years have used various methods, such as <span class="strong"><em class="calibre10">multivariate regressions</em></span> (the BellCore <a id="id235" class="calibre1"/>system for video recommendations), <span class="strong"><em class="calibre10">unweighted averages</em></span> (Ringo for music recommendations), and so on, but weighted average performs pretty well in practice.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note12" class="calibre1"/>Note</h3><p class="calibre8">For more information, have a look at W. Hill, L. Stead, M. Rosenstein, and G. Furnas, <span class="strong"><em class="calibre10">Recommending and evaluating choices in a virtual community of use</em></span>, in ACM CHI '95, pp. 194–201, ACM Press/Addison-Wesley Publishing Co., 1995.</p></div><p class="calibre8">Coming onto the second question of the optimal number of neighbours, this is something very application dependent. We saw in <a class="calibre1" title="Chapter 2. Let's Help Machines Learn" href="part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8">Chapter 2</a>, <span class="strong"><em class="calibre10">Let's Help Machines Learn</em></span>, how the number of neighbours can change the outcome of an algorithm (see <span class="strong"><em class="calibre10">K-Nearest Neighbors</em></span> (<span class="strong"><em class="calibre10">KNN</em></span>)), similarly the value of <code class="email">N</code> can affect the outcome of a recommender engine. In general, limiting the number of neighbouring users helps in reducing the noise by removing users with low correlation to the active user. But then again, the value of <code class="email">N</code> is application dependent and requires due diligence at the data scientist's end.</p></div><div class="book" title="Recommendations"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch04lvl3sec18" class="calibre1"/>Recommendations</h3></div></div></div><p class="calibre8">Once predictions <a id="id236" class="calibre1"/>have been done for the <span class="strong"><em class="calibre10">active user</em></span>, a recommendation list can be generated by ordering the items by predicted rank. This recommendation list may be further fine-tuned by applying certain minimal thresholds and other user specific characteristics, such as preferences for color, size, price sensitivity, and so on. Thus, this step generates a list of probable items which the user is more likely to buy based on his/her personal preferences. We will cover more on this in the coming <a id="id237" class="calibre1"/>section, <span class="strong"><em class="calibre10">Building a recommender engine</em></span>.</p></div><div class="book" title="Similarity"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch04lvl3sec19" class="calibre1"/>Similarity</h3></div></div></div><p class="calibre8">A similarity <a id="id238" class="calibre1"/>measure is an important component of our collaborative filtering based recommender engine algorithm. There are various similarity measures available for use. The most common amongst them is the <span class="strong"><strong class="calibre9">cosine similarity</strong></span> measure. This <a id="id239" class="calibre1"/>approach represents each user as an <code class="email">n</code> dimensional vector of ratings and similarity is measured by calculating the cosine distance between two such user vectors.</p><p class="calibre8">Mathematically, cosine similarity is given as:</p><div class="mediaobject"><img src="../images/00113.jpeg" alt="Similarity" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Where, <span class="strong"><img src="../images/00114.jpeg" alt="Similarity" class="calibre16"/></span> and <span class="strong"><img src="../images/00115.jpeg" alt="Similarity" class="calibre16"/></span> are the <span class="strong"><strong class="calibre9">L2</strong></span> or <span class="strong"><strong class="calibre9">Euclidean </strong></span><a id="id240" class="calibre1"/>
<span class="strong"><strong class="calibre9">norms</strong></span> for each of the rating vectors.</p><p class="calibre8"><span class="strong"><strong class="calibre9">Pearson </strong></span><a id="id241" class="calibre1"/>
<span class="strong"><strong class="calibre9">correlation</strong></span> and <span class="strong"><strong class="calibre9">Spearman rank correlation</strong></span> are a couple of <a id="id242" class="calibre1"/>statistical similarity measures which are also used widely.</p><p class="calibre8">Now that we understand the basics of collaborative filters and general concepts, we are ready to get our hands dirty with implementation details. Let us start with building the recommender system, brick-by-brick!</p></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Building a recommender engine"><div class="book" id="11C3M2-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec29" class="calibre1"/>Building a recommender engine</h1></div></div></div><p class="calibre8">As discussed in the <a id="id243" class="calibre1"/>previous section, collaborative filtering is a simple yet very effective approach for predicting and recommending items to users. If we look closely, the algorithms work on input data, which is nothing but a matrix representation of the user ratings for different products.</p><p class="calibre8">Bringing in a mathematical perspective <a id="id244" class="calibre1"/>into the picture, <span class="strong"><strong class="calibre9">matrix factorization</strong></span> is a technique to manipulate matrices and identify latent or hidden features from the data represented in the matrix. Building on the same concept, let us use matrix factorization as the basis for predicting ratings for items which the user has not yet rated.</p></div>

<div class="book" title="Building a recommender engine">
<div class="book" title="Matrix factorization"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec51" class="calibre1"/>Matrix factorization</h2></div></div></div><p class="calibre8">Matrix factorization <a id="id245" class="calibre1"/>refers to the identification of two or more <a id="id246" class="calibre1"/>matrices such that when these matrices are multiplied we get the original matrix. Matrix factorization, as mentioned earlier, can be used to discover latent features between two different kinds of entities. We will understand and use the concepts of matrix factorization as we go along preparing our recommender engine for our e-commerce platform.</p><p class="calibre8">As our aim for the current project is to personalize the shopping experience and recommend product ratings for an e-commerce platform, our input data contains user ratings for various products on the website. We process the input data and transform it into a matrix representation for analyzing it using matrix factorization. The input data looks like this:</p><div class="mediaobject"><img src="../images/00116.jpeg" alt="Matrix factorization" class="calibre11"/><div class="caption"><p class="calibre18">User ratings matrix</p></div></div><p class="calibre12"> </p><p class="calibre8">As you can see, the input data is a matrix with each row representing a particular user's rating for different items represented in the columns. For the current case, the columns representing items are different mobile phones such as iPhone 4, iPhone 5s, Nexus 5, and so on. Each row contains ratings for each of these mobile phones as given by eight different users. The ratings range from 1 to 5 with 1 being the lowest and 5 being the highest. A rating of 0 represents unrated items or missing rating.</p><p class="calibre8">The task of our recommender engine will be to predict the correct rating for the missing ones in the input matrix. We could then use the predicted ratings to recommend items most desired by the user.</p><p class="calibre8">The premise here is that two users would rate a product similarly if they like similar features of the product or item. Since our current data is related to user ratings for different mobile phones, people might rate the phones based on their hardware configuration, price, OS, and so on. Hence, matrix factorization tries to identify these latent features to predict ratings for a certain user and a certain product.</p><p class="calibre8">While trying to identify these latent features, we proceed with the basic assumption that the number of such features is less than the total number of items in consideration. This assumption makes sense because if this was the case, then each user would have a specific feature associated with him/her (and similarly for the product). This would in turn make recommendations futile as none of the users would be interested in items rated by other users (which is not usually the case).</p><p class="calibre8">Now let us get into <a id="id247" class="calibre1"/>the mathematical details of matrix factorization and our recommender engine.</p><p class="calibre8">Since we are dealing with <a id="id248" class="calibre1"/>user ratings for different products, let us assume <code class="email">U</code> to be a matrix representing user preferences and similarly a matrix <code class="email">P</code> represents the products for which we have the ratings. Then the ratings matrix <code class="email">R</code> will be defined as <span class="strong"><img src="../images/00117.jpeg" alt="Matrix factorization" class="calibre16"/></span>.</p><p class="calibre8">Assuming the process helps us identify <code class="email">K</code> latent features, our aim is to find two matrices <code class="email">X</code> and <code class="email">Y</code> such that their product (matrix multiplication) approximates <code class="email">R</code>.</p><div class="mediaobject"><img src="../images/00118.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Where, <code class="email">X</code> is a user related matrix which represents the associations between the users and the latent features. <code class="email">Y</code>, on the other hand, is the product related matrix which represents the associations between the products and the latent features.</p><p class="calibre8">The task of predicting the rating <span class="strong"><img src="../images/00119.jpeg" alt="Matrix factorization" class="calibre16"/></span> of a product <code class="email">p<sub class="calibre19">j</sub></code> by a user <code class="email">u<sub class="calibre19">i</sub></code> is done by calculating the dot product of the vectors corresponding to <code class="email">p<sub class="calibre19">j</sub></code> (<code class="email">vector Y</code>, that is the user) and <code class="email">u<sub class="calibre19">i</sub></code> (<code class="email">vector X</code>, that is the product<code class="email">)</code>.</p><div class="mediaobject"><img src="../images/00120.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Now, to find the matrices <code class="email">X</code> and <code class="email">Y</code>, we utilize a technique called <span class="strong"><strong class="calibre9">gradient descent</strong></span>. Gradient descent, in <a id="id249" class="calibre1"/>simple terms, tries to find the local minimum of a function; it is an optimization technique. We use gradient descent in the current context to iteratively minimize the difference between the predicted ratings and the actual ratings. To begin with, we randomly initialize the matrices <code class="email">X</code> and <code class="email">Y</code> and then calculate how different their product is from the actual ratings matrix <code class="email">R</code>.</p><p class="calibre8">The difference between the predicted and the actual values is what is termed the <span class="strong"><strong class="calibre9">error</strong></span>. For our <a id="id250" class="calibre1"/>problem, we <a id="id251" class="calibre1"/>will consider <a id="id252" class="calibre1"/>the <a id="id253" class="calibre1"/>
<span class="strong"><strong class="calibre9">squared error,</strong></span> which is calculated as:</p><div class="mediaobject"><img src="../images/00121.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Where, <code class="email">r<sub class="calibre19">ij</sub></code> is the actual rating by user <code class="email">i</code> for product <code class="email">j</code> and <span class="strong"><img src="../images/00119.jpeg" alt="Matrix factorization" class="calibre16"/></span> is the predicted value of the same.</p><p class="calibre8">To minimize the error, we need to find the correct direction or gradient to change our values to. To obtain the gradient for each of the variables <code class="email">x</code> and <code class="email">y</code>, we differentiate them separately as:</p><div class="mediaobject"><img src="../images/00122.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Hence, the equations to find <code class="email">x<sub class="calibre19">ik</sub></code> and <code class="email">y<sub class="calibre19">kj</sub></code> can be given as:</p><div class="mediaobject"><img src="../images/00123.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Where <code class="email">α</code> is the constant <a id="id254" class="calibre1"/>to denote the <span class="strong"><strong class="calibre9">rate of descent</strong></span> or the rate of approaching the minima (also known as the learning rate). The value of <code class="email">α </code>defines the size of steps we take in either direction to reach the minima. Large values may lead to oscillations as we may overshoot the minima every time. Usual practice is to select very small values for <code class="email">α</code>, of the order <code class="email">10<sup class="calibre15">-4</sup></code>. <span class="strong"><img src="../images/00124.jpeg" alt="Matrix factorization" class="calibre16"/></span> and <span class="strong"><img src="../images/00125.jpeg" alt="Matrix factorization" class="calibre16"/></span> are the updated values of <code class="email">x<sub class="calibre19">ik</sub></code> and <code class="email">y<sub class="calibre19">kj</sub></code> after each iteration of gradient descent.</p><p class="calibre8">As seen in <a class="calibre1" title="Chapter 2. Let's Help Machines Learn" href="part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8">Chapter 2</a>, <span class="strong"><em class="calibre10">Let's Help Machines Learn</em></span>, machine learning algorithms can suffer from overfitting. To avoid overfitting, along with controlling extreme or large values in the <a id="id255" class="calibre1"/>matrices <code class="email">X</code> and <code class="email">Y</code>, we introduce the concept of regularization. Formally, <span class="strong"><strong class="calibre9">regularization</strong></span> refers to the process of introducing additional information in order to prevent overfitting. Regularization penalizes models with extreme values.</p><p class="calibre8">To prevent overfitting <a id="id256" class="calibre1"/>in our case, we introduce the regularization constant called <code class="email">β</code>. With the introduction of <code class="email">β</code>, the equations are updated as follows:</p><div class="mediaobject"><img src="../images/00126.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Also,</p><div class="mediaobject"><img src="../images/00127.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><div class="mediaobject"><img src="../images/00128.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">As we already have the ratings matrix <code class="email">R</code> and we use it to determine how far our predicted values are from the actual, matrix factorization turns into a supervised learning problem. For this supervised problem, just as we saw in <a class="calibre1" title="Chapter 2. Let's Help Machines Learn" href="part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8">Chapter 2</a>, <span class="strong"><em class="calibre10">Let's Help Machines Learn</em></span>, we use some of the rows as our training samples. Let <code class="email">S</code> be our training set with elements being tuples of the form <code class="email">(u<sub class="calibre19">i</sub>, p<sub class="calibre19">j</sub>, r<sub class="calibre19">ij</sub>)</code>. Thus, our task is to minimize the error (<code class="email">e<sub class="calibre19">ij</sub></code>) for every tuple <code class="email">(u<sub class="calibre19">i</sub>, p<sub class="calibre19">j</sub>, r<sub class="calibre19">ij</sub>)</code> <code class="email">є</code> in training set <code class="email">S</code>.</p><p class="calibre8">The overall <a id="id257" class="calibre1"/>error (say <code class="email">E</code>) can be calculated as:</p><div class="mediaobject"><img src="../images/00129.jpeg" alt="Matrix factorization" class="calibre11"/></div><p class="calibre12"> </p></div></div>

<div class="book" title="Building a recommender engine">
<div class="book" title="Implementation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec52" class="calibre1"/>Implementation</h2></div></div></div><p class="calibre8">Now that we have <a id="id258" class="calibre1"/>looked into the mathematics of matrix factorization, let us convert the algorithm into code and prepare a recommender engine for the mobile phone ratings input data set discussed earlier.</p><p class="calibre8">As shown in the <span class="strong"><em class="calibre10">Matrix factorization</em></span> section, the input dataset is a matrix with each row representing a user's rating for the products mentioned as columns. The ratings range from 1 to 5 with 0 representing the missing values.</p><p class="calibre8">To transform our algorithm into working code, we need to compute and complete the following tasks:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Load the input data and transform it into ratings matrix representation</li><li class="listitem">Prepare a matrix factorization based recommendation model</li><li class="listitem">Predict and recommend products to the users</li><li class="listitem">Interpret and evaluate the model</li></ul></div><p class="calibre8">Loading and transforming input data into matrix representation is simple. As seen earlier, R provides us with <a id="id259" class="calibre1"/>easy to use utility functions for the same.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># load raw ratings from csv</strong></span>
<span class="strong"><strong class="calibre9">raw_ratings &lt;- read.csv(&lt;file_name&gt;)</strong></span>

<span class="strong"><strong class="calibre9"># convert columnar data to sparse ratings matrix</strong></span>
<span class="strong"><strong class="calibre9">ratings_matrix &lt;- data.matrix(raw_ratings)</strong></span>
</pre></div><p class="calibre8">Now that we have our data loaded into an <code class="email">R</code> matrix, we proceed and prepare the user-latent features matrix <code class="email">X</code> and item-latent features matrix <code class="email">Y</code>. We initialize both from uniform distributions using the <code class="email">runif</code> function.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># number of rows in ratings</strong></span>
<span class="strong"><strong class="calibre9">rows &lt;- nrow(ratings_matrix)</strong></span>

<span class="strong"><strong class="calibre9"># number of columns in ratings matrix</strong></span>
<span class="strong"><strong class="calibre9">columns &lt;- ncol(ratings_matrix)</strong></span>

<span class="strong"><strong class="calibre9"># latent features</strong></span>
<span class="strong"><strong class="calibre9">K &lt;- 2</strong></span>

<span class="strong"><strong class="calibre9"># User-Feature Matrix</strong></span>
<span class="strong"><strong class="calibre9">X &lt;- matrix(runif(rows*K), nrow=rows, byrow=TRUE)</strong></span>

<span class="strong"><strong class="calibre9"># Item-Feature Matrix</strong></span>
<span class="strong"><strong class="calibre9">Y &lt;- matrix(runif(columns*K), nrow=columns, byrow=TRUE)</strong></span>
</pre></div><p class="calibre8">The major component is the matrix factorization function itself. Let us split the task into two, calculation of the gradient and subsequently the overall error.</p><p class="calibre8">The calculation of the gradient involves the ratings matrix <code class="email">R</code> and the two factor matrices <code class="email">X</code> and <code class="email">Y,</code> along with the constants <code class="email">α</code> and <code class="email">β</code>. Since we are dealing with matrix manipulations (specifically, multiplication), we transpose <code class="email">Y</code> before we begin with any further calculations. The following lines of code convert the algorithm discussed previously into R syntax. All variables follow naming convention similar to the algorithm for ease of understanding.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">for (i in seq(nrow(ratings_matrix))){</strong></span>

<span class="strong"><strong class="calibre9">      for (j in seq(length(ratings_matrix[i, ]))){</strong></span>

<span class="strong"><strong class="calibre9">        if (ratings_matrix[i, j] &gt; 0){</strong></span>

<span class="strong"><strong class="calibre9">          # error </strong></span>
<span class="strong"><strong class="calibre9">          eij = ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j])</strong></span>

<span class="strong"><strong class="calibre9">       # gradient calculation </strong></span>

<span class="strong"><strong class="calibre9">          for (k in seq(K)){</strong></span>
<span class="strong"><strong class="calibre9">            X[i, k] = X[i, k] + alpha * (2 * eij * Y[k, j]/</strong></span>
<span class="strong"><strong class="calibre9">            - beta * X[i, k])</strong></span>

<span class="strong"><strong class="calibre9">            Y[k, j] = Y[k, j] + alpha * (2 * eij * X[i, k]/</strong></span>
<span class="strong"><strong class="calibre9">            - beta * Y[k, j])</strong></span>
<span class="strong"><strong class="calibre9">          }</strong></span>
<span class="strong"><strong class="calibre9">        }</strong></span>
<span class="strong"><strong class="calibre9">      }</strong></span>
<span class="strong"><strong class="calibre9">    }</strong></span>
</pre></div><p class="calibre8">The next part of the <a id="id260" class="calibre1"/>algorithm is to calculate the overall error; we again use similar variable names for consistency:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># Overall Squared Error Calculation</strong></span>

<span class="strong"><strong class="calibre9">e = 0</strong></span>

<span class="strong"><strong class="calibre9">for (i in seq(nrow(ratings_matrix))){</strong></span>

<span class="strong"><strong class="calibre9">   for (j in seq(length(ratings_matrix[i, ]))){</strong></span>

<span class="strong"><strong class="calibre9">     if (ratings_matrix[i, j] &gt; 0){</strong></span>

<span class="strong"><strong class="calibre9">       e = e + (ratings_matrix[i, j] - /</strong></span>
<span class="strong"><strong class="calibre9">           as.numeric(X[i, ] %*% Y[, j]))^2</strong></span>

<span class="strong"><strong class="calibre9">       for (k in seq(K)){</strong></span>
<span class="strong"><strong class="calibre9">          e = e + (beta/2) * (X[i, k]^2 + Y[k, j]^2)</strong></span>
<span class="strong"><strong class="calibre9">        }</strong></span>
<span class="strong"><strong class="calibre9">      }</strong></span>
<span class="strong"><strong class="calibre9">    }</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">As a final piece, we iterate over these calculations multiple times to mitigate the risks of cold start and sparsity. We <a id="id261" class="calibre1"/>term the variable controlling multiple starts as <span class="strong"><strong class="calibre9">epoch</strong></span>. We also terminate the calculations once the overall error drops below a certain threshold.</p><p class="calibre8">Moreover, as we had initialized <code class="email">X</code> and <code class="email">Y</code> from uniform distributions, the predicted values would be real numbers. We round the final output before returning the predicted matrix.</p><p class="calibre8">Note that this is a very simplistic implementation and a lot of complexity has been kept out for ease of understanding. Hence, this may result in the predicted matrix containing values greater than 5. For the current scenario, it is safe to assume the values above the max scale of 5 are equivalent to 5 (and similarly for values less than 0). We encourage the reader to fine tune the code to handle such cases.</p><p class="calibre8">Setting <code class="email">α</code> to <code class="email">0.0002</code>, <code class="email">β</code> to <code class="email">0.02</code>, <code class="email">K</code> (that is, latent features) to <code class="email">2</code>, and <code class="email">epoch</code> to <code class="email">1000</code>, let us see a sample run of <a id="id262" class="calibre1"/>our code with overall error threshold set to <code class="email">0.001</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># load raw ratings from csv</strong></span>
<span class="strong"><strong class="calibre9">raw_ratings &lt;- read.csv("product_ratings.csv")</strong></span>

<span class="strong"><strong class="calibre9"># convert columnar data to sparse ratings matrix</strong></span>
<span class="strong"><strong class="calibre9">ratings_matrix &lt;- data.matrix(raw_ratings)</strong></span>


<span class="strong"><strong class="calibre9"># number of rows in ratings</strong></span>
<span class="strong"><strong class="calibre9">rows &lt;- nrow(ratings_matrix)</strong></span>

<span class="strong"><strong class="calibre9"># number of columns in ratings matrix</strong></span>
<span class="strong"><strong class="calibre9">columns &lt;- ncol(ratings_matrix)</strong></span>

<span class="strong"><strong class="calibre9"># latent features</strong></span>
<span class="strong"><strong class="calibre9">K &lt;- 2</strong></span>

<span class="strong"><strong class="calibre9"># User-Feature Matrix</strong></span>
<span class="strong"><strong class="calibre9">X &lt;- matrix(runif(rows*K), nrow=rows, byrow=TRUE)</strong></span>

<span class="strong"><strong class="calibre9"># Item-Feature Matrix</strong></span>
<span class="strong"><strong class="calibre9">Y &lt;- matrix(runif(columns*K), nrow=columns, byrow=TRUE)</strong></span>

<span class="strong"><strong class="calibre9"># iterations</strong></span>
<span class="strong"><strong class="calibre9">epoch &lt;- 10000</strong></span>

<span class="strong"><strong class="calibre9"># rate of descent</strong></span>
<span class="strong"><strong class="calibre9">alpha &lt;- 0.0002</strong></span>

<span class="strong"><strong class="calibre9"># regularization constant</strong></span>
<span class="strong"><strong class="calibre9">beta &lt;- 0.02</strong></span>


<span class="strong"><strong class="calibre9">pred.matrix &lt;- mf_based_ucf(ratings_matrix, X, Y, K, epoch = epoch)</strong></span>

<span class="strong"><strong class="calibre9"># setting column names</strong></span>
<span class="strong"><strong class="calibre9">colnames(pred.matrix)&lt;-c("iPhone.4","iPhone.5s","Nexus.5","Moto.X","Moto.G","Nexus.6",/"One.Plus.One")</strong></span>
</pre></div><p class="calibre8">The preceding lines of code utilize the functions explained earlier to prepare the recommendation <a id="id263" class="calibre1"/>model. The predicted ratings or the output matrix looks like the following:</p><div class="mediaobject"><img src="../images/00130.jpeg" alt="Implementation" class="calibre11"/><div class="caption"><p class="calibre18">Predicted ratings matrix</p></div></div><p class="calibre12"> </p></div></div>

<div class="book" title="Building a recommender engine">
<div class="book" title="Result interpretation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec53" class="calibre1"/>Result interpretation</h2></div></div></div><p class="calibre8">Let us do a quick <a id="id264" class="calibre1"/>visual inspection to see how good or bad our predictions have been. Consider users 1 and 3 as our training samples. From the input dataset, we can clearly see that user 1 has given high ratings to iPhones while user 3 has done the same for Android based phones. The following side by side comparison shows that our algorithm has predicted values close enough to the actual values:</p><div class="mediaobject"><img src="../images/00131.jpeg" alt="Result interpretation" class="calibre11"/><div class="caption"><p class="calibre18">Ratings by user 1</p></div></div><p class="calibre12"> </p><p class="calibre8">Let us see the <a id="id265" class="calibre1"/>ratings of user 3 in the following screenshot:</p><div class="mediaobject"><img src="../images/00132.jpeg" alt="Result interpretation" class="calibre11"/><div class="caption"><p class="calibre18">Ratings by user 3</p></div></div><p class="calibre12"> </p><p class="calibre8">Now that we have our ratings matrix with updated values, we are ready to recommend products to users. It is common sense to show only the products which the user hasn't rated yet. The right set of recommendations will also enable the seller to pitch the products which have high probability of being purchased by the user.</p><p class="calibre8">The usual practice is to return a list of the top <span class="strong"><em class="calibre10">N</em></span> items from the unrated list of products for each user. The user in consideration is usually termed the <span class="strong"><strong class="calibre9">active-user</strong></span>. Let us consider user 6 as our active-user. This user <a id="id266" class="calibre1"/>has only rated Nexus 6, One Plus One, Nexus 5, and iPhone4 in that order of rating, that is Nexus 6 was highly rated and iPhone4 was rated the least. Getting a list of the <span class="strong"><em class="calibre10">Top 2</em></span> recommended phones for such a customer using our algorithm would result in Moto X and Moto G (very rightly indeed, do you see why?).</p><p class="calibre8">Thus, we built a recommender engine smart enough to recommend the right mobile phones to an Android fanboy and saved the world from yet another catastrophe!</p><p class="calibre8"><span class="strong"><em class="calibre10">Data to the rescue!</em></span></p><p class="calibre8">This simple <a id="id267" class="calibre1"/>implementation of a recommender engine using matrix factorization gave us a flavor of how such a system actually works. Next, let us get into some real world action using recommender engines.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Production ready recommender engines"><div class="book" id="12AK82-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec30" class="calibre1"/>Production ready recommender engines</h1></div></div></div><p class="calibre8">In this chapter so <a id="id268" class="calibre1"/>far, we have learnt about recommender engines in detail and even developed one from scratch (using matrix factorization). Through all this, it is clearly evident how widespread the application of such systems is.</p><p class="calibre8">E-commerce <a id="id269" class="calibre1"/>websites (or for that fact, any popular technology platform) out there today have tones of content to offer. Not only that, but the number of users is also huge. In such a scenario, where thousands of users are browsing/buying stuff simultaneously across the globe, providing recommendations to them is a task in itself. To complicate things even further, a good user experience (response times, for example) can create a big difference between two competitors. These are live examples of production systems handling millions of customers day in and day out.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note13" class="calibre1"/>Note</h3><p class="calibre8"><span class="strong"><strong class="calibre9">Fun Fact</strong></span></p><p class="calibre8">Amazon.com is one of the biggest names in the e-commerce space with 244 million active customers. Imagine the amount of data being processed to provide recommendations to such a huge customer base browsing through millions of products!</p><p class="calibre8">Source: <a class="calibre1" href="http://www.amazon.com/b?ie=UTF8&amp;node=8445211011">http://www.amazon.com/b?ie=UTF8&amp;node=8445211011</a></p></div><p class="calibre8">In order to provide a seamless capability for use in such platforms, we need highly optimized libraries and hardware. For a recommender engine to handle thousands of users simultaneously <a id="id270" class="calibre1"/>every second, R has a robust and reliable framework called the <span class="strong"><strong class="calibre9">recommenderlab</strong></span>.</p><p class="calibre8">Recommenderlab is a widely used R extension designed to provide a robust foundation for recommender engines. The focus of this library is to provide efficient handling of data, availability of standard algorithms and evaluation capabilities. In this section, we will be using recommenderlab to handle a considerably larger data set for recommending items to users. We will also use the evaluation functions from recommenderlab to see how good or bad our recommendation system is. These capabilities will help us build a production ready recommender system similar (or at least closer) to what many online applications such as Amazon or Netflix use.</p><p class="calibre8">The dataset used in this section contains ratings for 100 items as rated by 5000 users. The data has been anonymized and the product names have been replaced by product IDs. The rating scale used is 0 to 5 with 1 being the worst, 5 being the best, and 0 representing unrated items or missing ratings.</p><p class="calibre8">To build a <a id="id271" class="calibre1"/>recommender engine using recommenderlab for a production ready system, the following steps are to be performed:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Extract, transform, and analyze the data.</li><li class="listitem" value="2">Prepare a recommendation model and generate recommendations.</li><li class="listitem" value="3">Evaluate the recommendation model.</li></ol><div class="calibre14"/></div><p class="calibre8">We will look at all these steps in the following subsections.</p></div>

<div class="book" title="Production ready recommender engines">
<div class="book" title="Extract, transform, and analyze"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec54" class="calibre1"/>Extract, transform, and analyze</h2></div></div></div><p class="calibre8">As in case <a id="id272" class="calibre1"/>of any data intensive (particularly machine learning) application, the first and foremost step is to get the data, understand/explore it, and then transform it into the format required by the algorithm deemed fit for the current application. For our recommender engine using the recommenderlab package, we will first load the data from a csv file described in the previous section and then explore it using various R functions.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># Load recommenderlab library</strong></span>
<span class="strong"><strong class="calibre9">library("recommenderlab")</strong></span>

<span class="strong"><strong class="calibre9"># Read dataset from csv file</strong></span>
<span class="strong"><strong class="calibre9">raw_data &lt;- read.csv("product_ratings_data.csv")</strong></span>

<span class="strong"><strong class="calibre9"># Create rating matrix from data </strong></span>
<span class="strong"><strong class="calibre9">ratings_matrix&lt;- as(raw_data, "realRatingMatrix")</strong></span>

<span class="strong"><strong class="calibre9">#view transformed data</strong></span>
<span class="strong"><strong class="calibre9">image(ratings_matrix[1:6,1:10])</strong></span>
</pre></div><p class="calibre8">The preceding section of code loads the recommenderlab package and then uses the standard utility function to read the <code class="email">product_ratings_data.csv</code> file. For exploratory as well as further steps, we need the data to be transformed into the user-item ratings matrix format (as described in the <span class="strong"><em class="calibre10">Core concepts and definitions</em></span> section).</p><p class="calibre8">The <code class="email">as(&lt;data&gt;,&lt;type&gt;)</code> utility converts <code class="email">csv</code> into the required ratings matrix format.</p><p class="calibre8">The <code class="email">csv</code> file contains data in the format shown in the following screenshot. Each row contains a <a id="id273" class="calibre1"/>user's rating for a specific product. The column headers are self explanatory.</p><div class="mediaobject"><img src="../images/00133.jpeg" alt="Extract, transform, and analyze" class="calibre11"/><div class="caption"><p class="calibre18">Product ratings data</p></div></div><p class="calibre12"> </p><p class="calibre8">The <code class="email">realRatingMatrix</code> conversion transforms the data into a matrix as shown in the following image. The users are depicted as rows while the columns represent the products. Ratings are represented using a gradient scale where white represents missing/unrated rating while black denotes a rating of 5/best.</p><div class="mediaobject"><img src="../images/00134.jpeg" alt="Extract, transform, and analyze" class="calibre11"/><div class="caption"><p class="calibre18">Ratings matrix representation of our data</p></div></div><p class="calibre12"> </p><p class="calibre8">Now that we have the data in our environment, let us explore some of its characteristics and see if we can decipher some key patterns.</p><p class="calibre8">First of all, we extract a representative sample from our main data set (refer to the screenshot <span class="strong"><em class="calibre10">Product ratings data</em></span>) and analyze it for:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Average <a id="id274" class="calibre1"/>rating score for our user population</li><li class="listitem">Spread/distribution of item ratings across the user population</li><li class="listitem">Number of items rated per user</li></ul></div><p class="calibre8">The following lines of code help us explore our data set sample and analyze the points mentioned previously:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># Extract a sample from ratings matrix</strong></span>
<span class="strong"><strong class="calibre9">sample_ratings &lt;-sample(ratings_matrix,1000)</strong></span>

<span class="strong"><strong class="calibre9"># Get the mean product ratings as given by first user</strong></span>
<span class="strong"><strong class="calibre9">rowMeans(sample_ratings[1,])</strong></span>


<span class="strong"><strong class="calibre9"># Get distribution of item ratings</strong></span>
<span class="strong"><strong class="calibre9">hist(getRatings(sample_ratings), breaks=100,/</strong></span>
<span class="strong"><strong class="calibre9">     xlab = "Product Ratings",main = " Histogram of Product Ratings")</strong></span>

<span class="strong"><strong class="calibre9"># Get distribution of normalized item ratings</strong></span>
<span class="strong"><strong class="calibre9">hist(getRatings(normalize(sample_ratings)),breaks=100,/</strong></span>
<span class="strong"><strong class="calibre9">            xlab = "Normalized Product Ratings",main = /</strong></span>
<span class="strong"><strong class="calibre9">                " Histogram of Normalized Product Ratings")</strong></span>

<span class="strong"><strong class="calibre9"># Number of items rated per user</strong></span>
<span class="strong"><strong class="calibre9">hist(rowCounts(sample_ratings),breaks=50,/</strong></span>
<span class="strong"><strong class="calibre9">     xlab = "Number of Products",main =/</strong></span>
<span class="strong"><strong class="calibre9">     " Histogram of Product Count Distribution")</strong></span>
</pre></div><p class="calibre8">We extract a <a id="id275" class="calibre1"/>sample of 1,000 users from our dataset for exploration purposes. The mean of product ratings as given by the first row in our user-rating sample is <code class="email">2.055</code>. This tells us that this user either hasn't seen/rated many products or he usually rates the products pretty low. To get a better idea of how the users rate products, we generate a histogram of item rating distribution. This distribution peaks around the middle, that is, <code class="email">3</code>. The histogram is shown next:</p><div class="mediaobject"><img src="../images/00135.jpeg" alt="Extract, transform, and analyze" class="calibre11"/><div class="caption"><p class="calibre18">Histogram for ratings distribution</p></div></div><p class="calibre12"> </p><p class="calibre8">The histogram <a id="id276" class="calibre1"/>shows that the ratings are normally distributed around the mean with low counts for products with very high or very low ratings.</p><p class="calibre8">Finally, we check the spread of the number of products rated by the users. We prepare a histogram which shows this spread:</p><div class="mediaobject"><img src="../images/00136.jpeg" alt="Extract, transform, and analyze" class="calibre11"/><div class="caption"><p class="calibre18">Histogram of number of rated products</p></div></div><p class="calibre12"> </p><p class="calibre8">The preceding histogram shows that there are many users who have rated <code class="email">70</code> or more products, as well as there are many users who have rated all <code class="email">100</code> products.</p><p class="calibre8">The exploration <a id="id277" class="calibre1"/>step helps us get an idea of how our data is. We also get an idea about the way the users generally rate the products and how many products are being rated.</p></div></div>

<div class="book" title="Production ready recommender engines">
<div class="book" title="Model preparation and prediction"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec55" class="calibre1"/>Model preparation and prediction</h2></div></div></div><p class="calibre8">We have the <a id="id278" class="calibre1"/>data in our R environment which has been transformed into the ratings matrix format. In this section, we are interested in preparing a recommender engine based on user-based collaborative filtering. We will be using similar terminology as described in the previous sections. Recommenderlab provides straight-forward utilities to learn and prepare a model for building recommender engines.</p><p class="calibre8">We prepare our model based upon a sample of just 1,000 users. This way, we can use this model to predict the missing ratings for the rest of the users in our ratings matrix. The following lines of code utilize the first thousand rows for learning the model:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># Create 'User Based collaborative filtering' model </strong></span>
<span class="strong"><strong class="calibre9">ubcf_recommender &lt;- Recommender(ratings_matrix[1:1000],"UBCF")</strong></span>
</pre></div><p class="calibre8">"<code class="email">UBCF</code>" in the preceding code signifies user-based collaborative filtering. Recommenderlab <a id="id279" class="calibre1"/>also provides other algorithms, such as <span class="strong"><strong class="calibre9">IBCF</strong></span> or <span class="strong"><strong class="calibre9">Item-Based Collaborative Filtering</strong></span>, <span class="strong"><strong class="calibre9">PCA</strong></span> or <span class="strong"><strong class="calibre9">Principal Component Analysis</strong></span>, and <a id="id280" class="calibre1"/>others as well.</p><p class="calibre8">After preparing <a id="id281" class="calibre1"/>the model, we use it to predict the ratings for our 1,010<sup class="calibre15">th</sup> and 1,011<sup class="calibre15">th</sup> users in the system. Recommenderlab also requires us to mention the number of items to be recommended to the users (in the order of preference of course). For the current case, we mention 5 as the number of items to be recommended.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># Predict list of product which can be recommended to given users</strong></span>
<span class="strong"><strong class="calibre9">recommendations &lt;- predict(ubcf_recommender,/</strong></span>
<span class="strong"><strong class="calibre9">                  ratings_matrix[1010:1011], n=5)</strong></span>

<span class="strong"><strong class="calibre9"># show recommendation in form of the list</strong></span>
<span class="strong"><strong class="calibre9">as(recommendations, "list")</strong></span>
</pre></div><p class="calibre8">The preceding lines of code generate two lists, one for each of the users. Each element in these lists is a product for recommendation. The model predicted that, for user 1,010, product <code class="email">prod_93</code> should be recommended as the top most product followed by <code class="email">prod_79</code>, and so on.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># output generated by the model</strong></span>
<span class="strong"><strong class="calibre9">[[1]]</strong></span>
<span class="strong"><strong class="calibre9">[1] "prod_93" "prod_79" "prod_80" "prod_83" "prod_89"</strong></span>

<span class="strong"><strong class="calibre9">[[2]]</strong></span>
<span class="strong"><strong class="calibre9">[1] "prod_80" "prod_85" "prod_87" "prod_75" "prod_79"</strong></span>
</pre></div><p class="calibre8">Recommenderlab is a robust platform which is optimized to handle large datasets. With a few lines of code, we were able to load the data, learn a model, and even recommend products to the users in virtually no time. Compare this with the basic recommender engine we developed using matrix factorization which involved many lines of code (when compared to recommenderlab) apart from the obvious difference in performance.</p></div></div>

<div class="book" title="Production ready recommender engines">
<div class="book" title="Model evaluation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec56" class="calibre1"/>Model evaluation</h2></div></div></div><p class="calibre8">We have successfully <a id="id282" class="calibre1"/>prepared a model and used it for predicting and recommending products to the users in our system. But what do we know about the accuracy of our model? To evaluate the prepared model, recommenderlab has handy and easy to use utilities. Since we need to evaluate our model, we need to split it into training and test data sets. Also, recommenderlab requires us to mention the number of items to be used for testing (it uses the rest for computing the error).</p><p class="calibre8">For the current case, we will use 500 users to prepare an evaluation model. The model will be based on a <a id="id283" class="calibre1"/>90-10 training-testing dataset split with 15 items used for test sets.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># Evaluation scheme</strong></span>
<span class="strong"><strong class="calibre9">eval_scheme &lt;- evaluationScheme(ratings_matrix[1:500],/</strong></span>
<span class="strong"><strong class="calibre9">                      method="split",train=0.9,given=15)</strong></span>

<span class="strong"><strong class="calibre9"># View the evaluation scheme</strong></span>
<span class="strong"><strong class="calibre9">eval_scheme</strong></span>

<span class="strong"><strong class="calibre9"># Training model</strong></span>
<span class="strong"><strong class="calibre9">training_recommender &lt;- Recommender(getData(eval_scheme,/</strong></span>
<span class="strong"><strong class="calibre9">                       "train"), "UBCF")</strong></span>

<span class="strong"><strong class="calibre9"># Preditions on the test dataset</strong></span>
<span class="strong"><strong class="calibre9">test_rating &lt;- predict(training_recommender,/</strong></span>
<span class="strong"><strong class="calibre9">               getData(eval_scheme, "known"), type="ratings")</strong></span>

<span class="strong"><strong class="calibre9">#Error </strong></span>
<span class="strong"><strong class="calibre9">error &lt;- calcPredictionAccuracy(test_rating,/</strong></span>
<span class="strong"><strong class="calibre9">                   getData(eval_scheme, "unknown"))</strong></span>

<span class="strong"><strong class="calibre9">error</strong></span>
</pre></div><p class="calibre8">We use the evaluation scheme to train our model based on the <span class="strong"><em class="calibre10">UBCF</em></span> algorithm. The prepared model from the training dataset is used to predict ratings for the given items. We finally use the method <code class="email">calcPredictionAccuracy</code> to calculate the error in predicting the ratings between known and unknown components of the test set. For our case, we get an output as follows:</p><p class="calibre8"><span class="strong"><img src="../images/00137.jpeg" alt="Model evaluation" class="calibre16"/></span></p><p class="calibre8">The generated output <a id="id284" class="calibre1"/>mentions the values for <span class="strong"><strong class="calibre9">RMSE</strong></span> or root mean squared <a id="id285" class="calibre1"/>error, <span class="strong"><strong class="calibre9">MSE</strong></span> or mean squared error, and <span class="strong"><strong class="calibre9">MAE</strong></span> or mean <a id="id286" class="calibre1"/>absolute error. For RMSE in particular, the values deviate from the correct values by <code class="email">1.162</code> (note that the values might deviate slightly across runs due to various factors such as sampling, iterations, and so on). This evaluation will make more sense when the outcomes are compared from different CF algorithms.</p><p class="calibre8">To evaluate UBCF, we use IBCF as comparison. The following few lines of code help us prepare an IBCF <a id="id287" class="calibre1"/>based model and test the ratings, which can then be compared using the <code class="email">calcPredictionAccuracy</code> utility:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># Training model using IBCF</strong></span>
<span class="strong"><strong class="calibre9">training_recommender_2 &lt;- Recommender(getData(eval_scheme,/</strong></span>
<span class="strong"><strong class="calibre9">                                     "train"), "IBCF")</strong></span>

<span class="strong"><strong class="calibre9"># Preditions on the test dataset</strong></span>
<span class="strong"><strong class="calibre9">test_rating_2 &lt;- predict(training_recommender_2,/</strong></span>
<span class="strong"><strong class="calibre9">                  getData(eval_scheme, "known"),/</strong></span>
<span class="strong"><strong class="calibre9">                type="ratings")</strong></span>

<span class="strong"><strong class="calibre9">error_compare &lt;- rbind(calcPredictionAccuracy(test_rating,/</strong></span>
<span class="strong"><strong class="calibre9">                getData(eval_scheme, "unknown")),/</strong></span>
<span class="strong"><strong class="calibre9">                       calcPredictionAccuracy(test_rating_2,/</strong></span>
<span class="strong"><strong class="calibre9">                getData(eval_scheme, "unknown")))</strong></span>

<span class="strong"><strong class="calibre9">rownames(error_compare) &lt;- c("User Based CF","Item Based CF")</strong></span>
</pre></div><p class="calibre8">The comparative output shows that UBCF outperforms IBCF with lower values of RMSE, MSE, and MAE.</p><p class="calibre8"><span class="strong"><img src="../images/00138.jpeg" alt="Model evaluation" class="calibre16"/></span></p><p class="calibre8">Similarly, we can use the other algorithms available in recommenderlab to test/evaluate our models. We encourage the user to try out a few more and see which algorithm has the least error in predicted ratings.</p></div></div>
<div class="book" title="Summary" id="1394Q1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec31" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this chapter, we continued our pursuit of using machine learning in the field of e-commerce to enhance sales and overall user experience. The previous chapter had discussed recommendations based on transactional logs; in this chapter, we accounted for the human factor and looked into the recommendation engines based on user behavior.</p><p class="calibre8">We started off by understanding what recommendation systems and their classifications into user-based, content-based, and hybrid recommender systems. We touched on the problems associated with recommender engines in general. Then we dived deep into the specifics of collaborative filters and discussed the math around prediction and similarity measures. After getting our basics straight, we moved onto building a recommender engine of our own from scratch. We utilized matrix factorization to build a recommender engine step by step using a small dummy dataset. We then moved onto building a production ready recommender engine using R's popular library called recommenderlab. We used user-based CF as our core algorithm to build a recommendation model on a bigger dataset containing ratings for 100 products by 5,000 users. We closed our discussion by evaluating our recommendation model using recommenderlab's utility methods.</p><p class="calibre8">The next couple of chapters will move from e-commerce to the financial domain and utilize machine learning for some more interesting use cases.</p></div></body></html>