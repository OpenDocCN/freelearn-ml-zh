- en: '*Chapter 2*: Choosing the Right Machine Learning Service in Azure'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*: 在 Azure 中选择正确的机器学习服务'
- en: In the previous chapter, we learned about the end-to-end ML process and all
    the required steps, from data exploration to data preprocessing, training, optimization,
    deployment, and operation. Understanding the whole process will better help us
    in choosing the right service for building cloud-based ML services.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了端到端的机器学习过程以及所有必需的步骤，从数据探索到数据预处理、训练、优化、部署和运营。了解整个过程将更好地帮助我们选择构建基于云的机器学习服务的正确服务。
- en: In this chapter, we will help you navigate the different Azure AI services and
    show you how to select the right service for your ML task. First, we will classify
    the different services by service abstraction and application domain, and then
    look at the different trade-offs and benefits of the different services.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将帮助您了解不同的 Azure 人工智能服务，并展示如何为您的机器学习任务选择正确的服务。首先，我们将根据服务抽象和应用领域对不同的服务进行分类，然后探讨不同服务的不同权衡和益处。
- en: In the next section, we will focus on managed services and jump right into Azure
    Cognitive Services, multiple pre-trained ML services for general tasks and domains.
    We will then cover customized Cognitive Services, which is a way to fine-tune
    a Cognitive Service for a specific task or domain, and end the section by looking
    into applied AI services.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将重点关注托管服务，并直接进入 Azure 认知服务，这是针对一般任务和领域的多个预训练机器学习服务。然后，我们将介绍定制认知服务，这是一种针对特定任务或领域微调认知服务的方法，并在本节结束时探讨应用人工智能服务。
- en: In the following section, we will discuss custom ML services in Azure, such
    as Azure Automated Machine Learning, Azure Machine Learning designer, and the
    Azure Machine Learning service – the service that we will use throughout this
    book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论 Azure 中的定制机器学习服务，例如 Azure 自动机器学习、Azure 机器学习设计器和 Azure 机器学习服务——本书中将使用该服务。
- en: In the last section, we will look into custom compute services, such as Azure
    Databricks, Azure Batch, and Data Science Virtual Machines, for building custom
    ML solutions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们将探讨定制计算服务，例如 Azure Databricks、Azure Batch 和数据科学虚拟机，用于构建定制的机器学习解决方案。
- en: At the end of this chapter, you will know how to navigate the Azure AI landscape
    and understand why Azure Machine Learning is the preferred service to build custom
    ML solutions.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解如何导航 Azure 人工智能领域，并理解为什么 Azure 机器学习是构建定制机器学习解决方案的首选服务。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Choosing an Azure service for ML
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择 Azure 机器学习服务
- en: Managed ML services
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理机器学习服务
- en: Custom ML services
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定制机器学习服务
- en: Custom compute services for ML
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定制计算服务
- en: Choosing an Azure service for ML
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择 Azure 机器学习服务
- en: Azure provides more than 200 services, of which more than 30 services are targeted
    for building solutions for AI and ML. This vast number of services often makes
    it difficult for someone new to Azure to choose the right service for a specific
    task. Choosing the right service for your ML task is the most important decision
    you will have to make when starting with ML in Azure. In this section, we will
    provide clear guidance about how to choose the right ML and compute services in
    Azure.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 提供了超过 200 个服务，其中超过 30 个服务针对构建人工智能和机器学习解决方案。如此众多的服务往往使得 Azure 新手难以选择针对特定任务的正确服务。在
    Azure 中开始机器学习时，为您的机器学习任务选择正确的服务是您必须做出的最重要的决定。在本节中，我们将提供关于如何在 Azure 中选择正确的机器学习和计算服务的明确指导。
- en: The right service with the right layer of abstraction could save you months
    if not years of time to market your ML-based product or feature. It could help
    you avoid tedious time-consuming tasks such as improving model performance through
    transfer learning, re-training, managing, and re-deploying ML models, or monitoring,
    scaling, and operating inference services and endpoints.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 选择正确的服务以及适当的抽象层可以为您节省数月甚至数年的时间来推广基于机器学习的产品或功能。它可以帮助您避免诸如通过迁移学习、重新训练、管理、重新部署机器学习模型，或监控、扩展和操作推理服务和端点等繁琐且耗时的任务。
- en: Choosing the wrong service could mean that you start producing results quickly,
    but it might become impossible to improve model performance for a specific domain
    or extend a model for other tasks. Therefore, having a basic understanding of
    the different Azure AI and ML services will help you to make the right trade-offs
    and choose the right service for your use case. In the next section, we will help
    you navigate the many Azure services and Azure AI landscape to identify the right
    ML service for your use case.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Navigating the Azure AI landscape
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For many cloud-based services, such as compute, storage, database, or analytics,
    the most important choice is the service level abstraction – **Infrastructure
    as a Service** (**IaaS**), **Platform as a Service** (**PaaS**), or **Software
    as a Service** (**SaaS**). *Figure 2.1* shows the difference between the self-managed
    and managed parts of the application stack for cloud services:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – An IaaS versus PaaS versus SaaS comparison for cloud services
    ](img/B17928_02_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – An IaaS versus PaaS versus SaaS comparison for cloud services
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compare the different types of abstractions and responsibilities presented
    in the previous figure. The application stack is built from left to right, starting
    with a *data center* (building, cooling, power, and so on) that contains *hardware*
    (computers, disks, network cards, switches, and so on). Each machine is powered
    by an *operating system* (Linux or Windows) and runs specific *services* (web
    server, database, cache, and so on) and *applications* (for example, WordPress),
    which store and serve your *data* (for example, your custom website):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: With on-premises compute, you own and manage everything – from the building,
    cooling, power, physical servers, network connections, switches, and BIOS, up
    to the operating system, services, applications, and data. If a disk, network
    interface, or power connection fails, you need to get it changed.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With *IaaS* services, you consume infrastructure from your cloud provider such
    as a **Virtual Machine** (**VM**). You choose the number of CPUs, memory, disks,
    network interfaces, and so on, which will all be managed for you, but you need
    to manage the OS as well as all the services, applications, and data yourself.
    If there is an important kernel security update, you need to get it installed.
    IaaS services are the fundamental building blocks for all other services.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PaaS* services let you focus purely on your application. A typical example
    is so-called *serverless compute* such as Azure Functions. Here, you can choose
    your JVM version to deploy a Java-based application, but you don''t need to worry
    about patching your operating system, your service runtime, or the underlying
    hardware. PaaS services often provide a good trade-off between ownership, customization,
    and cost. Most cloud services fall into this category.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, *SaaS* services are whole applications that are designed, implemented,
    and managed by the cloud provider. You usually interact with these services through
    a website or API endpoint, without even knowing what operating system or service
    runtime is used or what the application code or data model looks like. SaaS services
    can be compared with popular web services that we use every day, such as Facebook,
    Netflix, Spotify, or YouTube. Cloud providers often build these services for specific
    use cases, such as IoT, genomics, computer vision, and others.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，*SaaS*服务是由云服务提供商设计、实施和管理的完整应用程序。您通常通过网站或API端点与这些服务交互，甚至不知道使用了什么操作系统或服务运行时，也不知道应用程序代码或数据模型的样子。SaaS服务可以与我们在日常生活中使用的流行网络服务相提并论，例如Facebook、Netflix、Spotify或YouTube。云服务提供商通常为特定的用例构建这些服务，例如物联网、基因组学、计算机视觉等。
- en: 'In conclusion, all Azure services can be placed somewhere on the IaaS, PaaS,
    and SaaS scale based on the level of service abstraction. We can use this scale
    to categorize all Azure AI services into three groups:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，所有Azure服务都可以根据服务抽象级别在IaaS、PaaS和SaaS规模上定位。我们可以使用这个规模将所有Azure AI服务分为三类：
- en: Managed ML services (SaaS)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理型机器学习服务（SaaS）
- en: Custom ML services (PaaS)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定制ML服务（PaaS）
- en: Custom compute services for ML (IaaS)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习定制计算服务（IaaS）
- en: Therefore, your first step in choosing an ML service in Azure is to determine
    the right service-level abstraction for your use case – by choosing the right
    trade-off between flexibility, ownership, skills, time, and cost.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在Azure中选择ML服务的第一步是确定适合您用例的正确服务级别抽象——通过选择正确的灵活性、所有权、技能、时间和成本之间的权衡。
- en: However, choosing an ML service is a bit more nuanced than differentiating only
    between managed and custom services. Especially for managed ML services, we also
    need to compare the different application domains and levels of customization
    and specialization.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，选择ML服务比仅仅区分托管和定制服务要复杂得多。特别是对于托管ML服务，我们还需要比较不同的应用领域和定制及专业化的水平。
- en: Azure provides many pre-trained domain-specific models and services, such as
    object detection, sentiment analysis, recommendation engines, and document parsing.
    Depending on your application domain, you could choose an ML service that includes
    a pre-trained model. For example, if you need a general face-recognition model,
    you could consume this as a managed service from Azure. This means that you don't
    need any training data at all for building such a feature. The decision of using
    a pre-trained model has a huge impact on your project timeline, as acquiring,
    cleaning, and labeling training data is one of the most tedious and time-consuming
    steps in the ML process.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Azure提供了许多预训练的特定领域模型和服务，例如目标检测、情感分析、推荐引擎和文档解析。根据您的应用领域，您可以选择包含预训练模型的ML服务。例如，如果您需要一个通用的面部识别模型，您可以从Azure中作为托管服务来使用它。这意味着您根本不需要任何训练数据来构建这样的功能。使用预训练模型的决定对您的项目时间表有巨大影响，因为获取、清理和标记训练数据是ML过程中最繁琐且耗时的工作之一。
- en: However, many ML applications are built for highly specialized domains such
    as medical data analysis, forensic analysis, and the legal profession. If you
    are building ML-based applications or features for such a domain, a pre-trained
    model without any customization for the application domain might not be the right
    fit. In this case, you can choose a managed ML service that provides customization
    capabilities – a way to use training data to fine-tune a pre-trained model for
    a custom domain. This process is also referred to as transfer learning and supported
    by some managed Azure Machine Learning services.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，许多ML应用是为高度专业化的领域构建的，例如医学数据分析、法医分析和法律职业。如果您正在为这样的领域构建基于ML的应用或功能，没有针对应用领域进行定制的预训练模型可能并不合适。在这种情况下，您可以选择提供定制功能的托管ML服务——一种使用训练数据来微调预训练模型以适应定制领域的方法。这个过程也被称为迁移学习，并得到一些托管Azure机器学习服务的支持。
- en: Some domains or ML-based applications don't fit into this category and can't
    easily be fine-tuned for a different application domain. For example, it's not
    practical to pre-train a recommendation engine on someone else's ratings, transfer
    text-to-speech features to a generative model for classical music, or fine-tune
    a two-dimensional model with three-dimensional image data. In these cases, you
    have no other choice but to create your own models using your own training data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一些领域或基于ML的应用不适合这个类别，并且不能轻易地针对不同的应用领域进行微调。例如，在别人的评分上预训练推荐引擎、将文本到语音功能转移到古典音乐的生成模型，或者用三维图像数据微调二维模型并不实用。在这些情况下，你除了使用自己的训练数据创建自己的模型外别无选择。
- en: 'Using the preceding examples, we can sub-divide the managed and custom ML services
    by the amount of required training data and application domain into the following
    groups:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的例子，我们可以根据所需训练数据量和应用领域将托管和自定义ML服务细分为以下几组：
- en: No training data required
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不需要训练数据
- en: Some training data required for customization
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一些训练数据用于定制
- en: Training data required
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要训练数据
- en: Therefore, the second option to choose a managed or custom ML service is based
    on your application domain and requirements for training data and model specialization.
    Similar to service abstraction, the trade-off is between flexibility (customization),
    ownership, skills, time, and cost.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，选择托管或自定义ML服务的第二个选项取决于你的应用领域以及对训练数据和模型专业化的需求。类似于服务抽象，权衡的是灵活性（定制）、所有权、技能、时间和成本。
- en: 'Let''s compare these requirements and look at a similar IaaS, PaaS, and SaaS
    comparison specifically for cloud-based ML services in *Figure 2.2*:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较这些需求，并查看*图2.2*中专门针对基于云的ML服务的IaaS、PaaS和SaaS比较：
- en: '![Figure 2.2 – An IaaS versus PaaS versus SaaS comparison for ML services ](img/B17928_02_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – IaaS与PaaS与SaaS在ML服务中的比较](img/B17928_02_02.jpg)'
- en: Figure 2.2 – An IaaS versus PaaS versus SaaS comparison for ML services
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – IaaS与PaaS与SaaS在ML服务中的比较
- en: As you can see in the preceding figure, you can evaluate the preferred service
    abstraction for your ML service along similar dimensions as any other cloud service
    – depending on which part of the stack you want to manage yourself. The table
    contains a few adjustments specifically for ML applications, such as *libraries*
    (ML frameworks, tools, and runtimes) instead of services and a *model* instead
    of an application. SaaS services for ML can either allow customization, which
    means you can bring your own data, or don't allow customization, which means you
    don't have to provide any training data at all.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，你可以根据与其他云服务类似的维度评估你ML服务的首选服务抽象——取决于你想要自己管理堆栈的哪一部分。该表包含了一些针对ML应用的特定调整，例如用*库*（ML框架、工具和运行时）代替服务，用*模型*代替应用。ML的SaaS服务可以允许定制，这意味着你可以自带数据，或者不允许定制，这意味着你根本不需要提供任何训练数据。
- en: Armed with this knowledge about service abstractions (IaaS versus PaaS versus
    SaaS) as well as application domain and required training data (no training data
    versus data for customization through transfer learning versus training data),
    we can start dissecting the Azure Machine Learning landscape.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 带着关于服务抽象（IaaS与PaaS与SaaS）以及应用领域和所需训练数据（无训练数据与通过迁移学习进行定制的训练数据）的知识，我们可以开始剖析Azure机器学习领域。
- en: Consuming a managed AI service
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消耗托管AI服务
- en: Consuming a managed AI service through an API is the easiest and quickest way
    to build ML-based features or applications. It's simple because you don't have
    to clean the training data and train the model, you don't have to manage compute
    clusters for training or inferencing, and you don't have to monitor and scale
    your model deployment for making batch predictions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过API消耗托管AI服务是构建基于ML的功能或应用最快、最简单的方式。这是因为你不需要清理训练数据或训练模型，你不需要管理用于训练或推理的计算集群，也不需要监控和扩展你的模型部署以进行批量预测。
- en: For many managed AI services in Azure, all you need is to call a web service
    with your API key and your data, and the API will respond with the corresponding
    prediction, which is often a combination of multiple model scores. The Azure Cognitive
    Services API for understanding images, for example, will return predictions for
    object detection, image tagging, adult content classification, gory and racy classification,
    face detection, gender and age detection, image description, and more within a
    single API call.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: If you are dealing with a general ML problem and a general domain – such as
    image tagging, text extraction, speech-to-text, and translation – you are lucky
    enough to be able to choose such a managed AI service for your application. Image
    analysis for general image domains (such as photos), text analysis, text-to-speech
    and speech-to-text, language, and translation services are common ML problems
    that can take advantage of an off-the-shelf ML solution. We will explore the different
    APIs and services for managed pre-trained AI services later, in the *Azure Cognitive
    Services* section.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: A downside of managed AI services is that they all ship with pre-trained black-box
    models that we can't see, interpret, analyze, or optimize. This makes it infeasible
    to use these APIs for highly specific domains. If you work with MRI images for
    cancer detection, you won't find Azure's general object detection algorithm very
    useful.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: For these specific cases – general ML problems with custom application domains
    – Azure provides customizable managed AI services. One such example is the Azure
    Custom Vision service, which lets you fine-tune a pre-trained model for common
    image recognition tasks. What sets these services apart is that you can provide
    your own training data to fine-tune a model for a custom application domain, while
    benefiting from the advantages of using a managed service.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Another such example is **Azure Form Recognizer**, a tool that allows you to
    extract printed and handwritten text from a structured document. It can be fine-tuned
    to detect custom text formats used in your application domain. We will take a
    look at all of these customizable managed services later, in the *Custom cognitive
    services* and *Azure applied services* sections.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: However, if you need the flexibility of choosing a specific model or algorithm
    that is not supported as a service (for example, image segmentation), then you
    don't have a choice but to implement your own model and build your own AI solution.
    We will dive deeper into this topic in the next section.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Let's end this section with important advice for developing cloud- and ML-based
    features or applications – if possible, opt for a managed service with a pre-trained
    model over building a custom ML solution. Consuming a pre-trained model through
    an API is often magnitudes easier, faster, and cheaper than training, deploying,
    and operating your own ML service. Many practical applications can take advantage
    of generalized pre-trained models or fine-tuned customized models, and the list
    of provided models, services, and domains is constantly growing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we will help you to master the skill of building custom
    ML applications in Azure, to cover all use cases where consuming a managed AI
    service is not possible.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Building a custom AI service
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you can't consume a managed AI service either because there is no model or
    service available for your use case, or the fine-tuning capabilities are not sufficient
    for your application domain, you have no other choice but to build a custom AI
    solution.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: You can choose either PaaS or IaaS services to build a custom AI solution in
    Azure. Both types of services will give you a similar flexibility in choosing
    your own ML ingredients, such as picking your preferred programming language and
    libraries for implementing and training ML models, choosing your own data sources
    and formats as training data, and choosing specific deployment strategies, such
    as optimization for batch prediction or low-latency on-device inferencing.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this flexibility comes at a cost, which is usually significantly higher
    than consuming a pre-trained or customized AI service. The higher costs are a
    result of the additional tasks, skills, and investments required for successfully
    building and operating an ML service. The most important differences for building
    a custom AI solution over consuming an AI service are the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Collecting, preprocessing, and labeling training data
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building infrastructure and automation for training and inferencing
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The modeling, training, and optimization of ML models
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating the ML service in production
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's easy to see that the additional complexity doesn't only come from training
    a custom model but from many other tasks in the end-to-end ML process. The availability
    of a sufficient amount of training data, the quality of the data and the availability
    of people for labeling this data are the major blockers to build a high-performing
    custom AI solutions. Therefore, you need to make sure that training data is available
    before the start of the project or can be acquired during the project.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: The second most important additional cost and resources are related to infrastructure.
    Modeling, training, and optimizing is an ongoing iterative process for the lifetime
    of an ML service. After a deployment, we often collect more training data, record
    model metrics, measure the model drift, and repeat the whole process over and
    over. Therefore, even for smaller ML projects, investments in infrastructure are
    significant but essential for the long-term success of the project.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Larger companies even split these responsibilities into different teams to address
    the need for different skillsets for both areas – one for building and maintaining
    the ML infrastructure and one for ML modeling, training, and optimization. This
    clearly shows that both infrastructure and modeling are equally important for
    developing successful ML projects.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: The best trade-off in terms of flexibility and ownership for building a cloud-based
    custom AI service is to choose a PaaS-based ML platform. Therefore, a great custom
    ML platform supports you with all these infrastructure setups and operations,
    facilitates your modeling and optimization tasks, provides abstractions to encapsulate
    repetitive workloads, and offers automation to minimize manual effort during the
    project life cycle. On top, a custom ML service provides you with the flexibility
    to choose any ML framework, any modeling technique and training algorithm, and
    any data source and format to build a fully custom AI solution.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning is a great example of a PaaS-based service for building
    custom ML solutions and for optimizing the whole end-to-end life cycle of ML projects.
    We will take a closer look at Azure Machine Learning and compare its capabilities
    with other custom ML services later, in the *Custom ML services* section, and
    cover it in much more detail in the subsequent chapters.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will give you all the required skills to build your own custom
    ML service from start to finish, using Azure Machine Learning as your managed
    ML service of choice.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: However, it's worth noting that in order to build custom AI services, you don't
    necessarily need a platform to register your models, to define your datasets,
    or to track your training scores. You can simply pick your favorite compute service
    (for example, Azure Kubernetes Service), your favorite storage service (for example,
    Azure Data Lake Storage), and your favorite database service (for example, Azure
    Cosmos DB) and build your own custom solution. In fact, you can use any compute
    service to build your custom IaaS-based ML application in Azure.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Choosing IaaS services to build your own ML applications gives you the most
    flexibility in terms of choosing any infrastructure component during your ML process.
    On the other hand, it also means that you need to manually set up, configure,
    and integrate these services as well as setting up identities, authentication,
    and access control, which results in a higher upfront investment, higher infrastructure
    development costs, and the need for a specific skillset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Azure provides excellent IaaS compute services to build custom ML solutions.
    You can choose from simple VMs, VMs with pre-installed ML images, batch computation
    services and services for scalable distributed computing. We will see a few service
    examples later, in the *Custom compute services for ML* section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: What is the Azure Machine Learning service?
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we start looking into the specific managed and custom ML services, we
    want to clear some confusion around the term **Azure Machine Learning**, which
    is not only prominent on the cover of this book but also a popular ML service
    in Azure, a workspace for other ML services, and a popular keyword across the
    internet, blogs, and books.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: First and foremost, the term *Azure Machine Learning* stands for a popular Azure
    service ([https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-azure-machine-learning](https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-azure-machine-learning))
    that provides capabilities for building custom ML solutions. The service contains
    different components to manage resources (such as compute clusters and data storage)
    and assets (such as datasets, experiments, models, pipelines, Docker environments,
    and endpoints), as well as access to these resources and assets, all within the
    same workspace.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: This is the service that we will use throughout this book to build an end-to-end
    pipeline for training, deploying, and operating custom ML models. You will start
    by creating your first Azure Machine Learning workspace in the next chapter.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: In order to build custom ML models, you will create training clusters, track
    experiments, register data as datasets, store trained models, manage Docker images
    for training and inferencing, and configure endpoints, all within Azure Machine
    Learning.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we will mostly use the Python APIs ([https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py))
    to interact with Azure Machine Learning. However, you can also use a UI portal
    to access and manage the resources and assets, create experiments, submit training
    jobs, visualize training results, create Docker environments, and deploy inference
    clusters.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: The UI to interact with Azure Machine Learning is called **Azure Machine Learning
    studio** ([https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-machine-learning-studio](https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-machine-learning-studio)).
    This name is not to be confused with an older Azure service, Azure Machine Learning
    Studio – a GUI-based service to create and deploy ML services through a block-based
    drag-and-drop interface, which is now called **Azure Machine Learning Studio (classic)**
    ([https://studio.azureml.net/](https://studio.azureml.net/)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: The Azure Machine Learning service also provides access to other ML services
    that share the same resources and assets through the ML workspace. This includes
    services such as Azure Automated Machine Learner, the Azure Machine Learning designer
    – the new GUI-based experience for Azure Machine Learning, a data labeling tool,
    and an integrated notebook server for Azure Machine Learning (not to be confused
    with the discontinued `https://notebooks.azure.com/experience`), which all can
    be created within a workspace in Azure Machine Learning. Therefore, Azure Machine
    Learning is sometimes referred to as the Azure Machine Learning service or the
    Azure Machine Learning workspace ([https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace)).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Knowing these subtle differences about the different terms and services for
    Azure Machine Learning, you are ready to learn more about the different managed
    and custom ML services in Azure.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Managed ML services
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are dealing with a well-defined general-purpose ML problem in the domain
    of text, image, video, language, or documents, then the chances are high that
    Azure already provides a managed ML service for this problem.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Managed ML services are very easy to use, quick to embed into an application,
    and usually don't require any operational overhead. This makes them perfect for
    creating AI-based applications or features without the need for collecting training
    data, training models, and operating model deployments in production. Most importantly,
    managed ML services don't require any ML expertise to build ML-based applications.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Some examples of well-defined ML problems are image classification, image tagging,
    object detection, face detection, handwriting recognition, speech-to-text and
    text-to-speech conversion, speaker recognition, translation, spell-checking, keywords
    and entity extraction, sentiment analysis, adult content filtering, and document
    parsing.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Managed ML services are usually used with pre-trained models that sometimes
    can be trained or fine-tuned for a specific application domain. Using customized
    models in managed ML services combines the benefits of managed services with the
    flexibility of custom application domains.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will look into Azure Cognitive Services, customizable AI
    services, and Azure Applied AI Services.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Azure Cognitive Services
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's start with Azure's most popular service for managed AI capabilities, Azure
    Cognitive Services. **Azure Cognitive Services** is a collection of APIs containing
    multiple pre-trained ML models for well-defined common problems across the following
    categories – vision, language, speech, and decision.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Cognitive Services models are very easy to use and can be integrated
    by a single REST API call from within any programming language. This makes Cognitive
    Services a popular choice for adding ML capabilities to existing applications.
    Some examples of popular Cognitive Services are the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '*Vision*: Computer Vision and Face API'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Language*: Text analytics and translator service'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Speech*: Text analytics, speech-to-text, text-to-speech, and speech translation'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Decision*: Anomaly detection and content moderation'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the Cognitive Services APIs work very similarly. You first deploy a
    specific Cognitive Service (for example, Computer Vision and text analytics) or
    a Cognitive Services multi-service account in Azure. Once the service is deployed,
    you can retrieve the API endpoint and access key from the service and call the
    Cognitive Service API with your data and API key. This is all you have to do to
    enrich an existing application with AI capabilities.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'To give you a taste of how these services are used, we will walk you through
    an example of the Cognitive Service for Computer Vision. We will embed the functionality
    in a simple Python application. The following code is an example for calling the
    Cognitive Services API for computer vision. We will use the Analyze Image API
    with the free F0 tier to extract categories, tags, and a description from a sample
    image. Let''s start with some setup code so that we can later use the `requests`
    library and fetch predictions from the Cognitive Services API:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the previous code snippet, we defined the region, language, API version,
    and access key for the Cognitive Services API. You can find these details on the
    **Service overview** or **Properties** tab in the Azure portal. We will use these
    components to build the service endpoint. Next, let''s define the parameters for
    the API call, including a URL to an image of the Eiffel Tower:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The only thing that is left is calling requests with all the parameters and
    the image URL. We get back a JSON response containing the scores of multiple models:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As you can see in the preceding code example, using Cognitive Services boils
    down to sending an HTTP request. In Python, this is straightforward, using the
    `requests` library. The response body contains standard JSON and encodes the results
    of the Cognitive Services API. The resulting JSON output from the API will have
    the following structure:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `categories` key contains object categories and derived classifications,
    such as a landmark detection result, including a confidence score. In the example
    of the Eiffel Tower image, the Cognitive Service detected a building with a score
    of almost 95% and identified it as a landmark with almost 100% confidence:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `tags` key shows you multiple tags that are relevant for the whole image.
    In addition, each tag comes with a confidence score. As we can see in the response
    of the API, the model is confident that the picture was taken outdoors:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, the `description` tag gives you more tags and an auto-generated image
    caption. This is cool, isn''t it? Imagine how fast you could implement a tag-based
    image search by simply extracting image tags using Azure Cognitive Services and
    indexing the tags for each image URL:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The result of the Cognitive Services computer vision API is just one example
    of how this service can be used. We requested the image features of categories,
    tags, and description from the API, which are returned as keys of the JSON object.
    Each of the category and tag predictions returns the top results in combination
    with a confidence value. Some categories might trigger other detection models,
    such as faces, handwritten text recognition, and OCR.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'You can explore and test many of the other Azure Cognitive Services APIs by
    visiting the respective service websites. Here are a few examples:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/](https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[https://azure.microsoft.com/en-us/services/cognitive-services/language-service/](https://azure.microsoft.com/en-us/services/cognitive-services/language-service/)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/](https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the preceding example, calling Azure Cognitive Service with `requests`,
    you can implement a method that automatically adds image captions to your product
    images in a retail application by wrapping the preceding snippet in an `analyze()`
    method and applying it to all images in your dataset:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can see that this is the quickest way to integrate a scalable deep learning-based
    image analysis service (such as creating a caption for an image) into your custom
    application. If you find this interesting, it is time to also experiment with
    the other Cognitive Services APIs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: All Azure Cognitive Services have one thing in common – they use a pre-trained
    black-box ML model to perform predictions of the individual ML tasks. This is
    fine when we are dealing with faces or photos but can be problematic when dealing
    with a specific application domain, such as medical images. In this case, you
    will be delighted to hear that you can fine-tune some of the Cognitive Services
    for your custom application domain by providing custom training data. Let's take
    a closer look at these customizable services in the next section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Custom Cognitive Services
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One major downside with Cognitive Services is that you can only use the functionalities
    that are provided by the API. This means you can't customize the labels or tags
    in the image classification API or, for example, use the model to classify different
    types of materials. To do so, you would need to customize the model in the Cognitive
    Services API – and this is exactly what some **custom Cognitive Services** allow
    you to do.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a list of popular customizable Cognitive Service APIs that can be fine-tuned
    to a specific application domain using your own training data:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '*Vision*: Azure Custom Vision'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Language*: Language Understanding and QnA Maker'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Speech*: Custom speech-to-text'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Speech*: Custom text-to-speech'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Speech*: Speaker recognition'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Decision*: Azure Personalizer'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of the preceding services provides an interface to train or customize a
    built-in ML model with your own domain-specific training data. We won't go into
    details for each of these services in this book but rather look at two examples
    of these customizable Cognitive Services – Azure Personalizer and Custom Vision.
    Azure Personalizer is an interesting service that lets you optimize an online
    recommendation engine through reinforcement learning. We will take a closer look
    at Azure Personalizer in [*Chapter 13*](B17928_13_ePub.xhtml#_idTextAnchor202),
    *Building a Recommendation Engine in Azure*, and compare it to other state-of-the-art
    recommendation systems.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Let's look into the Azure Custom Vision service as an example of a customizable
    managed AI service in Azure in this chapter. Azure Custom Vision lets you fine-tune
    a pre-trained ML model on your own training data. This process is called transfer
    learning and is often used in ML to transfer previously learned feature extraction
    capabilities to a new objective or domain.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Custom Vision provides a UI to upload and classify your images (or tag
    your objects) and subsequently train the model, using a state-of-the-art computer
    vision model through the press of a button. *Figure 2.3* shows the finished training
    for an object detection model in the Azure Custom Vision service:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Azure Custom Vision training results ](img/B17928_02_003.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – Azure Custom Vision training results
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: You can see in the preceding figure that training is as easy as clicking the
    **Train** button with the **Quick Test** option enabled at the top right, or customizing
    the training process using the advanced option. You don't have to write any code
    or select an error metric to be optimized; it's all managed for you. In the screenshot,
    you can see the result of training, with three metrics that are automatically
    computed on a validation set. By moving the classification probability threshold
    at the top left, you can even shift the weight toward higher precision or higher
    recall, depending on whether you want to avoid false positives or maximize true
    positives.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'This gives you the power of a pre-trained managed Cognitive Service with the
    flexibility of a custom application domain. Once the model is trained and published,
    it can be consumed using a REST API as we did with Cognitive Services. Click the
    `requests` library:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the preceding code, we implement a function that looks very similar to the
    one we used with Cognitive Services. In fact, only the endpoints and `requests`
    parameter have changed. We can now call the function as before:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The response is also a JSON object and now looks like the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The preceding response now contains a `Predictions` key with all the predicted
    categories and confidence values from Custom Vision. As you can see, the example
    looks very similar to the Cognitive Services example. However, we need to pass
    arguments to specify the project and published iteration of the trained model.
    Using this built-in serving API, we save ourselves a lot of effort in implementing
    and operating a deployment infrastructure. If we want to use the trained model
    somewhere else (for example, in an iPhone or Android application, or in a Kubernetes
    cluster), we can export the model in many different formats, such as TensorFlow,
    TensorFlow.js, Core ML, and ONNX.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Custom Cognitive Services are a fantastic way to efficiently test or showcase
    an ML model for a custom application domain when dealing with a well-defined ML
    problem. You can use either the GUI or API to interact with these services and
    consume the models through a managed API or export them to any device platform.
    Another benefit is that you don't need deep ML expertise to apply the transfer
    learning algorithm and can simply use the predefined models and error metrics.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Azure Applied AI Services
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous sections, we saw examples for Azure Cognitive Services for both
    fully pre-trained models and for customizable models. In this section, we will
    extend the list of customizable managed AI services to all services grouped under
    the name **Azure Applied AI Services**. These Applied AI Services are – like custom
    Cognitive Services – pre-trained customizable AI services loosely grouped under
    a common name to build specialized services.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'These Applied AI Services are all services that have been developed by Microsoft
    on top of Cognitive Services due to strong demand from large enterprise customers
    for these exact services. The following services are currently part of Applied
    AI Services, but unlike Cognitive Services, they don''t fit neatly into categories.
    Here is a list of Applied AI Services that you can use to build your own custom
    models for specific applications:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '*Conversations*: Azure Bot Service'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Documents*: Azure Form Recognizer'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Search*: Azure Cognitive Search'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Monitoring*: Azure Metrics Advisor'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Videos*: Azure Video Analyzer'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Accessibility*: Azure Immersive Reader'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will not go into much detail about every service in this list, but we encourage
    you to look into them in more detail if some of them made you curious. You can
    find detailed information and examples in the Azure documentation ([https://docs.microsoft.com/en-us/azure/applied-ai-services/](https://docs.microsoft.com/en-us/azure/applied-ai-services/))
    or the Azure product page for Applied AI Services ([https://azure.microsoft.com/en-us/product-categories/applied-ai-services](https://azure.microsoft.com/en-us/product-categories/applied-ai-services)).
    Both Azure Form Recognizer and Azure Cognitive Search use the Cognitive Service
    image APIs to extract text and handwritten notes from documents. While the former
    helps you to parse this data from structured documents, the latter creates a search
    index on all extracted data and provides a full-text search over unstructured
    documents, including handwritten documents.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, if you have these exact same problems, then it is easy to use
    these Applied AI Services and integrate them into your application. While the
    application domain is limited, you can greatly accelerate any project that deals
    with these use cases.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: If you require full customization of the algorithms, models, and error metrics,
    you need to implement the model and ML pipeline on your own. In the following
    sections, we will discuss how this can be done in Azure using custom ML services.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Custom ML services
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure provides many PaaS services for different specialized domains. Platform
    services are built on top of IaaS services and implement useful abstractions and
    functionalities commonly used for the relevant domain. One such domain is ML,
    where you will find various services for building custom ML models. In this section,
    we will take a look at the most popular custom ML PaaS services.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: We will start first with the GUI-based solutions Azure Machine Learning Studio
    (classic) and Azure Machine Learning designer, and then switch to the GUI and
    API-based Azure Automated Machine Learning. Finally, we will take a look at Azure
    Machine Learning, the service that provides the workspaces for resources and assets
    for both previous services.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning will help us to create notebook instances for authoring,
    train clusters for training, upload and register datasets, track experiments and
    trained models, as well as to track our Conda/PIP environments and Docker images.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning Studio (classic)
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Azure Machine Learning Studio (classic)** is a widely adopted tool in Azure
    to build, train, optimize, and deploy ML models using a GUI and drag and drop,
    block-based programming model. It''s one of the oldest managed cloud services
    for ML in Azure and provides a robust and large number of features, algorithms,
    and extensions through R and Python support. The service provides built-in building
    blocks for clustering, regression, classification, anomaly detection, and recommendation,
    as well as data and statistical and text analysis. You can also extend the functionality
    of Azure Machine Learning Studio by using custom code blocks for Python or R.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning Studio (classic) will be retired by August 31, 2024,
    and customers will have to transition to Azure Machine Learning. Therefore, we
    strongly recommend starting any new projects in Azure Machine Learning.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.4* shows an overview of the main drag and drop GUI of Azure Machine
    Learning Studio (classic):'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Azure Machine Learning Studio (classic)  ](img/B17928_02_004.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – Azure Machine Learning Studio (classic)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Functional blocks can be chosen from the catalog on the left, dropped onto the
    canvas on the right, and connected to form a complex computational graph. Each
    block can define input and output data, which is passed along through the connections
    from other blocks.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning Studio (classic) lets you import data from many different
    sources, such as CSV files from Azure Blob storage or direct imports from SQL
    Server, Azure Cosmos DB, or Apache Hive. It also provides many built-in blocks
    for the conversion of common data formats and data types, normalization, and cleaning.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: One of the reasons why Azure Machine Learning Studio (classic) was very popular
    lies in its deployment capabilities. If you have created a data pipeline and trained
    a model, you can save the trained model within Machine Learning Studio (classic).
    Now, within a few clicks, you can create a web service using the trained model
    to deploy a scoring service. The user input is defined through the very same data
    import block that was used for the training data. It can be connected to pipe
    user input to the pipeline or return the model predictions to the web service.
    With another click, you can deploy the pipeline to production using a web service
    plan.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: While Azure Machine Learning Studio was a very popular GUI-based tool for building
    ML pipelines – and to build simple web-based ML applications – it is not the tool
    of choice for writing custom ML applications. The workspace can get convoluted
    very quickly, which will make it difficult to follow the data flow through the
    pipeline. Another drawback is that the organization of custom code within blocks
    becomes difficult for larger pipelines, and that there are a limited number of
    integrations into other Azure services. And finally, after many years in service,
    Azure Machine Learning (classic) will be discontinued by 2024.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking for a similar type of block-based programming, with better
    support for code organization and pipelines and better integration into Azure,
    then you should look into Azure Machine Learning designer.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning designer
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While Azure Machine Learning Studio (classic) was very popular and feature-rich,
    its integration into other Azure services has always been limited. Ingesting and
    pre processing data from different data sources is not easy, managing access and
    sharing datasets is difficult, and customizations are limited to Azure Machine
    Learning Studio (classic). However, with the creation of Azure Machine Learning,
    Microsoft also revamped the old Studio and created a new version inside Azure
    Machine Learning called the designer.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Machine Learning designer** is fully integrated with Azure Machine
    Learning and therefore has access to and can share all resources and assets within
    the workspace. It allows the GUI-based creation of ML pipelines while collaborating
    with other data engineers and data scientists in the same workspace. They all
    can share the same compute resources that automatically scale up and down to the
    needs of the developers.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.5* shows the UI of the designer, which is based on the same block-based,
    drag and drop UI as Azure Machine Learning Studio (classic):'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – The Azure Machine Learning designer UI ](img/B17928_02_005.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – The Azure Machine Learning designer UI
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the previous figure, creating ML processes through graphical
    dataflows still has the same disadvantages as discussed previously. However, we
    can at least share data ingestion, preprocessing, cleaning, and feature extraction
    stages with other users in the workspace and focus solely on ML tasks in the designer.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: GUIs to create block-based ML training pipelines are not for everyone. However,
    if you prefer a block-based, drag and drop environment, then Azure Machine Learning
    designer is the right choice for you. On top, all your work is stored in the Azure
    Machine Learning workspace, which means you can easily extend or migrate parts
    of your GUI-based pipeline to a code-based version and vice versa. Overall, it's
    a good choice to start your ML project in Azure Machine Learning using the designer.
    However, if you want to build a scalable ML project that allows the collaboration
    of multiple teams, it's recommended to use a non-GUI service such as the Azure
    Machine Learning workspace, which we will use throughout this book.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Azure Automated Machine Learning
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every user should be given the possibility to create predictive models and turn
    conforming datasets into ML models. This is the democratization of AI, where every
    user who can use a spreadsheet application has the possibility to *create* ML
    models out of data in spreadsheets without any ML expertise.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: This is where **Azure Automated Machine Learning** comes into play! Azure Automated
    Machine Learning is a no-code tool that lets you specify a dataset, a target column,
    and ML tasks to train an ML model from a spreadsheet. It is a great abstraction
    for a user who just wants to fit training data to a target variable without the
    knowledge about feature extraction, modeling, training, and optimization. Similar
    to Azure Machine Learning designer, Automated ML is a service that can be created
    from the Azure Machine Learning workspace and, therefore, has access to all resources
    and assets defined in the workspace.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: It's worth noting that the typical spreadsheet user is not the only target group
    for using Automated ML to automatically train, optimize, and stack ML models.
    Automated ML is a natural extension of hyperparameter tuning, where the model
    architecture and preprocessing itself become hyperparameters. We will take a closer
    look at this field of application and its Python API in [*Chapter 11*](B17928_11_ePub.xhtml#_idTextAnchor178),
    *Hyperparameter Tuning and Automated Machine Learning*.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.6* shows the last step in the Automated ML interface, where the user
    needs to choose the ML task to be solved for the specified data:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Automated ML ](img/B17928_02_006.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – Automated ML
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the previous figure, Automated Machine Learning currently supports
    classification, regression, and time-series forecasting tasks. Together with the
    informative explanations for each task, this is something we can put into the
    hands of Excel users and can help ML engineers to quickly build and deploy a great
    baseline model.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, Automated Machine Learning gives you access to all training runs,
    all trained models, and their training scores, as well as useful built-in metrics,
    visualization, and insights. In *Figure 2.7*, we can see the ROC curve as one
    example of many built-in visualizations of the training runs:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – The Receiver Operating Characteristic (ROC) curve for the Automated
    ML result ](img/B17928_02_007.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – The Receiver Operating Characteristic (ROC) curve for the Automated
    ML result
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'Automated Machine Learning can also be accessed programmatically directly from
    your authoring environment through the Azure Machine Learning SDK. You can find
    more information about the Automated ML feature in the Azure Machine Learning
    Python SDK in the Microsoft documentation: [https://docs.microsoft.com/en-us/python/api/azureml-automl-core/azureml.automl.core?view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/azureml-automl-core/azureml.automl.core?view=azure-ml-py).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Automated Machine Learning is a great service, providing a true ML-as-a-service
    platform with a reasonable abstraction for non-experienced and highly skilled
    users. This service empowers every developer to take advantage of ML and will
    power the AI capabilities of future products.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning workspace
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Azure Machine Learning** is Azure''s flagship ML service to implement and
    automize all steps of the end-to-end ML process for building custom ML applications.
    It was initially built to combine all other ML services under a single workspace
    and facilitate the sharing of resources, assets, and permissions – therefore,
    is also often referred to as the Azure Machine Learning workspace.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Currently, Azure Machine Learning provides, combines, and abstracts many important
    ML infrastructure services and functionalities, such as tracking experiment runs
    and training jobs, a model registry, an environment and container registry based
    on conda/pip and Docker, a dataset registry, pipelines, and compute and storage
    infrastructure. It also implements a common set of identities and permissions
    to facilitate access to these individual components from within the Azure workspace.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Besides all the infrastructure services, it also integrates Azure Automated
    Machine Learning, Azure Machine Learning designer (the new Azure Machine Learning
    Studio (classic)), and a data-labeling service in a single workspace. All the
    services in the workspace can access and share resources and assets. Azure Machine
    Learning provides many useful abstractions and functionalities to develop custom
    ML applications and has a great trade-off in flexibility, ease of use, and price.
    Therefore, it is also our service of choice for building custom ML solutions in
    Azure, and we will use it throughout this book.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.8* shows Azure Machine Learning Studio, the UI of Azure Machine Learning.
    As mentioned previously, the name is not to be confused with Azure Machine Learning
    Studio (classic), which is the old GUI- and block-based ML service.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Azure Machine Learning Studio  ](img/B17928_02_008.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – Azure Machine Learning Studio
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the previous figure, we can manage different resources and
    assets in the Azure Machine Learning workspace. All these resources can not only
    be accessed through the UI but also through the SDK and the Azure Machine Learning
    CLI. Throughout this book, we will mostly use the Python SDK for Azure Machine
    Learning. You can find more information about the Azure Machine Learning Python
    SDK in the Microsoft documentation: [https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the book, we will use three types of compute resources for the different
    steps in the ML process. We can create these resources directly from within Azure
    Machine Learning with a couple of lines of code and the Azure Machine Learning
    SDK:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '**A compute instance for the authoring runtime and Jupyter**: This is a compute
    instance with pre-installed and pre-configured ML libraries and the Azure Machine
    Learning SDK optimized for authoring and experimentation.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A training cluster for the ML execution runtime during training**: This is
    an auto-scalable compute cluster with pre-installed and pre-configured ML libraries
    and the Azure Machine Learning SDK optimized for large- scale training and optimization.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An inferencing cluster for the execution runtime during scoring**: This is
    a managed Kubernetes cluster using Azure Kubernetes Service.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides compute, we will also use Azure Machine Learning to create storage resources
    that serve as storage for authoring and application code, job logs and output,
    visualization, trained models, dataset snapshots, and so on. We can use the ML
    SDK to manage Azure Blob storage containers in the ML workspace and to write the
    output and assets of jobs directly to the storage.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Besides managing infrastructure, Azure Machine Learning can do a lot more for
    us. Most importantly, it can track our experiment runs and collect output files,
    graphs, artifacts, logs, and custom metrics, such as training loss. This is also
    by far the most powerful gateway to enter the Azure Machine Learning platform.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: By simply annotating your existing ML project, you can track all your model
    scores, stream your log output, collect all your output images, and store the
    best model for each iteration or run. All you need is a few simple lines of code
    to never lose track of a model for a particular training run ever again, or to
    keep track of your training scores, graphs, and artifacts. All this can be done
    without changing anything about your ML setup; your experiments can run on a local
    machine and your training runs can be scheduled on AWS.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Besides tracking job artifacts, you can also track dataset versions, environments,
    and models in Azure Machine Learning using only a few lines of code. This gives
    you the benefit of being able to keep a predictable history of changes in your
    workspace. By doing this, you can create repeatable experiments that always read
    the same data snapshot for a training run, use the same specified Conda or PIP
    environment, and update the trained model in the model history and artifact store.
    This brings you on track toward a **Continuous Integration/Continuous Deployment**
    (**CI/CD**) approach for your training pipeline. We will discuss this approach
    in more detail in [*Chapter 16*](B17928_16_ePub.xhtml#_idTextAnchor252), *Bringing
    Models into Production with MLOps*.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of pipelines, Azure Machine Learning lets you abstract your authoring
    code into pipelines. A pipeline can trigger or run data preparation jobs in parallel,
    create and start training clusters, execute a training script on the cluster,
    or initiate and perform blue/green deployments. You can see how everything guides
    you toward a repeatable, versioned, end-to-end pipeline for your training process.
    The greatest part, however, is that you don't have to go all in to benefit from
    Azure Machine Learning.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Instead, you can start little by little, adding more and more useful functionalities
    to your existing training process and then gradually move an existing or new ML
    project to the Azure Machine Learning workspace. You will get your feet wet and
    set up your Azure Machine Learning workspace in the next chapter. This will show
    you how easy it is to get started, to integrate with existing ML projects, and
    how to set up your authoring and training environment for new projects.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning is the best PaaS service for building custom ML applications
    in Azure. However, if you prefer tinkering with VMs, debugging distributed job
    executions, and setting up MPI for distributed training jobs, you should take
    a closer look at the next section, where will learn more about custom compute
    services commonly used for ML.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Custom compute services for ML
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have had a look at services offering managed pre-trained ML models
    with and without some degree of customization, as well as custom ML services,
    including Azure Machine Learning. Azure Machine Learning is our service of choice
    for developing custom ML applications, due to the great trade-off between flexibility,
    functionality, and comfort.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: However, we understand that these trade-offs might not work for everyone and
    that some people want the highest flexibility for building custom ML applications
    using only IaaS services. These are the same services that build the foundation
    for any other PaaS service in Azure, including Azure Machine Learning. Hence,
    as a final step, we will delve into options where you can use custom compute services
    in Azure to build flexible ML solutions.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Azure Databricks
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Azure Databricks** is a managed service on Azure, offering the Databricks
    platform as a completely integrated solution. Azure Databricks is, therefore,
    a so-called first-class citizen in Azure. This means, compared to other third-party
    solutions, a user can deploy from the Azure Marketplace, and it is fully integrated
    with Azure Active Directory, allowing Azure administrators to treat this service
    the same way as any other Microsoft managed service on the platform.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: The Databricks platform itself is a big data analytics platform utilizing Apache
    Spark. The company behind this platform is also called Databricks ([https://databricks.com/](https://databricks.com/))
    and was founded by the original creators of Spark to offer this ever-changing
    open source technology as a ready-made product to customers.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: To understand how to perform ML in Azure Databricks, we will first have a look
    at the underlying technology for distributed computing that powers all computation
    and processing – Apache Spark.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Distributed computing using Apache Spark
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apache Spark is a distributed in-memory analytical engine, taking its roots
    from the Apache Hadoop framework. The main idea behind it is to distribute a graph
    of computations to the cluster's worker nodes. Think of these nodes as different
    independent servers, possibly even in different physical locations, that all together
    work on the same job, or – to be more precise – on their own part of the job.
    They are, in turn, controlled and orchestrated by a primary node that keeps an
    eye on scheduling, resource availability, and wiring up data streams.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.9* shows the most important components of Apache Spark. In the middle,
    we can see the main compute engine called Spark Core. Spark Core oversees job
    scheduling and monitoring, interaction with the underlying storage system, memory
    management on the nodes, and general fault tolerance for the overall cluster.
    For the scheduling, it either uses its own scheduler called **Spark Scheduler**
    or can run on other scheduling options, namely **Apache YARN** or **Apache Mesos**.
    When using Apache Spark in Azure Databricks, the job scheduling engine is part
    of the managed service and managed by Databricks:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – The Apache Spark framework ](img/B17928_02_09.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 – The Apache Spark framework
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: As a storage system, it supports a myriad of options, from standard local storage
    and the **Hadoop Distributed File System** (**HDFS**) to Azure Data Lake and Amazon
    S3 storage, and even has direct access to **Relational Database Management Systems**
    (**RDBMS**) and documents from NoSQL systems.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to define and dispatch jobs, the end user can utilize different programming
    languages, such as Scala, Python and R, to define the computational graphs that
    will be executed via Apache Spark. In addition to all available libraries and
    frameworks, Apache Spark provides a few built-in libraries to facilitate both
    data access and manipulation via Spark SQL, as well as distributed computations
    via Spark Streaming, MLlib, and GraphX.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: ML libraries for Azure Databricks
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To train ML models on Spark and consequently on Azure Databricks, we require
    libraries that, on the one hand, implement the relevant ML algorithms and numerical
    functions and, on the other hand, understand the Spark framework to take advantage
    of the distributed computation primitives.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark comes with such a built-in ML library called MLlib. This library
    is designed to implement traditional ML algorithms, such as different clustering
    and embedding techniques, logistic regression, random forest, gradient boosting,
    and **Alternating Least Squares** (**ALS**) matrix factorization for recommendations,
    while taking advantage of the distributed computation capabilities of Apache Spark.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to the supported languages, you can also use all other popular ML libraries
    in Apache Spark on Azure Databricks, such as TensorFlow, XGBoost, scikit-learn,
    PyTorch, Horovod, and many other well-known libraries (see [https://databricks.com/product/machine-learning-runtime](https://databricks.com/product/machine-learning-runtime)).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Azure Databricks also supports MLflow, an open source framework for automating
    the end-to-end ML process, which we will see in action in [*Chapter 16*](B17928_16_ePub.xhtml#_idTextAnchor252),
    *Bringing Models into Production with MLOps*, as well as their own version of
    AutoML, and a notebook server.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: However, large-scale distributed compute engines usually don't come without
    any downsides, and the same is true for Apache Spark and Databricks. While Databricks
    did a great job of hiding most of the complexity and made it easy to get up and
    running with Spark, the complexity is not gone. Monitoring jobs and utilized cluster
    resources, debugging, and optimizing jobs, as well as reading and understanding
    logs becomes very complex without in-depth knowledge about Spark.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Simply put, in addition to understanding machine learning processes and algorithms,
    the user also has to understand the internals of Spark and its distributed job
    scheduling and execution model. This adds another layer of complexity for running,
    debugging, and optimizing ML jobs, which makes the whole experience a lot more
    difficult.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, not all ML libraries and algorithms are easily capable of distributing
    the workload to different nodes, which often leads to suboptimal utilization of
    the cluster resources. Why use a complex framework for distributed computing and
    pay a premium for primary orchestration nodes when the underlying algorithms are
    executed on a single worker node?
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Azure Databricks is a good choice when migrating on-premises Spark-based services
    to Azure, or building big data analytics, transformation, or recommendation services.
    However, it's complexity and premium price make it most often a poor choice for
    ML projects.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Azure Batch
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Batch is a very mature and flexible batch-processing and scheduling framework
    for running massive parallel workloads in Azure. It lets you define custom applications
    and jobs that can be scheduled and executed on a pool of VMs. It processes data
    stored in Azure Storage and can dynamically scale the compute resources for you
    to up to tens of thousands of VMs. **Azure Batch** is the foundation for Azure
    Machine Learning training clusters and, hence, is a great solution if you want
    to build your own custom ML service.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Azure Batch is usually used for *embarrassing parallel* workloads, namely work
    that can be easily parallelized across multiple machines without the need for
    any orchestration. This makes Azure Batch less flexible than Azure Databricks,
    which provides primitives for distributed coordination, but therefore is also
    less complicated for end users. Typical applications are computing 3D renderings,
    video and image processing, compute-intensive simulations, or general batch computations,
    such as computing recommendation results or batch-scoring ML models.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Batch jobs will be executed on compute pools or custom VMs, which means Azure
    Batch supports many *exotic* compute instances, including high-performance compute
    instances, memory-optimized and GPU-enabled VMs, just to name a few. It also supports
    multi-instance workloads using a **Message Passing Interface** (**MPI**) and **Remote
    Direct Memory Access** (**RDMA**).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: If you are building your custom ML solution and want to avoid the comfort and
    flexibility of Azure Machine Learning, then Azure Batch is a great choice for
    you. It gives you all the flexibility to choose custom instances, frameworks,
    libraries, and data formats. However, Azure Machine Learning is – in almost every
    aspect – a better, easier, and more integrated solution, specifically for building
    ML applications.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Data Science Virtual Machines
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It doesn't require a separate section to explain that you can use traditional
    VMs in Azure for building a custom cloud-based ML service on top of IaaS services.
    This would be as low-level as it gets within a cloud service, where you have full
    control over every network interface, disk configuration, and user permission
    on the VM. You can use any instance type available in your region that fits any
    of your memory, compute, or graphics needs and requirements.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: However, if you are looking for a VM to be your cloud-based ML workstation –
    for example, to take advantage of flexible cloud compute, to run your ML experiments,
    or to perform on-demand GPU-accelerated training – there is a better choice than
    using a standard VM, namely **Data Science Virtual Machines** (**DSVMs**).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: A DSVM is a pre-built pre-configured VM optimized for data science and ML applications.
    It comes with many of the popular ML libraries pre-installed and supports Windows
    and Linux. Pre-installed libraries and services include CUDA and cuDNN, NVIDIA
    drivers and system management interfaces (`nvidia-smi`), CRAN-R, Julia, Python,
    Jupyter, TensorFlow, PyTorch, Horovod, XGBoost, LightGBM, OpenCV, and ONNX. You
    can start a DSVM on many different instance types, including GPU-accelerated instances.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: A DSVM is your service of choice whenever you need a carefree VM with your popular
    ML tools pre-installed and pre-configured. However, it is worth noting that you
    probably don't need a DSVM when working in an Azure Machine Learning workspace,
    as you can create compute instances and training clusters to run your ML experiments
    and training. Nevertheless, it's a great alternative ML experimentation environment.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to navigate the Azure AI landscape and choose
    the right ML service for your application and domain. While IaaS services give
    you great flexibility, PaaS services often provide useful abstractions and manage
    complex integrations for you. SaaS applications are great if they are designed
    for your application domain or can be customized.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: We investigated Azure services for building ML applications in each of the preceding
    categories, such as Azure Cognitive Services (SaaS), Azure Machine Learning (PaaS),
    and Azure Batch (IaaS). Azure Machine Learning is not only the most comprehensive
    and integrated ML service in Azure but also provides a good trade-off between
    flexibility, functionality, and comfort. Therefore, we will use Azure Machine
    Learning throughout this book to develop an end-to-end custom ML solution.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: If you really want to build your own ML infrastructure from scratch and not
    rely on any managed ML service, you should look into custom compute services that
    are optimized for large computational workloads, such as Azure Databricks or Azure
    Batch. If you simply need a VM ready for ML experiments without any pre-built
    service integrations or model and experiment tracking, you can choose a DSVM.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue our journey by setting up an Azure Machine
    Learning workspace. In order to do this, we will first learn how to deploy resources
    in Azure programmatically; we will then have an in-depth look at the ML workspace
    itself, at how we can use notebooks and incorporate compute nodes for model training,
    and finally, we will run our first little experiment.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
