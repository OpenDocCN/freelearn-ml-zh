<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Artificial Neural Network Algorithms</h1>
                </header>
            
            <article>
                
<p><strong>Artificial Neural Networks</strong> (<strong>ANNs</strong>) or, simply NNs, are arguably the most popular <strong>machine learning</strong> (<strong>ML</strong>) tool today, if not necessarily the most widely used. The tech media and commentary of the day love to focus on neural networks, and they are seen by many as the magical algorithm. It is believed that neural networks will pave the way to <strong>Artificial General Intelligence</strong> (<strong>AGI</strong>)—but the technical reality is much different.</p>
<p>While they are powerful, neural networks are highly specialized ML models that focus on solving individual tasks or problems—they are not magical <em>brains</em> that can solve problems out of the box. A model that exhibits 90% accuracy is typically considered good. Neural networks are slow to train and require thoughtful design and implementation. That said, they are indeed highly proficient problem solvers that can unravel even very difficult problems, such as object identification in images.</p>
<p>It is likely that neural networks will play a large part in achieving AGI. However, many other fields of ML and <strong>natural language processing</strong> (<strong>NLP</strong>) will need to be involved. Because ANNs are only specialized problem solvers, it is popularly believed that the way toward AGI is with a large ensemble of thousands of ANNs, each specialized for an individual task. I personally believe that we will see something resembling AGI surprisingly soon. However, AGI will only be achievable initially through immense resources—not in terms of computation power, but rather in terms of training data.</p>
<p>You will learn the basics of neural networks in this chapter. There are many ways to use neural networks, and many possible topologies for them—we'll discuss a number of these in this chapter and <span><span><a href="4b1941f5-8d1d-4796-9dcb-98067bcc5625.xhtml" target="_blank">Chapter 9</a>, <em>Deep Neural Networks</em></span></span>. Each neural network topology has its own purpose, strengths, and weaknesses.</p>
<p>First, we'll discuss neural networks conceptually. We'll examine their components and construction and explore their applications and strengths. We'll have a discussion on the backpropagation algorithm and how ANNs are trained. Then we'll take a brief peek at the mathematics of ANNs, before diving into some practical advice for neural networks in the wild. Finally, we'll demonstrate an example of a simple neural network using the <kbd>TensorFlow.js</kbd> library.</p>
<p>The following are the topics that we will be covering in this chapter:</p>
<ul>
<li>Conceptual overview of neural networks</li>
<li>Backpropagation training</li>
<li>Example—XOR in <kbd>TensorFlow.js</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conceptual overview of neural networks</h1>
                </header>
            
            <article>
                
<p>ANNs have been around almost as long as computers have, and indeed were originally constructed out of electrical hardware. One of the first ANNs was developed in the 1970s to adaptively filter echoes out of phone line transmissions. Despite their initial early success, ANNs waned in popularity until the mid-1980s, when the backpropagation training algorithm was popularized.</p>
<p>ANNs are modeled on our understanding of biological brains. An ANN contains many neurons that connect to one another. The manner, structure, and organization of these neuronal connections is called the <strong>topology</strong> (or <strong>shape</strong>) of the network. Each individual neuron is a simple construct: it accepts several numerical input values and outputs a single numerical value, which may in turn be transmitted to several other neurons. The following is a simple, conceptual example of a neuron:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-313 image-border" src="assets/f8aff5fa-7f2c-459c-bff1-a23a2a686c65.png" style="width:23.50em;height:15.08em;"/></div>
<p>Neurons are typically, but not always, arranged into layers. The specific arrangement and connections between neurons is defined by the network's topology. However, most ANNs will have three or four fully-connected layers, or layers where each neuron in the layer connects to every neuron in the next layer. In these common topologies, the first layer is the input layer and the last layer is the output layer. Input data is fed directly to the input neurons, and the results of the algorithm are read from the output neurons. In between the input and output layers, there are typically one or two hidden layers made up of neurons that the user or programmer doesn't interact with directly. <span>The following diagram shows a neural network with three layers:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-314 image-border" src="assets/0e64e195-6ec8-4b10-917b-34bd80678c4c.png" style="width:28.75em;height:22.58em;"/></div>
<p>The input layer has four neurons, the single hidden layer has six neurons, and the output layer has two neurons. A shorthand for describing this type of network is to list the number of neurons in each layer, so this could be called a <strong>4-6-2 network</strong> for short. Such a network is capable of accepting four different features and can output two pieces of information, such as X/Y coordinates, true/false values for two properties, or even the numbers 0-3 if the output is taken as binary bits.</p>
<p>When using an ANN to make a prediction, you are using the network in feed-forward mode, which is actually quite straightforward. We will discuss the mechanics of neurons in depth, but for now all you need to know is that a neuron takes a number of inputs and generates a single output based on simple weighted sums and a smoothing function (called the <strong>activation function</strong>).</p>
<p>To make a prediction, you load your input data directly into the input neurons. If your problem is an image recognition problem, then each input neuron might be fed the grayscale intensity of a single pixel (you would need 2,500 input neurons to process a 50 x 50 pixel grayscale image). The input neurons are activated, meaning their inputs are summed up, weighted, biased, and the result fed into an activation function which will return a numerical value (typically between -1 and +1, or between 0 and +1). The input neurons in turn send their activation outputs to the neurons in the hidden layer, which experience the same process, and send their results to the output layer, which again becomes activated. The result of the algorithm is the values of the activation functions at the output layer. If your image recognition problem is a classification problem with 15 possible classes, you would have 15 neurons in the output layer, each representing a class label. The output neurons will either return values of 1 or 0 (or fractions in between), and the output neurons with the highest values are the classes that are most likely represented by the image.</p>
<p>In order to understand how networks like these actually produce results, we need to take a closer look at the neuron. Neurons in ANNs have a few different properties. First, a neuron maintains a set (a vector) of weights. Each input to the neuron is multiplied by its corresponding weight. If you look at the topmost neuron in the hidden layer in the preceding image, you can see that it receives four inputs from the neurons in the input layer. The hidden-layer neurons therefore must each have a vector of four weights, one for each of the neurons in the previous layer that send it signals. The weights essentially determine how important a specific input signal is to the neuron in question. For instance, the topmost hidden-layer neuron might have a weight of 0 for the bottom-most input neuron; in that case, the two neurons are essentially unconnected. On the other hand, the next hidden neuron might have a very high weight for the bottom-most input neuron, meaning that it considers its input very strongly.</p>
<p>Each neuron also has a bias. The bias does not apply to any one single input, but instead is added to the sum of the weighted inputs before the activation function is invoked. The bias can be seen as a modifier to the threshold of the neuron's activation. We'll discuss activation functions shortly, but let's take a look at an updated diagram of the neuron:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-315 image-border" src="assets/19a65ada-0abf-4e14-a74d-fa097f51a1f8.png" style="width:26.25em;height:16.92em;"/></div>
<p>A mathematical form for the description of the neuron goes something like this, where bold figures <strong>w</strong> and <strong>x</strong> represent vectors of inputs and weights (that is, [x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>]), non-bold <em>b</em> and <em>y</em> represent the bias of the neuron and output of the neuron, respectively, and <em>fn(...)</em> represents the activation function. Here goes:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><em>y = fn( <strong>w·x</strong> + b)</em></div>
<p>The dot in between <strong>w</strong> and <strong>x</strong> is the vector dot product of the two vectors. Another way to write <strong>w·x</strong> would be <em>w<sub>1</sub>*x<sub>1</sub> + w<sub>2</sub>*x<sub>2</sub> + w<sub>3</sub>*x<sub>3</sub> + … + w<sub>n</sub>*x<sub>n</sub></em>, or simply Σ<em><sub>j</sub> w<sub>j</sub>*x<sub>j</sub></em> .</p>
<p>Taken together, it is the weights and the biases of the neurons in the network that actually do the learning and calculation. When you train a neural network, you are gradually updating the weights and biases with the goal of configuring them to solve your problem. Two neural networks with the same topology (for example, two fully-connected 10-15-5 networks) but different weights and biases are different networks that will solve different problems.</p>
<p>How does the activation function factor into all of this? The original model for an artificial neuron was called the perceptron, and its activation function was a step function. Basically, if <em><strong>w·x</strong> + b</em> for a neuron was greater than zero, the neuron would output 1. If, on the other hand, <em><strong>w·x</strong> + b</em> were less than zero, the neuron would output zero.</p>
<p>This early perceptron model was powerful because it was possible to represent logic gates with an artificial neuron. If you've ever taken a course on Boolean logic or circuits, you would have learned that you can use NAND gates to build any other type of logic gate, and it is trivially easy to build a NAND gate with a perceptron.</p>
<p>Imagine a perceptron that takes two inputs, each with a weight of -2. The perceptron's bias is +3. If both inputs are 0, then <em><strong>w·x</strong> + b = +3</em> (just the weight, because all inputs are zero). Since the perceptron's activation function is a step function, the output of the neuron in this case will be 1 (+3 is greater than zero, so the step function returns +1).</p>
<p>If the inputs are 1 and 0, in any order, then <em><strong>w·x</strong> + b = +1</em>, and therefore the output of the perceptron will also be 1. However, if both inputs are instead 1, then <em><strong>w·x</strong> + b = -1</em>. The two inputs, both weighted -2, will overcome the neuron's bias of +3, and the activation function (which returns 1 or 0), will return 0. This is the logic of the NAND gate: the perceptron will return 0 if both inputs are 1, otherwise it will return 1 for any other combination of inputs.</p>
<p>These early results excited the computer science and electronics community in the 1970s, and ANNs received a lot of hype. However, we had difficulty automatically training neural networks. Perceptron's could be crafted by hand to represent logic gates, and some amount of automated training for neural networks was possible, but large-scale problems remained inaccessible.</p>
<p>The problem was the step function used as the perceptron's activation function. When training an ANN, you want small changes to the weights or biases of the network to similarly result in only small changes to the network's output. But the step function gets in the way of the process; one small change to the weights might result in no change to the output, but the next small change to the weights could result in a huge change to the output! This happens because the step function is not a smooth function—it has an abrupt jump from 0 to 1 once the threshold is crossed, and it is exactly 0 or exactly 1 at all other points. This limitation of the perceptron, and thus the major limitation of ANNs, resulted in over a decade of research stagnation.</p>
<p>Eventually, researchers in 1986 rediscovered a training technique that had been discovered a few years prior. They found that this technique, called <strong>backpropagation</strong>, made training much faster and more reliable. Thus artificial neural networks experienced their second wind.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backpropagation training</h1>
                </header>
            
            <article>
                
<p>There was one key insight that brought neural network research out of stagnation and into the modern era: the choice of a better activation function for neurons. Step functions caused issues with the automated training of networks because tiny changes in the network parameters (the weights and biases) could alternately have either no effect or an abrupt major effect on the network. Obviously, this is not a desired property of a trainable system.</p>
<p>The general approach to automatically training ANNs is to start with the output layer and work backwards. For each example in your training set, you run the network in feed-forward mode (that is, <strong>prediction mode</strong>) and compare the actual output to the desired output. A good metric to use for comparing desired versus actual results is <strong>mean squared error</strong> (<strong>MSE</strong>); test all training examples, and for each calculate and square the difference in output from the desired values. Sum all the squared errors up and average over the number of training examples, and you have a cost function or loss function. The cost function is a function of the weights and biases of a given network topology. The goal in training ANNs is to reduce the cost function to—ideally—zero. You could potentially use the ANN's accuracy over all training examples as a cost function, but mean-squared error has better mathematical properties for training.</p>
<p>The backpropagation algorithm hinges on the following insight: if you know the weights and biases of all neurons, if you know the inputs and desired outputs, and if you know the activation function the neurons use, you can work backwards from an output neuron to discover which weights or biases are contributing to a large error. That is, if neuron Z has neuron inputs A, B, and C with weights of 100, 10, and 0, respectively, you would know that neuron C has no effect on neuron Z and therefore neuron C is not contributing to neuron Z's error. On the other hand, neuron A has an outsized impact on neuron Z, so if neuron Z has a large error it is likely that neuron A is to blame. The backpropagation algorithm is named such because it propagates the error in output neurons backwards through the network.</p>
<p>Taking this concept a step further, if you also know the activation function and its relationship between the weights, biases, and the errors, you can determine how much a weight would need to change in order to get a corresponding change to a neuron's output. Of course, there are many weights in an ANN and it is a highly complex system, so the approach we use is to make tiny changes to the weights<span>—</span>we can only predict changes to the network’s output if we use a simplifying approximation for small changes in weights. This part of the approach is called gradient descent, which is named such because we are trying to descend the gradient (the slope) of the cost function by making small modifications to weights and biases.</p>
<p>To picture this, imagine a nylon hammock hanging between two trees. The hammock represents the cost function, and the <em>x</em> and <em>y</em> axes (viewed from the sky) abstractly represent the biases and weights of the network (in reality, this is a multi-thousand-dimensional picture). There is some combination of weights and biases where the hammock hangs the lowest: that point is our goal. We are a tiny ant sitting somewhere on the surface of the hammock. We don't know where the lowest point of the hammock is, and we're so small that even wrinkles or creases in the fabric can throw us off. But we do know that the hammock is smooth and continuous, and we can feel around our immediate area. As long as we keep heading downhill for each individual step we take, we will eventually find the lowest point in the hammock—or, at least, a low point close to where we started (a local minimum), depending on how complex the shape of the hammock is.</p>
<p>This approach of gradient descent requires us to mathematically understand and be able to describe the gradient of the cost function, which means we must also understand the gradient of the activation function. The gradient of a function is essentially its slope, or derivative. The reason we can’t use the perceptron's original step function as an activation function is because the step function is not differentiable at all points; the giant, instantaneous leap between 0 and 1 in the step function is a non-differentiable discontinuity.</p>
<p>Once we figured out that we should be using gradient descent and backpropagation to train our neural networks, the rest came easily. Instead of using a step function for neuron activation functions, we started using sigmoid functions. Sigmoid functions are generally shaped like step functions, except they are smoothed out, continuous, and differentiable at all points. Here's an example of a sigmoid function versus a step function:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9cd7a8e7-fa84-425a-966c-3efa806bc7ff.png"/></div>
<p>There are many types of sigmoid functions; the preceding one is described by the equation <em>y = 1 / 1+e<sup>-x</sup></em> and is called the <strong>logistic function</strong> or <strong>logistic curve</strong>. Other popular sigmoid functions are hyperbolic tangent (that is, tanh), which has a range from -1 to +1 as opposed to the logistic function's range of 0 to +1. Another popular activation function is the <strong>rectified linear unit</strong> (<strong>ReLU</strong>), which is often used in image processing and output layers. There is also the <em>softplus</em> function, whose derivative is in fact the logistic function itself. The activation function you choose will depend on the specific mathematical properties you desire. It is also not uncommon to use different activation functions in different layers of the network; hidden layers will often use logistic or tanh activation functions, while the output layer might use <em>softmax</em> and the input layer might use ReLU. You can invent your own activation function for your neurons, however, you must be able to differentiate the function and determine its gradient in order to integrate it with the backpropagation algorithm.</p>
<p>This singular, minor change to the neuron's activation function made a world of difference to our training of ANNs. Once we started using differentiable activation functions, we were able to calculate the gradient of the cost and activation functions, and use that information to determine precisely how to update weights in the backpropagation algorithm. Neural network training became faster and more powerful, and neural networks were propelled into the modern era, though they still had to wait for hardware and software libraries to catch up. More importantly, neural network training became a study in mathematics<span>—</span>particularly vector calculus—rather than being limited to study by computer scientists.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Example - XOR in TensorFlow.js</h1>
                </header>
            
            <article>
                
<p>In this example, we're going to solve the XOR problem using a <kbd>TensorFlow.js</kbd> feedforward neural network. First, let's explore the XOR problem, and why it's a good starting point for us.</p>
<p>The XOR, or <em>exclusive or</em> operation, is a Boolean operator that returns true if only one, but not both, of its inputs is truth. Compare this to the regular Boolean OR that you're more commonly familiar with, which will return true if both inputs are true<span>—</span>the XOR will return false if both inputs are true. Here is a table comparing XOR to OR; I've highlighted the case where OR and XOR differ:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><strong>Input 1</strong></td>
<td><strong>Input 2</strong></td>
<td><strong>OR</strong></td>
<td><strong>XOR</strong></td>
</tr>
<tr>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr>
<td>False</td>
<td>True</td>
<td>True</td>
<td>True</td>
</tr>
<tr>
<td>True</td>
<td>False</td>
<td>True</td>
<td>True</td>
</tr>
<tr>
<td>True</td>
<td>True</td>
<td><strong>True</strong></td>
<td><strong>False</strong></td>
</tr>
</tbody>
</table>
<p>Why is the XOR problem a good test for us? Let's plot the XOR operations on a graph:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-large wp-image-174 image-border" src="assets/899339f7-7f6e-42d9-b834-adee57e8fd30.png" style="width:85.33em;height:52.58em;"/></div>
<p>Viewing the preceding graph, we can see that the two classes involved in the <strong>XOR</strong> operation are not linearly separable. In other words, it is impossible to draw a straight line that separates the circles from the X in the preceding graph.</p>
<p>The combined facts that the XOR operation is very simple but also that the classes are not linearly separable make the XOR operation an excellent entry point when testing out a new classification algorithm. You don't need a fancy dataset to test out whether a new library or algorithm will work for you.</p>
<p>Before jumping into the TensorFlow example, let's first discuss how we might build an XOR-solving neural network by hand. We will design our own weights and biases and see whether we can develop a manual neural network that solves XOR.</p>
<p>First, we know that the network requires two inputs and one output. We know that the inputs and output are binary, so we must pick activations functions that have the range [0, 1]; ReLU or sigmoid would be appropriate, while tanh, whose range is [-1, 1] would be less appropriate.</p>
<p>Finally, we know that XOR is not linearly separable and thus cannot be trivially solved; we need a hidden layer in our network. Let's therefore attempt to build a 2-2-1 neural network:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-316 image-border" src="assets/46fef899-238c-4a22-9621-3586a55b7732.png" style="width:26.17em;height:13.92em;"/></div>
<p>Next, we need to think about the weights and biases of the neurons in the network. We know that the network needs to be designed such that there is a penalty for both inputs being true. Therefore, one hidden-layer neuron should represent a weakly positive signal (that is, it activates when the inputs are activated) and the other hidden-layer neuron should represent a strongly negative signal (that is, if both inputs are true, this neuron should overwhelm the weakly-positive neuron).</p>
<p>Here's an example of one set of weights that would work to achieve XOR:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-317 image-border" src="assets/06a64a8c-ae56-4816-94a8-2307194ee0dc.png" style="width:27.92em;height:16.75em;"/></div>
<p>Let's run a few example calculations. I'll start with the differentiating case of both inputs being true. The hidden <strong>h1</strong> neuron will have a total weighted input of 4, because the weight for each input is 2 and both inputs are true. The h1 neuron also has a bias of -1, however, the bias is not enough to deactivate the neuron. The total sum of the biased inputs is therefore 3 for the h1 neuron; since we haven't decided on a specific activation function, we will not try to guess what the actual activation will become<span>—</span>suffice to say that an input of +3 is enough to activate the neuron.</p>
<p>We now turn our attention to the hidden <strong>h2</strong> neuron. It also receives input from both input neurons, however, these weights are negative, and so the unbiased input sum it receives is -4. The bias on h2 is +3, so the total biased input for h2 is -1. If we were to choose the ReLU activation function, the neuron's output would be zero. In any case, h2 is not activated.</p>
<p>Finally, we look at the output node. It receives a weighted input of +2 from h1, but receives no input from h2. Since the output node’s bias is -3 (essentially requiring both h1 and h2 to be activated), the output node will return 0 or false. This is the expected result for XOR with both inputs being set to true or 1.</p>
<p>Let's similarly tabulate the results for the other XOR cases. The columns for <kbd>h1</kbd>, <kbd>h2</kbd>, and <kbd>Out</kbd> represent the weighted and biased input to the neuron, before being applied to an activation function (since we haven't chosen one). Just remember that each neuron will transmit values in [0, 1] to the next neuron; it will not send values such as -1 or 3 after the activation function is applied:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>In 1</strong></p>
</td>
<td>
<p><strong>In 2</strong></p>
</td>
<td>
<p><strong>h1</strong></p>
</td>
<td>
<p><strong>h2</strong></p>
</td>
<td>
<p><strong>Out</strong></p>
</td>
</tr>
<tr>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>-1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>-1</p>
</td>
</tr>
<tr>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>-1</p>
</td>
<td>
<p>-1</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The preceding table proves that the handcrafted ANN works for all XOR test cases. It also gives us a little insight into the inner workings of a network. The hidden h1 and h2 neurons have specific roles. The h1 neuron is off by default but easily satisfied and will become activated if any of the inputs are active; h1 is essentially a typical OR operation. On the other hand, h2 is on by default and can only be deactivated if both inputs are on; h2 is essentially a NAND operation. The output neuron requires both h1 and h2 to be active, therefore the output neuron is an AND operator.</p>
<p>Let's now use the <kbd>TensorFlow.js</kbd> library and see whether we can achieve the same success. On your computer, create a new folder called <kbd>Ch8-ANN</kbd>. Add the following <kbd>package.json</kbd> file and then issue <kbd>yarn install</kbd>:</p>
<pre>{<br/>  <span>"name"</span>: <span>"Ch8-ANN"</span>,<br/>  <span>"version"</span>: <span>"1.0.0"</span>,<br/>  <span>"description"</span>: <span>"ML in JS Example for Chapter 8 - ANN"</span>,<br/>  <span>"main"</span>: <span>"src/index.js"</span>,<br/>  <span>"author"</span>: <span>"Burak Kanber"</span>,<br/>  <span>"license"</span>: <span>"MIT"</span>,<br/>  <span>"scripts"</span>: {<br/>    <span>"build-web"</span>: <span>"browserify src/index.js -o dist/index.js -t [ babelify --presets [ env ] ]"</span>,<br/>    <span>"build-cli"</span>: <span>"browserify src/index.js --node -o dist/index.js -t [ babelify --presets [ env ] ]"</span>,<br/>    <span>"start"</span>: <span>"yarn build-cli &amp;&amp; node dist/index.js"<br/></span><span>  </span>},<br/>  <span>"dependencies"</span>: {<br/>    <span>"@tensorflow/tfjs"</span>: <span>"^0.9.1"</span>,<br/>    <span>"babel-core"</span>: <span>"^6.26.0"</span>,<br/>    <span>"babel-plugin-transform-object-rest-spread"</span>: <span>"^6.26.0"</span>,<br/>    <span>"babel-preset-env"</span>: <span>"^1.6.1"</span>,<br/>    <span>"babelify"</span>: <span>"^8.0.0"</span>,<br/>    <span>"browserify"</span>: <span>"^15.1.0"<br/></span><span>  </span>}<br/>}</pre>
<p>Now add the <kbd>src/index.js</kbd> file and import TensorFlow:</p>
<pre><span>import </span>* as tf from <span>'@tensorflow/tfjs'</span>;</pre>
<p>TensorFlow is not simply an ANN library. The TensorFlow library provides a number of building blocks that are useful in both ANNs and general ML and linear algebra (that is, vector/matrix math) problems. Because TensorFlow is more of a toolbox than a singular tool, there will always be many ways to solve any given problem. </p>
<p>Let's start by creating a sequential model: </p>
<pre><span>const </span>model = tf.sequential();</pre>
<p>TensorFlow <em>models</em> are high-level containers that essentially run functions; they are mapping from input to output. You can use TensorFlow's low-level operators (the linear algebra tools that come with the library) to build your model, or you can use one of the higher-level model classes. In this case, we are building a <em>sequential model</em>, which is a special case of TensorFlow's generic model. You may think of a sequential model as a neural network that only feeds forward, and does not involve any recurrences or feedback loops internally. A sequential model is essentially a vanilla neural network. </p>
<p>Next, let's add layers to the model:</p>
<pre>model.add(tf.layers.dense({units: 4, activation: <span>'relu'</span>, inputDim: <span>2</span>}));<br/>model.add(tf.layers.dense({units: 4, activation: <span>'relu'</span>}));<br/>model.add(tf.layers.dense({units: <span>1</span>, activation: <span>'sigmoid'</span>}));</pre>
<p>We are adding three layers to our model. All layers are <strong>dense</strong> layers, meaning they are fully connected to the next layer. This is what you'd expect from a vanilla neural network. We've specified the <em>units</em> for each layer<span>—</span>units is TensorFlow's name for neurons, since TensorFlow can be used outside of ANN contexts. I've set this example up with four neurons per layer rather than two, because I found that the extra neurons greatly improve the speed and resilience of the training process. We've specified <kbd>inputDim</kbd><em> </em>in the first layer, telling the layer that it should expect two inputs per data point. The first and second layers use the ReLU activation function. The third layer, which is the output layer, has only one unit/neuron and uses the familiar sigmoid activation function, since I would like the results to snap more readily toward 0 or 1. </p>
<p>Now we must compile the model before we can use it. We will specify a loss function, which can be either a prebuilt loss function that ships with the library or a custom loss function that we provide. We will also specify our optimizer; we discussed gradient descent earlier in this chapter, but there are many other optimizers available, such as Adam, Adagrad, and Adadelta. In this case, we will use the stochastic gradient descent optimizer (typical for vanilla neural networks), however, we will choose the <kbd>binaryCrossentropy</kbd> loss function, which is more appropriate than mean squared error for our binary classification task: </p>
<pre><span>const </span>learningRate = <span>1</span>;<br/><span>const </span>optimizer = tf.train.sgd(learningRate);<br/>model.compile({loss: <span>'binaryCrossentropy'</span>, optimizer, metrics: [<span>'accuracy'</span>]});</pre>
<p>We've also set the learning rate for the gradient descent optimizer; the learning rate dictates how much the backpropagation training algorithm will modify the weights and biases in each training generation or epoch. A lower learning rate will result in a longer time to train the network, but will be more stable. A higher learning rate will train the network more quickly, but less reliably; your network may not converge at all if the learning rate is too high. </p>
<p>Finally, we've added <kbd>metrics: ['accuracy']</kbd> to the compilation step. This allows us to get a report on the network's accuracy when we eventually call <kbd>model.evaluate</kbd>.</p>
<p>Next we'll set up our training data, which is simply four data points. TensorFlow operates on <em>tensors</em>, which are essentially mathematical matrices. TensorFlow tensors are immutable, and all operations performed on tensors will return new tensors rather than modifying the existing tensor. If you need to modify tensors in place, you must use TensorFlow's <em>variables,</em> which are mutable wrappers around tensors. TensorFlow requires all math be performed through tensors so that the library can optimize calculations for GPU processing: </p>
<pre><span>// XOR data x values.<br/></span><span>const </span>xs = tf.tensor([<br/>    [<span>0</span>, <span>0</span>],<br/>    [<span>0</span>, <span>1</span>],<br/>    [<span>1</span>, <span>0</span>],<br/>    [<span>1</span>, <span>1</span>]<br/>],<br/><span>// Shape of the tensor is 4 rows x 2 cols<br/></span>[<span>4</span>, <span>2</span>]);<br/><br/><span>// XOR data y values.<br/></span><span>const </span>ys = tf.tensor([ <span>0</span>, <span>1</span>, <span>1</span>, <span>0 </span>], [<span>4</span>, <span>1</span>]);</pre>
<p>Because tensors are matrices, every tensor has a <em>shape</em>. Shape, for 2D tensors, is defined as <em>[rows, cols]</em>. For 3D tensors, shape is <em>[rows, cols, depth]</em>; image processing typically uses 3D tensors, where rows and cols represent pixel Y and X coordinates, and depth represents a color channel (for example, RGBA) for that pixel. Since we have four training examples, and each training example requires two fields for inputs, our input tensor has a shape of four rows by two columns. Similarly, our target values tensor has a shape of four rows by one column. TensorFlow will throw errors if you attempt to run calculations or train models with the wrong input and output shapes. </p>
<p>Our last step is to train the model with the data and then evaluate the model. TensorFlow's <kbd>model.fit</kbd> method is what trains the model, and once trained we can use <kbd>model.evaluate</kbd> to get statistics, such as accuracy and loss, and we can also use <kbd>model.predict</kbd> to run the model in feedforward or prediction mode:</p>
<pre>model.fit(xs, ys, {epochs: <span>1000</span>}).then(() =&gt; {<span><br/></span><span>    </span>console.log(<span>"Done training. Evaluating model..."</span>);<br/>    <span>const </span>r = model.evaluate(xs, ys);<br/><br/>    console.log(<span>"Loss:"</span>);<br/>    r[<span>0</span>].print();<br/>    console.log(<span>"Accuracy:"</span>);<br/>    r[<span>1</span>].print();<br/><br/>    console.log(<span>"Testing 0,0"</span>);<br/>    model.predict(tf.tensor2d([<span>0</span>, <span>0</span>], [<span>1</span>, <span>2</span>])).print();<br/>    console.log(<span>"Testing 0,1"</span>);<br/>    model.predict(tf.tensor2d([<span>0</span>, <span>1</span>], [<span>1</span>, <span>2</span>])).print();<br/>    console.log(<span>"Testing 1,0"</span>);<br/>    model.predict(tf.tensor2d([<span>1</span>, <span>0</span>], [<span>1</span>, <span>2</span>])).print();<br/>    console.log(<span>"Testing 1,1"</span>);<br/>    model.predict(tf.tensor2d([<span>1</span>, <span>1</span>], [<span>1</span>, <span>2</span>])).print();<br/>});</pre>
<p>Once you've added the code, run <kbd>yarn start</kbd> from the command line. Running this model takes about 60 seconds for me. When the model finishes, you should see something similar to the following as output. Note that ANNs and the stochastic gradient descent optimizer use random values for initialization and processing, and therefore some runs of the model may be unsuccessful, depending on the specific random initial conditions. The following is the output that will be obtained:</p>
<pre><strong>Done training. Evaluating model...</strong><br/><strong> Loss:</strong><br/><strong> Tensor</strong><br/><strong> 0.00011571444338187575</strong><br/><strong> Accuracy:</strong><br/><strong> Tensor</strong><br/><strong> 1</strong><br/><strong> Testing 0, 0</strong><br/><strong> Tensor</strong><br/><strong> [[0.0001664],]</strong><br/><strong> Testing 0, 1</strong><br/><strong> Tensor</strong><br/><strong> [[0.9999378],]</strong><br/><strong> Testing 1, 0</strong><br/><strong> Tensor</strong><br/><strong> [[0.9999322],]</strong><br/><strong> Testing 1, 1</strong><br/><strong> Tensor</strong><br/><strong> [[0.0001664],]</strong></pre>
<p>The preceding output shows that the model has learned to emulate XOR. The loss value is very low, while the accuracy is 1.0, which is what's required for such a simple problem. In real-world problems, accuracies of 80-90% are more realistic. Additionally, the program's output shows the individual predictions for each of the four test cases. You can see the effect of the sigmoid activation function in that the values get very close to 0 and 1, but don't quite get there. Internally, TensorFlow is rounding these values in order to determine whether the classification was correct.</p>
<p>At this point, you should play with the network parameters a bit. What happens if you reduce the number of training epochs? What happens if you switch the ReLU layers to sigmoid layers? What happens if you reduce the number of units/neurons in the first two layers to two? Does it work if you increase the number of training epochs? What is the effect of the learning rate on the training process? These are things that are best discovered through trial and error rather than lecture. This is an infinitely flexible neural network model, capable of handling much more complex problems than the simple XOR example, so you should become intimately familiar with all of these properties and parameters through experimentation and research.</p>
<p>While this example was only a simple XOR sample, this approach can also be used for many other types of ANN problems. We've created a three-layered binary classifier that automatically trains and evaluates itself<span>—</span>it's the ultimate vanilla neural network. I will leave it to you to take these concepts and apply them to your real-world problems, though in the next chapter we'll try out some advanced neural models, such as convolutional and recurrent networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>This chapter introduced and described the concept of artificial neural networks. We first discussed ANNs from a conceptual standpoint. You learned that neural networks are made of individual neurons, which are simple weighted adding machines that can apply an activation function to their output. You learned that neural networks can have many topologies, and it is the topology and the weights and biases between neurons in the network that do the actual work. You also learned about the backpropagation algorithm, which is the method by which neural networks are automatically trained. </p>
<p>We also looked at the classic XOR problem and looked at it through the lens of neural networks. We discussed the challenges and the approach to solving XOR with ANNs, and we even built<span>—</span>by hand!<span>—</span>a fully-trained ANN that solves the XOR problem. We then introduced the <kbd>TensorFlow.js</kbd> library and built a vanilla neural network with it, and successfully used that NN to train and solve the XOR problem.</p>
<p>In the next chapter, we're going to take a deeper look at the advanced ANN topologies. In particular, we'll discuss the <strong>Convolutional Neural Network</strong> (<strong>CNN</strong>), which is widely used in image processing, and we'll also look at <strong>recurrent neural networks</strong> (<strong>RNN</strong>), which are commonly used in artificial intelligence and natural language tasks.</p>


            </article>

            
        </section>
    </body></html>