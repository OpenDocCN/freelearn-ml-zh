<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Delving into Histogram and Filters</h1>
                </header>
            
            <article>
                
<p>In the last chapter, we learned the basics of user interfaces in OpenCV, using Qt libraries or native ones; we also learned how to use advanced OpenGL user interfaces. We learned about basic color conversions, and filters that allow us to create our first application. This chapter will introduce you to the following concepts:</p>
<ul>
<li>Histogram and histogram equalization</li>
<li>Look-up tables</li>
<li>Blur and median blur</li>
<li>Canny filter</li>
<li>Image-color equalization</li>
<li>Understanding the conversion between image types</li>
</ul>
<p>After we learn the basics of OpenCV and user interfaces, we are going to create our first complete application in this chapter, a basic photo tool, and cover the following topics:</p>
<ul>
<li>Generating a CMake script file</li>
<li>Creating the graphical user interface</li>
<li>Calculating and drawing a histogram</li>
<li>Histogram equalization</li>
<li>The lomography camera effect</li>
<li>The cartoonize effect</li>
</ul>
<p>This application will help us to understand how to create an entire project from scratch and understand the histogram concept. We will see how to equalize the histogram of the color image and create two effects, using a combination of filters and the use of look-up tables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>This chapter requires<span> </span>familiarity<span> </span>with the basics of the C++ programming language. All the code used in this chapter can be downloaded from the following GitHub link: <a href="https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_04">https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_04</a>. The code can be executed on any operating system, though it is only tested on Ubuntu.</p>
<p>Check out the following video to see the Code in Action:<br/>
<a href="http://bit.ly/2Sid17y">http://bit.ly/2Sid17y</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generating a CMake script file</h1>
                </header>
            
            <article>
                
<p>Before we start creating our source file, we are going to generate the <kbd><span class="CodeInTextPACKT">CMakeLists.txt</span></kbd> file to allow us to compile our project, structure it, and execute it. The following CMake script is simple and basic but enough to compile and generate the executable:</p>
<pre>cmake_minimum_required (VERSION 3.0)<br/><br/>PROJECT(Chapter4_Phototool)<br/><br/>set (CMAKE_CXX_STANDARD 11)<br/><br/># Requires OpenCV<br/>FIND_PACKAGE( OpenCV 4.0.0 REQUIRED )<br/>MESSAGE("OpenCV version : ${OpenCV_VERSION}")<br/><br/>include_directories(${OpenCV_INCLUDE_DIRS})<br/>link_directories(${OpenCV_LIB_DIR})<br/><br/>ADD_EXECUTABLE(${PROJECT_NAME} main.cpp)<br/>TARGET_LINK_LIBRARIES(${PROJECT_NAME} ${OpenCV_LIBS})</pre>
<p>The first line indicates the minimum CMake version required to generate our project, the second one sets the project name that we can use as the <kbd>${PROJECT_NAME}</kbd> variable, and the third one sets the required C++ version; in our case, we require the <strong>C++11</strong> version, as we can see in the next snippet:</p>
<pre>cmake_minimum_required (VERSION 3.0)<br/><br/>PROJECT(Chapter4_Phototool)<br/><br/>set (CMAKE_CXX_STANDARD 11)</pre>
<p>Moreover, we require the OpenCV library. First, we need to find the library, and then we'll show a message on the OpenCV library version found with the <kbd><span class="CodeInTextPACKT">MESSAGE</span></kbd> function:</p>
<pre># Requires OpenCV 
FIND_PACKAGE( OpenCV 4.0.0 REQUIRED ) 
MESSAGE("OpenCV version : ${OpenCV_VERSION}") </pre>
<p>If the library, with a minimum version of 4.0, is found, then we include the headers and library files in our project:</p>
<pre>include_directories(${OpenCV_INCLUDE_DIRS}) 
link_directories(${OpenCV_LIB_DIR})</pre>
<p>Now, we only need to add the source files to compile and link with the OpenCV library. T<span>he project name variable is</span> used as the executable name, and we use only a single source file, called <kbd><span class="CodeInTextPACKT">main.cpp</span></kbd>:</p>
<pre>ADD_EXECUTABLE(${PROJECT_NAME} main.cpp) 
TARGET_LINK_LIBRARIES(${PROJECT_NAME} ${OpenCV_LIBS})</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the graphical user interface</h1>
                </header>
            
            <article>
                
<p>Before we start with the image processing algorithms, we create the main user interface for our application. We are going to use the Qt-based user interface to allow us to create single buttons. The application receives one input parameter to load the image to process, and we are going to create four buttons, as follows:</p>
<ul>
<li><span class="packt_screen">Show histogram</span></li>
<li><span class="packt_screen">Equalize histogram</span></li>
<li><span class="packt_screen">Lomography effect</span></li>
<li><span class="packt_screen">Cartoonize effect</span></li>
</ul>
<p>We can see the four results in the following screenshot:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-808 image-border" src="assets/a38b1318-6814-42a2-9531-c45262b6fedd.png" style="width:44.83em;height:33.67em;"/></div>
<p>Let's begin developing our project. First of all, we are going to include the OpenCV – required headers, define an <span class="CodeInTextPACKT">image</span> matrix to store the input image, and create a constant string to use the new command-line parser already available from OpenCV 3.0; in this constant, we allow only two input parameters, <kbd>help</kbd> and the required image input:</p>
<pre>// OpenCV includes 
#include "opencv2/core/utility.hpp" 
#include "opencv2/imgproc.hpp" 
#include "opencv2/highgui.hpp" 
using namespace cv; 
// OpenCV command line parser functions 
// Keys accepted by command line parser 
const char* keys = 
{ 
   "{help h usage ? | | print this message}" 
    "{@image | | Image to process}" 
}; </pre>
<p>The main function starts with the command-line parser variable; next, we set the about instruction and print the help message. This line sets up the help instructions of our final executable:</p>
<pre>int main(int argc, const char** argv) 
{ 
   CommandLineParser parser(argc, argv, keys); 
    parser.about("Chapter 4. PhotoTool v1.0.0"); 
    //If requires help show 
    if (parser.has("help")) 
   { 
       parser.printMessage(); 
       return 0; 
   } </pre>
<p>If the user doesn't require help, then we have to get the file path image in the <kbd><span class="CodeInTextPACKT">imgFile</span></kbd> variable string and check that all required parameters are added with the <kbd><span class="CodeInTextPACKT">parser.check()</span></kbd> function:</p>
<pre>String imgFile= parser.get&lt;String&gt;(0); 
 
// Check if params are correctly parsed in his variables 
if (!parser.check()) 
{ 
    parser.printErrors(); 
    return 0; 
}</pre>
<p>Now, we can read the image file with the <kbd><span class="CodeInTextPACKT">imread</span></kbd> function, and then create the window in which the input image will be shown later with the <kbd><span class="CodeInTextPACKT">namedWindow</span></kbd> function:</p>
<pre>// Load image to process 
Mat img= imread(imgFile); 
 
// Create window 
namedWindow("Input"); </pre>
<p>With the image loaded and the window created, we only need to create the buttons for our interface and link them with the callback functions; each callback function is defined in the source code and we are going to explain these functions later in this chapter. We are going to create the buttons with the <kbd><span class="CodeInTextPACKT">createButton</span></kbd> function with the <kbd><span class="CodeInTextPACKT">QT_PUSH_BUTTON</span></kbd> constant to button style:</p>
<pre>// Create UI buttons 
createButton("Show histogram", showHistoCallback, NULL, QT_PUSH_BUTTON, 0); 
createButton("Equalize histogram", equalizeCallback, NULL, QT_PUSH_BUTTON, 0); 
createButton("Lomography effect", lomoCallback, NULL, QT_PUSH_BUTTON, 0); 
createButton("Cartoonize effect", cartoonCallback, NULL, QT_PUSH_BUTTON, 0); </pre>
<p>To finish our main function, we show the input image and wait for a key press to finish our application:</p>
<pre>// Show image 
imshow("Input", img); 
 
waitKey(0); 
return 0; </pre>
<p>Now, we only have to define each callback function, and in the next sections, we are going to do just that.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Drawing a histogram</h1>
                </header>
            
            <article>
                
<p>A histogram is a statistical graphic representation of variable distribution that allows us to understand the density estimation and probability distribution of data. A histogram is created by dividing the entire range of variable values into a small range of values, and then counting how many values fall into each interval.</p>
<p class="mce-root"/>
<p>If we apply this histogram concept to an image, it seems to be difficult to understand but, in fact, it is very simple. In a gray image, our variable values' ranges are each possible gray value (from <kbd>0</kbd> to <kbd>255</kbd>), and the density is the number of pixels of the image that have this value. This means that we have to count the number of pixels of the image that have a value of <kbd>0</kbd>, the number of pixels with a value of <kbd>1</kbd>, and so on.</p>
<p>The callback function that shows the histogram of the input image is <kbd><span class="CodeInTextPACKT">showHistoCallback</span></kbd> ; this function calculates the histogram of each channel image and shows the result of each histogram channel <span>in a new image</span>.</p>
<p>Now, check the following code:</p>
<pre>void showHistoCallback(int state, void* userData) 
{ 
    // Separate image in BRG 
    vector&lt;Mat&gt; bgr; 
    split(img, bgr); 
 
    // Create the histogram for 256 bins 
    // The number of possibles values [0..255] 
    int numbins= 256; 
 
    /// Set the ranges for B,G,R last is not included 
    float range[] = { 0, 256 } ; 
    const float* histRange = { range }; 
 
    Mat b_hist, g_hist, r_hist; 
 
    calcHist(&amp;bgr[0], 1, 0, Mat(), b_hist, 1, &amp;numbins, &amp;histRange); 
    calcHist(&amp;bgr[1], 1, 0, Mat(), g_hist, 1, &amp;numbins, &amp;histRange); 
    calcHist(&amp;bgr[2], 1, 0, Mat(), r_hist, 1, &amp;numbins, &amp;histRange); 
 
    // Draw the histogram 
    // We go to draw lines for each channel 
    int width= 512; 
    int height= 300; 
    // Create image with gray base 
    Mat histImage(height, width, CV_8UC3, Scalar(20,20,20)); 
 
    // Normalize the histograms to height of image 
    normalize(b_hist, b_hist, 0, height, NORM_MINMAX); 
    normalize(g_hist, g_hist, 0, height, NORM_MINMAX); 
    normalize(r_hist, r_hist, 0, height, NORM_MINMAX); 
 
    int binStep= cvRound((float)width/(float)numbins); 
    for(int i=1; i&lt; numbins; i++) 
    { 
        line(histImage,  
                Point( binStep*(i-1), height-cvRound(b_hist.at&lt;float&gt;(i-1) )), 
                Point( binStep*(i), height-cvRound(b_hist.at&lt;float&gt;(i) )), 
                Scalar(255,0,0) 
            ); 
        line(histImage,  
                Point(binStep*(i-1), height-cvRound(g_hist.at&lt;float&gt;(i-1))), 
                Point(binStep*(i), height-cvRound(g_hist.at&lt;float&gt;(i))), 
                Scalar(0,255,0) 
            ); 
        line(histImage,  
                Point(binStep*(i-1), height-cvRound(r_hist.at&lt;float&gt;(i-1))), 
                Point(binStep*(i), height-cvRound(r_hist.at&lt;float&gt;(i))), 
                Scalar(0,0,255) 
            ); 
    } 
 
    imshow("Histogram", histImage); 
 
} </pre>
<p>Let's understand how to extract each channel histogram and how to draw it. First, we need to create three matrices to process each input image channel. We use a <span class="CodeInTextPACKT">vector-</span>type variable to store each one and use the <kbd><span class="CodeInTextPACKT">split</span></kbd> OpenCV function to divide the input image <span>among</span> these three channels:</p>
<pre>// Separate image in BRG 
    vector&lt;Mat&gt; bgr; 
    split(img, bgr); </pre>
<p>Now, we are going to define the number of bins of our histogram, in our case, one per possible pixel value:</p>
<pre>int numbins= 256; </pre>
<p>Let's define our range of variables and create three matrices to store each histogram:</p>
<pre>/// Set the ranges for B,G,R 
float range[] = {0, 256} ; 
const float* histRange = {range}; 
 
Mat b_hist, g_hist, r_hist;</pre>
<p>We can calculate the histograms using the <kbd><span class="CodeInTextPACKT">calcHist</span></kbd> OpenCV function. This function has several parameters with this order:</p>
<ul>
<li><strong>The input image</strong>: In our case, we use one image channel stored in the <kbd><span class="CodeInTextPACKT">bgr</span></kbd> vector</li>
<li><strong>The number of images in the input to calculate the histogram</strong>: In our case, we only use <kbd>1</kbd> image</li>
<li><strong>The number channel dimensions used to compute the histogram</strong>: We use <kbd>0</kbd> in our case</li>
<li>The optional mask matrix.</li>
<li>The variable to store the calculated histogram.</li>
<li><strong>Histogram dimensionality</strong>: This is the dimension of the space where the image (here, a gray plane) is taking its values, in our case <kbd>1</kbd></li>
<li><strong>Number of bins to calculate</strong>: In our case <kbd>256</kbd> bins, one per pixel value</li>
<li><strong>Range of input variables</strong>: In our case, from <kbd>0</kbd> to <kbd>255</kbd> possible pixels values</li>
</ul>
<p>Our <kbd><span class="CodeInTextPACKT">calcHist</span></kbd> function for each channel looks as follows:</p>
<pre>calcHist(&amp;bgr[0], 1, 0, Mat(), b_hist, 1, &amp;numbins, &amp;histRange ); 
calcHist(&amp;bgr[1], 1, 0, Mat(), g_hist, 1, &amp;numbins, &amp;histRange ); 
calcHist(&amp;bgr[2], 1, 0, Mat(), r_hist, 1, &amp;numbins, &amp;histRange ); </pre>
<p>Now that we have calculated each channel histogram, we have to draw each one and show it to the user. To do this, we are going to create a color image that is <kbd>512</kbd> by <kbd>300</kbd> pixels in size:</p>
<pre>// Draw the histogram 
// We go to draw lines for each channel 
int width= 512; 
int height= 300; 
// Create image with gray base 
Mat histImage(height, width, CV_8UC3, Scalar(20,20,20)); </pre>
<p>Before we draw the histogram values into our image, we are going to normalize the histogram matrices between the minimum value, <kbd>0</kbd>, and a maximum value; the maximum value is the same as the height of our output histogram image:</p>
<pre>// Normalize the histograms to height of image 
normalize(b_hist, b_hist, 0, height, NORM_MINMAX); 
normalize(g_hist, g_hist, 0, height, NORM_MINMAX); 
normalize(r_hist, r_hist, 0, height, NORM_MINMAX);</pre>
<p>Now we have to draw a line from bin <kbd>0</kbd> to bin <kbd>1</kbd>, and so on. Between each bin, we have to calculate how many pixels there are; then, a <kbd><span class="CodeInTextPACKT">binStep</span></kbd> variable is calculated by dividing the width by the number of bins. Each small line is drawn from horizontal position <kbd>i-1</kbd> to <kbd>i</kbd>; the vertical position is the histogram value in the corresponding <kbd>i</kbd>, and it is drawn with the color channel representation:</p>
<pre>int binStep= cvRound((float)width/(float)numbins); 
    for(int i=1; i&lt; numbins; i++) 
    { 
        line(histImage,  
                Point(binStep*(i-1), height-cvRound(b_hist.at&lt;float&gt;(i-1))), 
                Point(binStep*(i), height-cvRound(b_hist.at&lt;float&gt;(i))), 
                Scalar(255,0,0) 
            ); 
        line(histImage,  
                Point(binStep*(i-1), height-cvRound(g_hist.at&lt;float&gt;(i-1))), 
                Point( binStep*(i), height-cvRound(g_hist.at&lt;float&gt;(i))), 
                Scalar(0,255,0) 
            ); 
        line(histImage,  
                Point(binStep*(i-1), height-cvRound(r_hist.at&lt;float&gt;(i-1))), 
                Point( binStep*(i), height-cvRound(r_hist.at&lt;float&gt;(i))), 
                Scalar(0,0,255) 
            ); 
    } </pre>
<p>Finally, we show the histogram image with the <kbd><span class="CodeInTextPACKT">imshow</span></kbd> function:</p>
<pre>    imshow("Histogram", histImage); </pre>
<p>This is the result for the <kbd>lena.png</kbd> image:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-809 image-border" src="assets/7cc7556f-246c-4765-b1d1-55c62e9a1869.png" style="width:23.67em;height:13.83em;"/></div>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Image color equalization</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to learn how to equalize a color image. Image equalization, or histogram equalization, tries to obtain a histogram with a uniform distribution of values. The result of equalization is an increase in the contrast of an image. Equalization allows lower local contrast areas to gain high contrast, spreading out the most frequent intensities. This method is very useful when the image is extremely dark or bright and there is a very small difference between the background and foreground. Using histogram equalization, we increase the contrast and the details that are over- or under-exposed. This technique is very useful in medical images, such as X-rays.</p>
<p>However, there are two main disadvantages to this method: the increase in background noise and a consequent decrease in useful signals. We can see the effect of equalization in the following photograph, and the histogram changes and spreads when increasing the image contrast:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-810 image-border" src="assets/56a126f0-b50e-4488-a28d-eb54b5eccd50.png" style="width:86.00em;height:42.67em;"/></p>
<p>Let's implement our equalization histogram; we are going to implement it in the <kbd>Callback</kbd> function defined in the user interface's code:</p>
<pre><span>void equalizeCallback(int state, void* userData)</span><br/>{ 
    Mat result; 
    // Convert BGR image to YCbCr 
    Mat ycrcb; 
    cvtColor(img, ycrcb, COLOR_BGR2YCrCb); 
 
    // Split image into channels 
    vector&lt;Mat&gt; channels; 
    split(ycrcb, channels); 
     
    // Equalize the Y channel only 
    equalizeHist(channels[0], channels[0]); 
 
    // Merge the result channels 
    merge(channels, ycrcb); 
 
    // Convert color ycrcb to BGR 
    cvtColor(ycrcb, result, COLOR_YCrCb2BGR); 
 
    // Show image 
    imshow("Equalized", result); 
} </pre>
<p>To equalize a color image, we only have to equalize the luminance channel. We can do this with each color channel but the result is not usable. Alternatively, we can use any other color image format, such as <strong>HSV</strong> or <strong>YCrCb</strong>, that separates the luminance component in an individual channel. Thus, we choose <strong>YCrCb</strong> and use the Y channel (luminance) to equalize. Then, we follow these steps:</p>
<p style="padding-left: 30px">1. Convert or input the <strong>BGR</strong> image into <strong>YCrCb</strong> using the <kbd><span class="CodeInTextPACKT">cvtColor</span></kbd> function:</p>
<pre style="padding-left: 60px">Mat result; 
// Convert BGR image to YCbCr 
Mat ycrcb; 
cvtColor(img, ycrcb, COLOR_BGR2YCrCb); </pre>
<p style="padding-left: 30px">2. Split the <strong>YCrCb</strong> image into different channels matrix:</p>
<pre style="padding-left: 60px">// Split image into channels 
vector&lt;Mat&gt; channels; 
split(ycrcb, channels); </pre>
<p style="padding-left: 30px">3. Equalize the histogram only in the Y channel, using the <kbd><span class="CodeInTextPACKT">equalizeHist</span></kbd> function which has only two parameters, the input and output matrices:</p>
<pre style="padding-left: 60px">// Equalize the Y channel only 
equalizeHist(channels[0], channels[0]); </pre>
<p style="padding-left: 30px">4. Merge the resulting channels and convert them into the <strong>BGR</strong> format to show the user the result:</p>
<pre style="padding-left: 60px">// Merge the result channels 
merge(channels, ycrcb); 
 
// Convert color ycrcb to BGR 
cvtColor(ycrcb, result, COLOR_YCrCb2BGR); 
 
// Show image 
imshow("Equalized", result);</pre>
<p>The process applied to a low-contrast <kbd>Lena</kbd> image will have the following result:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-811 image-border" src="assets/fa858d66-53c0-40ab-bdf2-f97db2cdb0ca.png" style="width:85.25em;height:48.25em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Lomography effect</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to create another image effect, which is a photograph effect that is very common in different mobile applications, such as Google Camera or Instagram. We are going to discover how to use a <strong>look-up table</strong> (<strong>LUT</strong>). We will go through LUTs later in this same section. We are going to learn how to add an over image, in this case a dark halo, to create our desired effect. The function that implements this effect is the <kbd><span class="CodeInTextPACKT">lomoCallback</span></kbd> callback and it has the following code:</p>
<pre>void lomoCallback(int state, void* userData) 
{ 
    Mat result; 
 
    const double exponential_e = std::exp(1.0); 
    // Create Look-up table for color curve effect 
    Mat lut(1, 256, CV_8UC1); 
    for (int i=0; i&lt;256; i++) 
    { 
        float x= (float)i/256.0;  
        lut.at&lt;uchar&gt;(i)= cvRound( 256 * (1/(1 + pow(exponential_e, -((x-0.5)/0.1)) )) ); 
    } 
    
    // Split the image channels and apply curve transform only to red channel 
    vector&lt;Mat&gt; bgr; 
    split(img, bgr); 
    LUT(bgr[2], lut, bgr[2]); 
    // merge result 
    merge(bgr, result); 
    
    // Create image for halo dark 
    Mat halo(img.rows, img.cols, CV_32FC3, Scalar(0.3,0.3,0.3) ); 
    // Create circle  
    circle(halo, Point(img.cols/2, img.rows/2), img.cols/3, Scalar(1,1,1), -1);  
    blur(halo, halo, Size(img.cols/3, img.cols/3)); 
     
    // Convert the result to float to allow multiply by 1 factor 
    Mat resultf; 
    result.convertTo(resultf, CV_32FC3); 
     
    // Multiply our result with halo 
    multiply(resultf, halo, resultf); 
     
    // convert to 8 bits 
    resultf.convertTo(result, CV_8UC3); 
 
    // show result 
    imshow("Lomography", result); 
} </pre>
<p>Let's look at how the lomography effect works and how to implement it. The lomography effect is divided into different steps, but in our example, we did a very simple lomography effect with two steps:</p>
<ol>
<li>A color manipulation effect by using a look-up table to apply a curve to the red channel</li>
<li>A vintage effect by applying a dark halo to the image</li>
</ol>
<p>The first step was to manipulate the red color with a curve transform by applying the following function:</p>
<div style="padding-left: 210px" class="packt_figure CDPAlignLeft CDPAlign"><img class="alignnone size-full wp-image-812 image-border" src="assets/e428a8cc-1511-412e-84cd-640a09c5df72.png" style="width:8.00em;height:4.33em;"/></div>
<p><span>This formula generates a curve that makes the dark values darker and the light values lighter, where <strong>x</strong> is the possible pixels value (<kbd>0</kbd> to <kbd>255</kbd>) and <strong>s</strong> is a constant that we set to <kbd>0.1</kbd> in our example. A lower constant value that generates pixels with values lower than <kbd>128</kbd> is very dark, and over <kbd>128</kbd> is very bright. Values near to <kbd>1</kbd> convert the curve into a line and do not generate our desired effect:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-813 image-border" src="assets/70093da0-1f3c-4924-b4f7-aba9a99af497.png" style="width:44.50em;height:34.58em;"/></div>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span>This function is very easy to implement by applying an LUT. An LUT is a vector or table that returns a preprocessed value for a given value to perform computation in the memory. An LUT is a common technique used to spare CPU cycles by avoiding performing costly computations repeatedly. Instead of calling the <kbd>exponential</kbd>/<kbd>divide</kbd> function for each pixel, we perform it only once for each possible pixel value ( <kbd>256</kbd> times) and store the result in a table. Thus, we have saved CPU time at the cost of a bit of memory. While this may not make a great difference on a standard PC with small image sizes, this makes a huge one for CPU-limited hardware, such as Raspberry Pi.</span></p>
<p><span>For example, in our case, if we want to apply a function for every pixel in our image, then we have to make</span> <span><em>width</em> x <em>height</em> operations; for example, in 100 x 100 pixels, there will be 10,000 calculations. If we can pre-calculate all possible results for all possible inputs, we can create the LUT table.</span> <span>I</span><span>n an image, there are only <strong>256</strong> possible values as a pixel value. If we want to change the color by applying a function, we can pre-calculate the 256 values and save them in an LUT vector.</span> In our sample code, we define the <kbd><span class="CodeInTextPACKT">E</span></kbd> variable and create an <kbd>lut</kbd> matrix of <kbd>1</kbd> row and <kbd>256</kbd> columns. Then, we do a loop over all possible pixel values by applying our formula and saving it into an <kbd>lut</kbd> variable:</p>
<pre>const double exponential_e = std::exp(1.0); 
// Create look-up table for color curve effect 
Mat lut(1, 256, CV_8UC1); 
Uchar* plut= lut.data; 
for (int i=0; i&lt;256; i++) 
{ 
    double x= (double)i/256.0;  
    plut[i]= cvRound( 256.0 * (1.0/(1.0 + pow(exponential_e, -((x-0.5)/0.1)) )) ); 
} </pre>
<p>As we mentioned earlier in this section, we don't apply the function to all channels; thus, we need to split our input image by channels using the <kbd><span class="CodeInTextPACKT">split</span></kbd> function:</p>
<pre>// Split the image channels and apply curve transform only to red channel 
vector&lt;Mat&gt; bgr; 
split(img, bgr); </pre>
<p>We then apply our <kbd><span class="CodeInTextPACKT">lut</span></kbd> table variable to the red channel. OpenCV gives us the <kbd><span class="CodeInTextPACKT">LUT</span></kbd> function, which has three parameters:</p>
<ul>
<li>Input image</li>
<li>Matrix of look-up table</li>
<li>Output image</li>
</ul>
<p>Then, our call to the <kbd><span class="CodeInTextPACKT">LUT</span></kbd> function and red channel looks like this:</p>
<pre>LUT(bgr[2], lut, bgr[2]); </pre>
<p>Now, we only have to merge our computed channels:</p>
<pre>// merge result 
merge(bgr, result);</pre>
<p>The first step is done and we only have to create the dark halo to finish our effect. Then, we create a gray image with a white circle inside, with the same input image size:</p>
<pre> // Create image for halo dark 
 Mat halo(img.rows, img.cols, CV_32FC3, Scalar(0.3,0.3,0.3)); 
 // Create circle  
 circle(halo, Point(img.cols/2, img.rows/2), img.cols/3, Scalar(1,1,1), -1);  </pre>
<p>Check out the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-814 image-border" src="assets/51793ccb-0ca9-4d51-a930-17105ecdad99.png" style="width:9.42em;height:9.42em;"/></p>
<p>If we apply this image to our input image, we will get a strong change from dark to white; thus, we can apply a big blur using the <kbd><span class="CodeInTextPACKT">blur</span></kbd> filter function to our circle halo image to get a smooth effect:</p>
<pre>blur(halo, halo, Size(img.cols/3, img.cols/3)); </pre>
<p>The image will be altered to give us the following result:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-815 image-border" src="assets/db62a585-6b82-4227-86b3-1aa64980bd09.png" style="width:10.33em;height:10.33em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Now, if we have to apply this halo to our image from step 1, an easy way to do this is to multiply both images. However, we will have to convert our input image from an 8-bit image to a 32-bit float, because we need to multiply our blurred image, which has values in the <kbd>0</kbd> to <kbd>1</kbd> range, with our input image, which has integer values. The following code will do it for us:</p>
<pre>// Convert the result to float to allow multiply by 1 factor 
Mat resultf; 
result.convertTo(resultf, CV_32FC3); </pre>
<p>After converting our image, we only need to multiply each matrix per element:</p>
<pre>// Multiply our result with halo 
multiply(resultf, halo, resultf); </pre>
<p>Finally, we will convert the float image matrix result to an 8-bit image matrix:</p>
<pre>// convert to 8 bits 
resultf.convertTo(result, CV_8UC3); 
 
// show result 
imshow("Lomograpy", result); </pre>
<p class="packt_figure">This will be the result:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-816 image-border" src="assets/b5c3ab57-53cc-46d2-8a7f-98fd05d371b4.png" style="width:85.08em;height:48.17em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cartoonize effect</h1>
                </header>
            
            <article>
                
<p>The last section of this chapter is dedicated to creating another effect, called <strong>cartoonize</strong>; the purpose of this effect is to create an image that looks like a cartoon. To do this, we divide the algorithm into two steps: <strong>edge detection</strong> and <strong>color filtering</strong>.</p>
<p>The <kbd><span class="CodeInTextPACKT">cartoonCallback</span></kbd> function defines this effect, which has the following code:</p>
<pre>void cartoonCallback(int state, void* userData) 
{ 
    /** EDGES **/ 
    // Apply median filter to remove possible noise 
    Mat imgMedian; 
    medianBlur(img, imgMedian, 7); 
 
    // Detect edges with canny 
    Mat imgCanny; 
    Canny(imgMedian, imgCanny, 50, 150); 
     
    // Dilate the edges 
    Mat kernel= getStructuringElement(MORPH_RECT, Size(2,2)); 
    dilate(imgCanny, imgCanny, kernel); 
 
    // Scale edges values to 1 and invert values 
    imgCanny= imgCanny/255; 
    imgCanny= 1-imgCanny; 
     
    // Use float values to allow multiply between 0 and 1 
    Mat imgCannyf; 
    imgCanny.convertTo(imgCannyf, CV_32FC3); 
 
    // Blur the edgest to do smooth effect 
    blur(imgCannyf, imgCannyf, Size(5,5)); 
 
    /** COLOR **/ 
    // Apply bilateral filter to homogenizes color 
    Mat imgBF; 
    bilateralFilter(img, imgBF, 9, 150.0, 150.0); 
 
    // truncate colors 
    Mat result= imgBF/25; 
    result= result*25; 
 
    /** MERGES COLOR + EDGES **/ 
    // Create a 3 channles for edges 
    Mat imgCanny3c; 
    Mat cannyChannels[]={ imgCannyf, imgCannyf, imgCannyf}; 
    merge(cannyChannels, 3, imgCanny3c); 
 
    // Convert color result to float  
    Mat resultf; 
    result.convertTo(resultf, CV_32FC3); 
 
    // Multiply color and edges matrices 
    multiply(resultf, imgCanny3c, resultf); 
 
    // convert to 8 bits color 
    resultf.convertTo(result, CV_8UC3); 
 
    // Show image 
    imshow("Result", result); 
 
} </pre>
<p>The first step is to detect the most important <em>edges</em> of the image. We need to remove noise from the input image before detecting the edges. There are several ways to do it. We are going to use a median filter to remove all possible small noise, but we can use other methods, such as Gaussian blur. The OpenCV function is <kbd>medianBlur</kbd>, which accepts three parameters: input image, output image, and the kernel size (a kernel is a small matrix used to apply some mathematical operation, such as convolutional means, to an image):</p>
<pre>Mat imgMedian; 
medianBlur(img, imgMedian, 7); </pre>
<p>After removing any possible noise, we detect the strong edges with the <kbd>Canny</kbd> filter:</p>
<pre>// Detect edges with canny 
Mat imgCanny; 
Canny(imgMedian, imgCanny, 50, 150); </pre>
<p>The <kbd>Canny</kbd> filter accepts the following parameters:</p>
<ul>
<li>Input image</li>
<li>Output image</li>
<li>First threshold</li>
<li>Second threshold</li>
<li>Sobel size aperture</li>
<li>Boolean value to indicate whether we need to use a more accurate image gradient magnitude</li>
</ul>
<p>The smallest value between the first threshold and the second threshold is used for edge linking. The largest value is used to find initial segments of strong edges. The sobel size aperture is the kernel size for the sobel filter that will be used in the algorithm. After detecting edges, we are going to apply a small dilation to join broken edges:</p>
<pre>// Dilate the edges 
Mat kernel= getStructuringElement(MORPH_RECT, Size(2,2)); 
dilate(imgCanny, imgCanny, kernel); </pre>
<p>Similar to what we did in the lomography effect, if we need to multiply our edges' result image with the color image, then we require the pixel values to be in the <kbd>0</kbd> and <kbd>1</kbd> range. For this, we will divide the canny result by <kbd>256</kbd> and invert the edges to black:</p>
<pre>// Scale edges values to 1 and invert values 
imgCanny= imgCanny/255; 
imgCanny= 1-imgCanny; </pre>
<p>We will also transform the canny 8 unsigned bit pixel format to a float matrix:</p>
<pre>// Use float values to allow multiply between 0 and 1 
Mat imgCannyf; 
imgCanny.convertTo(imgCannyf, CV_32FC3); </pre>
<p>To give a cool result, we can blur the edges, and to give smooth result lines, we can apply a <kbd>blur</kbd> filter:</p>
<pre>// Blur the edgest to do smooth effect 
blur(imgCannyf, imgCannyf, Size(5,5)); </pre>
<p>The first step of the algorithm is finished, and now we are going to work with the color. To get a cartoon look, we are going to use the <kbd>bilateral</kbd> filter:</p>
<pre>// Apply bilateral filter to homogenizes color 
Mat imgBF; 
bilateralFilter(img, imgBF, 9, 150.0, 150.0); </pre>
<p>The <kbd>bilateral</kbd> filter is a filter that reduces the noise of an image while keeping the edges. With appropriate parameters, which we will explore later, we can get a cartoonish effect.</p>
<p>The <kbd>bilateral</kbd> filter's parameters are as follows:</p>
<ul>
<li>Input image</li>
<li>Output image</li>
<li>Diameter of pixel neighborhood; if it's set to negative, it is computed from a sigma space value</li>
</ul>
<ul>
<li>Sigma color value</li>
<li>Sigma coordinate space</li>
</ul>
<div class="packt_infobox">With a diameter greater than five, the <kbd>bilateral</kbd> filter starts to become slow. With sigma values greater than 150, a cartoonish effect appears.</div>
<p>To create a stronger cartoonish effect, we truncate the possible color values to 10 by multiplying and dividing the pixels values:</p>
<pre>// truncate colors 
Mat result= imgBF/25; 
result= result*25; </pre>
<p>Finally, we have to merge the color and edges results. Then, we have to create a three-channel image as follows:</p>
<pre>// Create a 3 channles for edges 
Mat imgCanny3c; 
Mat cannyChannels[]={ imgCannyf, imgCannyf, imgCannyf}; 
merge(cannyChannels, 3, imgCanny3c); </pre>
<p>We can convert our color result image to a 32-bit float image and then multiply both images per element:</p>
<pre>// Convert color result to float  
Mat resultf; 
result.convertTo(resultf, CV_32FC3); 
 
// Multiply color and edges matrices 
multiply(resultf, imgCanny3c, resultf); </pre>
<p>Finally, we only need to convert our image to 8 bits and then show the resulting image to the user:</p>
<pre>// convert to 8 bits color 
resultf.convertTo(result, CV_8UC3); 
 
// Show image 
imshow("Result", result); </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In the next screenshot, we can see the input image (left image) and the result of applying the cartoonize effect (right image):</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-817 image-border" src="assets/b6a8c27a-6435-4b18-abc8-dad291b07de3.png" style="width:85.08em;height:48.08em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we saw how to create a complete project that manipulates images by applying different effects. We also split a color image into multiple matrices to apply effects to only one channel. We saw how to create look-up tables, merge multiple matrices into one, use the <kbd>Canny</kbd> and <kbd>bilateral</kbd> filters, draw circles, and multiply images to get halo effects.</p>
<p>In the next chapter, we will learn how to do object inspection, and how to segment an image into different parts and detect those parts.</p>


            </article>

            
        </section>
    </body></html>