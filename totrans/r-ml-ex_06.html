<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;5.&#xA0;Credit Risk Detection and Prediction &#x2013; Descriptive Analytics" id="147LC1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05" class="calibre1"/>Chapter 5. Credit Risk Detection and Prediction – Descriptive Analytics</h1></div></div></div><p class="calibre8">In the last two chapters, you saw some interesting problems revolving around the retail and e-commerce domains. You now know how to detect and predict shopping trends from shopping patterns as well as how to build recommendation systems. If you remember from <a class="calibre1" title="Chapter 1. Getting Started with R and Machine Learning" href="part0014_split_000.html#DB7S2-973e731d75c2419489ee73e3a0cf4be8">Chapter 1</a>, <span class="strong"><em class="calibre10">Getting started with R and Machine Learning</em></span> that the applications of machine learning are diverse, we can apply the same concepts and techniques to solve a wide variety of problems in the real world. We will be tackling a completely new problem here, but hold on to what you have learnt because several concepts you learnt previously will come in handy soon!</p><p class="calibre8">In the next couple of chapters, we will be tackling a new problem related to the financial domain. We will be looking at the bank customers of a particular German bank who could be credit risks for the bank, based on some data that has been previously collected. We will perform descriptive and exploratory analysis on this data to highlight different potential features in the dataset and also look at their relationship with credit risk. In the next step, we will be building predictive models using machine learning algorithms and these data features to detect and predict customers who could be potential credit risks. You may remember that the two main things that we need to do this analysis to remain unchanged are data and algorithms.</p><p class="calibre8">You might be surprised to know that risk analysis is one of the top most focus areas of financial organizations including in banks, investment firms, insurance firms, and brokerage firms. Each of these organizations often has dedicated teams for solving problems revolving around risk analysis. Some examples of risk which are frequently analyzed include credit risk, sales risk, fraud related risks, and many more.</p><p class="calibre8">In this chapter, we will be focusing on the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Descriptive analytics of our credit risk dataset</li><li class="listitem">Domain knowledge of the credit risk problem</li><li class="listitem">Detailed analysis of dataset features</li><li class="listitem">Exploratory analysis of the data</li><li class="listitem">Visualizations on various data features</li><li class="listitem">Statistical tests to determine feature significance</li></ul></div><p class="calibre8">Always remember that domain knowledge is essential before solving any machine learning problem because otherwise we will end up applying random algorithms and techniques blindly which may not give the right results.</p></div>

<div class="book" title="Chapter&#xA0;5.&#xA0;Credit Risk Detection and Prediction &#x2013; Descriptive Analytics" id="147LC1-973e731d75c2419489ee73e3a0cf4be8">
<div class="book" title="Types of analytics"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch05lvl1sec32" class="calibre1"/>Types of analytics</h1></div></div></div><p class="calibre8">Before we start tackling <a id="id288" class="calibre1"/>our next challenge, it will be useful to get an idea of the different types of analytics which broadly encompass the data science domain. We use a variety of data mining and machine learning techniques to solve different data problems. However, depending on the mechanism of the technique and its end result, we can broadly classify analytics into four different types which are explained next:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">Descriptive analytics</strong></span>: This is what we use when we have some data to analyze. We <a id="id289" class="calibre1"/>start with looking at the different attributes of the <a id="id290" class="calibre1"/>data, extract meaningful features, and use statistics and visualizations to understand what has already happened. The main aim of descriptive analytics is to get a broad idea of what kind of data we are dealing with and summarize what has happened in the past. Above almost 80% of all analytics in businesses today are descriptive.</li><li class="listitem"><span class="strong"><strong class="calibre9">Diagnostic analytics</strong></span>: This is sometimes clubbed together with descriptive analytics. Here the <a id="id291" class="calibre1"/>main objective is to delve deeper into the data <a id="id292" class="calibre1"/>to find specific patterns and answer questions such as why did this occur. Usually, it involves root-cause analysis to come to the root of why something happened and what were the main factors involved in doing during its occurrence. Sometimes techniques such as regression modeling help in achieving this.</li><li class="listitem"><span class="strong"><strong class="calibre9">Predictive analytics</strong></span>: This is the final step in any<a id="id293" class="calibre1"/> analytics pipeline. Once you have <a id="id294" class="calibre1"/>built consistent and stable predictive models with a good flow of clean data for predictions, you can build systems which utilize this and start prescribing actions which you might take to improve your business. Do remember that predictive modeling can only predict what might happen in the future because all models are probabilistic in nature and nothing is 100 <a id="id295" class="calibre1"/>percent certain.</li><li class="listitem"><span class="strong"><strong class="calibre9">Prescriptive analytics</strong></span>: This is the final step in any analytics pipeline if you are in the stage that you have built consistent predictive models with a good flow of clean data such that you are able to predict what might happen in the future. Then you <a id="id296" class="calibre1"/>can build systems which utilize this and start <a id="id297" class="calibre1"/>prescribing actions which you might take to improve your business. Do remember that you need working predictive models with good data and an excellent feedback mechanism to achieve this.</li></ul></div><p class="calibre8">Most organizations do a lot of descriptive analytics and some amount of predictive analytics. However, it is really difficult to implement prescriptive analytics due to the ever changing business conditions and data streams and problems associated with that, the most common one being data sanitization issues. We will be touching upon descriptive analytics in this chapter before moving on to predictive analytics in the next chapter to solve our problem related to credit risk analytics.</p></div></div>
<div class="book" title="Our next challenge" id="1565U1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec33" class="calibre1"/>Our next challenge</h1></div></div></div><p class="calibre8">We have dealt with some interesting applications of machine learning in the e-commerce domain in the last couple of chapters. For the next two chapters, our big challenge will be in the financial domain. We will be using data analysis and machine learning techniques to analyze financial data from a German bank. This data will contain a lot of information regarding customers of that bank. We will be analyzing that data in two stages which include descriptive and predictive analytics.</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">Descriptive</strong></span>: Here we will look closely at the data and its various attributes. We will perform descriptive analysis and visualizations to see the kind of features we are dealing with and how they might be related to credit risk. The data we will be <a id="id298" class="calibre1"/>dealing with here consists of labeled data already and we will be able to see how many customers were credit risks and how many weren't. We will also look closely at each feature in the data and understand its significance which will be useful in the next step.</li><li class="listitem"><span class="strong"><strong class="calibre9">Predictive</strong></span>: Here we <a id="id299" class="calibre1"/>will focus more on the machine learning algorithms used in predictive modeling to build predictive models using the data we have already acquired in the previous step. We will be using various machine learning algorithms and testing the accuracy of the models when predicting if a customer could be a potential credit risk. We will be using labeled data to train the model and then test the models on several data instances, comparing our predicted result with the actual result to see how well our models perform.</li></ul></div><p class="calibre8">The significance of predicting credit risks is quite useful for financial organizations, such as banks that have to often deal with loan applications from their customers. They have to then make the decision to approve or deny the loan based on information they have about the customer. If they have a robust machine learning system built in place which can analyze the data about the customer and say which customers might be credit risks, then they can prevent losses to their business by not approving loans to such customers.</p></div>
<div class="book" title="What is credit risk?" id="164MG1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec34" class="calibre1"/>What is credit risk?</h1></div></div></div><p class="calibre8">We have been using this <a id="id300" class="calibre1"/>term <span class="strong"><strong class="calibre9">credit risk</strong></span> since the start of this chapter and many of you might be wondering what exactly does this mean, even though you might have guessed it after reading the previous section. Here, we will be explaining this term clearly so that you will have no problem in understanding the data and its features in the subsequent sections when we will be analyzing the data.</p><p class="calibre8">The standard definition of credit risk is the risk of defaulting on a debt which takes place due to the borrower failing to make the required debt payments in time. This risk is taken by the lender since the lender incurs losses of both the principal amount as well as the interest on it.</p><p class="calibre8">In our case, we will be dealing with a bank which acts as the financial organization giving out loans to customers who apply for them. Hence, customers who might default on the loan payment would be credit risks for the bank. By analyzing customer data and applying machine learning algorithms on it, the bank will be able to predict in advance which customers might be potential credit risks. This will help in risk mitigation and in minimizing losses by not giving away loans to customers who could be credit risks for the bank.</p></div>
<div class="book" title="Getting the data" id="173721-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec35" class="calibre1"/>Getting the data</h1></div></div></div><p class="calibre8">The first step in <a id="id301" class="calibre1"/>our data analysis pipeline is to get the dataset. We have actually cleaned the data and provided meaningful names to the data attributes and you can check that out by opening the <code class="email">german_credit_dataset.csv</code> file. You can also get the actual dataset from the source which is from the Department of Statistics, University of Munich through <a id="id302" class="calibre1"/>the following URL: <a class="calibre1" href="http://www.statistik.lmu.de/service/datenarchiv/kredit/kredit_e.html">http://www.statistik.lmu.de/service/datenarchiv/kredit/kredit_e.html</a>.</p><p class="calibre8">You can download the data and then run the following commands by firing up R in the same directory with the data file, to get a feel of the data we will be dealing with in the following sections:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # load in the data and attach the data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df &lt;- read.csv("german_credit_dataset.csv", header = TRUE, sep = ",") </strong></span>
<span class="strong"><strong class="calibre9">&gt; # class should be data.frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; class(credit.df)</strong></span>
<span class="strong"><strong class="calibre9">[1] "data.frame"</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # get a quick peek at the data</strong></span>
<span class="strong"><strong class="calibre9">&gt; head(credit.df)</strong></span>
</pre></div><p class="calibre8">The following figure shows the first six rows of the data. Each column indicates an attribute of the dataset. We will be focusing on each attribute in more detail later.</p><div class="mediaobject"><img src="../images/00139.jpeg" alt="Getting the data" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">To get detailed information about the dataset and its attributes, you can use the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # get dataset detailed info</strong></span>
<span class="strong"><strong class="calibre9">&gt; str(credit.df)</strong></span>
</pre></div><p class="calibre8">The preceding code will enable you to get a quick look at the total number of data points you are dealing with, which <a id="id303" class="calibre1"/>includes the number of records, the number of attributes, and the detailed information about each attribute including things such as the attribute name, type, and some samples of attribute values, as you can see in the following screenshot. Using this, we can get a good idea about the different attributes and their data types so that we know what transformations to apply on them and what statistical methods to use during descriptive analytics.</p><div class="mediaobject"><img src="../images/00140.jpeg" alt="Getting the data" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">From the preceding output, you can see that our dataset has a total of 1000 records, where each record deals with data points pertaining to one bank customer. Each record has various data points or attributes describing the data and we have a total of 21 attributes for each record. The <a id="id304" class="calibre1"/>data type and sample values for each attribute are also shown in the previous image.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note14" class="calibre1"/>Note</h3><p class="calibre8">Do note that by default R has assigned the <code class="email">int</code> datatype to the variables based on their values but we will be changing some of that in our data preprocessing phase based on their actual semantics.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Data preprocessing" id="181NK1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec36" class="calibre1"/>Data preprocessing</h1></div></div></div><p class="calibre8">In this section, we will <a id="id305" class="calibre1"/>be focusing on data preprocessing which includes data cleaning, transformation, and normalizations if required. Basically, we perform operations to get the data ready before we start performing any analysis on it.</p></div>

<div class="book" title="Data preprocessing" id="181NK1-973e731d75c2419489ee73e3a0cf4be8">
<div class="book" title="Dealing with missing values"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec57" class="calibre1"/>Dealing with missing values</h2></div></div></div><p class="calibre8">There will be <a id="id306" class="calibre1"/>situations when the data you are dealing with will have missing values, which are often represented as <code class="email">NA</code> in R. There are several ways to detect them and we will show you a couple of ways next. Note that there are several ways in which you can do this.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # check if data frame contains NA values</strong></span>
<span class="strong"><strong class="calibre9">&gt; sum(is.na(credit.df))</strong></span>
<span class="strong"><strong class="calibre9">[1] 0</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # check if total records reduced after removing rows with NA </strong></span>
<span class="strong"><strong class="calibre9">&gt; # values</strong></span>
<span class="strong"><strong class="calibre9">&gt; sum(complete.cases(credit.df))</strong></span>
<span class="strong"><strong class="calibre9">[1] 1000</strong></span>
</pre></div><p class="calibre8">The <code class="email">is.na</code> function is really useful as it helps in finding out if any element has an <code class="email">NA</code> value in the dataset. There is another way of doing the same by using the <code class="email">complete.cases</code> function, which essentially returns a logical vector saying whether the rows are complete and if they have any <code class="email">NA</code> values. You can check if the total records count has decreased compared to the original dataset as then you will know that you have some missing values in the dataset. Fortunately, in our case, we do not have any missing values. However, in the future if you are dealing with missing values, there are various ways to deal with that. Some of them include removing the rows with missing values by using functions such as <code class="email">complete.cases</code>, or filling them up with a value which could be the most frequent value or the mean, and so on. This is also known as missing value imputation and it <a id="id307" class="calibre1"/>depends on the variable attribute and the domain you are dealing with. Hence, we won't be focusing too much in this area here.</p></div></div>

<div class="book" title="Data preprocessing" id="181NK1-973e731d75c2419489ee73e3a0cf4be8">
<div class="book" title="Datatype conversions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec58" class="calibre1"/>Datatype conversions</h2></div></div></div><p class="calibre8">We had mentioned <a id="id308" class="calibre1"/>earlier that by default all the attributes of the dataset had been declared as <code class="email">int</code>, which is a numeric type by R, but it is not so in this case and we have to change that based on the variable semantics and values. If you have taken a basic course on statistics, you might know that usually we deal with two types of variables:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">Numeric variables</strong></span>: The values of these variables carry some mathematical meaning. This <a id="id309" class="calibre1"/>means that you can carry out mathematical operations on them, such as addition, subtraction, and so on. Some examples can be a person's age, weight, and so on.</li><li class="listitem"><span class="strong"><strong class="calibre9">Categorical variables</strong></span>: The values of these variables do not have any mathematical <a id="id310" class="calibre1"/>significance and you cannot perform any mathematical operations on them. Each value in this variable belongs to a specific class or category. Some examples can be a person's gender, job, and so on.</li></ul></div><p class="calibre8">Since all the variables in our dataset have been converted to numeric by default, we will only need to convert the categorical variables from numeric data types to factors, which is a nice way to represent categorical variables in R.</p><p class="calibre8">The numeric variables in our dataset include <code class="email">credit.duration.months</code>, <code class="email">credit.amount</code>, and age and we will not need to perform any conversions. However, the remaining 18 variables are all categorical and we will be using the following utility function to convert their data types:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># data transformation</strong></span>
<span class="strong"><strong class="calibre9">to.factors &lt;- function(df, variables){</strong></span>
<span class="strong"><strong class="calibre9">  for (variable in variables){</strong></span>
<span class="strong"><strong class="calibre9">    df[[variable]] &lt;- as.factor(df[[variable]])</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  return(df)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">This function will <a id="id311" class="calibre1"/>be used on our existing data frame <code class="email">credit.df</code> as follows for transforming the variable data types:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # select variables for data transformation</strong></span>
<span class="strong"><strong class="calibre9">&gt; categorical.vars &lt;- c('credit.rating', 'account.balance', </strong></span>
<span class="strong"><strong class="calibre9">+                       'previous.credit.payment.status',</strong></span>
<span class="strong"><strong class="calibre9">+                       'credit.purpose', 'savings', </strong></span>
<span class="strong"><strong class="calibre9">+                       'employment.duration', 'installment.rate',</strong></span>
<span class="strong"><strong class="calibre9">+                       'marital.status', 'guarantor', </strong></span>
<span class="strong"><strong class="calibre9">+                       'residence.duration', 'current.assets',</strong></span>
<span class="strong"><strong class="calibre9">+                       'other.credits', 'apartment.type', </strong></span>
<span class="strong"><strong class="calibre9">+                       'bank.credits', 'occupation', </strong></span>
<span class="strong"><strong class="calibre9">+                       'dependents', 'telephone', </strong></span>
<span class="strong"><strong class="calibre9">+                       'foreign.worker')</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # transform data types</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df &lt;- to.factors(df = credit.df, </strong></span>
<span class="strong"><strong class="calibre9">+                         variables=categorical.vars)</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # verify transformation in data frame details</strong></span>
<span class="strong"><strong class="calibre9">&gt; str(credit.df)</strong></span>
</pre></div><p class="calibre8">Now we can see the attribute details in the data frame with the transformed data types for the selected categorical variables in the following output. You will notice that out of the 21 variables/attributes of the dataset, 18 of them have been successfully transformed into categorical variables.</p><div class="mediaobject"><img src="../images/00141.jpeg" alt="Datatype conversions" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">This brings an end <a id="id312" class="calibre1"/>to the data preprocessing step and we will now dive into analyzing our dataset.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note15" class="calibre1"/>Note</h3><p class="calibre8">Do note that several of our dataset attributes/features have a lot of classes or categories and we will need to do some more data transformations and feature engineering in the analysis phase to prevent overfitting of our predictive models, which we shall discuss later.</p></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Data analysis and transformation"><div class="book" id="190862-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec37" class="calibre1"/>Data analysis and transformation</h1></div></div></div><p class="calibre8">Now that we have <a id="id313" class="calibre1"/>processed our data, it is ready for analysis. We will be carrying out descriptive and exploratory analysis in this section, as mentioned earlier. We will analyze the different dataset attributes and talk about their significance, semantics, and relationship with the credit risk attribute. We will be using statistical functions, contingency tables, and visualizations to depict all of this.</p><p class="calibre8">Besides this, we will also be doing data transformation for some of the features in our dataset, namely the categorical variables. We will be doing this to combine the category classes which have similar semantics and remove the classes having very less proportion by merging them with a similar class. Some reasons for doing this include preventing the overfitting of our predictive models, which we will be building in <a class="calibre1" title="Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics" href="part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8">Chapter 6</a>, <span class="strong"><em class="calibre10">Credit Risk Detection and Prediction – Predictive Analytics</em></span>, linking semantically similar classes together and also because modeling techniques like logistic regression do not handle categorical variables with a large number of classes very well. We will analyze each feature/variable in the dataset first and then perform any transformations if necessary.</p></div>

<div class="book" title="Data analysis and transformation">
<div class="book" title="Building analysis utilities"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec59" class="calibre1"/>Building analysis utilities</h2></div></div></div><p class="calibre8">Before we <a id="id314" class="calibre1"/>begin our analysis, we will be developing some utility functions which we will be using to analyze the dataset features. Do note that all the utility functions are defined in a separate <code class="email">.R</code> file called <code class="email">descriptive_analytics_utils.R</code>. You can load all the functions in memory or in any other R script file by using the command <code class="email">source('descriptive_analytics_utils.R')</code> and then start using them. We will be talking about these utility functions now.</p><p class="calibre8">We will now talk about the various packages we have used. We have used some packages such as <code class="email">pastecs</code> and <code class="email">gmodels</code> for getting summary statistics of features and for building contingency tables. The packages <code class="email">gridExtra</code> and <code class="email">ggplot2</code> have been used for grid layouts and building visualizations respectively. If you do not have them installed, you can use the <code class="email">install.packages</code> command to install them. Next, load the packages as shown in the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># load dependencies</strong></span>
<span class="strong"><strong class="calibre9">library(gridExtra) # grid layouts</strong></span>
<span class="strong"><strong class="calibre9">library(pastecs) # details summary stats</strong></span>
<span class="strong"><strong class="calibre9">library(ggplot2) # visualizations</strong></span>
<span class="strong"><strong class="calibre9">library(gmodels) # build contingency tables</strong></span>
</pre></div><p class="calibre8">Now that we have all the required dependencies, we will first implement a function to get summary statistics about the numerical variables. The following code snippet achieves the same. If you see, we have made use of the <code class="email">stat.desc</code> and summary functions for getting detailed and condensed summary statistics about the variable. The conventions for independent variables and dependent variables are denoted by <code class="email">indep.var</code> and <code class="email">dep.var</code> in the code segments that follow and in other functions later on.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># summary statistics</strong></span>
<span class="strong"><strong class="calibre9">get.numeric.variable.stats &lt;- function(indep.var, detailed=FALSE){</strong></span>
<span class="strong"><strong class="calibre9">  options(scipen=100)</strong></span>
<span class="strong"><strong class="calibre9">  options(digits=2)</strong></span>
<span class="strong"><strong class="calibre9">  if (detailed){</strong></span>
<span class="strong"><strong class="calibre9">    var.stats &lt;- stat.desc(indep.var)</strong></span>
<span class="strong"><strong class="calibre9">  }else{</strong></span>
<span class="strong"><strong class="calibre9">    var.stats &lt;- summary(indep.var)</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  df &lt;- data.frame(round(as.numeric(var.stats),2))</strong></span>
<span class="strong"><strong class="calibre9">  colnames(df) &lt;- deparse(substitute(indep.var))</strong></span>
<span class="strong"><strong class="calibre9">  rownames(df) &lt;- names(var.stats)</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  if (names(dev.cur()) != "null device"){</strong></span>
<span class="strong"><strong class="calibre9">    dev.off()</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  grid.table(t(df))</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">Next, we will build some functions for visualizing the numeric variables. We will be doing that by using <a id="id315" class="calibre1"/>
<code class="email">histograms\density</code> plots and <code class="email">box plots</code> to depict the attribute distributions.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># visualizations</strong></span>
<span class="strong"><strong class="calibre9"># histograms\density</strong></span>
<span class="strong"><strong class="calibre9">visualize.distribution &lt;- function(indep.var){</strong></span>
<span class="strong"><strong class="calibre9">  pl1 &lt;- qplot(indep.var, geom="histogram", </strong></span>
<span class="strong"><strong class="calibre9">               fill=I('gray'), binwidth=5,</strong></span>
<span class="strong"><strong class="calibre9">               col=I('black'))+ theme_bw()</strong></span>
<span class="strong"><strong class="calibre9">  pl2 &lt;- qplot(age, geom="density",</strong></span>
<span class="strong"><strong class="calibre9">               fill=I('gray'), binwidth=5, </strong></span>
<span class="strong"><strong class="calibre9">               col=I('black'))+ theme_bw()</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  grid.arrange(pl1,pl2, ncol=2)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>

<span class="strong"><strong class="calibre9"># box plots</strong></span>
<span class="strong"><strong class="calibre9">visualize.boxplot &lt;- function(indep.var, dep.var){</strong></span>
<span class="strong"><strong class="calibre9">  pl1 &lt;- qplot(factor(0),indep.var, geom="boxplot", </strong></span>
<span class="strong"><strong class="calibre9">               xlab = deparse(substitute(indep.var)), </strong></span>
<span class="strong"><strong class="calibre9">               ylab="values") + theme_bw()</strong></span>
<span class="strong"><strong class="calibre9">  pl2 &lt;- qplot(dep.var,indep.var,geom="boxplot",</strong></span>
<span class="strong"><strong class="calibre9">               xlab = deparse(substitute(dep.var)),</strong></span>
<span class="strong"><strong class="calibre9">               ylab = deparse(substitute(indep.var))) + theme_bw()</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  grid.arrange(pl1,pl2, ncol=2)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">We have used the <code class="email">qplot</code> function from the <code class="email">ggplot2</code> package for building the visualizations which we will be seeing in action soon. Now we will be shifting our focus to <code class="email">categorical variables</code>. We will start with building a function to get summary statistics of any <code class="email">categorical variable</code>.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># summary statistics</strong></span>
<span class="strong"><strong class="calibre9">get.categorical.variable.stats &lt;- function(indep.var){</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  feature.name = deparse(substitute(indep.var))</strong></span>
<span class="strong"><strong class="calibre9">  df1 &lt;- data.frame(table(indep.var))</strong></span>
<span class="strong"><strong class="calibre9">  colnames(df1) &lt;- c(feature.name, "Frequency")</strong></span>
<span class="strong"><strong class="calibre9">  df2 &lt;- data.frame(prop.table(table(indep.var)))</strong></span>
<span class="strong"><strong class="calibre9">  colnames(df2) &lt;- c(feature.name, "Proportion")</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  df &lt;- merge(</strong></span>
<span class="strong"><strong class="calibre9">    df1, df2, by = feature.name</strong></span>
<span class="strong"><strong class="calibre9">  )</strong></span>
<span class="strong"><strong class="calibre9">  ndf &lt;- df[order(-df$Frequency),]</strong></span>
<span class="strong"><strong class="calibre9">  if (names(dev.cur()) != "null device"){</strong></span>
<span class="strong"><strong class="calibre9">    dev.off()</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  grid.table(ndf)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">The preceding function will summarize the categorical variable and talk about how many classes or categories are <a id="id316" class="calibre1"/>present in it and some other details such as frequency and proportion. If you remember, we had mentioned earlier that we will also be depicting the relationship of categorical variables with the class/dependent variable <code class="email">credit.risk</code>. The following function will help us achieve the same in the form of contingency tables:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># generate contingency table</strong></span>
<span class="strong"><strong class="calibre9">get.contingency.table &lt;- function(dep.var, indep.var, </strong></span>
<span class="strong"><strong class="calibre9">                                          stat.tests=F){</strong></span>
<span class="strong"><strong class="calibre9">  if(stat.tests == F){</strong></span>
<span class="strong"><strong class="calibre9">    CrossTable(dep.var, indep.var, digits=1, </strong></span>
<span class="strong"><strong class="calibre9">               prop.r=F, prop.t=F, prop.chisq=F)</strong></span>
<span class="strong"><strong class="calibre9">  }else{</strong></span>
<span class="strong"><strong class="calibre9">    CrossTable(dep.var, indep.var, digits=1, </strong></span>
<span class="strong"><strong class="calibre9">               prop.r=F, prop.t=F, prop.chisq=F,</strong></span>
<span class="strong"><strong class="calibre9">               chisq=T, fisher=T)</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">We will also build some functions for depicting visualizations. We will be visualizing <code class="email">categorical variable</code> distribution using bar charts by using the following function:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># visualizations</strong></span>
<span class="strong"><strong class="calibre9"># barcharts</strong></span>
<span class="strong"><strong class="calibre9">visualize.barchart &lt;- function(indep.var){</strong></span>
<span class="strong"><strong class="calibre9">  qplot(indep.var, geom="bar", </strong></span>
<span class="strong"><strong class="calibre9">        fill=I('gray'), col=I('black'),</strong></span>
<span class="strong"><strong class="calibre9">        xlab = deparse(substitute(indep.var))) + theme_bw()</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">We will use mosaic plots to depict visualizations of the previously mentioned contingency tables using the following function:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># mosaic plots</strong></span>
<span class="strong"><strong class="calibre9">visualize.contingency.table &lt;- function(dep.var, indep.var){</strong></span>
<span class="strong"><strong class="calibre9">  if (names(dev.cur()) != "null device"){</strong></span>
<span class="strong"><strong class="calibre9">    dev.off()</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  mosaicplot(dep.var ~ indep.var, color=T,  </strong></span>
<span class="strong"><strong class="calibre9">             main = "Contingency table plot")</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">Now that we have built <a id="id317" class="calibre1"/>all the necessary utilities, we will begin analyzing our data in the following section.</p></div></div>

<div class="book" title="Data analysis and transformation">
<div class="book" title="Analyzing the dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec60" class="calibre1"/>Analyzing the dataset</h2></div></div></div><p class="calibre8">We will be analyzing <a id="id318" class="calibre1"/>each feature of the dataset in this section and depicting our analysis in the form of summary statistics, relationships, statistical tests, and visualizations wherever necessary. We will denote necessary analysis which will be carried out for each variable in a table. An important point to remember is that the dependent feature denoted in code by <code class="email">dep.var</code> will always be <code class="email">credit.rating</code> since this is the variable which is dependent on the other features; these features are independent variables and will be denoted as <code class="email">indep.var</code> in the tables and plots often.</p><p class="calibre8">We will carry out detailed analysis and transformations for some of the important features which have a lot of significance, especially data features having a large number of classes, so that we can clearly understand data distributions and how they change on transformation of the data. For the remaining features, we will not focus too much on the summary statistics but emphasize more on feature engineering through transformations and their relationships with the dependent <code class="email">credit.rating</code> variable.</p><p class="calibre8">Now we will attach the data frame so that we can access the individual features easily. You can do that using the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # access dataset features directly</strong></span>
<span class="strong"><strong class="calibre9">&gt; attach(credit.df)</strong></span>
</pre></div><p class="calibre8">Now we will be starting our analysis with the dependent variable <code class="email">credit.risk</code>, also known as the class variable in our dataset, which we will be trying to predict in the next chapter.</p><p class="calibre8">The following code snippet helps us in getting the required summary statistics for this feature:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # credit.rating stats</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.categorical.variable.stats(credit.rating)</strong></span>
<span class="strong"><strong class="calibre9">&gt; # credit.rating visualizations</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.barchart(credit.rating)</strong></span>
</pre></div><p class="calibre8">The following visualizations tell us that <code class="email">credit.rating</code> has two classes, <code class="email">1</code> and <code class="email">0</code>, and gives the necessary statistics. Basically, customers with a credit rating of <code class="email">1</code> are credit worthy and those with a rating of <code class="email">0</code> are not credit worthy. We also observe from the bar chart that the proportion of credit worthy customers in the bank is significantly high compared to the rest.</p><div class="mediaobject"><img src="../images/00142.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Next, we will analyze <a id="id319" class="calibre1"/>the <code class="email">account.balance</code> feature. Basically, this attribute indicates the current balance of the current account of the customer.</p><p class="calibre8">We will start with getting the summary statistics and plotting a bar-chart using the following code snippet. We will include both the outputs together for better understanding.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # account.balance stats and bar chart</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.categorical.variable.stats(account.balance)</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.barchart(account.balance)</strong></span>
</pre></div><p class="calibre8">From the following visualizations, you can see that there are four distinct classes for <code class="email">account.balance</code> and they each have some specific semantics which we will be talking about soon.</p><div class="mediaobject"><img src="../images/00143.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">From the preceding output you can see that there are four distinct classes for <code class="email">account.balance</code>, and they each have some semantics, as defined next. The currency DM indicates Deutsche <a id="id320" class="calibre1"/>Mark, the old currency name of Germany.</p><p class="calibre8">The four classes indicate the following as the main semantics or checking account held for at least a year:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: No running bank account</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: No balance or debit</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Balance of <code class="email">&lt; 200</code> DM</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Balance of <code class="email">&gt;=200</code> DM</li></ul></div><p class="calibre8">The currency DM indicates Deutsche Mark, the old currency name of Germany. We will be doing some feature engineering here and will combine classes 3 and 4 together to indicate customers who have a positive balance in their account. We will do this because the proportion of class 3 is quite small compared to the rest and we don't want to unnecessarily keep too many classes per feature unless they are critical. We will achieve this by using the following code snippets.</p><p class="calibre8">First, we will load the necessary package for doing this. Install it using the command <code class="email">install.packages("car")</code> in case you do not have the package installed.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; #load dependencies</strong></span>
<span class="strong"><strong class="calibre9">&gt; library(car)</strong></span>
</pre></div><p class="calibre8">Now we will recode the necessary classes, as shown next:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.account.balance &lt;- recode(account.balance,</strong></span>
<span class="strong"><strong class="calibre9">+                           "1=1;2=2;3=3;4=3")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$account.balance &lt;- new.account.balance</strong></span>
</pre></div><p class="calibre8">We will now see the relationship between <code class="email">new.account.balance</code> and <code class="email">credit.rating</code> using a contingency table, as discussed earlier, and visualize it using a mosaic plot by using the following code snippet. We will also perform some statistical tests which I will explain in brief later.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # contingency table and mosaic plot </strong></span>
<span class="strong"><strong class="calibre9">&gt; get.contingency.table(credit.rating, new.account.balance, </strong></span>
<span class="strong"><strong class="calibre9">                                                  stat.tests=T)</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.contingency.table(credit.rating, new.account.balance)</strong></span>
</pre></div><p class="calibre8">In the following figure, you can now see how the various classes for <code class="email">account.balance</code> are distributed with <a id="id321" class="calibre1"/>regards to <code class="email">credit.rating</code> in both the table and the plot. An interesting thing to see is that 90% of people with funds in their account are not potential credit risks, which sounds reasonable.</p><div class="mediaobject"><img src="../images/00144.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We also perform two statistical tests here: the Chi-squared test and Fisher's test, both relevant tests in contingency tables used extensively for hypothesis testing. Going into details of the statistical calculations involved in these tests is out of scope of this chapter. I will put it in a way which is easy to understand. Usually, we start with a null hypothesis that between the two variables as depicted previously, there exists no association or relationship, as well as an alternative hypothesis that there is a possibility of a relationship or association between the two variables. If the p-value obtained from the test is less than or equal to <code class="email">0.05</code>, only then can we reject the null hypothesis in favor of the alternative hypothesis. In this case, you can clearly see that both the tests give p-values <code class="email">&lt; 0.05</code>, which definitely favors the alternative hypothesis that there is some association between <code class="email">credit.rating</code> and <code class="email">account.balance</code>. These types of tests are extremely useful when we build statistical models. You can look up the preceding tests on the internet or any statistics book to get a deeper insight into what p-values signify and how they work.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note16" class="calibre1"/>Note</h3><p class="calibre8">Do note that going forward we will show only the most important analysis results for each feature. However, you can always try getting relevant information for the various analysis techniques using the functions we explained earlier. For contingency tables, use the <code class="email">get.contingency.table()</code> function. Statistical tests can be performed by setting the <code class="email">stat.tests</code> parameter as <code class="email">TRUE</code> in the <code class="email">get.contingency.table()</code> function. You can also use the <code class="email">visualize.contingency.table()</code> function to view mosaic plots.</p></div><p class="calibre8">Now we will look at <code class="email">credit.duration.months</code>, which signifies the duration of the credit in months. This is a numerical variable and the analysis will be a bit different from the other categorical variables.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # credit.duration.months analysis</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.numeric.variable.stats(credit.duration.months)</strong></span>
</pre></div><p class="calibre8">We can visualize the same from the following figure:</p><div class="mediaobject"><img src="../images/00145.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">The values we see are in months and we get the typical summary statistics for this feature, including the <a id="id322" class="calibre1"/>mean, median, and quartiles. We will now visualize the overall distribution of the values for this feature using both <code class="email">histograms/density</code> plots and <code class="email">boxplots</code>.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # histogram\density plot</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.distribution(credit.duration.months)</strong></span>
</pre></div><p class="calibre8">The preceding snippet produces the following plots. We can clearly observe that this is a multimodal distribution with several peaks.</p><div class="mediaobject"><img src="../images/00146.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We now visualize the same in the form of box plots, including the one showing associations with <code class="email">credit.rating</code> next.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # box plot</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.boxplot(credit.duration.months, credit.rating)</strong></span>
</pre></div><p class="calibre8">Interestingly, from the <a id="id323" class="calibre1"/>following plots we see that the median credit duration for people who have a bad credit rating is higher than those who have a good credit rating. This seems to be plausible if we assume that many customers with long credit durations defaulted on their payments.</p><div class="mediaobject"><img src="../images/00147.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Moving on to the next variable, <code class="email">previous.credit.payment.status</code> indicates what is the status of the customer <a id="id324" class="calibre1"/>with regards to paying his previous credits. This is a <code class="email">categorical variable</code> and we get the statistics for it as shown next:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # previous.credit.payment.status stats and bar chart</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.categorical.variable.stats(previous.credit.payment.status)</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.barchart(previous.credit.payment.status)</strong></span>
</pre></div><p class="calibre8">This gives us the following table and bar chart depicting the data distribution:</p><div class="mediaobject"><img src="../images/00148.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">The classes indicate the following as the main semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">0</strong></span>: Hesitant payment</li><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Problematic running account</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: No previous credits left</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: No problem with the current credits at this bank</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Paid back the previous credits at this bank</li></ul></div><p class="calibre8">We will be applying the <a id="id325" class="calibre1"/>following transformations to this feature, so the new semantics will be:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Some problems with payment</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: All credits paid</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: No problems and credits paid in this bank only</li></ul></div><p class="calibre8">We will perform the transformations in the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.previous.credit.payment.status &lt;- </strong></span>
<span class="strong"><strong class="calibre9">                           recode(previous.credit.payment.status,</strong></span>
<span class="strong"><strong class="calibre9">+                                           "0=1;1=1;2=2;3=3;4=3")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$previous.credit.payment.status &lt;-      </strong></span>
<span class="strong"><strong class="calibre9">                                new.previous.credit.payment.status</strong></span>
</pre></div><p class="calibre8">The contingency table for the transformed feature is obtained as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # contingency table</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.contingency.table(credit.rating,</strong></span>
<span class="strong"><strong class="calibre9">                             new.previous.credit.payment.status)</strong></span>
</pre></div><p class="calibre8">We observe from the <a id="id326" class="calibre1"/>following table that maximum people who have a good credit rating have paid their previous credits without any problem and those who do not have a good credit rating had some problem with their payments, which makes sense!</p><div class="mediaobject"><img src="../images/00149.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">The next feature we will look at is <code class="email">credit.purpose</code>, which signifies the purpose of the credit amount. This is <a id="id327" class="calibre1"/>also a categorical variable and we get its summary statistics and plot the bar chart showing the frequency of its various classes as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # credit.purpose stats and bar chart</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.categorical.variable.stats(credit.purpose)</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.barchart(credit.purpose)</strong></span>
</pre></div><p class="calibre8">This gives us the following table and bar chart depicting the data distribution:</p><div class="mediaobject"><img src="../images/00150.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We observe that there are a staggering 11 classes just for this feature. Besides this, we also observe that several classes have extremely low proportions compared to the top 5 classes and class <a id="id328" class="calibre1"/>
<span class="strong"><strong class="calibre9">label 7</strong></span> doesn't even appear in the dataset! This is exactly why we need to do feature engineering by grouping some of these classes together, as we did previously.</p><p class="calibre8">The classes indicate the following as the main semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">0</strong></span>: Others</li><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: New car</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Used car</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Furniture items</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Radio or television</li><li class="listitem"><span class="strong"><strong class="calibre9">5</strong></span>: Household appliances</li><li class="listitem"><span class="strong"><strong class="calibre9">6</strong></span>: Repair</li><li class="listitem"><span class="strong"><strong class="calibre9">7</strong></span>: Education</li><li class="listitem"><span class="strong"><strong class="calibre9">8</strong></span>: Vacation</li><li class="listitem"><span class="strong"><strong class="calibre9">9</strong></span>: Retraining</li><li class="listitem"><span class="strong"><strong class="calibre9">10</strong></span>: Business</li></ul></div><p class="calibre8">We will be transforming this feature by combining some of the existing classes and the new semantics after transformation will be the following:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: New car</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Used car</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Home related items</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Others</li></ul></div><p class="calibre8">We will do this by using the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.credit.purpose &lt;- recode(credit.purpose,"0=4;1=1;2=2;3=3;</strong></span>
<span class="strong"><strong class="calibre9">+                                              4=3;5=3;6=3;7=4;</strong></span>
<span class="strong"><strong class="calibre9">+                                              8=4;9=4;10=4")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$credit.purpose &lt;- new.credit.purpose</strong></span>
</pre></div><p class="calibre8">The contingency table for the transformed feature is then obtained by the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # contingency table</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.contingency.table(credit.rating, new.credit.purpose)</strong></span>
</pre></div><p class="calibre8">Based on the <a id="id329" class="calibre1"/>following table, we see that the customers who have credit purposes of home related items or other items seem to have the maximum proportion in the bad credit rating category:</p><div class="mediaobject"><img src="../images/00151.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">The next feature we will analyze is <code class="email">credit.amount</code>, which basically signifies the amount of credit in DM being asked from the bank by the customer. This is a numerical variable and we use the following code for getting the summary statistics:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # credit.amount analysis</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.numeric.variable.stats(credit.amount)</strong></span>
</pre></div><div class="mediaobject"><img src="../images/00152.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We see the normal statistics, such as the average credit amount as 3270 DM and the median as around 3270 DM. We will now visualize the distribution of the preceding data using a histogram and density plot as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # histogram\density plot</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.distribution(credit.amount)</strong></span>
</pre></div><p class="calibre8">This will give us the histogram and density plot for <code class="email">credit.amount</code>, and you can see that it is a <a id="id330" class="calibre1"/>right-skewed distribution in the following figure:</p><div class="mediaobject"><img src="../images/00153.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Next, we will visualize the data using boxplots to see the data distribution and its relationship with <code class="email">credit.rating</code> using the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # box plot</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.boxplot(credit.amount, credit.rating)</strong></span>
</pre></div><p class="calibre8">This generates the following boxplots where you can clearly see the right skew in the distribution shown by the numerous dots in the boxplots. We also see an interesting insight that the median credit rating was bad for those customers who asked for a higher credit amount, which seems likely assuming many of them may have failed to make all the payments required to pay off the credit amount.</p><div class="mediaobject"><img src="../images/00154.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Now that you have a good idea about how to perform descriptive analysis for categorical and numerical variables, going forward we will not be showing outputs of all the different analysis <a id="id331" class="calibre1"/>techniques for each feature. Feel free to experiment with the functions we used earlier on the remaining variables to obtain the summary statistics and visualizations if you are interested in digging deeper into the data!</p><p class="calibre8">The next feature is savings, which is a categorical variable having the following semantics for the 5 class labels:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: No savings</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: <code class="email">&lt; 100</code> DM</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Between <code class="email">[100, 499]</code> DM</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Between <code class="email">[500, 999]</code> DM</li><li class="listitem"><span class="strong"><strong class="calibre9">5</strong></span>: <code class="email">&gt;= 1000</code> DM</li></ul></div><p class="calibre8">The feature signifies the average amount of savings/stocks belonging to the customer. We will be transforming it to the following four class labels:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: No savings</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: <code class="email">&lt; 100</code> DM</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Between <code class="email">[100, 999]</code> DM</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: <code class="email">&gt;= 1000</code> DM</li></ul></div><p class="calibre8">We will be using the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # feature: savings - recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.savings &lt;- recode(savings,"1=1;2=2;3=3;</strong></span>
<span class="strong"><strong class="calibre9">+                                4=3;5=4")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$savings &lt;- new.savings</strong></span>
</pre></div><p class="calibre8">Now we analyze the relationship between savings and <code class="email">credit.rating</code> using the following code for the contingency table:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # contingency table</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.contingency.table(credit.rating, new.savings)</strong></span>
</pre></div><p class="calibre8">This generates the following contingency table. On observing the table values, it is clear that people with no savings have the maximum proportion among customers who have a bad credit rating, which is not surprising! This number is also high for customers with a good credit rating since the total number of good credit rating records is also high compared to the total <a id="id332" class="calibre1"/>records in bad credit rating. However, we also see that the proportion of people having <code class="email">&gt; 1000</code> DM and a good credit rating is quite high in comparison to the proportion of people having both a bad credit rating and <code class="email">&gt; 1000</code> DM in their savings account.</p><div class="mediaobject"><img src="../images/00155.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We will now look at the feature named <code class="email">employment.duration</code>, which is a categorical variable signifying the duration for which the customer has been employed until present. The semantics for the five classes of the feature are:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Unemployed</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: <code class="email">&lt; 1</code> year</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Between <code class="email">[1, 4]</code> years</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Between <code class="email">[4, 7]</code> years</li><li class="listitem"><span class="strong"><strong class="calibre9">5</strong></span>: <code class="email">&gt;= 7</code> years</li></ul></div><p class="calibre8">We will be transforming it to the following four classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Unemployed or <code class="email">&lt; 1</code> year</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Between <code class="email">[1,4]</code> years</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Between <code class="email">[4,7]</code> years</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: <code class="email">&gt;= 7</code> years</li></ul></div><p class="calibre8">We will be using the following code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # feature: employment.duration - recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.employment.duration &lt;- recode(employment.duration,</strong></span>
<span class="strong"><strong class="calibre9">+                                   "1=1;2=1;3=2;4=3;5=4")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$employment.duration &lt;- new.employment.duration</strong></span>
</pre></div><p class="calibre8">Now we analyze its relationship using the contingency table, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # contingency table</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.contingency.table(credit.rating, new.employment.duration)</strong></span>
</pre></div><p class="calibre8">What we observe from the following table is that the proportion of customers having none or a significantly low number of years in employment and a bad credit rating is much higher than <a id="id333" class="calibre1"/>similar customers having a good credit rating. In the case of <code class="email">employment.duration</code> feature, the value 1 indicates the people who are unemployed or have <code class="email">&lt; 1</code> year of employment. The proportion of these people having a bad credit rating in 93 out of 300 people. This gives 31% which is lot higher compared to the same metric for the customers having a good credit rating which is 141 out of 700 customers, or 20%.</p><div class="mediaobject"><img src="../images/00156.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We now move on to the next feature named <code class="email">installment.rate</code>, which is a categorical variable with the following semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: <code class="email">&gt;=35%</code></li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Between <code class="email">[25, 35]%</code></li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Between <code class="email">[20, 25]%</code></li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: <code class="email">&lt; 20%</code> for the four classes</li></ul></div><p class="calibre8">There wasn't too much information in the original metadata for this attribute so there is some ambiguity, but what we assumed is that it indicates the percentage of the customer's salary which was <a id="id334" class="calibre1"/>used to pay the credit loan as monthly installments. We won't be doing any transformations here so we will directly go to the relationships.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # feature: installment.rate - contingency table and statistical tests</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.contingency.table(credit.rating, installment.rate, </strong></span>
<span class="strong"><strong class="calibre9">+                      stat.tests=TRUE)</strong></span>
</pre></div><p class="calibre8">We performed the statistical tests for this variable in the code snippet because we weren't really sure if our assumption for its semantics was correct or whether it could be a significant variable. From the following results, we see that both statistical tests yield p-values of <code class="email">&gt; 0.05</code>, thus ruling the null hypothesis in favor of the alternative. This tells us that these two variables do not have a significant association between them and this feature might not be one <a id="id335" class="calibre1"/>to consider when we make feature sets for our predictive models. We will look at feature selection in more detail in the next chapter.</p><div class="mediaobject"><img src="../images/00157.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">The next variable we will analyze is <code class="email">marital.status</code>, which indicates the marital status of the customer and is a categorical variable. It has four classes with the following semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Male divorced</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Male single</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Male married/widowed</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Female</li></ul></div><p class="calibre8">We will be transforming them into three classes with the following semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Male divorced/single</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Male married/widowed</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Female</li></ul></div><p class="calibre8">We will be using the <a id="id336" class="calibre1"/>following code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # feature: marital.status - recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.marital.status &lt;- recode(marital.status, "1=1;2=1;3=2;4=3")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$marital.status &lt;- new.marital.status</strong></span>
</pre></div><p class="calibre8">We now observe the relationship between <code class="email">marital.status</code> and <code class="email">credit.rating</code> by building a contingency table using the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # contingency table</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.contingency.table(credit.rating, new.marital.status)</strong></span>
</pre></div><p class="calibre8">From the following table, we notice that the ratio of single men to married men for customers with a good credit rating is <span class="strong"><strong class="calibre9">1:2</strong></span> compared to nearly <span class="strong"><strong class="calibre9">1:1</strong></span> for customers with a bad credit rating. Does this mean that maybe more married men tend to pay their credit debts in time? That could be a possibility for this dataset, but do remember that correlation does not imply causation in general.</p><div class="mediaobject"><img src="../images/00158.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">The p-values from the statistical tests give us a value of <code class="email">0.01</code>, indicating that there might be some association between the features.</p><p class="calibre8">The next feature is guarantor, which signifies if the customer has any further debtors or guarantors. This is a categorical variable with three classes having the following semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: None</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Co-applicant</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Guarantor</li></ul></div><p class="calibre8">We transform them into two variables with the following semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: No</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Yes</li></ul></div><p class="calibre8">For the transformation, we use the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # feature: guarantor - recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.guarantor &lt;- recode(guarantor, "1=1;2=2;3=2")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$guarantor &lt;- new.guarantor</strong></span>
</pre></div><p class="calibre8">Performing statistical tests on this yield a p-value of <code class="email">1</code>, which is much greater than <code class="email">0.05</code>, thus ruling the null <a id="id337" class="calibre1"/>hypothesis in favor and implying that there is probably no association between guarantor and <code class="email">credit.rating</code>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip04" class="calibre1"/>Tip</h3><p class="calibre8">You can also run the statistical tests using direct functions instead of calling the <code class="email">get.contingency.table(…)</code> function each time. For Fisher's exact test, call <code class="email">fisher.test(credit.rating, guarantor)</code>, and for Pearson's Chi-squared test, call <code class="email">chisq.test(credit,rating, guarantor)</code>. Feel free to substitute guarantor with any of the other independent variables to carry out these tests.</p></div><p class="calibre8">The next feature is <code class="email">residence.duration</code>, which signifies how long the customer has been residing at his current address.</p><p class="calibre8">This is a categorical variable with the following semantics for the four classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: <code class="email">&lt; 1</code> year</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Between <code class="email">[1,4]</code> years</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Between <code class="email">[4,7]</code> years</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: <code class="email">&gt;= 7</code> years</li></ul></div><p class="calibre8">We will not be doing any transformations and will be directly doing statistical tests to see if this feature has any association with <code class="email">credit,rating</code>. From in the previous tip, using the functions <code class="email">fisher.test</code> and <code class="email">chisq.test</code> both give us a p-value of <code class="email">0.9</code>, which is significantly <code class="email">&gt; 0.05</code> and thus there is no significant relationship between them. We will show the outputs of both the statistical tests here, just so you can get an idea of what they depict.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # perform statistical tests for residence.duration</strong></span>
<span class="strong"><strong class="calibre9">&gt; fisher.test(credit.rating, residence.duration)</strong></span>
<span class="strong"><strong class="calibre9">&gt; chisq.test(credit.rating, residence.duration)</strong></span>
</pre></div><p class="calibre8">You can see from the following outputs that we get the same p-value from both the tests we talked about earlier:</p><div class="mediaobject"><img src="../images/00159.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We now shift our <a id="id338" class="calibre1"/>focus to <code class="email">current.assets,</code> which is a categorical variable having the following semantics for the four classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: No assets</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Car/other</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Life insurance/savings contract</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: House/land ownership</li></ul></div><p class="calibre8">We will not be doing any transformations on this data and will directly run the same statistical tests to check if it has any association with <code class="email">credit.rating</code>. We get a p-value of <code class="email">3 x 10-5</code>, which is definitely <code class="email">&lt; 0.05</code>, and thus we can conclude that the alternative hypothesis holds good that there is some association between the variables.</p><p class="calibre8">The next variable we will analyze is <code class="email">age</code>. This is a numeric variable and we will get its summary statistics as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # age analysis</strong></span>
<span class="strong"><strong class="calibre9">&gt; get.numeric.variable.stats(age)</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output</strong></span>:</p><div class="mediaobject"><img src="../images/00160.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We can observe that the average age of customers is 35.5 years and the median age is 33 years. To view the feature distributions, we will visualize it using a histogram and density plot using the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # histogram\density plot</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.distribution(age)</strong></span>
</pre></div><p class="calibre8">We can observe from the following plots that the distribution is a right-skewed distribution with the majority of customer ages ranging from 25 to 45 years:</p><div class="mediaobject"><img src="../images/00161.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">We will now observe the relationship between <code class="email">age</code> and <code class="email">credit.rating</code> by visualizing it through boxplots, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # box plot</strong></span>
<span class="strong"><strong class="calibre9">&gt; visualize.boxplot(age, credit.rating)</strong></span>
</pre></div><p class="calibre8">The right-skew from the <a id="id339" class="calibre1"/>following plots is clearly distinguishable in the boxplots by the cluster of dots we see at the extreme end. The interesting observation we can make from the right plot is that people who have a bad credit rating have a lower median age than people who have a good credit rating.</p><div class="mediaobject"><img src="../images/00162.jpeg" alt="Analyzing the dataset" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">One reason for this association could be that younger people who are still not well settled and employed have failed to repay the credit loans which they had taken from the bank. But, once again, this is just an assumption which we cannot verify unless we look into the full background of each customer.</p><p class="calibre8">Next, we will look at the feature <code class="email">other.credits</code>, which has the following semantics for the three classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: At other banks</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: At stores</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: No further credits</li></ul></div><p class="calibre8">This feature indicates if the customer has any other pending credits elsewhere. We will transform this to two classes with the following semantics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Yes</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: No</li></ul></div><p class="calibre8">We will be using the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # feature: other.credits - recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.other.credits &lt;- recode(other.credits, "1=1;2=1;3=2")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$other.credits &lt;- new.other.credits</strong></span>
</pre></div><p class="calibre8">On performing statistical tests on the newly transformed feature, we get a p-value of <code class="email">0.0005</code>, which is <code class="email">&lt; 0.05</code>, and thus favors the alternative hypothesis over the null, indicating that there is some <a id="id340" class="calibre1"/>association between this feature and <code class="email">credit.rating</code>, assuming there is no influence from anything else.</p><p class="calibre8">The next feature <code class="email">apartment.type</code> is a categorical variable having the following semantics for the three classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Free apartment</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Rents flat</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Owns occupied flat</li></ul></div><p class="calibre8">This feature basically signifies the type of apartment in which the customer resides. We will not be doing any transformation to this variable and will be directly moving on to the statistical tests. Both the tests give us a p-value of <code class="email">&lt; 0.05</code>, which signifies that some association is present between <code class="email">apartment.type</code> and <code class="email">credit.rating</code>, assuming no other factors affect it.</p><p class="calibre8">Now we will look at the feature <code class="email">bank.credits</code>, which is a categorical variable having the following semantics for the four classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: One</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Two/three</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Four/five</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Six or more</li></ul></div><p class="calibre8">This feature signifies the total number of credit loans taken by the customer from this bank including the current one. We will transform this into a binary feature with the following semantics for the two classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: One</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: More than one</li></ul></div><p class="calibre8">We will be using the following code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # feature: bank.credits - recode classes and update data frame</strong></span>
<span class="strong"><strong class="calibre9">&gt; new.bank.credits &lt;- recode(bank.credits, "1=1;2=2;3=2;4=2")</strong></span>
<span class="strong"><strong class="calibre9">&gt; credit.df$bank.credits &lt;- new.bank.credits</strong></span>
</pre></div><p class="calibre8">Carrying out statistical tests on this transformed feature gives us a p-value of <code class="email">0.2</code>, which is much <code class="email">&gt; 0.05</code>, and hence we know that the null hypothesis still holds good that there is no significant association <a id="id341" class="calibre1"/>between <code class="email">bank.credits</code> and <code class="email">credit.rating</code>. Interestingly, if you perform statistical tests with the untransformed version of <code class="email">bank.credits</code>, you will get an even higher p-value of <code class="email">0.4</code>, which indicates no significant association.</p><p class="calibre8">The next feature is <code class="email">occupation</code>, which obviously signifies the present job of the customer. This is a categorical variable with the following semantics for its four classes:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Unemployed with no permanent residence</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Unskilled with permanent residence</li><li class="listitem"><span class="strong"><strong class="calibre9">3</strong></span>: Skilled worker/minor civil servant</li><li class="listitem"><span class="strong"><strong class="calibre9">4</strong></span>: Executive/self-employed/higher civil servant</li></ul></div><p class="calibre8">We won't be applying any transformations on this feature since each class is quite distinct in its characteristics. Hence, we will be moving on directly to analyzing the relationships with statistical tests. Both the tests yield a p-value of <code class="email">0.6</code>, which is definitely <code class="email">&gt; 0.05</code>, and the null hypothesis holds good that there is no significant relationship between the two features.</p><p class="calibre8">We will now look at the next feature dependents, which is a categorical variable having the following semantics for its two class labels:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Zero to two</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Three or more</li></ul></div><p class="calibre8">This feature signifies the total number of people who are dependents for the customer. We will not be applying any transformations since it is already a binary variable. Carrying out statistical tests on this feature yields a p-value of <code class="email">1</code>, which tells us that this feature does not have a significant relationship with <code class="email">credit.rating</code>.</p><p class="calibre8">Next up is the feature telephone, which is a binary categorical variable which has two classes with the following semantics indicating whether the customer has a telephone:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: No</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: Yes</li></ul></div><p class="calibre8">We do not need any further transformations here since it is a binary variable. So, we move on to the statistical tests which give us a p-value of <code class="email">0.3</code>, which is <code class="email">&gt; 0.05</code>, ruling the null hypothesis in favor of the alternative, thus indicating that no significant association exists between telephone and <code class="email">credit.rating</code>.</p><p class="calibre8">The final feature in the <a id="id342" class="calibre1"/>dataset is <code class="email">foreign.worker</code>, which is a binary categorical variable having two classes with the following semantics indicating if the customer is a foreign worker:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">1</strong></span>: Yes</li><li class="listitem"><span class="strong"><strong class="calibre9">2</strong></span>: No</li></ul></div><p class="calibre8">We do not perform any transformations since it is already a binary variable with two distinct classes and move on to the statistical tests. Both the tests give us a p-value of <code class="email">&lt; 0.05</code>, which might indicate that this variable has a significant relationship with <code class="email">credit.rating</code>.</p><p class="calibre8">With this, we come to an end of our data analysis phase for the dataset.</p></div></div>

<div class="book" title="Data analysis and transformation">
<div class="book" title="Saving the transformed dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec61" class="calibre1"/>Saving the transformed dataset</h2></div></div></div><p class="calibre8">We have <a id="id343" class="calibre1"/>performed a lot of feature engineering using data transformations for several categorical variables and since we will be building predictive models on the transformed feature sets, we need to store this dataset separately to disk. We use the following code snippet for the same:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; ## Save the transformed dataset</strong></span>
<span class="strong"><strong class="calibre9">&gt; write.csv(file='credit_dataset_final.csv', x = credit.df, </strong></span>
<span class="strong"><strong class="calibre9">+           row.names = F)</strong></span>
</pre></div><p class="calibre8">We can load the above file into R directly the next time start building predictive models, which we will be covering in the next chapter.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Next steps" id="19UOO1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec38" class="calibre1"/>Next steps</h1></div></div></div><p class="calibre8">We have analyzed our dataset, performed necessary feature engineering and statistical tests, built visualizations, and <a id="id344" class="calibre1"/>gained substantial domain knowledge about credit risk analysis and what kind of features are considered by banks when they analyze customers. The reason why we analyzed each feature in the dataset in detail was to give you an idea about each feature that is considered by banks when analyzing credit rating for customers. This was to give you good domain knowledge understanding and also to help you get familiar with the techniques of performing an exploratory and descriptive analysis of any dataset in the future. So, what next? Now comes the really interesting part of using this dataset; building feature sets from this data and feeding them into predictive models to predict which customers can be potential credit risks and which of them are not. As mentioned previously, there are two steps to this: data and algorithms. In <a id="id345" class="calibre1"/>fact, we will go a step further and say that there are feature sets and algorithms which will help us in achieving our main objective.</p></div>

<div class="book" title="Next steps" id="19UOO1-973e731d75c2419489ee73e3a0cf4be8">
<div class="book" title="Feature sets"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec62" class="calibre1"/>Feature sets</h2></div></div></div><p class="calibre8">A dataset is basically a file <a id="id346" class="calibre1"/>consisting of several records of observation where each tuple or record denotes one complete set of observations and the columns are specific attributes or features in that observation which talk about specific characteristics. In predictive analytics, usually there is one attribute or feature in the dataset whose class or category has to be predicted. This variable is <code class="email">credit.rating</code> in our dataset, also known as the dependent variable. All the other features on which this depends are the independent variables. Taking a combination of these features forms a feature vector, which is also known popularly as a feature set. There are various ways of identifying what feature sets we should consider for predictive models, and you will see going ahead that for any dataset there is never a fixed feature set. It keeps changing based on feature engineering, the type of predictive model we are building, and the significance of the features based on statistical tests.</p><p class="calibre8">Each property in the feature set is termed as a feature or attribute and these are also known as independent or explanatory variables in statistics. Features can be of various types, as we saw in our dataset. We can have categorical features with several classes, binary features with two classes, ordinal features which are basically categorical features but have some order inherent in them (for example, low, medium, high), and numerical features which could be integer values or real values. Features are highly important in building predictive models and more often than not, the data scientists spend a lot of time in building the perfect feature sets to highly boost the accuracy of predictive models. This is why domain knowledge is highly essential, besides knowing about the machine learning algorithms.</p></div></div>

<div class="book" title="Next steps" id="19UOO1-973e731d75c2419489ee73e3a0cf4be8">
<div class="book" title="Machine learning algorithms"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec63" class="calibre1"/>Machine learning algorithms</h2></div></div></div><p class="calibre8">Once we get the <a id="id347" class="calibre1"/>feature sets ready, we can start using predictive models to use them and start predicting the credit rating of customers based on their features. An important thing to remember is that this is an iterative process and we have to keep modifying our feature sets based on outputs and feedback obtained from our predictive models to further improve them. Several methods which are relevant in our scenario, which belong to the class of supervised machine learning algorithms, are explained briefly in this section.</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre9">Linear classification algorithms</strong></span>: These algorithms perform classification in terms <a id="id348" class="calibre1"/>of a linear function which assigns scores to each class by performing a dot product of the feature set and some weights associated with them. The predicted class is the one which has the highest score. The optimal weights for the feature set are determined in various ways and differ based on the chosen <a id="id349" class="calibre1"/>algorithms. Some examples of algorithms include logistic regression, support vector machines, and perceptrons.</li><li class="listitem"><span class="strong"><strong class="calibre9">Decision trees</strong></span>: Here <a id="id350" class="calibre1"/>we use decision trees as predictive models that map various observations from the data points to the observed class of the record we are to predict. A decision tree is just like a flowchart structure, where each internal nonleaf node denotes a check on a feature, each branch represents an outcome of that check, and each terminal leaf node contains a class label which we predict finally.</li><li class="listitem"><span class="strong"><strong class="calibre9">Ensemble learning methods</strong></span>: These include using multiple machine learning algorithms <a id="id351" class="calibre1"/>to obtain better predictive models. An example is the Random Forest classification algorithm which uses an ensemble of decision trees during the model training phase, and at each stage it takes the majority output decision from the ensemble of decision trees as its output. This tends to reduce overfitting, which occurs frequently when using decision trees.</li><li class="listitem"><span class="strong"><strong class="calibre9">Boosting algorithms</strong></span>: This is also an ensemble learning technique in the supervised <a id="id352" class="calibre1"/>learning family of algorithms. It consists of an iterative process of training several weak classification models and learning from them before adding them to a final classifier which is stronger than them. A weighted approach is followed when adding the classifiers, which is based on their accuracy. Future weak classifiers focus more on the records which were previously misclassified.</li><li class="listitem"><span class="strong"><strong class="calibre9">Neural networks</strong></span>: These algorithms are inspired by the biological neural networks which consist of systems of interconnected neurons that exchange <a id="id353" class="calibre1"/>messages with each other. In predictive modeling, we deal with artificial neural networks which consist of interconnected groups of nodes. Each node consists of a function which is usually a mathematical function (that is, sigmoid function) and has an adaptive weight associated with it which keeps changing based on inputs fed to the nodes and constantly checking the error obtained from the outputs in several iterations also known as <span class="strong"><strong class="calibre9">epochs</strong></span>.</li></ul></div><p class="calibre8">We will be covering several of these algorithms when building predictive models in the next chapter.</p></div></div>
<div class="book" title="Summary" id="1AT9A1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec39" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">Congratulations on staying until the end of this chapter! You have learnt several important things by now which we have covered in this chapter. You now have an idea about one of the most important areas in the financial domain, that is, Credit Risk analysis. Besides this, you also gained significant domain knowledge about how banks analyze customers for their credit ratings and what kind of attributes and features are considered by them. Descriptive and exploratory analysis of the dataset also gave you an insight into how to start working from scratch when you just have a problem to solve and a dataset given to you! You now know how to perform feature engineering, build beautiful publication quality visualizations using <code class="email">ggplot2</code>, and perform statistical tests to check feature associations. Finally, we wrapped up our discussion by talking about feature sets and gave a brief introduction to several supervised machine learning algorithms which will help us in the next step of predicting credit risks. The most interesting part is yet to come, so stay tuned!</p></div></body></html>