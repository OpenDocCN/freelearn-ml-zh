["```py\nfrom tpot import TPOTClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n```", "```py\nIrisData = load_iris()\n```", "```py\nXTrain, XTest, YTrain, YTest = train_test_split(IrisData.data.astype(np.float64),\n    IrisData.target.astype(np.float64), train_size=0.70, test_size=0.30)\n```", "```py\nTpotCL = TPOTClassifier(generations=5, population_size=50, verbosity=2)\n```", "```py\nTpotCL.fit(XTrain, YTrain)\n```", "```py\nprint(TpotCL.score(XTest, YTest))\n```", "```py\nTpotCL.export('TPOTIrisPipeline.py')\n```", "```py\n$ pip install autokeras \n```", "```py\nfrom keras.datasets import mnist\nimport autokeras as ak\n```", "```py\n(XTrain, YTrain), (XTest, YTest) = mnist.load_data()\n```", "```py\nXTrain = XTrain.reshape(XTrain.shape + (1,))\nXTest = XTest.reshape(XTest.shape + (1,))\n```", "```py\nAKClf = ak.ImageClassifier()\n```", "```py\nAKClf.fit(XTrain, YTrain)\n```", "```py\nResults = AKClf.predict(XTest)\n```", "```py\nimport autosklearn.classification\nimport sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\n```", "```py\nInput, Target = sklearn.datasets.load_digits()\n```", "```py\nXTrain, XTest, YTrain, YTest = sklearn.model_selection.train_test_split(Input, Target, random_state=3)\n```", "```py\nASKModel = autosklearn.classification.AutoSklearnClassifier()\n```", "```py\nASKModel.fit(XTrain, YTrain)\n```", "```py\nYPred = ASKModel.predict(XTest)\nprint(\"Accuracy score\", sklearn.metrics.accuracy_score(YTest, YPred))\n```", "```py\nfrom mlbox.preprocessing import *\nfrom mlbox.optimisation import *\nfrom mlbox.prediction import *\n```", "```py\npaths = [\"train.csv\",\"test.csv\"] \ntarget_name = \"SalePrice\"\n```", "```py\ndata = Reader(sep=\",\").train_test_split(paths, target_name)\ndata = Drift_thresholder().fit_transform(data)\n```", "```py\nOptimiser().evaluate(None, data)\n```", "```py\nPredictor().fit_predict(None, data)\n```", "```py\nspace = {\n\n       'ne__numerical_strategy' : {\"space\" : [0, 'mean']},\n\n        'ce__strategy' : {\"space\" : [\"label_encoding\", \"random_projection\", \"entity_embedding\"]},\n\n        'fs__strategy' : {\"space\" : [\"variance\", \"rf_feature_importance\"]},\n        'fs__threshold': {\"search\" : \"choice\", \"space\" : [0.1, 0.2, 0.3]},\n\n        'est__strategy' : {\"space\" : [\"XGBoost\"]},\n        'est__max_depth' : {\"search\" : \"choice\", \"space\" : [5,6]},\n        'est__subsample' : {\"search\" : \"uniform\", \"space\" : [0.6,0.9]}\n\n        }\n\nbest = opt.optimise(space, data, max_evals = 5)\n```", "```py\nPredictor().fit_predict(best, data)\n```", "```py\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\n```", "```py\nBasicModel=MobileNet(input_shape=(224, 224, 3), weights='imagenet',include_top=False)\n```", "```py\nModelLayers=BasicModel.output\nModelLayers=GlobalAveragePooling2D()(ModelLayers)\nModelLayers=Dense(1024,activation='relu')(ModelLayers) \nModelLayers=Dense(1024,activation='relu')(ModelLayers) \nModelLayers=Dense(512,activation='relu')(ModelLayers) \nOutpModel=Dense(3,activation='softmax')(ModelLayers) \n```", "```py\nConvModel=Model(inputs=BasicModel.input,outputs=OutpModel)\n```", "```py\nfor layer in ConvModel.layers[:20]:\n    layer.trainable=False\nfor layer in ConvModel.layers[20:]:\n    layer.trainable=True\n```", "```py\nTrainDataGen=ImageDataGenerator(preprocessing_function=preprocess_input)\n```", "```py\nTrainGenerator=TrainDataGen.flow_from_directory('training_images/', #'train/'\n                                                 target_size=(224,224),\n                                                 color_mode='rgb',\n                                                 batch_size=32,\n                                                 class_mode='categorical',\n                                                 shuffle=True)\n```", "```py\nConvModel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n```", "```py\nStepSizeTrain=TrainGenerator.n//TrainGenerator.batch_size\nConvModel.fit_generator(generator=TrainGenerator,\n steps_per_epoch=StepSizeTrain,\n epochs=10)\n```", "```py\nFound 60 images belonging to 3 classes.\nEpoch 1/10\n1/1 [==============================] - 31s 31s/step - loss: 1.1935 - acc: 0.3125\nEpoch 2/10\n1/1 [==============================] - 21s 21s/step - loss: 2.7700 - acc: 0.5714\nEpoch 3/10\n1/1 [==============================] - 24s 24s/step - loss: 0.0639 - acc: 1.0000\nEpoch 4/10\n1/1 [==============================] - 21s 21s/step - loss: 0.2819 - acc: 0.7500\nEpoch 5/10\n1/1 [==============================] - 26s 26s/step - loss: 0.0012 - acc: 1.0000\nEpoch 6/10\n1/1 [==============================] - 21s 21s/step - loss: 0.0024 - acc: 1.0000\nEpoch 7/10\n1/1 [==============================] - 22s 22s/step - loss: 8.7767e-04 - acc: 1.0000\nEpoch 8/10\n1/1 [==============================] - 24s 24s/step - loss: 1.3191e-04 - acc: 1.0000\nEpoch 9/10\n1/1 [==============================] - 25s 25s/step - loss: 9.6636e-04 - acc: 1.0000\nEpoch 10/10\n1/1 [==============================] - 21s 21s/step - loss: 3.2019e-04 - acc: 1.0000\n```", "```py\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n```", "```py\nPTModel = ResNet50(weights='imagenet')\n```", "```py\nImgPath = 'airplane.jpg'\nImg = image.load_img(ImgPath, target_size=(224, 224))\n```", "```py\nInputIMG = image.img_to_array(Img)\n```", "```py\nInputIMG = np.expand_dims(InputIMG, axis=0)\n```", "```py\nInputIMG = preprocess_input(InputIMG)\n```", "```py\nPredData = PTModel.predict(InputIMG)\n```", "```py\nprint('Predicted:', decode_predictions(PredData, top=3)[0])\n```", "```py\nPredicted: [('n02690373', 'airliner', 0.80847234), ('n04592741', 'wing', 0.17411195), ('n04552348', 'warplane', 0.008112171)]\n```", "```py\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nimport numpy as np\nfrom sklearn.cluster import KMeans\n```", "```py\nmodel = VGG16(weights='imagenet', include_top=False)\n```", "```py\nVGG16FeatureList = []\n```", "```py\nimport os\nfor path, subdirs, files in os.walk('training_images'):\n    for name in files:\n        img_path = os.path.join(path, name)\n        print(img_path)\n```", "```py\nimg = image.load_img(img_path, target_size=(224, 224))\n```", "```py\n        img_data = image.img_to_array(img)\n```", "```py\n        img_data = np.expand_dims(img_data, axis=0)\n```", "```py\n        img_data = preprocess_input(img_data)\n```", "```py\n        VGG16Feature = model.predict(img_data)\n```", "```py\n        VGG16FeatureNp = np.array(VGG16Feature)\n```", "```py\n        VGG16FeatureList.append(VGG16FeatureNp.flatten())\n```", "```py\nVGG16FeatureListNp = np.array(VGG16FeatureList)\n```", "```py\nKmeansModel = KMeans(n_clusters=3, random_state=0)\n```", "```py\nKmeansModel.fit(VGG16FeatureListNp)\n```", "```py\nprint(KmeansModel.labels_)\n```", "```py\n[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 \n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n```", "```py\nfrom numpy import array\nfrom numpy import zeros\nfrom numpy import asarray\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding\n```", "```py\nAdjectives = ['Wonderful',\n        'Heroic',\n        'Glamorous',\n 'Valuable',\n        'Excellent',\n        'Optimistic',\n        'Peaceful',\n        'Romantic',\n        'Loving',\n        'Faithful',\n        'Aggressive',\n        'Arrogant',\n        'Bossy',\n        'Boring',\n        'Careless',\n        'Selfish',\n        'Deceitful',\n        'Dishonest',\n        'Greedy',\n        'Impatient']\n```", "```py\nAdjLabels = array([1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0])\n```", "```py\nTKN = Tokenizer()\nTKN.fit_on_texts(Adjectives)\nVocabSize = len(TKN.word_index) + 1\n```", "```py\nEncodedAdjectives = TKN.texts_to_sequences(Adjectives)\nPaddedAdjectives = pad_sequences(EncodedAdjectives, maxlen=4, padding='post')\n```", "```py\nEmbeddingsIndex = dict()\nf = open('glove.6B.100d.txt',encoding=\"utf8\")\nfor line in f:\n  Values = line.split()\n  Word = Values[0]\n  Coefs = asarray(Values[1:], dtype='float32')\n  EmbeddingsIndex[Word] = Coefs\nf.close()\n```", "```py\nEmbeddingMatrix = zeros((VocabSize, 100))\nfor word, i in TKN.word_index.items():\n  EmbeddingVector = EmbeddingsIndex.get(word)\n  if EmbeddingVector is not None:\n    EmbeddingMatrix[i] = EmbeddingVector\n```", "```py\nAdjModel = Sequential()\nPTModel = Embedding(VocabSize, 100, weights=[EmbeddingMatrix], input_length=4, trainable=False)\nAdjModel.add(PTModel)\nAdjModel.add(Flatten())\nAdjModel.add(Dense(1, activation='sigmoid'))\nprint(AdjModel.summary())\n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param # \n=================================================================\nembedding_13 (Embedding) (None, 4, 100) 2100 \n_________________________________________________________________\nflatten_10 (Flatten) (None, 400) 0 \n_________________________________________________________________\ndense_17 (Dense) (None, 1) 401 \n=================================================================\nTotal params: 2,501\nTrainable params: 401\nNon-trainable params: 2,100\n```", "```py\nAdjModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\nAdjModel.fit(PaddedAdjectives, AdjLabels, epochs=50, verbose=1)\n```", "```py\nloss, accuracy = AdjModel.evaluate(PaddedAdjectives, AdjLabels, verbose=1)\nprint('Model Accuracy: %f' % (accuracy*100))\n```", "```py\nModel Accuracy: 100.000000\n```"]