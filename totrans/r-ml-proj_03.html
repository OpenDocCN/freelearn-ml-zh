<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Implementing a Jokes Recommendation Engine</h1>
                </header>
            
            <article>
                
<p class="mce-root">I am sure this is something you have experienced as well: while shopping for a cellphone on Amazon, you are also shown some product recommendations of mobile accessories, such as screen guards and phone cases. Not very surprisingly, most of us end up buying one or more of these recommendations! The primary purpose of a recommendation engine in an e-commerce site is to lure buyers into purchasing more from vendors. Of course, this is no different from a salesperson trying to up-sell or cross-sell to customers in a physical store.</p>
<p class="mce-root">You may recollect the <span class="calibre4">Customers Who Bought This Item Also Bought This</span> heading on Amazon (or any e-commerce site) where recommendations are shown. The aim of these recommendations is to get you to buy not just one product but a product combo, therefore pushing the sales revenues in an upward direction. Recommendations on Amazon are so successful that McKinsey estimated that a whopping 35% of the overall sales made on Amazon is due to their recommendations!</p>
<p class="mce-root">In this chapter, we will learn about the theory and implementation of a recommendation engine to suggest jokes to users. To do this, we use the Jester's jokes dataset that is available in the <kbd class="calibre11">recommenderlab</kbd> library of R. We will cover the following major topics:</p>
<ul class="calibre9">
<li class="calibre10">Fundamental aspects of recommendation engines</li>
<li class="calibre10">Understanding the Jokes recommendation problem and the dataset</li>
<li class="calibre10">Recommendation system using an item-based collaborative filtering technique</li>
<li class="calibre10">Recommendation system using a user-based collaborative filtering technique</li>
<li class="calibre10">Recommendation system using an association-rule mining technique</li>
<li class="calibre10">Content-based recommendation engine</li>
<li class="calibre10">Hybrid recommendation system for Jokes recommendation</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fundamental aspects of recommendation engines</h1>
                </header>
            
            <article>
                
<p class="mce-root">While the basic intent of showing recommendations is to push sales, they actually serve just beyond the better sales concept. Highly personalized content is something recommendation engines are able to deliver. This essentially means that recommendation engines on a retail platform such as Amazon are able to offer the right content to the right customer at the right time through the right channel. It makes sense to provide personalized content; after all, there is no point in showing an irrelevant product to a customer. Also, with the lower attention spans of customers, businesses want to be able to maximize their selling opportunities by showing the right products and encouraging them to buy the right products. At a very high level, personalized content recommendation is achieved in AI in several ways:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Mapping similar products that were bought together</strong>:<strong class="calibre1"> </strong>Let's take an example of an online shopper who searched for school bags on a shopping website. Very likely, the shopper would be interested in buying additional school-related items when buying a school bag. Therefore, displaying school bags along with notebooks, pencils, pens, and pencil cases ensures a higher probability of additional sales.</li>
<li class="calibre10"><strong class="calibre1">Recommendations based on customer demographics</strong>:<strong class="calibre1"> </strong>Showing high-end phones and stylish phone accessories as recommended products to conservative middle class customers, who generally look for steal deals, may not fetch a big upswing in sales of the recommended products. Instead, such customers might find these irrelevant recommendations to be annoying, therefore impacting their loyalty.</li>
<li class="calibre10"><strong class="calibre1">Recommendations based on similarities between customers</strong>:<strong class="calibre1"> </strong>Product recommendations to a customer are based on the products purchased or liked by other, similar customers. For example, recommending a newly-arrived cosmetic product to young women living in urban locations. The recommendation in this case is not just because of the attributes of the customer but because other customers of a similar type have bought this product. As the item grows in popularity among similar individuals, the product is chosen as the one to be recommended.</li>
<li class="calibre10"><strong class="calibre1">Recommendations based on product similarities</strong>:<strong class="calibre1"> </strong>If you search for a laptop backpack of a particular brand, along with the results of the searched item, you are also shown other brand laptop backpacks as recommendations. This recommendation is purely based on the similarity between the products.</li>
</ul>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Recommendations based on the historical purchase profile of customers</strong>:<strong class="calibre1"> </strong>If a customer has always purchased a particular brand of jeans, they are shown recommendations of newer varieties of jeans of the particular brand they tend to purchase. These recommendations are purely based on the historical purchases of the customer.</li>
<li class="calibre10"><strong class="calibre1">Hybrid recommendations</strong>:<strong class="calibre1"> </strong>It is possible that one or more recommendation approaches can be combined to arrive at the best recommendations for a customer. For example, a recommendation list can be arrived by using customer preferences inferred from the historical data as well as from the demographics information of the customer.</li>
</ul>
<p class="mce-root">Repurchase campaigns, newsletter recommendations, rebinding the sales from abandoned carts, customized discounts and offers, and smoothened browsing experience of e-commerce sites are some of the applications of recommendation systems in the online retail industry.</p>
<p class="mce-root">Due to several prevalent use cases, it might appear that recommender systems are used in only in the e-commerce industry. However, this is not true. The following are some of the use cases of recommender systems in non e-commerce domains:</p>
<ul class="calibre9">
<li class="calibre10">In the pharmaceutical industry, recommender systems are applied to identify drugs patients with certain characteristics that they will respond better to</li>
<li class="calibre10">Stocks recommendation are done based on the stock picks of a successful group of people</li>
<li class="calibre10">YouTube and online media use a recommendation engine to serve content that is similar to the content currently being watched by the user</li>
<li class="calibre10">Tourism recommendations are based on tourist spots that the user or similar users have visited</li>
<li class="calibre10">Identifying skills and personality traits of future employees in various roles</li>
<li class="calibre10">In the culinary sciences, dishes that go pair together can be explored through the application of recommender systems</li>
</ul>
<p class="mce-root">The list can grow to an enormous size, given that use cases for recommendation systems exist in almost every domain.</p>
<p class="mce-root">Now that we have a basic understanding of the concept of recommendation systems and the value it offers to business, we can now move to our next section, where we attempt to understand the Jester's Jokes recommendation dataset and the problems that could be solved by building a recommendation engine.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendation engine categories</h1>
                </header>
            
            <article>
                
<p class="mce-root">Prior to implementing our first recommender system, let's explore the types of recommender systems in detail. The following diagram shows the broad categories of recommender systems:</p>
<p class="CDPAlignCenter1"><img class="aligncenter20" src="assets/1fadf08c-415c-415c-81d3-ef14bdba4077.png"/></p>
<div class="packtfigref">Recommender system categories</div>
<p class="mce-root">Each of the techniques shown in the diagram may be used to build a recommender system model that is capable of suggesting jokes to the users. Let's briefly explore the various recommendation engine categories.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Content-based filtering</h1>
                </header>
            
            <article>
                
<p class="mce-root">Cognitive filtering, or content-based filtering, recommends items by comparing product attributes and customer profile attributes. The attributes of each product is represented as a set of tags or terms—typically the words that occur in a product description document. The customer profile is represented with the same terms and built by analyzing the content of products that have been seen or rated by the customer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Collaborative filtering</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">Social filtering, or collaborative filtering, filters information by using the recommendations of other people. The principle behind collaborative filtering is that the customers who have appreciated the same items in the past have a high probability of displaying similar interests in the future as well.</span></p>
<p class="mce-root">We generally ask for reviews and recommendation from friends prior to watching a movie. A recommendation from a friend is more accepted than recommendations from others as we share some interests with our friends. This is the same principle on which collaborative filtering works.</p>
<p class="mce-root">Collaborative filtering can be further classified into memory-based and model-based as follows:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Memory-based</strong>: <span>In this method, u</span>ser rating information is used to compute the likeness between users or items. This computed likeness is then used to come up with recommendations.</li>
<li class="calibre10"><strong class="calibre1">Model based</strong><span>: Data mining methods are applied to recognize patterns in the data, and the learned patterns are then used to generate recommendations.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hybrid filtering</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">In this class of recommendation systems, we combine more than one type of recommendation system to come up with final recommendations.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started</h1>
                </header>
            
            <article>
                
<p class="mce-root">To get started, you will have to download the supporting files from the GitHub link.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the Jokes recommendation problem and the dataset</h1>
                </header>
            
            <article>
                
<p class="mce-root">Dr. Ken Goldberg and his colleagues, <span class="calibre4">Theresa Roeder, Dhruv Gupta, and Chris Perkins<span class="calibre4"><span class="calibre4">,</span></span></span><span class="calibre4"> </span><span class="calibre4">introduced a dataset to the world</span> <span class="calibre4">through their paper </span><em class="calibre15">Eigentaste: A Constant Time Collaborative Filtering Algorithm</em><span class="calibre4">, which is pretty popular in the recommender-systems domain. The dataset is named the</span> Jester's jokes <span class="calibre4">dataset. To create it, a number of users are presented with several jokes and they are asked to rate them. The ratings provided by the users for the various jokes formed the dataset. The data in this dataset is collected between April 1999 and May 2003. The following are the attributes of the dataset:</span></p>
<p class="mce-root"/>
<ul class="calibre9">
<li class="calibre10">Over 11,000,000 ratings of 150 jokes from 79,681 users</li>
<li class="calibre10">Each row is a user (Row 1 = User #1)</li>
</ul>
<ul class="calibre9">
<li class="calibre10">Each column is a joke (Column 1 = Joke #1)</li>
<li class="calibre10">Ratings are given as real values from -10.00 to +10.00; -10 being the lowest possible rating and 10 being the highest</li>
<li class="calibre10">99 corresponds to a null rating</li>
</ul>
<p class="mce-root">The <kbd class="calibre11">recommenderlab</kbd> package in R provides a subset of this original dataset provided by Dr. Ken Goldberg's group. We will make use of this subset for our projects covered in this chapter.</p>
<p class="mce-root">The <kbd class="calibre11">Jester5k</kbd> dataset provided in the <kbd class="calibre11">recommenderlab</kbd> library contains a 5,000 x 100 rating matrix (5,000 users and 100 jokes) with ratings between -10.00 and +10.00. All selected users have rated 36 or more jokes. The dataset is in the <kbd class="calibre11">realRatingMatrix</kbd> format. This is a special matrix format that the <kbd class="calibre11">recommenderlab</kbd> expects the data to be in, to apply the various functions that are packaged in the library.</p>
<p class="mce-root">As we are already aware, <strong class="calibre3">exploratory data analysis</strong> (<strong class="calibre3">EDA</strong>) is the first step for any data science project. Going by this principle, let's begin by reading the data, and then proceed with the EDA step on the dataset:</p>
<pre class="calibre16"># including the required libraries<br class="title-page-name"/>library(data.table)<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/># setting the seed so as to reproduce the results<br class="title-page-name"/>set.seed(54)<br class="title-page-name"/># reading the data to a variable<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/>data(Jester5k)<br class="title-page-name"/>str(Jester5k)</pre>
<p class="mce-root">This will result in the following output:</p>
<pre class="calibre16">Formal class 'realRatingMatrix' [package "recommenderlab"] with 2 slots<br class="title-page-name"/>  ..@ data     :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots<br class="title-page-name"/>  .. .. ..@ i       : int [1:362106] 0 1 2 3 4 5 6 7 8 9 ...<br class="title-page-name"/>  .. .. ..@ p       : int [1:101] 0 3314 6962 10300 13442 18440 22513 27512 32512 35685 ...<br class="title-page-name"/>  .. .. ..@ Dim     : int [1:2] 5000 100<br class="title-page-name"/>  .. .. ..@ Dimnames:List of 2<br class="title-page-name"/>  .. .. .. ..$ : chr [1:5000] "u2841" "u15547" "u15221" "u15573" ...<br class="title-page-name"/>  .. .. .. ..$ : chr [1:100] "j1" "j2" "j3" "j4" ...<br class="title-page-name"/>  .. .. ..@ x       : num [1:362106] 7.91 -3.2 -1.7 -7.38 0.1 0.83 2.91 -2.77 -3.35 -1.99 ...<br class="title-page-name"/>  .. .. ..@ factors : list()<br class="title-page-name"/>  ..@ normalize: NULL</pre>
<p class="mce-root">The data structure output is pretty self explanatory and we see it provides empirical evidence for the details we have discussed already. Let's continue our EDA further:</p>
<pre class="calibre16"># Viewing the first 5 records in the dataset<br class="title-page-name"/>head(getRatingMatrix(Jester5k),5)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">2.5 x 100 sparse Matrix of class "dgCMatrix"<br class="title-page-name"/>   [[ suppressing 100 column names ‘j1’, ‘j2’, ‘j3’ ... ]]                                                                                                           <br class="title-page-name"/>u2841   7.91  9.17  5.34  8.16 -8.74  7.14  8.88 -8.25  5.87  6.21  7.72  6.12 -0.73  7.77 -5.83 -8.88  8.98<br class="title-page-name"/>u15547 -3.20 -3.50 -9.56 -8.74 -6.36 -3.30  0.78  2.18 -8.40 -8.79 -7.04 -6.02  3.35 -4.61  3.64 -6.41 -4.13<br class="title-page-name"/>u15221 -1.70  1.21  1.55  2.77  5.58  3.06  2.72 -4.66  4.51 -3.06  2.33  3.93  0.05  2.38 -3.64 -7.72  0.97<br class="title-page-name"/>u15573 -7.38 -8.93 -3.88 -7.23 -4.90  4.13  2.57  3.83  4.37  3.16 -4.90 -5.78 -5.83  2.52 -5.24  4.51  4.37<br class="title-page-name"/>u21505  0.10  4.17  4.90  1.55  5.53  1.50 -3.79  1.94  3.59  4.81 -0.68 -0.97 -6.46 -0.34 -2.14 -2.04 -2.57                                <br class="title-page-name"/>u2841  -9.32 -9.08 -9.13 7.77  8.59  5.29  8.25  6.02  5.24  7.82  7.96 -8.88  8.25  3.64 -0.73  8.25  5.34 -7.77<br class="title-page-name"/>u15547 -0.15 -1.84 -1.84 1.84 -1.21 -8.59 -5.19 -2.18  0.19  2.57 -5.78  1.07 -8.79  3.01  2.67 -9.22 -9.32  3.69<br class="title-page-name"/>u15221  2.04  1.94  4.42 1.17  0.10 -5.10 -3.25  3.35  3.30 -1.70  3.16 -0.29  1.36  3.54  6.17 -2.72  3.11  4.81<br class="title-page-name"/>u15573  4.95  5.49 -0.49 3.40 -2.14  5.29 -3.11 -4.56 -5.44 -6.89 -0.24 -5.15 -3.59 -8.20  2.18  0.39 -1.21 -2.62<br class="title-page-name"/>u21505 -0.15  2.43  3.16 1.50  4.37 -0.10 -2.14  3.98  2.38  6.84 -0.68  0.87  3.30  6.21  5.78 -6.21 -0.78 -1.36<br class="title-page-name"/>## number of ratings<br class="title-page-name"/>print(nratings(Jester5k))</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">362106## number of ratings per user</pre>
<p class="mce-root">We will print the summary of the dataset using the following command:</p>
<pre class="calibre16">print(summary(rowCounts(Jester5k)))</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>  36.00   53.00   72.00   72.42  100.00  100.00</pre>
<p class="mce-root">We will now plot the histogram:</p>
<pre class="calibre16">## rating distribution<br class="title-page-name"/>hist(getRatings(Jester5k), main="Distribution of ratings")</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter21" src="assets/e25c8393-971a-4c48-8978-0889a87024b8.png"/></p>
<p class="mce-root">From the output, we see a somewhat normal distribution. It can also be seen that the positive ratings outnumber the negative ratings.</p>
<p class="mce-root">The <kbd class="calibre11">Jester5K</kbd> dataset also provides a character vector called <kbd class="calibre11">JesterJokes</kbd>. The vector is of length 100. These are the actual 100 jokes among others that were shown to the users to get the ratings. We could examine the jokes with the following command:</p>
<pre class="calibre16">head(JesterJokes,5)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">j1 "A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well,thank God I don't have cancer!\""<br class="title-page-name"/>j2 "This couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \"What could they possibly have said to make you move out?\" \"They told me that you were a pedophile.\" He replied, \"That's an awfully big word for a ten year old.\""<br class="title-page-name"/>j3  "Q. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson Concert."<br class="title-page-name"/>j4 "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it."<br class="title-page-name"/>j5 "Q. What's O. J. Simpson's Internet address? A. Slash, slash, backslash, slash, slash, escape."</pre>
<p class="mce-root">Based on the 5,000 user ratings we have, we could perform additional EDA to identify the joke that is rated as best by the users. This can be done through the following code:</p>
<pre class="calibre16">## 'best' joke with highest average rating<br class="title-page-name"/>best &lt;- which.max(colMeans(Jester5k))<br class="title-page-name"/>cat(JesterJokes[best])</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">A guy goes into confession and says to the priest, "Father, I'm 80 years old, widower, with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice." The priest said: "Well, my son, when was the last time you were in confession?" "Never Father, I'm Jewish." "So then, why are you telling me?" "I'm telling everybody."</pre>
<p class="mce-root">We could perform additional EDA to visualize the univariate and multivariate analysis. This exploration will help us understand each of the variables in detail as well as the relationship between them. While we do not delve deep into each of these aspects, here are some thoughts that can be explored:</p>
<ul class="calibre9">
<li class="calibre10">Exploring the users who always provide high ratings to most jokes</li>
<li class="calibre10">Correlation between the ratings provided to jokes</li>
<li class="calibre10">Identification of users that are very critical</li>
<li class="calibre10">Exploring the most popular jokes or least popular jokes</li>
<li class="calibre10">Identifying the jokes with the fewest ratings and identifying the associations between them</li>
</ul>
<p class="mce-root"> </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Converting the DataFrame</h1>
                </header>
            
            <article>
                
<p class="mce-root">We are going to use functions from an R library called <kbd class="calibre11">recommenderlab</kbd> to build recommendation engine projects in this chapter. Irrespective of the category of recommendation system we implement, there are some prerequisites that the dataset needs to satisfy to be able to apply the <kbd class="calibre11">recommenderlab</kbd> functions. The prebuilt <kbd class="calibre11">recommenderlab</kbd> functions for collaborative filtering expects <kbd class="calibre11">realRatingMatrix</kbd> to be supplied as input. In our case, the <kbd class="calibre11">Jester5k</kbd> dataset is already in this format, therefore, we could directly use this matrix to apply the <kbd class="calibre11">recommenderlab</kbd> functions.</p>
<p class="mce-root">In case, we were to have our data as a R DataFrame and if we intend to convert into <kbd class="calibre11">realRatingMatrix</kbd>, the following steps may be performed:</p>
<ol class="calibre12">
<li class="calibre10">Convert the DataFrame into an R matrix as follows:</li>
</ol>
<pre class="calibre26"># convert the df dataframe to a matrix<br class="title-page-name"/>r_mat &lt;- as.matrix(df)</pre>
<ol start="2" class="calibre12">
<li class="calibre10">Convert the resultant matrix into <kbd class="calibre11">realRatingMatrix</kbd> with the help of the <kbd class="calibre11">as()</kbd> function as follows:</li>
</ol>
<pre class="calibre26"># convert r_mat matrix to a recommenderlab realRatingMatrix<br class="title-page-name"/>r_real_mat &lt;- as(r_mat,"realRatingMatrix")</pre>
<div class="packtinfobox">Here, we assume that the name of the DataFrame is <kbd class="calibre24">df</kbd>, the code will convert it into a <kbd class="calibre24">realRatingMatrix</kbd> that can be used as input to the <kbd class="calibre24">recommenderlab</kbd> functions.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dividing the DataFrame</h1>
                </header>
            
            <article>
                
<p class="mce-root">Another prerequisite is to divide the dataset into train and test subsets. These subsets will be used in later sections to implement our recommendation systems and to measure the performance. The <kbd class="calibre11">evaluationScheme()</kbd> function from the <kbd class="calibre11">recommenderlab</kbd> library can be used to split the dataset into training and testing subsets. A number of user-specified parameters can be passed to this function. In the following code, <kbd class="calibre11">realRatingMatrix</kbd> is split according to an 80/20 training/testing split, with up to 20 items recommended for each user. Furthermore, we specify that any rating greater than <kbd class="calibre11">0</kbd> is to be considered a positive rating, in conformance with the predefined <kbd class="calibre11">[-10, 10]</kbd> rating scale. The <kbd class="calibre11">Jester5k</kbd> dataset can be divided into the train and test datasets with the following code:</p>
<pre class="calibre16"># split the data into the training and the test set<br class="title-page-name"/>Jester5k_es &lt;- evaluationScheme(Jester5k, method="split", train=0.8, given=20, goodRating=0)<br class="title-page-name"/># verifying if the train - test was done successfully<br class="title-page-name"/>print(Jester5k_es)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">Evaluation scheme with 20 items given<br class="title-page-name"/>Method: ‘split’ with 1 run(s).<br class="title-page-name"/>Training set proportion: 0.800<br class="title-page-name"/>Good ratings: &gt;=0.000000<br class="title-page-name"/>Data set: 5000 x 100 rating matrix of class ‘realRatingMatrix’ with 362106 ratings.</pre>
<p class="mce-root">From the output of the <kbd class="calibre11">evaluationScheme()</kbd> function, we can observe that the function yielded a single R object containing both the training and test subsets. This object will be used to define and evaluate a variety of recommender models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a recommendation system with an item-based collaborative filtering technique</h1>
                </header>
            
            <article>
                
<p class="mce-root">The <kbd class="calibre11">recommenderlab</kbd> package of R offers the <strong class="calibre3">item-based collaborative filtering</strong> (<strong class="calibre3">ITCF</strong>) option to build a recommendation system. This is a very straightforward approach that just needs us to call the function and supply it with the necessary parameters. The parameters, in general, will have a lot of influence on the performance of the model; therefore, testing each parameter combination is the key to obtaining the best model for recommendations. The following are the parameters that can be passed to the <kbd class="calibre11">Recommender</kbd> function:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Data normalization</strong>: Normalizing the ratings matrix is a key step in preparing the data for the recommendation engine. The process of normalization processes the ratings in the matrix by removing the rating bias. The possible values for this parameter are <kbd class="calibre11">NULL</kbd>, <kbd class="calibre11">Center</kbd>, and <kbd class="calibre11">Z-Score</kbd>.</li>
<li class="calibre10"><strong class="calibre1">Distance</strong>: This represents the type of similarity metric to be used within the model. The possible values for this parameter are Cosine similarity, Euclidean distance, and Pearson's correlation.</li>
</ul>
<p class="mce-root">With these parameter combinations, we could build and test 3 x 3 ITCF models. The basic intuition behind ITCF is that if a person likes item A, there is a good probability that they like item B as well, as long as items A and B are similar. It may be understood that the term <em class="calibre15">similar</em> does not indicate similarity between the items based on the item's attributes, but, a similarity in user preferences, for example, a group of people that liked items A also liked item B. The following diagram shows the working principle of ITCF:</p>
<p class="CDPAlignCenter1"><img class="aligncenter22" src="assets/7c3012d9-a348-4945-b0e0-b9ac887cc18f.png"/></p>
<div class="packtfigref">Example showing the working of item based collaborative filtering</div>
<p class="mce-root">Let's explore the diagram in a little more detail. In ITCF, the watermelon and grapes will form the similar-items neighborhood, which means that irrespective of users, different items that are equivalent will form a neighborhood. So when user X likes watermelon, the other item from the same neighborhood, which is grapes, will be recommended by the recommender system based on item-based collaborative filter.</p>
<p class="mce-root">ITCF involves the following three steps:</p>
<ol class="calibre12">
<li class="calibre10"><strong class="calibre1">Computing the item-based similarities through a distance measure</strong>: This involves computing the distance between the items. The distance may be computed with one of the many distance measures, such as Cosine similarity, Euclidean distance, Manhattan distance, or Jaccard index. The output of this step is to obtain a similarity matrix where each cell corresponds to the similarity of the item specified on the row of the cell and the item specified on the column of the cell.</li>
</ol>
<ol start="2" class="calibre12">
<li class="calibre10"><strong class="calibre1">Predicting the targeted item rating for a specific user</strong>: The rating is arrived at by computing the weighted sum of ratings made to the item very similar to the target item.</li>
<li class="calibre10"><strong class="calibre1">Recommending the top N items</strong>: Once all the items are predicted, we recommend the top <em class="calibre22">N</em> items.</li>
</ol>
<p class="mce-root">Now, let's build each one of the ITCF models and measure the performance against the test dataset. The following code trains the ITCF models with several parameter combinations:</p>
<pre class="calibre16">type = "IBCF"<br class="title-page-name"/>##train ITCF cosine similarity models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>ITCF_N_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Cosine"))<br class="title-page-name"/># centered<br class="title-page-name"/>ITCF_C_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Cosine"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>ITCF_Z_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Cosine"))<br class="title-page-name"/>##train ITCF Euclidean Distance models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>ITCF_N_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Euclidean"))<br class="title-page-name"/># centered<br class="title-page-name"/>ITCF_C_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Euclidean"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>ITCF_Z_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Euclidean"))<br class="title-page-name"/>#train ITCF pearson correlation models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>ITCF_N_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="pearson"))<br class="title-page-name"/># centered<br class="title-page-name"/>ITCF_C_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="pearson"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>ITCF_Z_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="pearson"))</pre>
<p class="mce-root">We now have the ITCF models, so let's get to computing the performance on the test data with each of the models we have created. The objective is to identify the best-performing ITCF model for this dataset. The following code gets the performance measurements with all the nine models on the test dataset:</p>
<pre class="calibre16"># compute predicted ratings from each of the 9 models on the test dataset<br class="title-page-name"/>pred1 &lt;- predict(ITCF_N_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred2 &lt;- predict(ITCF_C_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred3 &lt;- predict(ITCF_Z_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred4 &lt;- predict(ITCF_N_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred5 &lt;- predict(ITCF_C_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred6 &lt;- predict(ITCF_Z_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred7 &lt;- predict(ITCF_N_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred8 &lt;- predict(ITCF_C_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred9 &lt;- predict(ITCF_Z_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/># set all predictions that fall outside the valid range to the boundary values<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/><span>pred7@data@x[pred7@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/></span>pred7@data@x[pred7@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/><span>pred8@data@x[pred8@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/></span>pred8@data@x[pred8@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/># aggregate the performance measurements obtained from all the models<br class="title-page-name"/>error_ITCF &lt;- rbind(<br class="title-page-name"/>  ITCF_N_C = calcPredictionAccuracy(pred1, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_C_C = calcPredictionAccuracy(pred2, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_Z_C = calcPredictionAccuracy(pred3, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_N_E = calcPredictionAccuracy(pred4, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_C_E = calcPredictionAccuracy(pred5, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_Z_E = calcPredictionAccuracy(pred6, getData(Jester5k_es, "unknown")),<br class="title-page-name"/><span>  ITCF_N_P = calcPredictionAccuracy(pred7, getData(Jester5k_es, "unknown")),<br class="title-page-name"/></span>  ITCF_C_P = calcPredictionAccuracy(pred8, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_Z_P = calcPredictionAccuracy(pred9, getData(Jester5k_es, "unknown"))<br class="title-page-name"/>)<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>kable(error_ITCF)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">|         |     RMSE|      MSE|      MAE|<br class="title-page-name"/>|:--------|--------:|--------:|--------:|<br class="title-page-name"/>|ITCF_N_C | 4.533455| 20.55221| 3.460860|<br class="title-page-name"/>|ITCF_C_C | 5.082643| 25.83326| 4.012391|<br class="title-page-name"/>|ITCF_Z_C | 5.089552| 25.90354| 4.021435|<br class="title-page-name"/>|ITCF_N_E | 4.520893| 20.43848| 3.462490|<br class="title-page-name"/>|ITCF_C_E | 4.519783| 20.42844| 3.462271|<br class="title-page-name"/>|ITCF_Z_E | 4.527953| 20.50236| 3.472080|<br class="title-page-name"/>|ITCF_N_P | 4.582121| 20.99583| 3.522113|<br class="title-page-name"/>|ITCF_C_P | 4.545966| 20.66581| 3.510830|<br class="title-page-name"/>|ITCF_Z_P | 4.569294| 20.87845| 3.536400|</pre>
<p class="mce-root">We see the output that the ITCF recommendation application on data with the Euclidean distance yielded the best performance measurement.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a recommendation system with a user-based collaborative filtering technique</h1>
                </header>
            
            <article>
                
<p class="mce-root">The Jokes recommendation system we built earlier, with item-based filtering, uses the powerful <kbd class="calibre11">recommenderlab</kbd> library available in R. In this implementation of the <strong class="calibre3">user-based collaborative filtering</strong> (<strong class="calibre3">UBCF</strong>) approach, we make use of the same library.</p>
<p class="mce-root">The following diagram shows the working principle of UBCF:</p>
<p class="CDPAlignCenter1"><img class="aligncenter23" src="assets/d22941f0-29d2-4c0e-8a79-5f065e5f527e.png"/></p>
<div class="packtfigref">Example depicting working principle of user based collaborative filter</div>
<p class="mce-root">To understand the concept better, let's discuss the preceding diagram in detail. Let's assume that there are three users: X,Y, and Z. In UBCF, users X and Z are very similar as both of them like strawberries and watermelons. User X also likes grapes and oranges. So a user-based collaborative filter recommends grapes and oranges to user Z. The idea is that similar people tend to like similar things.</p>
<p class="mce-root">The primary difference between a user-based collaborative filter and an item-based collaborative filter is demonstrated by the following recommendation captions often seen in online retail sites:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">ITCF</strong>: Customers who bought this item also bought</li>
<li class="calibre10"><strong class="calibre1">UBCF</strong>: Customers similar to you bought</li>
</ul>
<p class="mce-root">A user-based collaborative filter is built upon the following three key steps:</p>
<ol class="calibre12">
<li class="calibre10">Find the <strong class="calibre1">k-nearest neighbors</strong> (<strong class="calibre1">KNN</strong>) to the user <em class="calibre22">x</em>, using a similarity function, <em class="calibre22">w</em>, to measure the distance between each pair of users:</li>
</ol>
<p class="CDPAlignCenter1"><img class="fm-editor-equation2" src="assets/0052a429-61c2-4996-afe6-b51671d3ac79.png"/></p>
<ol start="2" class="calibre12">
<li class="calibre10">Predict the rating that user <em class="calibre22">x</em> will provide to all items the KNN has rated, but <em class="calibre22">x</em> has not.</li>
<li class="calibre10">The <em class="calibre22">N</em> recommended items to user <em class="calibre22">x</em> is the top <em class="calibre22">N</em> items that have the best predicted ratings.</li>
</ol>
<p class="mce-root">In short, a user-item matrix is constructed during the UBCF process and based on similar users, the ratings of the unseen items of a user are predicted. The items that get the highest ratings among the predictions form the final list of recommendations.</p>
<p class="mce-root">The implementation of this project is very similar to ITCF as we are using the same library. The only change required in the code is to change the IBCF method to use UBCF. The following code block is the full code of the project implementation with UBCF:</p>
<pre class="calibre16">library(recommenderlab)<br class="title-page-name"/>data(Jester5k)<br class="title-page-name"/># split the data into the training and the test set<br class="title-page-name"/>Jester5k_es &lt;- evaluationScheme(Jester5k, method="split", train=0.8, given=20, goodRating=0)<br class="title-page-name"/>print(Jester5k_es)<br class="title-page-name"/>type = "UBCF"<br class="title-page-name"/>#train UBCF cosine similarity models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>UBCF_N_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Cosine"))<br class="title-page-name"/># centered<br class="title-page-name"/>UBCF_C_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Cosine"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>UBCF_Z_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Cosine"))<br class="title-page-name"/>#train UBCF Euclidean Distance models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>UBCF_N_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Euclidean"))<br class="title-page-name"/><span># centered<br class="title-page-name"/></span>UBCF_C_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Euclidean"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>UBCF_Z_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Euclidean"))<br class="title-page-name"/>#train UBCF pearson correlation models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>UBCF_N_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="pearson"))<br class="title-page-name"/># centered<br class="title-page-name"/>UBCF_C_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="pearson"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>UBCF_Z_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="pearson"))<br class="title-page-name"/># compute predicted ratings from each of the 9 models on the test dataset<br class="title-page-name"/>pred1 &lt;- predict(UBCF_N_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred2 &lt;- predict(UBCF_C_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred3 &lt;- predict(UBCF_Z_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred4 &lt;- predict(UBCF_N_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred5 &lt;- predict(UBCF_C_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred6 &lt;- predict(UBCF_Z_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred7 &lt;- predict(UBCF_N_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred8 &lt;- predict(UBCF_C_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred9 &lt;- predict(UBCF_Z_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/># set all predictions that fall outside the valid range to the boundary values<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred7@data@x[pred7@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred7@data@x[pred7@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred8@data@x[pred8@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred8@data@x[pred8@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/># aggregate the performance statistics<br class="title-page-name"/>error_UBCF &lt;- rbind(<br class="title-page-name"/>  UBCF_N_C = calcPredictionAccuracy(pred1, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_C_C = calcPredictionAccuracy(pred2, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_Z_C = calcPredictionAccuracy(pred3, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_N_E = calcPredictionAccuracy(pred4, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_C_E = calcPredictionAccuracy(pred5, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_Z_E = calcPredictionAccuracy(pred6, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_N_P = calcPredictionAccuracy(pred7, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_C_P = calcPredictionAccuracy(pred8, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_Z_P = calcPredictionAccuracy(pred9, getData(Jester5k_es, "unknown"))<br class="title-page-name"/>)<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>print(kable(error_UBCF))</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">|         |     RMSE|      MSE|      MAE|<br class="title-page-name"/>|:--------|--------:|--------:|--------:|<br class="title-page-name"/>|UBCF_N_C | 4.877935| 23.79425| 3.986170|<br class="title-page-name"/>|UBCF_C_C | 4.518210| 20.41422| 3.578551|<br class="title-page-name"/>|UBCF_Z_C | 4.517669| 20.40933| 3.552120|<br class="title-page-name"/>|UBCF_N_E | 4.644877| 21.57488| 3.778046|<br class="title-page-name"/>|UBCF_C_E | 4.489157| 20.15253| 3.552543|<br class="title-page-name"/>|UBCF_Z_E | 4.496185| 20.21568| 3.528534|<br class="title-page-name"/>|UBCF_N_P | 4.927442| 24.27968| 4.074879|<br class="title-page-name"/>|UBCF_C_P | 4.487073| 20.13382| 3.553429|<br class="title-page-name"/>|UBCF_Z_P | 4.484986| 20.11510| 3.525356|</pre>
<p class="mce-root">Based on the UBCF output, we observe that the <kbd class="calibre11">Z-score</kbd> normalized data with Pearson's correlation as the distance has yielded the best performance measurement. Furthermore, if we want, the UBCF and ITCF results may be compared (testing needs to be done on the same test dataset) to arrive at a conclusion of accepting the best model among the 18 models that are built for the final recommendation engine deployment.</p>
<div class="packtinfobox">The key point to observe in the code is the <kbd class="calibre24">UBCF</kbd> value that is passed to the <kbd class="calibre24">method</kbd> parameter. In the previous project, we built an item-based collaborative filter; all that is needed is for us to replace the value passed to the <kbd class="calibre24">method</kbd> parameter with IBCF.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a recommendation system based on an association-rule mining technique</h1>
                </header>
            
            <article>
                
<p class="mce-root">Association-rule mining, or market-basket analysis, is a very popular data mining technique used in the retail industry to identify the products that need to be kept together so as to encourage cross sales. An interesting aspect behind this algorithm is that historical invoices are mined to identify the products that are bought together.</p>
<p class="mce-root"><span class="calibre4">There are several off-the-shelf algorithms available to perform market-basket analysis. Some of them are Apriori, <strong class="calibre3">equivalence class transformation</strong> (<strong class="calibre3">ECLAT</strong>), and <strong class="calibre3">frequent pattern growth</strong> (<strong class="calibre3">FP-growth</strong>). We will learn to solve our problem of recommending jokes to users through applying the Apriori algorithm on the Jester jokes dataset. W</span><span class="calibre4">e will now learn the theoretical aspects that underpin the Apriori algorithm.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Apriori algorithm</h1>
                </header>
            
            <article>
                
<p class="mce-root">The building blocks of the algorithm are the items that are found in any given transaction. Each transaction could have one or more items in it. The items that form a transaction are called an itemset. An example of a transaction is an invoice.</p>
<p class="mce-root">Given the transactions dataset, the objective is to find the items in data that are associated with each other. Association is measured as frequency of the occurrence of the items in the same context. For example, purchasing one product when another product is purchased represents an association rule. The association rule detects the common usage of items.</p>
<p class="mce-root">More formally, we can define association-rule mining as, given a set of items I = {I1,I2,..Im} and database of transactions D = {t1,t,2..tn}, where ti= { Ii1,Ii2..Iim} where Iik is element of, an association is an implication of X-&gt;Y where X,Y subset of I are set of items and X intersection Y is φ. In short, associations express an implication from X-&gt; Y, where X and Y are itemsets.</p>
<p class="mce-root">The algorithm can be better understood by an example. So, let's consider the following table, which shows a representative list of sample transactions in a supermarket:</p>
<table border="1" class="calibre17">
<tbody class="calibre18">
<tr class="calibre19">
<td class="calibre27">
<p class="CDPAlignCenter1"><strong class="calibre3">Transaction</strong></p>
</td>
<td class="calibre28">
<p class="CDPAlignCenter1"><strong class="calibre3">Items</strong></p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">1</p>
</td>
<td class="calibre28">
<p class="mce-root">Milk, curd, chocolate</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">2</p>
</td>
<td class="calibre28">
<p class="mce-root">Bread, butter</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">3</p>
</td>
<td class="calibre28">
<p class="mce-root">Coke, jam</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">4</p>
</td>
<td class="calibre28">
<p class="mce-root">Bread, milk, butter, Coke</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">5</p>
</td>
<td class="calibre28">
<p class="mce-root">Bread, milk, butter, jam</p>
</td>
</tr>
</tbody>
</table>
<div class="packtfigref">Sample transactions in a super market</div>
<p class="mce-root">Let's try to explore some fundamental concepts that will help us understand how the Apriori algorithm works:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Item</strong>: An item is any individual product that is part of each of the transactions. For example, milk, Coke, and butter are all termed as items.</li>
<li class="calibre10"><strong class="calibre1">Itemset</strong><span>: Collection of one or more items. For example, <em class="calibre22">{butter, milk, coke}, {butter, milk}</em>.</span></li>
</ul>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Support count</strong><span>: Frequency of occurrence of an itemset. </span><span>For example,</span><span> support count or <em class="calibre22">σ {butter, bread, milk} = 2</em>.</span></li>
<li class="calibre10"><strong class="calibre1">Support</strong><span>: A fraction of transactions that contain an itemset. </span><span>For example,</span><span> <em class="calibre22">s = {butter, bread, milk} = 2/5</em>.</span></li>
<li class="calibre10"><strong class="calibre1">Frequent itemset</strong><span>: An itemset whose support is greater than the minimum threshold.</span></li>
<li class="calibre10"><strong class="calibre1">Support for an itemset in a context</strong><span>: Fraction of contexts that contain both <em class="calibre22">X</em> and <em class="calibre22">Y</em></span>:</li>
</ul>
<p class="CDPAlignCenter1"><img class="fm-editor-equation3" src="assets/d64f7390-23d7-409f-94cf-887150e51c11.png"/></p>
<p class="calibre29">So, <em class="calibre15">s</em> for <em class="calibre15">{milk, butter} -&gt; {bread} will be s = σ {milk, butter, bread}/N = 2/5 = 0.4</em></p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Confidence</strong>: Measures the strength of the rule, whereas support measures how often it should occur in the database. It computes how often items in <em class="calibre22">Y</em> occur in containing <em class="calibre22">X</em> through the following formula:</li>
</ul>
<p class="CDPAlignCenter1"><img class="fm-editor-equation4" src="assets/d00a906f-97da-40fc-8a56-293d0461bcc9.png"/></p>
<p class="calibre29">For example: For {bread} -&gt; {butter}</p>
<p class="mce-root"><em class="calibre15">c or α = σ {butter, bread} / σ {bread} = 3/3 = 1</em></p>
<p class="mce-root">Let's consider another example confidence for <em class="calibre15">{curd} -&gt; {bread}</em>:</p>
<p class="mce-root"><em class="calibre15">c or α = σ {curd,bread} / σ {bread} = 0/3 = 0</em></p>
<p class="mce-root">The Apriori algorithm intends to generate all possible combinations of the itemsets from the list of the items and then prunes the itemsets that have met the predefined support and confidence parameter values that were passed to the algorithm. So, it may be understood that the Apriori algorithm is a two-step algorithm:</p>
<ol class="calibre12">
<li class="calibre10">Generating itemsets from the items</li>
<li class="calibre10">Evaluating and pruning the itemsets based on predefined support and confidence</li>
</ol>
<p class="mce-root">Let's discuss step 1 in detail. Assume there are <em class="calibre15">n</em> items in the collection. The number of itemsets one could create is 2^<em class="calibre15">n</em>, and all these need to be evaluated in the second step in order to come up with the final results. Even considering just 100 different items, the number of itemsets generated is 1.27e+30! The huge number of itemsets poses a severe computational challenge.</p>
<p class="mce-root">The Apriori algorithm overcomes this challenge by preempting the itemsets that are generally rare or less important. The Apriori principle states that <em class="calibre15">if an itemset is frequent, all of its subsets must also be frequent</em>. This means that if an item does not meet the predefined support threshold, then such item does not participate in the creation of itemsets. The Apriori algorithm thus comes up with restricted number of itemsets that are viable to be evaluated without encountering a computational challenge.</p>
<p class="mce-root">The first step of the algorithm is iterative in nature. In the first iteration, it considers all itemsets of length 1, that is, each itemset contains only one item in it. Then each item is evaluated to eliminate the itemsets that are found to not meet the preset support threshold. The output of the first iteration is all itemsets of length 1 that meet the required support. This becomes the input for iteration 2, and now itemsets of length 2 are formed using only the final itemsets that are output in first iteration. Each of the itemsets formed during step 2 is checked again for the support threshold; if it is not met, such itemsets are eliminated. The iterations continue until no new itemsets can be created. The process of itemsets is illustrated in the following diagram:</p>
<p class="CDPAlignCenter1"><img class="aligncenter24" src="assets/6eead20b-c634-450e-be63-eba894c02b86.png"/></p>
<div class="packtfigref">Illustration showing the itemsets creation in Apriori algorithm</div>
<p class="mce-root">Once we have all itemsets post all the step 1 iterations of the algorithm, step 2 kicks in. Each of the itemsets generated is tested to check whether it meets the predefined confidence value. If it does not meet the threshold, such itemsets are eliminated from the final output.</p>
<p class="mce-root">At a stage where all iterations are complete and the final rules are the output from Apriori, we make use of a metric called lift to consume the relevant rules from the final output. Lift defines how much more likely one item or itemset is purchased relative to its typical rate of purchase, given that we know another item or itemset has been purchased. For each itemset, we get the lift measurement using the following formula:</p>
<p class="CDPAlignCenter1"><img class="fm-editor-equation5" src="assets/d40eaf00-9435-4131-9272-b62dc512c54b.png"/></p>
<p class="mce-root">Let's delve a little deeper into understanding the lift metric. Assume that in a supermarket, milk and bread are bought together by chance. In such a case, a large number of transactions are expected to cover the milk and bread purchased. A lift (milk -&gt; bread) of more than 1 implies that these items are found together more often than these items are purchased together by chance. We generally would look for lift values greater than 1 when evaluating the rules for their usefulness in business. A lift value higher than 1 indicates that the itemset generated is very strong, and therefore worth considering for implementation.</p>
<p class="mce-root">Now, let's implement the recommendation system using the Apriori algorithm:</p>
<pre class="calibre16"># load the required libraries<br class="title-page-name"/>library(data.table)<br class="title-page-name"/>library(arules)<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/><span># set the seed so that the results are replicable<br class="title-page-name"/></span>set.seed(42)<br class="title-page-name"/># reading the Jester5k data<br class="title-page-name"/>data(Jester5k)<br class="title-page-name"/>class(Jester5k)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">[1] "realRatingMatrix"<br class="title-page-name"/>attr(,"package")<br class="title-page-name"/>[1] "recommenderlab"</pre>
<p class="mce-root">We can see from the output that the <kbd class="calibre11">Jester5k</kbd> data in the <kbd class="calibre11">recommenderlab</kbd> library is in the <kbd class="calibre11">realRatingsMatrix</kbd> format. We are also aware that the cells in this matrix contain the ratings provided by the users for various jokes and we are aware that the ratings range between -10 to +10.</p>
<p class="mce-root">Applying the Apriori algorithm on the <kbd class="calibre11">Jester5k</kbd> dataset give us an opportunity to understand the association between the jokes. However, prior to applying the Apriori algorithm, we will need to transform the dataset to binary values where 1 represents a positive rating and 0 represents a negative rating or no rating. The <kbd class="calibre11">recommenderlab</kbd> library comes up with the <kbd class="calibre11">binarize()</kbd> function, which can perform the required operation for us. The following code binarizes the ratings matrix:</p>
<pre class="calibre16"># binarizing the Jester ratings<br class="title-page-name"/>Jester5k_bin &lt;- binarize(Jester5k, minRating=1)<br class="title-page-name"/># let us verify the binarized object<br class="title-page-name"/>class(Jester5k_bin)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">[1] "binaryRatingMatrix"<br class="title-page-name"/>attr(,"package")<br class="title-page-name"/>[1] "recommenderlab"</pre>
<p class="mce-root">We can observe from the output that <kbd class="calibre11">realRatingsMatrix</kbd> is successfully converted into <kbd class="calibre11">binaryRatingMatrix</kbd>. The Apriori algorithm that mines the associations expects a matrix to be passed as input rather than <kbd class="calibre11">binaryRatingMatrix</kbd>. We can very easily convert the <kbd class="calibre11">Jester5k_bin</kbd> object to the matrix format with the following code:</p>
<pre class="calibre16"># converting the binaryratingsmatrix to matrix format<br class="title-page-name"/>Jester5k_bin_mat &lt;- as(Jester5k_bin,"matrix")<br class="title-page-name"/># visualizing the matrix object<br class="title-page-name"/>View(Jester5k_bin_mat)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter25" src="assets/94f50034-68a7-44df-9c4e-653e4d103700.png"/></p>
<p class="mce-root">We see from the output that all the cells of the matrix are represented as <kbd class="calibre11">TRUE</kbd> and <kbd class="calibre11">FALSE</kbd>, but Apriori expects the cells to be numeric. Let's now convert the cells into <kbd class="calibre11">1</kbd> and <kbd class="calibre11">0</kbd> for <kbd class="calibre11">TRUE</kbd> and <kbd class="calibre11">FALSE</kbd>, respectively, with the following code:</p>
<pre class="calibre16"># converting the cell values to 1 and 0<br class="title-page-name"/>Jester5k_bin_mat_num &lt;- 1*Jester5k_bin_mat<br class="title-page-name"/># viewing the matrix<br class="title-page-name"/>View(Jester5k_bin_mat_num)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter26" src="assets/5f7b4675-5f57-4d77-82bb-3768722b41c0.png"/></p>
<p class="mce-root">Now we are all set to apply the Apriori algorithm on the dataset. There are two parameters, <kbd class="calibre11">support</kbd> and <kbd class="calibre11">confidence</kbd>, that we need to pass to the algorithm. The algorithm mines the dataset based on these two parameter values. We pass <kbd class="calibre11">0.5</kbd> as the value for support and <kbd class="calibre11">0.8</kbd> as the value for confidence. The following line of code extracts the joke associations that exist in our Jester jokes dataset:</p>
<pre class="calibre16">rules &lt;- apriori(data = Jester5k_bin_mat_num, parameter = list(supp = 0.005, conf = 0.8))</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">Apriori<br class="title-page-name"/>Parameter specification:<br class="title-page-name"/> confidence minval smax arem  aval originalSupport maxtime support minlen maxlen target   ext<br class="title-page-name"/>        0.8    0.1    1 none FALSE            TRUE       5     0.5      1     10  rules FALSE<br class="title-page-name"/>Algorithmic control:<br class="title-page-name"/> filter tree heap memopt load sort verbose<br class="title-page-name"/>    0.1 TRUE TRUE  FALSE TRUE    2    TRUE<br class="title-page-name"/>Absolute minimum support count: 2500<br class="title-page-name"/>set item appearances ...[0 item(s)] done [0.00s].<br class="title-page-name"/>set transactions ...[100 item(s), 5000 transaction(s)] done [0.02s].<br class="title-page-name"/>sorting and recoding items ... [29 item(s)] done [0.00s].<br class="title-page-name"/>creating transaction tree ... done [0.00s].<br class="title-page-name"/>checking subsets of size 1 2 3 done [0.01s].<br class="title-page-name"/>writing ... [78 rule(s)] done [0.00s].<br class="title-page-name"/>creating S4 object  ... done [0.00s].</pre>
<p class="mce-root">The <kbd class="calibre11">rules</kbd> object that was created from the execution of the Apriori algorithm now has all the joke associations that were extracted and mined from the dataset. As we can see from the output, there are <kbd class="calibre11">78</kbd> jokes associations that were extracted in total. We can examine the rules with the following line of code:</p>
<pre class="calibre16">inspect(rules)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">     lhs          rhs   support confidence lift     count<br class="title-page-name"/>[1]  {j48}     =&gt; {j50} 0.5068  0.8376860  1.084523 2534<br class="title-page-name"/><span>[2]  {j56}     =&gt; {j36} 0.5036  0.8310231  1.105672 2518<br class="title-page-name"/></span>[3]  {j56}     =&gt; {j50} 0.5246  0.8656766  1.120762 2623<br class="title-page-name"/>[4]  {j42}     =&gt; {j50} 0.5150  0.8475971  1.097355 2575<br class="title-page-name"/>[5]  {j31}     =&gt; {j27} 0.5196  0.8255481  1.146276 2598</pre>
<p class="mce-root">The output shown is just five rules out of the overall 78 rules that are in the list. The way to read each rule is that the joke shown on the left column (<kbd class="calibre11">lhs</kbd>) leads to the joke on the right column (<kbd class="calibre11">rhs</kbd>); that is, a user that liked the joke on <kbd class="calibre11">lhs</kbd> of the rule generally tends to like the joke shown on <kbd class="calibre11">rhs</kbd>. For example, in the first rule, if a user has liked joke <kbd class="calibre11">j48</kbd>, it is likely that they will also like <kbd class="calibre11">j50</kbd>, therefore it is worth recommending joke <kbd class="calibre11">j50</kbd> to the user that has only read joke <kbd class="calibre11">j48</kbd>.</p>
<p class="mce-root">While there are several rules generated by the Apriori algorithm, the strength of each rule is specified by a metric, called <kbd class="calibre11">lift</kbd>. This is a metric that describes the worthiness of a rule in a business context. Note that for a rule to be considered general, it has to have a lift that is less than or equal to <kbd class="calibre11">1</kbd>. A lift value greater than 1 signifies a better rule for implementing in business. The aim of the following lines of code is to get such strong rules to the top of the list:</p>
<pre class="calibre16"># converting the rules object into a dataframe<br class="title-page-name"/>rulesdf &lt;- as(rules, "data.frame")<br class="title-page-name"/># employing quick sort on the rules dataframe. lift and confidence are<br class="title-page-name"/># used as keys to sort the dataframe. - in the command indicates that we<br class="title-page-name"/># want lift and confidence to be sorted in descending order<br class="title-page-name"/>rulesdf[order(-rulesdf$lift, -rulesdf$confidence), ]</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter27" src="assets/83ceb235-42e8-4278-8191-79cbceabdc2e.png"/></p>
<p class="mce-root">It may be observed that the output shown is only a subset of the rules output. The first rule indicates that <kbd class="calibre11">j35</kbd> is a joke that can be recommended to a user that has already read jokes <kbd class="calibre11">j29</kbd> and <kbd class="calibre11">j50</kbd>.</p>
<p class="mce-root">Likewise, we could just write a script to search all the jokes that a user has already read and match it with the left side of the rule; if a match is found, the corresponding right side of the rule can be recommended as the joke for the user.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Content-based recommendation engine</h1>
                </header>
            
            <article>
                
<p class="mce-root">A recommendation engine that is solely based on the explicit or implicit feedback received from customers is termed as <strong class="calibre3">content-based recommendation system</strong>. Explicit feedback is the customer's expression of the interest through filling in a survey about preferences or rating jokes of interest or opting for newsletters related to the joke or adding the joke on the watchlist, and so on. Implicit feedback is more of a mellowed-out approach where a customer visits a page, clicks on a joke link, or just spends time reading a joke review on an e-commerce page. Based on the feedback received, similar jokes are recommended to the customers. It may be noted that content-based recommendations do not take into consideration the preferences and feedback of other customers in the system; instead, it is purely based on the personalized feedback from the specific customer.</p>
<p class="mce-root">In the recommendation process, the system identifies the products that are already positively rated by the customer with the products that the customer has not rated and looks for equivalents. Products that are similar to the positively-rated ones are recommended to the customers. In this model, the customer's preferences and behavior play a major role in incrementally fine-tuning the recommendations—that is, with each recommendation and based on whether the customer responded to the recommendation, the system learns incrementally to recommend differently. The following diagram is an illustration of how a content-based recommendation system works:</p>
<p class="CDPAlignCenter1"><img class="aligncenter28" src="assets/62443519-42f8-4de0-9d16-df39c9b9205d.png"/></p>
<div class="packtfigref">Working of a content based recommendation system</div>
<p class="mce-root">In our Jester jokes dataset, we have ratings given by users for various jokes as well as the content of the jokes themselves. Remember that the <kbd class="calibre11">JesterJokes</kbd> character vector incorporates the text present in the jokes themselves. Similarities between the texts present in the jokes can be used as one method to recommend jokes to users. The assumption is that if a person liked the content in a joke, and if there is another joke whose content is very similar, recommending the latter joke is probably going to be liked by the user.</p>
<p class="mce-root">Additional metadata related to jokes is not given in the Jester jokes dataset, however such metadata may be created from the content of the jokes. For example, the length of the joke, number of nouns, number of funny terms present in the joke, and central theme in the joke. Processing the text is not purely a recommendation area but it involves using NLP techniques as well. As we will be covering NLP in a different chapter, we will not cover it here.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Differentiating between ITCF and content-based recommendations</h1>
                </header>
            
            <article>
                
<p class="mce-root">It might appear that item-based collaborative and content-based recommendations are the same. In reality, they are not the same. Let's touch upon the differences.</p>
<p class="mce-root">ITCF is totally based on user-item rankings. When we compute the similarity between items, we do not include the item attributes and just compute the similarity of items based on all customers' ratings. So the similarity between items is computed based on the ratings instead of the metadata of item itself.</p>
<p class="mce-root">In content-based recommendations, we make use of the content of both the user and the item. Generally, we construct a user profile and item profile using the content of a shared attribute space. For example, for a movie, we represent it with the actors in it and the genre (using binary coding, for example). For a user profile, we can do the same thing based on the user, such as some actors/genres. Then the similarity of user and item can be computed using cosine similarity, for example. This cosine measure leads to the recommendations.</p>
<p class="mce-root">Content-based filtering identifies products that are similar based on the tags assigned to each product. Each product is assigned weights on the basis of term frequency and inverse document frequency of each tag. After this, the user's probability of liking a product is calculated in order to arrive at the final recommendation list.</p>
<p class="mce-root">While content-based recommendation systems are highly efficient and personalized, there is an inherent problem with this model. Let's understand the over-specialization problem of content-based recommendations with an example.</p>
<p class="mce-root">Assume there are the following five movie genres:</p>
<ul class="calibre9">
<li class="calibre10">Comedy</li>
<li class="calibre10">Thriller</li>
<li class="calibre10">Science fiction</li>
<li class="calibre10">Action</li>
<li class="calibre10">Romance</li>
</ul>
<p class="mce-root">There is this customer, Jake, who generally watches thriller and science fiction movies. Based on this preference, the content-based recommendation engine will only recommend movies related to these genres and it is never going to recommend movies from other categories. This problem arises as content-based recommendation engine solely relies on the user's past behavior and preferences to determine the recommendation.</p>
<p class="mce-root">Unlike content-recommendation systems, in ITCF recommendations, similar products build neighborhoods based on positive preferences of customers. Therefore, the system generates recommendations with products in the neighborhood that a customer might prefer. ITCF does this by making use of the correlation between the items based on the ratings given them by different users, while collaborative filtering relies on past preferences or rating correlation between users and it is able to generate recommendations for similar products even from customer's interest domain. This technique can lead to bad predictions if the product is unpopular and very few users have given feedback about it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a hybrid recommendation system for Jokes recommendations</h1>
                </header>
            
            <article>
                
<p class="mce-root">We see that both content-based filtering and collaborative filtering have their strengths and weaknesses. To overcome the issues, organizations build recommender systems that combine two or more technique and they are termed hybrid recommendation models. An example of this is a combination of content-based, IBCF, UBCF, and model-based recommender engine. This takes into account all the possible aspects that contribute to making the most relevant recommendation to the user. The following diagram shows an example approach followed in hybrid recommendation engines:</p>
<p class="CDPAlignCenter1"><img class="aligncenter29" src="assets/de76d7c8-e602-45d1-a149-fba5f673ac84.png"/></p>
<div class="packtfigref">Sample approach to hybrid recommendation engine</div>
<p class="mce-root">We need to note that there is no standard approach to achieving a hybrid recommendation engine. In order to combine recommendations, here are some suggested strategies:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Voting</strong>: Apply voting among the recommendation output obtained from individual recommender systems.</li>
<li class="calibre10"><strong class="calibre1">Rules-based selection</strong>: We could devise rules that suggest weighting the output recommendations obtained from individual recommender systems. In this case, the output from recommender systems that got higher weights will be dominant and have more influence on the final recommendation outcome.</li>
<li class="calibre10"><strong class="calibre1">Combination</strong>: Recommendations from all the recommender engines are presented together. A final list of recommendations is just the union of all recommendation output obtained from individual recommender systems.</li>
<li class="calibre10"><strong class="calibre1">Attribute integration</strong>: Taking metadata from all recommender system to infuse it as input to another recommender.</li>
</ul>
<p class="mce-root">Again, what works for a problem may not work for another, therefore these strategies need to be tested individually prior to coming up with final recommendation strategy.</p>
<p class="mce-root">The <kbd class="calibre11">recommenderlab</kbd> library offers the <kbd class="calibre11">HybridRecommender</kbd> function which allows users to train multiple recommender engines on the same set of data in one go and combine the predictions. The function has a weights parameter that offers a way to specify the weight of each of the models that will be used to combine individual predictions to arrive at the final recommendation predictions on unseen data. Implementing a hybrid recommendation-engine-based project is super straightforward and not too different from the code we learned in item-based collaborative filtering or user-based collaborative filtering projects. Anyway, let's write the code and build a hybrid recommendation engine for the <kbd class="calibre11">Jester5k</kbd> dataset:</p>
<pre class="calibre16"># including the required libraries<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/><span># accessing the Jester5k dataset that is a part of recommenderlab library<br class="title-page-name"/></span>data(Jester5k)<br class="title-page-name"/># split the data into the training and the test set<br class="title-page-name"/>Jester5k_es &lt;- evaluationScheme(Jester5k, method="split", train=0.8, given=20, goodRating=0)</pre>
<p class="mce-root">The preceding code is what trains a hybrid recommender. This is where it differs from the <kbd class="calibre11">ITCF</kbd> or <kbd class="calibre11">UBCF</kbd> recommenders we've built. We can observe from the code that we have used four different recommender methods that will constitute the hybrid recommender. Let's discuss each of these methods:</p>
<ul class="calibre9">
<li class="calibre10">The popular recommendation method simply recommends the popular jokes (determined by the number of ratings received) to users.</li>
<li class="calibre10">The second recommender method we have used is item-based collaborative filtering method with non-normalized data but with distance being computed between items through cosine similarity.</li>
<li class="calibre10">User-based collaborative filtering on <kbd class="calibre11">Z-score</kbd> normalized data with Euclidean distance being computed between users in the data.</li>
<li class="calibre10">A random recommendation method that provides a random recommendation to the users.</li>
</ul>
<p class="mce-root">By no means, we finalize that the combination of these four recommender methods is the best hybrid for this problem. The intention of this project is to demonstrate the implementation of the hybrid recommender. The choice of the methods involved is purely arbitrary. In reality, we may need to try multiple combinations to identify the best hybrid. The hybrid classifier is built using the following code:</p>
<pre class="calibre16">#train a hybrid recommender model<br class="title-page-name"/>hybrid_recom &lt;- HybridRecommender(<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method = "POPULAR"),<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method="IBCF",<br class="title-page-name"/>              param=list(normalize = NULL, method="Cosine")),<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method="UBCF",<br class="title-page-name"/>                          param=list(normalize = "Z-score",method="Euclidean")),<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method = "RANDOM"),<br class="title-page-name"/>  weights = c(.2, .3, .3,.2)<br class="title-page-name"/>)<br class="title-page-name"/># Observe the model that is built<br class="title-page-name"/>print (getModel(hybrid_recom)</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">$recommender<br class="title-page-name"/>$recommender[[1]]<br class="title-page-name"/>Recommender of type ‘POPULAR’ for ‘realRatingMatrix’<br class="title-page-name"/>learned using 4000 users.<br class="title-page-name"/>$recommender[[2]]<br class="title-page-name"/>Recommender of type ‘IBCF’ for ‘realRatingMatrix’<br class="title-page-name"/>learned using 4000 users.<br class="title-page-name"/>$recommender[[3]]<br class="title-page-name"/>Recommender of type ‘UBCF’ for ‘realRatingMatrix’<br class="title-page-name"/>learned using 4000 users.<br class="title-page-name"/>$recommender[[4]]<br class="title-page-name"/>Recommender of type ‘RANDOM’ for ‘realRatingMatrix’<br class="title-page-name"/><span>learned using 4000 users.<br class="title-page-name"/></span>$weights<br class="title-page-name"/>[1] 0.2 0.3 0.3 0.2</pre>
<p class="mce-root">Observe the weights assignment in the hybrid model. We see that the popular and random recommenders are assigned 20% weight each, whereas the <kbd class="calibre11">ITCF</kbd> and <kbd class="calibre11">UBCF</kbd> methods involved in the preceding hybrid are assigned 30% weight each. It is not mandatory to set the weights while building a hybrid recommender, in which case, equal weights are assigned to each of the methods involved in the hybrid recommender. Now that our model is ready, let's make predictions and evaluate the performance with the following code:</p>
<pre class="calibre16"># making predictions<br class="title-page-name"/>pred &lt;- predict(hybrid_recom, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/># # set the predictions that fall outside the valid range to the boundary values<br class="title-page-name"/>pred@data@x[pred@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred@data@x[pred@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/># calculating performance measurements<br class="title-page-name"/>hybrid_recom_pred = calcPredictionAccuracy(pred, getData(Jester5k_es, "unknown"))<br class="title-page-name"/># printing the performance measurements<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>print(kable(hybrid_recom_pred))</pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<pre class="calibre16">|     |         x|<br class="title-page-name"/>|:----|---------:|<br class="title-page-name"/>|RMSE |  4.468849|<br class="title-page-name"/>|MSE  | 19.970611|<br class="title-page-name"/>|MAE  |  3.493577|</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we used the <kbd class="calibre11">recommenderlab</kbd> library extensively to build the various types of joke-recommendation engines based on the Jester jokes dataset. We also learned about the theoretical concepts behind the methods. </p>
<p class="mce-root">Recommender systems is an individual ML area on its own. This subject is so vast that it cannot be covered in just one chapter. Several types of recommendation systems exists and they may be applied to datasets in specific scenarios. Matrix factorization, singular-value decomposition approximation, most popular items, and SlopeOne are some techniques that may be employed to build recommendation systems. These techniques are outside the scope of this chapter as these are rarely used in business situations to build recommendation systems, and the aim of the chapter is provide exposure to more popular techniques. Further learning on recommendation engines could be in the direction of exploring and studying these rarely-used techniques and applying them to real-world problems.</p>
<p class="mce-root">The next chapter is focused on NLP techniques. We are going to implement a sentiment-analysis engine on Amazon product reviews using several popular techniques. We'll explore semantic and syntactic approaches to analyzing text and then apply them on the Amazon review corpus. I am all geared up to turn this page and move on to the next chapter. How about you?!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">References</h1>
                </header>
            
            <article>
                
<p class="mce-root">While the <kbd class="calibre11">recommenderlab</kbd> library is super popular in the R community, this is not the only choice for building a recommendation system. Here are some other popular libraries you may rely on to implement recommendation engines:</p>
<ul class="calibre9">
<li class="calibre10"><kbd class="calibre11">rrecsys</kbd>: There are several popular recommendation systems, such as Global/Item/User-Average baselines, Item-Based KNN, FunkSVD, BPR, and weighted ALS for rapid prototyping. Refer to <a href="https://cran.r-project.org/web/packages/rrecsys/index.htmlImplementations" class="calibre8">https://cran.r-project.org/web/packages/rrecsys/index.htmlImplementations</a> for more information.</li>
<li class="calibre10"><kbd class="calibre11">recosystem</kbd>: The R wrapper of the <kbd class="calibre11">libmf</kbd> library (<a href="http://www.csie.ntu.edu.tw/~cjlin/libmf/" class="calibre8">http://www.csie.ntu.edu.tw/~cjlin/libmf/</a>) for recommender system using matrix factorization. It is typically used to approximate an incomplete matrix using the product of two matrices in a latent space. Other common names for this task include collaborative filtering, matrix completion, and matrix recovery. High-performance multicore parallel computing is supported in this package.</li>
<li class="calibre10"><kbd class="calibre11">rectools</kbd>: An advanced package for recommender systems to incorporate user and item covariate information, including item category preferences with parallel computation, novel variations on statistical latent factor model, focus group finder, NMF, ANOVA, and cosine models.</li>
</ul>


            </article>

            
        </section>
    </body></html>