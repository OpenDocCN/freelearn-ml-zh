["```py\npip install tensorflow==2.2.0 pip install keras==2.3.1 pip install scipy==1.2.3\n```", "```py\ntry:  sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (    sys.version_info.major,    sys.version_info.minor,    'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])except IndexError:  pass\n```", "```py\npython -m easy_install carla-0.9.9-py3.7-win-amd64.egg\n```", "```py\nworld.render(display)\n```", "```py\nclient.load_world('Town04')\nclient.reload_world()\n```", "```py\nspawn_point = spawn_points[0] if spawn_points else carla.Transform()\n```", "```py\ndef set_last_controls(self, control):\n    self.last_steer = control.steer\n    self.last_throttle = control.throttle\n    self.last_brake = control.brake\n```", "```py\nimage.save_to_disk('_out/%08d_%s_%f_%f_%f.jpg' % (image.frame,     camera_name, self.last_steer, self.last_throttle,    self.last_brake))\n```", "```py\n00078843_MAIN_0.000000_0.500000_0.000000.jpg\n```", "```py\nbound_y = 0.5 + self._parent.bounding_box.extent.y\nself._camera_transforms = [\n    (carla.Transform(carla.Location(x=-5.5, z=2.5),        carla.Rotation(pitch=8.0)), Attachment.SpringArm),\n    (carla.Transform(carla.Location(x=1.6, z=1.7)),         Attachment.Rigid),\n    (carla.Transform(carla.Location(x=5.5, y=1.5, z=1.5)),        Attachment.SpringArm),\n    (carla.Transform(carla.Location(x=-8.0, z=6.0),         carla.Rotation(pitch=6.0)), Attachment.SpringArm),\n    (carla.Transform(carla.Location(x=-1, y=-bound_y, z=0.5)),        Attachment.Rigid)]\n```", "```py\n(carla.Transform(carla.Location(x=1.6, z=1.7)), Attachment.Rigid),(carla.Transform(carla.Location(x=1.6, y=-bound_y, z=1.7)),    Attachment.Rigid),(carla.Transform(carla.Location(x=1.6, y=bound_y, z=1.7)),    Attachment.Rigid)\n```", "```py\nbound_y = 4\n```", "```py\nself.camera_manager.add_camera(1)self.camera_manager.add_camera(2)\n```", "```py\ncamera_name = self.get_camera_name(camera_index)if not (camera_index in self.sensors_added_indexes):    sensor = self._parent.get_world().spawn_actor(                self.sensors[self.index][-1],                self._camera_transforms[camera_index][0],                attach_to=self._parent,                attachment_type=self._camera_transforms[camera_index][1])        self.sensors_added_indexes.add(camera_index)        self.sensors_added.append(sensor)        # We need to pass the lambda a weak reference to self to avoid         # circular reference.        weak_self = weakref.ref(self)        sensor.listen(lambda image: CameraManager._save_image(weak_self,         image, camera_name))\n```", "```py\ndef get_camera_name(self, index):    return 'MAIN' if index == 0 else ('LEFT' if index == 1 else         ('RIGHT' if index == 2 else 'UNK'))\n```", "```py\nif self.recording:\n    n = image.frame % 3\n\n    # Save only one camera out of 3, to increase fluidity\n    if (n == 0 and camera_name == 'MAIN') or (n == 1 and         camera_name == 'LEFT') or (n == 2 and camera_name ==            'RIGHT'):\n       # Code to convert, resize and save the image\n```", "```py\nimg = np.frombuffer(image.raw_data, dtype=np.dtype('uint8'))\nimg = np.reshape(img, (image.height, image.width, 4))\nimg = img[:, :, :3]\n```", "```py\nimg = cv2.resize(img, (200, 133))\nimg = img[67:, :, :]\n\ncv2.imwrite('_out/%08d_%s_%f_%f_%f.jpg' % (image.frame, camera_name,   self.last_steer, self.last_throttle, self.last_brake), img). \n```", "```py\nself._control.throttle = min(self._control.throttle + 0.01, 0.5)\n```", "```py\npython manual_control_packt.py --res 480x320\n```", "```py\nCarlaUE4  -ResX=480-ResY=320\n```", "```py\ndef expand_name(file):\n    idx = int(max(file.rfind('/'), file.rfind('\\\\')))\n    prefix = file[0:idx]\n    file = file[idx:].replace('.png', '').replace('.jpg', '')\n    parts = file.split('_')\n\n    (seq, camera, steer, throttle, brake, img_type) = parts\n\n    return (prefix + seq, camera, to_float(steer),        to_float(throttle), to_float(brake), img_type)\n```", "```py\n(seq, camera, steer, throttle, brake, img_type) = expand_name(file_name)\n\n    if camera == 'LEFT':\n        steer = steer + 0.25\n    if camera == 'RIGHT':\n        steer = steer - 0.25\n```", "```py\n    model = Sequential()\n    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(66, 200, 3)))\n    ```", "```py\n    model.add(Conv2D(24, (5, 5), strides=(2, 2), activation='elu'))\n    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='relu'))\n    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='relu'))\n\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    ```", "```py\n    model.add(Flatten())\n    model.add(Dense(1164, activation='relu'))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dense(10, activation='relu'))\n    model.add(Dense(1, activation='tanh'))\n    ```", "```py\nmodel.compile(loss=mse, optimizer=Adam(), metrics=    ['cosine_proximity'])\n```", "```py\nMin Loss: 0.0026791724107401277\nMin Validation Loss: 0.0006011795485392213\nMax Cosine Proximity: 0.72493887\nMax Validation Cosine Proximity: 0.6687041521072388\n```", "```py\nsudo pip install keras-vis\n```", "```py\nconv_layer, idx_layer = next((layer.output, idx) for idx, layer in   enumerate(model.layers) if layer.output.name.startswith(name))\nact_model = models.Model(inputs=model.input, outputs=[conv_layer])\n```", "```py\nconv_layer.activation = activations.linear\nsal_model = utils.apply_modifications(act_model)\n```", "```py\ngrads = visualize_saliency(sal_model, idx_layer,    filter_indices=None, seed_input=img)\nplt.imshow(grads, alpha=.6)\n```", "```py\nvehicles = world.get_blueprint_library().filter('vehicle.*')\n```", "```py\nvehicle.citroen.c3\nvehicle.chevrolet.impala\nvehicle.audi.a2\nvehicle.nissan.micra\nvehicle.carlamotors.carlacola\nvehicle.audi.tt\nvehicle.bmw.grandtourer\nvehicle.harley-davidson.low_rider\nvehicle.bmw.isetta\nvehicle.dodge_charger.police\nvehicle.jeep.wrangler_rubicon\nvehicle.mercedes-benz.coupe\nvehicle.mini.cooperst\nvehicle.nissan.patrol\nvehicle.seat.leon\nvehicle.toyota.prius\nvehicle.yamaha.yzf\nvehicle.kawasaki.ninja\nvehicle.bh.crossbike\nvehicle.tesla.model3\nvehicle.gazelle.omafiets\nvehicle.tesla.cybertruck\nvehicle.diamondback.century\nvehicle.audi.etron\nvehicle.volkswagen.t2\nvehicle.lincoln.mkz2017\nvehicle.mustang.mustang\n```", "```py\nbp=self.world.get_blueprint_library().filter(self._actor_filter)\nblueprint = next(x for x in bp if x.id == 'vehicle.audi.tt')\n```", "```py\nself.player = self.world.try_spawn_actor(blueprint, spawn_point)\n```", "```py\nspawn_point = spawn_points[0] if spawn_points else carla.Transform()\n```", "```py\nclient.load_world('Town04')\nclient.reload_world()\n```", "```py\nself.self_driving = False\n```", "```py\nelif event.key == K_d:\n  self.self_driving = not self.self_driving\n  if self.self_driving:\n    world.hud.notification('Self-driving with Neural Network')\n  else:\n    world.hud.notification('Self-driving OFF')\n```", "```py\narray_bgr = cv2.resize(array, (200, 133))\nself.last_image = array_bgr[67:, :, :]\narray = array[:, :, ::-1]  # BGR => RGB\n```", "```py\nmodel = keras.models.load_model('behave.h5')\n```", "```py\nif world.camera_manager.last_image is not None:\n  image_array = np.asarray(world.camera_manager.last_image)\n  controller.self_driving_steer = model.predict(image_array[    None, :, :, :], batch_size=1)[0][0].astype(float)\n```", "```py\nif self.self_driving:\n  self.player_max_speed = 0.3\n  self.player_max_speed_fast = 0.3\n  self._control.throttle = 0.3\n  self._control.steer = self.self_driving_steer\n  return\n```", "```py\nfailed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\n```", "```py\nimport tensorflow\ngpus = tensorflow.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    for gpu in gpus:\n      tensorflow.config.experimental.set_memory_growth(gpu, True)\n    print('TensorFlow allowed growth to ', len(gpus), ' GPUs')\n  except RuntimeError as e:\n    print(e)\n```", "```py\ndef extract_image(file_name):\n    return cv2.imread(file_name)\n```", "```py\ndef extract_label(file_name):\n  (seq, camera, steer, throttle, brake, img_type) =    expand_name(file_name)\n  return steer\n```", "```py\ndef generator(ids, fn_image, fn_label, batch_size=32):\n  num_samples = len(ids)\n  while 1: # The generator never terminates\n    samples_ids = shuffle(ids) # New epoch\n\n    for offset in range(0, num_samples, batch_size):\n      batch_samples_ids = samples_ids[offset:offset + batch_size]\n      batch_samples = [fn_image(x) for x in batch_samples_ids]\n      batch_labels = [fn_label(x) for x in batch_samples_ids]\n\n      yield np.array(batch_samples), np.array(batch_labels)\n```", "```py\nfiles = shuffle(files)idx_split = int(len(files) * 0.8)\nval_size = len(files) - idx_split\ntrain_gen = generator(files[0:idx_split], extract_image,  extract_label, batch_size)\nvalid_gen = generator(files[idx_split:], extract_image,  extract_label, batch_size)\nhistory_object = model.fit(train_gen, epochs=250,  steps_per_epoch=idx_split/batch_size, validation_data=valid_gen,  validation_steps=val_size/batch_size, shuffle=False, callbacks=  [checkpoint, early_stopping])\n```"]