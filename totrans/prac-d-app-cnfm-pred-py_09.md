# 9

# 计算机视觉中的一致性预测

在当今快节奏的世界里，计算机视觉已经超越了仅仅图像识别的范畴，成为众多现实应用中的基本基石。从在繁忙街道上导航的自动驾驶汽车到能够检测疾病早期迹象的医疗成像系统，对可靠且准确的计算机视觉模型的需求从未如此之高。然而，随着这些系统和它们应用的日益复杂，迫切需要一种能力来量化与它们预测相关的不确定性。

介绍**一致性预测**，这是一个开创性的框架，提供了一种稳健的方法来封装机器学习模型中固有的不确定性。虽然传统的计算机视觉模型通常只产生一个预测，但一致性预测的真正力量在于其提供一系列可能的输出，每个输出都附带一个置信水平。这为从业者提供了一个更明智、更细致的模型预测视角，使得在关键应用中部署更安全、更可靠的模型成为可能。

本章深入探讨了一致性预测与计算机视觉的结合。我们首先阐明在计算机视觉中量化不确定性的必要性，强调其在包括**自动驾驶**和**医疗诊断**在内的现实场景中的重要性。随着我们进一步探索，我们将揭示现代深度学习模型的阿喀琉斯之踵：*它们产生* *错误的预测*的倾向。

到旅程结束时，你将获得实际操作经验，构建融入一致性预测能力的最先进的计算机视觉分类器。我们将介绍并引导你通过计算机视觉应用中最佳的开放源代码一致性预测库，确保你拥有开始这段旅程所需的所有工具。

在本章中，我们将涵盖以下主要主题：

+   计算机视觉中的不确定性量化

+   为什么深度学习会产生错误的预测

+   计算机视觉问题中量化不确定性的各种方法

+   计算机视觉中的一致性预测

+   使用一致性预测构建计算机视觉分类器

# 计算机视觉中的不确定性量化

作为一个领域，计算机视觉通过自动化曾经仅限于人类视觉和认知的复杂任务，已经改变了众多行业。计算机视觉模型已成为现代技术不可或缺的一部分，无论是检测道路上的行人，识别医学扫描中的潜在肿瘤，还是分析卫星图像进行环境研究。然而，随着对这些模型的依赖性增加，理解和量化与它们预测相关的不确定性的需求也在增长。

## 为什么不确定性很重要？

在深入探讨机制之前，了解为什么我们需要**不确定性量化（UQ**）本身是至关重要的。以下是一些原因：

+   **安全和可靠性**：在关键应用中，如医学成像或自动驾驶，错误的预测可能带来严重的后果。了解预测的置信水平可以帮助决策，例如是否信任模型的预测或寻求人工干预。

+   **模型改进**：不确定性测量可以提供关于模型可能不足的领域的见解，有助于指导数据收集和训练改进。

+   **可信度**：知道一个系统承认其局限性，并能向最终用户和利益相关者提供置信区间或不确定性度量，使其更加可信。

在计算机视觉的世界中导航，不可避免地会遇到可能影响模型预测准确性的不确定性。但不确定性的来源是什么，它们可以被管理吗？让我们深入了解计算机视觉中的两种主要类型的不确定性。

## 计算机视觉中的不确定性类型

计算机视觉中的不确定性可以大致分为两类：

+   **随机不确定性**：这种不确定性源于数据中的固有噪声。例如，低光照图像、模糊图像或从不同角度拍摄的图像引入了模型可能难以处理的变异性。随机不确定性通常是不可减少的，这意味着无论模型变得多好，由于观察中的固有噪声，这种不确定性始终存在。

+   **认知不确定性**：这种不确定性源于模型本身。它可能是由于训练数据不完整、模型架构选择或优化过程造成的。只要有足够的数据或模型设计的改进，认知不确定性是可以降低的。

在计算机视觉领域，仅仅得到一个预测是不够的。尽管我们的模型很先进，但它们有时可能会过于自信，这可能导致错误的决策。我们如何衡量这些预测的可靠性？这就引入了不确定性量化（Uncertainty Quantification，UQ）的世界。

## 不确定性量化

现代计算机视觉模型，尤其是深度学习架构，产生的预测往往过于自信。这种误校准可能是误导性的，尤其是在关键应用中。因此，需要的不仅仅是产生预测，还要伴随一个置信度或不确定性的度量。

已经提出了各种方法来量化不确定性，从提供模型参数分布的贝叶斯神经网络，到依赖于不同模型预测变异性集成的集成方法。

然而，正如我们将在后续章节中看到的，符合预测为计算机视觉应用量身定制的不确定性量化提供了一种新颖而严谨的视角。

计算机视觉的不确定性量化并非理论练习，而是构建可靠、安全和值得信赖模型的关键方面。随着计算机视觉系统继续渗透到各个领域，理解和考虑其固有的不确定性将至关重要。

# 为什么深度学习会产生错误的预测？

**ImageNet大规模视觉识别挑战赛**（**ILSVRC**）是一个年度竞赛，研究团队在给定的数据集上评估他们的算法，旨在推动计算机视觉的边界。2012年是该领域的分水岭，标志着深度学习在计算机视觉领域的主导地位发生了重大转变（[https://www.image-net.org/challenges/LSVRC/2012/](https://www.image-net.org/challenges/LSVRC/2012/)）。

在深度学习出现之前，计算机视觉主要依赖于手工设计的特征和传统的机器学习技术。例如**尺度不变特征变换**（**SIFT**）、**方向梯度直方图**（**HOG**）和**加速鲁棒特征**（**SURF**）等算法常用于从图像中提取特征。然后，这些特征会被输入到机器学习分类器，如**支持向量机**（**SVM**）进行预测。虽然这些方法取得了一定的成功，但在可扩展性和在更复杂的数据集上的性能方面存在重大局限性。

2012年，由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton开发的一个名为AlexNet的深度卷积神经网络（[https://en.wikipedia.org/wiki/AlexNet](https://en.wikipedia.org/wiki/AlexNet)），被提交到ILSVRC竞赛中。它实现了15.3%的顶级错误率，比第二名低10.8个百分点，这是一个显著的进步，是性能的逐步提升和质的飞跃。

为什么AlexNet具有革命性？

+   **深度架构**：与当时其他网络相比，AlexNet的深度要大得多。它有五个卷积层，后面跟着三个全连接层。这种深度使得它能够从ImageNet数据集中学习更复杂和层次化的特征。

+   **GPU训练**：该团队利用**图形处理单元**（**GPU**）来训练网络，这使得处理ImageNet数据集中的大量数据并高效训练深度架构成为可能。

+   **ReLU激活**：与传统的tanh或sigmoid激活函数不同，AlexNet采用了**修正线性单元**（**ReLU**）激活。这一选择有助于解决梯度消失问题，使得训练更深层的网络成为可能。

+   **Dropout**：为了防止过拟合，AlexNet引入了dropout技术，在训练过程中随机丢弃神经元子集，迫使网络学习冗余表示。

2012年的黎明标志着计算机视觉领域的一个变革时刻。在ImageNet竞赛中AlexNet前所未有的成就的推动下，整个行业转向了深度学习，特别是**卷积** **神经网络**（**CNNs**）。随着我们穿越这场革命的余波，我们将见证研究的指数级增长、广泛的行业采用以及对更多数据和计算能力的不懈追求。

## 2012年后 – 深度学习的兴起

2012年的ImageNet竞赛，以AlexNet的胜利为标志，成为了计算机视觉领域的一个转折点。这次胜利凸显了深度学习的巨大潜力，特别是**卷积神经网络**（**CNNs**）。因此，以下情况发生了：

+   **研究热潮**：2012年后，对计算机视觉深度学习的研究爆炸式增长。AlexNet的变体和改进，如VGG、GoogLeNet和ResNet，迅速开发出来，进一步推动了边界。

+   **行业采用**：科技巨头和初创公司开始大量投资深度学习研究和应用，从面部识别系统到增强现实。

+   **数据集和计算资源**：深度学习成功推动了更大数据集的创建和更强大计算基础设施的竞赛，进一步加速了创新周期。

2012年的ImageNet竞赛是一个转折点，预示着计算机视觉深度学习时代的到来。AlexNet的原则和突破为今天我们所看到的从自动驾驶汽车到实时视频分析等后续进步奠定了基础。

## 深度学习的“校准危机”——2017年的转折点

自2012年ImageNet竞赛以来的辉煌上升之后，深度学习在许多领域经历了快速发展和广泛应用。社区连续五年专注于开发架构、优化技术和应用。然而，在这场创新的风暴中，一个重大的担忧却被很大程度上忽视了：**深度学习系统产生的预测结果的不准确校准**。

在实际应用中，自动化系统驱动决策时，分类网络仅仅提供准确结果是不够的。这些系统在医疗保健到金融等各个关键领域发挥着至关重要的作用，任何误判都可能产生重大后果。因此，这些分类网络不仅需要提供精确的结果，还需要具备自我意识，以标记预测中潜在的不确定性或错误。

例如，在医疗诊断工具中，除了正确识别疾病外，系统还应指出其对诊断的置信水平。如果医疗专业人员不确定，可以采取适当的预防措施，例如寻求额外的测试或专家意见。

再举一个例子：一辆配备神经网络以识别道路上行人和各种障碍物的自动驾驶汽车。在这种情况下，汽车的系统不仅需要识别人或障碍物，而且必须准确且实时地做到这一点。任何延迟或误识别都可能导致潜在的危险情况。

此外，这不仅仅是关于检测障碍，还包括理解检测的确定性水平。想象一下这样的场景：自动驾驶汽车的检测网络难以自信地确定前方是否有障碍。如果汽车的系统对物体不确定——可能是由于照明条件差或视线受阻——它应该被编程为更多地依赖来自其其他传感器的数据，例如激光雷达或雷达，以决定是否需要制动，并谨慎行驶，减速或甚至停车。这种精确检测和自我意识其确定性水平的双重要求确保了更安全的导航和决策，尤其是在动态和不可预测的道路环境中。如果您想了解更多关于这个主题的细节，请参阅文章《自动驾驶的风险敏感决策》（[https://uu.diva-portal.org/smash/get/diva2:1698692/FULLTEXT01.pdf](https://uu.diva-portal.org/smash/get/diva2:1698692/FULLTEXT01.pdf)）。

准确的置信度估计在增强模型可解释性方面发挥着关键作用。人类天生理解并能够与概率建立联系，这使得它成为衡量预测的一个直观指标。

当模型提供良好的校准置信水平时，它为用户提供了额外的信息层，增强了其可信度。这对于神经网络尤为重要，因为它们的决策过程可能复杂且难以解读。此外，可靠的概率评估可以集成到更广泛的概率模型中，进一步扩大其效用和应用范围。

这种准确性和内省的结合确保了自动化决策系统值得信赖且可靠，有助于增强其在关键应用中的集成信心。

校准误差指的是模型对其预测的置信度与实际预测准确度之间的差异。例如，如果一个模型声称对一组预测有90%的置信度，人们预期大约90%的预测是正确的。然而，尽管深度学习模型具有较高的准确率，但它们往往需要赶上其表达的置信度和实际正确性。

快进到今天，尽管与十年前相比，当代神经网络在准确性方面取得了显著进步，但值得注意的是，它们不再保持校准。

直到2017年，这个问题的重要性才被带到人工智能社区的关注焦点。一篇关键论文，*《现代神经网络的校准》（Guo, 2017）*，([https://proceedings.mlr.press/v70/guo17a.html](https://proceedings.mlr.press/v70/guo17a.html)) 发现深度神经网络校准不佳，突显了深度学习系统中固有的校准难题。

这项研究不仅强调了这些系统的严重误校准，而且还揭示了惊人的发现：一些被誉为突破性的*最先进*技术，如dropout、权重衰减和批量归一化，反而加剧了误校准问题。

这篇开创性的论文起到了警钟的作用。它促使社区进行反思，敦促研究人员质疑并重新审视他们所倡导的技术。这篇论文是对问题的批判和探索及纠正的邀请。它清晰的表达和深刻的洞察力使它成为该领域任何人的必读之作。

虽然2012年ImageNet竞赛之后的几年以快速进步和无拘无束的乐观为特征，但2017年的论文却是一个清算的时刻。它强调了科学中反思的重要性以及不断改进、重新校准和必要时重新思考我们方法的持续需求，以确保我们构建的人工智能系统是准确且可靠校准的。

置信度校准是预测表示实际结果的概率估计的问题。在许多应用中，这对于分类模型至关重要，因为良好的置信度估计可以为建立与用户的信任提供有价值的信息。良好的概率估计可用于模型可解释性，因为人类对概率有自然的认知直觉。

论文《现代神经网络的校准》的作者发现，模型容量增加和缺乏正则化与深度神经网络中观察到的误校准现象密切相关。在过去几年中，模型容量大幅增加，网络拥有数百或数千层，每层有数百个卷积滤波器。最近的研究表明，非常深或宽的模型可以比较小的模型更好地泛化，同时展现出轻松拟合训练集的能力。然而，这种增加的容量可能导致过拟合和误校准。

关于浅层经典神经网络，论文《现代神经网络的校准》提出，传统的（或浅层的）神经网络校准良好。这种信念源于Niculescu-Mizil和R. Caruana于2005年发表的一篇高度引用的论文，题为《使用监督学习预测良好的概率》([https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf))。这篇论文在著名的ICML会议上发表，自发表以来已有超过1,570次引用。其中得出的一个结论是，浅层（经典）神经网络“校准良好”。

然而，关于浅层神经网络校准的结论后来被颠覆了。在一篇2020年的研究中，题为《传统神经网络是否校准良好？》([https://ieeexplore.ieee.org/document/8851962](https://ieeexplore.ieee.org/document/8851962))，作者们驳斥了浅层神经网络校准良好的广泛观点。他们的发现显示，传统的浅层网络校准不良，其集成也表现出同样的问题。幸运的是，研究人员还强调，使用我们在前几章中了解到的Venn-ABERS一致性预测方法可以显著提高这些网络的校准。

## 现代深度学习计算机视觉模型的过度自信

为计算机视觉设计的许多深度学习模型主要利用基于卷积的架构。这些架构推动了该领域的发展，实现了前所未有的预测准确性。然而，存在一个意想不到的副作用：*这些模型经常产生* *过度自信的预测*：

+   **准确性 versus 质量**：深度学习对准确性的不懈追求导致了能够以非凡的精确度正确分类图像的模型。然而，准确性只是模型性能的一个方面。预测质量，包括预测的可靠性和校准等方面，同样至关重要。

+   **过度自信问题**：尽管这些模型实现了更高的准确率，但它们在预测中往往过于自信。这意味着当它们犯错时，会以很高的信心做出预测，表明它们坚信错误的预测。

+   **在关键应用中的影响**：这种过度自信带来了相当大的风险，尤其是在风险较高的领域。以医疗保健为例：一个分析医学扫描的计算机视觉系统如果做出误诊，并且有很高的信心，可能会导致医疗专业人员采取错误的治疗措施。同样，在自动驾驶汽车中，对道路场景过度自信的误解可能导致危险的操作。

从本质上讲，随着深度学习社区推动准确性的边界，也必须解决这些模型的校准问题。确保它们不仅做出准确的预测，而且适当地衡量这些预测的信心是至关重要的，尤其是在这些模型被用于生命攸关的应用时。

# 计算机视觉问题中量化不确定性的各种方法

在计算机视觉中量化不确定性对于确保基于视觉的系统可靠性和安全性至关重要，尤其是在部署在关键应用中时。多年来，已经开发出各种方法来处理和量化这种不确定性。以下是一些最显著的方法：

+   **贝叶斯神经网络**（**BNNs**）：这些神经网络将权重视为概率分布而不是固定值。通过这样做，它们可以为它们的预测提供不确定性度量。在推理期间，通过不同的权重样本进行多次正向传递，产生一个捕获模型不确定性的输出分布。

+   **蒙特卡洛dropout**：蒙特卡洛dropout涉及在推理期间执行dropout。通过多次运行具有dropout的网络并平均结果，可以得到一个输出分布，可以用来衡量不确定性。

+   **集成方法**：集成方法涉及训练多个模型并汇总它们的预测。模型之间预测的方差可以用作不确定性的代理。这种方法在计算上很昂贵，但通常会导致更稳健的不确定性估计。

+   **深度高斯过程**：深度高斯过程将深度学习与高斯过程相结合，提供了一种非参数估计不确定性的方法。它们提供了一种丰富的方式来捕捉复杂的不确定性，但对于大数据集来说可能在计算上具有挑战性。

+   **一致性预测**：一致性预测为预测提供了一组可能的输出，每个输出都有一个置信水平。这种基于集合的预测方法旨在保证覆盖范围，这意味着实际结果将以等于置信水平的概率落在预测集合中。

+   **校准技术**：虽然不是直接测量不确定性，但校准技术，如 Platt 缩放或温度缩放，确保预测的置信度得分反映了正确性的真实可能性。一个校准良好的模型的预测概率更具可解释性，可以用作不确定性的度量。

# 一致性预测在不确定性量化中的优越性

量化不确定性是构建稳健和可靠的机器学习模型的基础。多年来，已经出现了几种方法，每种方法都有其优点。然而，一致性预测脱颖而出，成为一个特别有吸引力的框架。让我们来解释一下原因：

+   **无分布框架**：一致性预测最显著的特点之一是它不对数据的分布做出任何假设。许多不确定性量化方法基于某些概率假设或依赖于特定的数据分布才能有效运作。相比之下，一致性预测对这些考虑因素保持无偏见，使其具有通用性和广泛适用于各种数据集。

+   **理论保证**：一致性预测为它的预测提供了稳健的理论保证。具体来说，它为预测提供了一组潜在的结果，并且每个结果都与一个置信水平相关联。该框架确保实际结果将以与置信水平相对应的概率落在预测集合内。这是一种强大的保证，尤其是在理解预测界限至关重要的关键应用中。

+   **模型独立性**：一致性预测的另一个显著优势是其与底层模型的独立性。无论您是在使用简单的线性回归、复杂的深度学习架构还是任何其他模型，一致性预测都可以无缝应用。这种灵活性确保了实践者在寻求量化不确定性时对模型的选择是开放的。

+   **与数据集大小可扩展性**：一致性预测对数据集的大小不敏感。无论是处理具有有限条目的小型数据集还是处理包含数百万数据点的庞大数据集，该框架都保持有效和可靠。这种可扩展性在数据可以从稀缺到极其丰富现代应用中特别有益。

虽然存在许多不确定性量化方法，但由于其无分布的特性、稳健的理论基础、模型独立性和可扩展性，一致性预测成为了一种领先的方法。对于寻求一种稳健且可靠的方法来评估其机器学习模型的不确定性的人来说，一致性预测提供了一个有吸引力的选择。

# 一致性预测在计算机视觉中的应用

在本节中，我们将深入探讨一致性预测在计算机视觉中的多样化应用。由于计算机视觉涵盖了从图像分类到目标检测的广泛问题，它提出了需要精确和可靠机器学习模型的挑战。在我们导航这些应用的过程中，我们将展示一致性预测是如何作为一种稳健的工具来量化与这些模型相关的不确定性的。

通过探索这些实际例子，我们旨在强调理解模型对其预测的置信度的重要性。理解至关重要，尤其是在基于这些预测的决策可能产生重大后果的情况下。具有提供不确定性度量能力的一致预测可以极大地帮助研究人员和实践者根据其模型输出做出明智的决策。这提高了系统的可靠性，并为计算机视觉中更透明和值得信赖的AI实现铺平了道路。

## 使用一致预测的图像分类器的不确定性集

在2020年，加州大学伯克利分校的研究人员发表了一篇题为《使用一致预测的图像分类器的不确定性集》(*Uncertainty sets for image classifiers using Conformal* *Prediction*)的论文([https://arxiv.org/abs/2009.14193](https://arxiv.org/abs/2009.14193))。

这是计算机视觉研究人员首次将一致预测应用于计算机视觉问题。论文描述了第一个专门为计算机视觉开发的一致预测方法RAPS，它是当前图像分类的最新水平。

下面是论文中的关键点：

+   论文提出了一种名为**正则化自适应预测集**(**RAPS**)的新方法，用于生成具有神经网络分类器保证达到所需覆盖水平的稳定预测集。

+   RAPS通过正则化对不可能类别的噪声概率估计的影响，修改了现有的一致预测算法，以产生更小、更稳定的预测集。

+   RAPS在ImageNet分类中使用ResNet和其他CNN模型进行评估。它在产生预测集的同时，实现了所需的覆盖水平，并且这些预测集的规模显著减小（比独立 Platt 缩放基线小5到10倍）。

+   该方法在覆盖范围上满足理论保证，并被证明在选择固定大小集合时提供最佳性能。

+   RAPS提供了一种从任何能够可靠量化不确定性和识别复杂测试示例的图像分类器中获取预测集的实用方法。作者建议在医学成像和主动学习等领域应用。

这里是RAPS算法工作原理的总结：

1.  它使用预训练的图像分类器来计算校准集中图像的类别概率估计以及新测试图像的类别概率估计。

1.  对于校准集中的每张图像，RAPS计算一致性分数，记为E j，如下所示：E j = ∑ i=1 k ′    ( ˆ π  (i)(x j) + λ1[i > k reg]). 这是通过将概率估计按降序排列来实现的。然后通过累积这些概率估计来计算分数，从最高开始，一直持续到（包括）图像实际类别的概率估计。计算过程如图9**.1**所示。

1.  高λ值起到阻止创建大于k reg的集合的威慑作用。

1.  在归纳一致预测中，模型随后计算在校准集上计算的一致性分数的1-α分位数。

1.  输出k*最高分数的类别，其中测试点的符合性分数E test大于或等于1-α分位数。

下图说明了RAPS方法。该图来自Anastasios N. Angelopoulos的博客 *使用一致预测的图像分类的不确定性集合* (*Uncertainty Sets for Image Classifiers using Conformal* *Prediction*)：([https://people.eecs.berkeley.edu/~angelopoulos/blog/posts/conformal-classification/](https://people.eecs.berkeley.edu/~angelopoulos/blog/posts/conformal-classification/))。

![图9.1 – RAPS方法的示意图（红线是为了达到精确覆盖率）](img/B19925_09_01.jpg)

图9.1 – RAPS方法的示意图（红线是为了达到精确覆盖率）

参数λ和k reg由RAPS模型在校准集上估计。参数背后的直觉是，高λ值会阻止大于k reg的集合。

通过构造，这个预测集以至少1-α的概率包含真实类别，其中α是期望的错误水平。正则化惩罚允许RAPS产生比以前的方法（如Platt缩放或未正则化的自适应方法）更小、更稳定的集合。

这种方法允许研究人员使用任何底层分类器，并产生确保满足指定错误率（如90%）的预测集，同时保持最小的平均大小。其部署的简便性使其成为衡量图像分类器不确定性的有吸引力的自动化方法，这在医疗诊断、自动驾驶和筛选危险在线内容等领域至关重要。

总结来说，RAPS利用一致预测的思想来保证覆盖率，修改一致分数以实现更小的集合，并使用保留数据正确校准程序。

# 使用一致预测构建计算机视觉分类器

让我们通过实际应用来说明一致预测在计算机视觉中的应用。我们将使用来自书籍存储库的笔记本，该存储库可在`https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_09.ipynb`找到。这个笔记本广泛使用了Anastasios Angelopolous的 *Conformal Prediction* 仓库中的笔记本，[https://github.com/aangelopoulos/conformal-prediction](https://github.com/aangelopoulos/conformal-prediction)。

加载数据后，设置问题和定义所需的覆盖率和校准集中的点数：

[PRE0]

[PRE1]

将softmax分数分为校准集和测试数据集，获得校准和测试标签：

[PRE2]

[PRE3]

[PRE4]

[PRE5]

[PRE6]

测试数据集包含49,000个点，校准数据集包含1,000个点。这两个数据集都包括来自ImageNet数据集的图像和可读标签。

## 朴素符合预测

我们首先将探讨使用符合预测的朴素方法来生成预测集：

+   为每个校准点计算一个非一致性分数

+   然后，将评估校准分数的经验分位数。

这与我们之前章节中观察到的归纳符合预测非常相似。我们通过 hinge 损失确定非一致性分数，然后使用这些分数的分布来根据所需的覆盖范围计算分位数。这个过程，包括最终的样本校正公式，与我们的归纳符合预测方法类似：

[PRE7]

[PRE8]

[PRE9]

我们可以使用计算得到的非一致性分数的调整分位数来为测试集对象形成预测集：

[PRE10]

结果是一个显示预测集合的数组。这个布尔数组根据它持有的布尔值表示ImageNet类别。布尔值表示模型选择的类别，其中`True`表示选择了该类别，而`False`表示该类别不包括在预测集中。

![图9.2 – 测试集预测集的示意图](img/B19925_09_02.jpg)

图9.2 – 测试集预测集的示意图

我们可以计算经验覆盖度，它非常接近指定的90%置信水平：

[PRE11]

[PRE12]

我们可以查看一些对象和预测集。

![图9.3 – 测试集中的对象，由符合预测的朴素变体产生的预测集标签为“宫殿”](img/B19925_09_03.jpg)

图9.3 – 测试集中的对象，由符合预测的朴素变体产生的预测集标签为“宫殿”

对于不确定性较高的对象，预测集中包含多个元素。

![图9.4 – 测试集中的对象，由符合预测的朴素变体产生的预测集为[‘慢炖锅’，‘数字时钟’]](img/B19925_09_04.jpg)

图9.4 – 测试集中的对象，由符合预测的朴素变体产生的预测集为[‘慢炖锅’，‘数字时钟’]

朴素方法存在两个显著问题：

+   首先，CNN生成的概率通常需要更准确，导致无法达到预期覆盖率的集合

+   其次，对于模型缺乏信心的实例，朴素方法必须包含多个类别以达到所需的置信度阈值，从而导致集合过大

温度缩放并不是解决办法，因为它只调整主要类的分数，而校准剩余分数是一项艰巨的任务。有趣的是，即使所有分数都完美校准，朴素方法仍然无法达到覆盖范围。

开发了构建预测集的替代方法来解决这些问题，即**自适应预测集**（**APS**）和**正则化自适应预测集**（**RAPS**）。

## 自适应预测集（APS）

接下来，我们将查看 NeurIPS 焦点论文中描述的 APS，即 *具有有效和自适应覆盖的分类*（2000）(https://proceedings.neurips.cc/paper/2020/file/244edd7e85dc81602b7615cd705545f5-Paper.pdf)。

从本质上讲，APS 提出了一种简单的方法。它不是直接使用软化分数，而是根据校准数据集确定一个新的阈值。例如，如果具有 93% 预测概率的集合在校准集上产生 90% 的覆盖率，则采用 93% 的阈值。APS 是 RAPS 的特定实现，与朴素方法不同，它旨在实现精确的覆盖率。

然而，APS 面临一个实际障碍：其集合的平均大小显著较大。深度学习分类器在与排列困境作斗争：对于不太确定的类别，如排名第 10 到 1,000 的类别，它们的分数并不反映准确的概率估计。这些类别的排列很大程度上受到噪声的影响，促使 APS 选择庞大的集合，特别是对于复杂图像。

描述 APS 的代码如下：

[PRE13]

[PRE14]

[PRE15]

[PRE16]

[PRE17]

[PRE18]

[PRE19]

[PRE20]

[PRE21]

[PRE22]

[PRE23]

[PRE24]

[PRE25]

让我们更详细地查看代码。它使用 APS 根据指定的分位数阈值生成预测集：

1.  `cal_pi = cal_smx.argsort(1)[:, ::-1]`: 这对每个实例的 `cal_smx` 软化分数进行降序排序，并返回排序值的索引。

1.  `cal_srt = np.take_along_axis(cal_smx, cal_pi, axis=1).cumsum(axis=1)`: 对于每一行，它根据 `cal_pi` 的索引重新排列分数，然后计算沿列的累积和。

1.  `cal_scores = np.take_along_axis(cal_srt, cal_pi.argsort(axis=1), axis=1)[range(n_cal), cal_labels]`: 此步骤检索与真实标签 `(cal_labels)` 对应的特定分数。它首先将 `cal_pi` 的排序顺序反转以获取原始顺序，然后为每个实例选择与真实标签相关的分数。

+   `qhat = np.quantile(cal_scores, np.ceil((n_cal + 1) * (1 - alpha)) / n_cal, method="higher")`: 基于提供的 `alpha` 计算分位数值。此值将作为预测阶段的阈值。*   `test_pi = test_smx.argsort(1)[:, ::-1]`: 类似地，对于测试集，它按降序对 `test_smx` 中的分数进行排序，并返回排序值的索引。*   `test_srt= np.take_along_axis(test_smx, test_pi, axis=1).cumsum(axis=1)`: 根据排序索引 `test_pi` 重新排列测试集分数，并计算累积和。*   `prediction_sets= np.take_along_axis(test_srt <= qhat, test_pi.argsort(axis=1), axis=1)`: 对于测试集中的每个实例，它确定哪些分数低于分位数阈值 `qhat`。然后，布尔数组 (`test_srt <= qhat`) 使用 `test_pi.argsort(axis=1)` 重新排列到其原始顺序，从而得到最终预测集，其中 `True` 条目表示包含在集合中。

本质上，此代码用于校准模型得分以定义一个阈值，然后使用此阈值为新（测试）数据集生成预测集。

我们可以查看一些由APS生成的对象和预测集。

![图9.5 – 测试集中的对象](img/B19925_09_05.jpg)

图9.5 – 测试集中的对象

不幸的是，正如前面提到的并在本例中演示的那样，APS生成的预测集可能非常庞大。前一个例子生成了一个预测集：

['King Charles Spaniel', 'Rhodesian Ridgeback', 'Afghan Hound', 'Basset Hound', 'Bloodhound', 'Redbone Coonhound', 'Otterhound', 'Weimaraner', 'Irish Terrier', 'Norfolk Terrier', 'Norwich Terrier', 'Australian Terrier', 'Dandie Dinmont Terrier', 'Tibetan Terrier', 'Soft-coated Wheaten Terrier', 'Flat-Coated Retriever', 'Golden Retriever', 'Labrador Retriever', 'Vizsla', 'English Setter', 'Irish Setter', 'Gordon Setter', 'Clumber Spaniel', 'English Springer Spaniel', 'Welsh Springer Spaniel', 'Cocker Spaniels', 'Sussex Spaniel', 'Irish Water Spaniel', 'Briard', 'Bullmastiff', 'Leonberger', 'Newfoundland', 'Chow Chow', 'Miniature Poodle', 'Standard Poodle', 'lion', 'brown bear', 'grasshopper', 'leafhopper', 'doormat', 'handkerchief', 'maze', 'prayer rug', 'tennis ball', 'acorn'].

## 正则化自适应预测集（RAPS）

现在我们来实际操作RAPS，它在本章前面的*使用一致性预测的图像分类器的置信集*部分中简要介绍过。

我们在以下代码块中设置了RAPS正则化参数（更大的`lam_reg`值和更小的`k_reg`值会导致集合更小）和正则化向量：

[PRE26]

[PRE27]

[PRE28]

[PRE29]

[PRE30]

如前所述，我们计算非一致性得分并获取得分分位数：

[PRE31]

[PRE32]

[PRE33]

[PRE34]

[PRE35]

[PRE36]

我们可以使用以下代码在测试集上部署预测：

[PRE37]

[PRE38]

[PRE39]

[PRE40]

[PRE41]

[PRE42]

[PRE43]

[PRE44]

让我们查看一些由RAPS生成的对象和预测集。

![图9.6 – 测试集中的对象；RAPS生成的预测集为[‘electric ray’]](img/B19925_09_06.jpg)

图9.6 – 测试集中的对象；RAPS生成的预测集为[‘electric ray’]

我们可以看到，对于不确定性较小的对象，RAPS生成单元素预测集。与APS不同，RAPS对于涉及更多不确定性的对象仍然生成相当节俭的预测集。

![图9.7 – 测试集中的对象；RAPS生成的预测集为[‘red wolf’，‘coyote’，‘dhole’，‘gray fox’]](img/B19925_09_07.jpg)

图9.7 – 测试集中的对象；RAPS生成的预测集为[‘red wolf’，‘coyote’，‘dhole’，‘gray fox’]

让我们总结本章内容。

# 摘要

在技术快速发展的领域，计算机视觉已经从单纯的图像识别转变为无数现实应用的重要组成部分。随着这些应用跨越多个领域，如自动驾驶汽车和医疗诊断，对计算机视觉模型提供准确和可靠预测的压力不断加大。随着这些模型日益复杂，一个迫切的需求随之而来：量化预测不确定性。

这就是一致性预测发光的地方。与通常只输出单一预测的传统模型不同，一致性预测提供了一系列可能的预测结果，每个结果都附带一个置信度度量。这种新颖的方法使用户能够获得对模型预测的详细视角，这对于精度至关重要的应用来说是无价的。

本章深入探讨了一致性预测与计算机视觉之间的共生关系。我们首先强调了不确定性量化在计算机视觉中的重要性，并引用了其在自动驾驶交通和医学成像等领域的关键作用。进一步地，我们揭示了当代深度学习模型的一个主要改进领域：它们倾向于提供失准的预测。

通过学习本章，您已经获得了制作融合一致性预测能力的尖端计算机视觉分类器的专业知识。此外，您还获得了使用针对计算机视觉定制的顶级开源一致性预测工具的经验，确保您为未来的努力做好了充分准备。

本章的关键成就包括掌握不确定性量化在计算机视觉中的作用，揭示深度学习预测失准的原因，探索测量计算机视觉任务中不确定性的多种策略，理解计算机视觉中一致性预测的基本原理和应用，以及掌握构建由一致性预测驱动的计算机视觉分类器。

在下一章中，我们将探索自然语言处理中的一致性预测世界，了解其重要性，并学习如何利用其力量进行更可靠和自信的预测。
