- en: Object Detection in Images using Deep Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度神经网络在图像中进行对象检测
- en: We used basic neural networks in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*, Beating
    CAPTCHAs with Neural Networks* with Neural Networks. Research in neural networks
    is creating some of the most advanced and accurate classification algorithms in
    many areas. The differences between the concepts introduced in this chapter, versus
    those introduced in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*, Beating CAPTCHAs with
    Neural Networks* is around *complexity*. In this chapter, we look at deep neural
    networks, those with many hidden layers, and also at more complex layer types
    for dealing with specific types of information, such as images.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第 8 章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络战胜 CAPTCHA*中使用了基本的神经网络，利用神经网络进行研究正在创造许多领域中最先进和最精确的分类算法。本章中介绍的概念与[第
    8 章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络战胜 CAPTCHA*中介绍的概念之间的区别主要在于*复杂性*。在本章中，我们将探讨深度神经网络，即具有许多隐藏层的神经网络，以及用于处理特定类型信息（如图像）的更复杂的层类型。
- en: These advances have come on the back of improvements in computational power,
    allowing us to train larger and more complex networks. However, the advances are
    much more than simply throwing more computational power at the problem. New algorithms
    and layer types have drastically improved performance, outside computational power.
    The cost is that these new classifiers need more data to learn from than other
    data mining classifiers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些进步是在计算能力提高的基础上取得的，使我们能够训练更大、更复杂的网络。然而，这些进步远不止于简单地投入更多的计算能力。新的算法和层类型极大地提高了性能，而不仅仅是计算能力。代价是这些新的分类器需要比其他数据挖掘分类器更多的数据来学习。
- en: In this chapter, we will look at determining what object is represented in an
    image. The pixel values will be used as input, and the neural network will then
    automatically find useful combinations of pixels to form higher-level features.
    These will then be used for the actual classification.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨确定图像中代表什么对象。像素值将被用作输入，然后神经网络将自动找到有用的像素组合来形成高级特征。这些特征将被用于实际的分类。
- en: 'Overall, in this chapter, we will examine the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，在本章中，我们将探讨以下内容：
- en: Classifying objects in images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像中分类对象
- en: Different types of deep neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度神经网络的不同类型
- en: The TensorFlow and Keras libraries to build and train neural networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 和 Keras 库构建和训练神经网络
- en: Using a GPU to improve the speed of the algorithms
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GPU 提高算法的速度
- en: Using cloud-based services for added horse-power for data mining
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于云的服务为数据挖掘提供额外的计算能力
- en: Object classification
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象分类
- en: Computer vision is becoming an important part of future technology. For example,
    we will have access to self-driving cars in the very near future - car manufacturers
    are scheduled to be releasing self-driving models in 2017 and are already partially
    self-driving. In order to achieve this, the car's computer needs to be able to
    see around it; identify obstacles, other traffic, and weather conditions; and
    then use that to plan a safe journey.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉正成为未来技术的重要组成部分。例如，我们将在不久的将来能够使用自动驾驶汽车 - 汽车制造商计划在 2017 年发布自动驾驶车型，并且已经部分实现了自动驾驶。为了实现这一点，汽车的电脑需要能够看到周围的环境；识别障碍物、其他交通和天气状况；然后利用这些信息来规划安全的行程。
- en: While we can easily detect whether there is an obstacle, for example using radar,
    it is also important we know what that object is. If it is an animal on the road,
    we can stop and let it move out of the way; if it is a building, this strategy
    won't work very well!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以轻松地检测是否有障碍物，例如使用雷达，但了解那个对象是什么也同样重要。如果它是在路上的动物，我们可以停车让它让开；如果它是一座建筑，这种策略可能不会很有效！
- en: Use cases
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例
- en: Computer vision is used in many scenarios. Following are some examples where
    they applications is very important.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉在许多场景中都有应用。以下是一些它们应用非常重要的例子。
- en: Online map websites, such as Google Maps, use computer vision for a number of
    reasons. One reason is to automatically blur any faces that they find, in order
    to give some privacy to the people being photographed as part of their Street
    View feature.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线地图网站，如 Google Maps，出于多个原因使用计算机视觉。其中一个原因是自动模糊他们发现的任何面孔，以保护作为其街景功能一部分的人的隐私。
- en: Face detection is also used in many industries. Modern cameras automatically
    detect faces, as a means to improve the quality of photos taken (the user most
    often wants to focus on a visible face). Face detection can also be used for identification.
    For example, Facebook automatically recognises people in photos, allowing for
    easy tagging of friends.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测也被广泛应用于许多行业。现代相机自动检测人脸，作为提高拍摄照片质量的一种手段（用户最常希望聚焦于可见的人脸）。人脸检测还可以用于身份识别。例如，Facebook
    自动识别照片中的人，以便轻松标记朋友。
- en: As we stated before, autonomous vehicles are highly dependent on computer vision
    to recognise their path and avoid obstacles. Computer vision is one of the key
    problems that is being addressed not only in research into autonomous vehicles,
    not just for consumer use, but also in mining and other industries.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们之前所述，自动驾驶汽车高度依赖于计算机视觉来识别它们的路径和避开障碍。计算机视觉是正在解决的关键问题之一，这不仅包括自动驾驶汽车的研究，不仅限于消费使用，还包括采矿和其他行业。
- en: Other industries are using computer vision too, including warehouses examining
    goods automatically for defects.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他行业也在使用计算机视觉，包括仓库自动检查货物是否存在缺陷。
- en: The space industry is also using computer vision, helping to automate the collection
    of data. This is critical for effective use of spacecraft, as sending a signal
    from Earth to a rover on Mars can take a long time and is not possible at certain
    times (for instance, when the two planets are not facing each other). As we start
    dealing with space-based vehicles more frequently, and from a greater distance,
    increasing the autonomy of these spacecraft is absolutely necessary and computer
    vision is a key part of this.The following picture shows the Mars rover designed
    and used by NASA; it made significant use of computer vision to identify its surroundings
    on a strange, inhospitable planet.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 航天工业也在使用计算机视觉，帮助自动化数据的收集。这对于有效使用航天器至关重要，因为从地球向火星上的漫游车发送信号可能需要很长时间，而且在某些时候（例如，当两颗行星不面对彼此时）是不可能的。随着我们越来越频繁地处理基于空间的车辆，并且距离越来越远，提高这些航天器的自主性绝对是必要的，而计算机视觉是这个过程中的关键部分。以下图片显示了美国宇航局设计和使用的火星漫游车；它在识别一个陌生、不适宜居住的星球周围环境时，显著使用了计算机视觉。
- en: '![](img/B06162_11_03.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B06162_11_03](img/B06162_11_03.jpg)'
- en: Application scenario
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用场景
- en: 'In this chapter, we will build a system that will take an image as an input
    and give a prediction on what the object in it is. We will take on the role of
    a vision system for a car, looking around at any obstacles in the way or on the
    side of the road. Images are of the following form:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建一个系统，该系统将接受图像作为输入，并预测图像中的物体是什么。我们将扮演汽车视觉系统的角色，观察道路上的任何障碍物。图像的形式如下：
- en: '![](img/B06162_11_01.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B06162_11_01](img/B06162_11_01.png)'
- en: This dataset comes from a popular dataset called CIFAR-10\. It contains 60,000
    images that are 32 pixels wide and 32 pixels high, with each pixel having a red-green-blue
    (RGB) value. The dataset is already split into training and testing, although
    we will not use the testing dataset until after we complete our training.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集来自一个流行的数据集，称为 CIFAR-10。它包含 60,000 张宽度为 32 像素、高度为 32 像素的图像，每个像素都有一个红绿蓝（RGB）值。数据集已经分为训练集和测试集，尽管我们将在完成训练后才会使用测试集。
- en: The CIFAR-10 dataset is available for download at [http://www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10 数据集可在 [http://www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)
    下载
- en: Download the python version, which has already been converted to NumPy arrays.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下载已转换为 NumPy 数组的 Python 版本。
- en: Opening a new Jupyter Notebook, we can see what the data looks like. First,
    we set up the data filenames. We will only worry about the first batch to start
    with, and scale up to the full dataset size towards the end;
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook，我们可以看到数据的样子。首先，我们设置数据文件名。我们将从第一批数据开始，并在最后扩展到整个数据集的大小；
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we create a function that can read the data stored in the batches. The
    batches have been saved using pickle, which is a python library to save objects.
    Usually, we can just call `pickle.load(file)` on the file to get the object. However,
    there is a small issue with this data: it was saved in Python 2, but we need to
    open it in Python 3\. In order to address this, we set the encoding to `latin`
    (even though we are opening it in byte mode):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个函数，可以读取存储在批次中的数据。这些批次已使用pickle保存，pickle是一个用于保存对象的Python库。通常，我们只需在文件上调用`pickle.load(file)`即可获取对象。然而，此数据存在一个小问题：它是在Python
    2中保存的，但我们需要在Python 3中打开它。为了解决这个问题，我们将编码设置为`latin`（即使我们是以字节模式打开的）：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Using this function, we can now load the batch dataset:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此函数，我们现在可以加载批处理数据集：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This batch is a dictionary containing the actual data in NumPy arrays, the corresponding
    labels and filenames, and a note to say which batch it is (this is training batch
    1 of 5, for instance).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个批次是一个包含实际数据的NumPy数组、相应的标签和文件名以及一个说明它是哪个批次的注释（例如，这是5个训练批次中的第1个）。
- en: 'We can extract an image by using its index in the batch''s data key:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用批次的键数据中的索引来提取图像：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The image array is a NumPy array with 3,072 entries, from 0 to 255\. Each value
    is the red, green, or blue intensity at a specific location in the image.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数组是一个包含3,072个条目的NumPy数组，范围从0到255。每个值是图像中特定位置的红色、绿色或蓝色强度。
- en: 'The images are in a different format than what matplotlib usually uses (to
    display images), so to show the image we first need to reshape the array and rotate
    the matrix. This doesn''t matter so much to train our neural network (we will
    define our network in a way that fits with the data), but we do need to convert
    it for matplotlib''s sake:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像的格式与matplotlib通常使用的格式不同（用于显示图像），因此为了显示图像，我们首先需要重塑数组并旋转矩阵。这对训练我们的神经网络（我们将以适合数据的方式定义我们的网络）来说并不重要，但我们确实需要将其转换为matplotlib的原因：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now we can show the image using matplotlib:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用matplotlib显示图像：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The resulting image, a boat, is displayed:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图像，一艘船，被显示出来：
- en: '![](img/B06162_11_02.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_11_02.png)'
- en: The resolution of this image is quite poor—it is only 32 pixels wide and 32
    pixels high. Despite that, most people will look at the image and see a boat.
    Can we get a computer to do the same?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像的分辨率相当低——它只有32像素宽和32像素高。尽管如此，大多数人看到这张图像都会看到一艘船。我们能否让计算机做到同样的事情？
- en: You can change the image index to show different images, getting a feel for
    the dataset's properties.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以更改图像索引以显示不同的图像，从而了解数据集的特性。
- en: 'The aim of our project, in this chapter, is to build a classification system
    that can take an image like this and predict what the object in it is. Before
    we do that though, we will take a detour to learn about the classifier we are
    going to use: **Deep neural networks**.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们的项目目标是构建一个分类系统，可以识别像这样的图像并预测其中的物体是什么。但在我们这样做之前，我们将绕道学习我们将要使用的分类器：**深度神经网络**。
- en: Deep neural networks
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: 'The neural networks we used in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*, Beating
    CAPTCHAs with Neural Networks*, have some fantastic *theoretical* properties.
    For example, only a single hidden layer is needed to learn any mapping (although
    the size of the middle layer may need to be very, very big). Neural networks were
    a very active area of research in the 1970s and 1980s due to this theoretical
    perfection. However several issues caused them to fall out of favor, particularly
    compared to other classification algorithms such as support vector machines. A
    few of the major ones are listed here:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络战胜CAPTCHAs*中使用的神经网络具有一些出色的**理论**特性。例如，学习任何映射只需要一个隐藏层（尽管中间层的大小可能需要非常大）。由于这种理论上的完美，神经网络在20世纪70年代和80年代是一个非常活跃的研究领域。然而，一些问题导致它们失去了人们的青睐，尤其是与其他分类算法（如支持向量机）相比。以下是一些主要问题：
- en: One of the main issues was that the computational power needed to run many neural
    networks was more than other algorithms and more than what many people had access
    to.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要问题之一是运行许多神经网络所需的计算能力超过了其他算法，也超过了许多人能够访问的能力。
- en: Another issue was training the networks. While the back propagation algorithm
    has been known about for some time, it has issues with larger networks, requiring
    a very large amount of training before the weights settle.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个问题是在网络上进行训练。虽然反向传播算法已经为人所知一段时间了，但它在大规模网络上存在问题，需要大量的训练才能使权重稳定。
- en: Each of these issues has been addressed in recent times, leading to a resurgence
    in popularity of neural networks. Computational power is now much more easily
    available than 30 years ago, and advances in algorithms for training mean that
    we can now readily use that power.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 近些年来，这些问题都得到了解决，导致神经网络再次受到欢迎。计算能力现在比30年前更容易获得，算法训练的进步意味着我们现在可以轻松地使用这种能力。
- en: Intuition
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 直觉
- en: The aspect that differentiates **deep neural networks** from the more basic
    neural network we saw in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*, Beating CAPTCHAs
    with Neural Networks*, is size.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 区分**深度神经网络**和我们在[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络战胜CAPTCHA*中看到的基本神经网络的方面是规模。
- en: A neural network is considered deep when it has two or more hidden layers. In
    practice, a deep neural network is often much larger, both in the number of nodes
    in each layer and also the number of layers. While some of the research of the
    mid -2000s focused on very large numbers of layers, smarter algorithms are reducing
    the actual number of layers needed.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当神经网络有两个或更多隐藏层时，它被认为是深度神经网络。在实践中，深度神经网络通常要大得多，包括每一层的节点数量和层数的数量。虽然2005年中期的某些研究关注了非常大的层数，但更智能的算法正在减少实际所需的层数。
- en: 'The size is one differentiator, but new layer types and neural network structures
    are assisting in creating deep neural networks for specific areas. We have already
    seen a feed-forward neural network composed of **dense layers**. This means we
    have a series of layers, in order, where each neuron from one layer is attached
    to each neuron from another layer. Other types include:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 尺寸是一个区分因素，但新的层类型和神经网络结构正在帮助为特定领域创建深度神经网络。我们已经看到了由**密集层**组成的正向神经网络。这意味着我们有一系列按顺序排列的层，其中每一层的每个神经元都连接到另一层的每个神经元。其他类型包括：
- en: '**Convolutional Neural Networks** (**CNN**) for image analysis. In this case,
    a small segment of the image is taken as a single input, and that input is passed
    onto a pooling layer to combine these outputs. This helps with issues such as
    rotation and translation of images. We will use these networks in this chapter.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNN**）用于图像分析。在这种情况下，图像的一个小部分被作为一个单独的输入，这个输入被传递到池化层以组合这些输出。这有助于处理图像的旋转和平移等问题。我们将在本章中使用这些网络。'
- en: '**Recurrent Neural Networks** (**RNN**) for text and time-series analysis.
    In this case, the previous state of the neural network is remembered and used
    to alter the current output. Think of the preceding word in a sentence modifying
    the output for the current word in the phrase: *United States*. One of the most
    popular types is an LSTM recurrent network, standing for **Long-Short Term Memory**.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环神经网络**（**RNN**）用于文本和时间序列分析。在这种情况下，神经网络的前一个状态被记住并用于改变当前的输出。想象一下句子中的前一个词如何修改短语中当前词的输出：*美国*。其中最受欢迎的类型是LSTM循环网络，代表**长短期记忆**。'
- en: '**Autoencoders**, which learn a mapping from the input, through a hidden layer
    (usually with fewer nodes), back to the input. This finds a compression of the
    input data, and this layer can be reused in other neural networks, reducing the
    amount of labelled training data needed.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自编码器**，它学习从输入通过一个隐藏层（通常节点较少）回到输入的映射。这找到了输入数据的压缩，并且这个层可以在其他神经网络中重用，从而减少所需的标记训练数据量。'
- en: There are many, many more types of neural networks. Research into applications
    and theory of deep neural networks is finding more and more forms of neural networks
    every month. Some are designed for general purpose learning, some for specific
    tasks. Further, there are multiple ways to combine layers, tweak parameters, and
    otherwise alter the learning strategy. For example, **dropout layers** randomly
    reduce some weights to zero during training, forcing all parts of the neural network
    to learn good weights.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络类型繁多。对深度神经网络的应用和理论研究每个月都在发现越来越多的神经网络形式。有些是为通用学习设计的，有些是为特定任务设计的。此外，还有多种方法可以组合层、调整参数以及改变学习策略。例如，**dropout层**在训练过程中随机将一些权重减少到零，迫使神经网络的所有部分都学习良好的权重。
- en: Despite all these differences, a neural network is usually designed to take
    very basic features as inputs—in the case of computer vision, it is simple pixel
    values. As that data is combined and pushed through the network, these basic features
    combine into more complex features. Sometimes, these features have little meaning
    to humans, but they represent the aspects of the sample that the computer looks
    for to make its classification.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在所有这些差异，神经网络通常被设计为接受非常基本的特征作为输入——在计算机视觉的情况下，是简单的像素值。随着这些数据被组合并通过网络传递，这些基本特征会组合成更复杂的特征。有时，这些特征对人类来说意义不大，但它们代表了计算机寻找以进行分类的样本的方面。
- en: Implementing deep neural networks
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现深度神经网络
- en: Implementing these deep neural networks can be quite challenging due to their
    size. A bad implementation will take significantly longer to run than a good one,
    and may not even run at all due to memory usage.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其规模，实现这些深度神经网络可能相当具有挑战性。一个糟糕的实现将比一个好的实现运行时间更长，并且可能由于内存使用而根本无法运行。
- en: A basic implementation of a neural network might start by creating a node class
    and collecting a set of these into a layer class. Each node is then connected
    to a node in the next layer using an instance of an *Edge* class. This type of
    implementation, a class-based one, is good to show how networks operate but too
    inefficient for larger networks. Neural networks simply have too many moving parts
    for this strategy to be efficient.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一个神经网络的基本实现可能从创建一个节点类并将这些节点集合到一个层类开始。然后，每个节点通过一个*边*类的实例连接到下一层的节点。这种基于类的实现对于展示网络如何运作是好的，但对于更大的网络来说效率太低。神经网络有太多的移动部件，这种策略效率太低。
- en: Instead, most neural networks operations can be expressed as mathematical expressions
    on matrices. The weights of the connections between one network layer and the
    next can be represented as a matrix of values, where the rows represent nodes
    in the first layer and the columns represent the nodes in the second layer (the
    transpose of this matrix is used sometimes too). The value is the weight of the
    edge between one layer and the next. A network can then be defined as a set of
    these weight matrices. In addition to the nodes, we add a bias term to each layer,
    which is basically a node that is always on and connected to each neuron in the
    next layer.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，大多数神经网络操作都可以表示为矩阵上的数学表达式。一个网络层与下一层之间连接的权重可以表示为一个值矩阵，其中行代表第一层的节点，列代表第二层的节点（有时也使用这个矩阵的转置）。这个值是层与层之间边的权重。然后，一个网络可以定义为这些权重矩阵的集合。除了节点外，我们还在每一层添加一个偏差项，这基本上是一个始终开启并连接到下一层每个神经元的节点。
- en: This insight allows us to use matrix operations to build, train, and use neural
    networks, as opposed to creating a class-based implementation. These mathematical
    operations are great, as many great libraries of highly optimised code have been
    written that we can use to perform these computations as efficiently as we can.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这个洞察力使我们能够使用矩阵运算来构建、训练和使用神经网络，而不是创建基于类的实现。这些数学运算很棒，因为已经编写了许多高度优化的代码库，我们可以使用它们以尽可能高的效率执行这些计算。
- en: The scikit-learn implementation that we used in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*,
    Beating CAPTCHAs with Neural Networks*, does contain some features for building
    neural networks but lacks several recent advances in the field. For larger and
    more customised networks, though, we need a library that gives us a bit more power.
    We will use the **Keras** library instead to create our deep neural network.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络战胜CAPTCHAs*中使用的scikit-learn实现确实包含了一些构建神经网络的特性，但缺乏该领域的一些最新进展。然而，对于更大和更定制的网络，我们需要一个能给我们更多权力的库。我们将使用**Keras**库来创建我们的深度神经网络。
- en: In this chapter, we will start by implementing a basic neural network with Keras
    and then (nearly) replicate our experiment in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*,
    Beating CAPTCHAs with Neural Networks*, on predicting which letter is in an image.
    Finally, we will use a much more complex convolution neural network to perform
    image classification on the CIFAR dataset, which will also include running this
    on GPUs rather than CPUs to improve the performance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先使用Keras实现一个基本的神经网络，然后（几乎）复制我们在[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络战胜CAPTCHAs*中进行的实验，预测图像中的哪个字母。最后，我们将使用一个更复杂的卷积神经网络在CIFAR数据集上进行图像分类，这还将包括在GPU上而不是CPU上运行以提高性能。
- en: Keras is a high-level interface to using a graph-computation library for implementing
    deep neural networks. Graph-computation libraries outline a series of operations
    and then later compute the values. These are great for matrix operations because
    they can be used to represent data flows, distribute those data flows across multiple
    systems and perform other optimisations. Keras can use either of two graph-computation
    libraries under the hood. The first is called **Theano**, which is a little older
    and has a strong following (and was used in the first edition of this book), and
    the second is **TensorFlow**, released recently by Google and is the library that
    powers much of their deep learning. Ultimately, you can use either library in
    this chapter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Keras是使用图计算库实现深度神经网络的顶层接口。图计算库概述了一系列操作，然后稍后计算这些值。这些对于矩阵操作非常出色，因为它们可以用来表示数据流，将这些数据流分配到多个系统，并执行其他优化。Keras可以在底层使用两种图计算库中的任何一种。第一种称为**Theano**，它稍微老一些，但拥有强大的追随者（并在本书的第一版中使用过），第二种是Google最近发布的**TensorFlow**，这是为他们的深度学习提供动力的库。最终，您可以在本章中使用这两个库中的任何一个。
- en: An Introduction to TensorFlow
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow简介
- en: TensorFlow is a graph computation library designed by engineers at Google, and
    is starting to power many of Google's recent advances in **deep learning** and
    **artificial intelligence**.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是由Google工程师设计的图计算库，并开始为Google在**深度学习**和**人工智能**方面的许多最新进展提供动力。
- en: 'A graph computation library has two steps. They are listed below:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图计算库有两个步骤。如下列出：
- en: Defining the sequence (or more complex graphs) of operations that take the input
    data, operate on it, and convert to outputs.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义操作序列（或更复杂的图）以处理输入数据，对其进行操作，并将其转换为输出。
- en: Compute on the graph obtained from step 1 with a given input.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用步骤1中获得的图和给定的输入进行计算。
- en: Many programmers don't use this type of programming day-to-day, but most of
    them interact with a related system that does. Relational databases, specifically
    SQL-based ones, use a similar concept called the declarative paradigm. While a
    programmer might define a `SELECT` query on a database with a `WHERE` clause,
    the database interprets that and creates an optimised query based on a number
    of factors, such as whether the `WHERE` clause is applied to a primary key, the
    format the data is stored in, and other factors. The programmer defines what they
    want and the system determines how to do it.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 许多程序员在日常工作中不使用这种类型的编程，但他们中的大多数人与使用这种相关系统的系统互动。关系数据库，特别是基于SQL的数据库，使用一个类似的概念，称为声明性范式。虽然程序员可能在数据库上定义一个带有`WHERE`子句的`SELECT`查询，但数据库会解释这一点，并根据多个因素创建一个优化的查询，例如`WHERE`子句是否应用于主键，数据存储的格式以及其他因素。程序员定义他们想要的内容，系统则确定如何实现。
- en: 'You can install TensorFlow using Anaconda: conda install tensorflow'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Anaconda安装TensorFlow：conda install tensorflow
- en: For more options, Google has a detailed installation page at [https://www.tensorflow.org/get_started/os_setup](https://www.tensorflow.org/get_started/os_setup)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更多选项，Google有一个详细的安装页面，见[https://www.tensorflow.org/get_started/os_setup](https://www.tensorflow.org/get_started/os_setup)
- en: 'Using TensorFlow, we can define many types of functions working on scalars,
    arrays, and matrices, as well as other mathematical expressions. For instance,
    we can create a graph that computes the values of a given quadratic equation:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFlow，我们可以定义许多在标量、数组和矩阵上工作的函数类型，以及其他数学表达式。例如，我们可以创建一个计算给定二次方程值的图：
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This *y* object is a Tensor object. It does not yet have a value as this hasn''t
    been computed. All we have done is create a graph that states:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这个*y*对象是一个张量对象。它还没有值，因为这还没有被计算。我们所做的一切只是创建了一个声明：
- en: '*When we do compute y, first take the square the value of x and multiply it
    by a, add b times x to it, and then add c to the result.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*当我们计算y时，首先取x的平方值并乘以a，然后加上b乘以x，最后再加上c。*'
- en: 'The graph itself can be viewed through TensorFlow. Here is some code to visualise
    this graph within a Jupyter Notebook, courtesy of  StackOverflow user Yaroslav
    Bulatov (see this answer: [http://stackoverflow.com/a/38192374/307363](http://stackoverflow.com/a/38192374/307363)):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图本身可以通过TensorFlow进行查看。以下是一些在Jupyter Notebook中可视化此图的代码，由StackOverflow用户Yaroslav
    Bulatov提供（见此答案：[http://stackoverflow.com/a/38192374/307363](http://stackoverflow.com/a/38192374/307363))）：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can then perform the actual visualisation using this code in a new cell:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下代码在新单元格中执行实际的可视化：
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The results show how these operations are linked in a directed graph. The visualisation
    platform is called **TensorBoard**, which comes with TensorFlow:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示了这些操作如何在有向图中链接。可视化平台称为**TensorBoard**，它是TensorFlow的一部分：
- en: '![](img/B06162_11_04.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_11_04.png)'
- en: When we want to compute a value for y, we need to pass a value for x through
    the other nodes in the graph, these are called OpNodes in the above graph, short
    for *Operation Node*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要计算y的值时，我们需要通过图中的其他节点传递x的值，这些节点在上图中被称为OpNodes，简称*操作节点*。
- en: 'To this point, we have defined the graph itself. The next step is to compute
    the values. We can do this a number of ways, especially considering x is a Variable.
    To compute y, using the current value of x, we create a TensorFlow Session object
    and then ask it to run y:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经定义了图本身。下一步是计算值。我们可以用多种方式来做这件事，特别是考虑到x是一个变量。要使用x的当前值来计算y，我们创建一个TensorFlow会话对象，然后请求它运行y：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The first line initialises the variables. TensorFlow lets you specify scopes
    of operations and namespaces. At this point, we are just using the global namespace,
    and this function is a handy shortcut to initialise that scope properly, which
    can be thought of as a step needed for TensorFlow to compile the graph.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行初始化变量。TensorFlow允许你指定操作的范围和命名空间。在这个点上，我们只是在全局命名空间中使用，这个函数是一个方便的快捷方式来正确初始化这个范围，这可以被视为TensorFlow编译图所需的步骤。
- en: The second creates a new session that will run the model itself. The result
    from `tf.global_variables_initializer()` is itself an operation on the graph,
    and must be executed to happen. The next line actually runs the variable y, which
    computes the necessary OpNodes needed to compute the value of y. In our case,
    that is all of the nodes but it is possible that larger graphs might not need
    all nodes computed - TensorFlow will do just enough work to get the answer and
    no more.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步创建一个新的会话，该会话将运行模型本身。`tf.global_variables_initializer()`的结果本身就是一个图上的操作，必须执行才能发生。下一行实际上运行变量y，它计算了计算y值所需的必要OpNodes。在我们的例子中，就是所有节点，但可能更大的图可能不需要计算所有节点——TensorFlow将只做足够的工作来得到答案，而不会更多。
- en: If you get an error that `global_variables_initializer` is not defined, replace
    it with `initialize_all_variables` - the interface was recently changed.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你得到一个错误，提示`global_variables_initializer`未定义，请将其替换为`initialize_all_variables`——该接口最近已更改。
- en: Printing the result gives us our value of 3.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 打印结果给出了我们的值为3。
- en: We can also do other operations, such as change the value of x. For instance,
    we can create an assign operation, which assigns a new value to an existing Variable.
    In this example, we change the value of x to 10 and then compute y, which results
    in 548.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以执行其他操作，例如更改x的值。例如，我们可以创建一个赋值操作，将新值赋给现有的变量。在这个例子中，我们将x的值更改为10，然后计算y，结果为548。
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: While this simple example may not seem much more powerful than what we can already
    do with Python, TensorFlow (and Theano) have large amounts of distribution options
    for computing larger networks over many computers and optimisations for doing
    it efficiently. Both libraries also contain extra tools for saving and loading
    networks, including values, which lets us save models created in these libraries.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个简单的例子可能看起来并不比我们用Python能做的更强大，但TensorFlow（和Theano）提供了大量的分布式计算选项，用于在多台计算机上计算更大的网络，并为此进行了优化。这两个库还包含额外的工具，用于保存和加载网络，包括值，这使得我们可以保存在这些库中创建的模型。
- en: Using Keras
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras
- en: TensorFlow is not a library to directly build neural networks. In a similar
    way, NumPy is not a library to perform data mining; it just does the heavy lifting
    and is generally used from another library. TensorFlow contains a built-in library,
    referred to as TensorFlow Learn to build networks and perform data mining. Other
    libraries, such as Keras, are also built with this in mind and use TensorFlow
    in the backend.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow不是一个直接构建神经网络的库。以类似的方式，NumPy不是一个执行数据挖掘的库；它只是做繁重的工作，通常用于其他库。TensorFlow包含一个内置库，称为TensorFlow
    Learn，用于构建网络和执行数据挖掘。其他库，如Keras，也是出于这个目的而构建的，并在后端使用TensorFlow。
- en: Keras implements a number of modern types of neural network layers and the building
    blocks for building them. In this chapter, we will use convolution layers which
    are designed to mimic the way in which human vision works. They use small collections
    of connected neurons that analyse only a segment of the input values - in this
    case, an image. This allows the network to deal with standard alterations such
    as dealing with translations of images. In the case of vision-based experiments,
    an example of an alteration dealt with by convolution layers is translating the
    image.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 实现了许多现代类型的神经网络层及其构建块。在本章中，我们将使用卷积层，这些层旨在模仿人类视觉的工作方式。它们使用连接的神经元小集合，只分析输入值的一部分——在这种情况下，是一个图像。这使得网络能够处理标准的改变，例如处理图像的平移。在基于视觉的实验中，卷积层处理的一个改变示例是图像的平移。
- en: In contrast, a traditional neural network is often heavily connected—all neurons
    from one layer connect to all neurons in the next layer. This is referred to as
    a dense layer.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，传统的神经网络通常是高度连接的——一个层的所有神经元都连接到下一层的所有神经元。这被称为密集层。
- en: The standard model for neural networks in Keras is a **Sequential** model, which
    is created by passing a list of layers. The input (X_train) is given to the first
    layer, and its output given to the next layer and so on, in a standard feed-forward
    configuration.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 中神经网络的标准模型是 **Sequential** 模型，它通过传递一个层列表创建。输入（X_train）被提供给第一层，其输出被提供给下一层，依此类推，形成一个标准的正向传播配置。
- en: Building a neural network in Keras is significantly easier than building it
    using just TensorFlow. Unless you are doing highly customised modifications to
    the neural network structure, I strongly recommend using Keras.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Keras 中构建神经网络比仅使用 TensorFlow 构建要容易得多。除非你对神经网络结构进行高度定制的修改，否则我强烈建议使用 Keras。
- en: To show the basics of using Keras for neural networks, we will implement a basic
    network to lean on the Iris dataset, which we saw in [Chapter 1](lrn-dtmn-py-2e_ch01.html)*,
    Getting Started with Data Mining*. The Iris dataset is great for testing new algorithms,
    even complex ones such as deep neural networks.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示使用 Keras 进行神经网络的基本方法，我们将实现一个基于 Iris 数据集的基本网络，我们在[第 1 章](lrn-dtmn-py-2e_ch01.html)*，数据挖掘入门*中见过这个数据集。Iris
    数据集非常适合测试新的算法，即使是像深度神经网络这样的复杂算法。
- en: First, open a new Jupyter Notebook. We will come back to the Notebook with the
    CIFAR data, later in the chapter.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开一个新的 Jupyter Notebook。我们将在本章后面回到包含 CIFAR 数据的 Notebook。
- en: 'Next, we load the dataset:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载数据集：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When dealing with libraries like TensorFlow, it is best to be quite explicit
    about data types. While Python will happily convert from one numerical data type
    to another implicitly, libraries like TensorFlow are wrappers around lower-level
    code (in this case, C++). These libraries are not able to always convert between
    numerical data types.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理像 TensorFlow 这样的库时，最好对数据类型非常明确。虽然 Python 会愉快地将一种数值数据类型隐式转换为另一种，但像 TensorFlow
    这样的库是底层代码（在这种情况下，是 C++）的包装器。这些库不能总是转换数值数据类型。
- en: 'Our output is currently a single array of categorical values (0, 1 or 2 depending
    on the class). Neural networks *can *be developed to output data in this format,
    but the *normal convention* is for the neural network to have *n* outputs, where
    *n* in the number of classes. Due to this, we use one-hot encoding to convert
    our categorical y into a one-hot encoded `y_onehot`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当前的输出是一个单维的分类值数组（0、1 或 2，取决于类别）。神经网络可以开发成以这种格式输出数据，但通常的约定是神经网络有 *n* 个输出，其中
    *n* 是类别的数量。因此，我们使用 one-hot 编码将我们的分类 y 转换为 one-hot 编码的 `y_onehot`：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We then split into training and testing datasets:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数据集分为训练集和测试集：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, we build our network by creating the different layers. Our dataset contains
    four input variables and three output classes. This gives us the size of the first
    and last layer, but not the layers in between. Playing around with this figure
    will give different results, and it is worth trailing different values to see
    what happens. We will create a small network to start with, with the following
    dimensions:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过创建不同的层来构建我们的网络。我们的数据集包含四个输入变量和三个输出类别。这给出了第一层和最后一层的大小，但不是中间层的大小。尝试不同的数值将给出不同的结果，尝试不同的值以查看会发生什么是有价值的。我们将从一个具有以下维度的小型网络开始：
- en: '[PRE14]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we create our hidden layer and our output layer (the input layer is implicit).
    For this example we will use Dense layers:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建我们的隐藏层和输出层（输入层是隐式的）。在这个例子中，我们将使用 Dense 层：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: I encourage you to play with the activation value, and see how that affects
    the results. The values here are great defaults if you have no further information
    about your problem. That is, use `relu` for hidden layers, and `sigmoid` for the
    output layer.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你尝试调整激活值，看看它如何影响结果。如果你对问题没有更多信息，这里的值是很好的默认值。也就是说，对于隐藏层使用`relu`，对于输出层使用`sigmoid`。
- en: 'We then combine the layers into a Sequential model:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将层组合成一个Sequential模型：
- en: '[PRE16]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: One necessary step from here is to compile the network, which creates the graph.
    In the compile step, we were given information on how the network will be trained
    and evaluated. The values here define what exactly it is that the neural network
    is trying to train to reduce, in the case below, it is the mean squared error
    between the output neurons and their expected values. The choice of optimizer
    largely affects how efficiently it can do this, often with a trade-off between
    speed and memory usage.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始的一个必要步骤是编译网络，这会创建图。在编译步骤中，我们得到了有关网络如何训练和评估的信息。这里的值定义了神经网络试图训练以减少的内容，在下面的例子中，它是输出神经元和它们的期望值之间的均方误差。优化器的选择在很大程度上影响了它执行此操作的效率，通常需要在速度和内存使用之间进行权衡。
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We then train our model using the `fit` function. Keras models return a history
    object from `fit()`, that allows us see the data at a fine-grained level.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后使用`fit`函数训练我们的模型。Keras模型从`fit()`返回一个历史对象，这允许我们以细粒度查看数据。
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: You will get quite a lot of output. The neural network will train 10 epochs,
    which are training cycles of taking the training data, running it through the
    neural network, updating the weights and evaluating the results. If you investigate
    the history object (try `print(history.history)`) you will see the loss function's
    score after each of these epochs (lower is better). Also included is the accuracy,
    where higher is better. You will probably also notice that it hasn't really improved
    that much.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你会得到相当多的输出。神经网络将训练10个epoch，这些是训练周期，包括取训练数据，通过神经网络运行它，更新权重并评估结果。如果你调查历史对象（尝试`print(history.history)`），你将看到每个epoch后的损失函数分数（越低越好）。还包括准确性，越高越好。你可能也会注意到它并没有真正改善多少。
- en: 'We can plot out the history object using `matplotlib`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`matplotlib`绘制历史对象：
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/B06162_11_05.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_11_05.png)'
- en: 'While the training loss is decreasing, it is not decreasing much. This is one
    issue with neural networks - they train slowly. By default, the fit function will
    only perform 10 epochs, which is nowhere near enough for nearly any application.
    To see this, use the neural network to predict the test set and run a classification
    report:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练损失在下降时，下降的幅度并不大。这是神经网络的一个问题——它们训练速度慢。默认情况下，拟合函数只会执行10个epoch，这对于几乎所有应用来说都远远不够。为了看到这一点，使用神经网络预测测试集并运行一个分类报告：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The results are quite poor, with an overall f1-score of 0.07, and the classifier
    only predicting class 2 for all instances. At first, it might seem that neural
    networks are not that great but let''s have a look at what happens when we train
    for 1000 epochs:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 结果相当糟糕，整体f1分数为0.07，分类器只预测所有实例为类别2。一开始，可能会觉得神经网络并不那么出色，但让我们看看当我们训练1000个epoch时会发生什么：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Visualizing the loss per epoch again, a very useful visualization when running
    iterative algorithms like neural networks, using the above code shows a very different
    story:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 再次可视化每个epoch的损失，这对于运行像神经网络这样的迭代算法非常有用，使用上面的代码显示了一个完全不同的故事：
- en: '![](img/B06162_11_06.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_11_06.png)'
- en: 'Finally, we perform a classification report again to see the results:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们再次运行分类报告以查看结果：
- en: '[PRE22]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Perfect.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 完美。
- en: Convolutional Neural Networks
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: 'To get started with image analysis with Keras, we are going to reimplement
    the example we used in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*, Beating CAPTCHAs
    with Neural Networks*, to predict which letter was represented in an image. We
    will recreate the dense neural network we used in [Chapter 8](lrn-dtmn-py-2e_ch08.html)*,
    Beating CAPTCHAs with Neural Networks*. To start with, we need to enter our dataset
    building code again in our notebook. For a description of what this code does,
    refer to [Chapter 8](lrn-dtmn-py-2e_ch08.html)*, Beating CAPTCHAs with Neural
    Networks *(*remember to update the file location of the Coval font*):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用Keras进行图像分析，我们将重新实现我们在[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络击败CAPTCHAs*中使用的示例，以预测图像中代表的是哪个字母。我们将重新创建我们在[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络击败CAPTCHAs*中使用的密集神经网络。首先，我们需要在我们的笔记本中再次输入我们的数据集构建代码。关于此代码的描述，请参阅[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络击败CAPTCHAs*
    (*请记住更新Coval字体的文件位置*)：
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After rerunning all of this code, you'll have a dataset similar to [Chapter
    8](lrn-dtmn-py-2e_ch08.html)*, Beating CAPTCHAs with Neural Networks* experiment.
    Next, instead of using scikit-learn to do our neural network, we will use Keras.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在重新运行所有这些代码之后，你将得到一个类似于[第8章](lrn-dtmn-py-2e_ch08.html)*，使用神经网络击败CAPTCHAs*实验的数据集。接下来，我们不会使用scikit-learn来构建我们的神经网络，而是将使用Keras。
- en: First, we create our two **Dense** layers and combine them in a **Sequential**
    model. I've chosen to put 100 neurons in the hidden layer.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建了两个**密集**层，并将它们组合在一个**顺序**模型中。我选择在隐藏层中放置100个神经元。
- en: '[PRE24]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Then, we fit the model. As before, you will want to have quite a larger number
    of epochs. I've used 1000 again, if you want better results, you can increase
    this number.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们拟合模型。和之前一样，你可能希望有相当多的epoch。我再次使用了1000，如果你想得到更好的结果，你可以增加这个数字。
- en: '[PRE25]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: You can also collect the resulting history object, like we did with the Iris
    example, to investigate the training further.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以收集结果的历史对象，就像我们在Iris示例中所做的那样，以进一步调查训练。
- en: '[PRE26]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Again, perfect.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，完美。
- en: At least, it was on my machine but your results may differ slightly.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 至少，在我的机器上是这样的，但你的结果可能会有所不同。
- en: GPU optimization
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU优化
- en: Neural networks can grow quite large in size. This has some implications for
    memory use; however, efficient structures such as sparse matrices mean that we
    don't generally run into problems fitting a neural network in memory.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络可以变得相当大。这对内存使用有一些影响；然而，像稀疏矩阵这样的高效结构意味着我们通常不会遇到在内存中拟合神经网络的难题。
- en: The main issue when neural networks grow large is that they take a very long
    time to compute. In addition, some datasets and neural networks will need to run
    many epochs of training to get a good fit for the dataset.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当神经网络变得很大时，主要问题在于它们计算时间非常长。此外，一些数据集和神经网络可能需要运行许多epoch的训练才能得到数据集的良好拟合。
- en: The neural network we will train in this chapter takes more than 8 minutes per
    epoch on my reasonably powerful computer, and we expect to run dozens, potentially
    hundreds, of epochs. Some larger networks can take hours to train a single epoch.
    To get the best performance, you may be considering thousands of training cycles.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中训练的神经网络在我的相当强大的计算机上每个epoch需要超过8分钟，我们预计将运行数十个，甚至数百个epoch。一些更大的网络可能需要数小时才能训练一个epoch。为了获得最佳性能，你可能正在考虑数千个训练周期。
- en: The scale of neural networks leads to long training times.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的比例导致训练时间过长。
- en: One positive is that neural networks are, at their core, full of floating point
    operations. There are also a large number of operations that can be performed
    in parallel, as neural network training is composed of mainly matrix operations.
    These factors mean that computing on GPUs is an attractive option to speed up
    this training.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一个积极因素是，神经网络的核心充满了浮点运算。还有大量可以并行执行的操作，因为神经网络训练主要由矩阵运算组成。这些因素意味着在GPU上进行计算是加快这一训练的一个有吸引力的选择。
- en: When to use GPUs for computation
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用GPU进行计算
- en: GPUs were originally designed to render graphics for display. These graphics
    are represented using matrices and mathematical equations on those matrices, which
    are then converted into the pixels that we see on our screen. This process involves
    lots of computation in parallel. While modern CPUs may have a number of cores
    (your computer may have 2, 4, or even 16—or more!), GPUs have thousands of small
    cores designed specifically for graphics.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: GPU最初是为了渲染显示图形而设计的。这些图形使用矩阵和矩阵上的数学方程来表示，然后转换成我们在屏幕上看到的像素。这个过程涉及到大量的并行计算。虽然现代CPU可能有多个核心（你的电脑可能有2、4个，甚至16个或更多！），但GPU有数千个专为图形设计的小核心。
- en: A CPU is better for sequential tasks, as the cores tend to be individually faster
    and tasks such as accessing the computer's memory are more efficient. It is also,
    honestly, easier to just let the CPU do the heavy lifting. Almost every machine
    learning library defaults to using the CPU, and there is extra work involved before
    you can use the GPU for computing. The benefits can be quite significant.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: CPU更适合顺序任务，因为核心通常单独运行得更快，而且像访问电脑内存这样的任务更有效率。实际上，让CPU做重活也更简单。几乎每个机器学习库默认都使用CPU，在使用GPU进行计算之前，你需要做额外的工作。这些好处可能非常显著。
- en: GPUs are therefore better suited for tasks in which there are lots of small
    operations on numbers that can be performed at the same time. Many machine learning
    tasks are like this, lending themselves to efficiency improvements through the
    use of a GPU.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，GPU更适合那些需要同时进行大量小规模数值运算的任务。许多机器学习任务都是这样的，通过使用GPU可以显著提高效率。
- en: Getting your code to run on a GPU can be a frustrating experience. It depends
    greatly on what type of GPU you have, how it is configured, your operating system,
    and whether you are prepared to make some low-level changes to your computer.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让你的代码在GPU上运行可能会是一个令人沮丧的经历。这很大程度上取决于你有什么类型的GPU，它的配置如何，你的操作系统，以及你是否准备对你的电脑进行一些低级修改。
- en: Luckily, Keras will automatically use a GPU for operations, if the operation
    suits and a GPU can be found (and if you use TensorFlow as the backend). However,
    you still need to setup your computer such that the GPU can be found by Keras
    and TensorFlow.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Keras会自动使用GPU进行操作，如果操作适合且找到了GPU（并且如果你使用TensorFlow作为后端）。然而，你仍然需要设置你的电脑，使得Keras和TensorFlow能够找到GPU。
- en: 'There are three main avenues to take:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 有三条主要途径可以选择：
- en: The first is to look at your computer, search for tools and drivers for your
    GPU and operating system, explore some of the many tutorials out there, and find
    one that fits your scenario. Whether this works depends on what your system is
    like. That said, this scenario is much easier than it was a few years ago, with
    better tools and drivers available to perform GPU-enabled computation.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，你需要查看你的电脑，搜索适合你的GPU和操作系统的工具和驱动程序，探索众多教程中的一些，并找到适合你场景的一个。这种方法是否有效取决于你的系统类型。尽管如此，与几年前相比，这个场景要容易得多，因为现在有更好的工具和驱动程序可以执行GPU加速计算。
- en: The second avenue is to choose a system, find good documentation on setting
    it up and buy a system to match. This will work better, but can be fairly expensive—in
    most modern computers, the GPU is one of the most expensive parts. This is especially
    true if you want to get great performance out of the system—you'll need a really
    good GPU, which can be very expensive. If you are a business (or have larger amounts
    of money to spend), you can buy high-end GPUs specifically for deep learning and
    talk more directly to vendors to ensure you get the right hardware.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二条途径是选择一个系统，找到设置它的良好文档，并购买一个与之匹配的系统。这会更好，但可能相当昂贵——在大多数现代电脑中，GPU是最昂贵的部件之一。如果你想要从系统中获得出色的性能，这一点尤其正确——你需要一个非常好的GPU，这可能会非常昂贵。如果你是一家企业（或者有更多的资金可以花费），你可以购买专门用于深度学习的高端GPU，并与供应商直接交谈，以确保你获得正确的硬件。
- en: The third avenue is to use a virtual machine, which is already configured for
    such a purpose. For example, Altoros Systems has created such a system that runs
    on Amazon's Web Services. The system will cost you money to run, but the price
    is much less than that of a new computer. Depending on your location, the exact
    system you get and how much you use it, you are probably looking at less than
    $1 an hour, and often much, much less. If you use spot instances in Amazon's Web
    Services, you can run them for just a few cents per hour (although, you will need
    to develop your code to run on spot instances separately).
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三种方法是使用已经配置好的虚拟机。例如，Altoros Systems已经创建了一个在亚马逊云服务上运行的系统。运行这个系统会花费您一些费用，但价格远低于新电脑的价格。根据您的位置，您得到的系统以及使用量，您可能每小时只需花费不到1美元，通常还要少得多。如果您在亚马逊云服务中使用spot实例，您每小时只需支付几分钱（尽管，您需要单独开发可以在spot实例上运行的代码）。
- en: If you aren't able to afford the running costs of a virtual machine, I recommend
    that you look into the first avenue, with your current system. You may also be
    able to pick up a good second-hand GPU from family or a friend who constantly
    updates their computer (gamer friends are great for this!).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您无法承担虚拟机的运行成本，我建议您考虑第一种方法，使用您当前的系统。您也可能能够从经常更新电脑的家庭成员或朋友那里购买到一台好的二手GPU（游戏玩家朋友在这方面很棒！）。
- en: Running our code on a GPU
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在GPU上运行我们的代码
- en: We are going to take the third avenue in this chapter and create a virtual machine
    based on Altoros Systems' base system. This will run on an Amazon's EC2 service.
    There are many other Web services to use, and the procedure will be slightly different
    for each. In this section, I'll outline the procedure for Amazon.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将选择第三种方法，基于Altoros Systems的基础系统创建一个虚拟机。这个虚拟机将在亚马逊的EC2服务上运行。还有许多其他Web服务可以使用，每种服务的流程都会略有不同。在本节中，我将概述亚马逊的流程。
- en: If you want to use your own computer and have it configured to run GPU-enabled
    computation, feel free to skip this section.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想使用自己的电脑并且已经配置好用于运行带GPU的计算，您可以跳过这一部分。
- en: You can get more information on how this was set up, see [https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&sr=0-1&ref_=srh_res_product_title](https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&sr=0-1&ref_=srh_res_product_title)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以获取更多有关如何设置此信息，请参阅[https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&sr=0-1&ref_=srh_res_product_title](https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&sr=0-1&ref_=srh_res_product_title)
- en: 'To start with, go to the AWS console at: [https://console.aws.amazon.com/console/home?region=us-east-1](https://console.aws.amazon.com/console/home?region=us-east-1)'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，请转到AWS控制台：[https://console.aws.amazon.com/console/home?region=us-east-1](https://console.aws.amazon.com/console/home?region=us-east-1)
- en: Log in with your Amazon account. If you don't have one, you will be prompted
    to create one, which you will need to do in order to continue.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的亚马逊账户登录。如果您没有账户，系统会提示您创建一个，这是您继续操作所必需的。
- en: Next, go to the EC2 service console at: [https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.](https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.)
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，转到EC2服务控制台：[https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.](https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.)
- en: Click on Launch Instance and choose N. California as your location in the drop-down
    menu at the top-right.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“启动实例”，并在右上角的下拉菜单中选择“加州北部”作为您的位置。
- en: Click on Community AMIs and search for Ubuntu x64 AMI with TensorFlow (GPU),
    which is the machine created by Altoros Systems. Then, click on Select. On the
    next screen, choose g2.2xlarge as the machine type and click on Review and Launch.
    On the next screen, click on Launch.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“社区AMI”，搜索带有TensorFlow（GPU）的Ubuntu x64 AMI，这是由Altoros Systems创建的机器。然后，点击“选择”。在下一屏幕上，选择“g2.2xlarge”作为机器类型，点击“审查和启动”。在下一屏幕上，点击“启动”。
- en: At this point, you will be charged, so please remember to shut down your machines
    when you are done with them. You can go to the EC2 service, select the machine,
    and stop it. You won't be charged for machines that are not running.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到这一步，您将开始收费，所以请记住，当您完成使用机器时请关闭它们。您可以去EC2服务，选择机器，然后停止它。对于未运行的机器，您将不会产生费用。
- en: You'll be prompted with some information on how to connect to your instance.
    If you haven't used AWS before, you will probably need to create a new key pair
    to securely connect to your instance. In this case, give your key pair a name,
    download the pemfile, and store it in a safe place—if lost, you will not be able
    to connect to your instance again!
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将收到一些有关如何连接到实例的信息。如果您之前没有使用过AWS，您可能需要创建一个新的密钥对以安全地连接到实例。在这种情况下，给您的密钥对起一个名字，下载pem文件，并将其存储在安全的地方——如果丢失，您将无法再次连接到您的实例！
- en: 'Click on Connect for information on using the pem file to connect to your instance.
    The most likely scenario is that you will use ssh with the following command:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“连接”以获取有关使用pem文件连接到实例的信息。最可能的情况是您将使用以下命令使用ssh：
- en: '[PRE27]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Setting up the environment
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置环境
- en: Next, we need to get our code onto the machine. There are many ways to get this
    file onto your computer, but one of the easiest is to just copy-and-paste the
    contents.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要将我们的代码上传到机器上。有许多方法可以将此文件上传到您的计算机，但其中一种最简单的方法就是直接复制粘贴内容。
- en: To start with, open the Jupyter Notebook we used before (on your computer, not
    on the Amazon Virtual Machine). On the Notebook itself is a menu. Click on File
    and then Download as. Select Python and save it to your computer. This procedure
    downloads the code in the Jupyter Notebook as a python script that you can run
    from the command line.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开我们之前使用的Jupyter Notebook（在您的计算机上，而不是在亚马逊虚拟机上）。在Notebook本身有一个菜单。点击文件，然后下载为。选择Python并将其保存到您的计算机上。此过程将Jupyter
    Notebook中的代码下载为Python脚本，您可以从命令行运行它。
- en: Open this file (on some systems, you may need to right-click and open with a
    text editor). Select all of the contents and copy them to your clipboard.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 打开此文件（在某些系统上，您可能需要右键单击并使用文本编辑器打开）。选择所有内容并将其复制到剪贴板。
- en: 'On the Amazon Virtual Machine, move to the home directory and open nano with
    a new filename:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在亚马逊虚拟机上，移动到主目录并使用新文件名打开nano：
- en: '[PRE28]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The nano program will open, which is a command-line text editor.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: nano程序将打开，这是一个命令行文本编辑器。
- en: With this program open, paste the contents of your clipboard into this file.
    On some systems, you may need to use a file option of the ssh program, rather
    than pressing Ctrl+ V to paste.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 打开此程序后，将剪贴板内容粘贴到该文件中。在某些系统上，您可能需要使用ssh程序中的文件选项，而不是按Ctrl+V粘贴。
- en: In nano, press Ctrl+ O to save the file on the disk and then Ctrl+ X to exit
    the program.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在nano中，按Ctrl+O保存文件到磁盘，然后按Ctrl+X退出程序。
- en: 'You''ll also need the font file. The easiest way to do this is to download
    it again from the original location. To do this, enter the following:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要字体文件。最简单的方法是从原始位置重新下载它。为此，请输入以下内容：
- en: '[PRE29]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'While still in the virtual machine, you can run the program with the following
    command:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟机中，您可以使用以下命令运行程序：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The program will run through as it would in the Jupyter Notebook and the results
    will print to the command line.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 程序将像在Jupyter Notebook中一样运行，并将结果打印到命令行。
- en: The results should be the same as before, but the actual training and testing
    of the neural network will be much faster. Note that it won't be that much faster
    in the other aspects of the program—we didn't write the CAPTCHA dataset creation
    to use a GPU, so we will not obtain a speedup there.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该与之前相同，但实际训练和测试神经网络的速度将快得多。请注意，在其他程序方面，它不会快那么多——我们没有编写CAPTCHA数据集创建以使用GPU，因此我们不会在那里获得加速。
- en: You may wish to shut down the Amazon virtual machine to save some money; we
    will be using it at the end of this chapter to run our main experiment, but will
    be developing the code on your main computer first.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望关闭亚马逊虚拟机以节省一些费用；我们将在本章末尾使用它来运行我们的主要实验，但首先将在您的计算机上开发代码。
- en: Application
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用程序
- en: Back on your main computer now, open the first Jupyter Notebook we created in
    this chapter—the one that we loaded the CIFAR dataset with. In this major experiment,
    we will take the CIFAR dataset, create a deep convolution neural network, and
    then run it on our GPU-based virtual machine.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到您的计算机上，打开本章中创建的第一个Jupyter Notebook——我们使用它加载了CIFAR数据集的那个。在这个主要实验中，我们将使用CIFAR数据集，创建一个深度卷积神经网络，然后在基于GPU的虚拟机上运行它。
- en: Getting the data
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'To start with, we will take our CIFAR images and create a dataset with them.
    Unlike previously, we are going to preserve the pixel structure—that is, in rows
    and columns. First, load all the batches into a list:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用我们的 CIFAR 图像并创建一个包含它们的数据库。与之前不同，我们将保留像素结构——即在行和列中。首先，将所有批次加载到一个列表中：
- en: '[PRE31]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The last line, the break, is to test the code—this will drastically reduce the
    number of training examples, allowing you to quickly see if your code is working.
    I'll prompt you later to remove this line after you have tested that the code
    works.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行，即 break，是为了测试代码——这将大大减少训练示例的数量，让您可以快速看到代码是否工作。我将在您测试代码工作后提示您删除此行。
- en: 'Next, create a dataset by stacking these batches on top of each other. We use
    NumPy''s vstack, which can be visualised as adding rows to the end of the array:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过将这些批次堆叠在一起来创建一个数据集。我们使用 NumPy 的 vstack，这可以看作是在数组的末尾添加行：
- en: '[PRE32]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We then normalise the dataset to the range 0 to 1 and then force the type to
    be a 32-bit float (this is the only datatype the GPU-enabled virtual machine can
    run with):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数据集归一化到 0 到 1 的范围，并强制类型为 32 位浮点数（这是 GPU 启用的虚拟机可以运行的唯一数据类型）：
- en: '[PRE33]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We then do the same with the classes, except we perform a hstack, which is
    similar to adding columns to the end of the array. We could then use the OneHotEncoder
    to turn this into a one-hot array. I''ll show an alternate method here using a
    utility function present in Keras, but the result is the same either way:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们对类别执行相同的操作，除了我们执行 hstack，这类似于在数组的末尾添加列。然后我们可以使用 OneHotEncoder 将其转换为独热数组。这里我将展示一个使用
    Keras 中提供的实用函数的替代方法，但结果是一样的：
- en: '[PRE34]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we split the dataset into training and testing sets:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将数据集分为训练集和测试集：
- en: '[PRE35]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Next, we reshape the arrays to preserve the original data structure. The original
    data was 32-by-32-pixel images, with 3 values per pixel (for the red, green, and
    blue values). While standard feed-forward neural networks only take a single array
    of input data (see the CAPTCHA example), Convolutional Neural Networks are built
    for images and accept 3-dimensional image data (2-D image, and another dimension
    containing colour depth).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将数组重塑以保留原始数据结构。原始数据是 32x32 像素的图像，每个像素有 3 个值（红色、绿色和蓝色值）。虽然标准的前馈神经网络只接受单个输入数据数组（参见
    CAPTCHA 示例），但卷积神经网络是为图像设计的，并接受三维图像数据（2D 图像，以及包含颜色深度的另一个维度）。
- en: '[PRE36]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We now have a familiar training and testing dataset, along with the target classes
    for each. We can now build the classifier.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个熟悉的训练和测试数据集，以及每个数据集的目标类别。我们现在可以构建分类器了。
- en: Creating the neural network
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建神经网络
- en: We will now build the convolutional neural network. I have performed some tinkering
    and found a layout that works well, but feel free to experiment with more layers
    (or fewer), layers of different types and different sizes. Smaller networks train
    faster, but larger networks can achieve better results.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将构建卷积神经网络。我已经进行了一些调整，发现了一个效果很好的布局，但您可以自由地尝试更多层（或更少层）、不同类型和不同大小的层。较小的网络训练更快，但较大的网络可以实现更好的结果。
- en: 'First, we create the layers of our neural network:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建神经网络层：
- en: '[PRE37]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We use dense layers for the last three layers as per a normal feed-forward neural
    network, but before that, we use convolution layers combined with pooling layers.
    We have three sets of these.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用密集层作为最后三层，按照正常的前馈神经网络，但在那之前，我们使用结合了池化层的卷积层。我们有三组这样的层。
- en: 'For each pair of Convolution2D and MaxPooling2D layers, the following happens:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一对 Convolution2D 和 MaxPooling2D 层，发生以下情况：
- en: The Convolution2D network fetches patches of the input data. These are passed
    through a filter, a matrix transformation akin to the kernel operator Support
    Vector Machines use. A filter is a smaller matrix, of size k by n (specified as
    3x3 in the Convolution2D initialiser above) that is applied to each k by n pattern
    found in the image. The result is a convolved feature.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Convolution2D 网络从输入数据中获取补丁。这些数据通过一个过滤器传递，这是一个类似于支持向量机使用的核操作符的矩阵变换。过滤器是一个较小的矩阵，大小为
    k x n（在上面的 Convolution2D 初始化器中指定为 3x3），它应用于图像中找到的每个 k x n 模式。结果是卷积特征。
- en: The MaxPooling2D layer takes the results from the Convolution2D layer and finds
    the maximum value for each convolved feature.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MaxPooling2D 层从 Convolution2D 层的结果中找到每个卷积特征的最大值。
- en: While this does discard lots of information, this actually helps for image detection.
    If the object of an image is a few pixels to the right, a standard neural network
    will consider it a completely new image. In contrast, the convolution layer will
    find it and report almost the same output (depending, of course, on a wide variety
    of other factors).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这确实丢弃了大量的信息，但这实际上有助于图像检测。如果一个图像中的物体只是向右偏移了几像素，标准的神经网络会将其视为一个全新的图像。相比之下，卷积层会发现它，并报告几乎相同的输出（当然，这取决于广泛的其它因素）。
- en: After passing through these pairs layers, the features that go into the dense
    part of the network are meta-features that represent abstract concepts of the
    image, rather than specific qualities. Often these can be visualised, resulting
    in features like *a little bit of a line pointing up*.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过这些对层之后，进入网络密集部分的特征是元特征，它们代表了图像的抽象概念，而不是具体特性。通常这些可以可视化，产生如*向上指的小线条*这样的特征。
- en: Next, we put these layers together to build our neural network and train it.
    This training will take substantially longer than previous training. I recommend
    starting with 10 epochs, make sure the code works all the way through, and then
    rerun with 100 epochs. Also, once you have confirmed that the code works and you
    get predictions out, go back and remove the `break` line we put in when creating
    the dataset (it is in the batches loop). This will allow the code to train on
    all of the samples, not just the first batch.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将这些层组合起来构建我们的神经网络并对其进行训练。这次训练将比之前的训练花费更长的时间。我建议从10个周期开始，确保代码能够完整运行，然后以100个周期重新运行。此外，一旦你确认代码可以正常工作并且得到了预测结果，返回并移除我们在创建数据集时放入的`break`行（它在批量循环中）。这将允许代码在所有样本上训练，而不仅仅是第一个批次。
- en: '[PRE38]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Finally, we can predict with the network and evaluate.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用网络进行预测并评估。
- en: '[PRE39]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: After running for 100 epochs, it is still not quite perfect in this case, but
    still an excellent result. If you have the time (say, overnight), try running
    the code for 1000 epochs. There is an increase in accuracy but a diminishing return
    on time invested. A (not so) good rule of thumb is that to halve the error, you
    need to double the training time.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 经过100个周期的运行后，在这个案例中它仍然不是完美无缺，但仍然是一个极好的结果。如果你有时间（比如一整夜），尝试运行1000个周期的代码。准确率有所提高，但投入的时间回报却在减少。一个（不是那么）好的经验法则是，为了将错误减少一半，你需要将训练时间加倍。
- en: Putting it all together
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有这些组合在一起
- en: Now that we have our network code working, we can train it with our training
    dataset on the remote machine. If you used your local machine to run the neural
    network, you can skip this section.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使网络代码工作，我们可以在远程机器上使用我们的训练数据集对其进行训练。如果你使用本地机器运行神经网络，你可以跳过这一部分。
- en: We need to upload the script to our virtual machine. As with before, click on
    File| Download as, Python, and save the script somewhere on your computer. Launch
    and connect to the virtual machine and upload the script as you did earlier (I
    called my script `chapter11cifar.py`—if you named yours differently, just update
    the following code).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将脚本上传到我们的虚拟机。和之前一样，点击文件|下载为，Python，并将脚本保存在你的电脑上的某个位置。启动并连接到虚拟机，然后像之前一样上传脚本（我称我的脚本为`chapter11cifar.py`——如果你命名不同，只需更新以下代码）。
- en: 'The next thing we need is for the dataset to be on the virtual machine. The
    easiest way to do this is to go to the virtual machine and type:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步我们需要的是将数据集放在虚拟机上。最简单的方法是进入虚拟机并输入以下命令：
- en: '[PRE40]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This will download the dataset. Once that has downloaded, you can extract the
    data to the Data folder by first creating that folder and then unzipping the data
    there:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这将下载数据集。一旦下载完成，你可以通过首先创建该文件夹然后在该文件夹中解压缩数据来将数据提取到数据文件夹中：
- en: '[PRE41]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Finally, we can run our example with the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用以下命令运行我们的示例：
- en: '[PRE42]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The first thing you'll notice is a drastic speedup. On my home computer, each
    epoch took over 100 seconds to run. On the GPU-enabled virtual machine, each epoch
    takes just 16 seconds! If we tried running 100 epochs on my computer, it would
    take nearly three hours, compared to just 26 minutes on the virtual machine.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先会注意到速度有显著提升。在我的家用电脑上，每个周期需要超过100秒来运行。在启用GPU的虚拟机上，每个周期只需要16秒！如果我们尝试在我的电脑上运行100个周期，将需要近三个小时，而在虚拟机上只需要26分钟。
- en: This drastic speedup makes trialing different models much faster. Often with
    trialing machine learning algorithms, the computational complexity of a single
    algorithm doesn't matter too much. An algorithm might take a few seconds, minutes,
    or hours to run. If you are only running one model, it is unlikely that this training
    time will matter too much—especially as prediction, as with most machine learning
    algorithms,  is quite quick and that is where a machine learning model is mostly
    used.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这种显著的速度提升使得尝试不同的模型变得更快。在尝试机器学习算法时，单个算法的计算复杂度并不太重要。一个算法可能只需要几秒钟、几分钟或几小时来运行。如果你只运行一个模型，这种训练时间不太可能很重要——特别是预测，正如大多数机器学习算法那样，预测相当快，这也是机器学习模型主要被使用的地方。
- en: However, when you have many parameters to run, you will suddenly need to train
    thousands of models with slightly different parameters—suddenly, these speed increases
    matter much more.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当你有很多参数要运行时，你将突然需要训练成千上万的模型，这些模型的参数略有不同——突然，这些速度提升变得非常重要。
- en: 'After 100 epochs of training, taking a whole 26 minutes, you will get a printout
    of the final result:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 经过100个epoch的训练，总共花费了26分钟，你将得到最终结果的打印输出：
- en: '[PRE43]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Not too bad! We can increase the number of epochs of training to improve this
    further or we might try changing the parameters instead; perhaps, more hidden
    nodes, more convolution layers, or an additional dense layer. There are other
    types of layers in Keras that could be tried too; although generally, convolution
    layers are better for vision.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错！我们可以增加训练的epoch数量来进一步提高这个结果，或者我们可能尝试改变参数；也许，更多的隐藏节点、更多的卷积层，或者一个额外的密集层。Keras还有其他类型的层可以尝试；尽管通常，卷积层更适合视觉。
- en: Summary
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at using deep neural networks, specifically convolution
    networks, in order to perform computer vision. We did this through the Keras package,
    which uses Tensorflow or Theano as its computation backend. The networks were
    relatively easy to build with Kera's helper functions.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了使用深度神经网络，特别是卷积网络，来执行计算机视觉。我们通过Keras包来完成这项工作，该包使用Tensorflow或Theano作为其计算后端。使用Keras的辅助函数，构建这些网络相对简单。
- en: The convolution networks were designed for computer vision, so it shouldn't
    be a surprise that the result was quite accurate. The final result shows that
    computer vision is indeed an effective application using today's algorithms and
    computational power.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络是为计算机视觉设计的，所以结果相当准确并不令人惊讶。最终结果表明，计算机视觉确实是使用今天算法和计算能力的一个有效应用。
- en: We also used a GPU-enabled virtual machine to drastically speed up the process,
    by a factor of almost 10 for my machine. If you need extra power to run some of
    these algorithms, virtual machines by cloud providers can be an effective way
    to do this (usually for less than a dollar per hour)—just remember to turn them
    off when you are done!
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用了一个启用GPU的虚拟机来显著加快这个过程，我的机器速度提高了近10倍。如果你需要额外的计算能力来运行这些算法，云服务提供商的虚拟机可以是一个有效的方法（通常每小时不到一美元）——只是记得用完之后关掉它们！
- en: To extend the work in this chapter, try play with the structure of the network
    to increase the accuracy further than what we obtained here. Another method that
    can be used to improve the accuracy is to create more data, either by taking your
    own pictures (slow) or by modifying the existing ones (much faster). To do the
    modification, you can flip images upside down, rotate, shear and so on. Keras
    has a function for doing this that is quite useful. See the documentation at [https://keras.io/preprocessing/image/](https://keras.io/preprocessing/image/)
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展本章的工作，尝试调整网络结构，以进一步提高我们在这里获得的准确性。另一种提高准确性的方法是创建更多数据，无论是通过拍摄自己的照片（较慢）还是修改现有的照片（更快）。要进行修改，你可以翻转图像上下颠倒，旋转，剪切等等。Keras有一个做这个的函数，相当有用。请参阅[https://keras.io/preprocessing/image/](https://keras.io/preprocessing/image/)的文档。
- en: Another area worth investigating is variations in neural network structure,
    more nodes, fewer nodes, more layers and so on. Also experiment with different
    activation types, different layer types and different combinations.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得研究的问题是神经网络结构的变体，更多的节点、更少的节点、更多的层等等。还可以尝试不同的激活类型、不同的层类型和不同的组合。
- en: This chapter's focus was on a very complex algorithm. Convolution networks take
    a long time to train and have many parameters to train. Ultimately, the size of
    the data was small in comparison; although it was a large dataset, we can load
    it all in memory without even using sparse matrices. In the next chapter, we go
    for a much simpler algorithm, but a much, much larger dataset that can't fit in
    memory. This is the basis of Big Data and it underpins applications of data mining
    in many large industries such as mining and social networks.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点是讨论一个非常复杂的算法。卷积网络训练时间较长，并且需要训练许多参数。最终，与数据集的大小相比，数据量较小；尽管这是一个大型数据集，但我们甚至无需使用稀疏矩阵就能将其全部加载到内存中。在下一章中，我们将转向一个更加简单的算法，但数据集规模要大得多，以至于无法全部装入内存。这是大数据的基础，也是数据挖掘在许多大型行业（如采矿和社交网络）中应用的基础。
