<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer151">
    <h1 class="chapterNumber">4</h1>
    <h1 class="chapterTitle" id="_idParaDest-93">Harnessing Seasonality and Trends for Strategic Planning</h1>
    <p class="normal">Unless it is a one-time marketing event, such as opening pop-up stores or occasional celebratory product sales, there will always be impacts on the marketing outcomes from time components. For example, companies selling umbrellas will naturally see significant sales increases during rainy seasons. Not only can there be seasonal impacts on businesses but there can also be general trends in businesses. For example, businesses selling landline phones will see a gradual decline in their sales as people use mobile phones more and more.</p>
    <p class="normal">This chapter discusses in depth the temporal impacts on marketing campaigns and how to utilize them for the most efficient marketing strategies. We will introduce the basics of time-series analysis, such as some of the common approaches to identifying overall trends and anomalies and visualizing time-series data. We’ll then move on to exploring how time-series data can be decomposed into trends and seasonalities, which will inform us of the contribution of breakdowns of certain events based on these factors and how this decomposition helps with building more efficient marketing strategies. We’ll end by learning how to build time-series forecasting models and understanding how these forecasts can be utilized for proper marketing campaigns. We will use a product sales dataset as an example and discuss how to conduct time-series analysis and modeling in Python.</p>
    <p class="normal">More specifically, we will cover the following topics:</p>
    <ul>
      <li class="bulletList">Time series analysis basics</li>
      <li class="bulletList">Trend and seasonality decomposition in time-series data</li>
      <li class="bulletList">Time series forecasting models</li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-94">Time series analysis basics</h1>
    <p class="normal">Understanding natural <a id="_idIndexMarker296"/>trends within businesses is critical, not only for marketers but also for operators, sales, and most other business units. Without a good grasp of how a business and its products are evolving and how customers are reacting and behaving around the services and products that you provide, it is very easy to fall behind, resulting in suboptimal revenue growth or even business growth slowing to a halt.</p>
    <p class="normal">It is easy to find how businesses build their product strategies around this temporal component of the business cycle. In the fashion industry, clothing businesses typically market spring and summer clothes from late winter to early spring, while fall and winter clothes are advertised from early summer to early fall, as customers tend to shop before the actual season comes as a preparation. Then, spring and summer clothes typically go on sale during the summer, typically from mid-July, as the demand for these clothes is low during the actual season. This illustrates how businesses can optimize their business cycles for different seasons based on the customer demands that naturally form and how they can maximize sales while minimizing the excess inventory.</p>
    <p class="normal"><strong class="keyWord">Time series analysis</strong> comes in handy when we try to understand these natural temporal components within businesses. Time series analysis, in short, is a way of analyzing a series of data points over time and how <strong class="keyWord">time</strong> affects the changes in data values. In this chapter, we will be using a historical sales dataset as an example to discuss how to conduct time series analysis and modeling.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">Source code and data</strong>:</p>
      <p class="normal"><a href="https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.4 "><span class="url">https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.4</span></a></p>
      <p class="normal"><strong class="keyWord">Data source</strong>: <a href="https://community.tableau.com/s/question/0D54T00000CWeX8SAL/sample-superstore-sales-excelxls"><span class="url">https://community.tableau.com/s/question/0D54T00000CWeX8SAL/sample-superstore-sales-excelxls</span></a></p>
    </div>
    <h2 class="heading-2" id="_idParaDest-95">Basic time series trends</h2>
    <p class="normal">Let’s look at <a id="_idIndexMarker297"/>overall monthly product sales using our example dataset. We will first need to load this data into a DataFrame and aggregate the data per month. Take a look at the following code (note that the CSV file used here is included in the book GitHub repository):</p>
    <pre class="programlisting code"><code class="hljs-code">df = pd.read_csv(<span class="hljs-string">"./data.csv"</span>, encoding=<span class="hljs-string">"latin"</span>)
df[<span class="hljs-string">"OrderDate"</span>] = pd.to_datetime(df[<span class="hljs-string">"OrderDate"</span>])
ts_df = df[[
    <span class="hljs-string">"OrderID"</span>, <span class="hljs-string">"OrderDate"</span>, <span class="hljs-string">"Quantity"</span>, <span class="hljs-string">"Sales"</span>, <span class="hljs-string">"Category"</span>
]].copy().set_index(<span class="hljs-string">"OrderDate"</span>)
df.columns = [x.replace(<span class="hljs-string">" "</span>, <span class="hljs-string">""</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> df.columns]
</code></pre>
    <p class="normal">Here, we are loading the data into a <code class="inlineCode">pandas</code> DataFrame. One thing that is different from previous chapters is the encoding parameter. This dataset contains non-UTF characters, so we are using <code class="inlineCode">latin</code> encoding to load the data. Then, we convert the values in the <code class="inlineCode">OrderDate</code> column into a datetime type and copy the key columns into a new <code class="inlineCode">DataFrame</code>, <code class="inlineCode">ts_df</code>. Lastly, for ease of use, we remove spaces in the column names by replacing all spaces with empty strings.</p>
    <p class="normal">One way to resample and aggregate the data into monthly frequency is as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">monthly_unique_orders = ts_df[<span class="hljs-string">"OrderID"</span>].resample(<span class="hljs-string">"MS"</span>).nunique()
monthly_unique_order_changes = (
    monthly_unique_orders - monthly_unique_orders.shift()
)/monthly_unique_orders.shift()*<span class="hljs-number">100</span>
</code></pre>
    <p class="normal">We are using the <code class="inlineCode">resample</code> function within <code class="inlineCode">pandas</code> with the argument <code class="inlineCode">MS</code>, which will resample the data into a monthly timeframe, and then counting the number of unique <code class="inlineCode">OrderID</code> values using the <code class="inlineCode">nunique</code> function, which will give us monthly unique order count data. We then compute month-over-month changes in percentages by subtracting the previous month’s value from the current month’s value and dividing it by the previous month’s value. The <code class="inlineCode">shift</code> function will move the data by one period, resulting in giving us the previous month’s value.</p>
    <p class="normal">We can apply the same to compute monthly order quantities and sales, as in the following:</p>
    <pre class="programlisting code"><code class="hljs-code">monthly_quantities = ts_df[<span class="hljs-string">"Quantity"</span>].resample(<span class="hljs-string">"</span><span class="hljs-string">MS"</span>).<span class="hljs-built_in">sum</span>()
monthly_quantities_changes = (
    monthly_quantities - monthly_quantities.shift()
)/monthly_quantities.shift()*<span class="hljs-number">100</span>
monthly_sales = ts_df[<span class="hljs-string">"Sales"</span>].resample(<span class="hljs-string">"MS"</span>).<span class="hljs-built_in">sum</span>()
monthly_sales_changes = (
    monthly_sales - monthly_sales.shift()
)/monthly_sales.shift()*<span class="hljs-number">100</span>
</code></pre>
    <p class="normal">The simplest approach <a id="_idIndexMarker298"/>to visualizing time-series data is using line charts. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">fig, axes = plt.subplots(
nrows=<span class="hljs-number">3</span>, ncols=<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>), sharex=<span class="hljs-literal">True</span>
)
monthly_unique_orders.plot(
    ax=axes[<span class="hljs-number">0</span>], grid=<span class="hljs-literal">True</span>
)
monthly_unique_order_changes.plot(
    ax=axes[<span class="hljs-number">0</span>], secondary_y=<span class="hljs-literal">True</span>, color=<span class="hljs-string">"silver"</span>, linestyle=<span class="hljs-string">"dashed"</span>
)
axes[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">"Monthly Unique Orders"</span>)
axes[<span class="hljs-number">0</span>].set_ylabel(<span class="hljs-string">"# Unique Orders"</span>)
axes[<span class="hljs-number">0</span>].right_ax.set_ylabel(<span class="hljs-string">"Month over Month Change (%)"</span>)
monthly_quantities.plot(
    ax=axes[<span class="hljs-number">1</span>], grid=<span class="hljs-literal">True</span>
)
monthly_quantities_changes.plot(
    ax=axes[<span class="hljs-number">1</span>], secondary_y=<span class="hljs-literal">True</span>, color=<span class="hljs-string">"silver"</span>, linestyle=<span class="hljs-string">"dashed"</span>
)
axes[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">"Monthly Order Quantities"</span>)
axes[<span class="hljs-number">1</span>].set_ylabel(<span class="hljs-string">"Order Quantity"</span>)
axes[<span class="hljs-number">1</span>].right_ax.set_ylabel(<span class="hljs-string">"Month over Month Change (%)"</span>)
monthly_sales.plot(
    ax=axes[<span class="hljs-number">2</span>], grid=<span class="hljs-literal">True</span>
)
monthly_sales_changes.plot(
    ax=axes[<span class="hljs-number">2</span>], secondary_y=<span class="hljs-literal">True</span>, color=<span class="hljs-string">"silver"</span>, linestyle=<span class="hljs-string">"dashed"</span>
)
axes[<span class="hljs-number">2</span>].set_title(<span class="hljs-string">"Monthly Sales"</span>)
axes[<span class="hljs-number">2</span>].set_ylabel(<span class="hljs-string">"Sales"</span>)
axes[<span class="hljs-number">2</span>].right_ax.set_ylabel(<span class="hljs-string">"Month over Month Change (%)"</span>)
plt.show()
</code></pre>
    <p class="normal">In this code, we are creating three line charts. The first one is for the monthly unique order, the second one is for the monthly order quantities, and the last one is for the monthly sales. This <a id="_idIndexMarker299"/>code generates the following charts:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_01.png"/></figure>
    <p class="packt_figref">Figure 4.1: Visualization of monthly time-series data</p>
    <p class="normal">Let’s dive into these charts deeper. As you may notice, all three charts show clear repeating patterns. They spike in March, September, and November-December. This can be confirmed by both looking at the solid lines, which are overall monthly values, and looking at the dotted lines, which are month-over-month changes in the values. This suggests that this business is cyclical with a larger volume of sales in those corresponding months. Marketers should turn this insight into actions by marketing more heavily slightly before the peak seasons to capture the greatest amount of sales potential. Also, marketers can offer discounts during the months that show weaker sales volumes in an effort to manage the inventory, as well as boost off-season sales.</p>
    <p class="normal">As you can see, visualizing time-series data itself gives great insight into the business cycles and how to prepare for the peak and trough seasons. Another thing you may notice from these charts is they are overall in an uptrend, meaning the values are typically rising year over year. This overall trend is more easily identifiable when we look at the moving<a id="_idIndexMarker300"/> averages in the time-series charts.</p>
    <div class="packt_tip">
      <p class="normal">You can not only sample time-series data by monthly frequency but also by daily, weekly, or yearly frequencies. There are many options you can resample by, so try different resample frequencies and see what other trends you can observe!</p>
      <p class="normal"><strong class="keyWord">Reference</strong>: <span class="url">https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling</span></p>
    </div>
    <h2 class="heading-2" id="_idParaDest-96">Moving averages</h2>
    <p class="normal"><strong class="keyWord">Moving averages</strong>, which are the averages over specific time periods, are good<a id="_idIndexMarker301"/> at smoothing out spiky or noisy <a id="_idIndexMarker302"/>time-series data and showing overall trends. They are essential tools to answer questions like “Are our product sales in an overall uptrend or downtrend?”. Within our example data, we can do the following to compute moving averages:</p>
    <pre class="programlisting code"><code class="hljs-code">m6_ma_sales = monthly_sales.rolling(<span class="hljs-number">6</span>).mean()
m12_ma_sales = monthly_sales.rolling(<span class="hljs-number">12</span>).mean()
</code></pre>
    <p class="normal">As you can see from this code, you can use the <code class="inlineCode">rolling</code> function within <code class="inlineCode">pandas</code> and apply the <code class="inlineCode">mean</code> function to get the moving average of monthly sales. The input into the <code class="inlineCode">rolling</code> function defines how many periods you would like to average the values for. Here, we have computed the 6-period moving average and the 12-period moving average of monthly sales.</p>
    <p class="normal">You can use the following code to visualize the moving averages:</p>
    <pre class="programlisting code"><code class="hljs-code">ax = monthly_sales[<span class="hljs-string">"2015-01-01"</span>:].plot(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))
m6_ma_sales[<span class="hljs-string">"2015-01-01"</span>:].plot(ax=ax, grid=<span class="hljs-literal">True</span>)
m12_ma_sales[<span class="hljs-string">"2015-01-01"</span>:].plot(ax=ax, grid=<span class="hljs-literal">True</span>)
ax.set_ylabel(<span class="hljs-string">"Sales Amount"</span>)
ax.set_xlabel(<span class="hljs-string">"</span><span class="hljs-string">Order Date"</span>)
ax.set_title(<span class="hljs-string">"Monthly Sales Amount"</span>)
plt.legend([<span class="hljs-string">"Monthly Sales"</span>, <span class="hljs-string">"6mo Moving Average"</span>, <span class="hljs-string">"12mo Moving Average"</span>])
plt.show()
</code></pre>
    <p class="normal">The resulting chart will look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_02.png"/></figure>
    <p class="packt_figref">Figure 4.2: Monthly sales with 6-month and 12-month moving averages</p>
    <p class="normal">As expected, the 12-month<a id="_idIndexMarker303"/> moving average chart is smoother<a id="_idIndexMarker304"/> than the 6-month moving average chart. However, the 6-month moving average chart is more responsive or captures the monthly trends more closely than the 12-month moving average chart while still smoothing out the spikes in the monthly sales chart. As you may notice, the moving average charts show a general uptrend in the monthly sales data, which may have been harder to notice due to spikes and noises when we were only looking at the monthly chart.</p>
    <p class="normal">Moving averages can also help you understand whether the spikes in certain months are within the normal range or are abnormal. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">m6_ma_sales_std = monthly_sales.rolling(<span class="hljs-number">6</span>).std()
ax = monthly_sales[<span class="hljs-string">"2015-01-01"</span>:].plot(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))
m6_ma_sales[<span class="hljs-string">"2015-01-01"</span>:].plot(ax=ax, grid=<span class="hljs-literal">True</span>)
(m6_ma_sales[<span class="hljs-string">"2015-01-01"</span>:] + m6_ma_sales_std[<span class="hljs-string">"2015-01-01"</span>:]).plot(
    ax=ax, grid=<span class="hljs-literal">True</span>, linestyle=<span class="hljs-string">"dashed"</span>, color=<span class="hljs-string">"silver"</span>, linewidth=<span class="hljs-number">1</span>
)
(m6_ma_sales[<span class="hljs-string">"</span><span class="hljs-string">2015-01-01"</span>:] - m6_ma_sales_std[<span class="hljs-string">"2015-01-01"</span>:]).plot(
    ax=ax, grid=<span class="hljs-literal">True</span>, linestyle=<span class="hljs-string">"dashed"</span>, color=<span class="hljs-string">"silver"</span>, linewidth=<span class="hljs-number">1</span>
)
ax.set_ylabel(<span class="hljs-string">"Sales Amount"</span>)
ax.set_xlabel(<span class="hljs-string">"Order Date"</span>)
ax.set_title(<span class="hljs-string">"Monthly Sales Amount"</span>)
dates = m6_ma_sales[<span class="hljs-string">"2015-01-01"</span>:].index
plt.fill_between(
    dates,
    m6_ma_sales[<span class="hljs-string">"</span><span class="hljs-string">2015-01-01"</span>:] + m6_ma_sales_std[<span class="hljs-string">"2015-01-01"</span>:],
    m6_ma_sales[<span class="hljs-string">"2015-01-01"</span>:] - m6_ma_sales_std[<span class="hljs-string">"2015-01-01"</span>:],
    facecolor=<span class="hljs-string">"grey"</span>,
    alpha=<span class="hljs-number">0.2</span>,
)
plt.legend([<span class="hljs-string">"Monthly Sales"</span>, <span class="hljs-string">"6mo Moving Average (MA)"</span>, <span class="hljs-string">"6mo MA Upper"</span>, <span class="hljs-string">"6mo MA Lower"</span>])
plt.show()
</code></pre>
    <p class="normal">This code <a id="_idIndexMarker305"/>calculates <a id="_idIndexMarker306"/>the moving standard deviations (which is the same as moving averages but measuring standard deviations over a certain period of time in the past) over a 6-month period by using the <code class="inlineCode">std</code> function and visualizes data with the bands where the upper boundary is one standard deviation above the 6-month moving average and the lower boundary is one standard deviation below the 6-month moving average. The chart will look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_03.png"/></figure>
    <p class="packt_figref">Figure 4.3: Monthly sales with 6-month moving average and 1-std boundaries</p>
    <p class="normal">This chart shows how the monthly sales volumes look compared to the moving averages and one standard deviation boundaries. Depending on your preference, you may want to consider values within one standard deviation as normal or within two standard deviations as normal. Using <a id="_idIndexMarker307"/>this example, if we assume values <a id="_idIndexMarker308"/>within one standard deviation to be normal, we can see that the months of February, September, November, and December are abnormal months and went beyond the defined boundaries, where the sales in February dropped significantly lower than expected and the sales in September, November, and December increased significantly higher than expected.</p>
    <p class="normal">Understanding the overall trend of a business is equally as important as understanding the seasonal or cycles within a business. Depending on the general trend, you can be better informed as to whether to expect higher or lower sales and marketing potential than last year. If the overall trend is in an uptrend, you should expect the demand for a given month is likely to be higher than the demand for the same month in the previous year. Also, having a good grasp of the sales that go above or below the normal ranges, such as during Black Fridays or the Christmas season, can help to build efficient marketing strategies to overcome the shortages and the abundance of marketing potential. Moving averages and moving standard deviations are handy tools for identifying overall trends and <a id="_idIndexMarker309"/>norma<a id="_idIndexMarker310"/>l expected ranges.</p>
    <h2 class="heading-2" id="_idParaDest-97">Autocorrelation</h2>
    <p class="normal">Another basic <a id="_idIndexMarker311"/>time-series analysis that comes in handy is <strong class="keyWord">autocorrelation</strong>. Autocorrelation<a id="_idIndexMarker312"/> represents the correlation with lagged versions of itself. It will be easier to discuss with an example. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_acf, plot_pacf
plot_acf(
    monthly_sales, lags=<span class="hljs-number">25</span>
)
plt.show()
</code></pre>
    <p class="normal">Here, we are utilizing the <code class="inlineCode">statsmodels</code> package, which you can install using the <code class="inlineCode">pip install statsmodels</code> command. The <code class="inlineCode">plot_acf</code> function will plot the autocorrelation of a given series for you. Here, we are plotting the autocorrelation of the monthly sales for the past 25 periods. The chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_04.png"/></figure>
    <p class="packt_figref">Figure 4.4: Autocorrelation plot of monthly sales data</p>
    <p class="normal">Let’s analyze this chart more closely. The x-axis represents the number of lags and the y-axis is the degree of correlation. This chart shows the correlation between the current point of time against one period before, two periods before, and up to 25 periods before. Here, in the monthly sales data, we have relatively strong positive correlations up to three lagged periods and slight negative correlations with the fourth and fifth periods. This suggests that if there were increases in sales for the past 3 months, it is likely that the current month’s sales will increase, and vice versa. Also, this means that observing an increase in sales 4–5 months ago likely results in a decrease in sales during the current month. As this example shows, autocorrelation is a way to see how different time periods may have affected the current time period’s result. In the <em class="italic">Time series forecasting models</em> section of this chapter, we will experiment with the <strong class="keyWord">autoregressive integrated moving average</strong> (<strong class="keyWord">ARIMA</strong>) model, and the autoregression part of it uses these lagged <a id="_idIndexMarker313"/>variables for time-series forecast modeling.</p>
    <p class="normal"><strong class="keyWord">Partial autocorrelation</strong>, in<a id="_idIndexMarker314"/> contrast<a id="_idIndexMarker315"/> to autocorrelation, ignores the <a id="_idIndexMarker316"/>influences of intermediate lags. Unlike autocorrelation, partial autocorrelation measures the direct impact and correlation at each lag. The <code class="inlineCode">plot_pacf </code>function can be used to plot partial autocorrelations, as in the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">plot_pacf(
    monthly_sales, lags=<span class="hljs-number">15</span>
)
plt.show()
</code></pre>
    <p class="normal">Here, we are plotting partial autocorrelations up to period 15. The chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_05.png"/></figure>
    <p class="packt_figref">Figure 4.5: Partial autocorrelation plot of monthly sales data</p>
    <p class="normal">As you can see, the degrees of correlations at each lag are different compared to the previous autoregression chart. This is due to the fact that partial autoregression measures the direct correlation at each lag, whereas autoregression includes the influence of intermediate lags. In this example, we can see that there is a significant positive partial autocorrelation at lag 1 and a negative partial autocorrelation at lag 4. This suggests that the prior month’s increase or decrease in sales is likely to result in an increase and decrease in the current month’s sales, respectively, whereas the increase in sales 4 months ago is likely to result in a decrease in the current month’s sales, excluding the influences of the sales results in the months between. Intuitively, these can be a result of natural business cycles, where, if your business cycle is quarterly, then you will likely<a id="_idIndexMarker317"/> see<a id="_idIndexMarker318"/> negative autocorrelations at lags 3–4, and for semi-annual cycles, you are likely to see negative autocorrelations at lags 6–7.</p>
    <h2 class="heading-2" id="_idParaDest-98">Product trends</h2>
    <p class="normal">All of the analysis and<a id="_idIndexMarker319"/> visualizations we have discussed so far can be applied to more granular levels. We have only looked at the overall monthly sales time-series data. However, we can dissect it by different products and discover how each product may have different overall trends and cyclical nature in the demands. We can also look at how different states or geographic regions show trends and business cycles that may be different from the overall sales trends.</p>
    <p class="normal">For illustration purposes, we will dissect the trends by different product categories. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">furniture_monthly_sales = ts_df.loc[
    ts_df[<span class="hljs-string">"Category"</span>] == <span class="hljs-string">"Furniture"</span>
][<span class="hljs-string">"Sales"</span>].resample(<span class="hljs-string">"MS"</span>).<span class="hljs-built_in">sum</span>()
office_monthly_sales = ts_df.loc[
    ts_df[<span class="hljs-string">"Category"</span>] == <span class="hljs-string">"Office Supplies"</span>
][<span class="hljs-string">"Sales"</span>].resample(<span class="hljs-string">"MS"</span>).<span class="hljs-built_in">sum</span>()
tech_monthly_sales = ts_df.loc[
    ts_df[<span class="hljs-string">"Category"</span>] == <span class="hljs-string">"Technology"</span>
][<span class="hljs-string">"Sales"</span>].resample(<span class="hljs-string">"MS"</span>).<span class="hljs-built_in">sum</span>()
fig, axes = plt.subplots(nrows=<span class="hljs-number">3</span>, ncols=<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>), sharex=<span class="hljs-literal">True</span>)
furniture_monthly_sales.plot(ax=axes[<span class="hljs-number">0</span>], grid=<span class="hljs-literal">True</span>)
axes[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">"Monthly Furniture Sales"</span>)
office_monthly_sales.plot(ax=axes[<span class="hljs-number">1</span>], grid=<span class="hljs-literal">True</span>)
axes[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">"Monthly Office Supplies Sales"</span>)
tech_monthly_sales.plot(ax=axes[<span class="hljs-number">2</span>], grid=<span class="hljs-literal">True</span>)
axes[<span class="hljs-number">2</span>].set_title(<span class="hljs-string">"Monthly Technology Sales"</span>)
plt.show()
</code></pre>
    <p class="normal">First, we create<a id="_idIndexMarker320"/> time-series records for each product category. Largely, we are creating three time series of monthly <code class="inlineCode">Furniture</code>, <code class="inlineCode">Office Supplies</code>, and <code class="inlineCode">Technology</code> sales, and then showing these charts side by side. The resulting charts look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_06.png"/></figure>
    <p class="packt_figref">Figure 4.6: Visualization of monthly sales data for Furniture, Office Supplies, and Technology products</p>
    <p class="normal">The overall trends are<a id="_idIndexMarker321"/> similar across these three product lines, where the sales spike in September and November/December. However, the spike in March sales is the most prominent in Technology sales and there was a rapid growth in Furniture sales from January 2017. Also, Office Supplies sales seem to spike more frequently than the other two product lines; they seem to spike every quarter or so, which may be a result of quarterly restocking of office supplies. As these results<a id="_idIndexMarker322"/> show, different product lines tend to show slightly different behaviors across time.</p>
    <div class="packt_tip">
      <p class="normal">Try diving deeper into segmentation and how time-series data differs by different segmentations. Try dissecting different variables, such as region, city, and sub-category!</p>
    </div>
    <h1 class="heading-1" id="_idParaDest-99">Trend and seasonality decomposition</h1>
    <p class="normal">We have seen how there are natural trends and cycles that are shown from the time-series data. By visualizing charts and utilizing moving averages, we were able to identify overall trends and seasonalities. However, there are more statistical approaches to decomposing time-series data into trend and seasonality components. Largely, there are two main ways to do time-series decomposition:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Additive</strong>: As the name suggests, the <strong class="keyWord">additive</strong> time-series decomposition method decomposes the data into trend, seasonality, and error (which is the component that cannot be explained by the overall trend and seasonality) so that when they are summed together, it can reconstruct the original time-series data:</li>
    </ul>
    <p class="center"><em class="italic">Y</em><sub class="subscript-italic" style="font-style: italic;">t</sub> = <em class="italic">Trend</em><sub class="subscript-italic" style="font-style: italic;">t</sub> + <em class="italic">Seasonality</em><sub class="subscript-italic" style="font-style: italic;">t</sub> + <em class="italic">Error</em><sub class="subscript-italic" style="font-style: italic;">t</sub></p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Multiplicative</strong>: On the other hand, the <strong class="keyWord">multiplicative</strong> time-series decomposition method decomposes the data into trend, seasonality, and error in a way that when they are multiplied together, the original time-series data can be reconstructed. The equation looks as follows:</li>
    </ul>
    <p class="center"><em class="italic">Y</em><sub class="subscript-italic" style="font-style: italic;">t</sub> = <em class="italic">Trend</em><sub class="subscript-italic" style="font-style: italic;">t</sub> * <em class="italic">Seasonality</em><sub class="subscript-italic" style="font-style: italic;">t</sub> * <em class="italic">Error</em><sub class="subscript-italic" style="font-style: italic;">t</sub></p>
    <p class="normal">Now let’s look at these methods in greater detail.</p>
    <h2 class="heading-2" id="_idParaDest-100">Additive time series decomposition</h2>
    <p class="normal">Conveniently, the <code class="inlineCode">statsmodels</code> package<a id="_idIndexMarker323"/> provides a function for easy trend and seasonality decomposition. As an example, we will decompose monthly <code class="inlineCode">Furniture</code> sales data and see what trends and seasonality it has. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> statsmodels.api <span class="hljs-keyword">as</span> sm
decomposition = sm.tsa.seasonal_decompose(
    furniture_monthly_sales, model=<span class="hljs-string">'additive'</span>
)
fig = decomposition.plot()
plt.show()
</code></pre>
    <p class="normal">As this code suggests, we are using the <code class="inlineCode">seasonal_decompose </code>function for the time-series decomposition of monthly <code class="inlineCode">Furniture</code> sales data, which is in the variable with the name <code class="inlineCode">furniture_monthly_sales</code>. Another thing to note is the <code class="inlineCode">model</code> parameter to the <code class="inlineCode">seasonal_decompose</code> function, with which you can decide whether to use additive or multiplicative approaches.</p>
    <p class="normal">This time-series<a id="_idIndexMarker324"/> decomposition can easily be visualized using the <code class="inlineCode">plot</code> function of the output of the <code class="inlineCode">seasonal_decompose</code> function. The chart should look something like the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_07.png"/></figure>
    <p class="packt_figref">Figure 4.7: Time-series decomposition plot of monthly furniture sales data</p>
    <p class="normal">The top chart shows the original time-series data, which, in our case, is the monthly <code class="inlineCode">Furniture</code> data. The second chart from the top shows the decomposed trend. As expected, there is a clear uptrend, where the sales grow year over year. The third chart is the decomposed seasonality chart. Here, it shows clear spikes in sales during September, November, and December and drops in sales during February. Lastly, the bottom chart shows the residuals or the error terms when this data is decomposed into trend and seasonality. According to the equation discussed in the previous section, these bottom three charts correspond to each decomposed component of the original time-series data.</p>
    <p class="normal">When properly decomposed, the error terms should be stationary, meaning there should not be a noticeable pattern in the residuals that are dependent on time. In our example, there is no noticeable pattern across time in the residuals, so the decomposed series seems reasonable. We can examine how well the decomposed series captures the original series by reconstructing the time-series data based on the trend and seasonality decomposition and how big a gap there is between the original series and the reconstructed<a id="_idIndexMarker325"/> series. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">reconstructed_wo_resid = decomposition.trend + decomposition.seasonal
corr = np.corrcoef(
    <span class="hljs-built_in">list</span>(furniture_monthly_sales[dates]),
    <span class="hljs-built_in">list</span>(reconstructed_wo_resid[dates])
)[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]
dist = np.sqrt(
    np.square(
        furniture_monthly_sales[dates] - reconstructed_wo_resid[dates]
    ).<span class="hljs-built_in">sum</span>()
)
rmse = np.sqrt(
    np.square(
        furniture_monthly_sales[dates] - reconstructed_wo_resid[dates]
    ).mean()
)
</code></pre>
    <p class="normal">The first line shows how we can reconstruct the time-series data using the decomposed trend and seasonality. Since we have used the additive approach for time-series decomposition in this example, we simply sum the trend and seasonality components together to get the reconstructed series.</p>
    <p class="normal">There are three metrics that we are using to measure the similarity or dissimilarity between the original series and the reconstructed series:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Correlation</strong>: Using the <code class="inlineCode">numpy</code> package’s <code class="inlineCode">corrcoef</code> function, this metric measures the similarity between the original and reconstructed series.</li>
      <li class="bulletList"><strong class="keyWord">Euclidean distance</strong>: This is the square root of the sum of the squared errors. This metric measures how big of a gap there is between the original and reconstructed series.</li>
      <li class="bulletList"><strong class="keyWord">Root mean squared error</strong> (<strong class="keyWord">RMSE</strong>): This is the square root of the mean of the squared <a id="_idIndexMarker326"/>errors. This metric measures the degree of error between the original and reconstructed series.</li>
    </ul>
    <p class="normal">The following code can be used:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Correlation: </span><span class="hljs-subst">{corr:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">\nEuclidean Distance: </span><span class="hljs-subst">{dist:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">\nRMSE: </span><span class="hljs-subst">{rmse:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">"</span>)
</code></pre>
    <p class="normal">The result should look like the following:</p>
    <pre class="programlisting con"><code class="hljs-con">Correlation: 0.95
Euclidean Distance: 15995.62
RMSE: 2665.94
</code></pre>
    <p class="normal">You can also<a id="_idIndexMarker327"/> visually compare the reconstructed series against the original series with the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">dates = reconstructed_wo_resid.dropna().index
ax = furniture_monthly_sales[dates].plot(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))
reconstructed_wo_resid[dates].plot(ax=ax, grid=<span class="hljs-literal">True</span>)
decomposition.trend[dates].plot(ax=ax, grid=<span class="hljs-literal">True</span>)
ax.set_ylabel(<span class="hljs-string">"Sales Amount"</span>)
ax.set_xlabel(<span class="hljs-string">"Order Date"</span>)
ax.set_title(<span class="hljs-string">"Monthly Furniture Sales Amount"</span>)
plt.legend([<span class="hljs-string">"Monthly Furniture Sales"</span>, <span class="hljs-string">"Reconstructed (Additive)"</span>, <span class="hljs-string">"Trend Decomposed"</span>])
plt.show()
</code></pre>
    <p class="normal">The chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_08.png"/></figure>
    <p class="packt_figref">Figure 4.8: Monthly furniture sales data along with decomposed trend and reconstructed series</p>
    <p class="normal">As you can see from this chart and as expected from the previous metrics, the reconstructed series does not capture 100% of the original series. However, they move closely together and <a id="_idIndexMarker328"/>the reconstructed series has a high degree of similarity with the original series.</p>
    <h2 class="heading-2" id="_idParaDest-101">Multiplicative time series decomposition</h2>
    <p class="normal">We will compare<a id="_idIndexMarker329"/> the results of the additive approach against the results of the multiplicative approach results to see which one captures the original time series more closely. As you may have guessed, you can replace the <code class="inlineCode">model</code> parameter of the <code class="inlineCode">seasonal_decompose</code> function with <code class="inlineCode">multiplicative</code>, as shown in the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">decomposition = sm.tsa.seasonal_decompose(
    furniture_monthly_sales, model=<span class="hljs-string">'multiplicative'</span>
)
fig = decomposition.plot()
plt.show()
</code></pre>
    <p class="normal">The resulting chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_09.png"/></figure>
    <p class="packt_figref">Figure 4.9: Time-series decomposition plot of monthly furniture sales data with the multiplicative approach</p>
    <p class="normal">This should look <a id="_idIndexMarker330"/>very similar to the chart with the additive approach. However, there are two key things that are noticeably different:</p>
    <ul>
      <li class="bulletList">The y-axis of the <em class="italic">Seasonal chart</em>, which is the second chart from the bottom, ranges from <strong class="keyWord">0</strong> to about <strong class="keyWord">2.0</strong>, whereas the y-axis of the Seasonal component of the additive chart ranges from about – 10,000 to 35,000.</li>
      <li class="bulletList">Similarly, the y-axis of the <em class="italic">Residual chart</em>, which is the bottom chart, ranges from <strong class="keyWord">0</strong> to about <strong class="keyWord">1.5</strong>.</li>
    </ul>
    <p class="normal">As you may have guessed, this is because we used the multiplicative approach in this example as opposed to the additive approach. In order to reconstruct the original series from the decomposed trend and seasonality components, we need to multiply these two components together, as in the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">reconstructed_wo_resid = decomposition.trend * decomposition.seasonal
</code></pre>
    <p class="normal">Similar to before, we can measure the degree of similarity between the reconstructed series from the multiplicative approach and the original series based on the three metrics we have used before (correlation, Euclidean distance, and RMSE) using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">corr = np.corrcoef(
    <span class="hljs-built_in">list</span>(furniture_monthly_sales[dates]),
    <span class="hljs-built_in">list</span>(reconstructed_wo_resid[dates])
)[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]
dist = np.sqrt(
    np.square(
        furniture_monthly_sales[dates] - reconstructed_wo_resid[dates]
    ).<span class="hljs-built_in">sum</span>()
)
rmse = np.sqrt(
    np.square(
        furniture_monthly_sales[dates] - reconstructed_wo_resid[dates]
    ).mean()
)
</code></pre>
    <p class="normal">The similarity measures can be viewed using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Correlation: </span><span class="hljs-subst">{corr:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">\nEuclidean Distance: </span><span class="hljs-subst">{dist:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">\nRMSE: </span><span class="hljs-subst">{rmse:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">"</span>)
</code></pre>
    <p class="normal">This gives us<a id="_idIndexMarker331"/> the following results:</p>
    <pre class="programlisting con"><code class="hljs-con">Correlation: 0.95
Euclidean Distance: 15307.16
RMSE: 2551.19
</code></pre>
    <p class="normal">If you compare these results against the previous results with the additive approach, you will notice that the Euclidean distance and RMSE are much lower with the multiplicative approach, while the correlation measure is similar. The Euclidean distance with the multiplicative approach is about <strong class="keyWord">700</strong> less than it is with the additive approach, and the RMSE with the multiplicative approach is about <strong class="keyWord">100</strong> less than it is with the additive approach. This suggests that the multiplicative decomposition approach may capture the original time-series data better in this case than the additive approach.</p>
    <p class="normal">Similarly, we can visually inspect the multiplicative approach’s reconstruction results with the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">dates = reconstructed_wo_resid.dropna().index
ax = furniture_monthly_sales[dates].plot(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))
reconstructed_wo_resid[dates].plot(ax=ax, grid=<span class="hljs-literal">True</span>)
decomposition.trend[dates].plot(ax=ax, grid=<span class="hljs-literal">True</span>)
ax.set_ylabel(<span class="hljs-string">"Sales Amount"</span>)
ax.set_xlabel(<span class="hljs-string">"Order Date"</span>)
ax.set_title(<span class="hljs-string">"Monthly Furniture Sales Amount"</span>)
plt.legend([<span class="hljs-string">"Monthly Furniture Sales"</span>, <span class="hljs-string">"Reconstructed (Additive)"</span>, <span class="hljs-string">"Trend Decomposed"</span>])
plt.show()
</code></pre>
    <p class="normal">The resulting<a id="_idIndexMarker332"/> chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_10.png"/></figure>
    <p class="packt_figref">Figure 4.10: Monthly furniture sales plot with the decomposed trend and reconstructed series with the multiplicative approach</p>
    <p class="normal">We have seen how we can decompose time-series data statistically with the <code class="inlineCode">statsmodels</code> package in this section. As previously mentioned, having an in-depth understanding of general trends as well as seasonal trends is critical in formulating product and target marketing strategies as the alignments of the marketing strategies with these trends and the timing of the actions ahead of the expected trends dictate the successes and failures of marketing campaigns. You do not want to be too late in the trend but you also do not want to be too early in the trend. This time-series decomposition technique <a id="_idIndexMarker333"/>should be a handy tool to strategize and time your marketing campaigns.</p>
    <h1 class="heading-1" id="_idParaDest-102">Time series forecasting models</h1>
    <p class="normal">The overall trends <a id="_idIndexMarker334"/>and the seasonalities bring valuable insights for efficient and timely marketing campaigns. We have discussed how time-series decomposition can help marketers put out timely promotions in order to capture the maximum sales and marketing potential when the demands are expected to rise, as well as minimize the dips and excess inventory when the demands are expected to fall via out-of-season sales promotions or focusing on the products that have different peak and trough cycles.</p>
    <p class="normal">We can take a step further <a id="_idIndexMarker335"/>with <strong class="keyWord">machine learning</strong> (<strong class="keyWord">ML</strong>) and <strong class="keyWord">artificial intelligence</strong> (<strong class="keyWord">AI</strong>) and <a id="_idIndexMarker336"/>build time-series forecasting models. The future forecasts with these AI/ML models can play a pivotal role not only for marketing but also for various other business units, including sales, operations, finance, supply chain, procurement, and many others. By utilizing time-series forecasts, marketers can optimize their marketing goals in numerous ways:</p>
    <ul>
      <li class="bulletList">If a marketing goal is to promote a <em class="italic">new product</em>, then the time-series forecast model output can inform the marketer when will be the best time to start promoting based on the expected demand rises or falls of similar product categories.</li>
      <li class="bulletList">If a marketing goal is to promote an <em class="italic">off-season sales</em> increase, then the time-series model can be built to forecast the types of off-season promotions that may result in the highest sales.</li>
      <li class="bulletList">If a marketing goal is to clean out the <em class="italic">excess inventory</em>, a time-series model that forecasts the different demands in different regions or demographics can help the marketer target certain regions or demographics for maximum efficiency in reducing the excess inventory.</li>
    </ul>
    <p class="normal">There are numerous time-series forecasting algorithms that can be used to build forecast models. Ranging from traditional statistical time-series models to more modern deep learning-based time-series models, there are various algorithms that can be used to forecast time-series data. In this section, we will experiment with the two most frequently used <a id="_idIndexMarker337"/>time-series <a id="_idIndexMarker338"/>models: ARIMA and Prophet.</p>
    <h2 class="heading-2" id="_idParaDest-103">ARIMA</h2>
    <p class="normal">The <strong class="keyWord">ARIMA</strong> model is<a id="_idIndexMarker339"/> a statistical model that is<a id="_idIndexMarker340"/> often used to predict future time-series data based on past values. ARIMA is a form of regression analysis that we discussed in <em class="chapterRef">Chapter 3</em>, but there are three key components that <a id="_idIndexMarker341"/>the ARIMA model is composed of:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Autoregression</strong>: The <strong class="keyWord">AR</strong> part of the ARIMA model</li>
    </ul>
    <p class="normal-one">Similar to <a id="_idIndexMarker342"/>what we discussed for autocorrelation, autoregression is a regression on its own lagged variables, where each lagged variable is a feature of the forecasting model.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Integrated</strong>: The <strong class="keyWord">I</strong> part<a id="_idIndexMarker343"/> of the ARIMA model</li>
    </ul>
    <p class="normal-one">This is the difference between the values and their previous values to achieve stationarity that, as discussed previously, means the errors do not depend on the time component.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Moving Average</strong>: The <strong class="keyWord">MA</strong> part of <a id="_idIndexMarker344"/>the ARIMA model</li>
    </ul>
    <p class="normal-one">As discussed previously, the moving average is an average over a rolling window and the ARIMA model regresses on these moving averages.</p>
    <p class="normal">Each of these three components – <strong class="keyWord">Autoregression</strong> (<strong class="keyWord">AR</strong>), <strong class="keyWord">Integrated</strong> (<strong class="keyWord">I</strong>), and <strong class="keyWord">Moving Average</strong> (<strong class="keyWord">MA</strong>) – in the ARIMA model has its own parameter. Typically, these parameters have notations of <em class="italic">p</em>, <em class="italic">d</em>, and <em class="italic">q</em>, and are<a id="_idIndexMarker345"/> defined as follows:</p>
    <ul>
      <li class="bulletList"><em class="italic">p</em>: The number of lag periods in the model for the AR component</li>
      <li class="bulletList"><em class="italic">d</em>: The number of times data are differenced for the I component</li>
      <li class="bulletList"><em class="italic">q</em>: The rolling window of the moving average for the MA component</li>
    </ul>
    <h3 class="heading-3" id="_idParaDest-104">Training the ARIMA model</h3>
    <p class="normal">The <code class="inlineCode">statsmodels</code> package<a id="_idIndexMarker346"/> in Python has a module that makes it easy for us to build ARIMA models. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> statsmodels.tsa.arima.model <span class="hljs-keyword">import</span> ARIMA
model = ARIMA(furniture_monthly_sales[:<span class="hljs-string">"2017-06-01"</span>], order=(<span class="hljs-number">12</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>))
model_fit = model.fit()
</code></pre>
    <p class="normal">As this code snippet shows, we are using the <code class="inlineCode">ARIMA</code> class to build an ARIMA model in Python. For the inputs for the model, we are giving the monthly furniture sales time-series data, which is the variable <code class="inlineCode">furniture_monthly_sales</code> in our case, and the parameters that we have discussed previously. As an example, we are using <code class="inlineCode">12</code> for the <em class="italic">p</em> or AR component, <code class="inlineCode">1</code> for the <em class="italic">d</em> or I component, and <code class="inlineCode">3</code> for the <em class="italic">q</em> or MA component. </p>
    <p class="normal">We recommend you try various combinations when you actually build a forecasting model with ARIMA to find the most optimal set of parameters. Here, we are training our ARIMA model up to June 2017 and we will test our predictions for July to December 2017.</p>
    <p class="normal">With the following command, we can view the trained model results:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(model_fit.summary())
</code></pre>
    <p class="normal">The model summary looks as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_11.png"/></figure>
    <p class="packt_figref">Figure 4.11: Summary of the ARIMA model fit</p>
    <p class="normal">Some of the <a id="_idIndexMarker347"/>key things to note in this model summary output are as follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">ar</strong>: These are the AR components within the ARIMA model. As we have given 12 for the AR component, there are 12 lagged variables that this model regresses on and each <code class="inlineCode">coef</code> shows the coefficient of each lag variable with the target variable.</li>
      <li class="bulletList"><strong class="keyWord">ma</strong>: These are the MA components within the ARIMA model. We have given 3 for our example for the MA component, so there are three variables that the model regresses on and each <code class="inlineCode">coef</code> shows the coefficient of each MA variable with the target variable.</li>
      <li class="bulletList"><strong class="keyWord">AIC/BIC</strong>: We won’t go into too much detail about these metrics, but the <strong class="keyWord">Akaike information criterion</strong> (<strong class="keyWord">AIC</strong>) and the <strong class="keyWord">Bayes information criterion</strong> (<strong class="keyWord">BIC</strong>) are <a id="_idIndexMarker348"/>the <a id="_idIndexMarker349"/>metrics that can be used to evaluate the model fit and compare among different models. The lower the values, the better the model fit is without overfitting.</li>
    </ul>
    <div class="packt_tip">
      <p class="normal">To find an optimal set of parameters, you will have to run numerous simulations with different sets of <code class="inlineCode">(p, q, d)</code> parameters. Or, you can also use a package, such as <code class="inlineCode">pmdarima</code>, to automatically discover the optimal parameters for <a id="_idIndexMarker350"/>the ARIMA model.</p>
      <p class="normal">Reference: <a href="https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html"><span class="url">https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html</span></a></p>
    </div>
    <h3 class="heading-3" id="_idParaDest-105">ARIMA model diagnostics</h3>
    <p class="normal">The <code class="inlineCode">statsmodels</code> package <a id="_idIndexMarker351"/>provides a handy way of diagnosing the trained ARIMA model. The <code class="inlineCode">plot_diagnostics</code> function of the <code class="inlineCode">ARIMA</code> model can be used to visualize the key diagnostic plots, as in the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">model_fit.plot_diagnostics(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">6</span>))
plt.show()
</code></pre>
    <p class="normal">The chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_12.png"/></figure>
    <p class="packt_figref">Figure 4.12: ARIMA model diagnostics plots</p>
    <p class="normal">As shown in this<a id="_idIndexMarker352"/> chart, there are four components in this diagnostic plot. Let’s dive deeper into each of these:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Standardized residuals over time (top-left chart)</strong>: This chart shows the residuals or the <a id="_idIndexMarker353"/>errors across time. For a perfect model, we would expect it to be completely random without any noticeable pattern. However, in our case, there still are some minor seasonal patterns that are noticeable.</li>
      <li class="bulletList"><strong class="keyWord">Histogram and estimated density of standardized residuals (top-right chart)</strong>: This chart shows the distribution of the standardized residuals. For a perfect model, we would expect it to show a Gaussian or normal curve with a mean of 0 and a standard deviation of 1. Our model is very close to the theoretical normal curve, which suggests that the residuals are nearly normally distributed.</li>
      <li class="bulletList"><strong class="keyWord">Normal Q-Q plot (bottom-left chart)</strong>: This chart shows theoretical quantile distributions against the actual quantile distributions of the fitted model. It suggests that the residuals are normal when the dots are closely aligned with the straight line. In our case, it is not perfect but somewhat closely aligned with the straight line, which suggests that the residuals are nearly normally distributed.</li>
      <li class="bulletList"><strong class="keyWord">Correlogram (bottom-right chart)</strong>: This chart shows the autocorrelation of residual terms across lag periods. The smaller the correlation values, the more random the residuals are. Our example shows minimal correlations that suggest that the residuals are not correlated with each other.</li>
    </ul>
    <p class="normal">In summary, these<a id="_idIndexMarker354"/> diagnostic plots tell us that the residuals are generally normally distributed in our case.</p>
    <h3 class="heading-3" id="_idParaDest-106">Forecasting with the ARIMA model</h3>
    <p class="normal">Now it is finally<a id="_idIndexMarker355"/> the time to make predictions with the ARIMA model that we have trained. Take a look at the following code first:</p>
    <pre class="programlisting code"><code class="hljs-code">pred = model_fit.get_forecast(steps=<span class="hljs-number">6</span>)
pred_ci = pred.conf_int()
</code></pre>
    <p class="normal">The <code class="inlineCode">statsmodels</code> package’s <code class="inlineCode">ARIMA</code> model provides a function named <code class="inlineCode">get_forecast</code>. The <code class="inlineCode">steps</code> parameter is used to define how many steps into the future you would like to make predictions for. It also provides a function named <code class="inlineCode">conf_int</code>, which gives a confidence band of the predictions.</p>
    <p class="normal">We can easily plot the prediction results with the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">ax = furniture_monthly_sales[<span class="hljs-string">"2015-01-01"</span>:].plot(figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">5</span>))
pred.predicted_mean.plot(
    ax=ax, grid=<span class="hljs-literal">True</span>
)
ax.fill_between(
    pred_ci.index,
    pred_ci.iloc[:, <span class="hljs-number">0</span>],
    pred_ci.iloc[:, <span class="hljs-number">1</span>],
    color=<span class="hljs-string">'cornflowerblue'</span>,
    alpha=<span class="hljs-number">.3</span>
)
ax.set_xlabel(<span class="hljs-string">'Date'</span>)
ax.set_ylabel(<span class="hljs-string">'Furniture Sales'</span>)
plt.legend([<span class="hljs-string">"Observed"</span>, <span class="hljs-string">"Forecasted"</span>])
plt.show()
</code></pre>
    <p class="normal">When you run this code, you should get a chart similar to the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_13.png"/></figure>
    <p class="packt_figref">Figure 4.13: ARIMA model prediction plot</p>
    <p class="normal">This chart shows previous monthly furniture sales data as well as the predictions and confidence band or interval for the predictions. As you may remember, we have trained the model with data up to June 2017 and we have made predictions for six steps from July 2017, which is from July to December 2017.</p>
    <p class="normal">As you can see from these predictions, the predictions from the ARIMA model are directionally well aligned with the actual observed data. Also, the actual values fall within the confidence <a id="_idIndexMarker356"/>bands, suggesting the reliability of the usage of the predictions based on the confidence intervals. One of the frequently used metrics for measuring the accuracy of time-series forecasts is RMSE, using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">rmse = np.sqrt(
    np.square(furniture_monthly_sales[<span class="hljs-string">"2017-07-01"</span>:] - pred.predicted_mean).mean()
)
rmse
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">5913.227463714012
</code></pre>
    <p class="normal">This gives us the result <code class="inlineCode">5913.227463714012</code>.</p>
    <p class="normal">Here, the RMSE of our predictions for the next 6 months was about 5913. We will compare this value against other time-series forecasting models’ values that we will experiment with in the following sections.</p>
    <div class="packt_tip">
      <p class="normal">There are many other metrics that can be used to measure the time-series model performance, aside from RMSE. Some other commonly used metrics are <strong class="keyWord">mean absolute error</strong> (<strong class="keyWord">MAE</strong>), <strong class="keyWord">mean absolute percentage error</strong> (<strong class="keyWord">MAPE</strong>), and <strong class="keyWord">mean absolute scaled error</strong> (<strong class="keyWord">MASE</strong>). Try some other regression metrics and see how they differ<a id="_idIndexMarker357"/> from each other!</p>
    </div>
    <h2 class="heading-2" id="_idParaDest-107">Prophet time-series modeling</h2>
    <p class="normal"><strong class="keyWord">Prophet</strong> is an open-source <a id="_idIndexMarker358"/>package<a id="_idIndexMarker359"/> from Meta (formerly Facebook) for time-series forecasting. Similar to the ARIMA model we have just discussed, the Prophet model also takes trend and seasonality into consideration, except there is more flexibility and more parameters you can fine-tune the time-series models with, and holiday effects are also included. So, there are largely three components in the Prophet model:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Growth (or trend)</strong>: Prophet <a id="_idIndexMarker360"/>models overall growth or trend. There are three assumptions you can make for your growth factor of the time-series data:<ul>
          <li class="bulletList level-2"><strong class="keyWord">Linear</strong>: This is the default assumption of Prophet and is used when the overall trend is expected to be linear.</li>
          <li class="bulletList level-2"><strong class="keyWord">Logistic</strong>: This should be used when there is a cap or floor in the trend of your time-series data.</li>
          <li class="bulletList level-2"><strong class="keyWord">Flat</strong>: This is when you assume there is no growth over time.</li>
        </ul>
      </li>
      <li class="bulletList"><strong class="keyWord">Seasonality</strong>: By default, this is set to <em class="italic">auto</em>, but depending on your observations within your time-series data, you can set it to model daily, weekly, or yearly seasonalities.</li>
      <li class="bulletList"><strong class="keyWord">Holidays</strong>: One of the key differentiators the Prophet has is its notion of holidays. As holidays have significant impacts on time-series outcomes, it is beneficial to be able to model holiday effects on your time-series data with Prophet.</li>
    </ul>
    <p class="normal">In this section, we are going to experiment with modeling the monthly furniture sales with Prophet.</p>
    <div class="packt_tip">
      <p class="normal">For more detailed information on the parameters that you can fine-tune with Prophet, we<a id="_idIndexMarker361"/> suggest you visit their official site (<a href="https://facebook.github.io/prophet/docs/quick_start.html"><span class="url">https://facebook.github.io/prophet/docs/quick_start.html</span></a>) or their GitHub page (<a href="https://github.com/facebook/prophet/blob/main/python/prophet/forecaster.py"><span class="url">https://github.com/facebook/prophet/blob/main/python/prophet/forecaster.py</span></a>).</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-108">Training a Prophet model</h3>
    <p class="normal">In order to train <a id="_idIndexMarker362"/>a Prophet model, make sure you have the package installed first. You can use the following command to have the package installed:</p>
    <pre class="programlisting con"><code class="hljs-con">pip install prophet
</code></pre>
    <p class="normal">The first step to training a Prophet model is to prepare the data that it expects. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> prophet <span class="hljs-keyword">import</span> Prophet
monthly_furniture_sales_df = pd.DataFrame(
    furniture_monthly_sales[:<span class="hljs-string">"2016-12-01"</span>]
).reset_index()
monthly_furniture_sales_df.columns = [<span class="hljs-string">"ds"</span>, <span class="hljs-string">"y"</span>]
</code></pre>
    <p class="normal">As you can see from this code, we are using monthly furniture data up to December 2016 as our train set. The requirements for the Prophet model for the train set are the columns <code class="inlineCode">ds</code> and <code class="inlineCode">y</code>, where <code class="inlineCode">ds</code> is for the dates and times of a given record and <code class="inlineCode">y</code> is for the time-series values.</p>
    <p class="normal">With this train set, we can easily train a Prophet model using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">model = Prophet()
model.fit(monthly_furniture_sales_df)
</code></pre>
    <p class="normal">Here, we are initializing the model with the <code class="inlineCode">Prophet</code> class and with the default parameters, which essentially instructs the model to assume linear growth trends and seasonality with no holiday effects. Then, we use the <code class="inlineCode">fit</code> function with the train set DataFrame that we have prepared previously to train the model.</p>
    <h3 class="heading-3" id="_idParaDest-109">Forecasting with a Prophet model</h3>
    <p class="normal">Now that we have a<a id="_idIndexMarker363"/> trained Prophet model, it is time to make some predictions. One thing we need to do for a Prophet model to make predictions is to generate a series of dates it should make predictions for. Prophet provides a handy function to do this, as shown in the following:</p>
    <pre class="programlisting code"><code class="hljs-code">dates = model.make_future_dataframe(periods=<span class="hljs-number">24</span>, freq=<span class="hljs-string">'MS'</span>)
</code></pre>
    <p class="normal">Here, we are using the <code class="inlineCode">make_future_dataframe</code> function. The <code class="inlineCode">periods</code> parameter defines how many future dates or periods we would like to make predictions for and the <code class="inlineCode">freq</code> parameter defines what the frequency of each future date or period should be, where we define it to be monthly with <code class="inlineCode">'MS'</code> as an input for the parameter. </p>
    <p class="normal">The newly created variable should now have dates ranging from January 2014 to December 2018. As you may remember, we have used monthly series up to December 2016 as our train set, so from January 2017 to December 2018 is essentially what we would like to make predictions for as out-of-sample predictions.</p>
    <p class="normal">You can use the following code for generating predictions with the trained model:</p>
    <pre class="programlisting code"><code class="hljs-code">forecast = model.predict(dates)
</code></pre>
    <p class="normal">The <code class="inlineCode">predict</code> function generates a DataFrame, <code class="inlineCode">forecast</code>, which contains predicted data for each period, such as predicted value, upper and lower bound, modeled trend, and so forth. Some of the key fields within the <code class="inlineCode">forecast</code> DataFrame that are the most relevant to us are as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_14.png"/></figure>
    <p class="packt_figref">Figure 14.14: Prediction results of a Prophet model</p>
    <p class="normal">The <code class="inlineCode">yhat</code> column is the predicted value for a given period and <code class="inlineCode">yhat_lower</code> and <code class="inlineCode">yhat_upper</code> are the lower and upper boundaries of the predicted confidence intervals.</p>
    <p class="normal">We can easily visualize these predictions and prediction confidence intervals with the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">fig = model.plot(forecast, uncertainty=<span class="hljs-literal">True</span>)
ax = fig.axes[<span class="hljs-number">0</span>]
outsample_dates = furniture_monthly_sales[<span class="hljs-string">"2017-01-01"</span>:].index
ax.plot(
    outsample_dates,
    furniture_monthly_sales.loc[outsample_dates],
    <span class="hljs-string">"k."</span>,
    marker=<span class="hljs-string">"x"</span>,
    color=<span class="hljs-string">"red"</span>
)
plt.legend([
    <span class="hljs-string">"actual (in-sample)"</span>, <span class="hljs-string">"predicted"</span>, <span class="hljs-string">"pred band"</span>, <span class="hljs-string">"actual (out-sample)"</span>
])
plt.show()
</code></pre>
    <p class="normal">Let’s take a closer <a id="_idIndexMarker364"/>look at this code. The Prophet model object has the <code class="inlineCode">plot</code> function, which generates a plot with predictions as a line chart, prediction intervals as an area chart, and actual values as a scatter chart. Then, we add out-of-sample data points as a scatter plot with the marker <code class="inlineCode">x</code>. This chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_15.png"/></figure>
    <p class="packt_figref">Figure 4.15: Prophet model prediction plot</p>
    <p class="normal">Similar to what<a id="_idIndexMarker365"/> we have done with the ARIMA model, we can also look at the RMSE of the Prophet model predictions using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">rmse = np.sqrt(
    np.square(
        forecast.loc[
            forecast[<span class="hljs-string">"ds"</span>].isin(outsample_dates)
        ][<span class="hljs-string">"yhat"</span>].to_numpy() - furniture_monthly_sales.loc[outsample_dates].to_numpy()
    ).mean()
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Out-Sample RMSE: </span><span class="hljs-subst">{rmse:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">"</span>)
</code></pre>
    <p class="normal">The result is as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">Out-Sample RMSE: 4295.65
</code></pre>
    <p class="normal">Compared to the RMSE of the ARIMA model, which was around 5913, the Prophet model with an RMSE of about 4295 seems to have predictions that are closer to the actuals.</p>
    <p class="normal">Lastly, Prophet also models trend and seasonality decompositions and provides an easy way to visualize them, as shown in the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">model.plot_components(forecast)
</code></pre>
    <p class="normal">The resulting<a id="_idIndexMarker366"/> chart should look as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_04_16.png"/></figure>
    <p class="packt_figref">Figure 4.16: Prophet model time-series decomposition plot</p>
    <p class="normal">Similar to what we have seen previously when we decomposed the time-series data into trend and seasonality, the Prophet model also identified an overall uptrend and spikes in December and drops in January. As we have seen so far, Prophet provides handy and reliable tools for modeling time-series data.</p>
    <p class="normal">With this knowledge, we will look at another way of modeling time-series data with a deep learning approach in the following section.</p>
    <h2 class="heading-2" id="_idParaDest-110">Other time-series models</h2>
    <p class="normal">We have discussed<a id="_idIndexMarker367"/> time-series modeling with ARIMA and Prophet in this chapter. However, there are various other algorithms and models that can be used to model time-series data. There are largely three types of approaches to time-series modeling:</p>
    <ol>
      <li class="numberedList" value="1"><strong class="keyWord">Statistical models</strong>: The<a id="_idIndexMarker368"/> statistical <a id="_idIndexMarker369"/>approaches to modeling time-series data have been around for decades. The ARIMA model is one of the most frequently used statistical models and was developed in the 1970s and is still used to date. To name a few other statistical models that are often used:<ul>
          <li class="bulletList level-2"><strong class="keyWord">Exponential smoothing</strong>: One of the oldest time-series forecasting methods, which gives more weight to recent observations for averaging time-series data points</li>
          <li class="bulletList level-2"><strong class="keyWord">Generalized AutoRegressive Conditional Heteroskedasticity (GARCH)</strong>: A frequently<a id="_idIndexMarker370"/> used model in finance that models the variance of the error terms that is dependent on time, such as increasing or decreasing volatility or variance over time</li>
          <li class="bulletList level-2"><strong class="keyWord">Seasonal ARIMA (SARIMA)</strong>: An<a id="_idIndexMarker371"/> extension of the ARIMA model that incorporates the seasonality component on top of the ARIMA components</li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord">ML models</strong>: Although <a id="_idIndexMarker372"/>not as frequently used as other statistical models and deep learning models, ML models are still used for time-series forecasting and for quick checks for predictability in time series. The advantage of ML models over statistical models is the ability to use various features when building forecasting models, whereas statistical models for time-series forecasting typically are univariate in nature. Here are some commonly used ML models:<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
          <li class="alphabeticList level-2" value="1"><strong class="keyWord">Linear regression</strong>: One of the most <a id="_idIndexMarker373"/>basic regression models in ML that can be used to model time-series data with various features. Feature engineering is the key to making a linear regression model powerful.</li>
          <li class="alphabeticList level-2"><strong class="keyWord">Tree-based models</strong>: XGBoost, which learns the data by sequentially building<a id="_idIndexMarker374"/> decision trees that learn from previous trees’ errors, or random forest, which learns the data by building a bag of decision trees that each learn subparts of the data, can be used for time-series forecasting. The ability to model interactions and relationships among various features provides an advantage in modeling time-series data that has complex intercorrelations<a id="_idIndexMarker375"/> among the features.</li>
          <li class="alphabeticList level-2"><strong class="keyWord">Support vector machine (SVM)</strong>: SVM does not perform when the dataset is <a id="_idIndexMarker376"/>noisy or the dimensionality of the dataset is large as it learns the data by finding a hyperplane that maximally separates different categories, and building such an effective hyperplane in high-dimensional<a id="_idIndexMarker377"/> space is difficult, but SVM is still used for time-series forecasting.</li>
        </ol>
      </li>
      <li class="numberedList"><strong class="keyWord">Deep learning (DL) models</strong>: With the rising accessibility and availability of compute resources, there<a id="_idIndexMarker378"/> have been lots of developments in DL-driven time-series<a id="_idIndexMarker379"/> modeling. Similar to other tasks, such as image recognition and <strong class="keyWord">Natural Language Processing</strong> (<strong class="keyWord">NLP</strong>), DL models are used more and more often to make accurate time-series forecasts:<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
          <li class="alphabeticList level-2" value="1"><strong class="keyWord">Recurrent neural network (RNN) models</strong>: RNN is a type of neural network that is <a id="_idIndexMarker380"/>designed to process sequential data. Because RNN models “remember” the previous inputs for future predictions, they work well for sequential data, such as speech and time-series data. DeepAR, ESRNN, and AR-Net are some of the RNN-based models for time-series forecasting.</li>
          <li class="alphabeticList level-2"><strong class="keyWord">Multilayer perceptron (MLP) models</strong>: MLP is a type of neural network where<a id="_idIndexMarker381"/> there are multiple layers of neurons, where each of the layers learns the data and extracts features. MLP-based models, such as N-BEATS, NHiTs, and TSMixer, typically have a deep stack of fully connected layers. This group of models is proven to work well in practice.</li>
          <li class="alphabeticList level-2"><strong class="keyWord">Transformer-based models</strong>: With the success of transformer-based models in NLP that use a multi-head attention mechanism that allows capturing different relationships and dependencies within the input, transformer-based time-series models and architectures are also actively being <a id="_idIndexMarker382"/>developed. <strong class="keyWord">Temporal Fusion Transformer</strong> (<strong class="keyWord">TFT</strong>) is an example of a transformer-based time-series forecasting model and is useful for multi-horizon and multivariate time-series forecasting.<div class="note">
              <p class="normal"><strong class="keyWord">How to build a DL model for time-series data</strong></p>
              <p class="normal">There is no<a id="_idIndexMarker383"/> shortage of Python packages that help<a id="_idIndexMarker384"/> you build time-series models. Darts, Kats, PyCaret, and PyTorch Forecasting are some of the frequently used Python packages that have easy-to-use implementations of DL models for time-series forecasting. If you’d like to see an example of N-BEATS model applications<a id="_idIndexMarker385"/> for this chapter, visit the following GitHub repository:</p>
              <p class="normal"><a href="https://github.com/yoonhwang/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.4/TimeSeriesAnalysis.ipynb"><span class="url">https://github.com/yoonhwang/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.4/TimeSeriesAnalysis.ipynb</span></a></p>
            </div>
          </li>
        </ol>
      </li>
    </ol>
    <h1 class="heading-1" id="_idParaDest-111">Summary</h1>
    <p class="normal">In this chapter, we have discussed the importance of time-series analysis and its applications for marketing. From fundamental analyses of how data progresses over time and what stories and insights can be gathered from such analyses to the development of advanced time-series forecasting models, we have touched on a wide range of topics in time-series analysis. We have seen how moving averages and autocorrelations and visualizations of them play a critical role in understanding the big picture of events happening over time. We have also covered how time-series data can be decomposed into trends and seasonalities that uncover the hidden insights of cycles within businesses and different product lines. Lastly, we have experimented with two of the frequently used statistical methods of modeling the time-series data and how to make forecasts for the future that can then be used for more efficient and timely marketing campaigns. Although not discussed in depth in this chapter, we have shared some of the other AI/ML models that are used and are in development. Make sure you check out this chapter’s GitHub repository for an example of building a DL model for time-series forecasting. We will also go deeper into DL and Generative AI later, in Part IV of this book.</p>
    <p class="normal">In the following chapter, we are going to explore language modeling and how you can benefit from it for your next marketing initiatives. We will be discussing how to use and apply some of the NLP techniques using sentiment analysis as an example and how it can equip marketers to gauge the public perception of the brand or products and monitor and refine the marketing messages for better alignment with customer preferences.</p>
    <h1 class="heading-1">Join our book’s Discord space</h1>
    <p class="normal">Join our Discord community to meet like-minded people and learn alongside more than 5000 members at:</p>
    <p class="normal"><a href="https://packt.link/genai"><span class="url">https://packt.link/genai</span></a></p>
    <p class="normal"><img alt="" src="../Images/QR_Code12856128601808671.png"/></p>
  </div>
</body></html>