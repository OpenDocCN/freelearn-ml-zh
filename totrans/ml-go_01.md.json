["```py\n1,blah1\n2,blah2\n3,blah3\n```", "```py\nimport pandas as pd\n\n# Define column names.\ncols = [\n 'integercolumn',\n 'stringcolumn'\n ]\n\n# Read in the CSV with pandas.\ndata = pd.read_csv('myfile.csv', names=cols)\n\n# Print out the maximum value in the integer column.\nprint(data['integercolumn'].max())\n```", "```py\n$ python myprogram.py\n3\n```", "```py\n1,blah1\n2,blah2\n,blah3\n```", "```py\n$ python myprogram.py\n2.0\n```", "```py\n// Open the CSV.\nf, err := os.Open(\"myfile.csv\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// Read in the CSV records.\nr := csv.NewReader(f)\nrecords, err := r.ReadAll()\nif err != nil {\n    log.Fatal(err)\n}\n\n// Get the maximum value in the integer column.\nvar intMax int\nfor _, record := range records {\n\n    // Parse the integer value.\n    intVal, err := strconv.Atoi(record[0])\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Replace the maximum value if appropriate.\n    if intVal > intMax {\n        intMax = intVal\n    }\n}\n\n// Print the maximum value.\nfmt.Println(intMax)\n```", "```py\n$ go build\n$ ./myprogram\n3\n```", "```py\n$ go build\n$ ./myprogram\n2017/04/29 12:29:45 strconv.ParseInt: parsing \"\": invalid syntax\n```", "```py\n$ head iris.csv \n5.1,3.5,1.4,0.2,Iris-setosa\n4.9,3.0,1.4,0.2,Iris-setosa\n4.7,3.2,1.3,0.2,Iris-setosa\n4.6,3.1,1.5,0.2,Iris-setosa\n5.0,3.6,1.4,0.2,Iris-setosa\n5.4,3.9,1.7,0.4,Iris-setosa\n4.6,3.4,1.4,0.3,Iris-setosa\n5.0,3.4,1.5,0.2,Iris-setosa\n4.4,2.9,1.4,0.2,Iris-setosa\n4.9,3.1,1.5,0.1,Iris-setosa\n```", "```py\n// Open the iris dataset file.\nf, err := os.Open(\"../data/iris.csv\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer f.Close()\n\n// Create a new CSV reader reading from the opened file.\nreader := csv.NewReader(f)\n```", "```py\n// Assume we don't know the number of fields per line. By setting\n// FieldsPerRecord negative, each row may have a variable\n// number of fields.\nreader.FieldsPerRecord = -1\n\n// Read in all of the CSV records.\nrawCSVData, err := reader.ReadAll()\nif err != nil {\n    log.Fatal(err)\n}\n```", "```py\n// Create a new CSV reader reading from the opened file.\nreader := csv.NewReader(f)\nreader.FieldsPerRecord = -1\n\n// rawCSVData will hold our successfully parsed rows.\nvar rawCSVData [][]string\n\n// Read in the records one by one.\nfor {\n\n    // Read in a row. Check if we are at the end of the file.\n    record, err := reader.Read()\n    if err == io.EOF {\n        break\n    }\n\n    // Append the record to our dataset.\n    rawCSVData = append(rawCSVData, record)\n}\n```", "```py\n4.3,3.0,1.1,0.1,Iris-setosa\n5.8,4.0,1.2,0.2,Iris-setosa\n5.7,4.4,1.5,0.4,Iris-setosa\n5.4,3.9,1.3,0.4,blah,Iris-setosa\n5.1,3.5,1.4,0.3,Iris-setosa\n5.7,3.8,1.7,0.3,Iris-setosa\n5.1,3.8,1.5,0.3,Iris-setosa\n```", "```py\n// We should have 5 fields per line. By setting\n// FieldsPerRecord to 5, we can validate that each of the\n// rows in our CSV has the correct number of fields.\nreader.FieldsPerRecord = 5\n```", "```py\n// rawCSVData will hold our successfully parsed rows.\nvar rawCSVData [][]string\n\n// Read in the records looking for unexpected numbers of fields.\nfor {\n\n    // Read in a row. Check if we are at the end of the file.\n    record, err := reader.Read()\n    if err == io.EOF {\n        break\n    }\n\n    // If we had a parsing error, log the error and move on.\n    if err != nil {\n        log.Println(err)\n        continue\n    }\n\n    // Append the record to our dataset, if it has the expected\n    // number of fields.\n    rawCSVData = append(rawCSVData, record)\n}\n```", "```py\n4.6,3.1,1.5,0.2,Iris-setosa\n5.0,string,1.4,0.2,Iris-setosa\n5.4,3.9,1.7,0.4,Iris-setosa\n5.3,3.7,1.5,0.2,Iris-setosa\n5.0,3.3,1.4,0.2,Iris-setosa\n7.0,3.2,4.7,1.4,Iris-versicolor\n6.4,3.2,4.5,1.5,\n6.9,3.1,4.9,1.5,Iris-versicolor\n5.5,2.3,4.0,1.3,Iris-versicolor\n4.9,3.1,1.5,0.1,Iris-setosa\n5.0,3.2,1.2,string,Iris-setosa\n5.5,3.5,1.3,0.2,Iris-setosa\n4.9,3.1,1.5,0.1,Iris-setosa\n4.4,3.0,1.3,0.2,Iris-setosa\n```", "```py\n// CSVRecord contains a successfully parsed row of the CSV file.\ntype CSVRecord struct {\n    SepalLength  float64\n    SepalWidth   float64\n    PetalLength  float64\n    PetalWidth   float64\n    Species      string\n    ParseError   error\n}\n```", "```py\n// Create a slice value that will hold all of the successfully parsed\n// records from the CSV.\nvar csvData []CSVRecord\n```", "```py\n\n// Read in the records looking for unexpected types.\nfor {\n\n    // Read in a row. Check if we are at the end of the file.\n    record, err := reader.Read()\n    if err == io.EOF {\n        break\n    }\n\n    // Create a CSVRecord value for the row.\n    var csvRecord CSVRecord\n\n    // Parse each of the values in the record based on an expected type.\n    for idx, value := range record {\n\n        // Parse the value in the record as a string for the string column.\n        if idx == 4 {\n\n            // Validate that the value is not an empty string. If the\n            // value is an empty string break the parsing loop.\n            if value == \"\" {\n                log.Printf(\"Unexpected type in column %d\\n\", idx)\n                csvRecord.ParseError = fmt.Errorf(\"Empty string value\")\n                break\n            }\n\n            // Add the string value to the CSVRecord.\n            csvRecord.Species = value\n            continue\n        }\n\n        // Otherwise, parse the value in the record as a float64.\n        var floatValue float64\n\n        // If the value can not be parsed as a float, log and break the\n        // parsing loop.\n        if floatValue, err = strconv.ParseFloat(value, 64); err != nil {\n            log.Printf(\"Unexpected type in column %d\\n\", idx)\n            csvRecord.ParseError = fmt.Errorf(\"Could not parse float\")\n            break\n        }\n\n        // Add the float value to the respective field in the CSVRecord.\n        switch idx {\n        case 0:\n            csvRecord.SepalLength = floatValue\n        case 1:\n            csvRecord.SepalWidth = floatValue\n        case 2:\n            csvRecord.PetalLength = floatValue\n        case 3:\n            csvRecord.PetalWidth = floatValue\n        }\n    }\n\n    // Append successfully parsed records to the slice defined above.\n    if csvRecord.ParseError == nil {\n        csvData = append(csvData, csvRecord)\n    }\n}\n```", "```py\nimport \"github.com/kniren/gota/dataframe\" \n```", "```py\n// Open the CSV file.\nirisFile, err := os.Open(\"iris.csv\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer irisFile.Close()\n\n// Create a dataframe from the CSV file.\n// The types of the columns will be inferred.\nirisDF := dataframe.ReadCSV(irisFile)\n\n// As a sanity check, display the records to stdout.\n// Gota will format the dataframe for pretty printing.\nfmt.Println(irisDF)\n```", "```py\n$ go build\n$ ./myprogram\n[150x5] DataFrame\n\n sepal_length sepal_width petal_length petal_width species \n 0: 5.100000 3.500000 1.400000 0.200000 Iris-setosa\n 1: 4.900000 3.000000 1.400000 0.200000 Iris-setosa\n 2: 4.700000 3.200000 1.300000 0.200000 Iris-setosa\n 3: 4.600000 3.100000 1.500000 0.200000 Iris-setosa\n 4: 5.000000 3.600000 1.400000 0.200000 Iris-setosa\n 5: 5.400000 3.900000 1.700000 0.400000 Iris-setosa\n 6: 4.600000 3.400000 1.400000 0.300000 Iris-setosa\n 7: 5.000000 3.400000 1.500000 0.200000 Iris-setosa\n 8: 4.400000 2.900000 1.400000 0.200000 Iris-setosa\n 9: 4.900000 3.100000 1.500000 0.100000 Iris-setosa\n ... ... ... ... ... \n <float> <float> <float> <float> <string>\n```", "```py\n// Create a filter for the dataframe.\nfilter := dataframe.F{\n    Colname: \"species\",\n    Comparator: \"==\",\n    Comparando: \"Iris-versicolor\",\n}\n\n// Filter the dataframe to see only the rows where\n// the iris species is \"Iris-versicolor\".\nversicolorDF := irisDF.Filter(filter)\nif versicolorDF.Err != nil {\n    log.Fatal(versicolorDF.Err)\n}\n\n// Filter the dataframe again, but only select out the\n// sepal_width and species columns.\nversicolorDF = irisDF.Filter(filter).Select([]string{\"sepal_width\", \"species\"})\n\n// Filter and select the dataframe again, but only display\n// the first three results.\nversicolorDF = irisDF.Filter(filter).Select([]string{\"sepal_width\", \"species\"}).Subset([]int{0, 1, 2})\n```", "```py\n{\n  \"last_updated\": 1495252868,\n  \"ttl\": 10,\n  \"data\": {\n    \"stations\": [\n      {\n        \"station_id\": \"72\",\n        \"num_bikes_available\": 10,\n        \"num_bikes_disabled\": 3,\n        \"num_docks_available\": 26,\n        \"num_docks_disabled\": 0,\n        \"is_installed\": 1,\n        \"is_renting\": 1,\n        \"is_returning\": 1,\n        \"last_reported\": 1495249679,\n        \"eightd_has_available_keys\": false\n      },\n      {\n        \"station_id\": \"79\",\n        \"num_bikes_available\": 0,\n        \"num_bikes_disabled\": 0,\n        \"num_docks_available\": 33,\n        \"num_docks_disabled\": 0,\n        \"is_installed\": 1,\n        \"is_renting\": 1,\n        \"is_returning\": 1,\n        \"last_reported\": 1495248017,\n        \"eightd_has_available_keys\": false\n      },\n\n      etc...\n\n      {\n        \"station_id\": \"3464\",\n        \"num_bikes_available\": 1,\n        \"num_bikes_disabled\": 3,\n        \"num_docks_available\": 53,\n        \"num_docks_disabled\": 0,\n        \"is_installed\": 1,\n        \"is_renting\": 1,\n        \"is_returning\": 1,\n        \"last_reported\": 1495250340,\n        \"eightd_has_available_keys\": false\n      }\n    ]\n  }\n}\n```", "```py\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"io/ioutil\"\n    \"log\"\n    \"net/http\"\n)\n\n// citiBikeURL provides the station statuses of CitiBike bike sharing stations.\nconst citiBikeURL = \"https://gbfs.citibikenyc.com/gbfs/en/station_status.json\"\n\n// stationData is used to unmarshal the JSON document returned form citiBikeURL.\ntype stationData struct {\n    LastUpdated int `json:\"last_updated\"`\n    TTL int `json:\"ttl\"`\n    Data struct {\n        Stations []station `json:\"stations\"`\n    } `json:\"data\"`\n}\n\n// station is used to unmarshal each of the station documents in stationData.\ntype station struct {\n    ID string `json:\"station_id\"`\n    NumBikesAvailable int `json:\"num_bikes_available\"`\n    NumBikesDisabled int `json:\"num_bike_disabled\"`\n    NumDocksAvailable int `json:\"num_docks_available\"`\n    NumDocksDisabled int `json:\"num_docks_disabled\"`\n    IsInstalled int `json:\"is_installed\"`\n    IsRenting int `json:\"is_renting\"`\n    IsReturning int `json:\"is_returning\"`\n    LastReported int `json:\"last_reported\"`\n    HasAvailableKeys bool `json:\"eightd_has_available_keys\"`\n}\n```", "```py\n// Get the JSON response from the URL.\nresponse, err := http.Get(citiBikeURL)\nif err != nil {\n    log.Fatal(err)\n}\ndefer response.Body.Close()\n\n// Read the body of the response into []byte.\nbody, err := ioutil.ReadAll(response.Body)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Declare a variable of type stationData.\nvar sd stationData\n\n// Unmarshal the JSON data into the variable.\nif err := json.Unmarshal(body, &sd); err != nil {\n    log.Fatal(err)\n}\n\n// Print the first station.\nfmt.Printf(\"%+v\\n\\n\", sd.Data.Stations[0])\n```", "```py\n$ go build\n$ ./myprogram \n{ID:72 NumBikesAvailable:11 NumBikesDisabled:0 NumDocksAvailable:25 NumDocksDisabled:0 IsInstalled:1 IsRenting:1 IsReturning:1 LastReported:1495252934 HasAvailableKeys:false}\n```", "```py\n// Marshal the data.\noutputData, err := json.Marshal(sd)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save the marshalled data to a file.\nif err := ioutil.WriteFile(\"citibike.json\", outputData, 0644); err != nil {\n    log.Fatal(err)\n}\n```", "```py\nimport (\n    \"database/sql\"\n    \"fmt\"\n    \"log\"\n    \"os\"\n\n    // pq is the library that allows us to connect\n    // to postgres with databases/sql.\n    _ \"github.com/lib/pq\"\n)\n```", "```py\n// Get the postgres connection URL. I have it stored in\n// an environmental variable.\npgURL := os.Getenv(\"PGURL\")\nif pgURL == \"\" {\n    log.Fatal(\"PGURL empty\")\n}\n\n// Open a database value. Specify the postgres driver\n// for databases/sql.\ndb, err := sql.Open(\"postgres\", pgURL)\nif err != nil {\n    log.Fatal(err)\n}\ndefer db.Close()\n```", "```py\nif err := db.Ping(); err != nil {\n    log.Fatal(err)\n}\n```", "```py\n// Query the database.\nrows, err := db.Query(`\n    SELECT \n        sepal_length as sLength, \n        sepal_width as sWidth, \n        petal_length as pLength, \n        petal_width as pWidth \n    FROM iris\n    WHERE species = $1`, \"Iris-setosa\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer rows.Close()\n```", "```py\n// Iterate over the rows, sending the results to\n// standard out.\nfor rows.Next() {\n\n    var (\n        sLength float64\n        sWidth float64\n        pLength float64\n        pWidth float64\n    )\n\n    if err := rows.Scan(&sLength, &sWidth, &pLength, &pWidth); err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Printf(\"%.2f, %.2f, %.2f, %.2f\\n\", sLength, sWidth, pLength, pWidth)\n}\n```", "```py\n// Check for errors after we are done iterating over rows.\nif err := rows.Err(); err != nil {\n    log.Fatal(err)\n}\n```", "```py\n// Update some values.\nres, err := db.Exec(\"UPDATE iris SET species = 'setosa' WHERE species = 'Iris-setosa'\")\nif err != nil {\n    log.Fatal(err)\n}\n```", "```py\n// See how many rows where updated.\nrowCount, err := res.RowsAffected()\nif err != nil {\n    log.Fatal(err)\n}\n\n// Output the number of rows to standard out.\nlog.Printf(\"affected = %d\\n\", rowCount)\n```", "```py\n// Create a cache with a default expiration time of 5 minutes, and which\n// purges expired items every 30 seconds\nc := cache.New(5*time.Minute, 30*time.Second)\n\n// Put a key and value into the cache.\nc.Set(\"mykey\", \"myvalue\", cache.DefaultExpiration)\n```", "```py\nv, found := c.Get(\"mykey\")\nif found {\n    fmt.Printf(\"key: mykey, value: %s\\n\", v)\n}\n```", "```py\n// Open an embedded.db data file in your current directory.\n// It will be created if it doesn't exist.\ndb, err := bolt.Open(\"embedded.db\", 0600, nil)\nif err != nil {\n    log.Fatal(err)\n}\ndefer db.Close()\n\n// Create a \"bucket\" in the boltdb file for our data.\nif err := db.Update(func(tx *bolt.Tx) error {\n    _, err := tx.CreateBucket([]byte(\"MyBucket\"))\n    if err != nil {\n        return fmt.Errorf(\"create bucket: %s\", err)\n    }\n    return nil\n}); err != nil {\n    log.Fatal(err)\n}\n```", "```py\n// Put the map keys and values into the BoltDB file.\nif err := db.Update(func(tx *bolt.Tx) error {\n    b := tx.Bucket([]byte(\"MyBucket\"))\n    err := b.Put([]byte(\"mykey\"), []byte(\"myvalue\"))\n    return err\n}); err != nil {\n    log.Fatal(err)\n}\n```", "```py\n// Output the keys and values in the embedded\n// BoltDB file to standard out.\nif err := db.View(func(tx *bolt.Tx) error {\n    b := tx.Bucket([]byte(\"MyBucket\"))\n    c := b.Cursor()\n    for k, v := c.First(); k != nil; k, v = c.Next() {\n        fmt.Printf(\"key: %s, value: %s\\n\", k, v)\n    }\n    return nil\n}); err != nil {\n    log.Fatal(err)\n}\n```", "```py\n$ pachctl create-repo myrepo\n```", "```py\n$ pachctl list-repo\nNAME CREATED SIZE \nmyrepo 2 seconds ago 0 B\n```", "```py\n$ cat blah.txt \nThis is an example file.\n```", "```py\n$ pachctl put-file myrepo master -c -f blah.txt \n```", "```py\n$ pachctl list-repo\nNAME CREATED SIZE \nmyrepo 10 minutes ago 25 B \n$ pachctl list-file myrepo master\nNAME TYPE SIZE \nblah.txt file 25 B\n```", "```py\n$ pachctl get-file myrepo master blah.txt\nThis is an example file.\n```"]