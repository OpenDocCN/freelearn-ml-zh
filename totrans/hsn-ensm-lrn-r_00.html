<html><head></head><body>
<div class="book" title="Preface" id="7K4G1-2006c10fab20488594398dc4871637ee"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="pref02" class="calibre1"/>Preface</h1></div></div></div><p class="calibre7">Ensemble learning! This specialized topic of machine learning broadly deals with putting together multiple models with the aim of providing higher accuracy and stable model performance. The ensemble methodology is based on sound theory and its usage has seen successful applications in complex data science scenarios. This book grabs the opportunity of dealing with this important topic.</p><p class="calibre7">Moderately sized datasets are used throughout the book. All the concepts—well, most of them—have been illustrated using the software, and R packages have been liberally used to drive home the point. While care has been taken to ensure that all the codes are error free, please feel free to write us with any bugs or errors in the codes. The approach has been mildly validated through two mini-courses based on earlier drafts. The material was well received by my colleagues and that gave me enough confidence to complete the book.</p><p class="calibre7">The Packt editorial team has helped a lot with the technical review, and the manuscript reaches you after a lot of refinement. The bugs and shortcomings belong to the author.</p><div class="book" title="Who this book is for"><div class="book"><div class="book"><div class="book"><div class="calibre12" id="calibre_pb_1"/>
</div></div></div></div></div>

<div class="book" title="Preface" id="7K4G1-2006c10fab20488594398dc4871637ee">
<div class="book" title="Who this book is for">
<div class="book">
<div class="book">
<div class="book">
<h1 class="title" id="calibre_pb_2"><a id="ch00lvl1sec06" class="calibre1"/>Who this book is for</h1></div></div></div><p class="calibre7">This book is for anyone who wants to master machine learning by building ensemble models with the power of R. Basic knowledge of machine learning techniques and programming knowledge of R are expected in order to get the most out of the book.</p></div></div>
<div class="book" title="What this book covers" id="8IL21-2006c10fab20488594398dc4871637ee"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch00lvl1sec07" class="calibre1"/>What this book covers</h1></div></div></div><p class="calibre7">
<a class="calibre1" title="Chapter 1. Introduction to Ensemble Techniques" href="part0012_split_000.html#BE6O2-2006c10fab20488594398dc4871637ee">Chapter 1</a>, <span class="strong"><em class="calibre9">Introduction to Ensemble Techniques</em></span>, will give an exposition to the need for ensemble learning, important datasets, essential statistical and machine learning models, and important statistical tests. This chapter displays the spirit of the book.</p><p class="calibre7">
<a class="calibre1" title="Chapter 2. Bootstrapping" href="part0018_split_000.html#H5A41-2006c10fab20488594398dc4871637ee">Chapter 2</a>, <span class="strong"><em class="calibre9">Bootstrapping</em></span>, will introduce the two important concepts of jackknife and bootstrap. The chapter will help you carry out statistical inference related to unknown complex parameters. Bootstrapping of essential statistical models, such as linear regression, survival, and time series, is illustrated through R programs. More importantly, it lays the basis for resampling techniques that forms the core of ensemble methods.</p><p class="calibre7">
<a class="calibre1" title="Chapter 3. Bagging" href="part0027_split_000.html#PNV61-2006c10fab20488594398dc4871637ee">Chapter 3</a>, <span class="strong"><em class="calibre9">Bagging</em></span>, will propose the first ensemble method of using a decision tree as a base model. Bagging is a combination of the words <span class="strong"><em class="calibre9">bootstrap aggregation.</em></span> Pruning of decision trees is illustrated, and it will lay down the required foundation for later chapters. Bagging of decision trees and k-NN classifiers are illustrated in this chapter.</p><p class="calibre7">
<a class="calibre1" title="Chapter 4. Random Forests" href="part0033_split_000.html#VF2I1-2006c10fab20488594398dc4871637ee">Chapter 4</a>, <span class="strong"><em class="calibre9">Random Forests</em></span>, will discuss the important ensemble extension of decision trees. Variable importance and proximity plots are two important components of random forests, and we carry out the related computations about them. The nuances of random forests are explained in depth. Comparison with the bagging method, missing data imputation, and clustering with random forests are also dealt with in this chapter.</p><p class="calibre7">
<a class="calibre1" title="Chapter 5. The Bare Bones Boosting Algorithms" href="part0042_split_000.html#181NK1-2006c10fab20488594398dc4871637ee">Chapter 5</a>, <span class="strong"><em class="calibre9">The Bare-Bones Boosting Algorithms</em></span>, will first state the boosting algorithm. Using toy data, the chapter will then explain the detailed computations of the adaptive boosting algorithm. Gradient boosting algorithm is then illustrated for the regression problem. The use of the <code class="literal">gbm</code> and <code class="literal">adabag</code> packages shows implementations of other boosting algorithms. The chapter concludes with a comparison of the bagging, random forest, and boosting methods.</p><p class="calibre7">
<a class="calibre1" title="Chapter 6. Boosting Refinements" href="part0045_split_000.html#1AT9A1-2006c10fab20488594398dc4871637ee">Chapter 6</a>, <span class="strong"><em class="calibre9">Boosting Refinements</em></span>, will begin with an explanation of the working of the boosting technique. The gradient boosting algorithm is then extended to count and survival datasets. The extreme gradient boosting implementation of the popular gradient boosting algorithm details are exhibited with clear programs. The chapter concludes with an outline of the important <code class="literal">h2o</code> package.</p><p class="calibre7">
<a class="calibre1" title="Chapter 7. The General Ensemble Technique" href="part0051_split_000.html#1GKCM1-2006c10fab20488594398dc4871637ee">Chapter 7</a>, <span class="strong"><em class="calibre9">The General Ensemble Technique</em></span>, will study the probabilistic reasons for the success of the ensemble technique. The success of the ensemble is explained for classification and regression problems.</p><p class="calibre7">
<a class="calibre1" title="Chapter 8. Ensemble Diagnostics" href="part0057_split_000.html#1MBG21-2006c10fab20488594398dc4871637ee">Chapter 8</a>, <span class="strong"><em class="calibre9">Ensemble Diagnostics</em></span>, will examine the conditions for the diversity of an ensemble. Pairwise comparisons of classifiers and overall interrater agreement measures are illustrated here.</p><p class="calibre7">
<a class="calibre1" title="Chapter 9. Ensembling Regression Models" href="part0062_split_000.html#1R42S1-2006c10fab20488594398dc4871637ee">Chapter 9</a>, <span class="strong"><em class="calibre9">Ensembling Regression Models</em></span>, will discuss in detail the use of ensemble methods in regression problems. A complex housing dataset from <code class="literal">kaggle</code> is used here. The regression data is modeled with multiple base learners. Bagging, random forest, boosting, and stacking are all illustrated for the regression data.</p><p class="calibre7">
<a class="calibre1" title="Chapter 10. Ensembling Survival Models" href="part0070_split_000.html#22O7C2-2006c10fab20488594398dc4871637ee">Chapter 10</a>, <span class="strong"><em class="calibre9">Ensembling Survival Models</em></span>, is where survival data is taken up. Survival analysis concepts are developed in considerable detail, and the traditional techniques are illustrated. The machine learning method of a survival tree is introduced, and then we build the ensemble method of random survival forests for this data structure.</p><p class="calibre7">
<a class="calibre1" title="Chapter 11. Ensembling Time Series Models" href="part0076_split_000.html#28FAO1-2006c10fab20488594398dc4871637ee">Chapter 11</a>, <span class="strong"><em class="calibre9">Ensembling Time Series Models</em></span>, deals with another specialized data structure in which observations are dependent on each other. The core concepts of time series and the essential related models are developed. Bagging of a specialized time series model is presented, and we conclude the chapter with an ensemble of heterogeneous time series models.</p><p class="calibre7">
<a class="calibre1" title="Chapter 12. What's Next?" href="part0079.html#2BASE2-2006c10fab20488594398dc4871637ee">Chapter 12</a>, <span class="strong"><em class="calibre9">What's Next?</em></span>, will discuss some of the unresolved topics in ensemble learning and the scope for future work.</p></div>

<div class="book" title="To get the most out of this book" id="9H5K1-2006c10fab20488594398dc4871637ee"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch00lvl1sec08" class="calibre1"/>To get the most out of this book</h1></div></div></div><div class="book"><ol class="orderedlist"><li class="listitem" value="1">The official website of R is the <span class="strong"><strong class="calibre8">Comprehensive R Archive Network</strong></span> (<span class="strong"><strong class="calibre8">CRAN</strong></span>) at <a class="calibre1" href="http://www.cran.r-project.org">www.cran.r-project.org</a>. At the time of writing this book, the most recent version of R is 3.5.1. This software is available for three platforms: Linux, macOS, and Windows. The reader can also download a nice frontend, such as RStudio.</li><li class="listitem" value="2">Every chapter has a header section titled <span class="strong"><em class="calibre9">Technical requirements</em></span>. It gives a list of R packages required to run the code in that chapter. For example, the requirements for <a class="calibre1" title="Chapter 3. Bagging" href="part0027_split_000.html#PNV61-2006c10fab20488594398dc4871637ee">Chapter 3</a>, <span class="strong"><em class="calibre9">Bagging</em></span>, are as follows:<div class="book"><ul class="itemizedlist1"><li class="listitem">class</li><li class="listitem">FNN</li><li class="listitem">ipred</li><li class="listitem">mlbench</li><li class="listitem">rpart</li></ul></div></li></ol><div class="calibre13"/></div><p class="calibre7">The reader then needs to install all of these packages by running the following lines in the R console:</p><div class="informalexample"><pre class="programlisting">install.packages("class")
install.packages("mlbench")
install.packages("FNN")
install.packages("rpart")
install.packages("ipred")</pre></div></div>

<div class="book" title="To get the most out of this book" id="9H5K1-2006c10fab20488594398dc4871637ee">
<div class="book" title="Download the example code files"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch00lvl2sec01" class="calibre1"/>Download the example code files</h2></div></div></div><p class="calibre7">You can download the example code files for this book from your account at <a class="calibre1" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a class="calibre1" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files emailed directly to you.</p><p class="calibre7">You can download the code files by following these steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Log in or register at <a class="calibre1" href="http://www.packtpub.com">http://www.packtpub.com</a>.</li><li class="listitem" value="2">Select the <span class="strong"><strong class="calibre8">SUPPORT</strong></span> tab.</li><li class="listitem" value="3">Click on <span class="strong"><strong class="calibre8">Code Downloads &amp; Errata</strong></span>.</li><li class="listitem" value="4">Enter the name of the book in the <span class="strong"><strong class="calibre8">Search</strong></span> box and follow the on-screen instructions.</li></ol><div class="calibre13"/></div><p class="calibre7">Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p><div class="book"><ul class="itemizedlist"><li class="listitem">WinRAR / 7-Zip for Windows</li><li class="listitem">Zipeg / iZip / UnRarX for Mac</li><li class="listitem">7-Zip / PeaZip for Linux</li></ul></div><p class="calibre7">The code bundle for the book is also hosted on GitHub at <a class="calibre1" href="https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-R">https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-R</a>. In case there's an update to the code, it will be updated on the existing GitHub repository.</p><p class="calibre7">We also have other code bundles from our rich catalog of books and videos available at <a class="calibre1" href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</p></div></div>

<div class="book" title="To get the most out of this book" id="9H5K1-2006c10fab20488594398dc4871637ee">
<div class="book" title="Download the color images"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch00lvl2sec02" class="calibre1"/>Download the color images</h2></div></div></div><p class="calibre7">We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a class="calibre1" href="http://www.packtpub.com/sites/default/files/downloads/HandsOnEnsembleLearningwithR_ColorImages.pdf">http://www.packtpub.com/sites/default/files/downloads/HandsOnEnsembleLearningwithR_ColorImages.pdf</a>.</p></div></div>

<div class="book" title="To get the most out of this book" id="9H5K1-2006c10fab20488594398dc4871637ee">
<div class="book" title="Conventions used"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch00lvl2sec03" class="calibre1"/>Conventions used</h2></div></div></div><p class="calibre7">There are a number of text conventions used throughout this book.</p><p class="calibre7">
<code class="literal">CodeInText</code>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. For example; "The computation of the values of the density functions using the <code class="literal">dexp</code> function."</p><p class="calibre7">A block of code is set as follows:</p><div class="informalexample"><pre class="programlisting">&gt; Events_Prob &lt;- apply(Elements_Prob,1,prod)
&gt; Majority_Events &lt;- (rowSums(APC)&gt;NT/2)
&gt; sum(Events_Prob*Majority_Events)
[1] 0.9112646</pre></div><p class="calibre7">
<span class="strong"><strong class="calibre8">Bold</strong></span>: Indicates a new term, an important word, or words that you see on the screen, for example, in menus or dialog boxes, also appear in the text like this. For example: "Select <span class="strong"><strong class="calibre8">System info</strong></span> from the <span class="strong"><strong class="calibre8">Administration</strong></span> panel."</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note01" class="calibre1"/>Note</h3><p class="calibre7">Warnings or important notes appear in a box like this.</p></div><div class="informalexample" title="Note"><h3 class="title2"><a id="tip01" class="calibre1"/>Tip</h3><p class="calibre7">Tips and tricks appear like this.</p></div></div></div>

<div class="book" title="Get in touch" id="AFM61-2006c10fab20488594398dc4871637ee"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch00lvl1sec09" class="calibre1"/>Get in touch</h1></div></div></div><p class="calibre7">Feedback from our readers is always welcome.</p><p class="calibre7">
<span class="strong"><strong class="calibre8">General feedback</strong></span>: Email <code class="literal">&lt;<a class="calibre1" href="mailto:feedback@packtpub.com">feedback@packtpub.com</a>&gt;</code>, and mention the book's title in the subject of your message. If you have questions about any aspect of this book, please email us at <code class="literal">&lt;<a class="calibre1" href="mailto:questions@packtpub.com">questions@packtpub.com</a>&gt;</code>.</p><p class="calibre7">
<span class="strong"><strong class="calibre8">Errata</strong></span>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book we would be grateful if you would report this to us. Please visit, <a class="calibre1" href="http://www.packtpub.com/submit-errata">http://www.packtpub.com/submit-errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p><p class="calibre7">
<span class="strong"><strong class="calibre8">Piracy</strong></span>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <code class="literal">&lt;<a class="calibre1" href="mailto:copyright@packtpub.com">copyright@packtpub.com</a>&gt;</code> with a link to the material.</p><p class="calibre7">
<span class="strong"><strong class="calibre8">If you are interested in becoming an author</strong></span>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a class="calibre1" href="http://authors.packtpub.com">http://authors.packtpub.com</a>.</p></div>

<div class="book" title="Get in touch" id="AFM61-2006c10fab20488594398dc4871637ee">
<div class="book" title="Reviews"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch00lvl2sec04" class="calibre1"/>Reviews</h2></div></div></div><p class="calibre7">Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p><p class="calibre7">For more information about Packt, please visit <a class="calibre1" href="http://packtpub.com">packtpub.com</a>.</p></div></div></body></html>