- en: Decomposing CO2 Trends Using Time Series Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are reading this book in the year 2055—assuming you're still using a
    year system based on the Common Era (a year is the time taken by the planet you're
    on to go around the sun once)—congratulations! You have survived. This book is
    written in the year 2018, and we as humans have much to worry about in terms of
    the survival of our species.
  prefs: []
  type: TYPE_NORMAL
- en: 'By and large, we have managed to work our way into a relatively stable peace,
    but the future of our species as a whole is somewhat at risk from various threats.
    Most of these threats have been caused by our own actions in the past. I''d like
    to emphasize a point here: I''m not assigning blame to anyone in the past for
    causing these threats. Our ancestors were busy optimizing to different goals,
    and the threats are typically an unforeseen/unforeseeable side-effect of the actions
    at that time.'
  prefs: []
  type: TYPE_NORMAL
- en: A compounding factor is that humans are, biologically speaking, not very well
    suited to thinking about the future. Our brains simply do not see our future selves
    as a continuity of our current selves [0],[1]. As a result, we often think of
    things that may happen to us in the future as things that happen to someone else,
    or that the future is exaggerated. This has led to decisions made today without
    consideration to the effect in the future. This has led to many threats that arise
    from past actions of our species.
  prefs: []
  type: TYPE_NORMAL
- en: One of those threats is runaway climate change that could ruin our entire way
    of living, and potentially threaten the entire human species with extinction.
    It is very real and very unexaggerated. Human-induced climate change is a very
    wide topic with many niches. The primary gist of the major cause of human-induced
    climate change is the increased rates release of **carbon dioxide** (**CO[2]**)
    into the air.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will perform a time series analysis on CO[2] in the air.
    The main goal of this chapter is to serve as an introduction to time series analysis.
    On the technical end, you will learn the finer side of plotting using **Gonum**.
    Also, we'll learn how to deal with non-conventional data formats.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The amount of CO[2] in the air can be measured. The **National Oceanic and Atmospheric
    Administration** (**NOAA**) department has been collecting data on the amount
    of CO[2] in the air since the early 1950s. The data we'll be using can be found
    at [https://www.esrl.noaa.gov/gmd/ccgg/trends/data.html](https://www.esrl.noaa.gov/gmd/ccgg/trends/data.html).
    We'll specifically be using that Mauna Loa monthly mean data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data, after removing the comments, looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In particular, we are interested in the `interpolated` column.
  prefs: []
  type: TYPE_NORMAL
- en: Because this is a particularly interesting dataset, it might be worth looking
    at how to download and preprocess the data directly in Go.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading from non-HTTP sources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll start by writing the function that will download the data, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The NOAA data sits on a publicly accessible FTP server: [ftp://aftp.cmdl.noaa.gov/products/trends/co2/co2_mm_mlo.txt](ftp://aftp.cmdl.noaa.gov/products/trends/co2/co2_mm_mlo.txt).
    If you visit the URI via a web browser, you would see the data immediately. To
    access the data programmatically is a little tricky, as this is not a typical
    HTTP URL.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle FTP connections, we will be using the `github.com/jlaffaye/ftp` package.
    The package can be installed using the standard `go get` method: `go get -u github.com/jlaffaye/ftp`.
    The documentation for the package is a little sparse and somewhat requires you
    to understand the FTP standards. But, fear not, using FTP to acquire the file
    is relatively simple.'
  prefs: []
  type: TYPE_NORMAL
- en: First we need to dial in to the server (you would need to do the same if you
    were working with HTTP endpoints—`net/http` merely abstracts out the dialing in
    so you wouldn't necessarily see what's happening in the background). Because dialing
    in is a fairly low-level procedure, we would need to supply the ports as well.
    Just like the convention for HTTP is for the server to listen on port `80`, the
    convention for an FTP server is to listen to port `21`, so we'd have to connect
    to a server specifying that we want to connect on port `21`.
  prefs: []
  type: TYPE_NORMAL
- en: An additional oddity to those not used to working with FTP is that FTP requires
    a login to the server. For servers with anonymous read-only access, the convention
    is typically to use "anonymous" as the username and password.
  prefs: []
  type: TYPE_NORMAL
- en: After successfully logging in, we retrieve the requested resource (the file
    that we want) and download the file. The `fttp` library at [github.com/jlaffaye/ftp](https://github.com/jlaffaye/ftp) returns
    `io.Reader.` Think of it as a file that contains the data.
  prefs: []
  type: TYPE_NORMAL
- en: Handling non-standard data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Parsing the data is a piece of cake with only the standard library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The parsing function takes a `loader`, which when called, returns a `io.Reader`.
    We then wrap the `io.Reader` in a `bufio.Scanner`. Recall that the format is not
    standard. There are some things that we want and some things we don't. The data
    however is in a fairly consistent format—we can use the standard library functions
    to filter the ones we want and the ones we don't.
  prefs: []
  type: TYPE_NORMAL
- en: The `s.Scan()` method scans `io.Reader` until it encounters a newline. We can
    retrieve the string using `s.Text()`. If the string starts with `#`, we skip the
    line.
  prefs: []
  type: TYPE_NORMAL
- en: Otherwise, we use `strings.Fields` to split the string into fields. The reason
    why we use `strings.Fields` instead of `strings.Split` is because the latter does
    not handle multiple spaces well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the splitting of the row into fields, we parse things that are necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Why do we need a `loader` type?
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason is simple: we want to be good citizens— we should not be repeatedly
    requesting data from the FTP server while we are developing the program. Rather,
    we would cache the file and work with that single file while in development mode.
    This way, we wouldn''t have to download from the internet all the time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The corresponding `loader` type that reads from the file looks something like
    this, and is rather self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Dealing with decimal dates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the more interesting custom formats used in this data is dates. It''s
    a format known as **decimal dates**. They look like as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'What this means is that this date represents the halfway point of the year
    2018\. There are 365 days in 2018\. The 50% mark would be 183 days into the year:
    July 3 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can translate this logic into the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step is to split the string into the year and the decimal portion.
    The year is parsed as an `int` datatype, while the decimal part is parsed as a
    floating point number to ensure we can perform math. Here, it''s important to
    note that a bug can happen if you''re not careful about it: after splitting the
    string, `"0."` needs to be prepended to the string.'
  prefs: []
  type: TYPE_NORMAL
- en: A cleaner alternative would be to parse the string as `float64`, and then use
    `math.Modf` to split the float into the integer component and the decimal component.
  prefs: []
  type: TYPE_NORMAL
- en: Either way, once we have the decimal component, we can use it to figure out
    how many days into the year it is. But first we'd have to figure out if the year
    is a leap year.
  prefs: []
  type: TYPE_NORMAL
- en: We can calculate the number of days into the years simply by multiplying the
    decimal number by the number of days in the year. Following from that, we simply
    add the number of dates, and return the date.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to note is that we pass in a `*time.Location`—in this specific instance,
    we know that the observatory is in Hawaii, and therefore we set it to `"Pacific/Honolulu"`.
    Although in this case, we could set the location to any other location in the
    world, and it wouldn't change the results of the data. But this is unique to this
    project—in other time series data, time zones may be important as the data collection
    method may involve time data from different time zones.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we''ve finished with getting the file and parsing it, let''s plot
    the data. Again, as in [Chapter 2](12c81095-6fcf-4da9-b554-6367d45b34f8.xhtml),
    *Linear Regression-House Price Prediction*,we will be using Gonum''s excellent
    plotting library. This time around, we''re going to be exploring more of it in
    detail. We''ll learn the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How to plot a time series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How a plot breaks down into its elements and how we can manipulate those elements
    to style a chart
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create plotters for chart types that Gonum does not provide for
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We''ll start by writing a function to plot a time series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use the already familiar `plotter.XYs` (which you would have been acquainted
    with in the first chapter). Instead of using `plotutil.AddLines` as we did the
    last time, we shall do it manually, which allows us to control the styling of
    the lines a bit better.
  prefs: []
  type: TYPE_NORMAL
- en: We simply create a new `*Line` object with `plotter.NewLine`. The `*Line` object
    is primarily `plot.Plotter`, which is any type that can draw itself onto a canvas.
    In the later part of this chapter, we shall explore how to create our own `plot.Plotter` interface
    and other associated types to draw a custom type.
  prefs: []
  type: TYPE_NORMAL
- en: Styling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'But, for now, having access to the `*Line` object allows us to play around
    with the styling a bit more. To set the right mood with the rather gloomy nature
    of this chapter, I have chosen a stark black line (in fact, I have grown rather
    fond of the stark black line charts and have started using them in my daily plots
    as well). A point to note is that I did this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`l.LineStyle.Color` takes `color.Color`—`color.RGBA` is a struct found in the
    `color` library in the standard library. It''s a struct that has four fields representing
    a color, such as `Red`, `Green`, `Blue`, and `Alpha`. Here I take advantage of
    Go''s default values—0s. But having an `Alpha` value of `0` would mean that it''s
    invisible. Hence, I only set the `A` field to `255`—the rest of the fields are
    defaulted to `0`, which gives it a stark black color.'
  prefs: []
  type: TYPE_NORMAL
- en: After we set the line style, we add the line to the plot with `p.Add(l)`. Because
    we're not using `plotutil.AddLines`, which abstracts away some of the manual work,
    we may find that if we run the function there isn't a legend in the plot. A plot
    without legends is generally useless. So, we also need to add a legend by using
    `p.Legend.Add(seriesName, l)`.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from color, width, and the like, I also want to set a more brutal feel
    to the plots I make for this chapter—after all, this chapter is rather doom and
    gloom. I feel that the default font, which is Times New Roman is a little too
    humanist. So, we'd need to change fonts. Luckily, the extended Go standard library
    comes with a font-processing library. While usually I'd choose to go with slab
    serif style fonts for the brutal look, Go itself comes with a font that works
    well—the Go family of fonts.
  prefs: []
  type: TYPE_NORMAL
- en: How do we change fonts in a `*plot.Plot`? Most components of `*plot.Plot` take
    a `draw.TextStyle`, which is a data structure that configures the styling of text,
    including fonts. So, we can set those fields to indicate we want to use the font
    we chose.
  prefs: []
  type: TYPE_NORMAL
- en: 'As I mentioned, in the extended standard library, Go comes with fonts and font-processing
    utilities. We''ll be using it here. First, we''d have to install the packages:
    `go get -u golang.org/x/image/font/gofont/gomono` and `go get -u github.com/golang/freetype/truetype`.
    The former is the official **Monospace Type** of the Go family of typefaces. The
    latter is a library to handle TrueType fonts.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, a caveat must be mentioned—while `draw.TextStyle` does allow for the configuration
    of fonts, the fonts are in a `vg.Font` type, which wraps a `*truetype.Font` type.
    If we use `truetype.Parse(gomono.TTF)`, we will get `*truetype.Font`. The `vg` package
    provides a function to make those fonts—`vg.MakeFont`. The reason why this is
    necessary instead of just using `*truetype.Font` is because `vg` has plenty of
    backends—some that could render fonts would require information about the font
    size.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to avoid having many calls to parse the font and making a `vg.Font` type,
    we can safely put it in a global variable, given we''ve already decided ahead
    that all fonts will be of the same brutal style:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Once that''s done, we can set all `draw.TextStyle.Font` to be `defaultFont`.
    Setting a default font size of 12 does not, however, mean that you''re stuck with
    the size for everything. Because `vg.Font` is a struct, not a pointer to a struct,
    once set in an object, you are free to change the font size of that particular
    field, as I have shown in the following two lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'With our `main` function we can execute the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is stark , as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18f0f7aa-e074-4ee2-a7d5-df9335a9c668.png)'
  prefs: []
  type: TYPE_IMG
- en: Decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two things to note about the previous screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: CO[2] levels in the air are steadily rising over time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are dips and then bumps in the levels of CO[2], but the result still ends
    up rising overall. These dips and bumps happen on a regular pattern.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first point is what is known to statisticians as a **trend**. You may already
    be familiar with the notion of a Trend Line from Microsoft Excel. A trend is a
    kind of pattern that describes gradual change over time. In our case, it is quite
    clear that the trend is upward.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second point is called **seasonality**—for very apt reasons, as it may
    turn out. Seasonality describes the pattern of variance that happens regularly.
    If you carefully look at the chart, typically at around August to October of each
    year, the CO[2] levels drop to the lowest point of the year. After which, they
    rise steadily again until around May, where they peak. Here''s a good hint as
    to why this happens: plants suck CO[2] from the air through a process called **photosynthesis**.
    Photosynthesis requires a organelle in a plant''s cell called a **chloroplast**,
    which contains a green pigment called **chlorophyll**. If you live in the Northern
    Hemisphere, you would be well aware that trees are greenest from Spring till Autumn.
    This largely coincides with the period from May till October. The changing of
    seasons cause a change in atmospheric carbon dioxide levels. You can certainly
    see why the term "seasonality" is quite apt.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A good question to ask  might be this: Can we separate the trend out from the
    seasonality so that we may be able to work on each component individually? The
    answer is yes, we can. In fact, in the remaining parts of this section, I''ll
    show how to do so.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, as to why you would want to do that, well, in our project so far, we've
    seen seasonalities that are affected by real-life calendar seasons. Imagine you
    were doing statistical analysis for a toy company in a Western country. You'd
    see a yearly spike around Christmas time. Often seasonality adds noise to our
    analysis—it's hard to tell whether a bump in sales was due to Christmas time or
    an actual increase in sales. Furthermore, there are some cycles that don't necessarily
    follow the calendar year. If you are dealing with sales in a largely Chinese/Vietnamese
    community, you'd see spikes in sales before Chinese New Year/Tet. Those do not
    follow our calendar year. Ditto, if you were in the dates industry—you'd see spikes
    around Ramadan as demand for dates increases sharply during the Muslim fasting
    period.
  prefs: []
  type: TYPE_NORMAL
- en: While it's true that most time series would have some kind of trend and seasonality
    component, it would be remiss for me to mention that not all trends and seasonalities
    are particularly useful. You might be tempted to take what you learn in this chapter
    and apply it on the stock markets but buyer beware! Analyzing complex market places
    is quite different from analyzing trends of CO[2] in the air or sales from a business.
    The fundamental properties of time series in markets are somewhat different—it's
    a process that has the Markov property, which is best described as **past performance
    does not indicate future performance**. By contrast, we shall see, for this project,
    that the past is quite well correlated with the present and the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'But back to the topic at hand—decomposition. If you read the comments on the
    data file (the lines we skipped from importing), the following is mentioned:'
  prefs: []
  type: TYPE_NORMAL
- en: '"First, we compute for each month the average seasonal cycle in a 7-year window
    around each monthly value. In this way, the seasonal cycle is allowed to change
    slowly over time. We then determine the "trend" value for each month by removing
    the seasonal cycle; this result is shown in the "trend" column."'
  prefs: []
  type: TYPE_NORMAL
- en: STL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: But how does one calculate a seasonal cycle? In this section, we'll be using
    an algorithm invented in the late 1980s called **Seasonal and Trend Decomposition** (**STL**)
    by LOESS by Cleveland et al. I wrote a library that implements that. You can install
    it by running `go get -u github.com/chewxy/stl`.
  prefs: []
  type: TYPE_NORMAL
- en: The library is really small—there is only one `main` function to call (`stl.Dcompose`),
    and the library comes with a litany of features to aid with decomposition of data.
  prefs: []
  type: TYPE_NORMAL
- en: Despite that, I think it would be a good idea to have a rough understanding
    of the STL algorithm before using it, as usage requires knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: LOESS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The thing that powers STL is the notion of local regression—LOESS itself is
    a terrible acronym formed from **LO**cal regr**ESS**ion—whatever drugs the statisticians
    were on in the 1990s, sign me up for them. We're already familiar with the idea
    of linear regression from [Chapter 1](3d68e167-a44d-4195-a270-f8180ff8f85f.xhtml),
    *How to Solve All Machine Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that the role of linear regression is that given a straight line function: ![](img/f064c2e5-f70b-4a80-a051-c6cee555629e.png).
    We want to estimate ![](img/44aac8a5-8a88-4adf-8423-9f978c3c58b9.png) and ![](img/7a3e53ed-c83b-448e-8ec3-50662b599ee7.png).
    Instead of trying to fit the whole dataset at once, what if we broke the dataset
    up into many small **local** components, and ran a regression on each small dataset?
    Here''s an example of what I mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding table is a function representing ![](img/dd55f36b-8373-4801-819c-016180524f17.png).
    Instead of pulling in the entire dataset for a regression, what if we did a running
    regression of every three rows? We''d start with row 2 (x = -0.9). And the data
    points under consideration are `1` before it and `1` after it (*x = -1* and *x
    = -0.8*). And for row 3, we''d do a linear regression using row `2`, `3`, `4`
    as data points. At this point, we''re not particularly interested in the errors
    of the local regression. We just want an estimate of the gradient and the crossings.
    Here''s the resulting table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In fact, we can show that if you plot each line individually, you will have
    a somewhat "curved" shape. So, here''s a side program I wrote to plot this out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will see how to plot the original function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code yields a chart, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8f5286c-098a-47da-adde-0df30cd3c54b.png)'
  prefs: []
  type: TYPE_IMG
- en: Most of the code will be explained in the latter parts of this chapter, but,
    for now, let's focus on the fact that you can indeed run many small linear regressions
    on "local" subsets of the data to plot a curve.
  prefs: []
  type: TYPE_NORMAL
- en: 'LOESS brings this idea further, by stating that if you have a window of values
    (in the toy example, we used `3`), then the values should be weighted. The logic
    is simple: the closer a value is to the row in consideration, the higher the weight.
    If we had used a window size of `5`, then when considering row `3`, `2`, and `4`
    would be weighted more heavily than rows `1` and `5`. This **width**, it turns
    out, is important to our smoothing.'
  prefs: []
  type: TYPE_NORMAL
- en: The subpackage, `"github.com/chewxy/stl/loess"`, implements LOESS as a smoothing
    algorithm. Do read through the code if you're interested in knowing more about
    the details.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recall that our goal is to split a time series into seasonality and trend. Obviously,
    once we've removed the seasonality and trend, there will be some remaining parts.
    We call those **residuals**. So, how do we do it?
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm has a lot of fine tuning for the sake of robustness. I will elide
    on explaining on the various robustness optimizations performed, but I think it
    is important to have a rough idea of how the algorithm works in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a rough overview of the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate trend (on the first loop, the trend is all 0s).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subtract the trend from the input data. This is called **detrending**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Cycle subseries smoothing: the data is partitioned into `N` subcycles. Each
    subcycle corresponds to a period. The data is then smoothed using LOESS. The result
    is a temporary seasonal dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each temporary seasonal dataset (one per period), we perform a low pass
    filter—we keep the values with a low frequency.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The low pass filtered values are subtracted from temporary seasonal dataset.
    This is the seasonal data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subtract the seasonal data from the input data. This is the new trend data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iterate step 1 to step 6 until the number of iterations is desired. This is
    typically 1 or 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, the algorithm is iterative—each iteration improves on the trend,
    which is then used to find the new seasonal data, which is then used to update
    the trend, and so on and so forth. But there is a very important blink-and-you-miss-it
    "magic" that STL relies on.
  prefs: []
  type: TYPE_NORMAL
- en: 'And so we come to the second important reason to understand the algorithm:
    **STL is dependent upon the definition of how many periods the dataset has**.'
  prefs: []
  type: TYPE_NORMAL
- en: Using STL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To recap, there are two important parts that are fundamental to the STL algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: The **width** used for smoothing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **periods** in the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we look at the CO[2] dataset, we can count the periods by counting the
    number of peaks in the chart. I counted 60 peaks. This corresponds to the fact
    that the observatory has been collecting data for the past 60 years.
  prefs: []
  type: TYPE_NORMAL
- en: From here, we move from the hard sciences of statistics into the softer realms
    of interpretation. This is often true in data science and machine learning—we
    often have to use our intuition to guide us.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we have a hard starting point: there has been 60 years so we
    expect at least 60 periods. Another starting point can be found in the notes of
    the dataset itself: the NOAA uses a seven-year window to calculate the seasonal
    component. I don''t see any reason to not use those values. So, let''s decompose
    our time series into the **trend**, **seasonal**, and **residual** components.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But before we begin, there is an additional note to make: we want to decompose
    the time series into three components, but how do these three components recompose
    to become whole again? In general, there are two methods: additive or multiplicative.
    Simply put, we can decompose the data as either one of the following equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/401f677e-a121-48ed-89e2-b6fb91b10c77.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This can also be stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4f5383b7-4228-4077-87d3-c6448772a58a.png)'
  prefs: []
  type: TYPE_IMG
- en: The `github.com/chewxy/stl` package supports both models, and even supports
    custom models that fall "in-between" additive and multiplicative models.
  prefs: []
  type: TYPE_NORMAL
- en: '**When to use an additive model**: Use an additive model when the seasonality
    does not vary with the level of the time series. Most standard business case time
    series fall in this category.'
  prefs: []
  type: TYPE_NORMAL
- en: '**When to use a multiplicative model**: Use a multiplicative model when the
    seasonality or trend does vary with the level of the time series. Most econometric
    models fall in this category.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the purpose of this project, we will be using an additive model. Here''s
    the `main` function again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s break this down; in particular, the parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following terms from the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`12`: We counted 60 periods. The data is monthly data; therefore, it would
    make sense that a period takes 12 months, or as we know it—a year.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`84`: We use the smoothing window as specified by the NOAA. Seven years is
    84 months.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stl.Additive()`: We want to use an additive model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stl.WithIter(1)`: STL is fairly sensitive to the number of iterations run.
    The default is `2`. But if you run it too many times, everything gets iteratively
    "smoothed" out. So, instead, we stick with `1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following sections, I'll show examples of misuse and why despite everything, 1
    and 2 are still pretty good iteration counts.
  prefs: []
  type: TYPE_NORMAL
- en: You may note that instead of specifying the number of periods, we specified
    the length of a period. The package expects the data to be evenly spaced—the distance
    between any two rows should be the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this yields the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d3062fd-419f-4ef8-b71b-3bf621deb3c4.png)'
  prefs: []
  type: TYPE_IMG
- en: The first chart is the original data, followed by the extracted trend and seasonality,
    and, finally, the residuals. There remains some weirdness with regards to the
    beginning of the graph, but that artifact is solely due to the fact that the `github.com/chewxy/stl`
    library does not "backcast". Hence, it's always a good idea to start with at least
    one extra period.
  prefs: []
  type: TYPE_NORMAL
- en: How to interpret the plot? Well, since this is an additive model, interpretation
    is a lot simpler—the `Y` values indicate the ppm of carbon dioxide in the air
    that each component contributes to the actual data, so the first chart is literally
    the result of adding the bottom charts together.
  prefs: []
  type: TYPE_NORMAL
- en: How to lie with statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is important to note that these parameters essentially control how much to
    attribute the CO[2] in the atmosphere to each component. And these controls are
    rather subjective. The `stl` package offers a lot of control over how a time series
    is decomposed, and I think it's up to the data scientist or statistician reading
    this book (that is you), to do statistics responsibly.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we said that a period was five years? Keeping everything the same,
    we can use the following code and find out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following chart is produced:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5158c053-0d20-4eba-b007-5635417914cb.png)'
  prefs: []
  type: TYPE_IMG
- en: We could then take this chart and parade the top two sections and say "Look!
    Statistics tells us that despite the data looking like it's going up, it's in
    fact trending down. Hashtag science."
  prefs: []
  type: TYPE_NORMAL
- en: You're of course free to do so. But I know you're not a dishonest person. Instead,
    I hope that you are reading this book with good intentions of saving the world.
  prefs: []
  type: TYPE_NORMAL
- en: 'But knowing the correct parameters to use is difficult. One suggestion I have
    is to go to extremes and then come back down. This is what I mean—we have a rough
    idea of how the STL algorithm works. A known controlling factor is the iteration
    count, which defaults to 2\. Here''s the original correct version, with 1, 2,
    5, 10, 20, and 100 iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28ab26b1-2529-420e-9616-f6bff601de06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Interations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/196427d7-6a3c-4edd-ad52-c7a2480c6d19.png)![](img/3d4a4d29-ea3e-49db-b06d-037c6b16b5f3.png)![](img/119460c2-8b34-4580-86e1-7140ad61bf0a.png)![](img/f7f12afb-c01f-4777-b99d-2213193305b1.png)![](img/c52bcaa6-f1f1-42f8-913a-b3c5b8529520.png)'
  prefs: []
  type: TYPE_IMG
- en: Over the iterations, having been smoothed iteratively, the seasonality loses
    its jaggedness. Nonetheless, the shape of the trend stays the same. Therefore,
    in this case, increasing the iteration counts merely shifts the seasonal contribution
    to the trend component. This implies that the trend component is the stronger
    "signal" of sorts.
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, if we run the "lies" version, we see that at two iterations, the
    shape of the trend changes, and by the 10th iteration onward, the shape of the
    trend stays the same. This gives us a clue as to what the "real" trend is.
  prefs: []
  type: TYPE_NORMAL
- en: With STL, the thing that we're really controlling is the seasonality. What we're
    saying to the algorithm is that we believe that a period is 12 months; therefore,
    please find a seasonality that fits. If we say to the algorithm that we believe
    that a period is five years (60 months), the algorithm will try its best to find
    a seasonality and trend that fits that pattern.
  prefs: []
  type: TYPE_NORMAL
- en: I wish to be clear—the notion of a seasonality that happens every five years
    is **not wrong**. In fact, it is common for business-related forecasting to work
    on multiple levels of seasonalities. But knowing how many iterations to run, that
    comes with experience and wisdom.
  prefs: []
  type: TYPE_NORMAL
- en: Check the units! If the units don't make sense, like in the "lies" chart, then
    it probably isn't real.
  prefs: []
  type: TYPE_NORMAL
- en: More plotting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A major theme in this chapter other than time series analysis is plotting. You
    may have also noticed a few new functions in the `main` function earlier. Now
    it's time to revisit them.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with the output of `stl.Decompose`. This is the definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: There is no notion of time in the result. It's assumed that when you pass in
    data into `stl.Decompose`, the data is ordered by the time series. The result
    also follows this notion.
  prefs: []
  type: TYPE_NORMAL
- en: We've already defined `newTSPlot` previously, which works fine for the data,
    trend, and seasonal, but not the residuals. The reason why we don't want to plot
    residuals as a line chart is because if done right, the residuals should be more
    or less random. Having a line plot run through random points would be rather messy.
  prefs: []
  type: TYPE_NORMAL
- en: Typical residual plots are simply scatter plots of the residuals. However, that
    too is relatively uninterpretable when squashed into a multiplot image.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we want to draw a straight vertical line for each residual value.
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap, this is what we want to do:'
  prefs: []
  type: TYPE_NORMAL
- en: Plot a time series chart for each of `Data`, `Trend`, and `Seasonal`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot a residuals chart for `Resid`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Combine all the preceding plots into one image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Step 1 is easy, as we simply call `newTSPlot` with the parsed dates from earlier
    for each of the components. Step 2 is a little trickier. Gonum doesn't have the
    residuals plots that we want by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'To plot it, we''d need to create a new `plot.Plotter` interface. Here''s the
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Despite the fact that Gonum doesn't have the chart type that we want, as you
    can see it doesn't take very many lines of code for us to define our own chart
    type. This is part of the power of Gonum's `plot` library—it's abstract enough
    to enable you to write your own chart type, and at the same time, it provides
    all the helper functions necessary to make it work without much code.
  prefs: []
  type: TYPE_NORMAL
- en: A primer on Gonum plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we go further, I think it might be worth it to have an understanding
    of Gonum's plotting library in general. We've so far been using Gonum's `plot` library
    in rather ad hoc ways. This was to familiarize you with how to use the library.
    Now that you're somewhat familiar, it's time to learn more about the internals
    in order to plot better in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'A `*plot.Plot` object holds the metadata of a plot. A plot consists of the
    following features:'
  prefs: []
  type: TYPE_NORMAL
- en: A title
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`X` and `Y` axes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A legend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A list of `plot.Plotter`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A `plot.Plotter` interface is simply anything that can take a `*plot.Plot` object
    and draw it on to `draw.Canvas`, defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: By separating the notions of a `plot` object and the canvas upon which the plot
    will be drawn, this opens Gonum's plots to a variety of different plotting backend
    options. To see what I mean about backend options, we need to take a closer look
    at `draw.Canvas`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `draw.Canvas` is a tuple of `vg.Canvas` and `vg.Rectangle`. So what exactly
    is `vg`? `vg`, it turns out, stands for **vector graphics**. In it, the `Canvas` type
    is defined as an interface with a bunch of methods. This allows for the rich variety
    of backends that `vg` has:'
  prefs: []
  type: TYPE_NORMAL
- en: '`vg/vgimg`: This is the primary package we''ve been using so far; it writes
    to an image file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vg/vgpdf`: This package writes to a PDF file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vg/vgsvg`: This package writes to a SVG file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vg/vgeps`: This package writes to a EPS file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vg/vgtex`: This package writes to a TEX file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these canvas implementations has a coordinate system that begins with
    (0, 0) at the bottom left.
  prefs: []
  type: TYPE_NORMAL
- en: The residuals plotter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A deeper look at the canvasing system will be explored later in the chapter.
    For now, let's return to the `Plot` method that satisfies the `plot.Plotter` interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most interesting are the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`p.Transforms(&c)` returns two functions, which will transform the coordinate
    of our data point to the coordinate of the backend. This way we wouldn''t have
    to worry about the absolute location of each point. Instead, it will be treated
    in relation to the absolute location in the final image.'
  prefs: []
  type: TYPE_NORMAL
- en: Having gotten the transformation functions, we then loop through the residuals
    that we have, and transform each to the coordinate (`x := trX(xy.X)` and `y :=
    trY(xy.Y)`) within the canvas.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we tell the canvas to draw a straight line between two points: (*x*,
    0) and (*x*, *y*). This draws a straight line up or down from the `X` axis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we have created our own `plot.Plotter` interface, which we can now add
    to the `plot` object. But adding to a `*plot.Plot` object directly requires a
    lot of tinkering. So, here''s a function to nicely wrap all that up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This function is reminiscent of `newTSPlot`—you provide it the `X` and `Y` values,
    and get a `*plot.Plot` object back out, with everything properly styled and formatted.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may note that we''re also adding the plotter object as a legend. To do
    this without an error, the `residChart` type needs to implement `plot.Thumbnailer`.
    Again, that''s fairly straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: At this point, you may be wondering about the `canvas` object. If we are to
    draw a line between the canvas's minimum `X` to maximum `X`, wouldn't that just
    cause a horizontal line across the entire canvas?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is not really. Recall earlier that the canvas is provided in the
    backend, and `draw.Canvas` is simply a tuple of a canvas backend and a rectangle?
    The rectangle actually serves to subset and constrain the canvas upon which it
    is being drawn.
  prefs: []
  type: TYPE_NORMAL
- en: We shall see this in action. Now that we've finished, we can turn our attention
    to the next section, which depicts a combination of all the plots into one image.
  prefs: []
  type: TYPE_NORMAL
- en: Combining plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A key function that allows us to do this is the `plot.Align` function. For
    us to see this in action, we need to write a that allows us to plot any number
    of plots to a file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We'll skip the part where if `a` is `plot.Plot`, we simply call the `.Save` method.
    Instead, we'll look at the second case, where `a` is `[][]*plot.Plot`.
  prefs: []
  type: TYPE_NORMAL
- en: At first this may seem rather strange—why have a slice of slice of plots when
    all we want to do is to combine them in quick succession. The key to understanding
    this is that Gonum supports the tiling of charts so if you want four charts arranged
    in 2x2 fashion, it can be done. Having four charts in a row is simply a special
    case of a 4x1 layout.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can arrange the layouts using a function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Having acquired `[][]*plot.Plot`, we need to tell Gonum the tiling format that
    we''re interested in, so the following code snippet defines the tiling format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If you're following along with the code, you will realize that `rows` is `3` and
    `cols` is `1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we have to provide a canvas to draw on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use the `vgimg` backend because we want to write to a PNG image. If,
    for example, you want to set the DPI of the image, you may use `vgimg.NewWith` instead,
    and pass in the DPI option.
  prefs: []
  type: TYPE_NORMAL
- en: '`dc` is `draw.Canvas` initiated from the large piece of canvas `img`. Now comes
    the magic: `canvases := plot.Align(at, t, dc)` basically splits the big canvas
    (`img`) into various smaller canvases—they''re still part of the big canvas, but
    now, each `*plot.Plot` object gets allocated a smaller piece of the canvas, each
    with their own coordinate systems that are relative to the bigger canvas.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code simply draws the plots onto their respective mini-canvases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Naturally, this process can be recursively repeated. A `Legend` object in `*plot.Plot` simply
    gets a smaller chunk of the canvas, and drawing a straight line from minimum `X`
    to maximum `X` simply draws a horizontal line across the entire mini canvas.
  prefs: []
  type: TYPE_NORMAL
- en: And this is how plots are made.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re decomposing a time series here with the STL algorithm. There are other
    methods of decomposing time series—you may be familiar with one: the discrete
    Fourier transform. If your data is a time-based signal (like electrical pulses
    or music), a Fourier transform essentially allows you to decompose a time series
    into various parts. Bear in mind that they are no longer seasonality and trend,
    but rather decompositions of different time and frequency domains.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This begs the question: what is the point of decomposing a time series?'
  prefs: []
  type: TYPE_NORMAL
- en: A primary reason why we do any machine learning at all is to be able to predict
    values based on an input. When done on time series, this is called **forecasting**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Think about this for a bit: if a time series is made up of multiple components,
    wouldn''t it be better to be able to predict per component? If we are able to
    break a time series up into its components, be it by STL or by Fourier transforms,
    we would get better results if we predict per component and then recombine the
    data at the end.'
  prefs: []
  type: TYPE_NORMAL
- en: Since we work on STL, we already have our series decomposed. A very simple exponential
    smoothing algorithm invented by Holt in 1957 allows us to use the trend and seasonal
    components, along with the original data, to forecast.
  prefs: []
  type: TYPE_NORMAL
- en: Holt-Winters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, I shall explain a modified form of the Holt-Winters exponential
    smoothing algorithm, which is quite useful for forecasting. Holt-Winters is a
    fairly simple algorithm. Here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Calling it is rather easy. We would wind up with a time series with a number
    of additional periods. Hence, we would also need to extend our dates range before
    we call `newTSPlot`. Again, it''s a rather simple matter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Ideally, we would also like to draw a gray background indicating that the values
    in the area are forecasts. Putting it all together, it looks rather like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This would yield the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c0f2a7f-b316-46a3-b56e-4f83cb42a4ce.png)'
  prefs: []
  type: TYPE_IMG
- en: If everything keeps going as it is, we can expect to see an increased CO[2]
    level in 10 years. Of course, it could go down if we take action now.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This has been a rather hard chapter to write. The primary subject matter, without
    exaggeration, is one of existential threat. The methods used in the science at
    large are far more sophisticated than what I have covered in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The techniques I covered is a small part of a large field of statistics known
    as time series analysis, where we've yet to even scratch the surface of it with
    this composition technique.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the references:'
  prefs: []
  type: TYPE_NORMAL
- en: '*[0] Hershfield, Hal. (2011). Future self-continuity*: How conceptions of the
    future self transform intertemporal choice. Annals of the New York Academy of
    Sciences. 1235\. 30-43\. 10.1111/j.1749-6632.2011.06201.x.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*[1] Qin, P. and Northoff, G. (2011)*: How is our self related to midline regions
    and the default-mode network?. NeuroImage, 57(3), pp.1221-1233.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
