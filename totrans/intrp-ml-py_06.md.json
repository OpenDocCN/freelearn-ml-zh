["```py\nimport math\nimport mldatasets\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom catboost import CatBoostClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom alibi.utils.mapping import ohe_to_ord, ord_to_ohe\nimport tensorflow as tf\nfrom alibi.explainers import AnchorTabular, CounterFactualProto\nimport shap\nimport witwidget\nfrom witwidget.notebook.visualization import WitWidget, \\ WitConfigBuilder \n```", "```py\ntf.compat.v1.disable_eager_execution()\nprint('Eager execution enabled:', tf.executing_eagerly()) \n```", "```py\nrecidivism_df = mldatasets.load(\"recidivism-risk\", prepare=True) \n```", "```py\nrecidivism_df.info() \n```", "```py\nInt64Index: 14788 entries, 0 to 18315\nData columns (total 23 columns):\n#   Column                 Non-Null Count  Dtype\n--  ------                 --------------  -----\n0   age                    14788 non-null  int8\n1   juv_fel_count          14788 non-null  int8\n2   juv_misd_count         14788 non-null  int8\n3   juv_other_count        14788 non-null  int64\n4   priors_count           14788 non-null  int8\n5   is_recid               14788 non-null  int8\n6   sex_Female             14788 non-null  uint8\n7   sex_Male               14788 non-null  uint8\n8   race_African-American  14788 non-null  uint8\n9   race_Asian             14788 non-null  uint8\n13  race_Other             14788 non-null  uint8\n14  c_charge_degree_(F1)   14788 non-null  uint8\n15  c_charge_degree_(F2)   14788 non-null  uint8\n21  c_charge_degree_Other  14788 non-null  uint8\n22  compas_score           14788 non-null  int64 \n```", "```py\ncf_matrix = metrics.confusion_matrix(\n    recidivism_df.is_recid,\n    recidivism_df.compas_score\n)\nsns.heatmap(\n    cf_matrix/np.sum(cf_matrix),\n    annot=True,\n    fmt='.2%',\n    cmap='Blues',\n    annot_kws={'size':16}\n) \n```", "```py\nrecidivism_c_df =\\\nrecidivism_df[recidivism_df['race_Caucasian'] == 1]\nrecidivism_aa_df =\\\nrecidivism_df[recidivism_df['race_African-American'] == 1]\n_ = mldatasets.compare_confusion_matrices(\n    recidivism_c_df.is_recid,\n    recidivism_c_df.compas_score,\n    recidivism_aa_df.is_recid,\n    recidivism_aa_df.compas_score,\n    'Caucasian',\n    'African-American',\n    compare_fpr=True\n) \nFigure 6.2. At a glance, you can tell that it’s like the confusion matrix for Caucasians has been flipped 90 degrees to form the African American confusion matrix, and even then, it is still less unfair. Pay close attention to the difference between FPs and TNs. As a Caucasian defendant, a result is more than half as likely to be an FP than a TN, but as an African American, it is a few percentage points more likely. In other words, an African American defendant who doesn’t re-offend is predicted to be at risk of recidivating more than half of the time:\n```", "```py\nrand = 9\nnp.random.seed(rand)\ny = recidivism_df['compas_score']\nX = recidivism_df.drop(\n    ['compas_score', 'is_recid'],\n    axis=1).copy()\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=rand\n) \n```", "```py\ncb_mdl = CatBoostClassifier(\n    iterations=500,\n    learning_rate=0.5,\n    depth=8\n)\nfitted_cb_mdl = cb_mdl.fit(\n    X_train,\n    y_train,\n    verbose=False\n)\ny_train_cb_pred, y_test_cb_prob, y_test_cb_pred = \\\nmldatasets.evaluate_class_mdl(\n    fitted_cb_mdl, X_train, X_test, y_train, y_test\n) \n```", "```py\nidx_aa = 5231\nidx_h = 2726\nidx_c = 10127\neval_idxs = X_test.index.isin([idx_aa, idx_h, idx_c])\nX_test_evals = X_test[eval_idxs]\neval_compare_df = pd.concat(\n    [\n        pd.DataFrame(\n            {'y':y_test[eval_idxs]},\n            index=[idx_c, idx_h, idx_aa]\n        ),\n        pd.DataFrame(\n            {'y_pred':y_test_cb_pred[eval_idxs]},\n            index=[idx_c, idx_h, idx_aa]\n        ),\n        X_test_evals\n    ],\n    axis=1\n).transpose()\neval_compare_df \n```", "```py\nclass_names = ['Low Risk', 'Medium/High Risk'] \n```", "```py\nX_test_eval = np.expand_dims(\n    X_test.values[\n        X_test.index.get_loc(idx_aa)\n    ],\n     axis=0\n)\nprint(X_test_eval) \n```", "```py\n[[23  0  0  0  2  0  1  1  0  ... 0  1  0  0  0  0]] \n```", "```py\ncat_vars_ohe = {5: 2, 7: 6, 13: 8}\nprint(ohe_to_ord(X_test_eval, cat_vars_ohe)[0]) \n```", "```py\n[[23  0  0  0  2  1  0  3]] \n```", "```py\ncategory_map = {\n    5: ['Female', 'Male'],\n    6: [\n        'African-American',\n        'Asian',\n        'Caucasian',\n        'Hispanic',\n        'Native American',\n        'Other'\n    ],\n    7: [\n        'Felony 1st Degree',\n        'Felony 2nd Degree',\n        'Felony 3rd Degree',\n        'Felony 7th Degree',\n        'Misdemeanor 1st Degree',\n        'Misdemeanor 2nd Degree',\n        'Misdemeanor 3rd Degree',\n        'Other Charge Degree'\n    ]\n}\nfeature_names = [\n    'age',\n    'juv_fel_count',\n    'juv_misd_count',\n    'juv_other_count',\n    'priors_count',\n    'sex',\n    'race',\n    'c_charge_degree'\n] \n```", "```py\ncategory_map_ohe = {\n    5: ['Not Female', 'Female'],\n    6: ['Not Male', 'Male'],\n    7:['Not African American', 'African American'],\n    8:['Not Asian', 'Asian'], 9:['Not Caucasian', 'Caucasian'],\n    10:['Not Hispanic', 'Hispanic'],\n    11:['Not Native American', 'Native American'],\n    12:['Not Other Race', 'Other Race'],\n    19:['Not Misdemeanor 3rd Deg', 'Misdemeanor 3rd Deg'],\n    20:['Not Other Charge Degree', 'Other Charge Degree']\n} \n```", "```py\npredict_cb_fn = lambda x: fitted_cb_mdl.predict_proba(x)\nanchor_cb_explainer = AnchorTabular(\n    predict_cb_fn,\n    X_train.columns,\n    categorical_names=category_map_ohe\n)\nanchor_cb_explainer.fit(X_train.values) \n```", "```py\nprint(\n    'Prediction: %s' %  class_names[anchor_cb_explainer.\n    predictor(X_test.loc[idx_aa].values)[0]]\n) \n```", "```py\nPrediction: Medium/High Risk \n```", "```py\nanchor_cb_explanation = anchor_cb_explainer.explain(\n    X_test.loc[idx_aa].values,threshold=0.85, seed=rand\n)\nprint('Anchor: %s' % (' AND'.join(anchor_cb_explanation.anchor)))\nprint('Precision: %.3f' % anchor_cb_explanation.precision)\nprint('Coverage: %.3f' % anchor_cb_explanation.coverage) \n```", "```py\nAnchor: age <= 25.00 AND\n    priors_count > 0.00 AND\n    race_African-American = African American\nPrecision: 0.863\nCoverage: 0.290 \n```", "```py\nAnchor: age <= 25.00 AND\n    priors_count > 0.00 AND\n    race_African-American = African American AND\n    c_charge_degree_(M1) = Not Misdemeanor 1st Deg AND\n    c_charge_degree_(F3) = Not Felony 3rd Level AND\n    race_Caucasian = Not Caucasian\nPrecision: 0.903\nCoverage: 0.290 \n```", "```py\nAnchor: priors_count <= 2.00 AND\n    race_African-American = Not African American AND\n    c_charge_degree_(M1) = Misdemeanor 1st Deg\nPrecision: 0.891 \nCoverage: 0.578 \n```", "```py\nAnchor: priors_count <= 2.00 AND \n    race_African-American = Not African American AND\n    juv_fel_count <= 0.00 AND \n    sex_Male = Male\nPrecision: 0.851\nCoverage: 0.578 \n```", "```py\nfeature_range = (\n    X_train.values.min(axis=0).reshape(1,21).astype(np.float32),\\\n    X_train.values.max(axis=0).reshape(1,21).astype(np.float32)\n)\nprint(feature_range) \n```", "```py\n(array([[18.,  0.,  ... , 0.,  0.,  0.]], dtype=float32), array([[96., 20., ... ,  1.,  1.,  1.]], dtype=float32)) \n```", "```py\ncf_cb_explainer = CounterFactualProto(\n    predict_cb_fn,\n    c_init=1,\n    X_test_eval.shape,\n    max_iterations=500,\n    feature_range=feature_range,\n    beta=.01,\n    theta=5,\n    use_kdtree=True\n)\ncf_cb_explainer.fit(X_test.values, d_type='abdm-mvdm') \n```", "```py\ncf_cb_explanation = cf_cb_explainer.explain(X_test_eval) mldatasets.describe_cf_instance(\n    X_test_eval,\n    cf_cb_explanation,\n    class_names,\n    cat_vars_ohe,\n    category_map,\n    feature_names\n) \n```", "```py\nInstance Outcomes and Probabilities\n-----------------------------------------------\n       original:  Medium/High Risk\n                  [0.46732193 0.53267807]\ncounterfactual:  Low Risk\n                  [0.50025815 0.49974185]\nCategorical Feature Counterfactual Perturbations\n------------------------------------------------\n                sex:  Male  -->  Female\n               race:  African-American  -->  Asian\n    c_charge_degree:  Felony 7th Degree  -->  Felony 1st Degree\nNumerical Feature Counterfactual Perturbations\n------------------------------------------------\n       priors_count:  2.00  -->  1.90 \n```", "```py\nshap_cb_explainer = shap.TreeExplainer(fitted_cb_mdl) \n```", "```py\ntest_df = recidivism_df.loc[y_test.index]\ntest_np = test_df.values\ncols_l = test_df.columns\ndelcol_idx = [\n    cols_l.get_loc(\"is_recid\"),\n    cols_l.get_loc(\"compas_score\")\n] \n```", "```py\ndef custom_predict_with_shap(examples_np):\n    #For shap values, we only need the same features\n    #that were used for training\n    inputs_np = np.delete(np.array(examples_np),delcol_idx,axis=1)\n    #Get the model's class predictions\n    preds = predict_cb_fn(inputs_np)\n    #With test data, generate SHAP values which converted\n    #to a list of dictionaries format\n    keepcols_l = [c for i, c in enumerate(cols_l)\\\n                  if i not in delcol_idx]\n    shap_output = shap_cb_explainer.shap_values(inputs_np)\n    attributions = []\n    for shap in shap_output:\n        attrs = {}\n        for i, col in enumerate(keepcols_l):\n            attrs[col] = shap[i]\n        attributions.append(attrs)  \n    #Prediction function must output predictions/attributions\n    #in dictionary\n    output = {'predictions': preds, 'attributions': attributions} \n    return output \n```", "```py\nprint(y_test.index.get_loc(5231)) \n```", "```py\nwit_config_builder = WitConfigBuilder(\n    test_np.tolist(),\n    feature_names=cols_l.tolist()\n).set_custom_predict_fn(custom_predict_with_shap\n).set_target_feature(\"is_recid\").set_label_vocab(class_names)\nWitWidget(wit_config_builder, height=800) \n```"]