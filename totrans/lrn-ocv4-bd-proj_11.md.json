["```py\n#include  \"opencv2/highgui.hpp\" \n#include  \"opencv2/imgproc.hpp\" \n#include  \"opencv2/text.hpp\" \n\n#include  <vector> \n#include  <iostream> \n\nusing namespace std; \nusing namespace cv; \nusing namespace cv::text; \n```", "```py\nvector<Mat> separateChannels(const Mat& src)  \n{ \n   vector<Mat> channels; \n   //Grayscale images \n   if (src.type() == CV_8U || src.type() == CV_8UC1) { \n         channels.push_back(src); \n         channels.push_back(255-src); \n         return channels; \n   } \n\n   //Colored images \n   if (src.type() == CV_8UC3) { \n         computeNMChannels(src, channels); \n         int size = static_cast<int>(channels.size())-1; \n         for (int c = 0; c < size; c++) \n               channels.push_back(255-channels[c]); \n         return channels; \n   } \n\n   //Other types \n   cout << \"Invalid image format!\" << endl; \n   exit(-1);    \n}\n```", "```py\nvoid computeNMChannels(InputArray src, OutputArrayOfArrays channels, int mode = ERFILTER_NM_RGBLGrad); \n```", "```py\nint main(int argc, const char * argv[]) \n{ \n   const char* image = argc < 2 ? \"easel.png\" : argv[1];     \n   auto input = imread(image); \n```", "```py\n   Mat processed; \n   cvtColor(input, processed, COLOR_RGB2GRAY); \n\n   auto channels = separateChannels(processed); \n```", "```py\nMat processed = input;\n```", "```py\n// Create ERFilter objects with the 1st and 2nd stage classifiers \nauto filter1 = createERFilterNM1(\n     loadClassifierNM1(\"trained_classifierNM1.xml\"),  15, 0.00015f,  \n    0.13f, 0.2f,true,0.1f); \n\nauto filter2 = createERFilterNM2(      \n     loadClassifierNM2(\"trained_classifierNM2.xml\"),0.5); \n\n```", "```py\nPtr<ERFilter> createERFilterNM1(const Ptr<ERFilter::Callback>& cb, int thresholdDelta = 1, float minArea = 0.00025, float maxArea = 0.13, float minProbability = 0.4, bool nonMaxSuppression = true, float minProbabilityDiff = 0.1); \n```", "```py\n//Extract text regions using Newmann & Matas algorithm \ncout << \"Processing \" << channels.size() << \" channels...\"; \ncout << endl; \nvector<vector<ERStat> > regions(channels.size()); \nfor (int c=0; c < channels.size(); c++) \n{ \n    cout << \"    Channel \" << (c+1) << endl; \n    filter1->run(channels[c], regions[c]); \n    filter2->run(channels[c], regions[c]);          \n}     \nfilter1.release(); \nfilter2.release(); \n```", "```py\n//Separate character groups from regions \nvector< vector<Vec2i> > groups; \nvector<Rect> groupRects; \nerGrouping(input, channels, regions, groups, groupRects, ERGROUPING_ORIENTATION_HORIZ); \n```", "```py\nvoid erGrouping(InputArray img, InputArrayOfArrays channels, std::vector<std::vector<ERStat> > &regions, std::vector<std::vector<Vec2i> > &groups, std::vector<Rect> &groups_rects, int method = ERGROUPING_ORIENTATION_HORIZ, const std::string& filename = std::string(), float minProbablity = 0.5); \n```", "```py\nerGrouping(input, channels, regions,  \n    groups, groupRects, ERGROUPING_ORIENTATION_ANY,  \n    \"trained_classifier_erGrouping.xml\", 0.5); \n```", "```py\n// draw groups boxes  \nfor (const auto& rect : groupRects) \n    rectangle(input, rect, Scalar(0, 255, 0), 3); \n\nimshow(\"grouping\",input); \nwaitKey(0);\n```", "```py\nint floodFill(InputOutputArray image, InputOutputArray mask,  Point seedPoint, Scalar newVal, \n CV_OUT Rect* rect=0, Scalar loDiff = Scalar(), Scalar upDiff = Scalar(), int flags = 4 ); \n```", "```py\nMat out = Mat::zeros(channels[0].rows+2, channels[0].cols+2, CV_8UC1); \n\nint flags = 4                    //4 neighbors \n   + (255 << 8)                        //paint mask in white (255) \n   + FLOODFILL_FIXED_RANGE       //fixed range \n   + FLOODFILL_MASK_ONLY;        //Paint just the mask \n```", "```py\nfor (int g=0; g < group.size(); g++) \n{ \n   int idx = group[g][0];         \n   auto er = regions[idx][group[g][1]]; \n\n//Ignore root region \n   if (er.parent == NULL)  \n         continue; \n```", "```py\nint px = er.pixel % channels[idx].cols; \nint py = er.pixel / channels[idx].cols; \nPoint p(px, py); \n```", "```py\nfloodFill( \n    channels[idx], out,          //Image and mask \n    p, Scalar(255),              //Seed and color \n    nullptr,                     //No rect \n    Scalar(er.level),Scalar(0),  //LoDiff and upDiff \n    flags                        //Flags \n```", "```py\nout = out(rect);\n```", "```py\n   vector<Point> points;    \n   findNonZero(out, points); \n   //Use deskew and crop to crop it perfectly \n   return deskewAndCrop(out, minAreaRect(points)); \n} \n```", "```py\ncv::Ptr<BaseOCR> initOCR2(const string& ocr) { if (ocr == \"tesseract\") { return OCRTesseract::create(nullptr, \"eng+por\"); } throw string(\"Invalid OCR engine: \") + ocr; } \n```", "```py\nPtr<OCRTesseract> create(const char* datapath=NULL, \n const char* language=NULL, \n const char* char_whitelist=NULL, \n int oem=3, int psmode=3); \n```", "```py\nauto ocr = initOCR(\"tesseract\"); \nfor (int i = 0; i < groups.size(); i++)  \n{ \n     auto wordImage = drawER(channels, regions, groups[i],  \n     groupRects[i]); \n\n     string word; \n     ocr->run(wordImage, word); \n     cout << word << endl; \n}\n```", "```py\nvirtual void run(Mat& image, std::string& output_text, \n std::vector<Rect>* component_rects=NULL, \n std::vector<std::string>* component_texts=NULL, \n std::vector<float>* component_confidences=NULL, int component_level=0) = 0; \n```"]