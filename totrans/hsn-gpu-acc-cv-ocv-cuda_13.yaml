- en: Assessments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The three options to increase the performance are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Having faster clock speed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: More work per clock cycle by a single processor
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Many small processors that can work in parallel. This option is used by GPU
    to improve performance.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CPUs are designed to improve latency and GPUs are designed to improve Throughput.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The car will take 4 hours to reach the destination but it can only accommodate
    5 persons, while the bus that can accommodate 40 persons takes 6 hours to reach
    the destination. The bus can transport 6.66 persons per hour, while the car can
    transport 1.2 persons per hour. Thus, car has better latency, and bus has better
    throughput.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Image is nothing but a two dimensional array. Most of the computer vision applications
    involve processing of these two-dimensional arrays. It involves similar operations
    on a large amount of data, which can be efficiently performed by GPUs. So GPUs
    and CUDA are very useful in computer vision applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`printf` statement is executed on the host'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CUDA program to subtract two numbers by passing parameters as value is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'CUDA program to multiply two numbers by passing parameters as reference is
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Three ways to launch 5000 threads for `gpuMul` kernel as are follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'False'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The program to find GPU Devices with version 5.0 or greater is as follows
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'CUDA program to find Cube of Number is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Communication pattern for a particular application is given as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Image Processing - stencil
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Moving Average - gather
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sorting Array in ascending order - Scatter
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Finding cube of numbers in Array - Map
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The best method to choose the number of threads and number of blocks is as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: There is a limit to the number of threads that can be launched per block which
    is 512 or 1024 for the latest processors. The same way there is a limit to the
    number of blocks per grid. So if there are a large number of threads then it is
    better to launch kernel by a small number of blocks and threads as described.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is the CUDA program to find the cube of 50000 number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: True, because it only needs to access local memory, which is a faster memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When variables of the kernel do not fit in register files, they uses local memory.
    This is called as register spilling. Because some of the data is not in the registers,
    it will need more time to fetch it from memory. This will take more time, and
    hence the performance of the program will be affected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No, because all the threads are running in parallel. So data might be read before
    it has been written, and thus it might not give the desired output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True. In atomic operations, all the other threads have to wait when one thread
    is accessing a particular memory location. This will incur time overhead when
    many threads are accessing the same memory locations. So, atomic operations will
    increase the execution time of the CUDA program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stencil communication pattern is ideal for texture memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When `__syncthreads` directive is used inside an `if` statement, then for threads
    that have this condition, `false` will never reach this point and `__syncthreads`
    will continuously wait for all the threads to reach this point. Thus, the program
    will never be terminated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CPU timers will include time overhead of thread latency in OS and scheduling
    in OS, among many other factors. The time measured using CPU will also depend
    on the availability of high precision CPU timer. The host is frequently performing
    asynchronous computation while GPU kernel is running, and hence CPU timers may
    not give correct time for kernel executions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open Nvidia Visual profiler from `C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\libnvvp`.
    Then, go to -> New Session and Select `.exe` file for matrix multiplication example.
    You can visualize the performance of your code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide by zero, incorrect variable types or sizes, nonexistent variables, subscripts
    out of range etc are examples of semantic errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'An example of thread divergence can be given as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the code, odd and even number of threads are performing different operations,
    and hence they will take different amount of time for completion. After `if` statement,
    these threads will again merge. This will incur time overhead because fast threads
    have to wait for slow threads. This will slow down the performance of the code.
  prefs: []
  type: TYPE_NORMAL
- en: '`cudaHostAlloc` function should be used with proper care because this memory
    is not swapped out of disk; your system may run out of memory. It may affect the
    performance of other applications running on the system.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The order of operation is important in CUDA stream operations as we want to
    overlap memory copy operations with kernel execution operations. So, operation
    queues should be made in such a way that these operations can overlap with each
    other, or else using CUDA stream won't help the performance of the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For 1024 x 1024 image, number of threads should be 32x32 (if your system supports
    1024 threads per block), and the number of blocks should be 32 x 32, which can
    be determined by image size divided by number of threads per block.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a difference between image processing and computer vision fields. Image
    processing is concerned with improving the visual quality of images by modifying
    pixel values, whereas computer vision is concerned with extracting important information
    from the images. So, in image processing, both input and output are images, while
    in computer vision, input is an image but the output is the information extracted
    from that image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The OpenCV library has an interface in C, C++, Java, and Python languages and
    it can be used in all operating systems like Windows, Linux, Mac, and Android
    without modifying the single line of code. This library can also take advantage
    of multi-core processing. It can take advantage of OpenGL and CUDA for parallel
    processing. As OpenCV is lightweight, it can be used on embedded platforms like
    Raspberry Pi as well. This makes it ideal for deploying computer vision applications
    on embedded systems in real life scenarios.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The command to initialize image with red color is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The program to capture video from webcam and store it on disk is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: BGR color format is used by OpenCV to read and display an Image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Program to capture video from a webcam and convert it to gray scale is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'OpenCV program to measure the performance of add and subtract operation is
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'OpenCV program for bitwise `AND` and `OR` operations is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenCV function to print pixel intensity at location`(200,200)` of any color
    image on the console is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'OpenCV function to resize an image to `(300,200)` pixels using bilinear Interpolation
    method is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'OpenCV function to upsample an image by 2 using `AREA` interpolation is as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: False. Blurring increases as we increase the size of a filter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False. The median filter can't remove Gaussian noise. It can remove salt and
    pepper noise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The image has to be blurred using an Averaging or Gaussian filter before applying
    lapacian operator to remove noise sensitivity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'OpenCV function to implement top hat and black hat morphological operation
    is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenCV code to detect objects with yellow color from a video is as follows:
    Note that the boilerplate code is not repeated here.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: When the color of an object is the same as the color of background, then color
    based object detection will fail. If there is a change in illumination, even then
    it can fail.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first step of canny edge detection algorithm is Gaussian blurring, which
    removes the noise present in the image. After that, the gradient is computed.
    Thus, the edges detected will be less affected by noise here, than other edge
    detection algorithms seen earlier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the image is affected by Gaussian or salt-pepper noise, then the result
    of the Hough transform is very poor. To improve the result image must be filtered
    by Gaussian and Median filter, as a preprocessing step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the intensity threshold for computing FAST keypoints is low, then more
    keypoints will pass the segment test and will be categorized as key-points. As
    this threshold is increased, the number of key-points detected will gradually
    decrease.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The larger value of hessian threshold in SURF will result in fewer but more
    salient interest points and a smaller value will result in more numerous but less
    salient points.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the scale factor of Haar cascade is increased from 1.01 to 1.05, then image
    size will be reduced by a larger factor at every scale. Thus, fewer images need
    to be processed per frame, which reduces computation time; however, this may fail
    to detect some of the objects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`MoG` is faster and less noisy compared to `GMG` algorithm for background subtraction.
    The morphological operation like opening and closing can be applied to the output
    of GMG to reduce the noise present.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Jetson TX1 offers performance in terms of Tera floating point operations per
    second, which is far better than Raspberry Pi. So Jetson TX1 can be used in computationally
    intensive applications like computer vision and deep learning for deployment in
    real time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jetson TX1 development board supports up to six 2-lane or three 4-lane cameras.
    It has one 5 megapixel camera attached to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The USB hub has to be used to connect more than two USB peripherals with Jetson
    TX1\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False. Jetson TX1 contains one ARM Cortex A57 quad-core CPU operating at 1.73
    GHz.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Though Jetson TX1 comes with pre-flashed Ubuntu, it does not contain any software
    packages needed for Computer Vision applications. The Jetpack contains Linux of
    Tegra (L4T) board support packages, TensorRT, which is used for deep learning
    inference in computer vision applications, latest CUDA toolkit, cuDNN, which is
    CUDA deep neural network library, Visionworks, which is also used for computer
    vision and deep learning applications, and OpenCV. So, by installing Jetpack,
    we can install all software packages needed to build computer vision applications
    rapidly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The global memory for the GPU device on Jetson TX1 is around 4 GB with a GPU
    clock speed of around 1 GHz. This clock speed is slower than Geforce 940 GPU used
    earlier in this book. The memory clock speed is only 13 MHz compared to 2.505
    GHz on Geforce 940, which makes Jetson TX1 slower. The L2 cache is 256 KB compared
    to 1 MB on Geforce 940\. Most of the other properties are similar to GeForce 940.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the latest Jetpack, OpenCV is not compiled with CUDA support nor does it
    have GStreamer support, which is needed for accessing the camera from the code.
    So, it is a good idea to remove OpenCV installation that comes with Jetpack and
    compile the new version of OpenCV with CUGA and GStreamer support.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False. OpenCV can capture video from both USB and CSI camera connected to Jetson
    TX1 board.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True. CSI camera is more close to hardware so frames are read quickly than USB
    camera so it is better to use CSI camera for computationally intensive applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Python OpenCV binding is not supported by CUDA acceleration so it is better
    to use C++ OpenCV binding for a computationally intensive task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No. Jetson TX1 comes preinstalled with python2 and python3 interpreter, while
    OpenCV is compiled for Jetson TX1; it also installs python binaries so there is
    no need to install separate python OpenCV bindings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is Open Source and has a large user community contributing to the language
    in terms of modules. These modules can be used easily to develop applications
    in a small time with few lines of code. The syntax of Python language is easy
    to read and interpret, which makes it easier to learn for a new programmer. It
    is an interpreted language that allows line by line execution of the code. These
    are the few advantages of python over C/C++.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The whole code is checked and converted to machine code in compiled type languages,
    while one statement at a time is translated in an interpreted language. An interpreted
    language requires less amount of time to analyze the source code, but the overall
    execution time is slower compared to compile type languages. Interpreted languages
    do not generate intermediate code as in the case of compiled type languages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False. Python is an interpreted language, which makes it slower than C/C++.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: PyOpenCL can take advantage of any Graphics processing Unit, while PyCUDA requires
    Nvidia GPU and CUDA toolkit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True. Python allows C/C++ code in a python script, and hence the computationally
    complex task can be written in C/C++ for faster processing, and python wrapper
    can be created for it. PyCUDA can leverage this capability for kernel code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C/C++ programming language is used to write kernel function inside `SourceModule`
    class, and this kernel function is compiled by `nvcc` (Nvidia C ) Compiler.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The kernel call function is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: False. The order of block execution is random in PyCUDA program, and it can't
    be determined by PyCUDA programmer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The directives from driver class remove the need of separate allocation of memory
    for the Array, uploading it to the device and downloading the result back to host.
    All operations are performed simultaneously during a kernel call. This makes the
    code simpler and easy to read.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The PyCUDA code for adding two to every element in an array is shown below:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The use of Python time measuring options for measuring the performance of PyCUDA
    programs will not give accurate results. It will include time overhead of thread
    latency in OS and scheduling in OS, among many other factors. The time measured
    using time class will also depend on the availability of high precision CPU timer.
    Many a times, host is performing asynchronous computation while GPU kernel is
    running, and hence CPU timers of Python may not give correct time for kernel executions.
    We can overcome these drawbacks by using CUDA events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: False. This line represents a read-modify-write operation that can yield wrong
    results when multiple threads are trying to increment the same memory location,
    as in the case of histogram calculation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the case of using shared memory, fewer threads are trying to access 256 memory
    elements in shared memory, instead of all threads as in the case without shared
    memory. This will help in reducing time overhead in the atomic operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The kernel call function in case of using share memory is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The size of the shared memory should be defined, while calling the kernel. This
    is specified by using the shared argument in the kernel call function.
  prefs: []
  type: TYPE_NORMAL
- en: The histogram is a statistical feature that gives important information regarding
    the contrast and brightness of an image. If it has a uniform distribution, then
    the image will have a good contrast. The histogram also conveys the information
    about the brightness of an image. If the histogram is concentrated on the left-hand
    side of the plot, then the image will be too dark, and if it is concentrated on
    the right-hand side, then the image will be too bright.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True. As RGB and BGR color format is same just the order of channels is different.
    The equation of conversion will still remain the same.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is simpler to work with single dimensional threads and blocks than multidimensional.
    It simplifies the indexing mechanism inside the kernel function, and hence it
    is performed in every example that appears in the chapter. It is not mandatory
    if we are working with multidimensional threads and blocks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `imshow` function, used to display an image on the screen, requires an image
    in unsigned integer format. So all the results computed by kernel function are
    converted `uint8` datatype of `numpy` library before displaying on the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
