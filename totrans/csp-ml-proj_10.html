<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Credit Card Fraud Detection</h1>
                
            
            <article>
                
<p class="calibre2">In the previous chapter, we built our first anomaly detection model using <strong class="calibre4">Principal Component Analysis</strong> (<strong class="calibre4">PCA</strong>) and saw how we can detect cyber attacks using principal components. Similar to cyber attack or network intrusion problems, anomaly detection models are frequently used for fraud detection. Various organizations in many industries, such as financial services, insurance companies, and government agencies, often come across fraudulent cases. Especially in financial sectors, frauds are directly related to monetary losses and these fraudulent cases can come in many different guises, such as stolen credit cards, accounting forgeries, or fake checks. Because these events occur relatively rarely, it is difficult and tricky to detect these fraudulent cases.</p>
<p class="calibre2">In this chapter, we are going to discuss how we can build an anomaly detection model for credit card fraud detection. We are going to use an anonymized credit card dataset that contains a large portion of normal credit card transactions and relatively fewer fraudulent credit card transactions. We will first look at the structure of the dataset, the distribution of the target classes, and the distributions of various anonymized features. Then, we are going to start applying PCA and building standardized principal components that will be used as features for our fraud detection model. In the model building step, we are going to experiment with two different approaches to building fraud detection models—the <strong class="calibre4">Principal Component Classifier</strong> (<strong class="calibre4">PCC</strong>) that is similar to what we built in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em> and the one-class <strong class="calibre4">Support Vector Machine</strong> (<strong class="calibre4">SVM</strong>) that learns from normal credit card transactions and detects any anomalies. With these models built, we are going to evaluate their anomaly detection rates and compare their performances for credit card fraud detection.</p>
<p class="calibre2">In this chapter, we will cover the following topics:</p>
<ul class="calibre10">
<li class="calibre11">Problem definition for the credit card fraud detection project</li>
<li class="calibre11">Data analysis for the anonymized credit card dataset</li>
<li class="calibre11">Feature engineering and PCA</li>
<li class="calibre11">The one-class SVM versus the PCC</li>
<li class="calibre11">Evaluating anomaly detection models</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Problem definition</h1>
                
            
            <article>
                
<p class="calibre2">Credit card fraud is relatively common among other fraudulent events, and can happen in our daily lives. There are various ways credit card fraud can happen. Credit cards can be lost or stolen and then used by a thief. Another way credit card fraud can occur is that your identity might have been exposed to malicious persons who then use your identity to open a new credit card account, or even take over your existing credit card accounts. Scammers can even use telephone phishing for credit card fraud. As there are many ways credit card fraud can happen, many credit card holders are exposed to the risk of this type of fraud, and having a proper way to prevent them from happening has become essential in our daily lives. Many credit card companies have employed various measures to prevent and detect these types of fraudulent activities, using various <strong class="calibre4">machine learning</strong> (<strong class="calibre4">ML</strong>) and anomaly-detection technologies.</p>
<p class="calibre2"><span class="calibre5">In this chapter, we are going to work on building a credit card fraud detection model by using and expanding our knowledge about building anomaly detection models. We will be using an anonymized credit card dataset that can be found at the following link: <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud/data" target="_blank" class="calibre9">https://www.kaggle.com/mlg-ulb/creditcardfraud/data</a>. This dataset has about 285,000 credit card transactions, and only about 0.17% of those transactions are fraudulent transactions, which reflects a real-life situation very well. With this data, we are going to look at how the dataset is structured, and then start looking at the distributions of the target and feature variables. Then, we will be building features by using PCA, similar to what we did in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>. For building credit card fraud detection models, we are going to experiment with both the PCC, similar to the one we built in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em></span>, a<span class="calibre5">nd the one-class SVM, which learns from normal credit card transactions and decides whether a new transaction is fraudulent or not. Lastly, we are going to look at false alarm and fraud detection rates to evaluate and compare the performances of these models.</span></p>
<p class="calibre2"><span class="calibre5">To summarize our problem definition for the credit card fraud detection project:</span></p>
<ul class="calibre10">
<li class="calibre11">What is the problem? We need an anomaly detection model for fraudulent credit card transactions that can identify, prevent, and stop potential fraudulent credit card activities.</li>
<li class="calibre11">Why is it a problem? E<span>very credit card holder is exposed to the risks of becoming the victim of credit card fraud, and without being properly prepared for such malicious attempts, the number of credit card fraud victims is going to increase. With a credit card fraud detection model, we can prevent and stop potential fraudulent credit card transactions from happening</span><span><span>.</span></span></li>
<li class="calibre11">What are some of the approaches to solving this problem? We are going to use anonymized credit card data that is publicly available, and has lots of normal credit card transactions and a small number of fraudulent transactions. We are going to apply PCA to this data and experiment with the PCC and the one-class SVM models for fraud detection.</li>
<li class="calibre11">What are the success criteria? Since any credit card fraud event will result in monetary loss, w<span>e want a high fraud detection rate. Even if there are some false positives or false alarms, it is better to flag any suspicious credit card activities to prevent any fraudulent transactions from going through.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Data analysis for anonymized credit card data</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">Let's now start looking at the credit card dataset. As mentioned before, we are going to use the dataset that is available at the following link: <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud/data" target="_blank" class="calibre9">https://www.kaggle.com/mlg-ulb/creditcardfraud/data</a>. It is a dataset that contains about 285,000 records of credit card transactions, where some of them are fraudulent transactions and the majority of the records are normal credit card transactions. Due to confidentiality issues, the feature names in the dataset are anonymized. We will be using the <kbd class="calibre12">creditcard.csv</kbd> file, which can be downloaded from the link.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Target variable distribution</h1>
                
            
            <article>
                
<p class="calibre2">The first thing we are going to examine is the distribution of fraudulent and non-fraudulent credit card transactions in the dataset. In the dataset, the column named <kbd class="calibre12">Class</kbd> is the target variable that is encoded with <kbd class="calibre12">1</kbd> for fraudulent credit card transactions and <kbd class="calibre12">0</kbd> for non-fraudulent transactions. You can use the following code to first load the data into a Deedle data frame:</p>
<pre class="calibre19">// Read in the Credit Card Fraud dataset<br class="title-page-name"/>// TODO: change the path to point to your data directory<br class="title-page-name"/>string dataDirPath = @"&lt;path-to-your-dir&gt;";<br class="title-page-name"/><br class="title-page-name"/>// Load the data into a data frame<br class="title-page-name"/>string dataPath = Path.Combine(dataDirPath, "creditcard.csv");<br class="title-page-name"/>Console.WriteLine("Loading {0}\n\n", dataPath);<br class="title-page-name"/>var df = Frame.ReadCsv(<br class="title-page-name"/>    dataPath,<br class="title-page-name"/>    hasHeaders: true,<br class="title-page-name"/>    inferTypes: true<br class="title-page-name"/>);</pre>
<p class="calibre2">This dataset has headers that represent each of the features and the target class, so we are loading this data with the <kbd class="calibre12">hasHeaders: true</kbd> flag. Now that we have the data loaded, you can use the following code to analyze the distribution of the target classes:</p>
<pre class="calibre19">// Target variable distribution<br class="title-page-name"/>var targetVarCount = df.AggregateRowsBy&lt;string, int&gt;(<br class="title-page-name"/>    new string[] { "Class" },<br class="title-page-name"/>    new string[] { "V1" },<br class="title-page-name"/>    x =&gt; x.ValueCount<br class="title-page-name"/>).SortRows("V1");<br class="title-page-name"/>targetVarCount.RenameColumns(new string[] { "is_fraud", "count" });<br class="title-page-name"/><br class="title-page-name"/>targetVarCount.Print();<br class="title-page-name"/><br class="title-page-name"/>DataBarBox.Show(<br class="title-page-name"/>    targetVarCount.GetColumn&lt;string&gt;("is_fraud").Values.ToArray(),<br class="title-page-name"/>    targetVarCount["count"].Values.ToArray()<br class="title-page-name"/>).SetTitle(<br class="title-page-name"/>    "Counts by Target Class"<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">As you might be familiar with this function already, we are using the <kbd class="calibre12">AggregateRowsBy</kbd> function in a Deedle data frame to group rows by the column <kbd class="calibre12">Class</kbd>, and then count the number of records in each target class. Since the column name, <kbd class="calibre12">Class</kbd>, is not a good representative of what our target class is and what it means, we renamed it with another name, <kbd class="calibre12">is_fraud</kbd>. As you can see from this code, you can use the <kbd class="calibre12">RenameColumns</kbd> function with an array of strings for new column names to rename the feature names. Lastly, we used the <kbd class="calibre12">DataBarBox</kbd> class in the Accord.NET framework to display a bar plot that visually shows the distributions of the target classes.</span></p>
<p class="calibre2">The following output shows the distribution of the target classes:</p>
<div class="mce-root"><img src="../images/00163.jpeg" class="calibre116"/></div>
<p class="calibre2"><span class="calibre5">As you can see from this output, there is a large gap between the number of fraudulent credit card transactions and non-fraudulent credit card transactions. We only have 492 records of frauds and over 284,000 records of non-frauds.</span></p>
<p class="calibre2">The following is a bar plot that the code generates for visually displaying the distribution of target classes:</p>
<div class="mce-root"><img src="../images/00164.jpeg" class="calibre117"/></div>
<p class="calibre2"><span class="calibre5">As expected from the previous output, there is a large gap between the number of records that belong to the target class, <strong class="calibre4">1</strong>, which represents fraud, and the number of records that belong to the target class, <strong class="calibre4">0</strong>, which represents non-fraud and normal credit card transactions. This large gap is expected as credit card frauds happen relatively rarely, compared to the large number of normal everyday credit card transactions. This large class imbalance makes it difficult for most ML models to accurately learn how to identify frauds from non-frauds.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Feature distributions</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The features, except for the transactional amounts, we have in this data are anonymized due to confidentiality issues. Because we do not know what each feature represents and what each feature means, it will be difficult to deduce any intuitive insights from the feature analysis. However, it is still helpful to understand how each of the features is distributed, how the distribution of each feature differs from the others, and whether there is any noticeable pattern we can derive from the set of features.</span></p>
<p class="calibre2">Let's first take a look at the code. The following code shows how we can compute and visualize the distributions of the features:</p>
<pre class="calibre19">// Feature distributions<br class="title-page-name"/>foreach (string col in df.ColumnKeys)<br class="title-page-name"/>{<br class="title-page-name"/>    if (col.Equals("Class") || col.Equals("Time"))<br class="title-page-name"/>    {<br class="title-page-name"/>        continue;<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    double[] values = df[col].DropMissing().ValuesAll.ToArray();<br class="title-page-name"/>    <br class="title-page-name"/>    Console.WriteLine(String.Format("\n\n-- {0} Distribution -- ", col));<br class="title-page-name"/>    double[] quartiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>        values,<br class="title-page-name"/>        new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>    );<br class="title-page-name"/>    Console.WriteLine(<br class="title-page-name"/>        "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>        quartiles[0], quartiles[1], quartiles[2], quartiles[3], quartiles[4]<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    HistogramBox.Show(<br class="title-page-name"/>        values,<br class="title-page-name"/>        title: col<br class="title-page-name"/>    )<br class="title-page-name"/>    .SetNumberOfBins(50);<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">As you can see from this code, we are computing the quartiles. As you might recall, quartiles are the points that separate the data into four different sections. The first quartile is the middle point between the minimum and the median, the second quartile is the median, and the third quartile is the middle point between the median and the maximum. You can easily compute the quartiles by using the <kbd class="calibre12">Accord.Statistics.Measures.Quantiles</kbd> function. After we compute the quartiles, we build histogram plots for each feature to visualize the distributions, using the <kbd class="calibre12">HistogramBox</kbd> class in the Accord.NET framework. Let's take a look at some of the outputs from this code.</span></p>
<p class="calibre2">The first distribution we are going to look at is for the <kbd class="calibre12">V1</kbd> feature, and the quartiles for <kbd class="calibre12">V1</kbd> look like the following:</p>
<div class="mce-root"><img src="../images/00165.jpeg" class="calibre118"/></div>
<p class="calibre2">It seems the distribution of the <kbd class="calibre12">V1</kbd> feature is skewed towards the negative direction. Even though the median is about 0, the negative values range from -56.41 to 0, while the positive values range only from 0 to 2.45. The following is the histogram output from the previous code:</p>
<div class="mce-root"><img src="../images/00166.jpeg" class="calibre26"/></div>
<p class="calibre2"><span class="calibre5">As expected, the histogram plot shows left skewness in the distribution of the feature, <kbd class="calibre12">V1</kbd>, while the majority of the values are around 0.</span></p>
<p class="calibre2">Next, let's look at the distribution of the second feature, <kbd class="calibre12">V2</kbd>, where the output looks as follows:</p>
<div class="mce-root"><img src="../images/00167.jpeg" class="calibre119"/></div>
<p class="calibre2">The histogram for <kbd class="calibre12">V2</kbd> looks like the following:</p>
<div class="mce-root"><img src="../images/00168.jpeg" class="calibre26"/></div>
<p class="calibre2"><span class="calibre5">It seems the values are centered around 0, although there are some extreme values in the negative direction and in the positive direction. The skewness is less obvious, compared to the previous feature,</span> <kbd class="calibre12">V1</kbd><span class="calibre5">.</span></p>
<p class="calibre2">Lastly, let's look at the distribution of the <kbd class="calibre12">amount</kbd> feature, which can tell us the range of transaction amounts. The following are the quartiles for the <kbd class="calibre12">amount</kbd> feature:</p>
<div class="mce-root"><img src="../images/00169.jpeg" class="calibre120"/></div>
<p class="calibre2">It seems any credit card transaction can take any positive number that ranges between 0 and 25,691.16 as a transaction amount. The following is a histogram for the <kbd class="calibre12">amount</kbd> feature:</p>
<div class="mce-root"><img src="../images/00170.jpeg" class="calibre26"/></div>
<p class="calibre2"><span class="calibre5">As expected, we can see there is a long tail to the right. This is somewhat expected, as the spending pattern for each individual differs from any other. Some people might typically buy moderately priced items, while some others might buy very expensive items.</span></p>
<p class="calibre2">Lastly, let's take a brief look at how well the current feature set separates fraudulent credit card transactions from non-fraudulent transactions. Let's take a look at the following code first:</p>
<pre class="calibre19">// Target Var Distributions on 2-dimensional feature space<br class="title-page-name"/>double[][] data = BuildJaggedArray(<br class="title-page-name"/>    df.ToArray2D&lt;double&gt;(), df.RowCount, df.ColumnCount<br class="title-page-name"/>);<br class="title-page-name"/>int[] labels = df.GetColumn&lt;int&gt;("Class").ValuesAll.ToArray();<br class="title-page-name"/><br class="title-page-name"/>double[][] first2Components = data.Select(<br class="title-page-name"/>    x =&gt; x.Where((y, i) =&gt; i &lt; 2<br class="title-page-name"/>).ToArray()).ToArray();<br class="title-page-name"/>ScatterplotBox.Show("Feature #1 vs. Feature #2", first2Components, labels);<br class="title-page-name"/><br class="title-page-name"/>double[][] next2Components = data.Select(<br class="title-page-name"/>    x =&gt; x.Where((y, i) =&gt; i &gt;= 1 &amp;&amp; i &lt;= 2).ToArray()<br class="title-page-name"/>).ToArray();<br class="title-page-name"/>ScatterplotBox.Show("Feature #2 vs. Feature #3", next2Components, labels);<br class="title-page-name"/><br class="title-page-name"/>next2Components = data.Select(<br class="title-page-name"/>    x =&gt; x.Where((y, i) =&gt; i &gt;= 2 &amp;&amp; i &lt;= 3).ToArray()<br class="title-page-name"/>).ToArray();<br class="title-page-name"/>ScatterplotBox.Show("Feature #3 vs. Feature #4", next2Components, labels);</pre>
<p class="calibre2">As you can see from this code, we first convert the Deedle data frame variable, <kbd class="calibre12">df</kbd>, to a two-dimensional array variable, <kbd class="calibre12">data</kbd>, to build scatter plots. Then, we take the first two features and display a scatter plot that shows the distribution of the target classes across these first two features. We repeat this process twice more for the second, third, and fourth features.</p>
<p class="calibre2">The following scatter plot is the distribution of target classes across the first and second features in our dataset:</p>
<div class="mce-root"><img src="../images/00171.jpeg" class="calibre93"/></div>
<p class="calibre2">From this scatter plot, it is quite difficult, <span class="calibre5">if not impossible,</span> to separate the frauds (encoded as 1) from the non-frauds (encoded as 0). Let's look at the scatter plot between the next two features:</p>
<div class="mce-root"><img src="../images/00172.jpeg" class="calibre121"/></div>
<p class="calibre2">Similar to the case of the first two features, there does not seem to be a clear line separating frauds from non-frauds. Lastly, the following is a scatter plot of the target classes between the third and fourth feature:</p>
<div class="mce-root"><img src="../images/00173.jpeg" class="calibre122"/></div>
<p class="calibre2">From looking at this scatter plot, it will be difficult to draw a clear line that separates the two target classes. The fraudulent transactions seem to reside more in the bottom-right side of this scatter plot, but the pattern is weak. In the following section, we will try to build features that better separate the two target classes.</p>
<p class="calibre2">The full code for this data analysis step can be found at the following link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/DataAnalyzer.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/DataAnalyzer.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Feature engineering and PCA</h1>
                
            
            <article>
                
<p class="calibre2">So far, we have analyzed what the distributions of the target and feature variables look like. In this chapter, we are going to focus on building features, using PCA.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Preparation for feature engineering</h1>
                
            
            <article>
                
<p class="calibre2">In order to fit the PCA, we will have to prepare our data first. Let's quickly look at the following code to load the credit card fraud data into Deedle's data frame:</p>
<pre class="calibre19">// Read in the Credit Card Fraud dataset<br class="title-page-name"/>// TODO: change the path to point to your data directory<br class="title-page-name"/>string dataDirPath = @"&lt;path-to-dir&gt;";<br class="title-page-name"/><br class="title-page-name"/>// Load the data into a data frame<br class="title-page-name"/>string dataPath = Path.Combine(dataDirPath, "creditcard.csv");<br class="title-page-name"/>Console.WriteLine("Loading {0}\n\n", dataPath);<br class="title-page-name"/>var df = Frame.ReadCsv(<br class="title-page-name"/>    dataPath,<br class="title-page-name"/>    hasHeaders: true,<br class="title-page-name"/>    inferTypes: true<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("* Shape: {0}, {1}\n\n", df.RowCount, df.ColumnCount);</pre>
<p class="calibre2"><span class="calibre5">Now that we have loaded the data into a variable, named <kbd class="calibre12">df</kbd>, we are going to have to split the data into two sets, one for normal credit card transaction data and another for fraudulent transaction data, so that we can fit PCA with the normal transactions only. Take a look at the following code for how we can separate out the normal transactions from the raw dataset:</span></p>
<pre class="calibre19">string[] featureCols = df.ColumnKeys.Where(<br class="title-page-name"/>    x =&gt; !x.Equals("Time") &amp;&amp; !x.Equals("Class")<br class="title-page-name"/>).ToArray();<br class="title-page-name"/><br class="title-page-name"/>var noFraudData = df.Rows[<br class="title-page-name"/>    df["Class"].Where(x =&gt; x.Value == 0.0).Keys<br class="title-page-name"/>].Columns[featureCols];<br class="title-page-name"/>double[][] data = BuildJaggedArray(<br class="title-page-name"/>    noFraudData.ToArray2D&lt;double&gt;(), noFraudData.RowCount, featureCols.Length<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">If you recall from the previous data analysis step, the target variable, <kbd class="calibre12">Class</kbd>, is encoded as 1 for fraudulent transactions and 0 for non-fraudulent transactions. As you can see from the code, we created a data frame, <kbd class="calibre12">noFraudData</kbd>, with only normal credit card transaction records. Then, we converted this data frame into a two-dimensional double array that will be used to fit the PCA, using the helper function, <kbd class="calibre12">BuildJaggedArray</kbd>. The code for this helper function looks like the following:</span></p>
<pre class="calibre19">private static double[][] BuildJaggedArray(double[,] ary2d, int rowCount, int colCount)<br class="title-page-name"/>{<br class="title-page-name"/>    double[][] matrix = new double[rowCount][];<br class="title-page-name"/>    for (int i = 0; i &lt; rowCount; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        matrix[i] = new double[colCount];<br class="title-page-name"/>        for (int j = 0; j &lt; colCount; j++)<br class="title-page-name"/>        {<br class="title-page-name"/>            matrix[i][j] = double.IsNaN(ary2d[i, j]) ? 0.0 : ary2d[i, j];<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/>    return matrix;<br class="title-page-name"/>}</pre>
<p class="calibre2">This code should look familiar, as we have used it in a number of previous chapters.</p>
<p class="calibre2">The next thing we need to do is convert the entire data frame, including both non-fraudulent and fraudulent records, into a two-dimensional array. U<span class="calibre5">sing the trained PCA, w</span>e are going to transform this newly created two-dimensional array that will later be used for building credit card fraud detection models. Let's take a look at the following code:</p>
<pre class="calibre19">double[][] wholeData = BuildJaggedArray(<br class="title-page-name"/>    df.Columns[featureCols].ToArray2D&lt;double&gt;(), df.RowCount, featureCols.Length<br class="title-page-name"/>);<br class="title-page-name"/>int[] labels = df.GetColumn&lt;int&gt;("Class").ValuesAll.ToArray();</pre>
<p class="calibre2">As you can see from this code snippet, we are simply converting the entire data frame, <kbd class="calibre12">df</kbd>, into a two-dimensional array, <kbd class="calibre12">wholeData</kbd>, by using the <kbd class="calibre12">BuildJaggedArray</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Fitting a PCA</h1>
                
            
            <article>
                
<p class="calibre2">We are now ready to fit a PCA using the non-fraudulent credit card data. Similar to what we did in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>, we are going to use the following code to fit a PCA:</p>
<pre class="calibre19">var pca = new PrincipalComponentAnalysis(<br class="title-page-name"/>    PrincipalComponentMethod.Standardize<br class="title-page-name"/>);<br class="title-page-name"/>pca.Learn(data);</pre>
<p class="calibre2"><span class="calibre5">As you can see from this code, we are using the <kbd class="calibre12">PrincipalComponentAnalysis</kbd> class in the Accord.NET framework to train a PCA. One more thing to note here is how we used <kbd class="calibre12">PrincipalComponentMethod.Standardize</kbd>. Since PCA is sensitive to the scales of the features, we are standardizing the feature values first and then fitting a PCA. Using this trained PCA, we can transform the whole data that contains both fraudulent and non-fraudulent transactions. The code for applying PCA transformation to the dataset looks as follows:</span></p>
<pre class="calibre19">double[][] transformed = pca.Transform(wholeData);</pre>
<p class="calibre2">Now, we have all the PCA features ready for the following model building step. Before we move one, let's see if we can find any noticeable patterns that can separate target classes with the new PCA features. Let's take a look at the following code first:</p>
<pre class="calibre19">double[][] first2Components = transformed.Select(x =&gt; x.Where((y, i) =&gt; i &lt; 2).ToArray()).ToArray();<br class="title-page-name"/>ScatterplotBox.Show("Component #1 vs. Component #2", first2Components, labels);<br class="title-page-name"/><br class="title-page-name"/>double[][] next2Components = transformed.Select(<br class="title-page-name"/>    x =&gt; x.Where((y, i) =&gt; i &gt;= 1 &amp;&amp; i &lt;= 2).ToArray()<br class="title-page-name"/>).ToArray();<br class="title-page-name"/>ScatterplotBox.Show("Component #2 vs. Component #3", next2Components, labels);<br class="title-page-name"/><br class="title-page-name"/>next2Components = transformed.Select(<br class="title-page-name"/>    x =&gt; x.Where((y, i) =&gt; i &gt;= 2 &amp;&amp; i &lt;= 3).ToArray()<br class="title-page-name"/>).ToArray();<br class="title-page-name"/>ScatterplotBox.Show("Component #3 vs. Component #4", next2Components, labels);<br class="title-page-name"/><br class="title-page-name"/>next2Components = transformed.Select(<br class="title-page-name"/>    x =&gt; x.Where((y, i) =&gt; i &gt;= 3 &amp;&amp; i &lt;= 4).ToArray()<br class="title-page-name"/>).ToArray();<br class="title-page-name"/>ScatterplotBox.Show("Component #4 vs. Component #5", next2Components, labels);</pre>
<p class="calibre2"><span class="calibre5">Similar to what we did in the data analysis step, we are taking two features and creating scatter plots of target classes across the selected features. From these plots, we can see if the principal components in the PCA-transformed data more effectively separate fraudulent credit card transactions from non-fraudulent transactions.</span></p>
<p class="calibre2">The following scatter plot applies between the first and second principal components:</p>
<div class="mce-root"><img src="../images/00174.jpeg" class="calibre123"/></div>
<p class="calibre2">There is a noticeable cutoff point that separates frauds (red points in the scatter plot) from non-frauds (blue points in the scatter plot). From this scatter plot, it seems fraudulent samples typically have Y-values (the second principal component values) of less than -5.</p>
<p class="calibre2">The following is a scatter plot between the second and third principal components:</p>
<div class="mce-root"><img src="../images/00175.jpeg" class="calibre124"/></div>
<p class="calibre2"><span class="calibre5">The pattern seems to be weaker in this plot, compared to the previous scatter plot, but there still seems to be a distinct line that separates many fraud cases from non-fraud cases.</span></p>
<p class="calibre2">The following scatter plot is between the third and fourth principal components:</p>
<div class="mce-root"><img src="../images/00176.jpeg" class="calibre125"/></div>
<p class="calibre2">And lastly, the following is a scatter plot between the fourth and fifth principal components:</p>
<div class="mce-root"><img src="../images/00177.jpeg" class="calibre126"/></div>
<p class="calibre2">In the last two scatter plots, we cannot find a noticeable pattern to separate the two target classes from each other. Given that there were some separable lines we could find when we looked at the first three principal components and their scatter plots, our anomaly detection model for credit card fraud detection will be able to learn how to classify frauds, when it learns from this data in a higher dimension and multiple principal components.</p>
<p class="calibre2"><span class="calibre5">Lastly, let's take a look at the proportion of variance explained by the principal components. Take a look at the following code first:</span></p>
<pre class="calibre19">DataSeriesBox.Show(<br class="title-page-name"/>    pca.Components.Select((x, i) =&gt; (double)i),<br class="title-page-name"/>    pca.Components.Select(x =&gt; x.CumulativeProportion)<br class="title-page-name"/>).SetTitle("Explained Variance");<br class="title-page-name"/>System.IO.File.WriteAllLines(<br class="title-page-name"/>    Path.Combine(dataDirPath, "explained-variance.csv"),<br class="title-page-name"/>    pca.Components.Select((x, i) =&gt; String.Format("{0},{1:0.0000}", i + 1, x.CumulativeProportion))<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">As we discussed in</span> <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>, <span class="calibre5">we can use the <kbd class="calibre12">Components</kbd> property within a <kbd class="calibre12">PrincipalComponentAnalysis</kbd> object to extract the cumulative proportion of variance explained by each component. As you can see from the third line in the code, we iterate through the <kbd class="calibre12">Components</kbd> property and extract <kbd class="calibre12">CumulativeProportion</kbd> values. Then, we display a line chart by using the <kbd class="calibre12">DataSeriesBox</kbd> class. When you run this code, you will see the following chart for the cumulative proportion of variance explained by the principal components:</span></p>
<div class="mce-root"><img src="../images/00178.jpeg" class="calibre127"/></div>
<p class="calibre2"><span class="calibre5">As you can see from this chart, by the twentieth principal component, about 80% of the variance in the data, is explained. We will use this chart to make a decision on how many principal components to use when we build an anomaly detection model in the following section.</span></p>
<p class="calibre2">Lastly, we need to export this data, as we just created a newly PCA-transformed dataset in this feature engineering step and we want to use this new data to build models. You can export this data by using the following code:</p>
<pre class="calibre19">Console.WriteLine("exporting train set...");<br class="title-page-name"/><br class="title-page-name"/>System.IO.File.WriteAllLines(<br class="title-page-name"/>    Path.Combine(dataDirPath, "pca-features.csv"),<br class="title-page-name"/>    transformed.Select((x, i) =&gt; String.Format("{0},{1}", String.Join(",", x), labels[i]))<br class="title-page-name"/>);</pre>
<p class="calibre2">As you can see from this code snippet, we are exporting this data into a CSV file named <kbd class="calibre12">pca-features.csv</kbd>. We will use this data to build anomaly detection models for credit card fraud detection in the following step.</p>
<p class="calibre2">The full code that was used in this feature engineering step can be found at the following link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/FeatureEngineering.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/FeatureEngineering.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">One-class SVM versus PCC</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">We are now ready to build anomaly detection models for the credit card fraud detection project. In this step, we are going to experiment with two different approaches. We are going to build a PCC, similarly to what we did in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>. Also, we are going to introduce a new learning algorithm, the one-class SVM, which learns from normal credit card transaction data and decides whether a new data point is similar to the normal data that it was trained with.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Preparation for model training</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">First, we need to load the data that we created in the previous feature-engineering step. You can use the following code to load the data:</span></p>
<pre class="calibre19">// Read in the Credit Card Fraud dataset<br class="title-page-name"/>// TODO: change the path to point to your data directory<br class="title-page-name"/>string dataDirPath = @"&lt;path-to-dir&gt;";<br class="title-page-name"/><br class="title-page-name"/>// Load the data into a data frame<br class="title-page-name"/>string dataPath = Path.Combine(dataDirPath, "pca-features.csv");<br class="title-page-name"/>Console.WriteLine("Loading {0}\n\n", dataPath);<br class="title-page-name"/>var featuresDF = Frame.ReadCsv(<br class="title-page-name"/>    dataPath,<br class="title-page-name"/>    hasHeaders: false,<br class="title-page-name"/>    inferTypes: true<br class="title-page-name"/>);<br class="title-page-name"/>featuresDF.RenameColumns(<br class="title-page-name"/>    featuresDF.ColumnKeys<br class="title-page-name"/>        .Select((x, i) =&gt; i == featuresDF.ColumnCount - 1 ? "is_fraud" : String.Format("component-{0}", i + 1))<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">If you recall from the previous feature-engineering step, we did not export the data with the column names. So, we are loading the data into a Deedle data frame, <kbd class="calibre12">featuresDF</kbd>, with the <kbd class="calibre12">hasHeaders</kbd> flag set to <kbd class="calibre12">false</kbd>. Then, we give the proper column names for each feature by using the <kbd class="calibre12">RenameColumns</kbd> method. Let's quickly check the target class distributions within this dataset, using the following code:</span></p>
<pre class="calibre19">Console.WriteLine("* Shape: ({0}, {1})", featuresDF.RowCount, featuresDF.ColumnCount);<br class="title-page-name"/><br class="title-page-name"/>var count = featuresDF.AggregateRowsBy&lt;string, int&gt;(<br class="title-page-name"/>    new string[] { "is_fraud" },<br class="title-page-name"/>    new string[] { "component-1" },<br class="title-page-name"/>    x =&gt; x.ValueCount<br class="title-page-name"/>).SortRows("component-1");<br class="title-page-name"/>count.RenameColumns(new string[] { "is_fraud", "count" });<br class="title-page-name"/>count.Print();</pre>
<p class="calibre2">The output of this code looks as follows:</p>
<div class="mce-root"><img src="../images/00179.jpeg" class="calibre128"/></div>
<p class="calibre2">As seen previously, in the data analysis step, the majority of the samples belong to non-fraudulent transactions and only a small portion of the data is fraudulent credit card transactions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Principal component classifier</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">We will first try to build an anomaly detection model using principal components, similar to what we did in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>. For training and testing a PCC model, we wrote a helper function, named <kbd class="calibre12">BuildPCAClassifier</kbd>. The detailed code for this helper function can be found at the following repo: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/Modeling.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/Modeling.cs</a>. Let's take a look at this helper function step by step.</span></p>
<p class="calibre2">You will see the following lines of code when you look at the code for the <kbd class="calibre12">BuildPCAClassifier</kbd> method:</p>
<pre class="calibre19">// First 13 components explain about 50% of the variance<br class="title-page-name"/>int numComponents = 13;<br class="title-page-name"/>string[] cols = featuresDF.ColumnKeys.Where((x, i) =&gt; i &lt; numComponents).ToArray();<br class="title-page-name"/><br class="title-page-name"/>// First, compute distances from the center/mean among normal events<br class="title-page-name"/>var normalDF = featuresDF.Rows[<br class="title-page-name"/>    featuresDF["is_fraud"].Where(x =&gt; x.Value == 0).Keys<br class="title-page-name"/>].Columns[cols];<br class="title-page-name"/><br class="title-page-name"/>double[][] normalData = BuildJaggedArray(<br class="title-page-name"/>    normalDF.ToArray2D&lt;double&gt;(), normalDF.RowCount, cols.Length<br class="title-page-name"/>);</pre>
<p class="calibre2">First, we are sub-selecting the first thirteen principal components that explain about 50% of the variance. Then, we create a non-fraudulent credit card transaction group, <kbd class="calibre12">normalDF</kbd> and <kbd class="calibre12">normalData</kbd>, so that we can use this subset to build an anomaly detection model.</p>
<p class="calibre2">The next thing we do is start computing the <strong class="calibre4">Mahalanobis distance</strong> metric to measure the distance between a data point and the distribution of the non-fraudulent credit card transactions. If you recall, we used the same distance metric in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>, and we recommend you review the <em class="calibre13">Model building</em> section in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>, for a more detailed explanation about this distance metric. The code to compute the distances looks like the following:</p>
<pre class="calibre19">double[] normalVariances = ComputeVariances(normalData);<br class="title-page-name"/>double[] rawDistances = ComputeDistances(normalData, normalVariances);<br class="title-page-name"/><br class="title-page-name"/>double[] distances = rawDistances.ToArray();<br class="title-page-name"/><br class="title-page-name"/>double meanDistance = distances.Average();<br class="title-page-name"/>double stdDistance = Math.Sqrt(<br class="title-page-name"/>    distances<br class="title-page-name"/>    .Select(x =&gt; Math.Pow(x - meanDistance, 2))<br class="title-page-name"/>    .Sum() / distances.Length<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "* Normal - mean: {0:0.0000}, std: {1:0.0000}",<br class="title-page-name"/>    meanDistance, stdDistance<br class="title-page-name"/>);</pre>
<p class="calibre2">As you can see from this code snippet, we are using two helper functions, <kbd class="calibre12">ComputeVariances</kbd> and <kbd class="calibre12">ComputeDistances</kbd>, to compute the variances of feature values and the distances. The following is the code for the <kbd class="calibre12">ComputeVariances</kbd> method:</p>
<pre class="calibre19">private static double[] ComputeVariances(double[][] data)<br class="title-page-name"/>{<br class="title-page-name"/>    double[] componentVariances = new double[data[0].Length];<br class="title-page-name"/><br class="title-page-name"/>    for (int j = 0; j &lt; data[0].Length; j++)<br class="title-page-name"/>    {<br class="title-page-name"/>        componentVariances[j] = data<br class="title-page-name"/>            .Select((x, i) =&gt; Math.Pow(data[i][j], 2))<br class="title-page-name"/>            .Sum() / data.Length;<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    return componentVariances;<br class="title-page-name"/>}</pre>
<p class="calibre2">This code should look familiar, as this is the same code we used in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>, to build a PCC model for cyber attack detection. Additionally, the following is the code for the <kbd class="calibre12">ComputeDistances</kbd> method:</p>
<pre class="calibre19">private static double[] ComputeDistances(double[][] data, double[] componentVariances)<br class="title-page-name"/>{<br class="title-page-name"/><br class="title-page-name"/>    double[] distances = data.Select(<br class="title-page-name"/>        (row, i) =&gt; Math.Sqrt(<br class="title-page-name"/>            row.Select(<br class="title-page-name"/>                (x, j) =&gt; Math.Pow(x, 2) / componentVariances[j]<br class="title-page-name"/>            ).Sum()<br class="title-page-name"/>        )<br class="title-page-name"/>    ).ToArray();<br class="title-page-name"/><br class="title-page-name"/>    return distances;<br class="title-page-name"/>}</pre>
<p class="calibre2">This code should also look familiar, as we used this same code in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em> as well. Using these two methods, we computed the mean and the standard deviation of the distance measures within the non-fraudulent transaction data. The output looks like the following:</p>
<div class="mce-root"><img src="../images/00180.jpeg" class="calibre129"/></div>
<p class="calibre2">With the distance measures within the normal transaction group computed, we now compute the distances between the fraudulent transactions and the distribution of non-fraudulent transactions. The following is the part of the <kbd class="calibre12">BuildPCAClassifier</kbd> code that computes the distances for frauds:</p>
<pre class="calibre19">// Detection<br class="title-page-name"/>var fraudDF = featuresDF.Rows[<br class="title-page-name"/>    featuresDF["is_fraud"].Where(x =&gt; x.Value &gt; 0).Keys<br class="title-page-name"/>].Columns[cols];<br class="title-page-name"/><br class="title-page-name"/>double[][] fraudData = BuildJaggedArray(<br class="title-page-name"/>    fraudDF.ToArray2D&lt;double&gt;(), fraudDF.RowCount, cols.Length<br class="title-page-name"/>);<br class="title-page-name"/>double[] fraudDistances = ComputeDistances(fraudData, normalVariances);</pre>
<p class="calibre2">As you can see from this code snippet, we first separate the fraud data from the whole dataset and create a two-dimensional array variable, <kbd class="calibre12">fraudData</kbd>, which we use for distance-measuring calculations. Then, using the <kbd class="calibre12">ComputeDistances</kbd> function that we wrote, we can compute the distances between the fraudulent credit card transactions and the distribution of non-fraudulent transactions. With these distances measures, we then start analyzing the fraud detection rates for each of the target false-alarm rates. Take a look at the following code snippet:</p>
<pre class="calibre19">// 5-10% false alarm rate<br class="title-page-name"/>for (int i = 0; i &lt; 4; i++)<br class="title-page-name"/>{<br class="title-page-name"/>    double targetFalseAlarmRate = 0.05 * (i + 1);<br class="title-page-name"/>    double threshold = Accord.Statistics.Measures.Quantile(<br class="title-page-name"/>        distances,<br class="title-page-name"/>        1 - targetFalseAlarmRate<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    int[] detected = fraudDistances.Select(x =&gt; x &gt; threshold ? 1 : 0).ToArray();<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("\n\n---- {0:0.0}% False Alarm Rate ----", targetFalseAlarmRate * 100.0);<br class="title-page-name"/>    double overallRecall = (double)detected.Sum() / detected.Length;<br class="title-page-name"/>    Console.WriteLine("* Overall Fraud Detection: {0:0.00}%", overallRecall * 100.0);<br class="title-page-name"/>}</pre>
<p class="calibre2">This code snippet should look familiar, as this is similar to what we did in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>. One thing that is different here, however, is the fact that we only have two target classes (fraud versus non-fraud), whereas we had five target classes (normal versus four different types of cyber attack) in <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em>. As you can see from this code, we experiment with five different target false alarm rates from 5% to 10%, and analyze the fraud detection rates for the given target false alarm rate. We will take a deeper look at this code in the following model evaluation step.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">One-class SVM</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The next approach we are going to explore for credit card fraud detection is training a</span> one-class SVM<span class="calibre5">. A one-class SVM is a special case of a SVM, where an SVM model is first trained with a data and then, when it sees a new data point, the SVM model can determine if the new data point is close enough to the data that it was trained with. For training a one-class SVM model, we wrote a helper function, <kbd class="calibre12">BuildOneClassSVM</kbd>, and the full code for this function can be found at the following repo: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/Modeling.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.10/Modeling.cs</a>. Let's go through this helper function step by step.</span></p>
<p class="calibre2">First, let's look at the part of the code that sub-selects non-fraudulent credit card transaction data that will be used to train the one-class SVM. The code looks like the following:</p>
<pre class="calibre19">// First 13 components explain about 50% of the variance<br class="title-page-name"/>int numComponents = 13;<br class="title-page-name"/>string[] cols = featuresDF.ColumnKeys.Where((x, i) =&gt; i &lt; numComponents).ToArray();<br class="title-page-name"/><br class="title-page-name"/>var rnd = new Random(1);<br class="title-page-name"/>int[] trainIdx = featuresDF["is_fraud"]<br class="title-page-name"/>    .Where(x =&gt; x.Value == 0)<br class="title-page-name"/>    .Keys<br class="title-page-name"/>    .OrderBy(x =&gt; rnd.Next())<br class="title-page-name"/>    .Take(15000)<br class="title-page-name"/>    .ToArray();<br class="title-page-name"/>var normalDF = featuresDF.Rows[<br class="title-page-name"/>    trainIdx<br class="title-page-name"/>].Columns[cols];<br class="title-page-name"/><br class="title-page-name"/>double[][] normalData = BuildJaggedArray(<br class="title-page-name"/>    normalDF.ToArray2D&lt;double&gt;(), normalDF.RowCount, cols.Length<br class="title-page-name"/>);</pre>
<p class="calibre2">Similar to the previous PCC model that we built, we are using the first thirteen principal components that explain about 50% of the total variance. Next, we are going to sub-select records <span class="calibre5">from the non-fraudulent transaction samples and build a</span> train set. As you can see from this code, we are randomly selecting 15,000 non-fraudulent samples as a train set.</p>
<p class="calibre2">Now that we have a train set to train a one-class SVM model with, let's take a look at the following code:</p>
<pre class="calibre19">var teacher = new OneclassSupportVectorLearning&lt;Gaussian&gt;();<br class="title-page-name"/>var model = teacher.Learn(normalData);</pre>
<p class="calibre2">We are using the <kbd class="calibre12">OneclassSupportVectorLearning</kbd> algorithm in the Accord.NET framework to train a one-class SVM model. As you can see, we built an SVM model with the <kbd class="calibre12">Gaussian</kbd> kernel in this chapter, but you can experiment with different kernels. Now, the only step left is to test this one-class SVM model that we just trained. The following code shows how we built a test set to evaluate this model:</p>
<pre class="calibre19">int[] testIdx = featuresDF["is_fraud"]<br class="title-page-name"/>    .Where(x =&gt; x.Value &gt; 0)<br class="title-page-name"/>    .Keys<br class="title-page-name"/>    .Concat(<br class="title-page-name"/>        featuresDF["is_fraud"]<br class="title-page-name"/>        .Where(x =&gt; x.Value == 0 &amp;&amp; !trainIdx.Contains(x.Key))<br class="title-page-name"/>        .Keys<br class="title-page-name"/>        .OrderBy(x =&gt; rnd.Next())<br class="title-page-name"/>        .Take(5000)<br class="title-page-name"/>        .ToArray()<br class="title-page-name"/>    ).ToArray();<br class="title-page-name"/><br class="title-page-name"/>var fraudDF = featuresDF.Rows[<br class="title-page-name"/>    testIdx<br class="title-page-name"/>].Columns[cols];<br class="title-page-name"/><br class="title-page-name"/>double[][] fraudData = BuildJaggedArray(<br class="title-page-name"/>    fraudDF.ToArray2D&lt;double&gt;(), fraudDF.RowCount, cols.Length<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>int[] fraudLabels = featuresDF.Rows[<br class="title-page-name"/>    testIdx<br class="title-page-name"/>].GetColumn&lt;int&gt;("is_fraud").ValuesAll.ToArray();</pre>
<p class="calibre2">As you can see from this code, we are taking all the fraud samples and 5,000 randomly sub-selected non-fraud samples as a test set. With this test set, we are going to evaluate how well this one-class SVM model performs at detecting credit card frauds.</p>
<p class="calibre2">We are going to look closer into the evaluation code in the following section, but let's take a quick look at how we can evaluate the performance of the one-class SVM model that we just trained. The code looks like the following:</p>
<pre class="calibre19">for(int j = 0; j &lt;= 10; j++)<br class="title-page-name"/>{<br class="title-page-name"/>    model.Threshold = -1 + j/10.0; <br class="title-page-name"/><br class="title-page-name"/>    int[] detected = new int[fraudData.Length];<br class="title-page-name"/>    double[] probs = new double[fraudData.Length];<br class="title-page-name"/>    for (int i = 0; i &lt; fraudData.Length; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        bool isNormal = model.Decide(fraudData[i]);<br class="title-page-name"/>        detected[i] = isNormal ? 0 : 1;<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("\n\n---- One-Class SVM Results ----");<br class="title-page-name"/>    Console.WriteLine("* Threshold: {0:0.00000}", model.Threshold);<br class="title-page-name"/>    double correctPreds = fraudLabels<br class="title-page-name"/>        .Select((x, i) =&gt; detected[i] == 1 &amp;&amp; x == 1 ? 1 : 0)<br class="title-page-name"/>        .Sum();<br class="title-page-name"/>    double precision = correctPreds / detected.Sum();<br class="title-page-name"/>    double overallRecall = correctPreds / fraudLabels.Sum();<br class="title-page-name"/>    Console.WriteLine("* Overall Fraud Detection: {0:0.00}%", overallRecall * 100.0);<br class="title-page-name"/>    Console.WriteLine("* False Alarm Rate: {0:0.00}%", (1 - precision) * 100.0);<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">As you can see from this code, we iterate through different values of thresholds, similar to how we set different thresholds for the previous PCC model. As in the third line of the code, you can use the <kbd class="calibre12">Threshold</kbd> property of the model to get or set the threshold that determines whether a record is normal or abnormal. Similar to how we evaluate the PCC, we are going to look at the fraud detection rate and the false-alarm rate for model validations.</span></p>
<p class="calibre2">The full code we used in the model building step can be found at the following link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/edit/master/ch.10/Modeling.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/edit/master/ch.10/Modeling.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Evaluating anomaly detection models</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">We have trained two anomaly detection models—one using principal components and another using a one-class SVM algorithm. In this section, we are going to take a closer look at the performance metrics and the codes used to evaluate these models.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Principal Component Classifier</h1>
                
            
            <article>
                
<p class="calibre2">As briefly mentioned in the previous section, we are going to look at the credit card fraud detection rates for each of the target false alarm rates. The code for evaluating the PCC model looks like the following:</p>
<pre class="calibre19">// 5-10% false alarm rate<br class="title-page-name"/>for (int i = 0; i &lt; 4; i++)<br class="title-page-name"/>{<br class="title-page-name"/>    double targetFalseAlarmRate = 0.05 * (i + 1);<br class="title-page-name"/>    double threshold = Accord.Statistics.Measures.Quantile(<br class="title-page-name"/>        distances,<br class="title-page-name"/>        1 - targetFalseAlarmRate<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    int[] detected = fraudDistances.Select(x =&gt; x &gt; threshold ? 1 : 0).ToArray();<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("\n\n---- {0:0.0}% False Alarm Rate ----", targetFalseAlarmRate * 100.0);<br class="title-page-name"/>    double overallRecall = (double)detected.Sum() / detected.Length;<br class="title-page-name"/>    Console.WriteLine("* Overall Fraud Detection: {0:0.00}%", overallRecall * 100.0);<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">Similar to <a target="_blank" href="part0116.html#3EK180-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 9</a>, <em class="calibre13">Cyber Attack Detection</em></span>, <span class="calibre5">we iterate through the target false alarm rates from 5% to 10% and inspect the detection rates for the given false alarm rates. Using the target false alarm rate variable, <kbd class="calibre12">targetFalseAlarmRate</kbd>, we compute the threshold using the <kbd class="calibre12">Accord.Statistics.Measures.Quantile</kbd> method. With this calculated threshold, we flag all records with distances greater than this threshold as fraud, and others as non-fraud.  Let's look at the evaluation results.</span></p>
<p class="calibre2">The following is the fraud detection rate at the 5% false alarm rate:</p>
<div class="mce-root"><img src="../images/00181.jpeg" class="calibre130"/></div>
<p class="calibre2"><span class="calibre5">The following is the fraud detection rate at the 10% false alarm rate:</span></p>
<div class="mce-root"><img src="../images/00182.jpeg" class="calibre131"/></div>
<p class="calibre2"><span class="calibre5">The following is the fraud detection rate at 15% false alarm rate:</span></p>
<div class="mce-root"><img src="../images/00183.jpeg" class="calibre132"/></div>
<p class="calibre2"><span class="calibre5">Lastly, the following is the fraud detection rate at 20% false alarm rate:</span></p>
<div class="mce-root"><img src="../images/00184.jpeg" class="calibre133"/></div>
<p class="calibre2"><span class="calibre5">As you can see from these results, as we relax and increase the target false alarm rate, the fraud detection rate improves. At the 5% target false alarm rate, we could only detect about 59% of the fraudulent transactions. However, at the 20% target false alarm rate, we can detect over 80% of the fraudulent credit card transactions.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">One-class SVM</h1>
                
            
            <article>
                
<p class="calibre2">Let's now take a look at how the one-class SVM model performed on the credit card fraud dataset. The code for the model evaluation looks like the following:</p>
<pre class="calibre19">for(int j = 0; j &lt;= 10; j++)<br class="title-page-name"/>{<br class="title-page-name"/>    model.Threshold = -1 + j/10.0; <br class="title-page-name"/><br class="title-page-name"/>    int[] detected = new int[fraudData.Length];<br class="title-page-name"/>    double[] probs = new double[fraudData.Length];<br class="title-page-name"/>    for (int i = 0; i &lt; fraudData.Length; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        bool isNormal = model.Decide(fraudData[i]);<br class="title-page-name"/>        detected[i] = isNormal ? 0 : 1;<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("\n\n---- One-Class SVM Results ----");<br class="title-page-name"/>    Console.WriteLine("* Threshold: {0:0.00000}", model.Threshold);<br class="title-page-name"/>    double correctPreds = fraudLabels<br class="title-page-name"/>        .Select((x, i) =&gt; detected[i] == 1 &amp;&amp; x == 1 ? 1 : 0)<br class="title-page-name"/>        .Sum();<br class="title-page-name"/>    double precision = correctPreds / detected.Sum();<br class="title-page-name"/>    double overallRecall = correctPreds / fraudLabels.Sum();<br class="title-page-name"/>    Console.WriteLine("* Overall Fraud Detection: {0:0.00}%", overallRecall * 100.0);<br class="title-page-name"/>    Console.WriteLine("* False Alarm Rate: {0:0.00}%", (1 - precision) * 100.0);<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">As you can see from this code, we iterate through different thresholds from -1.0 to 0.0, in increments of 0.1. You can set the threshold for the model by updating the <kbd class="calibre12">Threshold</kbd> property of the one-class SVM model object. This threshold will instruct the model on how to determine which record is fraudulent and which is not. When making a decision on the final model, you will need to experiment with different values for thresholds to settle on the best threshold that fits your requirements. Let's take a look at some of the performance results.</span></p>
<p class="calibre2">The following shows the performance metrics for the threshold at -0.4:</p>
<div class="mce-root"><img src="../images/00185.jpeg" class="calibre134"/></div>
<p class="calibre2"><span class="calibre5">The following shows the performance metrics for the threshold at -0.3:</span></p>
<div class="mce-root"><img src="../images/00186.jpeg" class="calibre135"/></div>
<p class="calibre2"><span class="calibre5">The following shows the performance metrics for the threshold at -0.2:</span></p>
<div class="mce-root"><img src="../images/00187.jpeg" class="calibre136"/></div>
<p class="calibre2">Lastly, t<span class="calibre5">he following shows the performance metrics for the threshold at -0.1:</span></p>
<div class="mce-root"><img src="../images/00188.jpeg" class="calibre137"/></div>
<p class="calibre2">As you can see from these results, as we increase the threshold, the false alarm rate decreases, but the fraud detection rate decreases as well. It is clear that there is a trade-off between higher precision and a higher fraud detection rate. At a threshold of -0.4, the model was able to detect about 70% of the fraudulent credit card transactions with a roughly 40% false alarm rate. On the other hand, at a threshold of -0.1, the model could only detect about 57% of the fraudulent credit card transactions, but the false alarm rate was only about 33%.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">In this chapter, we built another anomaly detection model for credit card fraud detection. We started this chapter by looking at the structure of the anonymized credit card fraud data, and then started analyzing the distributions of the target and feature variables. While we were analyzing the distribution of the target classes, we noticed that there was a large class imbalance between the fraud and non-fraud classes. This is normal when we face any kind of anomaly detection project, where the normal class outweighs by far the positive class. Then, we started analyzing the distributions of the anonymized features. Due to the fact that the features were anonymized for confidentiality issues, we could not arrive at any intuitions from the dataset.</span></p>
<p class="calibre2"><span class="calibre5">However, we were able to understand the distributions better and how we cannot easily separate frauds from non-frauds using raw features. We then applied PCA and exported the PCA features for the model building step. We experimented with two approaches to building a credit card fraud detection model—the Principal Component Classifier and the one-class SVM. We evaluated the performances of these models by looking at the fraud detection rates at various false alarm rates. It was clear that there are trade-offs between improving the false alarm rates and improving the fraud detection rates.</span></p>
<p class="calibre2"><span class="calibre5">This chapter was the last chapter about building ML models in C#. In the next chapter, we are going to summarize what we have done so far throughout all the chapters, and what additional real-life challenges there are when building ML models. Also, we are going to discuss some other software packages, as well as some other data-science technologies out there, that can be used for your future ML projects.</span></p>


            </article>

            
        </section>
    </body></html>