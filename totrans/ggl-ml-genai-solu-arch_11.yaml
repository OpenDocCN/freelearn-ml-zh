- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural Networks and Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will discuss **neural networks** (**NNs**) in **machine
    learning** (**ML**), often referred to as **artificial NNs** or **ANNs**. We will
    introduce many important topics in this field of science, including fundamental
    concepts that led to the development of ANNs, and relevant use cases for their
    application. At this point, it’s important to note that the term **deep learning**
    (**DL**) refers to ML that is implemented with the use of **deep NNs** (**DNNs**).
    We will explain the term “DNN” later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We will also introduce some tools and frameworks that make it easier for us
    to create NNs, such as TensorFlow and Keras, and we will use those tools to build
    an NN in our hands-on activities later in this chapter. Finally, we will expand
    the discussion to include different types of NN architectures, common challenges
    in NN implementations, and some practices for optimizing our NN architectures.
  prefs: []
  type: TYPE_NORMAL
- en: As a side note, I first started learning about ANNs when I was in college, and
    I remember being absolutely fascinated by the concept because I also had an avid
    interest in understanding how the human brain works. Although the concept of NNs
    is indeed loosely based on the theorized workings of the human brain, in this
    chapter, we will separate hype from reality and will focus on the practical, mathematical
    descriptions of this technology. Let’s start by covering some important concepts
    in this space.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: NN and DL concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a **multilayer perceptron** (**MLP**) in TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NN architectures, challenges, and optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NN and DL concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we discuss concepts that are important to understand in the
    context of NNs and DL. We begin by discussing how ANNs are linked to our understanding
    of the human brain.
  prefs: []
  type: TYPE_NORMAL
- en: Neurons and the perceptron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While the link between artificial neurons and biological neurons (as found
    in the human brain) is often over-emphasized, there is a conceptual link between
    them that helps us form a mental model of how they work. Biological neurons generally
    consist of three main parts, as depicted in *Figure 9**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1: Neuron (source: https://www.flickr.com/photos/187096960@N06/51173238594)](img/B18143_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: Neuron (source: https://www.flickr.com/photos/187096960@N06/51173238594)'
  prefs: []
  type: TYPE_NORMAL
- en: The cell body is the core part of the neuron that contains the nucleus and other
    important components. The dendrites (coming from the Greek word “dendron,” meaning
    “tree”) are structures that branch out from the cell body. They receive information
    from other neurons and transmit this information to the cell body. Finally, the
    axons are long, tube-like structures that extend from the cell body and send information
    out to the dendrites of other neurons (across an interface called a synapse).
    That’s about as deep as we’re going to get with regard to the biology of a neuron;
    I’ve simplified it quite a bit here because we just need high-level context for
    the comparison we’re going to make with ANNs, but the next thing we need to understand
    is how they transmit information, and this works at a high level as follows (again,
    simplified for relevant context).
  prefs: []
  type: TYPE_NORMAL
- en: When a neuron receives a signal from another neuron, this causes a change in
    what’s called the **electrical potential** across the neuron’s cell membrane (the
    difference in voltage between the inside and outside of the neuron), triggering
    what’s called an **action potential**, which is an electrical impulse that travels
    down the axon. When it reaches the end of the axon, it triggers the release of
    neurotransmitters, which are chemical messengers. These neurotransmitters cross
    something called the **synaptic gap** (the tiny space between neurons) and bind
    to receptors on the dendrites of the next neuron, and this binding can then either
    trigger or inhibit a new action potential in the second neuron.
  prefs: []
  type: TYPE_NORMAL
- en: Okay – we’ve just introduced a lot of biological terminology in the past two
    paragraphs, but those concepts are important to understand when we want to draw
    a comparison with ANNs. With this in mind, let’s move on and discuss how ANNs
    are constructed, beginning with their most basic concept, the perceptron, which
    I briefly mentioned in [*Chapter 1*](B18143_01.xhtml#_idTextAnchor015) when I
    summarized various milestones in the evolution of ML.
  prefs: []
  type: TYPE_NORMAL
- en: A perceptron can be seen as one of the simplest types of ANNs and as a building
    block for larger, more complex networks. It was developed by Frank Rosenblatt
    in the late 1950s, and it’s basically a binary classifier that maps its input
    X (a vector) to an output value f(x) (a single binary value) using a set of weights
    that are applied to the input features.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this process in more detail, let’s dive deeper into how a perceptron
    works, which can be summarized using the following set of steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The perceptron receives input values, which could be features or attributes
    from a dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each input has an associated **weight** that represents its importance. The
    weights are often just given random values at the beginning of training, and the
    values are then refined during the training process. We will discuss this in more
    detail shortly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A **bias unit** is also added to the perceptron model to increase the model’s
    flexibility. This is not related to the topic of bias that we will discuss in
    the context of fairness in later chapters of this book; it’s simply a mathematical
    trick that provides an additional control mechanism for refining our model’s performance
    when attempting to produce the desired output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, each input is multiplied by its corresponding weight, and all of the results
    of those multiplications are added together (as well as the bias), which results
    in a **weighted sum**, so this is simply a **linear transformation** of the inputs,
    based on the weights and bias values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This weighted sum is then passed through an **activation function** that produces
    a binary output. We will explain activation functions in more detail shortly,
    but at a high level, a non-linear transformation is performed on the weighted
    sum, and the results of that transformation are produced as an output from the
    perceptron. In the case of a single perceptron, a simple example would be that
    if the weighted sum of the inputs is greater than a threshold value, the perceptron
    would output a value of 1, or if the weighted sum is less than or equal to the
    threshold, it would output a value of 0, so this is basically an implementation
    of the process referred to as **logistic regression**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Mathematically, this can be written as the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If ∑ (weights * inputs) + bias > 0, output 1
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If ∑ (weights * inputs) + bias ≤ 0, output 0
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 9**.2* provides a visual representation of how a perceptron works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2: Perceptron (source: https://commons.wikimedia.org/wiki/File:Perceptron-unit.svg#file)](img/B18143_09_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: Perceptron (source: https://commons.wikimedia.org/wiki/File:Perceptron-unit.svg#file)'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 9**.2*, the *x* values on the far left of the diagram represent inputs
    to the perceptron. The *x*0 input is the bias, and *x*1 through *x*n represent
    the input features from our dataset. The *w* values represent the weights, the
    Greek characters (sigma and phi) within the green circle represent the activation
    function, and the Greek character (omicron) on the far right represents the output.
  prefs: []
  type: TYPE_NORMAL
- en: The important concept to understand is that the values of the weights and bias
    are what our perceptron model is trying to learn. That is, our model is trying
    to figure out what the best weights are for each feature, which results in a pattern
    that gets us as close as possible to the target outcome after we perform the linear
    and non-linear transformations we described (in combination with the bias). If
    we think back to the more traditional ML models we created in earlier chapters,
    such as linear regression, you may remember that our models were trying to figure
    out the optimal values of the coefficients for each of our features that would
    result in the desired outcomes. In perceptrons, and in ANNs in general, the weights
    (and the bias) are the coefficients that our models are trying to optimize.
  prefs: []
  type: TYPE_NORMAL
- en: With this understanding of how perceptrons work, let’s discuss how they can
    be used to build more complex NNs.
  prefs: []
  type: TYPE_NORMAL
- en: MLPs and NNs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While the perceptron is a simple and powerful algorithm, it can only model linearly
    separable functions. This means that if our data isn’t linearly separable (that
    is, we can’t draw a straight line to separate the classes), the perceptron won’t
    be able to accurately distinguish between the classes in the dataset. To overcome
    this limitation, multiple perceptrons can be combined in layers to form an MLP,
    which has the potential to solve non-linear problems. An MLP is a form of NN,
    so basically, when we combine multiple perceptrons in a sequential manner (that
    is, where the outputs of some perceptrons become the inputs for other perceptrons),
    we form a type of ANN.
  prefs: []
  type: TYPE_NORMAL
- en: Considering that the perceptron can be considered a type of artificial neuron,
    we will use the terms “perceptron” and “artificial neuron” (or sometimes just
    “neuron”) interchangeably from this point onward.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing the comparison to biological neural activity
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we’ve already discussed, a neuron receives inputs from sensory organs or
    from other neurons, and, depending on the resulting electrical potential, an action
    potential causes the neuron to fire (or not fire) a message to other neurons.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, a perceptron (or artificial neuron) receives inputs from our dataset,
    or from other artificial neurons if we are chaining the perceptrons together in
    an NN. Then, depending on the linear combination of these inputs and their weights
    and biases, the activation function will influence the output of the perceptron,
    which can be used as an input to another perceptron in the network.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s dive into more detail on how NNs are typically structured, and introduce
    the important concept of **layers** in NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Layers in an NN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When artificial neurons are combined together to form an NN, they are not just
    connected randomly but instead are connected in a structured manner using the
    concept of layers, as depicted in *Figure 9**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3: NN layers](img/B18143_09_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: NN layers'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in *Figure 9**.3*, the layers of an NN are generally categorized into
    three different types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The input layer**, which, as the name suggests, is how our inputs enter our
    NN. It is, of course, the first layer in the network.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hidden layers**, which sit between the input and output layers. Their job
    is to transform the inputs into something the output layer can use. The term “hidden”
    just means that they do not interface with the outside world (they are neither
    the input nor the output of the network). We usually do not have control over
    or direct interaction with them; they learn to represent the data on their own.
    The number of hidden layers and the number of neurons in each hidden layer define
    the complexity and structure of the NN.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The output layer**, which, again suggested by the name, presents the output
    of our NN, which is usually some kind of prediction.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In addition to the number of hidden layers and the number of neurons in each
    hidden layer, exactly how the layers are connected together depends on the architecture
    of the NN. We will discuss different types of common NN architectures later in
    this chapter, but what generally happens is that after our input data is fed into
    the NN’s input layer, each neuron in the subsequent layers of the network behaves
    similarly to how we described the perceptron earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: For example, each input is assigned a weight that represents its importance.
    These weights are typically initialized with random values and then refined during
    the learning process. The inputs are multiplied by their corresponding weights
    and the results are summed together, in addition to a bias value. The summed result
    is then used as the input to the activation function in a neuron in the subsequent
    layer (that is, beginning with the first hidden layer) of the NN. Generally, this
    process is performed by every neuron in the subsequent layers. The important thing
    to remember is that the weights and biases will be different for each neuron.
    Therefore, even though the exact same input data is seen by each neuron in the
    first hidden layer, how each neuron reacts to the data will vary because the various
    weights and biases will influence each neuron’s activation function differently.
  prefs: []
  type: TYPE_NORMAL
- en: The next thing to understand is that the outputs from the activation functions
    in each layer serve as inputs to the same process that will be performed again
    in subsequent layers of the network. So, the same process that we just described
    will be performed in each subsequent layer, but rather than our original dataset
    being used as an input in every layer, each subsequent layer will use the activation
    values from the previous layer as the input. This means that multiple transformations
    are being implemented as information travels through our network, and this is
    what makes NNs so powerful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s just be sure we have a clear understanding of this process. If we take
    the second hidden layer as an example, the process works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Each activation function output from the first layer is assigned a weight that
    represents its importance. These weights are typically initialized with random
    values and then refined during the learning process. The activation function outputs
    are multiplied by their corresponding weights and the results are summed together,
    in addition to the bias values. The summed result is then used as the input to
    the activation function in the neurons in the next layer of the NN. This process
    is repeated in each layer until we get to the final, output layer of the network.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Different NN architectures can use slightly different ways of propagating information
    through the network. We will discuss some common types of NN architectures in
    more detail in this chapter, but what we’ve described so far can be considered
    the building blocks of how ANNs work.
  prefs: []
  type: TYPE_NORMAL
- en: You may also hear the term “DNN” being used. Traditionally, any NN with at least
    two hidden layers is considered a DNN.
  prefs: []
  type: TYPE_NORMAL
- en: The fact that activations in neurons in one layer of the network influence the
    activations of neurons in the next layer brings us back to the loose analogy with
    the human brain, in which certain neurons firing can cause other neurons to fire,
    resulting in varied combinations of interactions that can produce much more complex
    higher-level functions. We must take this analogy with a pinch of salt, however,
    because even the most complex ANNs contain thousands of neurons, whereas the human
    brain has billions of neurons, and each neuron is capable of much more complex
    functionality than the relatively simple mathematical transformations performed
    by artificial neurons.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve discussed how information travels through an ANN, let’s dive
    into more detail on how an ANN learns, and to do that, we must introduce the concept
    of **backpropagation**.
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What we described in the previous section can be referred to as **forward propagation**,
    whereby information is being propagated forward from one layer to another in our
    NN. In order to discuss backpropagation, let’s think back on what we learned earlier
    in this book with regard to how **supervised ML** (**SML**) algorithms work. Remember
    that we use labels to describe what each data point is in our dataset. When we
    train a model, the model tries to learn patterns between the features in our dataset
    that will help it accurately predict the label for each data point. We then use
    a loss function to calculate how far off our model’s predictions were from the
    correct label; the primary purpose of the model training activity is to minimize
    the loss function (that is, to minimize the errors produced by our model), and
    we can use techniques such as gradient descent to minimize the loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a basic linear regression model trained on tabular data as an example.
    You may remember that in such a case, each row in the table of our dataset represents
    a data point or observation, and each column in the table is a feature. The linear
    regression model tries to guess which coefficients it could use for each feature,
    such that multiplying each feature by its coefficient and adding all of the results
    together would result in something as close as possible to the target label.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of linear regression, each time the model predicted incorrectly,
    we would use the loss function to calculate the error, then calculate the gradients
    of the loss function with respect to each coefficient, and then use gradient descent
    to determine how to adjust the coefficients accordingly, and the process would
    repeat many times until the model improved or was stopped for some reason.
  prefs: []
  type: TYPE_NORMAL
- en: This is where NNs become more complex than the simple regression models we implemented
    earlier in this book. In the case of NNs, we don’t have a one-to-one mapping of
    input features to coefficients. Instead, our data propagates through a complex
    network consisting of multiple layers, which each contain multiple neurons, and
    each neuron in each layer has a different set of weights (and bias values). Therefore,
    when our model makes a prediction and we use a loss function to calculate the
    error, it’s no longer simply a case of calculating the loss function’s gradient
    with respect to the coefficient of each input feature and then updating each feature’s
    coefficient and trying again. Instead, we must perform that process for all of
    the weights in each layer of the NN. One way to do this is referred to as “backward
    propagation of errors” or “backpropagation.”
  prefs: []
  type: TYPE_NORMAL
- en: With backpropagation, we update the weights in each layer, starting with the
    last layer (that is, the one closest to our output layer, which represents our
    model’s prediction), and then moving back through our network, layer by layer.
  prefs: []
  type: TYPE_NORMAL
- en: Since the loss function for our NN is composed of several nested functions (due
    to the layers in the network), the calculation of gradients in the backpropagation
    step uses something called the **chain rule**, which is a technique in calculus
    to compute the derivatives of the loss function with respect to the weights in
    each layer. These results are then used to determine how to update the weights
    in each pass through the network.
  prefs: []
  type: TYPE_NORMAL
- en: We will come back to the topic of backpropagation and the chain rule later in
    this chapter, but first, let’s dive into more detail on what kinds of algorithms
    we can use to optimize our cost function in each training pass.
  prefs: []
  type: TYPE_NORMAL
- en: Cost function optimization algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve already discussed using mechanisms such as gradient descent for optimizing
    our cost function during model training. In this section, we will briefly discuss
    some other common types of optimization algorithms that we can use.
  prefs: []
  type: TYPE_NORMAL
- en: Momentum
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This can be considered an upgrade to the basic gradient descent algorithm. When
    we discuss gradient descent in cost function optimization, we often use the analogy
    of walking downhill in a mountainous landscape until we reach the bottom of the
    mountain (or at least the bottom of a valley, which could be a “local minimum”).
    In the case of **stochastic gradient descent** (**SGD**), the analogy is more
    akin to jumping around somewhat randomly, in which case we may sometimes jump
    a little bit uphill (that is, in the incorrect direction), but overall, we usually
    end up going downhill (that is, in the correct direction). This case of jumping
    around in slightly different directions is referred to as **oscillating**. The
    Momentum algorithm accelerates SGD by navigating more prominently in the correct
    directions and reducing oscillations in incorrect directions. It does this by
    averaging the gradients of the updates in each step, which results in a smoother
    descent down the error gradient and often leads to reaching the bottom more quickly.
    The analogy used in this case is that of a ball rolling down the hill, in which
    case the movements are smoother than jumping around sporadically. Note that the
    ball can also gain momentum, which can help it to perform better even when the
    slope of the gradient is small (small gradient slopes result in slower learning
    for traditional gradient descent). In practice, Momentum almost always outperforms
    basic gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive Gradient Algorithm (Adagrad)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Adagrad, as the name suggests, is an adaptive optimization algorithm. That is,
    in each optimization cycle, Adagrad adapts the learning rate to each individual
    parameter. It performs smaller updates for parameters that have large gradients
    and larger updates for parameters with small gradients, which makes it particularly
    useful for dealing with sparse data and DL models with millions of parameters.
    Although it can be a useful algorithm, it can cause the learning rate to get too
    small too quickly, and effectively stop learning. This can be a problem in long
    training scenarios (such as in DL) where the learning process could prematurely
    stop. More recent variants such as **Root Mean Square Propagation** (**RMSProp**)
    and **Adaptive Moment Estimation** (**Adam**) were developed to tackle this issue,
    and we will discuss those next.
  prefs: []
  type: TYPE_NORMAL
- en: RMSProp
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: RMSProp resolves Adagrad’s rapidly diminishing learning rates by dividing the
    learning rate over a **moving average** (**MA**) of the squared gradients. Basically,
    it’s faster and often better than Adagrad.
  prefs: []
  type: TYPE_NORMAL
- en: Adam
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Adam combines the benefits of Momentum and RMSProp. It averages the gradients
    (like Momentum) and uses squared gradients (like RMSProp). It’s often the best
    choice of optimizer, especially for DL.
  prefs: []
  type: TYPE_NORMAL
- en: There are many more optimization algorithms in addition to the ones we have
    covered in this section, and we may use other optimizers in later chapters, but
    we will use Adam in this chapter, so for now, we’re just introducing the popular
    algorithms that Adam builds upon.
  prefs: []
  type: TYPE_NORMAL
- en: We will dive deeper into one more important concept before we begin our hands-on
    activities, and that is the concept of activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we’ve touched upon the topic of activation functions and how they work
    at a high level. In this section, we dive into more details on this topic and
    discuss some common types of activation functions that we can use in our NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Linear (identity) activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This activation function simply returns whatever input we provide to it, unchanged,
    and it’s typically used for simple tasks, or it’s often used as the output layer
    in regression use cases.
  prefs: []
  type: TYPE_NORMAL
- en: It is represented mathematically as f(x) = x.
  prefs: []
  type: TYPE_NORMAL
- en: This is generally not something we would use for the hidden layers in our network
    because it doesn’t allow for any kind of complex relationships to be learned.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to specifically call out the significance of non-linear transformations
    in NNs because the main power of NNs is their ability to combine multiple non-linear
    transformations in order to learn complex relationships in the data. Non-linear
    activation functions are, therefore, an important ingredient in complex NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Even if we combined many layers together in our network, if all of them just
    implemented a linear transformation, our whole network would just perform one
    big linear transformation, which we could implement without the need for NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The sigmoid function is an implementation of logistic regression, which maps
    any input into a range between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: It is represented mathematically as f(x) = 1 / (1 + exp(-x)).
  prefs: []
  type: TYPE_NORMAL
- en: 'See *Figure 9**.4* for a visual representation of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4: Sigmoid function (source: https://commons.wikimedia.org/wiki/File:Sigmoid-function-2.svg)](img/B18143_09_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.4: Sigmoid function (source: https://commons.wikimedia.org/wiki/File:Sigmoid-function-2.svg)'
  prefs: []
  type: TYPE_NORMAL
- en: The sigmoid function is one of the simpler activation functions, and it has
    generally been superseded by newer functions that we will discuss next. One of
    its limitations is that it is susceptible to a problem known as the vanishing
    gradient problem, which we will describe later in this chapter. However, it can
    still be useful in the context of output neurons in binary classification problems,
    where we interpret the output as the probability of the input being in one class
    or the other.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperbolic tangent (tanh) activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The tanh function is like the sigmoid function but it maps any input to a value
    in the range between -1 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: It is represented mathematically as f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)).
  prefs: []
  type: TYPE_NORMAL
- en: 'See *Figure 9**.5* for a visual representation of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5: tanh function (source: https://commons.wikimedia.org/wiki/File:Mplwp_tanh.svg)](img/B18143_09_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5: tanh function (source: https://commons.wikimedia.org/wiki/File:Mplwp_tanh.svg)'
  prefs: []
  type: TYPE_NORMAL
- en: Like the sigmoid function, tanh also suffers from the vanishing gradient problem,
    but it can still be useful in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Rectified Linear Unit (ReLU) activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ReLU function has become very popular in the last few years. Quite simply,
    it maps any positive number to itself and any negative number to zero.
  prefs: []
  type: TYPE_NORMAL
- en: It is represented mathematically as f(x) = max(0, x).
  prefs: []
  type: TYPE_NORMAL
- en: 'See *Figure 9**.6* for a visual representation of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6: ReLU function](img/B18143_09_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6: ReLU function'
  prefs: []
  type: TYPE_NORMAL
- en: A major benefit of ReLU is that it is computationally efficient because the
    function is essentially just checking whether the input is greater than zero and
    simply returning the input directly if it is greater than zero, or returning zero
    if it isn’t. This is an easy mathematical computation to perform, and this simplicity
    leads to much faster training.
  prefs: []
  type: TYPE_NORMAL
- en: Another major benefit is that it doesn’t suffer from the vanishing gradient
    problem. However, it suffers from another problem known as the dying ReLU problem,
    which is a phenomenon where neurons effectively become useless due to consistently
    outputting zero. This happens because when the inputs are zero, or negative, then
    the gradient of the function becomes zero. This means that during backpropagation,
    when the weights get updated, the weights of that neuron will not be adjusted.
    This situation leads to the neuron becoming “stuck” and continually outputting
    zero – effectively causing the neuron to “die” and play no role in discriminating
    the input.
  prefs: []
  type: TYPE_NORMAL
- en: Leaky ReLU activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This function attempts to solve the dying ReLU problem by outputting small negative
    values when the input is less than zero.
  prefs: []
  type: TYPE_NORMAL
- en: It is represented mathematically as f(x) = max(0.01x, x).
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the value of 0.01 represents a small, nonzero gradient for x,
    and it’s a hyperparameter that can be changed.
  prefs: []
  type: TYPE_NORMAL
- en: 'See *Figure 9**.7* for a visual representation of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7: Leaky ReLU](img/B18143_09_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.7: Leaky ReLU'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in *Figure 9**.7*, Leaky ReLU avoids the problem of the outputs
    becoming zero, even when the input is negative. There is also an extension of
    Leaky ReLU called **Parametric ReLU** (**PReLU**), which allows the small, nonzero
    gradient for x to be learned by backpropagation during learning, rather than specifying
    it as a static number via a hyperparameter.
  prefs: []
  type: TYPE_NORMAL
- en: Softmax activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The softmax function is often used for the output layer of an NN in multiclass
    classification use cases, where it transforms the raw outputs of the network into
    a vector of probabilities (that is, creating a probability distribution for the
    classes).
  prefs: []
  type: TYPE_NORMAL
- en: It is represented mathematically as f(xi) = exp(xi) / Σ(exp(xj)), where j runs
    over the set of neurons in the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: It’s an extension of the sigmoid function; while the sigmoid function can be
    used to provide the probability that the input is a member of one class or another
    (in a selection between two classes), the softmax function can provide the range
    of probabilities of the input being a member of multiple classes. For example,
    if our network tries to identify images of numbers between 1 and 10, then there
    are 10 possible classes to choose from. If we provide an image of the number 1
    and use softmax in the output layer of our network, it would hopefully determine
    that the number in the image has a high probability of being 1 and lower probabilities
    for each of the other potential classes (that is, 2 through 10).
  prefs: []
  type: TYPE_NORMAL
- en: There are more activation functions in addition to the ones we have covered
    in this section, but the ones we’ve covered here are among the most well known
    and widely used. Our choice of activation function can depend on the specific
    use case and other factors.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered many of the important theoretical concepts in the field
    of DL, let’s put what we’ve learned into practice by building our first NN. To
    do that, we’re going to introduce some important libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we describe the libraries we will use in this chapter, such
    as TensorFlow and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TensorFlow is an **open source software** (**OSS**) library developed by the
    Google Brain team for ML and DNN research. However, it is also possible to run
    it on a wide range of systems, from mobile devices to multi-GPU setups, and it
    can have many applications beyond just ML. In this section, we will discuss some
    of its important aspects, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Tensors, which are a generalization of vectors and matrices in multiple dimensions
    (we can think of them as multi-dimensional arrays or lists). They are the basic
    building blocks in TensorFlow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data-flow graphs** (**DFGs**), in which nodes in the graph represent mathematical
    operations and edges represent the data (tensors) transmitted between these nodes.
    This approach enables parallel computation across multiple devices, making TensorFlow
    suitable for training large NNs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple options for model deployment, such as TensorFlow Serving for server-side
    deployments or TensorFlow Lite for mobile and IoT devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backpropagation optimization by automatically computing the gradient of the
    loss with respect to the model weights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anyone interested in ML and DL should be familiar with TensorFlow because it
    is widely used in the industry.
  prefs: []
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Keras is a high-level NN API written in Python that can run on top of lower-level
    frameworks such as TensorFlow, Theano, and **Cognitive Toolkit** (**CNTK**). It
    was developed to enable fast experimentation and has become the official high-level
    API of TensorFlow (as of TensorFlow 2.0). Some of its main features include the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User-friendliness**: It has a simple and consistent interface that has been
    optimized for common use cases, and it provides clear error messages, as well
    as useful documentation and developer guides.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modularity**: A Keras model is assembled by connecting configurable building
    blocks together. For example, we can easily construct an NN by stacking multiple
    layers together.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extensibility**: We can write custom building blocks to express new ideas
    for research, and create new layers, loss functions, and models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The core data structure of Keras is a model, which is a way to organize layers.
    The main type of model is the Sequential model, which is a linear stack of layers,
    but for more complex architectures, we can use the Keras functional API, which
    allows us to build our own custom graphs of layers. A layer in Keras is a class
    that implements common NN operations, and Keras includes a wide range of pre-defined
    layers that we can use to build our models. It also allows us to specify the loss
    function and the metrics we want to evaluate during the training phase, and it
    provides many pre-defined loss functions such as `mean_squared_error` and metrics
    such as `accuracy`. Keras also includes many optimization algorithms, such as
    SGD. Overall, it includes lots of useful tools that make it easy for us to create
    NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve introduced the relevant libraries, let’s dive in and build our
    first NN!
  prefs: []
  type: TYPE_NORMAL
- en: Implementing an MLP in TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will build an MLP using TensorFlow. We will use Keras as
    the high-level API for interacting with TensorFlow. We can use the same Vertex
    AI Workbench notebook we created in [*Chapter* *5*](B18143_05.xhtml#_idTextAnchor168)
    for this purpose. In that notebook, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate into the folder named `Google-Machine-Learning-for-Solutions-Architects`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Double-click on the `Chapter-09` folder within it and then double-click on the
    `Chapter-9-TF-Keras.ipynb` file to open it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When prompted to select a kernel, select **TensorFlow**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The notebook we have opened contains some Python code that creates and tests
    an MLP using Keras and TensorFlow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run each of the cells in the notebook by clicking on each cell and pressing
    *Shift* + *Enter* on your keyboard. If you see any errors related to CUDA, you
    can ignore them because we are not using GPUs in this notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our code in the first cell of the notebook imports the necessary libraries and
    modules, loads a dataset using the `make_moons` function from `sklearn.datasets`,
    and then visualizes the data using `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we’re using the `moons` dataset, which is a mathematically generated
    dataset for binary classification that is often used as a simple test case for
    ML algorithms, especially those designed to handle non-linear data (such as NNs).
    The dataset consists of a two-dimensional array of two features (usually visualized
    on an X-Y plane) and a binary label (0 or 1) for each sample, and the samples
    are generated in such a way that they form two crescent moon-like shapes when
    plotted (hence the name “moons”), with each “moon” corresponding to one class.
    See *Figure 9**.**8* for reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8: The moons dataset](img/B18143_09_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.8: The moons dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the main characteristic of the dataset is its non-linearity (that
    is, the decision boundary separating the two classes is not a straight line).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code in the second cell of our Jupyter notebook then does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Splits the dataset into a training set and a test set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defines a Sequential model (which means that the layers are stacked on top of
    each other)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adds an input layer and the first hidden layer with 32 neurons and the `relu`
    activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adds a second hidden layer with 32 neurons and the `relu` activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adds an output layer with one neuron (for binary classification) and the `sigmoid`
    activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compiles the model with the `adam` optimizer and the `binary_crossentropy` loss
    function (suitable for binary classification)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trains the model for 50 epochs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When the code is running, you should see outputs from each epoch, as depicted
    in *Figure 9**.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.9: Training epoch outputs](img/B18143_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.9: Training epoch outputs'
  prefs: []
  type: TYPE_NORMAL
- en: Note that `loss` and `val_loss` (validation loss) should decrease as the training
    progresses, and `accuracy` and `val_accuracy` (validation accuracy) should increase
    as the training progresses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, our code in the third cell does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluates our model using the `model.evaluate` method, which returns the loss
    value and metric values (in this case, `accuracy`) for the model, in test mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gets some predictions from our model using the `model.predict` method, which
    outputs the probabilities that each input sample belongs to the positive class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to treat this as a binary classification use case, our code then converts
    these probabilities into binary class labels based on a threshold of 0.5 (that
    is, anything with a probability of more than 0.5 is deemed to be a member of the
    positive class).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we print out the first 10 predictions for a quick check. These outputs
    will be in the form of 0s and 1s, denoting the predicted class labels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s it! You’ve just created an NN! It might not be quite as smart as a human,
    but this is a basic example of an MLP in TensorFlow with Keras. We could extend
    this to more advanced DL use cases by adjusting things such as the number of layers,
    neurons, types of activation functions, types of optimizers, loss functions, and
    training configurations (such as the number of epochs, batch size, and so on).
    Great job!
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will dive into additional DL concepts, such as different types of NN
    architectures, challenges in applications of DNN, and optimization considerations.
  prefs: []
  type: TYPE_NORMAL
- en: NN architectures, challenges, and optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve primarily covered the basics of NNs so far in this chapter, and in this
    section, we will expand our discussion to include different types of NN architectures
    that can be used for different types of real-world use cases, as well as some
    challenges that are often encountered when training them. Finally, we will discuss
    how to optimize our NNs to address those challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Common NN architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The “architecture” of an NN refers to its structure in terms of the number of
    layers it contains and the number of neurons in each layer, as well as any special
    characteristics that influence how information is propagated through the network.
    The NN architectures we’ve described so far in this chapter are the simplest forms
    of ANNs, which are referred to as **feed-forward NNs** (**FFNNs**). Information
    in these networks travels in one direction only, from the input layer, through
    the hidden layers, to the output layer. Next, let’s take a look at some other
    commonly used NN architectures. We will introduce them at a high level here, and
    we will dive into much more detail in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When we talk about information traveling through the network in this section,
    we are not referring to the backpropagation step, because that is a separate step
    implemented during the iterative learning process. We are simply referring to
    how data is processed through our network in each training pass, or at inference
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional NNs (CNNs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CNNs are commonly used in **computer vision** (**CV**) for use cases such as
    object recognition and picture categorization. Consider the scenario where we
    wish to teach our model to recognize images of cats, keeping in mind that these
    images might take many different forms, such as being captured at various distances
    and perspectives. Our model would need to establish a kind of visual understanding
    of what a cat is, such as the shape of its face, ears, body, and tail, in order
    to correctly identify cats in the images.
  prefs: []
  type: TYPE_NORMAL
- en: CNNs do this by breaking pictures down into smaller components or “features”
    and learning each one separately. In this way, the network learns to detect small
    details in a larger image, such as an edge or a curve, and then combines those
    into larger features such as a single whisker or a portion of a cat’s ear, regardless
    of where they appear in the image, and then combining those characteristics to
    identify a cat. The concepts of **convolutional layers**, **pooling layers**,
    and **fully connected (FC) layers** are used by CNNs to do this. In later chapters
    of this book, we will dive further into those ideas and how they function.
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent NNs (RNNs) and long short-term memory (LSTM) networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RNNs are designed to find patterns in sequential data such as language or time
    series. In RNNs, the network contains loops, which enable information to be persisted
    from one step to the next, and this is what allows RNNs to create a kind of memory,
    unlike basic NNs that assume all inputs (and outputs) are independent of each
    other. In this way, the network blends current data with inputs from earlier phases
    in each step, which is important for activities such as language comprehension,
    in which the model needs to understand each word in relation to the other words
    in the input (that is, the words are not entirely independent).
  prefs: []
  type: TYPE_NORMAL
- en: However, one of the problems with RNNs is that, for reasons we’ll cover later,
    they “forget” prior inputs when dealing with long sequences. To address these
    issues, variations such as LSTM networks and **gated recurrent unit** (**GRU**)
    networks have been invented, which use gates and other techniques to maintain
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders (AEs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AEs are used to learn efficient encodings of unlabeled data, usually to reduce
    the dimensionality of the data. An AE’s basic idea is pretty straightforward:
    it is trained to try to duplicate its input to its output. Although it might seem
    like a simple (and redundant) operation, the restrictions we place on the network
    force it to discover interesting aspects of the data. Most commonly, we limit
    the number of nodes in the hidden layers, forcing the network to learn a compressed
    view of the data.'
  prefs: []
  type: TYPE_NORMAL
- en: AEs consist of an encoder, which encodes the input data as a compressed representation
    in a reduced-dimensional space, and a decoder, which attempts to reconstruct the
    input from the reduced-dimensional representation (that is, it “decodes” the compressed
    representation). The goal during training is to create a reconstructed output
    that is as close as possible to the input so that the network can learn to rebuild
    the input from the compressed representation.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, AEs are used for applications such as anomaly detection and
    recommendation systems. One particularly popular application of AEs is in **generative
    AI** (**GenAI**) models. In this case, after the AE has been trained, the decoder
    can generate new data that mimics the training data.
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks (GANs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The basic objective of GANs, which are made up of two competing NNs called a
    generator and a discriminator, is to create new fake data that closely matches
    “real” data (as determined by the training data). The two networks are trained
    in tandem using a **minimax** game, which is a type of game where the generator
    tries to trick the discriminator, and the discriminator tries to reliably distinguish
    real data from the generated data. During training, the generator becomes ever
    more accurate at providing data that appears real, while the discriminator becomes
    increasingly skillful at identifying forgeries.
  prefs: []
  type: TYPE_NORMAL
- en: Transformer networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Transformer networks are a type of model architecture invented by Google, in
    which the breakthrough innovation is the use of **self-attention** mechanisms,
    or **multi-head attention**, which enables the model to consider the relative
    significance of various words in a phrase while generating an output. For example,
    in a sentence such as “the dog tried to jump over the pond, but it was too wide,”
    the word “it” could refer to either the pond or the dog. To humans, it seems pretty
    obvious that it refers to the pond, but that’s because we’re using contextual
    awareness to intuit what makes the most sense. However, this is not inherently
    obvious to an ML model, and self-attention is the mechanism that allows the model
    to get a better understanding of the contextual meaning of each word in the sentence.
    The Transformer architecture also includes the concept of an encoder and a decoder,
    which are both made up of a stack of identical layers. And, because the self-attention
    mechanism alone does not account for the location of words in the input sequence,
    the Transformer design additionally contains a **positional encoding** system
    to track the positions of the words. We will dive into all of these components
    in much greater detail in a later chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage provided by Transformer models is that they handle all inputs
    in parallel, as opposed to sequence-based models such as RNNs or LSTM networks,
    and this can significantly speed up training and inference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Transformers have proven to be very useful for **natural language processing**
    (**NLP**) tasks including **sentiment analysis** (**SA**), text summarization,
    and machine translation, and the Transformer architecture serves as the foundation
    for models such as **Generative Pre-trained Transformer** (**GPT**), **Bidirectional
    Encoder Representations from Transformers** (**BERT**), and T5\. If you’re interested
    in learning more about this ground-breaking technology, I recommend reading the
    pivotal research paper that first introduced the concept of Transformers (Vaswani,
    A. et al., 2017), which can be found at the following URL: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762).'
  prefs: []
  type: TYPE_NORMAL
- en: There are more types of NN architectures in addition to the ones we have covered
    in this section, but the ones we’ve covered here are among the most well known
    and widely used. Researchers are constantly creating and experimenting with new
    NN configurations, and the choice of network configuration relies on the issue
    we’re seeking to resolve because each network type has advantages and disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s discuss some common challenges that people run into when training
    and using NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Common NN challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to all of the challenges we covered in earlier chapters with regard
    to traditional ML implementations, DNNs introduce their own set of challenges,
    such as interpretability, cost, and vanishing or exploding gradients.
  prefs: []
  type: TYPE_NORMAL
- en: Interpretability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Interpretability refers to how easily we can understand the inner workings of
    our models, and the reasons behind the decisions they produce. Models such as
    linear regression are generally quite easy to understand and explain because their
    outputs are just a straightforward mathematical transformation of whatever input
    is provided to the model.
  prefs: []
  type: TYPE_NORMAL
- en: However, DNNs can be extremely complex, with thousands of neurons and billions
    of parameters that influence their outputs. Also, their outputs are usually not
    just linear transformations of their inputs but instead are non-linear in nature.
  prefs: []
  type: TYPE_NORMAL
- en: In a later chapter, we will discuss the importance of interpretability in much
    more detail and will introduce mechanisms that can help us to better understand
    how our models work.
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DNNs can require a lot of computing resources to train and host, which can result
    in monetary expenses. If we consider the example of highly complex models with
    billions of parameters, those models can take weeks or even months to train, using
    large numbers of very powerful servers with the latest generation of cutting-edge
    GPUs. Those kinds of resources are not cheap, so we need to ensure that our models
    are optimized to use computing resources as efficiently as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Vanishing gradient problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We briefly touched on this topic in earlier sections of this chapter, so let’s
    take a look at this concept in more detail. The vanishing gradient problem develops
    when the gradients of the loss function are so tiny that they essentially vanish,
    leading to sluggish weight updates in the network’s first layers. Remember that
    backpropagation uses the chain rule of differentiation, which involves multiplying
    a sequence of derivatives (or gradients). This means that if the values of the
    derivatives are less than 1, we are essentially dividing them in an exponential
    manner into smaller and smaller values as we propagate back through the network.
    Because of this, early layers learn much more slowly than later layers.
  prefs: []
  type: TYPE_NORMAL
- en: When utilizing activation functions such as the sigmoid or tanh functions, which
    condense their input into a small range, this problem becomes more prominent.
    The sigmoid function, for example, compresses input values into a range between
    zero and one, which means that even when the inputs are large in size (either
    positive or negative), the output of the sigmoid function is between zero and
    one, and the result is that the gradients reduce to tiny values, causing backpropagation-based
    learning to slow down significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Exploding gradient problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On the other hand, the exploding gradient problem happens when the gradient
    becomes too large, causing the weights in the network to be updated by excessive
    increments. This can result in the network’s performance oscillating wildly, causing
    the model training process to fail.
  prefs: []
  type: TYPE_NORMAL
- en: The exploding gradient problem is more common in RNNs, especially with long
    sequences, but it can occur in any type of network.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizations to help prevent vanishing or exploding gradients
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have a better understanding of how vanishing and exploding gradient
    issues take place, the following considerations can help reduce their likelihood
    of occurring.
  prefs: []
  type: TYPE_NORMAL
- en: Weight initialization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Effective weight initialization can help mitigate problems of vanishing and
    exploding gradients. For example, techniques such as Xavier (Glorot) initialization
    and He initialization can help set the initial weights to values that prevent
    the gradients from becoming too small or too large early in training.
  prefs: []
  type: TYPE_NORMAL
- en: Choice of activation functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we discussed, using activation functions that squash their inputs, such as
    sigmoid or tanh, can increase the likelihood of encountering vanishing and exploding
    gradient issues. Therefore, it’s best to avoid those activation functions in cases
    that are prone to those issues. We can instead use activation functions such as
    Leaky ReLU or PReLU, as these functions do not squash their inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Batch normalization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Using this technique, we can normalize the output of a layer to stabilize the
    means and variances of each layer’s inputs. This helps control the scale of gradients,
    mitigating both vanishing and exploding gradient problems.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient clipping
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This technique puts a pre-defined limit or threshold on the gradients to prevent
    them from getting too large, which is especially useful for tackling the exploding
    gradient problem.
  prefs: []
  type: TYPE_NORMAL
- en: Architectural methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When we discussed RNNs earlier in this section, we mentioned that they “forget”
    prior inputs when dealing with long sequences. The vanishing gradient problem
    is one factor that causes this to happen, and this is one of the reasons why certain
    architectures such as LSTM and GRU were designed to address these issues in the
    context of RNNs by using a form of gating in their structure. Therefore, sometimes
    the choice of NN architecture can reduce the likelihood of encountering vanishing
    and exploding gradient problems.
  prefs: []
  type: TYPE_NORMAL
- en: These problems and their solutions are major factors in understanding how DL
    models work and how to effectively train DNNs.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve covered a lot of new concepts and terminology in this chapter. Let’s take
    a moment to summarize everything we’ve learned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started by exploring the comparison between artificial neurons
    (in the form of the perceptron) and biological neurons in the human brain. We
    then extended this idea to describe the activity of multiple neurons in an NN,
    both in terms of combining multiple perceptrons together and in terms of how the
    tiny neurons in our brain work together to produce extremely complex higher-level
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: We then dived deeper into the inner workings and components of ANNs, including
    concepts such as activation functions and backpropagation. We discussed many different
    types of activation functions, including how they work and what use cases are
    most appropriate for them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of backpropagation, we learned about various types of commonly
    used cost function optimization algorithms, such as Momentum and Adam, and then
    we introduced two very important libraries for DL: TensorFlow and Keras.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we built our first NN using those libraries, and we tested that network
    by successfully getting predictions based on the `moons` dataset, which we also
    explored in some detail.
  prefs: []
  type: TYPE_NORMAL
- en: After building our first simple NN, we expanded our discussion to cover more
    advanced kinds of NN architectures and their use cases, and we explored common
    challenges that people often run into when training and using NNs, as well as
    some approaches we can use to optimize our networks in order to reduce the likelihood
    of running into those issues.
  prefs: []
  type: TYPE_NORMAL
- en: These are some of the more advanced concepts in ML, so if you have understood
    the content we’ve covered in this chapter, then you have built an important foundation
    for the deeper dives we will perform on these concepts in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, let’s explore how we can bring trained models into production
    to host them for serving real-world use cases.
  prefs: []
  type: TYPE_NORMAL
