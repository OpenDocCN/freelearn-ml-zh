- en: '*Chapter 2*: Examining Bivariate and Multivariate Relationships between Features
    and Targets'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*：检查特征与目标变量之间的双变量和多变量关系'
- en: In this chapter, we'll look at the correlation between possible features and
    target variables. Bivariate exploratory analysis, using crosstabs (two-way frequencies),
    correlations, scatter plots, and grouped boxplots can uncover key issues for modeling.
    Common issues include high correlation between features and non-linear relationships
    between features and the target variable. We will use pandas methods for bivariate
    analysis and Matplotlib for visualizations in this chapter. We will also discuss
    the implications of what we find in terms of feature engineering and modeling.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨可能特征与目标变量之间的相关性。使用交叉表（双向频率）、相关性、散点图和分组箱线图的双变量探索性分析可以揭示建模的关键问题。常见问题包括特征之间高度相关以及特征与目标变量之间的非线性关系。在本章中，我们将使用pandas方法进行双变量分析，并使用Matplotlib进行可视化。我们还将讨论我们在特征工程和建模方面发现的影响。
- en: We will also use multivariate techniques to understand the relationship between
    features. This includes leaning on some machine learning algorithms to identify
    possibly problematic observations. After, we will provide tentative recommendations
    for eliminating certain observations from our modeling, as well as for transforming
    key features.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用多元技术来理解特征之间的关系。这包括依赖一些机器学习算法来识别可能存在问题的观测值。之后，我们将就消除某些观测值以及转换关键特征提供初步建议。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Identifying outliers and extreme values in bivariate relationships
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在双变量关系中识别异常值和极端值
- en: Using scatter plots to view bivariate relationships between continuous features
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用散点图查看连续特征之间的双变量关系
- en: Using grouped boxplots to view bivariate relationships between continuous and
    categorical features
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分组箱线图查看连续和分类特征之间的双变量关系
- en: Using linear regression to identify data points with significant influence
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性回归识别具有显著影响的数据点
- en: Using K-nearest neighbors to find outliers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用K近邻算法寻找异常值
- en: Using Isolation Forest to find outliers
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用隔离森林算法寻找异常值
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter will rely heavily on the pandas and Matplotlib libraries, but you
    don't require any prior knowledge of these. If you have installed Python from
    a scientific distribution, such as Anaconda or WinPython, then these libraries
    have probably already been installed. We will also be using Seaborn for some of
    our graphics and the statsmodels library for some summary statistics. If you need
    to install any of the packages, you can do so by running `pip install [package
    name]` from a terminal window or Windows PowerShell. The code for this chapter
    can be found in this book's GitHub repository at [https://github.com/PacktPublishing/Data-Cleaning-and-Exploration-with-Machine-Learning](https://github.com/PacktPublishing/Data-Cleaning-and-Exploration-with-Machine-Learning).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将大量依赖pandas和Matplotlib库，但你不需要对这些库有任何先前的知识。如果你是从科学发行版安装的Python，例如Anaconda或WinPython，那么这些库可能已经安装好了。我们还将使用Seaborn进行一些图形，并使用statsmodels库进行一些汇总统计。如果你需要安装任何包，可以从终端窗口或Windows
    PowerShell运行`pip install [package name]`。本章的代码可以在本书的GitHub仓库[https://github.com/PacktPublishing/Data-Cleaning-and-Exploration-with-Machine-Learning](https://github.com/PacktPublishing/Data-Cleaning-and-Exploration-with-Machine-Learning)中找到。
- en: Identifying outliers and extreme values in bivariate relationships
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在双变量关系中识别异常值和极端值
- en: It is hard to develop a reliable model without having a good sense of the bivariate
    relationships in our data. We not only care about the relationship between particular
    features and target variables but also about how features move together. If features
    are highly correlated, then modeling their independent effect becomes tricky or
    unnecessary. This may be a challenge, even if the features are highly correlated
    over just a range of values.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一个好的双变量关系感，很难开发出一个可靠的模型。我们不仅关心特定特征与目标变量之间的关系，还关心特征如何一起移动。如果特征高度相关，那么建模它们的独立效应可能变得棘手或没有必要。即使特征只是在某个值域内高度相关，这也可能是一个挑战。
- en: Having a good understanding of bivariate relationships is also important for
    identifying outliers. A value might be unexpected, even if it is not an extreme
    value. This is because some values for a feature are unusual when a second feature
    has certain values. This is easy to illustrate when one feature is categorical
    and the other is continuous.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对双变量关系的良好理解对于识别异常值也很重要。一个值可能出乎意料，即使它不是一个极端值。这是因为当第二个特征具有某些值时，某些特征的值可能是不寻常的。当其中一个特征是分类的，而另一个是连续的时，这一点很容易说明。
- en: 'The following diagram illustrates the number of bird sightings per day over
    several years but shows different distributions for the two sites. One site has
    a (mean) sightings per day of 33, while the other has 52\. (This is a fictional
    example that''s been pulled from my *Python Data Cleaning Cookbook*.) The overall
    mean (not shown) is 42\. What should we make of a value of 58 for daily sightings?
    Is it an outlier? This depends on which of the two sites was being observed. If
    there were 58 sightings in a day at site A, 58 would be an unusually high number.
    However, this wouldn''t be true for site B, where 58 sightings would not be very
    different from the mean for that site:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表说明了多年来每天鸟类观测的数量，但显示了两个地点不同的分布。一个地点每天的平均观测数为33，而另一个地点为52。（这是一个从我的*Python数据清洗食谱*中提取的虚构示例。）整体平均数（未显示）为42。对于每天58次观测的值我们应该如何看待？它是异常值吗？这取决于观察的是哪个地点。如果地点A一天有58次观测，那么58将是一个非常高的数字。然而，对于地点B来说，58次观测并不会与该地点的平均值有很大不同：
- en: '![Figure 2.1 – Daily Bird Sightings ](img/B17978_02_001.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – 每日鸟类观测](img/B17978_02_001.jpg)'
- en: Figure 2.1 – Daily Bird Sightings
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – 每日鸟类观测
- en: 'This hints at a useful rule of thumb: whenever a feature of interest is correlated
    with another feature, we should take that relationship into account when we''re
    trying to identify outliers (or any modeling with that feature, actually). It
    is helpful to state this a little more precisely and extend it to cases where
    both features are continuous. If we assume a linear relationship between feature
    *x* and feature *y*, we can describe that relationship with the familiar *y =
    mx + b* equation, where *m* is the slope and *b* is the *y*-intercept. Then, we
    can expect the value of *y* to be somewhere close to *x* times the estimated slope,
    plus the *y*-intercept. Unexpected values are those that deviate substantially
    from this relationship, where the value of *y* is much higher or lower than what
    would be predicted, given the value of *x*. This can be extended to multiple *x*,
    or predictor, variables.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这暗示了一个有用的经验法则：当感兴趣的特征与另一个特征相关时，我们在尝试识别异常值（或任何与该特征相关的建模）时应该考虑这种关系。更精确地表述这一点并将其扩展到两个特征都是连续的情况是有帮助的。如果我们假设特征*x*和特征*y*之间存在线性关系，我们可以用熟悉的*y
    = mx + b*方程来描述这种关系，其中*m*是斜率，*b*是*y*轴截距。然后，我们可以预期*y*的值将接近*x*乘以估计的斜率，加上*y*轴截距。意外值是那些与这种关系有较大偏差的值，其中*y*的值远高于或低于根据*x*的值预测的值。这可以扩展到多个*x*，或预测变量。
- en: In this section, we will learn how to identify outliers and unexpected values
    by examining the relationship a feature has with another feature. In subsequent
    sections of this chapter, we will use multivariate techniques to make additional
    improvements to our outlier detection.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何通过考察一个特征与另一个特征之间的关系来识别异常值和意外值。在本章的后续部分，我们将使用多元技术来进一步提高我们的异常值检测。
- en: 'We will work with data based on COVID-19 cases by country in this section.
    The dataset contains cases and deaths per million people in the population. We
    will treat both columns as possible targets. It also contains demographic data
    for each country, such as GDP per capita, median age, and diabetes prevalence.
    Let''s get started:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将基于各国COVID-19病例的数据进行工作。数据集包含每百万人口中的病例和死亡人数。我们将把这两个列都视为可能的靶标。它还包含每个国家的人口统计数据，例如人均GDP、中位数年龄和糖尿病患病率。让我们开始吧：
- en: Note
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Our World in Data provides COVID-19 public-use data at [https://ourworldindata.org/coronavirus-source-data](https://ourworldindata.org/coronavirus-source-data).
    The dataset that's being used in this section was downloaded on July 9, 2021\.
    There are more columns in the data than I have included. I created the `region`
    column based on country.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Our World in Data 在[https://ourworldindata.org/coronavirus-source-data](https://ourworldindata.org/coronavirus-source-data)提供COVID-19公共使用数据。本节所使用的数据集是在2021年7月9日下载的。数据中包含的列比我包含的要多。我根据国家创建了`region`列。
- en: 'Let''s start by loading the COVID-19 dataset and looking at how it is structured.
    We will also import the Matplotlib and Seaborn libraries since we will do a couple
    of visualizations:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从加载COVID-19数据集并查看其结构开始。我们还将导入Matplotlib和Seaborn库，因为我们将会进行一些可视化：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A great place to start with our examination of bivariate relationships is with
    correlations. First, let''s create a DataFrame that contains a few key features:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们检查双变量关系的过程中，从相关性开始是一个很好的起点。首先，让我们创建一个包含一些关键特征的DataFrame：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we can get the Pearson correlation matrix for these features. There is
    a strong positive correlation of 0.71 between cases and deaths per million. The
    percentage of the population that''s aged 65 or older is positively correlated
    with cases and deaths, at 0.53 for both. Life expectancy is also highly correlated
    with cases per million. There seems to be at least some correlation of **gross
    domestic product** (**GDP**) per person with cases:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以获取这些特征的皮尔逊相关矩阵。病例和每百万死亡之间的正相关系数为0.71。65岁或以上的人口百分比与病例和死亡都呈正相关，两者均为0.53。预期寿命也与每百万病例高度相关。似乎至少有一些与**国内生产总值**（**GDP**）每人相关的病例：
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It is worth noting the correlation between possible features, such as between
    life expectancy and GDP per capita (0.68) and life expectancy and those aged 65
    or older (0.73).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，可能特征之间的相关性，例如，预期寿命和人均GDP（0.68）以及预期寿命和65岁或以上人群（0.73）之间的相关性。
- en: 'It can be helpful to see the correlation matrix as a heat map. This can be
    done by passing the correlation matrix to the Seaborn `heatmap` method:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相关矩阵作为热图查看可能会有所帮助。这可以通过将相关矩阵传递给Seaborn的`heatmap`方法来完成：
- en: '[PRE3]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This creates the following plot:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这会创建以下图表：
- en: '![Figure 2.2 – Heat map of COVID data, with the strongest correlations in red
    and peach ](img/B17978_02_002.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – COVID数据的热图，最强的相关性用红色和桃色表示](img/B17978_02_002.jpg)'
- en: Figure 2.2 – Heat map of COVID data, with the strongest correlations in red
    and peach
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – COVID数据的热图，最强的相关性用红色和桃色表示
- en: We want to pay attention to the cells shown with warmer colors – in this case,
    mainly peach. I find that using a heat map helps me keep correlations in mind
    when modeling.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要关注用较暖色调显示的细胞——在这种情况下，主要是桃色。我发现使用热图有助于我在建模时记住相关性。
- en: Note
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: All the color images contained in this book can be downloaded. Check the *Preface*
    of this book for the respective link.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 本书包含的所有彩色图像都可以下载。请查看本书的*前言*以获取相应的链接。
- en: 'Let''s take a closer look at the relationship between total cases per million
    and deaths per million. One way to get a better sense of this than with just a
    correlation coefficient is by comparing the high and low values for each and seeing
    how they move together. In the following code, we''re using the `qcut` method
    to create a categorical feature with five values distributed relatively evenly,
    from very low to very high, for cases. We have done the same for deaths:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看每百万总病例数和每百万死亡数之间的关系。比仅仅通过相关系数更好地理解这一点的一种方法是比较每个的高值和低值，看看它们是如何一起变化的。在下面的代码中，我们使用`qcut`方法为病例创建一个具有五个值的分类特征，这些值从非常低到非常高分布得相对均匀：我们为死亡也做了同样的事情：
- en: '[PRE4]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can use the `crosstab` function to view the number of countries for each
    quintile of cases and quintile of deaths. As we would expect, most of the countries
    are along the diagonal. There are 27 countries with very low cases and very low
    deaths, and 25 countries with very high cases and very high deaths. The interesting
    counts are those not on the diagonal, such as the four countries with very high
    cases but only medium deaths, nor the one with medium cases and very high deaths.
    Let''s also look at the means of our features so that we can reference them later:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用`crosstab`函数查看每个病例五分位数和死亡五分位数的国家数量。正如我们所预期的，大多数国家都在对角线上。有27个国家病例和死亡都非常低，有25个国家病例和死亡都非常高。有趣的是那些不在对角线上的计数，例如，四个病例非常高但死亡中等的国家，以及一个病例中等但死亡非常高的国家。让我们也看看我们特征的均值，这样我们以后可以参考它们：
- en: '[PRE5]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let''s take a closer look at the countries away from the diagonal. Four countries
    – Cyprus, Kuwait, Maldives, and Qatar – have fewer deaths per million than average
    but well above average cases per million. Interestingly, all four countries are
    very small in terms of population; three of the four have population densities
    far below the average of 453; again, three of the four have people aged 65 or
    older percentages that are much lower than average:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们仔细看看远离对角线的国家。四个国家——塞浦路斯、科威特、马尔代夫和卡塔尔——的每百万死亡数低于平均水平，但每百万病例数则远高于平均水平。有趣的是，这四个国家在人口规模上都非常小；其中三个国家的人口密度远低于平均的453；再次，其中三个国家的65岁或以上人口比例远低于平均水平：
- en: '[PRE6]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s take a closer look at the country with more deaths than we would have
    expected based on cases. For Mexico, the number of cases per million are well
    below average, while the number of deaths per million are quite a bit above average:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们仔细看看那些根据病例数预期死亡数较多的国家。对于墨西哥来说，每百万病例数远低于平均水平，而每百万死亡数则相当高于平均水平：
- en: '[PRE7]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Correlation coefficients and heat maps are a good place to start when we want
    to get a sense of the bivariate relationships in our dataset. However, it can
    be hard to visualize the relationship between continuous variables with just a
    correlation coefficient. This is particularly true when the relationship is not
    linear – that is, when it varies based on the ranges of a feature. We can often
    improve our understanding of the relationship between two features with a scatter
    plot. We will do that in the next section.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要了解数据集中双变量关系时，相关系数和热图是一个好的起点。然而，仅用相关系数来可视化连续变量之间的关系可能很困难。这尤其适用于关系不是线性的情况——也就是说，当它基于特征的取值范围而变化时。我们通常可以通过散点图来提高我们对两个特征之间关系的理解。我们将在下一节中这样做。
- en: Using scatter plots to view bivariate relationships between continuous features
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用散点图查看连续特征之间的双变量关系
- en: In this section, we'll learn how to get a scatter plot of our data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何获取数据的散点图。
- en: 'We can use scatter plots to get a more complete picture of the relationship
    between two features than what can be detected by a correlation coefficient alone.
    This is particularly useful when that relationship changes across certain ranges
    of the data. In this section, we will create scatter plots of some of the same
    features we examined in the previous section. Let''s get started:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用散点图来获取比仅通过相关系数所能检测到的更完整的两个特征之间的关系图景。这在数据关系随数据范围变化而变化时尤其有用。在本节中，我们将创建一些与上一节中考察的相同特征的散点图。让我们开始吧：
- en: 'It is helpful to plot a regression line through the data points. We can do
    this with Seaborn''s `regplot` method. Let''s load the COVID-19 data again, along
    with the Matplotlib and Seaborn libraries, and generate a scatter plot of `total_cases_mill`
    by `total_deaths_mill`:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过数据点绘制回归线是有帮助的。我们可以使用Seaborn的`regplot`方法来做这件事。让我们再次加载COVID-19数据，以及Matplotlib和Seaborn库，并生成`total_cases_mill`与`total_deaths_mill`的散点图：
- en: '[PRE8]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This produces the following plot:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下图表：
- en: '![Figure 2.3 – Total COVID Cases and Deaths by Country ](img/B17978_02_003.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – 按国家划分的COVID病例和死亡总数](img/B17978_02_003.jpg)'
- en: Figure 2.3 – Total COVID Cases and Deaths by Country
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 按国家划分的COVID病例和死亡总数
- en: The regression line is an estimate of the relationship between cases per million
    and deaths per million. The slope of the line indicates how much we can expect
    deaths per million to increase with a 1-unit increase in cases per million. Those
    points on the scatter plot that are significantly above the regression line should
    be examined more closely.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 回归线是对每百万病例和每百万死亡之间关系的估计。线的斜率表明，我们可以预期每百万死亡数随着每百万病例数增加1个单位而增加多少。那些在散点图上显著高于回归线的点应该被更仔细地检查。
- en: 'The country with deaths per million near 6,000 and cases per million below
    75,000 is clearly an outlier. Let''s take a closer look:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 死亡率每百万接近6,000例，病例率每百万低于75,000例的国家显然是异常值。让我们仔细看看：
- en: '[PRE9]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, we can see that the outlier country is Peru. Peru does have above-average
    cases per million, but its number of deaths per million is still much greater
    than would be expected given the number of cases. If we draw a line that's perpendicular
    to the *x* axis at 62,830, we can see that it crosses the regression line at about
    1,000 deaths per million, which is far fewer than the 5,876 for Peru. The only
    other values in the data for Peru that also stand out as very different from the
    dataset averages are population density and GDP per person, both of which are
    substantially lower than average. Here, none of our features may help us explain
    the high number of deaths in Peru.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到异常值国家是秘鲁。秘鲁的确每百万人口病例数高于平均水平，但其每百万死亡人数仍然远高于按病例数预期的数值。如果我们画一条垂直于*x*轴的线，在62,830处，我们可以看到它在大约每百万1,000人死亡处与回归线相交，这比秘鲁的5,876要少得多。在秘鲁的数据中，除了病例数之外，还有两个非常不同于数据集平均值的数值也引人注目，那就是人口密度和人均GDP，这两个数值都显著低于平均水平。在这里，我们没有任何特征能帮助我们解释秘鲁的高死亡率。
- en: Note
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When creating a scatter plot, it is common to put a feature or predictor variable
    on the *x* axis and a target variable on the *y* axis. If a regression line is
    drawn, then that represents the increase in the target that's been predicted by
    a 1-unit increase in the predictor. But scatter plots can also be used to examine
    the relationship between two predictors or two possible targets.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建散点图时，通常会将一个特征或预测变量放在*x*轴上，将目标变量放在*y*轴上。如果画了一条回归线，那么它代表的是预测变量增加1个单位时目标变量的增加。但散点图也可以用来检查两个预测变量或两个可能的目标变量之间的关系。
- en: 'Looking back at how we defined an outlier in [*Chapter 1*](B17978_01_ePub.xhtml#_idTextAnchor014),
    *Examining the Distribution of Features and Targets*, an argument can be made
    that Peru is an outlier. But we still have more work to do before we can come
    to that conclusion. Peru is not the only country with points on the scatter plot
    far above or below the regression line. It is generally a good idea to investigate
    many of these points. Let''s take a look:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们在[*第一章*](B17978_01_ePub.xhtml#_idTextAnchor014)中定义的异常值，即*检查特征和目标变量的分布*，可以认为秘鲁是一个异常值。但我们还需要做更多的工作才能得出这个结论。秘鲁并不是唯一一个在散点图上点远高于或低于回归线的国家。通常来说，调查这些点中的许多点是件好事。让我们来看看：
- en: 'Creating scatter plots that contain most of the key continuous features can
    help us identify other possible outliers and better visualize the correlations
    we observed in the first section of this chapter. Let''s create scatter plots
    of people who are aged 65 and older and GDP per capita with total cases per million:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建包含大多数关键连续特征的散点图可以帮助我们识别其他可能的异常值，并更好地可视化我们在本章第一部分观察到的相关性。让我们创建65岁及以上人口和人均GDP与每百万总病例数的散点图：
- en: '[PRE10]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This produces the following plot:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下图表：
- en: '![Figure 2.4 – Age 65 Plus and GDP with Cases Per Million ](img/B17978_02_004.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4 – 65岁及以上人口和人均GDP与每百万总病例数](img/B17978_02_004.jpg)'
- en: Figure 2.4 – Age 65 Plus and GDP with Cases Per Million
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – 65岁及以上人口和人均GDP与每百万总病例数
- en: These scatter plots show that some countries that had very high cases per million
    had values close to what we would expect, given the age of the population or the
    GDP. These are extreme values, but not necessarily outliers as we have defined
    them.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些散点图显示，一些每百万病例数非常高的国家，其数值接近我们根据人口年龄或GDP预期的数值。这些是极端值，但并不一定是我们定义的异常值。
- en: It is possible to use scatter plots to illustrate the relationships between
    two features and a target, all in one graphic. Let's return to the land temperatures
    data that we worked with in the previous chapter to explore this.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用散点图可以展示两个特征与目标之间的关系，所有这些都在一个图形中。让我们回到上一章中我们处理过的陆地温度数据，来探讨这一点。
- en: Data Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据注意
- en: The land temperature dataset contains the average temperature readings (in Celsius)
    in 2019 from over 12,000 stations across the world, though the majority of the
    stations are in the United States. The dataset was retrieved from the Global Historical
    Climatology Network integrated database. It has been made available for public
    use by the United States National Oceanic and Atmospheric Administration at [https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 陆地温度数据集包含了2019年从全球超过12,000个气象站读取的平均温度（以摄氏度为单位），尽管大多数站点位于美国。该数据集是从全球历史气候学网络综合数据库中检索的。它已由美国国家海洋和大气管理局在[https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4)上提供给公众使用。
- en: 'We expect the average temperature at a weather station to be impacted by both
    latitude and elevation. Let''s say that our previous analysis showed that elevation
    does not start having much of an impact on temperature until approximately the
    1,000-meter mark. We can split the `landtemps` DataFrame into low- and high-elevation
    stations, with 1,000 meters as the threshold. In the following code, we can see
    that this gives us 9,538 low-elevation stations with an average temperature of
    12.16 degrees Celsius, and 2,557 high-elevation stations with an average temperature
    of 7.58:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们预计气象站的平均温度会受到纬度和海拔的影响。假设我们之前的分析表明，海拔对温度的影响直到大约1,000米才开始显著。我们可以将`landtemps`数据框分为低海拔和高海拔站，以1,000米为阈值。在下面的代码中，我们可以看到这给我们带来了9,538个低海拔站，平均温度为12.16摄氏度，以及2,557个高海拔站，平均温度为7.58：
- en: '[PRE11]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we can visualize the relationship between elevation and latitude and temperature
    in one scatter plot:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以在一个散点图中可视化海拔和纬度与温度之间的关系：
- en: '[PRE12]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This produces the following scatter plot:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下散点图：
- en: '![Figure 2.5 – Latitude and Average Temperature in 2019 ](img/B17978_02_005.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5 – 2019年纬度和平均温度](img/B17978_02_005.jpg)'
- en: Figure 2.5 – Latitude and Average Temperature in 2019
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 2019年纬度和平均温度
- en: Here, we can see that the temperatures gradually decrease as the distance from
    the equator (measured in latitude) increases. We can also see that high-elevation
    weather stations (those with red dots) are generally below low-elevation stations
    – that is, they have lower temperatures at similar latitudes.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到随着赤道距离（以纬度衡量）的增加，温度逐渐降低。我们还可以看到高海拔气象站（那些带有红色圆点的）通常位于低海拔站下方——也就是说，在相似的纬度上，它们的温度较低。
- en: 'There also seems to be at least some difference in slope between high- and
    low-elevation stations. Temperatures appear to decline more quickly as latitude
    increases with high-elevation stations. We can draw two regression lines through
    the scatter plot – one for high and one for low-elevation stations – to get a
    clearer picture of this. To simplify the code a bit, let''s create a categorical
    feature, `elevation_group`, for low- and high-elevation stations:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 似乎高海拔和低海拔站点之间的斜率也有至少一些差异。随着纬度的增加，高海拔站点的温度似乎下降得更快。我们可以在散点图上绘制两条回归线——一条用于高海拔站点，一条用于低海拔站点——以获得更清晰的图像。为了简化代码，让我们为低海拔和高海拔站点创建一个分类特征，`elevation_group`：
- en: '[PRE13]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This produces the following plot:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图形：
- en: '![Figure 2.6 – Latitude and Average Temperature in 2019 with regression lines
    ](img/B17978_02_006.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6 – 2019年纬度、平均温度和回归线](img/B17978_02_006.jpg)'
- en: Figure 2.6 – Latitude and Average Temperature in 2019 with regression lines
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 – 2019年纬度和平均温度及回归线
- en: Here, we can see the steeper negative slope for high-elevation stations.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到高海拔站点的更陡峭的负斜率。
- en: 'If we want to see a scatter plot with two continuous features and a continuous
    target, rather than forcing one of the features to be dichotomous, as we did in
    the previous example, we can take advantage of Matplotlib''s 3D functionality:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想看到一个包含两个连续特征和一个连续目标的散点图，而不是像上一个例子中那样将一个特征强制二分，我们可以利用Matplotlib的3D功能：
- en: '[PRE14]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This produces the following three-dimensional scatter plot:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下三维散点图：
- en: '![Figure 2.7 – Latitude, Temperature, and Elevation in 2019 ](img/B17978_02_007.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7 – 2019年纬度、温度和海拔](img/B17978_02_007.jpg)'
- en: Figure 2.7 – Latitude, Temperature, and Elevation in 2019
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 – 2019年的纬度、温度和海拔
- en: Scatter plots are a go-to visualization for teasing out relationships between
    continuous features. We get a better sense of those relationships than correlation
    coefficients alone can reveal. However, we need a very different visualization
    if we are examining the relationship between a continuous feature and a categorical
    one. Grouped boxplots are useful in those cases. We will learn how to create grouped
    boxplots with Matplotlib in the next section.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图是揭示连续特征之间关系的首选可视化工具。我们比仅通过相关系数更能感受到这些关系。然而，如果我们正在检查连续特征和分类特征之间的关系，我们需要一个非常不同的可视化。分组箱线图在这种情况下非常有用。在下一节中，我们将学习如何使用Matplotlib创建分组箱线图。
- en: Using grouped boxplots to view bivariate relationships between continuous and
    categorical features
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分组箱线图查看连续和分类特征之间的双变量关系
- en: Grouped boxplots are an underappreciated visualization. They are helpful when
    we're examining the relationship between continuous and categorical features since
    they show how the distribution of a continuous feature can vary by the values
    of the categorical feature.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 分组箱线图是一种被低估的视觉化工具。当我们检查连续和分类特征之间的关系时，它们非常有帮助，因为它们显示了连续特征的分布如何因分类特征的不同值而变化。
- en: We can explore this by returning to the **National Longitudinal Survey** (**NLS**)
    data we worked with in the previous chapter. The NLS has one observation per survey
    respondent but collects annual data on education and employment (data for each
    year is captured in different columns).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过回到上一章中我们使用过的**国家纵向调查**（**NLS**）数据来探索这一点。NLS对每位调查受访者有一个观测值，但收集有关教育和就业的年度数据（每年数据被捕获在不同的列中）。
- en: Data Note
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据备注
- en: As stated in [*Chapter 1*](B17978_01_ePub.xhtml#_idTextAnchor014), *Examining
    the Distribution of Features and Targets*, the NLS of Youth is conducted by the
    United States Bureau of Labor Statistics. Separate files for SPSS, Stata, and
    SAS can be downloaded from the respective repository. The NLS data can be downloaded
    from [https://www.nlsinfo.org/investigator/pages/search](https://www.nlsinfo.org/investigator/pages/search).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第1章*](B17978_01_ePub.xhtml#_idTextAnchor014)中所述，*检查特征和目标分布*，青年国家纵向调查由美国劳工统计局进行。可以从相应的存储库下载SPSS、Stata和SAS的单独文件。NLS数据可以从[https://www.nlsinfo.org/investigator/pages/search](https://www.nlsinfo.org/investigator/pages/search)下载。
- en: 'Follow these steps to create grouped bloxplots:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤创建分组箱线图：
- en: 'Among the many columns in the NLS DataFrame, there''s `highestdegree` and `weeksworked17`,
    which represent the highest degree the respondent earned and the number of weeks
    the person worked in 2017, respectively. Let''s look at the distribution of weeks
    worked for each value of the degree that was earned. First, we must define a function,
    `gettots`, to get the descriptive statistics we want. Then, we must pass a `groupby`
    series object, `groupby([''highestdegree''])[''weeksworked17'']`, to that function
    using `apply`:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在NLS DataFrame的许多列中，有`highestdegree`和`weeksworked17`，分别代表受访者获得的最高学位和2017年该人工作的周数。让我们看看获得不同学位的人的工作周数的分布。首先，我们必须定义一个函数`gettots`来获取我们想要的描述性统计。然后，我们必须使用`apply`将一个`groupby`系列对象`groupby(['highestdegree'])['weeksworked17']`传递给该函数：
- en: '[PRE15]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Here, we can see how different the distribution of weeks worked for people with
    less than a high school degree is from that distribution for people with a bachelor's
    degree or more. For those with no degree, more than 25% had 0 weeks worked. For
    those with a bachelor's degree, even those at the 25th percentile worked 45 weeks
    during the year. The interquartile range covers the whole distribution for individuals
    with no degree (0 to 52), but only a small part of the range for individuals with
    bachelor's degrees (45 to 52).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到没有高中学位的人的工作周数的分布与拥有学士学位或更高学位的人的分布有多么不同。对于没有学位的人，超过25%的人在一年中工作了0周。对于拥有学士学位的人，即使在第25百分位的人，一年中也工作了45周。四分位距覆盖了没有学位的个人的整个分布（0到52），但对于拥有学士学位的个人的分布（45到52）只覆盖了一小部分。
- en: We should also make note of the class imbalance for `highestdegree`. The counts
    get quite small after master's degrees and the counts for high school degrees
    are nearly twice that of the next largest group. We will likely need to collapse
    some categories before we do any modeling with this data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该注意`highestdegree`的类别不平衡。在硕士学位之后，计数变得相当小，而高中学位的计数几乎是下一个最大组的两倍。在我们使用这些数据进行任何建模之前，我们可能需要合并一些类别。
- en: 'Grouped boxplots make the differences in distributions even clearer. Let''s
    create some with the same data. We will use Seaborn for this plot:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分组箱线图使分布差异更加明显。让我们用相同的数据创建一些。我们将使用Seaborn来绘制此图：
- en: '[PRE16]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This produces the following plot:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图表：
- en: '![Figure 2.8 – Boxplots of Weeks Worked by Highest Degree ](img/B17978_02_008.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – 按最高学位划分的每周工作箱线图](img/B17978_02_008.jpg)'
- en: Figure 2.8 – Boxplots of Weeks Worked by Highest Degree
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 – 按最高学位划分的每周工作箱线图
- en: The grouped boxplots illustrate the dramatic difference in interquartile range
    for weeks worked by the degree earned. At the associate's degree level (a 2-year
    college degree in the United States) or above, there are values below the whiskers,
    represented by dots. Below the associate's degree level, the boxplots do not identify
    any outliers or extreme values. For example, a 0 weeks worked value is not an
    extreme value for someone with no degree, but it is for someone with an associate's
    degree or more.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 分组箱线图说明了按学位获得的每周工作时间之间的四分位距的显著差异。在副学士学位水平（美国两年制学院学位）或以上，有低于须股的值，用点表示。在副学士学位以下，箱线图没有识别出任何异常值或极端值。例如，对于没有学位的人来说，0周工作值不是极端值，但对于拥有副学士学位或更高学位的人来说，则是。
- en: 'We can also use grouped boxplots to illustrate how the distribution of COVID-19
    cases varies by region. Let''s also add a swarmplot to view the data points since
    there aren''t too many of them:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用分组箱线图来展示COVID-19病例的分布如何因地区而异。让我们也添加一个swarmplot来查看数据点，因为它们并不多：
- en: '[PRE17]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This produces the following plot:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图表：
- en: '![Figure 2.9 – Boxplots of Total Cases Per Million by Region ](img/B17978_02_009.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9 – 按地区划分的每百万总病例箱线图](img/B17978_02_009.jpg)'
- en: Figure 2.9 – Boxplots of Total Cases Per Million by Region
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 – 按地区划分的每百万总病例箱线图
- en: These grouped boxplots show just how much the median cases per million varies
    by region, from East Africa and East Asia on the low end to Eastern Europe and
    Western Europe on the high end. Extremely high values for East Asia are *below*
    the first quartile for Western Europe. We should probably avoid drawing too many
    conclusions beyond that since the counts for most regions (the number of countries)
    are fairly small.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分组箱线图显示了每百万个案例的中位数如何因地区而异，从东非和东亚的低端到东欧和西欧的高端。东亚的极端高值低于西欧的第一四分位数。鉴于大多数地区的计数（国家数量）相当小，我们可能应该避免从那以后得出太多结论。
- en: So far in this chapter, we have focused mainly on bivariate relationships between
    features, as well as those between a feature and a target. The statistics and
    visualizations we have generated will inform the modeling we will do. We are already
    getting a sense of likely features, their influence on targets, and how the distributions
    of some features change with the values of another feature.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们主要关注特征之间的双变量关系，以及特征与目标之间的那些关系。我们生成的统计和可视化将指导我们将要进行的建模。我们已经开始对可能的特征、它们对目标的影响以及某些特征的分布如何随着另一个特征的值而变化有所了解。
- en: We will explore multivariate relationships in the remaining sections of this
    chapter. We want to have some sense of how multiple features move together before
    we begin our modeling. Do some features no longer matter once other features are
    included? Which observations pull on our parameter estimates more than others,
    and what are the implications for model fitting? Similarly, which observations
    are not like the others, because they either have invalid values or because they
    seem to be capturing a completely different phenomenon than the other observations?
    We will begin to answer those questions in the next three sections. Although we
    will not get any definitive answers until we construct our models, we can start
    making difficult modeling decisions by anticipating them.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章剩余部分探索多元关系。在我们开始建模之前，我们希望对多个特征如何一起移动有所了解。一旦包含其他特征，某些特征是否不再重要？哪些观测值对我们的参数估计的影响大于其他观测值，这对模型拟合有什么影响？同样，哪些观测值与其他观测值不同，因为它们要么具有无效值，要么似乎在捕捉与其他观测值完全不同的现象？我们将在接下来的三个部分中开始回答这些问题。尽管我们不会在构建模型之前得到任何明确的答案，但我们可以通过预测来开始做出困难的建模决策。
- en: Using linear regression to identify data points with significant influence
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性回归来识别具有显著影响的数据点
- en: It is not unusual to find that a few observations have a surprisingly high degree
    of influence on our model, our parameter estimates, and our predictions. This
    may or may not be desirable. Observations with significant influence may be unhelpful
    if they reflect a different social or natural process than the rest of the data
    does. For example, let's say we have a dataset of flying animals that migrate
    a great distance, and this is almost exclusively bird species, except for data
    on monarch butterflies. If we are using the wing architecture as a predictor of
    migration distance, the monarch butterfly data should probably be removed.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 发现一些观测值对我们的模型、参数估计和预测有出奇高的影响力并不罕见。这可能是或可能不是所希望的。如果这些观测值反映了与数据中的其他部分不同的社会或自然过程，那么具有显著影响力的观测值可能是有害的。例如，假设我们有一个关于飞行动物的飞行距离的数据集，这些动物几乎都是鸟类，除了关于帝王蝶的数据。如果我们使用翅膀结构作为预测迁移距离的因素，那么帝王蝶的数据可能应该被移除。
- en: We should return to the distinction we made in the first section between an
    extreme value and an outlier. We mentioned that an outlier can be thought of as
    an observation with feature values, or relationships between feature values, that
    are so unusual that they cannot help explain relationships in the rest of the
    data. An extreme value, on the other hand, may reflect a natural and explainable
    trend in a feature, or the same relationship between features that has been observed
    throughout the data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该回到第一部分中提到的极端值和异常值之间的区别。我们提到，异常值可以被视为具有特征值或特征值之间关系异常的观测值，这些关系在数据中的其他部分无法解释。另一方面，极端值可能反映了特征中的自然且可解释的趋势，或者在整个数据中观察到的特征之间的相同关系。
- en: Distinguishing between an outlier and an extreme value matters most with observations
    that have a high influence on our model. A standard measure of influence in regression
    analysis is **Cook's Distance** (**Cook's D**). This gives us a measure of how
    much our predictions would change if an observation were to be removed from the
    data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有高影响力的观测值中区分异常值和极端值最为重要。回归分析中影响的一个标准度量是**库克距离**（**Cook's D**）。这给出了如果从数据中删除一个观测值，我们的预测将如何变化的度量。
- en: 'Let''s construct a relatively straightforward multivariate regression model
    in this section with the COVID-19 data we have been using, and then generate a
    Cook''s D value for each observation:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在本节中构建一个相对简单的多元回归模型，使用我们一直在使用的COVID-19数据，并为每个观测值生成一个Cook's D值：
- en: 'Let''s load the COVID-19 data and the Matplotlib and statsmodels libraries:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载COVID-19数据和Matplotlib以及statsmodels库：
- en: '[PRE18]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, let''s look at the distribution of total cases per million in population
    and some possible predictors:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们来看看每百万人口中的总病例分布以及一些可能的预测因素：
- en: '[PRE19]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Next, let's define a function, `getlm`, that uses statsmodels to run a linear
    regression model and generate influence statistics, including Cook's D. This function
    takes a DataFrame, the name of the target column, and the column names for the
    features (it is customary to refer to a target as *y* and features as *X*).
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们定义一个函数`getlm`，该函数使用statsmodels运行线性回归模型并生成影响统计量，包括Cook's D。此函数接受一个DataFrame，目标列的名称，以及特征列的名称（通常将目标称为*y*，将特征称为*X*）。
- en: 'We will use `dropna` to drop any observations where one of the features has
    a missing value. The function returns the estimated coefficients (along with `pvalues`),
    the influence measures for each observation, and the full regression results (`lm`):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`dropna`函数删除任何特征值缺失的观测值。该函数返回估计的系数（包括`pvalues`），每个观测值的影响度量，以及完整的回归结果（`lm`）：
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we can call the `getlm` function while specifying the total cases per
    million as the target and population density (people per square mile), age 65
    plus the percentage, GDP per capita, and diabetes prevalence as predictors. Then,
    we can print the parameter estimates. Ordinarily, we would want to look at a full
    summary of the model, which can be generated with `lm.summary()`. We''ll skip
    that here for ease of understanding:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以调用`getlm`函数，同时指定每百万人口中的总病例数作为目标，人口密度（每平方英里的人数），65岁及以上的人口百分比，人均GDP和糖尿病患病率作为预测因素。然后，我们可以打印参数估计值。通常，我们希望查看模型的完整摘要，这可以通过`lm.summary()`生成。这里我们将跳过这一步，以便于理解：
- en: '[PRE21]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The coefficients for population density, age 65 plus, and GDP are all significant
    at the 95% level (have p-values less than 0.05). The result for population density
    is interesting since our bivariate analysis did not reveal a relationship between
    population density and cases per million. The coefficient indicates a 6.9-point
    reduction in cases per million, with a 1-point increase in people per square mile.
    Put more broadly, more crowded countries have fewer cases per million people once
    we control for the percentage of people that are 65 or older and their GDP per
    capita. This could be spurious, or it could be a relationship that can only be
    detected with multivariate analysis. (It could also be that population density
    is highly correlated with a feature that has a greater effect on cases per million,
    but that feature has been left out of the model. This would give us a biased coefficient
    estimate for population density.)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 人口密度、65岁及以上人口和GDP的系数在95%的水平上都是显著的（p值小于0.05）。人口密度的结果很有趣，因为我们的双变量分析没有揭示人口密度与每百万病例数之间的关系。系数表明，每平方英里人口增加1人，每百万病例数减少6.9点。更广泛地说，一旦我们控制了65岁或以上人口的比例和人均GDP，人口密度更高的国家每百万人口病例数会更少。这可能是一个偶然的关系，也可能是一个只能通过多元分析检测到的关系。（也可能是因为人口密度与一个对每百万病例数有更大影响的特征高度相关，但这个特征被遗漏在模型之外。这将给我们一个关于人口密度的有偏系数估计。）
- en: We can use the influence DataFrame that we created in our call to `getlm` to
    take a closer look at those observations with a high Cook's D. One way of defining
    a high Cook's D is by using three times the mean value for Cook's D for all observations.
    Let's create a `covidtotalsoutliers` DataFrame with all the values above that
    threshold.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用我们在调用`getlm`时创建的影响DataFrame来更仔细地查看那些Cook's D值高的观测值。定义高Cook's D的一种方法是用所有观测值的Cook's
    D平均值的三倍。让我们创建一个包含所有高于该阈值的值的`covidtotalsoutliers` DataFrame。
- en: There were 13 countries with Cook's D values above the threshold. Let's print
    out the first five in descending order of the Cook's D value. Bahrain and Maldives
    are in the top quarter of the distribution for cases (see the descriptives we
    printed earlier in this section). They also have high population densities and
    low percentages of age 65 or older. All else being equal, we would expect lower
    cases per million for those two countries, given what our model says about the
    relationship between population density and age to cases. Bahrain does have a
    very high GDP per capita, however, which our model tells us is associated with
    high case numbers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 有13个国家的Cook's D值超过了阈值。让我们按Cook's D值降序打印出前五个国家。巴林和马尔代夫在病例分布的前四分之一（参见本节之前我们打印的描述性统计）中。它们的人口密度也较高，65岁或以上的人口比例较低。在其他条件相同的情况下，根据我们的模型关于人口密度与病例之间关系的说法，我们预计这两个国家的每百万病例数会较低。然而，巴林的人均GDP非常高，我们的模型告诉我们这与病例数的高发有关。
- en: 'Singapore and Hong Kong have extremely high population densities and below-average
    cases per million, particularly Hong Kong. These two locations, alone, may account
    for the direction of the population density coefficient. They both also have very
    high GDP per capita values, which might be a drag on that coefficient. It may
    just be that our model should not include locations that are city-states:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 新加坡和香港的人口密度极高，每百万病例数低于平均水平，尤其是香港。这两个地方单独可能就解释了人口密度系数的方向。它们的人均GDP也非常高，这可能会对该系数产生拖累。可能只是我们的模型不应该包括城邦这样的地区：
- en: '[PRE22]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'So, let''s take a look at our regression model estimates if we remove Hong
    Kong and Singapore:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那么，让我们看看如果我们移除香港和新加坡，我们的回归模型估计会有什么变化：
- en: '[PRE23]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The big change in the model is that the population density coefficient has now
    changed direction. This demonstrates how sensitive the population density estimate
    is to outlier observations whose feature and target values may not be generalizable
    to the rest of the data. In this case, that might be true for city-states such
    as Hong Kong and Singapore.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 模型中的重大变化是人口密度系数现在已改变方向。这表明人口密度估计对异常观测值的敏感性，这些观测值的特征和目标值可能无法推广到其他数据。在这种情况下，这可能适用于像香港和新加坡这样的城邦。
- en: 'Generating influence measures with linear regression is a very useful technique,
    and it has the advantage that it is fairly easy to interpret, as we have seen.
    However, it does have one important disadvantage: it assumes a linear relationship
    between features, and that features are normally distributed. This is often not
    the case. We also needed to understand the relationships in the data enough to
    create *labels*, to identify total cases per million as the target. This is not
    always possible either. In the next two sections, we''ll look at machine learning
    algorithms for outlier detection that do not make these assumptions.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性回归生成影响度量是一种非常有用的技术，并且它有一个优点，那就是它相对容易解释，正如我们所看到的。然而，它确实有一个重要的缺点：它假设特征之间存在线性关系，并且特征是正态分布的。这通常并不成立。我们还需要足够理解数据中的关系，以创建*标签*，将每百万总病例数识别为目标。这也不总是可能的。在接下来的两个部分中，我们将探讨不做出这些假设的异常值检测机器学习算法。
- en: Using K-nearest neighbors to find outliers
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用K近邻算法寻找异常值
- en: Machine learning tools can help us identify observations that are unlike others
    when we have unlabeled data – that is, when there is no target or dependent variable.
    Even when selecting targets and features is relatively straightforward, it might
    be helpful to identify outliers without making any assumptions about relationships
    between features, or the distribution of features.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们拥有未标记数据时，机器学习工具可以帮助我们识别与其他观测值不同的观测值——也就是说，当没有目标或因变量时。即使选择目标和特征相对简单，也可能有助于在不假设特征之间的关系或特征分布的情况下识别异常值。
- en: Although we typically use **K-nearest neighbors** (**KNN**) with labeled data,
    for classification or regression problems, we can use it to identify anomalous
    observations. These are observations where there is the greatest difference between
    their values and their nearest neighbors' values. KNN is a very popular algorithm
    because it is intuitive, makes few assumptions about the structure of the data,
    and is quite flexible. The main disadvantage of KNN is that it is not as efficient
    as many other approaches, particularly parametric techniques such as linear regression.
    We will discuss these advantages in much greater detail in [*Chapter 9*](B17978_09_ePub.xhtml#_idTextAnchor113),
    *K-Nearest Neighbors, Decision Tree, Random Forest, and Gradient Boosted Regression*,
    and [*Chapter 12*](B17978_12_ePub.xhtml#_idTextAnchor144), *K-Nearest Neighbors
    for Classification*.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们通常使用**K近邻算法**（**KNN**）来处理标记数据，用于分类或回归问题，我们也可以用它来识别异常观测值。这些观测值的特点是它们的价值与最近邻的价值之间差异最大。KNN是一个非常受欢迎的算法，因为它直观、对数据的结构假设很少，并且相当灵活。KNN的主要缺点是它不如许多其他方法高效，尤其是像线性回归这样的参数技术。我们将在[*第9章*](B17978_09_ePub.xhtml#_idTextAnchor113)，*K近邻、决策树、随机森林和梯度提升回归*，以及[*第12章*](B17978_12_ePub.xhtml#_idTextAnchor144)，*K近邻在分类中的应用*中更详细地讨论这些优点。
- en: 'We will use **PyOD**, short for **Python outlier detection**, to identify countries
    in the COVID-19 data that are significantly different from others. PyOD can use
    several algorithms to identify outliers, including KNN. Let''s get started:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**PyOD**，即**Python异常值检测**，来识别COVID-19数据中与其他国家显著不同的国家。PyOD可以使用多种算法来识别异常值，包括KNN。让我们开始吧：
- en: 'First, we need to import the KNN module from PyOD and `StandardScaler` from
    the `sklearn` preprocessing utility functions. We also load the COVID-19 data:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要从PyOD库中导入KNN模块，以及从`sklearn`的预处理实用函数中导入`StandardScaler`。我们还加载了COVID-19数据：
- en: '[PRE24]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we standardize the data, which is important when we have features with
    very different ranges, from over 100,000 for total cases per million and GDP per
    capita to less than 20 for diabetes prevalence and age 65 and older. We can use
    scikit-learn''s standard scaler, which converts each feature value into a z-score,
    as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要标准化数据，这在我们的特征范围差异很大时很重要，例如从每百万总病例数和人均GDP超过100,000到糖尿病患病率和65岁及以上人口数不到20。我们可以使用scikit-learn的标准缩放器，它将每个特征值转换为z分数，如下所示：
- en: '![](img/B17978_02_0011.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17978_02_0011.jpg)'
- en: Here, ![](img/B17978_02_002.png) is the value for the *i*th observation of the
    *j*th feature, ![](img/B17978_02_003.png) is the mean for feature ![](img/B17978_02_004.png),
    and ![](img/B17978_02_005.png) is the standard deviation for that feature.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![图片](img/B17978_02_002.png)是第j个特征的第i个观测值的值，![图片](img/B17978_02_003.png)是特征![图片](img/B17978_02_004.png)的均值，而![图片](img/B17978_02_005.png)是该特征的标准差。
- en: 'We can use the scaler for just the features we will be including in our model,
    and then drop all observations that are missing values for one or more features:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用缩放器仅针对我们将在模型中包含的特征，然后删除一个或多个特征缺失值的所有观测值：
- en: '[PRE25]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we can run the model and generate predictions and anomaly scores. First,
    we must set `contamination` to `0.1` to indicate that we want 10% of observations
    to be identified as outliers. This is pretty arbitrary but not a bad starting
    point. After using the `fit` method to run the KNN algorithm, we get predictions
    (1 if an outlier, 0 if an inlier) and an anomaly score, which is the basis of
    the prediction (in this case, the top 10% of anomaly scores will get a prediction
    of 1):'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以运行模型并生成预测和异常分数。首先，我们必须将`contamination`设置为`0.1`，以表示我们希望10%的观测值被识别为异常值。这相当随意，但不是一个坏的开始。在用`fit`方法运行KNN算法后，我们得到预测（异常值为1，内点值为0）和异常分数，这是预测的基础（在这种情况下，异常分数最高的前10%将被预测为1）：
- en: '[PRE26]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can combine the two NumPy arrays with the predictions and anomaly scores
    – `y_pred` and `y_scores`, respectively – and convert them into the columns of
    a DataFrame. This makes it easier to view the range of anomaly scores and their
    associated predictions. 18 countries have been identified as outliers (this is
    a result of setting `contamination` to `0.1`). Outliers have anomaly scores of
    1.77 to 9.34, while inliers have scores of 0.11 to 1.74:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将预测和异常分数的两个NumPy数组（分别命名为`y_pred`和`y_scores`）合并，并将它们转换为DataFrame的列。这使得查看异常分数的范围及其相关的预测变得更容易。有18个国家被识别为异常值（这是将`contamination`设置为`0.1`的结果）。异常值的异常分数在1.77到9.34之间，而内点值的分数在0.11到1.74之间：
- en: '[PRE27]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s take a closer look at the countries with the highest anomaly scores:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看异常分数最高的国家：
- en: '[PRE28]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Several of the locations we identified as having high influence in the previous
    section have high anomaly scores, including Singapore, Hong Kong, Bahrain, and
    Maldives. This is more evidence that we need to take a closer look at the data
    for these countries. Perhaps there is invalid data or there are theoretical reasons
    why they are very different than the rest of the data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中我们确定的具有高影响力的几个地点，包括新加坡、香港、巴林和马尔代夫，它们的异常分数都很高。这进一步证明我们需要对这些国家的数据进行更仔细的审查。可能存在无效数据，或者有理论上的原因导致它们与其他数据差异很大。
- en: Unlike the linear model in the previous section, there is no defined target.
    We include both total cases per million and total deaths per million in this case.
    Peru has been identified as an outlier here, though it was not with the linear
    model. This is partly because of Peru's very high deaths per million, which is
    the highest in the dataset (we did not use deaths per million in our linear regression
    model).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一节中的线性模型不同，这里没有定义的目标。在这种情况下，我们包括每百万总病例数和每百万总死亡数。秘鲁在这里被识别为异常值，尽管在线性模型中并不是。这部分是因为秘鲁每百万死亡人数非常高，是数据集中的最高值（我们没有在线性回归模型中使用每百万死亡人数）。
- en: 'Notice that Japan is not on this list of outliers. Let''s take a look at its
    anomaly score:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意到日本并不在这个异常值列表中。让我们看看它的异常分数：
- en: '[PRE29]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The anomaly score is the 15th highest in the dataset. Compare this with the
    4th highest Cook's D score for Japan from the previous section.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 异常分数是数据集中第15高的。与上一节中日本第4高的Cook's D分数进行比较。
- en: It is interesting to compare these results with a similar analysis we could
    conduct with Isolation Forest. We will do that in the next section.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些结果与我们可以用Isolation Forest进行的类似分析进行比较是很有趣的。我们将在下一节中这样做。
- en: Note
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This has been a very simplified example of the approach we would take with a
    typical machine learning project. The most important omission here is that we
    are conducting our analysis on the full dataset. For reasons we will discuss at
    the beginning of [*Chapter 4*](B17978_04_ePub.xhtml#_idTextAnchor043), *Encoding,
    Transforming, and Scaling Features*, we want to split our data into training and
    testing datasets very early in the process. We will learn how to incorporate outlier
    detection in a machine learning pipeline in the remaining chapters of this book.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个简化的例子，展示了我们通常在机器学习项目中采取的方法。这里最重要的遗漏是我们对整个数据集进行分析。正如我们将在[*第4章*](B17978_04_ePub.xhtml#_idTextAnchor043)“编码、转换和特征缩放”的开始部分讨论的那样，我们希望在早期就将数据分成训练集和测试集。我们将在本书的剩余章节中学习如何在机器学习管道中集成异常值检测。
- en: Using Isolation Forest to find outliers
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Isolation Forest寻找异常值
- en: '**Isolation Forest** is a relatively new machine learning technique for identifying
    anomalies. It has quickly become popular, partly because its algorithm is optimized
    to find outliers, rather than normal values. It finds outliers by successively
    partitioning the data until a data point has been isolated. Points that require
    fewer partitions to be isolated receive higher anomaly scores. This process turns
    out to be fairly easy on system resources. In this section, we will learn how
    to use it to detect outlier COVID-19 cases and deaths.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Isolation Forest is a good alternative to KNN, particularly when we''re working
    with large datasets. The efficiency of the algorithm allows it to handle large
    samples and a high number of features. Let''s get started:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do an analysis similar to the one in the previous section with Isolation
    Forest rather than KNN. Let''s start by loading scikit-learn''s `StandardScaler`
    and `IsolationForest` modules, as well as the COVID-19 data:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, we must standardize the data:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须标准化数据：
- en: '[PRE31]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, we are ready to run our anomaly detection model. The `n_estimators` parameter
    indicates how many trees to build. Setting `max_features` to `1.0` will use all
    of our features. The `predict` method gives us the anomaly prediction, which is
    `-1` for an anomaly. This is based on the anomaly score, which we can get using
    `decision_function`:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let''s take a closer look at the outliers (we will also create a DataFrame
    of the inliers to use in a later step). We sort by anomaly score and show the
    countries with the highest (most negative) score. Singapore, Hong Kong, Bahrain,
    Qatar, and Peru are, again, the most anomalous:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'It''s helpful to look at a visualization of the outliers and inliers:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看异常值和内属值的可视化很有帮助：
- en: '[PRE34]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This produces the following plot:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下图表：
- en: '![Figure 2.10 – Isolation Forest Anomaly Detection – GDP Per Capita and Cases
    Per Million ](img/B17978_02_010.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 – Isolation Forest Anomaly Detection – GDP Per Capita and Cases
    Per Million
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Although we are only able to see three dimensions with this visualization, the
    plot does illustrate some of what makes an outlier an outlier. We expect cases
    to increase as the GDP per capita and the age 65 plus percentage increase. We
    can see that the outliers deviate from the expected pattern, having cases per
    million noticeably above or below countries with similar GDPs and age 65 plus
    values.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used bivariate and multivariate statistical techniques and
    visualizations to get a better sense of bivariate relationships among features.
    We looked at common statistics, such as the Pearson correlation. We also examined
    bivariate relationships through visualizations, with scatter plots when both features
    are continuous, and with grouped boxplots when one feature is categorical. The
    last three sections of this chapter explored multivariate techniques for examining
    relationships and identifying outliers, including machine learning algorithms
    such as KNN and Isolation Forest.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good sense of the distribution of our data, we are ready
    to start engineering our features, including imputing missing values and encoding,
    transforming, and scaling our variables. This will be our focus for the next two
    chapters.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对数据的分布有了很好的了解，我们准备开始构建我们的特征，包括填充缺失值和编码、转换以及缩放我们的变量。这将是下一章的重点。
