<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer140">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">8</span></h1>
<h1 class="chapterTitle" id="_idParaDest-204"><span class="koboSpan" id="kobo.2.1">Building a Data Science Environment Using AWS ML Services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">While some organizations opt to build their own ML platforms using open-source technologies, many other organizations prefer to leverage fully managed ML services as the foundation for their ML platforms. </span><span class="koboSpan" id="kobo.3.2">In this chapter, we will delve into the fully managed ML services offered by AWS. </span><span class="koboSpan" id="kobo.3.3">Specifically, you will learn about </span><strong class="keyWord"><span class="koboSpan" id="kobo.4.1">Amazon SageMaker</span></strong><span class="koboSpan" id="kobo.5.1">, and other related services for building a data science environment for data scientists. </span><span class="koboSpan" id="kobo.5.2">We will examine various components of SageMaker, such as SageMaker Studio, SageMaker Training, and SageMaker Hosting. </span><span class="koboSpan" id="kobo.5.3">Additionally, we will delve into the architectural framework for constructing a data science environment and provide a hands-on exercise to guide you through the process.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.6.1">In a nutshell, this chapter will cover the following topics:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.7.1">SageMaker overview</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.8.1">Data science environment architecture using SageMaker</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.9.1">Best practices for building a data science environment</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.10.1">Hands-on lab – building a data science environment using AWS services</span></li>
</ul>
<h1 class="heading-1" id="_idParaDest-205"><span class="koboSpan" id="kobo.11.1">Technical requirements</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.12.1">In this chapter, you will need access to an AWS account and have the following AWS services for the hands-on lab:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.13.1">Amazon S3</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.14.1">Amazon SageMaker</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.15.1">Amazon ECR</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.16.1">You will also need to download the dataset from </span><a href="https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news"><span class="url"><span class="koboSpan" id="kobo.17.1">https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news</span></span></a><span class="koboSpan" id="kobo.18.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.19.1">The sample source code used in this chapter can be found at </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter08"><span class="url"><span class="koboSpan" id="kobo.20.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter08</span></span></a><span class="koboSpan" id="kobo.21.1">.</span></p>
<h1 class="heading-1" id="_idParaDest-206"><span class="koboSpan" id="kobo.22.1">SageMaker overview</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.23.1">Amazon</span><a id="_idIndexMarker751"/><span class="koboSpan" id="kobo.24.1"> SageMaker offers ML functionalities that cover the entire ML lifecycle, spanning from initial experimentation to production deployment and ongoing monitoring. </span><span class="koboSpan" id="kobo.24.2">It caters to various roles, such as data scientists, data analysts, and MLOps engineers. </span><span class="koboSpan" id="kobo.24.3">The following diagram showcases the key SageMaker features that support the complete data science journey for different personas:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.25.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B20836_08_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.26.1">Figure 8.1: SageMaker capabilities</span></p>
<p class="normal"><span class="koboSpan" id="kobo.27.1">Within SageMaker, data scientists have access to an array of features and services to support different ML tasks. </span><span class="koboSpan" id="kobo.27.2">These include Studio notebooks for model building, Data Wrangler for visual data preparation, the Processing service for large-scale data processing and transformation, the Training service, the Tuning service for model tuning, and the Hosting service for model hosting. </span><span class="koboSpan" id="kobo.27.3">With these tools, data scientists can handle various ML responsibilities, such as data preparation, model building and training, model tuning, and conducting model integration testing.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.28.1">On the other</span><a id="_idIndexMarker752"/><span class="koboSpan" id="kobo.29.1"> hand, data analysts can utilize SageMaker Canvas, a user-friendly model-building service that requires little to no coding. </span><span class="koboSpan" id="kobo.29.2">This visual interface empowers analysts to train models effortlessly. </span><span class="koboSpan" id="kobo.29.3">Additionally, they can use Studio notebooks for lightweight data analysis and processing.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.30.1">MLOps engineers play a crucial role in managing and governing the ML environment. </span><span class="koboSpan" id="kobo.30.2">They are responsible for automating ML workflows and can leverage SageMaker Pipelines, Model Registry, and endpoint monitoring to achieve this. </span><span class="koboSpan" id="kobo.30.3">Furthermore, MLOps engineers configure the processing, training, and hosting infrastructure to ensure smooth operations for both interactive usage by data scientists and automated operations.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.31.1">In this chapter, our focus will center on data science environments catered specifically to data scientists. </span><span class="koboSpan" id="kobo.31.2">Subsequently, in the following chapter, we will delve into the administration, governance, and automation of ML infrastructure.</span></p>
<h1 class="heading-1" id="_idParaDest-207"><span class="koboSpan" id="kobo.32.1">Data science environment architecture using SageMaker</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.33.1">Data scientists </span><a id="_idIndexMarker753"/><span class="koboSpan" id="kobo.34.1">use data science environments to iterate different data science experiments with various datasets</span><a id="_idIndexMarker754"/><span class="koboSpan" id="kobo.35.1"> and algorithms. </span><span class="koboSpan" id="kobo.35.2">These environments require essential tools like Jupyter Notebook to author and execute code, data processing engines for handling large-scale data processing and feature engineering, and model training services for training models at scale. </span><span class="koboSpan" id="kobo.35.3">Additionally, an effective data science environment should include utilities for managing and tracking different experimentation runs, enabling researchers to organize and monitor their experiments effectively. </span><span class="koboSpan" id="kobo.35.4">To manage artifacts such as source code and Docker images, the data scientists also need a code repository and a Docker container repository. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.36.1">The following diagram illustrates a basic data science environment architecture that uses Amazon SageMaker and other supporting services:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.37.1"><img alt="Figure 8.1 – Data science environment architecture " src="../Images/B20836_08_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.38.1">Figure 8.2: Data science environment architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.39.1">SageMaker </span><a id="_idIndexMarker755"/><span class="koboSpan" id="kobo.40.1">has multiple </span><a id="_idIndexMarker756"/><span class="koboSpan" id="kobo.41.1">data science environments, including Studio, which is the primary data science development environment for data scientists, RStudio for R users, and Canvas for users who want a no-code/low-code development environment for building ML models. </span><span class="koboSpan" id="kobo.41.2">You also have access to TensorBoard, a popular tool for monitoring and visualizing model metrics such as loss and accuracy.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.42.1">Now, let’s explore how data scientists can leverage the different components of SageMaker to accomplish data science tasks.</span></p>
<h2 class="heading-2" id="_idParaDest-208"><span class="koboSpan" id="kobo.43.1">Onboarding SageMaker users</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.44.1">The</span><a id="_idIndexMarker757"/><span class="koboSpan" id="kobo.45.1"> primary SageMaker user interface for data scientists is SageMaker Studio, a data </span><a id="_idIndexMarker758"/><span class="koboSpan" id="kobo.46.1">science </span><strong class="keyWord"><span class="koboSpan" id="kobo.47.1">integrated development environment</span></strong><span class="koboSpan" id="kobo.48.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.49.1">IDE</span></strong><span class="koboSpan" id="kobo.50.1">). </span><span class="koboSpan" id="kobo.50.2">It provides core features such as hosted notebooks for running experiments, as well as access to different backend services such as data wrangling, model training, and model hosting services from a single user interface. </span><span class="koboSpan" id="kobo.50.3">It is the main interface for data scientists to interact with most of SageMaker’s functionality. </span><span class="koboSpan" id="kobo.50.4">It also provides a Python SDK for interacting with its backend services programmatically from Python notebooks or scripts. </span><span class="koboSpan" id="kobo.50.5">The</span><a id="_idIndexMarker759"/><span class="koboSpan" id="kobo.51.1"> following diagram shows the key components </span><a id="_idIndexMarker760"/><span class="koboSpan" id="kobo.52.1">of SageMaker Studio:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.53.1"><img alt="Figure 8.2 – SageMaker Studio architecture " src="../Images/B20836_08_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.54.1">Figure 8.3: SageMaker Studio architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.55.1">SageMaker Studio implements the concept of domains to segregate user environments. </span><span class="koboSpan" id="kobo.55.2">A domain represents a collection of user profiles, each equipped with specific configurations, such as the AWS IAM role used when running Jupyter notebook, tags, and access permission to SageMaker Canvas. </span><span class="koboSpan" id="kobo.55.3">Within each domain, a Studio user can access different Studio applications such as JupyterLab, Code Editor, or Canvas through a user profile. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.56.1">To run certain Studio applications such as JupyterLab and Code Editor, you need to create SageMaker Studio spaces. </span><span class="koboSpan" id="kobo.56.2">SageMaker Studio spaces are used to manage the storage and resource needs of these applications. </span><span class="koboSpan" id="kobo.56.3">Each space has a 1:1 relationship with an instance of an application, and is composed of resources such as a storage volume, application type, and image the application is based on. </span><span class="koboSpan" id="kobo.56.4">A space can be either private or shared.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.57.1">To begin</span><a id="_idIndexMarker761"/><span class="koboSpan" id="kobo.58.1"> using SageMaker, the initial step is to onboard users into SageMaker Studio. </span><span class="koboSpan" id="kobo.58.2">The onboarding process starts by creating a SageMaker domain, if one doesn’t already exist. </span><span class="koboSpan" id="kobo.58.3">For the single-user scenario, SageMaker provides a quick domain setup option. </span><span class="koboSpan" id="kobo.58.4">With the quick setup option, SageMaker automatically configures the new domain with default settings for fast setup. </span><span class="koboSpan" id="kobo.58.5">For advanced multi-user scenarios, SageMaker provides an advanced domain setup option. </span><span class="koboSpan" id="kobo.58.6">With the advanced setting, you can configure various aspects of the domain for enterprise adoption, such as the authentication method, access to different services, networking configuration, and data encryption keys. </span><span class="koboSpan" id="kobo.58.7">Following that, user profiles are created within the domain, and users are granted access to these profiles. </span><span class="koboSpan" id="kobo.58.8">Once the user profiles are set up, users can launch a Studio environment by selecting their respective user profile in a domain. </span><span class="koboSpan" id="kobo.58.9">This allows them to start working within SageMaker Studio.</span></p>
<h2 class="heading-2" id="_idParaDest-209"><span class="koboSpan" id="kobo.59.1">Launching Studio applications</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.60.1">There are </span><a id="_idIndexMarker762"/><span class="koboSpan" id="kobo.61.1">multiple applications available inside Studio, including JupyterLab, RStudio, Canvas, and Code Editor. </span><span class="koboSpan" id="kobo.61.2">You also have the option to launch the previous Studio Classic experience.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.62.1">In the SageMaker Studio environment, initiating a Jupyter notebook is a straightforward process. </span><span class="koboSpan" id="kobo.62.2">Begin by selecting the JupyterLab application, followed by the creation of a JupyterLab space. </span><span class="koboSpan" id="kobo.62.3">A space, serving as a named, self-contained, and durable storage container, can be attached to the JupyterLab application. </span><span class="koboSpan" id="kobo.62.4">During the space creation, you have the flexibility to choose the server instance type and the Docker image for your JupyterLab. </span><span class="koboSpan" id="kobo.62.5">Once the space is successfully created, you can proceed to launch the JupyterLab application and initiate a notebook within it. </span><span class="koboSpan" id="kobo.62.6">The JupyterLab notebook now has an AI-powered programming assistant (Jupyternaut) feature that you can use to ask programming questions. </span><span class="koboSpan" id="kobo.62.7">For example, you can ask questions such as “How do I import a Python library?” </span><span class="koboSpan" id="kobo.62.8">or “How do I train a model using SageMaker?”.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.63.1">Similarly, launching</span><a id="_idIndexMarker763"/><span class="koboSpan" id="kobo.64.1"> the Canvas application involves selecting it within the SageMaker Studio environment. </span><span class="koboSpan" id="kobo.64.2">As a no-code ML tool, Canvas provides features for data preparation, model training, inference, and workflow automation. </span><span class="koboSpan" id="kobo.64.3">While primarily designed for data analysts with a limited background in data science and ML, it also proves to be valuable for experienced data scientists aiming to quickly establish baseline models for diverse datasets. </span><span class="koboSpan" id="kobo.64.4">Users can leverage Canvas’s ready-to-use models for predictions without model building or choose to create custom models tailored to specific business problems. </span><span class="koboSpan" id="kobo.64.5">Ready-to-use models cover various use cases like language detection and document analysis. </span><span class="koboSpan" id="kobo.64.6">For custom models, Canvas supports building diverse model types using tabular and image data for personalized predictions. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.65.1">Importing data, whether from local or external sources such as S3, Amazon Redshift, or Databricks, is supported. </span><span class="koboSpan" id="kobo.65.2">Additionally, Canvas facilitates data preparation through Data Wrangler and offers generative AI foundation models for initiating conversational chats.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.66.1">The Code Editor, built on Code-OSS and Visual Studio Code Open Source, facilitates writing, testing, debugging, and running analytics and ML code. </span><span class="koboSpan" id="kobo.66.2">To launch the Code Editor, simply select the application within Studio and create a dedicated private space. </span><span class="koboSpan" id="kobo.66.3">This space operates on a</span><a id="_idIndexMarker764"/><span class="koboSpan" id="kobo.67.1"> single </span><strong class="keyWord"><span class="koboSpan" id="kobo.68.1">Amazon Elastic Compute Cloud</span></strong><span class="koboSpan" id="kobo.69.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.70.1">Amazon EC2</span></strong><span class="koboSpan" id="kobo.71.1">) instance for computing and a </span><a id="_idIndexMarker765"/><span class="koboSpan" id="kobo.72.1">corresponding </span><strong class="keyWord"><span class="koboSpan" id="kobo.73.1">Amazon Elastic Block Store</span></strong><span class="koboSpan" id="kobo.74.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.75.1">Amazon EBS</span></strong><span class="koboSpan" id="kobo.76.1">) volume for storage. </span><span class="koboSpan" id="kobo.76.2">All elements within the space, including code, Git profiles, and environment variables, are stored on this unified Amazon EBS volume.</span></p>
<h2 class="heading-2" id="_idParaDest-210"><span class="koboSpan" id="kobo.77.1">Preparing data</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.78.1">Preparing and</span><a id="_idIndexMarker766"/><span class="koboSpan" id="kobo.79.1"> processing data for model training is an essential step in the ML lifecycle to optimize model performance. </span><span class="koboSpan" id="kobo.79.2">To do this in the Studio environment, you can install and use your preferred library packages directly inside your Studio notebook. </span><span class="koboSpan" id="kobo.79.3">SageMaker also provides several data wrangling and processing services to assist with data preparation, including SageMaker Data Wrangler, and integrated data preparation with Amazon EMR and Glue for large-scale data preparation and processing.</span></p>
<h2 class="heading-2" id="_idParaDest-211"><span class="koboSpan" id="kobo.80.1">Preparing data interactively with SageMaker Data Wrangler</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.81.1">SageMaker Data Wrangler is a </span><a id="_idIndexMarker767"/><span class="koboSpan" id="kobo.82.1">fully managed service that helps data </span><a id="_idIndexMarker768"/><span class="koboSpan" id="kobo.83.1">scientists and engineers prepare and analyze their data for ML. </span><span class="koboSpan" id="kobo.83.2">With a graphical user interface, it facilitates data preparation tasks, such as data cleaning, feature engineering, feature selection, and visualization.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.84.1">To use Data Wrangler, you construct a data flow, a pipeline that connects the dataset, transformation, and analysis. </span><span class="koboSpan" id="kobo.84.2">When you create and run a data flow, Data Wrangler spins up an EC2 instance to run the transformation and analysis. </span><span class="koboSpan" id="kobo.84.3">Each data flow is associated with an EC2 instance. </span><span class="koboSpan" id="kobo.84.4">A data flow normally starts with a data import step. </span><span class="koboSpan" id="kobo.84.5">Data Wrangler allows you to import data from multiple data sources, including Amazon S3, Athena, Amazon Redshift, Amazon EMR, Databricks, Snowflake, as well as </span><strong class="keyWord"><span class="koboSpan" id="kobo.85.1">Software-as-a-Service</span></strong><span class="koboSpan" id="kobo.86.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.87.1">SaaS</span></strong><span class="koboSpan" id="kobo.88.1">) platforms such as Datadog, GitHub, and Stripe.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.89.1">After the data is imported, you can use Data Wrangler to clean and explore the data and perform feature engineering with a built-in transform. </span><span class="koboSpan" id="kobo.89.2">You can also use the preconfigured visualization templates to understand data and detect outliers. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.90.1">You can assess the data quality with built-in reports. </span><span class="koboSpan" id="kobo.90.2">The following diagram shows the flow and architecture of Data Wrangler:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.91.1"><img alt="A diagram of a data processing process  Description automatically generated" src="../Images/B20836_08_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.92.1">Figure 8.4: SageMaker Data Wrangler architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.93.1">When </span><a id="_idIndexMarker769"/><span class="koboSpan" id="kobo.94.1">utilizing Data Wrangler, the first step involves importing sample data from various data sources to perform data processing and transformations. </span><span class="koboSpan" id="kobo.94.2">After completing the necessary </span><a id="_idIndexMarker770"/><span class="koboSpan" id="kobo.95.1">transformation steps, you have the option to export a recipe. </span><span class="koboSpan" id="kobo.95.2">This recipe can then be executed by SageMaker Processing, which processes the entire dataset based on the defined transformations.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.96.1">Additionally, you have the option to export the transformation steps into a notebook file. </span><span class="koboSpan" id="kobo.96.2">This notebook file can be used to initiate a SageMaker Processing job, allowing for the data to be processed and transformed. </span><span class="koboSpan" id="kobo.96.3">The resulting output can be either directed to SageMaker Feature Store or stored in Amazon S3 for further usage and analysis.</span></p>
<h2 class="heading-2" id="_idParaDest-212"><span class="koboSpan" id="kobo.97.1">Preparing data at scale interactively</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.98.1">When </span><a id="_idIndexMarker771"/><span class="koboSpan" id="kobo.99.1">dealing with large-scale data analysis, transformation, and preparation tasks, SageMaker offers built-in integration with Amazon EMR and AWS Glue. </span><span class="koboSpan" id="kobo.99.2">This built-in integration allows you to manage and handle large-scale interactive data preparation. </span><span class="koboSpan" id="kobo.99.3">By leveraging Amazon EMR, you can process and analyze massive datasets, while AWS Glue provides a serverless capability to prepare data at scale, as well as providing easy access to Glue data catalogs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.100.1">Within the Studio notebook environment, you have the capability to discover and establish connections with their existing Amazon EMR clusters. </span><span class="koboSpan" id="kobo.100.2">This enables them to interactively explore, visualize, and prepare large-scale data for ML tasks, leveraging powerful tools such as Apache Spark, Apache Hive, and Presto. </span><span class="koboSpan" id="kobo.100.3">The following diagram shows how SageMaker integration with EMR works:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.101.1"><img alt="A diagram of a software development process  Description automatically generated" src="../Images/B20836_08_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.102.1">Figure 8.5: SageMaker integration with EMR </span></p>
<p class="normal"><span class="koboSpan" id="kobo.103.1">As a user, you </span><a id="_idIndexMarker772"/><span class="koboSpan" id="kobo.104.1">connect to an existing EMR cluster from your Studio notebooks. </span><span class="koboSpan" id="kobo.104.2">If there is no EMR cluster available, you can self-provision one directly from the Studio environment by choosing a predefined template created by system administrators. </span><span class="koboSpan" id="kobo.104.3">System administrators use AWS Service Catalog to define parameterized templates for data scientists to use. </span><span class="koboSpan" id="kobo.104.4">Once your notebook is connected to an EMR cluster, you can run Spark commands or code inside your notebook cells.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.105.1">AWS Glue interactive sessions is a serverless service that provides you with the tools to collect, transform, cleanse, and prepare the data. </span><span class="koboSpan" id="kobo.105.2">The built-in integration between SageMaker and Glue interactive sessions allows you to run interactive sessions for data preparation interactively using Glue as the backend.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.106.1"><img alt="A diagram of a diagram  Description automatically generated" src="../Images/B20836_08_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.107.1">Figure 8.6: SageMaker integration with AWS Glue interactive sessions</span></p>
<p class="normal"><span class="koboSpan" id="kobo.108.1">To use</span><a id="_idIndexMarker773"/><span class="koboSpan" id="kobo.109.1"> Glue interactive sessions inside the Studio notebook, you choose the built-in Glue PySpark or Glue Spark kernel when you create your Studio notebook. </span><span class="koboSpan" id="kobo.109.2">After initialization, you can browse the Glue data catalog, run large queries, and interactively analyze and prepare data using Spark, all within your Studio notebook.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.110.1">Both EMR and Glue offer similar capabilities for large-scale interactive data processing. </span><span class="koboSpan" id="kobo.110.2">Glue interactive sessions are a good choice if you are looking for a quick and serverless way to run Spark sessions. </span><span class="koboSpan" id="kobo.110.3">EMR provides more robust capabilities and the flexibility to configure your compute cluster for optimization.</span></p>
<h2 class="heading-2" id="_idParaDest-213"><span class="koboSpan" id="kobo.111.1">Processing data as separate jobs</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.112.1">SageMaker Processing </span><a id="_idIndexMarker774"/><span class="koboSpan" id="kobo.113.1">provides a separate infrastructure for large-scale data processing such as data cleaning and feature engineering for large datasets as separate backend jobs. </span><span class="koboSpan" id="kobo.113.2">It can be accessed directly from a notebook environment via the SageMaker Python SDK or Boto3 SDK. </span><span class="koboSpan" id="kobo.113.3">SageMaker Processing uses Docker container images to run data processing jobs. </span><span class="koboSpan" id="kobo.113.4">Several built-in containers, such as scikit-learn containers and Spark containers, are provided out of the box. </span><span class="koboSpan" id="kobo.113.5">You also have the option to use your custom containers for processing. </span><span class="koboSpan" id="kobo.113.6">The following diagram shows the SageMaker Processing architecture:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.114.1"><img alt="Figure 8.3 – SageMaker Processing architecture " src="../Images/B20836_08_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.115.1">Figure 8.7: SageMaker Processing architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.116.1">When a</span><a id="_idIndexMarker775"/><span class="koboSpan" id="kobo.117.1"> SageMaker Processing job is initiated, the processing container is pulled from Amazon ECR and loaded into the EC2 compute cluster. </span><span class="koboSpan" id="kobo.117.2">The data in S3 is copied over to the storage attached to the compute nodes for the data processing scripts to access and process. </span><span class="koboSpan" id="kobo.117.3">Once the processing procedure is completed, the output data is copied back to the S3 output location.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.118.1">SageMaker Processing provides several processors for data processing, including a Spark processor, scikit-learn processor, and your own customer processor by bringing your containers. </span><span class="koboSpan" id="kobo.118.2">SageMaker Processing also supports processors for different ML frameworks, including PyTorch, TensorFlow, MXNet, Hugging Face, and XGBoost. </span><span class="koboSpan" id="kobo.118.3">You can use one of the processors if you need to use library packages as part of the processing script.</span></p>
<h2 class="heading-2" id="_idParaDest-214"><span class="koboSpan" id="kobo.119.1">Creating, storing, and sharing features</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.120.1">When</span><a id="_idIndexMarker776"/><span class="koboSpan" id="kobo.121.1"> data scientists perform feature engineering for training data preparation, they often need to reuse the same features for different model tasks. </span><span class="koboSpan" id="kobo.121.2">Further, features generated could be used for both training and inference to help reduce the training-serving skew. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.122.1">Amazon SageMaker Feature Store is a </span><a id="_idIndexMarker777"/><span class="koboSpan" id="kobo.123.1">service for sharing and managing ML features for ML development and serving. </span><span class="koboSpan" id="kobo.123.2">Feature Store is a centralized store for features and associated metadata so features can be discovered and reused. </span><span class="koboSpan" id="kobo.123.3">It has an online component as </span><a id="_idIndexMarker778"/><span class="koboSpan" id="kobo.124.1">well as an offline component. </span><span class="koboSpan" id="kobo.124.2">The online store is used for low-latency real-time inference use cases, and the offline store is used for training and batch inference. </span><span class="koboSpan" id="kobo.124.3">The following diagram shows how Feature Store works. </span><span class="koboSpan" id="kobo.124.4">As you can see, it is quite similar to the architecture of other open-source alternatives, such as Feast, with the key difference being it is fully managed.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.125.1"><img alt="A diagram of a software store  Description automatically generated" src="../Images/B20836_08_08.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.126.1">Figure 8.8: SageMaker Feature Store</span></p>
<p class="normal"><span class="koboSpan" id="kobo.127.1">To begin, you first read and process the raw data. </span><span class="koboSpan" id="kobo.127.2">The data is then ingested into online and offline stores via streaming, or directly to the offline store via batch. </span><span class="koboSpan" id="kobo.127.3">Feature Store uses the concept called </span><code class="inlineCode"><span class="koboSpan" id="kobo.128.1">FeatureGroup</span></code><span class="koboSpan" id="kobo.129.1"> to store and manage features. </span><span class="koboSpan" id="kobo.129.2">A </span><code class="inlineCode"><span class="koboSpan" id="kobo.130.1">FeatureGroup</span></code><span class="koboSpan" id="kobo.131.1"> is a collection of features that are defined via a schema in Feature Store, describing the structure and metadata associated with a record. </span><span class="koboSpan" id="kobo.131.2">You can visualize a feature group as a table in which each column is a feature, with a unique identifier for each row.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.132.1">The online store is specifically optimized for real-time predictions, offering low-latency reads and high-throughput writes. </span><span class="koboSpan" id="kobo.132.2">It is ideal for scenarios that require quick access to feature data for real-time inference. </span><span class="koboSpan" id="kobo.132.3">On the other hand, the offline store is designed for batch predictions and model training purposes. </span><span class="koboSpan" id="kobo.132.4">It operates as an append-only store, allowing historical feature data to be stored and accessed. </span><span class="koboSpan" id="kobo.132.5">The offline store is particularly useful for storing and serving features during exploration and model training processes.</span></p>
<h2 class="heading-2" id="_idParaDest-215"><span class="koboSpan" id="kobo.133.1">Training ML models</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.134.1">Once you</span><a id="_idIndexMarker779"/><span class="koboSpan" id="kobo.135.1"> have prepared the training data, you are all set to train the model. </span><span class="koboSpan" id="kobo.135.2">Data scientists can use the SageMaker Training service to handle model training that requires dedicated training infrastructure and instance types. </span><span class="koboSpan" id="kobo.135.3">The Training service is also ideal for large-scale distributed training using multiple nodes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.136.1">To start training, you first store your training data in storage such as Amazon S3, Amazon EFS, or Amazon FSx. </span><span class="koboSpan" id="kobo.136.2">You choose different storage options based on your specific requirements, such as cost and latency. </span><span class="koboSpan" id="kobo.136.3">S3 is the most common one, suitable for the majority of model training needs. </span><span class="koboSpan" id="kobo.136.4">With S3, you have multiple modes to ingest data from S3 to the training infrastructure:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.137.1">File mode</span></strong><span class="koboSpan" id="kobo.138.1">: This is </span><a id="_idIndexMarker780"/><span class="koboSpan" id="kobo.139.1">the default input model whereby SageMaker downloads the training data from S3 to a local directory in the training instance. </span><span class="koboSpan" id="kobo.139.2">The training starts when the full dataset has been downloaded. </span><span class="koboSpan" id="kobo.139.3">With this mode, the training instance must have sufficient local storage space to fit the entire dataset.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.140.1">Pipe mode</span></strong><span class="koboSpan" id="kobo.141.1">: With</span><a id="_idIndexMarker781"/><span class="koboSpan" id="kobo.142.1"> this mode, data is streamed directly from an S3 data source. </span><span class="koboSpan" id="kobo.142.2">This can provide faster start times and better throughput than the file mode. </span><span class="koboSpan" id="kobo.142.3">This model also reduces the size of the storage volumes attached to the training instances. </span><span class="koboSpan" id="kobo.142.4">It only needs enough space to store the final model artifacts.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.143.1">Fast file mode</span></strong><span class="koboSpan" id="kobo.144.1">: This </span><a id="_idIndexMarker782"/><span class="koboSpan" id="kobo.145.1">mode is the newer and simpler-to-use replacement of pipe mode. </span><span class="koboSpan" id="kobo.145.2">At the start of the training, the data files are identified but not downloaded. </span><span class="koboSpan" id="kobo.145.3">Training can start without waiting for the entire dataset to download. </span><span class="koboSpan" id="kobo.145.4">Fast file mode exposes S3 objects using a POSIX-compliant file system interface, as if the files are available on the local disk of the training instances. </span><span class="koboSpan" id="kobo.145.5">It streams the S3 data on demand as the training script consumes it, meaning that you don’t need to fit the training data into the training instance storage.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.146.1">In addition to S3, you can also store your training data in Amazon FSx for Lustre. </span><span class="koboSpan" id="kobo.146.2">You want to</span><a id="_idIndexMarker783"/><span class="koboSpan" id="kobo.147.1"> use FSx when you have high-throughput and low-latency data retrieval requirements for your training data. </span><span class="koboSpan" id="kobo.147.2">With FSx, you can scale to hundreds of gigabytes of throughput and millions </span><a id="_idIndexMarker784"/><span class="koboSpan" id="kobo.148.1">of </span><strong class="keyWord"><span class="koboSpan" id="kobo.149.1">Inputs/Outputs Operations Per Second</span></strong><span class="koboSpan" id="kobo.150.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.151.1">IOPS</span></strong><span class="koboSpan" id="kobo.152.1">) with low-latency file retrieval. </span><span class="koboSpan" id="kobo.152.2">When a training job is started, it mounts FSx to the training instance file system as a local drive. </span><span class="koboSpan" id="kobo.152.3">FSx allows the training job to run faster as it takes less time to read the files and it does not need to copy data to the training instance’s local storage like S3 file mode. </span><span class="koboSpan" id="kobo.152.4">EFS provides similar functionality as FSx, but at a lower throughput and higher latency.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.153.1">If you already have data in your EFS system, you can directly launch a training job using data in EFS without data movement. </span><span class="koboSpan" id="kobo.153.2">This reduces the training start time. </span><span class="koboSpan" id="kobo.153.3">Compared to FSx, EFS is less costly but has lower throughput and higher latency.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.154.1">Once the training data is ready in the storage system of your choice, you can kick off the training job using the AWS Boto3 SDK or the SageMaker Python SDK. </span><span class="koboSpan" id="kobo.154.2">To run the training job, you need to provide configuration details such as the training Docker image’s URL from ECR, the training script location, the framework version, the training dataset location, and the S3 model output location, as well as infrastructure details such as the compute instance type and number, as well as networking details. </span><span class="koboSpan" id="kobo.154.3">The following sample code shows how to configure and kick off a training job using the SageMaker SDK.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.155.1">The SageMaker Training service uses containers as a core technology for training management. </span><span class="koboSpan" id="kobo.155.2">All training jobs are executed inside containers hosted on SageMaker training infrastructure. </span><span class="koboSpan" id="kobo.155.3">The following diagram shows the architecture of the SageMaker Training service:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.156.1"><img alt="Figure 8.4 – SageMaker Training Service architecture " src="../Images/B20836_08_09.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.157.1">Figure 8.9: SageMaker Training Service architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.158.1">SageMaker</span><a id="_idIndexMarker785"/><span class="koboSpan" id="kobo.159.1"> provides various managed containers for model training using different ML algorithms and ML frameworks. </span><span class="koboSpan" id="kobo.159.2">Firstly, there is a list of built-in containerized algorithms for different ML tasks such as computer vision, NLP, forecasting, and common tabular regression and classifications. </span><span class="koboSpan" id="kobo.159.3">With these built-in algorithms, you only need to provide the training data location. </span><span class="koboSpan" id="kobo.159.4">SageMaker also provides a list of managed framework containers, such as containers for scikit-learn, TensorFlow, and PyTorch. </span><span class="koboSpan" id="kobo.159.5">With a managed framework container, in addition to providing data sources and infrastructure specifications, you also need to provide a training script that runs the model training loop.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.160.1">If the built-in algorithms and framework containers do not meet your needs, you can bring your own custom container for model training. </span><span class="koboSpan" id="kobo.160.2">This container needs to contain the model training scripts, as well as all the dependencies required to run the training loop.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.161.1">By default, SageMaker tracks all training jobs and their associated metadata, such as algorithms, input training dataset URLs, hyperparameters, and model output locations. </span><span class="koboSpan" id="kobo.161.2">Training jobs also emit system metrics and algorithm metrics to AWS CloudWatch for monitoring. </span><span class="koboSpan" id="kobo.161.3">Training logs are also sent to CloudWatch Logs for inspection and analysis needs. </span><span class="koboSpan" id="kobo.161.4">This metadata is critical for lineage tracking and reproducibility.</span></p>
<h2 class="heading-2" id="_idParaDest-216"><span class="koboSpan" id="kobo.162.1">Tuning ML models</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.163.1">To</span><a id="_idIndexMarker786"/><span class="koboSpan" id="kobo.164.1"> optimize the model’s performance, you also need to try different hyperparameters, such as a learning rate for gradient descent and model training. </span><span class="koboSpan" id="kobo.164.2">An algorithm can contain a large number of hyperparameters, and tuning them manually would be a highly labor-intensive task. </span><span class="koboSpan" id="kobo.164.3">The SageMaker Tuning service works with SageMaker training jobs to tune model training hyperparameters automatically. </span><span class="koboSpan" id="kobo.164.4">The following four types of hyperparameter tuning strategies are supported by the service:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.165.1">Grid search</span></strong><span class="koboSpan" id="kobo.166.1">: Grid search</span><a id="_idIndexMarker787"/><span class="koboSpan" id="kobo.167.1"> is an exhaustive search technique that systematically explores a predefined set of hyperparameter values over a specified range for each hyperparameter. </span><span class="koboSpan" id="kobo.167.2">It creates a grid of all possible combinations and evaluates the model’s performance for each configuration using cross-validation or a validation set. </span><span class="koboSpan" id="kobo.167.3">Grid search is highly focused, but it can be highly inefficient due to the large number of combinations, especially when the hyperparameter dimension is high.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.168.1">Random search</span></strong><span class="koboSpan" id="kobo.169.1">: Random search is a popular and effective hyperparameter optimization </span><a id="_idIndexMarker788"/><span class="koboSpan" id="kobo.170.1">technique that offers an alternative to exhaustive methods like grid search. </span><span class="koboSpan" id="kobo.170.2">Unlike grid search, which evaluates all possible combinations of hyperparameters within predefined ranges, random search takes a more stochastic approach. </span><span class="koboSpan" id="kobo.170.3">Instead of covering the entire search space systematically, it randomly samples hyperparameter values from defined distributions for each hyperparameter. </span><span class="koboSpan" id="kobo.170.4">Random search can be more efficient, compared to grid search; however, it might not always find the best combination of hyperparameters.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.171.1">Bayesian search</span></strong><span class="koboSpan" id="kobo.172.1">: This is</span><a id="_idIndexMarker789"/><span class="koboSpan" id="kobo.173.1"> where the hyperparameter search is treated like a regression problem, where the inputs for regression are the values of the hyperparameters and the output is the model’s performance metric once the model has been trained using the input values. </span><span class="koboSpan" id="kobo.173.2">The tuning service uses the values that have been collected from the training jobs to predict the next set of values that would produce model improvement. </span><span class="koboSpan" id="kobo.173.3">Compared to random search, Bayesian search is more efficient as it uses a model to focus on the most promising search spaces of hyperparameters.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.174.1">Hyperband</span></strong><span class="koboSpan" id="kobo.175.1">: Hyperband</span><a id="_idIndexMarker790"/><span class="koboSpan" id="kobo.176.1"> leverages the concept of bandit algorithms and successive halving to make the search process more effective and resource-efficient. </span><span class="koboSpan" id="kobo.176.2">It begins by randomly sampling a large number of hyperparameter configurations and then dividing them into multiple “bands” or sets. </span><span class="koboSpan" id="kobo.176.3">In each band, the configurations are evaluated through a predefined number of iterations, eliminating poorly performing ones at regular intervals. </span><span class="koboSpan" id="kobo.176.4">The surviving configurations are then promoted to the next band, where they are given additional iterations to fine-tune their performance. </span><span class="koboSpan" id="kobo.176.5">This process continues, gradually increasing the resources allocated to promising configurations while efficiently discarding underperforming ones. </span><span class="koboSpan" id="kobo.176.6">Hyperband is known to be more efficient than other methods, and it can find good combinations of hyperparameters with fewer iterations.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.177.1">The</span><a id="_idIndexMarker791"/><span class="koboSpan" id="kobo.178.1"> SageMaker tuning service works with SageMaker training jobs to optimize the hyperparameters. </span><span class="koboSpan" id="kobo.178.2">It works by sending different input hyperparameter values to the training jobs and picking the hyperparameter values that return the best model metrics. </span><span class="koboSpan" id="kobo.178.3">The following diagram shows how the SageMaker tuning service works:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.179.1"><img alt="A diagram of a training process  Description automatically generated" src="../Images/B20836_08_10.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.180.1">Figure 8.10: SageMaker tuning architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.181.1">To use the SageMaker tuning service, you create a tuning job and specify configuration details such as tuning strategy, objective metric to optimize, hyperparameters to tune and their ranges, max number of training jobs to run, and the number of jobs to run in parallel. </span><span class="koboSpan" id="kobo.181.2">Subsequently, the tuning job will kick off a number of training jobs. </span><span class="koboSpan" id="kobo.181.3">Depending on the tuning strategy, the tuning job will pass different hyperparameters to the training jobs to execute. </span><span class="koboSpan" id="kobo.181.4">The training metrics from the training jobs will be used by the tuning job to determine what hyperparameters to use in order to optimize the model performance.</span></p>
<h2 class="heading-2" id="_idParaDest-217"><span class="koboSpan" id="kobo.182.1">Deploying ML models for testing</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.183.1">Data scientists </span><a id="_idIndexMarker792"/><span class="koboSpan" id="kobo.184.1">normally do not deploy models for client application consumption directly. </span><span class="koboSpan" id="kobo.184.2">However, data scientists sometimes need to test the performance of models trained with the SageMaker training service, and they will need to deploy these models to an API endpoint for testing. </span><span class="koboSpan" id="kobo.184.3">This is especially needed for models of large sizes where they can’t be evaluated in a notebook instance. </span><span class="koboSpan" id="kobo.184.4">SageMaker provides a dedicated service for model hosting and its architecture is illustrated as follows: </span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.185.1"><img alt="A diagram of a server  Description automatically generated" src="../Images/B20836_08_11.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.186.1">Figure 8.11: SageMaker hosting architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.187.1">The SageMaker Hosting service offers multiple model inference options for different needs, from real-time inference to batch inference. </span><span class="koboSpan" id="kobo.187.2">The following are some options available for data scientists to use for model hosting evaluation and testing:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.188.1">One of the most common model serving use cases is low-latency prediction in real time on a sustained basis. </span><span class="koboSpan" id="kobo.188.2">For this use case, you should consider the </span><strong class="screenText"><span class="koboSpan" id="kobo.189.1">real-time inference</span></strong><span class="koboSpan" id="kobo.190.1"> option from the SageMaker hosting service. </span><span class="koboSpan" id="kobo.190.2">SageMaker real-time inference provides multiple options for model hosting, including single-model hosting, multiple-model hosting in a single container behind one endpoint, and multiple-model hosting using different containers behind one endpoint.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.191.1">Sometimes, you have models that are used for intermittent predictions with idle periods between traffic bursts. </span><span class="koboSpan" id="kobo.191.2">For this type of requirement, you can consider the </span><strong class="screenText"><span class="koboSpan" id="kobo.192.1">Serverless</span></strong><span class="koboSpan" id="kobo.193.1"> option from the SageMaker hosting service. </span><span class="koboSpan" id="kobo.193.2">The key benefit of using Serverless Inference is the removal of infrastructure configuration and management overhead. </span><span class="koboSpan" id="kobo.193.3">It is also more cost effective since you don’t need to pay for infrastructure when it is not used, unlike real-time inference, where </span><a id="_idIndexMarker793"/><span class="koboSpan" id="kobo.194.1">you need to pay for the infrastructure whether there is inference traffic or not. </span><span class="koboSpan" id="kobo.194.2">However, there might be a delay caused by cold-starts with Serverless Inference when the model is invoked for the first time or there is extended idle time between invocations to allow SageMaker Serverless Inference to launch instances.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.195.1">Sometimes, the payload size of an inference can be very large, and it takes a long time to generate the prediction. </span><span class="koboSpan" id="kobo.195.2">In this case, a real-time endpoint won’t work due to the large payload size and extended time for the inference. </span><span class="koboSpan" id="kobo.195.3">For this type of use case, you can consider </span><strong class="screenText"><span class="koboSpan" id="kobo.196.1">the asynchronous inference</span></strong><span class="koboSpan" id="kobo.197.1"> option of SageMaker hosting. </span><span class="koboSpan" id="kobo.197.2">Asynchronous inference queues the incoming requests and processes them asynchronously (as the name suggests). </span><span class="koboSpan" id="kobo.197.3">When using asynchronous inference, the input data and prediction output are stored in S3 instead of sending the payload and getting the response directly from the endpoint API. </span><span class="koboSpan" id="kobo.197.4">When the prediction is complete, you get a notification from the AWS SNS service.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.198.1">Another model inference </span><a id="_idIndexMarker794"/><span class="koboSpan" id="kobo.199.1">pattern is </span><strong class="keyWord"><span class="koboSpan" id="kobo.200.1">batch inference</span></strong><span class="koboSpan" id="kobo.201.1">. </span><span class="koboSpan" id="kobo.201.2">This is when you have a large number of inferences to do, and they don’t need individual predictions to be generated and returned. </span><span class="koboSpan" id="kobo.201.3">For example, you might need to run a propensity-to-buy model for a large number of users and store the output in a database for downstream consumption. </span><span class="koboSpan" id="kobo.201.4">For this usage pattern, you can consider the SageMaker Batch Transform feature for model inference. </span><span class="koboSpan" id="kobo.201.5">Batch inference is also more cost effective as you only need to spin up the infrastructure when running the batch job.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.202.1">Having discussed the various tasks involved in completing an ML project, ranging from data preparation to model deployment using the different SageMaker features, now let’s briefly talk about the need for automation. </span><span class="koboSpan" id="kobo.202.2">Data scientists frequently engage in iterative experimentation and model development, involving different datasets, new features, and various training scripts. </span><span class="koboSpan" id="kobo.202.3">Keeping track of configurations and model metrics for each run becomes essential. </span><span class="koboSpan" id="kobo.202.4">To streamline and automate these repetitive tasks, automation pipelines can be constructed, supporting various ML processes like data processing, model training, and model testing.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.203.1">There are</span><a id="_idIndexMarker795"/><span class="koboSpan" id="kobo.204.1"> several tools available for automation and orchestration, including SageMaker’s Pipelines feature. </span><span class="koboSpan" id="kobo.204.2">It allows the creation of a </span><strong class="keyWord"><span class="koboSpan" id="kobo.205.1">Directed Acyclic Graph</span></strong><span class="koboSpan" id="kobo.206.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.207.1">DAG</span></strong><span class="koboSpan" id="kobo.208.1">) to</span><a id="_idIndexMarker796"/><span class="koboSpan" id="kobo.209.1"> efficiently orchestrate and automate ML workflows. </span><span class="koboSpan" id="kobo.209.2">SageMaker Pipelines shares similarities with Airflow, an open-source workflow orchestration tool discussed in </span><em class="chapterRef"><span class="koboSpan" id="kobo.210.1">Chapter 7</span></em><span class="koboSpan" id="kobo.211.1">, </span><em class="italic"><span class="koboSpan" id="kobo.212.1">Open-Source ML Platforms</span></em><span class="koboSpan" id="kobo.213.1">. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.214.1">Additionally, AWS Step Functions serves as an alternative option for building automated workflow orchestration, providing flexibility and scalability to accommodate diverse ML tasks. </span><span class="koboSpan" id="kobo.214.2">By leveraging these tools, data scientists can enhance efficiency, reproducibility, and organization in their ML workflows.</span></p>
<h1 class="heading-1" id="_idParaDest-218"><span class="koboSpan" id="kobo.215.1">Best practices for building a data science environment</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.216.1">Data science environments </span><a id="_idIndexMarker797"/><span class="koboSpan" id="kobo.217.1">are meant for data scientists to perform quick experimentations using a wide range of ML frameworks and libraries. </span><span class="koboSpan" id="kobo.217.2">The following are some best practices to follow when providing such an environment for your data scientists:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.218.1">Run large-scale model training using the SageMaker Training service instead of Studio notebooks</span></strong><span class="koboSpan" id="kobo.219.1">: SageMaker Studio notebooks are meant for quick experimentation with small datasets. </span><span class="koboSpan" id="kobo.219.2">While it is possible to provision large EC2 instances for certain large model training jobs, it is not cost effective to always keep a large EC2 instance running for a notebook all the time.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.220.1">Abstract infrastructure configuration details from data scientists</span></strong><span class="koboSpan" id="kobo.221.1">: There are many infrastructure configurations to consider when using SageMaker, such as networking configuration, IAM roles, encryption keys, EC2 instance types, and storage options. </span><span class="koboSpan" id="kobo.221.2">To make the lives of data scientists easier, abstract these details away from the data scientists. </span><span class="koboSpan" id="kobo.221.3">For example, instead of having the data scientists enter specific networking configurations, have those details stored as environment variables or custom SDK options for data scientists to choose from.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.222.1">Create self-service provisioning</span></strong><span class="koboSpan" id="kobo.223.1">: To prevent provisioning bottlenecks, consider </span><a id="_idIndexMarker798"/><span class="koboSpan" id="kobo.224.1">building a self-service provisioning capability to streamline user onboarding. </span><span class="koboSpan" id="kobo.224.2">For example, use AWS Service Catalog to create an ML product for automated user onboarding.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.225.1">Use Studio notebook local mode for quick model training job testing</span></strong><span class="koboSpan" id="kobo.226.1">: SageMaker has support for local mode, meaning you can mimic running training jobs locally in your Studio notebook. </span><span class="koboSpan" id="kobo.226.2">With SageMaker Training jobs, there is an overhead of spinning up separate infrastructure. </span><span class="koboSpan" id="kobo.226.3">Running these tests locally can help speed up experimentation.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.227.1">Set up guardrails</span></strong><span class="koboSpan" id="kobo.228.1">: This helps prevent data scientists from making mistakes such as using the wrong instance types for model training or forgetting to use data encryption keys. </span><span class="koboSpan" id="kobo.228.2">You can use AWS service control policies to help with guardrail management.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.229.1">Clean up unused resources</span></strong><span class="koboSpan" id="kobo.230.1">: Regularly review and clean up unused notebooks, endpoints, and other resources to avoid unnecessary costs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.231.1">Use Spot instances</span></strong><span class="koboSpan" id="kobo.232.1">: For cost optimization, consider using Amazon EC2 Spot Instances for training jobs if possible. </span><span class="koboSpan" id="kobo.232.2">Spot instances can significantly reduce training costs while maintaining high performance. </span><span class="koboSpan" id="kobo.232.3">However, since Spot instances can be taken away unexpectedly, it is important to enable training checkpoints, so training can resume at the last checkpoint instead of restarting training from the beginning.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.233.1">Use built-in algorithms and managed containers for training</span></strong><span class="koboSpan" id="kobo.234.1">: SageMaker provides a list of built-in algorithms for different ML tasks and managed training containers for different ML frameworks. </span><span class="koboSpan" id="kobo.234.2">Taking advantage of these pre-existing resources can substantially reduce the engineering effort required, eliminating the need to build your own algorithms from scratch.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.235.1">Build automated pipelines for repeatable ML experimentation, model building, and model testing</span></strong><span class="koboSpan" id="kobo.236.1">: Having an automated pipeline can greatly reduce the manual effort and improve the tracking of different experiments. </span><span class="koboSpan" id="kobo.236.2">Consider different orchestration technology options based on your technology standards and preferences.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.237.1">By adhering to these best practices, you can make the most of SageMaker Studio’s capabilities, streamline your ML workflows, and ensure cost-effective and secure usage of the platform.</span></p>
<h1 class="heading-1" id="_idParaDest-219"><span class="koboSpan" id="kobo.238.1">Hands-on exercise – building a data science environment using AWS services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.239.1">The </span><a id="_idIndexMarker799"/><span class="koboSpan" id="kobo.240.1">primary goal of this lab is to offer practical, hands-on experience with the various SageMaker tools. </span><span class="koboSpan" id="kobo.240.2">Once you are familiar with the core functionality in this lab, you should independently explore other features such as Code Editor and RStudio.</span></p>
<h2 class="heading-2" id="_idParaDest-220"><span class="koboSpan" id="kobo.241.1">Problem statement</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.242.1">As an ML solutions architect, you have been tasked with building a data science environment on AWS for the data scientists in the equity research department. </span><span class="koboSpan" id="kobo.242.2">The data scientists in the equity research department have several NLP problems, such as detecting the sentiment of financial phrases. </span><span class="koboSpan" id="kobo.242.3">Once you have created the environment for the data scientists, you also need to build a proof of concept to show the data scientists how to build and train an NLP model using the environment.</span></p>
<h2 class="heading-2" id="_idParaDest-221"><span class="koboSpan" id="kobo.243.1">Dataset description</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.244.1">The data scientists have indicated that they like to use the BERT model to solve sentiment analysis problems, and they plan to use the financial phrases dataset to establish some initial benchmarks for the model: </span><a href="https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news"><span class="url"><span class="koboSpan" id="kobo.245.1">https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news</span></span></a><span class="koboSpan" id="kobo.246.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-222"><span class="koboSpan" id="kobo.247.1">Lab instructions</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.248.1">In this lab, you will begin by establishing a SageMaker domain and user profile to facilitate user onboarding to SageMaker Studio. </span><span class="koboSpan" id="kobo.248.2">Additionally, the lab encompasses learning to train a deep learning model through both the JupyterLab notebook directly and the SageMaker training job service.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.249.1">The final step will involve deploying the trained model utilizing the SageMaker hosting service. </span><span class="koboSpan" id="kobo.249.2">You will also explore SageMaker Canvas to learn how to train an ML model without any coding. </span><span class="koboSpan" id="kobo.249.3">After the lab, you will be able to use SageMaker as a data science tool for various experimentation, model training, and model deployment tasks. </span><span class="koboSpan" id="kobo.249.4">SageMaker has many other features.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.250.1">Let’s dive in!</span></p>
<h3 class="heading-3" id="_idParaDest-223"><span class="koboSpan" id="kobo.251.1">Setting up SageMaker Studio</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.252.1">Follow these steps</span><a id="_idIndexMarker800"/><span class="koboSpan" id="kobo.253.1"> to set up a SageMaker Studio environment:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.254.1">To create a SageMaker Studio environment, we need to set up a domain and a user profile in the respective AWS Region. </span><span class="koboSpan" id="kobo.254.2">Navigate to the SageMaker management console, once you’ve logged in to the AWS Management Console, and click on the </span><strong class="screenText"><span class="koboSpan" id="kobo.255.1">Studio</span></strong><span class="koboSpan" id="kobo.256.1"> link on the left.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.257.1">On the right-hand side of the screen, click on the </span><strong class="screenText"><span class="koboSpan" id="kobo.258.1">Create a SageMaker Domain</span></strong><span class="koboSpan" id="kobo.259.1"> button. </span><span class="koboSpan" id="kobo.259.2">Choose the </span><strong class="screenText"><span class="koboSpan" id="kobo.260.1">Setup for Single User</span></strong><span class="koboSpan" id="kobo.261.1"> option and click on </span><strong class="screenText"><span class="koboSpan" id="kobo.262.1">Set up.</span></strong><span class="koboSpan" id="kobo.263.1"> It will take a few minutes for the domain and a default user profile to be created.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.264.1">To start</span><a id="_idIndexMarker801"/><span class="koboSpan" id="kobo.265.1"> the Studio environment for the newly created user, click on the </span><strong class="keyWord"><span class="koboSpan" id="kobo.266.1">Studio</span></strong><span class="koboSpan" id="kobo.267.1"> link again, select the user profile you just created, and click on </span><strong class="screenText"><span class="koboSpan" id="kobo.268.1">Open Studio</span></strong><span class="koboSpan" id="kobo.269.1"> to launch Studio. </span><span class="koboSpan" id="kobo.269.2">It will take a few minutes for the Studio environment to appear. </span><span class="koboSpan" id="kobo.269.3">Once everything is ready, you will see a screen that is similar to the following:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.270.1"><img alt="" role="presentation" src="../Images/B20836_08_12.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.271.1">Figure 8.12: Studio UI</span></p>
<h3 class="heading-3" id="_idParaDest-224"><span class="koboSpan" id="kobo.272.1">Launching a JupyterLab notebook</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.273.1">Now, we </span><a id="_idIndexMarker802"/><span class="koboSpan" id="kobo.274.1">need to launch a JupyterLab application within the SageMaker Studio UI so we can have a Jupyter Notebook environment for authoring model-building scripts and training ML models. </span><span class="koboSpan" id="kobo.274.2">Continue with the following steps:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.275.1">Select the </span><strong class="screenText"><span class="koboSpan" id="kobo.276.1">JupterLab</span></strong><span class="koboSpan" id="kobo.277.1"> application under the </span><strong class="screenText"><span class="koboSpan" id="kobo.278.1">Applications</span></strong><span class="koboSpan" id="kobo.279.1"> section in the left navigation pane.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.280.1">Click on </span><strong class="screenText"><span class="koboSpan" id="kobo.281.1">Create JupyterLab Space</span></strong><span class="koboSpan" id="kobo.282.1"> on the right-hand side to create a space for the JupyterLab. </span><span class="koboSpan" id="kobo.282.2">Provide a name for the space on the subsequent pop-up screen and click </span><strong class="screenText"><span class="koboSpan" id="kobo.283.1">Create space</span></strong><span class="koboSpan" id="kobo.284.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.285.1">On the next screen, change the storage to </span><strong class="screenText"><span class="koboSpan" id="kobo.286.1">20 GB</span></strong><span class="koboSpan" id="kobo.287.1">, select </span><strong class="screenText"><span class="koboSpan" id="kobo.288.1">ml.g5.xLarge</span></strong><span class="koboSpan" id="kobo.289.1">, and keep all other configurations the same, and then click on </span><strong class="screenText"><span class="koboSpan" id="kobo.290.1">Run Space</span></strong><span class="koboSpan" id="kobo.291.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.292.1">It will take some time for the space to be created. </span><span class="koboSpan" id="kobo.292.2">Once it is ready, click on </span><strong class="screenText"><span class="koboSpan" id="kobo.293.1">Open JupyterLab</span></strong><span class="koboSpan" id="kobo.294.1"> to launch it, and it will be launched in a separate tab.</span></li>
</ol>
<h3 class="heading-3" id="_idParaDest-225"><span class="koboSpan" id="kobo.295.1">Training the BERT model in the Jupyter notebook</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.296.1">In this part </span><a id="_idIndexMarker803"/><span class="koboSpan" id="kobo.297.1">of the hands-on exercise, we will train a financial sentiment analysis NLP model using the BERT transformer, which</span><a id="_idIndexMarker804"/><span class="koboSpan" id="kobo.298.1"> we learned about in </span><em class="chapterRef"><span class="koboSpan" id="kobo.299.1">Chapter 3</span></em><span class="koboSpan" id="kobo.300.1">, </span><em class="italic"><span class="koboSpan" id="kobo.301.1">Exploring ML Algorithms</span></em><span class="koboSpan" id="kobo.302.1">. </span><span class="koboSpan" id="kobo.302.2">To get started, create a new notebook to author our code by selecting </span><strong class="screenText"><span class="koboSpan" id="kobo.303.1">File</span></strong><span class="koboSpan" id="kobo.304.1"> &gt; </span><strong class="screenText"><span class="koboSpan" id="kobo.305.1">New</span></strong><span class="koboSpan" id="kobo.306.1"> &gt; </span><strong class="screenText"><span class="koboSpan" id="kobo.307.1">Notebook</span></strong><span class="koboSpan" id="kobo.308.1"> from the menu dropdown. </span><span class="koboSpan" id="kobo.308.2">When prompted to select a kernel, pick </span><strong class="screenText"><span class="koboSpan" id="kobo.309.1">Python 3 (ipykernel)</span></strong><span class="koboSpan" id="kobo.310.1">. </span><span class="koboSpan" id="kobo.310.2">You can rename the file so that it has a more meaningful name by selecting </span><strong class="screenText"><span class="koboSpan" id="kobo.311.1">File</span></strong><span class="koboSpan" id="kobo.312.1"> &gt; </span><strong class="screenText"><span class="koboSpan" id="kobo.313.1">Rename Notebook</span></strong><span class="koboSpan" id="kobo.314.1"> from the menu. </span><span class="koboSpan" id="kobo.314.2">Download the dataset from Kaggle at </span><a href="https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news"><span class="url"><span class="koboSpan" id="kobo.315.1">https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news</span></span></a><span class="koboSpan" id="kobo.316.1">. </span><span class="koboSpan" id="kobo.316.2">Note that you will need a Kaggle account to download it. </span><span class="koboSpan" id="kobo.316.3">Once it’s been downloaded, you should see an </span><code class="inlineCode"><span class="koboSpan" id="kobo.317.1">archive.zip</span></code><span class="koboSpan" id="kobo.318.1"> file. </span><span class="koboSpan" id="kobo.318.2">Unzip the file using unzip tool on your local machine.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.319.1">Next, let’s upload the </span><code class="inlineCode"><span class="koboSpan" id="kobo.320.1">data</span></code><span class="koboSpan" id="kobo.321.1"> file to the Studio notebook. </span><span class="koboSpan" id="kobo.321.2">Create a new folder called </span><code class="inlineCode"><span class="koboSpan" id="kobo.322.1">data</span></code><span class="koboSpan" id="kobo.323.1"> in the same folder where the new notebook is located and upload it to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.324.1">data</span></code><span class="koboSpan" id="kobo.325.1"> directory using the </span><strong class="screenText"><span class="koboSpan" id="kobo.326.1">File Upload</span></strong><span class="koboSpan" id="kobo.327.1"> utility (the up arrow icon) in Studio UI. </span><span class="koboSpan" id="kobo.327.2">Select </span><code class="inlineCode"><span class="koboSpan" id="kobo.328.1">all-data.csv</span></code><span class="koboSpan" id="kobo.329.1"> to upload.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.330.1">Now, let’s install some additional packages for our exercise. </span><span class="koboSpan" id="kobo.330.2">Run the following code block inside the notebook cell to install the transformer package. </span><span class="koboSpan" id="kobo.330.3">The transformer package provides a list of pre-trained transformers such as BERT. </span><span class="koboSpan" id="kobo.330.4">You will use these transformers to fine-tune an ML task. </span><span class="koboSpan" id="kobo.330.5">Note that some of the code block samples are not complete. </span><span class="koboSpan" id="kobo.330.6">You can find the complete code samples at </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/bert-financial-sentiment.ipynb"><span class="url"><span class="koboSpan" id="kobo.331.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/bert-financial-sentiment.ipynb</span></span></a><span class="koboSpan" id="kobo.332.1">:</span></p>
<pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.333.1">!pip install transformers
!pip install ipywidgets
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.334.1">Restart</span><a id="_idIndexMarker805"/><span class="koboSpan" id="kobo.335.1"> the kernel of the notebook </span><a id="_idIndexMarker806"/><span class="koboSpan" id="kobo.336.1">after installing </span><code class="inlineCode"><span class="koboSpan" id="kobo.337.1">ipywidgets</span></code><span class="koboSpan" id="kobo.338.1">. </span><span class="koboSpan" id="kobo.338.2">Next, import some libraries into the notebook and set up the logger for logging purposes:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.339.1">import</span></span><span class="koboSpan" id="kobo.340.1"> logging
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.341.1">import</span></span><span class="koboSpan" id="kobo.342.1"> os
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.343.1">import</span></span><span class="koboSpan" id="kobo.344.1"> sys
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.345.1">import</span></span><span class="koboSpan" id="kobo.346.1"> numpy </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.347.1">as</span></span><span class="koboSpan" id="kobo.348.1"> np
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.349.1">import</span></span><span class="koboSpan" id="kobo.350.1"> pandas </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.351.1">as</span></span><span class="koboSpan" id="kobo.352.1"> pd
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.353.1">import</span></span><span class="koboSpan" id="kobo.354.1"> torch
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.355.1">from</span></span><span class="koboSpan" id="kobo.356.1"> torch.utils.data </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.357.1">import</span></span><span class="koboSpan" id="kobo.358.1"> DataLoader, TensorDataset
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.359.1">from</span></span><span class="koboSpan" id="kobo.360.1"> transformers </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.361.1">import</span></span><span class="koboSpan" id="kobo.362.1"> AdamW, BertForSequenceClassification, BertTokenizer
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.363.1">from</span></span><span class="koboSpan" id="kobo.364.1"> sklearn.preprocessing </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.365.1">import</span></span><span class="koboSpan" id="kobo.366.1"> OrdinalEncoder
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.367.1">from</span></span><span class="koboSpan" id="kobo.368.1"> sklearn.model_selection </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.369.1">import</span></span><span class="koboSpan" id="kobo.370.1"> train_test_split
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.371.1">from</span></span><span class="koboSpan" id="kobo.372.1"> types </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.373.1">import</span></span><span class="koboSpan" id="kobo.374.1"> SimpleNamespace
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
logger.addHandler(logging.StreamHandler(sys.stdout))
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.375.1">Now, we are ready to load the </span><code class="inlineCode"><span class="koboSpan" id="kobo.376.1">data</span></code><span class="koboSpan" id="kobo.377.1"> file and process it. </span><span class="koboSpan" id="kobo.377.2">The following code block loads the </span><code class="inlineCode"><span class="koboSpan" id="kobo.378.1">data</span></code><span class="koboSpan" id="kobo.379.1"> file and splits the data into train and test datasets. </span><span class="koboSpan" id="kobo.379.2">We will select the first two columns from the file and name them </span><code class="inlineCode"><span class="koboSpan" id="kobo.380.1">sentiment</span></code><span class="koboSpan" id="kobo.381.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.382.1">article</span></code><span class="koboSpan" id="kobo.383.1">. </span><span class="koboSpan" id="kobo.383.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.384.1">sentiment</span></code><span class="koboSpan" id="kobo.385.1"> column is the label column. </span><span class="koboSpan" id="kobo.385.2">It contains three different unique values (</span><code class="inlineCode"><span class="koboSpan" id="kobo.386.1">negative</span></code><span class="koboSpan" id="kobo.387.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.388.1">neutral</span></code><span class="koboSpan" id="kobo.389.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.390.1">positive</span></code><span class="koboSpan" id="kobo.391.1">). </span><span class="koboSpan" id="kobo.391.2">Since they are string values, we will convert them into integers (</span><code class="inlineCode"><span class="koboSpan" id="kobo.392.1">0, 1, 2</span></code><span class="koboSpan" id="kobo.393.1">) using </span><code class="inlineCode"><span class="koboSpan" id="kobo.394.1">OrdinalEncoder</span></code><span class="koboSpan" id="kobo.395.1"> from the scikit-learn library. </span><span class="koboSpan" id="kobo.395.2">We also need to determine the max length of the article column. </span><span class="koboSpan" id="kobo.395.3">The max length is used to prepare the input for the transformer since the transformer requires a fixed length:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.396.1">filepath = </span><span class="hljs-string"><span class="koboSpan" id="kobo.397.1">'./data/all-data.csv'</span></span><span class="koboSpan" id="kobo.398.1">
data = pd.read_csv(filepath, encoding=</span><span class="hljs-string"><span class="koboSpan" id="kobo.399.1">"ISO-8859-1"</span></span><span class="koboSpan" id="kobo.400.1">,
header=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.401.1">None</span></span><span class="koboSpan" id="kobo.402.1">, usecols=[</span><span class="hljs-number"><span class="koboSpan" id="kobo.403.1">0</span></span><span class="koboSpan" id="kobo.404.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.405.1">1</span></span><span class="koboSpan" id="kobo.406.1">],
names=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.407.1">"sentiment"</span></span><span class="koboSpan" id="kobo.408.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.409.1">"article"</span></span><span class="koboSpan" id="kobo.410.1">])
ord_enc = OrdinalEncoder()
data[</span><span class="hljs-string"><span class="koboSpan" id="kobo.411.1">"sentiment"</span></span><span class="koboSpan" id="kobo.412.1">] = ord_enc.fit_transform(data[[</span><span class="hljs-string"><span class="koboSpan" id="kobo.413.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.414.1">sentiment"</span></span><span class="koboSpan" id="kobo.415.1">]])
data = data.astype({</span><span class="hljs-string"><span class="koboSpan" id="kobo.416.1">'sentiment'</span></span><span class="koboSpan" id="kobo.417.1">:</span><span class="hljs-string"><span class="koboSpan" id="kobo.418.1">'int'</span></span><span class="koboSpan" id="kobo.419.1">})
train, test = train_test_split(data)
train.to_csv(</span><span class="hljs-string"><span class="koboSpan" id="kobo.420.1">"./data/train.csv"</span></span><span class="koboSpan" id="kobo.421.1">, index=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.422.1">False</span></span><span class="koboSpan" id="kobo.423.1">)
test.to_csv(</span><span class="hljs-string"><span class="koboSpan" id="kobo.424.1">"./data/test.csv"</span></span><span class="koboSpan" id="kobo.425.1">, index=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.426.1">False</span></span><span class="koboSpan" id="kobo.427.1">)
MAX_LEN = data.article.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.428.1">str</span></span><span class="koboSpan" id="kobo.429.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.430.1">len</span></span><span class="koboSpan" id="kobo.431.1">().</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.432.1">max</span></span><span class="koboSpan" id="kobo.433.1">()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.434.1"># this is the max length of the sentence</span></span>
</code></pre>
<p class="normal"><span class="koboSpan" id="kobo.435.1">Next, we </span><a id="_idIndexMarker807"/><span class="koboSpan" id="kobo.436.1">will build a list of utility functions to support the data loading and model training. </span><span class="koboSpan" id="kobo.436.2">We need to feed data to the transformer model in batches. </span><span class="koboSpan" id="kobo.436.3">The following </span><code class="inlineCode"><span class="koboSpan" id="kobo.437.1">get_data_loader()</span></code><span class="koboSpan" id="kobo.438.1"> function loads the dataset</span><a id="_idIndexMarker808"/><span class="koboSpan" id="kobo.439.1"> into the PyTorch </span><code class="inlineCode"><span class="koboSpan" id="kobo.440.1">DataLoader</span></code><span class="koboSpan" id="kobo.441.1"> class with a specified batch size. </span><span class="koboSpan" id="kobo.441.2">Note that we also encode the articles into tokens with the </span><code class="inlineCode"><span class="koboSpan" id="kobo.442.1">BertTokenizer</span></code><span class="koboSpan" id="kobo.443.1"> class:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.444.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.445.1">get_data_loader</span></span><span class="koboSpan" id="kobo.446.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.447.1">batch_size, training_dir, filename</span></span><span class="koboSpan" id="kobo.448.1">):
    logger.info(</span><span class="hljs-string"><span class="koboSpan" id="kobo.449.1">"Get data loader"</span></span><span class="koboSpan" id="kobo.450.1">)
    tokenizer = BertTokenizer.from_pretrained(</span><span class="hljs-string"><span class="koboSpan" id="kobo.451.1">"bert-base-uncased"</span></span><span class="koboSpan" id="kobo.452.1">, do_lower_case=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.453.1">True</span></span><span class="koboSpan" id="kobo.454.1">)
    dataset = pd.read_csv(os.path.join(training_dir, filename))
    articles = dataset.article.values
    sentiments = dataset.sentiment.values
    input_ids = []
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.455.1">for</span></span><span class="koboSpan" id="kobo.456.1"> sent </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.457.1">in</span></span><span class="koboSpan" id="kobo.458.1"> articles:
        encoded_articles = tokenizer.encode(sent, add_special_tokens=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.459.1">True</span></span><span class="koboSpan" id="kobo.460.1">)
        input_ids.append(encoded_articles)
...
       </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.461.1">return</span></span><span class="koboSpan" id="kobo.462.1"> tensor_dataloader
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.463.1">The following </span><code class="inlineCode"><span class="koboSpan" id="kobo.464.1">train()</span></code><span class="koboSpan" id="kobo.465.1"> function will run the training loop using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.466.1">BertForSequenceClassification</span></code><span class="koboSpan" id="kobo.467.1"> class. </span><span class="koboSpan" id="kobo.467.2">We will use the pre-trained BERT model for fine-tuning, instead of training from scratch. </span><span class="koboSpan" id="kobo.467.3">We will feed one batch of data to the BERT model at a time. </span><span class="koboSpan" id="kobo.467.4">Note that we will also check if there is a GPU device on the server. </span><span class="koboSpan" id="kobo.467.5">If there is one, we will use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.468.1">cuda</span></code><span class="koboSpan" id="kobo.469.1"> device for GPU training, instead of </span><code class="inlineCode"><span class="koboSpan" id="kobo.470.1">cpu</span></code><span class="koboSpan" id="kobo.471.1"> for CPU training. </span><span class="koboSpan" id="kobo.471.2">We need to manually move the data and BERT model to the same target device using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.472.1">.to(device)</span></code><span class="koboSpan" id="kobo.473.1"> function so that the training can happen on the target device with the data residing in memory on the same device. </span><span class="koboSpan" id="kobo.473.2">The optimizer we’re using here is AdamW, which is a variant of the gradient descent optimization algorithm. </span><span class="koboSpan" id="kobo.473.3">The training loop will run through the number of epochs specified. </span><span class="koboSpan" id="kobo.473.4">One epoch runs through the entire training dataset once:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.474.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.475.1">train</span></span><span class="koboSpan" id="kobo.476.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.477.1">args</span></span><span class="koboSpan" id="kobo.478.1">):
    use_cuda = args.num_gpus &gt; </span><span class="hljs-number"><span class="koboSpan" id="kobo.479.1">0</span></span><span class="koboSpan" id="kobo.480.1">
    device = torch.device(</span><span class="hljs-string"><span class="koboSpan" id="kobo.481.1">"cuda"</span></span> <span class="hljs-key ord"><span class="koboSpan" id="kobo.482.1">if</span></span><span class="koboSpan" id="kobo.483.1"> use_cuda </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.484.1">else</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.485.1">"cpu"</span></span><span class="koboSpan" id="kobo.486.1">)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.487.1"># set the seed for generating random numbers</span></span><span class="koboSpan" id="kobo.488.1">
    torch.manual_seed(args.seed)
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.489.1">if</span></span><span class="koboSpan" id="kobo.490.1"> use_cuda:
        torch.cuda.manual_seed(args.seed)
    train_loader = get_data_loader(args.batch_size, args.data_dir, args.train_file)
    test_loader = get_data_loader(args.test_batch_size, args.data_dir, args.test_file)
    model = BertForSequenceClassification.from_pretrained(
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.491.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.492.1">bert-base-uncased"</span></span><span class="koboSpan" id="kobo.493.1">,  
        num_labels=args.num_labels,
        output_attentions=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.494.1">False</span></span><span class="koboSpan" id="kobo.495.1">,  
        output_hidden_states=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.496.1">False</span></span><span class="koboSpan" id="kobo.497.1">,  )
</span><span class="hljs-meta"><span class="koboSpan" id="kobo.498.1">... </span></span>
<span class="hljs-key ord"><span class="koboSpan" id="kobo.499.1">return</span></span><span class="koboSpan" id="kobo.500.1"> model
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.501.1">We also </span><a id="_idIndexMarker809"/><span class="koboSpan" id="kobo.502.1">want to test the model’s performance </span><a id="_idIndexMarker810"/><span class="koboSpan" id="kobo.503.1">using a separate test dataset during training. </span><span class="koboSpan" id="kobo.503.2">To do this, we will implement the following </span><code class="inlineCode"><span class="koboSpan" id="kobo.504.1">test()</span></code><span class="koboSpan" id="kobo.505.1"> function, which is called by the </span><code class="inlineCode"><span class="koboSpan" id="kobo.506.1">train()</span></code><span class="koboSpan" id="kobo.507.1"> function:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.508.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.509.1">test</span></span><span class="koboSpan" id="kobo.510.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.511.1">model, test_loader, device</span></span><span class="koboSpan" id="kobo.512.1">):
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.513.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.514.1">get_correct_count</span></span><span class="koboSpan" id="kobo.515.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.516.1">preds, labels</span></span><span class="koboSpan" id="kobo.517.1">):
        pred_flat = np.argmax(preds, axis=</span><span class="hljs-number"><span class="koboSpan" id="kobo.518.1">1</span></span><span class="koboSpan" id="kobo.519.1">).flatten()
        labels_flat = labels.flatten()
        </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.520.1">return</span></span><span class="koboSpan" id="kobo.521.1"> np.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.522.1">sum</span></span><span class="koboSpan" id="kobo.523.1">(pred_flat == labels_flat), </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.524.1">len</span></span><span class="koboSpan" id="kobo.525.1">(labels_flat)
   
    model.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.526.1">eval</span></span><span class="koboSpan" id="kobo.527.1">()
    _, eval_accuracy = </span><span class="hljs-number"><span class="koboSpan" id="kobo.528.1">0</span></span><span class="koboSpan" id="kobo.529.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.530.1">0</span></span><span class="koboSpan" id="kobo.531.1">
    total_correct = </span><span class="hljs-number"><span class="koboSpan" id="kobo.532.1">0</span></span><span class="koboSpan" id="kobo.533.1">
    total_count = </span><span class="hljs-number"><span class="koboSpan" id="kobo.534.1">0</span></span>
<span class="hljs-meta"><span class="koboSpan" id="kobo.535.1">...</span></span><span class="koboSpan" id="kobo.536.1">
    logger.info(</span><span class="hljs-string"><span class="koboSpan" id="kobo.537.1">"Test set: Accuracy: %f\n"</span></span><span class="koboSpan" id="kobo.538.1">, total_correct/total_count)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.539.1">Now, we have all the functions needed to load and process data, run the training loop, and measure the model metrics using a test dataset. </span><span class="koboSpan" id="kobo.539.2">With that, we can kick off the training process. </span><span class="koboSpan" id="kobo.539.3">We will use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.540.1">args</span></code><span class="koboSpan" id="kobo.541.1"> variable to set up various values, such as batch size, data location, and learning rate, to be used by the training loop and the testing loop:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.542.1">args = SimpleNamespace(num_labels=</span><span class="hljs-number"><span class="koboSpan" id="kobo.543.1">3</span></span><span class="koboSpan" id="kobo.544.1">, batch_size=</span><span class="hljs-number"><span class="koboSpan" id="kobo.545.1">16</span></span><span class="koboSpan" id="kobo.546.1">, test_batch_size=</span><span class="hljs-number"><span class="koboSpan" id="kobo.547.1">10</span></span><span class="koboSpan" id="kobo.548.1">, epochs=</span><span class="hljs-number"><span class="koboSpan" id="kobo.549.1">3</span></span><span class="koboSpan" id="kobo.550.1">, lr=</span><span class="hljs-number"><span class="koboSpan" id="kobo.551.1">2e-5</span></span><span class="koboSpan" id="kobo.552.1">, seed=</span><span class="hljs-number"><span class="koboSpan" id="kobo.553.1">1</span></span><span class="koboSpan" id="kobo.554.1">,log_interval =</span><span class="hljs-number"><span class="koboSpan" id="kobo.555.1">50</span></span><span class="koboSpan" id="kobo.556.1">, model_dir = </span><span class="hljs-string"><span class="koboSpan" id="kobo.557.1">"model/"</span></span><span class="koboSpan" id="kobo.558.1">, data_dir=</span><span class="hljs-string"><span class="koboSpan" id="kobo.559.1">"data/"</span></span><span class="koboSpan" id="kobo.560.1">, num_gpus=</span><span class="hljs-number"><span class="koboSpan" id="kobo.561.1">1</span></span><span class="koboSpan" id="kobo.562.1">, train_file = </span><span class="hljs-string"><span class="koboSpan" id="kobo.563.1">"train.csv"</span></span><span class="koboSpan" id="kobo.564.1">, test_file=</span><span class="hljs-string"><span class="koboSpan" id="kobo.565.1">"test.csv"</span></span><span class="koboSpan" id="kobo.566.1">)
model = train(args)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.567.1">Once you </span><a id="_idIndexMarker811"/><span class="koboSpan" id="kobo.568.1">have run the preceding code, you should see training stats for each batch and epoch. </span><span class="koboSpan" id="kobo.568.2">The model will also be saved in the specified directory.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.569.1">Next, let’s </span><a id="_idIndexMarker812"/><span class="koboSpan" id="kobo.570.1">see how the trained model can be used to make predictions directly. </span><span class="koboSpan" id="kobo.570.2">To do this, we must implement several utility functions. </span><span class="koboSpan" id="kobo.570.3">The following </span><code class="inlineCode"><span class="koboSpan" id="kobo.571.1">input_fn()</span></code><span class="koboSpan" id="kobo.572.1"> function takes input in JSON format and outputs an input vector that represents the string input and its associated mask. </span><span class="koboSpan" id="kobo.572.2">The output will be sent to the model for prediction:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.573.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.574.1">input_fn</span></span><span class="koboSpan" id="kobo.575.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.576.1">request_body, request_content_type</span></span><span class="koboSpan" id="kobo.577.1">):
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.578.1">if</span></span><span class="koboSpan" id="kobo.579.1"> request_content_type == </span><span class="hljs-string"><span class="koboSpan" id="kobo.580.1">"application/json"</span></span><span class="koboSpan" id="kobo.581.1">:
        data = json.loads(request_body)
        </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.582.1">if</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.583.1">isinstance</span></span><span class="koboSpan" id="kobo.584.1">(data, </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.585.1">str</span></span><span class="koboSpan" id="kobo.586.1">):
            data = [data]
        </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.587.1">elif</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.588.1">isinstance</span></span><span class="koboSpan" id="kobo.589.1">(data, </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.590.1">list</span></span><span class="koboSpan" id="kobo.591.1">) </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.592.1">and</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.593.1">len</span></span><span class="koboSpan" id="kobo.594.1">(data) &gt; </span><span class="hljs-number"><span class="koboSpan" id="kobo.595.1">0</span></span> <span class="hljs-key ord"><span class="koboSpan" id="kobo.596.1">and</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.597.1">isinstance</span></span><span class="koboSpan" id="kobo.598.1">(data[</span><span class="hljs-number"><span class="koboSpan" id="kobo.599.1">0</span></span><span class="koboSpan" id="kobo.600.1">], </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.601.1">str</span></span><span class="koboSpan" id="kobo.602.1">):
            </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.603.1">pass</span></span>
<span class="hljs-key ord"><span class="koboSpan" id="kobo.604.1">else</span></span><span class="koboSpan" id="kobo.605.1">:
            </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.606.1">raise</span></span><span class="koboSpan" id="kobo.607.1"> ValueError(</span><span class="hljs-string"><span class="koboSpan" id="kobo.608.1">"Unsupported input type. </span><span class="koboSpan" id="kobo.608.2">Input type can be a string or a non-empty list. </span><span class="koboSpan" id="kobo.608.3">\</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.609.1">                             I got {}"</span></span><span class="koboSpan" id="kobo.610.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.611.1">format</span></span><span class="koboSpan" id="kobo.612.1">(data))
                       
        tokenizer = BertTokenizer.from_pretrained(</span><span class="hljs-string"><span class="koboSpan" id="kobo.613.1">"bert-base-uncased"</span></span><span class="koboSpan" id="kobo.614.1">, do_lower_case=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.615.1">True</span></span><span class="koboSpan" id="kobo.616.1">)
        
        input_ids = [tokenizer.encode(x, add_special_tokens=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.617.1">True</span></span><span class="koboSpan" id="kobo.618.1">) </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.619.1">for</span></span><span class="koboSpan" id="kobo.620.1"> x </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.621.1">in</span></span><span class="koboSpan" id="kobo.622.1"> data]
        
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.623.1"># pad shorter sentence</span></span><span class="koboSpan" id="kobo.624.1">
        padded =  torch.zeros(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.625.1">len</span></span><span class="koboSpan" id="kobo.626.1">(input_ids), MAX_LEN)
        </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.627.1">for</span></span><span class="koboSpan" id="kobo.628.1"> i, p </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.629.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.630.1">enumerate</span></span><span class="koboSpan" id="kobo.631.1">(input_ids):
            padded[i, :</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.632.1">len</span></span><span class="koboSpan" id="kobo.633.1">(p)] = torch.tensor(p)
     
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.634.1"># create mask</span></span><span class="koboSpan" id="kobo.635.1">
        mask = (padded != </span><span class="hljs-number"><span class="koboSpan" id="kobo.636.1">0</span></span><span class="koboSpan" id="kobo.637.1">)
        
        </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.638.1">return</span></span><span class="koboSpan" id="kobo.639.1"> padded.long(), mask.long()
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.640.1">raise</span></span><span class="koboSpan" id="kobo.641.1"> ValueError(</span><span class="hljs-string"><span class="koboSpan" id="kobo.642.1">"Unsupported content type: {}"</span></span><span class="koboSpan" id="kobo.643.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.644.1">format</span></span><span class="koboSpan" id="kobo.645.1">(request_content_type))
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.646.1">The </span><a id="_idIndexMarker813"/><span class="koboSpan" id="kobo.647.1">following </span><code class="inlineCode"><span class="koboSpan" id="kobo.648.1">predict_fn()</span></code><span class="koboSpan" id="kobo.649.1"> function takes </span><code class="inlineCode"><span class="koboSpan" id="kobo.650.1">input_data</span></code><span class="koboSpan" id="kobo.651.1"> returned by </span><code class="inlineCode"><span class="koboSpan" id="kobo.652.1">input_fn()</span></code><span class="koboSpan" id="kobo.653.1"> and uses the trained model to generate the prediction. </span><span class="koboSpan" id="kobo.653.2">Note that we will also use a GPU if a GPU device is available on the server:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.654.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.655.1">predict_fn</span></span><span class="koboSpan" id="kobo.656.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.657.1">input_data, model</span></span><span class="koboSpan" id="kobo.658.1">):
    device = torch.device(</span><span class="hljs-string"><span class="koboSpan" id="kobo.659.1">"cuda"</span></span> <span class="hljs-key ord"><span class="koboSpan" id="kobo.660.1">if</span></span><span class="koboSpan" id="kobo.661.1"> torch.cuda.is_available() </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.662.1">else</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.663.1">"cpu"</span></span><span class="koboSpan" id="kobo.664.1">)
    model.to(device)
    model.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.665.1">eval</span></span><span class="koboSpan" id="kobo.666.1">()
    input_id, input_mask = input_data
    input_id = input_id.to(device)
    input_mask = input_mask.to(device)
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.667.1">with</span></span><span class="koboSpan" id="kobo.668.1"> torch.no_grad():
        y = model(input_id, attention_mask=input_mask)[</span><span class="hljs-number"><span class="koboSpan" id="kobo.669.1">0</span></span><span class="koboSpan" id="kobo.670.1">]
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.671.1">return</span></span><span class="koboSpan" id="kobo.672.1"> y
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.673.1">Now, run </span><a id="_idIndexMarker814"/><span class="koboSpan" id="kobo.674.1">the following code to generate a prediction. </span><span class="koboSpan" id="kobo.674.2">Replace the value of the article with different financial text to see the result:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.675.1">import</span></span><span class="koboSpan" id="kobo.676.1"> json
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.677.1">print</span></span><span class="koboSpan" id="kobo.678.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.679.1">"sentiment label : "</span></span><span class="koboSpan" id="kobo.680.1"> + </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.681.1">str</span></span><span class="koboSpan" id="kobo.682.1">(np.argmax(preds)))
article = </span><span class="hljs-string"><span class="koboSpan" id="kobo.683.1">"Operating profit outpaced the industry average"</span></span><span class="koboSpan" id="kobo.684.1">
request_body = json.dumps(article)
enc_data, mask = input_fn(request_body, </span><span class="hljs-string"><span class="koboSpan" id="kobo.685.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.686.1">application/json'</span></span><span class="koboSpan" id="kobo.687.1">)
output = predict_fn((enc_data, mask), model)
preds = output.detach().cpu().numpy()
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.688.1">print</span></span><span class="koboSpan" id="kobo.689.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.690.1">"sentiment label : "</span></span><span class="koboSpan" id="kobo.691.1"> + </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.692.1">str</span></span><span class="koboSpan" id="kobo.693.1">(np.argmax(preds)))
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.694.1">With SageMaker, you have different options to train ML models. </span><span class="koboSpan" id="kobo.694.2">For quick experiments and light model building, the Jupyter Notebook environment is sufficient for many model training tasks. </span><span class="koboSpan" id="kobo.694.3">For more resource-demanding ML training tasks, we need to consider dedicated training resources for model training. </span><span class="koboSpan" id="kobo.694.4">In the next section, let us look at an alternative way to train the BERT model using the SageMaker training service.</span></p>
<h3 class="heading-3" id="_idParaDest-226"><span class="koboSpan" id="kobo.695.1">Training the BERT model with the SageMaker Training service</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.696.1">In the</span><a id="_idIndexMarker815"/><span class="koboSpan" id="kobo.697.1"> previous section, you trained the BERT model directly inside a GPU-based Jupyter notebook. </span><span class="koboSpan" id="kobo.697.2">Instead of provisioning a GPU-based notebook instance, you can provision a less costly CPU-based instance and send the model training task to the SageMaker Training service. </span><span class="koboSpan" id="kobo.697.3">To use the SageMaker Training service, you need to make some minor changes to the training script and create a separate launcher script to kick off the training. </span><span class="koboSpan" id="kobo.697.4">As we discussed in the </span><em class="italic"><span class="koboSpan" id="kobo.698.1">Training ML models </span></em><span class="koboSpan" id="kobo.699.1">section, there are three main approaches to training a model in SageMaker. </span><span class="koboSpan" id="kobo.699.2">Since SageMaker provides a managed container for PyTorch, we will use the managed container approach to train the model. </span><span class="koboSpan" id="kobo.699.3">With this approach, you will need to provide the following inputs:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.700.1">A training script as the entry point, as well as dependencies</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.701.1">An IAM role to be used by the training job</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.702.1">Infrastructure details such as the instance type and number</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.703.1">A data (training/validation/testing) location in S3</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.704.1">A model output location in S3</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.705.1">Hyperparameters for training the model</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.706.1">When a </span><a id="_idIndexMarker816"/><span class="koboSpan" id="kobo.707.1">training job is started, the SageMaker Training service will perform the following tasks in sequence:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.708.1">Launch the EC2 instances needed for the training job.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.709.1">Download the data from S3 to the training host.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.710.1">Download the appropriate managed container from the SageMaker ECR registry and run the container.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.711.1">Copy the training script and dependencies to the training container.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.712.1">Run the training script and pass the hyperparameters as command-line arguments to the training script. </span><span class="koboSpan" id="kobo.712.2">The training script will load the training/validation/testing data from specific directories in the container, run the training loop, and save the model to a specific directory in the container. </span><span class="koboSpan" id="kobo.712.3">Several environment variables will be set in the container to provide configuration details, such as directories for the data and model output, to the training script.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.713.1">Once the training script exits with success, the SageMaker Training service will copy the saved model artifacts from the container to the model output location in S3.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.714.1">Now, let’s create the following training script, name it </span><code class="inlineCode"><span class="koboSpan" id="kobo.715.1">train.py</span></code><span class="koboSpan" id="kobo.716.1">, and save it in a new directory called </span><code class="inlineCode"><span class="koboSpan" id="kobo.717.1">code</span></code><span class="koboSpan" id="kobo.718.1">. </span><span class="koboSpan" id="kobo.718.2">Note that the training script is almost the same as the code in the </span><em class="italic"><span class="koboSpan" id="kobo.719.1">Training the BERT model in the Jupyter notebook</span></em><span class="koboSpan" id="kobo.720.1"> section. </span><span class="koboSpan" id="kobo.720.2">We have added an </span><code class="inlineCode"><span class="koboSpan" id="kobo.721.1">if __name__ == "__main__":</span></code><span class="koboSpan" id="kobo.722.1"> section at the end. </span><span class="koboSpan" id="kobo.722.2">This section contains the code for reading the values </span><a id="_idIndexMarker817"/><span class="koboSpan" id="kobo.723.1">of the command-line arguments and the values of the system environment variables such as SageMaker’s data directory (</span><code class="inlineCode"><span class="koboSpan" id="kobo.724.1">SM_CHANNEL_TRAINING</span></code><span class="koboSpan" id="kobo.725.1">), the model output directory (</span><code class="inlineCode"><span class="koboSpan" id="kobo.726.1">SM_MODEL_DIR</span></code><span class="koboSpan" id="kobo.727.1">), and the number of GPUs (</span><code class="inlineCode"><span class="koboSpan" id="kobo.728.1">SM_NUM_GPUS</span></code><span class="koboSpan" id="kobo.729.1">) available on the host. </span><span class="koboSpan" id="kobo.729.2">The following code sample is not complete. </span><span class="koboSpan" id="kobo.729.3">You can find the complete code sample at </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/code/train.py"><span class="url"><span class="koboSpan" id="kobo.730.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/code/train.py</span></span></a><span class="koboSpan" id="kobo.731.1">:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.732.1">import</span></span><span class="koboSpan" id="kobo.733.1"> argparse
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.734.1">import</span></span><span class="koboSpan" id="kobo.735.1"> logging
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.736.1">import</span></span><span class="koboSpan" id="kobo.737.1"> os
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.738.1">import</span></span><span class="koboSpan" id="kobo.739.1"> sys
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.740.1">import</span></span><span class="koboSpan" id="kobo.741.1"> numpy </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.742.1">as</span></span><span class="koboSpan" id="kobo.743.1"> np
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.744.1">import</span></span><span class="koboSpan" id="kobo.745.1"> pandas </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.746.1">as</span></span><span class="koboSpan" id="kobo.747.1"> pd
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.748.1">import</span></span><span class="koboSpan" id="kobo.749.1"> torch
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.750.1">from</span></span><span class="koboSpan" id="kobo.751.1"> torch.utils.data </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.752.1">import</span></span><span class="koboSpan" id="kobo.753.1"> DataLoader, TensorDataset
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.754.1">from</span></span><span class="koboSpan" id="kobo.755.1"> transformers </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.756.1">import</span></span><span class="koboSpan" id="kobo.757.1"> AdamW, BertForSequenceClassification, BertTokenizer
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
logger.addHandler(logging.StreamHandler(sys.stdout))
...
    </span><span class="koboSpan" id="kobo.757.2">train(parser.parse_args())
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.758.1">The </span><a id="_idIndexMarker818"/><span class="koboSpan" id="kobo.759.1">preceding script requires library packages that are not available in the managed training container. </span><span class="koboSpan" id="kobo.759.2">You can install custom library packages using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.760.1">requirement.txt</span></code><span class="koboSpan" id="kobo.761.1"> file. </span><span class="koboSpan" id="kobo.761.2">Create a </span><code class="inlineCode"><span class="koboSpan" id="kobo.762.1">requirement.txt</span></code><span class="koboSpan" id="kobo.763.1"> file with the following code and save it in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.764.1">code</span></code><span class="koboSpan" id="kobo.765.1"> directory:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.766.1">transformers==</span><span class="hljs-number"><span class="koboSpan" id="kobo.767.1">2.3.0</span></span>
</code></pre>
<p class="normal"><span class="koboSpan" id="kobo.768.1">Next, let’s create a launcher notebook for kicking off the training job using the SageMaker Training service. </span><span class="koboSpan" id="kobo.768.2">The launcher notebook will do the following:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.769.1">Upload the training and test datasets to the S3 bucket and folders.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.770.1">Set up the SageMaker PyTorch estimator using the SageMaker SDK to configure the training job.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.771.1">Kick off the SageMaker training job.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.772.1">Create a new notebook called </span><code class="inlineCode"><span class="koboSpan" id="kobo.773.1">bert-financial-sentiment-launcher.ipynb</span></code><span class="koboSpan" id="kobo.774.1"> in the folder where the </span><code class="inlineCode"><span class="koboSpan" id="kobo.775.1">code</span></code><span class="koboSpan" id="kobo.776.1"> folder is located and copy the following code block into the notebook one cell at a time. </span><span class="koboSpan" id="kobo.776.2">When you’re prompted to choose a kernel, pick the </span><strong class="screenText"><span class="koboSpan" id="kobo.777.1">Python 3 (ipykernel)</span></strong><span class="koboSpan" id="kobo.778.1"> kernel.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.779.1">The</span><a id="_idIndexMarker819"/><span class="koboSpan" id="kobo.780.1"> following code specifies the S3 bucket to be used for saving the training and testing dataset, as well as the model artifacts. </span><span class="koboSpan" id="kobo.780.2">You can use the bucket that was created earlier in the </span><em class="italic"><span class="koboSpan" id="kobo.781.1">Setting up SageMaker Studio</span></em><span class="koboSpan" id="kobo.782.1"> section, when the Studio domain was configured. </span><span class="koboSpan" id="kobo.782.2">The training and test datasets we created earlier will be uploaded to the bucket. </span><span class="koboSpan" id="kobo.782.3">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.783.1">get_execution_role()</span></code><span class="koboSpan" id="kobo.784.1"> function returns the IAM role associated with the notebook, which we will use to run the training job later:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.785.1">import</span></span><span class="koboSpan" id="kobo.786.1"> os
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.787.1">import</span></span><span class="koboSpan" id="kobo.788.1"> numpy </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.789.1">as</span></span><span class="koboSpan" id="kobo.790.1"> np
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.791.1">import</span></span><span class="koboSpan" id="kobo.792.1"> pandas </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.793.1">as</span></span><span class="koboSpan" id="kobo.794.1"> pd
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.795.1">import</span></span><span class="koboSpan" id="kobo.796.1"> sagemaker
sagemaker_session = sagemaker.Session()
bucket = &lt;bucket name&gt;
prefix = </span><span class="hljs-string"><span class="koboSpan" id="kobo.797.1">"sagemaker/pytorch-bert-financetext"</span></span><span class="koboSpan" id="kobo.798.1">
role = sagemaker.get_execution_role()
inputs_train = sagemaker_session.upload_data(</span><span class="hljs-string"><span class="koboSpan" id="kobo.799.1">"./data/train.csv"</span></span><span class="koboSpan" id="kobo.800.1">, bucket=bucket, key_prefix=prefix)
inputs_test = sagemaker_session.upload_data(</span><span class="hljs-string"><span class="koboSpan" id="kobo.801.1">"./data/test.csv"</span></span><span class="koboSpan" id="kobo.802.1">, bucket=bucket, key_prefix=prefix)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.803.1">Finally, we </span><a id="_idIndexMarker820"/><span class="koboSpan" id="kobo.804.1">must set up the SageMaker PyTorch estimator and kick off the training job. </span><span class="koboSpan" id="kobo.804.2">Note that you can also specify the PyTorch framework version and Python version to set up the container. </span><span class="koboSpan" id="kobo.804.3">For simplicity, we are passing the name of the training file and test file, as well as the max length, as hyperparameters. </span><span class="koboSpan" id="kobo.804.4">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.805.1">train.py</span></code><span class="koboSpan" id="kobo.806.1"> file can also be modified to look them up dynamically:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.807.1">from</span></span><span class="koboSpan" id="kobo.808.1"> sagemaker.pytorch </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.809.1">import</span></span><span class="koboSpan" id="kobo.810.1"> PyTorch
output_path = </span><span class="hljs-string"><span class="koboSpan" id="kobo.811.1">f"s3://</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.812.1">{bucket}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.813.1">/</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.814.1">{prefix}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.815.1">"</span></span><span class="koboSpan" id="kobo.816.1">
estimator = PyTorch(
    entry_point=</span><span class="hljs-string"><span class="koboSpan" id="kobo.817.1">"train.py"</span></span><span class="koboSpan" id="kobo.818.1">,
    source_dir=</span><span class="hljs-string"><span class="koboSpan" id="kobo.819.1">"code"</span></span><span class="koboSpan" id="kobo.820.1">,
    role=role,
    framework_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.821.1">"1.6"</span></span><span class="koboSpan" id="kobo.822.1">,
    py_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.823.1">"py3"</span></span><span class="koboSpan" id="kobo.824.1">,
    instance_count=</span><span class="hljs-number"><span class="koboSpan" id="kobo.825.1">1</span></span><span class="koboSpan" id="kobo.826.1">,  
    instance_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.827.1">"ml.p3.2xlarge"</span></span><span class="koboSpan" id="kobo.828.1">,
    output_path=output_path,
    hyperparameters={
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.829.1">"epochs"</span></span><span class="koboSpan" id="kobo.830.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.831.1">4</span></span><span class="koboSpan" id="kobo.832.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.833.1">"lr"</span></span><span class="koboSpan" id="kobo.834.1"> : </span><span class="hljs-number"><span class="koboSpan" id="kobo.835.1">5e-5</span></span><span class="koboSpan" id="kobo.836.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.837.1">"num_labels"</span></span><span class="koboSpan" id="kobo.838.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.839.1">3</span></span><span class="koboSpan" id="kobo.840.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.841.1">"train_file"</span></span><span class="koboSpan" id="kobo.842.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.843.1">"train.csv"</span></span><span class="koboSpan" id="kobo.844.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.845.1">"test_file"</span></span><span class="koboSpan" id="kobo.846.1"> : </span><span class="hljs-string"><span class="koboSpan" id="kobo.847.1">"test.csv"</span></span><span class="koboSpan" id="kobo.848.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.849.1">"MAX_LEN"</span></span><span class="koboSpan" id="kobo.850.1"> : </span><span class="hljs-number"><span class="koboSpan" id="kobo.851.1">315</span></span><span class="koboSpan" id="kobo.852.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.853.1">"batch-size"</span></span><span class="koboSpan" id="kobo.854.1"> : </span><span class="hljs-number"><span class="koboSpan" id="kobo.855.1">16</span></span><span class="koboSpan" id="kobo.856.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.857.1">"test-batch-size"</span></span><span class="koboSpan" id="kobo.858.1"> : </span><span class="hljs-number"><span class="koboSpan" id="kobo.859.1">10</span></span><span class="koboSpan" id="kobo.860.1">
    }
)
estimator.fit({</span><span class="hljs-string"><span class="koboSpan" id="kobo.861.1">"training"</span></span><span class="koboSpan" id="kobo.862.1">: inputs_train, </span><span class="hljs-string"><span class="koboSpan" id="kobo.863.1">"testing"</span></span><span class="koboSpan" id="kobo.864.1">: inputs_test})
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.865.1">Once the </span><a id="_idIndexMarker821"/><span class="koboSpan" id="kobo.866.1">training job has been </span><a id="_idIndexMarker822"/><span class="koboSpan" id="kobo.867.1">completed, you can go to the SageMaker management console to access the training job’s details and metadata. </span><span class="koboSpan" id="kobo.867.2">Training jobs also send outputs to CloudWatch Logs and CloudWatch metrics. </span><span class="koboSpan" id="kobo.867.3">You can navigate to these logs by clicking on the respective links on the training job details page.</span></p>
<h3 class="heading-3" id="_idParaDest-227"><span class="koboSpan" id="kobo.868.1">Deploying the model</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.869.1">In this step, we</span><a id="_idIndexMarker823"/><span class="koboSpan" id="kobo.870.1"> will deploy the trained model to a SageMaker RESTful endpoint so that it can be integrated with downstream applications. </span><span class="koboSpan" id="kobo.870.2">We will use the managed PyTorch serving container to host the model. </span><span class="koboSpan" id="kobo.870.3">With the managed PyTorch serving container, you can provide an inference script to process the request data before it is sent to the model for inference, as well as controlling how to call the model for inference. </span><span class="koboSpan" id="kobo.870.4">Let’s create a new script called </span><code class="inlineCode"><span class="koboSpan" id="kobo.871.1">inference.py</span></code><span class="koboSpan" id="kobo.872.1"> in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.873.1">code</span></code><span class="koboSpan" id="kobo.874.1"> folder that contains the following code block. </span><span class="koboSpan" id="kobo.874.2">As you have probably noticed, we have used the same functions that we used in </span><em class="italic"><span class="koboSpan" id="kobo.875.1">Training the BERT model in the Jupyter notebook</span></em><span class="koboSpan" id="kobo.876.1"> section for the predictions. </span><span class="koboSpan" id="kobo.876.2">Note that you need to use the same function signatures for these two functions as SageMaker will be looking for the exact function name and parameter lists. </span><span class="koboSpan" id="kobo.876.3">You can find the complete source code at </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/code/inference.py"><span class="url"><span class="koboSpan" id="kobo.877.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/code/inference.py</span></span></a><span class="koboSpan" id="kobo.878.1">:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.879.1">import</span></span><span class="koboSpan" id="kobo.880.1"> logging
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.881.1">import</span></span><span class="koboSpan" id="kobo.882.1"> os
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.883.1">import</span></span><span class="koboSpan" id="kobo.884.1"> sys
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.885.1">import</span></span><span class="koboSpan" id="kobo.886.1"> json
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.887.1">import</span></span><span class="koboSpan" id="kobo.888.1"> numpy </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.889.1">as</span></span><span class="koboSpan" id="kobo.890.1"> np
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.891.1">import</span></span><span class="koboSpan" id="kobo.892.1"> pandas </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.893.1">as</span></span><span class="koboSpan" id="kobo.894.1"> pd
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.895.1">import</span></span><span class="koboSpan" id="kobo.896.1"> torch
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.897.1">from</span></span><span class="koboSpan" id="kobo.898.1"> torch.utils.data </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.899.1">import</span></span><span class="koboSpan" id="kobo.900.1"> DataLoader, TensorDataset
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.901.1">from</span></span><span class="koboSpan" id="kobo.902.1"> transformers </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.903.1">import</span></span><span class="koboSpan" id="kobo.904.1"> BertForSequenceClassification, BertTokenizer
</span><span class="hljs-meta"><span class="koboSpan" id="kobo.905.1">... </span></span>
<span class="hljs-key ord"><span class="koboSpan" id="kobo.906.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.907.1">model_fn</span></span><span class="koboSpan" id="kobo.908.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.909.1">model_dir</span></span><span class="koboSpan" id="kobo.910.1">):
    ...
    </span><span class="koboSpan" id="kobo.910.2">loaded_model = BertForSequenceClassification.from_pretrained(model_dir)
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.911.1">return</span></span><span class="koboSpan" id="kobo.912.1"> loaded_model.to(device)
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.913.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.914.1">input_fn</span></span><span class="koboSpan" id="kobo.915.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.916.1">request_body, request_content_type</span></span><span class="koboSpan" id="kobo.917.1">):
    ...
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.918.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.919.1">predict_fn</span></span><span class="koboSpan" id="kobo.920.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.921.1">input_data, model</span></span><span class="koboSpan" id="kobo.922.1">):
    device = torch.device(</span><span class="hljs-string"><span class="koboSpan" id="kobo.923.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.924.1">cuda"</span></span> <span class="hljs-key ord"><span class="koboSpan" id="kobo.925.1">if</span></span><span class="koboSpan" id="kobo.926.1"> torch.cuda.is_available() </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.927.1">else</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.928.1">"cpu"</span></span><span class="koboSpan" id="kobo.929.1">)
    model.to(device)
    model.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.930.1">eval</span></span><span class="koboSpan" id="kobo.931.1">()
    ...
    </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.932.1">return</span></span><span class="koboSpan" id="kobo.933.1"> y
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.934.1">Next, we</span><a id="_idIndexMarker824"/><span class="koboSpan" id="kobo.935.1"> need to modify the </span><code class="inlineCode"><span class="koboSpan" id="kobo.936.1">bert-financial-sentiment-launcher.ipynb</span></code><span class="koboSpan" id="kobo.937.1"> file to create the endpoint. </span><span class="koboSpan" id="kobo.937.2">You can deploy </span><a id="_idIndexMarker825"/><span class="koboSpan" id="kobo.938.1">trained models from the SageMaker </span><code class="inlineCode"><span class="koboSpan" id="kobo.939.1">estimator</span></code><span class="koboSpan" id="kobo.940.1"> class directly. </span><span class="koboSpan" id="kobo.940.2">Here, however, we want to show you how to deploy a model that’s been trained previously, as this is the most likely deployment scenario:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.941.1">from</span></span><span class="koboSpan" id="kobo.942.1"> sagemaker.pytorch.model </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.943.1">import</span></span><span class="koboSpan" id="kobo.944.1"> PyTorchModel
model_data = estimator.model_data
pytorch_model = PyTorchModel(model_data=model_data,
                             role=role,
                             framework_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.945.1">"1.6"</span></span><span class="koboSpan" id="kobo.946.1">,
                             source_dir=</span><span class="hljs-string"><span class="koboSpan" id="kobo.947.1">"code"</span></span><span class="koboSpan" id="kobo.948.1">,
                             py_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.949.1">"py3"</span></span><span class="koboSpan" id="kobo.950.1">,
                             entry_point=</span><span class="hljs-string"><span class="koboSpan" id="kobo.951.1">"inference.py"</span></span><span class="koboSpan" id="kobo.952.1">)
predictor = pytorch_model.deploy(initial_instance_count=</span><span class="hljs-number"><span class="koboSpan" id="kobo.953.1">1</span></span><span class="koboSpan" id="kobo.954.1">, instance_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.955.1">"ml.m4.xlarge"</span></span><span class="koboSpan" id="kobo.956.1">)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.957.1">After the model has been deployed, we can call the model endpoint to generate some predictions:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.958.1">predictor.serializer = sagemaker.serializers.JSONSerializer()
predictor.deserializer = sagemaker.deserializers.JSONDeserializer()
result = predictor.predict(</span><span class="hljs-string"><span class="koboSpan" id="kobo.959.1">"The market is doing better than last year"</span></span><span class="koboSpan" id="kobo.960.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.961.1">print</span></span><span class="koboSpan" id="kobo.962.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.963.1">"predicted class: "</span></span><span class="koboSpan" id="kobo.964.1">, np.argmax(result, axis=</span><span class="hljs-number"><span class="koboSpan" id="kobo.965.1">1</span></span><span class="koboSpan" id="kobo.966.1">))
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.967.1">Try out</span><a id="_idIndexMarker826"/><span class="koboSpan" id="kobo.968.1"> different phrases and see if the model predicts the sentiment correctly. </span><span class="koboSpan" id="kobo.968.2">You can also access the endpoint’s details by navigating to the SageMaker management console and clicking on the endpoint.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.969.1">To avoid any ongoing costs for the endpoint, let’s delete it. </span><span class="koboSpan" id="kobo.969.2">Run the following command in a new cell to delete the endpoint:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.970.1">predictor.delete_endpoint()
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.971.1">Congratulations – you have finished building a basic data science environment and used it to train and deploy an NLP model to detect its sentiment! </span><span class="koboSpan" id="kobo.971.2">If you don’t want to keep this environment </span><a id="_idIndexMarker827"/><span class="koboSpan" id="kobo.972.1">to avoid any associated costs, make sure that you shut down any instances of the SageMaker Studio notebooks.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.973.1">Next, let’s explore SageMaker Canvas and see how to use it to build custom ML models without any coding.</span></p>
<h3 class="heading-3" id="_idParaDest-228"><span class="koboSpan" id="kobo.974.1">Building ML models with SageMaker Canvas</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.975.1">In this lab, we </span><a id="_idIndexMarker828"/><span class="koboSpan" id="kobo.976.1">will train a customer churn classification model using Canvas’s custom model feature. </span><span class="koboSpan" id="kobo.976.2">We will go through the full cycle from dataset creation/selection, model training, and model analysis to prediction generation and model deployment.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.977.1">To get started, we first need to launch a SageMaker Canvas environment. </span><span class="koboSpan" id="kobo.977.2">To do that, go back to your Studio environment, select </span><strong class="screenText"><span class="koboSpan" id="kobo.978.1">Canvas</span></strong><span class="koboSpan" id="kobo.979.1"> under the </span><strong class="screenText"><span class="koboSpan" id="kobo.980.1">Applications</span></strong><span class="koboSpan" id="kobo.981.1"> section, and click on the </span><strong class="screenText"><span class="koboSpan" id="kobo.982.1">Run Canvas</span></strong><span class="koboSpan" id="kobo.983.1"> button in the right-hand pane. </span><span class="koboSpan" id="kobo.983.2">It is going to take 8-10 minutes for the Canvas environment to become available. </span><span class="koboSpan" id="kobo.983.3">When the Canvas status changes to </span><strong class="screenText"><span class="koboSpan" id="kobo.984.1">Running</span></strong><span class="koboSpan" id="kobo.985.1">, click on </span><strong class="screenText"><span class="koboSpan" id="kobo.986.1">Open Canvas</span></strong><span class="koboSpan" id="kobo.987.1">, and you will see a screen similar to </span><em class="italic"><span class="koboSpan" id="kobo.988.1">Figure 8.13</span></em><span class="koboSpan" id="kobo.989.1">.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.990.1"><img alt="" role="presentation" src="../Images/B20836_08_13.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.991.1">Figure 8.13: SageMaker Canvas</span></p>
<p class="normal"><span class="koboSpan" id="kobo.992.1">The </span><a id="_idIndexMarker829"/><span class="koboSpan" id="kobo.993.1">following steps will guide you through the rest of the lab:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.994.1">Select the </span><strong class="screenText"><span class="koboSpan" id="kobo.995.1">My models</span></strong><span class="koboSpan" id="kobo.996.1"> icon on the left-hand pane to start building a custom model using a custom dataset. </span><span class="koboSpan" id="kobo.996.2">You should see a screen similar to </span><em class="italic"><span class="koboSpan" id="kobo.997.1">Figure 8.14</span></em><span class="koboSpan" id="kobo.998.1">:
    </span><figure class="mediaobject"><span class="koboSpan" id="kobo.999.1"><img alt="" role="presentation" src="../Images/B20836_08_14.png"/></span> </figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1000.1">Figure 8.14: Canvas My models screen</span></p></li>
</ol>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="2"><span class="koboSpan" id="kobo.1001.1">Click </span><a id="_idIndexMarker830"/><span class="koboSpan" id="kobo.1002.1">on the </span><strong class="screenText"><span class="koboSpan" id="kobo.1003.1">New model</span></strong><span class="koboSpan" id="kobo.1004.1"> button,</span><strong class="screenText"> </strong><span class="koboSpan" id="kobo.1005.1">provide a name for the model, select </span><strong class="screenText"><span class="koboSpan" id="kobo.1006.1">Predictive analysis</span></strong><span class="koboSpan" id="kobo.1007.1"> as the problem type, and click on </span><strong class="screenText"><span class="koboSpan" id="kobo.1008.1">Create</span></strong><span class="koboSpan" id="kobo.1009.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1010.1">Download the dataset from </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/churn.csv"><span class="url"><span class="koboSpan" id="kobo.1011.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter08/churn.csv</span></span></a><span class="koboSpan" id="kobo.1012.1"> and save it to your local machine.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1013.1">On </span><a id="_idIndexMarker831"/><span class="koboSpan" id="kobo.1014.1">the </span><strong class="screenText"><span class="koboSpan" id="kobo.1015.1">Select dataset </span></strong><span class="koboSpan" id="kobo.1016.1">screen, click on the </span><strong class="screenText"><span class="koboSpan" id="kobo.1017.1">Create data</span></strong><span class="koboSpan" id="kobo.1018.1"> link in the top-right corner. </span><span class="koboSpan" id="kobo.1018.2">Provide a name for the dataset.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1019.1">On the next screen, click on </span><strong class="screenText"><span class="koboSpan" id="kobo.1020.1">Select files from your local computer</span></strong><span class="koboSpan" id="kobo.1021.1"> and navigate to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1022.1">churn.csv</span></code><span class="koboSpan" id="kobo.1023.1"> file you downloaded in </span><em class="italic"><span class="koboSpan" id="kobo.1024.1">step 4</span></em><span class="koboSpan" id="kobo.1025.1"> to upload the file. </span><span class="koboSpan" id="kobo.1025.2">After the file is uploaded, click on </span><strong class="screenText"><span class="koboSpan" id="kobo.1026.1">Create dataset</span></strong><span class="koboSpan" id="kobo.1027.1"> to continue.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1028.1">On the next screen, check the dataset you have just created, and click on </span><strong class="screenText"><span class="koboSpan" id="kobo.1029.1">Select datase</span></strong><span class="koboSpan" id="kobo.1030.1">t to continue.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1031.1">On the next screen, you will be asked to select a target column to predict. </span><span class="koboSpan" id="kobo.1031.2">Select the </span><strong class="screenText"><span class="koboSpan" id="kobo.1032.1">Exited</span></strong><span class="koboSpan" id="kobo.1033.1"> column from the dataset. </span><span class="koboSpan" id="kobo.1033.2">Also, you should uncheck some of the source columns, such as surname and row number, as they are not relevant to model training. </span><span class="koboSpan" id="kobo.1033.3">Finally, select </span><strong class="screenText"><span class="koboSpan" id="kobo.1034.1">Quick build</span></strong><span class="koboSpan" id="kobo.1035.1"> to build a model.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1036.1">On the next screen, you will see some information about the duration of the build and the build type. </span><span class="koboSpan" id="kobo.1036.2">Now you will need to wait for the build process to complete. </span><span class="koboSpan" id="kobo.1036.3">When it is complete, you will see a screen similar to the following figure. </span><span class="koboSpan" id="kobo.1036.4">You </span><a id="_idIndexMarker832"/><span class="koboSpan" id="kobo.1037.1">will be able to review the various training metrics, such as accuracy, precision, and recall. </span><span class="koboSpan" id="kobo.1037.2">You will also be able to see the impact of different source columns on the target columns.
    </span><figure class="mediaobject"><span class="koboSpan" id="kobo.1038.1"><img alt="" role="presentation" src="../Images/B20836_08_15.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1039.1">Figure 8.15: Model training results</span></p></li>
</ol>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="9"><span class="koboSpan" id="kobo.1040.1">Since model performance optimization is not our primary goal here, we will click on </span><strong class="screenText"><span class="koboSpan" id="kobo.1041.1">Predict</span></strong><span class="koboSpan" id="kobo.1042.1"> to generate some predictions on the next screen.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1043.1">On the next screen, select the </span><strong class="screenText"><span class="koboSpan" id="kobo.1044.1">Single prediction</span></strong><span class="koboSpan" id="kobo.1045.1"> option, and change the values for some of the fields, such as age, salary, and credit score, to see how they impact the results by clicking on </span><strong class="screenText"><span class="koboSpan" id="kobo.1046.1">Update</span></strong><span class="koboSpan" id="kobo.1047.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1048.1">Lastly, we </span><a id="_idIndexMarker833"/><span class="koboSpan" id="kobo.1049.1">will deploy the model to an endpoint so it can be used by other applications. </span><span class="koboSpan" id="kobo.1049.2">To deploy, you simply click on the </span><strong class="screenText"><span class="koboSpan" id="kobo.1050.1">Deploy</span></strong><span class="koboSpan" id="kobo.1051.1"> button to deploy the model. </span><span class="koboSpan" id="kobo.1051.2">You will have the option to select an instance type and the number of instances for the model. </span><span class="koboSpan" id="kobo.1051.3">Upon successful deployment, a deployment URL will be made available for other applications to use.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1052.1">Congratulations on completing the lab! </span><span class="koboSpan" id="kobo.1052.2">You have effectively trained and deployed a binary classification model using your custom dataset without any code, using SageMaker Canvas. </span><span class="koboSpan" id="kobo.1052.3">This no-code ML tool facilitates a swift initiation into ML projects, even for individuals without prior ML knowledge. </span><span class="koboSpan" id="kobo.1052.4">You now have first-hand experience with how Canvas automates numerous tasks for you, ranging from algorithm selection and model training to model deployment.</span></p>
<h1 class="heading-1" id="_idParaDest-229"><span class="koboSpan" id="kobo.1053.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1054.1">In this chapter, we explored how a data science environment can provide a scalable infrastructure for experimentation, model training, and model deployment for testing purposes. </span><span class="koboSpan" id="kobo.1054.2">You learned about the core architecture components for building a fully managed data science environment using AWS services such as Amazon SageMaker, Amazon ECR, and Amazon S3. </span><span class="koboSpan" id="kobo.1054.3">You practiced setting up a data science environment and trained and deployed an NLP model using both SageMaker Studio notebooks and the SageMaker Training service. </span><span class="koboSpan" id="kobo.1054.4">You have also developed hands-on experience with SageMaker Canvas to automate ML tasks from model building to model deployment.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1055.1">At this point, you should be able to talk about the key components of a data science environment, as well as how to build one using AWS services and use it for model building, training, and deployment. </span><span class="koboSpan" id="kobo.1055.2">In the next chapter, we will talk about how to build an enterprise ML platform for scale through automation.</span></p>
<h1 class="heading-1"><span class="koboSpan" id="kobo.1056.1">Join our community on Discord</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1057.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
<p class="normal"><a href="https://packt.link/mlsah "><span class="url"><span class="koboSpan" id="kobo.1058.1">https://packt.link/mlsah</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.1059.1"><img alt="" role="presentation" src="../Images/QR_Code70205728346636561.png"/></span></p>
</div>
</body></html>