- en: Chapter 12. Processing Video Sequences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Reading video sequences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing the video frames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing video sequences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting the foreground objects in a video
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Video signals constitute a rich source of visual information. They are made
    of a sequence of images, called **frames**, that are taken at regular time intervals
    (specified as the **frame rate**, generally expressed in frames per second) and
    show a scene in motion. With the advent of powerful computers, it is now possible
    to perform advanced visual analysis on video sequences-sometimes at rates close
    to, or even faster than, the actual video frame rate. This chapter will show you
    how to read, process, and store video sequences.
  prefs: []
  type: TYPE_NORMAL
- en: We will see that once the individual frames of a video sequence have been extracted,
    the different image processing functions presented in this book can be applied
    to each of them. In addition, we will also look at algorithms that perform a temporal
    analysis of the video sequence, comparing adjacent frames and accumulating image
    statistics over time in order to extract foreground objects.
  prefs: []
  type: TYPE_NORMAL
- en: Reading video sequences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to process a video sequence, we need to be able to read each of its
    frames. OpenCV has put in place an easy-to-use framework that can help us perform
    frame extraction from video files or even from USB or IP cameras. This recipe
    shows you how to use it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Basically, all you need to do in order to read the frames of a video sequence
    is create an instance of the `cv::VideoCapture` class. You then create a loop
    that will extract and read each video frame. Here is a basic main function that
    displays the frames of a video sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'A window will appear on which the video will play as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_12_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To open a video, you simply need to specify the video filename. This can be
    done by providing the name of the file in the constructor of the `cv::VideoCapture`
    object. It is also possible to use the `open` method if the `cv::VideoCapture`
    object has already been created. Once the video is successfully opened (this can
    be verified through the `isOpened` method), it is possible to start frame extraction.
    It is also possible to query the `cv::VideoCapture` object for information associated
    with the video file by using its `get` method with the appropriate flag. In the
    preceding example, we obtained the frame rate using the `CV_CAP_PROP_FPS` flag.
    Since it is a generic function, it always returns a double even if another type
    would be expected in some cases. For example, the total number of frames in the
    video file would be obtained (as an integer) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Have a look at the different flags that are available in the OpenCV documentation
    in order to find out what information can be obtained from the video.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is also a `set` method that allows you to input parameters into the `cv::VideoCapture`
    instance. For example, you can request to move to a specific frame using the `CV_CAP_PROP_POS_FRAMES`
    flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can also specify the position in milliseconds using `CV_CAP_PROP_POS_MSEC`,
    or you can specify the relative position inside the video using `CV_CAP_PROP_POS_AVI_RATIO`
    (with `0.0` corresponding to the beginning of the video and `1.0` to the end).
    The method returns `true` if the requested parameter setting is successful. Note
    that the possibility to get or set a particular video parameter largely depends
    on the codec that is used to compress and store the video sequence. If you are
    unsuccessful with some parameters, that could be simply due to the specific codec
    you are using.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the captured video is successfully opened, the frames can be sequentially
    obtained by repetitively calling the `read` method, as we did in the example of
    the previous section. One can equivalently call the overloaded reading operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to call the two basic methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Also note how, in our example, we introduced a delay in displaying each frame.
    This is done using the `cv::waitKey` function. Here, we set the delay at a value
    that corresponds to the input video frame rate (if `fps` is the number of frames
    per second, then `1/fps` is the delay between two frames in milliseconds). You
    can obviously change this value to display the video at a slower or faster speed.
    However, if you are going to display the video frames, it is important that you
    insert such a delay if you want to make sure that the window has sufficient time
    to refresh (since it is a process of low priority, it will never refresh if the
    CPU is too busy). The `cv::waitKey` function also allows us to interrupt the reading
    process by pressing any key. In this case, the function returns the ASCII code
    of the key that is pressed. Note that, if the delay specified to the `cv::waitKey`
    function is `0`, then it will wait indefinitely for the user to press a key. This
    is very useful if someone wants to trace a process by examining the results frame
    by frame.
  prefs: []
  type: TYPE_NORMAL
- en: The final statement calls the `release` method, which will close the video file.
    However, this call is not required since `release` is also called by the `cv::VideoCapture`
    destructor.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that in order to open the specified video file, your
    computer must have the corresponding codec installed; otherwise, `cv::VideoCapture`
    will not be able to decode the input file. Normally, if you are able to open your
    video file with a video player on your machine (such as Windows Media Player),
    then OpenCV should also be able to read this file.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also read the video stream produced by a camera that is connected to
    your computer (a USB camera, for example). In this case, you simply specify an
    ID number (an integer) instead of a filename to the `open` function. Specifying
    `0` for the ID will open the default installed camera. In this case, the role
    of the `cv::waitKey` function that stops the processing becomes essential, since
    the video stream from the camera will be infinitely read.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it is also possible to load a video from the Web. In this case, all
    you have to do is provide the correct address, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Writing video sequences* recipe in this chapter has more information on
    video codecs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [http://ffmpeg.org/](http://ffmpeg.org/) website presents a complete open
    source and cross-platform solution for audio/video reading, recording, converting,
    and streaming. The OpenCV classes that manipulate video files are built on top
    of this library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing the video frames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, our objective is to apply some processing functions to each
    of the frames of a video sequence. We will do this by encapsulating the OpenCV
    video capture framework into our own class. Among other things, this class will
    allow us to specify a function that will be called each time a new frame is extracted.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What we want is to be able to specify a processing function (a **callback function**)
    that will be called for each frame of a video sequence. This function can be defined
    as receiving a `cv::Mat` instance and outputting a processed frame. Therefore,
    in our framework, the processing function must have the following signature to
    be a valid callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As an example of such a processing function, consider the following simple
    function that computes the Canny edges of an input image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `VideoProcessor` class encapsulates all aspects of a video-processing task.
    Using this class, the procedure will be to create a class instance, specify an
    input video file, attach the callback function to it, and then start the process.
    Programmatically, these steps are accomplished using our proposed class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If this code is run, then two windows will play the input video and the output
    result at the original frame rate (a consequence of the delay introduced by the
    `setDelay` method). For example, considering the input video for which a frame
    is shown in the previous recipe, the output window will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_12_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we did in other recipes, our objective was to create a class that encapsulates
    the common functionalities of a video-processing algorithm. As one might expect,
    the class includes several member variables that control the different aspects
    of the video frame processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The first member variable is the `cv::VideoCapture` object. The second attribute
    is the `process` function pointer that will point to the callback function. This
    function can be specified using the corresponding setter method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following method opens the video file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'It is generally interesting to display the frames as they are processed. Therefore,
    two methods are used to create the display windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The main method, called `run`, is the one that contains the frame extraction
    loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This method uses a `private` method that reads the frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `run` method proceeds by first calling the read method of the `cv::VideoCapture`
    class. There is then a series of operations that are executed, but before each
    of them is invoked, a check is made to determine whether it has been requested.
    The input window is displayed only if an input window name has been specified
    (using the `displayInput` method); the callback function is called only if one
    has been specified (using the `setFrameProcessor` method). The output window is
    displayed only if an output window name has been defined (using `displayOutput`);
    a delay is introduced only if one has been specified (using the `setDelay` method).
    Finally, the current frame number is checked if a stop frame has been defined
    (using the `stopAtFrameNo` method).
  prefs: []
  type: TYPE_NORMAL
- en: 'One might also wish to simply open and play the video file (without calling
    the callback function). Therefore, we have two methods that specify whether or
    not we want the callback function to be called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the class also offers the possibility to stop at a certain frame number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The class also contains a number of getter and setter methods that are basically
    just a wrapper over the general `set` and `get` methods of the `cv::VideoCapture`
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our `VideoProcessor` class is there to facilitate the deployment of a video-processing
    module. A few additional refinements can be made to it.
  prefs: []
  type: TYPE_NORMAL
- en: Processing a sequence of images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sometimes, the input sequence is made of a series of images that are individually
    stored in distinct files. Our class can be easily modified to accommodate such
    input. You just need to add a member variable that will hold a vector of image
    filenames and its corresponding iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'A new `setInput` method is used to specify the filenames to be read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The `isOpened` method becomes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The last method that needs to be modified is the private `readNextFrame` method
    that will read from the video or from the vector of filenames, depending on the
    input that has been specified. The test is that if the vector of image filenames
    is not empty, then that is because the input is an image sequence. The call to
    `setInput` with a video filename clears this vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Using a frame processor class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In an object-oriented context, it might make more sense to use a frame processing
    class instead of a frame processing function. Indeed, a class would give the programmer
    much more flexibility in the definition of a video-processing algorithm. We can,
    therefore, define an interface that any class that wishes to be used inside the
    `VideoProcessor` will need to implement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'A setter method allows you to input a `FrameProcessor` instance to the `VideoProcessor`
    framework and assign it to the added `FrameProcessor` member variable that is
    defined as a pointer to a `FrameProcessor` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'When a frame `processor` class instance is specified, it invalidates any frame
    processing function that could have been set previously. The same obviously applies
    if a frame processing function is specified instead. The `while` loop of the `run`
    method is modified to take into account this modification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Tracking feature points in a video* recipe of [Chapter 13](ch13.html "Chapter 13. Tracking
    Visual Motion") , *Tracking Visual Motion*, gives you an example of how to use
    the `FrameProcessor` class interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The GitHub project at [https://github.com/asolis/vivaVideo](https://github.com/asolis/vivaVideo)
    presents a more sophisticated framework for processing video with multithreading
    in OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing video sequences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous recipes, we learned how to read a video file and extract its
    frames. This recipe will show you how to write frames and, therefore, create a
    video file. This will allow us to complete the typical video-processing chain:
    reading an input video stream, processing its frames, and then storing the results
    in a new video file.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Writing video files in OpenCV is done using the `cv::VideoWriter` class. An
    instance is constructed by specifying the filename, the frame rate at which the
    generated video should play, the size of each frame, and whether or not the video
    will be created in color:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In addition, you must specify the way you want the video data to be saved. This
    is the `codec` argument; this will be discussed at the end of this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the video file is opened, frames can be added to it by repetitively calling
    the `write` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `cv::VideoWriter` class, our `VideoProcessor` class introduced in
    the previous recipe can easily be expanded in order to give it the ability to
    write video files. A simple program that will read a video, process it, and write
    the result to a video file would then be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Proceeding as we did in the preceding recipe, we also want to give the user
    the possibility to write the frames as individual images. In our framework, we
    adopt a naming convention that consists of a prefix name followed by a number
    made of a given number of digits. This number is automatically incremented as
    frames are saved. Then, to save the output result as a series of images, you would
    swap the preceding statement with this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Using the specified number of digits, this call will create the `bikeOut000.jpg`,
    `bikeOut001.jpg`, and `bikeOut002.jpg` files, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s now describe how to modify our `VideoProcessor` class in order to give
    it the ability to write video files. First, a `cv::VideoWriter` variable member
    must be added to our class (plus a few other attributes):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'An extra method is used to specify (and open) the output video file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'A private method, called the `writeNextFrame` method, handles the frame writing
    procedure (in a video file or as a series of images):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'For the case where the output is made of individual image files, we need an
    additional setter method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, a new step is then added to the video capture loop of the `run` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a video is written to a file, it is saved using a codec. A **codec** is
    a software module that is capable of encoding and decoding video streams. The
    codec defines both the format of the file and the compression scheme that is used
    to store the information. Obviously, a video that has been encoded using a given
    codec must be decoded with the same codec. For this reason, four-character codes
    have been introduced to uniquely identify codecs. This way, when a software tool
    needs to write a video file, it determines the codec to be used by reading the
    specified four-character code.
  prefs: []
  type: TYPE_NORMAL
- en: The codec four-character code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As the name suggests, the four-character code is made up of four ASCII characters
    that can also be converted into an integer by appending them together. Using the
    `cv::CAP_PROP_FOURCC` flag of the `get` method of an opened `cv::VideoCapture`
    instance, you can obtain the code of an opened video file. We can define a method
    in our `VideoProcessor` class to return the four-character code of an input video:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `get` method always returns a `double` value that is then casted into an
    `integer`. This integer represents the code from which the four characters can
    be extracted using a `union` data structure. If we open our test video sequence,
    then we have the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding statements, we obtain, for our example, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: When a video file is written, the codec must be specified using its four-character
    code. This is the second parameter in the `open` method of the `cv::VideoWriter`
    class. You can use, for example, the same one as the input video (this is the
    default option in our `setOutput` method). You can also pass the value `-1` and
    the method will pop up a window that will ask you to select one codec from the
    list of available codecs. The list you will see in this window corresponds to
    the list of installed codecs on your machine. The code of the selected codec is
    then automatically sent to the `open` method.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [https://www.xvid.com/](https://www.xvid.com/) website offers you an open
    source video codec library based on the MPEG-4 standard for video compression.
    **Xvid** also has a competitor called **DivX**, which offers proprietary but free
    codec and software tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting the foreground objects in a video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is about reading, writing, and processing video sequences. The
    objective is to be able to analyze a complete video sequence. As an example, in
    this recipe, you will learn how to perform temporal analysis of a sequence in
    order to extract the moving foreground objects. Indeed, when a fixed camera observes
    a scene, the background remains mostly unchanged. In this case, the interesting
    elements are the moving objects that evolve inside this scene. In order to extract
    these foreground objects, we need to build a model of the background, and then
    compare this model with a current frame in order to detect any foreground objects.
    This is what we will do in this recipe. Foreground extraction is a fundamental
    step in intelligent surveillance applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we had an image of the background of the scene (that is, a frame that contains
    no foreground objects) at our disposal, then it would be easy to extract the foreground
    of a current frame through a simple image difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Each pixel for which this difference is high enough would then be declared as
    a foreground pixel. However, most of the time, this background image is not readily
    available. Indeed, it could be difficult to guarantee that no foreground objects
    are present in a given image, and in busy scenes, such situations might rarely
    occur. Moreover, the background scene often evolves over time because, for instance,
    the lighting condition changes (for example, from sunrise to sunset) or because
    new objects are added or removed from the background.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is necessary to dynamically build a model of the background scene.
    This can be done by observing the scene for a period of time. If we assume that
    most often, the background is visible at each pixel location, then it could be
    a good strategy to simply compute the average of all of the observations. However,
    this is not feasible for a number of reasons. First, this would require a large
    number of images to be stored before computing the background. Second, while we
    are accumulating images to compute our average image, no foreground extraction
    is done. This solution also raises the problem of when and how many images should
    be accumulated to compute an acceptable background model. In addition, the images
    where a given pixel is observing a foreground object would have an impact on the
    computation of the average background.
  prefs: []
  type: TYPE_NORMAL
- en: 'A better strategy is to dynamically build the background model by regularly
    updating it. This can be accomplished by computing what is called a **running
    average** (also called **moving average**). This is a way to compute the average
    value of a temporal signal that takes into account the latest received values.
    If `p[t]` is the pixel value at a given time `t` and `μ[t-1]` is the current average
    value, then this average is updated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Extracting the foreground objects in a video](img/B05388_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `α` parameter is called the **learning rate**, and it defines the influence
    of the current value over the currently estimated average. The larger this value
    is, the faster the running average will adapt to changes in the observed values
    but, at the same time, slowly moving objects will tend to disappear in the background
    when the learning rate is set too high. In fact, the appropriate learning rate
    largely depends on the dynamic of the scene. To build a background model, one
    just has to compute a running average for every pixel of the incoming frames.
    The decision to declare a foreground pixel is then simply based on the difference
    between the current image and the background model.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s build a class that will learn a background model using a moving average
    and that will extract foreground objects by subtraction. The required attributes
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The main process consists of comparing the current frame with the background
    model and then updating this model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Using our video-processing framework, the foreground extraction program will
    be built as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the resulting binary foreground images that will be displayed is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_12_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Computing the running average of an image is easily accomplished through the
    `cv::accumulateWeighted` function that applies the running average formula to
    each pixel of the image. Note that the resulting image must be a floating point
    image. This is why we had to convert the background model into a background image
    before comparing it with the current frame. A simple thresholded absolute difference
    (computed by `cv::absdiff` followed by `cv::threshold`) extracts the foreground
    image. Note that we then used the foreground image as a mask to `cv::accumulateWeighted`
    in order to avoid updating pixels declared as foreground. This works because our
    foreground image is defined as being `false` (that is, `0`) at foreground pixels
    (which also explains why the foreground objects are displayed as black pixels
    in the resulting image).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it should be noted that, for simplicity, the background model that
    is built by our program is based on the gray-level version of the extracted frames.
    Maintaining a color background would require the computation of a running average
    in some color space. As it is often the case with parametric vision algorithms,
    the main difficulty in the presented approach is to determine the appropriate
    value for the threshold that would give good results for a given video.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The preceding, simple method to extract foreground objects in a scene works
    well for simple scenes that show a relatively stable background. However, in many
    situations, the background scene might fluctuate in certain areas between different
    values, thus causing frequent false foreground detections. These might be due
    to, for example, a moving background object (for example, tree leaves) or a glaring
    effect (for example, on the surface of water). Casted shadows also pose a problem
    since they are often detected as part of a moving object. In order to cope with
    these problems, more sophisticated background modeling methods have been introduced.
  prefs: []
  type: TYPE_NORMAL
- en: The Mixture of Gaussian method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of these algorithms is the **Mixture of Gaussian** method. It proceeds in
    a way that is similar to the method presented in this recipe, but adds a number
    of improvements.
  prefs: []
  type: TYPE_NORMAL
- en: First, the method maintains more than one model per pixel (that is, more than
    one running average). This way, if a background pixel fluctuates between, let's
    say, two values, two running averages are then stored. A new pixel value will
    be declared as the foreground only if it does not belong to any of the most frequently
    observed models. The number of models used is a parameter of the method, and a
    typical value is `5`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, not only is the running average maintained for each model, but also
    for the running variance. This is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mixture of Gaussian method](img/B05388_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: These computed averages and variances are used to build a Gaussian model from
    which the probability of a given pixel value belonging to the background can be
    estimated. This makes it easier to determine an appropriate threshold since it
    is now expressed as a probability rather than an absolute difference. Consequently,
    in areas where the background values have larger fluctuations, a greater difference
    will be required to declare a foreground object.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, this is an adaptive model, that is when a given Gaussian model is not
    hit sufficiently often, it is excluded from being part of the background model.
    Reciprocally, when a pixel value is found to be outside the currently maintained
    background models (that is, it is a foreground pixel), a new Gaussian model is
    created. If, in the future, this new model frequently receives pixels, then it
    becomes associated with the background.
  prefs: []
  type: TYPE_NORMAL
- en: 'This more sophisticated algorithm is obviously more complex to implement than
    our simple background/foreground segmentor. Fortunately, an OpenCV implementation
    exists, called `cv::bgsegm::createBackgroundSubtractorMOG`, and is defined as
    a subclass of the more general `cv::BackgroundSubtractor` class. When used with
    its default parameter, this class is very easy to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it is just a matter of creating the class instance and calling
    the method that simultaneously updates the background and returns the foreground
    image (the extra parameter being the learning rate). Also note that the background
    model is computed in color here. The method implemented in OpenCV also includes
    a mechanism to reject shadows by checking whether the observed pixel variation
    is simply caused by a local change in brightness (if so, then it is probably due
    to a shadow) or whether it also includes some change in chromaticity.
  prefs: []
  type: TYPE_NORMAL
- en: A second implementation is also available and is simply called `cv::BackgroundSubtractorMOG2`.
    One of the improvements is that the number of appropriate Gaussian models per
    pixel to be used is now determined dynamically. You can use this in place of the
    previous one in the preceding example. You should run these different methods
    on a number of videos in order to appreciate their respective performances. In
    general, you will observe that `cv::BackgroundSubtractorMOG2` is much faster.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The article by *C. Stauffer* and *W.E.L. Grimso*n, *Adaptive Background Mixture
    Models for Real-Time Tracking*, in *Conf. on Computer Vision and Pattern Recognition*,
    1999, gives you a more complete description of the Mixture of Gaussian algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
