- en: Chapter 12. Processing Video Sequences
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章. 处理视频序列
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下配方：
- en: Reading video sequences
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取视频序列
- en: Processing the video frames
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理视频帧
- en: Writing video sequences
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写入视频序列
- en: Extracting the foreground objects in a video
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从视频中提取前景对象
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Video signals constitute a rich source of visual information. They are made
    of a sequence of images, called **frames**, that are taken at regular time intervals
    (specified as the **frame rate**, generally expressed in frames per second) and
    show a scene in motion. With the advent of powerful computers, it is now possible
    to perform advanced visual analysis on video sequences-sometimes at rates close
    to, or even faster than, the actual video frame rate. This chapter will show you
    how to read, process, and store video sequences.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 视频信号构成了丰富的视觉信息来源。它们由一系列图像组成，称为**帧**，这些图像以固定的时间间隔（指定为**帧率**，通常以每秒帧数表示）拍摄，并显示一个动态场景。随着强大计算机的出现，现在可以在视频序列上执行高级视觉分析——有时接近或甚至超过实际视频帧率。本章将向您展示如何读取、处理和存储视频序列。
- en: We will see that once the individual frames of a video sequence have been extracted,
    the different image processing functions presented in this book can be applied
    to each of them. In addition, we will also look at algorithms that perform a temporal
    analysis of the video sequence, comparing adjacent frames and accumulating image
    statistics over time in order to extract foreground objects.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到，一旦提取了视频序列的各个帧，就可以将本书中介绍的不同图像处理函数应用于每个帧。此外，我们还将探讨执行视频序列时间分析的算法，比较相邻帧，并随时间累积图像统计信息，以提取前景对象。
- en: Reading video sequences
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取视频序列
- en: In order to process a video sequence, we need to be able to read each of its
    frames. OpenCV has put in place an easy-to-use framework that can help us perform
    frame extraction from video files or even from USB or IP cameras. This recipe
    shows you how to use it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理视频序列，我们需要能够读取其每一帧。OpenCV提供了一个易于使用的框架，可以帮助我们从视频文件或甚至从USB或IP摄像头中提取帧。这个配方将向你展示如何使用它。
- en: How to do it...
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Basically, all you need to do in order to read the frames of a video sequence
    is create an instance of the `cv::VideoCapture` class. You then create a loop
    that will extract and read each video frame. Here is a basic main function that
    displays the frames of a video sequence:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，你只需要创建一个`cv::VideoCapture`类的实例，以便读取视频序列的帧。然后创建一个循环，用于提取和读取每个视频帧。以下是一个基本的main函数，用于显示视频序列的帧：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A window will appear on which the video will play as shown in the following
    screenshot:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 将会弹出一个窗口，视频将在其中播放，如下面的截图所示：
- en: '![How to do it...](img/image_12_001.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![如何做到这一点...](img/image_12_001.jpg)'
- en: How it works...
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'To open a video, you simply need to specify the video filename. This can be
    done by providing the name of the file in the constructor of the `cv::VideoCapture`
    object. It is also possible to use the `open` method if the `cv::VideoCapture`
    object has already been created. Once the video is successfully opened (this can
    be verified through the `isOpened` method), it is possible to start frame extraction.
    It is also possible to query the `cv::VideoCapture` object for information associated
    with the video file by using its `get` method with the appropriate flag. In the
    preceding example, we obtained the frame rate using the `CV_CAP_PROP_FPS` flag.
    Since it is a generic function, it always returns a double even if another type
    would be expected in some cases. For example, the total number of frames in the
    video file would be obtained (as an integer) as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要打开视频，你只需指定视频文件名。这可以通过在`cv::VideoCapture`对象的构造函数中提供文件名来实现。如果已经创建了`cv::VideoCapture`对象，也可以使用`open`方法。一旦视频成功打开（可以通过`isOpened`方法进行验证），就可以开始帧提取。还可以通过使用带有适当标志的`get`方法查询与视频文件相关的`cv::VideoCapture`对象信息。在先前的示例中，我们使用`CV_CAP_PROP_FPS`标志获取了帧率。由于它是一个通用函数，它总是返回一个双精度浮点数，即使在某些情况下预期返回其他类型。例如，视频文件中的总帧数可以通过以下方式获取（作为一个整数）：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Have a look at the different flags that are available in the OpenCV documentation
    in order to find out what information can be obtained from the video.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 查阅OpenCV文档中可用的不同标志，以了解可以从视频中获取哪些信息。
- en: 'There is also a `set` method that allows you to input parameters into the `cv::VideoCapture`
    instance. For example, you can request to move to a specific frame using the `CV_CAP_PROP_POS_FRAMES`
    flag:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个`set`方法，允许你将参数输入到`cv::VideoCapture`实例中。例如，你可以使用`CV_CAP_PROP_POS_FRAMES`标志请求移动到特定的帧：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can also specify the position in milliseconds using `CV_CAP_PROP_POS_MSEC`,
    or you can specify the relative position inside the video using `CV_CAP_PROP_POS_AVI_RATIO`
    (with `0.0` corresponding to the beginning of the video and `1.0` to the end).
    The method returns `true` if the requested parameter setting is successful. Note
    that the possibility to get or set a particular video parameter largely depends
    on the codec that is used to compress and store the video sequence. If you are
    unsuccessful with some parameters, that could be simply due to the specific codec
    you are using.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用`CV_CAP_PROP_POS_MSEC`指定以毫秒为单位的位臵，或者你可以使用`CV_CAP_PROP_POS_AVI_RATIO`指定视频内部的相对位臵（`0.0`对应视频的开始，`1.0`对应视频的结束）。该方法在请求的参数设置成功时返回`true`。请注意，获取或设置特定视频参数的可能性很大程度上取决于用于压缩和存储视频序列的编解码器。如果你在某些参数上不成功，那可能只是因为你使用的特定编解码器。
- en: 'Once the captured video is successfully opened, the frames can be sequentially
    obtained by repetitively calling the `read` method, as we did in the example of
    the previous section. One can equivalently call the overloaded reading operator:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦成功打开捕获的视频，就可以通过重复调用`read`方法来按顺序获取帧，就像我们在上一节的例子中所做的那样。也可以等价地调用重载的读取操作符：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It is also possible to call the two basic methods:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以调用两个基本方法：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Also note how, in our example, we introduced a delay in displaying each frame.
    This is done using the `cv::waitKey` function. Here, we set the delay at a value
    that corresponds to the input video frame rate (if `fps` is the number of frames
    per second, then `1/fps` is the delay between two frames in milliseconds). You
    can obviously change this value to display the video at a slower or faster speed.
    However, if you are going to display the video frames, it is important that you
    insert such a delay if you want to make sure that the window has sufficient time
    to refresh (since it is a process of low priority, it will never refresh if the
    CPU is too busy). The `cv::waitKey` function also allows us to interrupt the reading
    process by pressing any key. In this case, the function returns the ASCII code
    of the key that is pressed. Note that, if the delay specified to the `cv::waitKey`
    function is `0`, then it will wait indefinitely for the user to press a key. This
    is very useful if someone wants to trace a process by examining the results frame
    by frame.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，在我们的例子中，我们引入了显示每个帧的延迟。这是通过使用`cv::waitKey`函数实现的。在这里，我们将延迟设置为与输入视频帧率相对应的值（如果`fps`是每秒的帧数，那么两个帧之间的延迟以毫秒为单位就是`1/fps`）。显然，你可以改变这个值来以较慢或较快的速度显示视频。然而，如果你打算显示视频帧，确保窗口有足够的时间刷新是很重要的（因为这是一个低优先级的过程，如果CPU太忙，它将永远不会刷新）。`cv::waitKey`函数还允许我们通过按任意键来中断读取过程。在这种情况下，函数返回按下的键的ASCII码。请注意，如果指定给`cv::waitKey`函数的延迟是`0`，那么它将无限期地等待用户按下键。如果有人想通过逐帧检查结果来跟踪一个过程，这非常有用。
- en: The final statement calls the `release` method, which will close the video file.
    However, this call is not required since `release` is also called by the `cv::VideoCapture`
    destructor.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条语句调用`release`方法，这将关闭视频文件。然而，这个调用不是必需的，因为`release`也会在`cv::VideoCapture`析构函数中被调用。
- en: It is important to note that in order to open the specified video file, your
    computer must have the corresponding codec installed; otherwise, `cv::VideoCapture`
    will not be able to decode the input file. Normally, if you are able to open your
    video file with a video player on your machine (such as Windows Media Player),
    then OpenCV should also be able to read this file.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，为了打开指定的视频文件，你的计算机必须安装相应的编解码器；否则，`cv::VideoCapture`将无法解码输入文件。通常，如果你能在你的机器上的视频播放器（如Windows
    Media Player）中打开你的视频文件，那么OpenCV也应该能够读取这个文件。
- en: There's more...
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: You can also read the video stream produced by a camera that is connected to
    your computer (a USB camera, for example). In this case, you simply specify an
    ID number (an integer) instead of a filename to the `open` function. Specifying
    `0` for the ID will open the default installed camera. In this case, the role
    of the `cv::waitKey` function that stops the processing becomes essential, since
    the video stream from the camera will be infinitely read.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以读取连接到您计算机的摄像头（例如USB摄像头）产生的视频流。在这种情况下，您只需将ID号（一个整数）指定给 `open` 函数，而不是文件名。将ID指定为
    `0` 将打开默认安装的摄像头。在这种情况下，`cv::waitKey` 函数停止处理的作用变得至关重要，因为来自摄像头的视频流将被无限读取。
- en: 'Finally, it is also possible to load a video from the Web. In this case, all
    you have to do is provide the correct address, for example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从Web加载视频也是可能的。在这种情况下，您只需提供正确的地址即可，例如：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: See also
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Writing video sequences* recipe in this chapter has more information on
    video codecs.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *写入视频序列* 菜谱提供了有关视频编解码器的更多信息。
- en: The [http://ffmpeg.org/](http://ffmpeg.org/) website presents a complete open
    source and cross-platform solution for audio/video reading, recording, converting,
    and streaming. The OpenCV classes that manipulate video files are built on top
    of this library.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://ffmpeg.org/](http://ffmpeg.org/) 网站提供了一个完整的开源和跨平台解决方案，用于音频/视频的读取、录制、转换和流式传输。OpenCV处理视频文件的类建立在上述库之上。'
- en: Processing the video frames
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理视频帧
- en: In this recipe, our objective is to apply some processing functions to each
    of the frames of a video sequence. We will do this by encapsulating the OpenCV
    video capture framework into our own class. Among other things, this class will
    allow us to specify a function that will be called each time a new frame is extracted.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们的目标是将对视频序列中的每一帧应用一些处理函数。我们将通过将OpenCV视频捕获框架封装到我们自己的类中来完成此操作。这个类将允许我们在每次提取新帧时调用一个函数。
- en: How to do it...
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'What we want is to be able to specify a processing function (a **callback function**)
    that will be called for each frame of a video sequence. This function can be defined
    as receiving a `cv::Mat` instance and outputting a processed frame. Therefore,
    in our framework, the processing function must have the following signature to
    be a valid callback:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够指定一个处理函数（一个**回调函数**），该函数将为视频序列的每一帧调用。此函数可以定义为接收一个 `cv::Mat` 实例并输出一个处理后的帧。因此，在我们的框架中，处理函数必须具有以下签名才能成为有效的回调：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As an example of such a processing function, consider the following simple
    function that computes the Canny edges of an input image:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 作为此类处理函数的一个示例，考虑以下简单的函数，该函数计算输入图像的Canny边缘：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Our `VideoProcessor` class encapsulates all aspects of a video-processing task.
    Using this class, the procedure will be to create a class instance, specify an
    input video file, attach the callback function to it, and then start the process.
    Programmatically, these steps are accomplished using our proposed class, as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `VideoProcessor` 类封装了视频处理任务的所有方面。使用这个类，步骤将是创建一个类实例，指定输入视频文件，将其回调函数附加到它，然后开始处理。程序上，这些步骤是通过我们提出的类来完成的，如下所示：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If this code is run, then two windows will play the input video and the output
    result at the original frame rate (a consequence of the delay introduced by the
    `setDelay` method). For example, considering the input video for which a frame
    is shown in the previous recipe, the output window will look as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果运行此代码，则两个窗口将以原始帧率播放输入视频和输出结果（这是由 `setDelay` 方法引入的延迟的结果）。例如，考虑上一个菜谱中显示的输入视频，输出窗口将如下所示：
- en: '![How to do it...](img/image_12_002.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_12_002.jpg)'
- en: How it works...
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'As we did in other recipes, our objective was to create a class that encapsulates
    the common functionalities of a video-processing algorithm. As one might expect,
    the class includes several member variables that control the different aspects
    of the video frame processing:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在其他菜谱中所做的那样，我们的目标是创建一个类，该类封装了视频处理算法的常见功能。正如人们所预期的那样，该类包括几个成员变量，用于控制视频帧处理的不同方面：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The first member variable is the `cv::VideoCapture` object. The second attribute
    is the `process` function pointer that will point to the callback function. This
    function can be specified using the corresponding setter method:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个成员变量是 `cv::VideoCapture` 对象。第二个属性是 `process` 函数指针，它将指向回调函数。此函数可以使用相应的设置方法指定：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following method opens the video file:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方法打开视频文件：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It is generally interesting to display the frames as they are processed. Therefore,
    two methods are used to create the display windows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在处理过程中显示帧是很有趣的。因此，使用了两种方法来创建显示窗口：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The main method, called `run`, is the one that contains the frame extraction
    loop:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 主方法，称为 `run`，是包含帧提取循环的方法：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This method uses a `private` method that reads the frames:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用一个 `private` 方法来读取帧：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `run` method proceeds by first calling the read method of the `cv::VideoCapture`
    class. There is then a series of operations that are executed, but before each
    of them is invoked, a check is made to determine whether it has been requested.
    The input window is displayed only if an input window name has been specified
    (using the `displayInput` method); the callback function is called only if one
    has been specified (using the `setFrameProcessor` method). The output window is
    displayed only if an output window name has been defined (using `displayOutput`);
    a delay is introduced only if one has been specified (using the `setDelay` method).
    Finally, the current frame number is checked if a stop frame has been defined
    (using the `stopAtFrameNo` method).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`run` 方法首先调用 `cv::VideoCapture` 类的读取方法。然后执行一系列操作，但在调用每个操作之前，都会进行检查以确定是否已请求。只有当指定了输入窗口名称（使用
    `displayInput` 方法）时，才会显示输入窗口；只有当指定了回调函数（使用 `setFrameProcessor` 方法）时，才会调用回调函数。只有当定义了输出窗口名称（使用
    `displayOutput`）时，才会显示输出窗口；只有当指定了延迟（使用 `setDelay` 方法）时，才会引入延迟。最后，如果定义了停止帧（使用 `stopAtFrameNo`
    方法），则会检查当前帧号。'
- en: 'One might also wish to simply open and play the video file (without calling
    the callback function). Therefore, we have two methods that specify whether or
    not we want the callback function to be called:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可能还希望简单地打开并播放视频文件（不调用回调函数）。因此，我们有两个方法来指定是否调用回调函数：
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, the class also offers the possibility to stop at a certain frame number:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，该类还提供了在特定帧号处停止的可能性：
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The class also contains a number of getter and setter methods that are basically
    just a wrapper over the general `set` and `get` methods of the `cv::VideoCapture`
    framework.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 该类还包含了一些getter和setter方法，基本上只是 `cv::VideoCapture` 框架的通用 `set` 和 `get` 方法的包装器。
- en: There's more...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Our `VideoProcessor` class is there to facilitate the deployment of a video-processing
    module. A few additional refinements can be made to it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `VideoProcessor` 类旨在简化视频处理模块的部署。可以对它进行一些额外的改进。
- en: Processing a sequence of images
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理一系列图像
- en: 'Sometimes, the input sequence is made of a series of images that are individually
    stored in distinct files. Our class can be easily modified to accommodate such
    input. You just need to add a member variable that will hold a vector of image
    filenames and its corresponding iterator:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，输入序列是由一系列单独存储在各自文件中的图像组成的。我们的类可以很容易地修改以适应这种输入。你只需要添加一个成员变量，它将保存一个图像文件名向量和其对应的迭代器：
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'A new `setInput` method is used to specify the filenames to be read:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的 `setInput` 方法来指定要读取的文件名：
- en: '[PRE18]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `isOpened` method becomes as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`isOpened` 方法变为以下形式：'
- en: '[PRE19]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The last method that needs to be modified is the private `readNextFrame` method
    that will read from the video or from the vector of filenames, depending on the
    input that has been specified. The test is that if the vector of image filenames
    is not empty, then that is because the input is an image sequence. The call to
    `setInput` with a video filename clears this vector:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 需要修改的最后一种方法是私有的 `readNextFrame` 方法，它将根据指定的输入从视频或文件名向量中读取。测试方法是，如果图像文件名向量不为空，那么这是因为输入是一个图像序列。使用视频文件名调用
    `setInput` 会清除这个向量：
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Using a frame processor class
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用帧处理器类
- en: 'In an object-oriented context, it might make more sense to use a frame processing
    class instead of a frame processing function. Indeed, a class would give the programmer
    much more flexibility in the definition of a video-processing algorithm. We can,
    therefore, define an interface that any class that wishes to be used inside the
    `VideoProcessor` will need to implement:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在面向对象的环境中，使用帧处理类而不是帧处理函数可能更有意义。确实，一个类会给程序员在视频处理算法定义上提供更多的灵活性。因此，我们可以定义一个接口，任何希望被用于
    `VideoProcessor` 内部的类都需要实现：
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'A setter method allows you to input a `FrameProcessor` instance to the `VideoProcessor`
    framework and assign it to the added `FrameProcessor` member variable that is
    defined as a pointer to a `FrameProcessor` object:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一个设置方法允许您将一个`FrameProcessor`实例输入到`VideoProcessor`框架中，并将其分配给定义为指向`FrameProcessor`对象的指针的添加的`FrameProcessor`成员变量：
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'When a frame `processor` class instance is specified, it invalidates any frame
    processing function that could have been set previously. The same obviously applies
    if a frame processing function is specified instead. The `while` loop of the `run`
    method is modified to take into account this modification:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当指定了一个帧`processor`类实例时，它将使之前可能已设置的任何帧处理函数无效。如果指定了帧处理函数，同样适用。`run`方法的`while`循环被修改以考虑这种修改：
- en: '[PRE23]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: See also
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Tracking feature points in a video* recipe of [Chapter 13](ch13.html "Chapter 13. Tracking
    Visual Motion") , *Tracking Visual Motion*, gives you an example of how to use
    the `FrameProcessor` class interface
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第13章](ch13.html "第13章。跟踪视觉运动")中关于*视频中的跟踪特征点*的配方，*跟踪视觉运动*，为你提供了一个如何使用`FrameProcessor`类接口的例子。'
- en: The GitHub project at [https://github.com/asolis/vivaVideo](https://github.com/asolis/vivaVideo)
    presents a more sophisticated framework for processing video with multithreading
    in OpenCV
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub项目[https://github.com/asolis/vivaVideo](https://github.com/asolis/vivaVideo)展示了在OpenCV中使用多线程处理视频的更复杂的框架。
- en: Writing video sequences
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写视频序列
- en: 'In the previous recipes, we learned how to read a video file and extract its
    frames. This recipe will show you how to write frames and, therefore, create a
    video file. This will allow us to complete the typical video-processing chain:
    reading an input video stream, processing its frames, and then storing the results
    in a new video file.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的配方中，我们学习了如何读取视频文件并提取其帧。这个配方将向您展示如何写入帧，从而创建视频文件。这将使我们能够完成典型的视频处理链：读取输入视频流，处理其帧，然后将结果存储在新视频文件中。
- en: How to do it...
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Writing video files in OpenCV is done using the `cv::VideoWriter` class. An
    instance is constructed by specifying the filename, the frame rate at which the
    generated video should play, the size of each frame, and whether or not the video
    will be created in color:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，使用`cv::VideoWriter`类来编写视频文件。通过指定文件名、生成视频应播放的帧率、每帧的大小以及视频是否以彩色创建来构造一个实例：
- en: '[PRE24]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In addition, you must specify the way you want the video data to be saved. This
    is the `codec` argument; this will be discussed at the end of this recipe.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您必须指定您想要保存视频数据的方式。这是`codec`参数；这将在本配方的末尾讨论。
- en: 'Once the video file is opened, frames can be added to it by repetitively calling
    the `write` method:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦视频文件被打开，可以通过重复调用`write`方法将其添加帧：
- en: '[PRE25]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Using the `cv::VideoWriter` class, our `VideoProcessor` class introduced in
    the previous recipe can easily be expanded in order to give it the ability to
    write video files. A simple program that will read a video, process it, and write
    the result to a video file would then be written as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cv::VideoWriter`类，我们前面配方中引入的`VideoProcessor`类可以很容易地扩展，以便赋予它写入视频文件的能力。一个简单的程序将读取视频，处理它，并将结果写入视频文件，如下所示：
- en: '[PRE26]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Proceeding as we did in the preceding recipe, we also want to give the user
    the possibility to write the frames as individual images. In our framework, we
    adopt a naming convention that consists of a prefix name followed by a number
    made of a given number of digits. This number is automatically incremented as
    frames are saved. Then, to save the output result as a series of images, you would
    swap the preceding statement with this one:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 按照前面配方中的做法，我们也想给用户提供将帧作为单独图像写入的可能性。在我们的框架中，我们采用一个命名约定，它由一个前缀名称后跟一个由给定数量的数字组成的数字组成。这个数字在保存帧时会自动增加。然后，为了将输出结果保存为一系列图像，您可以将前面的语句替换为以下语句：
- en: '[PRE27]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Using the specified number of digits, this call will create the `bikeOut000.jpg`,
    `bikeOut001.jpg`, and `bikeOut002.jpg` files, and so on.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定的数字位数，这个调用将创建`bikeOut000.jpg`、`bikeOut001.jpg`和`bikeOut002.jpg`等文件。
- en: How it works...
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s now describe how to modify our `VideoProcessor` class in order to give
    it the ability to write video files. First, a `cv::VideoWriter` variable member
    must be added to our class (plus a few other attributes):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们描述如何修改我们的`VideoProcessor`类，以便赋予它写入视频文件的能力。首先，必须向我们的类中添加一个`cv::VideoWriter`变量成员（以及一些其他属性）：
- en: '[PRE28]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'An extra method is used to specify (and open) the output video file:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用额外的方法来指定（并打开）输出视频文件：
- en: '[PRE29]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'A private method, called the `writeNextFrame` method, handles the frame writing
    procedure (in a video file or as a series of images):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为`writeNextFrame`的私有方法处理帧写入过程（在视频文件中或作为一系列图像）：
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'For the case where the output is made of individual image files, we need an
    additional setter method:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输出由单个图像文件组成的情况，我们需要一个额外的设置方法：
- en: '[PRE31]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Finally, a new step is then added to the video capture loop of the `run` method:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在`run`方法的视频捕获循环中添加了一个新的步骤：
- en: '[PRE32]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There's more...
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: When a video is written to a file, it is saved using a codec. A **codec** is
    a software module that is capable of encoding and decoding video streams. The
    codec defines both the format of the file and the compression scheme that is used
    to store the information. Obviously, a video that has been encoded using a given
    codec must be decoded with the same codec. For this reason, four-character codes
    have been introduced to uniquely identify codecs. This way, when a software tool
    needs to write a video file, it determines the codec to be used by reading the
    specified four-character code.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当将视频写入文件时，它使用编解码器进行保存。**编解码器**是一个能够对视频流进行编码和解码的软件模块。编解码器定义了文件的格式以及用于存储信息的压缩方案。显然，使用给定编解码器编码的视频必须使用相同的编解码器进行解码。因此，引入了四字符代码来唯一标识编解码器。这样，当软件工具需要写入视频文件时，它通过读取指定的四字符代码来确定要使用的编解码器。
- en: The codec four-character code
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编解码器四字符代码
- en: 'As the name suggests, the four-character code is made up of four ASCII characters
    that can also be converted into an integer by appending them together. Using the
    `cv::CAP_PROP_FOURCC` flag of the `get` method of an opened `cv::VideoCapture`
    instance, you can obtain the code of an opened video file. We can define a method
    in our `VideoProcessor` class to return the four-character code of an input video:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，四字符代码由四个ASCII字符组成，也可以通过将它们连接起来转换为整数。使用打开的`cv::VideoCapture`实例的`get`方法的`cv::CAP_PROP_FOURCC`标志，您可以获取打开视频文件的代码。我们可以在`VideoProcessor`类中定义一个方法来返回输入视频的四字符代码：
- en: '[PRE33]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The `get` method always returns a `double` value that is then casted into an
    `integer`. This integer represents the code from which the four characters can
    be extracted using a `union` data structure. If we open our test video sequence,
    then we have the following statements:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`get`方法始终返回一个`double`值，然后将其转换为`integer`。这个整数代表一个代码，可以使用`union`数据结构从中提取四个字符。如果我们打开我们的测试视频序列，那么我们将有以下语句：'
- en: '[PRE34]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'From the preceding statements, we obtain, for our example, the following:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的语句中，我们得到以下内容，针对我们的示例：
- en: '[PRE35]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: When a video file is written, the codec must be specified using its four-character
    code. This is the second parameter in the `open` method of the `cv::VideoWriter`
    class. You can use, for example, the same one as the input video (this is the
    default option in our `setOutput` method). You can also pass the value `-1` and
    the method will pop up a window that will ask you to select one codec from the
    list of available codecs. The list you will see in this window corresponds to
    the list of installed codecs on your machine. The code of the selected codec is
    then automatically sent to the `open` method.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当写入视频文件时，必须使用其四字符代码指定编解码器。这是`cv::VideoWriter`类`open`方法的第二个参数。例如，您可以使用与输入视频相同的编解码器（这是我们的`setOutput`方法中的默认选项）。您还可以传递值`-1`，此时方法将弹出一个窗口，让您从可用的编解码器列表中选择一个编解码器。您将在该窗口中看到的列表对应于您机器上安装的编解码器列表。所选编解码器的代码随后将自动发送到`open`方法。
- en: See also
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The [https://www.xvid.com/](https://www.xvid.com/) website offers you an open
    source video codec library based on the MPEG-4 standard for video compression.
    **Xvid** also has a competitor called **DivX**, which offers proprietary but free
    codec and software tools.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.xvid.com/](https://www.xvid.com/)网站为您提供了一个基于MPEG-4标准的开源视频编解码器库。**Xvid**还有一个竞争对手叫做**DivX**，它提供专有但免费的编解码器和软件工具。'
- en: Extracting the foreground objects in a video
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从视频中提取前景对象
- en: This chapter is about reading, writing, and processing video sequences. The
    objective is to be able to analyze a complete video sequence. As an example, in
    this recipe, you will learn how to perform temporal analysis of a sequence in
    order to extract the moving foreground objects. Indeed, when a fixed camera observes
    a scene, the background remains mostly unchanged. In this case, the interesting
    elements are the moving objects that evolve inside this scene. In order to extract
    these foreground objects, we need to build a model of the background, and then
    compare this model with a current frame in order to detect any foreground objects.
    This is what we will do in this recipe. Foreground extraction is a fundamental
    step in intelligent surveillance applications.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本章主要介绍阅读、编写和视频序列的处理。目标是能够分析完整的视频序列。作为一个例子，在本食谱中，你将学习如何执行序列的时间分析，以提取移动的前景物体。实际上，当固定摄像机观察一个场景时，背景基本上保持不变。在这种情况下，有趣的是场景内部移动的物体。为了提取这些前景物体，我们需要构建一个背景模型，然后将其与当前帧进行比较，以检测任何前景物体。这正是本食谱要做的。前景提取是智能监控应用中的基本步骤。
- en: 'If we had an image of the background of the scene (that is, a frame that contains
    no foreground objects) at our disposal, then it would be easy to extract the foreground
    of a current frame through a simple image difference:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们手头有一幅场景背景的图像（即，一个不包含前景物体的框架），那么通过简单的图像差分就可以轻松地提取当前帧的前景：
- en: '[PRE36]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Each pixel for which this difference is high enough would then be declared as
    a foreground pixel. However, most of the time, this background image is not readily
    available. Indeed, it could be difficult to guarantee that no foreground objects
    are present in a given image, and in busy scenes, such situations might rarely
    occur. Moreover, the background scene often evolves over time because, for instance,
    the lighting condition changes (for example, from sunrise to sunset) or because
    new objects are added or removed from the background.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个差值足够高的每个像素，将被宣布为前景像素。然而，大多数情况下，这个背景图像并不容易获得。实际上，可能很难保证给定图像中没有前景物体，在繁忙的场景中，这种情况可能很少发生。此外，背景场景通常会随着时间的推移而变化，例如，由于光照条件的变化（例如，从日出到日落）或因为新物体被添加到背景或从背景中移除。
- en: Therefore, it is necessary to dynamically build a model of the background scene.
    This can be done by observing the scene for a period of time. If we assume that
    most often, the background is visible at each pixel location, then it could be
    a good strategy to simply compute the average of all of the observations. However,
    this is not feasible for a number of reasons. First, this would require a large
    number of images to be stored before computing the background. Second, while we
    are accumulating images to compute our average image, no foreground extraction
    is done. This solution also raises the problem of when and how many images should
    be accumulated to compute an acceptable background model. In addition, the images
    where a given pixel is observing a foreground object would have an impact on the
    computation of the average background.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有必要动态地构建背景场景的模型。这可以通过观察场景一段时间来实现。如果我们假设大多数情况下，背景在每个像素位置都是可见的，那么简单地计算所有观察的平均值可能是一个好的策略。然而，由于多种原因，这并不可行。首先，这需要在计算背景之前存储大量的图像。其次，当我们积累图像来计算平均图像时，不会进行前景提取。这种解决方案还提出了何时以及需要积累多少图像来计算可接受的背景模型的问题。此外，观察到一个像素正在观察前景物体的图像将对平均背景的计算产生影响。
- en: 'A better strategy is to dynamically build the background model by regularly
    updating it. This can be accomplished by computing what is called a **running
    average** (also called **moving average**). This is a way to compute the average
    value of a temporal signal that takes into account the latest received values.
    If `p[t]` is the pixel value at a given time `t` and `μ[t-1]` is the current average
    value, then this average is updated using the following formula:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的策略是动态地通过定期更新来构建背景模型。这可以通过计算所谓的**运行平均值**（也称为**移动平均值**）来实现。这是一种计算时间信号平均值的办法，它考虑了最新接收到的值。如果`p[t]`是给定时间`t`处的像素值，而`μ[t-1]`是当前的平均值，那么这个平均值将使用以下公式进行更新：
- en: '![Extracting the foreground objects in a video](img/B05388_12_04.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![在视频中提取前景物体](img/B05388_12_04.jpg)'
- en: The `α` parameter is called the **learning rate**, and it defines the influence
    of the current value over the currently estimated average. The larger this value
    is, the faster the running average will adapt to changes in the observed values
    but, at the same time, slowly moving objects will tend to disappear in the background
    when the learning rate is set too high. In fact, the appropriate learning rate
    largely depends on the dynamic of the scene. To build a background model, one
    just has to compute a running average for every pixel of the incoming frames.
    The decision to declare a foreground pixel is then simply based on the difference
    between the current image and the background model.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`α`参数被称为**学习率**，它定义了当前值对当前估计平均值的影响。这个值越大，运行平均值就越快适应观察值的变化，但与此同时，当学习率设置得太高时，缓慢移动的对象倾向于在背景中消失。实际上，适当的学习率在很大程度上取决于场景的动态。为了构建背景模型，只需对输入帧的每个像素计算运行平均值。然后，根据当前图像与背景模型之间的差异来简单地决定是否声明前景像素。'
- en: How to do it...
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s build a class that will learn a background model using a moving average
    and that will extract foreground objects by subtraction. The required attributes
    are as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个类，该类将使用移动平均学习背景模型，并通过减法提取前景对象。所需的属性如下：
- en: '[PRE37]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The main process consists of comparing the current frame with the background
    model and then updating this model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 主要过程包括将当前帧与背景模型进行比较，然后更新此模型：
- en: '[PRE38]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Using our video-processing framework, the foreground extraction program will
    be built as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的视频处理框架，前景提取程序将构建如下：
- en: '[PRE39]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'One of the resulting binary foreground images that will be displayed is as
    follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 将要显示的其中一个二值前景图像如下：
- en: '![How to do it...](img/image_12_004.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_12_004.jpg)'
- en: How it works...
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Computing the running average of an image is easily accomplished through the
    `cv::accumulateWeighted` function that applies the running average formula to
    each pixel of the image. Note that the resulting image must be a floating point
    image. This is why we had to convert the background model into a background image
    before comparing it with the current frame. A simple thresholded absolute difference
    (computed by `cv::absdiff` followed by `cv::threshold`) extracts the foreground
    image. Note that we then used the foreground image as a mask to `cv::accumulateWeighted`
    in order to avoid updating pixels declared as foreground. This works because our
    foreground image is defined as being `false` (that is, `0`) at foreground pixels
    (which also explains why the foreground objects are displayed as black pixels
    in the resulting image).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`cv::accumulateWeighted`函数计算图像的运行平均值是很容易实现的，该函数将运行平均值公式应用于图像的每个像素。请注意，结果图像必须是一个浮点图像。这就是为什么我们不得不在将背景模型与当前帧比较之前将其转换为背景图像。通过`cv::absdiff`后跟`cv::threshold`计算的一个简单的阈值绝对差值（提取前景图像）。请注意，我们随后使用前景图像作为掩码来`cv::accumulateWeighted`，以避免更新被声明为前景的像素。这是因为我们的前景图像在前景像素上定义为`false`（即`0`），这也解释了为什么前景对象在结果图像中显示为黑色像素）。
- en: Finally, it should be noted that, for simplicity, the background model that
    is built by our program is based on the gray-level version of the extracted frames.
    Maintaining a color background would require the computation of a running average
    in some color space. As it is often the case with parametric vision algorithms,
    the main difficulty in the presented approach is to determine the appropriate
    value for the threshold that would give good results for a given video.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，需要注意的是，为了简化，我们程序构建的背景模型基于提取帧的灰度版本。保持彩色背景将需要在某些颜色空间中计算运行平均值。正如参数化视觉算法通常的情况一样，所提出的方法中的主要困难是确定适当的阈值，以便为给定的视频提供良好的结果。
- en: There's more...
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The preceding, simple method to extract foreground objects in a scene works
    well for simple scenes that show a relatively stable background. However, in many
    situations, the background scene might fluctuate in certain areas between different
    values, thus causing frequent false foreground detections. These might be due
    to, for example, a moving background object (for example, tree leaves) or a glaring
    effect (for example, on the surface of water). Casted shadows also pose a problem
    since they are often detected as part of a moving object. In order to cope with
    these problems, more sophisticated background modeling methods have been introduced.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 之前简单的方法在场景中提取前景对象效果良好，适用于显示相对稳定背景的简单场景。然而，在许多情况下，背景场景可能在某些区域之间在不同值之间波动，从而造成频繁的错误前景检测。这些可能是由例如移动的背景对象（例如树叶）或刺眼的效果（例如水面上）引起的。投射的阴影也造成问题，因为它们通常被检测为移动对象的一部分。为了应对这些问题，已经引入了更复杂的背景建模方法。
- en: The Mixture of Gaussian method
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高斯混合方法
- en: One of these algorithms is the **Mixture of Gaussian** method. It proceeds in
    a way that is similar to the method presented in this recipe, but adds a number
    of improvements.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法之一是**高斯混合**方法。它以与本文献中介绍的方法类似的方式进行，但增加了一些改进。
- en: First, the method maintains more than one model per pixel (that is, more than
    one running average). This way, if a background pixel fluctuates between, let's
    say, two values, two running averages are then stored. A new pixel value will
    be declared as the foreground only if it does not belong to any of the most frequently
    observed models. The number of models used is a parameter of the method, and a
    typical value is `5`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，该方法为每个像素维护多个模型（即多个运行平均值）。这样，如果一个背景像素在两个值之间波动，比如，两个运行平均值就会被存储。只有当一个新像素值不属于观察到的最频繁的任何模型时，才会将其宣布为前景。所使用的模型数量是该方法的参数之一，一个典型值是`5`。
- en: 'Second, not only is the running average maintained for each model, but also
    for the running variance. This is computed as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，不仅为每个模型维护运行平均值，还维护运行方差。计算方法如下：
- en: '![The Mixture of Gaussian method](img/B05388_12_05.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![高斯混合方法](img/B05388_12_05.jpg)'
- en: These computed averages and variances are used to build a Gaussian model from
    which the probability of a given pixel value belonging to the background can be
    estimated. This makes it easier to determine an appropriate threshold since it
    is now expressed as a probability rather than an absolute difference. Consequently,
    in areas where the background values have larger fluctuations, a greater difference
    will be required to declare a foreground object.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些计算出的平均值和方差被用来构建一个高斯模型，从而可以估计给定像素值属于背景的概率。这使得确定适当的阈值变得更容易，因为它现在是以概率而不是绝对差异的形式表达的。因此，在背景值波动较大的区域，需要更大的差异来宣布前景对象。
- en: Finally, this is an adaptive model, that is when a given Gaussian model is not
    hit sufficiently often, it is excluded from being part of the background model.
    Reciprocally, when a pixel value is found to be outside the currently maintained
    background models (that is, it is a foreground pixel), a new Gaussian model is
    created. If, in the future, this new model frequently receives pixels, then it
    becomes associated with the background.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是一个自适应模型，也就是说，如果一个给定的高斯模型没有被足够频繁地命中，它就会被排除在背景模型之外。相反，当一个像素值被发现目前维护的背景模型之外（即它是前景像素）时，就会创建一个新的高斯模型。如果在未来，这个新模型经常接收像素，那么它就与背景相关联。
- en: 'This more sophisticated algorithm is obviously more complex to implement than
    our simple background/foreground segmentor. Fortunately, an OpenCV implementation
    exists, called `cv::bgsegm::createBackgroundSubtractorMOG`, and is defined as
    a subclass of the more general `cv::BackgroundSubtractor` class. When used with
    its default parameter, this class is very easy to use:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更复杂的算法显然比我们简单的背景/前景分割器更难实现。幸运的是，存在一个OpenCV实现，称为`cv::bgsegm::createBackgroundSubtractorMOG`，它被定义为更通用`cv::BackgroundSubtractor`类的子类。当使用其默认参数时，这个类非常容易使用：
- en: '[PRE40]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: As you can see, it is just a matter of creating the class instance and calling
    the method that simultaneously updates the background and returns the foreground
    image (the extra parameter being the learning rate). Also note that the background
    model is computed in color here. The method implemented in OpenCV also includes
    a mechanism to reject shadows by checking whether the observed pixel variation
    is simply caused by a local change in brightness (if so, then it is probably due
    to a shadow) or whether it also includes some change in chromaticity.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这只是一个创建类实例并调用同时更新背景并返回前景图像（额外参数为学习率）的方法的问题。此外，请注意，这里的背景模型是按颜色计算的。OpenCV中实现的方法还包括一个机制，通过检查观察到的像素变化是否仅仅是由于亮度（如果是，那么可能是由于阴影）的局部变化来拒绝阴影，或者它是否还包括一些色度变化。
- en: A second implementation is also available and is simply called `cv::BackgroundSubtractorMOG2`.
    One of the improvements is that the number of appropriate Gaussian models per
    pixel to be used is now determined dynamically. You can use this in place of the
    previous one in the preceding example. You should run these different methods
    on a number of videos in order to appreciate their respective performances. In
    general, you will observe that `cv::BackgroundSubtractorMOG2` is much faster.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个实现也可用，简单称为 `cv::BackgroundSubtractorMOG2`。其中一个改进是，现在动态确定每个像素要使用的适当高斯模型的数量。您可以在前面的示例中使用这个代替之前的版本。您应该在多个视频上运行这些不同的方法，以便欣赏它们各自的性能。一般来说，您将观察到
    `cv::BackgroundSubtractorMOG2` 要快得多。
- en: See also
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The article by *C. Stauffer* and *W.E.L. Grimso*n, *Adaptive Background Mixture
    Models for Real-Time Tracking*, in *Conf. on Computer Vision and Pattern Recognition*,
    1999, gives you a more complete description of the Mixture of Gaussian algorithm
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C. Stauffer 和 W.E.L. Grimso 在 1999 年的 *Conf. on Computer Vision and Pattern
    Recognition* 发表的论文 *Adaptive Background Mixture Models for Real-Time Tracking*
    中，对高斯混合算法给出了更完整的描述。
