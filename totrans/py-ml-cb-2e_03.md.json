["```py\nimport numpy as np \nimport matplotlib.pyplot as plt \n\nimport utilities  \n\n# Load input data \ninput_file = 'data_multivar.txt' \nX, y = utilities.load_data(input_file) \n```", "```py\n# Load multivar data in the input file \ndef load_data(input_file): \n    X = [] \n    y = [] \n    with open(input_file, 'r') as f: \n        for line in f.readlines(): \n            data = [float(x) for x in line.split(',')] \n            X.append(data[:-1]) \n            y.append(data[-1])  \n\n    X = np.array(X) \n    y = np.array(y) \n\n    return X, y \n```", "```py\nclass_0 = np.array([X[i] for i in range(len(X)) if y[i]==0]) \nclass_1 = np.array([X[i] for i in range(len(X)) if y[i]==1]) \n```", "```py\nplt.figure() \nplt.scatter(class_0[:,0], class_0[:,1], facecolors='black', edgecolors='black', marker='s') \nplt.scatter(class_1[:,0], class_1[:,1], facecolors='None', edgecolors='black', marker='s') \nplt.title('Input data') \nplt.show() \n```", "```py\n# Train test split and SVM training \nfrom sklearn import cross_validation \nfrom sklearn.svm import SVC \n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.25, random_state=5) \n```", "```py\nparams = {'kernel': 'linear'} \nclassifier = SVC(**params, gamma='auto') \n```", "```py\nclassifier.fit(X_train, y_train) \n```", "```py\nutilities.plot_classifier(classifier, X_train, y_train, 'Training dataset') \nplt.show() \n```", "```py\ny_test_pred = classifier.predict(X_test) \nutilities.plot_classifier(classifier, X_test, y_test, 'Test dataset') \nplt.show()\n```", "```py\nfrom sklearn.metrics import classification_report \n\ntarget_names = ['Class-' + str(int(i)) for i in set(y)]\nprint(\"\\n\" + \"#\"*30)\nprint(\"\\nClassifier performance on training dataset\\n\")\nprint(classification_report(y_train, classifier.predict(X_train), target_names=target_names))\nprint(\"#\"*30 + \"\\n\")\n```", "```py\nprint(\"#\"*30)\nprint(\"\\nClassification report on test dataset\\n\")\nprint(classification_report(y_test, y_test_pred, target_names=target_names))\nprint(\"#\"*30 + \"\\n\")\n```", "```py\nparams = {'kernel': 'linear'} \n```", "```py\nparams = {'kernel': 'poly', 'degree': 3} \n```", "```py\nparams = {'kernel': 'poly', 'degree': 3} \n```", "```py\nparams = {'kernel': 'rbf'} \n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nimport utilities\n```", "```py\ninput_file = 'data_multivar_imbalance.txt' \nX, y = utilities.load_data(input_file) \n\n```", "```py\n# Separate the data into classes based on 'y'\nclass_0 = np.array([X[i] for i in range(len(X)) if y[i]==0])\nclass_1 = np.array([X[i] for i in range(len(X)) if y[i]==1])\n# Plot the input data\nplt.figure()\nplt.scatter(class_0[:,0], class_0[:,1], facecolors='black', edgecolors='black', marker='s')\nplt.scatter(class_1[:,0], class_1[:,1], facecolors='None', edgecolors='black', marker='s')\nplt.title('Input data')\nplt.show()\n```", "```py\nfrom sklearn import model_selection\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=5)\nparams = {'kernel': 'linear'}\nclassifier = SVC(**params, gamma='auto')\nclassifier.fit(X_train, y_train)\nutilities.plot_classifier(classifier, X_train, y_train, 'Training dataset')\nplt.show()\n```", "```py\nfrom sklearn.metrics import classification_report\ntarget_names = ['Class-' + str(int(i)) for i in set(y)]\nprint(\"\\n\" + \"#\"*30)\nprint(\"\\nClassifier performance on training dataset\\n\")\nprint(classification_report(y_train, classifier.predict(X_train), target_names=target_names))\nprint(\"#\"*30 + \"\\n\")\nprint(\"#\"*30)\nprint(\"\\nClassification report on test dataset\\n\")\nprint(classification_report(y_test, y_test_pred, target_names=target_names))\nprint(\"#\"*30 + \"\\n\")\n```", "```py\nparams = {'kernel': 'linear'}\n```", "```py\nparams = {'kernel': 'linear', 'class_weight': 'balanced'}  \n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nimport utilities\n\n# Load input data\ninput_file = 'data_multivar.txt'\nX, y = utilities.load_data(input_file)\n```", "```py\nfrom sklearn import model_selection\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=5)\nparams = {'kernel': 'rbf'}\nclassifier = SVC(**params, gamma='auto')\nclassifier.fit(X_train, y_train)\n```", "```py\ninput_datapoints = np.array([[2, 1.5], [8, 9], [4.8, 5.2], [4, 4], [2.5, 7], [7.6, 2], [5.4, 5.9]])\n```", "```py\nprint(\"Distance from the boundary:\")\nfor i in input_datapoints:\n    print(i, '-->', classifier.decision_function([i])[0])\n```", "```py\n# Confidence measure \nparams = {'kernel': 'rbf', 'probability': True} \nclassifier = SVC(**params, gamma='auto') \n```", "```py\nclassifier.fit(X_train, y_train) \n```", "```py\nprint(\"Confidence measure:\")\nfor i in input_datapoints:\n    print(i, '-->', classifier.predict_proba([i])[0])\n```", "```py\nutilities.plot_classifier(classifier, input_datapoints, [0]*len(input_datapoints), 'Input datapoints', 'True') \n```", "```py\nfrom sklearn import svm\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nimport utilities \n```", "```py\ninput_file = 'data_multivar.txt'\nX, y = utilities.load_data(input_file)\n```", "```py\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=5)\n```", "```py\n# Set the parameters by cross-validation\nparameter_grid = {\"C\": [1, 10, 50, 600],\n                  'kernel':['linear','poly','rbf'],\n                  \"gamma\": [0.01, 0.001],\n                  'degree': [2, 3]}\n```", "```py\nmetrics = ['precision'] \n```", "```py\nfor metric in metrics:\n\n    print(\"#### Grid Searching optimal hyperparameters for\", metric)\n\n    classifier = GridSearchCV(svm.SVC(C=1), \n            parameter_grid, cv=5,scoring=metric,return_train_score=True) \n\n    classifier.fit(X_train, y_train)\n```", "```py\n    print(\"Scores across the parameter grid:\")\n    GridSCVResults = pd.DataFrame(classifier.cv_results_)\n    for i in range(0,len(GridSCVResults)):\n        print(GridSCVResults.params[i], '-->', round(GridSCVResults.mean_test_score[i],3))    \n```", "```py\n    print(\"Highest scoring parameter set:\", classifier.best_params_)\n```", "```py\n#### Grid Searching optimal hyperparameters for precision\nScores across the parameter grid:\n{'C': 1, 'degree': 2, 'gamma': 0.01, 'kernel': 'linear'} --> 0.676\n{'C': 1, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'} --> 0.527\n{'C': 1, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'} --> 0.98\n{'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'linear'} --> 0.676\n{'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'} --> 0.533\n...\n...\n{'C': 600, 'degree': 2, 'gamma': 0.001, 'kernel': 'linear'} --> 0.676\n{'C': 600, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'} --> 0.9\n{'C': 600, 'degree': 2, 'gamma': 0.001, 'kernel': 'rbf'} --> 0.983\n{'C': 600, 'degree': 3, 'gamma': 0.01, 'kernel': 'linear'} --> 0.676\n{'C': 600, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'} --> 0.884\n{'C': 600, 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf'} --> 0.967\n{'C': 600, 'degree': 3, 'gamma': 0.001, 'kernel': 'linear'} --> 0.676\n{'C': 600, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'} --> 0.533\n{'C': 600, 'degree': 3, 'gamma': 0.001, 'kernel': 'rbf'} --> 0.983\nHighest scoring parameter set: {'C': 10, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n```", "```py\n    y_true, y_pred = y_test, classifier.predict(X_test)\n    print(\"Full performance report:\\n\")\n    print(classification_report(y_true, y_pred))\n```", "```py\n# Perform a randomized search on hyper parameters\nfrom sklearn.model_selection import RandomizedSearchCV\nparameter_rand = {'C': [1, 10, 50, 600],\n                  'kernel':['linear','poly','rbf'],\n                  'gamma': [0.01, 0.001],\n                  'degree': [2, 3]}\nmetrics = ['precision']\nfor metric in metrics:\n    print(\"#### Randomized Searching optimal hyperparameters for\", metric)\n    classifier = RandomizedSearchCV(svm.SVC(C=1), \n             param_distributions=parameter_rand,n_iter=30,           \n             cv=5,return_train_score=True)\n    classifier.fit(X_train, y_train)\n    print(\"Scores across the parameter grid:\")\n    RandSCVResults = pd.DataFrame(classifier.cv_results_)\n    for i in range(0,len(RandSCVResults)):\n         print(RandSCVResults.params[i], '-->', \n                 round(RandSCVResults.mean_test_score[i]\n```", "```py\n#### Randomized Searching optimal hyperparameters for precision\nScores across the parameter grid:\n{'kernel': 'rbf', 'gamma': 0.001, 'degree': 2, 'C': 50} --> 0.671\n{'kernel': 'rbf', 'gamma': 0.01, 'degree': 3, 'C': 600} --> 0.951\n{'kernel': 'linear', 'gamma': 0.01, 'degree': 3, 'C': 50} --> 0.591\n{'kernel': 'poly', 'gamma': 0.01, 'degree': 2, 'C': 10} --> 0.804\n...\n...\n{'kernel': 'rbf', 'gamma': 0.01, 'degree': 3, 'C': 10} --> 0.92\n{'kernel': 'poly', 'gamma': 0.001, 'degree': 3, 'C': 600} --> 0.533\n{'kernel': 'linear', 'gamma': 0.001, 'degree': 2, 'C': 10} --> 0.591\n{'kernel': 'poly', 'gamma': 0.01, 'degree': 3, 'C': 50} --> 0.853\n{'kernel': 'linear', 'gamma': 0.001, 'degree': 2, 'C': 600} --> 0.591\n{'kernel': 'poly', 'gamma': 0.01, 'degree': 3, 'C': 10} --> 0.844\nHighest scoring parameter set: {'kernel': 'rbf', 'gamma': 0.01, 'degree': 3, 'C': 600}\n```", "```py\n print(\"Highest scoring parameter set:\", classifier.best_params_)\n y_true, y_pred = y_test, classifier.predict(X_test)\n print(\"Full performance report:\\n\")\n print(classification_report(y_true, y_pred))\n\n```", "```py\nimport numpy as np \nfrom sklearn import preprocessing \nfrom sklearn.svm import SVC \n\ninput_file = 'building_event_binary.txt' \n\n# Reading the data \nX = [] \ncount = 0 \nwith open(input_file, 'r') as f: \n    for line in f.readlines(): \n        data = line[:-1].split(',') \n        X.append([data[0]] + data[2:]) \n\nX = np.array(X) \n```", "```py\n# Convert string data to numerical data \nlabel_encoder = []  \nX_encoded = np.empty(X.shape) \nfor i,item in enumerate(X[0]): \n    if item.isdigit(): \n        X_encoded[:, i] = X[:, i] \n    else: \n        label_encoder.append(preprocessing.LabelEncoder()) \n        X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i]) \n\nX = X_encoded[:, :-1].astype(int) \ny = X_encoded[:, -1].astype(int) \n```", "```py\n# Build SVM \nparams = {'kernel': 'rbf', 'probability': True, 'class_weight': 'balanced'}  \nclassifier = SVC(**params, gamma='auto') \nclassifier.fit(X, y) \n```", "```py\nfrom sklearn import model_selection\n\naccuracy = model_selection.cross_val_score(classifier, \n        X, y, scoring='accuracy', cv=3)\nprint(\"Accuracy of the classifier: \" + str(round(100*accuracy.mean(), 2)) + \"%\")\n```", "```py\n# Testing encoding on single data instance\ninput_data = ['Tuesday', '12:30:00','21','23']\ninput_data_encoded = [-1] * len(input_data)\ncount = 0\n\nfor i,item in enumerate(input_data):\n    if item.isdigit():\n        input_data_encoded[i] = int(input_data[i])\n    else:\n        input_data_encoded[i] = int(label_encoder[count].transform([input_data[i]]))\n        count = count + 1 \n\ninput_data_encoded = np.array(input_data_encoded)\n\n# Predict and print(output for a particular datapoint\noutput_class = classifier.predict([input_data_encoded])\nprint(\"Output class:\", label_encoder[-1].inverse_transform(output_class)[0])\n```", "```py\nAccuracy of the classifier: 93.95%\nOutput class: noevent  \n```", "```py\nAccuracy of the classifier: 65.33%\nOutput class: eventA\n```", "```py\n# SVM regressor to estimate traffic \n\nimport numpy as np \nfrom sklearn import preprocessing \nfrom sklearn.svm import SVR \n\ninput_file = 'traffic_data.txt' \n\n# Reading the data \nX = [] \ncount = 0 \nwith open(input_file, 'r') as f: \n    for line in f.readlines(): \n        data = line[:-1].split(',') \n        X.append(data) \n\nX = np.array(X) \n```", "```py\n# Convert string data to numerical data \nlabel_encoder = []  \nX_encoded = np.empty(X.shape) \nfor i,item in enumerate(X[0]): \n    if item.isdigit(): \n        X_encoded[:, i] = X[:, i] \n    else: \n        label_encoder.append(preprocessing.LabelEncoder()) \n        X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i]) \n\nX = X_encoded[:, :-1].astype(int) \ny = X_encoded[:, -1].astype(int) \n```", "```py\n# Build SVR \nparams = {'kernel': 'rbf', 'C': 10.0, 'epsilon': 0.2}  \nregressor = SVR(**params) \nregressor.fit(X, y) \n```", "```py\n# Cross validation\nimport sklearn.metrics as sm\n\ny_pred = regressor.predict(X)\nprint(\"Mean absolute error =\", round(sm.mean_absolute_error(y, y_pred), 2))\n```", "```py\n# Testing encoding on single data instance\ninput_data = ['Tuesday', '13:35', 'San Francisco', 'yes']\ninput_data_encoded = [-1] * len(input_data)\ncount = 0\nfor i,item in enumerate(input_data):\n    if item.isdigit():\n        input_data_encoded[i] = int(input_data[i])\n    else:\n        input_data_encoded[i] = int(label_encoder[count].transform([input_data[i]]))\n        count = count + 1 \n\ninput_data_encoded = np.array(input_data_encoded)\n\n# Predict and print output for a particular datapoint\nprint(\"Predicted traffic:\", int(regressor.predict([input_data_encoded])[0]))\n```", "```py\n Mean absolute error = 4.08\n    Predicted traffic: 29\n```", "```py\nfrom sklearn import datasets\nfrom sklearn import model_selection\nimport tensorflow as tf\n```", "```py\niris = datasets.load_iris()\n```", "```py\nx_train, x_test, y_train, y_test = model_selection.train_test_split(iris.data, \n                                                                    iris.target, \n                                                                    test_size=0.7, \n                                                                    random_state=1)\n```", "```py\nfeature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\nclassifier_tf = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns, \n                                                 hidden_units=[10], \n                                                 n_classes=3)\n```", "```py\nclassifier_tf.fit(x_train, y_train, steps=5000)\n```", "```py\npredictions = list(classifier_tf.predict(x_test, as_iterable=True))\n```", "```py\nn_items = y_test.size\naccuracy = (y_test == predictions).sum() / n_items\nprint(\"Accuracy :\", accuracy)\n```", "```py\nAccuracy : 0.9333333333333333\n```", "```py\nfrom heamy.dataset import Dataset\nfrom heamy.estimator import Regressor\nfrom heamy.pipeline import ModelsPipeline\n\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n```", "```py\ndata = load_boston()\n```", "```py\nX, y = data['data'], data['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\n```", "```py\nData = Dataset(X_train,y_train,X_test)\n```", "```py\nRfModel = Regressor(dataset=Data, estimator=RandomForestRegressor, parameters={'n_estimators': 50},name='rf')\nLRModel = Regressor(dataset=Data, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n```", "```py\nPipeline = ModelsPipeline(RfModel,LRModel)\nStackModel = Pipeline.stack(k=10,seed=2)\n```", "```py\nStacker = Regressor(dataset=StackModel, estimator=LinearRegression)\n```", "```py\nResults = Stacker.predict()\nResults = Stacker.validate(k=10,scorer=mean_absolute_error)\n```"]