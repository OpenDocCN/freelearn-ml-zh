- en: '*Chapter 8*: Choosing Real-Time versus Batch Scoring'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*：选择实时评分与批量评分'
- en: 'As you have experienced in the previous chapters, training AutoML models is
    simple and straightforward. Whether you choose to train a model using the **Azure
    Machine Learning Studio** (**AMLS**) **GUI** or code an AutoML solution in Python
    using Jupyter, you can build highly accurate **machine learning** (**ML**) models
    in minutes. However, you still need to learn how to deploy them. In Azure, there
    are two main ways you can deploy a previously trained ML model to score new data:
    **real-time** and **batch**.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在前几章中体验到的，训练AutoML模型简单直接。无论你选择使用**Azure机器学习工作室**（**AMLS**）**GUI**来训练模型，还是在Python中使用Jupyter编写AutoML解决方案的代码，你都可以在几分钟内构建高度准确的机器学习（ML）模型。然而，你仍然需要学习如何部署它们。在Azure中，你可以将之前训练好的机器学习模型以**实时**和**批量**两种方式部署到新数据的评分中。
- en: In this chapter, you will begin by learning what a **batch scoring solution**
    is, when to use it, and when it makes sense to retrain batch models. Continuing,
    you will learn what a **real-time scoring solution** is, when to use it, and when
    it makes sense to retrain real-time models. Finally, you will conclude by reading
    a variety of different scenarios and determining which type of scoring you should
    use. All scenarios are based on common problems faced by real companies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将首先学习什么是**批量评分解决方案**，何时使用它，以及何时重新训练批量模型是有意义的。接着，你将学习什么是**实时评分解决方案**，何时使用它，以及何时重新训练实时模型是有意义的。最后，你将通过阅读各种不同的场景，确定应该使用哪种类型的评分。所有场景都是基于真实公司面临的常见问题。
- en: 'By the time you finish this chapter, you will have gained an invaluable skill:
    being able to identify when you should build a batch scoring solution and when
    you should build a real-time solution.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到你完成本章时，你将获得一项宝贵的技能：能够识别何时应该构建批量评分解决方案，何时应该构建实时解决方案。
- en: Batch scoring scenarios require you to build ML pipelines, which you will learn
    about in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129)*, Implementing a
    Batch Scoring Solution*. Real-time scoring scenarios, on the other hand, require
    you to build real-time scoring endpoints hosted on **Azure Kubernetes Service**
    (**AKS**), which are covered in [*Chapter 11*](B16595_11_ePub.xhtml#_idTextAnchor172)*,
    Implementing a Real-Time Scoring Solution*. Many times, organizations mistakenly
    implement the wrong type of solution, but you will be available to avoid that
    pitfall.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 批量评分场景需要你构建机器学习（ML）管道，你将在[*第9章*](B16595_09_ePub.xhtml#_idTextAnchor129)*，实现批量评分解决方案*中学习到这方面的内容。另一方面，实时评分场景需要你在**Azure
    Kubernetes服务**（**AKS**）上构建实时评分端点，这将在[*第11章*](B16595_11_ePub.xhtml#_idTextAnchor172)*，实现实时评分解决方案*中介绍。很多时候，组织错误地实施了错误类型的解决方案，但你将能够避免这种陷阱。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Architecting batch scoring solutions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构批量评分解决方案
- en: Architecting real-time scoring solutions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构实时评分解决方案
- en: Determining batch versus real-time scoring scenarios
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定批量与实时评分场景
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: '[*Chapter 7*](B16595_07_ePub.xhtml#_idTextAnchor094)*, Using the Many Models
    Solution Accelerator*, featured a lot of heavy Python coding. This chapter is
    a bit of a reprieve; you will not be coding, but you will be learning important
    skills through reading business scenarios and applying the proper solutions. As
    such, there are no technical requirements in this chapter.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第7章*](B16595_07_ePub.xhtml#_idTextAnchor094)*，使用多模型解决方案加速器*，涉及大量的复杂Python编程。本章提供了一些喘息的机会；你将不会进行编码，而是通过阅读业务场景和应用适当的解决方案来学习重要的技能。因此，本章没有技术要求。'
- en: Architecting batch scoring solutions
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构批量评分解决方案
- en: '**Batch inferencing** refers to scoring new data points in batches on a recurring
    time-based schedule. New data is collected over time and subsequently scored,
    generating new predictions. This is the most common way modern companies use ML
    models.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**批量推理**是指在基于时间周期性重复的批次上对新数据点进行评分。随着时间的推移收集新数据，然后进行评分，生成新的预测。这是现代公司使用机器学习模型最常见的方式。'
- en: In this section, you will learn how to architect a complete, end-to-end batch
    scoring solution using Azure AutoML-trained models. You will also learn why, and
    in what situations, you should prioritize batch scoring over real-time scoring
    solutions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用Azure AutoML训练的模型架构一个完整的、端到端的批量评分解决方案。你还将了解为什么以及在什么情况下应该优先考虑批量评分而不是实时评分解决方案。
- en: Understanding the five-step batch scoring process
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解五步批量评分流程
- en: 'Each batch scoring solution you make should follow a five-step process. This
    process begins by training and registering an ML model as you did in the previous
    chapters using AMLS. Regression, classification, and forecasting models all follow
    the same pattern. In order, the five steps are as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您制作的每个批量评分解决方案都应该遵循一个五步流程。这个过程从使用AMLS训练并注册一个机器学习模型开始，就像您在前几章中所做的那样。回归、分类和预测模型都遵循相同的模式。依次的五步如下：
- en: '**Train a model**. You can train a model either using the AMLS GUI as you did
    in [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044)*, Training Your First
    AutoML Model*, or using Python on a compute instance as you did in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*,
    Building an AutoML Regression Solution*, [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068)*,
    Building an AutoML Classification Solution*, and [*Chapter 6*](B16595_06_ePub.xhtml#_idTextAnchor081)*,
    Building an AutoML Forecasting Solution*.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练模型**。您可以使用与[*第3章*](B16595_03_ePub.xhtml#_idTextAnchor044)*“训练您的第一个AutoML模型”中相同的方式，使用AMLS图形用户界面进行模型训练，或者使用计算实例上的Python进行训练，就像在[*第4章*](B16595_04_ePub.xhtml#_idTextAnchor056)*“构建AutoML回归解决方案”、[*第5章*](B16595_05_ePub.xhtml#_idTextAnchor068)*“构建AutoML分类解决方案”和[*第6章*](B16595_06_ePub.xhtml#_idTextAnchor081)*“构建AutoML预测解决方案”中所做的那样。'
- en: '**Register your model**. Once again, you can accomplish this either with the
    AMLS GUI or by using Python running on a compute instance. Registering a model
    saves it to your AMLS workspace and lets you reference it later.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注册您的模型**。同样，您可以使用AMLS图形用户界面或通过在计算实例上运行的Python来完成这项任务。注册一个模型将其保存到您的AMLS工作空间，并允许您稍后引用它。'
- en: '**Determine a schedule**. Common schedules for batch inferencing are hourly,
    weekly, or monthly, although you may want to schedule it more or less frequently
    based on the needs of your business problem.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**确定时间表**。批量推理的常见时间表是每小时、每周或每月，尽管您可能需要根据业务问题的需求更频繁或更少地安排它。'
- en: '**Score data in batches**. Batch sizes run anywhere from a single data point
    to billions of data points at once. This step is where you run your batch inferencing
    code. In Azure, we use ML pipelines. You will learn how to code ML pipelines in
    [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129)*, Implementing a Batch Scoring
    Solution*.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**批量评分数据**。批量大小可以从一个数据点到一次处理数十亿个数据点不等。这一步是您运行批量推理代码的地方。在Azure中，我们使用机器学习管道。您将在[*第9章*](B16595_09_ePub.xhtml#_idTextAnchor129)*“实现批量评分解决方案”中学习如何编码机器学习管道。'
- en: '**Deliver results**. Once you run your ML pipeline and make new predictions
    or forecasts, you need to send those results to either a report or a database.
    In Azure, sending results from AMLS to other databases is done with a tool called
    **Azure Data Factory** (**ADF**). You will learn how to use ADF in [*Chapter 10*](B16595_10_ePub.xhtml#_idTextAnchor151)*,
    Creating End-to-End AutoML Solutions*.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**交付结果**。一旦您运行了机器学习管道并做出了新的预测或预测，您需要将这些结果发送到报告或数据库。在Azure中，使用名为**Azure Data
    Factory**（**ADF**）的工具将AMLS的结果发送到其他数据库。您将在[*第10章*](B16595_10_ePub.xhtml#_idTextAnchor151)*“创建端到端AutoML解决方案”中学习如何使用ADF。'
- en: '*Figure 8.1* shows the whole end-to-end process. While you will implement a
    batch inference solution for your AutoML-trained models, you can use this same
    process to deploy any ML model. The key to ensuring the success of your solution
    lies in aligning your batch job schedule with the needs of your business:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.1*展示了整个端到端过程。虽然您将为您的AutoML训练模型实现批量推理解决方案，但您可以使用相同的过程部署任何机器学习模型。确保您解决方案成功的关键在于将您的批量作业时间表与您的业务需求相匹配：'
- en: '![Figure 8.1 – Batch scoring process ](img/Figure_8.1_B16595.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 批量评分过程](img/Figure_8.1_B16595.jpg)'
- en: Figure 8.1 – Batch scoring process
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 批量评分过程
- en: Now that you know the process, it's time to dive deeper into each of the steps.
    You're already familiar with training AutoML models and registering them to your
    AMLS workspace. Next, you will learn what to take into consideration when determining
    the schedule of your batch scoring solution.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了这个过程，是时候深入了解每一步了。您已经熟悉了训练AutoML模型并将它们注册到您的AMLS工作空间中。接下来，您将学习在确定批量评分解决方案的时间表时需要考虑哪些因素。
- en: Scheduling your batch scoring solution
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安排您的批量评分解决方案
- en: Ultimately, you have trained an AutoML model to meet some business goal. Perhaps
    you need to decide which products to keep in your lineup and which ones to drop.
    Maybe you need to forecast product demand over the next quarter. You may be in
    charge of a professional sports team and need to decide which players to draft
    for the upcoming season. In any case, you need to make sure that you schedule
    your batch inferencing job in a way that makes sense and meets your business needs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你已经训练了一个AutoML模型来满足某些商业目标。也许你需要决定保留哪些产品以及淘汰哪些产品。也许你需要预测下季度的产品需求。你可能负责一支职业体育队伍，需要决定为即将到来的赛季挑选哪些球员。无论如何，你需要确保以合理的方式安排你的批量推理作业，以满足你的商业需求。
- en: 'The key to determining when you should schedule your job is based on three
    things:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 确定何时安排你的作业的关键基于三个因素：
- en: How often the business needs to make the decision
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业需要做出决策的频率
- en: Data availability
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可用性
- en: How long your batch scoring job takes to run
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的批量评分作业运行所需的时间
- en: First, you need to know how often the business makes the decision that your
    model is trying to assist. In the case of a professional sports team making a
    drafting decision, this means that you only need to run your job once a year.
    If you work for a business that decides its product mix on a quarterly basis,
    your product demand model should be scheduled to run four times a year. Likewise,
    if you built a model for a fast food restaurant that tells them what food they
    should prepare for the next hour, your batch inferencing solution should run every
    hour. How often you run your model is called **model cadence**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要知道业务多久做出一次决策，以帮助你的模型。对于一个职业体育队伍做出选秀决策的情况，这意味着你只需要每年运行一次作业。如果你为一家每季度决定其产品组合的企业工作，你的产品需求模型应该安排每年运行四次。同样，如果你为一家快餐店构建了一个模型，告诉他们为下一小时准备什么食物，你的批量推理解决方案应该每小时运行一次。你运行模型频率被称为**模型节奏**。
- en: Second, you need to make sure that new data is available for your model to score.
    This is called **data availability**. Even if your business problem requires new
    predictions to be made once an hour, if your data only refreshes once a day, you
    should build a model that scores data once a day. In other words, you would need
    to train a forecasting model that predicts 24 hours out and scores it once a day
    instead of a forecasting model that predicts 1 hour out that runs 24 times a day.
    Always figure out data availability at the onset of your project. It will save
    you a lot of time.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，你需要确保有新的数据可供你的模型评分。这被称为**数据可用性**。即使你的业务问题要求每小时做出新的预测，如果你的数据只每天刷新一次，你应该构建一个每天评分一次数据的模型。换句话说，你需要训练一个预测24小时并每天评分一次的预测模型，而不是一个预测1小时并每天运行24次的预测模型。始终在项目开始时确定数据可用性。这将为你节省大量时间。
- en: Lastly, you need to pay attention to how long your batch job runs. Even if you
    want to score data every 5 minutes and you have new data available every 5 minutes,
    if your batch scoring job takes 10 minutes to complete you'll be limited in how
    often you can score and deliver results. In this case, consider switching to a
    real-time solution.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你需要注意你的批量作业运行的时间。即使你希望每5分钟评分一次数据，并且每5分钟就有新的数据可用，如果你的批量评分作业需要10分钟才能完成，你将限制评分和交付结果的频率。在这种情况下，考虑切换到实时解决方案。
- en: Once you've determined your model cadence, data availability, and how long your
    batch job takes to run, the next step is to figure out when your job should run
    – down to the second.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定了模型的节奏、数据的可用性以及你的批量作业运行所需的时间，下一步就是确定你的作业应该在何时运行——精确到秒。
- en: In an ideal world, you would only run your model once all relevant data is available.
    For the professional sports example, you would want to have data on all players
    in the draft. For the hourly restaurant data, you would want up-to-the-minute
    foot-traffic, sales, weather, and traffic data to make your prediction.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个理想的世界里，你会在所有相关数据都可用时才运行你的模型。对于职业体育的例子，你希望拥有所有选秀球员的数据。对于每小时餐厅数据，你希望有最新的客流量、销售额、天气和交通数据来做出你的预测。
- en: In the real world, however, you should always expect that there will be data
    availability issues. Some player data will be randomly missing. Sometimes, weather
    or foot-traffic data will be late for no reason at all. Sales data may be corrupted
    by canceled orders or maxed-out credit cards. For this reason, you should simply
    schedule your job to run at the last possible second it can. Make sure you include
    a buffer to account for **compute cluster startup time**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现实世界中，您应该始终预期会出现数据可用性问题。某些玩家数据可能会随机缺失。有时，天气或人流量数据可能会无故迟到。销售数据可能会因取消订单或信用额度用尽而损坏。因此，您应该简单地安排您的作业在最后可能的一刻运行。确保您包括一个缓冲时间来考虑**计算集群启动时间**。
- en: Compute cluster startup time can vary substantially, so it's important that
    you run a lot of tests on your solution to get an idea of the maximum time it
    will take to spin up. Set your buffer to the maximum time your cluster takes to
    start up, so long as it seems reasonable. Usually, this should be no more than
    5 to 10 minutes. If it takes longer, open a support ticket. This way, you will
    ensure your job always runs on time.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 计算集群的启动时间可能会有很大差异，因此您在解决方案上运行大量测试以了解启动所需的最大时间是很重要的。将您的缓冲时间设置为集群启动所需的最大时间，只要这看起来合理。通常，这不应超过5到10分钟。如果需要更长的时间，请提交支持工单。这样，您可以确保您的作业始终按时运行。
- en: Important tip
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: While you can set your minimum compute cluster nodes to `1` to achieve a faster,
    more consistent ramp-up time, this means that you are paying for usage 24 hours
    a day, 7 days a week, negating the cost savings advantage inherent to batch solutions.
    Setting compute cluster nodes to `0` will lead to substantial cost savings over
    time.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以设置您的最小计算集群节点数为`1`以实现更快、更一致的加速时间，但这意味着您每天24小时、每周7天都在付费，抵消了批量解决方案固有的成本节约优势。将计算集群节点数设置为`0`将随着时间的推移带来实质性的成本节约。
- en: By scheduling your job to run right around the same time the business will be
    reviewing your predictions to assist their decision making, you give as much time
    as possible for systems upstream to collect, transform, and fix data. You also
    give the business the best predictions you can, based on the most up-to-date data.
    You also need to consider how to batch score data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过安排您的作业在业务将审查您的预测以协助其决策的同一时间运行，您为上游系统收集、转换和修复数据提供了尽可能多的时间。您还基于最新的数据提供了尽可能好的预测。您还需要考虑如何批量评分数据。
- en: Scoring data in batches and delivering results
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批量评分数据和交付结果
- en: Within AMLS, batch scoring takes place within an ML pipeline. ML pipelines require
    you to specify an environment, write a scoring script that accesses your model,
    and write results to a datastore, most likely to a filesystem sitting on a blob
    container in an Azure storage account in the form of a CSV file. You will learn
    how to do all of this in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129)*,
    Implementing a Batch Scoring Solution*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在AMLS中，批量评分发生在ML管道内。ML管道要求您指定一个环境，编写一个评分脚本以访问您的模型，并将结果写入数据存储，最可能的是写入Azure存储账户中blob容器上的文件系统，以CSV文件的形式。您将在[*第9章*](B16595_09_ePub.xhtml#_idTextAnchor129)“实现批量评分解决方案”中学习如何完成所有这些操作。
- en: However, running an ML pipeline only generates and stores predictions. It is
    not the same as delivering results. Consulting the business directly is the best
    way to determine where your data should ultimately land. Sometimes, they will
    want you to store your predictions in a SQL database to which they have direct
    access. Other times, they will want to receive an Excel file in their email. Often,
    they will ask you to push the results to a web application accessible by their
    mobile device.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，运行机器学习（ML）管道仅仅生成和存储预测结果。这并不等同于交付结果。直接咨询业务部门是确定您的数据最终应放置何处的最佳方式。有时，他们可能希望您将预测存储在他们可以直接访问的SQL数据库中。其他时候，他们可能希望通过电子邮件收到Excel文件。通常，他们会要求您将结果推送到他们可以通过移动设备访问的Web应用程序。
- en: AMLS itself can write results directly to Azure Data Lake Storage accounts (Gen
    1 and Gen 2), Azure SQL databases, Azure Blob storage, Azure file shares, Azure
    PostGreSQL, Azure Database for MySQL, and Databricks filesystems. ML pipelines
    can move data directly into these types of storage. That's all, though; you cannot
    directly move data out of Azure with an ML pipeline alone.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: AMLS本身可以直接将结果写入Azure Data Lake Storage账户（第一代和第二代）、Azure SQL数据库、Azure Blob存储、Azure文件共享、Azure
    PostGreSQL、Azure Database for MySQL和Databricks文件系统。ML管道可以直接将这些类型的数据存储移动到这些存储中。但这仅限于此；仅使用ML管道无法直接将数据从Azure中移出。
- en: Usually, however, business people will request that you land the results of
    your AutoML models someplace else, such as an on-premises database or file share.
    ADF is the perfect tool for moving data both in to and out of Azure. You will
    learn how to use ADF in [*Chapter 10*](B16595_10_ePub.xhtml#_idTextAnchor151)*,
    Creating End-to-End AutoML Solutions*, to solve this common task.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，商业人士会要求你在其他地方落地你的AutoML模型的结果，例如本地数据库或文件共享。ADF是移动数据进入和离开Azure的完美工具。你将在[*第10章*](B16595_10_ePub.xhtml#_idTextAnchor151)“创建端到端AutoML解决方案”中学习如何使用ADF来解决这个问题。
- en: Understanding the process is the first step. The next is to understand when
    and why you should use batch scoring solutions over their real-time counterparts.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这个过程是第一步。接下来，你需要了解何时以及为什么应该使用批量评分解决方案而不是它们的实时对应方案。
- en: Choosing batch over real time
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择批量而非实时
- en: 'Real-time solutions score new data points as they come in. Unlike with batching,
    there is no waiting for a compute cluster to spin up; real-time scoring clusters
    never spin down. As soon as new data comes in, new predictions are automatically
    generated. While this seems like an attractive alternative to batch scoring, there
    are two major reasons why you should prioritize batch inferencing over real-time
    inferencing: cost and complexity.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 实时解决方案在数据点到来时立即对它们进行评分。与批量不同，不需要等待计算集群启动；实时评分集群永远不会关闭。一旦新数据到来，新的预测就会自动生成。虽然这似乎是批量评分的一个有吸引力的替代方案，但有两个主要原因你应该优先考虑批量推理而不是实时推理：成本和复杂性。
- en: When using cloud computing, you are only paying for resources when you need
    them. With batch inferencing, when your job runs, a compute cluster spins up,
    and as soon as it finishes running the job, it spins down. With real-time inferencing,
    your cluster will be up and running 24 hours a day, 7 days a week. This means
    that real-time inferencing solutions are orders of magnitude more costly than
    their batch inferencing equivalents.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用云计算时，你只有在需要时才为资源付费。对于批量推理，当你的作业运行时，一个计算集群会启动，一旦作业运行完成，它就会关闭。对于实时推理，你的集群将全天候运行，每周7天。这意味着实时推理解决方案的成本比它们的批量推理等效方案高得多。
- en: Complexity is also a key issue. With batch solutions, all you need to do is
    move new data into your Azure datastore, score it, and send it off to another
    database for final delivery. This is an easy, repeatable pattern applicable to
    a wide array of problems.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂性也是一个关键问题。对于批量解决方案，你只需要将新数据移动到你的Azure数据存储中，对其进行评分，然后发送到另一个数据库进行最终交付。这是一个简单、可重复的模式，适用于广泛的问题。
- en: Real-time solutions, on the other hand, are never as straightforward. At the
    heart of any real-time solution is a **scoring endpoint**. These endpoints can
    be used anywhere in any piece of code. Sometimes, you'll want to integrate them
    with a web application; other times, you'll want to integrate them with an application
    that supports streaming data that never stops flowing in. Whereas batch scoring
    solutions follow a cookie cutter template, real-time solutions are usually more
    complex and unique.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，实时解决方案从来都不是那么简单直接。任何实时解决方案的核心都是一个**评分端点**。这些端点可以在任何代码的任何地方使用。有时，你可能希望将它们集成到Web应用程序中；其他时候，你可能希望将它们集成到支持持续流动数据的应用程序中。而批量评分解决方案遵循的是一种标准模板，实时解决方案通常更复杂且独特。
- en: 'To recap, batch scoring solutions have the following advantages over real-time
    solutions:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，批量评分解决方案相对于实时解决方案有以下优势：
- en: They are cheaper to run.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行成本更低。
- en: They are less complex.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构更简单。
- en: They are easy to replicate as they follow a boilerplate.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们很容易复制，因为它们遵循一个模板。
- en: Now that you have a handle on what batch inferencing solutions are and why you
    should use them, it's time to look at real-time solutions. Real-time solutions
    aren't as prevalent as batch ones, but they do exclusively support plenty of use
    cases. They're also powerful, require thought, and are fun to create.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了批量推理解决方案是什么以及为什么应该使用它们，是时候看看实时解决方案了。实时解决方案不像批量解决方案那样普遍，但它们确实专门支持大量的用例。它们也非常强大，需要深思熟虑，并且创建起来很有趣。
- en: Architecting real-time scoring solutions
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构实时评分解决方案
- en: '**Real-time inferencing** refers to scoring new data points as they arrive
    instead of on a time-based schedule. New data flows in, new predictions come out.
    While not as common as batch inferencing, real-time inferencing is used by companies
    in a number of scenarios such as credit card fraud detection, anomaly detection
    on the factory floor, and recommending products when you''re online shopping.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**实时推理**指的是在数据点到达时进行评分，而不是基于时间表进行评分。新数据流入，新的预测结果产生。虽然不如批量推理常见，但实时推理在许多场景中被公司使用，例如信用卡欺诈检测、工厂地面的异常检测，以及在线购物时推荐产品。'
- en: In this section, you will learn how to architect a complete, end-to-end real-time
    scoring solution using Azure AutoML-trained models. You will also learn why, and
    in what situations, you should prioritize real-time scoring over batch scoring
    solutions.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何使用Azure AutoML训练的模型构建一个完整、端到端的实时评分解决方案。您还将了解为什么以及在什么情况下，您应该优先考虑实时评分而不是批量评分解决方案。
- en: Understanding the four-step real-time scoring process
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解四步实时评分过程
- en: 'Real-time scoring solutions follow a slightly different process than batch
    scoring solutions. There are only four steps. Like batch solutions, the process
    begins by training an ML model and registering it as you did in previous chapters.
    You can use any type of ML model, including regression, classification, and forecasting,
    all of which follow the same pattern. The four steps are as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 实时评分解决方案遵循与批量评分解决方案略有不同的流程。只有四个步骤。与批量解决方案一样，该过程从训练一个ML模型并将其注册，就像您在前几章中所做的那样开始。您可以使用任何类型的ML模型，包括回归、分类和预测，它们都遵循相同的模式。以下四个步骤如下：
- en: '**Train a model**. When training a model for deployment in real time, pay extra
    attention to what data will be available to your model at the time of scoring.
    It''s easy to mistakenly include data that, realistically, won''t always be available
    to a real-time solution.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练模型**。当训练用于实时部署的模型时，请特别注意在评分时模型将可用的数据。错误地包含那些实际上不会始终可用给实时解决方案的数据是很常见的。'
- en: '**Register your model**. You can register with either the AMLS GUI or with
    Python code running on a Jupyter notebook in a compute instance.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注册您的模型**。您可以使用AMLS图形用户界面或在一个计算实例中运行的Python代码进行注册。'
- en: '**Score data in real time**. This step is where you run your real-time inferencing
    code. In Azure, we use AKS to create a real-time scoring endpoint. You will learn
    how to create and use AKS and real-time scoring endpoints in [*Chapter 11*](B16595_11_ePub.xhtml#_idTextAnchor172)*,
    Implementing a Real-Time Scoring Solution*.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实时评分数据**。这一步是您运行实时推理代码的地方。在Azure中，我们使用AKS创建实时评分端点。您将在[*第11章*](B16595_11_ePub.xhtml#_idTextAnchor172)“实现实时评分解决方案”中学习如何创建和使用AKS以及实时评分端点。'
- en: '**Deliver results**. Delivering results in real time is quite different from
    delivering results in batches, and is problem dependent. Usually, the results
    will be displayed on some user-facing app. In other cases, your results will be
    funneled to a database that triggers an alert if a condition is met. Think about
    how you may receive a text message if an algorithm detects fraudulent credit card
    usage on your account.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**交付结果**。实时交付结果与批量交付结果有很大不同，并且取决于问题。通常，结果将显示在某个面向用户的应用程序上。在其他情况下，您的结果将被输送到一个数据库中，如果满足条件，则会触发警报。想想看，如果算法检测到您的账户上有欺诈性的信用卡使用，您可能会收到短信。'
- en: '*Figure 8.2* shows the whole end-to-end process. While you will implement a
    real-time inference solution for your AutoML-trained models, you can use this
    same process to deploy any ML model in real time. The key to ensuring the success
    of your solution lies in aligning your real-time solution with the needs of your
    business:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.2*显示了整个端到端过程。虽然您将为AutoML训练的模型实现实时推理解决方案，但您可以使用此相同的过程来实时部署任何ML模型。确保您解决方案成功的关键在于将您的实时解决方案与您的业务需求相一致：'
- en: '![Figure 8.2 – Real-time scoring process](img/Figure_8.2_B16595.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 实时评分过程](img/Figure_8.2_B16595.jpg)'
- en: Figure 8.2 – Real-time scoring process
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 实时评分过程
- en: Now that you know the process, it's time to dive deeper into each of the steps.
    First, you need to review the unique considerations of training a model for real-time
    deployment.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了这个过程，是时候深入了解每个步骤了。首先，您需要回顾为实时部署训练模型时的独特考虑因素。
- en: Training a model for real-time deployment
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为实时部署训练模型
- en: When you train a model for deployment in real time using AutoML or a custom
    ML model, the single most important consideration is the availability of your
    data. Batch scoring solutions do not run that often; data builds up, and you pass
    it in all at once. With a real-time solution, data is constantly being generated
    and constantly being scored. Thus, you need to ask yourself if your solution will
    always have timely access to data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用AutoML或自定义ML模型训练用于实时部署的模型时，最重要的考虑因素是数据可用性。批量评分解决方案并不经常运行；数据会积累，你一次将它们全部传递。在实时解决方案中，数据不断生成和评分。因此，你需要问自己，你的解决方案是否始终能够及时访问数据。
- en: A great example of this is real-time scoring for fast-food product demand on
    a minute-by-minute basis. One of the greatest predictors of demand is how many
    cars are currently lined up in the drive-thru line. If you have reliable video
    technology that can record the cars, count them, and deliver them to your real-time
    scoring endpoint on a minute-by-minute basis, by all means, you should use that
    data. If, however, the video feed takes 3-5 minutes to deliver that piece of data,
    you shouldn't use it for minute-by-minute scoring.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的例子是按分钟实时评分快餐产品需求。需求的最大预测因素之一是当前排队在快车道上的汽车数量。如果你有可靠的视频技术可以记录汽车、计数并将它们按分钟传递到你的实时评分端点，那么你应该使用这些数据。然而，如果视频流需要3-5分钟才能传递这些数据，那么你不应该用它进行按分钟评分。
- en: Therefore, at the onset of every project, you should spend a lot of time figuring
    out what data will be available to you and when. This is another type of data
    availability problem. If your data will be available to match the cadence at which
    it will be scored, use it. If not, discard it. Furthermore, if data is only sometimes
    available due to reliability issues, such as a weather API that often returns
    null values, discard it.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在每一个项目的开始阶段，你应该花大量时间去弄清楚你将何时以及如何获得哪些数据。这是另一种数据可用性问题。如果你的数据将在评分的节奏下可用，请使用它。如果不行，请丢弃它。此外，如果由于可靠性问题（例如，一个经常返回空值的天气API）数据有时才可用，请丢弃它。
- en: You should now have a firm understanding of the importance of data availability
    for real-time scoring. It's time to think about how you should score data and
    deliver results.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该对数据可用性对于实时评分的重要性有了一个明确的理解。现在是时候考虑你应该如何评分数据和交付结果了。
- en: Delivering results in real time
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时交付结果
- en: Creating a real-time solution with AMLS means creating an AKS-hosted real-time
    scoring endpoint. You will learn more on this topic in [*Chapter 11*](B16595_11_ePub.xhtml#_idTextAnchor172)*,
    Implementing a Real-Time Scoring Solution*. A **scoring endpoint** is a web service
    into which you pass data to generate predictions. Once created, you can place
    these endpoints anywhere, in any piece of code.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AMLS创建实时解决方案意味着创建一个由AKS托管的实时评分端点。你将在[*第11章*](B16595_11_ePub.xhtml#_idTextAnchor172)“实现实时评分解决方案”中了解更多关于这个主题的内容。**评分端点**是一个你可以传递数据以生成预测的Web服务。一旦创建，你可以在任何代码片段中放置这些端点。
- en: 'Most often, the results of a real-time scoring solution are going to be embedded
    within an app. You should always consider three things when thinking about delivery:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，实时评分解决方案的结果将被嵌入到应用程序中。在考虑交付时，你应该始终考虑以下三个因素：
- en: Is a human or an automated system receiving your predictions?
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是人类还是自动化系统接收你的预测？
- en: How will a human receive your results?
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类将如何接收你的结果？
- en: What will an automated system do with your predictions?
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化系统会对你的预测做些什么？
- en: In the case where a human being receives your predictions, you need to determine
    how they expect to receive them. Usually, it is through some sort of application
    that they can access on their PC or mobile device. Predictions in a restaurant
    are likely to be displayed on an in-store app facing the workers. Predictions
    on a factory floor are likely to be sent to mobile devices.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在人类接收你的预测的情况下，你需要确定他们期望如何接收它们。通常，是通过他们可以在PC或移动设备上访问的应用程序。餐厅中的预测可能显示在面向员工的店内应用程序上。工厂车间的预测可能发送到移动设备上。
- en: In the case where your predictions are being sent to an automated system, you
    need to figure out if the system will send an alert to humans based on some events,
    or if the predictions will merely be used to control some process. If it is the
    latter, you only need to write code to move predictions to the appropriate database
    used by that process.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的预测被发送到自动化系统的情况下，您需要弄清楚系统是否会根据某些事件向人类发送警报，或者预测是否仅用于控制某些流程。如果是后者，您只需要编写将预测移动到该流程使用的适当数据库的代码。
- en: On the other hand, if the automated system needs to alert humans, you need to
    decide which events humans will be alerted to. Think of credit card fraud detection.
    You would only want to alert users of a fraudulent transaction; you wouldn't want
    to inundate them with alerts for every transaction.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果自动化系统需要向人类发送警报，您需要决定人类将收到哪些事件的警报。以信用卡欺诈检测为例。您只想提醒用户有欺诈交易；您不希望他们被每个交易的警报淹没。
- en: With the importance of delivery in mind, you next need to develop a strong grasp
    of when to use real-time scoring solutions over their batch equivalents.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到交付的重要性，您接下来需要深入了解何时使用实时评分解决方案而不是它们的批量等效方案。
- en: Knowing when to use real-time scoring
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解何时使用实时评分
- en: Batch inferencing is the default type of scoring that data scientists use. This
    is because it's cheap, reliable, and easy to replicate. However, many situations
    mandate real-time inferencing. The key question to ask yourself is, "*Once the
    data becomes available, how much time do I have to give the business a prediction?*"
    This is really the only consideration. From the moment new data is available and
    ready to be scored, if users expect to have results in a period of time that cannot
    be achieved with batch scoring, you must use real-time scoring.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 批量推理是数据科学家使用的默认评分类型。这是因为它成本低、可靠且易于复制。然而，许多情况要求实时推理。关键问题是，"一旦数据可用，我需要多少时间给业务部门提供预测？"这实际上是最重要的考虑因素。从新数据可用并准备好评分的那一刻起，如果用户期望在无法通过批量评分实现的时间内获得结果，就必须使用实时评分。
- en: Consider the case where users send data to a web-based application and a prediction
    is returned on the screen. In this scenario, if you use batch processing, the
    prediction may take between 5 and 15 minutes to show up on the screen. This is
    because the compute cluster needs time to spin up, the environment takes a little
    bit of time to create, and your code requires time to run.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这样一个案例，用户将数据发送到基于Web的应用程序，并在屏幕上返回预测。在这种情况下，如果您使用批量处理，预测可能需要5到15分钟才能显示在屏幕上。这是因为计算集群需要时间启动，环境需要一点时间来创建，而您的代码需要时间运行。
- en: If you use real-time scoring, however, only your code needs to run, vastly reducing
    the total runtime. If your user expects near-instantaneous results, you need to
    build a real-time solution. If they are willing to wait, then you should build
    a cheaper batch solution instead.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您使用实时评分，则只需运行您的代码，这大大减少了总运行时间。如果您的用户期望几乎即时的结果，您需要构建实时解决方案。如果他们愿意等待，那么您应该构建更便宜的批量解决方案。
- en: Important tip
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: When choosing a CPU for a real-time solution, always go with the cheapest available
    that will score your data in a timely manner. While more powerful CPUs may save
    you time, they will also cost hundreds of extra dollars per month, every month
    your solution is in existence.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择实时解决方案的CPU时，始终选择最便宜的，它可以在及时的方式下评分您的数据。虽然更强大的CPU可能会节省您的时间，但它们每个月也会额外花费数百美元，每个月您的解决方案存在。
- en: Other common scenarios that demand a real-time solution include **transactional
    fraud detection**, **anomaly detection** in a factory setting, and **recommendation
    engines**. This is because these situations require instant predictions as soon
    as the data becomes available. Once again, this is the key consideration. However,
    there are similar situations where batch processing would be more appropriate.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 其他需要实时解决方案的常见场景包括**交易欺诈检测**、工厂环境中的**异常检测**以及**推荐引擎**。这是因为这些情况需要一旦数据可用就立即进行预测。再次强调，这是关键考虑因素。然而，也存在一些情况，批量处理可能更为合适。
- en: Consider the case of anomaly detection. If you have numerous machines running
    on a factory floor and need to know when one breaks so you can *immediately* replace
    it with a backup machine, that situation requires a real-time solution; the key
    word is *immediately*. The faster you replace the machine with a backup, the better
    your factory performs, the more money you save.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑异常检测的案例。如果你在工厂车间有众多机器运行，并且需要知道何时有一台机器损坏以便你能够**立即**用备用机器替换它，这种情况需要实时解决方案；关键词是**立即**。你越快用备用机器替换损坏的机器，你的工厂表现越好，节省的金钱越多。
- en: On the other hand, imagine that those machines also show signs of wear and tear
    and, a few days in advance, you can schedule an engineer to come and perform maintenance
    to keep them up and running. In this case, you would still use an anomaly detection
    ML solution to detect when a machine needs maintenance, but you should score the
    data in batches. This is because there is no pressing need to immediately fix
    the machine. Thus, you should score the data once a day, at the end of the day,
    and order an engineer as needed.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，想象一下，这些机器也显示出磨损的迹象，并且几天前，你可以安排工程师来维修以保持它们正常运行。在这种情况下，你仍然会使用异常检测机器学习解决方案来检测何时需要维护机器，但你应该批量评分数据。这是因为没有迫切需要立即修复机器。因此，你应该每天在一天结束时评分数据，并按需安排工程师。
- en: The more experience you gain in creating real-time scoring solutions, the more
    you will be able to tell when it is a requirement. Always ask yourself, *"How
    long can my customers wait for a prediction once my data becomes available?"*
    If they can wait, build a batch solution. If they cannot, build a real-time solution.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你在创建实时评分解决方案方面获得的经验越多，你就能越准确地判断何时是必需的。始终问自己，“一旦我的数据可用，我的客户能等多久才能得到预测？”如果他们可以等待，就构建一个批量解决方案。如果他们不能等待，就构建一个实时解决方案。
- en: There are also some other considerations to take into account when deciding
    which type of solution to use.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定使用哪种类型的解决方案时，还有一些其他因素需要考虑。
- en: Choosing real-time over batch solutions
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择实时而非批量解决方案
- en: To recap, batch solutions should always be prioritized over real-time solutions
    if there is no pressing need to score data as soon it arrives. This is because
    real-time scoring solutions are inherently more expensive than batch scoring solutions,
    as your compute clusters never spin down. On the other hand, if there is a pressing
    need to score data as soon as it becomes available, you need to use a real-time
    solution to avoid the lag inherent with batch processes.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，如果没有迫切需要在数据到达时立即评分，批量解决方案应该始终优先于实时解决方案。这是因为实时评分解决方案本质上比批量评分解决方案更昂贵，因为你的计算集群永远不会关闭。另一方面，如果迫切需要在数据可用时立即评分，你需要使用实时解决方案来避免批量过程中固有的延迟。
- en: 'Complexity is also an issue. Batch scoring solutions always follow the same
    template: collect data, score data, send the results to some file or database.
    This is not the case with real-time solutions; they need to be thoughtfully integrated
    into an application. compares real-time and batch scoring solutions:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂性也是一个问题。批量评分解决方案总是遵循相同的模板：收集数据，评分数据，将结果发送到某个文件或数据库。实时解决方案并非如此；它们需要仔细集成到应用程序中。以下比较了实时和批量评分解决方案：
- en: '![Figure 8.3 – Comparing batch and real-time scoring ](img/Figure_8.3_B16595.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3 – 比较批量和实时评分](img/Figure_8.3_B16595.jpg)'
- en: Figure 8.3 – Comparing batch and real-time scoring
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 比较批量和实时评分
- en: Being able to understand the differences between batch and real-time scoring
    solutions is one thing; being able to use that knowledge is another. In the next
    section, you will put your knowledge to the test.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 能够理解批量和实时评分解决方案之间的区别是一回事；能够运用这种知识是另一回事。在下一节中，你将测试你的知识。
- en: Determining batch versus real-time scoring scenarios
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定批量与实时评分场景
- en: When confronted with real business use cases, it is often difficult to distinguish
    how you should deploy your ML model. Many data scientists make the mistake of
    implementing a batch solution when a real-time solution is required, while others
    implement real-time solutions even when a cheaper batch solution would be sufficient.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当面对实际业务案例时，往往很难区分你应该如何部署你的机器学习模型。许多数据科学家在需要实时解决方案时错误地实现了批量解决方案，而其他人则在更便宜的批量解决方案就足够的情况下实现了实时解决方案。
- en: In the following sections, you will look at different problem scenarios and
    solutions. Read each of the six scenarios and determine whether you should implement
    a real-time or batch inferencing solution. First, you will look at every scenario.
    Then, you will read each answer along with an explanation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下各节中，您将查看不同的问题场景和解决方案。阅读这六个场景，并确定您是否应该实施实时或批量推理解决方案。首先，您将查看每个场景。然后，您将阅读每个答案及其解释。
- en: Scenarios for real-time or batch scoring
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时或批量评分的场景
- en: In this section, you are presented with six scenarios. Read each carefully and
    decide whether a batch or real-time scoring solution is most appropriate.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将看到六个场景。仔细阅读每个场景，并决定批量评分解决方案或实时评分解决方案哪个更合适。
- en: Scenario 1 – Demand forecasting
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景1 – 需求预测
- en: A fast-food company is trying to determine how many bags of frozen French fries
    it needs to have on hand on any given day. The predictions generated by your ML
    regression algorithm will be used to determine how many bags of fries are delivered
    to each location. Once a week, fleets of trucks will deliver the French fries
    from centrally located warehouses to every store. Should your scoring solution
    be real-time or batch? If the solution is batch, how often should you score new
    data?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一家快餐公司正在尝试确定在任何给定的一天需要多少袋冷冻薯条。您的机器学习回归算法生成的预测将用于确定每个地点需要多少袋薯条。每周一次，车队将从位于中心的仓库将薯条运送到每个商店。您的评分解决方案应该是实时处理还是批量处理？如果是批量处理，那么应该多久评分一次新数据？
- en: Scenario 2 – Web-based supply chain optimization application
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景2 – 基于网络的供应链优化应用程序
- en: A chemical company is trying to optimize its supply chain and has operators
    located onsite at each of their warehouses. Once a day, they input data into a
    web-based application that will be used to determine delivery routes for the next
    day.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 一家化工公司正在尝试优化其供应链，并在每个仓库都设有操作员。他们每天都会将数据输入到基于网络的应用程序中，该应用程序将用于确定第二天送货路线。
- en: The predictions generated by your ML regression algorithm will predict total
    profitability for each of the possible routes and generate the best route. Operators
    are expected to manually enter data into the application once a day. Should this
    solution be batch or real-time? If the solution is real time, what benefits would
    it bring?
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机器学习回归算法生成的预测将预测每条可能路线的总盈利能力，并生成最佳路线。预计操作员每天会手动将数据输入到应用程序中。这个解决方案应该是批量处理还是实时处理？如果是实时处理，那么它将带来哪些好处？
- en: Scenario 3 – Fraud detection
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景3 – 欺诈检测
- en: A credit card company is implementing a fraud detection algorithm. Recently,
    customers have been reporting many suspicious transactions and are leaving as
    a result. As soon as fraudulent activity is detected, the company would like to
    block the transaction and notify customers that their transaction was blocked.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一家信用卡公司正在实施欺诈检测算法。最近，客户报告了许多可疑交易，并因此离开。一旦检测到欺诈活动，公司希望立即阻止交易并通知客户他们的交易已被阻止。
- en: The predictions generated by your ML classification algorithm will block any
    suspicious transactions and an application will send a text message to the customer's
    mobile phone. Should this solution be batch or real-time? If batch, how often
    should you score new data?
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机器学习分类算法生成的预测将阻止任何可疑交易，并将发送短信到客户的手机。这个解决方案应该是批量处理还是实时处理？如果是批量处理，那么应该多久评分一次新数据？
- en: Scenario 4 – Predictive maintenance
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景4 – 预测性维护
- en: An automotive company is having difficulty with its machines breaking down.
    Every time a machine breaks down, it costs the company tens of thousands of dollars
    as the entire assembly line shuts down waiting for the machine to be fixed. About
    once a month, engineers perform maintenance on the machines, but there are only
    enough engineers to repair 20% of the machines.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一家汽车公司正面临机器故障的问题。每次机器出现故障，整个生产线都会停工等待机器修复，这给公司造成了数万美元的损失。大约每个月一次，工程师会对机器进行维护，但工程师的数量仅足以修复20%的机器。
- en: Your ML classification algorithm will tell these engineers which machines to
    repair and order the repairs by priority. Should this solution be batch or real-time?
    If batch, how often should you score new data?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机器学习分类算法将告诉这些工程师哪些机器需要维修，并按优先级安排维修。这个解决方案应该是批量处理还是实时处理？如果是批量处理，那么应该多久评分一次新数据？
- en: Scenario 5 – Web-based product cost planning
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景5 – 基于网络的成本规划
- en: An aerospace company is trying to predict the profitability of a new line of
    aircraft, and would like to predict the cost of raw materials and labor based
    on specifications. Pricing managers will enter relevant data manually into a web-based
    application and would like to see the projected price immediately from your ML
    regression algorithm. There is no set time that they are expected to do this,
    and they may run the application many times in a single session.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一家航空航天公司正在尝试预测一款新飞机系列的盈利能力，并希望根据规格预测原材料和劳动力的成本。定价经理将手动将相关数据输入到基于网络的程序中，并希望立即从您的机器学习回归算法中看到预测价格。他们没有固定的时间来做这件事，他们可能在单个会话中多次运行该程序。
- en: Should you design this solution to be batch or real-time? If batch, how often
    should you score new data?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该设计这个解决方案为批量还是实时？如果是批量，应该多久评分一次新数据？
- en: Scenario 6 – Recommendation engine
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景 6 – 推荐引擎
- en: A retail store is building a website. As customers browse and add new items
    to their shopping cart, the store would like to recommend other items for those
    customers to purchase. Your ML regression algorithm will assign scores to items
    on the fly based on what customers browse, and the highest-scoring items will
    be automatically displayed to them. Should this solution be designed as a real-time
    or batch solution? If batch, how often should you score new data?
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一家零售店正在建立一个网站。当客户浏览并添加新项目到他们的购物车时，该店希望向这些客户推荐其他要购买的项目。您的机器学习回归算法将根据客户浏览的内容实时为项目分配分数，得分最高的项目将自动显示给他们。这个解决方案应该设计为实时还是批量？如果是批量，应该多久评分一次新数据？
- en: Think deeply about each scenario and then proceed to the next section.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 深入思考每个场景，然后继续下一节。
- en: Answers for the type of solution appropriate for each scenario
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每个场景适合的解决方案类型答案
- en: In this section, you will review answers for each of the six scenarios. Read
    each explanation and then review the original scenario for clarity.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将回顾每个六个场景的答案。阅读每个解释，然后回顾原始场景以获得清晰。
- en: Scenario 1 – Batch inferencing solution
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景 1 – 批量推理解决方案
- en: Scenario 1 features a typical case for ML. The fast-food company wishes to forecast
    demand for French fries on a weekly basis. Data is collected from all of the stores
    and should be scored using a batch inferencing process once a week. Once the predictions
    are generated, French fries can be loaded onto trucks and delivered to all of
    their locations.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 场景 1 是机器学习的典型案例。快餐公司希望每周预测薯条的销量。数据来自所有门店，应每周使用批量推理过程进行评分。一旦生成预测，薯条就可以装上卡车，并运送到所有门店。
- en: This is a *batch solution* because the data only needs to be scored once a week,
    and there's no pressing need to generate predictions as soon as new data becomes
    available.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个*批量解决方案*，因为数据只需要每周评分一次，而且没有迫切需要在数据可用时立即生成预测。
- en: Scenario 2 – Batch inferencing solution
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景 2 – 批量推理解决方案
- en: Scenario 2 could use either a real-time or batch inferencing solution. When
    operators manually pass data into the web-based application, it's simply a matter
    of how long they are willing to wait for results. Since this is a once-a-day operation
    and the results will not be used until the next day, it's best to trade time for
    money and go with a *batch inferencing process*. However, if you built a *real-time
    solution* in this scenario, there is a benefit. Operators would be able to see
    results right away instead of having to wait 10 to 15 minutes.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 场景 2 可以使用实时或批量推理解决方案。当操作员手动将数据输入到基于网络的程序中时，这仅仅是一个他们愿意等待多长时间的问题。由于这是一次性每日操作，结果将在第二天使用，因此最好是牺牲时间换取金钱，选择*批量推理过程*。然而，如果您在这个场景中构建了一个*实时解决方案*，这将有一个好处。操作员可以立即看到结果，而无需等待
    10 到 15 分钟。
- en: Scenario 3 – Real-time inferencing solution
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景 3 – 实时推理解决方案
- en: Scenario 3 is a classic real-time inferencing use case. Fraudulent transactions
    must be detected immediately, that is, as soon as data on the transaction becomes
    available. This speed enables both the transaction to be blocked and the customer
    to receive a notification as soon as possible.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 场景 3 是一个经典的实时推理用例。欺诈交易必须立即检测到，也就是说，一旦交易数据可用。这种速度使得交易可以立即被阻止，并且客户可以尽快收到通知。
- en: There's no way that a batch inferencing solution could provide the necessary
    speed. Furthermore, each data point must be scored individually as it arrives.
    There's no time to lump data together in batches, or to spin up a compute cluster.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 批量推理解决方案无法提供所需的速度。此外，每个数据点都必须在到达时单独评分。没有时间将数据批量汇总，或者启动计算集群。
- en: Scenario 4 – Batch inferencing solution
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景 4 – 批量推理解决方案
- en: Scenario 4 is tricky. Predictive maintenance can sometimes require real-time
    inferencing, particularly in cases where an anomalous detection indicates imminent
    failure and there are emergency staff on standby ready to fix the problem.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 场景 4 是一个棘手的情况。预测性维护有时可能需要实时推理，尤其是在异常检测表明即将发生故障并且有应急人员待命准备修复问题时。
- en: In this case, however, engineers are only available to service machines once
    a month. As a result, there is no pressing need for immediate results. A *once-a-month
    batch processing solution* is most appropriate for this scenario.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这种情况下，工程师们每月只能服务一次机器。因此，没有迫切需要立即的结果。对于这种情况，*每月一次的批量处理解决方案*最为合适。
- en: Scenario 5 – Real-time inferencing solution
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景 5 – 实时推理解决方案
- en: 'Scenario 5 is similar to `Scenario` `2` with three major exceptions:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 场景 5 与场景 2 类似，但有三个主要区别：
- en: The pricing managers do not run the scoring solution on a set schedule.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定价经理不会按照固定的时间表运行评分解决方案。
- en: The pricing managers may run the solution many times in a single setting.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定价经理可能会在一个设置中多次运行该解决方案。
- en: The pricing managers expect immediate results.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定价经理期望立即得到结果。
- en: Immediate results should indicate to you a *real-time scoring solution*. If
    you designed this solution with a batch process, every single time the pricing
    managers ran their numbers, they would experience a long wait. One way you could
    alter the application to be more batch friendly is if it allowed the pricing managers
    to enter data for all of their scenarios at once, instead of one at a time.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 立即的结果应该让你知道这是一个 *实时评分解决方案*。如果你用批量处理设计了此解决方案，每次定价经理运行他们的数字时，他们都会经历长时间的等待。你可以改变应用程序以使其更友好地处理批量的一种方法就是允许定价经理一次输入所有场景的数据，而不是逐个输入。
- en: Scenario 6 – Real-time inferencing solution
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景 6 – 实时推理解决方案
- en: Scenario 6 is another classic real-time inferencing scenario. Recommendation
    engines need to be extremely fast and change based on what users click, view,
    and add to their cart. They also need to change based on what customers purchase.
    Each time the screen changes, new data must be scored so that the appropriate
    items can be advertised to the user. Performance is also extremely important,
    as the algorithm must keep up with user actions. Every recommendation engine powered
    by ML should only be used in *real time*.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 场景 6 是另一个经典的实时推理场景。推荐引擎需要非常快，并根据用户点击、查看和添加到购物车的内容进行变化。它们还需要根据客户购买的内容进行变化。每次屏幕变化时，都必须对新的数据进行评分，以便向用户展示适当的商品。性能也非常重要，因为算法必须跟上用户的行为。每个由机器学习驱动的推荐引擎都应该在
    *实时* 下使用。
- en: 'How did you do on the six scenarios? Were you able to achieve 100% accuracy?
    In either case, have a look at *Figure 8.4* to see how common scenarios map to
    real-time or batch scoring solutions:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你在六个场景中的表现如何？你是否达到了 100% 的准确率？无论哪种情况，看看 *图 8.4* 以了解常见场景如何映射到实时或批量评分解决方案：
- en: '![Figure 8.4 – How common scenarios map to real-time or batch ](img/Figure_8.4_B16595.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 常见场景如何映射到实时或批量处理](img/Figure_8.4_B16595.jpg)'
- en: Figure 8.4 – How common scenarios map to real-time or batch
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 常见场景如何映射到实时或批量处理
- en: If you were able to accurately decide which type of scoring solution fits each
    scenario on your first try, you have passed with flying colors. You now have a
    deep understanding of which situations warrant a real-time inferencing solution
    and which situations warrant a batch inferencing solution. If you made a mistake
    on one or more of the scenarios, reread all of them until you intuitively understand
    the differences.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你第一次尝试就能准确地决定哪种评分解决方案适合你的每个场景，那么你已经顺利通过了。你现在对哪些情况需要实时推理解决方案以及哪些情况需要批量推理解决方案有了深入的理解。如果你在一个或多个场景中犯了错误，请重新阅读所有场景，直到你直觉上理解了它们之间的区别。
- en: Remember the most important factor in deciding which type of solution to use
    is how fast you need the prediction relative to when the data becomes available.
    If the end user can wait, use batch. If the application demands an immediate response,
    use real-time. Understanding the difference will not only make you a great data
    scientist, but it will also save you and your organization time, money, and work.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，决定使用哪种类型解决方案的最重要因素是相对于数据何时可用，你需要预测的速度有多快。如果最终用户可以等待，请使用批处理。如果应用程序需要即时响应，请使用实时。理解这种差异不仅会使你成为一名优秀的数据科学家，而且还能为你和你的组织节省时间、金钱和精力。
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: You now have a firm understanding of batch and real-time inferencing, and when
    to use which type of scoring solution. This is important, as even seasoned data
    scientists occasionally make mistakes when designing end-to-end ML solutions.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在对批处理和实时推理有了牢固的理解，以及何时使用哪种类型的评分解决方案。这很重要，因为即使是经验丰富的数据科学家在设计端到端ML解决方案时偶尔也会犯错误。
- en: Furthermore, most ML courses focus on training models instead of deploying them,
    but to be an effective data scientist, you must be proficient at both. In the
    upcoming chapters, you will learn how to code each of these inferencing methods
    in AMLS.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，大多数ML课程都侧重于模型训练而不是部署，但要想成为一名有效的数据科学家，你必须在这两方面都精通。在接下来的章节中，你将学习如何在AMLS中编写这些推理方法的代码。
- en: In [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129)*, Implementing a Batch
    Scoring Solution*, you will learn step by step how to use the ML models you've
    already built in batch scoring scenarios. You will create ML pipelines in AMLS
    and learn how to schedule them to run on a timer. This will allow you to easily
    productionalize your ML models and become a valuable asset to your company or
    organization.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第9章*](B16595_09_ePub.xhtml#_idTextAnchor129)*，实现批评分级解决方案*中，你将逐步学习如何使用你已构建的ML模型在批评分级场景中。你将在AMLS中创建ML管道，并学习如何安排它们在定时器上运行。这将使你能够轻松地将你的ML模型投入生产，并成为你公司或组织的宝贵资产。
