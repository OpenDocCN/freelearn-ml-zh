- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Micro-Targeting with Retrieval-Augmented Generation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于检索增强生成的微目标
- en: This chapter introduces the advanced capabilities of **retrieval-augmented generation**
    (**RAG**) and its strategic application in precision marketing, building on the
    foundations laid by **zero-shot learning** (**ZSL**) and **few-shot learning**
    (**FSL**) discussed in the previous two chapters. Unlike ZSL, which operates without
    prior examples, and FSL, which relies on a minimal dataset, RAG leverages a real-time
    retrieval system to enhance generative models, enabling them to access and incorporate
    the most current and specific information available. This ability allows RAG to
    surpass the limitations of ZSL and FSL by providing personalized content tailored
    to individual consumer profiles or current market conditions – capabilities crucial
    for micro-targeting in marketing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了**检索增强生成**（**RAG**）的高级功能及其在精准营销中的战略应用，这是在前两章讨论的**零样本学习**（**ZSL**）和**少样本学习**（**FSL**）的基础上建立的。与ZSL不同，ZSL在无先验示例的情况下运行，而FSL依赖于最小数据集，RAG利用实时检索系统来增强生成模型，使其能够访问和纳入最最新和最具体的信息。这种能力使RAG能够超越ZSL和FSL的限制，提供针对个人消费者档案或当前市场状况的个性化内容——这对于营销中的微目标至关重要。
- en: The chapter will detail the operational framework of RAG, emphasizing its hybrid
    structure, which merges generative AI with dynamic information retrieval. This
    synthesis not only ensures the generation of contextually appropriate and accurate
    content but also introduces a level of personalization that was previously unattainable
    with either ZSL or FSL alone. We will explore how RAG’s real-time data retrieval
    component plays a critical role in adapting marketing strategies swiftly to align
    with consumer behavior and preferences using the consumer interaction data from
    a multi-product e-commerce platform as an example.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将详细阐述RAG的操作框架，强调其混合结构，该结构将生成式AI与动态信息检索相结合。这种综合不仅确保了生成符合上下文和准确的内容，还引入了一种以前仅通过ZSL或FSL单独使用无法实现的程度上的个性化。我们将探讨RAG的实时数据检索组件如何通过以一个多产品电子商务平台的消费者交互数据为例，迅速调整营销策略以适应消费者行为和偏好，从而发挥关键作用。
- en: 'By the conclusion of this chapter, you will be equipped with the knowledge
    to:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将具备以下知识：
- en: Understand the integration of RAG with traditional generative models and its
    superiority in handling real-time, relevant data compared to ZSL and FSL.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解RAG与传统生成模型的集成及其在处理实时、相关数据方面的优越性，与ZSL和FSL相比。
- en: Recognize the enhanced capability of RAG in micro-targeting and personalizing
    content, which can dramatically improve consumer engagement and conversion.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认识到RAG在微目标和个性化内容方面的增强能力，这可以显著提高消费者参与度和转化率。
- en: Apply RAG concepts to develop cutting-edge marketing strategies that are not
    only data-driven but also highly adaptable to the nuances of consumers.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将RAG概念应用于开发前沿的营销策略，这些策略不仅数据驱动，而且能够高度适应消费者的细微差别。
- en: Introduction to RAG for precision marketing
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAG在精准营销中的介绍
- en: Generative models, particularly those developed on transformer frameworks like
    **generative pre-trained transformer** (**GPT**), have revolutionized how machines
    understand and generate human-like text. These models are trained on vast corpora
    of text data and are capable of learning complex patterns and structures of language
    that enable them to predict and generate coherent and contextually appropriate
    text sequences. However, despite their sophistication, pure generative models
    often lack the ability to incorporate real-time, specific information that isn’t
    explicitly present in their training data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型，尤其是那些在**生成预训练转换器**（**GPT**）等转换器框架上开发的模型，已经彻底改变了机器理解和生成类似人类文本的方式。这些模型在庞大的文本数据语料库上训练，能够学习语言的复杂模式和结构，从而能够预测和生成连贯且符合上下文的文本序列。然而，尽管这些模型非常复杂，纯生成模型通常缺乏将实时、特定信息纳入其训练数据的能力。
- en: This is where the “retrieval” component of RAG comes into play. RAG is a fusion
    of **Generative AI** (**GenAI**) with information retrieval systems, forming a
    hybrid model designed to enhance the quality and relevance of generated content.
    RAG achieves this by incorporating a dynamic retrieval component that pulls relevant
    information from an external dataset or knowledge base during the generation process.
    The retrieval system in RAG is designed to query a structured or unstructured
    database to fetch information that is relevant to the context of the generation
    task. This approach ensures that the generative model has access to the most current
    and relevant data to enhance the accuracy and relevance of the content it produces.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是RAG的“检索”组件发挥作用的地方。RAG是**生成式人工智能**（**GenAI**）与信息检索系统的融合，形成一个旨在提高生成内容质量和相关性的混合模型。RAG通过在生成过程中结合动态检索组件，从外部数据集或知识库中检索相关信息来实现这一点。RAG中的检索系统旨在查询结构化或非结构化数据库，以获取与生成任务上下文相关的信息。这种方法确保生成模型能够访问最新和最相关的数据，以增强其生成内容的准确性和相关性。
- en: How RAG works
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG是如何工作的
- en: 'In addition to its role in enhancing content relevance, RAG enables a bidirectional
    flow of information between generative models and external databases. As illustrated
    in*Figure 11.1*, the process of RAG can be broken down into several key steps,
    with each step discussed further:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 除了增强内容的相关性之外，RAG（Retrieval-Augmented Generation）还实现了生成模型和外部数据库之间信息的双向流动。如图11.1所示，RAG的过程可以分解为几个关键步骤，每个步骤都将进一步讨论：
- en: '![](img/B30999_11_01.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_01.png)'
- en: 'Figure 11.1: The key components of the RAG workflow'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：RAG工作流程的关键组件
- en: 'Let’s explore these steps further:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步探讨这些步骤：
- en: '**Input prompt**: In this step, the generative model is fed the user’s input
    prompt or the ongoing (fine-tuned) generation context.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输入提示**：在这一步中，生成模型被输入用户的输入提示或当前的（微调的）生成上下文。'
- en: '**Query generation**: Initially, the generative model produces a query based
    on the input provided in step 1\. This query is written to retrieve the most relevant
    information from the knowledge base. This bidirectional flow of information between
    the generative model and the external database fosters a symbiotic relationship,
    enriching both data utilization and model performance.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查询生成**：最初，生成模型根据第1步中提供的输入生成一个查询。这个查询被编写来从知识库中检索最相关的信息。生成模型和外部数据库之间的这种双向信息流动促进了共生关系，丰富了数据利用和模型性能。'
- en: '**Information retrieval**: In step 3, the query is then processed by the retrieval
    system, which searches through the database to find matches or closely related
    information. The sophistication of this system can vary, from simple keyword-based
    searches to more complex neural network models that understand semantic meanings.
    The retrieved data is then integrated into the content generation process in the
    next step.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**信息检索**：在第3步中，查询被检索系统处理，该系统通过数据库搜索以找到匹配项或密切相关信息。这个系统的复杂性可能有所不同，从简单的基于关键词的搜索到更复杂的理解语义意义的神经网络模型。检索到的数据随后将在下一步整合到内容生成过程中。'
- en: '**Content generation**: Armed with the retrieved data, in step 4, the generative
    model then incorporates this information into its ongoing text generation process.
    This step is crucial as it involves blending the newly retrieved data with the
    generated content to maintain coherence and flow. This content may serve as the
    basis for an initiative like a marketing campaign, as illustrated above.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**内容生成**：在第4步中，生成模型利用检索到的数据，将其纳入其持续的文字生成过程中。这一步至关重要，因为它涉及到将新检索到的数据与生成内容混合，以保持连贯性和流畅性。这种内容可能成为上述示例中营销活动等倡议的基础。'
- en: '**Iterative refinement**: Often, the process is iterative, with the generative
    model adjusting the queries based on the feedback loop between what has been generated
    and what needs to be generated next. This is captured in step 5, where the iterative
    refinement loop ensures the continuous adaptation and optimization of the generative
    process based on feedback such as marketing KPIs or customer feedback.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代优化**：通常，这个过程是迭代的，生成模型根据已生成内容和需要生成的内容之间的反馈循环调整查询。这体现在第5步中，迭代优化循环确保根据如营销KPI或客户反馈等反馈持续调整和优化生成过程。'
- en: Next, we will discuss how the query generation and retrieval steps work from
    a mathematical perspective.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将从数学角度讨论查询生成和检索步骤的工作原理。
- en: Mathematical model of RAG retrieval
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG 检索的数学模型
- en: The mathematical model of RAG captures the relationship between a document query
    and its retrieval components (steps 2 and 3 in *Figure 11.1*, respectively), laying
    the groundwork for its dynamic content generation process. At its core, RAG combines
    probabilistic frameworks to integrate text generation with information retrieval,
    which can be expressed through equations that quantify the probabilities involved
    in generating text given an input and retrieved documents.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 的数学模型捕捉了文档查询与其检索组件之间的关系（分别对应于 *图 11.1* 中的步骤 2 和 3），为其动态内容生成过程奠定了基础。在其核心，RAG
    结合概率框架将文本生成与信息检索相结合，这可以通过量化给定输入和检索到的文档生成文本中涉及的概率的方程来表示。
- en: 'The process begins with the generative model creating a query *q* based on
    the input prompt or ongoing context. Simultaneously, the retrieval system processes
    this query to fetch relevant documents from the database. The retrieval process
    is governed by a probability model that estimates the relevance of each document
    in the database given the query *q*. This estimation incorporates factors such
    as semantic similarity and document recency, ensuring that the retrieved information
    aligns closely with the context of the generation task. Mathematically, the probability
    of selecting document *r* from the database given the query *q* can be expressed
    as:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程始于生成模型根据输入提示或持续上下文创建查询 *q*。同时，检索系统处理此查询以从数据库中检索相关文档。检索过程受一个概率模型控制，该模型根据查询
    *q* 估计数据库中每个文档的相关性。这种估计包括诸如语义相似性和文档新鲜度等因素，确保检索到的信息与生成任务的上下文紧密一致。从数学上讲，给定查询 *q*
    从数据库中选择文档 *r* 的概率可以表示为：
- en: '![](img/B30999_11_001.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_001.png)'
- en: Where *D* represents the set of all possible documents in the database and *score(q,r)*
    is a function that computes the relevance of document *r* to the query *q*. The
    score function is typically learned through training and can involve complex embeddings
    that capture the semantic similarity between the query and the documents. The
    denominator in the equation ensures that the probability of selecting any document
    from the database sums to `1`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *D* 代表数据库中所有可能的文档集合，而 *score(q,r)* 是一个计算文档 *r* 对查询 *q* 相关性的函数。该评分函数通常通过训练学习，可能涉及复杂的嵌入，这些嵌入可以捕捉查询与文档之间的语义相似性。方程中的分母确保从数据库中选择任何文档的概率之和为
    `1`。
- en: Now that we know how the model works, let’s discuss the critical importance
    of the external data used in RAG systems.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了模型的工作原理，让我们讨论外部数据在 RAG 系统中的关键重要性。
- en: The importance of data in RAG
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据在 RAG 中的重要性
- en: 'External data acts as the cornerstone of the RAG framework, influencing both
    the quality of the content generated and the accuracy of the information retrieved.
    In marketing, where precision and relevance directly correlate with consumer engagement
    and conversion, the proper application and management of data within a RAG system
    becomes critical. There are two fundamental components embedded within the retrieval
    framework that warrant deeper exploration and should be prioritized due to their
    profound impact on the resulting outcome:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 外部数据是 RAG 框架的基石，影响着生成内容的质量和信息检索的准确性。在营销领域，精确性和相关性直接关联着消费者参与度和转化率，因此，在 RAG 系统中正确应用和管理数据变得至关重要。检索框架中嵌入的两个基本组件值得深入探讨，并且由于它们对结果的影响深远，应优先考虑：
- en: '**Data freshness**: Keeping data up to date allows the model to capitalize
    on current trends, events, and behaviors, enhancing consumer engagement.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据新鲜度**：保持数据更新使模型能够利用当前趋势、事件和行为，从而增强消费者参与度。'
- en: '**Data specificity**: By incorporating detailed consumer data, content can
    be precisely tailored to individual preferences and behaviors. This specificity
    not only increases the relevance of marketing messages but also can significantly
    boost conversion rates.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据特定性**：通过整合详细的消费者数据，内容可以精确地针对个人偏好和行为进行定制。这种特定性不仅增加了营销信息的相关性，还可以显著提高转化率。'
- en: Now let’s look at these concepts in detail.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来详细探讨这些概念。
- en: Data freshness
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据新鲜度
- en: In practical terms, data freshness means the system consistently accesses and
    prioritizes the most recent information available. This is particularly significant
    in marketing, where information can quickly become outdated due to rapidly changing
    market conditions or consumer preferences. For example, during a major sales event
    like Black Friday, having the latest data allows RAG systems to produce content
    that highlights current promotions, available stock levels, or last-minute deals,
    greatly enhancing the effectiveness of marketing campaigns. Unlike previously
    discussed GenAI approaches such as ZSL and FSL, which primarily rely on pre-existing
    datasets and may not update their knowledge base in real time, RAG systems integrate
    a dynamic retrieval mechanism that actively fetches and utilizes the most current
    data available.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际意义上，数据新鲜度意味着系统持续访问和优先考虑可用的最新信息。这在营销中尤为重要，因为信息可能会由于市场条件或消费者偏好的快速变化而迅速过时。例如，在像黑色星期五这样的主要销售活动中，拥有最新数据允许RAG系统生成强调当前促销活动、可用库存水平或最后时刻交易的内容，大大提高了营销活动的有效性。与之前讨论的GenAI方法（如ZSL和FSL）不同，这些方法主要依赖于预存在的数据集，并且可能不会实时更新其知识库，RAG系统集成了动态检索机制，主动获取并利用最新的可用数据。
- en: 'To ensure content remains relevant, RAG systems can adjust their retrieval
    processes to favor newer documents. Mathematically, this adjustment can be represented
    by modifying the relevance score to include a term that increases the weight of
    more recent documents:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保内容保持相关性，RAG系统可以调整其检索过程，优先考虑较新的文档。从数学上讲，这种调整可以通过修改相关性评分来包括一个术语，该术语增加较新文档的权重：
- en: '![](img/B30999_11_002.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_002.png)'
- en: Where ![](img/B30999_11_003.png) is a parameter that determines the impact of
    a document’s recency on its score. By prioritizing recent data, RAG systems can
    respond more dynamically to the latest trends, ensuring that the content they
    generate resonates with current consumer behaviors and preferences.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 其中![图片](img/B30999_11_003.png)是一个参数，用于确定文档的新鲜度对其评分的影响。通过优先考虑最新数据，RAG系统可以更动态地响应最新趋势，确保它们生成的内容与当前消费者的行为和偏好产生共鸣。
- en: Data specificity
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据特异性
- en: Data specificity refers to how detailed and relevant the information is in relation
    to a specific query. In RAG systems, high data specificity ensures that the content
    retrieved and generated is directly aligned with the user’s current needs or questions,
    therefore enhancing user engagement and satisfaction. While other methods like
    transfer learning also allow access to detailed datasets, RAG integrates real-time
    data retrieval with generative capabilities, making it particularly well-suited
    for applications where up-to-the-minute information is crucial.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据特异性指的是信息与特定查询的相关性和详细程度。在RAG系统中，高数据特异性确保检索和生成的内容直接与用户的当前需求或问题对齐，从而增强用户参与度和满意度。虽然其他方法如迁移学习也允许访问详细的数据集，但RAG将实时数据检索与生成能力相结合，使其特别适合需要最新信息的应用。
- en: 'In technical terms, RAG systems can use advanced semantic matching algorithms
    to ensure that the content they retrieve matches the user’s query not just by
    keywords but in overall meaning and context. This approach involves adjusting
    the scoring mechanism to prioritize documents that are not only relevant but also
    contextually specific to the user’s inquiry:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术术语中，RAG系统可以使用高级语义匹配算法来确保检索到的内容不仅与用户的查询关键字匹配，而且在整体意义和上下文中也匹配。这种方法涉及调整评分机制，以优先考虑不仅相关而且与用户查询上下文特定的文档：
- en: '![](img/B30999_11_004.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_004.png)'
- en: For example, consider a user searching for “best skincare for sensitive skin”.
    A RAG system with high data specificity would be able to pull and generate content
    that not only mentions skincare products but specifically addresses products designed
    for sensitive skin, potentially including user reviews, expert advice, and the
    latest product innovations. This level of detail in content generation can significantly
    improve the effectiveness of personalized marketing campaigns, enhancing customer
    conversion rates and building brand loyalty.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个用户正在搜索“针对敏感皮肤的最好护肤品”。具有高数据特异性的RAG系统能够检索和生成不仅提及护肤品，而且专门针对敏感皮肤设计的产品的内容，可能包括用户评论、专家建议和最新的产品创新。这种程度的内容生成可以显著提高个性化营销活动的有效性，提高客户转化率并建立品牌忠诚度。
- en: Understanding the retrieval index
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解检索索引
- en: The **retrieval index** is a fundamental component of any RAG system, acting
    as the bedrock on which the retrieval functionality operates. It ensures that
    the queries processed by the system are matched with accurate and contextually
    relevant responses. Managing this index effectively is crucial for the system’s
    performance and can involve several key strategies. Let’s look at some management
    approaches.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**检索索引**是任何RAG系统的基本组成部分，它是检索功能运作的基础。它确保系统处理的查询与准确和上下文相关的响应相匹配。有效地管理此索引对于系统的性能至关重要，可能涉及几个关键策略。让我们看看一些管理方法。'
- en: Indexing strategies
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 索引策略
- en: 'Effective indexing is vital for the swift and accurate retrieval of information.
    The backbone of a robust RAG system lies in its ability to quickly sift through
    vast amounts of data and find information that best matches the user’s query.
    This is achieved through sophisticated indexing strategies that organize data
    in a way that optimizes search processes, such as:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的索引对于快速准确地检索信息至关重要。一个强大RAG系统的核心在于其快速筛选大量数据并找到与用户查询最佳匹配信息的能力。这是通过复杂的索引策略实现的，这些策略以优化搜索过程的方式组织数据，例如：
- en: '**Inverted indices**: These are used to store a mapping from content keywords
    to their locations in the database. For example, in an e-commerce setting, an
    inverted index might link terms like “wireless headphones” or “thermal jacket”
    directly to the relevant product listings. This allows the system to quickly gather
    all relevant documents during a query, enhancing search efficiency and response
    speed.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**倒排索引**：这些用于存储从内容关键词到其在数据库中位置的映射。例如，在电子商务环境中，倒排索引可能会将“无线耳机”或“保暖夹克”等术语直接链接到相关的产品列表。这允许系统在查询期间快速收集所有相关文档，提高搜索效率和响应速度。'
- en: '**Vector space models**: This approach involves converting text into vector
    forms or embeddings that are easy to compare and analyze. Using algorithms like
    TF-IDF or neural network-based embeddings, such as those introduced in *Chapters
    5*, *9*, and *10*, these models help in understanding and comparing the semantic
    similarity between the user’s query and available documents, leading to more nuanced
    and contextually appropriate responses.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量空间模型**：这种方法涉及将文本转换为易于比较和分析的向量形式或嵌入。使用TF-IDF或基于神经网络的嵌入算法，如第5章、第9章和第10章中介绍的那样，这些模型有助于理解并比较用户查询与可用文档之间的语义相似性，从而产生更细微和上下文相关的响应。'
- en: '**Graph-based indexing**: This approach is useful for applications like social
    media analytics where understanding complex user relationships enhances content
    targeting. More generally, this approach is valuable when relationships between
    data points are as important as the data itself.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于图的索引**：这种方法对于社交媒体分析等应用很有用，在这些应用中，理解复杂的用户关系可以增强内容定位。更普遍地说，当数据点之间的关系与数据本身一样重要时，这种方法非常有价值。'
- en: '**Multi-dimensional indexing**: This technique is beneficial in cases such
    as geographic data applications such as real estate analysis where efficient searches
    across multiple attributes like location and time are needed. This method is particularly
    valuable for queries that involve ranges or require simultaneous consideration
    of several dimensions.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多维索引**：这种技术在需要高效搜索多个属性（如位置和时间）的地理数据应用（如房地产分析）中很有用。这种方法对于涉及范围或需要同时考虑多个维度的查询尤其有价值。'
- en: Choosing the appropriate indexing strategy depends on the application’s data
    needs and query complexity. Inverted indices are optimized for quick keyword lookups,
    ideal for environments where speed is crucial. Vector space models offer richer
    semantic analysis and are better suited for contexts requiring a deeper understanding
    of content. For handling more complex data relationships or multiple query dimensions,
    graph-based and multi-dimensional indexing provide valuable solutions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 选择适当的索引策略取决于应用程序的数据需求和查询复杂性。倒排索引针对快速关键词查找优化，对于速度至关重要的环境来说非常理想。向量空间模型提供了更丰富的语义分析，更适合需要更深入理解内容的环境。对于处理更复杂的数据关系或多个查询维度，基于图和多维索引提供了有价值的解决方案。
- en: Data curation and updating
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据整理和更新
- en: 'To maintain its efficacy, the retrieval index must be regularly updated and
    curated. The following are a couple of concepts to consider:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持其有效性，检索索引必须定期更新和维护。以下是一些需要考虑的概念：
- en: '**Dynamic updating**: As new information becomes available or old information
    becomes obsolete, the index needs to be updated to reflect these changes. This
    ensures that the RAG system remains effective and relevant over time. For instance,
    in a marketing campaign, promotional content might need frequent updates to reflect
    the most current offers by the company so that the RAG system can adjust its responses.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态更新**：随着新信息的出现或旧信息的过时，索引需要更新以反映这些变化。这确保了RAG系统随着时间的推移保持有效和相关性。例如，在营销活动中，促销内容可能需要频繁更新以反映公司最新的优惠，从而使RAG系统能够调整其响应。'
- en: '**Automated monitoring**: Implementing automated systems to continuously monitor
    and update indices can greatly enhance a RAG system’s responsiveness to changes.
    In digital marketing, this could include adjusting strategies based on new consumer
    trend analyses to make sure the marketing content is aligned with the economic
    environment.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动监控**：实施自动系统以持续监控和更新索引可以大大提高RAG系统对变化的响应能力。在数字营销中，这可能包括根据新的消费者趋势分析调整策略，以确保营销内容与经济环境保持一致。'
- en: Proper data updating and curation are key for keeping RAG systems useful, especially
    in marketing, given that these systems currently do not include advanced data
    management features and often need separate practices to manage data curation
    and updates.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的数据更新和整理对于保持RAG系统的有用性至关重要，尤其是在营销领域，因为这些系统目前不包括高级数据管理功能，通常需要单独的实践来管理数据整理和更新。
- en: RAG implementation challenges
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG实施挑战
- en: 'There are several challenges in RAG implementation that are worth highlighting.
    As discussed in the previous section, ensuring the quality and relevance of the
    underlying external database is crucial, and often separate data engineering practices
    are needed to achieve this. The following are a couple of other major issues that
    RAG systems can face:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在RAG实施中存在一些值得强调的挑战。如前所述，确保底层外部数据库的质量和相关性至关重要，通常需要单独的数据工程实践来实现这一点。以下是一些RAG系统可能面临的其他重大问题：
- en: '**Handling long documents**: RAG systems need to break retrieval documents
    into smaller chunks to avoid memory issues and slow response times. However, breaking
    longer documents into smaller chunks can lead to a loss of context. To address
    this, solutions such as summarization algorithms and context-aware chunking methods
    can be used.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理长文档**：RAG系统需要将检索文档分解成更小的块以避免内存问题和缓慢的响应时间。然而，将较长的文档分解成更小的块可能会导致上下文丢失。为了解决这个问题，可以使用摘要算法和上下文感知分块方法等解决方案。'
- en: '**Retrieving relevant data from multiple sources**: Combining data from various
    sources can be challenging due to inconsistencies and differences in data formats.
    For instance, if customer data comes from both chat history and tabular purchase
    data, the system might face issues linking the two sources and generate marketing
    messages based on inconsistent information. Techniques such as multi-modal AI
    models (see *Chapter 12*) and knowledge graphs can help address this.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从多个来源检索相关数据**：由于数据格式的不一致和差异，从各种来源结合数据可能具有挑战性。例如，如果客户数据来自聊天历史和表格购买数据，系统可能会面临将两个来源链接起来并基于不一致信息生成营销信息的问题。多模态AI模型（见*第12章*）和知识图谱等技术可以帮助解决这个问题。'
- en: Despite these challenges, major organizations such as Meta AI Research, Google
    AI, and Microsoft have successfully implemented RAG systems. For instance, Google
    has integrated RAG to enhance the relevance of its search results and Microsoft
    integrates RAG within Azure AI services to improve virtual assistants’ capabilities.
    RAG is also becoming increasingly accessible to smaller organizations through
    services that offer to curate their existing enterprise data into formats that
    are compatible with RAG applications.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些挑战，Meta AI Research、Google AI和Microsoft等主要组织已经成功实施了RAG系统。例如，Google已将RAG集成以增强其搜索结果的相关性，而Microsoft则将RAG集成到Azure
    AI服务中，以提升虚拟助手的性能。通过提供将现有企业数据整理成与RAG应用兼容格式的服务，RAG也越来越容易为小型组织所采用。
- en: Applications of RAG in marketing
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG在营销中的应用
- en: RAG systems that uniquely combine real-time data retrieval with advanced content
    generation offer a number of transformative applications in marketing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将实时数据检索与高级内容生成独特结合的RAG系统在营销中提供了许多变革性应用。
- en: 'Given that these systems enable marketers to craft personalized and contextually
    aware content by integrating the most relevant data into the content creation
    process, there are some pivotal areas where RAG systems can significantly enhance
    marketing strategies:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些系统通过将最相关的数据整合到内容创作过程中，使营销人员能够制作出个性化的、上下文感知的内容，因此RAG系统可以在以下关键领域显著提升营销策略：
- en: '**Dynamic personalized content creation**: RAG systems excel in generating
    advertising content that adapts in real time to changes in user interactions,
    browsing behaviors, or purchase histories. By accessing data specific to an individual’s
    recent activities, RAG can tailor advertisements to match personal preferences
    and interests.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态个性化内容创建**：RAG系统在生成实时适应用户互动、浏览行为或购买历史变化的广告内容方面表现出色。通过访问与个人近期活动相关的数据，RAG可以定制广告以匹配个人偏好和兴趣。'
- en: '**Example**: Imagine a user recently explored camping gear online. A RAG system
    could use this data to dynamically create ads for related items like hiking boots
    or travel guides. This targeted advertising not only increases the relevance and
    appeal of the ads but also boosts engagement rates and potential conversions.
    We will discuss other examples of this in the hands-on exercise presented later
    in this chapter.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：想象一个用户最近在网上探索露营装备。RAG系统可以利用这些数据动态创建相关物品如徒步靴或旅行指南的广告。这种有针对性的广告不仅增加了广告的相关性和吸引力，而且提高了参与率和潜在转化率。我们将在本章后面的动手练习中讨论其他此类示例。'
- en: '**Segment-specific content generation**: RAG enables marketers to produce content
    finely targeted to specific demographic segments, enriched with the latest data
    relevant to these groups. This strategy ensures the content deeply resonates with
    its intended audience, therefore enhancing reader engagement and brand loyalty.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对特定细分市场的个性化内容生成**：RAG使营销人员能够生产出针对特定人口细分市场的精细内容，并丰富这些群体相关的最新数据。这种策略确保内容与其目标受众产生深刻共鸣，从而增强读者参与度和品牌忠诚度。'
- en: '**Example**: A RAG system might generate blog posts for first-time home buyers
    that include up-to-date mortgage rates and real-time housing market trends. This
    not only provides valuable information but also establishes the brand as a credible
    resource in the home-buying journey.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：一个RAG系统可能会为首次购房的人生成包含最新抵押贷款利率和实时房地产市场趋势的博客文章。这不仅提供了有价值的信息，而且使品牌在购房之旅中成为一个可信的资源。'
- en: '**Enhanced customer engagement:** By harnessing the power of real-time data
    retrieval and advanced content generation, these systems enable the production
    of highly personalized content that resonates deeply with individual customers.
    Whether through personalized emails, targeted social media posts, or bespoke newsletters,
    RAG systems ensure that all communications are timely, relevant, and tailored
    to each customer’s unique profile.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强客户参与度**：通过利用实时数据检索和高级内容生成的力量，这些系统能够生产出与个别客户产生深刻共鸣的高度个性化内容。无论是通过个性化的电子邮件、有针对性的社交媒体帖子还是定制新闻通讯，RAG系统确保所有沟通都是及时的、相关的，并且针对每个客户的独特档案进行定制。'
- en: '**Example**: For a customer who recently celebrated a significant event like
    an anniversary, RAG can generate personalized greetings or offers that reflect
    the customer’s preferences and past interactions with the brand. This could include
    curated content, special promotions, or personalized messages from brand ambassadors,
    creating a highly personalized and memorable customer experience.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：对于一个最近庆祝了重要事件（如周年纪念日）的客户，RAG可以生成反映客户偏好和品牌过往互动的个性化问候或优惠。这可能包括精选内容、特别促销或品牌大使的个性化信息，从而创造一个高度个性化且难忘的客户体验。'
- en: '**Automated response generation for customers**: RAG enhances customer support
    by generating informative and contextually relevant responses to inquiries. By
    pulling information from FAQs, product manuals, or customer databases, RAG systems
    deliver precise, customized answers.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面向客户的自动响应生成**：RAG通过生成针对性强、与上下文相关的响应来增强客户支持。通过从常见问题解答、产品手册或客户数据库中提取信息，RAG系统提供精确、定制的答案。'
- en: '**Example**: When a customer inquires about the return policy for an online
    purchase, RAG can generate a response that includes details tailored to the item’s
    category or the date of purchase. This application of RAG in customer support
    not only improves response times but also boosts overall customer satisfaction.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：当客户询问在线购买的退货政策时，RAG 可以生成一个包含针对商品类别或购买日期定制的详细信息的响应。这种 RAG 在客户支持中的应用不仅提高了响应时间，还提升了整体客户满意度。'
- en: Now that you have the theoretical knowledge in place, let’s move on to the application
    and get familiar with the process of building a knowledge retrieval system.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经具备了理论知识，让我们继续应用，熟悉构建知识检索系统的过程。
- en: 'If you would like to explore RAG further, here are a couple of valuable resources:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进一步探索 RAG，以下是一些有价值的资源：
- en: '*Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks* ([https://arxiv.org/pdf/2005.11401](https://arxiv.org/pdf/2005.11401))
    is a seminal paper by researchers from Meta AI that explores the integration of
    retrieval and generation to enhance language models for knowledge-intensive tasks.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*知识密集型 NLP 任务中的检索增强生成* ([https://arxiv.org/pdf/2005.11401](https://arxiv.org/pdf/2005.11401))
    是 Meta AI 研究人员的一篇开创性论文，探讨了检索和生成的集成，以增强语言模型在知识密集型任务中的应用。'
- en: '*Searching for Best Practices in Retrieval-Augmented Generation* ([https://arxiv.org/abs/2407.01219](https://arxiv.org/abs/2407.01219))
    is a more recent review/survey of the literature covering key advancements and
    current challenges.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*检索增强生成中的最佳实践搜索* ([https://arxiv.org/abs/2407.01219](https://arxiv.org/abs/2407.01219))
    是对涵盖关键进展和当前挑战的文献的最新综述/调查。'
- en: Building a knowledge retrieval system for marketing with LangChain
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain 构建营销知识检索系统
- en: This section will explore the practical aspects of setting up a knowledge retrieval
    system specifically tailored for marketing purposes using LangChain, a library
    designed to facilitate the integration of language models with retrieval systems.
    We will do this via an example that readers can follow to construct their own
    retrieval systems for enhancing the capabilities of generative AI in their own
    marketing strategies.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨使用 LangChain（一个旨在促进语言模型与检索系统集成库）为营销目的设置知识检索系统的实际方面。我们将通过一个读者可以跟随的示例来完成这项工作，以构建他们自己的检索系统，以增强他们在营销策略中生成
    AI 的能力。
- en: Introduction to LangChain
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain 简介
- en: LangChain is a framework that significantly enhances the capabilities of language
    models by integrating them with retrieval systems. Its flexible design allows
    it to support a variety of backend databases and customizable retrieval strategies
    using modules like `langchain-retrieval` and `langchain-storage`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 通过将检索系统集成到语言模型中，显著增强了语言模型的能力。其灵活的设计允许它支持各种后端数据库和可定制的检索策略，使用模块如 `langchain-retrieval`
    和 `langchain-storage`。
- en: '**LangChain essentials**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**LangChain 精要**'
- en: LangChain facilitates the combination of language models with robust retrieval
    systems. This integration captures the principles of RAG, enabling applications
    to generate content that is not only human-like but also highly relevant and informed
    by the latest data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 促进语言模型与强大检索系统的结合。这种集成捕捉了 RAG 的原则，使应用程序能够生成既像人类又高度相关且由最新数据信息的内容。
- en: 'Further documentation and resources can be found on LangChain’s official documentation
    page: [https://python.langchain.com/docs/get_started/introduction/](https://python.langchain.com/docs/get_started/introduction/)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的文档和资源可以在 LangChain 的官方文档页面上找到：[https://python.langchain.com/docs/get_started/introduction/](https://python.langchain.com/docs/get_started/introduction/)
- en: 'LangChain stands out as a top choice for Python developers looking to integrate
    advanced AI capabilities into their marketing strategies. While other tools such
    as LlamaIndex specialize in data indexing and retrieval for quick access to large
    datasets, LangChain offers a more versatile platform for creating complex NLP
    applications. Some of the key features making LangChain ideal for Python developers
    are the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 作为 Python 开发者将高级 AI 功能集成到其营销策略中的首选工具脱颖而出。虽然其他工具如 LlamaIndex 专注于数据索引和检索，以便快速访问大量数据集，但
    LangChain 提供了一个更通用的平台，用于创建复杂的 NLP 应用程序。使 LangChain 成为 Python 开发者理想选择的一些关键特性如下：
- en: '**Ease of integration**: LangChain simplifies the incorporation of complex
    AI models with retrieval databases through high-level abstraction, allowing you
    to focus more on creating unique application logic rather than wrestling with
    backend complexities, speeding up development and deployment processes.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于集成**：LangChain通过高级抽象简化了复杂AI模型与检索数据库的结合，让您可以更多地关注创建独特的应用逻辑，而不是与后端复杂性搏斗，从而加快开发和部署过程。'
- en: '**Modularity**: The framework’s high modularity supports a diverse range of
    language models and retrieval databases, alongside custom logic for specific interactions.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模块化**：框架的高模块化支持多种语言模型和检索数据库，以及针对特定交互的定制逻辑。'
- en: '**Scalability**: LangChain is designed to scale effortlessly from handling
    small tasks to managing large-scale applications, such as real-time personalized
    advertising and extensive email marketing campaigns. This scalability ensures
    that as marketing strategies grow and evolve, their technological infrastructure
    can grow without needing a complete overhaul.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：LangChain被设计成能够轻松地从处理小任务扩展到管理大规模应用，例如实时个性化广告和广泛的电子邮件营销活动。这种可扩展性确保了随着营销策略的增长和演变，其技术基础设施可以增长而无需进行全面的重构。'
- en: In the following sections, we will dive deeper into setting up LangChain, designing
    a retrieval model, and integrating this system with generative models to demonstrate
    its application in real-world marketing scenarios.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨LangChain的设置、检索模型的设计以及将该系统与生成模型集成，以展示其在现实世界营销场景中的应用。
- en: Understanding the external dataset
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解外部数据集
- en: The dataset that we’ll be using as the source of external data for our retrieval
    model comes from a large multi-category e-commerce platform and captures user
    interactions over the course of one month (December 2019). It includes different
    types of events related to product interactions by users, such as viewing, adding
    to the cart, removing from the cart, and purchasing.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用作检索模型外部数据源的数据集来自一个大型多品类电子商务平台，并捕捉了用户在2019年12月一个月内的交互。它包括与产品交互相关的不同类型的事件，例如查看、添加到购物车、从购物车中移除和购买。
- en: We will use this as a basis for our setup process of a knowledge retrieval system
    with LangChain as it will set the stage for the hands-on example we will walk
    through in the final part of the chapter, where we will be using the user interactions
    from this same database for the purpose of RAG micro-targeting of consumers.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以此为基础，使用LangChain构建知识检索系统的设置流程，因为它将为我们在章节最后部分将进行实操的示例奠定基础。在这个部分，我们将使用来自同一数据库的用户交互数据，用于对消费者进行RAG微定位。
- en: '**Source code and data**: [https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.11](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.11)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**源代码和数据**：[https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.11](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.11)'
- en: '**Data source**: [https://www.kaggle.com/code/annettecatherinepaul/ecommerce-analysis-and-recommendations/input](https://www.kaggle.com/code/annettecatherinepaul/ecommerce-analysis-and-recommendations/input)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据来源**：[https://www.kaggle.com/code/annettecatherinepaul/ecommerce-analysis-and-recommendations/input](https://www.kaggle.com/code/annettecatherinepaul/ecommerce-analysis-and-recommendations/input)'
- en: 'Before incorporating this dataset into our retrieval model, it’s important
    to thoroughly understand its characteristics to ensure effective data ingestion
    and utilization in the retrieval system. A preliminary examination of the data
    can tailor the retrieval architecture and refine the indexing strategy, facilitating
    optimized query responses. To start, let’s examine the first few entries to understand
    the type of data each column contains:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在将此数据集纳入我们的检索模型之前，了解其特征对于确保在检索系统中有效摄取和利用数据至关重要。对数据的初步检查可以定制检索架构和优化索引策略，从而促进优化的查询响应。首先，让我们检查前几条记录，以了解每列包含的数据类型：
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This yields the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下结果：
- en: '![](img/B30999_11_02.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_11_02.png)'
- en: 'Figure 11.2: First three rows from the Kaggle e-commerce user interactions
    dataset'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2：Kaggle电子商务用户交互数据集的前三行
- en: The dataset features columns such as `event_time`, which marks when an event
    occurred, `event_type`, indicating the nature of the interaction (viewing, purchasing,
    or adding or removing from the cart), and other identifiers such as `product_id`,
    `category_id`, `brand`, and `price`. Taken together, this will help us understand
    the user’s journey through the e-commerce platform, including their actions, the
    products involved, and the pricing dynamics during their sessions.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含诸如`event_time`等列，它标记了事件发生的时间，`event_type`表示交互的性质（查看、购买或添加或从购物车中删除），以及其他标识符，如`product_id`、`category_id`、`brand`和`price`。综合来看，这将帮助我们了解用户在电子商务平台上的旅程，包括他们的行为、涉及的产品以及会话期间的定价动态。
- en: 'To deepen our understanding, we can perform basic statistical analyses that
    highlight the distribution and range of key data points by running the `describe`
    function:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加深我们的理解，我们可以通过运行`describe`函数来执行基本的统计分析，以突出显示关键数据点的分布和范围：
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output shows that the dataset comprises over 3.5 million events:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示数据集包含超过350万个事件：
- en: '![](img/B30999_11_03.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_03.png)'
- en: 'Figure 11.3: Key statistics for numeric columns in the dataset'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3：数据集中数值列的关键统计数据
- en: The product prices range significantly from as low as -$79.37 (possibly indicating
    returns or pricing errors) to a high of $327.80, with a mean of around $8.87\.
    Such variability suggests diverse consumer behavior and purchasing power, which
    are crucial for segmenting and targeting marketing campaigns.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 产品价格范围从低至-79.37美元（可能表示退货或定价错误）到高达327.80美元，平均约为8.87美元。这种可变性表明消费者行为和购买力的多样性，这对于细分和定位营销活动至关重要。
- en: 'We can also obtain a deeper understanding of two more key columns that are
    not included in the above summary, `event_type` and `brand`, which help us identify
    consumer preferences and buying patterns:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以更深入地了解两个未包含在上文总结中的关键列，即`event_type`和`brand`，这些列帮助我们识别消费者偏好和购买模式：
- en: '[PRE2]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This gives us the following output:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '![](img/B30999_11_04.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_04.png)'
- en: 'Figure 11.4: Counts of event_type values in the dataset'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：数据集中`event_type`值的计数
- en: This first output shows that views are the most common `event_type` (approximately
    1.73 million instances), followed by additions to the cart, removals from the
    cart, and purchases. The substantial drop from cart interactions to actual purchases
    (over 700,000 fewer purchases than cart additions) is a point of interest for
    improving conversion rates. More generally, the reduction of counts from views
    to cart interactions to overall purchases highlights a typical e-commerce sales
    funnel.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个输出显示，查看是最常见的`event_type`（约173万次实例），其次是添加到购物车、从购物车中删除和购买。从购物车交互到实际购买的巨大下降（比购物车添加少700,000次购买）是提高转化率的一个关注点。更普遍地说，从查看到购物车交互再到整体购买的计数减少突出了典型的电子商务销售漏斗。
- en: 'By running our second command of `value_counts` on the `brand` column, we can
    also see which brands appear most commonly throughout the dataset:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在`brand`列上运行我们的第二个命令`value_counts`，我们还可以看到哪些品牌在数据集中出现得最频繁：
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following is the output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '![](img/B30999_11_05.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_05.png)'
- en: 'Figure 11.5: Counts of brand values in the dataset'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：数据集中品牌值的计数
- en: 'It is also important to understand the null values in the data. This gives
    us a way to understand both the data quality and key information around missing
    values that will need to be accounted for when indexing data for our retrieval
    index:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 理解数据中的空值也很重要。这为我们提供了一种理解数据质量和关键信息的方法，这些信息将需要在为我们的检索索引索引数据时考虑：
- en: '[PRE4]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following result indicates significant gaps in `category_code` (almost
    3.5 million missing values) and `brand` (over 1.5 million missing values) data:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果表明`category_code`（近350万个缺失值）和`brand`（超过150万个缺失值）数据存在重大差距：
- en: '![](img/B30999_11_06.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_06.png)'
- en: 'Figure 11.6: Counts of missing values across columns in the dataset'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6：数据集中各列缺失值的计数
- en: This could hinder our ability to perform detailed product category analysis
    and brand-specific marketing using this dataset. The minor missing count in `user_session`
    (`779`) suggests nearly complete tracking of user sessions, which is most vital
    for our goal of analyzing user behavior throughout their sessions.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会阻碍我们使用此数据集进行详细的产品类别分析和品牌特定的市场营销。`user_session`中的轻微缺失计数（779）表明用户会话的跟踪几乎完整，这对于我们分析用户在整个会话中的行为的目标至关重要。
- en: Designing the retrieval model with LangChain
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LangChain设计检索模型
- en: As we move forward in constructing our knowledge retrieval system using LangChain,
    the next step involves the effective indexing of our e-commerce dataset. Indexing
    is a foundational process that enables the efficient retrieval of data. This section
    outlines the setup of an indexing system to support the queries that will allow
    us to achieve our goal of micro-targeting based on their shopping behaviors. To
    implement our retrieval system, we will utilize Elasticsearch for our backend
    system due to its robust full-text search capabilities and suitability for handling
    large datasets.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们使用LangChain构建我们的知识检索系统，下一步涉及有效地索引我们的电子商务数据集。索引是一个基础过程，它使得高效检索数据成为可能。本节概述了索引系统的设置，以支持查询，这将使我们能够根据他们的购物行为实现基于微目标的定位。为了实现我们的检索系统，我们将利用Elasticsearch作为我们的后端系统，因为它具有强大的全文搜索功能，并且适合处理大型数据集。
- en: Install and connect to Elasticsearch
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装并连接到Elasticsearch
- en: 'Before creating the index, we need to ensure that Elasticsearch is installed
    and running on our system. Follow these steps based on your operating system:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建索引之前，我们需要确保Elasticsearch已安装并在我们系统上运行。根据您的操作系统遵循以下步骤：
- en: 'Here are the steps to be followed by Windows users:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是Windows用户需要遵循的步骤：
- en: '**Download**: Visit the Elasticsearch official download page ([https://www.elastic.co/downloads/elasticsearch](https://www.elastic.co/downloads/elasticsearch))
    and download the latest version for Windows.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载**：访问Elasticsearch官方下载页面([https://www.elastic.co/downloads/elasticsearch](https://www.elastic.co/downloads/elasticsearch))，并下载Windows的最新版本。'
- en: '**Install**: Extract the downloaded ZIP file to your desired location and navigate
    to the extracted folder.'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安装**：将下载的ZIP文件提取到您希望的位置，并导航到提取的文件夹。'
- en: '**Start**: Open Command Prompt as `Administrator`, change directory to where
    Elasticsearch is installed (e.g., `cd C:\path\to\elasticsearch-<version>\bin`),
    and execute `elasticsearch.bat` to start Elasticsearch. Substitute `<version>`
    with the specific version of Elasticsearch that was downloaded from their official
    download page.'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启动**：以管理员身份打开命令提示符，更改到Elasticsearch安装的目录（例如，`cd C:\path\to\elasticsearch-<version>\bin`），并执行`elasticsearch.bat`以启动Elasticsearch。将`<version>`替换为从官方下载页面下载的Elasticsearch的具体版本。'
- en: 'macOS/Linux users can follow these steps:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: macOS/Linux用户可以遵循以下步骤：
- en: '**Download**: Use the below command in a terminal window, replacing `<version>`
    with the latest version:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载**：在终端窗口中使用以下命令，将`<version>`替换为最新版本：'
- en: '[PRE5]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Install**: Extract the file with the below command and navigate to the newly
    created directory:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安装**：使用以下命令提取文件，并导航到新创建的目录：'
- en: '[PRE6]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Start**: Open a terminal window and change to the `bin` directory:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启动**：打开终端窗口并切换到`bin`目录：'
- en: '[PRE7]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Start Elasticsearch by running:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令启动Elasticsearch：
- en: '[PRE8]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you have an ARM-powered MacBook, you may need to install via Homebrew instead.
    Instructions for this, as well as alternative ways of installing Elasticsearch,
    can be found on their website: [https://www.elastic.co/guide/en/elasticsearch/reference/7.17/install-elasticsearch.html](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/install-elasticsearch.html).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是ARM芯片的MacBook，您可能需要通过Homebrew进行安装。有关此操作以及安装Elasticsearch的替代方法的说明，可以在他们的网站上找到：[https://www.elastic.co/guide/en/elasticsearch/reference/7.17/install-elasticsearch.html](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/install-elasticsearch.html)。
- en: 'After starting Elasticsearch, verify that it is running by using the following
    `curl` command in your terminal or command prompt:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动Elasticsearch后，使用以下`curl`命令在您的终端或命令提示符中验证它是否正在运行：
- en: '[PRE9]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should see a JSON response from Elasticsearch indicating that it is running
    correctly, such as the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该会看到Elasticsearch返回的JSON响应，表明它正在正确运行，如下所示：
- en: '[PRE10]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With Elasticsearch running, you can now connect from Python using the Elasticsearch
    client. Here’s how to set it up:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当Elasticsearch运行时，您现在可以使用Elasticsearch客户端从Python连接。以下是设置方法：
- en: '[PRE11]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Indexing data in Elasticsearch
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Elasticsearch中索引数据
- en: 'Next, we can define the data schema and index data from the dataset. Given
    the diversity of data types and volume of data captured within the dataset, it
    is important to configure our indexing mappings to efficiently handle the range
    and type of data present. This mapping for our index is informed by our earlier
    exploratory analysis that we performed on this dataset, where we discovered that
    our dataset consists of over 3.5 million entries with data types ranging from
    integers and floating-point numbers to categorical and textual data. This diversity
    necessitates a robust indexing strategy to ensure efficient data retrieval and
    query performance:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以定义数据架构并从数据集中索引数据。鉴于数据集中数据类型的多样性和数据量，配置我们的索引映射以有效地处理现有数据的范围和类型非常重要。我们的索引映射是基于我们对该数据集进行的早期探索性分析，我们发现我们的数据集包含超过350万个条目，数据类型从整数和浮点数到类别和文本数据不等。这种多样性需要一种稳健的索引策略，以确保高效的数据检索和查询性能：
- en: '[PRE12]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Some key aspects of the decisions that were made in defining the above mapping
    types are the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义上述映射类型时所做的决策的一些关键方面如下：
- en: '**Numeric and identifier fields**: `product_id`, `category_id`, and `user_id`
    are all stored as integers with significant ranges. Given their use as identifiers,
    they are mapped to Elasticsearch’s integer and long data types, which are optimized
    for numeric operations and comparisons. `price`, a floating-point field, shows
    a wide range of values, from negative (likely indicating refunds) to over 300\.
    This field is mapped as a float to accurately represent and query price data.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值和标识字段**：`product_id`、`category_id` 和 `user_id` 都存储为具有显著范围的整数。鉴于它们作为标识符的使用，它们被映射到
    Elasticsearch 的整数和长数据类型，这些类型针对数值操作和比较进行了优化。`price` 是一个浮点字段，显示广泛的值范围，从负数（可能表示退款）到超过
    300。此字段被映射为浮点数，以准确地表示和查询价格数据。'
- en: '**Categorical and textual fields**: `event_type` and `user_session` are categorical
    fields with high cardinality. These are mapped as keyword types, which support
    the exact matching necessary for filtering and aggregations. `brand` and `category_code`,
    however, contain textual data that might be used for full-text search as well
    as for exact matches. These fields are defined with the text type and a keyword
    multi-field to allow both full-text searching and aggregations.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别和文本字段**：`event_type` 和 `user_session` 是具有高基数值的类别字段。这些字段被映射为关键词类型，支持过滤和聚合所需的精确匹配。然而，`brand`
    和 `category_code` 包含可能用于全文搜索以及精确匹配的文本数据。这些字段使用文本类型和关键词多字段定义，以允许全文搜索和聚合。'
- en: '**Date fields**: `event_time` represents timestamps and is mapped as a date.
    This allows for time-based queries, which are essential for analyzing trends over
    time.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日期字段**：`event_time` 表示时间戳，被映射为日期类型。这允许基于时间的查询，这对于分析随时间变化的趋势至关重要。'
- en: 'Next, we will create the index based on the mapping defined above using:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用以下方式创建基于上述映射的索引：
- en: '[PRE13]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Upon execution, this should result in a response such as the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 执行后，应产生如下响应：
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: With these configurations, your Elasticsearch environment is now fully equipped
    for indexing and querying our dataset.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些配置，您的 Elasticsearch 环境现在已完全配备用于索引和查询我们的数据集。
- en: Data ingestion into Elasticsearch
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据导入到 Elasticsearch
- en: Ingesting the dataset into the Elasticsearch index is the step that involves
    transferring data from our DataFrame into Elasticsearch. This process uses an
    efficient bulk indexing method, which is essential for handling large volumes
    of data effectively.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集导入到 Elasticsearch 索引是涉及将我们的 DataFrame 中的数据传输到 Elasticsearch 的步骤。此过程使用高效的批量索引方法，这对于有效地处理大量数据至关重要。
- en: Starting from the dataset load step, we include handling of the inconsistent
    and missing values that we identified earlier and replace these with `None` types
    to avoid errors in the indexing process. Depending on your device hardware, the
    indexing process may take some time, ranging from minutes to hours, given the
    dataset size. You can track this progress using the `tqdm` progress bar.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据集加载步骤开始，我们包括处理之前识别的不一致和缺失值，并用 `None` 类型替换这些值以避免索引过程中的错误。根据您的设备硬件，索引过程可能需要一些时间，从几分钟到几小时不等，具体取决于数据集的大小。您可以使用
    `tqdm` 进度条跟踪此进度。
- en: 'To further optimize the indexing performance, we include the `chunk_size` parameter
    in the bulk indexing method. This parameter controls the number of documents processed
    in each bulk request and adjusting its value can impact the speed of indexing
    and memory usage. In addition to `chunk_size`, we also suggest truncating the
    data before indexing if you still experience memory issues. To truncate the data,
    you can use a `pandas` function such as `df = df.head(n)` to limit the DataFrame
    to the first `n` rows. Let’s take a look at the code:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步优化索引性能，我们在批量索引方法中包含 `chunk_size` 参数。此参数控制每个批量请求中处理的文档数量，调整其值可能会影响索引速度和内存使用。除了
    `chunk_size` 之外，如果您仍然遇到内存问题，我们还建议在索引之前截断数据。要截断数据，您可以使用 `pandas` 函数，例如 `df = df.head(n)`，将
    DataFrame 限制为前 `n` 行。让我们看一下代码：
- en: '[PRE15]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Upon completion of the indexing process, you should see an output similar to
    the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在索引过程完成后，您应该看到以下类似的输出：
- en: '[PRE16]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Integrating with LangChain using GPT
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 GPT 与 LangChain 集成
- en: 'Integrating LangChain with your Elasticsearch backend involves setting up the
    environment so that LangChain can use an LLM to dynamically generate content based
    on the data retrieved from Elasticsearch. We will demonstrate this using the gpt-3.5-turbo
    LLM, but you should refer to the latest LangChain documentation for the latest
    models available ([https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)):'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 将 LangChain 与您的 Elasticsearch 后端集成涉及设置环境，以便 LangChain 可以使用 LLM 动态根据从 Elasticsearch
    获取的数据生成内容。我们将使用 gpt-3.5-turbo LLM 进行演示，但您应参考最新的 LangChain 文档以获取最新的模型信息 ([https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html))：
- en: 'The first step involves initializing the GPT model as a LangChain model. You
    may also need to generate an OpenAI API key for the model if you haven’t done
    this step already, a process that currently includes the creation of an OpenAI
    account. Further details on the instructions for this can be found on the OpenAI
    website ([https://platform.openai.com/docs/introduction](https://platform.openai.com/docs/introduction)):'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步涉及初始化 GPT 模型作为 LangChain 模型。如果您还没有完成此步骤，您可能还需要为该模型生成一个 OpenAI API 密钥，这个过程目前包括创建一个
    OpenAI 账户。有关此指令的更多详细信息，可以在 OpenAI 网站上找到 ([https://platform.openai.com/docs/introduction](https://platform.openai.com/docs/introduction))：
- en: '[PRE17]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Once the model is set up, the next step involves constructing queries to fetch
    relevant data from Elasticsearch. This data serves as the input for GPT, allowing
    it to generate contextually relevant content based on user behavior.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型设置完成，下一步就是构建查询以从 Elasticsearch 获取相关数据。这些数据作为 GPT 的输入，使其能够根据用户行为生成上下文相关的內容。
- en: 'For example, here is how you can define a function to retrieve data based on
    any matching query from Elasticsearch:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是您如何定义一个函数来根据任何匹配的查询从 Elasticsearch 获取数据：
- en: '[PRE18]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This function `retrieve_data_from_es` takes a dictionary representing the Elasticsearch
    query and returns a list of documents that match this query. The example provided
    fetches records associated with a specific user ID, allowing for the generation
    of personalized content based on the user’s previous interactions, such as products
    viewed or added to the cart. For example, to grab content related to `user_id`
    `576802932`, we can execute the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数 `retrieve_data_from_es` 接收一个表示 Elasticsearch 查询的字典，并返回与该查询匹配的文档列表。提供的示例检索与特定用户
    ID 相关的记录，允许根据用户的先前交互生成个性化内容，例如查看或添加到购物车的产品。例如，要获取与 `user_id` `576802932` 相关的内容，我们可以执行以下操作：
- en: '[PRE19]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `data` response retrieved from Elasticsearch includes detailed records
    of the user’s activities, each of which is tagged with precise timestamps, product
    identifiers, category details, and session information. We can see examples of
    these types of interactions via the following:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Elasticsearch 获取的 `data` 响应包括用户活动的详细记录，每条记录都带有精确的时间戳、产品标识符、类别细节和会话信息。我们可以通过以下方式查看这些类型交互的示例：
- en: '[PRE20]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following screenshot shows the output:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了输出结果：
- en: '![](img/B30999_11_07.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_07.png)'
- en: 'Figure 11.7: example entries for remove_from_cart and view event types from
    the dataset'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7：从数据集中移除购物车和查看事件类型的示例条目
- en: In these examples, one entry shows a user removing an item from the cart around
    midnight, suggesting reconsideration or a preference change. The second entry
    captures a view event, where a user is browsing products but has not yet made
    a purchase decision. Understanding these interactions can help in designing personalized
    re-engagement strategies to encourage users to complete their purchases and enhance
    conversion rates.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些例子中，一条记录显示用户在午夜左右从购物车中移除商品，这表明重新考虑或偏好改变。第二条记录捕捉到一个查看事件，其中用户正在浏览产品，但尚未做出购买决定。理解这些交互可以帮助设计个性化的重新参与策略，鼓励用户完成购买并提高转化率。
- en: Now that we have designed, implemented, and tested the framework for our knowledge
    retrieval model, let’s explore the application of this model via an example.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设计、实施并测试了我们的知识检索模型框架，让我们通过一个例子来探索这个模型的应用。
- en: Implementing RAG for micro-targeting based on customer data
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于客户数据实现RAG的微定位
- en: Having thoroughly analyzed the dataset and constructed a robust retrieval system,
    we now transition from theoretical frameworks to practical implementation. In
    this section, we will learn how to apply RAG to dynamically address common challenges
    in digital marketing, such as outdated information in trained models and capturing
    recent user interactions. Traditional **zero-shot learning** (**ZSL**) and **few-shot
    learning** (**FSL**) models, while powerful, often lag in real-time responsiveness
    and rely on pre-existing data, limiting their effectiveness in such a fast-paced
    marketing scenario.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在彻底分析数据集并构建了一个稳健的检索系统之后，我们现在从理论框架过渡到实际实施。在本节中，我们将学习如何应用RAG来动态解决数字营销中常见的挑战，例如训练模型中的过时信息和捕捉最新的用户交互。尽管传统的**零样本学习**（**ZSL**）和**少样本学习**（**FSL**）模型功能强大，但它们往往在实时响应方面落后，并且依赖于现有数据，限制了它们在这样快节奏的营销场景中的有效性。
- en: To overcome these limitations, we will utilize RAG to generate marketing content
    that is not only up to date but also deeply relevant to current consumer behaviors.
    By integrating our retrieval system with GPT, we can pull the latest user interaction
    data directly from our database. With RAG, we can also generate real-time content
    tailored to individual user scenarios, effectively re-engaging customers who have
    abandoned their carts. This approach allows us to generate marketing strategies
    that are informed by the most recent and relevant user activities, something that
    static models cannot achieve.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些限制，我们将利用RAG生成不仅是最新的，而且与当前消费者行为高度相关的营销内容。通过将我们的检索系统与GPT集成，我们可以直接从我们的数据库中提取最新的用户交互数据。借助RAG，我们还可以根据个别用户场景生成实时内容，有效地重新吸引那些已经放弃购物车的客户。这种方法使我们能够生成基于最新和最相关用户活动的营销策略，这是静态模型无法实现的。
- en: Determining the campaign strategy
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定营销活动策略
- en: As we transition from the theoretical frameworks discussed earlier, it’s important
    to understand the strategic underpinnings of the upcoming example where we demonstrate
    how RAG can be applied. Before diving into the real-world examples, we will set
    the stage for the basis of our micro-targeting strategies by performing a couple
    more crucial elements of exploratory analysis on the dataset in order to determine
    our optimal campaign strategy and its goals.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们从之前讨论的理论框架过渡，了解即将展示的例子中的战略基础非常重要，我们将演示如何应用RAG。在深入现实世界例子之前，我们将通过在数据集上执行更多关键探索性分析来设定我们微定位策略的基础，以确定我们的最佳营销策略及其目标。
- en: Message timing
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消息时间
- en: 'Efficiency in digital marketing not only reduces costs but also enhances the
    effectiveness of campaigns. One strategic component for our campaign will be the
    optimization of the timing for our marketing messages. As discussed in *Chapter
    4*, understanding the time-series trends in user interactions can be particularly
    insightful for this. Rather than performing a date-based analysis, since we only
    have access to one month of data, we will instead examine how interactions vary
    by time of day so that we can use this information to give us insight into the
    optimal time of day for user engagement for the following months. We can extract
    the insights needed to make this decision via the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 数字营销的效率不仅降低了成本，还提高了营销活动的有效性。我们营销活动的战略组成部分之一将是优化营销信息的时间安排。如第4章所述，理解用户交互的时间序列趋势可以特别有洞察力。由于我们只有一个月的数据，我们不会基于日期进行分析，而是将检查交互如何随一天中的时间变化，以便我们可以使用这些信息来了解用户参与的最佳时间，为下个月提供洞察。我们可以通过以下方式提取做出此决策所需的见解：
- en: '[PRE21]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This gives us the following graph:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了以下图表：
- en: '![](img/B30999_11_08.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_11_08.png)'
- en: 'Figure 11.8: Number of user interactions by event type across different hours
    of the day'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8：不同时间跨度的用户交互事件类型数量
- en: 'From the plotted data, we observe a few distinct user behavior patterns throughout
    the day that have important implications for the timing of our micro-targeting
    strategy:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 从绘制的数据中，我们观察到一天中几个明显的用户行为模式，这对我们微目标策略的时间安排具有重要意义：
- en: '**Peak viewing hours**: The highest user activity, specifically views, occurs
    between `17:00` and `20:00`. This peak period is optimal for pushing advertisements
    and personalized content to maximize exposure and engagement.'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**高峰观看时间**：最高的用户活动，特别是观看，发生在`17:00`到`20:00`之间。这个高峰期是推送广告和个性化内容的最佳时期，以最大化曝光和参与度。'
- en: '**High transaction activities**: Cart additions and purchases are also generally
    high from `17:00` to `20:00`. This indicates not only active browsing but also
    a higher propensity to finalize purchases, making it an ideal time for promotional
    offers.'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**高交易活动**：购物车添加和购买行为通常在`17:00`到`20:00`之间也较高。这不仅表明了活跃的浏览行为，还表明了更高的最终购买倾向，使其成为促销活动的理想时间。'
- en: '**Cart removal insights**:Cart removals closely mirror the two preceding trends
    and peak between `18:00` and `20:00`, suggesting a reconsideration phase among
    users. This period could be strategically targeted with reminders or incentives
    such as discount offers or free shipping to convert hesitations into sales.'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**购物车移除洞察**：购物车移除趋势与前面提到的两个趋势紧密相关，并在`18:00`到`20:00`之间达到峰值，这表明用户处于重新考虑阶段。这个时期可以通过提醒或激励措施，如折扣优惠或免费送货，将犹豫转化为销售。'
- en: '**Early morning and late night trends**: While there’s a gradual increase in
    activity from the morning, it sharply declines after `21:00`, indicating late
    night hours might not be as effective for targeted campaigns.'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**早晨和晚上的趋势**：虽然从早晨开始活动逐渐增加，但在`21:00`之后急剧下降，这表明晚上的时间可能并不适合进行针对性的营销活动。'
- en: Given these patterns, a targeted strategy can be specifically implemented during
    the `19:00` to `21:00` window to mitigate cart abandonment rates. During this
    time, deploying personalized re-engagement campaigns such as sending reminder
    emails, offering limited-time discount codes, or displaying pop-up messages with
    special offers can be particularly effective.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些模式，可以在`19:00`到`21:00`的时间窗口内实施针对性的策略，以降低购物车放弃率。在此期间，部署个性化的重新参与活动，如发送提醒邮件、提供限时折扣代码或显示带有特别优惠的弹出消息，可以特别有效。
- en: For your own analysis, it is important to consider that behavior patterns will
    differ when analyzing user interactions across different time zones. It is therefore
    important to confirm that user time zones are accurately recorded and stored in
    your database, or that time zone differences are accounted for after the fact
    based on the region of the user. Failing to do so could result in analysis that
    involves a convolution of user behaviors across regions, leading to poor message
    timing.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行自己的分析时，重要的是要考虑，当分析不同时区的用户交互时，行为模式会有所不同。因此，重要的是要确认用户时区被准确记录并存储在您的数据库中，或者根据用户的地区在事后对时区差异进行考虑。未能做到这一点可能会导致涉及跨区域用户行为的分析，从而导致信息发送时间不当。
- en: Choosing the brand
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择品牌
- en: 'As we continue to refine our marketing strategy, it’s crucial to identify which
    brands within our dataset present the highest potential for increasing conversion
    rates. In previous analyses, we explored the frequency of brand appearances to
    gauge their prevalence. Let’s now go deeper by examining the top five brands to
    understand how different types of interactions vary across these brands:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This yields the following output:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_11_09.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.9: Number of user interactions by event type for the five most popular
    brands'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the brand interactions, `bpw.style` stands out as a candidate for
    focused improvement, especially in terms of cart abandonment metrics. While `bpw.style`
    shows a substantial presence in the dataset, there’s a noticeable discrepancy
    between the number of items added to carts (`21995`) and those removed (`18014`).
    This pattern suggests a significant gap between initial interest and final purchasing
    decisions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'To quantify the opportunity for improvement, let’s calculate the cart abandonment
    rate for the `bpw.style` brand:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Addressing the gap in cart abandonment could significantly boost `bpw.style`'s
    performance by converting potential sales into actual purchases.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Using LangChain for micro-targeting
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier, we established a retrieval system integrated with GPT to dynamically
    generate content based on the data from Elasticsearch. We will now utilize the
    marketing campaign goals that we just defined to leverage the insights gained
    from our analysis of user behavior by brand and timing to create highly personalized
    content aimed at enhancing customer engagement. We will start with two examples
    that are user-specific, before transitioning to a third example that is targeted
    specifically toward consumers of the `bpw.style` brand.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'Case study 1: Targeted product discounts'
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given that our data indicates that user interactions, especially cart additions
    and removals, peak roughly between `17:00` and `21:00`, we will use this timeframe
    as the optimal window for sending out marketing messages, capturing when users
    are most active and likely reconsidering their purchase decisions. The preferred
    medium for this outreach will be email, which allows for rich, personalized content
    and can effectively re-engage users by reminding them of items left in their carts
    or providing time-sensitive offers.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate tailored marketing content, we deploy a function that constructs
    prompts for GPT based on user interactions, transforming these data points into
    actionable marketing strategies:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This function constructs a series of messages to feed into the LLM, each representing
    a significant user interaction, such as adding to a cart or removing from it.
    These descriptions culminate in a request for a marketing strategy tailored to
    these activities, prompting the LLM to generate a custom message.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: 'Going back to our earlier analysis of the data stored in our retrieval index
    for “`user_id`": “`576802932`", we can run an analysis on this customer and obtain
    a response such as the following:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This yields the following:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Our marketing campaign could time this prompt generation to take place based
    on the most recent customer interaction data for this consumer as of roughly `17:00`
    and then send the email shortly thereafter. This not only provides a direct incentive
    to reduce abandonment but also creates a sense of urgency that the customer is
    more likely to act upon.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'Case study 2: Product upselling'
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building on the insights from the first case study, which focused on reducing
    cart abandonment rates through targeted discounts during peak interaction hours,
    this second case study explores a complementary strategy. Here, we aim to enhance
    product upselling by offering personalized product recommendations based on user
    behavior and preferences during similar peak hours.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: 'This function is designed to harness user data to not only remind them of their
    abandoned carts but also to upsell related or complementary products based on
    their browsing and purchasing history. By doing this, we not only aim to recover
    abandoned carts but also increase the average order value:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This function is designed to construct a narrative that not only addresses the
    immediate need to reduce cart abandonment but also strategically suggests additional
    products that enhance the user’s initial choice, potentially increasing the transaction
    value.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now apply this function to the same consumer as last time and see the
    result, this time prompting the model to return a full email message in its entirety:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This produces the following email content:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_11_10.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.10: Tailored upselling content strategy generated for user 576802932,
    based on their interaction data retrieved from the Elasticsearch database'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Case study 3: Real-time content customization for bpw.style'
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Building on our strategy to utilize RAG for micro-targeting, this case study
    focuses specifically on enhancing engagement and reducing cart abandonment rates
    for the `bpw.style` brand. Recognizing the disparity between cart additions and
    completions, as previously analyzed, we target users who might benefit from a
    gentle reminder or an incentive to complete their transactions. This query will
    specifically look for cart addition and removal events:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a function with the Elasticsearch query to fetch this specific type
    of brand interaction data:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'With the targeted data retrieved, we can now integrate this into our `generate_reengagement_content`
    function. The modified function will use the data fetched by our new query function
    to generate personalized re-engagement strategies:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can run our new query and content generation commands via the following:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This yields the following:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_11_11.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.11: Personalized re-engagement strategy created for users interested
    in bpw.style products who have abandoned their carts'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: As shown by the output, by honing in on specific brands that exhibit high cart
    abandonment rates, we can tailor marketing strategies that address unique challenges
    related to brand perception and customer engagement. This approach allows for
    the creation of highly specific content that resonates with the brand’s audience,
    potentially transforming browsing behaviors into completed transactions. While
    this strategy emphasizes brand-specific data, it can seamlessly integrate with
    user-specific insights illustrated earlier, including demographic information,
    if available, to enhance the precision and relevance of the marketing messages.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has provided a detailed exploration of RAG and its transformative
    impact on precision marketing. By integrating generative AI with dynamic retrieval
    systems, RAG overcomes the limitations inherent in previous models like ZSL and
    FSL by incorporating real-time, context-specific data into content generation.
    This enables an unprecedented level of personalization in marketing strategies,
    enhancing the relevance and efficacy of marketing content tailored to individual
    consumer preferences and current market conditions.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: We’ve used practical examples and mathematical models to demonstrate how RAG
    effectively combines data freshness and specificity, thereby elevating consumer
    engagement and optimizing conversion rates.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: The discussion also covered the technical mechanisms that underpin RAG, from
    query generation and information retrieval to the iterative refinement of generated
    content. These elements ensure that the content not only resonates with the audience
    but also stays aligned with the latest trends and data insights, a crucial advantage
    in today’s rapidly evolving digital marketing landscape.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: As we look to the future, in the next chapter, we will move on to the broader
    landscape of AI and ML in marketing, consolidating the knowledge acquired throughout
    this book while exploring emerging technologies. We will combine current methods
    and predicted advancements in AI that will revolutionize marketing even further.
    Additionally, we will examine how AI is becoming integral to emerging digital
    platforms that offer novel ways to engage customers and personalize marketing
    efforts. This forward-looking perspective will give you the insights and skills
    that you will need to navigate the evolving AI landscape, preparing you for the
    future of digital marketing.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genai](https://packt.link/genai)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code12856128601808671.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
