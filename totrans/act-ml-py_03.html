<html><head></head><body>
<div id="book-content" class="calibre2">
<div id="sbo-rt-content" class="calibre3"><div id="_idContainer047" class="calibre4">
			<h1 id="_idParaDest-27" class="calibre8"><a id="_idTextAnchor027" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>2</h1>
			<h1 id="_idParaDest-28" class="calibre8"><a id="_idTextAnchor028" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Designing Query Strategy Frameworks</h1>
			<p class="calibre6"><strong class="bold"><a id="_idTextAnchor029" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Query strategies</strong> act as<a id="_idIndexMarker049" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> the engine that drives active ML and determines which data points get selected for labeling. In this chapter, we aim to provide a comprehensive and detailed explanation of the most widely used and highly effective query strategy frameworks that are employed in active ML. These frameworks play a crucial role in the field of active ML, aiding in selecting informative and representative data points for labeling. The strategies that we will delve into include uncertainty sampling, query-by-committee, <strong class="bold">expected model change</strong> (<strong class="bold">EMC</strong>), <strong class="bold">expected error reduction</strong> (<strong class="bold">EER</strong>), and density-weighted methods. By thoroughly <a id="_idIndexMarker050" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>understanding <a id="_idIndexMarker051" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>these frameworks and the underlying principles, you can make informed decisions when designing and implementing active <span>ML algorithms.</span></p>
			<p class="calibre6">In this chapter, you will gain skills that will equip you to design and deploy query strategies that extract maximum value from labeling efforts. You will gain intuition for matching strategies to datasets and use cases when building active <span>ML systems.</span></p>
			<p class="calibre6"> We will cover the <span>following topics:</span></p>
			<ul class="calibre16">
				<li class="calibre20">Exploring uncertainty <span>sampling methods</span></li>
				<li class="calibre20">Understanding <span>query-by-committee approaches</span></li>
				<li class="calibre20">Labeling with <span>EMC sampling</span></li>
				<li class="calibre20">Sampling <span>with EER</span></li>
				<li class="calibre20">Understanding density-weighted <span>sampling methods</span></li>
			</ul>
			<h1 id="_idParaDest-29" class="calibre8"><a id="_idTextAnchor030" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Technical requirements</h1>
			<p class="calibre6">For the code examples demonstrated in this chapter, we have used Python 3.9.6 with the <span>following packages:</span></p>
			<ul class="calibre16">
				<li class="calibre20"><strong class="source-inline">numpy</strong> (<span>version 1.23.5)</span></li>
				<li class="calibre20"><strong class="source-inline">scikit-learn</strong> (<span>version 1.2.2)</span></li>
				<li class="calibre20"><strong class="source-inline">matplotlib</strong> (<span>version 3.7.1)</span></li>
			</ul>
			<h1 id="_idParaDest-30" class="calibre8"><a id="_idTextAnchor031" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Exploring uncertainty sampling methods</h1>
			<p class="calibre6"><strong class="bold">Uncertainty sampling</strong> refers<a id="_idIndexMarker052" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to querying data points for which the model is least certain about their prediction. These are samples the model finds most ambiguous and cannot confidently label on its own. Getting these high-uncertainty points labeled allows the model to clarify where its knowledge <span>is lacking.</span></p>
			<p class="calibre6">In uncertainty sampling, the active ML system queries instances for which the current model’s predictions exhibit <em class="italic">high uncertainty</em>. The goal is to select data points that are <em class="italic">near the decision boundary</em> between classes. Labeling these ambiguous examples helps the model gain confidence in areas where its knowledge <span>is weakest.</span></p>
			<p class="calibre6">Uncertainty sampling methods select data points close <a id="_idIndexMarker053" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>to the <strong class="bold">decision boundary</strong> because points near this boundary exhibit the highest prediction ambiguity. The decision boundary is defined as the point where the model shows the most uncertainty in distinguishing between different classes for a given input. Points on the boundary represent the most ambiguous, uncertain cases for <span>a model.</span></p>
			<p class="calibre6"><span><em class="italic">Figure 2</em></span><em class="italic">.1</em> illustrates the difference between uncertainty sampling and <span>random sampling:</span></p>
			<div class="calibre18">
				<div id="_idContainer013" class="img---figure">
					<img src="image/B21789_02_01.jpg" alt="" role="presentation" class="calibre26"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US"> Figure 2.1 – Uncertainty sampling versus random sampling</p>
			<p class="calibre6">For data points that are located far away from the decision boundary (<span><em class="italic">Figure 2</em></span><em class="italic">.1</em>) within a class region (labeled as A or B), the model will exhibit a high level of confidence in assigning them to that class (for example, &gt;95%). These points are considered certain and will not be selected when employing uncertainty sampling. However, there is a possibility that some of these points may be chosen when using random sampling. For data points that are extremely close to or directly on the decision boundary, the model will struggle to distinguish between the classes. The predicted class probabilities will be more evenly distributed, with the top predictions being very close to each other. Therefore, these points are considered uncertain and will be selected when using uncertainty sampling. These important data points might have been overlooked when using random sampling. As a result, the distance to the<a id="_idIndexMarker054" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> boundary correlates to uncertainty – the closest points will have the lowest max confidence, the smallest margin between top classes, and the highest entropy over the <span>class probabilities.</span></p>
			<p class="calibre6">Therefore, by selecting points based on metrics such as low confidence, low margin, and high entropy, uncertainty sampling queries the instances nearest to the decision boundary. We will discuss these metrics in detail in the upcoming sections of this chapter. Labeling these provides information to help clarify class regions and refine the boundary. The model is unlikely to gain much information from examples it can already predict correctly with high confidence. However, querying data points that the model is very uncertain about directly provides useful information about its gaps. Uncertainty sampling takes advantage of this by targeting points with high <span>prediction ambiguity.</span></p>
			<p class="calibre6">For example, an image classifier’s least confident predictions likely correspond to challenging out-of-distribution examples that traditional sampling would miss. By querying these unusual cases for labels, the model rapidly improves at classifying edge cases. Now, let’s discuss some of the common methods that are used for <span>uncertainty sampling.</span></p>
			<p class="calibre6">First, we will talk <a id="_idIndexMarker055" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>about <strong class="bold">least-confidence sampling</strong>, where the data points are ranked according to their least-confidence score. This score is obtained by subtracting the most confident prediction label for each item from 1, which represents 100% confidence. To facilitate understanding, it is beneficial to convert the uncertainty scores into a range of 0-1, where 1 signifies the highest level of uncertainty. The magnitude of the score that’s assigned to each data point lies in its association with the uncertainty of the model’s prediction. Consequently, data samples with the highest least-confident scores should be given priority <span>for annotation.</span></p>
			<p class="calibre6">The most <a id="_idIndexMarker056" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>informative sample, x, can be computed <span>as follows:</span></p>
			<p class="calibre6"><img src="image/1.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;*&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;argmax&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" width="458" height="59" class="calibre27"/></p>
			<p class="calibre6">Here, we have <span>the following:</span></p>
			<p class="calibre6"><img src="image/2.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;argmax&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" width="374" height="59" class="calibre28"/></p>
			<p class="calibre6">For instance, let’s say we have a model that classifies samples into three different classes. Now, we are trying to rank two samples using least-confidence sampling. The predicted probabilities of the two samples are <strong class="source-inline">[0.05, 0.85, 0.10]</strong> for sample 1 and <strong class="source-inline">[0.35, 0.15, 0.50]</strong> for sample 2. Let’s find out which sample is the most informative when using the least-confidence sampling method by using the following <span>Python code:</span></p>
			<pre class="source-code">
import numpy as np
# Model's probabilities of samples 1 and 2 for the 3 classes
probs_sample_1 = np.array([0.05, 0.85, 0.10])
probs_sample_2 = np.array([0.35, 0.15, 0.50])
def least_confident_score(predicted_probs):
    return 1 - predicted_probs[np.argmax(predicted_probs)]
LC_samples_scores = np.array(
    [least_confident_score(probs_sample_1),
    least_confident_score(probs_sample_2)])
print(f'Least confident score for sample 1 is: 
    {LC_samples_scores[0]}')
print(f'Least confident score for sample 2 is: 
    {LC_samples_scores[1]}')
most_informative_sample = np.argmax(LC_samples_scores)
print(f'The most informative sample is sample 
    {most_informative_sample+1}')</pre>			<p class="calibre6">The output of the preceding code snippet is <span>as follows:</span></p>
			<pre class="source-code">
Least confident score for sample 1 is: 0.15000000000000002
Least confident score for sample 2 is: 0.5</pre>			<p class="calibre6">Thus, the most informative sample is <span>sample 2.</span></p>
			<p class="calibre6">In this case, we can see that sample 2 is chosen when using the least-confidence sampling approach because the model’s predictions were the least confident for <span>that sample.</span></p>
			<p class="calibre6">Next, we will <a id="_idIndexMarker057" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>discuss <strong class="bold">margin sampling</strong>. This <a id="_idIndexMarker058" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>method is designed to identify and select data points that have the smallest disparity in probability between the top two predicted classes. By focusing on data points with minimal margin between classes, we can effectively prioritize the annotation of data samples that result in a higher level of confusion for the model. Therefore, the model’s level of uncertainty is higher when it encounters data points with a lower margin score, making them ideal candidates for annotation. The formula to calculate the score of the most informative data point with the margin sampling method is <span>as follows:</span></p>
			<p class="calibre6"><img src="image/3.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;*&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;argmin&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" width="683" height="61" class="calibre29"/></p>
			<p class="calibre6">Let’s use the samples from our previous <span>example again:</span></p>
			<pre class="source-code">
import numpy as np
# Model's probabilities of sample 1 and 2 for the 3 classes
probs_sample_1 = np.array([0.05, 0.85, 0.10])
probs_sample_2 = np.array([0.35, 0.15, 0.50])
def margin_score(predicted_probs):
    predicted_probs_max_1 = np.sort(predicted_probs)[-1]
    predicted_probs_max_2 = np.sort(predicted_probs)[-2]
    margin_score = predicted_probs_max_1 - predicted_probs_max_2
    return margin_score
# For sample 1
margin_score_sample_1 = margin_score(probs_sample_1)
print(f'The margin score of sample 1 is: {margin_score_sample_1}')
# For sample 2
margin_score_sample_2 = margin_score(probs_sample_2)
print(f'The margin score of sample 2 is: {margin_score_sample_2}')
margin_scores = np.array([margin_score_sample_1, 
    margin_score_sample_2])
most_informative_sample = np.argmin(margin_scores)
print(f'The most informative sample is sample 
    {most_informative_sample+1}')</pre>			<p class="calibre6">The output of the preceding script is <span>as follows:</span></p>
			<pre class="source-code">
The margin score of sample 1 is: 0.75
The margin score of sample 2 is: 0.15000000000000002
The most informative sample is sample 2</pre>			<p class="calibre6">With the margin sampling method, sample 2 is selected as well because it has the smallest disparity in probability between the top two <span>predicted classes.</span></p>
			<p class="calibre6">In the <strong class="bold">ratio of confidence</strong> method, the data points that have the smallest ratio between the <a id="_idIndexMarker059" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>probability of the top predicted class and the probability of the second most likely class are selected. This targets examples where the model’s top two predictions are closest in likelihood. A lower ratio indicates that the model is less confident in the top class relative to the second class. By querying points with the minimum ratio between the top two class probabilities, this technique focuses on cases where the model is nearly equivocal between two classes. Getting these boundary points labeled will push the model to gain greater confidence in the true class. A lower ratio means higher ambiguity, so the ratio of confidence sampling finds points where the model is most unsure of which class <span>is correct.</span></p>
			<p class="calibre6">We can calculate<a id="_idIndexMarker060" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> the score of the most informative data point using the ratio of confidence sampling method via the <span>following equation:</span></p>
			<p class="calibre6"><img src="image/4.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;R&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;*&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;argmin&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" width="447" height="99" class="calibre30"/></p>
			<p class="calibre6">Once again, we’ll utilize the samples that we used previously for <span>this method:</span></p>
			<pre class="source-code">
import numpy as np
# Model's probabilities of sample 1 and 2 for the 3 classes
probs_sample_1 = np.array([0.05, 0.85, 0.10])
probs_sample_2 = np.array([0.35, 0.15, 0.50])
def ratio_score(predicted_probs):
    predicted_probs_max_1 = np.sort(predicted_probs)[-1]
    predicted_probs_max_2 = np.sort(predicted_probs)[-2]
    margin_score = predicted_probs_max_1 / predicted_probs_max_2
    return margin_score
# For sample 1
ratio_score_sample_1 = ratio_score(probs_sample_1)
print(f'The ratio score of sample 1 is: {ratio_score_sample_1}')
# For sample 2
ratio_score_sample_2 = ratio_score(probs_sample_2)
print(f'The ratio score of sample 2 is: {ratio_score_sample_2}')
margin_scores = np.array([ratio_score_sample_1, ratio_score_sample_2])
most_informative_sample = np.argmin(margin_scores)
print(f'The most informative sample is sample 
    {most_informative_sample+1}')</pre>			<p class="calibre6">The output of<a id="_idIndexMarker061" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> this script is <span>as follows:</span></p>
			<pre class="source-code">
The ratio score of sample 1 is: 8.5
The ratio score of sample 2 is: 1.4285714285714286
The most informative sample is sample 2</pre>			<p class="calibre6">So, sample 2 is selected when using the ratio of confidence sampling method as it has the smallest ratio between the probability of the top predicted class and the probability of the second most <span>likely class.</span></p>
			<p class="calibre6">Another method is <strong class="bold">entropy sampling</strong>. This method selects data points that have the highest <a id="_idIndexMarker062" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>entropy across the probability distribution over classes. Entropy represents the overall uncertainty in the predicted class probabilities. Higher entropy means the model is more uncertain, with a more uniform probability spread over classes. Lower entropy indicates confidence, with probability concentrated on <span>one class.</span></p>
			<p class="calibre6">By querying points with maximum entropy, this technique targets instances where the model’s predicted class probabilities are most evenly distributed. These highly uncertain points provide the most information gain since the model cannot strongly favor one class – its predictions are maximally unsure. Getting these high entropy points labeled enables the model to gain more confidence in areas in which it is the most uncertain. Overall, entropy sampling finds points with the highest total ambiguity. The formula to calculate the score of the most informative data point with the entropy sampling method is <span>as follows:</span></p>
			<p class="calibre6"><img src="image/5.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;H&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;*&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;argmax&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∑&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;l&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;o&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;g&lt;/mml:mi&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" width="709" height="85" class="calibre31"/></p>
			<p class="calibre6">Let’s use our<a id="_idIndexMarker063" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> sample examples again with <span>this method:</span></p>
			<pre class="source-code">
import numpy as np
# Model's probabilities of sample 1 and 2 for the 3 classes
probs_sample_1 = np.array([0.05, 0.85, 0.10])
probs_sample_2 = np.array([0.35, 0.15, 0.50])
def entropy_score(predicted_probs):
    return -np.multiply(predicted_probs, \
        np.nan_to_num(np.log2(predicted_probs))).sum()
# For sample 1
entropy_score_sample_1 = entropy_score(probs_sample_1)
print(f'The margin score of sample 1 is: {entropy_score_sample_1}')
# For sample 2
entropy_score_sample_2 = entropy_score(probs_sample_2)
print(f'The margin score of sample 2 is: {entropy_score_sample_2}')
entropy_scores = np.array([entropy_score_sample_1, \
    entropy_score_sample_2])
most_informative_sample = np.argmax(entropy_scores)
print(f'The most informative sample is sample 
    {most_informative_sample+1}')</pre>			<p class="calibre6">This script outputs the <span>following results:</span></p>
			<pre class="source-code">
The margin score of sample 1 is: 0.747584679824574
The margin score of sample 2 is: 1.4406454496153462
The most informative sample is sample 2.</pre>			<p class="calibre6">Using entropy <a id="_idIndexMarker064" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>sampling, sample 2 was chosen as it has the highest entropy across the probability distribution <span>over classes.</span></p>
			<p class="calibre6">These common uncertainty sampling techniques provide simple but effective strategies to identify highly ambiguous points <span>to query.</span></p>
			<p class="calibre6">Now, let’s explore the key benefits that uncertainty sampling provides for <span>active ML:</span></p>
			<ul class="calibre16">
				<li class="calibre20">Uncertainty sampling is a conceptually intuitive query strategy that is efficient to compute. Metrics such as confidence, margin, ratio, and entropy have clear uncertainty interpretations and can be <span>calculated quickly.</span></li>
				<li class="calibre20">It actively enhances model confidence in areas where it is uncertain, expanding knowledge boundaries. For example, a sentiment classifier can gain more certainty on ambiguous reviews containing rare phrases by querying the most uncertain cases for their <span>true sentiment.</span></li>
				<li class="calibre20">Uncertainty sampling is widely applicable across classification tasks and model types <a id="_idIndexMarker065" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>such as <strong class="bold">support vector machines</strong> (<strong class="bold">SVMs</strong>), logistic regression, random forests, and <strong class="bold">neural networks</strong> (<strong class="bold">NNs</strong>). Uncertainty <a id="_idIndexMarker066" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>applies broadly to <span>classification tasks.</span></li>
				<li class="calibre20">Uncertainty sampling is useful for anomaly detection by finding ambiguous outliers the model cannot explain. Uncertainty highlights <span>unusual cases.</span></li>
				<li class="calibre20">It can identify labeling errors by seeking points with inconsistent predictions between models. High uncertainty may indicate <span>noisy data.</span></li>
			</ul>
			<p class="calibre6">Overall, uncertainty sampling is a highly effective and versatile active ML method. It can be used in various domains and is intuitive and efficient. It helps expand a model’s capabilities and discover unknown points. Whether it’s used for classification, regression, or other ML tasks, uncertainty sampling consistently improves model performance. By selecting uncertain data points for annotation, the model learns from informative examples and improves predictions. It has proven useful in natural language processing, computer vision, and data mining. Uncertainty sampling actively acquires new knowledge and enhances ML models. While uncertainty <a id="_idIndexMarker067" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>sampling focuses on points the model is individually unsure of, query-by-committee approaches aim to add diversity by identifying points where an ensemble of models disagrees. We will discuss query-by-committee approaches in the <span>next section.</span></p>
			<h1 id="_idParaDest-31" class="calibre8"><a id="_idTextAnchor032" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Understanding query-by-committee approaches</h1>
			<p class="calibre6"><strong class="bold">Query-by-committee</strong> aims to <a id="_idIndexMarker068" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>add diversity by querying points where an ensemble of models disagrees the most. Different models will disagree where the data is most uncertain <span>or ambiguous.</span></p>
			<p class="calibre6">In the query-by-committee approach, a group of models is trained using a labeled set of data. By doing so, the ensemble can work together and provide a more robust and <span>accurate prediction.</span></p>
			<p class="calibre6">One interesting aspect of this approach is that it identifies the data point that causes the most disagreement among the ensemble members. This data point is then chosen to be queried to obtain <span>a label.</span></p>
			<p class="calibre6">The reason why this method works well is because different models tend to have the most disagreement on difficult and boundary examples, as depicted in <span><em class="italic">Figure 2</em></span><em class="italic">.2</em>. These are the instances where there is ambiguity or uncertainty, and by focusing on these points of maximal disagreement, the ensemble can gain consensus and make more <span>confident predictions:</span></p>
			<div class="calibre18">
				<div id="_idContainer019" class="img---figure">
					<img src="image/B21789_02_02.jpg" alt="Figure 2.2 – Query-by-committee sampling with five unlabeled data points" class="calibre32"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.2 – Query-by-committee sampling with five unlabeled data points</p>
			<p class="calibre6"><span><em class="italic">Figure 2</em></span><em class="italic">.2</em> reveals a<a id="_idIndexMarker069" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> disagreement between models 1 and 4, as opposed to models 2 and 3, regarding data point 2. A similar pattern can be observed with data point 4. Therefore, data points 2 and 4 have been chosen to be sent to the oracle <span>for labeling.</span></p>
			<p class="calibre6">Query-by-committee is a widely used and effective active ML strategy that addresses the limitations of uncertainty sampling. While uncertainty sampling can be biased toward the current learner and may overlook crucial examples that are not within its estimator’s focus, query-by-committee overcomes these challenges. This approach involves maintaining multiple hypotheses simultaneously and selecting queries that lead to disagreements among these hypotheses. By doing so, it ensures a more comprehensive and diverse exploration of the data, ultimately enhancing the learning process. For instance, a committee of image classifiers may heavily disagree on ambiguous images that traditional sampling fails to capture. By querying labels for images with maximal disagreement, such as varied predictions for an unusual object, the committee <span>collectively improves.</span></p>
			<p class="calibre6">Some of the <a id="_idIndexMarker070" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>common techniques for query-by-committee sampling include <strong class="bold">maximum disagreement</strong>, <strong class="bold">vote entropy</strong>, and <strong class="bold">average KL divergence</strong>, all of which we will <span>discuss now.</span></p>
			<h2 id="_idParaDest-32" class="calibre9"><a id="_idTextAnchor033" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Maximum disagreement</h2>
			<p class="calibre6">This simple<a id="_idIndexMarker071" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> approach<a id="_idIndexMarker072" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> looks at direct disagreement in the predicted labels between committee members. The data points where most ensemble members disagree on the label are queried. For example, if a three-model committee’s label votes for a point are (1, 2, 3), this exemplifies maximum disagreement as each model predicts a different class. Querying the points with the most label conflicts helps us focus only on cases that divide the committee. Maximum disagreement target instances create the largest rifts within the ensemble. Getting these high disagreement points labeled will aim to resolve the core differences <span>between models.</span></p>
			<p class="calibre6">Let’s explore a numerical example of the query-by-committee maximum disagreement method in active ML. For this example, we will consider a pool of 10 unlabeled data points, as shown in <span><em class="italic">Figure 2</em></span><em class="italic">.3</em>, that we want to label to train a classifier. We create two committee members (models) called M1 and M2. We evaluate each unlabeled data point using M1 and M2 to get the following <span>predicted labels:</span></p>
			<div class="calibre18">
				<div id="_idContainer020" class="img---figure">
					<img src="image/B21789_02_03.jpg" alt="Figure 2.3 – A numerical example to illustrate the query-by-committee maximum disagreement method" class="calibre33"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.3 – A numerical example to illustrate the query-by-committee maximum disagreement method</p>
			<p class="calibre6">Then, we select the data point with the maximum disagreement between the two committee members. Here, data points 1, 4, 5, 8, and 9 have different predicted labels by M1 and M2. We<a id="_idIndexMarker073" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> select<a id="_idIndexMarker074" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> one of these points, say point 4, to query the true label from an oracle. We then add the newly labeled point to retrain the <span>committee members.</span></p>
			<p class="calibre6">We can do this with a simple <span>Python script:</span></p>
			<pre class="source-code">
import numpy as np
# Predicted labels from 2 committee members
y1 = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
y2 = np.array([1, 1, 0, 0, 1, 1, 0, 0, 1, 1])
# Calculate disagreement
disagreement = np.abs(y1 - y2)
# Find index of point with max disagreement
query_index = np.argmax(disagreement)
print(f"Data point {query_index+1} selected with maximum disagreement")</pre>			<p class="calibre6">This returns the <span>following output:</span></p>
			<pre class="source-code">
Data point 1 selected with maximum disagreement</pre>			<p class="calibre6">This process is then repeated, querying points with maximum disagreement in labels predicted <a id="_idIndexMarker075" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>by the committee, until <a id="_idIndexMarker076" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>we reach sufficient performance. The most informative points surface through the maximum disagreement of the <span>committee members.</span></p>
			<h2 id="_idParaDest-33" class="calibre9"><a id="_idTextAnchor034" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Vote entropy</h2>
			<p class="calibre6">This technique<a id="_idIndexMarker077" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> calculates the entropy over <a id="_idIndexMarker078" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>the label votes from each model in the ensemble committee. <strong class="bold">Entropy</strong> represents the overall uncertainty, where higher entropy means the models have a wider spread of predictions. Lower entropy indicates the models largely agree on the label. Querying the data points with maximum entropy in the vote distribution helps target the instances where the committee displays the highest collective uncertainty and disagreement. Getting these maximally entropic points labeled will push the ensemble toward greater consensus. Overall, vote entropy identifies cases that divide the committee the most, focusing labeling on their disagreements. If we go back to using a numerical example to better understand how the query-by-committee vote entropy method works, we can once again use a pool of 10 unlabeled data points, as shown in <span><em class="italic">Figure 2</em></span><em class="italic">.4</em>, and a committee of two models, M1 and M2. We get the following predicted probabilities for each class on the <span>data points:</span></p>
			<div class="calibre18">
				<div id="_idContainer021" class="img---figure">
					<img src="image/B21789_02_04.jpg" alt="Figure 2.4 – A numerical example to illustrate the query-by-committee vote entropy method" class="calibre34"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.4 – A numerical example to illustrate the query-by-committee vote entropy method</p>
			<p class="calibre6">We calculate the vote entropy for each point <span>as follows:</span></p>
			<p class="calibre6"><img src="image/6.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" width="439" height="73" class="calibre35"/></p>
			<p class="calibre6">Here, <img src="image/7.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" width="104" height="46" class="calibre36"/> is <a id="_idIndexMarker079" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>averaged over the <span>committee</span><span><a id="_idIndexMarker080" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/></span><span> members.</span></p>
			<p class="calibre6">The probabilities from the committee members are averaged when calculating the vote entropy because we want to measure the total uncertainty or disagreement of the entire committee on a data point. By averaging, we essentially get the <em class="italic">vote</em> of the full committee on the probabilities of each class, rather than just considering individual members’ predictions. This allows us to select the data points where the committee has the most uncertainty or disagrees the most with <span>its predictions:</span></p>
			<div class="calibre18">
				<div id="_idContainer024" class="img---figure">
					<img src="image/B21789_02_05.jpg" alt="Figure 2.5 – A numerical example to illustrate the query-by-committee vote entropy method with averages per class and entropy calculated" class="calibre37"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.5 – A numerical example to illustrate the query-by-committee vote entropy method with averages per class and entropy calculated</p>
			<p class="calibre6">The points with maximum entropy will have the most disagreement among models. In <span><em class="italic">Figure 2</em></span><em class="italic">.5</em>, points 1, 4, 5, 8, and 9 have the highest entropy, so we query their labels. The next step <a id="_idIndexMarker081" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>would be to retrain the <a id="_idIndexMarker082" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>models and repeat <span>the process.</span></p>
			<p class="calibre6">We can write this with some Python code <span>as well:</span></p>
			<pre class="source-code">
import numpy as np
p1 = np.array([[0.6, 0.4], [0.2, 0.8], [0.8, 0.2], [0.4, 0.6], [0.7, 0.3],
               [0.2, 0.8], [0.9, 0.1], [0.5, 0.5], [0.3, 0.7], [0.1, 0.9]])
p2 = np.array([[0.3, 0.7], [0.1, 0.9], [0.9, 0.1], [0.7, 0.3], [0.4, 0.6],
               [0.1, 0.9], [0.8, 0.2], [0.4, 0.6], [0.6, 0.4], [0.2, 0.8]])
# Average probabilities per class
p_class0 = (p1[:, 0] + p2[:, 0]) / 2
p_class1 = (p1[:, 1] + p2[:, 1]) / 2
p_avg = np.concatenate((p_class0.reshape(-1, 1), \
    p_class1.reshape(-1, 1)), axis=1)
# Calculate entropy
H = -np.sum(p_avg * np.log2(p_avg), axis=1)
query_index = np.argmax(H)
print(f"Data point {query_index+1} selected with maximum entropy of {H[query_index]}")</pre>			<p class="calibre6">The output of this script is <span>as follows:</span></p>
			<pre class="source-code">
Data point 1 selected with maximum entropy of 0.9927744539878083</pre>			<p class="calibre6">Next, we will<a id="_idIndexMarker083" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> move our focus to computing<a id="_idIndexMarker084" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> predictions using the KL <span>divergence method.</span></p>
			<h2 id="_idParaDest-34" class="calibre9"><a id="_idTextAnchor035" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Average KL divergence</h2>
			<p class="calibre6">This method <a id="_idIndexMarker085" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>measures<a id="_idIndexMarker086" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> the <strong class="bold">Kullback-Leibler divergence</strong> (<strong class="bold">KL divergence</strong>) between <a id="_idIndexMarker087" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>each committee member’s predicted label distribution and the average predicted distribution across <span>all members.</span></p>
			<p class="calibre6">KL divergence is defined <span>as follows:</span></p>
			<p class="calibre6"><img src="image/8.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mfenced open=&quot;|&quot; close=&quot;)&quot;&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" width="586" height="86" class="calibre38"/></p>
			<p class="calibre6">Here, P and Q are two <span>probability distributions.</span></p>
			<p class="calibre6">The data points with the highest average KL divergence are then queried. A higher KL divergence indicates a larger difference between a model’s predictions and the committee consensus. Querying points with maximum divergence targets instances where individual models strongly disagree with the overall ensemble. Labeling these high-divergence points will bring the individual models closer to the committee average. Average KL divergence identifies cases with outlying model predictions to focus labeling on reconciliation. Let’s take a look at our numerical example for the query-by-committee average KL divergence method. Again, we’re using the pool of 10 unlabeled data points, as shown in <span><em class="italic">Figure 2</em></span><em class="italic">.6</em>, and a committee of two models, M1 and M2. We get the predicted class probabilities on each data point from M1 and M2 and calculate the KL divergence between M1’s and M2’s predictions <a id="_idIndexMarker088" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>for <span>each </span><span><a id="_idIndexMarker089" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/></span><span>point:</span></p>
			<div class="calibre18">
				<div id="_idContainer026" class="img---figure">
					<img src="image/B21789_02_06.jpg" alt="Figure 2.6 – A numerical example to illustrate the query-by-committee average KL divergence method" class="calibre39"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.6 – A numerical example to illustrate the query-by-committee average KL divergence method</p>
			<p class="calibre6">We average the KL divergence between M1 and M2, and M2 and M1. We calculate the KL divergence in both directions (KL(M1||M2) and KL(M2||M1)) – because KL divergence is asymmetric, it will give different values depending on <span>the direction.</span></p>
			<p class="calibre6">The KL divergence from M1 to M2, KL(M1||M2), measures how well M2’s distribution approximates M1’s. On the other hand, KL(M2||M1) measures how well M1’s distribution <span>approximates M2’s.</span></p>
			<p class="calibre6">In query-by-committee, we want to measure the total disagreement between the two committee members’ distributions. Just using KL(M1||M2) or just using KL(M2||M1) will not capture the full divergence. By taking the average of KL(M1||M2) and KL(M2||M1), we get a symmetric measure of the total divergence between the two distributions. This gives a better indication of the overall disagreement between the two committee members on a <span>data point.</span></p>
			<p class="calibre6">Taking the average KL in both directions ensures we select the points with maximum mutual divergence between the two models’ predictions. This surfaces the most informative points for labeling to resolve the committee’s uncertainty. The point with maximum average KL divergence has the most disagreement. So, here, points 1, 4, 5, and 9 have the highest average KL divergence. We would then query these labels, retrain the models, and repeat <span>the process.</span></p>
			<p class="calibre6">We can write <a id="_idIndexMarker090" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>this with some<a id="_idIndexMarker091" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> Python code <span>as well:</span></p>
			<pre class="source-code">
import numpy as np
p1 = np.array([[0.6, 0.4], [0.2, 0.8], [0.8, 0.2], [0.4, 0.6], [0.7, 0.3],
               [0.2, 0.8], [0.9, 0.1], [0.5, 0.5], [0.3, 0.7], [0.1, 0.9]])
p2 = np.array([[0.3, 0.7], [0.1, 0.9], [0.9, 0.1], [0.7, 0.3], [0.4, 0.6],
               [0.1, 0.9], [0.8, 0.2], [0.4, 0.6], [0.6, 0.4], [0.2, 0.8]])
KL1 = np.sum(p1 * np.log(p1 / p2), axis=1)
KL2 = np.sum(p2 * np.log(p2 / p1), axis=1)
avg_KL = (KL1 + KL2) / 2
print("KL(M1||M2):", KL1)
print("KL(M2||M1):", KL2)
print("Average KL:", avg_KL)
query_index = np.argmax(avg_KL)
print("\nData point", query_index+1, "selected with max average KL of", avg_KL[query_index])</pre>			<p class="calibre6">Here’s the output <span>we get:</span></p>
			<pre class="source-code">
KL(M1||M2): [0.19204199 0.04440301 0.04440301 0.19204199 0.1837869  0.04440301
0.03669001 0.020411   0.1837869  0.03669001]
KL(M2||M1): [0.1837869  0.03669001 0.03669001 0.1837869  0.19204199 0.03669001
0.04440301 0.02013551 0.19204199 0.04440301]
Average KL: [0.18791445 0.04054651 0.04054651 0.18791445 0.18791445 0.04054651
0.04054651 0.02027326 0.18791445 0.04054651]
Data point 1 selected with max average KL of 0.18791444527430518</pre>			<p class="calibre6">Upon<a id="_idIndexMarker092" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> exploring<a id="_idIndexMarker093" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> different methods that are used to perform query-by-committee sampling, we’ve noticed that it can be quite computationally intensive. Indeed, as shown in <span><em class="italic">Figure 2</em></span><em class="italic">.7</em>, the query-by-committee technique is an iterative approach that requires retraining the models from the committee every time new labeled data is added to the <span>training set:</span></p>
			<div class="calibre18">
				<div id="_idContainer027" class="img---figure">
					<img src="image/B21789_02_07.jpg" alt="Figure 2.7 – The iteration process in the query-by-committee sampling technique" class="calibre40"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.7 – The iteration process in the query-by-committee sampling technique</p>
			<p class="calibre6">In conclusion, this technique is designed to identify informative query points by quantifying the<a id="_idIndexMarker094" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> level of <a id="_idIndexMarker095" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>disagreement among the ensemble models and offers several <span>key advantages:</span></p>
			<ul class="calibre16">
				<li class="calibre20">It promotes diversity by finding points that various models interpret differently. The techniques can effectively prioritize query points that are likely to provide valuable information, thus improving the overall quality of the query-based <span>learning process.</span></li>
				<li class="calibre20">It encourages exploration by actively seeking out query points that are less predictable or commonly known, allowing for a more comprehensive understanding of <span>the dataset.</span></li>
				<li class="calibre20">It provides the ability to construct committees with an array of distinct models such as SVMs, NNs, and many others. This versatility allows for a diverse range of strategies and approaches to be employed when making important decisions. By leveraging these various models, you can gain deeper insights and improve the overall performance of your committee. The query-by-committee approach differs from traditional techniques such as bagging and boosting. Its main objective is to choose the most informative unlabeled data points for labeling and inclusion in the training set. On the other hand, traditional ensemble methods such as bagging and boosting focus on combining multiple models to enhance overall predictive performance. Indeed, query-by-committee methods calculate disagreement between committee members to find optimal queries for labeling, as we have seen previously. Traditional ensembles combine predictions through voting or averaging to produce a <span>unified prediction.</span></li>
				<li class="calibre20">It is very useful in situations where the unlabeled data pool contains a limited representation of the underlying distribution. By combining the opinions and predictions of different committee members, query-by-committee methods can effectively address the challenges posed by poorly covered distributions in unlabeled <span>data pools.</span></li>
			</ul>
			<p class="calibre6">By leveraging the varying opinions of the committee, query-by-committee enhances the overall <a id="_idIndexMarker096" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>performance <a id="_idIndexMarker097" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>of the <span>learning system.</span></p>
			<p class="calibre6">We will now delve deeper into the implementation of EMC strategies and explore their <span>potential benefits.</span></p>
			<h1 id="_idParaDest-35" class="calibre8"><a id="_idTextAnchor036" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Labeling with EMC sampling</h1>
			<p class="calibre6">EMC aims to <a id="_idIndexMarker098" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>query points that will induce the greatest change in the current model when labeled and trained on. This focuses labeling on points with the highest <span>expected impact.</span></p>
			<p class="calibre6">EMC techniques involve selecting a specific data point to label and learn from to cause the most significant alteration to the current model’s parameters and predictions. The core idea is to query the point that would impact the maximum change to the model’s parameters if we knew its label. By carefully identifying this particular data point, the EMC method aims to maximize the impact on the model and improve its overall performance. The process involves assessing various factors and analyzing the potential effects of each data point, ultimately choosing the one that is expected to yield the most substantial changes to the model, as depicted in <span><em class="italic">Figure 2</em></span><em class="italic">.8</em>. The goal is to enhance the model’s accuracy and make it more effective in <span>making predictions.</span></p>
			<p class="calibre6">When we refer to querying points that lead to larger updates in the model targets, what we are discussing is identifying highly informative examples located in uncertain areas of the input space. These examples play a crucial role in influencing and enhancing the model’s performance. By paying attention to these specific instances, we can gain deeper insights into the complexities and subtleties of the input space, resulting in a more thorough understanding and improved <span>overall outcomes:</span></p>
			<div class="calibre18">
				<div id="_idContainer028" class="img---figure">
					<img src="image/B21789_02_08.jpg" alt="Figure 2.8 – EMC sampling" class="calibre41"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.8 – EMC sampling</p>
			<p class="calibre6">The initial model is<a id="_idIndexMarker099" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> trained using the training dataset. Then, the unlabeled samples are evaluated based on the changes in model outputs after including them in the training set. In <span><em class="italic">Figure 2</em></span><em class="italic">.8</em>, the graphs show the resulting <strong class="bold">model output change</strong> (<strong class="bold">MOC</strong>) for three example samples. The sample that leads <a id="_idIndexMarker100" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>to the largest output change, when considering all data, is chosen to be <span>labeled next.</span></p>
			<p class="calibre6">In other words, in EMC sampling, the process begins by ranking the unlabeled examples. This ranking is determined by estimating the expected change that would occur in the model’s predictions if each example were to be labeled. This estimation takes into account various factors and considerations, ultimately providing a basis for the prioritization <span>of labeling.</span></p>
			<p class="calibre6">This estimation is typically based on calculating the <strong class="bold">expected gradient length</strong> (<strong class="bold">EGL</strong>). The EGL method<a id="_idIndexMarker101" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> estimates the expected length of the gradient of the loss function if the model was trained on the newly labeled point. When training discriminative probabilistic models, gradient-based optimization is commonly used. To assess the <em class="italic">change</em> in the model, we can examine the size of the training gradient. This gradient refers to the vector that is employed to update the parameter values during the training process. In simpler terms, the learner should choose the instance, <img src="image/9.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;mml:mi&gt;G&lt;/mml:mi&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;*&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;/mml:math&gt;" width="61" height="44" class="calibre42"/>, that, when labeled and included in the labeled dataset, (<img src="image/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;/mml:math&gt;" width="39" height="29" class="calibre43"/>), would result in the greatest magnitude for the new <span>training gradient:</span></p>
			<p class="calibre6"><img src="image/11.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;*&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;argmax&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mfenced open=&quot;‖&quot; close=&quot;‖&quot;&gt;&lt;mrow&gt;&lt;mo&gt;∇&lt;/mo&gt;&lt;mi mathvariant=&quot;script&quot;&gt;l&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi mathvariant=&quot;script&quot;&gt;L&lt;/mi&gt;&lt;mo&gt;∪&lt;/mo&gt;&lt;mfenced open=&quot;〈&quot; close=&quot;〉&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" width="793" height="75" class="calibre44"/></p>
			<p class="calibre6">Here, ||.|| is the Euclidean norm of each resulting gradient vector, θ is the model parameters, x is an unlabeled point, y is the predicted label for x, and <img src="image/12.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;∇&lt;/mo&gt;&lt;mi mathvariant=&quot;script&quot;&gt;l&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi mathvariant=&quot;script&quot;&gt;L&lt;/mi&gt;&lt;mo&gt;∪&lt;/mo&gt;&lt;mfenced open=&quot;〈&quot; close=&quot;〉&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" width="312" height="54" class="calibre45"/> is the new gradient that would be obtained by adding the training tuple, <img src="image/13.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mfenced open=&quot;⟨&quot; close=&quot;⟩&quot; separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" width="86" height="34" class="calibre46"/>, to the labeled dataset, (<img src="image/14.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;/mml:math&gt;" width="39" height="29" class="calibre47"/>). Data points that result in a longer expected gradient are prioritized for querying. A longer gradient indicates a greater expected change in the model parameters during training. By selecting points with high expected gradient length, the model focuses on samples that will highly influence the model once labeled. This targets points in uncertain regions that will have an outsized impact on updating model predictions. In short, EGL identifies data points that are likely to substantially reshape the <span>decision boundary.</span></p>
			<p class="calibre6">By employing this <a id="_idIndexMarker102" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>technique, the algorithm can pinpoint and identify the specific data points that are anticipated to yield substantial alterations in the model’s predictions. The selected examples are subsequently sent for labeling as they are believed to possess the most value in terms of training the model effectively. Once designated, these informative samples are seamlessly integrated into the existing training data, thereby facilitating the necessary updates and improvements to the model’s overall performance <span>and accuracy.</span></p>
			<p class="calibre6">There are several key advantages of the <span>EMC method:</span></p>
			<ul class="calibre16">
				<li class="calibre20">Its ability to actively<a id="_idIndexMarker103" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> seek out influential and under-represented regions within the input space. This means that it can effectively identify areas that may have been overlooked or not given enough attention in a traditional modeling approach. Suppose we are training a model to predict housing prices. The input features are things such as square footage, number of bedrooms, location, and so on. Using a traditional modeling approach, we may collect a random sample of houses to train the model on. However, this could lead to certain neighborhoods or house styles being under-represented if they are less common. The EMC method would analyze the current model and identify areas where new training data would likely lead to the largest change in the model predictions. For example, it may find that adding more samples from older houses could better calibrate the model’s understanding of how age affects price, or gathering data from a new suburban development that is under-represented could improve the performance of houses in that area. By actively seeking these influential regions, EMC can make the model more robust with fewer overall training examples. It reduces the risk of underfitting certain areas of the input space compared to passive or random data collection. It can help uncover hidden patterns or relationships that may not be immediately apparent, further enhancing the overall understanding of <span>the dataset.</span></li>
				<li class="calibre20">It is compatible <a id="_idIndexMarker104" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>with probabilistic and kernel-based<a id="_idIndexMarker105" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> models. By leveraging the probabilistic nature of these models, the EMC method can provide insightful and accurate predictions. Additionally, its compatibility with kernel-based models allows for an enhanced understanding of complex data patterns and relationships. This combination of features makes the EMC method a powerful tool for analyzing and interpreting data in a wide range <span>of domains.</span></li>
				<li class="calibre20">It allows for estimation without the need for full retraining at each step. This means that the process can be more efficient and less time-consuming as it eliminates the need to repeatedly train the model from scratch. Instead, the method enables model changes to be estimated by focusing on the expected changes in the model’s parameters. By utilizing this approach, you can save valuable time and resources while still obtaining accurate and <span>reliable</span><span><a id="_idIndexMarker106" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/></span><span> estimations.</span></li>
			</ul>
			<p class="calibre6">In summary, EMC queries aim to identify points with the highest potential impact on the model. It selects those with the maximum expected impact. This method is widely discussed in literature but not implemented in practice due to its high <span>computational cost.</span></p>
			<p class="calibre6">Next, we’ll explore EER sampling. This technique reduces the model’s error by selecting points<a id="_idIndexMarker107" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> that are expected to contribute the most to error reduction. By strategically sampling these points, we can improve overall <span>model accuracy.</span></p>
			<h1 id="_idParaDest-36" class="calibre8"><a id="_idTextAnchor037" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Sampling with EER</h1>
			<p class="calibre6">EER focuses on<a id="_idIndexMarker108" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> measuring the potential decrease in generalization error instead of the expected change in the model, as seen in the previous approach. The goal is to estimate the anticipated future error of a model by training it with the current labeled set and the remaining unlabeled samples. EER can be defined <span>as follows:</span></p>
			<p class="calibre6"><img src="image/15.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi mathvariant=&quot;script&quot;&gt;L&lt;/mi&gt;&lt;/msub&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mover&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" width="501" height="68" class="calibre48"/></p>
			<p class="calibre6">Here, <img src="image/16.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;/mml:math&gt;" width="39" height="29" class="calibre49"/> is the pool of paired labeled data, <img src="image/17.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" width="170" height="47" class="calibre50"/>, and <img src="image/18.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" width="129" height="52" class="calibre51"/> is the estimated output distribution. L is a chosen loss function that measures the error between the true distribution, <img src="image/19.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" width="109" height="46" class="calibre52"/>, and the learner’s <span>prediction, </span><span><img src="image/20.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:math&gt;" width="134" height="52" class="calibre53"/></span><span>.</span></p>
			<p class="calibre6">This involves selecting the instance that is expected to have the lowest future error (referred to as <em class="italic">risk</em>) for querying. This focuses active ML on reducing long-term generalization errors rather than just immediate <span>training performance.</span></p>
			<p class="calibre6">In other words, EER selects unlabeled data points that, when queried and learned from, are expected to significantly reduce the model’s errors on new data points from the same distribution. By focusing on points that minimize future expected errors, as shown in <span><em class="italic">Figure 2</em></span><em class="italic">.9</em>, EER aims to identify valuable training examples that will enhance the model’s ability to generalize effectively. This technique targets high-value training examples that will improve the model’s performance by minimizing <span>incorrect predictions.</span></p>
			<p class="calibre6">This approach helps prevent short-term overfitting by avoiding the inclusion of redundant similar examples and instead focusing on diverse edge cases that better span the feature space. For instance, in the case of an image classifier, the technique may prioritize the inclusion of diverse edge cases that capture a wide range of features rather than including redundant <span>similar examples:</span></p>
			<div class="calibre18">
				<div id="_idContainer041" class="img---figure">
					<img src="image/B21789_02_09.jpg" alt="Figure 2.9 – EER sampling" class="calibre54"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.9 – EER sampling</p>
			<p class="calibre6">Computing the expected model’s prediction error can be done using various loss functions, such<a id="_idIndexMarker109" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> as the log loss, which is defined as <img src="image/21.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;l&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi mathvariant=&quot;script&quot;&gt;L&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" width="518" height="58" class="calibre55"/>, or the 0/1 loss, which is defined <span>as </span><span><img src="image/22.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mover&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;true&quot;&gt;ˆ&lt;/mo&gt;&lt;/mover&gt;&lt;mi mathvariant=&quot;script&quot;&gt;L&lt;/mi&gt;&lt;/msub&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" width="346" height="63" class="calibre56"/></span><span>.</span></p>
			<p class="calibre6">EER incurs a significant time cost due to the estimation of error reduction. To calculate the expected generalization error, the classifier must be re-optimized for each data point, considering its possible labels. Additionally, it is necessary to re-infer the labels of other data points. However, this technique offers a couple of <span>key advantages:</span></p>
			<ul class="calibre16">
				<li class="calibre20">It allows direct<a id="_idIndexMarker110" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> optimization of the true objective of reducing the generalization error instead of solely focusing on improving training performance. By prioritizing the reduction of the generalization error, EER allows for more accurate and reliable predictions in real-world scenarios. This not only enhances the overall performance of the model but also ensures that it can effectively generalize to <span>unseen data.</span></li>
				<li class="calibre20">It considers the impact on unseen data points, going beyond just the training set. By doing so, EER helps to mitigate overfitting, which is a common challenge in ML and statistical modeling. Overfitting occurs when a model performs exceedingly well on the training data but fails to generalize well to new, unseen data. EER tackles this issue head-on by incorporating a comprehensive evaluation of potential errors and their reduction. This ensures that the model’s performance is not limited to the training set and instead extends<a id="_idIndexMarker111" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to real-world scenarios, making it a valuable tool in <span>data-driven decision-making.</span></li>
			</ul>
			<p class="calibre6">EER is a predictive and robust query framework that focuses on maximally reducing the model’s generalization error. Similar to the EMC method, the EER method is a topic of extensive discussion in literature. However, it has not been widely adopted in practical <a id="_idIndexMarker112" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>applications primarily because of the significant computational resources <span>it demands.</span></p>
			<p class="calibre6">The next sampling method that we will explore, density-weighted sampling, aims to improve diversity by selecting representative points from all <span>density regions.</span></p>
			<h1 id="_idParaDest-37" class="calibre8"><a id="_idTextAnchor038" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Understanding density-weighted sampling methods</h1>
			<p class="calibre6"><strong class="bold">Density-weighted methods</strong> are <a id="_idIndexMarker113" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>approaches that aim to carefully choose points that accurately represent the densities of their respective local neighborhoods. By doing so, these methods prioritize the labeling of diverse cluster centers, ensuring a comprehensive and inclusive representation of <span>the data.</span></p>
			<p class="calibre6">Density-weighted techniques are highly beneficial and effective when it comes to querying points. These techniques utilize a clever combination of an informativeness measure and a density weight. An <strong class="bold">informativeness measure</strong> provides a score of how useful a data point would be for improving the model if we queried its label. Higher informativeness indicates the point is more valuable to label and add to the training set. In this chapter, we have explored several informativeness measures, such as uncertainty and disagreement. In density-weighted methods, the informativeness score is combined with a density weight to ensure we select representative and diverse queries across different regions of the input space. This is done by assigning a weight to each data point based on both its density and its informativeness. Data points with higher informativeness and lower density will be given a higher weight, and will therefore be more likely to be selected for labeling. Points in dense clusters receive lower weights. The density and informativeness are combined through multiplicative, exponential, or additive formulations. This balances informativeness with density to <span>achieve diversity.</span></p>
			<p class="calibre6">The density weight represents the density of the local neighborhood surrounding each point, allowing for a more comprehensive and accurate sampling of points from different densities, as shown in <span><em class="italic">Figure 2</em></span><em class="italic">.10</em>. This approach avoids the pitfall of solely focusing on dense clusters, which could result in redundant points. By taking into account the <a id="_idIndexMarker114" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>density weight, these techniques guarantee that the selected points effectively capture the overall distribution of the dataset. As a result, the obtained results are more meaningful and provide deeper insights into <span>the data:</span></p>
			<div class="calibre18">
				<div id="_idContainer044" class="img---figure">
					<img src="image/B21789_02_10.jpg" alt="Figure 2.10 – Density-weighted sampling" class="calibre57"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.10 – Density-weighted sampling</p>
			<p class="calibre6">In <span><em class="italic">Figure 2</em></span><em class="italic">.10</em>, we can observe the significance of sample density in the active ML process. With instance 1 being positioned near the decision boundary, this makes it a prime candidate for being chosen as the most uncertain one. However, if we analyze the situation more closely, it becomes apparent that selecting instance 2 would be more advantageous in terms of enhancing the overall quality of the model. This is because instance 2 not only represents itself accurately but also acts as a representative for other instances within the data distribution. Therefore, its inclusion in the active ML process can lead to more comprehensive and reliable <span>model improvements.</span></p>
			<p class="calibre6">Implementing queries that would select instance 2 in the preceding example can be done with various density-weighted sampling methods, such as kNN density, <strong class="bold">kernel density estimation</strong> (<strong class="bold">KDE</strong>), K-means clustering, and <strong class="bold">maximum mean </strong><span><strong class="bold">discrepancy</strong></span><span> (</span><span><strong class="bold">MMD</strong></span><span>).</span></p>
			<p class="calibre6">Let’s start with <a id="_idIndexMarker115" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>the imports and generating the <span>dummy data:</span></p>
			<pre class="source-code">
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
from sklearn.neighbors import KernelDensity
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import pairwise_distances
# Generate sample 2D data
np.random.seed(1)
X = np.concatenate((np.random.randn(100, 2) + [2, 2],
                    np.random.randn(50, 2)))</pre>			<p class="calibre6">Now, let’s understand and apply different density-based techniques for our <strong class="source-inline">X</strong> <span>sample data:</span></p>
			<ul class="calibre16">
				<li class="calibre20"><strong class="bold">kNN density</strong> calculates the <a id="_idIndexMarker116" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>local density around each data point using its <em class="italic">k-nearest neighbors</em>. The density is estimated by taking the inverse of the average distance<a id="_idIndexMarker117" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to the k-closest points. Denser points have higher density, while isolated points have lower density. The estimated density is then used as a weight. When combined with informativeness criteria such as uncertainty, points in sparser neighborhoods get higher density weights, increasing their priority. kNN density weighting provides an efficient way to increase sample diversity and avoid over-sampling clusters <span>when querying:</span><pre class="source-code">
# kNN density
knn = NearestNeighbors(n_neighbors=5).fit(X)
distances, _ = knn.kneighbors(X)
knn_density = 1 / distances.sum(axis=1)</pre></li>				<li class="calibre20"><strong class="bold">KDE</strong> estimates the local density around each point using a kernel function centered on the point. Typically, a Gaussian kernel is used. The densities from the kernels of nearby points are summed to get the overall estimated density. As with kNN <a id="_idIndexMarker118" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>density, points in sparser regions will have lower kernel density compared to crowded areas. These density values can be used as weights when combined with informativeness criteria. Points in isolated clusters will be up-weighted, increasing their query priority. KDE provides a smooth, probabilistic estimate of local density, as opposed to the discrete clusters of kNN. It is more computationally expensive than kNN but can be implemented efficiently in high dimensions. KDE weighting focuses sampling on representative <span>low-density points:</span><pre class="source-code">
# Kernel density estimation
kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(X)
kde_dens = np.exp(kde.score_samples(X))</pre></li>				<li class="calibre20"><strong class="bold">K-means density</strong> clusters the unlabeled data points using k-means into k clusters. The size of each cluster indicates its density – smaller clusters correspond to sparser regions. This cluster density can be used as a weight when combined with informativeness criteria. Points in smaller, tighter clusters get increased weight, making them more likely to be queried. This balances sampling across varying densities. K-means provides a simple way to estimate density and identify representative points from all densities. It is fast and scales well to large datasets. One limitation is determining the number of clusters, k, upfront. K-means density weighting focuses active ML on diverse cases from all <span>densities equally:</span><pre class="source-code">
# K-means clustering
km = KMeans(n_clusters=5).fit(X)
km_density = 1 / pairwise_distances(X, 
    km.cluster_centers_).sum(axis=1)</pre></li>				<li class="calibre20"><strong class="bold">MMD</strong> measures the <em class="italic">distance</em> between distributions to identify points in low-density regions. The MMD between a point’s neighborhood distribution and the overall data<a id="_idIndexMarker119" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> distribution is calculated. A higher MMD indicates that the local region is very different from the overall distribution, so it is likely a low-density area. These MMD density scores are then used as weights when combined with informativeness measures. Points in sparse, isolated regions with high MMD get increased priority for querying. This results in balanced sampling across varying densities, thereby avoiding cluster oversampling. MMD provides a principled way to estimate density that captures useful nonlinear variations. MMD density weighting focuses active ML on representative <span>low-density areas:</span><pre class="source-code">
# Maximum Mean Discrepancy
mmd = pairwise_distances(X).mean()
mmd_density = 1 / pairwise_distances(X).sum(axis=1)</pre></li>			</ul>
			<p class="calibre6">Now, let’s visualize these density-weight <span>sampling methods:</span></p>
			<pre class="source-code">
# Plot the density estimations
fig, axs = plt.subplots(2, 2, figsize=(12, 8))
axs[0, 0].scatter(X[:, 0], X[:, 1], c=knn_density)
axs[0, 0].set_title('kNN Density')
axs[0, 1].scatter(X[:, 0], X[:, 1], c=kde_dens)
axs[0, 1].set_title('Kernel Density')
axs[1, 0].scatter(X[:, 0], X[:, 1], c=km_density)
axs[1, 0].set_title('K-Means Density')
axs[1, 1].scatter(X[:, 0], X[:, 1], c=mmd_density)
axs[1, 1].set_title('Maximum mean discrepancy (MMD) Density')
fig.suptitle('Density-Weighted Sampling methods')
plt.show()</pre>			<p class="calibre6">The resulting graph <a id="_idIndexMarker120" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>is presented in <span><em class="italic">Figure 2</em></span><span><em class="italic">.11</em></span><span>:</span></p>
			<div class="calibre18">
				<div id="_idContainer045" class="img---figure">
					<img src="image/B21789_02_11.jpg" alt="Figure 2.11 – A comparison of different density-weighted sampling methods" class="calibre58"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.11 – A comparison of different density-weighted sampling methods</p>
			<p class="calibre6">Density-weighted sampling methods, including the ones mentioned previously, offer <span>diverse advantages:</span></p>
			<ul class="calibre16">
				<li class="calibre20">They can help<a id="_idIndexMarker121" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> improve the performance of the ML model by selecting samples that are more likely to be informative. This is because samples that are in high-density regions of the data are more likely to be representative of the underlying distribution and therefore more likely to be informative for <span>the model.</span></li>
				<li class="calibre20">They help reduce the number of labeled samples needed to train the model. This is because density-weighted sampling can help focus the labeling effort on the most informative samples, which can lead to faster convergence of <span>the model.</span></li>
				<li class="calibre20">They can be used with any type of data. Density-weighted sampling does not make any assumptions about the data distribution, so it can be used with any type of data, including <a id="_idIndexMarker122" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>structured and <span>unstructured data.</span></li>
			</ul>
			<p class="calibre6">To conclude, density weighting, which is a technique that’s used to increase the diversity and coverage of samples, offers an effective and efficient approach. By assigning weights to each sample based on their density, this method ensures that the resulting sample set represents the underlying population more accurately. With this approach, you can obtain a more comprehensive understanding of the data, allowing for <a id="_idIndexMarker123" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>better decision-making and analysis. Overall, density weighting is a valuable tool in research and statistical analysis, allowing you to highlight hidden patterns and trends that might otherwise <span>be overlooked.</span></p>
			<p class="calibre6">Now that we have discussed several query strategies, let’s compare them to understand how they fare against <span>each other:</span></p>
			<div class="calibre18">
				<div id="_idContainer046" class="img---figure">
					<img src="image/B21789_02_12.jpg" alt="Figure 2.12 – Comparison chart for query strategies" class="calibre59"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 2.12 – Comparison chart for query strategies</p>
			<p class="calibre6"><span><em class="italic">Figure 2</em></span><em class="italic">.12</em> summarizes<a id="_idIndexMarker124" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> and compares various query strategies that have been discussed in <span>this chapter.</span></p>
			<h1 id="_idParaDest-38" class="calibre8"><a id="_idTextAnchor039" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Summary</h1>
			<p class="calibre6">In this chapter, we covered key techniques such as uncertainty sampling, query-by-committee, EMC, EER, and density weighting for designing effective active ML query strategies. Moving forward, in the next chapter, our focus will shift toward exploring strategies for managing the human in the loop. It is essential to optimize the interactions with the oracle labeler to ensure maximum efficiency in the active ML process. By understanding the intricacies of human interaction and leveraging this knowledge to streamline the labeling process, we can significantly enhance the efficiency and effectiveness of active ML algorithms.In the next chapter we will discuss how to manage the role of human labelers in <span>active ML.</span></p>
		</div>
	</div>
</div>
</body></html>