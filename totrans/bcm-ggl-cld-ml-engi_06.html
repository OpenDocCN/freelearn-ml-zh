<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer070">
<h1 class="chapter-number" id="_idParaDest-132"><a id="_idTextAnchor133"/>6 </h1>
<h1 id="_idParaDest-133"><a id="_idTextAnchor134"/>Learning BQ/BQML, TensorFlow, and Keras</h1>
<p>After building the GCP and Python foundations in part one and understanding the ML concepts and development process in part two, we are now entering part three of the book: <em class="italic">Mastering ML in GCP</em>. We will start by learning how Google does ML for structured data and the Google ML frameworks TensorFlow and Keras. In this chapter, we will cover the following topics:</p>
<ul>
<li>GCP BQ</li>
<li>GCP BQML</li>
<li>Introduction to TensorFlow</li>
<li>Introduction to Keras</li>
</ul>
<p>In recent years, relational databases have been widely used in many enterprises, and thus structural data is a big portion of the big data available for many businesses. Google’s BQ and BQML play a big role in relational/structural data processing and analytics.</p>
<h1 id="_idParaDest-134"><a id="_idTextAnchor135"/>GCP BQ </h1>
<p>As we mentioned in the <em class="italic">Google Cloud BigQuery</em> section in <a href="B18333_01.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Comprehending Google Cloud Services</em>, BigQuery is a petabyte cloud enterprise data warehouse. BigQuery has the following features:</p>
<ul>
<li><strong class="bold">Fully managed GCP service</strong> – you do not concern yourself with the underlying <a id="_idIndexMarker373"/>backend data processing infrastructure, including compute, network storage, and other resources.</li>
<li><strong class="bold">Serverless</strong> – you do not manage any servers in BigQuery. All of the data processing <a id="_idIndexMarker374"/>engines are taken care of by Google, including the invisible BigQuery BI Engine and ML Engine.</li>
<li><strong class="bold">Highly scalable</strong> – it is <a id="_idIndexMarker375"/>incredibly elastic and can scale to any size, quickly and seamlessly. </li>
<li><strong class="bold">Cost-effective</strong> – you are <a id="_idIndexMarker376"/>only charged for the BigQuery resources you consume.</li>
</ul>
<p>In the Google Cloud big data processing pipeline, BigQuery is a key service for data ingestion, storing, analyzing, and visualization, as follows: </p>
<ul>
<li>BigQuery ingests <a id="_idIndexMarker377"/>data from data sources in three ways: archive, batch, and real-time streaming. With archived data, you can create a dataset with tables generated from data sources such as <a id="_idIndexMarker378"/>your computer, GCS, other GCP databases such as Bigtable, and Amazon <strong class="bold">Simple Storage Services</strong> (<strong class="bold">S3</strong>). With batch processing, you can load data into BigQuery from cloud storage or local storage, and the source data can be in the format of Avro, CSV, ORC, JSON, Parquet, or Firestore exports stored in GCS. Real-time events can be streamed into BigQuery. A common pattern is to push the events to GCP Pub/Sub, process them using a dataflow job, and ingest the outputs to BigQuery.</li>
<li>BigQuery stores <a id="_idIndexMarker379"/>data with scalable storage, which is ACID compliant and cost-effective. The separation of storage and compute in BigQuery provides high performance and service decoupling. </li>
<li>BigQuery <a id="_idIndexMarker380"/>processes data with an in-memory business intelligence engine – BigQuery BI Engine. Because BigQuery supports standard SQL, which is compliant with the ANSI SQL 2011 standard, it opens an avenue for the traditional relational databases and professionals to transform to BQ and BQML platforms. With SQL, BigQuery allows you to run queries, create reports and dashboards quickly, and export the results to Google Sheets or GCS.</li>
<li>With BigQuery, you <a id="_idIndexMarker381"/>can visualize your data with its integrated Google Data Studio tool. Leveraging the BigQuery connector in Data Studio, you can create a data source, a report, and charts that visualize data in BigQuery data warehouses. You can leverage other tools such as Google Datalab, Looker, and Tableau.</li>
</ul>
<p>You can launch the BigQuery service from the GCP web console, or the command-line tools from Cloud Shell – <strong class="source-inline">bq</strong> is a Python-based command-line tool. There are also a number of client libraries for programmatic access to BigQuery, using C#, Go, Java, Node.js, PHP, Python, Ruby, and so on.</p>
<h1 id="_idParaDest-135"><a id="_idTextAnchor136"/>GCP BQML</h1>
<p>BQML enables <a id="_idIndexMarker382"/>data scientists to create and train ML models directly in BigQuery using standard SQL queries. BQML improves the ML model development speed by eliminating the need to move data and directly using BigQuery datasets as training and testing datasets. BQML-trained models can be exported directly to Vertex AI (to be discussed in later chapters) or other cloud serving layers.</p>
<p>BQML can <a id="_idIndexMarker383"/>be accessed and used in the following ways:</p>
<ul>
<li>The GCP console via a web browser</li>
<li>The <strong class="source-inline">bq</strong> command-line tool via Google Cloud Shell or a VM shell</li>
<li>The BigQuery REST API</li>
<li>External tools such as Jupyter Notebook</li>
</ul>
<p>As we discussed in <a href="B18333_03.xhtml#_idTextAnchor072"><em class="italic">Chapter 3</em></a>, <em class="italic">Preparing for ML Development</em>, and <a href="B18333_04.xhtml#_idTextAnchor094"><em class="italic">Chapter 4</em></a>, <em class="italic">ML Model Developing and Deploying</em>, the ML process includes data preparation, model creation and training, model validation/evaluation, and model deployment/prediction. Let’s go over this process with BQML.</p>
<p>The <em class="italic">first step</em> is data <a id="_idIndexMarker384"/>preparation. With BQML, you can prepare the training dataset by loading CSV files in the BigQuery console and directly running SQL statements after data is imported to BigQuery. </p>
<p>The <em class="italic">second step</em> is model <a id="_idIndexMarker385"/>creation and training. BigQuery <a id="_idIndexMarker386"/>ML supports the following ML models:</p>
<ul>
<li><strong class="bold">Linear regression</strong> – where <a id="_idIndexMarker387"/>we have a number of data points, and we basically fit a line to those data points to minimize the error. </li>
<li><strong class="bold">Binary logistic regression</strong> – where <a id="_idIndexMarker388"/>we have two classes and we assign each example to one of the classes.</li>
<li><strong class="bold">Multiclass logistic regression</strong> – where <a id="_idIndexMarker389"/>we have more than two classes and we assign each example to one of the classes.</li>
<li><strong class="bold">K-means clustering</strong> – where <a id="_idIndexMarker390"/>we have a number of points and we are able to separate them into different clusters.</li>
<li>Other <a id="_idIndexMarker391"/>models are supported by BQML. For more details, please refer to <a href="https://cloud.google.com/bigquery-ml/docs/introduction#supported_models_in">https://cloud.google.com/bigquery-ml/docs/introduction#supported_models_in</a>.</li>
</ul>
<p>BQML implements the model creation and training in a single step using the BQML <strong class="source-inline">create model</strong> statement. Using <em class="italic">example 2</em> that we discussed in the previous chapters, <em class="italic">Table 6.1</em> shows two samples for the loan application processing model where the target is a binary value, <em class="italic">approval or not</em>, and the features include the application date, applicant credit score, loan amount, annual income, age, and so on. </p>
<div>
<div class="IMG---Figure" id="_idContainer066">
<img alt="Table 6.1 – Sample table structure " height="206" src="image/Figure_6.1.jpg" width="1100"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.1 – Sample table structure</p>
<p>The following is sample code for creating a model with logistic regression using the dataset from a sample table <strong class="source-inline">t</strong>:</p>
<pre class="source-code">CREATE OR REPLACE MODEL m
 OPTIONS(MODEL_TYPE='LOGISTIC_REG' DEL_TYPE='LOGISTIC_REG')
AS 
SELECT * FROM t
WHERE t.date BETWEEN '20160801' AND '20190731'</pre>
<p>When the <a id="_idIndexMarker392"/>preceding code is run, BQML will execute <a id="_idIndexMarker393"/>the <strong class="source-inline">SELECT</strong> statement to filter all of the samples ranging from August 01, 2016 to July 31, 2019, and then use the results as the dataset input to train the logistic regression model. </p>
<p>The <em class="italic">third step</em> is model validation/evaluation to determine how good the model is. With BQML, model evaluation is done using the <strong class="source-inline">ML.EVALUATE</strong> function as follows:</p>
<pre class="source-code">SELECT *
FROM
 ML.EVALUATE(MODEL `m`, (
SELECT * FROM t
WHERE t.date BETWEEN '20190801' AND '20200731'))</pre>
<p>When the preceding code is run, BQML will execute the <strong class="source-inline">SELECT</strong> statement to filter all of the samples ranging from August 01, 2019 to July 31, 2020, and then use the results as the dataset input to evaluate the performance of the classifier (the logistic regression model). When the code is completed, you can view the results. </p>
<div>
<div class="IMG---Figure" id="_idContainer067">
<img alt="Table 6.2 – Sample BQML model evaluation result " height="151" src="image/Figure_6.2.jpg" width="1550"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.2 – Sample BQML model evaluation result</p>
<p><em class="italic">Table 6.2</em> shows the sample metrics for our binary classification model as follows:</p>
<ul>
<li><strong class="source-inline">Precision</strong> – a metric <a id="_idIndexMarker394"/>that identifies the frequency with which a model was correct when predicting the positive class.</li>
<li><strong class="source-inline">recall</strong> – a metric <a id="_idIndexMarker395"/>that answers the following question: out of all the possible positive labels, how many did the model correctly identify?</li>
<li><strong class="source-inline">accuracy</strong> – the <a id="_idIndexMarker396"/>fraction of predictions that a classification model got right.</li>
<li><strong class="source-inline">f1_score</strong> – the <a id="_idIndexMarker397"/>harmonic average of the precision and recall. </li>
<li><strong class="source-inline">log_loss</strong> – the <a id="_idIndexMarker398"/>loss function used in a logistic regression. </li>
<li><strong class="source-inline">roc_auc</strong> – the <a id="_idIndexMarker399"/>area under the ROC curve. </li>
</ul>
<p>Depending <a id="_idIndexMarker400"/>on the business use case, we can review the evaluation results, measure the model performance, and find the business indications. During the model evaluation process, we can tune model perimeters using the <strong class="source-inline">model create</strong> statement. More details <a id="_idIndexMarker401"/>are at <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-hyperparameter-tuning">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-hyperparameter-tuning</a>.</p>
<p>In the <em class="italic">fourth step</em>, we can use the model to predict production outcomes. A sample query to predict the outcome is as follows:</p>
<pre class="source-code">SELECT * 
FROM 
ML.PREDICT(MODEL `m`, (
SELECT * FROM t
WHERE t.date BETWEEN '20200801' AND '20210731'))</pre>
<p>As you can see from the preceding four steps, BQML completes the full process of ML development within the BigQuery cloud service. For structured data, BQML has many advantages for our data scientists to train and develop ML models.</p>
<p>Google <a id="_idIndexMarker402"/>Cloud BQ and BQML provide services for structured data processing and learning, and they are widely used in many business use cases. In the following section, we will introduce Google’s ML frameworks, TensorFlow and Keras. </p>
<h1 id="_idParaDest-136"><a id="_idTextAnchor137"/>Introduction to TensorFlow</h1>
<p>TensorFlow is <a id="_idIndexMarker403"/>an end-to-end open source platform for ML, developed by Google Brain, and it is one of the most widely used ML frameworks by data scientists. </p>
<p><strong class="bold">TensorFlow flow tensors</strong> – TensorFlow’s <a id="_idIndexMarker404"/>name is directly derived from its core framework components: tensors. Let’s start by understanding <strong class="bold">tensors</strong>.</p>
<h2 id="_idParaDest-137"><a id="_idTextAnchor138"/>Understanding the concept of tensors</h2>
<p>A tensor is a <a id="_idIndexMarker405"/>container that holds data of various sizes and shapes in an N-dimensional space. A tensor can be originated from the input data or a computation of the input data. In ML, we call the tensor components <strong class="bold">features</strong>. A tensor has three main characters to describe itself, called a tensor’s <strong class="bold">rank</strong>, <strong class="bold">shape</strong>, and <strong class="bold">dtype</strong> as follows:</p>
<ul>
<li>Rank is <a id="_idIndexMarker406"/>the number of directions</li>
<li>Shape is <a id="_idIndexMarker407"/>the number of elements in each direction</li>
<li>Dtype is <a id="_idIndexMarker408"/>the data type</li>
</ul>
<p>The rank of a tensor specifies the number of directions being measured for a tensor. From the number of ranks, a tensor can be categorized as follows:</p>
<ul>
<li><strong class="bold">Rank 0</strong>: A tensor that only has a magnitude and 0 directions. </li>
<li><strong class="bold">Rank 1</strong>: A tensor that has one direction and a magnitude.</li>
<li><strong class="bold">Rank 2</strong>: A tensor that has two directions (rows and columns), with each element having a magnitude. </li>
<li><strong class="bold">Rank 3</strong>: A tensor that has three directions.</li>
<li><strong class="bold">Rank 4</strong>: A tensor with four directions.</li>
<li><strong class="bold">High-rank tensors</strong>.</li>
</ul>
<p><em class="italic">Figure 6.3</em> illustrates the <a id="_idIndexMarker409"/>ranks of the tensors using the basic geometrical objects as follows: </p>
<ul>
<li>A rank 0 tensor is a scalar with a magnitude but no directions. </li>
<li>A rank 1 tensor is a vector with one direction and a magnitude.</li>
<li>A rank 2 tensor is a matrix with two directions – its elements have magnitudes.</li>
<li>A rank 3 tensor has three directions – its elements have two-dimensional magnitudes.</li>
<li>A rank 4 tensor is a list of rank 3 sensors.</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer068">
<img alt="Figure 6.3 – Ranks of tensors " height="366" src="image/Figure_6.3.jpg" width="1358"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Ranks of tensors</p>
<p>If we use the <strong class="source-inline">list</strong> data type, which we discussed in The <em class="italic">Python Basic Data Structure</em> section in <a href="B18333_02.xhtml#_idTextAnchor054"><em class="italic">Chapter 2</em></a>, <em class="italic">Mastering Python Programming</em>, to define the rank of a tensor, then <em class="italic">each rank of tensors gives us a list of the objects from the previous rank of sensors</em> as follows:</p>
<ul>
<li>Rank 1 tensors (vectors) gave us a list of rank 0 tensors (scalars).</li>
<li>Rank 2 tensors (matrixes) gave us a list of rank 1 tensors (vectors).</li>
<li>Rank 3 tensors (tensors) gave us a list of rank 2 tensors (matrixes).</li>
<li>Rank 4 tensors gave us a list of rank 3 tensors (tensors).</li>
</ul>
<p>Let’s use a color image as an example to illustrate the concept of <em class="italic">rank</em> for a tensor. For a color image, we can use three channels to describe each pixel: a red channel, a green channel, and a blue channel. Each channel measures the magnitude of the pixel within that color channel. The red channel is a <em class="italic">rank 2</em> tensor since it uses a matrix to represent the image pixel map in red light (0 means zero light and 255 means maximum light), and so are the green channel and the blue channel. Combining these three channels, we have a <em class="italic">rank 3</em> tensor. If we add a time axis for the order of the color frames/images to form a video, then it becomes a <em class="italic">rank 4</em> tensor. If we then batch the videos, it will then come up with a list of <em class="italic">rank 4</em> tensors – a <em class="italic">rank 5</em> tensor.</p>
<p>After we have <a id="_idIndexMarker410"/>examined the tensor ranks, let’s check out the shape and dtype of a tensor – shape is the number of elements of a tensor and dtype is the element’s data type. With the tensors of ranks 0, 1, 2, 3, and n, we have the following:</p>
<ul>
<li>The shape for the <em class="italic">rank 0</em> tensor (scalar) is empty <em class="italic">()</em>.</li>
<li>The shape for a <em class="italic">rank 1</em> tensor, for example, a vector ([3, 5, 7]), is <em class="italic">(3)</em> since it has three elements.</li>
<li>The shape for a <em class="italic">rank 2</em> tensor, for example, a matrix ([3, 5, 7], [4, 6, 8]) is <em class="italic">(2,3)</em> since it has two elements in one direction (rows) and three elements in the other direction (columns).</li>
</ul>
<p>Now that we have a good understanding of the tensor concept, let’s look at the second part of the name <em class="italic">TensorFlow</em>, flow, and see how tensors flow.</p>
<h2 id="_idParaDest-138"><a id="_idTextAnchor139"/>How tensors flow</h2>
<p>To describe <a id="_idIndexMarker411"/>the flowing of tensors in the <strong class="bold">TensorFlow</strong> (<strong class="bold">TF</strong>) framework, we adopt a computational graph with nodes and edges called a <strong class="bold">Directed Acyclic Graph</strong> (<strong class="bold">DAG</strong>). Directed <a id="_idIndexMarker412"/>means that the tensor (data) moves in a given order along a path in the graph. Acyclic means that the moving path does not form any cycles. So, tensors flow in no-loop DAGs to transform data. </p>
<p>Using DAGs, a tensor has a node and an edge. The nodes represent the operations we perform on the tensor/data, and the edges represent the path that the tensor/data flows along. Let’s use a DAG to describe a sample algorithm. As shown in <em class="italic">Figure 6.4</em>, we input two numbers, multiply them to get their product, and add the numbers to get their sum. Then, we divide the product by the sum and print the result. If we replace the constant values with variables and add more complex mathematical operations, we can see that this tensor <a id="_idIndexMarker413"/>flowing process is really an ML model – we can change the variables or the weights to produce the expected output from the inputs.</p>
<div>
<div class="IMG---Figure" id="_idContainer069">
<img alt="Figure 6.4 – A sample algorithm with DAG  " height="309" src="image/Figure_6.4.jpg" width="738"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4 – A sample algorithm with DAG </p>
<p>Since DAGs are mono-directional and have an order of execution, we can parallelize the operations when tensors flow in the diagram. For example, If you want to add 1,000 tensors and multiply the same 1,000 tensors, the addition and multiplication operations can be performed in parallel by distributing the operations to multiple computing resources by <a id="_idIndexMarker414"/>utilizing many CPU, <strong class="bold">Graphics Processing Unit</strong> (<strong class="bold">GPU</strong>), or <strong class="bold">Tensor Processing Unit</strong> (<strong class="bold">TPU</strong>) cores, or even <strong class="bold">Quantum Processors</strong> (<strong class="bold">QU</strong>). Since DAG <a id="_idIndexMarker415"/>allows the execution of parallel <a id="_idIndexMarker416"/>operations on different physical machines or platforms, we can further execute these operations in parallel on distributed server farms or edge devices. As we know, cloud computing is featured as on-demand, globally distributed, auto-scalable, and pay-as-you-go and thus it provides a perfect environment to parallelize TensorFlow operations and train ML models. As we have also discussed in the previous chapters, Google Colab has preinstalled TensorFlow packages, and you can practice TensorFlow in Colab, with GPU and TPU free of cost. </p>
<p>Now that we have grasped the concepts of tensors and understand how tensors flow in the TF frame, it’s time to introduce Keras—a high-level API that is designed for us to develop ML models with TensorFlow very easily.</p>
<h1 id="_idParaDest-139"><a id="_idTextAnchor140"/>Introduction to Keras</h1>
<p>Keras is a Google platform and a high-level interface to build ML/DL models with TensorFlow. Keras provides a high-level API that encapsulates data transformations and operations <a id="_idIndexMarker417"/>using logic units, called <strong class="bold">layers</strong>, as <a id="_idIndexMarker418"/>the building blocks to create neural networks. A layer performs data manipulation operations such as taking an average, calculating the minimum, and so on. </p>
<p>With Keras, ML models are built from layers. During the ML model training process, the variables in the layers are adjusted, via backpropagation, to optimize the model cost function. Behind the scenes, TensorFlow and Keras complete detailed data operations, such as linear algebra and calculus calculations, in the background. Keras provides the following two APIs:</p>
<ul>
<li>The <strong class="bold">sequential API</strong> provides <a id="_idIndexMarker419"/>the simplest interface <a id="_idIndexMarker420"/>and least complexity. With the sequential API, we can create the model layer by layer and thus build an ML/DL model as a simple list of layers. </li>
<li>The <strong class="bold">functional API</strong> is more <a id="_idIndexMarker421"/>flexible and powerful than the sequential <a id="_idIndexMarker422"/>API since it allows thebranching or sharing of layers. With the functional API, we can have multiple inputs and outputs for ML models.</li>
</ul>
<p>The following snippet shows an ML model training with the sequential API:</p>
<pre class="source-code"><strong class="bold">##Import the tensorflow libraries</strong>
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.optimizers import Adam
<strong class="bold">## Creating the model</strong>
model = Sequential()
model.add(Dense(4,activation='relu')) 
model.add(Dense(4,activation='relu'))
model.add(Dense(1))
<strong class="bold">## defining the optimizer and loss function</strong>
model.compile(optimizer='adam',loss='mse')
<strong class="bold">## training the model</strong>
model.fit(x=X_train,y=y_train,
          validation_data=(X_test,y_test),
          batch_size=128,epochs=400)</pre>
<p>The following <a id="_idIndexMarker423"/>snippet shows an ML model training with the functional API:</p>
<pre class="source-code"><strong class="bold">##Import the tensorflow libraries</strong>
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input,Dense
<strong class="bold">## Creating the layers</strong>
input_layer = Input(shape=(3,))
Layer_1 = Dense(4, activation="relu")(input_layer)
Layer_2 = Dense(4, activation="relu")(Layer_1)
output_layer= Dense(1, activation="linear")(Layer_2)
##Defining the model by specifying the input and output layers
model = Model(inputs=input_layer, outputs=output_layer)
<strong class="bold">## defining the optimizer and loss function</strong>
model.compile(optimizer='adam',loss='mse')
<strong class="bold">## training the model</strong>
model.fit(X_train, y_train,epochs=400, batch_size=128,validation_data=(X_test,y_test))</pre>
<p>As we can see, the preceding <a id="_idIndexMarker424"/>two Keras APIs have their own pros and cons. The sequential API is simple and straightforward, and the functional API can be used to build complex models. </p>
<h1 id="_idParaDest-140"><a id="_idTextAnchor141"/>Summary</h1>
<p>In this chapter, we discussed Google Cloud BQ and BQML and introduced some examples of using BQ/BQML for data processing and ML model development. We also learned about the concepts of TensorFlow and Keras – Google’s frameworks for building ML models and projects. </p>
<p>In the following chapter, we will focus on Vertex AI, which provides an end-to-end platform for ML in the Google Cloud.</p>
<h1 id="_idParaDest-141"><a id="_idTextAnchor142"/>Further reading</h1>
<p>For further insights on the learning of the chapter, you can refer to the following links:</p>
<ul>
<li><a href="https://cloud.google.com/bigquery/docs/">https://cloud.google.com/bigquery/docs/</a></li>
<li><a href="https://cloud.google.com/bigquery-ml/docs/">https://cloud.google.com/bigquery-ml/docs/</a></li>
<li><a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a></li>
<li><a href="https://keras.io/about/">https://keras.io/about/</a></li>
</ul>
</div>
<div>
<div id="_idContainer071">
</div>
</div>
</div>
</body></html>