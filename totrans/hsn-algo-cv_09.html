<html><head></head><body>
        

                            
                    <h1 class="header-title" id="calibre_pb_0">Assessments</h1>
                
            
            
                


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 1, Introduction to Computer Vision</h1>
                
            
            
                
<p class="calibre2">1. Name two industries besides the ones mentioned in this chapter that can significantly benefit from computer vision.</p>
<p class="calibre32">The sports industry can use computer vision for better analysis of matches.<br class="calibre5"/>
The food industry can use computer vision for quality control of products.</p>
<p class="calibre2">2. What would be an example of a computer vision application used for security purposes? (Think about an idea for an application that you haven't come across.)</p>
<p class="calibre32">A very random example would be an application that uses face recognition for ticket checks on trains, flights, and so on.</p>
<p class="calibre2">3. What would be an example of a computer vision application used for productivity reasons? (Again, think about an idea for an application that you haven't come across, even though you might suspect that it exists.)</p>
<p class="calibre32">An application that uses its camera to help visually impaired people.</p>
<p class="calibre2">4. How many megabytes would be needed to store a 1920 x 1080 image with four channels and a depth of 32-bits?</p>
<p class="calibre32">Approximately 31.64 megabytes:</p>
<div><img src="img/00112.jpeg" class="calibre120"/></div>
<p class="calibre2">5. Ultra-HD images, also known as 4K, or 8K images are quite common nowadays, but how many megapixels does an Ultra-HD image contain?</p>
<p class="calibre32">This mostly depends on the aspect ratio. For a common 16:9 aspect ratio, here are the answers:</p>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">4K</strong>: 8.3 megapixels</li>
<li class="calibre11"><strong class="calibre1">8K</strong>: 33.2 megapixels</li>
</ul>
<p class="calibre32">Have a look at this link for more info:<br class="calibre5"/>
<a href="https://en.wikipedia.org/wiki/Ultra-high-definition_television" class="calibre9">https://en.wikipedia.org/wiki/Ultra-high-definition_television</a></p>
<p class="calibre2">6. Name two commonly used color spaces besides the ones mentioned in this chapter.</p>
<p class="calibre32">YUV and LUV color spaces<br class="calibre5"/>
<a href="https://en.wikipedia.org/wiki/List_of_color_spaces_and_their_uses" class="calibre9">https://en.wikipedia.org/wiki/List_of_color_spaces_and_their_uses</a></p>
<p class="calibre2">7. Compare OpenCV libraries with computer vision tools in MATLAB. What are the pros and cons of each one, when compared?</p>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre32">In general, MATLAB is best used when a computer vision application needs to be simulated and prototyped, while OpenCV is more straightforward when it comes to real-life scenarios and applications where speed and full control over the end product is needed.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 2, Getting Started with OpenCV</h1>
                
            
            
                
<p class="calibre2">1. Name three Extra OpenCV modules, along with their usage.</p>
<p class="calibre32">The <kbd class="calibre13">xfeatures2d</kbd> module can be used to access additional feature detection algorithms.<br class="calibre5"/>
The <kbd class="calibre13">face</kbd> module can be used to include face analysis algorithms in OpenCV.<br class="calibre5"/>
The <kbd class="calibre13">text</kbd> module can be used to add OCR functionalities (Tesseract OCR) to OpenCV.</p>
<p class="calibre2">2. What is the effect of building OpenCV 3 with the <kbd class="calibre13">BUILD_opencv_world</kbd> flag turned on?</p>
<p class="calibre32">Building OpenCV 3 with the <kbd class="calibre13">BUILD_opencv_world</kbd> flag will combine all binary library files, such as <kbd class="calibre13">core</kbd>, <kbd class="calibre13">imcodecs</kbd>, and <kbd class="calibre13">highgui</kbd>, into a single world library.</p>
<p class="calibre2">3. Using the ROI pixel access method described in this chapter, how can we construct a <kbd class="calibre13">Mat</kbd> class that can access the middle pixel, plus all of its neighboring pixels (the middle nine pixels) in another image?</p>
<p class="calibre32">Here's an example code that can achieve this goal:</p>
<pre class="calibre33">Mat image = imread("Test.png");<br class="title-page-name"/>if(image.empty())<br class="title-page-name"/> {<br class="title-page-name"/> cout &lt;&lt; "image empty";<br class="title-page-name"/> return 0;<br class="title-page-name"/> }<br class="title-page-name"/>int centerRow = (image.rows / 2) - 1;<br class="title-page-name"/> int centerCol = (image.cols / 2) - 1;<br class="title-page-name"/> Mat roi(image, Rect(centerCol - 1, centerRow - 1, 3, 3));<br class="title-page-name"/>roi = Scalar(0,0,255); // alter the pixels (make them red)<br class="title-page-name"/>imshow("image", image);<br class="title-page-name"/> waitKey();</pre>
<p class="calibre2">4. Name another pixel access method of the <kbd class="calibre13">Mat</kbd> class, besides the ones mentioned in this chapter.</p>
<pre class="calibre33">Mat::row can be used to access a single row<br class="title-page-name"/> Mat::column can be used to access a single column</pre>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">5. Write a program, only using the <kbd class="calibre13">Mat</kbd> method and a <kbd class="calibre13">for</kbd> loop, that creates three separate color images, each one containing only one channel of an RGB image read from disk.</p>
<pre class="calibre33">Mat image = imread("Test.png");<br class="title-page-name"/>if(image.empty())<br class="title-page-name"/> {<br class="title-page-name"/> cout &lt;&lt; "image empty";<br class="title-page-name"/> return 0;<br class="title-page-name"/> }<br class="title-page-name"/>Mat red(image.rows, image.cols, CV_8UC3, Scalar::all(0));<br class="title-page-name"/> Mat green(image.rows, image.cols, CV_8UC3, Scalar::all(0));<br class="title-page-name"/> Mat blue(image.rows, image.cols, CV_8UC3, Scalar::all(0));<br class="title-page-name"/>for(int i=0; i&lt;image.rows; i++)<br class="title-page-name"/> {<br class="title-page-name"/> for(int j=0; j&lt;image.cols; j++)<br class="title-page-name"/> {<br class="title-page-name"/> blue.at&lt;Vec3b&gt;(i, j)[0] = image.at&lt;Vec3b&gt;(i, j)[0];<br class="title-page-name"/> green.at&lt;Vec3b&gt;(i, j)[1] = image.at&lt;Vec3b&gt;(i, j)[1];<br class="title-page-name"/> red.at&lt;Vec3b&gt;(i, j)[2] = image.at&lt;Vec3b&gt;(i, j)[2];<br class="title-page-name"/> }<br class="title-page-name"/> }<br class="title-page-name"/>imshow("Blue", blue);<br class="title-page-name"/> imshow("Green", green);<br class="title-page-name"/> imshow("Red", red);<br class="title-page-name"/>waitKey();</pre>
<p class="calibre2"> </p>
<div><img src="img/00113.gif" class="calibre121"/><img src="img/00114.gif" class="calibre122"/><img src="img/00115.gif" class="calibre121"/></div>
<p class="calibre2">6. Using STL-like iterators, calculate the average pixel value of a grayscale image.</p>
<pre class="calibre33">Mat image = imread("Test.png", IMREAD_GRAYSCALE);<br class="title-page-name"/>if(image.empty())<br class="title-page-name"/> {<br class="title-page-name"/> cout &lt;&lt; "image empty";<br class="title-page-name"/> return 0;<br class="title-page-name"/> }<br class="title-page-name"/>int sum = 0;<br class="title-page-name"/>MatIterator_&lt;uchar&gt; it_begin = image.begin&lt;uchar&gt;();<br class="title-page-name"/> MatIterator_&lt;uchar&gt; it_end = image.end&lt;uchar&gt;();<br class="title-page-name"/> for( ; it_begin != it_end; it_begin++)<br class="title-page-name"/> {<br class="title-page-name"/> sum += (*it_begin);<br class="title-page-name"/> }<br class="title-page-name"/>double average = sum / (image.cols * image.rows);<br class="title-page-name"/>cout &lt;&lt; "Pixel count is " &lt;&lt; image.cols * image.rows &lt;&lt; endl;<br class="title-page-name"/> cout &lt;&lt; "Average pixel value is " &lt;&lt; average &lt;&lt; endl;</pre>
<p class="calibre2">7. Write a program using <kbd class="calibre13">VideoCapture</kbd>, <kbd class="calibre13">waitKey</kbd>, and <kbd class="calibre13">imwrite</kbd>, that displays your webcam and saves the visible image when the <em class="calibre7">S</em> key is pressed. This program will stop the webcam and exit if the spacebar is pressed.</p>
<pre class="calibre33">VideoCapture cam(0);<br class="title-page-name"/>if(!cam.isOpened())<br class="title-page-name"/> return -1;<br class="title-page-name"/>while(true)<br class="title-page-name"/> {<br class="title-page-name"/> Mat frame;<br class="title-page-name"/> cam &gt;&gt; frame;<br class="title-page-name"/> if(frame.empty())<br class="title-page-name"/> break;<br class="title-page-name"/>imshow("Camera", frame);<br class="title-page-name"/>// stop camera if space is pressed<br class="title-page-name"/>char key = waitKey(10);<br class="title-page-name"/>if(key == ' ')<br class="title-page-name"/> break;<br class="title-page-name"/>if(key == 's')<br class="title-page-name"/> imwrite("d:/snapshot.png", frame);<br class="title-page-name"/> }<br class="title-page-name"/>cam.release();</pre>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 3, Array and Matrix Operations</h1>
                
            
            
                
<p class="calibre2">1. Which of the element-wise mathematical operations and bitwise operations would produce the exact same results?</p>
<p class="calibre2"/>
<p class="calibre32">The <kbd class="calibre13">bitwise_xor</kbd> and <kbd class="calibre13">absdiff</kbd> functions would produce the same result.</p>
<p class="calibre2">2. What is the purpose of the <kbd class="calibre13">gemm</kbd> function in OpenCV? What is the equivalent of <em class="calibre7">A</em>x<em class="calibre7">B</em> with the <kbd class="calibre13">gemm</kbd> function?</p>
<p class="calibre32">The <kbd class="calibre13">gemm</kbd> function is the generalized multiplication function in OpenCV. Here's the <kbd class="calibre13">gemm</kbd> function call equivalent to the simple multiplication of two matrices:</p>
<pre class="calibre33">gemm(image1, image2, 1.0, noArray(), 1.0, result);</pre>
<p class="calibre2">3. Use the <kbd class="calibre13">borderInterpolate</kbd> function to calculate the value of a non-existing pixel at point (-10, 50), with a border type of <kbd class="calibre13">BORDER_REPLICATE</kbd>. What is the function call required for such a calculation?</p>
<pre class="calibre33">Vec3b val = image.at&lt;Vec3b&gt;(borderInterpolate(50,<br class="title-page-name"/>                               image.rows,<br class="title-page-name"/>                               cv::BORDER_REFLECT_101),<br class="title-page-name"/>                            borderInterpolate(-10,<br class="title-page-name"/>                               image.cols,<br class="title-page-name"/>                               cv::BORDER_WRAP));</pre>
<p class="calibre2">4. Create the same identity matrix in the <em class="calibre7">Identity matrix</em> section of this chapter, but use the <kbd class="calibre13">setIdentity</kbd> function instead of the <kbd class="calibre13">Mat::eye</kbd> function.</p>
<pre class="calibre33">Mat m(10, 10, CV_32F);<br class="title-page-name"/>setIdentity(m, Scalar(0.25));</pre>
<p class="calibre2">5. Write a program using the <kbd class="calibre13">LUT</kbd> function (a look-up table transformation) that performs the same task as <kbd class="calibre13">bitwise_not</kbd> (invert colors) when executed on grayscale and color (RGB) images.</p>
<pre class="calibre33">Mat image = imread("Test.png");<br class="title-page-name"/><br class="title-page-name"/>Mat lut(1, 256, CV_8UC1);<br class="title-page-name"/><br class="title-page-name"/>for(int i=0; i&lt;256; i++)<br class="title-page-name"/>{<br class="title-page-name"/>  lut.at&lt;uchar&gt;(0, i) = 255 - i;<br class="title-page-name"/>}<br class="title-page-name"/><br class="title-page-name"/>Mat result;<br class="title-page-name"/>LUT(image, lut, result);</pre>
<p class="calibre2">6. Besides normalizing the values of a matrix, the <kbd class="calibre13">normalize</kbd> function can be used to brighten or darken images. Write the required function call to darken and brighten a grayscale image using the <kbd class="calibre13">normalize</kbd> function.</p>
<p class="calibre2"/>
<pre class="calibre33">normalize(image, result, 200, 255, CV_MINMAX); // brighten<br class="title-page-name"/>normalize(image, result, 0, 50, CV_MINMAX); // darken</pre>
<p class="calibre2">7. Remove the blue channel (the first channel) from an image (a BGR image created using the <kbd class="calibre13">imread</kbd> function) using the <kbd class="calibre13">merge</kbd> and <kbd class="calibre13">split</kbd> functions.</p>
<pre class="calibre33">vector&lt;Mat&gt; channels;<br class="title-page-name"/>split(image, channels);<br class="title-page-name"/>channels[0] = Scalar::all(0);<br class="title-page-name"/>merge(channels, result);</pre>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 4, Drawing, Filtering, and Transformation</h1>
                
            
            
                
<p class="calibre2">1. Write a program that draws a cross over the whole image, with a thickness of 3 pixels and a red color.</p>
<pre class="calibre33">line(image,<br class="title-page-name"/> Point(0,0),<br class="title-page-name"/> Point(image.cols-1,image.rows-1),<br class="title-page-name"/> Scalar(0,0,255),<br class="title-page-name"/> 3);<br class="title-page-name"/>line(image,<br class="title-page-name"/> Point(0,image.rows-1),<br class="title-page-name"/> Point(image.cols-1,0),<br class="title-page-name"/> Scalar(0,0,255),<br class="title-page-name"/> 3);</pre>
<p class="calibre2">2. Create a window with a trackbar to change the <kbd class="calibre13">ksize</kbd> of a <kbd class="calibre13">medianBlur</kbd> function. The range for the <kbd class="calibre13">kszise</kbd> value should be between 3 and 99.</p>
<pre class="calibre33">Mat image;<br class="title-page-name"/> int ksize = 3;<br class="title-page-name"/> string window = "Image";<br class="title-page-name"/> string trackbar = "ksize";<br class="title-page-name"/>void onChange(int ksize, void*)<br class="title-page-name"/> {<br class="title-page-name"/> if(ksize %2 == 1)<br class="title-page-name"/> {<br class="title-page-name"/> medianBlur(image,<br class="title-page-name"/> image,<br class="title-page-name"/> ksize);<br class="title-page-name"/> imshow(window, image);<br class="title-page-name"/> }<br class="title-page-name"/> }<br class="title-page-name"/>int main()<br class="title-page-name"/> {<br class="title-page-name"/> image = imread("Test.png");<br class="title-page-name"/> namedWindow(window);<br class="title-page-name"/> createTrackbar(trackbar, window, &amp;ksize, 99, onChange);<br class="title-page-name"/> setTrackbarMin(trackbar, window, 3);<br class="title-page-name"/> setTrackbarMax(trackbar, window, 99);<br class="title-page-name"/> onChange(3, NULL);<br class="title-page-name"/> waitKey();<br class="title-page-name"/> }</pre>
<p class="calibre2">3. Perform a gradient morphological operation on an image, considering a kernel size of 7 and a rectangle morphological shape for the structuring element.</p>
<pre class="calibre33">int ksize = 7;<br class="title-page-name"/> morphologyEx(image,<br class="title-page-name"/> result,<br class="title-page-name"/> MORPH_GRADIENT,<br class="title-page-name"/> getStructuringElement(MORPH_RECT,<br class="title-page-name"/> Size(ksize,ksize)));</pre>
<p class="calibre2">Here's an example:</p>
<div><img src="img/00116.jpeg" class="calibre123"/></div>
<p class="calibre2">4. Using <kbd class="calibre13">cvtColor</kbd>, convert a color image to grayscale and make sure only the darkest 100 shades of gray are filtered out using the <kbd class="calibre13">threshold</kbd> function. Make sure the filtered pixels are set to white in the resulting image, and the rest of the pixels are set to black.</p>
<pre class="calibre33">Mat imageGray;<br class="title-page-name"/> cvtColor(image,<br class="title-page-name"/> imageGray,<br class="title-page-name"/> COLOR_BGR2GRAY);<br class="title-page-name"/>threshold(imageGray,<br class="title-page-name"/> result,<br class="title-page-name"/> 100,<br class="title-page-name"/> 255,<br class="title-page-name"/> THRESH_BINARY_INV);</pre>
<p class="calibre2"/>
<p class="calibre2">Here's an example:</p>
<div><img src="img/00117.jpeg" class="calibre124"/></div>
<p class="calibre2">5. Use the <kbd class="calibre13">remap</kbd> function to resize an image to half of its original width and height, thus preserving the aspect ratio of the original image. Use a default border type for the extrapolation.</p>
<pre class="calibre33">Mat mapX(image.size(), CV_32FC1);<br class="title-page-name"/> Mat mapY(image.size(), CV_32FC1);<br class="title-page-name"/> for(int i=0; i&lt;image.rows; i++)<br class="title-page-name"/> for(int j=0; j&lt;image.cols; j++)<br class="title-page-name"/> {<br class="title-page-name"/> mapX.at&lt;float&gt;(i,j) = j*2.0;<br class="title-page-name"/> mapY.at&lt;float&gt;(i,j) = i*2.0;<br class="title-page-name"/> }<br class="title-page-name"/> InterpolationFlags interpolation = INTER_LANCZOS4;<br class="title-page-name"/> BorderTypes borderMode = BORDER_DEFAULT;<br class="title-page-name"/> remap(image,<br class="title-page-name"/> result,<br class="title-page-name"/> mapX,<br class="title-page-name"/> mapY,<br class="title-page-name"/> interpolation,<br class="title-page-name"/> borderMode);</pre>
<p class="calibre2">Here's an example:</p>
<div><img src="img/00118.jpeg" class="calibre125"/></div>
<p class="calibre2">6. a) Use colormaps to convert an image to grayscale. b) How about converting an image to grayscale and inverting its pixels at the same time?</p>
<p class="calibre32">a)</p>
<pre class="calibre33">Mat userColor(256, 1, CV_8UC3);<br class="title-page-name"/> for(int i=0; i&lt;=255; i++)<br class="title-page-name"/> userColor.at&lt;Vec3b&gt;(i,0) = Vec3b(i, i, i);<br class="title-page-name"/> applyColorMap(image,<br class="title-page-name"/> result,<br class="title-page-name"/> userColor);</pre>
<p class="calibre32">b)</p>
<pre class="calibre33">Mat userColor(256, 1, CV_8UC3);<br class="title-page-name"/> for(int i=0; i&lt;=255; i++)<br class="title-page-name"/> userColor.at&lt;Vec3b&gt;(i,0) = Vec3b(255-i, 255-i, 255-i);<br class="title-page-name"/> applyColorMap(image,<br class="title-page-name"/> result,<br class="title-page-name"/> userColor);</pre>
<p class="calibre2">7. Did you read about perspective transformation functions? Which OpenCV function covers all similar transformations in one function?</p>
<p class="calibre2">The <kbd class="calibre13">findHomography</kbd> function.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 5, Back-Projection and Histograms</h1>
                
            
            
                
<p class="calibre2">1. Calculate the histogram of the second channel in a three-channel image. Use an optional bin size and a range of 0 to 100 for possible values of the second channel.</p>
<pre class="calibre33">int bins = 25; // optional<br class="title-page-name"/> int nimages = 1;<br class="title-page-name"/> int channels[] = {1};<br class="title-page-name"/> Mat mask;<br class="title-page-name"/> int dims = 1;<br class="title-page-name"/> int histSize[] = { bins };<br class="title-page-name"/> float range[] = {0, 100};<br class="title-page-name"/> const float* ranges[] = { range };<br class="title-page-name"/> Mat histogram;<br class="title-page-name"/> calcHist(&amp;image,<br class="title-page-name"/> nimages,<br class="title-page-name"/> channels,<br class="title-page-name"/> mask,<br class="title-page-name"/> histogram,<br class="title-page-name"/> dims,<br class="title-page-name"/> histSize,<br class="title-page-name"/> ranges);</pre>
<p class="calibre2">2. Create a histogram that can be used with <kbd class="calibre13">calcBackProject</kbd> function to extract the darkest pixels from a grayscale image. Consider the darkest 25% possible pixel values as the grayscale intensities we are looking to extract.</p>
<pre class="calibre33">int bins = 4;<br class="title-page-name"/> float rangeGS[] = {0, 256};<br class="title-page-name"/> const float* ranges[] = { rangeGS };<br class="title-page-name"/> int channels[] = {0};<br class="title-page-name"/> Mat histogram(bins, 1, CV_32FC1, Scalar(0.0));<br class="title-page-name"/> histogram.at&lt;float&gt;(0, 0) = 255.0;<br class="title-page-name"/> calcBackProject(&amp;imageGray,<br class="title-page-name"/> 1,<br class="title-page-name"/> channels,<br class="title-page-name"/> histogram,<br class="title-page-name"/> backProj,<br class="title-page-name"/> ranges);</pre>
<p class="calibre2">3. In the previous question, what if we needed the darkest and brightest 25% to be excluded, instead of extracted in a mask?</p>
<pre class="calibre33">int bins = 4;<br class="title-page-name"/> float rangeGS[] = {0, 256};<br class="title-page-name"/> const float* ranges[] = { rangeGS };<br class="title-page-name"/> int channels[] = {0};<br class="title-page-name"/> Mat histogram(bins, 1, CV_32FC1, Scalar(0.0));<br class="title-page-name"/> histogram.at&lt;float&gt;(1, 0) = 255.0;<br class="title-page-name"/> histogram.at&lt;float&gt;(2, 0) = 255.0;<br class="title-page-name"/> calcBackProject(&amp;imageGray,<br class="title-page-name"/> 1,<br class="title-page-name"/> channels,<br class="title-page-name"/> histogram,<br class="title-page-name"/> backProj,<br class="title-page-name"/> ranges);</pre>
<p class="calibre2">4. What is the hue value of the red color? How much should it be shifted to get the blue color?</p>
<p class="calibre32">0 and 360 are the hue values for the red color. Shifting it by 240 would result in the blue color.</p>
<p class="calibre2">5. Create a hue histogram that can be used to extract red colored pixels from an image. Consider an offset of 50 for pixels that are considered red. Finally, visualize the created hue histogram.</p>
<pre class="calibre33">const int bins = 360;<br class="title-page-name"/> int hueOffset = 35;<br class="title-page-name"/> Mat histogram(bins, 1, CV_32FC1);<br class="title-page-name"/> for(int i=0; i&lt;bins; i++)<br class="title-page-name"/> {<br class="title-page-name"/> histogram.at&lt;float&gt;(i, 0) =<br class="title-page-name"/> (i &lt; hueOffset) || (i &gt; bins - hueOffset) ? 255.0 : 0.0;<br class="title-page-name"/> }<br class="title-page-name"/>double maxVal = 255.0;<br class="title-page-name"/>int gW = 800, gH = 100;<br class="title-page-name"/> Mat theGraph(gH, gW, CV_8UC3, Scalar::all(0));<br class="title-page-name"/>Mat colors(1, bins, CV_8UC3);<br class="title-page-name"/> for(int i=0; i&lt;bins; i++)<br class="title-page-name"/> {<br class="title-page-name"/> colors.at&lt;Vec3b&gt;(i) =<br class="title-page-name"/> Vec3b(saturate_cast&lt;uchar&gt;(<br class="title-page-name"/> (i+1)*180.0/bins), 255, 255);<br class="title-page-name"/> }<br class="title-page-name"/> cvtColor(colors, colors, COLOR_HSV2BGR);<br class="title-page-name"/> Point p1(0,0), p2(0,theGraph.rows-1);<br class="title-page-name"/> for(int i=0; i&lt;bins; i++)<br class="title-page-name"/> {<br class="title-page-name"/> float value = histogram.at&lt;float&gt;(i,0);<br class="title-page-name"/> value = maxVal - value; // invert<br class="title-page-name"/> value = value / maxVal * theGraph.rows; // scale<br class="title-page-name"/> p1.y = value;<br class="title-page-name"/> p2.x = float(i+1) * float(theGraph.cols) / float(bins);<br class="title-page-name"/> rectangle(theGraph,<br class="title-page-name"/> p1,<br class="title-page-name"/> p2,<br class="title-page-name"/> Scalar(colors.at&lt;Vec3b&gt;(i)),<br class="title-page-name"/> CV_FILLED);<br class="title-page-name"/> p1.x = p2.x;<br class="title-page-name"/> }</pre>
<div><img src="img/00119.gif" class="calibre20"/></div>
<p class="calibre2">6. Calculate the integral of a histogram.</p>
<pre class="calibre33">float integral = 0.0;<br class="title-page-name"/> for(int i=0; i&lt;bins; i++)<br class="title-page-name"/> {<br class="title-page-name"/> integral += histogram.at&lt;float&gt;(i, 0);<br class="title-page-name"/> }</pre>
<p class="calibre2">7. Perform histogram equalization on a color image. Note that the <kbd class="calibre13">equalizeHist</kbd> function only supports histogram equalization of single-channel 8-bit grayscale images.</p>
<pre class="calibre15">Mat channels[3], equalized[3];<br class="title-page-name"/> split(image, channels);<br class="title-page-name"/>equalizeHist(channels[0], equalized[0]);<br class="title-page-name"/> equalizeHist(channels[1], equalized[1]);<br class="title-page-name"/> equalizeHist(channels[2], equalized[2]);<br class="title-page-name"/>Mat output;<br class="title-page-name"/> cv::merge(equalized, 3, output);</pre>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 6, Video Analysis – Motion Detection and Tracking</h1>
                
            
            
                
<p class="calibre2">1. All the examples in this chapter that deal with cameras return when there is a single failed or corrupted frame that leads to the detection of an empty frame. What type of modification is needed to allow a predefined number of retries before stopping the process?</p>
<pre class="calibre33">const int RETRY_COUNT = 10;<br class="title-page-name"/> int retries = RETRY_COUNT;<br class="title-page-name"/>while(true)<br class="title-page-name"/> {<br class="title-page-name"/>Mat frame;<br class="title-page-name"/> cam &gt;&gt; frame;<br class="title-page-name"/> if(frame.empty())<br class="title-page-name"/> {<br class="title-page-name"/> if(--retries &lt; 0)<br class="title-page-name"/> break;<br class="title-page-name"/> else<br class="title-page-name"/> continue;<br class="title-page-name"/> }<br class="title-page-name"/> else<br class="title-page-name"/> {<br class="title-page-name"/> retries = RETRY_COUNT;<br class="title-page-name"/> }<br class="title-page-name"/>// rest of the process<br class="title-page-name"/> }</pre>
<p class="calibre2">2. How can we call the <kbd class="calibre13">meanShift</kbd> function to perform the Mean Shift algorithm with 10 iterations and an epsilon value of 0.5?</p>
<pre class="calibre33">TermCriteria criteria(TermCriteria::MAX_ITER<br class="title-page-name"/> + TermCriteria::EPS,<br class="title-page-name"/> 10,<br class="title-page-name"/> 0.5);<br class="title-page-name"/>meanShift(backProject,<br class="title-page-name"/> srchWnd,<br class="title-page-name"/> criteria);</pre>
<p class="calibre2">3. How do you visualize the hue histogram of the tracked object? Assume that <kbd class="calibre13">CamShift</kbd> is used for tracking.</p>
<pre class="calibre33">Having the following function:<br class="title-page-name"/> void visualizeHue(Mat hue)<br class="title-page-name"/> {<br class="title-page-name"/> int bins = 36;<br class="title-page-name"/> int histSize[] = {bins};<br class="title-page-name"/> int nimages = 1;<br class="title-page-name"/> int dims = 1;<br class="title-page-name"/> int channels[] = {0};<br class="title-page-name"/> float rangeHue[] = {0, 180};<br class="title-page-name"/> const float* ranges[] = {rangeHue};<br class="title-page-name"/> bool uniform = true;<br class="title-page-name"/> bool accumulate = false;<br class="title-page-name"/> Mat histogram, mask;<br class="title-page-name"/>calcHist(&amp;hue,<br class="title-page-name"/> nimages,<br class="title-page-name"/> channels,<br class="title-page-name"/> mask,<br class="title-page-name"/> histogram,<br class="title-page-name"/> dims,<br class="title-page-name"/> histSize,<br class="title-page-name"/> ranges,<br class="title-page-name"/> uniform,<br class="title-page-name"/> accumulate);<br class="title-page-name"/>double maxVal;<br class="title-page-name"/> minMaxLoc(histogram,<br class="title-page-name"/> 0,<br class="title-page-name"/> &amp;maxVal,<br class="title-page-name"/> 0,<br class="title-page-name"/> 0);<br class="title-page-name"/>int gW = 800, gH = 100;<br class="title-page-name"/> Mat theGraph(gH, gW, CV_8UC3, Scalar::all(0));<br class="title-page-name"/>Mat colors(1, bins, CV_8UC3);<br class="title-page-name"/> for(int i=0; i&lt;bins; i++)<br class="title-page-name"/> {<br class="title-page-name"/> colors.at&lt;Vec3b&gt;(i) =<br class="title-page-name"/> Vec3b(saturate_cast&lt;uchar&gt;(<br class="title-page-name"/> (i+1)*180.0/bins), 255, 255);<br class="title-page-name"/> }<br class="title-page-name"/> cvtColor(colors, colors, COLOR_HSV2BGR);<br class="title-page-name"/> Point p1(0,0), p2(0,theGraph.rows-1);<br class="title-page-name"/> for(int i=0; i&lt;bins; i++)<br class="title-page-name"/> {<br class="title-page-name"/> float value = histogram.at&lt;float&gt;(i,0);<br class="title-page-name"/> value = maxVal - value; // invert<br class="title-page-name"/> value = value / maxVal * theGraph.rows; // scale<br class="title-page-name"/> p1.y = value;<br class="title-page-name"/> p2.x = float(i+1) * float(theGraph.cols) / float(bins);<br class="title-page-name"/> rectangle(theGraph,<br class="title-page-name"/> p1,<br class="title-page-name"/> p2,<br class="title-page-name"/> Scalar(colors.at&lt;Vec3b&gt;(i)),<br class="title-page-name"/> CV_FILLED);<br class="title-page-name"/> p1.x = p2.x;<br class="title-page-name"/> }<br class="title-page-name"/>imshow("Graph", theGraph);<br class="title-page-name"/> }</pre>
<p class="calibre2">We can call the following right after the <kbd class="calibre13">CamShift</kbd> function call to visualize the hue of the detected object:</p>
<pre class="calibre15">CamShift(backProject,<br class="title-page-name"/> srchWnd,<br class="title-page-name"/> criteria);<br class="title-page-name"/>visualizeHue(Mat(hue, srchWnd));</pre>
<p class="calibre2">4. Set the process noise covariance in the <kbd class="calibre13">KalmanFilter</kbd> class so that the filtered and measured values overlap. Assume that only process noise covariance is set of all the available matrices for the <kbd class="calibre13">KalmanFilter</kbd> class's behavior control.</p>
<pre class="calibre33">setIdentity(kalman.processNoiseCov,<br class="title-page-name"/> Scalar::all(1.0));</pre>
<div><img src="img/00120.gif" class="calibre126"/></div>
<p class="calibre2">5. Let's assume that the <em class="calibre7">Y</em> position of the mouse on a window is used to describe the height of a filled rectangle that starts from the top-left corner of the window and has a width that equals the window's width. Write a Kalman filter that can be used to correct the height of the rectangle (single value) and remove noise in the mouse's movement, resulting in a visually smooth resizing of the filled rectangle.</p>
<pre class="calibre33">int fillHeight = 0;<br class="title-page-name"/>void onMouse(int, int, int y, int, void*)<br class="title-page-name"/> {<br class="title-page-name"/> fillHeight = y;<br class="title-page-name"/> }<br class="title-page-name"/>int main()<br class="title-page-name"/> {<br class="title-page-name"/> KalmanFilter kalman(2,1);<br class="title-page-name"/>Mat_&lt;float&gt; tm(2, 2); // transition matrix<br class="title-page-name"/> tm &lt;&lt; 1,0,<br class="title-page-name"/> 0,1;<br class="title-page-name"/>kalman.transitionMatrix = tm;<br class="title-page-name"/> Mat_&lt;float&gt; h(1,1);<br class="title-page-name"/> h.at&lt;float&gt;(0) = 0;<br class="title-page-name"/>kalman.statePre.at&lt;float&gt;(0) = 0; // init x<br class="title-page-name"/> kalman.statePre.at&lt;float&gt;(1) = 0; // init x'<br class="title-page-name"/>setIdentity(kalman.measurementMatrix);<br class="title-page-name"/>setIdentity(kalman.processNoiseCov,<br class="title-page-name"/> Scalar::all(0.001));<br class="title-page-name"/>string window = "Canvas";<br class="title-page-name"/> namedWindow(window);<br class="title-page-name"/> setMouseCallback(window, onMouse);<br class="title-page-name"/>while(waitKey(10) &lt; 0)<br class="title-page-name"/> {<br class="title-page-name"/> // empty canvas<br class="title-page-name"/> Mat canvas(500, 500, CV_8UC3, Scalar(255, 255, 255));<br class="title-page-name"/>h(0) = fillHeight;<br class="title-page-name"/>Mat estimation = kalman.correct(h);<br class="title-page-name"/>float estH = estimation.at&lt;float&gt;(0);<br class="title-page-name"/>rectangle(canvas,<br class="title-page-name"/> Rect(0,0,canvas.cols, estH),<br class="title-page-name"/> Scalar(0),<br class="title-page-name"/> FILLED);<br class="title-page-name"/>imshow(window, canvas);<br class="title-page-name"/>kalman.predict();<br class="title-page-name"/> }<br class="title-page-name"/> return 0;<br class="title-page-name"/>}</pre>
<p class="calibre2">6. Create a <kbd class="calibre13">BackgroundSubtractorMOG2</kbd> object to extract the foreground image's contents while avoiding the shadow changes.</p>
<pre class="calibre33">Ptr&lt;BackgroundSubtractorMOG2&gt; bgs =<br class="title-page-name"/> createBackgroundSubtractorMOG2(500, // hist<br class="title-page-name"/> 16, // thresh<br class="title-page-name"/> false // no shadows<br class="title-page-name"/> );</pre>
<p class="calibre2">7. Write a program to display the current (as opposed to sampled) background image using a background segmentation algorithm.</p>
<pre class="calibre33">VideoCapture cam(0);<br class="title-page-name"/> if(!cam.isOpened())<br class="title-page-name"/> return -1;<br class="title-page-name"/>Ptr&lt;BackgroundSubtractorKNN&gt; bgs =<br class="title-page-name"/> createBackgroundSubtractorKNN();<br class="title-page-name"/>while(true)<br class="title-page-name"/> {<br class="title-page-name"/>Mat frame;<br class="title-page-name"/> cam &gt;&gt; frame;<br class="title-page-name"/> if(frame.empty())<br class="title-page-name"/> break;<br class="title-page-name"/>Mat mask;<br class="title-page-name"/> bgs-&gt;apply(frame,<br class="title-page-name"/> mask);<br class="title-page-name"/>bitwise_not(mask, mask);<br class="title-page-name"/>Mat bg;<br class="title-page-name"/> bitwise_and(frame, frame, bg, mask);<br class="title-page-name"/>imshow("bg", bg);<br class="title-page-name"/>int key = waitKey(10);<br class="title-page-name"/> if(key == 27) // escape key<br class="title-page-name"/> break;<br class="title-page-name"/> }<br class="title-page-name"/>cam.release();<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/></pre>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 7, Object Detection – Features and Descriptors</h1>
                
            
            
                
<p class="calibre2">1. The template matching algorithm is not scale- and rotation-invariant by itself. How can we make it so for a) double the scale of the template image, and b) a 90 degrees rotated version of the template image?</p>
<p class="calibre32">a) Use the <kbd class="calibre13">resize</kbd> function to scale the template image, and then call the <kbd class="calibre13">matchTemplate</kbd> function:</p>
<pre class="calibre33">resize(templ, templ, Size(), 2.0, 2.0);<br class="title-page-name"/> matchTemplate(image, templ, TM_CCOEFF_NORMED);</pre>
<p class="calibre32">b) Rotate the template by 90 degrees and then call the <kbd class="calibre13">matchTemplate</kbd> function:</p>
<pre class="calibre33">rotate(templ, templ, ROTATE_90_CLOCKWISE);<br class="title-page-name"/> matchTemplate(image, templ, TM_CCOEFF_NORMED);</pre>
<p class="calibre2">2. Use the <kbd class="calibre13">GFTTDetector</kbd> class to detect the keypoints with the Harris corner-detection algorithm. You can set any values for the corner-detection algorithm.</p>
<pre class="calibre33">Mat image = imread("Test.png");<br class="title-page-name"/> Ptr&lt;GFTTDetector&gt; detector =<br class="title-page-name"/> GFTTDetector::create(500,<br class="title-page-name"/> 0.01,<br class="title-page-name"/> 1,<br class="title-page-name"/> 3,<br class="title-page-name"/> true);<br class="title-page-name"/>vector&lt;KeyPoint&gt; keypoints;<br class="title-page-name"/> detector-&gt;detect(image, keypoints);<br class="title-page-name"/>drawKeypoints(image,<br class="title-page-name"/> keypoints,<br class="title-page-name"/> image);</pre>
<p class="calibre2">3. The Hough transformation can also be used to detect circles in an image using the <kbd class="calibre13">HoughCircles</kbd> function. Search for it in the OpenCV documentation and write a program to detect circles in an image.</p>
<p class="calibre2"/>
<pre class="calibre33">Mat image = imread("Test.png");<br class="title-page-name"/> cvtColor(image, image, COLOR_BGR2GRAY);<br class="title-page-name"/> vector&lt;Vec3f&gt; circles;<br class="title-page-name"/> HoughCircles(image,<br class="title-page-name"/> circles,<br class="title-page-name"/> HOUGH_GRADIENT,<br class="title-page-name"/> 2,<br class="title-page-name"/> image.rows/4);<br class="title-page-name"/> for(int i=0; i&lt;circles.size(); i++)<br class="title-page-name"/> {<br class="title-page-name"/> Point center(cvRound(circles[i][0]),<br class="title-page-name"/> cvRound(circles[i][1]));<br class="title-page-name"/> int radius = cvRound(circles[i][2]);<br class="title-page-name"/>circle( image, center, radius, Scalar(0,0,255));<br class="title-page-name"/> }</pre>
<p class="calibre2">4. Detect and draw the convex contours in an image.</p>
<pre class="calibre33">Mat image = imread("Test.png");<br class="title-page-name"/> Mat imgGray;<br class="title-page-name"/> cvtColor(image, imgGray, COLOR_BGR2GRAY);<br class="title-page-name"/>double threshold1 = 100.0;<br class="title-page-name"/> double threshold2 = 200.0;<br class="title-page-name"/> int apertureSize = 3;<br class="title-page-name"/> bool L2gradient = false;<br class="title-page-name"/> Mat edges;<br class="title-page-name"/> Canny(image,<br class="title-page-name"/> edges,<br class="title-page-name"/> threshold1,<br class="title-page-name"/> threshold2,<br class="title-page-name"/> apertureSize,<br class="title-page-name"/> L2gradient);<br class="title-page-name"/>vector&lt;vector&lt;Point&gt; &gt; contours;<br class="title-page-name"/> int mode = CV_RETR_TREE;<br class="title-page-name"/> int method = CV_CHAIN_APPROX_TC89_KCOS;<br class="title-page-name"/> findContours(edges,<br class="title-page-name"/> contours,<br class="title-page-name"/> mode,<br class="title-page-name"/> method);<br class="title-page-name"/>Mat result(image.size(), CV_8UC3, Scalar::all(0));<br class="title-page-name"/> for( int i = 0; i&lt; contours.size(); i++ )<br class="title-page-name"/> {<br class="title-page-name"/> if(isContourConvex(contours[i]))<br class="title-page-name"/> {<br class="title-page-name"/> drawContours(result,<br class="title-page-name"/> contours,<br class="title-page-name"/> i,<br class="title-page-name"/> Scalar(0, 255, 0),<br class="title-page-name"/> 2);<br class="title-page-name"/> }<br class="title-page-name"/> }</pre>
<p class="calibre2">5. Use the <kbd class="calibre13">ORB</kbd> class to detect keypoints in two images, extract their descriptors, and match them.</p>
<pre class="calibre33">Mat object = imread("Object.png");<br class="title-page-name"/> Mat scene = imread("Scene.png");<br class="title-page-name"/>Ptr&lt;ORB&gt; orb = ORB::create();<br class="title-page-name"/> vector&lt;KeyPoint&gt; objKPs, scnKPs;<br class="title-page-name"/> Mat objDesc, scnDesc;<br class="title-page-name"/> orb-&gt;detectAndCompute(object,<br class="title-page-name"/> Mat(),<br class="title-page-name"/> objKPs,<br class="title-page-name"/> objDesc);<br class="title-page-name"/> orb-&gt;detectAndCompute(scene,<br class="title-page-name"/> Mat(),<br class="title-page-name"/> scnKPs,<br class="title-page-name"/> scnDesc);<br class="title-page-name"/>Ptr&lt;BFMatcher&gt; matcher = BFMatcher::create();<br class="title-page-name"/>vector&lt;DMatch&gt; matches;<br class="title-page-name"/> matcher-&gt;match(objDesc, scnDesc, matches);<br class="title-page-name"/>Mat result;<br class="title-page-name"/> drawMatches(object,<br class="title-page-name"/> objKPs,<br class="title-page-name"/> scene,<br class="title-page-name"/> scnKPs,<br class="title-page-name"/> matches,<br class="title-page-name"/> result);<br class="title-page-name"/> imshow("image", result);</pre>
<p class="calibre2">6. Which feature descriptor matching algorithm is incompatible with the ORB algorithm, and why?</p>
<p class="calibre32">You cannot use the FLANN-based matching algorithm with descriptors that have a bit string type, such as ORB.</p>
<p class="calibre2">7. You can use the following OpenCV functions and the sample to calculate the time required to run any number of lines of code. Use it to calculate the time it takes for the matching algorithms on your computer.</p>
<pre class="calibre33">double freq = getTickFrequency();<br class="title-page-name"/> double countBefore = getTickCount();<br class="title-page-name"/>// your code goes here ..<br class="title-page-name"/>double countAfter = getTickCount();<br class="title-page-name"/> cout &lt;&lt; "Duration: " &lt;&lt;<br class="title-page-name"/> (countAfter - countBefore) / freq &lt;&lt; " seconds";</pre>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Chapter 8, Machine Learning in Computer Vision</h1>
                
            
            
                
<p class="calibre2">1. What is the difference between the <kbd class="calibre13">train</kbd> and <kbd class="calibre13">trainAuto</kbd> methods in the <kbd class="calibre13">SVM</kbd> class?</p>
<p class="calibre32">The <kbd class="calibre13">trainAuto</kbd> method chooses the optimal values for the SVM parameters, such as <kbd class="calibre13">C</kbd>, <kbd class="calibre13">Gamma</kbd> and so on, and trains the model, while the <kbd class="calibre13">train</kbd> method simply uses any given parameters. (Read the <kbd class="calibre13">SVM</kbd> class documentation for more details about the <kbd class="calibre13">trainAuto</kbd> function and how exactly the optimization happens.</p>
<p class="calibre2">2. Demonstrate the difference between linear and histogram intersection.</p>
<p class="calibre32">We can set the kernel type to <kbd class="calibre13">LINEAR</kbd> using the following code:</p>
<pre class="calibre33">svm-&gt;setKernel(SVM::LINEAR);</pre>
<p class="calibre32">Here is the result of the classification (segmentation) if we have displayed groups of black, white, and gray dots:</p>
<div><img src="img/00121.gif" class="calibre127"/></div>
<p class="calibre32">Similarly, we can use the following code to set the kernel type to histogram intersection:</p>
<pre class="calibre33">svm-&gt;setKernel(SVM::INTER);</pre>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre32">Here is the result of the same data segmented with the histogram intersection kernel:</p>
<div><img src="img/00122.gif" class="calibre128"/></div>
<p class="calibre2">3. How do you calculate the <kbd class="calibre13">HOGdescriptor</kbd> size for a HOG window size of 128 by 96 pixels? (The rest of the HOG parameters are untouched.)</p>
<pre class="calibre33">HOGDescriptor hog;<br class="title-page-name"/>hog.winSize = Size(128, 128);<br class="title-page-name"/>vector&lt;float&gt; tempDesc;<br class="title-page-name"/>hog.compute(Mat(hog.winSize, CV_8UC3),<br class="title-page-name"/>       tempDesc);<br class="title-page-name"/>int descriptorSize = tempDesc.size();<br class="title-page-name"/><br class="title-page-name"/></pre>
<p class="calibre2">4. How do you update an existing trained <kbd class="calibre13">ANN_MLP</kbd>, instead of training from scratch?</p>
<p class="calibre32">You do this by setting the <kbd class="calibre13">UPDATE_WEIGHTS</kbd> flag during the training. Here's an example:</p>
<pre class="calibre33">ann-&gt;train(trainData, UPDATE_WEIGHTS);</pre>
<p class="calibre2">5. What is the required command (by using <kbd class="calibre13">opencv_createsamples</kbd>) you need to use to create a positive samples vector from a single image of a company logo? Assume you want to have 1,000 samples with a width of 24 and a height of 32, and by using default parameters for rotations and inversions.</p>
<pre class="calibre33">opencv_createsamples -vec samples.vec -img sign.png -bg bg.txt    <br class="title-page-name"/>  -num 1000 -w 24 -h 32</pre>
<p class="calibre2">6. What is the command required to train an LBP cascade classifier for the company logo from the previous question?</p>
<pre class="calibre33">opencv_traincascade -data classifier -vec samples.vec<br class="title-page-name"/>  -bg bg.txt -numPos 1000 -numNeg 1000 -w 24 -h 32<br class="title-page-name"/>   -featureType LBP</pre>
<p class="calibre2">7. What is the default number of stages for training a cascade classifier in <kbd class="calibre13">opencv_traincascade</kbd>? How can we change it? What is the downside of increasing and decreasing the number of stages far beyond its default value?</p>
<p class="calibre32">The default number of stages when training a classifier is 20, which is enough for most use cases. You can set it to any other value you want by using the <kbd class="calibre13">numStages</kbd> parameter. Increasing the number of stages too much can lead to overtraining the classifier and far more time is then required to train it, and vice versa.</p>


            

            
        
    </body></html>