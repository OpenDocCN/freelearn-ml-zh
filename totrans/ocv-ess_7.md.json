["```py\n#include \"opencv2/opencv.hpp\"\n\nusing namespace std;\nusing namespace cv;\n\nint videoCamera()\n{\n    //1-Open the video camera\n    VideoCapture capture(0);\n\n    //Check if video camera is opened\n    if(!capture.isOpened()) return 1;\n\n    bool finish = false;\n    Mat frame;\n    Mat prev_frame;\n    namedWindow(\"Video Camera\");\n\n    if(!capture.read(prev_frame)) return 1;\n\n    //Convert to gray image\n cvtColor(prev_frame,prev_frame,COLOR_BGR2GRAY);\n\n    while(!finish)\n    {\n        //2-Read each frame, if possible\n        if(!capture.read(frame)) return 1;\n\n        //Convert to gray image\n cvtColor(frame ,frame, COLOR_BGR2GRAY);\n\n        //Here, we will put other functions \n\n        imshow(\"Video Camera\", prev_frame);\n\n        //Press Esc to finish\n        if(waitKey(1)==27) finish = true;\n\n        prev_frame = frame;\n    }\n    //Release the video camera\n    capture.release();\n    return 0;\n}\n\nint main( )\n{\n videoCamera();\n}\n```", "```py\n*I(x, y, t) = I(x + ∆x, y + ∆y, t + ∆t)            (1)*\n\n```", "```py\nvoid maxMovementLK(Mat& prev_frame, Mat& frame)\n{\n    // 1-Detect right features to apply the Optical Flow technique\n    vector<Point2f> initial_features;\n goodFeaturesToTrack(prev_frame, initial_features,MAX_FEATURES, 0.1, 0.2 );\n\n    // 2-Set the parameters\n    vector<Point2f>new_features;\n    vector<uchar>status;\n    vector<float> err;\n    TermCriteria criteria(TermCriteria::COUNT | TermCriteria::EPS, 20, 0.03);\n    Size window(10,10);\n    int max_level = 3;\n    int flags = 0;\n    double min_eigT = 0.004;\n\n    // 3-Lucas-Kanade method for the Optical Flow technique\n calcOpticalFlowPyrLK(prev_frame, frame, initial_features, new_features, status, err, window, max_level, criteria, flags, min_eigT );\n\n    // 4-Show the results\n    double max_move = 0;\n    double movement = 0;\n    for(int i=0; i<initial_features.size(); i++)\n    {\n        Point pointA (initial_features[i].x, initial_features[i].y);\n        Point pointB(new_features[i].x, new_features[i].y);\n        line(prev_frame, pointA, pointB, Scalar(255,0,0), 2);\n\n        movement = norm(pointA-pointB);\n        if(movement > max_move)\n            max_move = movement;\n    }\n    if(max_move >MAX_MOVEMENT)\n    {\n        putText(prev_frame,\"INTRUDER\",Point(100,100),FONT_ITALIC,3,Scalar(255,0,0),5);\n        imshow(\"Video Camera\", prev_frame);\n        cout << \"Press a key to continue...\" << endl;\n        waitKey();\n    }\n} \n```", "```py\n...\nwhile(!finish)\n{\n   capture.read(frame);\n\n   cvtColor(frame,frame,COLOR_BGR2GRAY);\n\n// Detect Maximum Movement with Lucas-Kanade Method\n maxMovementLK(prev_frame, frame);\n...\n```", "```py\nvoid maxMovementFarneback(Mat& prev_frame, Mat& frame)\n{\n    // 1-Set the Parameters\n    Mat optical_flow = Mat(prev_frame.size(), COLOR_BGR2GRAY);\n    double pyr_scale = 0.5;\n    int levels = 3;\n    int win_size = 5;\n    int iterations = 5;\n    int poly_n = 5;\n    double poly_sigma = 1.1;\n    int flags = 0;\n\n    // 2-Farneback method for the Optical Flow technique\n calcOpticalFlowFarneback(prev_frame, frame, optical_flow, pyr_scale, levels, win_size, iterations, poly_n, poly_sigma, flags);\n\n    // 3-Show the movements\n    int max_move = 0;\n    for (int i = 1; i <optical_flow.rows ; i++)\n    {\n        for (int j = 1; j <optical_flow.cols ; j++)\n        {\n            Point2f &p = optical_flow.at<Point2f>(i, j);\n            Point pA = Point(round(i + p.x),round(j + p.y));\n            Point pB = Point(i, j);\n            int move = sqrt(p.x*p.x + p.y*p.y);\n            if( move >MIN_MOVEMENT )\n            {\n                line(prev_frame, pA, pB, Scalar(255,0,0),2);\n                if ( move > max_move )\n                    max_move = move;\n            }\n        }\n    }\n    if(max_move >MAX_MOVEMENT)\n    {\n        putText(prev_frame,\"INTRUDER\",Point(100,100),FONT_ITALIC,3,Scalar(255,0,0),5);\n        imshow(\"Video Camera\", prev_frame);\n        cout << \"Press a key to continue...\" << endl;\n        waitKey();\n    }\n}\n```", "```py\nvoid trackingMeanShift(Mat& img, Rect search_window)\n{\n    // 1-Criteria to MeanShift function\n    TermCriteria criteria(TermCriteria::COUNT | TermCriteria::EPS, 10, 1);\n\n    // 2-Tracking using MeanShift\nmeanShift(img, search_window, criteria);\n\n    // 3-Show the result\n    rectangle(img, search_window, Scalar(0,255,0), 3);\n} \n```", "```py\n...\nwhile(!finish)\n{\n   capture.read(frame);\n\n   cvtColor(frame,frame,COLOR_BGR2GRAY);\n\n// Tracking using MeanShift with an initial search window\n Rect search_window(200,150,100,100);\n trackingMeanShift(prev_frame, search_window);\n...\n```", "```py\nvoid trackingCamShift(Mat& img, Rect search_window)\n{\n    //1-Criteria to CamShift function\n    TermCriteria criteria(TermCriteria::COUNT | TermCriteria::EPS, 10, 1);\n\n    //2-Tracking using CamShift\n    RotatedRect found_object = CamShift(img, search_window, criteria);\n\n    //3-Bounding rectangle and show the result\n    Rect found_rect = found_object.boundingRect();\n    rectangle(img, found_rect, Scalar(0,255,0),3);\n}\n```", "```py\nvoid updateMotionHistoryTemplate(Mat& prev_frame, Mat& frame, Mat& history)\n{\n    //1-Calculate the silhouette of difference between the two \n    //frames\n    absdiff(frame, prev_frame, prev_frame);\n\n    //2-Applying a threshold on the difference image\n    double threshold_val = 100; threshold(prev_frame,prev_frame,threshold_val,255,THRESH_BINARY);\n\n    //3-Calculate the current time\n    clock_t aux_time = clock();\n    double current_time = (aux_time-INITIAL_TIME)/CLOCKS_PER_SEC;\n\n    //4-Performing the Update Motion history template\n updateMotionHistory(prev_frame, history, current_time, DURATION);\n}\n```", "```py\n...\n// Calculate the initial time\nINITIAL_TIME = clock()/CLOCKS_PER_SEC;\n\n//Create a Mat to save the Motion history template\nMat history(prev_frame.rows, prev_frame.cols, CV_32FC1);\nwhile(!finish)\n{\n  capture.read(frame);\n\n  cvtColor(frame,frame,COLOR_BGR2GRAY);\n\n// Using Update Motion history template\n  updateMotionHistoryTemplate(prev_frame, frame, history);\n\n   imshow(\"Video Camera\", history);\n...\n```", "```py\nvoid motionGradientMethod(Mat& history, Mat& orientations)\n{\n    //1-Set the parameters\n    double max_gradient = 3.0;\n    double min_gradient = 1.0;\n    //The default 3x3 Sobel filter\n    int apertura_size = 3;\n    //Distance to show the results\n    int dist = 20;\n    Mat mask = Mat::ones(history.rows, history.cols, CV_8UC1);\n\n    //2-Calcule motion gradients\ncalcMotionGradient(history, mask, orientations, max_gradient, min_gradient, apertura_size);\n\n    //3-Show the results\n    Mat result = Mat::zeros(orientations.rows, orientations.cols, CV_32FC1);\n    for (int i=0;i<orientations.rows; i++)\n    {\n        for (int j=0;j<orientations.cols; j++)\n        {\n            double angle = 360-orientations.at<float>(i,j);\n            if (angle!=360)\n            {\n                Point point_a(j, i);\n                Point point_b(round(j+ cos(angle)*dist), round(i+ sin(angle)*dist));\n                line(result, point_a, point_b, Scalar(255,0,0), 1);\n            }\n        }\n    }\n    imshow(\"Result\", result);\n}\n```", "```py\n...\n//Create a Mat to save the Motion history template\nMat history(prev_frame.rows, prev_frame.cols, CV_32FC1);\nwhile(!finish)\n{\n    capture.read(frame);\n\n    cvtColor(frame,frame,COLOR_BGR2GRAY);\n\n//Using Update Motion history template\n updateMotionHistoryTemplate(prev_frame, frame, history);\n\n//Calculate motion gradients\nMat orientations = Mat::ones(history.rows, history.cols, CV_32FC1);\nmotionGradientMethod(history, orientations);\n...\n```", "```py\n#include<opencv2/opencv.hpp>\n\nusing namespace cv;\nusing namespace std;\n\nint backGroundSubKNN()\n{\n    //1-Set the parameters and initializations\n    Mat frame;\n    Mat background;\n    Mat foreground;\n    bool finish = false;\n    int history = 500;\n    double dist2Threshold = 400.0;\n    bool detectShadows = false;\n    vector< vector<Point>> contours;\n    namedWindow(\"Frame\");\n    namedWindow(\"Background\");\n    VideoCapture capture(0);\n\n    //Check if the video camera is opened\n    if(!capture.isOpened()) return 1;\n\n    //2-Create the background subtractor KNN\n    Ptr <BackgroundSubtractorKNN> bgKNN = createBackgroundSubtractorKNN (history, dist2Threshold, detectShadows);\n\n    while(!finish)\n    {\n        //3-Read every frame if possible\n        if(!capture.read(frame)) return 1;\n\n        //4-Using apply and getBackgroundImage method to get\n        //foreground and background from this frame\n        bgKNN->apply(frame, foreground);\n        bgKNN->getBackgroundImage(background); \n        //5-Reduce the foreground noise\n        erode(foreground, foreground, Mat());\n        dilate(foreground, foreground, Mat());\n\n        //6-Find the foreground contours\n        findContours(foreground,contours,RETR_EXTERNAL,CHAIN_APPROX_NONE);\n        drawContours(frame,contours,-1,Scalar(0,0,255),2);\n\n        //7-Show the results\n        imshow(\"Frame\", frame);\n        imshow(\"Background\", background);\n        moveWindow(\"Frame\", 0, 100);\n        moveWindow(\"Background\",800, 100);\n\n        //Press Esc to finish\n        if(waitKey(1) == 27) finish = true;\n    }\n    capture.release();\n    return 0;\n}\n\nint main()\n{\n    backGroundSubKNN();\n}\n```", "```py\n#include <opencv2/opencv.hpp>\n\nusing namespace cv;\nusing namespace std;\n\nint findCameraMovement()\n{\n    //1-Set the parameters and initializations\n    bool finish = false;\n    Mat frame;\n    Mat initial_frame;\n    Mat warp_matrix;\n    Mat warped_frame;\n    int warp_mode = MOTION_HOMOGRAPHY;\n    TermCriteria criteria(TermCriteria::COUNT | TermCriteria::EPS, 50, 0.001);\n    VideoCapture capture(0);\n Rect rec(100,50,350,350);   //Initial rectangle\n    Mat aux_initial_frame;\n    bool follow = false;\n\n    //Check if video camera is opened\n    if(!capture.isOpened()) return 1;\n\n    //2-Initial capture\n    cout << \"\\n Press 'c' key to continue...\" << endl;\n    while(!follow)\n    {\n        if(!capture.read(initial_frame)) return 1;\n        cvtColor(initial_frame ,initial_frame, COLOR_BGR2GRAY);\n        aux_initial_frame = initial_frame.clone();\n        rectangle(aux_initial_frame, rec, Scalar(255,255,255),3);\n        imshow(\"Initial frame\", aux_initial_frame);\n        if (waitKey(1) == 99) follow = true;\n    }\n    Mat template_frame(rec.width,rec.height,CV_32F);\n    template_frame = initial_frame.colRange(rec.x, rec.x + rec.width).rowRange(rec.y, rec.y + rec.height);\n    imshow(\"Template image\", template_frame);\n\n    while(!finish)\n    {\n        cout << \"\\n Press a key to continue...\" << endl;\n        waitKey();\n\nwarp_matrix = Mat::eye(3, 3, CV_32F);\n\n        //3-Read each frame, if possible\n        if(!capture.read(frame)) return 1;\n\n        //Convert to gray image\n        cvtColor(frame ,frame, COLOR_BGR2GRAY);\n\n        try\n        {\n            //4-Use findTransformECC function\n findTransformECC(template_frame, frame, warp_matrix, warp_mode, criteria);\n\n            //5-Obtain the new perspective\n warped_frame = Mat(template_frame.rows, template_frame.cols, CV_32F);\n warpPerspective (frame, warped_frame, warp_matrix, warped_frame.size(), WARP_INVERSE_MAP + WARP_FILL_OUTLIERS);\n        }\n        catch(Exception e) { cout << \"Exception: \" << e.err << endl;}\n\n        imshow (\"Frame\", frame);\n        imshow (\"Warped frame\", warped_frame);\n\n        //Press Esc to finish\n        if(waitKey(1) == 27) finish = true;\n    }\n    capture.release();\n    return 0;\n}\n\nmain()\n{\n    findCameraMovement();\n}\n```"]