["```py\n    class FeatureTracker : public FrameProcessor { \n\n      cv::Mat gray;      // current gray-level image \n      cv::Mat gray_prev; // previous gray-level image \n      // tracked features from 0->1 \n      std::vector<cv::Point2f> points[2]; \n      // initial position of tracked points \n      std::vector<cv::Point2f> initial; \n      std::vector<cv::Point2f> features;  // detected features \n      int max_count;               // maximum number of features to detect \n      double qlevel;               // quality level for feature detection \n      double minDist;              // min distance between two points \n      std::vector<uchar> status;   // status of tracked features \n      std::vector<float> err;      // error in tracking \n\n      public: \n\n        FeatureTracker() : max_count(500), qlevel(0.01), minDist(10.) {} \n\n```", "```py\n    void process(cv:: Mat &frame, cv:: Mat &output) { \n\n      // convert to gray-level image \n      cv::cvtColor(frame, gray, CV_BGR2GRAY);  \n      frame.copyTo(output); \n\n      // 1\\. if new feature points must be added \n      if(addNewPoints()){ \n        // detect feature points \n        detectFeaturePoints(); \n        // add the detected features to  \n        // the currently tracked features \n        points[0].insert(points[0].end(),  \n                         features.begin(), features.end()); \n        initial.insert(initial.end(),  \n                       features.begin(), features.end()); \n      } \n\n      // for first image of the sequence \n      if(gray_prev.empty()) \n        gray.copyTo(gray_prev); \n\n      // 2\\. track features \n      cv::calcOpticalFlowPyrLK( \n                gray_prev, gray, // 2 consecutive images \n                points[0],       // input point positions in first image \n                points[1],       // output point positions in the 2nd image \n                status,          // tracking success \n                err);            // tracking error \n\n      // 3\\. loop over the tracked points to reject some \n      int k=0; \n      for( int i= 0; i < points[1].size(); i++ ) { \n\n        // do we keep this point? \n        if (acceptTrackedPoint(i)) { \n          // keep this point in vector \n          initial[k]= initial[i]; \n          points[1][k++] = points[1][i]; \n        } \n      } \n\n      // eliminate unsuccesful points \n      points[1].resize(k); \n      initial.resize(k); \n\n      // 4\\. handle the accepted tracked points \n      handleTrackedPoints(frame, output); \n\n      // 5\\. current points and image become previous ones \n      std::swap(points[1], points[0]); \n      cv::swap(gray_prev, gray); \n    } \n\n```", "```py\n    // feature point detection \n    void detectFeaturePoints() { \n\n      // detect the features \n      cv::goodFeaturesToTrack(gray,  // the image \n                        features,    // the output detected features \n                        max_count,   // the maximum number of features  \n                        qlevel,      // quality level \n                        minDist);    // min distance between two features \n    } \n\n```", "```py\n    // determine if new points should be added \n    bool addNewPoints() { \n\n      // if too few points \n      return points[0].size()<=10; \n    } \n\n```", "```py\n    //determine which tracked point should be accepted \n    bool acceptTrackedPoint(int i) { \n\n      return status[i] &&  //status is false if unable to track point i \n        // if point has moved \n        (abs(points[0][i].x-points[1][i].x)+ \n            (abs(points[0][i].y-points[1][i].y))>2); \n    } \n\n```", "```py\n    // handle the currently tracked points \n    void handleTrackedPoints(cv:: Mat &frame, cv:: Mat &output) { \n\n      // for all tracked points \n      for (int i= 0; i < points[1].size(); i++ ) { \n\n        // draw line and circle \n        cv::line(output, initial[i],  // initial position  \n                 points[1][i],        // new position  \n                 cv::Scalar(255,255,255)); \n        cv::circle(output, points[1][i], 3,       \n                   cv::Scalar(255,255,255),-1); \n      } \n    } \n\n```", "```py\n    int main() { \n      // Create video procesor instance \n      VideoProcessor processor; \n\n      // Create feature tracker instance \n      FeatureTracker tracker; \n      // Open video file \n      processor.setInput(\"bike.avi\"); \n\n      // set frame processor \n      processor.setFrameProcessor(&tracker); \n\n      // Declare a window to display the video \n      processor.displayOutput(\"Tracked Features\"); \n\n      // Play the video at the original frame rate \n      processor.setDelay(1000./processor.getFrameRate()); \n\n      // Start the process \n      processor.run(); \n    } \n\n```", "```py\n    //Create the optical flow algorithm \n    cv::Ptr<cv::DualTVL1OpticalFlow> tvl1 = cv::createOptFlow_DualTVL1(); \n\n```", "```py\n    cv::Mat oflow;   // image of 2D flow vectors \n    //compute optical flow between frame1 and frame2 \n    tvl1->calc(frame1, frame2, oflow); \n\n```", "```py\n    // Drawing optical flow vectors on an image \n    void drawOpticalFlow(const cv::Mat& oflow,  // the optical flow \n          cv::Mat& flowImage,      // the produced image \n          int stride,              // the stride for displaying the vectors \n          float scale,             // multiplying factor for the vectors \n          const cv::Scalar& color) // the color of the vectors \n    { \n      // create the image if required \n      if (flowImage.size() != oflow.size()) { \n        flowImage.create(oflow.size(), CV_8UC3); \n        flowImage = cv::Vec3i(255,255,255); \n      } \n\n      //for all vectors using stride as a step \n      for (int y = 0; y < oflow.rows; y += stride) \n        for (int x = 0; x < oflow.cols; x += stride) { \n          //gets the vector \n          cv::Point2f vector = oflow.at< cv::Point2f>(y, x); \n          // draw the line      \n          cv::line(flowImage, cv::Point(x,y), \n                   cv::Point(static_cast<int>(x + scale*vector.x + 0.5),             \n                             static_cast<int>(y + scale*vector.y + 0.5)),\n                   color); \n          // draw the arrow tip \n          cv::circle(flowImage, \n                     cv::Point(static_cast<int>(x + scale*vector.x + 0.5),  \n                               static_cast<int>(y + scale*vector.y + 0.5)),\n                     1, color, -1); \n        } \n    } \n\n```", "```py\n    // Draw the optical flow image \n    cv::Mat flowImage; \n    drawOpticalFlow(oflow,                // input flow vectors \n                    flowImage,            // image to be generated \n                    8,                    // display vectors every 8 pixels \n                    2,                    // multiply size of vectors by 2 \n                    cv::Scalar(0, 0, 0)); // vector color \n\n```", "```py\n    // compute a smoother optical flow between 2 frames \n    tvl1->setLambda(0.075); \n    tvl1->calc(frame1, frame2, oflow); \n\n```", "```py\n    class VisualTracker : public FrameProcessor { \n\n      cv::Ptr<cv::Tracker> tracker; \n      cv::Rect2d box; \n      bool reset; \n\n      public: \n      // constructor specifying the tracker to be used \n      VisualTracker(cv::Ptr<cv::Tracker> tracker) :   \n                    reset(true), tracker(tracker) {} \n\n```", "```py\n   // set the bounding box to initiate tracking \n   void setBoundingBox(const cv::Rect2d& bb) { \n      box = bb; \n      reset = true; \n   } \n\n```", "```py\n    // callback processing method \n    void process(cv:: Mat &frame, cv:: Mat &output) { \n\n      if (reset) { // new tracking session \n        reset = false; \n        tracker->init(frame, box); \n\n      } else { \n        // update the target's position \n        tracker->update(frame, box); \n      } \n\n      // draw bounding box on current frame \n      frame.copyTo(output); \n      cv::rectangle(output, box, cv::Scalar(255, 255, 255), 2); \n    } \n\n```", "```py\n    int main(){ \n      // Create video procesor instance \n      VideoProcessor processor; \n\n      // generate the filename \n      std::vector<std::string> imgs; \n      std::string prefix = \"goose/goose\"; \n      std::string ext = \".bmp\"; \n\n      // Add the image names to be used for tracking \n      for (long i = 130; i < 317; i++) { \n\n        std::string name(prefix); \n        std::ostringstream ss; ss << std::setfill('0') <<  \n                 std::setw(3) << i; name += ss.str(); \n        name += ext; \n        imgs.push_back(name); \n      } \n\n      // Create feature tracker instance \n      VisualTracker tracker(cv::TrackerMedianFlow::createTracker()); \n\n      // Open video file \n      processor.setInput(imgs); \n\n      // set frame processor \n      processor.setFrameProcessor(&tracker); \n\n      // Declare a window to display the video \n      processor.displayOutput(\"Tracked object\"); \n\n      // Define the frame rate for display \n      processor.setDelay(50); \n\n      // Specify the original target position \n      tracker.setBoundingBox(cv::Rect(290,100,65,40)); \n\n      // Start the tracking \n      processor.run(); \n    } \n\n```", "```py\n     VisualTracker tracker(cv::TrackerKCF::createTracker()); \n\n```"]