<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer157">
			<h1 id="_idParaDest-221" class="chapter-number"><a id="_idTextAnchor221"/>15</h1>
			<h1 id="_idParaDest-222"><a id="_idTextAnchor222"/>Recommender Systems – Predict What Movies a User Would Like to Watch</h1>
			<p>Recommender systems, as the name suggests, are solutions that are designed to provide recommendations to users based on various parameters, such as past behavior, item similarity, or even user demographics. These systems are used in a range of applications, such as for suggesting videos on YouTube, movies on Netflix, or products <span class="No-Break">on Amazon.</span></p>
			<p>The primary goal of recommender systems is to personalize online user experiences to drive business outcomes such as higher user engagement and increased revenues. As the amount of available content and choices increases, personalized recommendations become crucial for enhancing user experience and ensuring that the customers don’t get overwhelmed by the <span class="No-Break">available options.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Overview of the different types of <span class="No-Break">recommender systems</span></li>
				<li>Deploying a movie recommender system on <span class="No-Break">Vertex AI</span></li>
			</ul>
			<p>First, we’ll look at the different types of recommender systems you will typically find in <span class="No-Break">the wild.</span></p>
			<h1 id="_idParaDest-223"><a id="_idTextAnchor223"/>Different types of recommender systems</h1>
			<p>In this section, we’ll delve into <a id="_idIndexMarker1010"/>the diverse types of recommendation engines, shedding light on their methodologies and the unique advantages each brings to <span class="No-Break">the table:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Collaborative filtering</strong></span><span class="No-Break">:</span><p class="list-inset">This approach is<a id="_idIndexMarker1011"/> based on the idea that users who have agreed in the past will agree in the future about their preference for certain items. As shown in the following figure, the model tries to find similar users by looking at their viewing/reading and recommends the content viewed by one user to other, <span class="No-Break">similar users:</span></p></li>
			</ul>
			<div>
				<div id="_idContainer155" class="IMG---Figure">
					<img src="image/B17792_15_1.jpg" alt="Figure 15.1 – Collaborative filtering" width="701" height="723"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.1 – Collaborative filtering</p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Content-based filtering</strong></span><span class="No-Break">:</span><p class="list-inset">This method <a id="_idIndexMarker1012"/>uses item<a id="_idIndexMarker1013"/> attributes to recommend additional items similar to what the user likes, based on their previous actions or <span class="No-Break">explicit feedback.</span></p><p class="list-inset">For example, if a user has shown a preference for movies directed by Christopher Nolan, the system will rank the movies that were directed by him higher when making recommendations. Here, the content (director, genre, actors, and more) of the movies is taken <span class="No-Break">into account.</span></p><p class="list-inset"><strong class="bold">Advantages</strong>: Can handle <a id="_idIndexMarker1014"/>new items, so there’s no need for other <span class="No-Break">user’s data.</span></p><p class="list-inset"><strong class="bold">Challenges</strong>: Over-specialization (may <a id="_idIndexMarker1015"/>only show very similar items) and requires good <span class="No-Break">quality metadata.</span></p><p class="list-inset">As shown in the following figure, in content-based filtering, the model tries to find content similar to the content the user has viewed in the past and then recommends<a id="_idIndexMarker1016"/> similar content to the user in <span class="No-Break">the future:</span></p></li>
			</ul>
			<div>
				<div id="_idContainer156" class="IMG---Figure">
					<img src="image/B17792_15_2.jpg" alt="Figure 15.2 – Content-based filtering" width="697" height="698"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.2 – Content-based filtering</p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Demographic filtering</strong></span><span class="No-Break">:</span><p class="list-inset">Demographic<a id="_idIndexMarker1017"/> recommenders provide personalized recommendations by categorizing users based on personal attributes and then offering recommendations based on <span class="No-Break">demographic classes.</span></p><p class="list-inset">For example, if data indicates that males aged 18-24 in a particular region have a high affinity for action movies such as <em class="italic">Fast and Furious</em>, then a male in that age bracket from that region would be more likely to receive a recommendation for that movie or <a id="_idIndexMarker1018"/>similar <span class="No-Break">action-packed movies.</span></p><p class="list-inset"><strong class="bold">Advantages</strong>: Straightforward<a id="_idIndexMarker1019"/> and doesn’t need past <span class="No-Break">user-item interactions.</span></p><p class="list-inset"><strong class="bold">Challenges</strong>: Less<a id="_idIndexMarker1020"/> personalized, stereotype-based, and requires user <span class="No-Break">demographic data.</span></p><p class="list-inset">In practice, many state-of-the-art systems use hybrid methods that combine elements from multiple types of recommendation techniques to overcome the limitations of any single approach. An example is Netflix’s recommendation engine, which uses a mix of collaborative, content-based, and other techniques to provide its users with movie and <span class="No-Break">show recommendations.</span></p></li>
			</ul>
			<p>Next, we’ll look at how <a id="_idIndexMarker1021"/>content recommender systems are evaluated in real-world applications through user behavior <span class="No-Break">and feedback.</span></p>
			<h2 id="_idParaDest-224"><a id="_idTextAnchor224"/>Real-world evaluation of recommender systems</h2>
			<p>In the real world, the<a id="_idIndexMarker1022"/> evaluation of recommender systems extends beyond traditional machine learning metrics to encompass a broader <a id="_idIndexMarker1023"/>range of <strong class="bold">key performance indicators</strong> (<strong class="bold">KPIs</strong>) that align more closely with business objectives and user experience. Unlike typical “lab” settings, where accuracy metrics such as precision, recall, or RMSE are emphasized, real-world evaluations prioritize KPIs such as <strong class="bold">click-through rate</strong> (<strong class="bold">CTR</strong>), conversion <a id="_idIndexMarker1024"/>rate, and user engagement. These KPIs offer a direct reflection of how users interact with the recommendations in a <span class="No-Break">live environment.</span></p>
			<p>For instance, a high CTR indicates that users find the recommendations relevant enough to explore them further, while a strong conversion rate suggests that the recommendations are effective in driving the desired user actions, such as purchases or <span class="No-Break">content consumption.</span></p>
			<p>Additionally, metrics<a id="_idIndexMarker1025"/> such as <strong class="bold">customer lifetime value</strong> (<strong class="bold">CLV</strong>) and <strong class="bold">net promoter score</strong> (<strong class="bold">NPS</strong>) provide <a id="_idIndexMarker1026"/>insights into the long-term impact of the recommender system on business revenue and user loyalty. By focusing on these KPIs, organizations can assess the real-world effectiveness of their recommender systems, ensuring they not only perform well in terms of machine learning metrics but also contribute positively to user satisfaction and business goals. This approach recognizes that the ultimate success of recommender systems lies in their ability to enhance the user experience and drive business outcomes, rather<a id="_idIndexMarker1027"/> than just achieving high scores on traditional evaluation metrics. Let’s take a closer look at the different types <span class="No-Break">of metrics:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Engagement metrics</strong></span><span class="No-Break">:</span><p class="list-inset">Engagement metrics assess<a id="_idIndexMarker1028"/> how users interact <a id="_idIndexMarker1029"/>with the recommendations, providing insights into the system’s ability to capture and retain <span class="No-Break">user interest.</span></p><p class="list-inset">Let’s look at some different <span class="No-Break">engagement metrics:</span></p><ul><li><strong class="bold">CTR</strong>: The ratio of clicks to the number of recommendations displayed, indicating how engaging the <span class="No-Break">recommendations are</span></li><li><strong class="bold">Conversion rate</strong>: The percentage of recommendations that result in a desired action, such as a purchase or <span class="No-Break">a subscription</span></li><li><strong class="bold">Average time spent</strong>: The amount of time users spend interacting with the recommended content, reflecting user engagement and <span class="No-Break">content relevance</span></li></ul></li>
				<li><span class="No-Break"><strong class="bold">User satisfaction</strong></span><span class="No-Break">:</span><p class="list-inset">User satisfaction metrics<a id="_idIndexMarker1030"/> evaluate the extent to which users are pleased with the recommendations, serving as a direct indicator of the system’s success from the <span class="No-Break">user’s perspective.</span></p><p class="list-inset">The following are some user <span class="No-Break">satisfaction metrics:</span></p><ul><li><strong class="bold">User feedback and ratings</strong>: Direct user feedback on the recommended items, providing insights into <span class="No-Break">user satisfaction</span></li><li><strong class="bold">NPS</strong>: A metric that gauges user satisfaction and loyalty by asking users how likely they are to recommend the system <span class="No-Break">to others</span></li></ul></li>
				<li><strong class="bold">Business </strong><span class="No-Break"><strong class="bold">impact metrics</strong></span><span class="No-Break">:</span><p class="list-inset">Business<a id="_idIndexMarker1031"/> impact metrics quantify the economic value and effectiveness of the recommender system in contributing to the organization’s <span class="No-Break">financial goals.</span></p><p class="list-inset">The following are key business <span class="No-Break">impact metrics:</span></p><ul><li><strong class="bold">Revenue per user</strong> (<strong class="bold">RPU</strong>): The average <a id="_idIndexMarker1032"/>revenue generated per user, indicating the economic value of <span class="No-Break">the recommendations</span></li><li><strong class="bold">CLV</strong>: The total revenue expected from a user over their lifetime, impacted by the effectiveness of <span class="No-Break">the recommendations</span></li></ul></li>
				<li><span class="No-Break"><strong class="bold">Coverage metrics</strong></span><span class="No-Break">:</span><p class="list-inset">Coverage metrics<a id="_idIndexMarker1033"/> determine the extent to which the recommender system effectively utilizes the available content and reaches a wide <span class="No-Break">user base.</span></p><p class="list-inset">The following are some different <span class="No-Break">coverage metrics:</span></p><ul><li><strong class="bold">Catalog coverage</strong>: The proportion of items in the catalog recommended to users, reflecting the system’s ability to utilize the <span class="No-Break">entire inventory</span></li><li><strong class="bold">User coverage</strong>: The <a id="_idIndexMarker1034"/>percentage of users receiving relevant recommendations. This is crucial for user inclusivity <span class="No-Break">and engagement</span></li></ul></li>
			</ul>
			<p>In recommender systems, KPIs are essential for monitoring performance, understanding user preferences, and<a id="_idIndexMarker1035"/> aligning recommendations with business goals. A balanced focus on accuracy, user engagement, satisfaction, and business impact ensures the development of an effective and user-centric recommender system. Continuous monitoring and optimization of these KPIs are vital to maintaining relevance and effectiveness in a dynamic <span class="No-Break">user environment.</span></p>
			<p>Now, let’s look at how to build and deploy a recommender system on <span class="No-Break">Vertex AI.</span></p>
			<h1 id="_idParaDest-225"><a id="_idTextAnchor225"/>Deploying a movie recommender system on Vertex AI</h1>
			<p>Now, let’s walk through <a id="_idIndexMarker1036"/>an example of creating a movie recommendation system based on a collaborative filtering type model, deploying it on Vertex AI, and then querying it to get movie recommendations for specific users and movie genre types. The key steps are <span class="No-Break">as follows:</span></p>
			<ol>
				<li><span class="No-Break">Data preparation</span></li>
				<li>Model design <span class="No-Break">and training</span></li>
				<li>Local <span class="No-Break">model testing</span></li>
				<li>Registering the model on <span class="No-Break">Vertex AI</span></li>
				<li>Deploying <span class="No-Break">the model</span></li>
				<li><span class="No-Break">Getting predictions</span></li>
			</ol>
			<p class="callout-heading">Note</p>
			<p class="callout">The notebook for this exercise can be found <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter15/Chp-15_Movie_Recommender.ipynb"><span class="No-Break">https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter15/Chp-15_Movie_Recommender.ipynb</span></a><span class="No-Break">.</span></p>
			<p><strong class="bold">Dataset</strong>: To train the model, we will<a id="_idIndexMarker1037"/> use the <strong class="bold">MovieLens dataset</strong> (<em class="italic">F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: </em><span class="No-Break"><em class="italic">19:1–19:19.</em></span><span class="No-Break"> </span><a href="https://doi.org/10.1145/2827872"><span class="No-Break">https://doi.org/10.1145/2827872</span></a><span class="No-Break">).</span></p>
			<p>The MovieLens dataset is one of the most popular datasets that’s used in the field of recommendation systems. It’s a collection of movie ratings and has been produced by the <em class="italic">GroupLens Research Project</em> at the <em class="italic">University </em><span class="No-Break"><em class="italic">of Minnesota</em></span><span class="No-Break">.</span></p>
			<p>Additional details about <span class="No-Break">this dataset:</span></p>
			<p>Data: The dataset contains multiple versions with different sizes (ranging from 100k ratings to 25M ratings). It consists of movie ratings, movie metadata (genres and year of release), and demographic data of <span class="No-Break">the users.</span></p>
			<p><span class="No-Break">Data fields:</span></p>
			<ul>
				<li><strong class="bold">User data</strong>: User ID, age, gender, occupation, and <span class="No-Break">ZIP code</span></li>
				<li><strong class="bold">Movie data</strong>: Movie ID, title, release date, and associated genres (such as action, adventure, comedy, and <span class="No-Break">so on)</span></li>
				<li><strong class="bold">Ratings</strong>: User ID, movie ID, rating (typically on a scale of 1 to 5), <span class="No-Break">and timestamp</span></li>
			</ul>
			<p>Use cases: It is mainly used for experimenting with collaborative filtering, content-based filtering, and hybrid <span class="No-Break">recommendation algorithms.</span></p>
			<p>The dataset aids in understanding user behavior and patterns in <span class="No-Break">movie ratings.</span></p>
			<p>The MovieLens dataset’s popularity stems from its relatively clean data, which lacks much of the noise and inconsistencies found in larger, more real-world datasets. This makes it ideal for <a id="_idIndexMarker1038"/>prototyping, learning, and initial experimentation in the realm of <span class="No-Break">recommender systems.</span></p>
			<p>Now, let’s use this dataset to create a simple collaborative filtering-based movie <span class="No-Break">recommendation solution.</span></p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor226"/>Data preparation</h2>
			<p>In this section, we will<a id="_idIndexMarker1039"/> download and preprocess the MovieLens dataset to get the model training data ready for the recommendation model. Follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li><strong class="bold">Download and extract the dataset</strong>: Download the <strong class="source-inline">ml-latest-small.zip</strong> file, which contains the <span class="No-Break">MovieLens dataset:</span><pre class="source-code">
# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
movielens_data_url = (
    "http://files.grouplens.org/datasets/movielens/ml-latest-small.zip")
movielens_zip_file = keras.utils.get_file(
    "ml-latest-small.zip", movielens_data_url, extract=False)
movie_datasets_path = Path(movielens_zip_file).parents[0]
movielens_dir = movie_datasets_path / "ml-latest-small"
with ZipFile(movielens_zip_file, "r") as zip:
zip.extractall(path=movie_datasets_path)</pre></li>				<li><strong class="bold">Load the ratings data</strong>: Read<a id="_idIndexMarker1040"/> the <strong class="source-inline">ratings.csv</strong> file into a DataFrame <span class="No-Break">for processing:</span><pre class="source-code">
# Load the Movie Ratings file
ratings_file = movielens_dir / "ratings.csv"
df = pd.read_csv(ratings_file)</pre></li>				<li><strong class="bold">Encode the data</strong>: Encode both the user and movie IDs as integer indices for <span class="No-Break">model training:</span><pre class="source-code">
# Extract the unique user IDs from the 'userId' column and convert them to a list
user_ids = df["userId"].unique().tolist()
# Create a dictionary that maps each user ID to a unique integer (encoded form)
user2user_encoded = {x: i for i, x in enumerate(user_ids)}
# Create a dictionary that maps each unique integer back to its original user ID
userencoded2user = {i: x for i, x in enumerate(user_ids)}
# Extract the unique movie IDs from the 'movieId' column and convert them to a list
movie_ids = df["movieId"].unique().tolist()
# Create a dictionary that maps each movie ID to a unique integer (encoded form)
movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}
# Create a dictionary that maps each unique integer back to its original movie ID
movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}
# Map the original user IDs in the 'userId' column to their encoded forms and store in a new column 'user'
df["user"] = df["userId"].map(user2user_encoded)
# Map the original movie IDs in the 'movieId' column to their encoded forms and store in a new column 'movie'
df["movie"] = df["movieId"].map(movie2movie_encoded)</pre></li>			</ol>
			<p>Since our training<a id="_idIndexMarker1041"/> data is now ready in the form of the <strong class="source-inline">users</strong> and <strong class="source-inline">movies</strong> DataFrames, let’s build the <span class="No-Break">recommender model.</span></p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor227"/>Model building</h2>
			<p>In this section, we’ll build<a id="_idIndexMarker1042"/> the structure of our deep learning recommendation model using Keras and train it on the dataset we <a id="_idIndexMarker1043"/>created in the <span class="No-Break">previous section:</span></p>
			<p><strong class="bold">Define the model</strong>: Define the <strong class="source-inline">RecommendationModel</strong> model class, which uses embeddings for users <span class="No-Break">and movies:</span></p>
			<pre class="source-code">
class RecommendationModel(keras.Model):
    def __init__(self, num_users, num_movies, embedding_size, **kwargs):
        super().__init__(**kwargs)
        self.num_users = num_users
        self.num_movies = num_movies
        self.embedding_size = embedding_size
        # User embeddings layer: Represents each user as a vector in the embedding space
        self.user_embedding = layers.Embedding(
            num_users, embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),)
        self.user_bias = layers.Embedding(num_users, 1)
        # Movie embeddings layer: Represents each movie as a vector in the embedding space
        self.movie_embedding = layers.Embedding(
            num_movies, embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),)
        self.movie_bias = layers.Embedding(num_movies, 1)</pre>			<p>The model <a id="_idIndexMarker1044"/>calculates <a id="_idIndexMarker1045"/>a match score through a dot product of user and <span class="No-Break">movie embeddings.</span></p>
			<pre class="source-code">
# Forward pass: Given user and movie IDs, predict the rating
    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        movie_vector = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])
        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)
        x = dot_user_movie + user_bias + movie_bias
        # The sigmoid activation forces the rating to between 0 and 1
        return tf.nn.sigmoid(x))</pre>			<p><strong class="bold">Model compilation</strong>: Compile the <a id="_idIndexMarker1046"/>model using binary cross-entropy as the loss function and Adam as <span class="No-Break">the optimizer:</span></p>
			<pre class="source-code">
# # Instantiate the Recommender model with the defined number of users, movies, and embedding size
model = RecommendationModel(num_users, num_movies, EMBEDDING_SIZE)
# Compile the Recommender model
model.compile(
    #Define loss function
    loss=tf.keras.losses.BinaryCrossentropy(),
    #Define Optimizer function
 optimizer=keras.optimizers.Adam(learning_rate=0.001))</pre>			<p><strong class="bold">Model training</strong>: Train the<a id="_idIndexMarker1047"/> model using the training data and validate it using the <span class="No-Break">validation data:</span></p>
			<pre class="source-code">
# Train the model
history = model.fit(
    x=x_train,y=y_train,batch_size=64,
    epochs=5,verbose=1,validation_data=(x_val, y_val),)</pre>			<h2 id="_idParaDest-228"><a id="_idTextAnchor228"/>Local model testing</h2>
			<p>Before deploying the model, let’s<a id="_idIndexMarker1048"/> test its predictions locally to ensure it works <span class="No-Break">as expected:</span></p>
			<ol>
				<li><strong class="bold">Prepare the test data</strong>: For a random user, create an array of movies they haven’t <span class="No-Break">watched yet:</span><pre class="source-code">
#Load the metadata for the movies
movie_df = pd.read_csv(movielens_dir / "movies.csv")
# Pick a user and select their top recommendations.
user_id = df.userId.sample(1).iloc[0]
movies_watched_by_user = df[df.userId == user_id]
movies_not_watched = movie_df[~movie_df["movieId"] .isin(
    movies_watched_by_user.movieId.values)]["movieId"]
movies_not_watched = list(set(movies_not_watched).intersection(
    set(movie2movie_encoded.keys())))
movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]
user_encoder = user2user_encoded.get(user_id)
#Create a array of data instances to be sent for predictions
user_prediction_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))</pre></li>				<li><strong class="bold">Predict ratings</strong>: Use the model to predict ratings for movies the user hasn’t <span class="No-Break">rated before:</span><pre class="source-code">
#Get predicted ratings for the unwatched movies and the selected user
ratings = model.predict(user_movie_array).flatten()</pre></li>				<li><strong class="bold">Recommend movies</strong>: Now, based on the predicted ratings, let’s identify and display the top 10 movie<a id="_idIndexMarker1049"/> recommendations for <span class="No-Break">the user:</span><pre class="source-code">
# Sort and pick top 10 ratings
movie_indices_top10 = ratings.argsort()[-10:][::-1]
movie_recommendations_ids = [
    movie_encoded2movie.get(movies_not_watched[x][0]) for x in movie_indices_top10
]
print("----" * 10)
print("Top movies recommendations for user id: {}".format(user_id))
print("----" * 10)
recommended_movies = movie_df[movie_df["movieId"].isin(
    movie_recommendations_ids)]
for row in recommended_movies.itertuples():
    print(row.title, ":", row.genres)</pre><p class="list-inset">The final predictions from the model are shown here. Your list of movies will vary based on the user selected from <span class="No-Break">the dataset:</span></p><pre class="source-code">--------------------------------
Top 10 movie recommendations
--------------------------------
Volunteers (1985) : Comedy
Emperor's New Clothes, The (2001) : Comedy
Caveman (1981) : Comedy
Juwanna Mann (2002) : Comedy
Top Secret! (1984) : Comedy
Unfaithfully Yours (1948) : Comedy
Oh, God! You Devil (1984) : Comedy
Fish Story (Fisshu sutôrî) (2009) : Comedy
Kevin Smith: Too Fat For 40 (2010) : Comedy
War Dogs (2016) : Comedy</pre></li>			</ol>
			<p>So, it seems like the<a id="_idIndexMarker1050"/> model is working well in the local environment and can generate movie recommendations. Now, let’s deploy the model to <span class="No-Break">the cloud.</span></p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor229"/>Deploying the model on Google Cloud</h2>
			<p>The first step is <a id="_idIndexMarker1051"/>to deploy the model on GCP so that we can upload and register our local model on Vertex AI. Follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li><strong class="bold">Register the model on Vertex AI</strong>: To register/upload the model on Vertex AI, we need to save the core machine learning model <a id="_idIndexMarker1052"/>artifacts to a <strong class="bold">Google Cloud Storage</strong> (<span class="No-Break"><strong class="bold">GCS</strong></span><span class="No-Break">) bucket:</span><pre class="source-code">
# Save the model in GCS bucket so that we can import it into Vertex AI Model Registry
MODEL_DIR = BUCKET_URI + "/model/"
model.save(MODEL_DIR)</pre><p class="list-inset">Now, we must upload the saved model to the Vertex AI Model Registry. To do this, we will need to pass the <span class="No-Break">following parameters:</span></p><ul><li><strong class="source-inline">display_name</strong>: The model’s display name that will be displayed in the Vertex AI <span class="No-Break">Model Registry.</span></li><li><strong class="source-inline">artifact_uri</strong>: The location of the saved model <span class="No-Break">in GCS.</span></li><li><strong class="source-inline">serving_container_image_uri</strong>: The Docker image to be used as a serving container. You can use one of the images provided as part of Vertex AI or upload a custom container image to the GCP Artifact Registry. This chapter’s Jupyter Notebook provides <span class="No-Break">more details.</span></li><li><strong class="source-inline">is_default_version</strong>: This specifies whether this will be the default version for the <span class="No-Break">model resource.</span></li><li><strong class="source-inline">version_ailiases</strong>: Alternative alias names for the <span class="No-Break">model version.</span></li><li><strong class="source-inline">version_description</strong>: User<a id="_idIndexMarker1053"/> description of the <span class="No-Break">model version.</span></li></ul><pre class="source-code">#Define service container configuration
DEPLOY_GPU, DEPLOY_NGPU = (None, None)
TF = "2.12".replace(".", "-")
if DEPLOY_GPU:
    DEPLOY_VERSION = "tf2-gpu.{}".format(TF)
else:
    DEPLOY_VERSION = "tf2-cpu.{}".format(TF)
DEPLOY_IMAGE = "{}-docker.pkg.dev/vertex-ai/prediction/{}:latest".format(
    REGION.split("-")[0], DEPLOY_VERSION)
#Upload the Model to Vertex AI Model Registry
model = aip.Model.upload(
    display_name="recommender_model_chp15",
    artifact_uri=MODEL_DIR,
    serving_container_image_uri=DEPLOY_IMAGE,
    is_default_version=True,
    version_aliases=["v1"],
    version_description="This is the first version of the model",)</pre></li>				<li><strong class="bold">Deploy the model as a Vertex </strong><span class="No-Break"><strong class="bold">AI endpoint</strong></span><span class="No-Break">:</span><p class="list-inset">Create an endpoint <a id="_idIndexMarker1054"/>on Vertex AI and deploy the model for real-time inference. Ensure you provide a <span class="No-Break">display name:</span></p><pre class="source-code">
endpoint = aip.Endpoint.create(
    display_name="recommender_model_chp15",
    project=PROJECT_ID,
    location=REGION,)
print(endpoint)</pre><p class="list-inset">Now, deploy the model to the newly created endpoint while specifying the machine type and <a id="_idIndexMarker1055"/>other <span class="No-Break">configuration settings:</span></p><pre class="source-code">#Deploy the model to the Vertex AI endpoint
DEPLOY_COMPUTE = "n1-standard-4" #Virtual Machine type
response = endpoint.deploy(
    model=model,
    deployed_model_display_name="example_",
    machine_type=DEPLOY_COMPUTE,)
print(endpoint)</pre></li>			</ol>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor230"/>Using the model for inference</h2>
			<p>This is the fun part! We’ll <a id="_idIndexMarker1056"/>use our machine learning model, which has been deployed in Google Cloud Vertex AI, to make predictions using API calls. First, we’ll create a Python function to send the prediction requests, then create a test/inference dataset we can send to the model as part of our request. Finally, we’ll parse the prediction response we receive back from the model. Let’s <span class="No-Break">get started:</span></p>
			<ol>
				<li><strong class="bold">Create a prediction function</strong>: Create a function called <strong class="source-inline">predict_custom_trained_model_sample</strong> so that you can make predictions using the deployed model on <span class="No-Break">Vertex AI:</span><pre class="source-code">
def predict_custom_trained_model_sample(
    project: str,
    endpoint_id: str,
    instances: Union[Dict, List[Dict]],
    location: str = "us-central1",
    api_endpoint: str = "us-central1-aiplatform.googleapis.com",):
    # Initialize client that will be used to create and send requests.
    client_options = {"api_endpoint": api_endpoint}
    client = aiplatform.gapic.PredictionServiceClient(
        client_options=client_options)
    # The format of each instance should conform to the deployed model's prediction
    instances = [
        json_format.ParseDict(instance_dict, Value()) for instance_dict in instances]
    parameters_dict = {}
    parameters = json_format.ParseDict(parameters_dict, Value())
    endpoint = client.endpoint_path(
        project=project, location=location, endpoint=endpoint_id)
    response = client.predict(
        endpoint=endpoint, instances=instances, parameters=parameters)
     print(" deployed_model_id:", response.deployed_model_id)
    # The predictions are a google.protobuf.Value representation of the model's predictions.
    predictions = response.predictions
    return(predictions)</pre></li>				<li><strong class="bold">Create the inference dataset</strong>: Create<a id="_idIndexMarker1057"/> a sample inference dataset for a user <span class="No-Break">and genre:</span><pre class="source-code">
# Pick a random user for whom we can try to predict movie predictions
user_id = df.userId.sample(1).iloc[0]
#Add filter for the category for which you need recommendations
genre_filter = "Drama"</pre><ul><li>Create a prediction input dataset consisting of all movies in the selected genre that the <a id="_idIndexMarker1058"/>user has not watched (<span class="No-Break">not rated):</span><pre class="source-code"># Create Test Dataset for a User and the selected Genre
movie_df = pd.read_csv(movielens_dir / "movies.csv")
movies_watched_by_user = df[df.userId == user_id]
#Create Dataframe with Movies not watched by the User
movies_not_watched_df = movie_df[
    (~movie_df["movieId"].isin(movies_watched_by_user.movieId.values)) &amp; (movie_df["genres"].str.contains(genre_filter))
][["movieId","title","genres"]]
#Get the list of Movie Ids which can the be encoded using the movie id encoder we had built earlier
movies_not_watched = movies_not_watched_df["movieId"]
movies_not_watched = list(
    set(movies_not_watched).intersection(set(movie2movie_encoded.keys())))
movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]
#Get the encoded value of the user id based on the encoder built earlier
user_encoder = user2user_encoded.get(user_id)
user_movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))
#Create data instances that would be sent to the API for inference
instances = user_movie_array.tolist()</pre></li></ul></li>				<li><strong class="bold">Send a prediction request</strong>: Submit the inference dataset to the Vertex AI Prediction <span class="No-Break">API endpoint:</span><pre class="source-code">
# Get predicted ratings for the unwatched movies and the selected user
predictions = predict_custom_trained_model_sample(
    project=endpoint.project,
    endpoint_id=endpoint.name,
    location=endpoint.location,
    instances = instances)</pre></li>				<li><strong class="bold">Parse the results</strong>: Parse the<a id="_idIndexMarker1059"/> predictions received from the API endpoint and <span class="No-Break">combine them:</span><pre class="source-code">
# Create a DataFrame from the predictions list/array
predictions_df = pd.DataFrame(predictions)
# Rename the column in the predictions DataFrame to 'rating'
predictions_df.columns = ['rating']</pre></li>				<li><strong class="bold">Create a DataFrame</strong>: Create a DataFrame from the <span class="No-Break">instances list/array:</span><pre class="source-code">
instances_df = pd.DataFrame(instances)
# Rename the columns in the instances DataFrame to 'userId' and 'movieId' respectively
instances_df.columns = ['userId','movieId']
# Merge the instances and predictions DataFrames
combined_results = instances_df.join(predictions_df)
# Sort the results by the rating column in descending order
combined_results_sorted = combined_results.sort_values('rating',ascending=False)
# Filter the results to show only the top 15 results
combined_results_sorted_top = combined_results_sorted.head(15)["movieId"].values
# Map the encoded Movie IDs to the actual Movie IDs
recommended_movie_ids = [
    movie_encoded2movie.get(x) for x in combined_results_sorted_top]</pre></li>				<li><strong class="bold">Print</strong>: Print the final<a id="_idIndexMarker1060"/> recommended list <span class="No-Break">of movies:</span><pre class="source-code">
print("----" * 10)
print("Top 15 recommended movies recommendations for User:",user_id," and Genre",genre_filter)
print("Genre:",genre_filter)
print("----" * 10)
recommended_movies = movie_df[movie_df["movieId"].isin(recommended_movie_ids)]
for row in recommended_movies.itertuples():
    print(row.title, ":", row.genres)</pre></li>				<li>The output will look<a id="_idIndexMarker1061"/> something <span class="No-Break">like this:</span><pre class="source-code">
----------------------------------------
Top 15 recommended movies recommendations for User: 551
Genre: Drama
--------------------------------
Stunt Man, The (1980) : Action|Adventure|Comedy|Drama|Romance|Thriller
Affair of the Necklace, The (2001) : Drama
Baran (2001) : Adventure|Drama|Romance
Business of Strangers, The (2001) : Action|Drama|Thriller
No Man's Land (2001) : Drama|War
Blue Angel, The (Blaue Engel, Der) (1930) : Drama
Moscow on the Hudson (1984) : Comedy|Drama
Iris (2001) : Drama
Kandahar (Safar e Ghandehar) (2001) : Drama
Lantana (2001) : Drama|Mystery|Thriller
Brothers (Brødre) (2004) : Drama
Flightplan (2005) : Action|Drama|Thriller
Green Street Hooligans (a.k.a. Hooligans) (2005) : Crime|Drama
History of Violence, A (2005) : Action|Crime|Drama|Thriller
Oliver Twist (2005) : Drama</pre></li>			</ol>
			<p>Starting with a dataset of movies rated by users, we were able to train a model that can now provide movie<a id="_idIndexMarker1062"/> recommendations for the users in <span class="No-Break">the group.</span></p>
			<h1 id="_idParaDest-231"><a id="_idTextAnchor231"/>Summary</h1>
			<p>In this chapter, we provided a brief overview of recommender systems, different techniques used for building them, and detailed steps for training, deploying, and querying a movie recommender model on Google Cloud’s Vertex AI. Since the key objective was to showcase how you can address a real-world use case using GCP Vertex AI, we kept the core model somewhat simple. But if you are interested in doing a deeper dive into recommender solutions, you can look at courses such as <em class="italic">Recommender Systems Specialization</em> <span class="No-Break">on Coursera.</span></p>
			<p>In the next chapter, we will look into another real-world use case around building a vision-based machine learning solution to detect defects during the <span class="No-Break">manufacturing process.</span></p>
			<h1 id="_idParaDest-232"><a id="_idTextAnchor232"/>References</h1>
			<p>To learn more about the topics that were covered in this chapter, take a look at the <span class="No-Break">following resources:</span></p>
			<p><em class="italic">Collaborative Filtering for Movie </em><span class="No-Break"><em class="italic">Recommendations</em></span><span class="No-Break">: </span><a href="https://keras.io/examples/structured_data/collaborative_filtering_movielens/"><span class="No-Break">https://keras.io/examples/structured_data/collaborative_filtering_movielens/</span></a></p>
			<p><em class="italic">Get started with Vertex AI Model </em><span class="No-Break"><em class="italic">Registry</em></span><span class="No-Break">: </span><a href="https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_registry/get_started_with_model_registry.ipynb"><span class="No-Break">https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_registry/get_started_with_model_registry.ipynb</span></a></p>
		</div>
	</div>
</div>
</body></html>