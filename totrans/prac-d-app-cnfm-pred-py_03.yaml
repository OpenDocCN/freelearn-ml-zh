- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Fundamentals of Conformal Prediction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一致性预测的基础
- en: This chapter will dive into **conformal prediction**, a powerful and versatile
    probabilistic prediction framework. Conformal prediction allows for effective
    quantification of uncertainty in machine learning applications. By learning and
    utilizing conformal prediction techniques, you will be able to make more informed
    decisions and manage risks associated with data-driven solutions more effectively.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将深入探讨**一致性预测**，这是一个强大且多功能的概率预测框架。一致性预测允许在机器学习应用中有效地量化不确定性。通过学习和利用一致性预测技术，您将能够做出更明智的决策，并更有效地管理与数据驱动解决方案相关的风险。
- en: This chapter will cover the mathematical underpinnings of conformal prediction.
    You will learn how to accurately measure the uncertainty that comes with your
    predictions. You will also become familiar with nonconformity measures, grasp
    the idea of prediction sets, and be able to evaluate your model’s performance
    in a thorough and meaningful manner. The abilities you will acquire through this
    chapter will be highly valuable in various academic and industrial fields where
    comprehending the uncertainty associated with predictions is essential.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖一致性预测的数学基础。您将学习如何准确测量预测伴随的不确定性。您还将熟悉非一致性度量，掌握预测集的概念，并能够以全面和有意义的方式评估您模型的性能。通过本章，您将获得在各个学术和工业领域中非常有价值的能力，在这些领域中，理解与预测相关的不确定性是至关重要的。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Fundamentals of conformal prediction
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一致性预测的基础知识
- en: Basic components of a conformal predictor
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一致性预测的基本组件
- en: By mastering the concepts and techniques presented in this chapter, you will
    be well equipped to harness the power of conformal prediction and effectively
    apply it to your industrial applications.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 通过掌握本章中介绍的概念和技术，您将能够充分利用一致性预测的力量，并有效地将其应用于您的工业应用中。
- en: Fundamentals of conformal prediction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一致性预测的基础
- en: In this section, we will cover the fundamentals of conformal prediction. There
    are two variants of conformal prediction – **inductive conformal prediction**
    (**ICP**) and **transductive conformal prediction** (**TCP**). We will discuss
    the benefits of the conformal prediction framework and learn about the basic components
    of conformal predictors and the different types of nonconformity measures. We
    will also learn how to use nonconformity measures to create probabilistic prediction
    sets in classification tasks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖一致性预测的基础知识。一致性预测有两种变体——**归纳一致性预测**（**ICP**）和**归纳一致性预测**（**TCP**）。我们将讨论一致性预测框架的优势，了解一致性预测的基本组件和非一致性度量的不同类型。我们还将学习如何使用非一致性度量在分类任务中创建概率预测集。
- en: Definition and principles
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义和原则
- en: Conformal prediction is a machine learning framework that quantifies uncertainty
    to produce probabilistic predictions. These predictions can be prediction sets
    for classification tasks or prediction intervals for regression tasks. Conformal
    prediction has significant advantages in equipping statistical, machine learning,
    and deep learning models with valuable additional features that instill confidence
    in their predictions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性预测是一种机器学习框架，它量化不确定性以产生概率预测。这些预测可以是分类任务的预测集或回归任务的预测区间。一致性预测在为统计、机器学习和深度学习模型提供有价值附加功能方面具有显著优势，这些功能可以增强对预测的信心。
- en: Moreover, it is the only uncertainty quantification framework that offers strong
    mathematical assurances that the error rate will never surpass the significance
    level determined by the user. Simply put, conformal prediction models always generate
    valid and unbiased prediction sets and prediction intervals, which is a crucial
    aspect of making informed decisions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它还是唯一提供强大数学保证的不确定性量化框架，即错误率永远不会超过用户确定的显著性水平。简单来说，一致性预测模型总是生成有效且无偏的预测集和预测区间，这是做出明智决策的关键方面。
- en: For comprehensive resources, visit *Awesome Conformal Prediction* ([https://github.com/valeman/awesome-conformal-prediction](https://github.com/valeman/awesome-conformal-prediction)).
    It is the most extensive, professionally curated resource on conformal prediction.
    Over time, conformal prediction has developed into an extensive framework suitable
    for use with any underlying point prediction model, regardless of the size of
    the dataset, the underlying point prediction model, or the data distribution.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 想要获取全面资源，请访问 *Awesome Conformal Prediction* ([https://github.com/valeman/awesome-conformal-prediction](https://github.com/valeman/awesome-conformal-prediction))。这是关于一致预测最全面、专业整理的资源。随着时间的推移，一致预测已经发展成为一个广泛的框架，适用于与任何底层点预测模型一起使用，无论数据集的大小、底层点预测模型或数据分布如何。
- en: 'Today, the principles of conformal prediction can be expressed as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，一致预测的原则可以表达如下：
- en: '**Validity**: The objective of conformal prediction is to create **prediction
    regions** (such as **prediction** **sets** for classification tasks or **prediction
    intervals** for regression tasks) that encompass the actual target value with
    a confidence level specified by the user. The goal is to attain a coverage probability
    at least as large as the user-defined confidence level. For example, if the user
    selects a 95% confidence level, the prediction regions (sets or intervals) should
    contain the correct target values at least 95% of the time.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效性**：一致预测的目标是创建**预测区域**（例如，对于分类任务的**预测集**或对于回归任务的**预测区间**），这些区域以用户指定的置信水平包含实际的目标值。目标是达到至少与用户定义的置信水平一样大的覆盖概率。例如，如果用户选择95%的置信水平，预测区域（集或区间）应该至少在95%的时间内包含正确的目标值。'
- en: '**Efficiency**: Conformal prediction aims to generate prediction intervals
    or regions that are as small as possible while preserving the desired confidence
    level. This approach ensures the predictions are valid and precise while conveying
    useful information.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：一致预测旨在生成尽可能小的预测区间或区域，同时保持所需的置信水平。这种方法确保预测有效且精确，同时传达有用的信息。'
- en: '**Adaptivity**: Conformal prediction aims to generate prediction sets that
    are adaptive to individual examples. For examples that are hard to predict, prediction
    sets are expected to be wider to account for uncertainty in predictions.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适应性**：一致预测旨在生成对个别示例具有适应性的预测集。对于难以预测的示例，预测集预计会更宽，以考虑到预测的不确定性。'
- en: '**Distribution-free**: Conformal prediction is a versatile and robust framework
    that can be utilized with various data types and machine learning tasks since
    it does not depend on specific assumptions about the underlying data distribution.
    The only assumption made by conformal prediction is data exchangeability, which
    is a less restrictive requirement than that of **independent, identically distributed**
    (**IID**)data. Nevertheless, conformal prediction has succeeded in numerous applications
    beyond exchangeability, including time series and forecasting applications.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无分布依赖性**：一致预测是一个多才多艺且稳健的框架，可以用于各种数据类型和机器学习任务，因为它不依赖于底层数据分布的特定假设。一致预测所做的唯一假设是数据可交换性，这是一个比**独立同分布**（**IID**）数据要求更宽松的条件。尽管如此，一致预测在许多超出可交换性的应用中取得了成功，包括时间序列和预测应用。'
- en: '**Online adaptivity**: Conformal prediction can operate in both online and
    offline scenarios. In online settings, a conformal predictor can adjust to new
    incoming data points and modify its predictions accordingly without retraining
    the model.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在线适应性**：一致预测可以在在线和离线场景中运行。在在线设置中，一致预测器可以调整到新的数据点，并相应地修改其预测，而无需重新训练模型。'
- en: '**Compatibility**: Conformal prediction is a flexible framework that can be
    seamlessly integrated with various statistical and machine learning techniques,
    including decision trees, neural networks, support vector machines, boosted trees
    (XGBoost/LightGBM/CatBoost), bagging trees (random forest), and deep learning
    models. This is achieved by defining an appropriate nonconformity measure that
    can be applied to any existing machine learning algorithm.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性**：一致预测是一个灵活的框架，可以无缝集成到各种统计和机器学习技术中，包括决策树、神经网络、支持向量机、提升树（XGBoost/LightGBM/CatBoost）、袋装树（随机森林）和深度学习模型。这是通过定义一个适当的非一致性度量来实现的，该度量可以应用于任何现有的机器学习算法。'
- en: '**Non-intrusive**: Conformal prediction does not necessitate statistical, machine
    learning, or deep learning point prediction model changes. This is particularly
    important for models that have been deployed into production. Conformal prediction
    can be added as an uncertainty quantification layer on top of any deployed model
    without any modification or knowledge of how the prediction model functions.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非侵入性**: 符合预测不需要对统计、机器学习或深度学习点预测模型进行更改。这对于已经部署到生产中的模型尤为重要。符合预测可以作为不确定性量化层添加到任何已部署模型之上，无需任何修改或了解预测模型的工作方式。'
- en: '**Interpretability**: Conformal prediction produces prediction sets and intervals
    that are easy to understand and provide a clear way to measure uncertainty. This
    makes it a valuable tool for industries such as finance, healthcare, and autonomous
    vehicles, where understanding prediction uncertainty is crucial.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性**: 符合预测生成易于理解和提供明确测量不确定性的预测集和区间。这使得它成为金融、医疗保健和自动驾驶汽车等行业的有价值工具，在这些行业中，理解预测不确定性至关重要。'
- en: In the next section, we will look at the basic components of a conformal predictor
    and learn about nonconformity measures.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨符合预测器的基本组件，并了解非一致性度量。
- en: Basic components of a conformal predictor
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 符合预测器的基本组件
- en: 'We will now look at the basic components of a conformal predictor:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将探讨符合预测器的基本组件：
- en: '**Nonconformity measure**: The nonconformity measure is a function that evaluates
    how much a new data point differs from the existing data points. It compares the
    new observation to either the entire dataset (in the full transductive version
    of conformal prediction) or the calibration set (in the most popular variant –
    **ICP**. The selection of the nonconformity measure is based on a particular machine
    learning task, such as classification, regression, or time series forecasting,
    as well as the underlying model. This chapter will examine several nonconformity
    measures suitable for classification and regression tasks.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非一致性度量**: 非一致性度量是一个函数，用于评估新数据点与现有数据点之间的差异程度。它将新的观测值与整个数据集（在符合预测的完整归纳版本中）或校准集（在最受欢迎的变体——**ICP**中）进行比较。非一致性度量的选择基于特定的机器学习任务，如分类、回归或时间序列预测，以及底层模型。本章将探讨几个适合分类和回归任务的非一致性度量。'
- en: '**Calibration set**: The calibration set is a portion of the dataset used to
    calculate nonconformity scores for the known data points. These scores are a reference
    for establishing prediction intervals or regions for new test data points. The
    calibration set should be a representative sample of the entire data distribution
    and is typically randomly selected. The calibration set should contain a sufficient
    number of data points (at least 500). If the dataset is small and insufficient
    to reserve enough data for the calibration set, the user should consider other
    variants of conformal prediction – including **TCP** (see, for example, *Mastering
    Classical Transductive Conformal Prediction in Action* – [https://medium.com/@valeman/how-to-use-full-transductive-conformal-prediction-7ed54dc6b72b](https://medium.com/@valeman/how-to-use-full-transductive-conformal-prediction-7ed54dc6b72b)).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准集**: 校准集是数据集的一部分，用于计算已知数据点的非一致性得分。这些得分是建立新测试数据点的预测区间或区域时的参考。校准集应该是整个数据分布的代表样本，通常是随机选择的。校准集应包含足够数量的数据点（至少500个）。如果数据集较小，不足以保留足够的校准集数据，用户应考虑其他符合预测的变体——包括**TCP**（例如，参见*Mastering
    Classical Transductive Conformal Prediction in Action* – [https://medium.com/@valeman/how-to-use-full-transductive-conformal-prediction-7ed54dc6b72b](https://medium.com/@valeman/how-to-use-full-transductive-conformal-prediction-7ed54dc6b72b))）。'
- en: '**Test set**: The test set contains new data points for generating predictions.
    For every data point in the test set, the conformal prediction model calculates
    a nonconformity score using the nonconformity measure and compares it to the scores
    from the calibration set. Using this comparison, the conformal predictor generates
    a prediction region that includes the target value with a user-defined confidence
    level.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集**: 测试集包含用于生成预测的新数据点。对于测试集中的每一个数据点，符合预测模型使用非一致性度量来计算非一致性得分，并将其与校准集的得分进行比较。通过这种比较，符合预测器生成一个包含目标值并具有用户定义置信水平的预测区域。'
- en: All these components work in tandem to create a conformal prediction framework
    that facilitates valid and efficient uncertainty quantification in a wide range
    of machine learning tasks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些组件协同工作，创建了一个一致预测框架，该框架有助于在广泛的机器学习任务中进行有效的和高效的不确定性量化。
- en: In the previous chapter, we examined nonconformity measures, which are the fundamental
    element of any conformal prediction model. To recap, the primary role of the nonconformity
    measure is to enable the quantification of uncertainty for new data points by
    evaluating the extent to which they differ from previously observed data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了非一致性度量，这是任何一致预测模型的基本元素。为了回顾，非一致性度量的主要作用是通过评估新数据点与先前观察到的数据差异的程度，来量化新数据点的不确定性。
- en: In the conformal prediction framework, any model provides valid prediction sets
    regardless of the chosen nonconformity measure. However, selecting the proper
    nonconformity measure is essential for creating more precise, informative, and
    adaptive prediction regions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在一致预测框架中，任何模型都提供有效的预测集，无论选择的是哪种非一致性度量。然而，选择合适的非一致性度量对于创建更精确、信息丰富和自适应的预测区域至关重要。
- en: In conformal prediction, the size of these regions determines the effectiveness
    of predictive systems. Smaller regions are considered more efficient and informative.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在一致预测中，这些区域的大小决定了预测系统的有效性。较小的区域被认为是更有效和更有信息的。
- en: The effectiveness of a conformal prediction model can be influenced by the nonconformity
    measure that is chosen by the user. However, the best nonconformity measure for
    machine learning is dependent on the context.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一致预测模型的有效性可能受到用户选择的非一致性度量的影响。然而，最适合机器学习的非一致性度量取决于上下文。
- en: For further understanding, you can explore the *no free l**unch* theorem, which
    discusses the limitations of universal optimization and learning algorithms. You
    can find more information on this theorem at ([https://en.wikipedia.org/wiki/No_free_lunch_theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem
    )).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步理解，您可以探索*没有免费的午餐*定理，该定理讨论了通用优化和学习算法的限制。您可以在[https://en.wikipedia.org/wiki/No_free_lunch_theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem)上找到有关此定理的更多信息。
- en: Despite the theorem’s implications, research papers have provided valuable insights
    into selecting effective nonconformity measures. These papers have examined diverse
    datasets and offer guidance on choosing nonconformity measures that have demonstrated
    effectiveness across various scenarios. By leveraging these research findings,
    you can make informed decisions when selecting nonconformity measures for your
    specific machine learning tasks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管该定理有影响，但研究论文已经提供了关于选择有效非一致性度量的宝贵见解。这些论文检查了不同的数据集，并提供了关于选择在各种场景中已证明有效的非一致性度量的指导。通过利用这些研究成果，您可以在为特定的机器学习任务选择非一致性度量时做出明智的决定。
- en: In the research paper titled *Model-Agnostic Nonconformity Functions for Conformal
    Classification* ([https://ieeexplore.ieee.org/abstract/document/7966105](https://ieeexplore.ieee.org/abstract/document/7966105)),
    the authors examined the efficiency of three model-agnostic nonconformity measures
    for classification problems. In the experiments on 21 multi-class datasets using
    neural networks and neural network ensembles as classifiers, the authors discovered
    that the choice of the nonconformity measure substantially influenced the efficiency
    of prediction sets. These findings highlight the importance of selecting an appropriate
    nonconformity measure to enhance the efficiency of conformal prediction in classification
    problems.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在题为*Model-Agnostic Nonconformity Functions for Conformal Classification*的研究论文[https://ieeexplore.ieee.org/abstract/document/7966105](https://ieeexplore.ieee.org/abstract/document/7966105)中，作者们检查了三种模型无关的非一致性度量在分类问题中的效率。在用神经网络和神经网络集成作为分类器对21个多类数据集进行的实验中，作者们发现非一致性度量的选择对预测集的效率有显著影响。这些发现强调了选择适当非一致性度量以增强分类问题中一致预测效率的重要性。
- en: The researchers concluded that choosing the optimal nonconformity measure depends
    on the efficiency metric most suitable for the use case. When evaluating the efficiency
    in terms of the proportion of single-label predictions (singletons), the margin-based
    nonconformity measure emerged as the preferred option. On the other hand, when
    assessing the average width of prediction sets, the hinge loss measure resulted
    in the narrowest prediction sets, indicating its effectiveness in producing more
    precise and focused predictions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员得出结论，选择最佳的非一致性度量取决于最适合用例的效率指标。当从单标签预测（单例）的比例来评估效率时，基于边界的非一致性度量成为首选选项。另一方面，当评估预测集的平均宽度时，铰链损失度量产生了最窄的预测集，这表明它在产生更精确和专注的预测方面的有效性。
- en: In conformal prediction, the nonconformity measures are derived from the predictions
    generated by the underlying point prediction model. Instances more prone to misclassification
    or greater inherent uncertainty are assigned higher nonconformity scores. The
    efficiency of a conformal prediction model depends on both the accuracy of the
    underlying model and the quality of the chosen nonconformity measure. Selecting
    an appropriate nonconformity measure becomes particularly crucial when dealing
    with challenging datasets where the underlying point prediction model needs additional
    support to classify objects accurately.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在一致性预测中，非一致性度量是从底层点预测模型生成的预测中推导出来的。更容易误分类或具有更高内在不确定性的实例被分配更高的非一致性得分。一致性预测模型的效率取决于底层模型的准确性和所选非一致性度量的质量。在选择合适的非一致性度量时，尤其是在处理需要额外支持以准确分类对象的具有挑战性的数据集时，这一点变得尤为重要。
- en: Types of nonconformity measures
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非一致性度量的类型
- en: There are two types of nonconformity measures – **model-dependent** and **model-independent**
    ones.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 非一致性度量有两种类型——**模型依赖型**和**模型独立型**。
- en: Model-dependent nonconformity measures are specific to a particular type of
    underlying model used in conformal prediction. These measures rely on the internal
    workings or characteristics of the model to compute nonconformity scores. Unlike
    model-agnostic nonconformity measures, which can be applied to any type of point
    prediction model, model-dependent measures are tailored to the specific model
    used.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的非一致性度量是针对一致性预测中使用的特定类型底层模型而言的。这些度量依赖于模型的内部工作或特征来计算非一致性得分。与可以应用于任何类型点预测模型的模型无关的非一致性度量不同，模型依赖性度量是根据特定模型定制的。
- en: Model-dependent nonconformity measures take advantage of the unique features
    or properties of the underlying model to assess the deviation or uncertainty of
    a new data point from the training (in classical TCP) or calibration (in ICP)
    data. These measures can be customized based on the model’s output, such as the
    probability estimates or decision boundaries. They can also leverage model-specific
    attributes, such as the learned weights or parameters, to determine the nonconformity
    scores.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的非一致性度量利用底层模型的独特特征或属性来评估新数据点与训练数据（在经典TCP中）或校准数据（在ICP中）的偏差或不确定性。这些度量可以根据模型的输出进行定制，例如概率估计或决策边界。它们还可以利用模型特定的属性，如学习到的权重或参数，来确定非一致性得分。
- en: Examples of model-dependent nonconformity measures include the distance to support
    vectors in support vector machines, the residual error in linear regression models,
    or the discrepancy between predicted and actual class probabilities in probabilistic
    classifiers.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的非一致性度量的例子包括支持向量机中支持向量的距离、线性回归模型中的残差误差，或在概率分类器中预测类别概率与实际类别概率之间的差异。
- en: Model-dependent nonconformity measures offer the advantage of potentially capturing
    model-specific information and characteristics, leading to tailored and potentially
    more accurate uncertainty quantification. However, they are limited to the specific
    model they are designed for and may not generalize well to other models. For this
    reason, we will only cover model-independent nonconformity measures.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的非一致性度量具有潜在地捕捉模型特定信息和特性的优势，从而实现定制和可能更准确的不确定性量化。然而，它们仅限于它们设计的特定模型，并且可能无法很好地推广到其他模型。因此，我们只将涵盖模型无关的非一致性度量。
- en: In *Model-Agnostic Nonconformity Functions for Conformal Classification*, the
    authors investigated three popular loss functions – hinge loss, margin, and Brier
    score – as popular choices of model-independent nonconformity measures for predictive
    classification. Since these functions work with any classification model producing
    class estimates, they can be utilized with any classifier that generates class
    scores, making them model-agnostic.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在《适用于一致性分类的模型无关非一致性函数》一文中，作者研究了三种流行的损失函数——鸟结损失、边界和布里尔分数——作为预测分类中模型无关非一致性度量的流行选择。由于这些函数与任何产生类别估计的分类模型一起工作，因此它们可以与任何生成类别分数的分类器一起使用，这使得它们具有模型无关性。
- en: It is important to note that, in a conformal predictor, only the ordering of
    nonconformity scores matters. In two-class problems, all three loss functions
    – hinge loss, margin, and Brier score – will arrange the instances in the same
    order, resulting in the same efficiency.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，在一致性预测器中，只有非一致性得分的顺序很重要。在双类问题中，所有三个损失函数——鸟结损失、边界和布里尔分数——都将实例按相同的顺序排列，从而产生相同的效率。
- en: To compare these efficiency measures, the authors focused on multi-class problems.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较这些效率度量，作者关注了多类问题。
- en: Let’s look at the three nonconformity measures in more detail.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看三种非一致性度量。
- en: Hinge loss
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 鸟结损失
- en: The hinge loss (also sometimes called **LAC loss** or **inverse probability**)
    can be described in the context of classification problems where we obtain class
    probabilities as outputs from a model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 鸟结损失（有时也称为**LAC损失**或**逆概率**）可以在分类问题的背景下进行描述，在这种情况下，我们从模型中获得类别概率作为输出。
- en: 'For a particular instance, let’s say the true label is *y* and the predicted
    probability of the model for that label is *P(y)*. Then, the hinge loss for this
    instance is calculated as:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定的实例，假设真实标签是*y*，模型对该标签的预测概率是*P(y)*。那么，该实例的鸟结损失计算如下：
- en: Hinge loss = 1 − P(y)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 鸟结损失 = 1 − P(y)
- en: Explanation
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解释
- en: If the model is very confident and assigns a probability of 1 to the true label
    *y*, then the hinge loss is 0\. This indicates a perfect prediction.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型非常自信，并将概率1分配给真实标签*y*，那么鸟结损失为0。这表明了一个完美的预测。
- en: If the model assigns a probability of 0 to the true label *y*, then the hinge
    loss is 1\. This indicates a completely incorrect prediction.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型将0的概率分配给真实标签*y*，那么鸟结损失为1。这表明了一个完全错误的预测。
- en: For probabilities between 0 and 1, the hinge loss will range between 0 and 1,
    with higher values indicating lower confidence in the correct label and vice versa.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于介于0和1之间的概率，鸟结损失将在0和1之间变化，较高的值表示对正确标签的信心较低，反之亦然。
- en: In essence, the hinge loss gives a measure of how “off” the prediction is from
    the true label. Lower hinge loss values are better, indicating that the predicted
    probability for the true label is closer to 1\. Conversely, higher hinge loss
    values indicate greater disagreement between the predicted probability and the
    true label.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，鸟结损失给出了预测与真实标签“偏离”程度的度量。较低的鸟结损失值更好，表明预测的真实标签概率更接近1。相反，较高的鸟结损失值表示预测概率与真实标签之间的差异更大。
- en: 'To illustrate how to compute the hinge loss nonconformity score, consider a
    classifier that produces three class scores: *class_0 = 0.5*, *class_1 = 0.3*,
    and *class_2 = 0.2*,and the actual label *y =* *1*.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明如何计算鸟结损失非一致性得分，考虑一个产生三个类别分数的分类器：*class_0 = 0.5*，*class_1 = 0.3*，和*class_2
    = 0.2*，以及实际标签*y = 1*。
- en: To compute the nonconformity score, take the probability score of the true class
    (in this case, 1) and subtract it from 1\. Thus, this example’s inverse probability
    (hinge) nonconformity score is 0.7.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算非一致性得分，取真实类别的概率分数（在这种情况下，1）并从1中减去。因此，这个示例的逆概率（鸟结）非一致性得分是0.7。
- en: Margin nonconformity measure
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 边界非一致性度量
- en: 'The margin nonconformity measure is defined as the difference between the predicted
    probability of the most likely incorrect class label and the predicted probability
    of the true label:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 边界非一致性度量定义为预测的最可能错误类别标签的概率与真实标签的预测概率之间的差异：
- en: Δ[h(x i), y i] = max y≠y i   ˆ P  h(y ∣ x i) −  ˆ P  h(y i ∣ x i)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Δ[h(x i), y i] = max y≠y  i  ˆ P  h(y ∣ x i) − ˆ P  h(y i ∣ x i)
- en: Explanation
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解释
- en: The measure captures the difference in probabilities between the highest probability
    given to any incorrect label and the probability of the true label *y*i for the
    instance *x*i. For a particular instance *x*i with true label *y*i, we first identify
    the probability of the most likely incorrect class and then subtract from this
    value the probability of the true label to get the margin.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该度量捕捉了分配给任何错误标签的最高概率与实例 *x*i 的真实标签 *y*i 的概率之间的差异。对于具有真实标签 *y*i 的特定实例 *x*i，我们首先确定最可能错误的类别的概率，然后从该值中减去真实标签的概率以得到边缘。
- en: If the margin is close to zero or negative, it means that the model is confident
    in its prediction for the true class label and there isn’t another class with
    a closely competing probability. This indicates a conforming example.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果边缘值接近零或为负，这意味着模型对其对真实类别标签的预测有信心，并且没有其他类别具有接近竞争概率。这表明是一个符合规范的反例。
- en: If the margin is positive and large, it indicates that there’s another class
    (an incorrect one) for which the model assigns a higher probability than the true
    class. This is a nonconforming example, indicating that the model is more confident
    in an incorrect class than in the true one.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果边缘值是正的且较大，这表明模型为另一个类别（一个错误的类别）分配了比真实类别更高的概率。这是一个不符合规范的反例，表明模型对错误类别的信心比对真实类别的信心更大。
- en: The larger the margin, the more nonconforming the example is, as it suggests
    greater disagreement between the predicted probabilities for the true class and
    the most likely incorrect class.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘越大，反例越不符合规范，因为它表明预测的真实类别的概率与最可能错误的类别的概率之间的不一致性更大。
- en: In essence, the margin-based nonconformity measure gives an indication of how
    “risky” a prediction is. If the measure is high, it indicates potential problems
    with the model’s prediction for that instance, signaling that the prediction might
    be unreliable. If the measure is close to zero or negative, it means the model
    is more confident in its prediction of the true class.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，基于边缘的非一致性度量提供了一个关于预测“风险”的指示。如果度量值高，表明模型对该实例的预测可能存在问题，表明预测可能不可靠。如果度量值接近零或为负，这意味着模型对其对真实类别的预测更有信心。
- en: 'To illustrate how to compute the margin nonconformity score, consider a classifier
    that produces three class scores: *class_0 = 0.5*, *class_1 = 0.3*, *and class_2
    = 0.2*, and the actual label *y =* *1*.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明如何计算边缘非一致性得分，考虑一个产生三个类别得分的分类器：*class_0 = 0.5*，*class_1 = 0.3*，*class_2 =
    0.2*，以及实际标签 *y =* *1*。
- en: To calculate the margin nonconformity score, one would take the probability
    of the most likely but incorrect class (in this case, 0) and subtract it from
    the probability of the true class (1) to get a margin nonconformity score of 0.2.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算边缘非一致性得分，需要取最可能但错误的类别的概率（在这种情况下，为0）并从真实类别的概率（1）中减去，以得到0.2的边缘非一致性得分。
- en: The Brier score
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Brier得分
- en: The Brier score measures the accuracy of probability-based predictions in classification
    tasks. It calculates the squared difference between the predicted probabilities
    and the actual binary results. The score’s values can range from 0 (perfect accuracy)
    to 1 (complete inaccuracy).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Brier得分衡量分类任务中基于概率的预测的准确性。它计算预测概率与实际二元结果之间的平方差。该分数的值可以从0（完美准确性）到1（完全不准确）不等。
- en: The Brier score is an example of a **proper scoring rule** (another example
    of a proper scoring rule in classification problems is log loss).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Brier得分是**正确评分规则**的一个例子（分类问题中另一个正确的评分规则是交叉熵损失）。
- en: A proper scoring rule is a metric used to evaluate the accuracy of probabilistic
    predictions. Specifically, it’s a rule that assigns a numerical score to each
    prediction in such a way that the most accurate (or calibrated) probabilistic
    forecast will, on average, receive a better (typically lower) score than any other
    biased or less accurate forecast.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正确评分规则是一种用于评估概率预测准确性的度量。具体来说，它是一种规则，为每个预测分配一个数值分数，使得最准确（或校准）的概率预测在平均情况下将获得更好的（通常是更低的）分数，比任何其他有偏或不太准确的预测。
- en: The idea behind a proper scoring rule is to encourage honest reporting of probabilities.
    If a scoring rule is “proper,” then a forecaster has the best expected score when
    they report their true beliefs or true estimated probabilities, rather than exaggerating
    or downplaying their forecasts.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正确评分规则背后的思想是鼓励诚实地报告概率。如果一个评分规则是“正确的”，那么预报员在报告他们的真实信念或真实估计的概率时，而不是夸大或贬低他们的预测时，将获得最佳的预期分数。
- en: In essence, a proper scoring rule ensures that forecasters are best rewarded,
    in terms of the score, when they provide their genuine assessments of the probabilities
    of events.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，合适的评分规则确保预报员在提供对事件概率的真实评估时，在评分方面获得最佳回报。
- en: As a proper scoring rule, the Brier score promotes well-calibrated probability
    estimates. It uniquely captures both the calibration, which refers to the alignment
    between predicted probabilities and actual outcomes, and the discrimination, or
    the model’s ability to distinguish between the classes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种合适的评分规则，布里尔分数促进了准确度良好的概率估计。它独特地捕捉了校准，即预测概率与实际结果之间的对齐，以及区分度，即模型区分类别的能力。
- en: Glenn W. Brier, who worked in weather forecasting, invented the Brier score
    in the 1950s and described it in his paper *Verification of forecasts expressed
    in terms of probability* ([https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml](https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml)).
    Along with log loss, the Brier score is widely used today to evaluate the performance
    of probabilistic classifiers and understand the quality of predicted probabilities.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 格伦·W·布里尔（Glenn W. Brier），在气象预报领域工作，于20世纪50年代发明了布里尔分数（Brier score），并在他的论文《以概率表示的预报验证》（[https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml](https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml)）中对其进行了描述）。与对数损失一样，布里尔分数今天被广泛用于评估概率分类器的性能和理解预测概率的质量。
- en: 'To illustrate how to compute the Brier score using our example, consider the
    same classifier, which produces three class scores: *class_0 = 0.5*, *class_1
    = 0.3*, *and class_2 = 0.2*, and the actual label *y = 1*. Here’s a step-by-step
    guide to how to compute the Brier score for the given example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明如何使用我们的示例计算布里尔分数，考虑同一个分类器，它产生了三个类别得分：*class_0 = 0.5*，*class_1 = 0.3*，*和class_2
    = 0.2*，以及实际标签*y = 1*。以下是计算给定示例布里尔分数的逐步指南：
- en: '*Encode the* *actual class*:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*编码实际类别*：'
- en: 'For a multi-class problem, you’ll want to use one-hot encoding for the actual
    labels:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于多类别问题，您将希望使用one-hot编码对实际标签进行编码：
- en: '*class_0*: 0'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*class_0*: 0'
- en: '*class_1*: 1'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*class_1*: 1'
- en: '*class_2*: 0'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*class_2*: 0'
- en: '*Compute the squared differences for* *each class*:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*计算每个类别的平方差异*：'
- en: 'Calculate the squared difference between predicted probabilities and the actual
    outcomes:'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算预测概率与实际结果之间的平方差异：
- en: '*For class 0: (0-0.5)^2 =* *0.25*'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对于类别0: (0-0.5)^2 =* *0.25*'
- en: '*For class 1: (1-0.3)^2 =* *0.49*'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对于类别1: (1-0.3)^2 =* *0.49*'
- en: '*For class 2: (0-0.2)^2 =* *0.04*'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对于类别2: (0-0.2)^2 =* *0.04*'
- en: '*Average the* *squared differences*:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*平均平方差异*：'
- en: Brier score =  0.25 + 0.49 + 0.04  _____________ 3  = 0.26
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 布里尔分数 = 0.25 + 0.49 + 0.04 _______ 3 = 0.26
- en: Thus, the Brier score for this example is 0.26\. A lower Brier score indicates
    better performance, with 0 being the best possible score.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，此例的布里尔分数为0.26。较低的布里尔分数表示更好的性能，0是最佳可能分数。
- en: Effectiveness of model-agnostic nonconformity measures
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型无关非一致性度量措施的有效性
- en: 'In the paper *Model-Agnostic Nonconformity Functions for Conformal Classification*,
    the authors assessed the effectiveness of three nonconformity measures using two
    criteria: **one-class classification** (**OneC**) and *AvgC*.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文《用于一致性分类的模型无关非一致性函数》中，作者使用两个标准评估了三种非一致性措施的有效性：**单类别分类**（**OneC**）和*AvgC*。
- en: '*OneC* refers to the proportion of all predictions that consist of singleton
    sets containing only one label. These sets are desired because they provide the
    most informative predictions.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*OneC*指的是所有预测中只包含一个标签的单例集的比例。这些集是期望的，因为它们提供了最有信息的预测。'
- en: '**AvgC**, on the other hand, refers to the average number of class labels in
    the prediction set. A lower **AvgC** value indicates that the model is better
    at producing more specific and informative predictions by eliminating class labels
    that do not fit well.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**AvgC**指的是预测集中类别标签的平均数量。较低的**AvgC**值表明模型在消除不适合的类别标签后，能更好地产生更具体和有信息的预测。
- en: 'For example, consider a binary classification problem with the following predictions
    for five instances:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个二元分类问题，以下是对五个实例的预测：
- en: '*Prediction Set* *1: {0}*'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测集1: {0}*'
- en: '*Prediction Set* *2: {1}*'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测集2: {1}*'
- en: '*Prediction Set 3: {**0, 1}*'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测集3: {**0, 1}*'
- en: '*Prediction Set* *4: {1}*'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测集4: {1}*'
- en: '*Prediction Set* *5: {0}*'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测集5: {0}*'
- en: 'In this case, there are five predictions, four of which are singleton sets
    (prediction sets 1, 2, 4, and 5). To calculate **OneC**, we compute the proportion
    of singleton sets among all predictions:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，有五个预测，其中四个是单例集（预测集1、2、4和5）。为了计算**OneC**，我们计算所有预测中单例集的比例：
- en: '*OneC = (Number of Singleton Sets) / (Total Number of Prediction Sets) = (4)
    / (5) =* *0.8*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*OneC = (单例集数量) / (预测集总数) = (4) / (5) =* *0.8*'
- en: A higher **OneC** value indicates that the conformal prediction model produces
    specific and informative predictions more efficiently. In this example, 80% of
    the prediction sets are singletons, reflecting a relatively efficient classifier.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 较高的**OneC**值表明，符合预测模型更有效地产生具体和有信息的预测。在这个例子中，80%的预测集是单例集，反映了相对高效的分类器。
- en: 'To calculate **AvgC**, which represents the average number of class labels
    in the prediction set, we first compute the sum of the class labels in each prediction
    set:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算代表预测集中平均类别标签数的**AvgC**，我们首先计算每个预测集中类别标签的总和：
- en: '**Prediction Set 1**: 1 label'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测集1**：1个标签'
- en: '**Prediction Set 2**: 1 label'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测集2**：1个标签'
- en: '**Prediction Set 3**: 2 labels'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测集3**：2个标签'
- en: '**Prediction Set 4**: 1 label'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测集4**：1个标签'
- en: '**Prediction Set 5**: 1 label'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测集5**：1个标签'
- en: The sum of the class labels is 1 + 1 + 2 + 1 + 1 = 6.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 类别标签的总和是1 + 1 + 2 + 1 + 1 = 6。
- en: 'Next, we divide this sum by the total number of prediction sets:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将这个总和除以预测集的总数：
- en: '*AvgC = (Sum of Class Labels) / (Total Number of Prediction Sets) = (6) / (5)
    =* *1.2*'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*AvgC = (类别标签总和) / (预测集总数) = (6) / (5) =* *1.2*'
- en: In this example, **AvgC** is 1.2, indicating that, on average, each prediction
    set contains 1.2 class labels. A lower **AvgC** value signifies that the model
    is better at producing more specific and informative predictions. In this case,
    the **AvgC** value of 1.2 reflects a relatively efficient classifier, as it is
    close to the minimum possible value of 1, which would occur if all prediction
    sets were singleton sets.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，**AvgC**为1.2，表示平均每个预测集包含1.2个类别标签。较低的**AvgC**值表明模型在产生更具体和有信息的预测方面表现更好。在这种情况下，**AvgC**值为1.2反映了相对高效的分类器，因为它接近最小可能值1，这会在所有预测集都是单例集时发生。
- en: Researchers have determined that the most effective approach is to use a margin-based
    nonconformity function to achieve a high rate of singleton predictions (**OneC**).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员已经确定，最有效的方法是使用基于边界的非一致性函数来实现高比例的单例预测（**OneC**）。
- en: On the other hand, a nonconformity measure utilizing the hinge (inverse probability)
    nonconformity measure yielded the smallest label sets on average, as measured
    by **AvgC**.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用铰链（逆概率）非一致性度量的非一致性度量在平均**AvgC**值上产生了最小的标签集，这是通过**AvgC**来衡量的。
- en: What is the intuition behind such results?
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 这种结果背后的直觉是什么？
- en: To achieve a high **OneC** score, the predictions should predominantly be singleton
    sets that contain only one label. This means that high nonconformity scores must
    be assigned to all other labels. The margin-based nonconformity measure fosters
    this outcome, especially when the underlying model attributes a high probability
    to a single label. In this scenario, the probability associated with that single
    label is added to the nonconformity scores for all other labels, effectively promoting
    the selection of a singleton set and thereby improving the **OneC** performance.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得高的**OneC**分数，预测应该主要是包含单个标签的单例集。这意味着必须将所有其他标签分配高非一致性分数。基于边界的非一致性度量促进了这种结果，尤其是在基础模型赋予单个标签高概率的情况下。在这种情况下，与该单个标签相关的概率被添加到所有其他标签的非一致性分数中，从而有效地促进了单例集的选择，并因此提高了**OneC**性能。
- en: However, the hinge loss function, which assesses each label on an individual
    basis, might only exclude some labels, leaving the high-probability ones intact
    in certain cases. This situation arises because all other labels must have inherently
    low probabilities, and the hinge loss function does not take into account how
    the remaining probability mass is distributed specifically to the high-probability
    label. Consequently, the hinge loss function’s inability to consider this distribution
    may lead to it only eliminating some labels and not necessarily focusing on the
    high-probability ones. This difference in how the two nonconformity measures assign
    scores leads to margin-based nonconformity measures being better suited for achieving
    a high proportion of singleton predictions.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，铰链损失函数，它对每个标签进行单独评估，可能只排除一些标签，而在某些情况下保留高概率的标签。这种情况发生是因为所有其他标签必须具有固有的低概率，而铰链损失函数并没有考虑到剩余的概率质量是如何具体分配给高概率标签的。因此，铰链损失函数无法考虑这种分布可能导致它只排除一些标签，而不一定专注于高概率的标签。这两种非一致性度量分配分数的不同导致基于边界的非一致性度量更适合实现高比例的单例预测。
- en: On the other hand, to obtain smaller label sets on average as measured by **AvgC**,
    a nonconformity measure based on the hinge (inverse probability) nonconformity
    measure is more effective. This is because hinge loss considers only the probability
    of the true class label. In contrast, the margin-based nonconformity measure considers
    both the probability of the true class label and the most likely incorrect class
    label. This leads to the margin-based nonconformity measure producing broader
    sets on average, whereas hinge loss is more likely to eliminate incorrect labels
    and produce smaller, more informative sets.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，为了通过**AvgC**获得平均更小的标签集，基于铰链（逆概率）非一致性度量的非一致性度量更有效。这是因为铰链损失函数只考虑真实类标签的概率。相比之下，基于边界的非一致性度量考虑了真实类标签的概率以及最可能的错误类标签的概率。这导致基于边界的非一致性度量平均产生更宽的集合，而铰链损失函数更有可能排除错误标签，并产生更小、更有信息的集合。
- en: 'Compared to classification, regression problems are relatively straightforward
    regarding the selection of nonconformity measures:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 与分类相比，回归问题在选择非一致性度量方面相对简单：
- en: '**Absolute error**: The absolute error nonconformity measure is the absolute
    difference between the predicted value and the true target value for a given data
    point. This measure can be used with any regression model:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**绝对误差**：绝对误差非一致性度量是给定数据点的预测值与真实目标值之间的绝对差值。这个度量可以与任何回归模型一起使用：'
- en: Nonconformity (x) = |y _ pred − y _ true|
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 非一致性（x）= |y_pred - y_true|
- en: '**Normalized error**: The normalized error nonconformity measure is the absolute
    error divided by an estimate of the prediction error’s scale, such as the **mean
    absolute error** (**MAE**) or the standard deviation of the residuals. This measure
    can be used with any regression model and helps account for heteroscedasticity
    in the data:'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化误差**：归一化误差非一致性度量是绝对误差除以预测误差尺度的估计，例如**平均绝对误差**（**MAE**）或残差的方差。这个度量可以与任何回归模型一起使用，并有助于解释数据中的异方差性：'
- en: Nonconformity (x) = |y _ pred − y _ true| / scale
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 非一致性（x）= |y_pred - y_true| / scale
- en: Let’s now consider the pros and cons of both nonconformity measures in the regression
    problem.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑回归问题中这两种非一致性度量的优缺点。
- en: Absolute error
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 绝对误差
- en: 'The pros are given as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 优点如下：
- en: '**Simplicity**: It is straightforward to compute and understand, making it
    a go-to choice for many practitioners'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单性**：计算和理解都很简单，因此成为许多实践者的首选选择'
- en: '**Uniform interpretation**: Given that it is not scaled, the interpretation
    remains consistent across different datasets'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一解释**：由于它没有缩放，解释在不同数据集之间保持一致'
- en: 'The cons are given as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点如下：
- en: '**Scale sensitivity**: The absolute error can be sensitive to the scale of
    the target variable. For datasets with large target values, the absolute error
    might be large, even if the predictions are relatively accurate.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尺度敏感性**：绝对误差可能对目标变量的尺度敏感。对于具有大目标值的数据集，即使预测相对准确，绝对误差也可能很大。'
- en: '**No consideration for data distribution**: It does not consider the variability
    or distribution of errors in the dataset, which might lead to overly optimistic
    or pessimistic conformal predictions.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不考虑数据分布**：它不考虑数据集中误差的变异性或分布，这可能导致过于乐观或悲观的符合预测。'
- en: Normalized error
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 归一化误差
- en: 'The pros are given as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 优点如下：
- en: '**Scale invariance**: By normalizing the error with respect to the error’s
    scale (e.g., MAE or standard deviation of residuals), it becomes less sensitive
    to the scale of the target variable, allowing for more consistent performance
    across datasets with varying scales.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尺度不变性**：通过根据误差的尺度（例如，平均绝对误差或残差的标准差）归一化误差，它对目标变量的尺度变得不那么敏感，从而允许在具有不同尺度的数据集上实现更一致的性能。'
- en: '**Accounts for heteroscedasticity**: This measure can be particularly useful
    for data that exhibits heteroscedasticity (i.e., where the variability of errors
    changes across the data). By normalizing with a measure of spread, it can give
    a more accurate representation of the prediction’s relative accuracy.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释异方差性**：这种度量对于表现出异方差性（即误差的变异性随数据变化）的数据尤其有用。通过使用一个度量来归一化，它可以更准确地表示预测的相对准确性。'
- en: '**More adaptive**: The normalization factor can adapt to the local properties
    of the data, providing more meaningful error measurements.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更适应**：归一化因子可以适应数据的局部特性，提供更有意义的误差度量。'
- en: 'The cons are given as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点如下：
- en: '**Complexity**: It introduces an additional layer of complexity as one needs
    to determine the best way to normalize the errors. The choice of normalization
    (e.g., using MAE versus standard deviation of residuals) can influence the results.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂性**：它引入了一个额外的复杂性层，因为需要确定最佳归一化误差的方法。归一化的选择（例如，使用平均绝对误差与残差的标准差）可能会影响结果。'
- en: '**Risk of misleading results**: If the normalization factor is not well chosen
    or if it is computed from a small sample, it might lead to misleading conformal
    predictions.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误导性结果的风险**：如果归一化因子选择不当或从小的样本中计算得出，可能会导致误导性的符合预测。'
- en: '**Requires more data**: Estimating the scale of prediction error typically
    requires a sufficiently large sample size to be reliable.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**需要更多数据**：估计预测误差的尺度通常需要一个足够大的样本量才能可靠。'
- en: In the context of conformal prediction for regression, the choice between these
    measures often depends on the properties of the data and the specific needs of
    the application. If heteroscedasticity is a concern, the normalized error might
    be more appropriate. Otherwise, the simplicity of the absolute error might be
    preferred.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归的符合预测的背景下，这些度量之间的选择通常取决于数据的特性和应用的特定需求。如果存在异方差性的担忧，归一化误差可能更合适。否则，绝对误差的简单性可能更受欢迎。
- en: The second component of a conformal predictor is the **calibration set**, which
    is used to compute nonconformity scores for the known data points. The calibration
    set is a feature of the most popular variant, ICP, while TCP does not require
    a calibration set. In contrast to ICP, TCP utilizes all available data, making
    it efficient regarding data usage. However, TCP is computationally inefficient,
    requiring retraining the underlying point prediction model for each new test object.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 符合预测器的第二个组成部分是**校准集**，用于计算已知数据点的非符合度分数。校准集是最受欢迎的变体ICP的特征，而TCP不需要校准集。与ICP相比，TCP利用所有可用数据，在数据使用方面效率更高。然而，TCP在计算上效率低下，需要为每个新的测试对象重新训练底层点预测模型。
- en: We will focus on ICP, the most popular and widely used variant in current research
    and open source libraries, to better understand conformal prediction. ICP was
    introduced in a 2002 paper *Inductive Confidence Machines for* *Regression* ([https://link.springer.com/chapter/10.1007/3-540-36755-1_29](https://link.springer.com/chapter/10.1007/3-540-36755-1_29)).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关注ICP，这是当前研究和开源库中最流行和最广泛使用的变体，以更好地理解符合预测。ICP是在2002年的一篇论文中引入的，题为《用于回归的归纳置信机器》(*Inductive
    Confidence Machines for Regression*) ([https://link.springer.com/chapter/10.1007/3-540-36755-1_29](https://link.springer.com/chapter/10.1007/3-540-36755-1_29))。
- en: ICP has a significant advantage in terms of computational efficiency, as it
    is almost as fast as the underlying point prediction model. This is because ICP
    generates a single model, based on the training data, which can then be used to
    produce predictions for all test instances. Any predictive model can be combined
    with ICP to convert it into a conformal predictor.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ICP在计算效率方面具有显著优势，因为它几乎与底层点预测模型一样快。这是因为ICP基于训练数据生成单个模型，然后可以使用该模型为所有测试实例生成预测。任何预测模型都可以与ICP结合，将其转换为符合预测器。
- en: When developing an ICP, remember that the training set is exclusively for training
    the base prediction model. Do not use it to construct the conformal predictor.
    Likewise, the calibration set should be reserved solely for the conformal predictor
    and not for training the base model.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发ICP时，请记住，训练集仅用于训练基础预测模型。不要用它来构建符合预测器。同样，校准集应仅保留用于符合预测器，而不是用于训练基础模型。
- en: The main objective of conformal prediction is to provide valid prediction sets
    for new, unseen examples. The ICP approach enables the model to learn about uncertainty
    by comparing predictions made by the underlying point prediction model with the
    actual labels.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 符合预测的主要目标是为新出现的未见示例提供有效的预测集。ICP方法通过比较底层点预测模型做出的预测与实际标签，使模型能够了解不确定性。
- en: 'The ICP is constructed as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ICP的构建如下：
- en: Divide your training data into two disjoint subsets *I**T* and *I**C* where
    *T* and *C* denote the proper training and calibration sets.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的训练数据分为两个不相交的子集IT和IC，其中T和C分别表示适当的训练集和校准集。
- en: Train your point prediction model, *H*, using data exclusively from the appropriate
    proper training set, IT. As discussed in the previous chapter, H can be any point
    prediction model, including statistical, machine learning, deep learning, or even
    any model based on expert opinions, business rules, or heuristics.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用适当的训练集IT中的数据来训练您的点预测模型H。如前一章所述，H可以是任何点预测模型，包括统计模型、机器学习、深度学习，甚至是基于专家意见、业务规则或启发式方法的任何模型。
- en: Use an appropriate nonconformity measure for your classification or regression
    task to calculate nonconformity scores α1, α2, ..., αn, where *n* represents the
    total number of data points in the calibration dataset.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用适当的非一致性度量来计算分类或回归任务的非一致性得分α1, α2, ..., αn，其中n代表校准数据集中的数据点总数。
- en: Tentatively assign a label *y* as the potential label for the new test point
    *x*, and compute the nonconformity score α for (x,y).
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 暂时将标签y分配为新测试点x的潜在标签，并计算(x,y)的非一致性得分α。
- en: 'Calculate the p-value as follows:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式计算p值：
- en: 'p = |{z i : α i ≥ : α T}| + 1 _ n + 1 .'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'p = |{z i : α i ≥ : α T}| + 1 _ n + 1 .'
- en: Let’s briefly discuss this important step of calculating the p-value for each
    test data point. In previous steps, we computed the nonconformity scores for all
    points in the calibration set. We then compute the nonconformity score of a new
    test point to determine how the test point’s nonconformity score compares to those
    in the calibration set. The p-value provides a measure of how different the test
    object is from the calibration data, based on its nonconformity score. It is calculated
    by first calculating a nonconformity score for the test object using the model,
    then calculating nonconformity scores for all objects in the calibration set using
    the same model. The number of calibration objects that have a nonconformity score
    greater than or equal to the test object’s score is then counted, and 1 is added
    to this count. This count plus 1 is then divided by the total number of calibration
    objects plus 1 to determine the p-value, which indicates the proportion of calibration
    objects that are at least as extreme as the test object. The resulting p-value
    provides a quantitative metric of how nonconforming the test object is to the
    pattern in the calibration data, with a low p-value meaning the test object is
    highly unusual compared to the calibration data.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们简要讨论计算每个测试数据点的p值这一重要步骤。在前面的步骤中，我们计算了校准集中所有点的非一致性得分。然后，我们计算新测试点的非一致性得分，以确定测试点的非一致性得分与校准集中的那些得分相比如何。p值提供了一个衡量测试对象与校准数据差异的指标，基于其非一致性得分。它是通过首先使用模型计算测试对象的非一致性得分，然后使用相同的模型计算校准集中所有对象的非一致性得分来计算的。然后，计算校准对象中非一致性得分大于或等于测试对象得分的对象数量，并将1加到这个计数上。这个计数加1然后除以校准对象总数加1，以确定p值，这表明了至少与测试对象一样极端的校准对象的比例。得到的p值提供了测试对象与校准数据模式非一致性的定量指标，低p值意味着测试对象与校准数据相比非常不寻常。
- en: Conformal prediction’s core idea is to assign a tentative label y to the test
    point (a class label in classification problems or a real y value in regression
    problems) and evaluate how well the test object, including its features and assigned
    label, fits in with the observed objects from the calibration set. To measure
    this fit, we compute the p-value by comparing the test object’s “strangeness”
    using the test object’s nonconformity score to that of the calibration set objects.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 符合性预测的核心思想是为测试点分配一个暂定的标签y（在分类问题中是一个类别标签，在回归问题中是一个真实的y值）并评估测试对象（包括其特征和分配的标签）与校准集中观察到的对象如何拟合。为了衡量这种拟合，我们通过比较测试对象的“异常性”来计算p值，使用的是测试对象的非一致性得分与校准集对象的得分。
- en: It is essential to note that when calculating the p-value, the numerator and
    denominator (n+1) include the test object in the same bag, together with the calibration
    set data. Due to the exchangeability assumption, data can be shuffled, making
    all data points equivalent in terms of their order.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要的是要注意，在计算p值时，分子和分母（n+1）包括测试对象，与校准集数据一起放在同一个袋子里。由于可交换性假设，数据可以被洗牌，使得所有数据点在顺序方面都是等效的。
- en: Once we have the p-value for the test point with a tentatively assigned label,
    we compare it to the significance level. If the p-value is lower than the significance
    level, it indicates that very few, if any, objects in the calibration set are
    as strange as our test point. This suggests that the proposed label y does not
    fit, and we exclude it from the prediction set.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦我们得到了具有暂时分配标签的测试点的p值，我们就将其与显著性水平进行比较。如果p值低于显著性水平，这表明校准集中几乎没有，如果有的话，对象与我们的测试点一样异常。这表明提出的标签y不适合，我们将其排除在预测集之外。
- en: On the other hand, if the p-value is equal to or higher than the significance
    level, assigning the potential label y would not make our test object particularly
    strange, given the observed data. In this sense, we use p-values to test the statistical
    hypothesis of whether each potential y value fits previously observed data given
    the exchangeability assumption.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一方面，如果p值等于或高于显著性水平，考虑到观察到的数据，将潜在标签y分配给我们的测试对象并不会使其显得特别异常。从这个意义上讲，我们使用p值来测试在可交换性假设下，每个潜在y值是否适合之前观察到的数据。
- en: We repeat the process mentioned above for each possible value of y. As a result,
    we obtain a prediction set that includes the true label with a probability of
    1 - ε, where ε is our chosen significance level (for example, 5%).
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对y的每个可能值重复上述过程。结果，我们获得一个包含真实标签的概率为1 - ε的预测集，其中ε是我们选择的显著性水平（例如，5%）。
- en: 'We will now discuss the concepts of confidence and credibility, which help
    assess the quality of predictions:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将讨论置信度和可信度的概念，这些概念有助于评估预测的质量：
- en: '**Confidence level**: The confidence level, denoted by (1 - ε), represents
    the probability with which the true label (or value) falls within the prediction
    set. A higher confidence level indicates that the predictions are more likely
    to be accurate. The confidence level is usually chosen in advance, and common
    values are 0.95 (95%) or 0.99 (99%). With a 95% confidence level, for example,
    one can expect that the true label will be included in the prediction set 95%
    of the time.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度水平**：置信度水平，用(1 - ε)表示，代表真实标签（或值）落在预测集中的概率。更高的置信度水平表明预测更有可能是准确的。置信度水平通常提前选择，常见值是0.95（95%）或0.99（99%）。例如，以95%的置信度水平，可以预期真实标签将有95%的时间包含在预测集中。'
- en: '**Credibility level**: The credibility level, denoted by p, measures the likelihood
    of each element within the prediction set being the true label. We have discussed
    calculating p-values for each potential value of label ‘y’. In classification
    tasks, credibility levels can be interpreted as a normalized measure of confidence
    in each class label. Credibility levels help determine the most likely value(s)
    within the prediction interval for regression tasks. The credibility level can
    be used as a threshold to filter out less probable predictions, leading to a more
    precise, albeit smaller, prediction set.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可信度水平**：可信度水平，用p表示，衡量预测集中每个元素是真实标签的可能性。我们讨论了计算标签‘y’每个潜在值的p值。在分类任务中，可信度水平可以解释为对每个类别标签的置信度的归一化度量。可信度水平有助于确定回归任务预测区间内最可能的价值。可信度水平可以用作阈值来过滤掉不太可能的预测，从而得到更精确、尽管规模较小的预测集。'
- en: 'Let’s consider a binary classification problem with two possible class labels:
    *A* and *B*. We’ll use a conformal prediction framework to calculate confidence
    and credibility levels for a test data point.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个具有两个可能类别标签的二分类问题：*A*和*B*。我们将使用符合性预测框架来计算测试数据点的置信度和可信度水平。
- en: Assume we have already trained a point prediction model and calculated the nonconformity
    scores for the calibration dataset and the test point.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经训练了一个点预测模型，并计算了校准数据集和测试点的非一致性得分。
- en: 'Nonconformity scores for the calibration dataset are as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 校准数据集的非一致性得分如下：
- en: '*Point 1 (Label* *A): 0.4*'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第1点（标签*A*）：0.4*'
- en: '*Point 2 (Label* *A): 0.3*'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第2点（标签*A*）：0.3*'
- en: '*Point 3 (Label* *B): 0.2*'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第3点（标签*B*）：0.2*'
- en: '*Point 4 (Label* *B): 0.5*'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第4点（标签*B*）：0.5*'
- en: 'Nonconformity scores are calculated for a test point using the model’s predicted
    labels and probabilities. For example, if the model produces probability estimates
    of 0.75 for class A and 0.65 for class B, nonconformity scores would be computed
    as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型的预测标签和概率来计算测试点的非一致性得分。例如，如果模型为类别A产生0.75的概率估计，为类别B产生0.65的概率估计，则非一致性得分将按以下方式计算：
- en: For class A, the model assigns a probability of 0.75\. The nonconformity score
    is calculated by subtracting this probability from 1, giving 1–0.75 = 0.25.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于类别A，模型分配的概率为0.75。非一致性得分是通过从1减去这个概率来计算的，即1–0.75 = 0.25。
- en: For class B, the model assigns a probability of 0.65\. The nonconformity score
    is 1–0.65 = 0.35.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于类别B，模型分配的概率为0.65。非一致性得分为1–0.65 = 0.35。
- en: In general, the nonconformity score is 1 minus the model’s probability for the
    tentative label. This measures how much the prediction deviates from full confidence
    (a probability of 1). Higher nonconformity scores mean the model’s label assignments
    are less certain or conforming. Hinge loss is commonly used when the model outputs
    probability estimates for each class. Subtracting the probability from 1 provides
    an intuitive nonconformity measure.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，非一致性得分是1减去模型对候选标签的概率。这衡量了预测与完全置信（概率为1）的偏差程度。更高的非一致性得分意味着模型的标签分配不太确定或不一致。当模型为每个类别输出概率估计时，通常会使用Hinge损失。从1减去概率提供了一个直观的非一致性度量。
- en: 'Now, we’ll calculate p-values for each tentative label:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将为每个候选标签计算p值：
- en: '*Label A*: Count the number of calibration points with nonconformity scores
    greater than or equal to 0.25: 3 (Points 1, 2, and 4)'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*标签A*：计算非一致性得分大于或等于0.25的校准点数量：3（点1、2和4）'
- en: p−value = (3 + 1) / (4 + 1) = 4 / 5 = 0.8
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: p值 = (3 + 1) / (4 + 1) = 4 / 5 = 0.8
- en: '*Label B*: Count the number of calibration points with nonconformity scores
    greater than or equal to 0.35: 2 (Points 1 and 4)'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*标签B*：计算非一致性得分大于或等于0.35的校准点数量：2（点1和4）'
- en: p−value = (2 + 1) / (4 + 1) = 3 / 5 = 0.6
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: p值 = (2 + 1) / (4 + 1) = 3 / 5 = 0.6
- en: These p-values are the credibility levels for each label. Thus, the credibility
    of label A is 0.8, and the credibility of label B is 0.6.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这些p值是每个标签的可信度水平。因此，标签A的可信度为0.8，标签B的可信度为0.6。
- en: Our desired confidence level is 95% (1–ε = 0.95, ε = 0.05). Since both credibility
    levels (p-values) are greater than the chosen significance level ε = 0.05, we
    include both labels A and B in the prediction set.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望的置信水平是95%（1–ε = 0.95，ε = 0.05）。由于两个可信度水平（p值）都大于选择的显著性水平ε = 0.05，我们将标签A和B都包含在预测集中。
- en: In this example, the confidence level is 95%, indicating that the true label
    is included in the prediction set with a 95% probability. The credibility levels
    are 0.8 for label A and 0.6 for label B, suggesting that label A is more likely
    to be the correct label than label B.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，置信水平为95%，表示真实标签有95%的概率包含在预测集中。可信度水平为标签A的0.8和标签B的0.6，这表明标签A更有可能是正确的标签，而不是标签B。
- en: However, both labels are included in the prediction set because their credibility
    levels are higher than the significance level.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于两个标签的可信度水平都高于显著性水平，它们都被包含在预测集中。
- en: 'Online and offline conformal prediction are two variants of conformal prediction
    that differ in how they process and incorporate new data points:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在线一致性预测和离线一致性预测是两种不同的一致性预测变体，它们在处理和整合新数据点的方式上有所不同：
- en: '**Offline conformal prediction**: In offline conformal prediction, a model
    is trained on a fixed dataset, and the nonconformity scores are calculated for
    a separate calibration dataset. The model does not update or change as new data
    points become available. This method is suitable when the dataset is static or
    when you have a large amount of data available for training and calibration. The
    disadvantage of offline conformal prediction is that it doesn’t adapt to new data
    or changes in data distribution over time.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离线一致性预测**：在离线一致性预测中，模型在固定数据集上训练，并为单独的校准数据集计算非一致性得分。当新数据点可用时，模型不会更新或改变。这种方法适用于数据集静态或你有大量数据可用于训练和校准时。离线一致性预测的缺点是它不适应新的数据或数据分布随时间的变化。'
- en: '**Online conformal prediction**: In online conformal prediction, the model
    continuously updates as new data points become available. It incorporates new
    information by updating the nonconformity scores and adjusting the predictions
    accordingly. Online conformal prediction is particularly useful when working with
    streaming data or when the underlying data distribution changes over time. This
    method lets the model stay up to date with the most recent data, providing more
    accurate predictions in dynamic environments. However, online conformal prediction
    can be computationally more demanding due to the need for constant updates.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在线一致性预测**：在线一致性预测中，当新数据点可用时，模型会持续更新。它通过更新非一致性得分并相应调整预测来整合新信息。在线一致性预测在处理流数据或当潜在数据分布随时间变化时特别有用。这种方法使模型能够与最新数据保持同步，在动态环境中提供更准确的预测。然而，由于需要不断更新，在线一致性预测可能计算上要求更高。'
- en: 'Conditional and unconditional coverage are two criteria used to evaluate the
    performance of prediction intervals in forecasting models. They assess the coverage
    of the true values by the prediction intervals, but they focus on different aspects:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 条件覆盖和无条件覆盖是评估预测模型预测区间性能的两个标准。它们评估预测区间对真实值的覆盖情况，但它们关注不同的方面：
- en: '**Unconditional coverage**: Unconditional coverage assesses the proportion
    of true values that fall within the prediction intervals without considering specific
    conditions or patterns. It measures the overall ability of the prediction intervals
    to capture the true values across the entire dataset. A model with good unconditional
    coverage will include the true values within the prediction intervals for a specified
    proportion (e.g., 95%) of the time. Unconditional coverage is useful for evaluating
    the general performance of a model, but it does not account for potential dependencies
    between observations or changes in data distribution.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无条件覆盖**：无条件覆盖评估真实值落在预测区间内的比例，而不考虑特定的条件或模式。它衡量预测区间在整个数据集上捕捉真实值的能力。具有良好无条件覆盖的模型将在指定比例（例如，95%）的时间内将真实值包含在预测区间内。无条件覆盖对于评估模型的总体性能很有用，但它不考虑观察之间的潜在依赖关系或数据分布的变化。'
- en: '**Conditional coverage**: On the other hand, conditional coverage evaluates
    the performance of prediction intervals while accounting for specific conditions
    or patterns in the data. It examines how well the prediction intervals capture
    the true values when considering subsets of the data that share certain characteristics
    or dependencies (e.g., time periods, categories, etc.). A model with good conditional
    coverage will maintain the desired coverage rate for each specific condition or
    subset of the data. Conditional coverage provides a more nuanced evaluation of
    a model’s performance, helping to identify potential weaknesses or biases in the
    model’s predictions for certain data subsets.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件覆盖**：另一方面，条件覆盖在考虑数据中的特定条件或模式的同时，评估预测区间的性能。它检查预测区间在考虑具有某些特征或依赖关系（例如，时间段、类别等）的数据子集时，捕捉真实值的程度。具有良好条件覆盖的模型将保持每个特定条件或数据子集所需的覆盖率。条件覆盖为模型性能提供了一种更细致的评价，有助于识别模型对某些数据子集预测中可能存在的弱点或偏差。'
- en: In summary, unconditional coverage evaluates the overall ability of a model’s
    prediction intervals to include the true values. In contrast, conditional coverage
    assesses the performance of prediction intervals within specific conditions or
    data subsets. Both criteria are important for understanding the performance of
    forecasting models, but they focus on different aspects of a model’s predictions.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，无条件覆盖评估模型预测区间包含真实值的总体能力。相比之下，条件覆盖评估在特定条件或数据子集中预测区间的性能。这两个标准对于理解预测模型的性能都很重要，但它们关注模型预测的不同方面。
- en: 'Conformal prediction is a framework for producing reliable and valid predictions
    with quantifiable uncertainty. It can be applied to a wide range of machine learning,
    statistical, or deep learning models and other prediction methods. Here, we’ll
    discuss the relationship of conformal prediction with other frameworks:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 符合性预测是一个产生可靠和有效预测并具有可量化不确定性的框架。它可以应用于广泛的机器学习、统计或深度学习模型以及其他预测方法。在这里，我们将讨论符合性预测与其他框架的关系：
- en: '**Traditional machine learning frameworks**: Conformal prediction can be combined
    with traditional machine learning methods (e.g., linear regression, SVM, decision
    trees, etc.) to provide valid confidence or credibility measures for the predictions.
    By doing so, conformal prediction enhances these methods, giving users a better
    understanding of the uncertainty associated with each prediction.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**传统机器学习框架**：符合性预测可以与传统机器学习方法（例如，线性回归、SVM、决策树等）相结合，为预测提供有效的置信度或可信度度量。通过这样做，符合性预测增强了这些方法，使用户能够更好地理解与每个预测相关的不确定性。'
- en: '**Ensemble methods**: Ensemble methods such as bagging, boosting, and random
    forests can also benefit from conformal prediction. By adding conformal prediction
    to these methods, the ensemble can produce a point estimate and a prediction interval
    or set with associated confidence levels.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成方法**：例如，袋装、提升和随机森林等集成方法也可以从符合性预测中受益。通过将这些方法与符合性预测相结合，集成可以产生一个点估计和一个带有相关置信水平的预测区间或集合。'
- en: '**Deep learning frameworks**: Conformal prediction can be integrated with deep
    learning models, such as neural networks, to provide quantifiable uncertainty
    estimates for their predictions. This allows practitioners to better understand
    the reliability of the predictions produced by these complex models.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习框架**：一致性预测可以与深度学习模型（如神经网络）集成，为其预测提供可量化的不确定性估计。这允许从业者更好地理解这些复杂模型产生的预测的可靠性。'
- en: '**Bayesian frameworks**: Bayesian methods inherently provide uncertainty quantification
    through probability distributions. However, conformal prediction can still be
    combined with Bayesian frameworks to offer a frequentist approach to uncertainty
    quantification. This combination can provide a complementary perspective on the
    uncertainty associated with predictions.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯框架**：贝叶斯方法本质上通过概率分布提供不确定性量化。然而，一致性预测仍然可以与贝叶斯框架结合，以提供一种频率主义的不确定性量化方法。这种结合可以提供对预测相关不确定性的补充视角。'
- en: '**Model validation techniques**: Conformal prediction can be used alongside
    model validation techniques such as cross-validation or bootstrapping to assess
    the performance of a model. While these validation techniques evaluate the model’s
    accuracy and generalization, conformal prediction provides a complementary perspective
    on the model’s uncertainty quantification.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证技术**：一致性预测可以与交叉验证或自助法等模型验证技术结合使用，以评估模型的性能。虽然这些验证技术评估模型的准确性和泛化能力，但一致性预测提供了对模型不确定性量化的补充视角。'
- en: In [*Chapter 4*](B19925_04.xhtml#_idTextAnchor040), we will look into the concepts
    of validity and efficiency in the context of probabilistic prediction models,
    building upon the foundations laid in the previous chapters.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B19925_04.xhtml#_idTextAnchor040)中，我们将探讨在概率预测模型背景下有效性和效率的概念，基于前几章所奠定的基础。
- en: Summary
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have deep-dived into the fundamentals and mathematical foundations
    of conformal prediction, a powerful and versatile probabilistic prediction framework.
    We have learned about different measures of nonconformity used in classification
    and regression, building solid foundations for applying conformal prediction to
    your industry applications.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了一致性预测的基本原理和数学基础，这是一个强大且通用的概率预测框架。我们学习了在分类和回归中使用的不同非一致性度量，为将一致性预测应用于您的行业应用奠定了坚实的基础。
- en: In the next chapter, we’ll cover the concepts of validity and efficiency in
    the context of probabilistic prediction models, building upon the foundations
    laid in the previous chapters.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨在概率预测模型背景下有效性和效率的概念，基于前几章所奠定的基础。
