<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Recurrent Neural Networks</h1>
                </header>
            
            <article>
                
<p>After we reviewed the recent developments in deep learning, we are now reaching the cutting-edge of machine learning, and we are now adding a very special dimension to our model (time, and hence sequences of inputs) through a recent series of algorithms called <strong>recurrent neural networks (RNNs)</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Solving problems with order — RNNs</h1>
                </header>
            
            <article>
                
<p class="mce-root">In the previous chapters, we have examined a number of models, from simple ones to more sophisticated ones, with some common properties:</p>
<ul>
<li class="mce-root">They accept unique and isolated input</li>
<li class="mce-root">They have unique and fixed size output</li>
<li class="mce-root">The outputs will depend exclusively on the current input characteristics, without dependency on past or previous input</li>
</ul>
<p>In real life, the pieces of information that the brain processes have an inherent structure and order, and the organization and sequence of every phenomenon we perceive has an influence on how we treat them. Examples of this include speech comprehension (the order of the words in a sentence), video sequence (the order of the frames in a video), and language translation. This prompted the creation of new models. The most important ones are grouped under the RNN umbrella.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">RNN definition</h1>
                </header>
            
            <article>
                
<p>RNNs are <strong>Artificial Neural Network</strong> (<strong>ANN</strong>) models whose inputs and outputs are sequences. A more formal definition can be expressed as follows:</p>
<div class="packt_quote">"An RNN represents a sequence with a high-dimensional vector (called the hidden state) of a fixed dimensionality that incorporates new observations using a complex non-linear function."</div>
<p>RNNs are highly expressive and can implement an arbitrary memory-bounded computation, and as a result, they can be configured to achieve non-trivial performance on difficult sequence tasks. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of sequence to be modeled</h1>
                </header>
            
            <article>
                
<p>RNNs work with sequences models, both in the input and the output realm. Based on this, we can have all the possible combinations to solve different kinds of problems. In the following diagram, we illustrate the main architectures used in this field, and then a reference of the recursive ones: </p>
<div class="CDPAlignCenter CDPAlign"><img height="173" width="424" src="assets/21c36793-0b24-4644-be7f-f1d24452af93.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Type of sequences modes</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Development of RNN</h1>
                </header>
            
            <article>
                
<p>The origin of RNNs is surprisingly common to the other modern neural network architectures, dating back to Hopfield networks from the 1980s, but with counterparts in the 1970s.</p>
<p>The common structure for the first iterations of the recurrent architecture can be represented in the following way:</p>
<div class="CDPAlignCenter CDPAlign"><img height="147" width="413" src="assets/f28d6f32-e9b2-43f0-85d9-cbb5d2e8fa56.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Recurrent cell unrolling</div>
<p>Classic RNN nodes have recurrent connections to themselves, and so they can evolve their weights as the input sequence progresses. Additionally, on the right of the diagram, you can see how the network can be <em>unrolled</em> to generate a set of outputs based on the stochastic model it has saved internally. It stores representations of recent input events in the form of activation (<strong>short-term memory</strong>, as opposed to <strong>long-term memory</strong>, embodied by slowly changing weights). This is potentially significant for many applications, including speech processing, music composition (such as <em>Mozer, 1992</em>), <strong>Natural Language Processing</strong> (<strong>NLP</strong>), and many other fields.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training method — backpropagation through time</h1>
                </header>
            
            <article>
                
<p>After the considerable number of model types we've been studying, it's possible that you can already see a pattern in the implementation of the training steps.</p>
<p>For recurrent neural networks, the most well-known error minimization technique is a variation of the well-known (for us) backpropagation methods, with a simple element – <strong>backpropagation through time</strong><span> (</span><strong>BPTT</strong><span>)</span> works by unrolling all input timesteps. Each timestep has one input timestep, one copy of the whole network, and one output. Errors are calculated and accumulated for each timestep, and finally the network is rolled back up and the weights are updated.</p>
<p>Spatially, each timestep of the unrolled recurrent neural network can be seen as an additional layer, given the dependence from one timestep to another and how every timestep output is taken as an input for the subsequent timestep. This can lead to really complex training performance requirements, and thus, <strong>truncated backpropagation through time</strong> was born.</p>
<p>The following pseudocode represents the whole process:</p>
<pre>Unfold the network to contain k instances of the cell
While (error &lt; ε or iteration&gt;max):
    x = zeros(sequence_legth)
    for t in range (0, n-sequence_length)  # initialize the weights 
        copy sequence_length input values into the input x
        p = (forward-propagate the inputs over the whole unfolded network)
        e = y[t+k] - p;           # calculate error as target - prediction
        Back-propagate the error e, back across the whole unfolded network
        Sum the weight changes in the k model instances together.
            Update all the weights in f and g.
            x = f(x, a[t]);    # compute new input for the next time-step</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Main problems of the traditional RNNs — exploding and vanishing gradients</h1>
                </header>
            
            <article>
                
<p>However, RNNs have turned out to be difficult to train, especially on problems with complicated long-range temporal structures – precisely the setting where RNNs ought to be most useful. Since their potential has not been realized, methods that address the difficulty of training RNNs are of great importance.</p>
<p>The most widely used algorithms for learning what to put in short-term memory, however, take too much time or do not work well at all, especially when minimal time lags between inputs and corresponding teacher signals are long. Although theoretically fascinating, the existing methods did not provide clear practical advantages over traditional feedforward networks.</p>
<p>One of the main problems with RNNs happens in the backpropagation stage. Given its recurrent nature, the number of steps that the backpropagation of the errors has corresponds to a very deep network. This cascade of gradient calculations could lead to a very insignificant value in the last stages, or on the contrary, to ever-increasing and unbounded parameters. Those phenomena receive the names of vanishing and exploding gradients. This is one of the reasons for which LSTM was created.</p>
<p>The problem with conventional BPTT is that error signals going backwards in time tend to either blow up or vanish – the temporal evolution of the backpropagated error exponentially depends on the size of the weights. It could lead to oscillating weights, or taking a prohibitive amount of time, or it could not work at all.</p>
<p>As a consequence of many different attempts to solve the problem with vanishing and exploding gradients, finally in 1997, <em>Schmidhuber</em> and <em>Sepp</em> published a fundamental paper on RNNs, and LSTM, which paved the way for all modern developments in the area.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LSTM</h1>
                </header>
            
            <article>
                
<p><strong>LSTMs</strong> are a fundamental step in RNNs, because they introduce long-term dependencies into the cells. The unrolled cells contain two different parameter lines: one long-term status, and the other representing short-term memory.</p>
<p>Between steps, the long-term forgets less important information, and adds filtered information from short-term events, incorporating them into the future.</p>
<p>LSTMs are really versatile in their possible applications, and they are the most commonly employed recurrent models, along with GRUs, which we will explain later. Let's try to break down an LSTM into its components to get a better understanding of how they work.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The gate and multiplier operation</h1>
                </header>
            
            <article>
                
<p>LSTMs have two fundamental values: remembering important things from the present, and slowly forgetting unimportant things from the past. What kind of mechanism can we use to apply this kind of filtering? It's called the <strong>gate</strong> operation.</p>
<p><span>The gate operation basically has a multivariate vector input and a filter vector, which will be dot multiplied with the input, allowing or rejecting the elements from the inputs to be</span> transferred<span>. How do we adjust this gate's filters? This</span> multivariate control vector (marked with an arrow on the diagram) is connected with a neural network layer with a sigmoid activation function. If we apply the control vector and pass through the sigmoid function, we will get a binary-like output vector.</p>
<p>In the following diagram, the gate will be represented by a series of switches:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="119" width="214" src="assets/d40d6035-e0b8-420a-80ed-48b8095d5d64.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">LSTM gate</div>
<p>Another important part of the process is the multiplications, which formalize the trained filters, effectively multiplying the inputs by an included gate. The arrow icon indicates the direction in which the filtered information will flow:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="84" width="192" src="assets/31203714-478a-44ff-9488-df48560da1d1.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Gate multiplication step</div>
<p>Now, it's time to describe an LSTM cell in more detail.</p>
<p>An LSTM has three gates to protect and control the cell state: one at the start of the data flow, another in the middle, and the last at the end of the cell's informational boundaries. This operation will allow both discarding (hopefully not important) low-important state data and incorporating (hopefully important) new data to the state.</p>
<p>The following diagram shows all the concepts in the operation of one LSTM cell. As inputs, we have the following:</p>
<ul>
<li>
<p>The cell state, which will store long-term information, because it carries the optimized weights dating from the origin of the cell training</p>
</li>
<li>
<p>The short-term state, <em>h(t)</em>, which will be directly combined with the current input on each iteration, and so it will have a much bigger influence on the latest values of the inputs:</p>
</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="370" width="524" src="assets/4874cf1c-76ae-4cb1-95e9-3af19d8f6a7e.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Depiction of an LSTM cell, with all its components</div>
<p>Now, let's explore the data flow on this LSTM unit in order to better understand how the different gates and operations work together in a single cell.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Part 1 — set values to forget (input gate)</h1>
                </header>
            
            <article>
                
<p>In this stage, we take the values coming from the short-term memory combined with the input itself, and these values will then output a binary function, represented by a multivariable sigmoid. Depending on the input and short-term memory values, the sigmoid output will filter the long-term knowledge, represented by the weights of the cell's state:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="152" width="315" src="assets/529af80b-efe4-4d92-9612-27619fdd7734.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">State forget parameters setup</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Part 2 — set values to keep</h1>
                </header>
            
            <article>
                
<p>Now, it's time to set the filter that will allow or reject the incorporation of new and short-term memory to the cell's semi-permanent state. Then it is time to set the filter that will allow or reject the incorporation of new and short-term memory to the cell's semi-permanent state.</p>
<p>So, at this stage, we will determine how much of the new and semi-new information will be incorporated in the cell's new state:</p>
<div class="CDPAlignCenter CDPAlign"><img height="156" width="323" src="assets/71b9d57f-6861-46bf-9ce0-1a318b602600.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Short-term values selection step</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Part 3 — apply changes to cell</h1>
                </header>
            
            <article>
                
<p>In this part of the sequence, we will finally pass through the information filter we have been configuring, and as a result, we will have an updated long-term state.</p>
<p>In order to normalize the new and short-term information, we pass the new input and the short-term state via a neural network with <strong>tanh</strong> activation. This will allow us to feed the new information in a normalized <em>[-1,1]</em> range:</p>
<div class="CDPAlignCenter CDPAlign"><img height="151" width="314" src="assets/0b3418fd-359f-4ac4-b1bc-548766fb5c97.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">State changes persistence step</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Part 4 — output filtered cell state</h1>
                </header>
            
            <article>
                
<p>Now, it's the turn of the short-term state. It will also use the new and previous short-term state to set up the filter that will pass the long-term state, dot multiplied by a tanh function, again to normalize the information to incorporate a <em>(-1,1)</em> range:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="171" width="343" src="assets/4a048a2f-5c05-433d-8584-de049c86d8de.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">New short-term generation step</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Univariate time series prediction with energy consumption data</h1>
                </header>
            
            <article>
                
<p>In this example, we will be solving a problem in the domain of regression. For this reason, we will build a multi-layer RNN with two LSTMs. The type of regression we will do is of the <em>many to one</em> type, because the network will receive a sequence of energy consumption values and will try to output the next value based on the previous four registers.</p>
<p>The dataset we will be working on is a compendium of many measurements of the power consumption of one home over a period of time. As we might infer, this kind of behavior can easily follow patterns (it increases when the occupants use the microwave to prepare breakfast and use computers during the day, it decreases a bit in the afternoon, and then increases in the evening with all the lights, finally decreasing to zero when the occupants are asleep). </p>
<p>Let's start by setting the appropriate environment variables and loading the required libraries:</p>
<div class="sourceCode">
<pre><span class="op">%</span>matplotlib inline
<span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> {<span class="st">'png'</span>, <span class="st">'retina'</span>}

<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> tensorflow <span class="im">as</span> tf
<span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt

<span class="im">from</span> keras.models <span class="im">import</span> Sequential  
<span class="im">from</span> keras.layers.core <span class="im">import</span> Dense, Activation  
<span class="im">from</span> keras.layers.recurrent <span class="im">import</span> LSTM
<span class="im">from</span> keras.layers <span class="im">import</span> Dropout<br/><br/>Using TensorFlow backend.</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataset description and loading</h1>
                </header>
            
            <article>
                
<p>In this example, we will be using the <strong>Electricity Load Diagrams Data Sets</strong>, from <em>Artur Trindade</em> (<a href="https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014" target="_blank">https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014</a>). This is the description of the original dataset:</p>
<div class="packt_quote">"Data set has no missing values.<br/>
Values are in kW of each 15 min. To convert values in kWh values must be divided by 4.<br/>
Each column represent one client. Some clients were created after 2011. In these cases consumption were considered zero.<br/>
All time labels report to Portuguese hour. However all days present 96 measures (24*15). Every year in March time change day (which has only 23 hours) the values between 1:00 am and 2:00 am are zero for all points. Every year in October time change day (which has 25 hours) the values between 1:00 am and 2:00 am aggregate the consumption of two hours."</div>
<p>In order to simplify our model description, we took just one client's complete measurements and converted its format to standard CSV. It is located in the <kbd>data</kbd> subfolder of this chapter's code folder.</p>
<p>So, we will load the first 1,500 values of the consumption of a sample home from the dataset:</p>
<div class="sourceCode">
<pre class="sourceCode python">df <span class="op">=</span> pd.read_csv(<span class="st">"data/elec_load.csv"</span>, error_bad_lines<span class="op">=</span><span class="va">False</span>)
plt.subplot()
plot_test, <span class="op">=</span> plt.plot(df.values[:<span class="dv">1500</span>], label<span class="op">=</span><span class="st">'Load'</span>)
plt.legend(handles<span class="op">=</span>[plot_test])</pre></div>
<p>The following graph shows the subset of data that we need to model:</p>
<div class="figure CDPAlignCenter CDPAlign"><img height="234" width="351" src="assets/70e61ce5-14e6-4465-a264-08bd834e1a3a.png"/></div>
<p>If we take a look at this representation (we took the first 1,500 samples) we can see an initial transient state, probably when the measurements were put in place, and then we see a really clear cycle of high and low consumption levels. From simple observation, we can also see that the cycles are of more or less 100 samples, pretty close to the 96 samples per day this dataset has.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataset preprocessing</h1>
                </header>
            
            <article>
                
<p>In order to assure a better convergence of the backpropagation methods, we should try to normalize the input data. So, we will be applying the classic scale and centering technique, subtracting the mean value, and scaling by the <kbd>floor()</kbd> of the maximum value. To get the required values, we use the pandas <kbd>describe()</kbd> method:</p>
<div class="sourceCode">
<pre><span class="bu">print</span>(df.describe())
array<span class="op">=</span>(df.values <span class="op">-</span> <span class="fl">145.33</span>) <span class="op">/</span><span class="fl">338.21</span>
plt.subplot()
plot_test, <span class="op">=</span> plt.plot(array[:<span class="dv">1500</span>], label<span class="op">=</span><span class="st">'Normalized Load'</span>)
plt.legend(handles<span class="op">=</span>[plot_test])<br/><br/>                Load
count  140256.000000
mean      145.332503
std        48.477976
min         0.000000
25%       106.850998
50%       151.428571
75%       177.557604
max       338.218126</pre></div>
<p>This is the graph of our normalized data:</p>
<div class="figure CDPAlignCenter CDPAlign"><img height="178" width="276" src="assets/cbb950bc-0fcc-49ad-aaa6-b31334d715b9.png"/></div>
<p>In this step, we will prepare our input dataset, because we need an input <kbd>x</kbd> (the previous 5 values) with a corresponding input <kbd>y</kbd> (the value after 5 timesteps). Then, we will assign the first 13,000 elements to the training set, and then we will assign the following 1,000 samples to the testing set:</p>
<div class="sourceCode">
<pre class="sourceCode python">listX <span class="op">=</span> []
listy <span class="op">=</span> []
X<span class="op">=</span>{}
y<span class="op">=</span>{}

<span class="cf">for</span> i <span class="op">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(array)<span class="op">-</span><span class="dv">6</span>):
    listX.append(array[i:i<span class="dv">+5</span>].reshape([<span class="dv">5</span>,<span class="dv">1</span>]))
    listy.append(array[i<span class="dv">+6</span>])

arrayX<span class="op">=</span>np.array(listX)
arrayy<span class="op">=</span>np.array(listy)

X[<span class="st">'train'</span>]<span class="op">=</span>arrayX[<span class="dv">0</span>:<span class="dv">13000</span>]
X[<span class="st">'test'</span>]<span class="op">=</span>arrayX[<span class="dv">13000</span>:<span class="dv">14000</span>]

y[<span class="st">'train'</span>]<span class="op">=</span>arrayy[<span class="dv">0</span>:<span class="dv">13000</span>]
y[<span class="st">'test'</span>]<span class="op">=</span>arrayy[<span class="dv">13000</span>:<span class="dv">14000</span>]</pre></div>
<p>Now, we will build the model, which will be a dual LSTM with a dropout layer at the end of each:</p>
<div class="sourceCode">
<pre class="sourceCode python"><span class="co">#Build the model</span>
model <span class="op">=</span> Sequential()

model.add(LSTM( units<span class="op">=</span><span class="dv">50</span>, input_shape<span class="op">=</span>(<span class="va">None</span>, <span class="dv">1</span>), return_sequences<span class="op">=</span><span class="va">True</span>))

model.add(Dropout(<span class="fl">0.2</span>))

model.add(LSTM( units<span class="op">=</span><span class="dv">200</span>, input_shape<span class="op">=</span>(<span class="va">None</span>, <span class="dv">100</span>), return_sequences<span class="op">=</span><span class="va">False</span>))
model.add(Dropout(<span class="fl">0.2</span>))

model.add(Dense(units<span class="op">=</span><span class="dv">1</span>))
model.add(Activation(<span class="st">"linear"</span>))

model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"mse"</span>, optimizer<span class="op">=</span><span class="st">"rmsprop"</span>)  </pre></div>
<p>Now it's time to run the model and adjust the weights. The model fitter will use 8% of the dataset values as the validation set:</p>
<div class="sourceCode">
<pre><span class="co">#Fit the model to the data</span>

model.fit(X[<span class="st">'train'</span>], y[<span class="st">'train'</span>], batch_size<span class="op">=</span><span class="dv">512</span>, epochs<span class="op">=</span><span class="dv">10</span>, validation_split<span class="op">=</span><span class="fl">0.08</span>)<br/><br/>Train on 11960 samples, validate on 1040 samples
Epoch 1/10
11960/11960 [==============================] - 41s - loss: 0.0035 - val_loss: 0.0022
Epoch 2/10
11960/11960 [==============================] - 61s - loss: 0.0020 - val_loss: 0.0020
Epoch 3/10
11960/11960 [==============================] - 45s - loss: 0.0019 - val_loss: 0.0018
Epoch 4/10
11960/11960 [==============================] - 29s - loss: 0.0017 - val_loss: 0.0020
Epoch 5/10
11960/11960 [==============================] - 30s - loss: 0.0016 - val_loss: 0.0015
Epoch 6/10
11960/11960 [==============================] - 28s - loss: 0.0015 - val_loss: 0.0013
Epoch 7/10
11960/11960 [==============================] - 43s - loss: 0.0014 - val_loss: 0.0012
Epoch 8/10
11960/11960 [==============================] - 37s - loss: 0.0013 - val_loss: 0.0013
Epoch 9/10
11960/11960 [==============================] - 31s - loss: 0.0013 - val_loss: 0.0012
Epoch 10/10
11960/11960 [==============================] - 25s - loss: 0.0012 - val_loss: 0.0011



&lt;keras.callbacks.History at 0x7fa435512588&gt;</pre></div>
<p>After rescaling, it's time to see how our model predicts the values compared with the actual test values, which didn't participate in the training of the models, to understand how the model generalizes the behavior of the sample home:</p>
<div class="sourceCode">
<pre class="sourceCode python"><span class="co"># Rescale the test dataset and predicted data</span>

test_results <span class="op">=</span> model.predict( X[<span class="st">'test'</span>])

test_results <span class="op">=</span> test_results <span class="op">*</span> <span class="fl">338.21</span> <span class="op">+</span> <span class="fl">145.33</span>
y[<span class="st">'test'</span>] <span class="op">=</span> y[<span class="st">'test'</span>] <span class="op">*</span> <span class="fl">338.21</span> <span class="op">+</span> <span class="fl">145.33</span>

plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">15</span>))
plot_predicted, <span class="op">=</span> plt.plot(test_results, label<span class="op">=</span><span class="st">'predicted'</span>)

plot_test, <span class="op">=</span> plt.plot(y[<span class="st">'test'</span>]  , label<span class="op">=</span><span class="st">'test'</span>)<span class="op">;</span>
plt.legend(handles<span class="op">=</span>[plot_predicted, plot_test])<span class="op">;</span></pre></div>
<div class="CDPAlignCenter CDPAlign"><img height="460" width="703" src="assets/279595ac-742c-4790-a2de-d131878c6892.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Final regressed data</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p><span>In this chapter, our scope has expanded even more, adding the important dimension of time to the set of elements to be included in our generalization. Also, we learned how to solve a practical problem with RNNs, based on real data.</span></p>
<p>But if you think you have covered all the possible options, there are many more model types to see!</p>
<p><span>In the next chapter, we will talk about cutting edge architectures that can be trained to produce very clever elements, for example, transfer the style of famous painters to a picture, and even play video games! Keep reading for reinforcement learning and generative adversarial networks.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">References</h1>
                </header>
            
            <article>
                
<ul>
<li><span>Hopfield, John J, <em>Neural networks and physical systems with emergent collective computational abilities.</em></span> Proceedings of the national academy of sciences<span> 79.8 (1982): 2554-2558.</span></li>
<li>Bengio, Yoshua, Patrice Simard, and Paolo Frasconi, <em>Learning long-term dependencies with gradient descent is difficult.</em> IEEE transactions on neural networks 5.2 (1994): 157-166.</li>
<li><span>Hochreiter, Sepp, and Jürgen Schmidhuber, </span><em>long short-term memory</em><span>. Neural Computation 9.8 (1997): 1735-1780.</span></li>
<li>Hochreiter, Sepp.<span> </span><em>Recurrent neural net learning and vanishing gradient.</em><span> </span>International Journal Of Uncertainity, Fuzziness and Knowledge-Based Systems 6.2 (1998): 107-116.</li>
<li>Sutskever, Ilya, <em>Training recurrent neural networks.</em> University of Toronto, Toronto, Ont., Canada (2013).</li>
<li>Chung, Junyoung, et al, <em>Empirical evaluation of gated recurrent neural networks on sequence modeling.</em> arXiv preprint arXiv:1412.3555 (2014).</li>
</ul>


            </article>

            
        </section>
    </body></html>