<html><head></head><body>
		<div id="_idContainer027" class="Content">
			<h1 id="_idParaDest-75"><em class="italics"><a id="_idTextAnchor075"/>Chapter 2:</em></h1>
		</div>
		<div id="_idContainer028" class="Content">
			<h1 id="_idParaDest-76"><a id="_idTextAnchor076"/>Exploratory Analysis of Data</h1>
		</div>
		<div id="_idContainer029" class="Content">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will be able to:</p>
			<ul>
				<li class="bullets">Define a problem statement with industry standard frameworks</li>
				<li class="bullets">Perform univariate and bivariate analysis</li>
				<li class="bullets">Explain multivariate analysis</li>
				<li class="bullets">Perform hypothesis testing</li>
				<li class="bullets">Perform data wrangling using the dplyr and reshape2 packages</li>
				<li class="bullets">Visualize data using the ggplot2 package</li>
			</ul>
			<p>In this chapter, we will acquaint learners with techniques to clean, transform, and visualize data in order to get useful insights.</p>
		</div>
		<div id="_idContainer054" class="Content">
			<h2 id="_idParaDest-77"><a id="_idTextAnchor077"/>Introduction</h2>
			<p><em class="italics">Chapter 1</em>, <em class="italics">R for Advanced Analytics</em>, introduced to you the R language and its ecosystem for data science. We are now ready to enter a crucial part of data science and machine learning, that is, <strong class="bold">Exploratory Data Analysis</strong> (<strong class="bold">EDA</strong>), the art of understanding the data.</p>
			<p>In this chapter, we will approach EDA with the same banking dataset used in the previous chapter, but in a more problem-centric way. We will start by defining the problem statement with industry standard artifacts, design a solution for the problem, and learn how EDA fits in the larger problem framework. We will then tackle the EDA for the direct marketing campaigns (phone calls) of a Portuguese banking institution use case using a combination of data engineering, data wrangling, and data visualization techniques in R, backed up by a business-centric approach.</p>
			<p>In any data science use case, understanding the data consumes the bulk of the time and effort. Most data science professionals spend around 80% of their time understanding data. Given that this is the most crucial part of your journey, it is important to have a macro-view of the overall process for any data science use case.</p>
			<p>A typical data science use case takes the path of a core business-analytics problem or a machine-learning problem. With either path approached, EDA is inevitable. <em class="italics">Figure 2.1</em> demonstrates the life cycle of a basic data science use case. It starts by defining the problem statement using one or more standard frameworks, and then it delves into data gathering and reaches EDA. The majority of efforts and time in any project is consumed in EDA. Once the process of understanding the data is complete, a project may take a different path based on the scope of the use case. In most business analytics-based use cases, the next step is to assimilate all the observed patterns into meaningful insights. Though this might sound trivial, it is an iterative and arduous task. This step then evolves into story-telling, where the condensed insights are tailored into a meaningful story for the business stakeholders. Similarly, in scenarios where the objective is to develop a predictive model, the next step would be to actually develop a machine learning model and then deploy it into a production system/product.</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/C12624_02_01.jpg" alt="Figure 2.1: Life cycle of a data science use case&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.1: Life cycle of a data science use case</h6>
			<p>Let's take a brief look at the first step, <em class="italics">Defining the Problem Statement</em>.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor078"/>Defining the Problem Statement</h2>
			<p>If you recollect the data we explored in <em class="italics">Chapter 1</em>, <em class="italics">R for Advanced Analytics</em>, bank marketing data, we have a dataset that captures the telemarketing campaigns conducted by a bank to attract customers.</p>
			<p>A large multinational bank is designing a marketing campaign to achieve its growth target by enticing customers for bank deposits. The campaign has been ineffective in luring customers, and the marketing team wants to understand how the campaign can be improved to achieve the growth targets.</p>
			<p>We can reframe the problem from the business stakeholders' perspective and try to see what kind of solution would best fit here.</p>
			<h3 id="_idParaDest-79"><a id="_idTextAnchor079"/>Problem-Designing Artifacts</h3>
			<p>Just like there are several frameworks, templates, and artifacts for software engineering and other industrial projects, data science and business analytics projects can also be effectively represented using industry standard artifacts. Some popular choices are available from consulting giants such as McKinsey, BCG, and decision sciences giants such as Mu Sigma. We will use a popular framework based on the <strong class="bold">Minto Pyramid</strong> principle called <strong class="bold">Situation - Complication -Question Analysis</strong> (<strong class="bold">SCQ</strong>).</p>
			<p>Let's try defining the problem statement in the following construct:</p>
			<ul>
				<li><strong class="bold">Situation</strong>: Define the current situation. We can simplify this by answering the question—what happened?<p>A large multinational bank is designing a marketing campaign to achieve its growth target by enticing customers for bank deposits. The campaign has been ineffective in luring customers, and the marketing team wants to understand how the campaign can be improved to achieve the growth targets.</p></li>
			</ul>
			<p>In the previous section, we saw a hypothetical business problem framed for the banking data's use case. Though this might be different in reality, we are definitely trying to solve a valid use case. By representing the problem statement in the format demonstrated as in the previous format, we have a clear area to focus on and solve. This solves the first step in the life cycle of a typical data science use case. The second step is data gathering, which we explored in the previous chapter. We will refer to the same dataset provided by UCI machine learning repository at <a href="https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing">https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing</a>.</p>
			<h4>Note</h4>
			<p class="callout">[Moro et al., 2014] S. Moro, P. Cortez, and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014.</p>
			<p>This brings us to the final step: EDA. In this use case, we want to understand the various factors that are leading to the poor performance of the campaign. Before we delve into the actual exercise, let's take a moment to understand the concept of EDA in a more intuitive way.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor080"/>Understanding the Science Behind EDA</h2>
			<p>In layman's terms, we can define EDA as the science of understanding data. A more formal definition is the process of analyzing and exploring datasets to summarize its characteristics, properties, and latent relationships using statistical, visual, analytical, or a combination of techniques.</p>
			<p>To cement our understanding, let's break down the definition further. The dataset is a combination of numeric and categorical features. To study the data, we might need to explore features individually, and to study relationships, we might need to explore features together. Depending on the number of features and the type of features, we may cross paths with different types of EDA.</p>
			<p>To simplify, we can broadly classify the process of EDA as follows:</p>
			<ul>
				<li><strong class="bold">Univariate analysis</strong>: Studying a single feature</li>
				<li><strong class="bold">Bivariate analysis</strong>: Studying the relationship between two features</li>
				<li><strong class="bold">Multivariate analysis</strong>: Studying the relationship between more than two features</li>
			</ul>
			<p>For now, we will restrict the scope of the chapter to <strong class="bold">univariate</strong> and <strong class="bold">bivariate</strong> analysis. A few forms of multivariate analysis, such as regression, will be covered in the upcoming chapters.</p>
			<p>To accomplish each of the previously mentioned analyses, we can use visualization techniques such as boxplots, scatter plots, and bar charts; statistical techniques such as hypothesis testing; or simple analytical techniques such as averages, frequency counts, and so on.</p>
			<p>Breaking this further down, we have another dimension to cater to, that is, the types of features—<strong class="bold">numeric</strong> or <strong class="bold">categorical</strong>. In each of the type of analysis mentioned—<strong class="bold">univariate</strong> and <strong class="bold">bivariate</strong>—based on the type of the feature, we might have a different visual technique to accomplish the study. So, for univariate analysis of a numeric variable, we could use a histogram or a boxplot, whereas we might use a frequency bar chart for a categorical variable. We will get into the details of the overall exercise of EDA using a <em class="italics">lazy programming</em> approach, that is, we will explore the context and details of the analysis as and when it occurs in the book.</p>
			<p>With the basic background context set for the exercise, let's get ready for a specific EDA exercise.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor081"/>Exploratory Data Analysis</h2>
			<p>We will get started with the dataset available to download from UCI ML Repository at <a href="https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing">https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing</a>.</p>
			<p>Download the ZIP file and extract it to a folder in your workspace and use the file named <strong class="inline">bank-additional-full.csv</strong>. Ask the students to start a new Jupyter notebook or an IDE of their choice and load the data into memory.</p>
			<h3 id="_idParaDest-82"><a id="_idTextAnchor082"/>Exercise 18: Studying the Data Dimensions</h3>
			<p>Let's quickly ingest the data using the simple commands we explored in the previous chapter and take a look at a few essential characteristics of the dataset.</p>
			<p>We are exploring the length and breadth of the data, that is, the number of rows and columns, the names of each column, the data type of each column, and a high-level view of what is stored in each column.</p>
			<p>Perform the following steps to explore the bank dataset:</p>
			<ol>
				<li>First, import all the required libraries in RStudio:<p class="snippet">library(dplyr)</p><p class="snippet">library(ggplot2)</p><p class="snippet">library(repr)</p><p class="snippet">library(cowplot)</p></li>
				<li>Now, use the <strong class="inline">option</strong> method to set the <strong class="inline">width</strong> and <strong class="inline">height</strong> of the plot as <strong class="inline">12</strong> and <strong class="inline">4</strong>, respectively:<p class="snippet">options(repr.plot.width=12, repr.plot.height=4)</p><p>Ensure that you download and place the <strong class="inline">bank-additional-full.csv</strong> file in the appropriate folder. You can access the file from <a href="http://bit.ly/2DR4P9I">http://bit.ly/2DR4P9I</a>.</p></li>
				<li>Create a DataFrame object and read the CSV file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Now, use the following command to display the data from the dataset:<p class="snippet">str(df)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/C12624_02_02.jpg" alt="Figure 2.2: Bank data from the bank-additional-full CSV file&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.2: Bank data from the bank-additional-full CSV file</h6>
			<p>In the preceding example, we used the traditional <strong class="inline">read.csv</strong> function that's available in R to read the file into memory. We added an argument to the <strong class="inline">sep=";"</strong> function since the file is semicolon separated. The <strong class="inline">str</strong> function prints the high-level information we require about the dataset. If you carefully observe the output snippet, you can see that the first line denotes the shape of data, that is, the number of rows/observations and the number of columns/variables.</p>
			<p>The next 21 lines in the output snippet give us a sneak-peek of each variable in dataset. It displays the name of the variable, its datatype, and the first few values in the dataset. We have one line for each column. The <strong class="inline">str</strong> function practically gives us a macro-view of the entire dataset.</p>
			<p>As you can see from the dataset, we have 20 independent variables, such as <strong class="inline">age</strong>, <strong class="inline">job</strong>, and <strong class="inline">education</strong>, and one outcome/dependent variable—<strong class="inline">y</strong>. Here, the outcome variable defines whether the campaign call made to the client resulted in a successful deposit sign-up with <strong class="inline">yes</strong> or <strong class="inline">no</strong>. To understand the overall dataset, we now need to study each variable in the dataset. Let's first hop on to univariate analysis.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor083"/>Univariate Analysis</h2>
			<p><strong class="bold">Univariate analysis</strong> is the study of a single feature/variable. Here, we describe the data to help us get an overall view of how it is organized. For numeric features, such as <strong class="inline">age</strong>, <strong class="inline">duration</strong>, <strong class="inline">nr.employed</strong> (numeric features in the dataset) and many others, we look at summary statistics such as min, max, mean, standard deviation, and percentile distribution. These measures together help us understand the spread of the data. Similarly, for categorical features such as <strong class="inline">job</strong>, <strong class="inline">marital</strong>, and <strong class="inline">education</strong>, we need to study the distinct values in the feature and the frequency of these values. To accomplish this, we can implement a few analytical, visual, and statistical techniques. Let's take a look at the analytical and visual techniques for exploring numeric features.</p>
			<h3 id="_idParaDest-84"><a id="_idTextAnchor084"/>Exploring Numeric/Continuous Features</h3>
			<p>If you explored the previous output snippet, you might have noted that we have a mix of numeric and categorical features in the dataset. Let's start by looking at the first feature in the dataset, which is a numeric feature named <strong class="inline">age</strong>. As the name suggests, it denotes the age of the customer being targeted. Let's take a look at the summary statistics of the feature and visualize it using a simple boxplot.</p>
			<h3 id="_idParaDest-85"><a id="_idTextAnchor085"/>Exercise 19: Visualizing Data Using a Box Plot</h3>
			<p>In this exercise, we will explore using a boxplot for univariate analysis, explain how to interpret the boxplot, and walk through the code.</p>
			<p>Perform the following steps to visualize the data using a boxplot:</p>
			<ol>
				<li value="1">First, import the ggplot2 package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Print the <strong class="inline">age</strong> data, such as <strong class="inline">mean</strong> and <strong class="inline">max</strong>, using the following command:<p class="snippet">print(summary(df$age))</p><p>The output is as follows:</p><p class="snippet">Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p><p class="snippet">17.00   32.00   38.00   40.02   47.00   98.00</p></li>
				<li>Next, print the standard deviation of age as follows:<p class="snippet">print(paste("Std.Dev:",round(sd(df$age),2)))</p><p>The output is as follows:</p><p class="snippet">[1] "Std.Dev: 10.42"</p></li>
				<li>Now, plot the boxplot using of age with following parameters:<p class="snippet">ggplot(data=df,aes(y=age)) + geom_boxplot(outlier.colour="black")</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/C12624_02_03.jpg" alt="Figure 2.3: Boxplot of age.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.3: Boxplot of age.</h6>
			<p>We first load the <strong class="inline">ggplot2</strong> library, which provides handy functions for visualizing the data. R provides a simple function called <strong class="inline">summary</strong>, which prints summary statistics such as min, max, median, mean, 75th percentile, and 25th percentile values. The next line uses the <strong class="inline">sd</strong> function to compute the standard deviation, and, lastly, the final line uses the <strong class="inline">ggplot</strong> library to plot the boxplot for the data.</p>
			<p>If you explore the variable with the output from the summary statistics, we can see that age has a minimum value of 17, a max of 98, and a mean of 42. If you take a close look at the gap between the 75th percentile (3rd quartile) and the 100th percentile (max), we can see a huge jump. This indicates that there are outliers present in the age variable. The presence of outliers will incorrectly change your conclusions from the analysis. In some cases, when there is just one data point with a value of <strong class="inline">1000x</strong> the 75th percentile, your mean will shift toward the right. In scenarios where you would use just mean as a ballpark figure to give an estimate of the variable, the whole understanding of the feature might be misleading.</p>
			<p>The boxplot, on the other hand, helps us visually consume this information in a simple and lucid way. The boxplot splits the data into three quartiles. The lower quartile, that is, the line below the box, represents the min and the 25th percentile. The middle quartile represents the 25th to 50th to 75th percentile. The upper quartile represents the 75th to the 100th percentile. The dots above the 100th percentile are outliers determined by the internal functions. As we can see, the observation from the summary statistics are in line with the boxplots. We do see outliers, marked as dots above the upper quartile.</p>
			<p>In the next exercise, we will perform an EDA on the age variable using a histogram. Let's see what insight we can get from the histogram plot.</p>
			<h3 id="_idParaDest-86"><a id="_idTextAnchor086"/>Exercise 20: Visualizing Data Using a Histogram</h3>
			<p>In this exercise, we will discuss how to interpret the histogram and outliers. Let's continue from the previous exercise.</p>
			<p>In order to get a more detailed view of the data and closely understand how the <strong class="inline">age</strong> variable is organized, we can use histograms. A histogram is a special bar plot, where the data is grouped and sequentially arranged into equal intervals called <strong class="inline">bins</strong>, and the frequency of data points in the respective bins are plotted. The histogram helps us to understand the distribution of the data more effectively. The exercise plots the histogram to help us visualize the data more effectively.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">First, import the ggplot2 package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Now, use the following command to plot the histogram for age using the provided parameters:<p class="snippet">ggplot(data=df,aes(x=age)) + </p><p class="snippet">       geom_histogram(bins=10,fill="blue", color="black", alpha =0.5)  + </p><p class="snippet">       ggtitle("Histogram for Age") + </p><p class="snippet">       theme_bw()  </p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/C12624_02_04.jpg" alt="Figure 2.4: Histogram for age&#13;&#10; &#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.4: Histogram for age</h6>
			<p>The <strong class="inline">ggplot</strong> function defines the base layer for visualization, which is then followed by the <strong class="inline">geom_histogram</strong> function with parameters that define the histogram-related aspects such as the number of bins, color to fill, alpha (opacity), and many more. The number of bins is also calculated by default, but it can be overridden by passing a value to the <strong class="inline">bin</strong> parameter, such as <strong class="inline">bin=10</strong>. The next function, <strong class="inline">ggtitle</strong>, is used to add a title to the plot, and the <strong class="inline">theme_bw</strong> function is added to change the theme to black and white instead of the default. The <strong class="inline">theme</strong> function is optional and is added here for only visually appealing plots.</p>
			<p>As you can clearly see, the histogram gives us a more granular view of the data distribution for the feature. We can understand that the number of records drastically reduce after 65 and only a few records have values beyond 75. In some cases, choosing the number of bins for the histogram becomes important as higher number of bins make the distribution messy and a smaller number of bins make the distribution less informative. In scenarios where we would want to see a much more granular view of the distribution, instead of increasing the number of bins for the histogram, we can opt for visualizing using a density plot that visualizes the plot over a continuous interval while using kernel smoothing to smooth out the noise.</p>
			<p>We can also visualize the age variable using a density plot rather a histogram. The next exercise goes into the details of how to do it.</p>
			<h3 id="_idParaDest-87"><a id="_idTextAnchor087"/>Exercise 21: Visualizing Data Using a Density Plot</h3>
			<p>In this exercise, we will demonstrate the density plot for the same feature, <strong class="inline">age</strong>.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">First, import the ggplot2 package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Now, use the following command to plot the density plot for age:<p class="snippet">ggplot(data=df,aes(x=age)) + geom_density(fill="red",alpha =0.5) + </p><p class="snippet">                             ggtitle("Density Plot for Age") + </p><p class="snippet">                             theme_bw()</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/C12624_02_05.jpg" alt="Figure 2.5: Density plot for age.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.5: Density plot for age.</h6>
			<p>Similar to the previous exercise, we use the same base for the visualization with the <strong class="inline">ggplot</strong> function and use a different <strong class="inline">geom_density</strong> function for the density plot. The rest of the additional functions used for the visualization remain the same.</p>
			<p>Density plots give finer details than a histogram. While this level of detail can also be achieved using higher number of bins for a histogram, there is often a hit and try method required to get the best number of bins. In such cases, an easier option to opt for would be density plots.</p>
			<p>Now that we have understood the idea of univariate analysis for numeric variables, let's speed up the data exploration for other variables. We have a total of 10 categorical features and 10 numeric columns. Let's try to take a look at four numeric variables together using a histogram.</p>
			<p>Just like we plotted the histogram for age, we can do it for multiple variables at the same time by defining a custom function. The next exercise shows how to do this.</p>
			<h3 id="_idParaDest-88"><a id="_idTextAnchor088"/>Exercise 22: Visualizing Multiple Variables Using a Histogram</h3>
			<p>In this exercise, we will combine the four histograms, one for each of the variables of interest, into a single plot. We have <strong class="inline">campaign</strong>, which indicates the number of contacts performed during the campaign, and <strong class="inline">pdays</strong>, which indicates the number of days since the client was last contacted by the previous campaign; a value of 999 indicates that the client was never contacted before. <strong class="inline">previous</strong> indicates the number of contacts previously made for this client, and lastly, <strong class="inline">emp.var.rate</strong> indicates the employment variance rate.</p>
			<p>Let's perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">cowplot</strong> package using the following command:<p class="snippet">library(cowplot)</p><p>Ensure that the <strong class="inline">cowplot</strong> package is installed.</p></li>
				<li>Next, define a function to plot histograms for all numeric columns:<p class="snippet">plot_grid_numeric &lt;- function(df,list_of_variables,ncols=2){</p><p class="snippet">    plt_matrix&lt;-list()</p><p class="snippet">    i&lt;-1</p><p class="snippet">    for(column in list_of_variables){</p><p class="snippet">        plt_matrix[[i]]&lt;-ggplot(data=df,aes_string(x=column)) + </p><p class="snippet">            geom_histogram(binwidth=2,fill="blue", color="black", </p><p class="snippet">                           alpha =0.5)  +</p><p class="snippet">            ggtitle(paste("Histogram for variable: ",column)) + theme_bw()</p><p class="snippet">            i&lt;-i+1</p><p class="snippet">            }</p><p class="snippet">    plot_grid(plotlist=plt_matrix,ncol=2)</p><p class="snippet">}</p></li>
				<li>Now, use the <strong class="inline">summary</strong> function to print the mean, max, and other parameters for the <strong class="inline">campaign</strong>, <strong class="inline">pdays</strong>, <strong class="inline">previous</strong>, and <strong class="inline">emp.var.rate</strong> columns:<p class="snippet">summary(df[,c("campaign","pdays","previous","emp.var.rate")])</p><p>The output is as follows:</p><p class="snippet">   campaign          pdays          previous      emp.var.rate     </p><p class="snippet">Min.   : 1.000   Min.   :  0.0   Min.   :0.000   Min.   :-3.40000  </p><p class="snippet">1st Qu.: 1.000   1st Qu.:999.0   1st Qu.:0.000   1st Qu.:-1.80000  </p><p class="snippet">Median : 2.000   Median :999.0   Median :0.000   Median : 1.10000  </p><p class="snippet">Mean   : 2.568   Mean   :962.5   Mean   :0.173   Mean   : 0.08189  </p><p class="snippet">3rd Qu.: 3.000   3rd Qu.:999.0   3rd Qu.:0.000   3rd Qu.: 1.40000  </p><p class="snippet">Max.   :56.000   Max.   :999.0   Max.   :7.000   Max.   : 1.40000</p></li>
				<li>Call the function we defined earlier to plot the histogram:<p class="snippet">plot_grid_numeric(df,c("campaign","pdays","previous","emp.var.rate"),2)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="image/C12624_02_06.jpg" alt="Figure 2.6: Visualizing multiple variables using a histogram&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.6: Visualizing multiple variables using a histogram</h6>
			<p>In this exercise, we automated the process of stacking multiple plots of the same kind into a consolidated plot. We first load the required <strong class="inline">cowplot</strong> library. This library provides handy functions for creating a plot grid for plots rendered by the <strong class="inline">ggplot</strong> library. If you do not have the library loaded, install the packages using the <strong class="inline">install.packages('cowplot')</strong> command. We then define a function called <strong class="inline">plot_grid_numeric</strong>, which accepts the parameters dataset, a list of features to plot, and the number of columns to be used in the grid. If you observe the internals of the function, you will see that we simply traverse through the list of provided variables using a <strong class="inline">for</strong> loop and collect the individual plots into a list called <strong class="inline">plt_matrix</strong>. Later, we use the <strong class="inline">plot_grid</strong> function provided by the <strong class="inline">cowplot</strong> library to arrange the plots into a grid with two columns. </p>
			<p>The same function can be used to display a grid of any number of histograms; use a number based on your screen size. The current number has been restricted to 4 for best results. We also use the <strong class="inline">summary</strong> function to display the overall statistics for the same set of numeric variables in conjunction with the histogram plots.</p>
			<h4>Note</h4>
			<p class="callout">There is no exception handling code used in the previous function. We have ignored implementing sophisticated code for now in order to focus on the topic of interest. In the event of using the function for non-numeric variables, the error messages will not be the most effective to solve it.</p>
			<p>As we can see in the previous plot, we now have four variables together for analysis. Studying the summary statistics in tandem with the histogram plots helps us uncover the underlying variable better. <strong class="inline">Campaign</strong> has 75% of the values below or equal to 3. We can see that there is an outlier at 56, but a significant majority of the records have values less than 5. <strong class="inline">pdays</strong> seems to not be a useful variable for our analysis as almost all records have the default value of 999. The tall bar in 1000 makes it clear that barely any records will have values other than 999.</p>
			<p>For the <strong class="inline">previous</strong> variable, we see the exact opposite of <strong class="inline">pdays</strong>; most records have a value of 0. Lastly, <strong class="inline">emp.var.rate</strong> shows us an interesting result. Though the values range from <strong class="inline">-4</strong> to <strong class="inline">2</strong>, more than half of the records have a positive value.</p>
			<p>So, with the analysis of these four variables, we can roughly conclude that the previously conducted campaigns didn't communicate very often by phone with the clients, or it could also mean that close to none of the clients targeted in the previous campaign were contacted for the current campaign. Also, the ones who were contacted earlier were contacted seven times at most. The number of days since the client was last contacted naturally is in sync with the results from the previous campaign, because hardly any have been contacted earlier. However, for the current campaign, clients have been contacted an average of 2.5 times, 75% of the clients have been contacted up to 3 times, and some clients have been contacted as high as 56 times. The employment variance rate is an indicator of how many people are hired or fired due to macro-economic situations. We understand that the economic situation has been fairly steady for most of the time during the campaigns.</p>
			<p>Similar to the function created in the previous section to stack histograms together, in this activity, we will create another function to stack density plots and another for boxplots.</p>
			<h3 id="_idParaDest-89"><a id="_idTextAnchor089"/>Activity 4: Plotting Multiple Density Plots and Boxplots</h3>
			<p>In this activity, we will create a function to stack density plots, and another for boxplots. Use the newly created functions to visualize the same set of variables as in the previous section and study the most effective way to analyze numeric variables.</p>
			<p>By end of this activity, you will learn how to plot multiple variables in density plot at the same time. Doing so makes it easy to compare the different variables in one go and draw insights about the data.</p>
			<p>Perform the following steps to complete this activity:</p>
			<ol>
				<li value="1">First, load the necessary libraries and packages in RStudio.</li>
				<li>Read the <strong class="inline">bank-additional-full.csv</strong> dataset into a DataFrame named <strong class="inline">df</strong>.</li>
				<li>Define the <strong class="inline">plot_grid_numeric</strong> function for the density plot:<p class="snippet">plot_grid_numeric &lt;- function(df,list_of_variables,ncols=2){</p><p class="snippet">  plt_matrix&lt;-list()</p><p class="snippet">  i&lt;-1</p><p class="snippet">  }</p><p class="snippet">  plot_grid(plotlist=plt_matrix,ncol=2)</p><p class="snippet">}</p></li>
				<li>Plot the density plot for the <strong class="inline">campaign</strong>, <strong class="inline">pdays</strong>, <strong class="inline">previous</strong>, and <strong class="inline">emp.var.rate</strong> variables:<div id="_idContainer036" class="IMG---Figure"><img src="image/C12624_02_07.jpg" alt="Figure 2.7: Density plots for the campaign, pdays, previous, and emp.var.rate variables&#13;&#10;"/></div><h6>Figure 2.7: Density plots for the campaign, pdays, previous, and emp.var.rate variables</h6><p>Observe that the interpretations we obtained using the histogram are visibly true in the density plot as well. Hence, this serves as another alternative plot for looking at the same trend.</p></li>
				<li>Repeat the steps for the boxplot:<p class="snippet">plot_grid_numeric &lt;- function(df,list_of_variables,ncols=2){</p><p class="snippet">  plt_matrix&lt;-list()</p><p class="snippet">  i&lt;-1</p><p class="snippet">}</p><p class="snippet">plot_grid_numeric(df,c("campaign","pdays","previous","emp.var.rate"),2)</p><p>The plot is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer037" class="IMG---Figure">
					<img src="image/C12624_02_08.jpg" alt="Figure 2.8: Boxplots for the campaign, pdays, previous, and emp.var.rate variables&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.8: Boxplots for the campaign, pdays, previous, and emp.var.rate variables</h6>
			<p>An additional point to note in the boxplot is that it shows the clear presence of outliers in the <strong class="inline">campaign</strong> variable, which wasn't very visible in the other two plots. A similar observation could be made for <strong class="inline">previous</strong> and <strong class="inline">pdays</strong> variables as well. Students should try to plot boxplots after removing the outliers and see how different they look then.</p>
			<h4>Note</h4>
			<p class="callout">You can find the solution for this activity on page 442.</p>
			<h3 id="_idParaDest-90"><a id="_idTextAnchor090"/>Exercise 23: Plotting a Histogram for the nr.employed, euribor3m, cons.conf.idx, and duration Variables</h3>
			<p>In this exercise, we will move to the next and the last set of four numeric variables. We have <strong class="inline">nr.employed</strong>, which indicates the number of employees employed at the bank, and <strong class="inline">euribor3m</strong>, which indicates the 3-month euro interbank rates for average interest rates. Also, we have <strong class="inline">cons.conf.index</strong>, which is the consumer confidence indicator measured as the degree of optimism on the state by consumers by expressing through the activities of savings and spending. Lastly, there is <strong class="inline">duration</strong>, which indicates the last contact duration. As per the metadata provided by UCI, this variable is highly correlated with the outcome and will lead to possible data leakage. Therefore, we will drop this variable from our future analysis.</p>
			<p>Perform the following steps to study the next set of numeric variables:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">cowplot</strong> package using the following command:<p class="snippet">library(cowplot)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Print the details using the <strong class="inline">summary</strong> method:<p class="snippet">summary(df[,c("nr.employed","euribor3m","cons.conf.idx","duration")])</p><p>The output is as follows:</p><p class="snippet"> nr.employed     euribor3m     cons.conf.idx      duration     </p><p class="snippet">Min.   :4964   Min.   :0.634   Min.   :-50.8   Min.   :   0.0  </p><p class="snippet">1st Qu.:5099   1st Qu.:1.344   1st Qu.:-42.7   1st Qu.: 102.0  </p><p class="snippet">Median :5191   Median :4.857   Median :-41.8   Median : 180.0  </p><p class="snippet">Mean   :5167   Mean   :3.621   Mean   :-40.5   Mean   : 258.3  </p><p class="snippet">3rd Qu.:5228   3rd Qu.:4.961   3rd Qu.:-36.4   3rd Qu.: 319.0  </p><p class="snippet">Max.   :5228   Max.   :5.045   Max.   :-26.9   Max.   :4918.0</p></li>
				<li>Plot the histogram for the defined variables, as illustrated in the following command:<p class="snippet">plot_grid_numeric(df,c("nr.employed","euribor3m","cons.conf.idx","duration"),2)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/C12624_02_09.jpg" alt="Figure 2.9: Histogram of count and duration for various variables&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.9: Histogram of count and duration for various variables</h6>
			<p>Just like <em class="italics">Exercise 5</em>, <em class="italics">Visualizing Multiple Variables Using a Histogram</em>, we first perform the summary statistics on our desired set of variables with the <strong class="inline">summary</strong> function, and then plot the combined histogram for all the desired variables together by calling the same functions we defined earlier.</p>
			<p>As we can see, the number of employees employed has been mostly constant at <strong class="inline">5228</strong>, but it has also decreased during the time period to different values. This number is measured quarterly, and hence the frequency is not very dynamic, which is why we can see values centered around only a few bins. The euro interbank interest rate has been mostly between <strong class="inline">2.5</strong> and <strong class="inline">5</strong>. There are just 1 or 2 records that have values above 5, and we can see that the max value measured for this variable is <strong class="inline">5.045</strong>. The consumer confidence index is mostly negative, which means that the consumers mostly perceived the state of the economy negatively during this time. We see two peaks in the bins of the histogram, which calls for the most common confidence index during the time and vaguely suggests limited variation in the index during the length of the campaign. The duration of the call, in seconds, shall be ignored from our analysis for now.</p>
			<p>To summarize, we understand that the bank's number of employees increased and decreased during the campaigns in a range of ~250, which is ~5% of the total employees. It ranged between <strong class="inline">4964</strong> and <strong class="inline">5228</strong> and mostly had little variation. The consumer confidence index remained mostly negative and with little variation during the time period, and the euro interbank rates had an average of 3.6, with most of the records between 2.5 and 5.</p>
			<p>Now, let's move on to study the categorical variables using univariate analysis.</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor091"/>Exploring Categorical Features</h2>
			<p>Categorical features differ from numeric or continuous features in nature, and therefore the traditional methods used earlier aren't applicable here. We can analyze the number of different classes within a categorical variable and the frequency associated with each. This can be achieved using either simple analytical techniques or visual techniques. Let's explore a list of categorical features using a combination of both.</p>
			<h3 id="_idParaDest-92"><a id="_idTextAnchor092"/>Exercise 24: Exploring Categorical Features</h3>
			<p>In this exercise, we will start with a simple variable, that is, <strong class="inline">marital</strong>, which indicates the marital status of the client. Let's use the <strong class="inline">dplyr</strong> library to perform grouped data aggregation.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">dplyr</strong> library in the system using the following command:<p class="snippet">library(dplyr)</p></li>
				<li>Next, we will create an object named <strong class="inline">marital_distribution</strong> and store the value based on the following condition:<p class="snippet">marital_distribution &lt;- df %&gt;% group_by(marital) %&gt;% </p><p class="snippet">                               summarize(Count = n()) %&gt;% </p><p class="snippet">                               mutate(Perc.Count = round(Count/sum(Count)*100))</p></li>
				<li>Now, print the value stored in the <strong class="inline">marital_distribution</strong> object:<p class="snippet">print(marital_distribution)</p><p>The output is as follows:</p><p class="snippet"># A tibble: 4 x 3</p><p class="snippet">  marital  Count Perc.Count</p><p class="snippet">  &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt;</p><p class="snippet">1 divorced  4612         11</p><p class="snippet">2 married  24928         61</p><p class="snippet">3 single   11568         28</p><p class="snippet">4 unknown     80          0</p></li>
			</ol>
			<p>To count the distinct number of classes within the categorical column and to get the count of records within each of the individual classes, we use the <strong class="inline">group_by</strong> functions available under the <strong class="inline">dplyr</strong> library. The <strong class="inline">%&gt;%</strong>, also called the <strong class="bold">concatenation command</strong>, is analogous to the Linux piped operations. It extracts output from the left of the operator, passes on to the right of the operator, and concatenates the entire series of operations. Here, we first group the DataFrame by the variable of our interest, that is, <strong class="inline">marital</strong> and then pass the output to the <strong class="inline">summarize</strong> function, which aggregates the DataFrame to the grouped level using the aggregation function we provide; in this case, <strong class="inline">n()</strong> is a simple <strong class="inline">count</strong> equivalent. Finally, we use the <strong class="inline">mutate</strong> function to calculate the percentage of counts for each of the individual group members.</p>
			<p>We see that majority of the campaign calls were made to married clients, around 61%, followed by calls to single clients at 28% and so on.</p>
			<h3 id="_idParaDest-93"><a id="_idTextAnchor093"/>Exercise 25: Exploring Categorical Features Using a Bar Chart</h3>
			<p>In this exercise, we will plot a bar chart with the frequency counts for each class visualized. We could also use the bar chart to represent the frequency distribution of each of these individual categories with a plot.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">ggplot2</strong> package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Now, plot the bar chart of marital status per count using the following command:<p class="snippet">ggplot(data = marital_distribution,aes(x=marital,y=Perc.Count)) + </p><p class="snippet">              geom_bar(stat="identity",fill="blue",alpha=0.6) + </p><p class="snippet">              geom_text(aes(label=marital_distribution$Perc.Count, vjust = -0.3))</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/C12624_02_10.jpg" alt="Figure 2.10: Bar chart of marital status per count&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.10: Bar chart of marital status per count</h6>
			<p>We use the same dataset engineered in the previous snippet, which calculates the frequency of each class and its relative percentage. To plot the bar chart, we use the same base function of <strong class="inline">ggplot</strong>, where we define the aesthetics of the <em class="italics">x</em> and <em class="italics">y</em> variables and append the bar plot using the <strong class="inline">geom_bar</strong> function. The <strong class="inline">geom_text</strong> function allows us to add labels to each bar in the plot.</p>
			<p>We can now see the same numbers displayed in the previous exercise visualized here with a bar plot. In scenarios where we have a large number of classes within the variable, glancing through each individual class to study them might not be the most effective method. A simple plot easily helps us to understand the frequency distribution of the categorical variable in an easy-to-consume way.</p>
			<h3 id="_idParaDest-94"><a id="_idTextAnchor094"/>Exercise 26: Exploring Categorical Features using Pie Chart</h3>
			<p>In this exercise, we will define the pie chart and the various components within it.</p>
			<p>Similar to the bar plot, we also have a pie chart that makes understanding the percentage distribution of the classes easier. Perform the following steps to visualize the same variable, that is, marital status using a pie chart:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">ggplot2</strong> package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Next, define the label positions using the following command:<p class="snippet">plot_breaks = 100 - (cumsum(marital_distribution$Perc.Count) - </p><p class="snippet">                   marital_distribution$Perc.Count/2)</p></li>
				<li>Now, define labels for the plots:<p class="snippet">plot_labels = paste0(marital_distribution$marital,"-",marital_distribution$Perc.Count,"%")</p></li>
				<li>Set the plot size for better visuals:<p class="snippet">options(repr.plot.width=12, repr.plot.height=8)</p></li>
				<li>Create the pie chart using the following command:<p class="snippet">ggplot(data = marital_distribution,aes(x=1,y=Perc.Count, fill=marital)) + </p><p class="snippet">              geom_bar(stat="identity") + #Creates the base bar visual</p><p class="snippet">              coord_polar(theta ="y")  + #Creates the pie chart</p><p class="snippet">              scale_y_continuous(breaks=plot_breaks, labels = plot_labels,position = "left") + </p><p class="snippet">              theme(axis.text.x = element_text(angle = 30, hjust =1)) + #rotates the labels</p><p class="snippet">              theme(text = element_text(size=15)) + #increases the font size for the legend</p><p class="snippet">              ggtitle("Percentage Distribution of Marital Status") #Adds the plot title</p></li>
			</ol>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="image/C12624_02_11.jpg" alt="Figure 2.11: Pie chart for the percentage distribution for the marital status&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.11: Pie chart for the percentage distribution for the marital status</h6>
			<p>We first define a few extra variables that will help us to get the plot in an easier way. In order to label the pie chart, we would need the break points and the actual labels. The break point should ideally be located in the middle part of the pie piece. So, we take a cumulative sum of the percentage distribution and subtract half of each category to find the mid-point of the section. We then subtract the entire number from 100 to arrange the labels in a clockwise direction.</p>
			<p>The next step defines the label for each pie piece; we use the <strong class="inline">paste</strong> function to concatenate the label name and the actual percentage values. The pie chart functionality in <strong class="inline">ggplot</strong> works by constructing elements on top of a bar chart. We first use the base from <strong class="inline">ggplot</strong> and <strong class="inline">geom_bar</strong> to render the base for a stacked bar plot and use the <strong class="inline">coord_polar</strong> function to transform this into the required pie chart. The <strong class="inline">scale_y_continuous</strong> function helps in placing the labels on the pie distribution. The next line adds a rotation angle to the positioning of the text. The <strong class="inline">size</strong> parameter inside the <strong class="inline">element_text</strong> portion of the <strong class="inline">theme</strong> function defines the font size for the text in the plot. The rest is the same as we studied in the earlier plots.</p>
			<p>We can see that the pie chart provides us with an intuitive way to explore the percentage distribution for the categories within each variable. A word of caution to choose the pie chart over bar plot would be based on the number of distinct categories within a variable. Though pie charts are visually more appealing, with many distinct classes, pie charts become overcrowded.</p>
			<h4>Note</h4>
			<p class="callout">Pie charts are best avoided when the number of distinct classes within a categorical variable is high. There is no definite rule, but anything that makes visually cluttered pie charts would not be ideal to study.</p>
			<h3 id="_idParaDest-95"><a id="_idTextAnchor095"/>Exercise 27: Automate Plotting Categorical Variables</h3>
			<p>In this exercise, we will automate the plotting of categorical variables.</p>
			<p>Just like numeric variables, we also have 10 categorical variables, excluding the target variable. Similar to automating the exploration of numeric features, let's now create a function for categorical variables. To keep things simple, we will primarily use boxplots with a percentage distribution instead of a pie chart. We will start with four categorical features and then move to the next remainder set.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">cowplot</strong> package using the following command:<p class="snippet">library(cowplot)</p></li>
				<li>Define a function to plot histograms for all numeric columns:<p class="snippet">plot_grid_categorical &lt;- function(df,list_of_variables,ncols=2){</p><p class="snippet">    plt_matrix &lt;- list()</p><p class="snippet">    i&lt;-1</p><p class="snippet">    #Iterate for each variable</p><p class="snippet">    for(column in list_of_variables){</p><p class="snippet">        #Creating a temporary DataFrame with the aggregation</p><p class="snippet">        var.dist &lt;- df %&gt;% group_by_(column) %&gt;% </p><p class="snippet">                           summarize(Count = n()) %&gt;% </p><p class="snippet">                           mutate(Perc.Count = round(Count/sum(Count)*100,1))</p><p class="snippet">        options(repr.plot.width=12, repr.plot.height=10)</p><p class="snippet">        plt_matrix[[i]]&lt;-ggplot(data = var.dist,aes_string(x=column,y="Perc.Count")) +</p><p class="snippet">            geom_bar(stat="identity",fill="blue",alpha=0.6) + #Defines the bar plot</p><p class="snippet">            geom_text(label=var.dist$Perc.Count,vjust=-0.3)+  #Adds the labels</p><p class="snippet">            theme(axis.text.x = element_text(angle = 90, vjust = 1)) + #rotates the labels</p><p class="snippet">            ggtitle(paste("Percentage Distribution of variable: ",column))  #Creates the title +</p><p class="snippet">            i&lt;-i+1</p><p class="snippet">    }</p><p class="snippet">        plot_grid(plotlist=plt_matrix,ncol=ncols) #plots the grid</p><p class="snippet">}</p></li>
				<li>Next, call the <strong class="inline">summary</strong> statistics using the following command:<p class="snippet">summary(df[,c("job","education","default","contact")])</p><p>The output is as follows:</p><p class="snippet">          job                      education        default           contact     </p><p class="snippet"> admin.     :10422   university.degree  :12168   no     :32588   cellular :26144  </p><p class="snippet"> blue-collar: 9254   high.school        : 9515   unknown: 8597   telephone:15044  </p><p class="snippet"> technician : 6743   basic.9y           : 6045   yes    :    3</p><p class="snippet"> services   : 3969   professional.course: 5243</p><p class="snippet"> management : 2924   basic.4y           : 4176</p><p class="snippet"> retired    : 1720   basic.6y           : 2292</p><p class="snippet"> (Other)    : 6156   (Other)            : 1749</p></li>
				<li>Call the function we defined earlier to plot the histogram:<p class="snippet">plot_grid_categorical(df,c("job","education","default","contact"),2)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="image/C12624_02_12.jpg" alt="Figure 2.12: Bar plot for categorical variables&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.12: Bar plot for categorical variables</h6>
			<p>Similar to the earlier function we created for the numeric features visual automation, we have created a simple function to explore the percentage distribution for categorical features. Some additions to the function are the creation of the temporary aggregation dataset and some additional cosmetic enhancements to the plot. We add the labels and rotate them by 30 degrees so that they can neatly align with the plot, and the rest remains the same. We get the frequency count by calling the <strong class="inline">summary</strong> function on the <strong class="inline">categorical</strong> column. Similar to numeric columns, we explore the categorical columns first using the <strong class="inline">summary</strong> function and then use the defined function to visualize the collated bar plots.</p>
			<p>Exploring the <strong class="inline">job</strong> feature, we can see 12 distinct values, with most of the records for admin, blue-collar, and technician. Overall, the <strong class="inline">job</strong> category seems to have a fairly diverse distribution of values. Education level of the client also has a diverse set of values, with ~50% of the values from high school and university. For the <strong class="inline">default</strong> variable, which indicates whether the client has defaulted in credit previously, we have ~80% of the values as <strong class="inline">no</strong> and around ~20% unknown. This doesn't seem to be useful information. Finally, <strong class="inline">contact</strong>, which defines the mode of contact used for the campaign communication, shows that 64% was through cellular phones, and the rest through landlines.</p>
			<p>Let's move on and repeat the same analysis for the next set of features.</p>
			<h3 id="_idParaDest-96"><a id="_idTextAnchor096"/>Exercise 28: Automate Plotting for the Remaining Categorical Variables</h3>
			<p>In this exercise, we will reuse the same function for the next set of four categorical variables. Remember that you need to use the frequency count generated using the <strong class="inline">summary</strong> command in conjunction with the plots to interpret the value.</p>
			<p>Let's perform the following procedure to complete the exercise:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">cowplot</strong> package using the following command:<p class="snippet">library(cowplot)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Next, call the <strong class="inline">summary</strong> statistics using the following command:<p class="snippet">summary(df[,c("loan","month","day_of_week","poutcome")])</p><p>The output is as follows:</p><p class="snippet">      loan           month       day_of_week        poutcome    </p><p class="snippet"> no     :33950   may    :13769   fri:7827    failure    : 4252  </p><p class="snippet"> unknown:  990   jul    : 7174   mon:8514    nonexistent:35563  </p><p class="snippet"> yes    : 6248   aug    : 6178   thu:8623    success    : 1373  </p><p class="snippet">                 jun    : 5318   tue:8090                       </p><p class="snippet">                 nov    : 4101   wed:8134                       </p><p class="snippet">                 apr    : 2632                                  </p><p class="snippet">                 (Other): 2016</p></li>
				<li>Call the defined function to plot the histogram:<p class="snippet">plot_grid_categorical(df,c("loan","month","day_of_week","poutcome"),2)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/C12624_02_13.jpg" alt="Figure 2.13: Automate plotting for the remaining categorical variables&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.13: Automate plotting for the remaining categorical variables</h6>
			<p>We reuse the previously defined functions to explore the new set of four variables just like we explored the previous set of features.</p>
			<p>The <strong class="inline">loan</strong> variable indicates whether the client has a personal loan. We have ~86.6% of clients with no personal loan, 10.3% with a loan, and 3.3% unknown. Similarly, the <strong class="inline">month</strong> variable indicates the actual month when the campaign calls were executed. We see that the majority of communication was conducted in the month of <strong class="inline">may</strong>, followed by <strong class="inline">jul</strong> and <strong class="inline">aug</strong>. Overall, the <strong class="inline">month</strong> feature also seems to be a fairly diverse variable with a good distribution of values. The <strong class="inline">day_of_week</strong> variable shows a consistent distribution across all days of the week. <strong class="inline">poutcome</strong> indicates the result of the previously executed campaign; a significant majority was non-existent, a small chunk of around 3.3% was successful, and ~10% failed.</p>
			<h3 id="_idParaDest-97"><a id="_idTextAnchor097"/>Exercise 29: Exploring the Last Remaining Categorical Variable and the Target Variable</h3>
			<p>Finally, let's explore the last remaining categorical variable and the target variable. Since both are categorical, we can continue using the same function for the exploration.</p>
			<p>Repeat the same process for the last independent categorical variable and the dependent variable (which is also categorical):</p>
			<ol>
				<li value="1">First, after importing the required packages and creating DataFrame object, call the summary statistics using the following command:<p class="snippet">summary(df[,c("y","housing")])</p><p>The output is as follows:</p><p class="snippet">   y            housing     </p><p class="snippet"> no :36548   no     :18622  </p><p class="snippet"> yes: 4640   unknown:  990  </p><p class="snippet">             yes    :21576</p></li>
				<li>Call the defined function to plot the histogram:<p class="snippet">plot_grid_categorical(df,c("y","housing"),2)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/C12624_02_14.jpg" alt="Figure 2.14: Histogram of housing per count&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.14: Histogram of housing per count</h6>
			<p>If we carefully look at the distribution of the outcome variable, we can see that a large majority of the clients have negatively responded to the campaign calls. Only ~11% of the overall campaign base have positively responded to the campaign. Similarly, if we look at the <strong class="inline">housing</strong> variable, we can see that roughly 50% of the clients had a housing loan.</p>
			<p>To summarize, we can distill our observations as follows:</p>
			<ul>
				<li>The campaign was conducted with a major focus of new customers who had not been previously contacted.</li>
				<li>Around 60% of the client base are married and 80% have not defaulted in credit history.</li>
				<li>Roughly 50% of the client base has a housing loan and over 80% has never opted for a personal loan.</li>
				<li>The campaign was the most active during the month of May and demonstrated fairly strong momentum in July and August.</li>
				<li>More than 60% of the communication of the campaign was through cellular phones, and over 50% of the client base at least had a high school degree.</li>
				<li>Overall, only 11% of the campaign calls had a positive response.</li>
			</ul>
			<p>With the univariate analysis of all the numeric and categorical variables complete, we now have a fair understanding of the story the data conveys. We almost understand each data dimension and its distribution. Let's move on to explore another interesting facet of EDA: bivariate analysis.</p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor098"/>Bivariate Analysis</h2>
			<p>In <strong class="bold">bivariate analysis</strong>, we extend our analysis to study two variables together. In our use case, we have around 20 independent variables. It is indeed possible to study all permutation combinations of the available 20 variables, but we won't go to that extent in this chapter. In our use case, we are more interested in studying all the factors that led to the poor performance of the campaign. Therefore, our primary focus will be to perform bivariate analysis and study the relationship between all the independent variables and our dependent target variable. Again, depending on the type of variable, we will have a different type of visual or analytical technique to analyze the relationship between the two variables. The possible combinations are numeric and numeric, and numeric and categorical. Given that our dependent variable is a categorical variable, we might have to explore the relationship between two independent variables in our list to study the relationship between two numeric variables. Let's get started.</p>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor099"/>Studying the Relationship between Two Numeric Variables</h2>
			<p>To understand how we can study the relationship between two numeric variables, we can leverage scatter plots. It is a 2-dimensional visualization of the data, where each variable is plotted on an axis along its length. Relationships between the variables are easily identified by studying the trend across the visualization. Let's take a look at an example in the following exercise.</p>
			<h3 id="_idParaDest-100"><a id="_idTextAnchor100"/>Exercise 30: Studying the Relationship between Employee Variance Rate and Number of Employees</h3>
			<p>Let's study the relationship between employee variance rate and the number of employees. Ideally, the number of employees should increase as the variation rate increases.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">ggplot2</strong> package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Now, plot the scatter plot using the following command:<p class="snippet">ggplot(data=df,aes(x=emp.var.rate,y=nr.employed)) + geom_point(size=4) + </p><p class="snippet">ggtitle("Scatterplot of Employment variation rate v/s Number of Employees")</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/C12624_02_15.jpg" alt="Figure 2.15: Scatterplot of employment variation versus the number of employees&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.15: Scatterplot of employment variation versus the number of employees</h6>
			<p>We use the same base function, <strong class="inline">ggplot</strong>, with a new wrapper for the scatterplot. The <strong class="inline">geom_point</strong> function in <strong class="inline">ggplot</strong> provides the necessary constructs for using a scatterplot.</p>
			<p>We can see an overall increasing trend, that is, as employment variance rate increases, we see the number of employees also increases. The fewer number of dots are due to repetitive records in <strong class="inline">nr.employed</strong>.</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor101"/>Studying the Relationship between a Categorical and a Numeric Variable</h2>
			<p>Let's first recall the methods discussed to study the relationship between the numeric and categorical variable and discuss the approach to execute it.</p>
			<p>In this section, we will discuss the different aggregation metrics that we can use for summarizing the data. So far, we have used <strong class="inline">avg</strong>, but a better approach would be to use a combination of <strong class="inline">avg</strong>, <strong class="inline">min</strong>, <strong class="inline">max</strong>, and other metrics.</p>
			<h3 id="_idParaDest-102"><a id="_idTextAnchor102"/>Exercise 31: Studying the Relationship between the y and age Variables</h3>
			<p>We have a categorical dependent variable and nine numeric variables to explore. To start small, we will first explore the relationship between our target, <strong class="inline">y</strong>, and <strong class="inline">age</strong>. To study the relationship between a categorical and numeric variable, we can choose a simple analytical technique where we calculate the average age across each target outcome; if we see stark differences, we can make insights from the observations.</p>
			<p>In this exercise, we will calculate the average age across each target outcome and also count the number of records in each bucket, followed by a visual representation.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">ggplot2</strong> package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Create a <strong class="inline">temp</strong> object and store the value using the following command:<p class="snippet">temp &lt;- df %&gt;% group_by(y) %&gt;% </p><p class="snippet">                           summarize(Avg.Age = round(mean(age),2),</p><p class="snippet">                                     Num.Records = n())</p></li>
				<li>Print the value stored in the <strong class="inline">temp</strong> object:<p class="snippet">print(temp)</p><p>The output is as follows:</p><p class="snippet"># A tibble: 2 x 3</p><p class="snippet">  y     Avg.Age Num.Records</p><p class="snippet">  &lt;fct&gt;   &lt;dbl&gt;       &lt;int&gt;</p><p class="snippet">1 no       39.9       36548</p><p class="snippet">2 yes      40.9        4640</p></li>
				<li>Now, create a plot using the <strong class="inline">ggplot</strong> command:<p class="snippet">ggplot(data= temp, aes(x=y, y=Avg.Age)) + </p><p class="snippet">       geom_bar(stat="identity",fill="blue",alpha= 0.5) +   #Creates the bar plot</p><p class="snippet">       geom_text(label=temp$Avg.Age,vjust=-0.3)+  #Adds the label</p><p class="snippet">       ggtitle(paste("Average Age across target outcome"))  #Creates the title</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/C12624_02_16.jpg" alt="Figure 2.16: Histogram for the average age across target outcome&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.16: Histogram for the average age across target outcome</h6>
			<p>The first line of code creates the temporary aggregation datasets, which summarizes the average age and the number of records in each category. The plotting functionality used is on the lines of our previous visuals. We extend the <strong class="inline">ggplot</strong> function with the <strong class="inline">geom_bar</strong> to render the bar plots.</p>
			<p>We can see that there is barely any difference between the two outcomes. We don't see any interesting patterns.</p>
			<h4>Note</h4>
			<p class="callout">In bivariate analysis, we need to be careful before concluding any interesting patterns as insights. In many cases, due to the skewed distribution of data, the patterns would seem surprisingly interesting.</p>
			<p>Let's move on to the next set of variables.</p>
			<h3 id="_idParaDest-103"><a id="_idTextAnchor103"/>Exercise 32: Studying the Relationship between the Average Value and the y Variable</h3>
			<p>In this exercise, we will study the relationship between the next set of variables: <strong class="inline">average</strong> and <strong class="inline">y</strong>.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the required libraries and create the DataFrame object.</li>
				<li>Next, create the <strong class="inline">plot_bivariate_numeric_and_categorical</strong> object using the following command:<p class="snippet">plot_bivariate_numeric_and_categorical &lt;- function(df,target,list_of_variables,ncols=2){</p><p class="snippet">    target&lt;-sym(target) #Defined for converting text to column names</p><p class="snippet">    plt_matrix &lt;- list()</p><p class="snippet">    i&lt;-1</p><p class="snippet">for(column in list_of_variables){</p><p class="snippet">        col &lt;-sym(column) #defined for converting text to column name</p><p class="snippet">        temp &lt;- df %&gt;% group_by(!!sym(target)) %&gt;% </p><p class="snippet">                       summarize(Avg.Val = round(mean(!!sym(col)),2))</p><p class="snippet">        options(repr.plot.width=12, repr.plot.height=8) #Defines plot size</p><p class="snippet">           plt_matrix[[i]]&lt;-ggplot(data= temp, aes(x=!!sym(target), y=Avg.Val)) + </p><p class="snippet">           geom_bar(stat="identity",fill="blue",alpha= 0.5) +   </p><p class="snippet">           geom_text(label=temp$Avg.Val,vjust=-0.3)+  #Adds the labels</p><p class="snippet">           ggtitle(paste("Average",column,"across target outcomes"))  #Creates the title </p><p class="snippet">            i&lt;-i+1</p><p class="snippet">    }</p><p class="snippet">    plot_grid(plotlist = plt_matrix,ncol=ncols)</p><p class="snippet">}</p></li>
				<li>Now, print the distribution of records across target outcomes:<p class="snippet">print("Distribution of records across target outcomes-")</p><p class="snippet">print(table(df$y))</p><p>The output is as follows:</p><p class="snippet">[1] "Distribution of records across target outcomes-"</p><p class="snippet">   no   yes </p><p class="snippet">36548  4640</p></li>
				<li>Now, plot the histogram using the following command for the defined variables:<p class="snippet">plot_bivariate_numeric_and_categorical(df,"y",c("campaign","pdays","previous","emp.var.rate"),2)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/C12624_02_17.jpg" alt="Figure 2.17: Histogram of average value versus the y variable&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.17: Histogram of average value versus the y variable</h6>
			<p>In order to automate the data exploration task for bivariate analysis between a categorical and a numeric variable, we have defined a function similar to the one we defined in the previous exercise. We have additionally used the <strong class="inline">sym</strong> function, which will help us use dynamic column names in the function. Using <strong class="inline">!!sym(column)</strong> converts a string to a real column name that's analogous to passing the actual value. The previous function first aggregates the average value of the target across the variable of interest. The <strong class="inline">plot</strong> function then uses the information to plot the bar chart with the average values across the target outcomes.</p>
			<p>In bivariate analysis, it is important to carefully validate the patterns observed before concluding a specific insight. In some cases, outliers might skew the results and therefore deliver incorrect findings. Additionally, fewer of records for a particular pattern might also be a risky pattern to conclude. It is always recommended to collect all the insights observed and further validate them with additional extensive EDA or statistical techniques for significance.</p>
			<p>Here, we don't see any prominent results to conclude. In the <strong class="inline">campaign</strong> variable, the average number of contacts made during the campaign is a bit lower for successful campaigns, but the difference is too small to make any possible conclusions. <strong class="inline">pdays</strong>, which indicate the number of days since the last contact in the previous campaign shows a big difference between the outcomes for the target. </p>
			<p>However, this difference is purely due to most clients being not contacted in the previous campaign. All of those records have values set to 999. The same holds true for <strong class="inline">previous</strong>; though there is a decent difference between the two, most clients were contacted for the first time in the current campaign. The employment variance rate, however, shows counter-intuitive results. We would actually expect the variance rate to be higher when the outcome is <strong class="inline">yes</strong>, but we see it the other way around. This sounds interesting, we will make a note of this insight for now and later come back for more validation before making any conclusions.</p>
			<p>Let's move on to the next set of categorical dependent variables to be studied with the categorical dependent variable.</p>
			<h3 id="_idParaDest-104"><a id="_idTextAnchor104"/>Exercise 33: Studying the Relationship between the cons.price.idx, cons.conf.idx, curibor3m, and nr.employed Variables</h3>
			<p>Let's move on to the next set of categorical dependent variables to be studied with the categorical dependent variable. For this exercise, we will explore the relationship between <strong class="inline">cons.price.idx</strong>, <strong class="inline">cons.conf.idx</strong>, <strong class="inline">euribor3m</strong>, and <strong class="inline">nr.employed</strong>, with the target variable <strong class="inline">y</strong> using histogram.</p>
			<ol>
				<li value="1">Import the required libraries and create the DataFrame object.</li>
				<li>Next, create a <strong class="inline">plot_bivariate_numeric_and_categorical</strong> function and plot the histogram:<p class="snippet">plot_bivariate_numeric_and_categorical(df,"y",</p><p class="snippet">               c("cons.price.idx","cons.conf.idx", "euribor3m", "nr.employed"),2)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/C12624_02_18.jpg" alt="Figure 2.18: Histogram of the cons.price.idx, cons.conf.idx, euribor3m, and nr.employed variables&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.18: Histogram of the cons.price.idx, cons.conf.idx, euribor3m, and nr.employed variables</h6>
			<p>Again, for most cases, we don't see any prominent patterns. However, the <strong class="inline">euribor3m</strong> variable demonstrates some good differences between the average values for <strong class="inline">yes</strong> and <strong class="inline">no</strong> outcomes of the campaign and, again, seems counter-intuitive. We ideally expected higher bank deposits with higher interest rates. Therefore, let's make a note of the insight and validate it later.</p>
			<p>Moving on, let's now explore the relationship between two categorical variables.</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor105"/>Studying the Relationship Between Two Categorical Variables</h2>
			<p>To study the relationship and patterns that exist between two categorical variables, we can first explore the frequency distribution across each category of the variables. A higher concentration in any outcome might be a potential insight. The most effective way to visualize this is using stacked bar charts.</p>
			<p>A stacked bar chart will help us to observe the distribution of the target variable across multiple categorical variables. The distribution will reveal whether a specific category in a categorical variable dominates the target variable, <strong class="inline">y</strong>. If yes, we can further explore its influence on our problem.</p>
			<p>In the next few exercises, we will explore various categorical variables across target variable <strong class="inline">y</strong> using stacked bar chart. We will plot absolute count and percentage to understand the distribution better.</p>
			<h3 id="_idParaDest-106"><a id="_idTextAnchor106"/>Exercise 34: Studying the Relationship Between the Target y and marital status Variables</h3>
			<p>In this exercise, we will demonstrate the study between two categorical variables using plain frequency counts and then show how inconvenient it is.</p>
			<p>To start simple, let's begin with exploring the relationship between the target, <strong class="inline">y</strong>, and <strong class="inline">marital status</strong>.</p>
			<ol>
				<li value="1">First, import the <strong class="inline">ggplot2</strong> package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Next, create a <strong class="inline">temp</strong> aggregation dataset:<p class="snippet">temp &lt;- df %&gt;% group_by(y,marital) %&gt;% summarize(Count = n()) </p></li>
				<li>Define plot size, as illustrated here:<p class="snippet">options(repr.plot.width=12, repr.plot.height=4)</p></li>
				<li>Plot the chart with frequency distribution:<p class="snippet">ggplot(data = temp,aes(x=marital,y=Count,fill=y)) + </p><p class="snippet">       geom_bar(stat="identity") + </p><p class="snippet">       ggtitle("Distribution of target 'y' across Marital Status")</p><p>The output is as follows:</p><div id="_idContainer048" class="IMG---Figure"><img src="image/C12624_02_19.jpg" alt="Figure 2.19: Using ggplot to study the relationship between the target y and marital status variables&#13;&#10;"/></div><h6>Figure 2.19: Using ggplot to study the relationship between the target y and marital status variables</h6><p>We first aggregate the categorical columns using the <strong class="inline">group_by</strong> function. This would help us cross frequency count for each category combination. We now use this temporary dataset to plot the frequency distribution across the independent variable.</p><p>As we can see, the <strong class="inline">yes</strong> frequency is highest for married clients, but this may be true just because the number of married clients is high. To understand the relationship better, we can further break this down using a stacked bar chart with percentage distribution, where each bar represents the percentage of <strong class="inline">yes</strong> and <strong class="inline">no</strong>, respectively.</p></li>
				<li>Create a <strong class="inline">temp</strong> aggregation dataset:<p class="snippet">temp &lt;- df %&gt;% group_by(y,marital) %&gt;% </p><p class="snippet">               summarize(Count = n()) %&gt;% </p><p class="snippet">               ungroup() %&gt;%  #This function ungroups the previously grouped dataframe</p><p class="snippet">               group_by(marital) %&gt;%</p><p class="snippet">               mutate(Perc = round(Count/sum(Count)*100)) %&gt;%</p><p class="snippet">               arrange(marital)</p></li>
				<li>Define the plot size using the <strong class="inline">options</strong> method:<p class="snippet">options(repr.plot.width=12, repr.plot.height=4)</p></li>
				<li>Plot the percentage distribution using the <strong class="inline">ggplot</strong> method:<p class="snippet">ggplot(data = temp,aes(x=marital,y=Perc,fill=y)) + </p><p class="snippet">    geom_bar(stat="identity") + </p><p class="snippet">    geom_text(aes(label = Perc), size = 5, hjust = 0.5, vjust = 0.3, position = "stack") + </p><p class="snippet">    ggtitle("Distribution of target 'y' percentage across Marital Status")</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/C12624_02_20.jpg" alt="Figure 2.20: Distribution of target y percentage across marital status&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.20: Distribution of target y percentage across marital status</h6>
			<p>We can now see counter-intuitive results compared to the previous plot. After we normalize the results, we see that <strong class="inline">single</strong> clients are more responsive to the campaign than those who are married. This is true for <strong class="inline">unknown</strong> too, but given the uncertainty of the value and the extremely low number of records, we should ignore this. We cannot directly conclude the result that single customers are more effective in responding to campaigns, but we can validate this later.</p>
			<h3 id="_idParaDest-107"><a id="_idTextAnchor107"/>Exercise 35: Studying the Relationship between the job and education Variables</h3>
			<p>In this exercise, we will accelerate our exploration. Let's build a custom function where we can combine the two charts, that is, frequency distribution as well percentage distribution, for categorical variable's bivariate analysis.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">First, import the <strong class="inline">ggplot2</strong> package using the following command:<p class="snippet">library(ggplot2)</p></li>
				<li>Create a DataFrame object, <strong class="inline">df</strong>, and use the <strong class="inline">bank-additional-full.csv</strong> file using the following command:<p class="snippet">df &lt;- read.csv("/Chapter 2/Data/bank-additional/bank-additional-full.csv",sep=';')</p></li>
				<li>Create a <strong class="inline">temp</strong> aggregation dataset:<p class="snippet">plot_bivariate_categorical &lt;-  function(df, target, list_of_variables){</p><p class="snippet">    target &lt;- sym(target) #Converting the string to a column reference</p><p class="snippet">    i &lt;-1 </p><p class="snippet">    plt_matrix &lt;- list()</p><p class="snippet">    for(column in list_of_variables){</p><p class="snippet">        col &lt;- sym(column) </p><p class="snippet">        temp &lt;- df %&gt;% group_by(!!sym(target),!!sym(col)) %&gt;% </p><p class="snippet">           summarize(Count = n()) %&gt;% </p><p class="snippet">           ungroup() %&gt;% #This fucntion ungroups the previously grouped dataframe</p><p class="snippet">           group_by(!!sym(col)) %&gt;%</p><p class="snippet">           mutate(Perc = round(Count/sum(Count)*100)) %&gt;%</p><p class="snippet">           arrange(!!sym(col))</p></li>
				<li>Define the plot size:<p class="snippet">options(repr.plot.width=14, repr.plot.height=12)</p></li>
				<li>Plot the chart with a frequency distribution:<p class="snippet">    plt_matrix[[i]]&lt;- ggplot(data = temp,aes(x=!!sym(col),y=Count,fill=!!sym(target))) + </p><p class="snippet">        geom_bar(stat="identity") + </p><p class="snippet">        geom_text(aes(label = Count), size = 3, hjust = 0.5, vjust = -0.3, position = "stack") + </p><p class="snippet">        theme(axis.text.x = element_text(angle = 90, vjust = 1)) + #rotates the labels</p><p class="snippet">        ggtitle(paste("Distribution of target 'y'  frequency across",column))</p><p class="snippet">    i&lt;-i+1</p></li>
				<li>Plot the percentage distribution:<p class="snippet">    plt_matrix[[i]] &lt;- ggplot(data = temp,aes(x=!!sym(col),y=Perc,fill=!!sym(target))) + </p><p class="snippet">        geom_bar(stat="identity") + </p><p class="snippet">        geom_text(aes(label = Perc), size = 3, hjust = 0.5, vjust = -1, position = "stack") + </p><p class="snippet">        theme(axis.text.x = element_text(angle = 90, vjust = 1)) + #rotates the labels</p><p class="snippet">        ggtitle(paste("Distribution of target 'y' percentage across",column))</p><p class="snippet">    i &lt;- i+1</p><p class="snippet">    }</p><p class="snippet">    plot_grid(plotlist = plt_matrix, ncol=2)</p><p class="snippet">}</p></li>
				<li>Plot the <strong class="inline">plot_bivariate_categorical</strong> using the following command:<p class="snippet">plot_bivariate_categorical(df,"y",c("job","education"))</p><p>The output is as follows:</p><div id="_idContainer050" class="IMG---Figure"><img src="image/C12624_02_21.jpg" alt="Figure 2.21: Studying the relationship between the job and education variables&#13;&#10;"/></div><h6>Figure 2.21: Studying the relationship between the job and education variables</h6><p>We use the same principles to define the function that would plot the charts together. The additional difference here would be two plots for each combination. The first (left) is the frequency plot across the category combinations, and the right-hand side plot showcases the percentage distribution (normalized across category) visual. Studying both the plots together helps validate results more effectively. The creation of temporary aggregated datasets has an additional step with the use of the <strong class="inline">ungroup</strong> function. This is used to enable the relative percentage distribution of target outcome within the categorical levels of independent variable, that is, distribution of <strong class="inline">y</strong> across each level within <strong class="inline">marital</strong>.</p><p>If we observe the results from the previous output plots, we can see that the highest response rates for the campaign are from student and retired professionals, but this comes with a caveat. We see that both of these categories have far less observations as compared to the other categories. Therefore, we would need additional validation before making further conclusions. We, therefore, make a note of this insight too. From education levels, we don't see any interesting trends. Though <strong class="inline">illiterate</strong> clients have a high response rate, the number of observations are far too low to conclude anything tangible.</p></li>
				<li>Let's take a look at credit default and housing loan categories:<p class="snippet">plot_bivariate_categorical(df,"y",c("default","housing"))</p><p>The output is as follows:</p><div id="_idContainer051" class="IMG---Figure"><img src="image/C12624_02_22.jpg" alt="Figure 2.22: Studying the relationship between the default and housing variables&#13;&#10;"/></div><h6>Figure 2.22: Studying the relationship between the default and housing variables</h6></li>
				<li>Again, we don't see any interesting trends. Let's continue the exploration for personal loan and contact mode:<p class="snippet">plot_bivariate_categorical(df,"y",c("loan","contact"))</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/C12624_02_23.jpg" alt="Figure 2.23: Studying the relationship between the loan and contact variables&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.23: Studying the relationship between the loan and contact variables</h6>
			<p>Here, we can see an interesting trend for the mode of contact used. There is generally a higher response rate when the mode of campaign communication is cellular rather than landline. Let's make a note of this trend too and huddle back with further validation.</p>
			<p>I encourage you to explore the relationships between our target variable and the remaining dependent categorical variables: month, day of week, and the previous outcome of the campaign.</p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor108"/>Multivariate Analysis</h2>
			<p>Multivariate analysis is the process of studying the relationships between more than two variables; essentially, one dependent variable and more than one independent variable. Bivariate analysis is a form of multivariate analysis. There are several forms of multivariate analysis that are important, but we will skip the details for now to restrict the scope of the chapter. In the next few chapters, we will take a closer look at linear and logistic regression, which are two popular multivariate analysis techniques.</p>
			<p>Some of the most common techniques used in multivariate analysis are as follows:</p>
			<ul>
				<li>Multiple linear regression (studying the impact of more than one independent variable on a numeric/continuous target variable)</li>
				<li>Logistic regression (studying the impact of more than one independent variable on a categorical target variable)</li>
				<li>Factor analysis</li>
				<li>MANOVA</li>
			</ul>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor109"/>Validating Insights Using Statistical Tests</h2>
			<p>Throughout the journey of EDA, we have collected and noted some interesting patterns for further validation. It is now the right time to test whether whatever we observed previously are actually valid patterns or just appeared to be interesting due to random chance. The most effective and straightforward way to approach this validation is by performing a set of statistical tests and measuring the statistical significance of the pattern. We have a ton of options in the available set of tests to choose from. The options vary based on the type of independent and dependent variable. The following is a handy reference diagram that explains the types of statistical test that we can perform to validate our observed patterns:</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/C12624_02_24.jpg" alt="Figure 2.24: Validating dependent and independent variables&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 2.24: Validating dependent and independent variables</h6>
			<p>Let's collect all our interesting patterns into one place here:</p>
			<ul>
				<li>The campaign outcome has a higher chance of <strong class="inline">yes</strong> when the employee variance rate is low.</li>
				<li>The campaign outcome has a higher chance of <strong class="inline">yes</strong> when the euro interest rates are low.</li>
				<li>Single clients have a higher chance of responding positively to the campaign.</li>
				<li>Student and retired clients have a higher chance of responding positively to the campaign.</li>
				<li>Cellular contacts have a higher chance of responding positively to the campaign.</li>
			</ul>
			<p>If you try to categorize these hypotheses, we can see that we have a categorical dependent variable in all cases. So, we should use a chi-squared test or logistic regression test to validate our results.</p>
			<p>Let's perform these tests one by one.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor110"/>Categorical Dependent and Numeric/Continuous Independent Variables</h2>
			<p>Hypotheses 1 and 2 have a continuous independent variable. Referring to the figure in the previous section, we will opt for the chi-squared test. In the process of hypothesis testing, we start by defining a null hypothesis and an alternate hypothesis. Start with a negative approach, that is, assume the null hypothesis to be what we don't want to happen. The hypothesis test examines the chances that the pattern observed happens due to random chance or there if is certainty about the observation. This measure is quantified as probability. If the probability of the significance of the null hypothesis to happen is less than 5% (or a suitable cut-off), we reject the null hypothesis and confirm the validity of the alternate hypothesis.</p>
			<p>Let's begin; for hypothesis 1, we define the following:</p>
			<ul>
				<li><strong class="bold">Null hypothesis</strong>: The campaign outcome has no relationship with the employee variance rate.</li>
				<li><strong class="bold">Alternate hypothesis</strong>: The campaign outcome has a relationship with employee variance rate.</li>
			</ul>
			<p>We test the validity of our null hypothesis with simple logistic regression. We will discuss this topic in more detail in the following chapters. For now, we will quickly perform a simple check to test our hypothesis. The following exercise leverages R's built-in function for performing logistic regression.</p>
			<h3 id="_idParaDest-111"><a id="_idTextAnchor111"/>Exercise 36: Hypothesis 1 Testing for Categorical Dependent Variables and Continuous Independent Variables</h3>
			<p>To perform hypothesis testing for categorical dependent variables and continuous independent variables, we will use the <strong class="inline">glm()</strong> function to fit the logistic regression model (more on this in <em class="italics">Chapter 5</em>, <em class="italics">Classification</em>). This exercise will help us statistically test whether a categorical dependent variable (for example, <strong class="inline">y</strong>) has any relationship with a continuous independent variable, for example, </p>
			<p><strong class="inline">emp.var.rate</strong>.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the required libraries and create the DataFrame objects.</li>
				<li>First, convert the dependent variable into a <strong class="inline">factor</strong> type:<p class="snippet">df$y &lt;- factor(df$y)</p></li>
				<li>Next, perform logistic regression:<p class="snippet">h.test &lt;- glm(y ~ emp.var.rate, data = df, family = "binomial")</p></li>
				<li>Print the test summary:<p class="snippet">summary(h.test)</p><p>The output is as follows:</p><p class="snippet">Call:</p><p class="snippet">glm(formula = y ~ emp.var.rate, family = "binomial", data = df)</p><p class="snippet">Deviance Residuals: </p><p class="snippet">    Min       1Q   Median       3Q      Max  </p><p class="snippet">-1.0047  -0.4422  -0.3193  -0.2941   2.5150  </p><p class="snippet">Coefficients:</p><p class="snippet">             Estimate Std. Error z value Pr(&gt;|z|)    </p><p class="snippet">(Intercept)  -2.33228    0.01939 -120.31   &lt;2e-16 ***</p><p class="snippet">emp.var.rate -0.56222    0.01018  -55.25   &lt;2e-16 ***</p><p class="snippet">---</p><p class="snippet">Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</p><p class="snippet">(Dispersion parameter for binomial family taken to be 1)</p><p class="snippet">    Null deviance: 28999  on 41187  degrees of freedom</p><p class="snippet">Residual deviance: 25597  on 41186  degrees of freedom</p><p class="snippet">AIC: 25601</p><p class="snippet">Number of Fisher Scoring iterations: 5</p></li>
			</ol>
			<p>We convert the target variable, <strong class="inline">y</strong>, as a <strong class="inline">factor</strong> (if it was not already). We use the <strong class="inline">glm</strong> function provided by R for logistic regression. The <strong class="inline">glm</strong> function also performs other forms of regression, and we specify the <strong class="inline">family = 'binomial'</strong> parameter for using the function as a logistic regression. The formula in the first place of the function defines the dependent and independent variables.</p>
			<p>There are quite a few results shared in the output. We will ignore most of them for now and focus only on the final output. One of the results provided is the significance probability, which confirms that there is less than a <strong class="inline">2e-16</strong> chance that our null hypothesis is true, and therefore we can reject it. Therefore, the target outcome has a statistically significant relationship with the employee variance rate and, as we can see, there is a higher chance of campaign conversion as the rate decreases.</p>
			<p>Similarly, let's repeat the same test for our second hypothesis. We define the following:</p>
			<ul>
				<li><strong class="bold">Null hypothesis</strong>: The campaign outcome has no relationship with the euro interest rate.</li>
				<li><strong class="bold">Alternate hypothesis</strong>: The campaign outcome has a relationship with the euro interest rate.</li>
			</ul>
			<h3 id="_idParaDest-112"><a id="_idTextAnchor112"/>Exercise 37: Hypothesis 2 Testing for Categorical Dependent Variables and Continuous Independent Variables</h3>
			<p>Once again, we will use logistic regression to statistically test whether there is a relationship between the target variable, <strong class="inline">y</strong>, and the independent variable. In this exercise, we will use the <strong class="inline">euribor3m</strong> variable.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Import the required libraries and create the DataFrame objects.</li>
				<li>First, convert the dependent variable into a <strong class="inline">factor</strong> type:<p class="snippet">df$y &lt;- factor(df$y)</p></li>
				<li>Next, perform logistic regression:<p class="snippet">h.test2 &lt;- glm(y ~ euribor3m, data = df, family = "binomial")</p></li>
				<li>Print the test summary:<p class="snippet">summary(h.test2)</p><p>The output is as follows:</p><p class="snippet">Call:</p><p class="snippet">glm(formula = y ~ euribor3m, family = "binomial", data = df)</p><p class="snippet">Deviance Residuals: </p><p class="snippet">    Min       1Q   Median       3Q      Max  </p><p class="snippet">-0.8568  -0.3730  -0.2997  -0.2917   2.5380  </p><p class="snippet">Coefficients:</p><p class="snippet">             Estimate Std. Error z value Pr(&gt;|z|)    </p><p class="snippet">(Intercept) -0.472940   0.027521  -17.18   &lt;2e-16 ***</p><p class="snippet">euribor3m   -0.536582   0.009547  -56.21   &lt;2e-16 ***</p><p class="snippet">---</p><p class="snippet">Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</p><p class="snippet">(Dispersion parameter for binomial family taken to be 1)</p><p class="snippet">    Null deviance: 28999  on 41187  degrees of freedom</p><p class="snippet">Residual deviance: 25343  on 41186  degrees of freedom</p><p class="snippet">AIC: 25347</p><p class="snippet">Number of Fisher Scoring iterations: 5</p></li>
			</ol>
			<p>Focusing exclusively on the previous output, we can confirm that we can reject the null hypothesis and accept the alternative hypothesis. Therefore, the target outcome has a statistically significant relationship with the Euro Interest rate and, as we can see, there is a higher chance of campaign conversion as the rate decreases.</p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor113"/>Categorical Dependent and Categorical Independent Variables</h2>
			<p>Moving on, let's take a look at the third hypothesis. To test the relationship between the categorical dependent variable and categorical independent variable, we can use the chi squared test.</p>
			<p>For hypothesis 3, we define the following:</p>
			<ul>
				<li><strong class="bold">Null hypothesis</strong>: The campaign outcome has no relationship with clients who never married.</li>
				<li><strong class="bold">Alternate hypothesis</strong>: The campaign outcome has a relationship with clients who never married.</li>
			</ul>
			<p>In the following exercise, we will leverage R's chi-square test function to validate the hypothesis..</p>
			<h3 id="_idParaDest-114"><a id="_idTextAnchor114"/>Exercise 38: Hypothesis 3 Testing for Categorical Dependent Variables and Categorical Independent Variables</h3>
			<p>In this exercise, we will perform a statistical test using the chi-squared test. We use the chi-squared test because both the independent and dependent variables are categorical, particularly when testing the relationship between <strong class="inline">y</strong> and marital status.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Import the required libraries and create the DataFrame objects.</li>
				<li>First, convert the dependent variable into a <strong class="inline">factor</strong> type:<p class="snippet">df$y &lt;- factor(df$y)</p></li>
				<li>Create a flag for <strong class="inline">single</strong> clients:<p class="snippet">df$single_flag &lt;- as.factor(ifelse(df$marital == "single","single","other"))</p></li>
				<li>Create a <strong class="inline">sample</strong> object and print the value:<p class="snippet">sample &lt;- table(df$y, df$single_flag)</p><p class="snippet">print(sample)</p><p>The output is as follows:</p><p class="snippet">  other single</p><p class="snippet">no  26600   9948</p><p class="snippet">yes  3020   1620</p></li>
				<li>Perform the chi-squared test:<p class="snippet">h.test3 &lt;- chisq.test(sample)</p></li>
				<li>Print the test summary:<p class="snippet">print(h.test3)</p><p>The output is as follows:</p><p class="snippet">Pearson's Chi-squared test with Yates' continuity correction</p><p class="snippet">data:  sample</p><p class="snippet">X-squared = 120.32, df = 1, p-value &lt; 2.2e-16</p></li>
			</ol>
			<p>We first create a new variable/flag for this test where we define whether a client is <strong class="inline">single</strong> or not. Since we are exclusively defining our relationship between the target and client's <strong class="inline">single</strong> marital status, we mask all other classes within marital status.</p>
			<p>The <strong class="inline">table</strong> command creates a new DataFrame with a simple frequency distribution between each individual class. Finally, we use this DataFrame to perform the chi-squared test.</p>
			<p>As we can see, the p-value or the chance of the null hypothesis being true is far less than 5%. Therefore, we can accept our alternate hypothesis, which confirms the fact that the campaign's outcome is positively influenced by single clients rather than other clients.</p>
			<p>Moving on, let's take a quick look at the validity of our 4th and 5th hypotheses.</p>
			<p>For the 4th and 5th hypotheses, we define the following:</p>
			<ul>
				<li><strong class="bold">Null hypothesis</strong>: The campaign outcome has no relationship with clients who are students or retired. The campaign outcome has no relationship with the contact mode used.</li>
				<li><strong class="bold">Alternate hypothesis</strong>: The campaign outcome has no relationship with clients who are students or retired. The campaign outcome has a relationship with the contact mode used.</li>
			</ul>
			<h3 id="_idParaDest-115"><a id="_idTextAnchor115"/>Exercise 39: Hypothesis 4 and 5 Testing for a Categorical Dependent Variable and a Categorical Independent Variable</h3>
			<p>Once again, let's use the chi-squared test to statistically check whether there is a relationship between the target variable, <strong class="inline">y</strong>, the categorical independent variable <strong class="inline">job_flag</strong>, and <strong class="inline">contact</strong>.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Import the required libraries and create the DataFrame objects.</li>
				<li>First, convert the dependent variable into a <strong class="inline">factor</strong> type:<p class="snippet">df$y &lt;- factor(df$y)</p></li>
				<li>Prepare the independent variable:<p class="snippet">df$job_flag &lt;- as.factor(ifelse(df$job %in% c("student","retired"),as.character(df$job),"other"))</p><p class="snippet">df$contact &lt;- as.factor(df$contact)</p></li>
				<li>Create an object named <strong class="inline">sample4</strong> and print the value:<p class="snippet">sample4 &lt;- table(df$y, df$job_flag)</p><p class="snippet">print("Frequency table for Job")</p><p class="snippet">print(sample4)</p><p>The output is as follows:</p><p class="snippet">[1] "Frequency table for Job"</p><p class="snippet">  other retired student</p><p class="snippet">no  34662    1286     600</p><p class="snippet">yes  3931     434     275</p></li>
				<li>Perform the test for the 4th hypothesis:<p class="snippet">h.test4 &lt;- chisq.test(sample4)</p></li>
				<li>Print the test summary for the 4th hypothesis:<p class="snippet">print("Hypothesis #4 results")</p><p class="snippet">print(h.test4)</p><p>The output is as follows:</p><p class="snippet">[1] "Hypothesis #4 results"</p><p class="snippet">Pearson's Chi-squared test</p><p class="snippet">data:  sample4</p><p class="snippet">X-squared = 736.53, df = 2, p-value &lt; 2.2e-16</p></li>
				<li>Now, create a new <strong class="inline">sample5</strong> object and print the value:<p class="snippet">print("Frequency table for Contact")</p><p class="snippet">sample5 &lt;- table(df$y, df$contact)</p><p class="snippet">print(sample5)</p><p>The output is as follows:</p><p class="snippet">[1] "Frequency table for Contact"</p><p class="snippet">  cellular telephone</p><p class="snippet">no     22291     14257</p><p class="snippet">yes     3853       787</p></li>
				<li>Perform the test on the <strong class="inline">test5</strong> variable:<p class="snippet">h.test5 &lt;- chisq.test(sample5)</p></li>
				<li>Print the test summary for the 5th hypothesis:<p class="snippet">print("Hypothesis #5 results")</p><p class="snippet">print(h.test5)</p><p>The output is as follows:</p><p class="snippet">[1] "Hypothesis #5 results"</p><p class="snippet">Pearson's Chi-squared test with Yates' continuity correction</p><p class="snippet">data:  sample5</p><p class="snippet">X-squared = 862.32, df = 1, p-value &lt; 2.2e-16</p></li>
			</ol>
			<p>We can see that results have been validated in our favor. We can also see that there is definitely a relationship between student and retired clients and the cellular mode of communication with a positive outcome in the campaign.</p>
			<h3 id="_idParaDest-116"><a id="_idTextAnchor116"/>Collating Insights – Refine the Solution to the Problem</h3>
			<p>We have now traversed the length and breadth of EDA. In the different sections, we studied the data in varying levels of depth. Now that we have valid answers for the data exploration problem, we can touch base again with the initial problem defined. If you recall the <strong class="bold">complication</strong> and <strong class="bold">question</strong> section in the problem statement, we had <em class="italics">What are factors that lead to poor performance of the campaign</em>. Well, we now have an answer based on the patterns we discovered during the bivariate analysis and validated with statistical tests.</p>
			<p>Collating all the hypotheses validated with the correct story brings about the solution to our problem. Spend good time with the outcome of each of the hypothesis test results to knit the story together. Each hypothesis tells us whether an independent variable has a relationship with a dependent variable.</p>
			<h2 id="_idParaDest-117"><a id="_idTextAnchor117"/>Summary</h2>
			<p>In this chapter, we explored EDA using a practical use case and traversed the<a id="_idTextAnchor118"/> business problem. We started by understanding the overall process of executing a data science problem and then defined our business problem using an industry standard framework. With the use case being cemented with appropriate questions and complications, we understood the role of EDA in designing the solution for the problem. Exploring the journey of EDA, we studied univariate, bivariate, and multivariate analysis. We performed the analysis using a combination of analytical as well as visual techniques. Through this, we explored the R packages for visualization, that is, <strong class="inline">ggplot</strong> and some packages for data wrangling through <strong class="inline">dplyr</strong>. We also validated our insights with statistical tests and, finally, collated the insights noted to loop back with the original problem statement.</p>
			<p>In the next chapter, we will lay the foundation for various machine learning algorithms, and discuss supervised learning in depth.</p>
		</div>
	</body></html>