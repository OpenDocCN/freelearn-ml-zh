- en: Building a Cloud-Based Multibiometric Identity Authentication Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, using **IBM Watson Studio**, we will walk through the construction
    of a functioning cloud-based *human* identification system using **biometric traits**.
    We will first introduce biometrics and consider what we mean by biometric data.
    Then, we will explain the types of preprocessing needed for each biometric. Additionally,
    we will learn about the process of how to extract meaningful features from biometric
    data. Lastly, we will cover the concepts behind **multimodal data fusion**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding biometrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring biometric data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biometric recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multimodal fusion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our example
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding biometrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we start by breaking down the word itself, **biometrics** is derived from
    the Greek words **bio** (life) and **metrics** (to measure), and so biometric
    relates to the application of statistical analysis to biological data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Biometric verification** is defined as the process by which someone can be
    uniquely identified by evaluating one (or more) distinguishing biological traits.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unique identifiers typically used in the process of biometric verification
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Fingerprints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hand geometry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Earlobe geometry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retina/iris patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voice (waves)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signatures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For those of us who are *Forensic Files* fans, one of the oldest forms of biometric
    verification is fingerprinting. You can refer to the article in the following
    link for more details about how the first forensic files came into implementation:
    [http://onin.com/fp/fphistory.html](http://onin.com/fp/fphistory.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Biometric verification and authentication have advanced significantly with technology
    advancements, such as the digitization of analog data (not to mention IBM Watson!),
    which now allow for practically instantaneous personal identification to take
    place.
  prefs: []
  type: TYPE_NORMAL
- en: While it may be quite obvious that the biometric authentication process uses
    physical characteristics (fingerprinting) to digitally identify (or authenticate)
    a person, more advanced solutions may also utilize behavioral human traits (like
    voice cadence) as well.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these (characteristics) is considered unique to a particular individual,
    and, therefore, they may be used in combination (more on combining identifiers
    a bit later on in this chapter) to ensure greater accuracy of identification.
  prefs: []
  type: TYPE_NORMAL
- en: Making a case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is biometric verification such a topic of interest?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is that, in an instantaneous and ever more internet-enabled world,
    password authentication is slow and, frankly, just not good (strong) enough.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to recent popular opinion (*4 reasons why biometric security is the
    way forward*, Digitial Biometrics, AUG 2015), the following four reasons top the
    list as to why biometric verification is so important:'
  prefs: []
  type: TYPE_NORMAL
- en: The IoT landscape is becoming more complex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Passwords are not strong enough
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biometric security is more efficient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More companies and institutions are embracing biometrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Almost every one of us has had to create or choose a password and has been informed
    that the chosen phrase is weak or not strong enough. A weak password is one that
    is easy to detect both by humans or an automated process.
  prefs: []
  type: TYPE_NORMAL
- en: People frequently use guessable passwords such as the names of their children
    or their house number (so that they won't forget the password) but the simpler
    or the weaker the **password**, the easier it will be to detect or duplicate.
  prefs: []
  type: TYPE_NORMAL
- en: Biometric authentication is a more effective way to prove identity or authenticate
    someone since it cannot be simulated or replicated, and it is nearly impossible
    for hackers to manipulate the authentication process, even with the use of malware
    and other viruses.
  prefs: []
  type: TYPE_NORMAL
- en: Popular use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the *current* and practical areas where biometric authentication technologies
    are at work include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Border and immigration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Workforce management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Criminal identification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Airport security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time-keeping and attendance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Law enforcement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access control and **Single Sign On** (**SSO**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Banking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All indications are that this technology will continue to grow and mature as
    apparent in the article *Use of Biometrics Across the Globe* by John Trader of
    M2SYS Technology ([http://www.m2sys.com/blog/biometric-hardware/top-5-uses-biometrics-across-globe/amp/](http://www.m2sys.com/blog/biometric-hardware/top-5-uses-biometrics-across-globe/amp/)).
  prefs: []
  type: TYPE_NORMAL
- en: From a financial perspective, according to the **Security Industry Association**
    (**SIA**), the market for electronic access controls in the USA alone is expected
    to top 4.47 billion in 2019 (up from just over 3 billion in 2014).
  prefs: []
  type: TYPE_NORMAL
- en: To further make the case for biometric authentication, an online article, *Millennials
    Accelerating the End of the Password Era* (January 29, 2018, by Limor Kessem),
    we see that although password use is not popular, when logging into applications
    *security* is the biggest (by far) concern for users ([https://securityintelligence.com/new-ibm-study-consumers-weigh-in-on-biometrics-authentication-and-the-future-of-identity/](https://securityintelligence.com/new-ibm-study-consumers-weigh-in-on-biometrics-authentication-and-the-future-of-identity/)).
  prefs: []
  type: TYPE_NORMAL
- en: Privacy concerns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the convenience and security of biometrics comes a concern for privacy.
    For any biometric authentication solution to work, it requires a database containing
    the relevant information for each individual to be identified and authorized by
    the system. This means that every user's biometric signature would have to be
    recorded so that the solution could use the information to verify each person's
    identity. The safekeeping, ethical use, and governance of this information becomes
    critical.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the aforementioned, by their nature, biometric systems also collect
    more information than just the users' fingerprints, retinal patterns, or other
    biometric data. At a basic level, most systems will record the time and place
    a person is at the time of an authentication. This also leads to the concern over
    how and where this information could potentially be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some final words on this particular topic: a recent court ruling emphasized
    the importance of providing (prior) notice of biometric data collection and use.
    Be careful when dealing with biometrics: violating the law will most likely result
    in you or your company being sued.'
  prefs: []
  type: TYPE_NORMAL
- en: Components of a biometric authentication solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The components that make up a biometric authentication solution include the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: A sensor or other device to capture the biometrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data storage to save the biometrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A machine learning matching algorithm(s)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A decision processor or how to handle the results of the previous three
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will start exploring biometric data.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring biometric data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After reading the preceding sections of this chapter and, hopefully, understanding
    the purpose and opportunity of using biometrics data within a solution, the next
    step is a walk-through, conceptually at least, for building the solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using biometric information for authentication, we would see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Collection of biometric data**: This step uses some sort of input device
    to capture biometric data. The input of this information is typically referred
    to as biometric scanning. This scanning may be a fingerprint, the iris of the
    eye, vocal prompts, or other forms of biometric scanning (quite often photographs
    are the first biometric form that is used, since photographs are easy to understand
    and manage).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conversion, labeling, and storage of biometric data**: The data that is collected
    through scanning must then be converted into a digital format and saved in a database
    and appropriately labeled. This database stores the biometric data of individuals
    that will need to be authorized by the solution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Selection and configuration of an ML algorithm**: A **matching algorithm**
    is used to compare newly scanned data to data that is stored and labeled within
    the digital database. Upon a match, the individual is authenticated, and then
    decision logic is used to decide what the next step will be, such as granting
    access to a system or location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specific Individual identification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, biometric identification involves determining the identity of a specific
    person by comparing an individual presented (or scanned) **biometric signature**
    with that which is already cataloged in the solutions database and making a decision:
    does it or doesn''t it match? This can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf12c3a3-df26-419b-bb94-dcec65caf706.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A biometric signature can be an item obtained from the individual such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: A photo of their face
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A record of their voice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An image of their fingerprint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep in mind that **biometric data** is a general term used to refer to any
    data that is created during a **biometric** **scanning process**.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the previously mentioned, this biometric data may also include
    any samples, models, fingerprints, similarity scores, and all verification or
    identification data including the individual's name and demographics.
  prefs: []
  type: TYPE_NORMAL
- en: Also included in the individual’s signature can be palm veins, face recognition,
    DNA, palm print, hand geometry, iris recognition, retina, and odor/scent. Further,
    **behavioral characteristics** that are related to the pattern of behavior of
    an individual (for example, his or her a gait or typing rhythm) may also be part
    of the biometric database.
  prefs: []
  type: TYPE_NORMAL
- en: It should also be of note that, since biometric data is digital in format, it
    can be efficiently processed by computer systems and easily encrypted as a safeguard
    against unethical manipulation and use by unauthorized persons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another point is the submission of a single set of biometric samples to a biometric
    system for identification or verification is referred to as an attempt. For obvious
    reasons, solutions typically allow only a single attempt to identify or verify
    an individual. Attempts made by individuals who do not have a cataloged biometric
    signature previously scanned and cataloged within the solutions database will
    fail authentication. This is significant since it reduces the amount of data needing
    to be scanned and cataloged for the solution to work: you only need to establish
    digital signatures for those individuals that do need to be authenticated and
    granted access.'
  prefs: []
  type: TYPE_NORMAL
- en: The Challenge of Biometric Data Use
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Collecting, cataloging, and using biometric data can be a challenge. This form
    of data is, like most data, subject to uncertainty and variation. Perhaps unique
    to biometric data, we see that this information may be affected by changes in
    an individual's age, environmental influences, disease, stress, occupational factors,
    training and prompting, intentional alterations, sociocultural aspects of the
    situation in which the presentation occurs, changes in human interface with the
    system, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, each interaction or attempt of an individual may be associated
    with different biometric information.
  prefs: []
  type: TYPE_NORMAL
- en: Sample sizing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml), *Creating a Facial
    Expression Platform on IBM Cloud* , we constructed an expression analysis model
    using facial images for the model to train on and use to detect human emotions:
    happiness, sadness, and anger. In that exercise, we chose a sample size for each
    emotion of just 11 images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/263dc466-cf1c-40c3-8536-38b73ddf24f8.png)'
  prefs: []
  type: TYPE_IMG
- en: In that exercise, the sample size (11) was sufficient since the goal was to
    prove our concept. Obviously, the bigger the sample size the more accurate the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: A **biometric authentication** solution works on the same premise; however,
    rather than detecting emotion from an attempt, the model will compare the *scanned*
    image to its cataloged database, looking for a match. Since the scanned image
    will not be one that is in the database, the matching algorithm must compare the
    databased images and detect the individual based upon its facial recognition and
    evaluation logics. If there is simply one image of each authenticated user within
    the database, the margin for error increases. Therefore, how many images (for
    each user) are needed? What is the optimal sample size (for a biometric authentication
    solution) to be used?
  prefs: []
  type: TYPE_NORMAL
- en: Biometric system performance is typically evaluated by collecting biometric
    templates (or biometric signatures) from *n* different subjects, and, for convenience,
    acquiring multiple instances of that biometric (for example, photographs) for
    each of the *n* subjects.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, you most likely found that there isn't much work available to
    date on constructing confidence regions based on the **Receiver Operating Characteristic
    (ROC)** curve for validating the claimed performance levels and determining the
    required number of biometric samples needed to establish confidence regions of
    prespecified width for the ROC curve.
  prefs: []
  type: TYPE_NORMAL
- en: ROC is widely used to determine how a predictive model can distinguish between
    true positives and negatives. To accomplish this task, a model needs to correctly
    predict not only a positive as a positive but also a negative as a negative.
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Biometric feature extraction (also sometimes named minutia extraction) refers
    to the process by which established *key* features of a sample are selected or
    enhanced for more efficient processing. Typically, the process of feature extraction
    relies on a set of algorithms that varies depending on the type (face image or
    fingerprints, for example) of biometric identification used.
  prefs: []
  type: TYPE_NORMAL
- en: Biometric authentication is the matching of samples that have been converted
    (previously or upon attempt) from, for example, an image of a biometric trait
    into a searchable set of data. This conversion is the process known as feature
    extraction.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look for example of how feature extraction fundamentally works, you
    see that it depends upon the type of sample, but is, for the most part, quite
    easy to conceptualize. You can head over to the following link to know more on
    how a biometric matching works: [http://devtechnology.com/2013/11/emerging-biometric-technology-revocable-biometric-features/](http://devtechnology.com/2013/11/emerging-biometric-technology-revocable-biometric-features/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some other examples of biometric feature extraction can also be referred to
    the article in the following link: [http://arindamcctvaccesscontrol.blogspot.com/2010/05/access-control-index-terminology.html](http://arindamcctvaccesscontrol.blogspot.com/2010/05/access-control-index-terminology.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Biometric recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A biometric recognition and ultimately a successful authentication depend upon
    the robustness of the selected machine learning algorithm used within the solution
    but also on (as we discussed in the *Feature extraction* section of this chapter)
    the sample size.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these requirements, it is important to consider the quality of
    the samples as well as the type. Poor image quality, for example, can significantly
    impact the accuracy of a biometric authentication. We also briefly mentioned using
    **behavioral traits** as part of a biometric signature.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking though, **physiological characteristics** (such as a fingerprint
    or facial picture, for instance) are always the most static, showing little dissimilarity
    over time, while **behavioral characteristics** (that is, a gait or cadence) can
    and usually do experience variations, and can be prejudiced by external factors
    or by particular emotional conditions such as stress or strong psychological impacts.
  prefs: []
  type: TYPE_NORMAL
- en: Interesting **behavioral** **characteristics** already in use by some biometric
    authentication solutions include vocal imprints, writing and/or typing style,
    movements of the body, the style and the trend of walk, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal fusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most simply put, the more gates surrounding an individual's property, the more
    secure it will be, since we would need to possess the ability to successfully
    pass more than a single test to proceed. The same applies to any system or solution
    that makes a decision to proceed based upon the outcome of a test (match or no-match).
    Adding additional tests produces additional outcomes and additional decisions
    based upon those outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Biometric authentication solutions are typically considered unimodal (conducts
    only a single test) or multimodal (conducts more than a single test):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multimodal biometric authentication**: This describes an implemented solution
    that utilizes multiple biometric indicators for identifying the authenticated
    individuals, such as a photo/image and a signature. A successful match of both
    biometrics is required to succeed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unimodal biometric authentication**: This describes a solution that utilizes
    only a single level of authentication, such as only a photo/image or a signature.
    In this case, if the solution matches successfully to the biometric (for example,
    and image) the attempt is successful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have an idea and understanding of just what a biometric authentication
    solution is and how it works, we will try to build a simple but actually working
    prototype using the same **IBM Watson Visual Recognition service** we used in
    [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml), *Creating a Facial Expression
    Platform on IBM Cloud*, as well as that project as a guide for our new solution.
  prefs: []
  type: TYPE_NORMAL
- en: As a reminder, the IBM Watson Visual Recognition service understands the image
    content out-of-the-box (we demonstrated this in our [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml),
    *Creating a Facial Expression Platform on IBM Cloud* project). The pretrained
    models provided enable you to analyze images for objects, faces, colors, food,
    explicit content, and other subjects for insights into your visual content. We
    successfully used the service to detect faces and then determine expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Premise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The general premise will be to clone our [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml),
    *Creating a Facial Expression Platform on IBM Cloud*, project and create a class
    or classes to be used as a simple biometric signature for myself; one loaded with
    a dozen images of, well, my face, as well as a negative class loaded with a dozen
    images of random faces (none will be of me).
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, there will be at least one other class, designed to be a biometric
    signature of another individual. So we expect that, in this chapter''s project,
    we will have the following three classes:'
  prefs: []
  type: TYPE_NORMAL
- en: Jim class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Individual two or other classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The final step will be to use a mobile device to take several photos of myself
    and others and, without preparation or any processing of the images, submit the
    facial images to our project and record the results: matched or not matched. These
    image submissions will be considered our attempts for biometric authentication.'
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps to test the project fairly, we will need to be sure to submit several
    images of myself (none of which would be part of the model's class definitions
    my biometric signature) and several faces that are not mine and record the results
    of each submission.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will evaluate and record the results.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Straightaway, we need to have a sample of 10 images of my face. The images should
    be of reasonable quality and, for best results, close-up photos taken over a period
    of time so that the algorithm can have some accounting for variances in my appearance.
  prefs: []
  type: TYPE_NORMAL
- en: If you have forgotten, you can review [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml),
    *Creating a Facial Expression Platform on IBM Cloud,* for the specific file image
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the images that will be used to create my biometric signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e180569-c5ed-401c-aee3-a53c6d764d51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we need to establish a biometric signature (with the same size sample)
    for another individual:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/545ddb3a-30b1-4803-a058-95c8ca098157.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, the negative class of 10 random faces (of course, borrowed from our
    project) needs to be set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29ea8706-1f29-459a-b9ff-e62e4516f65d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A reminder from Watson docs: The **create a classifier** call requires that
    you provide at least two example ZIP files: two positive examples files or one
    positive and one negative file. The negative examples defines what the updated
    classifier is not. It is not used to create a class within the created classifier.
    Negative example files will contain images **that do not match the subject of
    any of the positive examples**. In a single call, there can be only one single
    example specified.'
  prefs: []
  type: TYPE_NORMAL
- en: Project setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once again, we will assume that we have already created a new IBM Watson Studio
    project and now (as in [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml),
    *Creating a Facial Expression Platform on IBM Cloud*) add a new visual recognition
    model by going to the Assets tab and under Models, click on New Visual Recognition
    model (you can go back to [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml),
    *Creating a Facial Expression Platform on IBM Cloud,* for a quick review).
  prefs: []
  type: TYPE_NORMAL
- en: Just like in [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml), *Creating
    a Facial Expression Platform on IBM Cloud,* once the model is created (it should
    take only a few moments), you can drag and drop the image `.zip` files we prepared
    in the preceding sections of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will upload the image files to **Cloud Object Storage** (**COO**), making
    them available to be used in our project (as shown in the following screenshot):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b573a9c-4e4d-4929-b5d8-5edec44e772f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the Default Custom Model screen (in the following screenshot), we are
    ready to build our model classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0867f42-5b0d-42f3-b49c-bb2c5cb8d685.png)'
  prefs: []
  type: TYPE_IMG
- en: Creating classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can now click on the Create a class button (shown on the bottom left in
    the following screenshot) to create both the Jim and Other classes (remember,
    the Negative class is already created for you):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/847968ed-1434-45ec-996d-773d11d6aa3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Again, you can refer back to [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml),
    *Creating a Facial Expression Platform on IBM Cloud,* to the *Creating Classes
    for Our Model* section for the step-by-step instructions for creating classes.
  prefs: []
  type: TYPE_NORMAL
- en: Training the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have our three classes created (and loaded with images) and saved,
    and the model status shows Ready to train, we can then click on the Train Model
    button to start training the model on the images we provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dd2e7694-c322-48ef-a626-67864320efd9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once more, this is a small model with only 30 training images; the training
    process will take less than 5 or 10 minutes. Part of the beauty of using IBM Watson
    and services is that many of the "detailed tasks" like creating model definitions
    and training a model is simply a "button click". To learn more about training
    a visual recognition model, you can visit:'
  prefs: []
  type: TYPE_NORMAL
- en: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/visual-recognition-train.html?linkInPage=true
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the model training has been completed and you notice (see the following
    screenshot) that the model status says Trained, you can proceed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d08e02f2-88dc-45f3-ac44-e925bd7a2daa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Just as we did in [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml),
    *Creating a Facial Expression Platform on IBM Cloud,* to test and validate our
    model, we can upload images in the Test area of the Default Custom Model page,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/48e08013-2c97-4c76-8fb3-82ac202c9246.png)'
  prefs: []
  type: TYPE_IMG
- en: Testing our project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just as we have planned, the final step of our project exercise is to use a
    mobile device to take several photos of myself and others and, without preparation
    of the images, submit the facial images to our project for authentication and
    record the results: matched or not matched.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using my smartphone, I took the following three head shots. I tried to capture
    a variation in lighting and expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/624b1f02-df8f-4725-b505-36bcd7662b3d.png)'
  prefs: []
  type: TYPE_IMG
- en: In addition, as we stated earlier, to test our project fairly, we need to submit
    several images of faces that are not mine and record the results of each submission
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'For these test subjects, I collected the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/373b0dc4-0637-43e4-9d48-efdef1bc3520.png)'
  prefs: []
  type: TYPE_IMG
- en: Now it's testing time!
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see in the following screenshot, I submitted the first four images:
    Jim, Jim, Jim, and other. The model correctly authenticated each image that was
    submitted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d8cd12f7-557b-46fe-9ff9-b15732154c27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'That''s pretty good, right? Now we can submit the fourth and final image (*not*
    Jim and *not* other) and zoom in on all of the scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fbfd6a9c-9f85-420d-93f7-fcb9544468cb.png)'
  prefs: []
  type: TYPE_IMG
- en: Guidelines for good training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have now created a simple biometric authentication proof of concept using
    IBM Watson Studio and the IBM Watson Visual Recognition service. It works but
    of course this is not ready for deployment. There are many things to consider
    before a model is ready for deployment and production use. For example, guidelines
    provided with the Visual Recognition service state that it is best practice to
    include at least 50 positive images *per class* before you can begin to realistically
    assess your training results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other recommendations provided include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Assuming similar quality and content for your training data, more training images
    generally provide more accurate results than fewer images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 150 to 200 images per `.zip` file provides the best balance between processing
    time and accuracy. More than 200 images will increase the time and the accuracy,
    but with diminishing returns for the amount of time it takes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To the right of the Test tab is the Implementation tab (shown in the following
    screenshot). From here, you can see the the code snippets provided for you by
    Watson to classify images against the model you just built:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1db89612-9d62-41bf-847c-045269acaffd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For reference, the full API specification you will need to deploy the model
    is available here: [https://cloud.ibm.com/apidocs/visual-recognition](https://cloud.ibm.com/apidocs/visual-recognition).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced and discussed collecting and using biometric
    data in a biometric authentication solution, how such a solution works as well
    as feature extraction (in regard to biometric data solutions) was the idea of
    multimodal fusion. Finally, we expanded the expression detection and analysis
    solution from [Chapter 8](4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml), *Creating
    a Facial Expression Platform on IBM Cloud*, again using the IBM Watson Visual
    Recognition service, to create a working biometric authentication solution proof
    of concept.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter concludes this book with an overview of what we have covered.
    The chapter will also shed some light on some of the practical considerations
    related to developing machine learning systems on the cloud with IBM Watson Studio.
  prefs: []
  type: TYPE_NORMAL
