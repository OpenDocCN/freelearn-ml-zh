<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Introduction to Computer Vision</h1>
                
            
            <article>
                
<p class="calibre2">Without a doubt, computer science, and especially the approach to implementing algorithms, has developed rapidly over the years. This is due to the fact that your personal computer and even the smartphone in your pocket are much faster and a lot cheaper than their predecessors. One of the most important fields in computer science that has been impacted by this change is the field of computer vision. The way computer vision algorithms are implemented and used has seen a dramatic change in recent years. This book, starting with this introductory chapter, is an effort to teach computer vision algorithms using the most up-to-date and modern technologies that are used to implement them.</p>
<p class="calibre2">This is intended as a brief introductory chapter that lays out the foundation of concepts that will be used in many, if not all, of the computer vision algorithms available. Even if you are already familiar with computer vision and the basics, such as images, pixels, channels, and so on, it is still a good idea to go through this chapter briefly to make sure that you understand the fundamental concepts of computer vision and to refresh your memory.</p>
<p class="calibre2">In this chapter, we'll be starting with a brief introduction to the field of computer vision. We'll go through some of the most important industries where computer vision is used, with examples. After that, we'll directly dive into some basic computer vision concepts, starting with images. We'll learn what images are in terms of computer vision and what their building blocks are, too. During this process, we'll cover concepts such as pixels, depth, and channels, all of which are crucial to understanding and successfully working hands-on with computer vision algorithms.</p>
<p class="calibre2">By the end of this chapter, you will have learned about the following:</p>
<ul class="calibre10">
<li class="calibre11">What computer vision is and where it is used?</li>
<li class="calibre11">What an image is in terms of computer vision?</li>
<li class="calibre11">Pixels, depth, and channels and their relationships</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Technical requirements</h1>
                
            
            <article>
                
<p class="calibre2">As this is an introductory chapter, we are focusing solely on theory. There are, therefore, no technical requirements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Understanding computer vision</h1>
                
            
            <article>
                
<p class="calibre2">Defining computer vision is not an easy task, and computer vision experts tend to disagree with each other when it comes to providing a textbook definition for it. Doing so is completely out of the scope and interest of this book, so we'll focus on a simple and practical definition that suits our purpose instead. Historically, computer vision has been synonymous with image processing, which essentially refers to the methods and technologies that take an image as input and produce an output image or a set of output values (or measurements) based on that input image, which is done after performing a set of processes. Fast forward to now and you'll notice that, when computer vision engineers talk about computer vision, what they mean, in most cases, is a concept relating to an algorithm that is able to mimic human vision, such as seeing (detecting) an object or a person in an image.</p>
<p class="calibre2">So, which definition are we to accept? The answer is quite simple—both. To put it in just a few words, computer vision refers to the algorithms, methods, and technologies that deal with digital visual data (or any data that can be visualized) in any way imaginable. Note that visual data in this sense does not mean just images taken using conventional cameras, but they might be, for instance, a graphical representation or elevation on a map, a heat intensity map, or any data that can be visualized regardless of its real-world meaning.</p>
<p class="calibre2">With this definition, all of the following questions—as well as many more—can be solved with computer vision:</p>
<ul class="calibre10">
<li class="calibre11">How do we soften or sharpen an image?</li>
<li class="calibre11">How do we reduce the size of an image?</li>
<li class="calibre11">How do we increase or decrease the brightness of an image?</li>
<li class="calibre11">How do we detect the brightest region in an image?</li>
<li class="calibre11">How do we detect and track a face in a video (or a series of consecutive images)?</li>
<li class="calibre11">How do we recognize faces in a video feed from a security camera?</li>
<li class="calibre11">How do we detect motion in a video?</li>
</ul>
<div class="packt_infobox">In modern computer vision science, image processing is usually a subcategory of computer vision methods and algorithms dealing with image filtering, transformation, and so on. Still, many use the terms computer vision and image processing interchangeably.</div>
<p class="calibre2">In this day and age, computer vision is one of the hottest topics in the computer science and software industry. The reason for this lies in the fact that it is used in a variety of ways, whether it's bringing to life the ideas for applications, digital devices, or industrial machines that handle or simplify a wide range of tasks that are usually expected from the human eye. There are a lot of working examples for what we just mentioned, which vary across a wide spectrum of industries, including the automotive, motion picture, biomedical devices, defense, photo editing and sharing tools, and video game industries. We are going to talk about just a couple of these examples and leave the rest of them for you to research.</p>
<p class="calibre2">Computer vision is used persistently in the automotive industry to improve the safety and functionality of modern vehicles. Vehicles are able to detect traffic signs and warn the driver about a speed limit breach or even detect lanes and obstacles on the road and notify drivers about possible hazards. There is no end to the number of practical examples we can present about how computer vision can be used to modernize the automotive industry—and that's without touching on self-driving cars. Major tech companies are investing a huge amount of resources and are even sharing some of their achievements with the open source community. As you'll see in the final chapters of this book, we'll make use of some of them, especially for the real-time detection of multiple objects of multiple types.</p>
<p class="calibre2">The following image depicts some of the objects, symbols, and areas of interest for the automotive industry, as images that are commonly seen through the cameras mounted on vehicles:</p>
<div class="cdpaligncenter"><span><img src="../images/00005.jpeg" class="calibre18"/></span></div>
<p class="calibre2">Another great example of an industry on the verge of a technological revolution is the biomedical industry. Not only have the imaging methods of human organs and body parts undergone a great deal of enhancement, but the way these images are interpreted and visualized has also been improved by computer vision algorithms. Computers are used to detect cancerous tissues in images taken by microscopes with an extremely high level of precision. There are also promising and emerging results from robots that are able to perform surgery, for example.</p>
<p class="calibre2">The following image is an example of using computer vision to count a specific type of biological object of interest (cells, in this case) in various areas of tissue, scanned by a digital microscope:</p>
<div class="cdpaligncenter"><span><img src="../images/00006.jpeg" class="calibre19"/></span></div>
<p class="calibre2">Besides the automotive and biomedical industries, computer vision is also used in thousands of mobile and desktop applications to perform many different tasks. It's a good idea to browse through online application stores on your smartphone to view some computer vision-related application examples. Do so, and you'll immediately realize that there is literally nothing but your imagination standing between you and your potential computer vision application ideas.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Learning all about images</h1>
                
            
            <article>
                
<p class="calibre2">Now, it's time to cover the basics of computer vision, starting with images. So, what exactly is an image? In terms of computer vision, an image is simply a matrix, or in other words a 2D vector, with a valid number of rows, columns, and so on. This way of looking at an image simplifies not just the description of an image itself, but also all of its components, which are as follows:</p>
<ul class="calibre10">
<li class="calibre11">The width of an image corresponds to the number of columns in the matrix.</li>
<li class="calibre11">The height of the image is the number of rows in the matrix.</li>
<li class="calibre11">Each element of the matrix represents a pixel, which is the most basic component of an image. An <strong class="calibre1">image</strong> is a collection of pixels.</li>
<li class="calibre11">Each pixel, or each element in the matrix, can contain one or more numeric values that correspond to the visual representation (color, brightness, and so on) of it. We'll learn more about this later when we talk about color spaces in computer vision. However, it's important to note that each numeric value associated with a pixel represents a channel. For instance, pixels in a grayscale image are commonly represented using a single unsigned 8-bit integer value that varies between 0 and 255; thus, a grayscale image is a single-channel image. In this form of representation, 0 represents black and 255 represents white, while all other numbers correspond to a grayscale value. Another example is standard RGB image representation, in which each pixel is represented by three unsigned 8-bit integer values that vary between 0 and 255. The three channels representing each pixel in RGB images correspond to the intensity values of red, blue, and green, which in combination can form any possible color. Such an image is known as a <strong class="calibre1">three-channel image</strong>.</li>
</ul>
<p class="calibre2">The following image depicts two zoomed-in versions of the same area from the same image in both a grayscale and colored (RGB) format. Notice how higher values in the grayscale image (on the left-hand side) correspond to brighter values and vice versa. Similarly, in the color image (on the right-hand side), you can see that the value of the red channel is quite high, which is consistent with the reddish color of that area, as well as the white channels:</p>
<div class="cdpaligncenter"><img src="../images/00007.jpeg" class="calibre20"/></div>
<p class="calibre2">In addition to what we mentioned previously, an image has a few more specifications, which are as follows:</p>
<ul class="calibre10">
<li class="calibre11">Each pixel, or an element of the matrix, can be an integer or a floating-point number. It can be an 8-bit number, 16-bit, and so on. The type of the numeric value representing each pixel in conjunction with the number of channels resembles the depth of an image. For instance, a four-channel image which uses a 16-bit integer value to represent each channel would have a depth of 16 multiplied by 4-bits, or 64-bits (or 4 bytes).</li>
<li class="calibre11">The resolution of an image refers to the number of pixels in it. For instance, an image which has a width of 1920 and height of 1080 (as is the case in full-HD images) has a resolution of 1920 multiplied by 1080, which is a bit more than 2 million pixels, or about 2 megapixels.</li>
</ul>
<p class="calibre2">It is all because of this form of representation of an image that it can be easily perceived as a mathematical entity, meaning many different types of algorithms can be designed to act or work on images. If we go back to the simplest representation of an image (a grayscale image), with a few simple examples we can see that most picture editing software (and computer vision algorithms) use this representation along with fairly simple algorithms and matrix operations to modify the image with ease. In the following image, a constant number (80, in our example) is simply added to each pixel in the input image (the middle image), which has made the resulting image brighter (the right-hand image). A number can also be subtracted from each pixel to make the resulting image darker (the left-hand image):</p>
<div class="cdpaligncenter"><span><img src="../images/00008.gif" class="calibre21"/></span></div>
<div class="packt_infobox">For now, we'll only focus on the basic concepts of computer vision and not go into the implementation details of the preceding image modification example. We'll learn about this and many more image processing techniques and algorithms in the upcoming chapters.</div>
<p class="calibre2">The image properties mentioned in this section (width, height, resolution, depth, and channels) are extensively used in computer vision. For instance, in several cases, if an image processing algorithm is too complex and time-consuming, then the image can be resized to make it smaller so that less time is used to process it. Once processed, the results can then be mapped back to the original image size and displayed to the user. The same process also applies to depth and channels. If an algorithm only needs a specific channel of an image, you can either extract and process it separately or use the grayscale-converted version of an image. Note that, once the object detection algorithm has completed its job, you'll want to display the results over the original colored image. Having a correct understanding of these kinds of image properties will help you a lot when confronting various computer vision problems and when working with computer vision algorithms. Without further ado, let's move on to color spaces.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Color spaces</h1>
                
            
            <article>
                
<p class="calibre2">Although its definition can vary, in general, a color space (sometimes referred to as a color model) is a method that is used for interpreting, storing, and reproducing a set of colors. Let's break this down with an example—a grayscale color space. In a grayscale color space, each pixel is represented with a single 8-bit unsigned integer value that corresponds to brightness or gray-intensity of that pixel. This makes it possible to store 256 different levels of grayscale, in which zero corresponds to absolute black and 255 corresponds to the absolute white. In other words, the higher the value of a pixel, the brighter it is, and vice versa. The following image displays all possible colors that exist within the grayscale color space:</p>
<div class="cdpaligncenter"><span><img src="../images/00009.gif" class="calibre22"/></span></div>
<p class="calibre2">Another commonly-used color space is RGB, in which each pixel is represented by three different 8-bit integer values that correspond to the red, green, and blue color intensity of that pixel. This color space is particularly known for being used in TVs, LCDs, and similar displays. You can check this out for yourself by looking at the surface of your monitor using a magnifier. It relies on the simple fact that all colors can be represented by combining various amounts of red, green, and blue. The following image depicts how all other colors (such as yellow or pink) between the three main colors are formed:</p>
<div class="cdpaligncenter"><span><img src="../images/00010.jpeg" class="calibre23"/></span></div>
<div class="packt_infobox">An RGB image that has the same R, G, and B values in each of its individual pixels would result in a grayscale image. In other words, the same intensity of red, green, and blue would result in a shade of gray.</div>
<p class="calibre2">Another color space that is widely used in computer vision is the <strong class="calibre4">HSV</strong> (<strong class="calibre4">Hue</strong>, <strong class="calibre4">Saturation</strong>, and <strong class="calibre4">Value</strong>) color space. In this color space, each pixel is represented by three values for hue (the color), saturation (the color strength), and value (how bright or dark it is). Hue, as seen in the following image, can be a value between 0 and 360 (degrees), which represents the color of that pixel. For instance, zero and nearby degrees correspond to red and other similar colors:</p>
<div class="cdpaligncenter"><span><img src="../images/00011.jpeg" class="calibre24"/></span></div>
<p class="calibre2">This color space is especially popular in computer vision detection and tracking algorithms that are based on the color of an object, as you'll see later on in this book. The reason for this is that the HSV color space allows us to work with colors regardless of how dark or bright they are. This is not easy to achieve with RGB and similar color spaces, as looking at an individual pixel channel value cannot tell us its color.</p>
<p class="calibre2">The following image is another representation of the HSV color space, which shows the variation of hue (from left to right), saturation, and value in one image, thus producing all possible colors:</p>
<div class="cdpaligncenter"><span><img src="../images/00012.jpeg" class="calibre25"/></span></div>
<p class="calibre2">Besides the color spaces mentioned in this section, there are many other color spaces, each with their own use cases. For instance, the four channel <strong class="calibre4">CMYK</strong> color space (<strong class="calibre4">Cyan</strong>, <strong class="calibre4">Maroon</strong>, <strong class="calibre4">Yellow</strong>, and <strong class="calibre4">Key</strong>/<strong class="calibre4">Black</strong>) has proven to be most effective in printing systems.</p>
<p class="calibre2">Make sure to learn about other popular color spaces from the internet and how they might be useful for any particular computer vision problem.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Input, process, and output</h1>
                
            
            <article>
                
<p class="calibre2">So, now that we know images are basically matrix-like entities that have essential properties such as width, height, element type, channels, depth, and so on, the only big question that remains is where do they come from, what happens to them, and where do they go?</p>
<p class="calibre2">Let's break this down further with a simple photo gallery application as an example. Odds are, you have a smartphone that contains such an application by default. A photo gallery application usually allows you to take new pictures or videos using the built-in camera on your smartphone, use the previously-recorded files, apply filters on images, and even share them on social media, via email, or with your friends and family. This example, though it might look like a simple application when you are using it, contains all the crucial parts of a proper computer vision application.</p>
<p class="calibre2">By taking this example as a pretext, we can say that images are provided by a wide range of different input devices based on the use case. Some of the most common image input devices are as follows:</p>
<ul class="calibre10">
<li class="calibre11">Image files stored on a disk, memory, a network, or any other accessible location. Note that stored image files can be raw (containing the exact image data) or encoded (such as JPG); nevertheless, they're still considered image files.</li>
<li class="calibre11">Images captured by cameras. Note that cameras in this sense mean webcams on a personal computer, cameras on a smartphone, or any other professional photography device, digital microscope, telescope, and so on.</li>
<li class="calibre11">Consecutive or non-consecutive frames from a video file that are stored on a disk, memory, a network, and so on. Similar to image files, video files can be encoded, in which case a special type of software (called a <strong class="calibre1">codec</strong>) is needed to encode them before they can be used.</li>
<li class="calibre11">Consecutive frames from a live video camera feed.</li>
</ul>
<p class="calibre2">After an image is read using an input device, the actual processing of it starts. This is probably the part of the computer vision process cycle that you are looking for in this book —and for good reason. This is where actual computer vision algorithms are used to extract values from an image, modify it in one way or another, or perform any type of computer vision task in general. This part is usually done by software on a given device.</p>
<p class="calibre2">Now, the output of this whole process needs to be created. This part completely depends on the computer vision algorithm and the type of device that the computer vision process is running on, but in general, the following types of outputs are expected from computer vision algorithms:</p>
<ul class="calibre10">
<li class="calibre11">Numbers, shapes, graphs, or any other non-image type of output that is derived from the processed image. For instance, an algorithm that counts the number of people in an image needs to only output a single integer number or a graph representing the number of people that are found in consecutive video frames from a security camera.</li>
<li class="calibre11">Images or video files stored on a disk, memory, and similar devices. A typical example of this is the photo editing software on your phone or personal computer that allows you to record the modified image as a JPG or PNG file.</li>
<li class="calibre11">Images and video frames drawn and rendered on a display screen. Displays are usually controlled with a firmware (which might be on an operating system) that controls whatever is being shown on them.</li>
</ul>
<p class="calibre2">Similar to input devices, a slightly different interpretation of an image output device will yield more results and entries (such as printers, plotters, video projectors, and so on). However, the preceding list is still sufficient as it covers the most basic and crucial types of output we'll be dealing with when working with computer vision algorithms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Computer vision frameworks and libraries</h1>
                
            
            <article>
                
<p class="calibre2">In order to build computer vision applications, we need a set of tools, a framework, or a library that supports the input, output, and the processing of images. The choice of a computer vision library is a very important one because you might end up in a position where you'll need to <em class="calibre7">reinvent the wheel</em> all by yourself. You may also end up writing functions and codes that will take up a lot of your resources and time, such as reading or writing an image in the format that you require.</p>
<p class="calibre2">In general, there are two main types of computer vision libraries that you can choose from when developing computer vision applications; they are as follows:</p>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">Proprietary</strong>: <span>Proprietary computer vision libraries are usually well-documented and supported by the companies providing it, but they come at a price and are often aimed at a specific set of computer vision problems</span></li>
<li class="calibre11"><strong class="calibre1">Open source</strong>: Open source libraries, on the other hand, usually cover a much wider range of computer vision related issues and they are free to use and explore</li>
</ul>
<p class="calibre2">You can search for many good examples of both proprietary and open source computer vision libraries online to compare them for yourself.</p>
<p class="calibre2">The library that we'll be using throughout this book is the <strong class="calibre4">Open Source Computer Vision</strong> library (<span class="calibre12"><strong class="calibre4">OpenCV</strong>). OpenCV</span> is a computer vision library with the following features:</p>
<ul class="calibre10">
<li class="calibre11">It is open source and free for use on academic or commercial projects</li>
<li class="calibre11">It supports C++, Python, and Java languages</li>
<li class="calibre11">It is cross-platform, which means it can be used to develop applications for Windows, macOS, Linux, Android, and iOS</li>
<li class="calibre11">It is built in a modular fashion and it is fast, well-documented, and well-supported</li>
</ul>
<p class="calibre2">It is worth noting that OpenCV also uses a few third-party libraries to take care of various computer vision tasks. For instance, the FFmpeg library is used within OpenCV to deal with reading certain video file formats.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we introduced the most basic concepts of computer vision science. We started the chapter by learning about computer vision as a term and its use cases, before taking a look at some of the industries that make extensive use of it. Then, we moved on to learn about images and their most crucial properties, namely pixels, resolution, channels, depth, and so on. We then discussed some of the most widely-used color spaces and learned how they affect the number of channels and other properties of an image. After that, we were presented with the common input and output devices used in computer vision and how computer vision algorithms and processes fit between the two. We ended the chapter with a very brief discussion on computer vision libraries and introduced our computer vision library of choice, which is OpenCV.</p>
<p class="calibre2">In the next chapter, we'll introduce the OpenCV framework and start with some hands-on computer vision lessons. We'll learn how OpenCV can be used to access input devices, perform computer vision algorithms, and access output devices to display or record results. The next chapter will be the first real hands-on chapter in the book and will set us up for later, more practical chapters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Questions</h1>
                
            
            <article>
                
<ol class="calibre14">
<li value="1" class="calibre11">Name two industries, besides the ones mentioned in this chapter, that can significantly benefit from computer vision.</li>
<li value="2" class="calibre11">What would be an example of a computer vision application used for security purposes? (Think about an idea for an application you haven't come across.)</li>
<li value="3" class="calibre11">What would be an example of a computer vision application used for productivity reasons? (Again, think about an idea for an application that you haven't come across, even though you might suspect that it exists.)</li>
<li value="4" class="calibre11">How many megabytes would be needed to store a 1920 x 1080 image with four channels and a depth of 32-bits?</li>
<li value="5" class="calibre11">Ultra-HD images, also known as 4K or 8K images, are quite common nowadays, but how many megapixels does an ultra-HD image contain?</li>
<li value="6" class="calibre11">Name two commonly-used color spaces besides the ones mentioned in this chapter.</li>
<li value="7" class="calibre11">Compare OpenCV libraries with computer vision tools in MATLAB. What are the pros and cons of each?</li>
</ol>


            </article>

            
        </section>
    </body></html>