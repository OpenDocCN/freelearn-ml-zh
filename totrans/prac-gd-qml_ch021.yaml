- en: Chapter 12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quantum Generative Adversarial Networks
  prefs: []
  type: TYPE_NORMAL
- en: '*Fake it ‘till you make it*'
  prefs: []
  type: TYPE_NORMAL
- en: — Someone, somewhere
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have only dealt with quantum machine learning models in the context
    of supervised learning. In this final chapter of our QML journey, we will discuss
    the wonders and mysteries of a QML model that will lead us into the domain of
    unsupervised learning. We will discuss quantum versions of the famous **Generative
    Adversarial Networks** (often abbreviated as **GANs**) that are called **Quantum
    Generative Adversarial Networks**, **quantum GANs**, or **QGANs**.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn what classical and quantum GANs are, what they
    are useful for, and how they can be used. We will begin from the basics, exploring
    the intuitive ideas that lead to the concept of a GAN. Then, we will get into
    some of the details and discuss QGANs. In particular, we will talk about the different
    types of QGANs out there and their (possible) advantages. You will also learn
    how to work with them using PennyLane (with its TensorFlow interface) and Qiskit.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: GANs and their quantum counterparts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantum GANs in PennyLane
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantum GANs in Qiskit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Excited about this last chapter? Let’s begin by understanding what these GANs
    are all about.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1 GANs and their quantum counterparts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quantum GANs are **generative models** that can be trained in a perfectly unsupervised
    manner. By the fact that they are generative models we mean that quantum GANs
    will be useful for generating data that can mimic a training dataset; for instance,
    if you had a large dataset with pictures of people, a good generative model would
    be able to generate new pictures of people that would be indiscernible from those
    coming from the original distribution. The fact that QGANs can be trained in an
    unsupervised fashion simply means that our datasets will not have to be labeled;
    we won’t have to tell the generator whether its output is good or bad, the model
    will figure that out on its own. How exactly? Stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: That’s the big picture of GANs, but, before we can explore all their details,
    there’s something we need to talk about. Let’s talk about how to counterfeit money.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1.1 A seemingly unrelated story about money
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Of course, all of us reading these lines are law-abiding citizens — no need
    to call the police just now — but, for the purposes of intellectual illustration,
    let’s put ourselves in the place of the bad guys for one day. In the process of
    counterfeiting money, there are two main actors involved:'
  prefs: []
  type: TYPE_NORMAL
- en: We, the bad guys who create (generate) counterfeit money, trying to make it
    as close to the real thing as possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some authority, usually a central bank, which is in charge of designing tools
    and techniques to discern real money from counterfeit money
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is shown in *Figure* [*12.1*](#Figure12.1). By the way, we have drawn the
    fake dollar ourselves. Graphic design is our passion.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1: Schematic representation of the agents involved in the generation
    of counterfeit money](img/file1438.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.1**: Schematic representation of the agents involved in the generation
    of counterfeit money'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are all set, we can imagine what our counterfeiting career could
    look like. Since none of us has any experience in this field, our first attempts
    at faking banknotes would be extremely disastrous: any of our generated banknotes
    would be very easily identified as fake by the central bank. However, that would
    just be the beginning of the story. Along the process — and assuming we didn’t
    get arrested — we could always try to study how the central bank is discerning
    real notes from counterfeit ones and use it to our advantage by trying to fool
    its detection mechanisms. Naturally, however, that would only be a temporary solution,
    for it wouldn’t take long for the central bank to notice our improved fake notes
    and design better detection systems, which would take us back to the drawing board,
    starting the process all over again.'
  prefs: []
  type: TYPE_NORMAL
- en: Banknotes have a finite amount of defining features, so, after a large enough
    number of iterations of this process, at some point, we would likely end up producing
    banknotes that would be identical to the real ones. And, thus, a beautiful equilibrium
    would be reached in which the central bank would no longer be able to detect our
    fake notes. Sadly for us, this adventure would most surely end with the central
    bank changing the notes completely and sending us before a judge. But let’s ignore
    those tiny details!
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Just in case it wasn’t obvious, we are joking when we talk about imagining ourselves
    doing counterfeiting. Counterfeiting money is, as you hopefully know, a serious
    criminal offense that we, of course, don’t encourage or endorse in any way. Please,
    don’t do illegal stuff. The editorial team thought — with good reason! — that
    this was worth a disclaimer; so here it is!
  prefs: []
  type: TYPE_NORMAL
- en: Now, you may wonder why we have discussed this. Well, because, as it turns out,
    the process of training a GAN is just like that of counterfeiting money — minus
    the risk of ending up in prison. Let’s see how it works!
  prefs: []
  type: TYPE_NORMAL
- en: 12.1.2 What actually is a GAN?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'GANs were introduced in 2014 in a very influential paper [[46](ch030.xhtml#Xgoodfellow2014generative)]
    by Goodfellow et al. As we mentioned in the introduction, a GAN is a machine learning
    model that can be trained to generate data closely reassembling the patterns and
    properties of a given dataset. In order to accomplish this, a GAN has two main
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: A ”generative” neural network (generator), which will be nothing more than a
    neural network taking arbitrary seeds as input and returning outputs that match
    the datatype of the elements in the original dataset. The goal of this neural
    network will be, by the end of the training, to generate new data that be indistinguishable
    from the data in the original dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A discriminator neural network, which will be a binary-classifier neural network
    taking as input the original data in the dataset and the output of the generative
    network. This discriminator network will be tasked with trying to discern the
    generated data from the original data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These components are depicted in *Figure* [*12.2*](#Figure12.2). By the way,
    we have drawn the fake tree ourselves. Graphic design is our passion.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2: Schematic representation of the agents involved in a generative
    adversarial network](img/file1439.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.2**: Schematic representation of the agents involved in a generative
    adversarial network'
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: GANs have been very successfully used in practical generative tasks. For instance,
    StyleGANs are GANs introduced by NVIDIA researchers [[57](ch030.xhtml#Xkarras2019style)]
    that are able to generate extremely realistic human faces. Their code is open
    source (you can find it at [https://github.com/NVlabs/stylegan](https://github.com/NVlabs/stylegan))
    and they power the mesmerizing website ”This Person Does Not Exist” ([https://www.thispersondoesnotexist.com/](https://www.thispersondoesnotexist.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'This description settles the question of what a GAN is, but now we need to
    understand how these GANs are actually trained. In essence, this is how the whole
    training process works:'
  prefs: []
  type: TYPE_NORMAL
- en: You initialize the generator and the discriminator to some random configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You train the discriminator to discern the real data from the output of the
    generator. At this initial stage, this should be a very easy task for the discriminator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You then train the generator to fool the discriminator: you train it in a way
    that the discriminator — as trained in the previous step — will classify as many
    of the generated outputs as real. Once trained, you use it to generate a bunch
    of fake data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And here is where the fun begins. You re-train the discriminator on the new
    generated dataset, and then you re-train the generator to fool the new discriminator.
    And you repeat this process in as many iterations as you want. Ideally, in each
    iteration, it will be harder for the discriminator to tell the generated data
    from the real data. And, eventually, an equilibrium will be reached in which the
    generated data will be indiscernible from the original data. Just like in our
    previous counterfeiting adventure — and with no legal troubles on the horizon!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process is exemplified schematically in *Figure* [*12.3*](#Figure12.3),
    where we present a schematic illustration of the training process of a GAN meant
    to generate pictures of cute cats. When the GAN is initialized, the generator
    just produces random noise. After subsequent training iterations, the output of
    the generator will more closely resemble the images in the original dataset —
    which, in this example, should be a dataset with pictures of cats. By the way,
    we have drawn the fake cats ourselves. Have we mentioned that graphic design is
    our passion?
  prefs: []
  type: TYPE_NORMAL
- en: We should highlight that this scheme is very oversimplified. In truth, you usually
    don’t ”fully” train the discriminator and the generator alternately, but you optimize
    them in an alternate fashion. For example, if you were using gradient descent
    with a given batch size, then, on each epoch and on each batch, you would optimize
    the weights of the discriminator in a single optimizer step, and then you would
    do the same for the weights of the generator.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3: Schematic illustration of the training process of a GAN meant
    to generate pictures of cute cats ](img/file1440.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.3**: Schematic illustration of the training process of a GAN meant
    to generate pictures of cute cats'
  prefs: []
  type: TYPE_NORMAL
- en: With this description of the training process, we can now make sense of the
    term GAN. These models are ”generative” because they are aimed at generating data.
    They are ”networks” because, well, they use neural networks. And they are ”adversarial”
    because the whole training process consists in a competition between a generator
    network and a discriminator network. These networks engage in a fierce competition
    in which we, their programmers and creators, shall be the only true winners.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: All this time, we have been talking about how GANs use neural networks in both
    the discriminator and the generator. However, these neural networks are not always
    like the ones we have discussed in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The neural networks that we have studied are known as ”dense” neural networks.
    In these networks, all the layers are dense, which means that neurons in subsequent
    layers are fully connected. However, when neural networks are designed to handle
    images — whether it be generating them, classifying them, or manipulating them
    — a different kind of layer is often employed: convolutional layers. We won’t
    get into the details of how these layers work (check Chapter 14 in Gerón’s book
    [[104](ch030.xhtml#Xhandsonml)] for a thorough explanation), but you should at
    least know that they exist.'
  prefs: []
  type: TYPE_NORMAL
- en: GANs are often used in image generation tasks, so, should you ever decide to
    study classical GANs, be aware that you will surely have to deal with these layers
    at some point. And, yes, there are quantum versions of convolutional layers and
    convolutional networks [[114](ch030.xhtml#Xquantum-conv), [52](ch030.xhtml#Xhavlivcek2019supervised)]
    that, sadly, we do not have the time to cover in this book.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few details that we should highlight about the training process
    of a GAN. The first and most important one is the fact that at no point in the
    training is the generator network ”exposed” to or fed the original data. The only
    way the generator network can learn about the data it has to replicate is through
    the discriminator. In this way, instead of us having to tell the generator network
    what its output should look like, the discriminator takes up our role as teachers
    and enables us to train the whole network in a fully unsupervised manner.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue to which we should pay attention is that GANs, like any other
    machine learning model, are vulnerable to problems in training. For instance,
    how could we have any guarantee that the generated outputs are not just slightly
    distorted copies of the original data, rather than new data elements that match
    the patterns in the original dataset? For instance, in the cat GAN that we considered
    in *Figure* [*12.3*](#Figure12.3), how could we have guarantees that the generated
    images are new cat pictures rather than, say, blurred copies of our original images
    that have lost any resemblance to cats but that were nevertheless able to fool
    the discriminator network? This could happen, for example, if our discriminator
    weren’t powerful enough compared to the generator.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: The training of a GAN can also fail if the resulting GAN is unable to generate
    all the possible variations (or **modes**) of data that can be found in the dataset.
    For instance, in the example that we have been considering, we would find this
    problem if our GAN were only able to generate pictures of a small selection of
    cats, maybe even only one! This occurrence is known as **mode collapse**. To try
    to avoid it, several modified GANs have been proposed, including **Wasserstein
    GANs** (**WGANs**) [[7](ch030.xhtml#Xarjovsky2017wasserstein)], which derive their
    loss function from a distance called the Wasserstein metric.
  prefs: []
  type: TYPE_NORMAL
- en: In the models that we considered in previous chapters, there was always a simple,
    straightforward way to effectively assess their performance — namely evaluating
    loss functions on test datasets. When working with GANs, things can be more subtle.
    In general, you should always take a look at the generated data and check if the
    results are satisfactory.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'A GAN consists of two neural networks: a generator and a discriminator. They
    compete against each other in an iterative training process. The discriminator
    is tasked with discerning a dataset of real data from the output of the generator
    network, while the generator network is tasked with generating data that the discriminator
    will mistakenly identify as real.'
  prefs: []
  type: TYPE_NORMAL
- en: Just to conclude this overview of classical GANs, let’s discuss a few technicalities
    about the training of the generator and discriminator networks.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1.3 Some technicalities about GANs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already mentioned how the generator and discriminator networks are ordinary
    neural network models — even if they may be different from the ones that we’ve
    discussed so far — that are constantly re-trained in an iterative process. We
    will now briefly talk about how this training is carried out.
  prefs: []
  type: TYPE_NORMAL
- en: Let ![X](img/file9.png "X") be a set of real data and let ![S](img/file73.png
    "S") be a set of ”seeds” that we give to the generator. In the case of the discriminator
    neural network, we are just training a binary classifier and, as is standard,
    this classifier will return an output bounded between ![0](img/file12.png "0")
    and ![1](img/file13.png "1"). Without loss of generality, we will assume that
    values closer to ![1](img/file13.png "1") are meant to represent inputs from the
    real dataset while values closer to ![0](img/file12.png "0") are labeled as generated
    inputs — that’s an arbitrary choice; it could perfectly be the other way around.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with any other binary classifier, the most natural loss function to use
    will be the binary cross-entropy loss, and hence this classifier will be trained
    as it would in supervised learning: assigning the ”true label” ![1](img/file13.png
    "1") to any input from the real dataset and the ”true label” ![0](img/file12.png
    "0") to any generated input. In this way, if we let ![G](img/file1441.png "G")
    and ![D](img/file1101.png "D") denote the actions of the generator and the discriminator,
    the discriminator training loss, ![L_{D}](img/file1442.png "L_{D}"), would be
    computed as'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![L_{D} = - \frac{1}{&#124;X&#124; + &#124;S&#124;}\left( {\sum\limits_{x
    \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right),](img/file1443.png
    "L_{D} = - \frac{1}{&#124;X&#124; + &#124;S&#124;}\left( {\sum\limits_{x \in X}\log
    D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right),") |'
  prefs: []
  type: TYPE_TB
- en: where we are using ![|X|](img/file1444.png "|X|") and ![|S|](img/file1445.png
    "|S|") to denote the sizes of the sets ![X](img/file9.png "X") and ![S](img/file73.png
    "S"), respectively. The job of the discriminator would be to minimize this loss.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what about the generator network? What could be a good choice for the loss
    function that we would like to minimize in its training process? Our goal when
    training the generator is to fool the discriminator trying to get it to classify
    our generated data as real data. Hence, the goal in the training of the generator
    is to maximize the loss function of the discriminator, that is, to minimize
  prefs: []
  type: TYPE_NORMAL
- en: '| ![- L_{D} = \frac{1}{&#124;X&#124; + &#124;S&#124;}\left( {\sum\limits_{x
    \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right).](img/file1446.png
    "- L_{D} = \frac{1}{&#124;X&#124; + &#124;S&#124;}\left( {\sum\limits_{x \in X}\log
    D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right).") |'
  prefs: []
  type: TYPE_TB
- en: Nevertheless, the contribution of the first term in the sum is necessarily constant
    in the generator training since it does not depend on the generator in any way.
    Thus, equivalently, we may consider the goal of the generator training to be the
    minimization of the generator loss function
  prefs: []
  type: TYPE_NORMAL
- en: '| ![L_{G}^{\prime} = \frac{1}{&#124;S&#124;}\sum\limits_{s \in S}\log\left(
    {1 - D(G(s)} \right).](img/file1447.png "L_{G}^{\prime} = \frac{1}{&#124;S&#124;}\sum\limits_{s
    \in S}\log\left( {1 - D(G(s)} \right).") |'
  prefs: []
  type: TYPE_TB
- en: That is how things are in theory. However, in practice, it has been shown [[46](ch030.xhtml#Xgoodfellow2014generative)]
    that it is usually more stable to take the goal of the generator training to be
    the minimization of the loss
  prefs: []
  type: TYPE_NORMAL
- en: '| ![L_{G} = - \frac{1}{&#124;S&#124;}\sum\limits_{s \in S}\log\left( {D(G(s)}
    \right).](img/file1448.png "L_{G} = - \frac{1}{&#124;S&#124;}\sum\limits_{s \in
    S}\log\left( {D(G(s)} \right).") |'
  prefs: []
  type: TYPE_TB
- en: The crucial thing here is that, with both definitions, if these generator loss
    functions decrease while training the generator, it will be more likely for our
    generated data to be (mistakenly) classified as real data by our classifier. That
    will mean, in turn, that our data should be gradually getting more and more similar
    to the data in the original dataset.
  prefs: []
  type: TYPE_NORMAL
- en: It has also been shown that, in the optimal equilibrium between the generator
    and the discriminator, the discriminator assigns values ![D(x)](img/file1449.png
    "D(x)") and ![G(D(s))](img/file1450.png "G(D(s))") equal to ![\left. 1\slash 2
    \right.](img/file136.png "\left. 1\slash 2 \right.") (because it cannot distinguish
    between real and generated data), and, hence, when ![\left. L_{D} = L_{G} = -
    \log 1\slash 2 = \log 2 \approx 0.6931 \right.](img/file1451.png "\left. L_{D}
    = L_{G} = - \log 1\slash 2 = \log 2 \approx 0.6931 \right."). You can find the
    proof (with slightly different but equivalent loss functions) in the original
    GANs paper [[46](ch030.xhtml#Xgoodfellow2014generative)].
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: It can be shown that the optimal configuration of a GAN is a Nash equilibrium
    of an adversarial game between the generator and the discriminator (see, for instance,
    the helpful tutorial given by Goodfellow at NIPS [[47](ch030.xhtml#Xgoodfellow2016nips)]).
    In this equilibrium, the configuration of the GAN is a (local) minimizer of both
    the generator and discriminator losses.
  prefs: []
  type: TYPE_NORMAL
- en: That should be enough of an introduction to classical GANs. Let’s now see what
    quantum GANs are and what they have to offer.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1.4 Quantum GANs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is a quantum GAN? It’s just a GAN, with its competing discriminator and
    generator, where a part of the model is implemented by a quantum model (usually
    some form of a quantum neural network), and it is trained just like a classical
    GAN. In other words, training a quantum GAN is just like counterfeiting money
    — but you don’t risk going to prison and you get to play with quantum stuff.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: By the way, did you know that there are proposals of quantum money that cannot
    be counterfeited at all? The original idea was proposed by Stephen Wiesner [[97](ch030.xhtml#Xwiesner1983conjugate)]
    and it became the inspiration for unbreakable quantum cryptographical protocols
    such as the famous BB84 proposed by Bennett and Brassard [[13](ch030.xhtml#Xbennett84quantum)].
  prefs: []
  type: TYPE_NORMAL
- en: In truth, that is as close to a precise definition as we can get, because the
    range of models that can fit into the category of QGAN is vast. Depending on the
    kind of problem that you want to tackle, you may want to use quantum GANs with
    completely different architectures which, still, will share the same core elements
    of a competing discriminator and generator. The examples that we will consider
    in the following sections will help us exemplify this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Broadly speaking, any quantum GAN could fit into one of the following categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Uses quantum data and both the generator and the** **discriminator are quantum:**
    This quantum data will just be some quantum states, and the generator and discriminator
    will be implemented by quantum circuits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This situation allows for a very special QGAN architecture, with a fully quantum
    model. Since we are dealing with quantum data (states), and all the components
    of the GAN are quantum circuits, they can be perfectly joined together without
    having to resort to feature maps or measurement operations in the middle of the
    model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Later in the chapter, we will study an example of this purely quantum architecture
    on PennyLane.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Uses quantum data and a quantum generator with a classical** **discriminator:**
    If the discriminator is classical, the architecture of our QGANs will be more
    similar to that of classical GANs. The generator will produce quantum states but,
    ultimately, they will be transformed into classical data by some measurement operation
    in order to feed them into the classifier. Of course, the original quantum data
    will also have to be measured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Uses classical data with a quantum generator** **or discriminator:** This
    is the scenario in which QGANs can best match their classical counterparts. The
    use of QGANs in these cases essentially mounts up to replacing the generator or
    the discriminator (or both) with a quantum model with classical inputs and outputs.
    In the case of a quantum discriminator, for example, we would have to use a feature
    map to load classical data into a quantum state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the availability of classical data is much bigger than that of quantum
    data, this is the type of architecture that has been studied more widely by the
    quantum computing community.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Later in the chapter, we will consider a QGAN with classical data and a classical
    classifier, but with a quantum generator. That will be in our Qiskit section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: In the literature, there are many different proposals of quantum versions of
    GANs. Some of the earliest ones include works by Lloyd and Weedbrook [[64](ch030.xhtml#Xlloyd2018quantum)],
    by Dallaire-Demers and Killoran [[28](ch030.xhtml#Xdallaire2018quantum)], and
    by Zoufal, Lucchi, and Woerner [[101](ch030.xhtml#Xzoufal2019quantum)].
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 12.1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this book, we have discussed four different QML models: quantum support
    vector machines, quantum neural networks, hybrid QNNs and quantum GANs. Decide
    which of these models would be suitable for the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Distinguishing cat pictures from dog pictures.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generating pictures of dogs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deciding whether a financial transaction is fraudulent based on its metadata.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assessing the risk of heart failure from a patients’ medical records and data
    from an electrocardiogram.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a dataset of random images of electrocardiograms in order to train
    future doctors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We should give you a word of caution. GANs aren’t the easiest models to train.
    As we mentioned previously, when you train a GAN, you don’t have a single and
    straightforward loss function that can measure how successful your training is.
    Training a GAN is not a simple optimization problem, but a more intricate process.
    Using quantum models, of course, only makes matters more difficult, and training
    quantum GANs can be…complicated.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now consider a couple of interesting QGAN examples, in both PennyLane
    and Qiskit. Naturally, since we’ve picked them, our quantum GANs will learn smoothly.
    But you have been warned: quantum GANs are usually wild creatures.'
  prefs: []
  type: TYPE_NORMAL
- en: 12.2 Quantum GANs in PennyLane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to train a purely quantum GAN that will learn
    a one-qubit state. In our previous counterfeiting example, we imagined ourselves
    as behaving like a GAN in order to replicate some training data (a banknote) to
    produce fake banknotes that, ideally, would get closer and closer to the real
    thing in each iteration. In this case, our training data will be a one-qubit state,
    characterized by some amplitudes, and the job of our QGAN will be to replicate
    that state without the generator having direct access to it. Our dataset, then,
    will consist of multiple copies of a one-qubit state, and our goal will be to
    train a generator able to prepare that state (or something very close to it).
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: Notice that this setting does not violate the no-cloning theorem that we proved
    in *Section* *[*1.4.5*](ch008.xhtml#x1-320001.4.5). We will have multiple copies
    of the same quantum state and we will perform operations on them, including measuring
    them (and, hence, collapsing their states). From that, we will learn some properties
    of the state that we will use to reproduce it with the generator. But we won’t
    be having a unitary operation (a quantum gate) that creates an additional, independent
    copy of a given state. In fact, we will destroy the original copies in the process!*
  prefs: []
  type: TYPE_NORMAL
- en: '*What we will be doing here is more similar to **quantum state** **tomography**
    (see, for instance, the review by Altepeter, James, and Kwiat [[6](ch030.xhtml#Xaltepeter2005photonic)]),
    which can be defined as the process of applying quantum operations and measurements
    to multiple copies of a state and, from the results, learning to reconstruct the
    original state.*  *For this example, we will use the PyTorch machine learning
    package. Please, have a look at *Subsection* [*11.3.1*](ch020.xhtml#x1-20500011.3.1)
    if you haven’t already.'
  prefs: []
  type: TYPE_NORMAL
- en: The reason behind our choice to use PyTorch is simple. As much as we have used
    TensorFlow so far, we only know how to use it at a basic level, relying heavily
    on the Keras interface. On the other hand, we have studied PyTorch extensively
    in the previous chapter, which makes it a better tool for us when it comes to
    dealing with more complex architectures. In other words, this choice isn’t grounded
    in any technical superiority of any package over the other, but solely on what’s
    most practical given the content that we’ve covered in this book. In fact, virtually
    any model that can be built and trained on PyTorch can also be dealt with on TensorFlow
    and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: With those preliminaries aside, let’s get to our model.
  prefs: []
  type: TYPE_NORMAL
- en: 12.2.1 Preparing a QGAN model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The purely quantum GAN that we seek to implement and train will run on a device
    with two qubits, and it will be made up of the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: A quantum circuit that will be able to prepare the one-qubit state ![\left|
    \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle") that
    we want our QGAN to learn. This circuit will run on the first qubit of the device.
    We should regard it as a black box, the inner working of which is fully opaque
    to our model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The state ![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1}
    \right\rangle"), which we will refer to as the ”true state,” is the quantum training
    data that we will use in our QGAN. This circuit will just provide us with a way
    of accessing the training data: as many copies of the ![\left| \psi_{1} \right\rangle](img/file177.png
    "\left| \psi_{1} \right\rangle") state as we may need in the training process.
    This emulates, for instance, a physics experiment that produces some quantum state
    that we want to learn.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A quantum generator, which will also run on the first qubit of the device and
    which aims to prepare a state similar to ![\left| \psi_{1} \right\rangle](img/file177.png
    "\left| \psi_{1} \right\rangle") on the first qubit. The quantum generator will
    be implemented by a variational form dependent on some trainable parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quantum discriminator, which will run on the first and second qubits of the
    device. Its ”input” will be the state on the first qubit, which can either be
    the state we want our QGAN to learn or the state prepared by the generator. Of
    course, the job of the discriminator will be to try to distinguish these two states.
    We implement it with two qubits (instead of just one) to be sure that it has enough
    discriminative power.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since this discriminator already takes a quantum input, it only needs to consist
    of a variational form followed by a measurement operation — there will be no need
    to use feature maps, as we had to do when working with classical data. As usual,
    we will place the measurement operation on the first qubit.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: All the components that we have just described are depicted in *Figure* [*12.4*](#Figure12.4).
  prefs: []
  type: TYPE_NORMAL
- en: '![(a) Circuit preparing the state  that we want our QGAN to learn.](img/file1453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(a)** Circuit preparing the state ![img](img/file1452.png) that we want our
    QGAN to learn.'
  prefs: []
  type: TYPE_NORMAL
- en: '![(b) Generator circuit that outputs a state . We aim for  to be similar to  .](img/file1455.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(b)** Generator circuit that outputs a state ![img](img/file1454.png). We
    aim for ![img](img/file1454.png) to be similar to ![img](img/file1452.png) .'
  prefs: []
  type: TYPE_NORMAL
- en: '![(c) Discriminator circuit, tasked with deciding whether the state  is the
    state  or the output of the generator.](img/file1457.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(c)** Discriminator circuit, tasked with deciding whether the state ![img](img/file1456.png)
    is the state ![img](img/file1452.png) or the output of the generator.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 12.4**: Components of the quantum GAN that we will train to generate
    ![img](img/file1452.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a sense of where we are heading, let’s get ready to write
    some code. First of all, we will do our usual imports and set some seeds to ensure
    the reproducibility of our results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will construct the state ![\left| \psi_{1} \right\rangle](img/file177.png
    "\left| \psi_{1} \right\rangle") using the universal one-qubit gate ![U_{3}(\varphi,\theta,\delta)](img/file1458.png
    "U_{3}(\varphi,\theta,\delta)") since, as we learned back in *Chapter* [*1*](ch008.xhtml#x1-180001),
    *Foundations of Quantum Computing*, it allows us to create any one-qubit state.
    In particular, we will feed it the values ![\left. \varphi = \pi\slash 3 \right.](img/file1459.png
    "\left. \varphi = \pi\slash 3 \right."), ![\left. \theta = \pi\slash 4 \right.](img/file1460.png
    "\left. \theta = \pi\slash 4 \right."), and ![\left. \delta = \pi\slash 5 \right.](img/file1461.png
    "\left. \delta = \pi\slash 5 \right."):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With these values set, we can define a function that will construct the circuit
    that will prepare ![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1}
    \right\rangle"):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we have defined this as a function and not as a quantum node. That’s
    because, for the purposes of the training, we are not interested in running any
    of the components of the quantum GAN individually. We will instead have to run
    them in composition. For instance, we will have to run this circuit that we’ve
    just defined composed with the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a circuit that can prepare ![\left| \psi_{1} \right\rangle](img/file177.png
    "\left| \psi_{1} \right\rangle"), it’s time for us to think about the two core
    components of our QGAN: the generator and the discriminator. Specifically, we
    will have to find some suitable variational forms for them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the generator, we will simply use a parametrized U3 gate, whereas, for
    the discriminator, we will use a variation of the two-local variational form.
    These can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can see a graphical representation of the discriminator variational form
    in *Figure* [*12.5*](#Figure12.5); its implementation is mostly analogous to that
    of the two-local variational form with just a few small differences. On a very
    minor note, we have renamed the vector of optimizable parameters to `weights`
    (instead of `theta`) to avoid any sort of confusion with the angle `theta` that
    defines ![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle").
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5: Discriminator variational form on two qubits and two repetitions](img/file1462.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.5**: Discriminator variational form on two qubits and two repetitions'
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking advantage of these newly-defined variational forms, we will define the
    circuits of the generator and the discriminator as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now ready to define the quantum nodes that we will use in the training.
    In the classifier, we shall take the measurement operation to be the computation
    of the expectation value of ![M = \left| 0 \right\rangle\left\langle 0 \right|](img/file1388.png
    "M = \left| 0 \right\rangle\left\langle 0 \right|") on the first qubit. For this
    purpose, we may construct the matrix ![M](img/file704.png "M") as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And we can now define two quantum nodes: one concatenating the generation of
    the state ![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")
    with the discriminator, and one concatenating the generator with the discriminator.
    We can achieve this with the following piece of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The measurement operation is the computation of the expectation value of ![M](img/file704.png
    "M") on the first qubit in both nodes; since this operation is the output of the
    discriminator, these measurement operations need be identical. Notice, by the
    way, that, since the discriminator works on the two qubits of our device, we could
    have also used the expectation value of ![M](img/file704.png "M") on the second
    qubit.
  prefs: []
  type: TYPE_NORMAL
- en: The training process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we have fully set up our model, and we have defined all the nodes that
    we will use in its training. But there’s something essential that we haven’t yet
    defined: the loss functions of the discriminator and the generator.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we discussed before, a reasonable choice for the loss function of the discriminator
    of a GAN is the binary cross-entropy. In our case, our discriminator only has
    to classify two data points: the true state ![\left| \psi_{1} \right\rangle](img/file177.png
    "\left| \psi_{1} \right\rangle") with intended label ![1](img/file13.png "1"),
    and the generated state ![\left| \psi_{g} \right\rangle](img/file1463.png "\left|
    \psi_{g} \right\rangle") with intended label ![0](img/file12.png "0"). Therefore,
    if we let ![D](img/file1101.png "D") denote the action of the discriminator under
    a certain configuration, the binary cross-entropy loss would be'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![L_{D} = - \frac{1}{2}\left( {\log\left( {1 - D(\left&#124; \psi_{g} \right\rangle)}
    \right) + \log\left( {D(\left&#124; \psi_{1} \right\rangle} \right)} \right).](img/file1464.png
    "L_{D} = - \frac{1}{2}\left( {\log\left( {1 - D(\left&#124; \psi_{g} \right\rangle)}
    \right) + \log\left( {D(\left&#124; \psi_{1} \right\rangle} \right)} \right).")
    |'
  prefs: []
  type: TYPE_TB
- en: 'This loss function can be implemented with our previously-defined nodes as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now, what about the loss of the generator? We already know that the goal of
    the generator is to fool the discriminator into misclassifying the generated state
    as real. Moreover, we have also mentioned a reasonable generator loss function
    is
  prefs: []
  type: TYPE_NORMAL
- en: '| ![L_{G} = - \log\left( {D(\left&#124; \psi_{g} \right\rangle)} \right).](img/file1465.png
    "L_{G} = - \log\left( {D(\left&#124; \psi_{g} \right\rangle)} \right).") |'
  prefs: []
  type: TYPE_TB
- en: This would be the binary cross-entropy loss of the discriminator if it were
    tasked with classifying the generated state as the true state.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily implement this loss as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'And that defines all our losses. Let’s now prepare ourselves for the training
    process. First and foremost, let’s initialize the weights of the generator and
    the discriminator to a tensor with random values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The dimensions of these arrays are justified from the fact that the generator
    uses ![3](img/file472.png "3") weights and the variational form of the discriminator
    has ![3 + 1](img/file1466.png "3 + 1") groups of parametrized gates, with ![3](img/file472.png
    "3") parameters being used on each of the ![2](img/file302.png "2") qubits on
    which the form acts. Also, remember that we need to set `requires_grad` `=` `True`
    in order for PyTorch to be able to compute gradients on these weights later on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can define the optimizers that we will use in the training. For this
    problem, we will rely on the stochastic gradient descent algorithm, which is a
    more simple version of the Adam optimizer that we used in previous chapters (see
    *Section* [*8.2.3*](ch017.xhtml#x1-1520008.2.3) for a refresher). When invoking
    the optimizers, we have to provide an array or dictionary with the parameters
    that we want our optimizer to look after. Back when we defined PyTorch models
    as subclasses of `nn``.``Module`, we could just get this with the `parameters`
    method, but in this case, we will create the list ourselves. This can be done
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this call to the optimizers, we have set their learning rate to ![0.5](img/file1166.png
    "0.5").
  prefs: []
  type: TYPE_NORMAL
- en: 'And those are all the ingredients needed to train our model. We can execute
    the following piece of code in order to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: There is quite a lot to digest here. In the first few lines of code, we are
    simply defining some arrays in which we will store data as the training progresses.
    The arrays `dis_losses` and `gen_losses` will save the discriminator and generator
    losses in each training cycle, and the array `log_weights` will store the generator
    weights obtained at the end of each training cycle. We will later use this information
    in order to assess the effectiveness of the training.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have fixed the training to run for ![150](img/file1467.png "150") optimization
    cycles. In each of them, we will optimize the values of the discriminator, then
    optimize those of the generator, and, finally, log all the results. Let’s go through
    it step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: When we optimize the discriminator, we reset its optimizer (`optd`) and then
    compute the discriminator loss function and store it in `lossd`. Observe that,
    when we send the generator weights, we pass them through the `detach` method.
    This method removes the need to compute gradients for these weights. The discriminator
    optimizer is not going to touch those weights either way, so this will save us
    some computation time. Once we have the loss, we just compute its gradients with
    the `backward` method and run a step of the discriminator optimizer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The optimization of the generator is fully analogous. We simply use the generator
    optimizer `optg` on the gradients obtained from the generator loss `lossg`. Of
    course, we detach the discriminator weights in the call to the generator loss
    function instead of the generator weights.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we log the values of the losses. For this purpose, we simply store
    the values of the losses that we computed in the training cycle. These will probably
    be different from the ones at the end of the cycle, but they will still be informative
    enough.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After this, we store the generator weights. Please observe the call to the `clone`
    method. This call ensures that we are getting a copy of the weights and not a
    reference to the weights tensor. If we didn’t call this method, all the weight
    arrays in `log_weights` would reference the same tensor and their values would
    all be the same and would change (simultaneously) as the training progresses!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, we print some information about the training. Since we are going to
    execute this loop for ![150](img/file1467.png "150") training cycles and the training
    will be fast, we shall only print information every ![15](img/file599.png "15")
    cycles.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Notice how, instead of fully training the discriminator and the generator in
    an alternating fashion, we are optimizing them in an alternating fashion in every
    training cycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output that we get upon running the preceding code is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Just by looking at this raw output, we can see that there is a chance that
    our training may have been successful: the discriminator loss and the generator
    loss are both approaching ![\left. - \log 1\slash 2 \right.](img/file1468.png
    "\left. - \log 1\slash 2 \right."), just as they should do at the optimal point.
    This is a good sign!'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to have a better insight on the evolution of these losses, we may
    use the `gen_losses` and `dis_losses` array in order to plot their evolution.
    This can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The resulting graph can be found in *Figure* [*12.6*](#Figure12.6) and, indeed,
    we can see a nice trend from which to draw some optimism.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6: Evolution of the losses of the discriminator and the generator
    along the training process ](img/file1469.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.6**: Evolution of the losses of the discriminator and the generator
    along the training process'
  prefs: []
  type: TYPE_NORMAL
- en: But now comes the moment of truth. Let’s see if, indeed, our model has learned
    as we wanted it to. We mentioned in the previous section that, when training generative
    adversarial networks, the best criteria for determining whether a training process
    was successful or not depends on the problem at hand. In our case, our training
    will be successful if the state returned by the generator is close to ![\left|
    \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle").
  prefs: []
  type: TYPE_NORMAL
- en: Now, how do we determine the state vector of a qubit? It turns out that the
    state of a qubit is fully characterized (up to an unimportant global phase, as
    we saw back in *Section* *[*1.3.4*](ch008.xhtml#x1-250001.3.4)) by its Bloch sphere
    coordinates. And now that we’ve come across these coordinates, let’s learn how
    to compute them with an exercise that we hope you will find interesting — although,
    admittedly, is slightly orthogonal to this chapter.*
  prefs: []
  type: TYPE_NORMAL
- en: '*Exercise 12.2'
  prefs: []
  type: TYPE_NORMAL
- en: Prove that the Bloch sphere coordinates of a one-qubit state are the expectation
    values of the observables given by the three Pauli matrices ![X](img/file9.png
    "X"), ![Y](img/file11.png "Y"), and ![Z](img/file8.png "Z").
  prefs: []
  type: TYPE_NORMAL
- en: 'We can prepare two quantum nodes that return these expectation values for both
    ![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")
    and the state returned by the generator after the training. This can be done as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'And the output that we get is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The outputs are identical, so we can safely say that our training has been a
    huge success!
  prefs: []
  type: TYPE_NORMAL
- en: In order to bring this section to an end, we will visually explore how the state
    created by the generator has evolved throughout the training. We can do this using
    the array of weights `log_weights` and the `generated_coordinates` function that
    we have just defined. This function takes the weights of the generator as input,
    so we can get the Bloch coordinates of the generated states at any point in the
    training using the saved weights.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can accomplish this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This function will plot, for any training cycle, a representation of the Bloch
    coordinates of the generated states superposed to the coordinates of the state
    that we want our QGAN to learn. In *Figure* [*12.7*](#Figure12.7) you can see
    the plots corresponding to a wide range of cycles.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7: Evolution of the Bloch coordinates of the generated state as
    the training progresses](img/file1470.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.7**: Evolution of the Bloch coordinates of the generated state
    as the training progresses'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 12.3
  prefs: []
  type: TYPE_NORMAL
- en: Try to replicate this example on a different state (you may need to increase
    the number of training cycles to reach convergence in some cases).
  prefs: []
  type: TYPE_NORMAL
- en: That brings this example to an end. Let’s now consider a different QGAN, this
    time implemented in Qiskit.
  prefs: []
  type: TYPE_NORMAL
- en: 12.3 Quantum GANs in Qiskit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An early proposal of a QGAN was introduced by IBM researchers Zoufal, Lucchi,
    and Woerner [[101](ch030.xhtml#Xzoufal2019quantum)] to learn a probability distribution
    using a QGAN with a quantum generator and a classical discriminator. In this section,
    we will discuss how to implement this kind of QGAN with Qiskit, so let’s put everything
    in more precise terms.
  prefs: []
  type: TYPE_NORMAL
- en: This type of quantum GAN is given a dataset of real numbers that follow a certain
    probability distribution. This distribution may potentially be continuous, but
    it could be discretized to take some values ![m,m + 1,m + 2,\ldots,M - 1,M](img/file1471.png
    "m,m + 1,m + 2,\ldots,M - 1,M") with ![m < M](img/file1472.png "m < M"); this
    will usually be done by fixing the values ![m](img/file259.png "m") and ![M](img/file704.png
    "M"), rounding the samples and ignoring those that are smaller than ![m](img/file259.png
    "m") or bigger than ![M](img/file704.png "M"). Each of the resulting labels ![j
    = m,\ldots,M](img/file1473.png "j = m,\ldots,M") will have a certain probability
    ![p_{j}](img/file1474.png "p_{j}") of appearing in the dataset. That is the distribution
    that we want the generator in our QGAN to learn.
  prefs: []
  type: TYPE_NORMAL
- en: And what does the generator of these QGANs look like? It is a quantum generator
    that is dependent on some classical parameters. It needs to be designed to have
    ![n](img/file244.png "n") qubits in such a way that ![M - m < 2^{n}](img/file1475.png
    "M - m < 2^{n}"), so that we may assign, to each possible outcome ![r](img/file1337.png
    "r") after a measurement in the computational basis of the generator, a label
    ![\alpha(r)](img/file1476.png "\alpha(r)") in ![m,\ldots M](img/file1477.png "m,\ldots
    M"). Thus, the goal of the training will be for the state returned by the generator
    to be as close as possible to
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\sum\limits_{r}\sqrt{p_{\alpha(r)}}\left&#124; r \right\rangle.](img/file1478.png
    "\sum\limits_{r}\sqrt{p_{\alpha(r)}}\left&#124; r \right\rangle.") |'
  prefs: []
  type: TYPE_TB
- en: In this way, measuring samples from the trained generator should be equivalent
    to extracting more data samples from the original distribution, because the probability
    of measuring ![\left| r \right\rangle](img/file1479.png "\left| r \right\rangle")
    (which is associated to label ![\alpha(r)](img/file1476.png "\alpha(r)")) is exactly
    ![\left| \sqrt{p_{\alpha(r)}} \right|^{2} = p_{\alpha(r)}](img/file1480.png "\left|
    \sqrt{p_{\alpha(r)}} \right|^{2} = p_{\alpha(r)}").
  prefs: []
  type: TYPE_NORMAL
- en: The discriminator that enables the training of this QGAN is a classical neural
    network tasked with distinguishing whether an input datum belongs to the original
    dataset or has been generated by the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: 'So that’s the QGAN that we are going to work with: a hybrid QGAN in which the
    generator is quantum and the discriminator is classic. Sounds interesting? Let’s
    see how we can implement it and train it using Qiskit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to get started, let’s import NumPy and Qiskit while setting some seeds
    to ensure the reproducibility of our results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will consider a particular example of the general problem that we outlined
    previously. We will take a dataset with ![1000](img/file790.png "1000") samples
    generated from the binomial distribution with ![n = 3](img/file1481.png "n = 3")
    trials and probability ![\left. p = 1\slash 2 \right.](img/file1482.png "\left.
    p = 1\slash 2 \right."). These distributions can only take ![4 = 2^{2}](img/file1483.png
    "4 = 2^{2}") possible values (![0,1,2,3](img/file1484.png "0,1,2,3")), so will
    have to use ![2](img/file302.png "2") qubits in our generator. We may generate
    the samples of our dataset using NumPy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The Qiskit framework already incorporates a `QGAN` class that can create and
    train the QGAN architecture that we discussed previously — it’s almost tailor-made
    for this problem! We may import the class from the `qiskit_machine_learning``.``algorithms`
    module and define our QGAN as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In the call to the `QGAN` initializer, we had to specify the dataset whose distribution
    we want to learn, the bounds at which we want to ”cut” the dataset (in this case,
    we just specified the actual bounds of our distribution), an array containing
    the number of qubits of the generator circuit, the batch size, the number of training
    cycles that we want our QGAN to run for, the quantum instance on which the QGAN
    will run and, lastly, an optional seed.
  prefs: []
  type: TYPE_NORMAL
- en: You may be confused by the fact that we’ve had to send the number of qubits
    of the quantum generator in an array. That’s because this `QGAN` class could support
    generating samples of any dimension ![d](img/file1485.png "d") (using ![d](img/file1485.png
    "d") generators); in our case, we have ![d = 1](img/file1486.png "d = 1"), hence
    we only need to pass an array with a single element.
  prefs: []
  type: TYPE_NORMAL
- en: This QGAN object already comes with a default implementation for the generator
    and the discriminator, and we will rely on them.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: In this default implementation, the discriminator is a dense neural network
    having two consecutive intermediate layers with ![50](img/file1390.png "50") and
    ![20](img/file588.png "20") neurons each; the activation function in these intermediate
    layers is the leaky ReLU function and that of the output layer is the sigmoid
    function. The generator uses a variational form consisting of a layer of Hadamard
    gates applied on each qubit followed by the two-local variational form with one
    repetition and circular entanglement.
  prefs: []
  type: TYPE_NORMAL
- en: These details are not specified in the documentation, but they can be found
    in the source code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to train the QGAN, we may run the following instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The training will take a few minutes to complete, depending on the hardware
    configuration of your computer. In order to plot the evolution of the generator
    and discriminator losses throughout the training process, we may run the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This yields the plot shown in *Figure* [*12.8*](#Figure12.8). We can see how
    both losses are approaching ![\left. - \log 1\slash 2 \right.](img/file1468.png
    "\left. - \log 1\slash 2 \right."), which can give us hope for the success of
    our training.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8: Evolution of the generator and discriminator losses during the
    QGAN training, learning a distribution ](img/file1487.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.8**: Evolution of the generator and discriminator losses during
    the QGAN training, learning a distribution'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to check if our training has been successful, we will plot the distribution
    of the measurement outcomes of our generator against the original distribution.
    We may generate the data for this plot as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In this piece of code, we have first asked our QGAN to generate a sample with
    the distribution it has learned. Then, we have created an array `real_distr` with
    the relative frequencies of the values in the distribution (entry `j` corresponds
    to the relative frequency of the value ![j](img/file258.png "j")). Lastly, we
    have plotted the real distribution against our generated distribution. The output
    can be found in *Figure* [*12.9*](#Figure12.9).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9: Histogram comparing the real distribution (thicker bar) with
    the one generated by the QGAN (thinner bar) ](img/file1488.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.9**: Histogram comparing the real distribution (thicker bar) with
    the one generated by the QGAN (thinner bar)'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, for the purposes of this example, this visualization is more than
    enough to convince us that the training, indeed, has been effective. In more sophisticated
    examples, one may instead want to rely on more quantitative metrics of success.
    One such metric is the **relative entropy** or **Kullback–Leibler** **divergence**
    from one distribution to another. In layman’s terms, this entropy measures how
    ”different” two distributions are in a way that if two distributions ![P_{0}](img/file1489.png
    "P_{0}") and ![P_{1}](img/file1490.png "P_{1}") are identical, the relative entropy
    from ![P_{0}](img/file1489.png "P_{0}") to ![P_{1}](img/file1490.png "P_{1}")
    is ![0](img/file12.png "0"). As ![P_{1}](img/file1490.png "P_{1}") becomes more
    different from ![P_{0}](img/file1489.png "P_{0}"), the relative entropy increases.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: When you are given two discrete probability distributions ![P_{0}](img/file1489.png
    "P_{0}") and ![P_{1}](img/file1490.png "P_{1}") over a space ![X](img/file9.png
    "X"), the relative entropy from ![P_{0}](img/file1489.png "P_{0}") to ![P_{1}](img/file1490.png
    "P_{1}") can be defined as
  prefs: []
  type: TYPE_NORMAL
- en: '| ![D(P_{1} \parallel P)0) = \sum\limits_{x \in X}P_{1}(x)\log\left( \frac{P_{1}(x)}{P_{0}(x)}
    \right).](img/file1491.png "D(P_{1} \parallel P)0) = \sum\limits_{x \in X}P_{1}(x)\log\left(
    \frac{P_{1}(x)}{P_{0}(x)} \right).") |'
  prefs: []
  type: TYPE_TB
- en: 'Qiskit’s QGAN implementation logs the values of the relative entropy throughout
    the QGAN training. In this way, we may plot the evolution of the relative entropy
    over the training process of our QGAN with the following instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The output is shown in *Figure* [*12.10*](#Figure12.10).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10: Evolution of the relative entropy over the training of our
    QGAN, learning a distribution](img/file1492.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.10**: Evolution of the relative entropy over the training of our
    QGAN, learning a distribution'
  prefs: []
  type: TYPE_NORMAL
- en: Here it can be clearly shown that the relative entropy approaches ![0](img/file12.png
    "0") as the training progresses, just as we expected. This concludes our example.
    It’s time to wrap up!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have explored a whole new kind of quantum machine learning
    models: quantum GANs. Unlike the models we had considered before, these are used
    primarily for generation tasks. And, unlike our previous models, they are trained
    in a fully unsupervised manner.'
  prefs: []
  type: TYPE_NORMAL
- en: After understanding what GANs are in general, we introduced the general notion
    of a QGAN, and then we learned how to implement a couple of QGAN models using
    PennyLane and Qiskit.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we also conclude our study of quantum machine learning for this book.
    We hope that you have had a good time learning about all these ways of making
    quantum computers learn! But your quantum journey does not need to end here. Please,
    keep on reading for a sneak peek of what you can expect in the near future in
    the quantum computing field.**
  prefs: []
  type: TYPE_NORMAL
