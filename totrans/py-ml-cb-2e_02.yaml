- en: Constructing a Classifier
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建分类器
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下配方：
- en: Building a simple classifier
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建简单的分类器
- en: Building a logistic regression classifier
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建逻辑回归分类器
- en: Building a Naive Bayes classifier
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建朴素贝叶斯分类器
- en: Splitting a dataset for training and testing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集拆分为训练集和测试集
- en: Evaluating accuracy using cross-validation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用交叉验证评估准确性
- en: Visualizing a confusion matrix
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化混淆矩阵
- en: Extracting a performance report
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取性能报告
- en: Evaluating cars based on their characteristics
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据特征评估汽车
- en: Extracting validation curves
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取验证曲线
- en: Extracting learning curves
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取学习曲线
- en: Estimating a income bracket
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估算收入区间
- en: Predicting the quality of wine
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测葡萄酒质量
- en: Newsgroup trending topics classification
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新闻组热门话题分类
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To work on the recipes in this chapter, you need the following files (available
    on GitHub):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本章中处理配方，你需要以下文件（可在GitHub上找到）：
- en: '`simple_classifier.py`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simple_classifier.py`'
- en: '`logistic_regression.py`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logistic_regression.py`'
- en: '`naive_bayes.py`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`naive_bayes.py`'
- en: '`data_multivar.txt`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_multivar.txt`'
- en: '`splitting_dataset.py`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`splitting_dataset.py`'
- en: '`confusion_matrix.py`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`confusion_matrix.py`'
- en: '`` `performance_report.py` ``'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`` `performance_report.py` ``'
- en: '`car.py`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`car.py`'
- en: '`car.data.txt`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`car.data.txt`'
- en: '`income.py`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`income.py`'
- en: '`adult.data.txt`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adult.data.txt`'
- en: '`wine.quality.py`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wine.quality.py`'
- en: '`wine.txt`'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wine.txt`'
- en: '`post.classification`'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`post.classification`'
- en: Introduction
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In the field of machine learning, **classification** refers to the process of
    using the characteristics of data to separate it into a certain number of classes.
    This is different than regression, which we discussed in [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml),
    *The Realm of Supervised Learning*, where the output is a real number. A supervised
    learning classifier builds a model using labeled training data and then uses this
    model to classify unknown data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，**分类**指的是使用数据的特征将其分为一定数量的类别的过程。这与我们在[第1章](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml)“监督学习领域”中讨论的回归不同，其中输出是一个实数。监督学习分类器使用标记的训练数据构建模型，然后使用此模型对未知数据进行分类。
- en: A classifier can be any algorithm that implements classification. In simple
    cases, a classifier can be a straightforward mathematical function. In more real-world
    cases, a classifier can take very complex forms. In the course of study, we will
    see that classification can be either binary, where we separate data into two
    classes, or it can be multi-class, where we separate data into more than two classes.
    The mathematical techniques that are devised to deal with classification problems
    tend to deal with two classes, so we extend them in different ways to deal with
    multi-class problems as well.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器可以是任何实现分类的算法。在简单的情况下，分类器可以是一个直接的数学函数。在更现实的情况下，分类器可以采取非常复杂的形式。在学习过程中，我们将看到分类可以是二元的，其中我们将数据分为两个类别，或者它是多类的，其中我们将数据分为两个以上的类别。为处理分类问题而设计的数学技术往往处理两个类别，因此我们以不同的方式扩展它们以处理多类问题。
- en: Evaluating the accuracy of a classifier is vital for machine learning. What
    we need to know is, how we can use the available data, and get a glimpse of how
    the model performs in the real world. In this chapter, we will look at recipes
    that deal with all these things.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 评估分类器的准确性对于机器学习至关重要。我们需要了解的是，我们如何使用可用的数据，并一窥模型在现实世界中的表现。在本章中，我们将探讨处理所有这些内容的配方。
- en: Building a simple classifier
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建简单的分类器
- en: A **classifier** is a system with some characteristics that allow you to identify
    the class of the sample examined. In different classification methods, groups
    are called **classes**. The goal of a classifier is to establish the classification
    criterion to maximize performance. The performance of a classifier is measured
    by evaluating the capacity for generalization. **Generalization** means attributing
    the correct class to each new experimental observation. The way in which these
    classes are identified discriminates between the different methods that are available.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类器**是一个具有某些特征的系统，允许你识别所检查样本的类别。在不同的分类方法中，组被称为**类别**。分类器的目标是建立分类标准以最大化性能。分类器的性能通过评估泛化能力来衡量。**泛化**意味着将正确的类别分配给每个新的实验观察结果。这些类别被识别的方式区分了不同可用的方法。'
- en: Getting ready
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Classifiers identify the class of a new objective, based on knowledge that's
    been extracted from a series of samples (a dataset). Starting from a dataset,
    a classifier extracts a model, which is then used to classify new instances.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器根据从一系列样本（数据集）中提取的知识来识别新目标对象的类别。从一个数据集开始，分类器提取一个模型，然后使用该模型对新实例进行分类。
- en: How to do it…
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to build a simple classifier using some training data:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用一些训练数据构建一个简单的分类器：
- en: 'We will use the `simple_classifier.py` file, already provided to you as a reference.
    To start, we import the `numpy` and `matplotlib.pyplot` packages, as we did in
    [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml), *The Realm of Supervised
    Learning*, and then we create some sample data:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用已经提供给你作为参考的`simple_classifier.py`文件。首先，我们导入`numpy`和`matplotlib.pyplot`包，就像我们在[第1章](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml)，“监督学习领域”中所做的那样，然后我们创建一些样本数据：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s assign some labels to these points:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们给这些点分配一些标签：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As we have only two classes, the `y` list contains 0''s and 1''s. In general,
    if you have *N* classes, then the values in `y` will range from 0 to *N-1*. Let''s
    separate the data into classes based on the labels:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们只有两个类别，`y`列表包含0和1。一般来说，如果你有*N*个类别，那么`y`中的值将范围从0到*N-1*。让我们根据标签将数据分开成类别：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To get an idea about our data, let''s plot it, as follows:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了了解我们的数据，让我们按照以下方式绘制它：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This is a **scatterplot**, where we use squares and crosses to plot the points.
    In this context, the `marker` parameter specifies the shape you want to use. We
    use squares to denote points in `class_0` and crosses to denote points in `class_1`. If
    you run this code, you will see the following output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个**散点图**，我们使用方块和交叉来绘制点。在这个上下文中，`marker`参数指定了你想要使用的形状。我们用方块表示`class_0`中的点，用交叉表示`class_1`中的点。如果你运行这段代码，你会看到以下输出：
- en: '![](img/542cb6f5-7a7c-486e-a1be-823c65eb12d8.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/542cb6f5-7a7c-486e-a1be-823c65eb12d8.png)'
- en: 'In the preceding two lines, we just use the mapping between `X` and `y` to
    create two lists. If you were asked to inspect the datapoints visually and draw
    a separating line, what would you do? You would simply draw a line in between
    them. Let''s go ahead and do this:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前两行中，我们只是使用`X`和`y`之间的映射来创建两个列表。如果你被要求视觉检查数据点并绘制一条分隔线，你会怎么做？你会在它们之间简单地画一条线。让我们来做这件事：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We just created a line with the mathematical equation *y = x*. Let''s plot
    it, as follows:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们刚刚使用数学方程*y = x*创建了一条线。让我们按照以下方式绘制它：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If you run this code, you should see the following output:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行这段代码，你应该看到以下输出：
- en: '![](img/fde419aa-36d1-4312-9a2c-f49b054f62c8.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fde419aa-36d1-4312-9a2c-f49b054f62c8.png)'
- en: The preceding shows how that construction of a separation line between the two
    classes was simple. In this simple example, this operation was easy, but in many
    cases, building a line of separation between two classes can be very difficult.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子展示了在两个类别之间构建分隔线是如何简单的。在这个简单的例子中，这个操作很容易，但在许多情况下，在两个类别之间构建分隔线可能非常困难。
- en: How it works...
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we showed how simple it is to build a classifier. We started
    from a series of identifying pairs of as many points on a plane (*x, y*). We therefore
    assigned a class to each of these points (0,1) so as to divide them into two groups.
    To understand the spatial arrangement of these points, we visualized them by associating
    a different marker to each class. Finally, to divide the two groups, we have drew
    the line of the *y = x* equation.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们展示了构建分类器是多么简单。我们从平面上尽可能多的点（*x, y*）的识别对开始。因此，我们给这些点中的每一个分配了一个类别（0,1），以便将它们分成两组。为了理解这些点的空间排列，我们通过为每个类别关联不同的标记来可视化它们。最后，为了将这两组分开，我们绘制了*y
    = x*方程的线。
- en: There's more…
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We built a simple classifier using the following rule—the input point (*a, b*)
    belongs to `class_0` if *a* is greater than or equal to *b;* otherwise, it belongs
    to `class_1`. If you inspect the points one by one, you will see that this is,
    in fact, true. That's it! You just built a linear classifier that can classify
    unknown data. It's a linear classifier because the separating line is a straight
    line. If it's a curve, then it becomes a *nonlinear* classifier.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下规则构建了一个简单的分类器——输入点（*a, b*）属于`class_0`当且仅当*a*大于或等于*b*；否则，它属于`class_1`。如果你逐个检查这些点，你会看到这实际上是正确的。就是这样！你刚刚构建了一个可以分类未知数据的线性分类器。它是一个线性分类器，因为分隔线是直线。如果它是曲线，那么它就变成了*非线性*分类器。
- en: This formation worked well, because there were a limited number of points, and
    we could visually inspect them. What if there were thousands of points? How would
    we generalize this process? Let's discuss that in the next recipe.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这种形式工作得很好，因为点的数量有限，我们可以直观地检查它们。如果有成千上万的点呢？我们将如何泛化这个过程？让我们在下一个菜谱中讨论这个问题。
- en: See also
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考阅读
- en: The official documentation of the NumPy library ([http://www.numpy.org/](http://www.numpy.org/))
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 库的官方文档([http://www.numpy.org/](http://www.numpy.org/))
- en: The official documentation of the Matplotlib library ([https://matplotlib.org/](https://matplotlib.org/))
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib 库的官方文档([https://matplotlib.org/](https://matplotlib.org/))
- en: Building a logistic regression classifier
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建逻辑回归分类器
- en: Despite the word *regression* being present in the name, logistic regression
    is actually used for classification purposes. Given a set of datapoints, our goal
    is to build a model that can draw linear boundaries between our classes. It extracts
    these boundaries by solving a set of equations derived from the training data.
    In this recipe, we will build a logistic regression classifier.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管名称中包含 `regression` 一词，但逻辑回归实际上用于分类目的。给定一组数据点，我们的目标是构建一个模型，该模型可以在我们的类别之间绘制线性边界。它通过解决从训练数据导出的一组方程来提取这些边界。在这个菜谱中，我们将构建一个逻辑回归分类器。
- en: Getting ready
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Logistic regression is a non-linear regression model used when the dependent
    variable is dichotomous. The purpose is to establish the probability with which
    an observation can generate one or the other value of the dependent variable;
    it can also be used to classify observations, according to their characteristics,
    into two categories.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种非线性回归模型，当因变量是二元时使用。目的是确定一个观测值可以生成因变量一个或另一个值的概率；它也可以根据其特征将观测值分类到两个类别中。
- en: How to do it…
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现它……
- en: 'Let''s see how to build a logistic regression classifier:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建一个逻辑回归分类器：
- en: 'Let''s see how to do this in Python. We will use the `logistic_regression.py`
    file, provided to you as a reference. Assuming that you imported the necessary
    packages, let''s create some sample data, along with training labels:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看如何在 Python 中实现这个功能。我们将使用提供的 `logistic_regression.py` 文件作为参考。假设你已经导入了必要的包，让我们创建一些样本数据，以及相应的训练标签：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we assume that we have three classes (`0`, `1`, and `2`).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们假设我们有三个类别（`0`、`1` 和 `2`）。
- en: 'Let''s initialize the logistic regression classifier:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们初始化逻辑回归分类器：
- en: '[PRE7]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There are a number of input parameters that can be specified for the preceding
    function, but a couple of important ones are `solver` and `C`. The `solver` parameter
    specifies the type of `solver` that the algorithm will use to solve the system
    of equations. The `C` parameter controls the regularization strength. A lower
    value indicates higher regularization strength.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面的函数，可以指定许多输入参数，但其中两个重要的参数是 `solver` 和 `C`。`solver` 参数指定算法将用于解决方程组的 `solver`
    类型。`C` 参数控制正则化强度。较低的值表示较高的正则化强度。
- en: 'Let''s train the classifier:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们训练分类器：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s draw datapoints and boundaries. To do this, first, we need to define
    ranges to plot the diagram, as follows:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制数据点和边界。为此，首先，我们需要定义绘图的范围，如下所示：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding values indicate the range of values that we want to use in our
    figure. The values usually range from the minimum value to the maximum value present
    in our data. We add some buffers, such as `1.0`, to the preceding lines, for clarity.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的值表示我们想在图中使用的值的范围。这些值通常从我们数据中的最小值到最大值。为了清晰起见，我们在前面的行中添加了一些缓冲区，例如 `1.0`。
- en: 'In order to plot the boundaries, we need to evaluate the function across a
    grid of points and plot it. Let''s go ahead and define the grid:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了绘制边界，我们需要在点网格上评估函数并绘制它。让我们继续定义网格：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `x_values` and `y_values` variables contain the grid of points where the
    function will be evaluated.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`x_values` 和 `y_values` 变量包含函数将被评估的点网格。'
- en: 'Let''s compute the output of the classifier for all these points:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算分类器对所有这些点的输出：
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s plot the boundaries using colored regions:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用彩色区域绘制边界：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is basically a 3D plotter that takes the 2D points and the associated values
    to draw different regions using a color scheme.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上是一个 3D 绘图器，它接受 2D 点和相关的值，使用颜色方案绘制不同的区域。
- en: 'Let''s overlay the training points on the plot:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在图上叠加训练点：
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, `plt.scatter` plots the points on the 2D graph. `X[:, 0]` specifies that
    we should take all the values along the 0 axis (the *x* axis in our case), and
    `X[:, 1]` specifies axis 1 (the *y* axis). The `c=y` parameter indicates the color
    sequence. We use the target labels to map to colors using `cmap`. Basically, we
    want different colors that are based on the target labels. Hence, we use `y` as
    the mapping. The limits of the display figure are set using `plt.xlim` and `plt.ylim`. In
    order to mark the axes with values, we need to use `plt.xticks` and `plt.yticks`. These
    functions mark the axes with values so that it's easier for us to see where the
    points are located. In the preceding code, we want the ticks to lie between the
    minimum and maximum values with a buffer of one unit. Also, we want these ticks
    to be integers. So, we use the `int()` function to round off the values.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`plt.scatter` 在二维图上绘制点。`X[:, 0]` 指定我们应该取沿着0轴（在我们的情况下是*x*轴）的所有值，而 `X[:, 1]`
    指定轴1（*y*轴）。`c=y` 参数表示颜色序列。我们使用目标标签通过 `cmap` 来映射颜色。基本上，我们想要基于目标标签的不同颜色。因此，我们使用
    `y` 作为映射。显示图形的界限是通过 `plt.xlim` 和 `plt.ylim` 来设置的。为了标记轴上的值，我们需要使用 `plt.xticks`
    和 `plt.yticks`。这些函数通过值标记轴，这样我们更容易看到点的位置。在先前的代码中，我们希望刻度位于最小值和最大值之间，并有一个单位宽度的缓冲区。同时，我们希望这些刻度是整数。因此，我们使用
    `int()` 函数来四舍五入值。
- en: 'If you run this code, you should see the following output:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行这段代码，你应该看到以下输出：
- en: '![](img/34c330f7-3444-4265-b0cd-f37c27e72382.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/34c330f7-3444-4265-b0cd-f37c27e72382.png)'
- en: 'Let''s see how the `C` parameter affects our model. The `C` parameter indicates
    the penalty for misclassification. If we set it to `1.0`, we will get the following:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看 `C` 参数如何影响我们的模型。`C` 参数表示误分类的惩罚。如果我们将其设置为 `1.0`，我们将得到以下结果：
- en: '![](img/72defd40-8554-499b-b9ef-562ef7291b64.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/72defd40-8554-499b-b9ef-562ef7291b64.png)'
- en: 'If we set `C` to `10000`, we get the following:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们将 `C` 设置为 `10000`，我们将得到以下结果：
- en: '![](img/ac2af76f-7377-4329-a287-9e74512b7094.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac2af76f-7377-4329-a287-9e74512b7094.png)'
- en: As we increase `C`, there is a higher penalty for misclassification. Hence,
    the boundaries become more optimized.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 随着C的增加，误分类的惩罚更高。因此，边界变得更加优化。
- en: How it works...
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '**Logistic regression** is a classification method within the family of supervised
    learning algorithms. Using statistical methods, logistic regression allows us
    to generate a result that, in fact, represents a probability that a given input
    value belongs to a given class. In binomial logistic regression problems, the
    probability that output belongs to a class will be *P*, whereas the probability
    of it belonging to another class will be *1-P* (where *P* is a number between
    0 and 1 because it expresses probability).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归**是监督学习算法家族中的分类方法。使用统计方法，逻辑回归允许我们生成一个结果，实际上它代表了一个给定输入值属于给定类的概率。在二项逻辑回归问题中，输出属于某一类的概率将是
    *P*，而属于另一类的概率将是 *1-P*（其中 *P* 是一个介于0和1之间的数字，因为它表示概率）。'
- en: 'Logistic regression uses the logistic function to determine the classification
    of input values. Also called the **sigmoid** function, the logistic function is
    an S-shaped curve that can take any number of of a real value and map it to a
    value between 0 and 1, extremes excluded. It can be described by the following
    equation:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归使用逻辑函数来确定输入值的分类。也称为**Sigmoid**函数，逻辑函数是一个S形曲线，可以将任何实数值映射到0到1之间的值（不包括极端值）。它可以由以下方程描述：
- en: '![](img/00e3c0f7-9412-4655-95a8-116901dcc226.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00e3c0f7-9412-4655-95a8-116901dcc226.png)'
- en: This function transforms the real values into numbers between 0 and 1.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将实数值转换为0到1之间的数字。
- en: There's more...
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'To obtain the logistic regression equation expressed in probabilistic terms,
    we need to include the probabilities in the logistic regression equation:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得用概率术语表示的逻辑回归方程，我们需要在逻辑回归方程中包含概率：
- en: '![](img/416b339e-3214-4a8f-bab8-433e2a986a65.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/416b339e-3214-4a8f-bab8-433e2a986a65.png)'
- en: 'Recalling that the `e` function is the opposite of the natural logarithm (`ln`),
    we can write:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，`e` 函数是自然对数（`ln`）的逆函数，我们可以写出：
- en: '![](img/1ff52b3b-5cbb-41a7-b55b-cd2e44a6804e.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1ff52b3b-5cbb-41a7-b55b-cd2e44a6804e.png)'
- en: This function is called a **logit** function. The logit function, on the other
    hand, allows us to associate the probabilities (therefore, a value included between
    0 and 1) to the whole range of real numbers. It is a link function and represents
    the inverse of the logistic function.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数被称为 **logit** 函数。另一方面，logit 函数允许我们将概率（因此，一个介于 0 和 1 之间的值）与实数范围的全部关联起来。它是一个链接函数，代表逻辑函数的逆函数。
- en: See also
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: '*Logit Models for Binary Data*, Princeton University: [https://data.princeton.edu/](https://data.princeton.edu/wws509/notes/c3.pdf)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Logit Models for Binary Data*，普林斯顿大学：[https://data.princeton.edu/](https://data.princeton.edu/wws509/notes/c3.pdf)'
- en: '*Regression Analysis with R*, Giuseppe Ciaburro, Packt Publishing'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 R 进行回归分析*，Giuseppe Ciaburro，Packt 出版'
- en: '[wws509/notes/c3.pdf](https://data.princeton.edu/wws509/notes/c3.pdf)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[wws509/notes/c3.pdf](https://data.princeton.edu/wws509/notes/c3.pdf)'
- en: Matplotlib color scheme options: [https://matplotlib.org/examples/color/colormaps_reference.html](http://matplotlib.org/examples/color/colormaps_reference.html)
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib 颜色方案选项：[https://matplotlib.org/examples/color/colormaps_reference.html](http://matplotlib.org/examples/color/colormaps_reference.html)
- en: Building a Naive Bayes classifier
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建朴素贝叶斯分类器
- en: A classifier solves the problem of identifying sub-populations of individuals
    with certain features in a larger set, with the possible use of a subset of individuals
    known as a priori (a training set). A Naive Bayes classifier is a supervised learning
    classifier that uses Bayes' theorem to build the model. In this recipe, we will
    build a Naive Bayes classifier.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器解决的是在较大集合中识别具有某些特征的个人子集的问题，可能使用一组称为先验（训练集）的个人子集。朴素贝叶斯分类器是一种监督学习分类器，它使用贝叶斯定理来构建模型。在本教程中，我们将构建一个朴素贝叶斯分类器。
- en: Getting ready
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The underlying principle of a Bayesian classifier is that some individuals belong
    to a class of interest with a given probability based on some observations. This
    probability is based on the assumption that the characteristics observed can be
    either dependent or independent from one another; in this second case, the Bayesian
    classifier is called Naive because it assumes that the presence or absence of
    a particular characteristic in a given class of interest is not related to the
    presence or absence of other characteristics, greatly simplifying the calculation.
    Let's go ahead and build a Naive Bayes classifier.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯分类器的潜在原理是，某些个人基于某些观察结果，以一定的概率属于感兴趣的类别。这个概率基于这样的假设，即观察到的特征可以是相互依赖的或相互独立的；在第二种情况下，贝叶斯分类器被称为朴素，因为它假设在感兴趣的类别中，特定特征的呈现或缺失与其他特征的呈现或缺失无关，这大大简化了计算。让我们继续构建朴素贝叶斯分类器。
- en: How to do it…
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Let''s see how to build a Naive Bayes classifier:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建朴素贝叶斯分类器：
- en: 'We will use `naive_bayes.py`, provided to you as a reference. Let''s import
    some libraries:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用提供的 `naive_bayes.py` 作为参考。让我们导入一些库：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You were provided with a `data_multivar.txt` file. This contains data that
    we will use here. This contains comma-separated numerical data in each line. Let''s
    load the data from this file:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您提供了一个 `data_multivar.txt` 文件。这个文件包含我们将在这里使用的数据。每行包含逗号分隔的数值数据。让我们从这个文件中加载数据：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We have now loaded the input data into `X` and the labels into `y`. There are
    four labels: 0, 1, 2, and 3.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已将输入数据加载到 `X` 中，并将标签加载到 `y` 中。有四个标签：0、1、2 和 3。
- en: 'Let''s build the Naive Bayes classifier:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们构建朴素贝叶斯分类器：
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `gauusiannb` function specifies the Gaussian Naive Bayes model.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`gauusiannb` 函数指定高斯朴素贝叶斯模型。'
- en: 'Let''s compute the `accuracy` measure of the classifier:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算分类器的 `accuracy` 测量值：
- en: '[PRE17]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following accuracy is returned:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下准确度：
- en: '[PRE18]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s plot the data and the boundaries. We will use the procedure followed
    in the previous recipe, *Building a logistic regression classifier*:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制数据和边界。我们将使用在先前的教程中遵循的程序，*构建逻辑回归分类器*：
- en: '[PRE19]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You should see the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下内容：
- en: '![](img/b8c4578e-99bb-4249-ba9e-1658a56cffc9.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b8c4578e-99bb-4249-ba9e-1658a56cffc9.png)'
- en: There is no restriction on the boundaries to be linear here. In the preceding
    recipe, *Building a logistic regression classifier*, we used up all the data for
    training. A good practice in machine learning is to have non-overlapping data
    for training and testing. Ideally, we need some unused data for testing so that
    we can get an accurate estimate of how the model performs on unknown data. There
    is a provision in `scikit-learn` that handles this very well, as shown in the
    next recipe.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里对边界的限制没有线性要求。在前面的配方中， *构建逻辑回归分类器*，我们使用了所有数据进行训练。在机器学习中，有一个好的做法是训练和测试数据不重叠。理想情况下，我们需要一些未使用的数据进行测试，以便我们可以准确估计模型在未知数据上的表现。`scikit-learn`
    中有一个很好的处理这个问题的方案，如下一个配方所示。
- en: How it works...
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: A **Bayesian classifier** is a classifier based on the application of Bayes'
    theorem. This classifier requires the knowledge of a priori and conditional probabilities
    related to the problem; quantities that, in general, are not known but are typically
    estimable. If reliable estimates of the probabilities involved in the theorem
    can be obtained, the Bayesian classifier is generally reliable and potentially
    compact.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**贝叶斯分类器** 是基于贝叶斯定理应用的分类器。这个分类器需要有关问题的先验和条件概率的知识；这些量通常未知，但通常是可估计的。如果可以获取定理中涉及的概率的可靠估计，贝叶斯分类器通常是可靠的，并且可能是紧凑的。'
- en: 'The probability that a given event (*E*) occurs, is the ratio between the number
    (*s*) of favorable cases of the event itself and the total number (*n*) of the
    possible cases, provided all the considered cases are equally probable. This can
    be better represented using the following formula:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 给定事件 (*E*) 发生的概率，是事件本身有利情况的数量 (*s*) 与可能情况总数 (*n*) 的比率，前提是所有考虑的情况都是等可能的。这可以用以下公式更好地表示：
- en: '![](img/a6c805cf-487c-462a-aeb1-c403af96d89d.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a6c805cf-487c-462a-aeb1-c403af96d89d.png)'
- en: 'Given two events, *A* and *B*, if the two events are independent (the occurrence
    of one does not affect the probability of the other), the joint probability of
    the event is equal to the product of the probabilities of *A* and *B*:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 给定两个事件， *A* 和 *B*，如果这两个事件是独立的（一个事件的发生不影响另一个事件发生的概率），那么事件的联合概率等于 *A* 和 *B* 的概率乘积：
- en: '![](img/79748dbb-b02c-44a6-b528-0b310abefd67.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/79748dbb-b02c-44a6-b528-0b310abefd67.png)'
- en: 'If the two events are dependent (that is, the occurrence of one affects the
    probability of the other), then the same rule may apply, provided *P(B | A)* is
    the probability of event *A* given that event *B* has occurred. This condition
    introduces conditional probability, which we are going to dive into now:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个事件是相关的（即，一个事件的发生会影响另一个事件发生的概率），那么相同的规则可能适用，前提是 *P(B | A)* 是在事件 *B* 发生的情况下事件
    *A* 发生的概率。这个条件引入了条件概率，我们现在将深入探讨：
- en: '![](img/53491427-e7b8-4df8-bddc-9a084ac16632.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/53491427-e7b8-4df8-bddc-9a084ac16632.png)'
- en: 'The probability that event *A* occurs, calculated on the condition that event
    *B* occurred, is called **conditional probability**, and is indicated by *P(A
    | B)*. It is calculated using the following formula:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件 *B* 发生的条件下，计算事件 *A* 发生的概率被称为 **条件概率**，用 *P(A | B)* 表示。它是使用以下公式计算的：
- en: '![](img/cba40f96-9806-4cb3-8c79-9854a24051cd.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cba40f96-9806-4cb3-8c79-9854a24051cd.png)'
- en: 'Let *A* and *B* be two dependent events, as we stated that the joint probability
    between them is calculated using the following formula:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 设 *A* 和 *B* 为两个相关事件，正如我们所述，它们之间的联合概率是使用以下公式计算的：
- en: '![](img/08b9a04b-428f-404e-b067-96923b283638.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/08b9a04b-428f-404e-b067-96923b283638.png)'
- en: 'Or, similarly, we can use the following formula:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，类似地，我们可以使用以下公式：
- en: '![](img/0bc29719-ee15-483d-b8e6-a1e6125e4f59.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0bc29719-ee15-483d-b8e6-a1e6125e4f59.png)'
- en: 'By looking at the two formulas, we see that they have the first equal member.
    This shows that even the second members are equal, so the following equation can
    be written:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察这两个公式，我们看到它们有第一个相等的成员。这表明即使第二个成员也相等，所以可以写出以下方程：
- en: '![](img/a06d2fd7-d73f-471d-a77f-e3675deab9c8.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a06d2fd7-d73f-471d-a77f-e3675deab9c8.png)'
- en: 'By solving these equations for conditional probability, we get the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解这些关于条件概率的方程，我们得到以下结果：
- en: '![](img/a145cfc1-adaf-4937-8bd2-f1bca05834ef.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a145cfc1-adaf-4937-8bd2-f1bca05834ef.png)'
- en: The proposed formulas represent the mathematical statement of Bayes' theorem.
    The use of one or the other depends on what we are looking for.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的公式代表了贝叶斯定理的数学表述。使用哪一个取决于我们寻找什么。
- en: There's more...
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In 1763, an article by Reverend Thomas Bayes was published in England; the
    article became famous for its implications. According to the article, making predictions
    about a phenomenon depends not only on the observations that the scientist obtains
    from his experiments, but also on what he himself thinks and understands of the
    phenomenon studied, even before proceeding to the experiment itself. These premises
    were developed in the 1900s by distinguished scholars, such as Bruno de Finetti
    (*La prévision: ses lois logiques, ses sources subjectives*, 1937), L J Savage
    (*The Fondations of statistics Reconsidered*, 1959), and others.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 1763年，托马斯·贝叶斯牧师在英国发表了一篇文章；这篇文章因其含义而闻名。根据文章，对现象的预测不仅取决于科学家从实验中获得的观察结果，还取决于他自己对研究现象的看法和理解，甚至在开始实验之前。这些前提在20世纪由一些杰出的学者发展，如布鲁诺·德·菲尼蒂（*《预测：其逻辑法则，其主观来源》，1937年*），L
    J 萨维奇（*《统计学基础再思考》，1959年*）等人。
- en: See also
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Keras 2.x Projects*, Giuseppe Ciaburro, Packt Publishing.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Keras 2.x 项目*，Giuseppe Ciaburro，Packt 出版。'
- en: '*Bayes'' Theorem*, Stanford Encyclopedia of Philosophy: [https://plato.stanford.edu/entries/bayes-theorem/](https://plato.stanford.edu/entries/bayes-theorem/)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*贝叶斯定理*，斯坦福哲学百科全书：[https://plato.stanford.edu/entries/bayes-theorem/](https://plato.stanford.edu/entries/bayes-theorem/)'
- en: 'The official documentation of the `sklearn.naive_bayes.GaussianNB` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.naive_bayes.GaussianNB`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)'
- en: Splitting a dataset for training and testing
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分割数据集以进行训练和测试
- en: Let's see how to split our data properly into training and testing datasets.
    As we said in [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml), *The Realm
    of Supervised Learning*, in the *Building a linear regressor* recipe, when we
    build a machine learning model, we need a way to validate our model to check whether
    it is performing at a satisfactory level. To do this, we need to separate our
    data into two groups—a **training** dataset and a **testing** dataset. The training
    dataset will be used to build the model, and the testing dataset will be used
    to see how this trained model performs on unknown data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何正确地将我们的数据分割成训练集和测试集。正如我们在[第1章](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml)中提到的，*监督学习领域*，在*构建线性回归器*配方中，当我们构建机器学习模型时，我们需要一种方法来验证我们的模型，以检查其是否在令人满意的水平上运行。为此，我们需要将我们的数据分成两组——一个**训练**集和一个**测试**集。训练集将用于构建模型，测试集将用于查看训练好的模型在未知数据上的表现。
- en: In this recipe, we will learn how to split the dataset for training and testing
    phases.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将学习如何分割数据集以进行训练和测试阶段。
- en: Getting ready
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The fundamental objective of a model based on machine learning is to make accurate
    predictions. Before using a model to make predictions, it is necessary to evaluate
    the predictive performance of the model. To estimate the quality of a model''s
    predictions, it is necessary to use data that you have never seen before. Training
    a predictive model and testing it on the same data is a methodological error:
    a model that simply classifies the labels of samples it has just seen would have
    a high score but would not be able to predict the new data class. Under these
    conditions, the generalization capacity of the model would be less.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 基于机器学习的模型的基本目标是做出准确的预测。在使用模型进行预测之前，有必要评估模型的预测性能。为了估计模型预测的质量，有必要使用你以前从未见过的数据。在相同的数据上训练预测模型并进行测试是一种方法上的错误：一个仅仅对刚刚看到的样本标签进行分类的模型会有很高的分数，但无法预测新的数据类别。在这些条件下，模型的泛化能力会较低。
- en: How to do it…
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Let''s see how to split the dataset:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何分割数据集：
- en: 'The first part of the recipe is similar to the previous recipe, *Building a
    Naive Bayes classifier* (load the `Splitting_dataset.py` file):'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配方的第一部分与之前的配方类似，*构建朴素贝叶斯分类器*（加载`Splitting_dataset.py`文件）：
- en: '[PRE20]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here, we allocated 25% of the data for testing, as specified by the `test_size`
    parameter. The remaining 75% of the data will be used for training.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们按照`test_size`参数指定的，分配了25%的数据用于测试，剩余的75%数据将用于训练。
- en: 'Let''s evaluate the classifier on the test data:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在测试数据上评估分类器：
- en: '[PRE21]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s compute the `accuracy` measure of the classifier:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算分类器的`accuracy`度量：
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following result is printed:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出以下结果：
- en: '[PRE23]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let''s plot the datapoints and the boundaries on the test data:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在测试数据上绘制数据点和边界：
- en: '[PRE24]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You should see the following:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该看到以下内容：
- en: '![](img/562ba592-f77d-4143-b8f7-ebeadc718a95.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/562ba592-f77d-4143-b8f7-ebeadc718a95.png)'
- en: How it works...
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we split the data using the `train_test_split()` function of
    the `scikit-learn` library. This function splits arrays or matrices into random
    train and testing subsets. Random division of input data into data sources for
    training and testing ensures that data distribution is similar for training and
    testing data sources. You choose this option when it is not necessary to preserve
    the order of the input data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用`scikit-learn`库的`train_test_split()`函数来分割数据。这个函数将数组或矩阵分割成随机的训练和测试子集。将输入数据随机分割成训练和测试数据源确保了训练和测试数据源的数据分布相似。当不需要保留输入数据的顺序时，您可以选择此选项。
- en: There's more...
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The performance estimate depends on the data used. Therefore, simply dividing
    data randomly into a training and a testing set does not guarantee that the results
    are statistically significant. The repetition of the evaluation on different random
    divisions and the calculation of the performance in terms of the average and standard
    deviation of the individual evaluations creates a more reliable estimate.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 性能估计取决于所使用的数据。因此，简单地将数据随机分割成训练和测试集并不能保证结果具有统计学意义。在不同随机分割上重复评估以及计算性能的平均值和标准差可以创建一个更可靠的估计。
- en: However, even the repetition of evaluations on different random divisions could
    prevent the most complex data being classified in the testing (or training) phase.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使在不同的随机分割上重复评估，也可能防止最复杂的数据在测试（或训练）阶段被分类。
- en: See also
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考阅读
- en: 'The official documentation of the `sklearn.model_selection.train_test_split`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection.train_test_split`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)'
- en: '*Data Splitting*, Charles University: [https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf](https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据分割*，查尔斯大学：[https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf](https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf)'
- en: Evaluating accuracy using cross-validation metrics
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用交叉验证指标评估精度
- en: '**Cross-validation** is an important concept in machine learning. In the previous
    recipe, we split the data into training and testing datasets. However, in order
    to make it more robust, we need to repeat this process with different subsets.
    If we just fine-tune it for a particular subset, we may end up overfitting the
    model. **Overfitting** refers to a situation where we fine-tune a model to a dataset
    too much and it fails to perform well on unknown data. We want our machine learning
    model to perform well on unknown data. In this recipe, we will learn how to evaluate
    model accuracy using cross-validation metrics.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**交叉验证**是机器学习中的一个重要概念。在前一个菜谱中，我们将数据分割成训练和测试数据集。然而，为了使其更加稳健，我们需要用不同的子集重复这个过程。如果我们只为特定的子集微调，我们可能会过度拟合模型。**过度拟合**是指我们将模型过度微调到数据集上，以至于它在未知数据上的表现不佳。我们希望我们的机器学习模型在未知数据上表现良好。在这个菜谱中，我们将学习如何使用交叉验证指标来评估模型精度。'
- en: Getting ready…
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作…
- en: When we are dealing with machine learning models, we usually care about three
    things—precision, recall, and F1 score. We can get the required performance metric
    using parameter scoring. **Precision** refers to the number of items that are
    correctly classified as a percentage of the overall number of items in the list.
    **Recall** refers to the number of items that are retrieved as a percentage of
    the overall number of items in the training list.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理机器学习模型时，我们通常关注三个指标——精确度、召回率和F1分数。我们可以使用参数评分来获取所需性能指标。**精确度**是指正确分类的项目数占列表中所有项目总数的百分比。**召回率**是指检索到的项目数占训练列表中所有项目总数的百分比。
- en: How to do it…
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Let''s see how to evaluate model accuracy using cross-validation metrics:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用交叉验证指标来评估模型精度：
- en: 'We will use the classifier just used in the *Building a Naive Bayes* classifier
    recipe (load the `naive_bayes.py` file). We will start with the `accuracy` measure:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用在*构建朴素贝叶斯分类器*配方中使用的分类器（加载`naive_bayes.py`文件）。我们将从`准确度`度量开始：
- en: '[PRE25]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We will use the preceding function to compute `precision`, `recall`, and the
    `F1` score as well:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用前面的函数来计算`精确度`、`召回率`和`F1`分数：
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s consider a test dataset containing 100 items, out of which 82 are of
    interest to us. Now, we want our classifier to identify these 82 items for us.
    Our classifier picks out 73 items as the items of interest. Out of these 73 items,
    only 65 are actually items of interest, and the remaining 8 are misclassified.
    We can compute precision in the following way:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个包含100个项目的测试数据集，其中82个对我们来说是有兴趣的。现在，我们希望我们的分类器为我们识别这82个项目。我们的分类器挑选出73个项目作为感兴趣的项目。在这些73个项目中，只有65个实际上是感兴趣的项目，其余的8个被错误分类。我们可以以下方式计算精确度：
- en: The number of correct identifications = 65
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确识别的数量 = 65
- en: The total number of identifications = 73
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别的总数 = 73
- en: Precision = 65 / 73 = 89.04%
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度 = 65 / 73 = 89.04%
- en: 'To compute recall, we use the following:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算召回率，我们使用以下方法：
- en: The total number of items of interest in the dataset = 82
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中感兴趣项目的总数 = 82
- en: The number of items retrieved correctly = 65
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确检索的项目数量 = 65
- en: Recall = 65 / 82 = 79.26%
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率 = 65 / 82 = 79.26%
- en: 'A good machine learning model needs to have good precision and good recall
    simultaneously. It''s easy to get one of them to 100%, but the other metric suffers!
    We need to keep both metrics high at the same time. To quantify this, we use an
    F1 score, which is a combination of precision and recall. This is actually the
    harmonic mean of precision and recall:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的机器学习模型需要同时具有良好的精确度和良好的召回率。虽然很容易使其中一个达到100%，但另一个指标会受到影响！我们需要同时保持这两个指标都很高。为了量化这一点，我们使用F1分数，它是精确度和召回率的组合。这实际上是精确度和召回率的调和平均数：
- en: '![](img/c9aa3ca0-efcb-46da-a9ef-329b618d3b7e.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c9aa3ca0-efcb-46da-a9ef-329b618d3b7e.png)'
- en: 'In the preceding case, the F1 score will be as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的情况下，F1分数将如下：
- en: '![](img/1af8b3e1-849e-432e-816b-5b30076ce4c4.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1af8b3e1-849e-432e-816b-5b30076ce4c4.png)'
- en: There's more...
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In cross-validation, all available data is used, in groups of a fixed size,
    alternatively as a testing and as a training set. Therefore, each pattern is either
    classified (at least once) or used for training. The performances obtained depend,
    however, on the particular division. Therefore, it may be useful to repeat cross-validation
    several times in order to become independent of the particular division.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在交叉验证中，所有可用数据都按固定大小的组交替作为测试集和训练集使用。因此，每个模式要么被分类（至少一次），要么用于训练。然而，所获得的效果取决于特定的划分。因此，重复交叉验证几次可能是有用的，以便独立于特定的划分。
- en: See also
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The official documentation of the `sklearn.model_selection.cross_val_score`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection.cross_val_score`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)'
- en: '*Cross-validation* (from scikit-learn''s official documentation): [http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/cross_validation.html](http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/cross_validation.html)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*交叉验证*（来自scikit-learn官方文档）：[http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/cross_validation.html](http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/cross_validation.html)'
- en: Visualizing a confusion matrix
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化混淆矩阵
- en: 'A **confusion matrix** is a table that we use to understand the performance
    of a classification model. This helps us understand how we classify testing data
    into different classes. When we want to fine-tune our algorithms, we need to understand
    how data gets misclassified before we make these changes. Some classes are worse
    than others, and the confusion matrix will help us understand this. Let''s look
    at the following:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆矩阵**是一个表格，我们用它来了解分类模型的性能。这有助于我们了解如何将测试数据分类到不同的类别。当我们想要微调我们的算法时，我们需要在做出这些更改之前了解数据是如何被错误分类的。有些类别比其他类别更差，混淆矩阵将帮助我们了解这一点。让我们看看以下内容：'
- en: '![](img/d1564065-1bf8-4576-ac73-5c69187fd71f.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d1564065-1bf8-4576-ac73-5c69187fd71f.png)'
- en: In the preceding diagram, we can see how we categorize data into different classes.
    Ideally, we want all the non-diagonal elements to be 0\. This would indicate perfect
    classification! Let's consider class 0\. Overall, 52 items actually belong to
    class 0\. We get 52 if we sum up the numbers in the first row. Now, 45 of these
    items are being predicted correctly, but our classifier says that 4 of them belong
    to class 1 and three of them belong to class 2\. We can apply the same analysis
    to the remaining 2 rows as well. An interesting thing to note is that 11 items
    from class 1 are misclassified as class 0\. This constitutes around 16% of the
    datapoints in this class. This is an insight that we can use to optimize our model.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，我们可以看到我们如何将数据分类到不同的类别中。理想情况下，我们希望所有非对角线元素都是 0。这将表示完美的分类！让我们考虑类别 0。总体而言，52
    个项目实际上属于类别 0。如果我们把第一行的数字加起来，我们会得到 52。现在，其中 45 个项目被正确预测，但我们的分类器说其中 4 个属于类别 1，3
    个属于类别 2。我们可以对剩余的 2 行也进行同样的分析。值得注意的是，有 11 个来自类别 1 的项目被错误分类为类别 0。这构成了这个类别中数据点的约
    16%。这是一个我们可以用来优化我们模型的见解。
- en: Getting ready
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: A confusion matrix identifies the nature of the classification errors, as our
    classification results are compared to real data. In this matrix, the diagonal
    cells show the number of cases that were correctly classified; all the others
    cells show the misclassified cases.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵确定了分类错误的性质，因为我们的分类结果与真实数据进行了比较。在这个矩阵中，对角线单元格显示了正确分类的案例数量；所有其他单元格显示了错误分类的案例。
- en: How to do it…
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to visualize the confusion matrix:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何可视化混淆矩阵：
- en: 'We will use the `confusion_matrix.py` file that we already provided to you
    as a reference. Let''s see how to extract the confusion matrix from our data:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用您已经提供的 `confusion_matrix.py` 文件作为参考。让我们看看如何从我们的数据中提取混淆矩阵：
- en: '[PRE27]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We use some sample data here. We have 4 classes with values ranging from 0 to
    3\. We have predicted labels as well. We use the `confusion_matrix` method to
    extract the confusion matrix and plot it.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用一些样本数据。我们有 4 个类别，其值从 0 到 3。我们还有预测标签。我们使用 `confusion_matrix` 方法提取混淆矩阵并绘制它。
- en: 'Let''s go ahead and define this function:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们继续定义这个函数：
- en: '[PRE28]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We use the `imshow` function to plot the confusion matrix. Everything else in
    the function is straightforward! We just set the title, color bar, ticks, and
    the labels using the relevant functions. The `tick_marks` argument range from
    0 to 3 because we have 4 distinct labels in our dataset. The `np.arange` function
    gives us this `numpy` array.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `imshow` 函数来绘制混淆矩阵。函数中的其他一切都很简单！我们只是使用相关函数设置标题、颜色条、刻度和标签。`tick_marks` 参数从
    0 到 3，因为我们数据集中有 4 个不同的标签。`np.arange` 函数给我们这个 `numpy` 数组。
- en: 'Let''s define the data (real and predicted) and then we will call the `confusion_matrix`
    function:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义数据（真实和预测），然后我们将调用 `confusion_matrix` 函数：
- en: '[PRE29]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If you run the preceding code, you will see the following:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行前面的代码，你会看到以下内容：
- en: '![](img/a194b459-0515-4dde-9a5c-fa1fd33ecbe9.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a194b459-0515-4dde-9a5c-fa1fd33ecbe9.png)'
- en: The diagonal colors are strong, and we want them to be strong. The black color
    indicates zero. There are a couple of gray squares in the non-diagonal spaces,
    which indicate misclassification. For example, when the real label is 0, the predicted
    label is 1, as we can see in the first row. In fact, all the misclassifications
    belong to class 1 in the sense that the second column contains 3 rows that are
    non-zero. It's easy to see this from the matrix.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对角线的颜色很强烈，我们希望它们很强烈。黑色表示零。非对角线空间中有几个灰色方块，表示错误分类。例如，当真实标签为 0 时，预测标签为 1，正如我们在第一行中看到的那样。实际上，所有错误分类都属于类别
    1，因为在第二列中有 3 行非零。从矩阵中很容易看出这一点。
- en: How it works...
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: A confusion matrix displays information about the actual and predicted classifications
    made by a model. The performance of such systems is evaluated with the help of
    data in the matrix.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵显示了模型做出的实际和预测分类的信息。这些系统的性能通过矩阵中的数据来评估。
- en: 'The following table shows the confusion matrix for a two-class classifier:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了双类分类器的混淆矩阵：
- en: '|  | PREDICTED POSITIVE | PREDICTED NEGATIVE |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | 预测为正 | 预测为负 |'
- en: '| **Actual TRUE** | TP | FN |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| **实际为真** | TP | FN |'
- en: '| **Actual FALSE** | FP | TN |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| **实际为假** | FP | TN |'
- en: 'The entries in the confusion matrix have the following meanings:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵中的条目具有以下含义：
- en: TP is the number of correct predictions that an instance is positive
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP 表示一个实例被正确预测为正数的正确预测数量
- en: FN is the number of incorrect predictions that an instance is negative
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FN 是一个实例被错误地预测为负的预测数量
- en: FP is the number of incorrect predictions that an instance is positive
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FP 是一个实例被错误地预测为正的预测数量
- en: TN is the number of correct predictions that an instance is negative
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TN 是一个实例被正确预测为负的预测数量
- en: There's more...
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: The confusion matrix shows us the performance of an algorithm. Each row returns
    the instances in an actual class, while each column returns the instances in an
    expected class. The term *confusion matrix* results from the fact that it makes
    it easy to see whether the system is confusing two classes.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵显示了算法的性能。每一行返回实际类别的实例，而每一列返回预期类别的实例。*混淆矩阵*这一术语源于它使得容易看出系统是否混淆了两个类别。
- en: See also
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: 'The official documentation of the `sklearn.metrics.confusion_matrix()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.metrics.confusion_matrix()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)'
- en: '*Confusion Matrix*, University of Notre Dame: [https://www3.nd.edu/~busiforc/Confusion_Matrix.html](https://www3.nd.edu/~busiforc/Confusion_Matrix.html)'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*混淆矩阵*，圣母大学：[https://www3.nd.edu/~busiforc/Confusion_Matrix.html](https://www3.nd.edu/~busiforc/Confusion_Matrix.html)'
- en: Extracting a performance report
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取性能报告
- en: In the *Evaluating accuracy using cross-validation metrics* recipe, we calculated
    some metrics to measure the accuracy of the model. Let's remember its meaning.
    The accuracy returns the percentage of correct classifications. Precision returns
    the percentage of positive classifications that are correct. Recall (sensitivity)
    returns the percentage of positive elements of the testing set that have been
    classified as positive. Finally, in F1, both the precision and the recall are
    used to compute the score. In this recipe, we will learn how to extract a performance
    report.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *使用交叉验证指标评估准确度* 的配方中，我们计算了一些指标来衡量模型的准确度。让我们记住它的含义。准确度返回正确分类的百分比。精确度返回正确分类的正分类的百分比。召回率（灵敏度）返回测试集中被分类为正的正元素百分比。最后，在
    F1 中，精确度和召回率都用于计算分数。在这个配方中，我们将学习如何提取性能报告。
- en: Getting ready
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We also have a function in `scikit-learn` that can directly print the precision,
    recall, and F1 scores for us. Let's see how to do this.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `scikit-learn` 中还有一个可以直接打印精确度、召回率和 F1 分数的函数。让我们看看如何做这个。
- en: How to do it…
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to extract a performance report:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何提取性能报告：
- en: 'Add the following lines to a new Python file (load the `performance_report.py`
    file):'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下行添加到新的 Python 文件中（加载 `performance_report.py` 文件）：
- en: '[PRE30]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'If you run this code, you will see the following on your Terminal:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端上看到以下内容：
- en: '![](img/7e6c43dc-441a-4ce6-a256-d1fa06905490.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7e6c43dc-441a-4ce6-a256-d1fa06905490.png)'
- en: Instead of computing these metrics separately, you can directly use the preceding
    function to extract those statistics from your model.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是单独计算这些指标，你可以直接使用前面的函数从你的模型中提取这些统计数据。
- en: How it works...
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In this recipe, we used the `classification_report ()` function of the scikit-learn
    library to extract a performance report. This function builds a text report showing
    the main classification metrics. A text summary of the precision, recall, and
    the F1 score for each class is returned. Referring to the terms introduced in
    the confusion matrix addressed in the previous recipe, these metrics are calculated
    as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用了 scikit-learn 库的 `classification_report()` 函数来提取性能报告。此函数构建一个文本报告，显示主要的分类指标。返回每个类别的精确度、召回率和
    F1 分数的文本摘要。参照前一个配方中提到的混淆矩阵中的术语，这些指标按以下方式计算：
- en: The precision is the ratio tp / (tp + fp), where tp is the number of true positives
    and fp the number of false positives. The precision is the ability of the classifier
    to not label a sample that is negative as positive.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度是 tp / (tp + fp) 的比率，其中 tp 是真正例的数量，fp 是假正例的数量。精确度是分类器不将负样本标记为正样本的能力。
- en: The recall is the ratio tp / (tp + fn), where tp is the number of true positives
    and fn the number of false negatives. The recall is the ability of the classifier
    to find the positive samples.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率是 tp / (tp + fn) 的比率，其中 tp 是真正例的数量，fn 是假负例的数量。召回率是分类器找到正样本的能力。
- en: The F1 score is said to be a weighted harmonic mean of the precision and recall,
    where an F-beta score reaches its peak value at 1 and its lowest score at 0.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1 分数被认为是精确率和召回率的加权调和平均值，其中 F-beta 分数在 1 处达到峰值，在 0 处达到最低分。
- en: There's more...
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: The reported averages include the **micro average** (averaging the total true
    positives, false negatives, and false positives), the **macro average** (averaging
    the unweighted mean per label), the **weighted** **average** (averaging the support-weighted
    mean per label), and the **sample average** (only for multilabel classification).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 报告的平均值包括 **微观平均**（平均总真实阳性、假阴性和假阳性）、**宏观平均**（平均每个标签的无权平均值）、**加权平均**（平均每个标签的支持加权平均值）和
    **样本平均**（仅适用于多标签分类）。
- en: See also
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The official documentation of the `sklearn.metrics.classification_report()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.metrics.classification_report()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)'
- en: Evaluating cars based on their characteristics
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 根据汽车特征进行评估
- en: 'In this recipe, let''s see how we can apply classification techniques to a
    real-world problem. We will use a dataset that contains some details about cars,
    such as number of doors, boot space, maintenance costs, and so on. Our goal is
    to determine the quality of the car. For the purposes of classification, quality
    can take four values: unacceptable, acceptable, good, or very good.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将看看如何将分类技术应用于现实世界问题。我们将使用一个包含一些关于汽车细节的数据集，例如车门数量、后备箱空间、维护成本等。我们的目标是确定汽车的质量。对于分类的目的，质量可以取四个值：不可接受、可接受、良好或非常好。
- en: Getting ready
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: You can download the dataset at [https://archive.ics.uci.edu/ml/datasets/Car+Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处下载数据集：[https://archive.ics.uci.edu/ml/datasets/Car+Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation)。
- en: 'You need to treat each value in the dataset as a string. We consider six attributes
    in the dataset. Here are the attributes along with the possible values they can
    take:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要将数据集中的每个值都视为字符串。我们考虑数据集中的六个属性。以下是属性及其可能取的值：
- en: '`buying`: These will be `vhigh`, `high`, `med`, and `low`.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`buying`: 这些将是 `非常高`、`高`、`中` 和 `低`。'
- en: '`maint`: These will be `vhigh`, `high`, `med`, and `low`.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maint`: 这些将是 `非常高`、`高`、`中` 和 `低`。'
- en: '`doors`: These will be `2`, `3`, `4`, `5`, and `more`.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`doors`: 这些将是 `2`、`3`、`4`、`5` 和 `更多`。'
- en: '`persons`: These will be `2`, `4`, and `more`.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`persons`: 这些将是 `2`、`4` 和 `更多`。'
- en: '`lug_boot`: These will be `small`, `med`, and `big`.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lug_boot`: 这些将是 `小`、`中` 和 `大`。'
- en: '`safety`: These will be `low`, `med`, and `high`.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety`: 这些将是 `低`、`中` 和 `高`。'
- en: Given that each line contains strings, we need to assume that all the features
    are strings and design a classifier. In the previous chapter, we used random forests
    to build a regressor. In this recipe, we will use random forests as a classifier.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每行都包含字符串，我们需要假设所有特征都是字符串，并设计一个分类器。在上一章中，我们使用随机森林构建了一个回归器。在本食谱中，我们将使用随机森林作为分类器。
- en: How to do it…
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Let''s see how to evaluate cars based on their characteristics:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何根据汽车特征进行评估：
- en: 'We will use the `car.py` file that we already provided to you as reference.
    Let''s go ahead and import a couple of packages:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用您已经提供的 `car.py` 文件作为参考。让我们继续并导入一些包：
- en: '[PRE31]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let''s load the dataset:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载数据集：
- en: '[PRE32]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Each line contains a comma-separated list of words. Therefore, we parse the
    input file, split each line, and then append the list to the main data. We ignore
    the last character on each line because it's a newline character. Python packages
    only work with numerical data, so we need to transform these attributes into something
    that those packages will understand.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 每行包含一个以逗号分隔的单词列表。因此，我们解析输入文件，分割每一行，然后将列表追加到主数据中。我们忽略每行的最后一个字符，因为它是一个换行符。Python
    包只处理数值数据，因此我们需要将这些属性转换成那些包可以理解的形式。
- en: 'In the previous chapter, we discussed label encoding. That is what we will
    use here to convert strings to numbers:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了标签编码。这就是我们在这里将字符串转换为数字所使用的：
- en: '[PRE33]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: As each attribute can take a limited number of values, we can use the label
    encoder to transform them into numbers. We need to use different label encoders
    for each attribute. For example, the `lug_boot` attribute can take three distinct
    values, and we need a label encoder that knows how to encode this attribute. The
    last value on each line is the class, so we assign it to the *y* variable.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个属性可以取有限数量的值，我们可以使用标签编码器将它们转换为数字。我们需要为每个属性使用不同的标签编码器。例如，`lug_boot`属性可以取三个不同的值，我们需要一个知道如何编码这个属性的标签编码器。每行的最后一个值是类别，所以我们将其分配给*y*变量。
- en: 'Let''s train the classifier:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们训练分类器：
- en: '[PRE34]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: You can play around with the `n_estimators` and `max_depth` parameters to see
    how they affect classification accuracy. We will actually do this soon in a standardized
    way.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以调整`n_estimators`和`max_depth`参数，看看它们如何影响分类准确率。我们实际上很快就会以标准化的方式进行这项操作。
- en: 'Let''s perform cross-validation:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们进行交叉验证：
- en: '[PRE35]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Once we train the classifier, we need to see how it performs. We use three-fold
    cross-validation to calculate the accuracy here. The following result is returned:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们训练了分类器，我们需要看看它的表现。我们使用三折交叉验证来计算这里的准确率。以下结果被返回：
- en: '[PRE36]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'One of the main goals of building a classifier is to use it on isolated and
    unknown data instances. Let''s use a single datapoint and see how we can use this
    classifier to categorize it:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建分类器的主要目标之一是将其用于孤立和未知的数据实例。让我们使用一个数据点，看看我们如何使用这个分类器对其进行分类：
- en: '[PRE37]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The first step was to convert that data into numerical data. We need to use
    the label encoders that we used during training because we want it to be consistent.
    If there are unknown values in the input datapoint, the label encoder will complain
    because it doesn't know how to handle that data. For example, if you change the
    first value in the list from `high` to `abcd`, then the label encoder won't work
    because it doesn't know how to interpret this string. This acts like an error
    check to see whether the input datapoint is valid.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将数据转换为数值数据。我们需要使用在训练期间使用的标签编码器，因为我们希望它保持一致性。如果输入数据点中存在未知值，标签编码器会抱怨，因为它不知道如何处理这些数据。例如，如果你将列表中的第一个值从`high`改为`abcd`，那么标签编码器将无法工作，因为它不知道如何解释这个字符串。这就像一个错误检查，用来查看输入数据点是否有效。
- en: 'We are now ready to predict the output class for this datapoint:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好预测这个数据点的输出类别：
- en: '[PRE38]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We use the `predict()` method to estimate the output class. If we output the
    encoded output label, it won''t mean anything to us. Therefore, we use the `inverse_transform`
    method to convert this label back to its original form and print out the output
    class. The following result is returned:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`predict()`方法来估计输出类别。如果我们输出编码后的输出标签，对我们来说没有任何意义。因此，我们使用`inverse_transform`方法将此标签转换回其原始形式并打印输出类别。以下结果被返回：
- en: '[PRE39]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: How it works...
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The **random forest** was developed by Leo Breiman (University of California,
    Berkeley, USA) based on the use of classification trees. He has extended the classification
    tree technique by integrating it into a Monte Carlo simulation procedure and named
    it **random forest**. It is based on the creation of a large set of tree classifiers,
    each of which is proposed to classify a single instance, wherein some features
    have been evaluated. Comparing the classification proposals provided by each tree
    in the forest shows the class to which to attribute the request: it is the one
    that received the most votes.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机森林**是由Leo Breiman（美国加州大学伯克利分校）基于分类树的使用而开发的。他通过将其整合到蒙特卡洛模拟过程中扩展了分类树技术，并将其命名为**随机森林**。它基于创建大量树分类器，每个分类器都旨在对单个实例进行分类，其中一些特征已被评估。比较森林中每棵树提供的分类建议，以确定请求应归因于哪个类别：即获得最多投票的那个类别。'
- en: There's more...
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Random forest has three adjustment parameters: the number of trees, the minimum
    amplitude of the terminal nodes, and the number of variables sampled in each node.
    The absence of overfitting makes the first two parameters important only from
    a computational point of view.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林有三个调整参数：树的数量、终端节点的最小幅度以及每个节点中采样的变量数量。由于不存在过拟合，前两个参数仅从计算角度考虑才显得重要。
- en: See also
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The official documentation of the `sklearn.ensemble.RandomForestClassifier()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.ensemble.RandomForestClassifier()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)'
- en: '*Random Forests* by Leo Breiman and Adele Cutler (from the University of California,
    Berkeley): [https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*随机森林*，由Leo Breiman和Adele Cutler（加州大学伯克利分校）所著：[https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)'
- en: Extracting validation curves
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取验证曲线
- en: 'We used random forests to build a classifier in the previous recipe, *Evaluating
    cars based on their characteristics*, but we don''t exactly know how to define
    the parameters. In our case, we dealt with two parameters: `n_estimators` and
    `max_depth`. They are called **hyperparameters**, and the performance of the classifier
    depends on them. It would be nice to see how the performance gets affected as
    we change the hyperparameters. This is where validation curves come into the picture.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的食谱*根据特征评估汽车*中，我们使用了随机森林来构建分类器，但我们并不确切知道如何定义参数。在我们的情况下，我们处理了两个参数：`n_estimators`和`max_depth`。它们被称为**超参数**，分类器的性能取决于它们。看到我们改变超参数时性能如何受到影响将是非常有用的。这就是验证曲线发挥作用的地方。
- en: Getting ready
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Validation curves help us understand how each hyperparameter influences the
    training score. Basically, all other parameters are kept constant and we vary
    the hyperparameter of interest according to our range. We will then be able to
    visualize how this affects the score.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 验证曲线帮助我们理解每个超参数如何影响训练分数。基本上，所有其他参数都保持不变，我们根据我们的范围改变感兴趣的超参数。然后我们将能够可视化这如何影响分数。
- en: How to do it…
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Let''s see how to extract validation curves:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何提取验证曲线：
- en: 'Add the following code to the same Python file as in the previous recipe, *Evaluating
    cars based on their characteristics*:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码添加到与之前食谱相同的Python文件中，*根据特征评估汽车*：
- en: '[PRE40]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In this case, we defined the classifier by fixing the `max_depth` parameter.
    We want to estimate the optimal number of estimators to use, and so have defined
    our search space using `parameter_grid`. It is going to extract training and validation
    scores by iterating from 25 to 200 in 8 steps.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们通过固定`max_depth`参数来定义分类器。我们想要估计使用最佳估计器的数量，因此使用`parameter_grid`定义了我们的搜索空间。它将通过从25迭代到200，以8步为间隔来提取训练和验证分数。
- en: 'If you run it, you will see the following on your Terminal:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行它，你将在你的终端上看到以下内容：
- en: '![](img/1d6021de-2c8e-4628-aeeb-5e64c53c3e5f.png)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d6021de-2c8e-4628-aeeb-5e64c53c3e5f.png)'
- en: 'Let''s plot it:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制它：
- en: '[PRE41]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here is what you''ll get:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是你将得到的结果：
- en: '![](img/c6c67e06-26df-495b-9a64-833b85df460e.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6c67e06-26df-495b-9a64-833b85df460e.png)'
- en: 'Let''s do the same for the `max_depth` parameter:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们对`max_depth`参数做同样的操作：
- en: '[PRE42]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We fixed the `n_estimators` parameter at 20 to see how the performance varies
    with `max_depth`. Here is the output on the Terminal:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`n_estimators`参数固定为20，以查看性能如何随`max_depth`的变化而变化。以下是终端上的输出：
- en: '![](img/b9cd9ace-c7e5-44aa-835e-8745adf5c9ef.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b9cd9ace-c7e5-44aa-835e-8745adf5c9ef.png)'
- en: 'Let''s plot it:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制它：
- en: '[PRE43]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'If you run this code, you will get the following:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将得到以下结果：
- en: '![](img/359e4feb-d95f-438a-ab51-087000626f5d.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](img/359e4feb-d95f-438a-ab51-087000626f5d.png)'
- en: How it works...
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we used the `validation_curve` function of the scikit-learn
    library to plot the validation curve. This function determines training and test
    scores for varying parameter values and computes scores for an estimator with
    different values of a specified parameter.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们使用了scikit-learn库的`validation_curve`函数来绘制验证曲线。此函数确定不同参数值下的训练和测试分数，并计算具有不同参数值的估计器的分数。
- en: There's more...
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容…
- en: Choosing an estimator's hyperparameters is a fundamental procedure for setting
    up a model. Among the available procedures, grid search is one of the most used.
    This procedure selects the hyperparameter with the maximum score on a validation
    set or a multiple validation set.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 选择估计器的超参数是设置模型的基本程序之一。在可用的程序中，网格搜索是最常用的方法之一。此程序选择在验证集或多个验证集上具有最高分数的超参数。
- en: See also
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考阅读
- en: 'The official documentation of the `sklearn.model_selection.validation_curve()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection.validation_curve()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)'
- en: '*Validation curves: plotting scores to evaluate models* (from scikit-learn''s
    official documentation): [https://scikit-learn.org/stable/modules/learning_curve.html](https://scikit-learn.org/stable/modules/learning_curve.html)'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*验证曲线：绘制分数以评估模型*（来自scikit-learn的官方文档）：[https://scikit-learn.org/stable/modules/learning_curve.html](https://scikit-learn.org/stable/modules/learning_curve.html)'
- en: Extracting learning curves
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取学习曲线
- en: Learning curves help us understand how the size of our training dataset influences
    the machine learning model. This is very useful when you have to deal with computational
    constraints. Let's go ahead and plot learning curves by varying the size of our
    training dataset.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线帮助我们理解训练数据集的大小如何影响机器学习模型。当你必须处理计算限制时，这非常有用。让我们继续通过改变训练数据集的大小来绘制学习曲线。
- en: Getting ready
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: A learning curve shows the validation and training score of an estimator for
    varying numbers of training samples.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线显示了不同数量的训练样本的估计器的验证和训练分数。
- en: How to do it…
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to extract learning curves:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何提取学习曲线：
- en: 'Add the following code to the same Python file as in the previous recipe, *Extracting
    validation curves*:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码添加到与之前菜谱中相同的Python文件中，*提取验证曲线*：
- en: '[PRE44]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We want to evaluate the performance metrics using training datasets of 200,
    500, 800, and 1,100 samples. We use five-fold cross-validation, as specified by
    the cv parameter in the `validation_curve` method.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想使用200、500、800和1,100个样本的训练数据集来评估性能指标。我们使用五折交叉验证，如`validation_curve`方法中cv参数所指定的。
- en: 'If you run this code, you will get the following output on the Terminal:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在终端上得到以下输出：
- en: '![](img/47a5108a-7027-4eda-a025-d5a845516da1.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![](img/47a5108a-7027-4eda-a025-d5a845516da1.png)'
- en: 'Let''s plot it:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制它：
- en: '[PRE45]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Here is the output:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '![](img/5e35fc89-5c17-435c-a647-8ce915bf76a3.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5e35fc89-5c17-435c-a647-8ce915bf76a3.png)'
- en: Although smaller training sets seem to give better accuracy, they are prone
    to overfitting. If we choose a bigger training dataset, it consumes more resources.
    Therefore, we need to make a trade-off here to pick the right size for the training
    dataset.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然较小的训练集似乎能给出更好的准确度，但它们容易过拟合。如果我们选择更大的训练数据集，它会消耗更多资源。因此，我们需要在这里进行权衡，以选择合适的训练数据集大小。
- en: How it works...
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used the `validation_curve` function of the scikit-learn
    library to plot the learning curve. This function determines cross-validated training
    and testing scores for different training set sizes.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了scikit-learn库的`validation_curve`函数来绘制学习曲线。此函数确定不同训练集大小的交叉验证训练和测试分数。
- en: There's more...
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: A learning curve allows us to check whether the addition of training data leads
    to a benefit. It also allows us to estimate the contribution deriving from variance
    error and bias error. If the validation score and the training score converge
    with the size of the training set too low, we will not benefit from further training
    data.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线使我们能够检查添加训练数据是否带来好处。它还允许我们估计来自方差误差和偏差误差的贡献。如果验证分数和训练分数在训练集大小太低时与训练集大小收敛，我们将不会从更多的训练数据中受益。
- en: See also
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: 'The official documentation of the `sklearn.model_selection.validation_curve`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection.validation_curve` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)'
- en: '*Learning curve* (from scikit-learn''s official documentation): [https://scikit-learn.org/stable/modules/learning_curve.html](https://scikit-learn.org/stable/modules/learning_curve.html)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习曲线*（来自scikit-learn的官方文档）：[https://scikit-learn.org/stable/modules/learning_curve.html](https://scikit-learn.org/stable/modules/learning_curve.html)'
- en: Estimating the income bracket
  id: totrans-372
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算收入区间
- en: We will build a classifier to estimate the income bracket of a person based
    on 14 attributes. The possible output classes are higher than 50,000 or lower
    than or equal to 50,000\. There is a slight twist in this dataset, in the sense
    that each datapoint is a mixture of numbers and strings. Numerical data is valuable,
    and we cannot use a label encoder in these situations. We need to design a system
    that can deal with numerical and non-numerical data at the same time.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个分类器，根据14个属性估计一个人的收入区间。可能的输出类别是高于50,000或低于或等于50,000。在这个数据集中有一个小小的转折，即每个数据点都是数字和字符串的混合。数值数据很有价值，在这些情况下我们不能使用标签编码器。我们需要设计一个可以同时处理数值和非数值数据的系统。
- en: Getting ready
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use the census income dataset available at [https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/census+income).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用可从[https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/census+income)获取的普查收入数据集。
- en: 'The dataset has the following characteristics:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集具有以下特征：
- en: 'Number of instances: 48,842'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实例数量：48,842
- en: 'Number of attributes: 14'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 属性数量：14
- en: 'The following is a list of attributes:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个属性列表：
- en: 'Age: continuous'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Age: 连续型'
- en: 'Workclass: text'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Workclass: 文本'
- en: 'fnlwgt: continuous'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'fnlwgt: 连续型'
- en: 'Education: text'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Education: 文本'
- en: 'Education-num: continuous'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Education-num: 连续型'
- en: 'Marital-status: text'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Marital-status: 文本'
- en: 'Occupation: text'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Occupation: 文本'
- en: 'Relationship: text'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Relationship: 文本'
- en: 'Race: text'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Race: 文本'
- en: 'Sex: female or male'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sex: 女性 或 男性'
- en: 'Capital-gain: continuous'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Capital-gain: 连续型'
- en: 'Capital-loss: continuous'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Capital-loss: 连续型'
- en: 'Hours-per-week: continuous'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hours-per-week: 连续型'
- en: 'Native-country: text'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Native-country: 文本'
- en: How to do it…
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Let''s see how to estimate the income bracket:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何估计收入区间：
- en: 'We will use the `income.py` file, already provided to you as a reference. We
    will use a Naive Bayes classifier to achieve this. Let''s import a couple of packages:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用已提供的作为参考的`income.py`文件。我们将使用朴素贝叶斯分类器来实现这一点。让我们导入一些包：
- en: '[PRE46]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let''s load the dataset:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载数据集：
- en: '[PRE47]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We will use 20,000 datapoints from the datasets—10,000 for each class to avoid
    class imbalance. During training, if you use many datapoints that belong to a
    single class, the classifier tends to get biased toward that class. Therefore,
    it''s better to use the same number of datapoints for each class:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从数据集中使用20,000个数据点——每个类别10,000个，以避免类别不平衡。在训练过程中，如果你使用属于单个类别的许多数据点，分类器往往会偏向该类别。因此，最好为每个类别使用相同数量的数据点：
- en: '[PRE48]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: It's a comma-separated file again. We just loaded the data in the `X` variable
    just as before.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是一个以逗号分隔的文件。我们就像之前一样，将数据加载到`X`变量中。
- en: 'We need to convert string attributes to numerical data while leaving out the
    original numerical data:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将字符串属性转换为数值数据，同时保留原始数值数据：
- en: '[PRE49]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The `isdigit()` function helps us to identify numerical data. We converted string
    data to numerical data and stored all the label encoders in a list so that we
    can use it when we want to classify unknown data.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '`isdigit()`函数帮助我们识别数值数据。我们将字符串数据转换为数值数据，并将所有标签编码器存储在一个列表中，以便我们在需要分类未知数据时使用。'
- en: 'Let''s train the classifier:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们训练分类器：
- en: '[PRE50]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let''s split the data into training and testing to extract performance metrics:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据拆分为训练集和测试集以提取性能指标：
- en: '[PRE51]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let''s extract performance metrics:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们提取性能指标：
- en: '[PRE52]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The following result is returned:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE53]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Let''s see how to classify a single datapoint. We need to convert the datapoint
    into something that our classifier can understand:'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看如何对单个数据点进行分类。我们需要将数据点转换为我们的分类器可以理解的形式：
- en: '[PRE54]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We are now ready to classify it:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好进行分类：
- en: '[PRE55]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Just as before, we use the `predict` method to get the `output` class and the
    `inverse_transform` method to convert this label back to its original form to
    print it out on the Terminal. The following result is returned:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前一样，我们使用`predict`方法获取`output`类别，并使用`inverse_transform`方法将这个标签转换回其原始形式，以便在终端上打印出来。以下为返回结果：
- en: '[PRE56]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: How it works...
  id: totrans-420
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The underlying principle of a Bayesian classifier is that some individuals belong
    to a class of interest with a given probability based on some observations. This
    probability is based on the assumption that the characteristics observed can be
    dependent or independent from one another; in the second case, the Bayesian classifier
    is called *naive* because it assumes that the presence or absence of a particular
    characteristic in a given class of interest is not related to the presence or
    absence of other characteristics, greatly simplifying the calculation. Let's go
    ahead and build a Naive Bayes classifier.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯分类器的潜在原理是，基于某些观察，某些个体以一定的概率属于感兴趣的类别。这个概率基于这样的假设，即观察到的特征可以相互依赖或独立；在后一种情况下，贝叶斯分类器被称为*朴素*，因为它假设在感兴趣的给定类别中，特定特征的呈现与否与其他特征的呈现与否无关，这大大简化了计算。让我们继续构建一个朴素贝叶斯分类器。
- en: There's more...
  id: totrans-422
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'The concept of Bayes applied to classification is very intuitive: if I look
    at a particular measurable feature, I can estimate the probability that this feature
    represents a certain class after the observation.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 将贝叶斯理论应用于分类的概念非常直观：如果我观察一个特定的可测量特征，我可以在观察后估计这个特征代表某个类别的概率。
- en: See also
  id: totrans-424
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The official documentation of the `sklearn.naive_bayes.GaussianNB` function: [https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.naive_bayes.GaussianNB` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)'
- en: Predicting the quality of wine
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测葡萄酒的质量
- en: In this recipe, we will predict the quality of wine based on the chemical properties of
    wines grown. The code uses a wine dataset, which contains a DataFrame with 177
    rows and 13 columns; the first column contains the class labels. This data is
    obtained from the chemical analyses of wines grown in the same region in Italy
    (Piemonte) but derived from three different cultivars—namely, the Nebbiolo, Barberas,
    and Grignolino grapes. The wine from the Nebbiolo grape is called Barolo.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将根据种植的葡萄酒的化学特性来预测葡萄酒的质量。代码使用了一个葡萄酒数据集，它包含一个包含 177 行和 13 列的 DataFrame；第一列包含类别标签。这些数据来自意大利（皮埃蒙特）同一地区种植的葡萄酒的化学分析，但来自三种不同的品种——即内比奥洛、巴贝拉和格里尼奥洛葡萄。来自内比奥洛葡萄的葡萄酒被称为巴罗洛。
- en: Getting ready
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The data consists of the amounts of several constituents found in each of the
    three types of wines, as well as some spectroscopic variables. The attributes
    are as follows:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 数据包括在三种类型的葡萄酒中发现的几种成分的量，以及一些光谱变量。属性如下：
- en: Alcohol
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 酒精
- en: Malic acid
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 苹果酸
- en: Ash
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灰分
- en: Alcalinity of ash
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灰分的碱性
- en: Magnesium
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镁
- en: Total phenols
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总酚
- en: Flavanoids
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黄酮
- en: Nonflavanoid phenols
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非黄酮酚
- en: Proanthocyanins
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原花青素
- en: Color intensity
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜色强度
- en: Hue
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜色
- en: OD280/OD315 of diluted wines
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀释葡萄酒的 OD280/OD315
- en: Proline
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: �脯氨酸
- en: The first column of the DataFrame contains the class which indicates one of
    three types of wine as (0, 1, or 2).
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 的第一列包含类别，表示三种类型的葡萄酒之一（0、1或2）。
- en: How to do it…
  id: totrans-444
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to predict the quality of wine:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何预测葡萄酒的质量：
- en: 'We will use the `wine.quality.py` file, already provided to you as a reference. We
    start, as always, by importing the NumPy library and loading the data (`wine.txt`):'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用已提供的`wine.quality.py`文件作为参考。我们像往常一样，首先导入NumPy库并加载数据（`wine.txt`）：
- en: '[PRE57]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Two arrays are returned: `X` (input data), and `y` (target).'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 返回两个数组：`X`（输入数据）和`y`（目标）。
- en: 'Now we need to separate our data into two groups: a training dataset and a testing dataset.
    The training dataset will be used to build the model, and the testing dataset
    will be used to see how this trained model performs on unknown data:'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要将我们的数据分为两组：一个训练数据集和一个测试数据集。训练数据集将用于构建模型，测试数据集将用于查看这个训练模型在未知数据上的表现：
- en: '[PRE58]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Four arrays are returned: `X_train`, `X_test`, `y_train`, and `y_test`. This
    data will be used to train and validate the model.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 返回四个数组：`X_train`、`X_test`、`y_train`和`y_test`。这些数据将用于训练和验证模型。
- en: 'Let''s train the classifier:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们训练这个分类器：
- en: '[PRE59]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: To train the model, a decision tree algorithm has been used. A decision tree
    algorithm is based on a non-parametric supervised learning method used for classification
    and regression. The aim is to build a model that predicts the value of a target
    variable using decision rules inferred from the data features.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练模型，使用了决策树算法。决策树算法基于一种非参数监督学习方法，用于分类和回归。目标是构建一个模型，使用从数据特征推断出的决策规则来预测目标变量的值。
- en: 'Now it''s time to the compute accuracy of the classifier:'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是计算分类器准确率的时候了：
- en: '[PRE60]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The following result is returned:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE61]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, a confusion matrix will be calculated to compute the model performance:'
  id: totrans-459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将计算混淆矩阵以计算模型性能：
- en: '[PRE62]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The following result is returned:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE63]'
  id: totrans-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Values not present on the diagonals represent classification errors. So, only
    four errors were committed by the classifier.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 对角线上没有出现的值表示分类错误。因此，分类器只犯了四个错误。
- en: How it works...
  id: totrans-464
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, the quality of wine based on the chemical properties of wines
    grown was predicted. To do this, a decision tree algorithm was used. A decision
    tree shows graphically the choices made or proposed. It does not happen so often
    that things are so clear that the choice between two solutions is immediate. Often,
    a decision is determined by a series of cascading conditions. Representing this
    concept with tables and numbers is difficult. In fact, even if a table represents
    a phenomenon, it may confuse the reader because the justification for the choice
    is not obvious.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，基于种植的葡萄酒的化学性质预测了葡萄酒的质量。为此，使用了决策树算法。决策树以图形方式显示所做的或建议的选择。事情并不总是如此清晰，以至于两个解决方案之间的选择是立即的。通常，一个决定是由一系列级联条件决定的。用表格和数字表示这个概念是困难的。事实上，即使表格代表了一个现象，它也可能使读者困惑，因为选择的理由并不明显。
- en: There's more...
  id: totrans-466
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: A tree structure allows us to extract the information with clear legibility
    by highlighting the branch we have inserted to determine the choice or evaluation.
    Decision tree technology is useful for identifying a strategy or pursuing a goal
    by creating a model with probable results. The decision tree graph immediately
    orients the reading of the result. A plot is much more eloquent than a table full
    of numbers. The human mind prefers to see a solution first and then go back to
    understand a justification of the solution, instead of a series of algebraic descriptions,
    percentages, and data to describe a result.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 树状结构使我们能够通过突出显示我们插入的分支来确定选择或评估，从而以清晰的易读性提取信息。决策树技术通过创建一个具有可能结果的模型来识别策略或追求目标是有用的。决策树图立即指引结果的阅读。图表比充满数字的表格更有说服力。人类的大脑更喜欢先看到解决方案，然后再回头理解解决方案的合理性，而不是一系列代数描述、百分比和数据来描述结果。
- en: See also
  id: totrans-468
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The official documentation of the `sklearn.tree.DecisionTreeClassifier()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.tree.DecisionTreeClassifier()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)'
- en: '*Decision Trees* (from the University of Hildesheim, Germany): [https://www.ismll.uni-hildesheim.de/lehre/ml-06w/skript/ml-4up-04-decisiontrees.pdf](https://www.ismll.uni-hildesheim.de/lehre/ml-06w/skript/ml-4up-04-decisiontrees.pdf)'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*决策树*（来自德国希尔德斯海姆大学）：[https://www.ismll.uni-hildesheim.de/lehre/ml-06w/skript/ml-4up-04-decisiontrees.pdf](https://www.ismll.uni-hildesheim.de/lehre/ml-06w/skript/ml-4up-04-decisiontrees.pdf)'
- en: '*Decision Trees* (from scikit-learn''s official documentation): [https://scikit-learn.org/stable/modules/tree.html#tree](https://scikit-learn.org/stable/modules/tree.html#tree)'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*决策树*（来自scikit-learn官方文档）：[https://scikit-learn.org/stable/modules/tree.html#tree](https://scikit-learn.org/stable/modules/tree.html#tree)'
- en: Newsgroup trending topics classification
  id: totrans-472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新组趋势主题分类
- en: Newsgroups are discussion groups on many issues and are made available by news-servers,
    located all over the world, which collect messages from clients and transmit them,
    on the one hand, to all their users and, on the other, to other news-servers connected
    to the network. The success of this technology is due to user interaction in discussions.
    Everyone has to respect the rules of the group.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 新闻组是关于许多问题的讨论组，由位于世界各地的新闻服务器提供，这些服务器收集来自客户端的消息并将它们传输给所有用户，另一方面，传输给连接到网络的其它新闻服务器。这项技术的成功归功于讨论中的用户互动。每个人都必须遵守组规。
- en: Getting ready
  id: totrans-474
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, we will build a classifier that will allow us to classify the
    membership of a topic into a particular discussion group. This operation will
    be useful to verify whether the topic is relevant to the discussion group. We
    will use the data contained in the 20 newsgroups dataset, available at the following
    URL: [http://qwone.com/~jason/20Newsgroups/](http://qwone.com/~jason/20Newsgroups/).'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将构建一个分类器，使我们能够将主题的成员资格分类到特定的讨论组中。这个操作将有助于验证主题是否与讨论组相关。我们将使用以下URL中可用的20个新闻组数据集中的数据：[http://qwone.com/~jason/20Newsgroups/](http://qwone.com/~jason/20Newsgroups/)。
- en: 'This is a collection of about 20,000 newsgroup documents, divided into 20 different
    newsgroups. Originally collected by Ken Lang, and published in *Newsweeder paper:
    Learning to filter netnews,* the dataset is particularly useful for dealing with
    text classification problems.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个大约有20,000篇新闻组文档的集合，分为20个不同的新闻组。最初由Ken Lang收集，并在*Newsweeder论文：学习过滤网络新闻*中发表，这个数据集特别适用于处理文本分类问题。
- en: How to do it…
  id: totrans-477
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'In this recipe, we will learn how to perform newsgroup trending topics classification:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何执行新闻组趋势主题分类：
- en: 'We will use the `post.classification.py` file, already provided to you as a
    reference. We start importing the dataset as follows:'
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用已经提供给你作为参考的`post.classification.py`文件。我们开始导入数据集如下：
- en: '[PRE64]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'This dataset is contained in the `sklearn.datasets` library; in this way, it
    will be very easy for us to recover the data. As anticipated, the dataset contains
    posts related to 20 newsgroups. We will limit our analysis to only the following
    two newsgroups:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含在`sklearn.datasets`库中；这样，我们将很容易恢复数据。正如预期的那样，数据集包含与20个新闻组相关的帖子。我们将仅分析以下两个新闻组：
- en: '[PRE65]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Download the data:'
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载数据：
- en: '[PRE66]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The data has two attributes: `data` and `target`. Obviously, `data` represents
    the input and `target` is the output. Let''s check which newsgroups have been
    selected:'
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据有两个属性：`data`和`target`。显然，`data`代表输入，`target`是输出。让我们检查哪些新闻组已被选中：
- en: '[PRE67]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The following results are printed:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 打印以下结果：
- en: '[PRE68]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Let''s check the shape:'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查形状：
- en: '[PRE69]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The following results are returned:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE70]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'To extract features from texts, we will use the `CountVectorizer()` function
    as follows:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了从文本中提取特征，我们将使用以下`CountVectorizer()`函数：
- en: '[PRE71]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The following result is returned:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE72]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: In this way, we have made a count of the occurrences of words.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们已经对单词的出现次数进行了计数。
- en: 'Now let''s divide the number of occurrences of each word in a document by the
    total number of words in the document:'
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将文档中每个单词出现的次数除以文档中单词的总数：
- en: '[PRE73]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Now we can build the classifier:'
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以构建分类器：
- en: '[PRE74]'
  id: totrans-501
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Finally, we will compute the accuracy of the classifier:'
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将计算分类器的准确率：
- en: '[PRE75]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The following result is returned:'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE76]'
  id: totrans-505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: How it works...
  id: totrans-506
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we built a classifier to classify the membership of a topic
    into a particular discussion group. To extract features from the text, a **tokenization**
    procedure was needed. In the tokenization phase, within each single sentence,
    atomic elements called **tokens** are identified; based on the token identified,
    it's possible to carry out an analysis and evaluation of the sentence itself. Once
    the characteristics of the text had been extracted, a classifier based on the
    multinomial Naive Bayes algorithm was constructed.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们构建了一个分类器，用于将主题的成员资格分类到特定的讨论组中。为了从文本中提取特征，需要一个**分词**过程。在分词阶段，在每个单独的句子中，识别出称为**标记**的原子元素；基于识别出的标记，可以执行句子本身的分析和评估。一旦提取了文本的特征，就构建了一个基于多项式朴素贝叶斯算法的分类器。
- en: There's more...
  id: totrans-508
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The Naive Bayes multinomial algorithm is used for text and images when features
    represent the frequency of words (textual or visual) in a document.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 当特征表示文档中单词（文本或视觉）的频率时，朴素贝叶斯多项式算法用于文本和图像。
- en: See also
  id: totrans-510
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The official documentation of the *Dataset loading utilities*: [https://scikit-learn.org/stable/datasets/index.html](https://scikit-learn.org/stable/datasets/index.html)'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据集加载工具*的官方文档：[https://scikit-learn.org/stable/datasets/index.html](https://scikit-learn.org/stable/datasets/index.html)'
- en: 'The official documentation of the `sklearn.feature_extraction.text.CountVectorizer()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.feature_extraction.text.CountVectorizer()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)'
- en: 'The official documentation of the `sklearn.feature_extraction.text.TfidfTransformer()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.feature_extraction.text.TfidfTransformer()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)'
- en: 'The official documentation of the `sklearn.naive_bayes.MultinomialNB()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.naive_bayes.MultinomialNB()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)'
