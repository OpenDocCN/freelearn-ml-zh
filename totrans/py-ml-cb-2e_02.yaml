- en: Constructing a Classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a simple classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a logistic regression classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a Naive Bayes classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splitting a dataset for training and testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating accuracy using cross-validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing a confusion matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting a performance report
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating cars based on their characteristics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting validation curves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting learning curves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating a income bracket
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the quality of wine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Newsgroup trending topics classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To work on the recipes in this chapter, you need the following files (available
    on GitHub):'
  prefs: []
  type: TYPE_NORMAL
- en: '`simple_classifier.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logistic_regression.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`naive_bayes.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data_multivar.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`splitting_dataset.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`confusion_matrix.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`` `performance_report.py` ``'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`car.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`car.data.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`income.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adult.data.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`wine.quality.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`wine.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`post.classification`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the field of machine learning, **classification** refers to the process of
    using the characteristics of data to separate it into a certain number of classes.
    This is different than regression, which we discussed in [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml),
    *The Realm of Supervised Learning*, where the output is a real number. A supervised
    learning classifier builds a model using labeled training data and then uses this
    model to classify unknown data.
  prefs: []
  type: TYPE_NORMAL
- en: A classifier can be any algorithm that implements classification. In simple
    cases, a classifier can be a straightforward mathematical function. In more real-world
    cases, a classifier can take very complex forms. In the course of study, we will
    see that classification can be either binary, where we separate data into two
    classes, or it can be multi-class, where we separate data into more than two classes.
    The mathematical techniques that are devised to deal with classification problems
    tend to deal with two classes, so we extend them in different ways to deal with
    multi-class problems as well.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the accuracy of a classifier is vital for machine learning. What
    we need to know is, how we can use the available data, and get a glimpse of how
    the model performs in the real world. In this chapter, we will look at recipes
    that deal with all these things.
  prefs: []
  type: TYPE_NORMAL
- en: Building a simple classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **classifier** is a system with some characteristics that allow you to identify
    the class of the sample examined. In different classification methods, groups
    are called **classes**. The goal of a classifier is to establish the classification
    criterion to maximize performance. The performance of a classifier is measured
    by evaluating the capacity for generalization. **Generalization** means attributing
    the correct class to each new experimental observation. The way in which these
    classes are identified discriminates between the different methods that are available.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classifiers identify the class of a new objective, based on knowledge that's
    been extracted from a series of samples (a dataset). Starting from a dataset,
    a classifier extracts a model, which is then used to classify new instances.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to build a simple classifier using some training data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `simple_classifier.py` file, already provided to you as a reference.
    To start, we import the `numpy` and `matplotlib.pyplot` packages, as we did in
    [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml), *The Realm of Supervised
    Learning*, and then we create some sample data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s assign some labels to these points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As we have only two classes, the `y` list contains 0''s and 1''s. In general,
    if you have *N* classes, then the values in `y` will range from 0 to *N-1*. Let''s
    separate the data into classes based on the labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To get an idea about our data, let''s plot it, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a **scatterplot**, where we use squares and crosses to plot the points.
    In this context, the `marker` parameter specifies the shape you want to use. We
    use squares to denote points in `class_0` and crosses to denote points in `class_1`. If
    you run this code, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/542cb6f5-7a7c-486e-a1be-823c65eb12d8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding two lines, we just use the mapping between `X` and `y` to
    create two lists. If you were asked to inspect the datapoints visually and draw
    a separating line, what would you do? You would simply draw a line in between
    them. Let''s go ahead and do this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We just created a line with the mathematical equation *y = x*. Let''s plot
    it, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this code, you should see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fde419aa-36d1-4312-9a2c-f49b054f62c8.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding shows how that construction of a separation line between the two
    classes was simple. In this simple example, this operation was easy, but in many
    cases, building a line of separation between two classes can be very difficult.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we showed how simple it is to build a classifier. We started
    from a series of identifying pairs of as many points on a plane (*x, y*). We therefore
    assigned a class to each of these points (0,1) so as to divide them into two groups.
    To understand the spatial arrangement of these points, we visualized them by associating
    a different marker to each class. Finally, to divide the two groups, we have drew
    the line of the *y = x* equation.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We built a simple classifier using the following rule—the input point (*a, b*)
    belongs to `class_0` if *a* is greater than or equal to *b;* otherwise, it belongs
    to `class_1`. If you inspect the points one by one, you will see that this is,
    in fact, true. That's it! You just built a linear classifier that can classify
    unknown data. It's a linear classifier because the separating line is a straight
    line. If it's a curve, then it becomes a *nonlinear* classifier.
  prefs: []
  type: TYPE_NORMAL
- en: This formation worked well, because there were a limited number of points, and
    we could visually inspect them. What if there were thousands of points? How would
    we generalize this process? Let's discuss that in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The official documentation of the NumPy library ([http://www.numpy.org/](http://www.numpy.org/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The official documentation of the Matplotlib library ([https://matplotlib.org/](https://matplotlib.org/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a logistic regression classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Despite the word *regression* being present in the name, logistic regression
    is actually used for classification purposes. Given a set of datapoints, our goal
    is to build a model that can draw linear boundaries between our classes. It extracts
    these boundaries by solving a set of equations derived from the training data.
    In this recipe, we will build a logistic regression classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is a non-linear regression model used when the dependent
    variable is dichotomous. The purpose is to establish the probability with which
    an observation can generate one or the other value of the dependent variable;
    it can also be used to classify observations, according to their characteristics,
    into two categories.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to build a logistic regression classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how to do this in Python. We will use the `logistic_regression.py`
    file, provided to you as a reference. Assuming that you imported the necessary
    packages, let''s create some sample data, along with training labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we assume that we have three classes (`0`, `1`, and `2`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s initialize the logistic regression classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: There are a number of input parameters that can be specified for the preceding
    function, but a couple of important ones are `solver` and `C`. The `solver` parameter
    specifies the type of `solver` that the algorithm will use to solve the system
    of equations. The `C` parameter controls the regularization strength. A lower
    value indicates higher regularization strength.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s draw datapoints and boundaries. To do this, first, we need to define
    ranges to plot the diagram, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The preceding values indicate the range of values that we want to use in our
    figure. The values usually range from the minimum value to the maximum value present
    in our data. We add some buffers, such as `1.0`, to the preceding lines, for clarity.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to plot the boundaries, we need to evaluate the function across a
    grid of points and plot it. Let''s go ahead and define the grid:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `x_values` and `y_values` variables contain the grid of points where the
    function will be evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compute the output of the classifier for all these points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s plot the boundaries using colored regions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This is basically a 3D plotter that takes the 2D points and the associated values
    to draw different regions using a color scheme.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s overlay the training points on the plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, `plt.scatter` plots the points on the 2D graph. `X[:, 0]` specifies that
    we should take all the values along the 0 axis (the *x* axis in our case), and
    `X[:, 1]` specifies axis 1 (the *y* axis). The `c=y` parameter indicates the color
    sequence. We use the target labels to map to colors using `cmap`. Basically, we
    want different colors that are based on the target labels. Hence, we use `y` as
    the mapping. The limits of the display figure are set using `plt.xlim` and `plt.ylim`. In
    order to mark the axes with values, we need to use `plt.xticks` and `plt.yticks`. These
    functions mark the axes with values so that it's easier for us to see where the
    points are located. In the preceding code, we want the ticks to lie between the
    minimum and maximum values with a buffer of one unit. Also, we want these ticks
    to be integers. So, we use the `int()` function to round off the values.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run this code, you should see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/34c330f7-3444-4265-b0cd-f37c27e72382.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how the `C` parameter affects our model. The `C` parameter indicates
    the penalty for misclassification. If we set it to `1.0`, we will get the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/72defd40-8554-499b-b9ef-562ef7291b64.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we set `C` to `10000`, we get the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ac2af76f-7377-4329-a287-9e74512b7094.png)'
  prefs: []
  type: TYPE_IMG
- en: As we increase `C`, there is a higher penalty for misclassification. Hence,
    the boundaries become more optimized.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Logistic regression** is a classification method within the family of supervised
    learning algorithms. Using statistical methods, logistic regression allows us
    to generate a result that, in fact, represents a probability that a given input
    value belongs to a given class. In binomial logistic regression problems, the
    probability that output belongs to a class will be *P*, whereas the probability
    of it belonging to another class will be *1-P* (where *P* is a number between
    0 and 1 because it expresses probability).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Logistic regression uses the logistic function to determine the classification
    of input values. Also called the **sigmoid** function, the logistic function is
    an S-shaped curve that can take any number of of a real value and map it to a
    value between 0 and 1, extremes excluded. It can be described by the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00e3c0f7-9412-4655-95a8-116901dcc226.png)'
  prefs: []
  type: TYPE_IMG
- en: This function transforms the real values into numbers between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To obtain the logistic regression equation expressed in probabilistic terms,
    we need to include the probabilities in the logistic regression equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/416b339e-3214-4a8f-bab8-433e2a986a65.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Recalling that the `e` function is the opposite of the natural logarithm (`ln`),
    we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ff52b3b-5cbb-41a7-b55b-cd2e44a6804e.png)'
  prefs: []
  type: TYPE_IMG
- en: This function is called a **logit** function. The logit function, on the other
    hand, allows us to associate the probabilities (therefore, a value included between
    0 and 1) to the whole range of real numbers. It is a link function and represents
    the inverse of the logistic function.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Logit Models for Binary Data*, Princeton University: [https://data.princeton.edu/](https://data.princeton.edu/wws509/notes/c3.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Regression Analysis with R*, Giuseppe Ciaburro, Packt Publishing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[wws509/notes/c3.pdf](https://data.princeton.edu/wws509/notes/c3.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matplotlib color scheme options: [https://matplotlib.org/examples/color/colormaps_reference.html](http://matplotlib.org/examples/color/colormaps_reference.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a Naive Bayes classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A classifier solves the problem of identifying sub-populations of individuals
    with certain features in a larger set, with the possible use of a subset of individuals
    known as a priori (a training set). A Naive Bayes classifier is a supervised learning
    classifier that uses Bayes' theorem to build the model. In this recipe, we will
    build a Naive Bayes classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The underlying principle of a Bayesian classifier is that some individuals belong
    to a class of interest with a given probability based on some observations. This
    probability is based on the assumption that the characteristics observed can be
    either dependent or independent from one another; in this second case, the Bayesian
    classifier is called Naive because it assumes that the presence or absence of
    a particular characteristic in a given class of interest is not related to the
    presence or absence of other characteristics, greatly simplifying the calculation.
    Let's go ahead and build a Naive Bayes classifier.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to build a Naive Bayes classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use `naive_bayes.py`, provided to you as a reference. Let''s import
    some libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You were provided with a `data_multivar.txt` file. This contains data that
    we will use here. This contains comma-separated numerical data in each line. Let''s
    load the data from this file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We have now loaded the input data into `X` and the labels into `y`. There are
    four labels: 0, 1, 2, and 3.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build the Naive Bayes classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `gauusiannb` function specifies the Gaussian Naive Bayes model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compute the `accuracy` measure of the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following accuracy is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s plot the data and the boundaries. We will use the procedure followed
    in the previous recipe, *Building a logistic regression classifier*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8c4578e-99bb-4249-ba9e-1658a56cffc9.png)'
  prefs: []
  type: TYPE_IMG
- en: There is no restriction on the boundaries to be linear here. In the preceding
    recipe, *Building a logistic regression classifier*, we used up all the data for
    training. A good practice in machine learning is to have non-overlapping data
    for training and testing. Ideally, we need some unused data for testing so that
    we can get an accurate estimate of how the model performs on unknown data. There
    is a provision in `scikit-learn` that handles this very well, as shown in the
    next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **Bayesian classifier** is a classifier based on the application of Bayes'
    theorem. This classifier requires the knowledge of a priori and conditional probabilities
    related to the problem; quantities that, in general, are not known but are typically
    estimable. If reliable estimates of the probabilities involved in the theorem
    can be obtained, the Bayesian classifier is generally reliable and potentially
    compact.
  prefs: []
  type: TYPE_NORMAL
- en: 'The probability that a given event (*E*) occurs, is the ratio between the number
    (*s*) of favorable cases of the event itself and the total number (*n*) of the
    possible cases, provided all the considered cases are equally probable. This can
    be better represented using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6c805cf-487c-462a-aeb1-c403af96d89d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Given two events, *A* and *B*, if the two events are independent (the occurrence
    of one does not affect the probability of the other), the joint probability of
    the event is equal to the product of the probabilities of *A* and *B*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79748dbb-b02c-44a6-b528-0b310abefd67.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If the two events are dependent (that is, the occurrence of one affects the
    probability of the other), then the same rule may apply, provided *P(B | A)* is
    the probability of event *A* given that event *B* has occurred. This condition
    introduces conditional probability, which we are going to dive into now:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53491427-e7b8-4df8-bddc-9a084ac16632.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The probability that event *A* occurs, calculated on the condition that event
    *B* occurred, is called **conditional probability**, and is indicated by *P(A
    | B)*. It is calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cba40f96-9806-4cb3-8c79-9854a24051cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let *A* and *B* be two dependent events, as we stated that the joint probability
    between them is calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08b9a04b-428f-404e-b067-96923b283638.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Or, similarly, we can use the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bc29719-ee15-483d-b8e6-a1e6125e4f59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By looking at the two formulas, we see that they have the first equal member.
    This shows that even the second members are equal, so the following equation can
    be written:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a06d2fd7-d73f-471d-a77f-e3675deab9c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By solving these equations for conditional probability, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a145cfc1-adaf-4937-8bd2-f1bca05834ef.png)'
  prefs: []
  type: TYPE_IMG
- en: The proposed formulas represent the mathematical statement of Bayes' theorem.
    The use of one or the other depends on what we are looking for.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In 1763, an article by Reverend Thomas Bayes was published in England; the
    article became famous for its implications. According to the article, making predictions
    about a phenomenon depends not only on the observations that the scientist obtains
    from his experiments, but also on what he himself thinks and understands of the
    phenomenon studied, even before proceeding to the experiment itself. These premises
    were developed in the 1900s by distinguished scholars, such as Bruno de Finetti
    (*La prévision: ses lois logiques, ses sources subjectives*, 1937), L J Savage
    (*The Fondations of statistics Reconsidered*, 1959), and others.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Keras 2.x Projects*, Giuseppe Ciaburro, Packt Publishing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Bayes'' Theorem*, Stanford Encyclopedia of Philosophy: [https://plato.stanford.edu/entries/bayes-theorem/](https://plato.stanford.edu/entries/bayes-theorem/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.naive_bayes.GaussianNB` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splitting a dataset for training and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's see how to split our data properly into training and testing datasets.
    As we said in [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml), *The Realm
    of Supervised Learning*, in the *Building a linear regressor* recipe, when we
    build a machine learning model, we need a way to validate our model to check whether
    it is performing at a satisfactory level. To do this, we need to separate our
    data into two groups—a **training** dataset and a **testing** dataset. The training
    dataset will be used to build the model, and the testing dataset will be used
    to see how this trained model performs on unknown data.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to split the dataset for training and testing
    phases.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The fundamental objective of a model based on machine learning is to make accurate
    predictions. Before using a model to make predictions, it is necessary to evaluate
    the predictive performance of the model. To estimate the quality of a model''s
    predictions, it is necessary to use data that you have never seen before. Training
    a predictive model and testing it on the same data is a methodological error:
    a model that simply classifies the labels of samples it has just seen would have
    a high score but would not be able to predict the new data class. Under these
    conditions, the generalization capacity of the model would be less.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to split the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first part of the recipe is similar to the previous recipe, *Building a
    Naive Bayes classifier* (load the `Splitting_dataset.py` file):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here, we allocated 25% of the data for testing, as specified by the `test_size`
    parameter. The remaining 75% of the data will be used for training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s evaluate the classifier on the test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s compute the `accuracy` measure of the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s plot the datapoints and the boundaries on the test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/562ba592-f77d-4143-b8f7-ebeadc718a95.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we split the data using the `train_test_split()` function of
    the `scikit-learn` library. This function splits arrays or matrices into random
    train and testing subsets. Random division of input data into data sources for
    training and testing ensures that data distribution is similar for training and
    testing data sources. You choose this option when it is not necessary to preserve
    the order of the input data.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The performance estimate depends on the data used. Therefore, simply dividing
    data randomly into a training and a testing set does not guarantee that the results
    are statistically significant. The repetition of the evaluation on different random
    divisions and the calculation of the performance in terms of the average and standard
    deviation of the individual evaluations creates a more reliable estimate.
  prefs: []
  type: TYPE_NORMAL
- en: However, even the repetition of evaluations on different random divisions could
    prevent the most complex data being classified in the testing (or training) phase.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.model_selection.train_test_split`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data Splitting*, Charles University: [https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf](https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating accuracy using cross-validation metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cross-validation** is an important concept in machine learning. In the previous
    recipe, we split the data into training and testing datasets. However, in order
    to make it more robust, we need to repeat this process with different subsets.
    If we just fine-tune it for a particular subset, we may end up overfitting the
    model. **Overfitting** refers to a situation where we fine-tune a model to a dataset
    too much and it fails to perform well on unknown data. We want our machine learning
    model to perform well on unknown data. In this recipe, we will learn how to evaluate
    model accuracy using cross-validation metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we are dealing with machine learning models, we usually care about three
    things—precision, recall, and F1 score. We can get the required performance metric
    using parameter scoring. **Precision** refers to the number of items that are
    correctly classified as a percentage of the overall number of items in the list.
    **Recall** refers to the number of items that are retrieved as a percentage of
    the overall number of items in the training list.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to evaluate model accuracy using cross-validation metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the classifier just used in the *Building a Naive Bayes* classifier
    recipe (load the `naive_bayes.py` file). We will start with the `accuracy` measure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the preceding function to compute `precision`, `recall`, and the
    `F1` score as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s consider a test dataset containing 100 items, out of which 82 are of
    interest to us. Now, we want our classifier to identify these 82 items for us.
    Our classifier picks out 73 items as the items of interest. Out of these 73 items,
    only 65 are actually items of interest, and the remaining 8 are misclassified.
    We can compute precision in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of correct identifications = 65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total number of identifications = 73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision = 65 / 73 = 89.04%
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To compute recall, we use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The total number of items of interest in the dataset = 82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of items retrieved correctly = 65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recall = 65 / 82 = 79.26%
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A good machine learning model needs to have good precision and good recall
    simultaneously. It''s easy to get one of them to 100%, but the other metric suffers!
    We need to keep both metrics high at the same time. To quantify this, we use an
    F1 score, which is a combination of precision and recall. This is actually the
    harmonic mean of precision and recall:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9aa3ca0-efcb-46da-a9ef-329b618d3b7e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding case, the F1 score will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1af8b3e1-849e-432e-816b-5b30076ce4c4.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In cross-validation, all available data is used, in groups of a fixed size,
    alternatively as a testing and as a training set. Therefore, each pattern is either
    classified (at least once) or used for training. The performances obtained depend,
    however, on the particular division. Therefore, it may be useful to repeat cross-validation
    several times in order to become independent of the particular division.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.model_selection.cross_val_score`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cross-validation* (from scikit-learn''s official documentation): [http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/cross_validation.html](http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/cross_validation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing a confusion matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **confusion matrix** is a table that we use to understand the performance
    of a classification model. This helps us understand how we classify testing data
    into different classes. When we want to fine-tune our algorithms, we need to understand
    how data gets misclassified before we make these changes. Some classes are worse
    than others, and the confusion matrix will help us understand this. Let''s look
    at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1564065-1bf8-4576-ac73-5c69187fd71f.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, we can see how we categorize data into different classes.
    Ideally, we want all the non-diagonal elements to be 0\. This would indicate perfect
    classification! Let's consider class 0\. Overall, 52 items actually belong to
    class 0\. We get 52 if we sum up the numbers in the first row. Now, 45 of these
    items are being predicted correctly, but our classifier says that 4 of them belong
    to class 1 and three of them belong to class 2\. We can apply the same analysis
    to the remaining 2 rows as well. An interesting thing to note is that 11 items
    from class 1 are misclassified as class 0\. This constitutes around 16% of the
    datapoints in this class. This is an insight that we can use to optimize our model.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A confusion matrix identifies the nature of the classification errors, as our
    classification results are compared to real data. In this matrix, the diagonal
    cells show the number of cases that were correctly classified; all the others
    cells show the misclassified cases.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to visualize the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `confusion_matrix.py` file that we already provided to you
    as a reference. Let''s see how to extract the confusion matrix from our data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We use some sample data here. We have 4 classes with values ranging from 0 to
    3\. We have predicted labels as well. We use the `confusion_matrix` method to
    extract the confusion matrix and plot it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go ahead and define this function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We use the `imshow` function to plot the confusion matrix. Everything else in
    the function is straightforward! We just set the title, color bar, ticks, and
    the labels using the relevant functions. The `tick_marks` argument range from
    0 to 3 because we have 4 distinct labels in our dataset. The `np.arange` function
    gives us this `numpy` array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s define the data (real and predicted) and then we will call the `confusion_matrix`
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the preceding code, you will see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a194b459-0515-4dde-9a5c-fa1fd33ecbe9.png)'
  prefs: []
  type: TYPE_IMG
- en: The diagonal colors are strong, and we want them to be strong. The black color
    indicates zero. There are a couple of gray squares in the non-diagonal spaces,
    which indicate misclassification. For example, when the real label is 0, the predicted
    label is 1, as we can see in the first row. In fact, all the misclassifications
    belong to class 1 in the sense that the second column contains 3 rows that are
    non-zero. It's easy to see this from the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A confusion matrix displays information about the actual and predicted classifications
    made by a model. The performance of such systems is evaluated with the help of
    data in the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the confusion matrix for a two-class classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | PREDICTED POSITIVE | PREDICTED NEGATIVE |'
  prefs: []
  type: TYPE_TB
- en: '| **Actual TRUE** | TP | FN |'
  prefs: []
  type: TYPE_TB
- en: '| **Actual FALSE** | FP | TN |'
  prefs: []
  type: TYPE_TB
- en: 'The entries in the confusion matrix have the following meanings:'
  prefs: []
  type: TYPE_NORMAL
- en: TP is the number of correct predictions that an instance is positive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FN is the number of incorrect predictions that an instance is negative
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FP is the number of incorrect predictions that an instance is positive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TN is the number of correct predictions that an instance is negative
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The confusion matrix shows us the performance of an algorithm. Each row returns
    the instances in an actual class, while each column returns the instances in an
    expected class. The term *confusion matrix* results from the fact that it makes
    it easy to see whether the system is confusing two classes.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.metrics.confusion_matrix()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Confusion Matrix*, University of Notre Dame: [https://www3.nd.edu/~busiforc/Confusion_Matrix.html](https://www3.nd.edu/~busiforc/Confusion_Matrix.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting a performance report
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the *Evaluating accuracy using cross-validation metrics* recipe, we calculated
    some metrics to measure the accuracy of the model. Let's remember its meaning.
    The accuracy returns the percentage of correct classifications. Precision returns
    the percentage of positive classifications that are correct. Recall (sensitivity)
    returns the percentage of positive elements of the testing set that have been
    classified as positive. Finally, in F1, both the precision and the recall are
    used to compute the score. In this recipe, we will learn how to extract a performance
    report.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We also have a function in `scikit-learn` that can directly print the precision,
    recall, and F1 scores for us. Let's see how to do this.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to extract a performance report:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following lines to a new Python file (load the `performance_report.py`
    file):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this code, you will see the following on your Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7e6c43dc-441a-4ce6-a256-d1fa06905490.png)'
  prefs: []
  type: TYPE_IMG
- en: Instead of computing these metrics separately, you can directly use the preceding
    function to extract those statistics from your model.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we used the `classification_report ()` function of the scikit-learn
    library to extract a performance report. This function builds a text report showing
    the main classification metrics. A text summary of the precision, recall, and
    the F1 score for each class is returned. Referring to the terms introduced in
    the confusion matrix addressed in the previous recipe, these metrics are calculated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The precision is the ratio tp / (tp + fp), where tp is the number of true positives
    and fp the number of false positives. The precision is the ability of the classifier
    to not label a sample that is negative as positive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The recall is the ratio tp / (tp + fn), where tp is the number of true positives
    and fn the number of false negatives. The recall is the ability of the classifier
    to find the positive samples.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The F1 score is said to be a weighted harmonic mean of the precision and recall,
    where an F-beta score reaches its peak value at 1 and its lowest score at 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The reported averages include the **micro average** (averaging the total true
    positives, false negatives, and false positives), the **macro average** (averaging
    the unweighted mean per label), the **weighted** **average** (averaging the support-weighted
    mean per label), and the **sample average** (only for multilabel classification).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.metrics.classification_report()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating cars based on their characteristics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, let''s see how we can apply classification techniques to a
    real-world problem. We will use a dataset that contains some details about cars,
    such as number of doors, boot space, maintenance costs, and so on. Our goal is
    to determine the quality of the car. For the purposes of classification, quality
    can take four values: unacceptable, acceptable, good, or very good.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the dataset at [https://archive.ics.uci.edu/ml/datasets/Car+Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation).
  prefs: []
  type: TYPE_NORMAL
- en: 'You need to treat each value in the dataset as a string. We consider six attributes
    in the dataset. Here are the attributes along with the possible values they can
    take:'
  prefs: []
  type: TYPE_NORMAL
- en: '`buying`: These will be `vhigh`, `high`, `med`, and `low`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maint`: These will be `vhigh`, `high`, `med`, and `low`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doors`: These will be `2`, `3`, `4`, `5`, and `more`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`persons`: These will be `2`, `4`, and `more`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lug_boot`: These will be `small`, `med`, and `big`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safety`: These will be `low`, `med`, and `high`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given that each line contains strings, we need to assume that all the features
    are strings and design a classifier. In the previous chapter, we used random forests
    to build a regressor. In this recipe, we will use random forests as a classifier.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to evaluate cars based on their characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `car.py` file that we already provided to you as reference.
    Let''s go ahead and import a couple of packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s load the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Each line contains a comma-separated list of words. Therefore, we parse the
    input file, split each line, and then append the list to the main data. We ignore
    the last character on each line because it's a newline character. Python packages
    only work with numerical data, so we need to transform these attributes into something
    that those packages will understand.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous chapter, we discussed label encoding. That is what we will
    use here to convert strings to numbers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As each attribute can take a limited number of values, we can use the label
    encoder to transform them into numbers. We need to use different label encoders
    for each attribute. For example, the `lug_boot` attribute can take three distinct
    values, and we need a label encoder that knows how to encode this attribute. The
    last value on each line is the class, so we assign it to the *y* variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: You can play around with the `n_estimators` and `max_depth` parameters to see
    how they affect classification accuracy. We will actually do this soon in a standardized
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s perform cross-validation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we train the classifier, we need to see how it performs. We use three-fold
    cross-validation to calculate the accuracy here. The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the main goals of building a classifier is to use it on isolated and
    unknown data instances. Let''s use a single datapoint and see how we can use this
    classifier to categorize it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The first step was to convert that data into numerical data. We need to use
    the label encoders that we used during training because we want it to be consistent.
    If there are unknown values in the input datapoint, the label encoder will complain
    because it doesn't know how to handle that data. For example, if you change the
    first value in the list from `high` to `abcd`, then the label encoder won't work
    because it doesn't know how to interpret this string. This acts like an error
    check to see whether the input datapoint is valid.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are now ready to predict the output class for this datapoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the `predict()` method to estimate the output class. If we output the
    encoded output label, it won''t mean anything to us. Therefore, we use the `inverse_transform`
    method to convert this label back to its original form and print out the output
    class. The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **random forest** was developed by Leo Breiman (University of California,
    Berkeley, USA) based on the use of classification trees. He has extended the classification
    tree technique by integrating it into a Monte Carlo simulation procedure and named
    it **random forest**. It is based on the creation of a large set of tree classifiers,
    each of which is proposed to classify a single instance, wherein some features
    have been evaluated. Comparing the classification proposals provided by each tree
    in the forest shows the class to which to attribute the request: it is the one
    that received the most votes.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Random forest has three adjustment parameters: the number of trees, the minimum
    amplitude of the terminal nodes, and the number of variables sampled in each node.
    The absence of overfitting makes the first two parameters important only from
    a computational point of view.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.ensemble.RandomForestClassifier()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Random Forests* by Leo Breiman and Adele Cutler (from the University of California,
    Berkeley): [https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting validation curves
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We used random forests to build a classifier in the previous recipe, *Evaluating
    cars based on their characteristics*, but we don''t exactly know how to define
    the parameters. In our case, we dealt with two parameters: `n_estimators` and
    `max_depth`. They are called **hyperparameters**, and the performance of the classifier
    depends on them. It would be nice to see how the performance gets affected as
    we change the hyperparameters. This is where validation curves come into the picture.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Validation curves help us understand how each hyperparameter influences the
    training score. Basically, all other parameters are kept constant and we vary
    the hyperparameter of interest according to our range. We will then be able to
    visualize how this affects the score.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to extract validation curves:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following code to the same Python file as in the previous recipe, *Evaluating
    cars based on their characteristics*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we defined the classifier by fixing the `max_depth` parameter.
    We want to estimate the optimal number of estimators to use, and so have defined
    our search space using `parameter_grid`. It is going to extract training and validation
    scores by iterating from 25 to 200 in 8 steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run it, you will see the following on your Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1d6021de-2c8e-4628-aeeb-5e64c53c3e5f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s plot it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is what you''ll get:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c6c67e06-26df-495b-9a64-833b85df460e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s do the same for the `max_depth` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We fixed the `n_estimators` parameter at 20 to see how the performance varies
    with `max_depth`. Here is the output on the Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b9cd9ace-c7e5-44aa-835e-8745adf5c9ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s plot it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this code, you will get the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/359e4feb-d95f-438a-ab51-087000626f5d.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we used the `validation_curve` function of the scikit-learn
    library to plot the validation curve. This function determines training and test
    scores for varying parameter values and computes scores for an estimator with
    different values of a specified parameter.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Choosing an estimator's hyperparameters is a fundamental procedure for setting
    up a model. Among the available procedures, grid search is one of the most used.
    This procedure selects the hyperparameter with the maximum score on a validation
    set or a multiple validation set.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.model_selection.validation_curve()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Validation curves: plotting scores to evaluate models* (from scikit-learn''s
    official documentation): [https://scikit-learn.org/stable/modules/learning_curve.html](https://scikit-learn.org/stable/modules/learning_curve.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting learning curves
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning curves help us understand how the size of our training dataset influences
    the machine learning model. This is very useful when you have to deal with computational
    constraints. Let's go ahead and plot learning curves by varying the size of our
    training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A learning curve shows the validation and training score of an estimator for
    varying numbers of training samples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to extract learning curves:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following code to the same Python file as in the previous recipe, *Extracting
    validation curves*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: We want to evaluate the performance metrics using training datasets of 200,
    500, 800, and 1,100 samples. We use five-fold cross-validation, as specified by
    the cv parameter in the `validation_curve` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run this code, you will get the following output on the Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/47a5108a-7027-4eda-a025-d5a845516da1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s plot it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5e35fc89-5c17-435c-a647-8ce915bf76a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Although smaller training sets seem to give better accuracy, they are prone
    to overfitting. If we choose a bigger training dataset, it consumes more resources.
    Therefore, we need to make a trade-off here to pick the right size for the training
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we used the `validation_curve` function of the scikit-learn
    library to plot the learning curve. This function determines cross-validated training
    and testing scores for different training set sizes.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A learning curve allows us to check whether the addition of training data leads
    to a benefit. It also allows us to estimate the contribution deriving from variance
    error and bias error. If the validation score and the training score converge
    with the size of the training set too low, we will not benefit from further training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.model_selection.validation_curve`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learning curve* (from scikit-learn''s official documentation): [https://scikit-learn.org/stable/modules/learning_curve.html](https://scikit-learn.org/stable/modules/learning_curve.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating the income bracket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will build a classifier to estimate the income bracket of a person based
    on 14 attributes. The possible output classes are higher than 50,000 or lower
    than or equal to 50,000\. There is a slight twist in this dataset, in the sense
    that each datapoint is a mixture of numbers and strings. Numerical data is valuable,
    and we cannot use a label encoder in these situations. We need to design a system
    that can deal with numerical and non-numerical data at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the census income dataset available at [https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/census+income).
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset has the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Number of instances: 48,842'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Number of attributes: 14'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a list of attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Age: continuous'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Workclass: text'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'fnlwgt: continuous'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Education: text'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Education-num: continuous'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marital-status: text'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Occupation: text'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Relationship: text'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Race: text'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sex: female or male'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Capital-gain: continuous'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Capital-loss: continuous'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hours-per-week: continuous'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Native-country: text'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to estimate the income bracket:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `income.py` file, already provided to you as a reference. We
    will use a Naive Bayes classifier to achieve this. Let''s import a couple of packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s load the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use 20,000 datapoints from the datasets—10,000 for each class to avoid
    class imbalance. During training, if you use many datapoints that belong to a
    single class, the classifier tends to get biased toward that class. Therefore,
    it''s better to use the same number of datapoints for each class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: It's a comma-separated file again. We just loaded the data in the `X` variable
    just as before.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to convert string attributes to numerical data while leaving out the
    original numerical data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The `isdigit()` function helps us to identify numerical data. We converted string
    data to numerical data and stored all the label encoders in a list so that we
    can use it when we want to classify unknown data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s split the data into training and testing to extract performance metrics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s extract performance metrics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how to classify a single datapoint. We need to convert the datapoint
    into something that our classifier can understand:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now ready to classify it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Just as before, we use the `predict` method to get the `output` class and the
    `inverse_transform` method to convert this label back to its original form to
    print it out on the Terminal. The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The underlying principle of a Bayesian classifier is that some individuals belong
    to a class of interest with a given probability based on some observations. This
    probability is based on the assumption that the characteristics observed can be
    dependent or independent from one another; in the second case, the Bayesian classifier
    is called *naive* because it assumes that the presence or absence of a particular
    characteristic in a given class of interest is not related to the presence or
    absence of other characteristics, greatly simplifying the calculation. Let's go
    ahead and build a Naive Bayes classifier.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The concept of Bayes applied to classification is very intuitive: if I look
    at a particular measurable feature, I can estimate the probability that this feature
    represents a certain class after the observation.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The official documentation of the `sklearn.naive_bayes.GaussianNB` function: [https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the quality of wine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will predict the quality of wine based on the chemical properties of
    wines grown. The code uses a wine dataset, which contains a DataFrame with 177
    rows and 13 columns; the first column contains the class labels. This data is
    obtained from the chemical analyses of wines grown in the same region in Italy
    (Piemonte) but derived from three different cultivars—namely, the Nebbiolo, Barberas,
    and Grignolino grapes. The wine from the Nebbiolo grape is called Barolo.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data consists of the amounts of several constituents found in each of the
    three types of wines, as well as some spectroscopic variables. The attributes
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Alcohol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Malic acid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alcalinity of ash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Magnesium
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total phenols
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flavanoids
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nonflavanoid phenols
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proanthocyanins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Color intensity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OD280/OD315 of diluted wines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first column of the DataFrame contains the class which indicates one of
    three types of wine as (0, 1, or 2).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to predict the quality of wine:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `wine.quality.py` file, already provided to you as a reference. We
    start, as always, by importing the NumPy library and loading the data (`wine.txt`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Two arrays are returned: `X` (input data), and `y` (target).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to separate our data into two groups: a training dataset and a testing dataset.
    The training dataset will be used to build the model, and the testing dataset
    will be used to see how this trained model performs on unknown data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Four arrays are returned: `X_train`, `X_test`, `y_train`, and `y_test`. This
    data will be used to train and validate the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: To train the model, a decision tree algorithm has been used. A decision tree
    algorithm is based on a non-parametric supervised learning method used for classification
    and regression. The aim is to build a model that predicts the value of a target
    variable using decision rules inferred from the data features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it''s time to the compute accuracy of the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, a confusion matrix will be calculated to compute the model performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Values not present on the diagonals represent classification errors. So, only
    four errors were committed by the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, the quality of wine based on the chemical properties of wines
    grown was predicted. To do this, a decision tree algorithm was used. A decision
    tree shows graphically the choices made or proposed. It does not happen so often
    that things are so clear that the choice between two solutions is immediate. Often,
    a decision is determined by a series of cascading conditions. Representing this
    concept with tables and numbers is difficult. In fact, even if a table represents
    a phenomenon, it may confuse the reader because the justification for the choice
    is not obvious.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A tree structure allows us to extract the information with clear legibility
    by highlighting the branch we have inserted to determine the choice or evaluation.
    Decision tree technology is useful for identifying a strategy or pursuing a goal
    by creating a model with probable results. The decision tree graph immediately
    orients the reading of the result. A plot is much more eloquent than a table full
    of numbers. The human mind prefers to see a solution first and then go back to
    understand a justification of the solution, instead of a series of algebraic descriptions,
    percentages, and data to describe a result.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.tree.DecisionTreeClassifier()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Decision Trees* (from the University of Hildesheim, Germany): [https://www.ismll.uni-hildesheim.de/lehre/ml-06w/skript/ml-4up-04-decisiontrees.pdf](https://www.ismll.uni-hildesheim.de/lehre/ml-06w/skript/ml-4up-04-decisiontrees.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Decision Trees* (from scikit-learn''s official documentation): [https://scikit-learn.org/stable/modules/tree.html#tree](https://scikit-learn.org/stable/modules/tree.html#tree)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Newsgroup trending topics classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Newsgroups are discussion groups on many issues and are made available by news-servers,
    located all over the world, which collect messages from clients and transmit them,
    on the one hand, to all their users and, on the other, to other news-servers connected
    to the network. The success of this technology is due to user interaction in discussions.
    Everyone has to respect the rules of the group.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will build a classifier that will allow us to classify the
    membership of a topic into a particular discussion group. This operation will
    be useful to verify whether the topic is relevant to the discussion group. We
    will use the data contained in the 20 newsgroups dataset, available at the following
    URL: [http://qwone.com/~jason/20Newsgroups/](http://qwone.com/~jason/20Newsgroups/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a collection of about 20,000 newsgroup documents, divided into 20 different
    newsgroups. Originally collected by Ken Lang, and published in *Newsweeder paper:
    Learning to filter netnews,* the dataset is particularly useful for dealing with
    text classification problems.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to perform newsgroup trending topics classification:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `post.classification.py` file, already provided to you as a
    reference. We start importing the dataset as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'This dataset is contained in the `sklearn.datasets` library; in this way, it
    will be very easy for us to recover the data. As anticipated, the dataset contains
    posts related to 20 newsgroups. We will limit our analysis to only the following
    two newsgroups:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Download the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The data has two attributes: `data` and `target`. Obviously, `data` represents
    the input and `target` is the output. Let''s check which newsgroups have been
    selected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the shape:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract features from texts, we will use the `CountVectorizer()` function
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: In this way, we have made a count of the occurrences of words.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s divide the number of occurrences of each word in a document by the
    total number of words in the document:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can build the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will compute the accuracy of the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we built a classifier to classify the membership of a topic
    into a particular discussion group. To extract features from the text, a **tokenization**
    procedure was needed. In the tokenization phase, within each single sentence,
    atomic elements called **tokens** are identified; based on the token identified,
    it's possible to carry out an analysis and evaluation of the sentence itself. Once
    the characteristics of the text had been extracted, a classifier based on the
    multinomial Naive Bayes algorithm was constructed.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Naive Bayes multinomial algorithm is used for text and images when features
    represent the frequency of words (textual or visual) in a document.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official documentation of the *Dataset loading utilities*: [https://scikit-learn.org/stable/datasets/index.html](https://scikit-learn.org/stable/datasets/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.feature_extraction.text.CountVectorizer()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.feature_extraction.text.TfidfTransformer()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The official documentation of the `sklearn.naive_bayes.MultinomialNB()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
