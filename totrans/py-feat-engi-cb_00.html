<html><head></head><body>
		<div id="_idContainer004">
			<h1 id="_idParaDest-6"><a id="_idTextAnchor005"/><st c="0">Preface</st></h1>
			<p><em class="italic"><st c="8">Python Feature Engineering Cookbook</st></em><st c="44">, covers almost every aspect of feature engineering for tabular data, including missing data imputation, categorical encoding, variable transformation, discretization, scaling, and the handling of outliers. </st><st c="251">It also discusses how to extract features from date and time, text, time series, and </st><span class="No-Break"><st c="336">relational datasets.</st></span></p>
			<p><st c="356">This book will take the pain out of feature engineering by showing you how to use open  source Python libraries to accelerate the feature engineering process, via multiple practical, hands-on recipes. </st><st c="557">Throughout the book, you will transform and create new variables utilizing </st><strong class="source-inline"><st c="632">pandas</st></strong><st c="638"> and </st><strong class="source-inline"><st c="643">scikit-learn</st></strong><st c="655">. Additionally, you’ll learn to leverage the power of four major open source feature engineering libraries – Feature-engine, Category Encoders, Featuretools, </st><span class="No-Break"><st c="813">and tsfresh.</st></span></p>
			<p><st c="825">You’ll also discover additional recipes that weren’t in the second edition. </st><st c="902">These cover imputing missing data in time series, creating new features with decision trees, and highlighting outliers using the median absolute deviation. </st><st c="1058">More importantly, we provide guidelines to help you decide which transformations to use, based on your model and data features. </st><st c="1186">You’ll know exactly what, why, and how to implement each </st><span class="No-Break"><st c="1243">feature transformation.</st></span></p>
			<h1 id="_idParaDest-7"><a id="_idTextAnchor006"/><st c="1266">Who this book is for</st></h1>
			<p><st c="1287">This book is for machine learning and data science students and professionals, as well as software engineers involved in deploying machine learning models, who seek to enhance their skills in data transformation and feature creation for improved model training. </st><st c="1550">It is designed for anyone interested in or currently engaged in feature engineering, providing clear guidance on what to do, how to do it, and why it matters. </st><st c="1709">This resource goes beyond basic knowledge, offering practical insights and detailed explanations to help you master feature </st><span class="No-Break"><st c="1833">engineering effectively.</st></span></p>
			<h1 id="_idParaDest-8"><a id="_idTextAnchor007"/><st c="1857">What this book covers</st></h1>
			<p><a href="B22396_01.xhtml#_idTextAnchor020"><span class="No-Break"><em class="italic"><st c="1879">Chapter 1</st></em></span></a><st c="1889">, </st><em class="italic"><st c="1891">Imputing Missing Data</st></em><st c="1912">, explores techniques to replace missing values with suitable estimates for numerical, categorical, and time series data. </st><st c="2034">It covers both single and multiple imputation methods and demonstrates how to streamline the imputation process using scikit-learn </st><span class="No-Break"><st c="2165">and Feature-engine.</st></span></p>
			<p><a href="B22396_02.xhtml#_idTextAnchor182"><span class="No-Break"><em class="italic"><st c="2184">Chapter 2</st></em></span></a><st c="2194">, </st><em class="italic"><st c="2196">Encoding Categorical Variables</st></em><st c="2226">, covers methods to transform categorical variables into numerical features. </st><st c="2303">It begins with common techniques such as one-hot and ordinal encoding and then explores adaptations for high cardinality and linear models. </st><st c="2443">The chapter also discusses domain-specific methods, such as weight of evidence, and demonstrates how to encode highly cardinal variables using methods such as target encoding, ensuring that you understand how to regularize the process to </st><span class="No-Break"><st c="2681">avoid overfitting.</st></span></p>
			<p><a href="B22396_03.xhtml#_idTextAnchor351"><span class="No-Break"><em class="italic"><st c="2699">Chapter 3</st></em></span></a><st c="2709">, </st><em class="italic"><st c="2711">Transforming Numerical Variables</st></em><st c="2743">, discusses when and why you need to transform variables for use in machine learning models. </st><st c="2836">Then, it shows you different variable transformation functions and highlights which types of variables each function is best suited for. </st><st c="2973">By the end of this chapter, you’ll understand when you need to transform your variables and why you apply the logarithm or the square root, among </st><span class="No-Break"><st c="3119">other functions.</st></span></p>
			<p><a href="B22396_04.xhtml#_idTextAnchor516"><span class="No-Break"><em class="italic"><st c="3135">Chapter 4</st></em></span></a><st c="3145">, </st><em class="italic"><st c="3147">Performing Variable Discretization</st></em><st c="3181">, introduces the concept of discretization, highlighting its uses in machine learning. </st><st c="3268">The chapter then explores various discretization methods, detailing their advantages and limitations. </st><st c="3370">It covers the basic equal-with and equal-frequency discretization procedures, as well as discretization using decision trees and </st><em class="italic"><st c="3499">k</st></em><st c="3500">-means. </st><st c="3508">Finally, it pairs discretization with encoding to return variables that are monotonic with </st><span class="No-Break"><st c="3599">the target.</st></span></p>
			<p><a href="B22396_05.xhtml#_idTextAnchor662"><span class="No-Break"><em class="italic"><st c="3610">Chapter 5</st></em></span></a><st c="3620">, </st><em class="italic"><st c="3622">Working with Outliers</st></em><st c="3643">, presents methods to identify outliers and understand their characteristics. </st><st c="3721">It then discusses techniques to remove outliers or adjust their values to fit within accepted boundaries, utilizing pandas </st><span class="No-Break"><st c="3844">and Feature-engine.</st></span></p>
			<p><a href="B22396_06.xhtml#_idTextAnchor748"><span class="No-Break"><em class="italic"><st c="3863">Chapter 6</st></em></span></a><st c="3873">, </st><em class="italic"><st c="3875">Extracting Features from Date and Time</st></em><em class="italic"><st c="3913"> Variables</st></em><st c="3923">, describes how to create features from dates and time variables. </st><st c="3989">It covers how to extract date and time components from features, as well as how to combine datetime variables and how to work with different </st><span class="No-Break"><st c="4130">time zones.</st></span></p>
			<p><a href="B22396_07.xhtml#_idTextAnchor873"><span class="No-Break"><em class="italic"><st c="4141">Chapter 7</st></em></span></a><st c="4151">, </st><em class="italic"><st c="4153">Performing Feature Scaling</st></em><st c="4179">, covers methods to put the variables on a similar scale. </st><st c="4237">It discusses standardization, how to scale to maximum and minimum values, and how to perform more robust forms of variable scaling. </st><st c="4369">You’ll also find guidelines about which method to use, based on your model </st><span class="No-Break"><st c="4444">and variables.</st></span></p>
			<p><a href="B22396_08.xhtml#_idTextAnchor987"><span class="No-Break"><em class="italic"><st c="4458">Chapter 8</st></em></span></a><st c="4468">, </st><em class="italic"><st c="4470">Creating New Features</st></em><st c="4491">, describes various methods to combine existing variables to generate new features. </st><st c="4575">It shows the use of mathematical operations to combine features based on domain knowledge. </st><st c="4666">Then, it discusses how to transform features through the sine, cosine, and the use of splines. </st><st c="4761">Finally, it shows you the value of creating features from one or more variables through </st><span class="No-Break"><st c="4849">decision trees.</st></span></p>
			<p><a href="B22396_09.xhtml#_idTextAnchor1143"><span class="No-Break"><em class="italic"><st c="4864">Chapter 9</st></em></span></a><st c="4874">, </st><em class="italic"><st c="4876">Extracting Features from Relational Data with Featuretools</st></em><st c="4934">, introduces relational datasets and then moves on to explain how we can create features at different data aggregation levels, utilizing Featuretools. </st><st c="5085">You will learn how to automatically create dozens of features from numerical and categorical variables, datetime, </st><span class="No-Break"><st c="5199">and text.</st></span></p>
			<p><a href="B22396_10.xhtml#_idTextAnchor1323"><span class="No-Break"><em class="italic"><st c="5208">Chapter 10</st></em></span></a><st c="5219">, </st><em class="italic"><st c="5221">Creating Features from a Time Series with tsfresh</st></em><st c="5270">, discusses how to automatically create hundreds of features from time series data for use in supervised classification or regression. </st><st c="5405">You’ll leverage the power of tsfresh to automatically create and select relevant features from your </st><span class="No-Break"><st c="5505">time series.</st></span></p>
			<p><a href="B22396_11.xhtml#_idTextAnchor1459"><span class="No-Break"><em class="italic"><st c="5517">Chapter 11</st></em></span></a><st c="5528">, </st><em class="italic"><st c="5530">Extracting Features from Text Variables</st></em><st c="5569">, explores effective methods to clean and extract features from short text segments for use in supervised learning models. </st><st c="5692">The chapter covers techniques to count words, sentences, and characters and measure lexical diversity. </st><st c="5795">Additionally, it guides you through text cleaning processes and demonstrates how to build feature matrices by </st><span class="No-Break"><st c="5905">counting words.</st></span></p>
			<h1 id="_idParaDest-9"><a id="_idTextAnchor008"/><st c="5920">To get the most out of this book</st></h1>
			<p><st c="5953">This book provides practical tools and techniques to streamline your feature engineering pipelines, allowing you to enhance code quality and simplify processes. </st><st c="6115">The book explores methods to transform and create features to effectively train machine learning models with Python. </st><st c="6232">Therefore, familiarity with machine learning and Python programming will benefit your understanding and application of the </st><span class="No-Break"><st c="6355">concepts presented.</st></span></p>
			<p><st c="6374">The recipes have been tested in the following </st><span class="No-Break"><st c="6421">library versions:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="6438">category-encoders == 2.6.3</st></strong></li>
				<li><strong class="source-inline"><st c="6465">Feature-engine == 1.8.0</st></strong></li>
				<li><strong class="source-inline"><st c="6489">featuretools == 1.31.0</st></strong></li>
				<li><strong class="source-inline"><st c="6512">matplotlib==3.8.3</st></strong></li>
				<li><strong class="source-inline"><st c="6530">nltk=3.8.1</st></strong></li>
				<li><strong class="source-inline"><st c="6541">numpy==1.26.4</st></strong></li>
				<li><strong class="source-inline"><st c="6555">pandas==2.2.1</st></strong></li>
				<li><strong class="source-inline"><st c="6569">scikit-learn==1.5.0</st></strong></li>
				<li><strong class="source-inline"><st c="6589">scipy==1.12.0</st></strong></li>
				<li><strong class="source-inline"><st c="6603">seaborn==0.13.2</st></strong></li>
				<li><strong class="source-inline"><st c="6619">tsfresh==0.20.0</st></strong></li>
			</ul>
			<table id="table001" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold"><st c="6635">Software/hardware covered in </st></strong><span class="No-Break"><strong class="bold"><st c="6665">the book</st></strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold"><st c="6673">OS requirements</st></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><st c="6689">Python 3.9 </st><span class="No-Break"><st c="6701">or greater</st></span></p>
						</td>
						<td class="No-Table-Style">
							<p><st c="6711">Windows, macOS, </st><span class="No-Break"><st c="6728">or Linux</st></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p><em class="italic"><st c="6736">Note that earlier or newer versions of the Python libraries may prevent code from running. </st><st c="6828">If you are using newer versions, make sure to check their documentation for any recent updates, parameter name changes, </st></em><span class="No-Break"><em class="italic"><st c="6948">or deprecation.</st></em></span></p>
			<p><strong class="bold"><st c="6963">If you are using the digital version of this book, we advise you to type the code yourself or access the code via the GitHub repository (the link is available in the next section). </st><st c="7145">Doing so will help you avoid any potential errors related to the copying and pasting </st></strong><span class="No-Break"><strong class="bold"><st c="7230">of code.</st></strong></span></p>
			<h2 id="_idParaDest-10"><a id="_idTextAnchor009"/><st c="7238">Download the example code files</st></h2>
			<p><st c="7270">You can download the example code files for this book from GitHub at </st><a href="https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition"><st c="7340">https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition</st></a><st c="7424">. If there’s an update to the code, it will be updated on the existing </st><span class="No-Break"><st c="7495">GitHub repository.</st></span></p>
			<p><st c="7513">We also have other code bundles from our rich catalog of books and videos available at </st><a href="https://github.com/PacktPublishing/"><st c="7601">https://github.com/PacktPublishing/</st></a><st c="7636">. Check </st><span class="No-Break"><st c="7644">them out!</st></span></p>
			<h1 id="_idParaDest-11"><a id="_idTextAnchor010"/><st c="7653">Conventions used</st></h1>
			<p><st c="7670">There are a number of text conventions used throughout </st><span class="No-Break"><st c="7726">this book.</st></span></p>
			<p><strong class="source-inline"><st c="7736">Code in text</st></strong><st c="7749">: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. </st><st c="7902">Here is an example: “We used </st><strong class="source-inline"><st c="7931">year</st></strong><st c="7935">, </st><strong class="source-inline"><st c="7937">month</st></strong><st c="7942">, and </st><strong class="source-inline"><st c="7948">quarter</st></strong><st c="7955"> to capture the year, month, and quarter, respectively, in new columns of </st><span class="No-Break"><st c="8029">the DataFrame.”</st></span></p>
			<p><st c="8044">A block of code is set </st><span class="No-Break"><st c="8068">as follows:</st></span></p>
			<pre class="source-code"><st c="8079">
date = "2024-05-17"
rng_hr = pd.date_range(date, periods=20, freq="h")
rng_month = pd.date_range(date, periods=20, freq="ME")
df = pd.DataFrame({"date1": rng_hr, "date2": rng_month})</st></pre>			<p><st c="8262">Any command-line input or output is written </st><span class="No-Break"><st c="8307">as follows:</st></span></p>
			<pre class="console"><st c="8318">
pip install yellowbrick</st></pre>			<p class="callout-heading"><st c="8342">Tips or important notes</st></p>
			<p class="callout"><st c="8366">Appear like this.</st></p>
			<h1 id="_idParaDest-12"><a id="_idTextAnchor011"/><st c="8384">Sections</st></h1>
			<p><st c="8393">In this book, you will find several headings that appear frequently (</st><em class="italic"><st c="8463">Getting ready</st></em><st c="8477">, </st><em class="italic"><st c="8479">How to do it...</st></em><st c="8494">, </st><em class="italic"><st c="8496">How it works...</st></em><st c="8511">, </st><em class="italic"><st c="8513">There’s more...</st></em><st c="8528">, and </st><span class="No-Break"><em class="italic"><st c="8534">See also</st></em></span><span class="No-Break"><st c="8542">).</st></span></p>
			<p><st c="8545">To give clear instructions on how to complete a recipe, use these sections </st><span class="No-Break"><st c="8621">as follows:</st></span></p>
			<h2 id="_idParaDest-13"><a id="_idTextAnchor012"/><st c="8632">Getting ready</st></h2>
			<p><st c="8646">This section tells you what to expect in the recipe and describes how to set up any software or any preliminary settings required for </st><span class="No-Break"><st c="8781">the recipe.</st></span></p>
			<h2 id="_idParaDest-14"><a id="_idTextAnchor013"/><st c="8792">How to do it…</st></h2>
			<p><st c="8806">This section contains the steps required to follow </st><span class="No-Break"><st c="8858">the recipe.</st></span></p>
			<h2 id="_idParaDest-15"><a id="_idTextAnchor014"/><st c="8869">How it works…</st></h2>
			<p><st c="8883">This section usually consists of a detailed explanation of what happened in the </st><span class="No-Break"><st c="8964">previous section.</st></span></p>
			<h2 id="_idParaDest-16"><a id="_idTextAnchor015"/><st c="8981">There’s more…</st></h2>
			<p><st c="8995">This section consists of additional information about the recipe to make you more knowledgeable </st><span class="No-Break"><st c="9092">about it.</st></span></p>
			<h2 id="_idParaDest-17"><a id="_idTextAnchor016"/><st c="9101">See also</st></h2>
			<p><st c="9110">This section provides helpful links to other useful information for </st><span class="No-Break"><st c="9179">the recipe.</st></span></p>
			<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/><st c="9190">Get in touch</st></h1>
			<p><st c="9203">Feedback from our readers is </st><span class="No-Break"><st c="9233">always welcome.</st></span></p>
			<p><strong class="bold"><st c="9248">General feedback</st></strong><st c="9265">: If you have questions about any aspect of this book, mention the book title in the subject of your message and email us </st><span class="No-Break"><st c="9388">at </st></span><a href="mailto:customercare@packtpub.com"><span class="No-Break"><st c="9391">customercare@packtpub.com</st></span></a><span class="No-Break"><st c="9416">.</st></span></p>
			<p><strong class="bold"><st c="9417">Errata</st></strong><st c="9424">: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. </st><st c="9520">If you have found a mistake in this book, we would be grateful if you would report this to us. </st><st c="9615">Please visit </st><a href="http://www.packtpub.com/support/errata"><st c="9628">www.packtpub.com/support/errata</st></a><st c="9659">, select your book, click on the </st><strong class="bold"><st c="9692">Errata Submission Form</st></strong><st c="9714"> link, and enter </st><span class="No-Break"><st c="9731">the details.</st></span></p>
			<p><strong class="bold"><st c="9743">Piracy</st></strong><st c="9750">: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. </st><st c="9921">Please contact us at </st><a href="mailto:copyright@packt.com"><st c="9942">copyright@packt.com</st></a><st c="9961"> with a link to </st><span class="No-Break"><st c="9977">the material.</st></span></p>
			<p><strong class="bold"><st c="9990">If you are interested in becoming an author</st></strong><st c="10034">: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please </st><span class="No-Break"><st c="10159">visit </st></span><a href="http://authors.packtpub.com"><span class="No-Break"><st c="10165">authors.packtpub.com</st></span></a><span class="No-Break"><st c="10185">.</st></span></p>
			<h1 id="_idParaDest-19"><a id="_idTextAnchor018"/><st c="10186">Share Your Thoughts</st></h1>
			<p><st c="10206">Once you’ve read </st><em class="italic"><st c="10224">Python Feature Engineering Cookbook</st></em><st c="10259">, we’d love to hear your thoughts! </st><st c="10294">Please </st><a href="https://packt.link/r/1835883591"><st c="10301">click here to go straight to the Amazon review page</st></a><st c="10352"> for this book and share </st><span class="No-Break"><st c="10377">your feedback.</st></span></p>
			<p><st c="10391">Your review is important to us and the tech community and will help us make sure we’re delivering excellent </st><span class="No-Break"><st c="10500">quality content.</st></span></p>
			<h1 id="_idParaDest-20"><a id="_idTextAnchor019"/><st c="10516">Download a free PDF copy of this book</st></h1>
			<p><st c="10554">Thanks for purchasing </st><span class="No-Break"><st c="10577">this book!</st></span></p>
			<p><st c="10587">Do you like to read on the go but are unable to carry your print </st><span class="No-Break"><st c="10653">books everywhere?</st></span></p>
			<p><st c="10670">Is your eBook purchase not compatible with the device of </st><span class="No-Break"><st c="10728">your choice?</st></span></p>
			<p><st c="10740">Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at </st><span class="No-Break"><st c="10827">no cost.</st></span></p>
			<p><st c="10835">Read anywhere, any place, on any device. </st><st c="10877">Search, copy, and paste code from your favorite technical books directly into your application. </st></p>
			<p><st c="10973">The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your </st><span class="No-Break"><st c="11088">inbox daily</st></span></p>
			<p><st c="11099">Follow these simple steps to get </st><span class="No-Break"><st c="11133">the benefits:</st></span></p>
			<ol>
				<li><st c="11146">Scan the QR code or visit the </st><span class="No-Break"><st c="11177">link below</st></span></li>
			</ol>
			<div>
				<div id="_idContainer003" class="IMG---Figure">
					<img src="image/B22396_QR_Free_PDF.jpg" alt="" role="presentation"/><st c="11187"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a href="https://packt.link/free-ebook/978-1-83588-358-7"><st c="11189">https://packt.link/free-ebook/978-1-83588-358-7</st></a></p>
			<ol>
				<li value="2"><st c="11236">Submit your proof </st><span class="No-Break"><st c="11255">of purchase</st></span></li>
				<li><st c="11266">That’s it! </st><st c="11278">We’ll send your free PDF and other benefits to your </st><span class="No-Break"><st c="11330">email directly</st></span></li>
			</ol>
		</div>
	<div id="charCountTotal" value="11344"/></body></html>