<html><head></head><body>
  <div><div><div><div><div><h1 class="title"><a id="ch01"/>Chapter 1. Applying Geometric Transformations to Images</h1></div></div></div><p>In this chapter, we are going to learn how to apply cool geometric effects to images. Before we get started, we need to install OpenCV-Python. We will discuss how to install the necessary tools and packages as well.</p><p>By the end of this chapter, you will know:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">How to install OpenCV-Python</li><li class="listitem" style="list-style-type: disc">How to read, display, and save images</li><li class="listitem" style="list-style-type: disc">How to convert between multiple color spaces</li><li class="listitem" style="list-style-type: disc">How to apply geometric transformations like translation, rotation, and scaling</li><li class="listitem" style="list-style-type: disc">How to use affine and projective transformations to apply funny geometric effects on photos</li></ul></div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec08"/>Installing OpenCV-Python</h1></div></div></div><p>Let's see how to install <a id="id0" class="indexterm"/>OpenCV <a id="id1" class="indexterm"/>with Python support on multiple platforms.</p><div><div><div><div><h2 class="title"><a id="ch01lvl2sec08"/>Windows</h2></div></div></div><p>In order to get <a id="id2" class="indexterm"/>OpenCV-Python up and <a id="id3" class="indexterm"/>running, we need to<a id="id4" class="indexterm"/> perform the following steps:</p><div><ol class="orderedlist arabic"><li class="listitem">Install Python: Make sure you have Python 2.7.x<a id="id5" class="indexterm"/> installed on your machine. If you don't have it, you can install it from <a class="ulink" href="https://www.python.org/downloads/windows/">https://www.python.org/downloads/windows/</a></li><li class="listitem">Install NumPy: NumPy<a id="id6" class="indexterm"/> is a great package to do numerical computing in Python. It is very powerful and has a wide variety of functions. OpenCV-Python plays nicely with NumPy, and we will be using this package a lot, during<a id="id7" class="indexterm"/> the course of this book. You can install the latest version from <a class="ulink" href="http://sourceforge.net/projects/numpy/files/NumPy/">http://sourceforge.net/projects/numpy/files/NumPy/</a></li></ol></div><p>We need to<a id="id8" class="indexterm"/> install all these packages in their default<a id="id9" class="indexterm"/> locations. Once we install Python and<a id="id10" class="indexterm"/> NumPy, we need to ensure that they're working fine. Open up the Python shell and type the following:</p><div><pre class="programlisting">
<strong>&gt;&gt;&gt; import numpy</strong>
</pre></div><p>If the installation has gone well, this shouldn't throw any error. Once you confirm it, you can go ahead and download the latest OpenCV<a id="id11" class="indexterm"/> version from <a class="ulink" href="http://opencv.org/downloads.html">http://opencv.org/downloads.html</a>.</p><p>Once you finish downloading it, double-click to install it. We need to make a couple of changes, as follows:</p><div><ol class="orderedlist arabic"><li class="listitem">Navigate to <code class="literal">opencv/build/python/2.7/</code></li><li class="listitem">You will see a file named <code class="literal">cv2.pyd</code>. Copy this file to <code class="literal">C:/Python27/lib/site-packages</code></li></ol></div><p>You're all set! Let's make sure that OpenCV is working. Open up the Python shell and type the following:</p><div><pre class="programlisting">
<strong>&gt;&gt;&gt; import cv2</strong>
</pre></div><p>If you don't see any errors, then you are good to go! You are now ready to use OpenCV-Python.</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec09"/>Mac OS X</h2></div></div></div><p>To install <a id="id12" class="indexterm"/>OpenCV-Python, we will be using <a id="id13" class="indexterm"/><strong>Homebrew</strong>. Homebrew<a id="id14" class="indexterm"/> is a great<a id="id15" class="indexterm"/> package manager for Mac OS X and it will come in handy when you are installing various libraries and utilities on OS X. If you don't have Homebrew, you can install it by running the following command on your terminal:</p><div><pre class="programlisting">
<strong>$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</strong>
</pre></div><p>Even though OS X comes with inbuilt Python, we need to install Python using Homebrew to make our lives easier. This version is called brewed Python. Once you install Homebrew, the next step is to install brewed Python. Open up the terminal and type the following:</p><div><pre class="programlisting">
<strong>$ brew install python</strong>
</pre></div><p>This will<a id="id16" class="indexterm"/> automatically install <code class="literal">pip</code> as well. Pip is a<a id="id17" class="indexterm"/> package<a id="id18" class="indexterm"/> management tool to install packages in Python and we will be using it to install other packages. Let's make sure the brewed Python is working correctly. Go to your terminal and type the following:</p><div><pre class="programlisting">
<strong>$ which python</strong>
</pre></div><p>You <a id="id19" class="indexterm"/>should see <code class="literal">/usr/local/bin/python</code> printed on the terminal. This means that we are using the brewed Python and not the inbuilt system Python. Now that we have installed brewed Python, we can go ahead and add the repository, <code class="literal">homebrew/science</code>, which is where OpenCV is located. Open the terminal and run the following command:</p><div><pre class="programlisting">
<strong>$ brew tap homebrew/science</strong>
</pre></div><p>Make sure the package NumPy is installed. If not, run the following in your terminal:</p><div><pre class="programlisting">
<strong>$ pip install numpy</strong>
</pre></div><p>Now, we are ready to install OpenCV. Go ahead and run the following command from your terminal:</p><div><pre class="programlisting">
<strong>$ brew install opencv --with-tbb --with-opengl</strong>
</pre></div><p>OpenCV is now installed on your machine and you can find it at <code class="literal">/usr/local/Cellar/opencv/2.4.9/</code>. You can't use it just yet. We need to tell Python where to find our OpenCV packages. Let's go ahead and do that by symlinking the OpenCV files. Run the following commands from your terminal:</p><div><pre class="programlisting">
<strong>$ cd /Library/Python/2.7/site-packages/</strong>
<strong>$ ln -s /usr/local/Cellar/opencv/2.4.9/lib/python2.7/site-packages/cv.py cv.py</strong>
<strong>$ ln -s /usr/local/Cellar/opencv/2.4.9/lib/python2.7/site-packages/cv2.so cv2.so</strong>
</pre></div><p>You're all set! Let's see if it's installed properly. Open up the Python shell and type the following:</p><div><pre class="programlisting">
<strong>&gt;&gt;&gt; import cv2</strong>
</pre></div><p>If the installation went well, you will not see any error message. You are now ready to use OpenCV in Python.</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec10"/>Linux (for Ubuntu)</h2></div></div></div><p>Before we start, we <a id="id20" class="indexterm"/>need to install some dependencies. Let's <a id="id21" class="indexterm"/>install them using the package <a id="id22" class="indexterm"/>manager as shown below:</p><div><pre class="programlisting">
<strong>$ sudo apt-get -y install libopencv-dev build-essential cmake libdc1394-22 libdc1394-22-dev libjpeg-dev libpng12-dev libtiff4-dev libjasper-dev libavcodec-dev libavformat-dev libswscale-dev libxine-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev libv4l-dev libtbb-dev libqt4-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev x264 v4l-utils python-scipy python-pip python-virtualenv</strong>
</pre></div><p>Now that you have installed the necessary packages, let's go ahead and build OpenCV with Python support:</p><div><pre class="programlisting">
<strong>$ wget "https://github.com/Itseez/opencv/archive/2.4.9.tar.gz" -O ./opencv/opencv.tar.gz</strong>
<strong>$ cd opencv</strong>
<strong>$ tar xvzf opencv.tar.gz -C .</strong>
<strong>$ mkdir release</strong>
<strong>$ cd release</strong>
<strong>$ sudo apt-get –y install cmake</strong>
<strong>$ cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_PYTHON_SUPPORT=ON -D WITH_XINE=ON -D WITH_OPENGL=ON -D WITH_TBB=ON -D WITH_EIGEN=ON -D BUILD_EXAMPLES=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON ../ </strong>
<strong>$ make –j4</strong>
<strong>$ sudo make install</strong>
</pre></div><p>Let's make sure that it's installed correctly. Open up the Python shell and type the following:</p><div><pre class="programlisting">
<strong>&gt;&gt;&gt; import cv2</strong>
</pre></div><p>If you don't see any errors, you are good to go.</p><p>If you have any other Linux distribution, please refer to the OpenCV<a id="id23" class="indexterm"/> downloads page (<a class="ulink" href="http://opencv.org/downloads.html">http://opencv.org/downloads.html</a>) for installation details.</p></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec09"/>Reading, displaying, and saving images</h1></div></div></div><p>Let's see <a id="id24" class="indexterm"/>how <a id="id25" class="indexterm"/>we can<a id="id26" class="indexterm"/> load an image in OpenCV-Python. Create a file named <code class="literal">first_program.py</code> and open it in your favorite code editor. Create a folder<a id="id27" class="indexterm"/> named <code class="literal">images</code> in the current folder and make sure that you have an image named <code class="literal">input.jpg</code> in <a id="id28" class="indexterm"/>that<a id="id29" class="indexterm"/> folder.</p><p>Once you do that, add the following lines to that Python file:</p><div><pre class="programlisting">import cv2
img = cv2.imread('./images/input.jpg')
cv2.imshow('Input image', img)
cv2.waitKey()</pre></div><p>If you run the preceding program, you will see an image being displayed in a new window.</p><div><div><div><div><h2 class="title"><a id="ch01lvl2sec11"/>What just happened?</h2></div></div></div><p>Let's understand the previous piece of code, line by line. In the first line, we are importing the OpenCV library. We need this for all the functions we will be using in the code. In the second line, we are reading the image and storing it in a variable. OpenCV uses NumPy<a id="id30" class="indexterm"/> data structures to store the images. You can learn more about NumPy at <a class="ulink" href="http://www.numpy.org">http://www.numpy.org</a>
</p><p>So if you open up the Python shell and type the following, you will see the datatype printed on the terminal:</p><div><pre class="programlisting">
<strong>&gt;&gt;&gt; import cv2</strong>
<strong>&gt;&gt;&gt; img = cv2.imread('./images/input.jpg')</strong>
<strong>&gt;&gt;&gt; type(img)</strong>
<strong>&lt;type 'numpy.ndarray'&gt;</strong>
</pre></div><p>In the next line, we display the image in a new window. The first argument in <code class="literal">cv2.imshow</code> is the name of the window. The second argument is the image you want to display.</p><p>You must be wondering why we have the last line here. The function, <code class="literal">cv2.waitKey()</code>, is used in OpenCV for keyboard binding. It takes a number as an argument, and that number indicates the time in milliseconds. Basically, we use this function to wait for a specified duration, until we encounter a keyboard event. The program stops at this point, and waits for you to press any key to continue. If we don't pass any argument or if we pass <code class="literal">0</code> as the argument, this function will wait for a keyboard event indefinitely.</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec12"/>Loading and saving an image</h2></div></div></div><p>OpenCV provides multiple ways of loading an image. Let's say we want to load a color image in grayscale mode. We can do that using the following piece of code:</p><div><pre class="programlisting">import cv2
gray_img = cv2.imread('images/input.jpg', cv2.IMREAD_GRAYSCALE)
cv2.imshow('Grayscale', gray_img)
cv2.waitKey()</pre></div><p>Here, we are <a id="id31" class="indexterm"/>using the flag <code class="literal">cv2.IMREAD_GRAYSCALE</code> to load the image in grayscale <a id="id32" class="indexterm"/>mode. You can see that from the image being displayed in the new window. Next, is the input image:</p><div><img src="img/B04554_01_01.jpg" alt="Loading and saving an image"/></div><p>Following is the corresponding grayscale image:</p><div><img src="img/B04554_01_02.jpg" alt="Loading and saving an image"/></div><p>We can save this image into a file as well:</p><div><pre class="programlisting">cv2.imwrite('images/output.jpg', gray_img)</pre></div><p>This will save the <a id="id33" class="indexterm"/>grayscale image into an output file named <code class="literal">output.jpg</code>. Make<a id="id34" class="indexterm"/> sure you get comfortable with reading, displaying, and saving images in OpenCV, because we will be doing this quite a bit during the course of this book.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec10"/>Image color spaces</h1></div></div></div><p>In computer vision and image processing, color space refers to a specific way of organizing colors. A <a id="id35" class="indexterm"/>color space is actually a combination of two things: a color model and a mapping function. The reason we want color models is because it helps us in representing pixel values using tuples. The mapping function maps the color model to the set of all possible colors that can be represented.</p><p>There are many different color spaces that are useful. Some of the more popular color spaces are RGB, YUV, HSV, Lab, and so on. Different color spaces provide different advantages. We just need to pick the color space that's right for the given problem. Let's take a couple of color spaces and see what information they provide:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>RGB</strong>: It's probably the <a id="id36" class="indexterm"/>most<a id="id37" class="indexterm"/> popular color space. It stands for Red, Green, and Blue. In this color space, each color is represented as a weighted combination of red, green, and blue. So every pixel value is represented as a tuple of three numbers corresponding to red, green, and blue. Each value ranges between 0 and 255.</li><li class="listitem" style="list-style-type: disc"><strong>YUV</strong>: Even though<a id="id38" class="indexterm"/> RGB is good for many purposes, it tends<a id="id39" class="indexterm"/> to be very limited for many real life applications. People started thinking about different methods to separate the intensity information from the color information. Hence, they came up with the YUV color space. Y refers to the luminance or intensity, and U/V channels represent color information. This works well in many applications because the human visual system perceives intensity information very differently from color information.</li><li class="listitem" style="list-style-type: disc"><strong>HSV</strong>: As it<a id="id40" class="indexterm"/> turned out, even<a id="id41" class="indexterm"/> YUV was still not good enough for some of the applications. So people started thinking about how humans perceive color and they came up with the HSV color space. HSV stands for Hue, Saturation, and Value. This is a cylindrical system where we separate three of the most primary properties of colors and represent them using different channels. This is closely related to how the human visual system understands color. This gives us a lot of flexibility as to how we can handle images.</li></ul></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec13"/>Converting between color spaces</h2></div></div></div><p>Considering all the<a id="id42" class="indexterm"/> color spaces, there are around 190 conversion options available in OpenCV. If you want to see a list of all available flags, go to the Python shell and type the following:</p><div><pre class="programlisting">
<strong>&gt;&gt;&gt; import cv2</strong>
<strong>&gt;&gt;&gt; print [x for x in dir(cv2) if x.startswith('COLOR_')]</strong>
</pre></div><p>You will see a list of options available in OpenCV for converting from one color space to another. We can pretty much convert any color space into any other color space. Let's see how we can convert a color image into a grayscale image:</p><div><pre class="programlisting">import cv2
img = cv2.imread('./images/input.jpg')
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
cv2.imshow('Grayscale image', gray_img)
cv2.waitKey()</pre></div></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec14"/>What just happened?</h2></div></div></div><p>We use the function <code class="literal">cvtColor</code> to convert between color spaces. The first argument is the input image and the second argument specifies the color space conversion. You can convert to YUV by using the following flag:</p><div><pre class="programlisting">yuv_img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)</pre></div><p>The image will look something like the following one:</p><div><img src="img/B04554_01_03.jpg" alt="What just happened?"/></div><p>This may look like a deteriorated version of the original image, but it's not. Let's separate out the three channels:</p><div><pre class="programlisting">cv2.imshow('Y channel', yuv_img[:, :, 0])
cv2.imshow('U channel', yuv_img[:, :, 1])
cv2.imshow('V channel', yuv_img[:, :, 2])
cv2.waitKey()</pre></div><p>Since <code class="literal">yuv_img</code> is a numPy<a id="id43" class="indexterm"/> array, we can separate out the three channels by slicing it. If you look at <code class="literal">yuv_img.shape</code>, you will see that it is a 3D array whose dimensions are <code class="literal">NUM_ROWS x NUM_COLUMNS x NUM_CHANNELS</code>. So once you run the preceding piece of code, you will see three different images. Following is the <code class="literal">Y</code> channel:</p><div><img src="img/B04554_01_04.jpg" alt="What just happened?"/></div><p>The <code class="literal">Y</code> channel is basically the grayscale image. Next is the <code class="literal">U</code> channel:</p><div><img src="img/B04554_01_05.jpg" alt="What just happened?"/></div><p>And lastly, the<a id="id44" class="indexterm"/> <code class="literal">V</code> channel:</p><div><img src="img/B04554_01_06.jpg" alt="What just happened?"/></div><p>As we can see here, the <code class="literal">Y</code> channel is the same as the grayscale image. It represents the intensity values. The <code class="literal">U</code> and <code class="literal">V</code> channels represent the color information.</p><p>Let's convert to HSV and see what happens:</p><div><pre class="programlisting">hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
cv2.imshow('HSV image', hsv_img)</pre></div><div><img src="img/B04554_01_07.jpg" alt="What just happened?"/></div><p>Again, let's <a id="id45" class="indexterm"/>separate the channels:</p><div><pre class="programlisting">cv2.imshow('H channel', hsv_img[:, :, 0])
cv2.imshow('S channel', hsv_img[:, :, 1])
cv2.imshow('V channel', hsv_img[:, :, 2])
cv2.waitKey()</pre></div><p>If you run the<a id="id46" class="indexterm"/> preceding piece of code, you will see three different images. Take a look at the <code class="literal">H</code> channel:</p><div><img src="img/B04554_01_08.jpg" alt="What just happened?"/></div><p>Next is the <code class="literal">S</code> channel:</p><div><img src="img/B04554_01_09.jpg" alt="What just happened?"/></div><p>Following is the <code class="literal">V</code> channel:</p><div><img src="img/B04554_01_10.jpg" alt="What just happened?"/></div><p>This should <a id="id47" class="indexterm"/>give you a basic idea of how to convert between color spaces. You can play around with more color spaces to see what the images look like. We will discuss the relevant color spaces as and when we encounter them during subsequent chapters.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec11"/>Image translation</h1></div></div></div><p>In this section, we will<a id="id48" class="indexterm"/> discuss about shifting an image. Let's say we want to move the image within our frame of reference. In computer vision terminology, this is referred to as <code class="literal">translation</code>. Let's go ahead and see how we can do that:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('images/input.jpg')
num_rows, num_cols = img.shape[:2]

translation_matrix = np.float32([ [1,0,70], [0,1,110] ])
img_translation = cv2.warpAffine(img, translation_matrix, (num_cols, num_rows))
cv2.imshow('Translation', img_translation)
cv2.waitKey()</pre></div><p>If you run the preceding code, you will see something like the following:</p><div><img src="img/B04554_01_11.jpg" alt="Image translation"/></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec15"/>What just happened?</h2></div></div></div><p>To understand the preceding code, we need to understand how warping works. Translation basically means that we are shifting the image by adding/subtracting the X and Y coordinates. In order to do this, we need to create a transformation matrix, as shown as follows:</p><div><img src="img/B04554_01_12.jpg" alt="What just happened?"/></div><p>Here, the <strong>tx</strong> and <strong>ty</strong><a id="id49" class="indexterm"/> values are the X and Y translation values, that is, the image will be moved by <code class="literal">X</code> units towards the right, and by <code class="literal">Y</code> units downwards. So once we create a matrix like this, we can use the function, <code class="literal">warpAffine</code>, to apply to our image. The third argument in <code class="literal">warpAffine</code> refers to the number of rows and columns in the resulting image. Since the number of rows and columns is the same as the original image, the resultant image is going to get cropped. The reason for this is because we didn't have enough space in the output when we applied the translation matrix. To avoid cropping, we can do something like this:</p><div><pre class="programlisting">img_translation = cv2.warpAffine(img, translation_matrix, (num_cols + 70, num_rows + 110))</pre></div><p>If you replace the corresponding line in our program with the preceding line, you will see the following image:</p><div><img src="img/B04554_01_13.jpg" alt="What just happened?"/></div><p>Let's say you want to<a id="id50" class="indexterm"/> move the image in the middle of a bigger image frame; we can do something like this by carrying out the following:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('images/input.jpg')
num_rows, num_cols = img.shape[:2]

translation_matrix = np.float32([ [1,0,70], [0,1,110] ])
img_translation = cv2.warpAffine(img, translation_matrix, (num_cols + 70, num_rows + 110))
translation_matrix = np.float32([ [1,0,-30], [0,1,-50] ])
img_translation = cv2.warpAffine(img_translation, translation_matrix, (num_cols + 70 + 30, num_rows + 110 + 50))
cv2.imshow('Translation', img_translation)
cv2.waitKey()</pre></div><p>If you run the preceding <a id="id51" class="indexterm"/>code, you will see an image like the following:</p><div><img src="img/B04554_01_14.jpg" alt="What just happened?"/></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec12"/>Image rotation</h1></div></div></div><p>In this section, we will see how to <a id="id52" class="indexterm"/>rotate a given image by a certain angle. We can do it using the following piece of code:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('images/input.jpg')
num_rows, num_cols = img.shape[:2]

rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 30, 1)
img_rotation = cv2.warpAffine(img, rotation_matrix, (num_cols, num_rows))
cv2.imshow('Rotation', img_rotation)
cv2.waitKey()</pre></div><p>If you run the preceding code, you will see an image like this:</p><div><img src="img/B04554_01_15.jpg" alt="Image rotation"/></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec16"/>What just happened?</h2></div></div></div><p>In order to understand this, let's see how we handle rotation mathematically. Rotation is also a form of transformation, and we can achieve it by using the following transformation matrix:</p><div><img src="img/B04554_01_16.jpg" alt="What just happened?"/></div><p>Here, <code class="literal">θ</code> is the angle of <a id="id53" class="indexterm"/>rotation in the counterclockwise direction. OpenCV provides closer control over the creation of this matrix through the function, <code class="literal">getRotationMatrix2D</code>. We can specify the point around which the image would be rotated, the angle of rotation in degrees, and a scaling factor for the image. Once we have the transformation matrix, we can use the <code class="literal">warpAffine</code> function to apply this matrix to any image.</p><p>As we can see from the previous figure, the image content goes out of boundary and gets cropped. In order to prevent this, we need to provide enough space in the output image. Let's go ahead and do that using the translation functionality we discussed earlier:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('images/input.jpg')
num_rows, num_cols = img.shape[:2]

translation_matrix = np.float32([ [1,0,int(0.5*num_cols)], [0,1,int(0.5*num_rows)] ])
2*num_cols, 2*num_rows))
rotation_matrix = cv2.getRotationMatrix2D((num_cols, num_rows), 30, img_translation = cv2.warpAffine(img, translation_matrix, (1)
img_rotation = cv2.warpAffine(img_translation, rotation_matrix, (2*num_cols, 2*num_rows)) 

cv2.imshow('Rotation', img_rotation)
cv2.waitKey()</pre></div><p>If we run the preceding code, we <a id="id54" class="indexterm"/>will see something like this:</p><div><img src="img/B04554_01_17.jpg" alt="What just happened?"/></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec13"/>Image scaling</h1></div></div></div><p>In this section, we will<a id="id55" class="indexterm"/> discuss about resizing an image. This is one of the most common operations in computer vision. We can resize an image using a <code class="literal">scaling</code> factor, or we can resize it to a particular size. Let's see how to do that:</p><div><pre class="programlisting">img_scaled = cv2.resize(img,None,fx=1.2, fy=1.2, interpolation = cv2.INTER_LINEAR)
cv2.imshow('Scaling - Linear Interpolation', img_scaled) img_scaled = cv2.resize(img,None,fx=1.2, fy=1.2, interpolation = cv2.INTER_CUBIC)
cv2.imshow('Scaling - Cubic Interpolation', img_scaled) img_scaled = cv2.resize(img,(450, 400), interpolation = cv2.INTER_AREA)
cv2.imshow('Scaling - Skewed Size', img_scaled) cv2.waitKey()</pre></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec17"/>What just happened?</h2></div></div></div><p>Whenever we resize an image, there are multiple ways to fill in the pixel values. When we are enlarging an image, we need to fill up the pixel values in between pixel locations. When we are shrinking an image, we need to take the best representative value. When we are scaling by a non-integer value, we need to interpolate values appropriately, so that the quality of the image is maintained. There are multiple ways to do interpolation. If we are enlarging an image, it's preferable to use linear or cubic interpolation. If we are shrinking an image, it's preferable to use the area-based interpolation. Cubic interpolation is computationally more complex, and hence slower than linear interpolation. But the quality of the resulting image will be higher.</p><p>OpenCV provides a function called <code class="literal">resize</code> to achieve image scaling. If you don't specify a size (by using <code class="literal">None</code>), then it expects the X and Y scaling factors. In our example, the image will be enlarged by a factor of <code class="literal">1.2</code>. If we do the same enlargement using cubic interpolation, we can see that the quality improves, as seen in the following figure. The following screenshot shows what linear interpolation looks like:</p><div><img src="img/B04554_01_18.jpg" alt="What just happened?"/></div><p>Here is the <a id="id56" class="indexterm"/>corresponding cubic interpolation:</p><div><img src="img/B04554_01_19.jpg" alt="What just happened?"/></div><p>If we want to resize<a id="id57" class="indexterm"/> it to a particular size, we can use the format shown in the last resize instance. We can basically skew the image and resize it to whatever size we want. The output will look something like the following:</p><div><img src="img/B04554_01_20.jpg" alt="What just happened?"/></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec14"/>Affine transformations</h1></div></div></div><p>In this section, we will discuss<a id="id58" class="indexterm"/> about the various generalized geometrical transformations of 2D images. We have been using the function <code class="literal">warpAffine</code> quite a bit over the last couple of sections, it's about time we understood what's happening underneath.</p><p>Before talking about affine transformations, let's see what Euclidean transformations are. Euclidean transformations are a type of geometric transformations that preserve length and angle measure. As in, if we take a geometric shape and apply Euclidean transformation to it, the shape will remain unchanged. It might look rotated, shifted, and so on, but the basic structure will not change. So technically, lines will remain lines, planes will remain planes, squares will remain squares, and circles will remain circles.</p><p>Coming back to affine transformations, we can say that they are generalizations of Euclidean transformations. Under the realm of affine transformations, lines will remain lines but squares might become rectangles or parallelograms. Basically, affine transformations don't preserve lengths and angles.</p><p>In order to build a general affine transformation matrix, we need to define the control points. Once we have these control points, we need to decide where we want them to be mapped. In this particular situation, all we need are three points in the source image, and three points in the output image. Let's see how we can convert an image into a parallelogram-like image:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('images/input.jpg')
rows, cols = img.shape[:2]

src_points = np.float32([[0,0], [cols-1,0], [0,rows-1]])
dst_points = np.float32([[0,0], [int(0.6*(cols-1)),0], [int(0.4*(cols-1)),rows-1]])
affine_matrix = cv2.getAffineTransform(src_points, dst_points)
img_output = cv2.warpAffine(img, affine_matrix, (cols,rows))

cv2.imshow('Input', img)
cv2.imshow('Output', img_output)
cv2.waitKey()</pre></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec18"/>What just happened?</h2></div></div></div><p>As we discussed earlier, we <a id="id59" class="indexterm"/>are defining control points. We just need three points to get the affine transformation matrix. We want the three points in <code class="literal">src_points</code> to be mapped to the corresponding points in <code class="literal">dst_points</code>. We are mapping the points as shown in the following:</p><div><img src="img/B04554_01_21.jpg" alt="What just happened?"/></div><p>To get the transformation matrix, we have a function called <code class="literal">getAffineTransform</code> in OpenCV. Once we have the affine transformation matrix, we use the <code class="literal">warpAffine</code> function to apply this matrix to the input image.</p><p>Following is the input image:</p><div><img src="img/B04554_01_22.jpg" alt="What just happened?"/></div><p>If you run the <a id="id60" class="indexterm"/>preceding code, the output will look something like this:</p><div><img src="img/B04554_01_23.jpg" alt="What just happened?"/></div><p>We can also get the mirror <a id="id61" class="indexterm"/>image of the input image. We just need to change the control points in the following way:</p><div><pre class="programlisting">src_points = np.float32([[0,0], [cols-1,0], [0,rows-1]])
dst_points = np.float32([[cols-1,0], [0,0], [cols-1,rows-1]])</pre></div><p>Here, the mapping looks something like this:</p><div><img src="img/B04554_01_24.jpg" alt="What just happened?"/></div><p>If you replace the corresponding lines in our affine transformation code with these two lines, you will get the <a id="id62" class="indexterm"/>following result:</p><div><img src="img/B04554_01_25.jpg" alt="What just happened?"/></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec15"/>Projective transformations</h1></div></div></div><p>Affine transformations are nice, but<a id="id63" class="indexterm"/> they impose certain restrictions. A projective transformation, on the other hand, gives us more freedom. It is also referred to as <a id="id64" class="indexterm"/><strong>homography</strong>. In order to understand projective transformations, we need to understand how projective geometry works. We basically describe what happens to an image when the point of view is changed. For example, if you are standing right in front of a sheet of paper with a square drawn on it, it will look like a square. Now, if you start tilting that sheet of paper, the square will start looking more and more like a trapezoid. Projective transformations allow us to capture this dynamic in a nice mathematical way. These transformations preserve neither sizes nor angles, but they do preserve incidence and cross-ratio.</p><div><div><h3 class="title"><a id="note02"/>Note</h3><p>You can read more about incidence<a id="id65" class="indexterm"/> and cross-ratio<a id="id66" class="indexterm"/> at <a class="ulink" href="http://en.wikipedia.org/wiki/Incidence_(geometry)">http://en.wikipedia.org/wiki/Incidence_(geometry)</a> and <a class="ulink" href="http://en.wikipedia.org/wiki/Cross-ratio">http://en.wikipedia.org/wiki/Cross-ratio</a>.</p></div></div><p>Now that we know what projective transformations are, let's see if we can extract more information here. We can say that any two images on a given plane are related by a homography. As long as they are in the same plane, we can transform anything into anything else. This has many practical applications such as augmented reality, image rectification, image registration, or the computation of camera motion between two images. Once the camera rotation and translation have been extracted from an estimated homography matrix, this information may be used for navigation, or to insert models of 3D objects into an image or video. This way, they are rendered with the correct perspective and it will<a id="id67" class="indexterm"/> look like they were part of the original scene.</p><p>Let's go ahead and see how to do this:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('images/input.jpg')
rows, cols = img.shape[:2]

src_points = np.float32([[0,0], [cols-1,0], [0,rows-1], [cols-1,rows-1]])
dst_points = np.float32([[0,0], [cols-1,0], [int(0.33*cols),rows-1], [int(0.66*cols),rows-1]]) 
projective_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
img_output = cv2.warpPerspective(img, projective_matrix, (cols,rows))

cv2.imshow('Input', img)
cv2.imshow('Output', img_output)
cv2.waitKey()</pre></div><p>If you run the preceding code, you will see a funny looking output like the following screenshot:</p><div><img src="img/B04554_01_26.jpg" alt="Projective transformations"/></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec19"/>What just happened?</h2></div></div></div><p>We can choose <a id="id68" class="indexterm"/>four control points in the source image and map them to the destination image. Parallel lines will not remain parallel lines after the transformation. We use a function called <code class="literal">getPerspectiveTransform</code> to get the transformation matrix.</p><p>Let's apply a couple of fun effects using projective transformation and see what they look like. All we need to do is change the control points to get different effects.</p><p>Here's an example:</p><div><img src="img/B04554_01_27.jpg" alt="What just happened?"/></div><p>The control points are as shown next:</p><div><pre class="programlisting">src_points = np.float32([[0,0], [0,rows-1], [cols/2,0], [cols/2,rows-1]])
dst_points = np.float32([[0,100], [0,rows-101], [cols/2,0], [cols/2,rows-1]])</pre></div><p>As an exercise, you should <a id="id69" class="indexterm"/>map the above points on a plane and see how the points are mapped (just like we did earlier, while discussing Affine Transformations). You will get a good understanding about the mapping system, and you can create your own control points.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec16"/>Image warping</h1></div></div></div><p>Let's have some more fun with<a id="id70" class="indexterm"/> the images and see what else we can achieve. Projective transformations are pretty flexible, but they still impose some restrictions on how we can transform the points. What if we want to do something completely random? We need more control, right? As it so happens, we can do that as well. We just need to create our own mapping, and it's not that difficult. Following are a few effects you can achieve with image warping:</p><div><img src="img/B04554_01_28.jpg" alt="Image warping"/></div><p>Here is the<a id="id71" class="indexterm"/> code to create these effects:</p><div><pre class="programlisting">import cv2
import numpy as np
import math

img = cv2.imread('images/input.jpg', cv2.IMREAD_GRAYSCALE)
rows, cols = img.shape

#####################
# Vertical wave

img_output = np.zeros(img.shape, dtype=img.dtype)

for i in range(rows):
    for j in range(cols):
        offset_x = int(25.0 * math.sin(2 * 3.14 * i / 180))
        offset_y = 0
        if j+offset_x &lt; rows:
            img_output[i,j] = img[i,(j+offset_x)%cols]
        else:
            img_output[i,j] = 0

cv2.imshow('Input', img)
cv2.imshow('Vertical wave', img_output)

#####################
# Horizontal wave

img_output = np.zeros(img.shape, dtype=img.dtype)

for i in range(rows):
    for j in range(cols):
        offset_x = 0
        offset_y = int(16.0 * math.sin(2 * 3.14 * j / 150))
        if i+offset_y &lt; rows:
            img_output[i,j] = img[(i+offset_y)%rows,j]
        else:
            img_output[i,j] = 0

cv2.imshow('Horizontal wave', img_output)

#####################
# Both horizontal and vertical 

img_output = np.zeros(img.shape, dtype=img.dtype)

for i in range(rows):
    for j in range(cols):
        offset_x = int(20.0 * math.sin(2 * 3.14 * i / 150))
        offset_y = int(20.0 * math.cos(2 * 3.14 * j / 150))
        if i+offset_y &lt; rows and j+offset_x &lt; cols:
            img_output[i,j] = img[(i+offset_y)%rows,(j+offset_x)%cols]
        else:
            img_output[i,j] = 0

cv2.imshow('Multidirectional wave', img_output)

#####################
# Concave effect

img_output = np.zeros(img.shape, dtype=img.dtype)

for i in range(rows):
    for j in range(cols):
        offset_x = int(128.0 * math.sin(2 * 3.14 * i / (2*cols)))
        offset_y = 0
        if j+offset_x &lt; cols:
            img_output[i,j] = img[i,(j+offset_x)%cols]
        else:
            img_output[i,j] = 0

cv2.imshow('Concave', img_output)

cv2.waitKey()</pre></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec17"/>Summary</h1></div></div></div><p>In this chapter, we learned how to install OpenCV-Python on various platforms. We discussed how to read, display, and save images. We talked about the importance of various color spaces and how we can convert between multiple color spaces. We learned how to apply geometric transformations to images and understood how to use those transformations to achieve cool geometric effects. We discussed the underlying formulation of transformation matrices and how we can formulate different kinds of transformations based on our needs. We learned how to select control points based on the required geometric transformation. We discussed about projective transformations and learned how to use image warping to achieve any given geometric effect. In the next chapter, we are going to discuss edge detection and image filtering. We can apply a lot of visual effects using image filters, and the underlying formation gives us a lot of freedom to manipulate images in creative ways.</p></div></div>
</body></html>