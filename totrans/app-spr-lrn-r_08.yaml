- en: '*Chapter 8:*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 8 章：*'
- en: Model Deployment
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型部署
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Deploy an ML model as an API using the R plumber package
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 R plumber 包将 ML 模型部署为 API
- en: Develop serverless APIs using AWS SageMaker, AWS Lambda, and AWS API Gateway
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS SageMaker、AWS Lambda 和 AWS API Gateway 开发无服务器 API
- en: Create infrastructure from scratch using AWS CloudFormation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS CloudFormation 从零开始创建基础设施
- en: Deploy an ML model as an API using Docker containers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Docker 容器将 ML 模型部署为 API
- en: In this chapter, we will learn how to host, deploy, and manage models on AWS
    and Docker containers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何在 AWS 和 Docker 容器上托管、部署和管理模型。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: In the previous chapter, we studied model improvements and explored the various
    techniques within hyperparameter tuning to improve model performance and develop
    the best model for a given use case. The next step is to deploy the machine learning
    model into production so that it can be easily consumed by or integrated into
    a large software product.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们研究了模型改进，并探讨了超参数调优中的各种技术，以提升模型性能并开发出针对特定用例的最佳模型。下一步是将机器学习模型部署到生产环境中，以便它可以轻松被消费或集成到大型软件产品中。
- en: Most data science professionals assume that the process of developing machine
    learning models ends with hyperparameter tuning when we have the best model in
    place. In reality, the value and impact delivered by a machine learning model
    is limited (mostly futile) if it isn't deployed and (or) integrated with other
    software services/products into a large tech ecosystem. Machine learning and software
    engineering are definitely two separate disciplines. Most data scientists have
    limited proficiency in understanding the software engineering ecosystem and, similarly,
    software engineers have a limited understanding of the machine learning field.
    Thus, in large enterprises where they build a product where a machine learning
    use case evolves into a major feature for a software product, there is a need
    for data scientists and software engineers to collaborate. However, collaboration
    between software engineers and data scientists in most cases is extremely challenging,
    as both find each other's fields highly overwhelming to comprehend.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据科学专业人士认为，当最佳模型已经确定时，开发机器学习模型的过程就结束了，即超参数调优。然而，如果机器学习模型没有被部署并且（或）与其他软件服务/产品集成到大型技术生态系统中，那么它所带来的价值和影响是有限的（大多数情况下是徒劳的）。机器学习和软件工程绝对是两个不同的学科。大多数数据科学家在理解软件工程生态系统方面能力有限，同样，软件工程师对机器学习领域的理解也有限。因此，在大型企业中，他们构建的产品中机器学习用例发展成为软件产品的主要功能时，数据科学家和软件工程师之间的协作是必要的。然而，在大多数情况下，软件工程师和数据科学家之间的协作极其具有挑战性，因为双方都认为对方的领域难以理解。
- en: Over the years, there has been a lot of effort invested in developing tools
    and resources by large corporations to aid data scientists to easily embrace a
    few software engineering components and vice versa. These tools have enabled easier
    collaboration between the two disciplines, accelerating the process of developing
    large-scale, enterprise-grade machine learning products.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型企业投入了大量努力开发工具和资源，以帮助数据科学家轻松地接受一些软件工程组件，反之亦然。这些工具使得两个学科之间的协作更加容易，加速了开发大规模、企业级机器学习产品的过程。
- en: In this chapter, we will learn about a few approaches to deploying machine learning
    models as web services that can easily integrate with other services in a large
    software ecosystem. We will also discuss the pros and cons of the different approaches
    and best practices for model deployment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解一些将机器学习模型作为网络服务部署的方法，这些方法可以轻松地与其他服务集成到大型软件生态系统中。我们还将讨论不同方法的优缺点以及模型部署的最佳实践。
- en: What is an API?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 API？
- en: Before delving into the specifics of model deployment, we need to study an important
    software engineering topic that simplifies the entire process of model deployment,
    that is, an **Application Program Interface**, commonly referred to as an **API**.
    An API is a set of clearly defined methods for communication between various software
    components. Software development has been made significantly easier with the advent
    of APIs. If a developer, say, wanted to develop an iPhone app that would add some
    filters to an image, they need not write the entire code to capture the image
    from the phone's camera, save it to the library, and then apply their app-specific
    filters to it. Instead, they can use the phone camera API, which provides an easy
    way to communicate with the camera and only focus on writing code that would add
    filters to an image. In a nutshell, an API is the means for heterogeneous software
    components to communicate with each other.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究模型部署的具体细节之前，我们需要研究一个重要的软件工程主题，它可以简化整个模型部署过程，那就是**应用程序编程接口**，通常简称为**API**。API是一组明确定义的用于各种软件组件之间通信的方法。随着API的出现，软件开发变得显著更容易。如果一个开发者，比如说，想要开发一个iPhone应用，该应用可以为图片添加一些滤镜，他们不需要编写整个代码来从手机的相机捕获图片，将其保存到库中，然后再应用他们特定的滤镜。相反，他们可以使用手机相机API，这提供了一个简单的方法与相机通信，并且只需专注于编写添加滤镜到图片的代码。简而言之，API是异构软件组件之间通信的手段。
- en: In a large software product, there would be several components that are responsible
    for a specific task. These components interact with each other through a defined
    language that ensures the smooth communication of data, events, and alerts.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个大型软件产品中，会有几个负责特定任务的组件。这些组件通过一种定义良好的语言相互交互，确保数据、事件和警报的顺畅通信。
- en: 'Here are some salient features of APIs:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是API的一些显著特点：
- en: APIs help in **modularizing** software applications and enable the building
    of better products.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API有助于**模块化**软件应用程序，并使构建更好的产品成为可能。
- en: APIs are commonly known by software engineers and are **language agnostic**.
    Thus, heterogenous applications developed in a completely different language or
    system can also effectively communicate with each other.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API通常为软件工程师所熟知，并且是**语言无关**的。因此，在完全不同的语言或系统中开发的异构应用程序也可以有效地相互通信。
- en: Communication between services is also enabled using a common language, that
    is, **JavaScript Object Notation** (short for, **JSON**). However, there are other
    popular languages too, for example, XML.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务之间的通信也使用一种通用语言，即**JavaScript对象表示法**（简称，**JSON**）。然而，还有其他流行的语言，例如，XML。
- en: They also support HTTP, which means APIs are accessible through web browsers
    (such as Google Chrome or Mozilla Firefox) or a tool such as *Postman*.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们也支持HTTP，这意味着API可以通过网络浏览器（如Google Chrome或Mozilla Firefox）或像*Postman*这样的工具访问。
- en: Note
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 备注
- en: Postman is a free tool that offers easy-to-use services in the entire life cycle
    of an API, such as designing, debugging, testing, documenting, monitoring, and
    publishing. It is available for download on the Windows, Linux, and macOS platforms.
    You can learn more about Postman at https://www.getpostman.com/.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Postman是一个免费工具，它在整个API的生命周期中提供易于使用的服务，例如设计、调试、测试、文档、监控和发布。它可在Windows、Linux和macOS平台上下载。您可以在https://www.getpostman.com/了解更多关于Postman的信息。
- en: 'We are particularly interested in the development of RESTful APIs, that is,
    APIs that communicate over HTTP. RESTful APIs are also called **REST APIs** and
    have two main types of methods:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们特别关注RESTful API的发展，即通过HTTP进行通信的API。RESTful API也被称为**REST API**，主要有两种方法类型：
- en: '**GET method**: This is used when we want to read data from a service.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GET方法**：当我们想要从服务中读取数据时使用。'
- en: '**POST method**: This is used when we want to send data to a service.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**POST方法**：当我们想要向服务发送数据时使用。'
- en: A few other methods are **head**, **put**, and **delete**.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他的方法是**head**、**put**和**delete**。
- en: Deploying machine learning models as (web service) REST APIs eases the process
    of integrating a service with other services. Software engineers are fond of using
    REST APIs and since the service is language-agnostic, we have a tremendous advantage
    in developing the model in the language of our choice. The software engineer could
    use Python, Java, Ruby, or one of many other languages for the development of
    other services, whereas we can develop the model in R, Python, Julia, and so on,
    and yet effectively and effortlessly integrate services into a large software
    product.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 将机器学习模型作为（Web服务）REST API部署简化了将服务与其他服务集成的过程。软件工程师喜欢使用REST API，由于该服务是语言无关的，我们在用我们选择的语言开发模型时具有巨大的优势。软件工程师可以使用Python、Java、Ruby或许多其他语言来开发其他服务，而我们可以用R、Python、Julia等语言开发模型，并且能够有效地无缝地将服务集成到大型软件产品中。
- en: Now that we have a fair understanding of APIs, let's understand how we can deploy
    an ML model in R as an API.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对API有了相当的了解，让我们来了解一下如何将一个ML模型部署到R中作为API。
- en: Introduction to plumber
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Plumber简介
- en: '**Plumber** is an R package that helps in translating R functions into an HTTP
    API that can be invoked from other machines within a network, enabling communication
    between systems. By using R plumber, we will be able to achieve the advantages
    discussed, such as developing modularized, language agnostic, common communication
    language (JSON) based HTTP rest APIs that provide a defined path of communication
    between systems. Using plumber is extremely straightforward. With a few lines
    of code, we can convert our existing R functions into a web service that can be
    served as an endpoint.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**Plumber**是一个R包，它帮助将R函数转换为HTTP API，可以从网络中的其他机器调用，从而实现系统间的通信。通过使用R plumber，我们将能够实现所讨论的优势，例如开发模块化、语言无关、基于通用通信语言（JSON）的HTTP
    rest API，这些API为系统间提供定义的通信路径。使用Plumber非常简单。只需几行代码，我们就可以将现有的R函数转换为可以作为一个端点提供服务的Web服务。'
- en: In this chapter, we will extend the same model and use case we built in *Chapter
    7*, *Model Improvements*, to classify whether a patient is diabetic using the
    `PimaIndiasDiabetes` dataset in the `mlbench` library. Later, we will extend the
    same use case to deploy the model as a web service using a Docker container and
    serverless applications.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将扩展我们在*第7章*，*模型改进*中构建的相同模型和用例，使用`mlbench`库中的`PimaIndiasDiabetes`数据集来分类患者是否患有糖尿病。稍后，我们将扩展相同的用例，使用Docker容器和无服务器应用程序将模型部署为Web服务。
- en: 'Exercise 98: Developing an ML Model and Deploying It as a Web Service Using
    Plumber'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习98：使用Plumber开发ML模型并将其作为Web服务部署
- en: In this exercise, we will develop a logistic regression model using three independent
    variables and deploy it as a REST API using Plumber. We will create a simple binary
    classification model and use the `plumber` package's services to wrap the model
    as an API by defining the HTTP get and post methods.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用三个独立变量开发一个逻辑回归模型，并使用Plumber将其作为REST API部署。我们将创建一个简单的二分类模型，并使用`plumber`包的服务通过定义HTTP
    get和post方法将模型封装为API。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Create an R script named `model.R` using RStudio or Jupyter Notebook.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用RStudio或Jupyter Notebook创建一个名为`model.R`的R脚本。
- en: 'Load the required libraries and build a logistic regression model. Now, define
    the `get` methods that accept the input parameters and return the prediction as
    an outcome:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载所需的库并构建一个逻辑回归模型。现在，定义接受输入参数并返回预测结果的`get`方法：
- en: '[PRE0]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'This data has been taken from the UCI Repository Of Machine Learning Databases
    from the following URLs:'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些数据是从以下URL的UCI机器学习数据库仓库中获取的：
- en: ftp://ftp.ics.uci.edu/pub/machine-learning-databases
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ftp://ftp.ics.uci.edu/pub/machine-learning-databases
- en: http://www.ics.uci.edu/~mlearn/MLRepository.html
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: http://www.ics.uci.edu/~mlearn/MLRepository.html
- en: It was converted to the R format by Friedrich Leisch.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它被Friedrich Leisch转换成了R格式。
- en: 'Train a logistic regression model with the `df` DataFrame object:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`df` DataFrame对象训练一个逻辑回归模型：
- en: '[PRE1]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define the API endpoint as a function with the additional `#'' @get /` construct:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用额外的`#' @get /`构造定义API端点为一个函数：
- en: '[PRE2]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Within the function, convert the parameters into `numeric` values using the
    `as.numeric` command:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在函数内部，使用`as.numeric`命令将参数转换为`numeric`值：
- en: '[PRE3]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, create a DataFrame with the same column names as we did in the previous
    step:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，创建一个与上一步相同的列名的DataFrame：
- en: '[PRE4]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Use the newly created `sample` DataFrame to make predictions on the trained
    model:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用新创建的`sample` DataFrame对训练好的模型进行预测：
- en: '[PRE5]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Package the result as a `list` for the function''s return call and complete/close
    the function definition with `}` parentheses:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果打包为一个`list`作为函数的返回调用，并使用`}`括号完成/关闭函数定义：
- en: '[PRE6]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The previous exercise demonstrates regular R model code with one additional
    construct. The model we developed is rather a simple one with only three independent
    variables and one dependent variable (unlike the eight independent variables we
    saw in *Chapter 7*, *Model Improvements)*. We also created a function that will
    accept three input parameters, each representing one independent variable for
    the model. This function will be used as the endpoint when we deploy the model
    as a REST API. We added one additional construct just before the function (refer
    to the fourth step of the previous exercise):'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之前的练习演示了带有额外结构的常规R模型代码。我们开发的模型相当简单，只有三个自变量和一个因变量（与我们在*第7章*，*模型改进*中看到的八个自变量不同）。我们还创建了一个函数，该函数将接受三个输入参数，每个参数代表模型的一个自变量。当我们将模型作为REST
    API部署时，这个函数将被用作端点。我们在函数之前添加了一个额外的结构（参考之前练习的第四步）：
- en: '[PRE7]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This construct defines that the `predict_data` endpoint will be serving the
    GET requests. The function we defined for this endpoint accepts three parameters
    with no default values. Let's now install the `plumber` package and make a call
    using the web server.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此结构定义了`predict_data`端点将服务GET请求。我们为该端点定义的函数接受三个参数，没有默认值。现在让我们安装`plumber`包，并使用web服务器进行调用。
- en: 'The final complete `model.R` file should look like this:'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终完整的`model.R`文件应如下所示：
- en: '[PRE8]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can also refer to the GitHub URL: https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson08/Docker/model.R.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以参考GitHub URL：https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson08/Docker/model.R。
- en: 'Create another R script called `main.R`. Now, install the `plumber` package
    and load it into memory, and then deploy the R function using the `plumb` function,
    as illustrated here:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建另一个名为`main.R`的R脚本。现在，安装`plumber`包并将其加载到内存中，然后使用`plumb`函数部署R函数，如图所示：
- en: '[PRE9]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Use the following command to pass the R file to the `plumb` function:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将R文件传递给`plumb`函数：
- en: '[PRE10]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After executing the previous code, the plumber library creates a web server
    within your `localhost` and responds to the requests. To test whether the endpoint
    functions we wrote are functioning in the expected way, we will invoke the endpoint
    from the browser.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行上一段代码后，Plumber库会在你的`localhost`上创建一个web服务器并响应请求。为了测试我们编写的端点是否按预期工作，我们将从浏览器中调用该端点。
- en: Note
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE11]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The parameters are passed to the endpoint after the `?` symbol, and multiple
    parameters are separated by the `&` symbol.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参数在`?`符号之后传递给端点，多个参数由`&`符号分隔。
- en: 'Since we deployed the endpoint to localhost, that is, `127.0.0.1` on the `8080`
    port, we will have the following API definition for the endpoint. Invoke the API
    using the browser:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们将端点部署到了localhost，即`127.0.0.1`的`8080`端口，我们将为该端点有以下API定义。使用浏览器调用API：
- en: '[PRE12]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Execute the previous API definition, which will return the following prediction
    value:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行之前的API定义，将返回以下预测值：
- en: '[PRE13]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To test the APIs, we can use a better tool, such as Postman, instead of the
    browser. Postman (https://www.getpostman.com/) is currently one of the most popular
    tools used in API testing. It is available for free on the Windows, Mac, and Linux
    platforms. Using Postman is relatively simple and doesn't include any new learning.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了测试API，我们可以使用更好的工具，例如Postman，而不是浏览器。Postman（https://www.getpostman.com/）是目前在API测试中最受欢迎的工具之一。它在Windows、Mac和Linux平台上免费提供。使用Postman相对简单，不涉及任何新的学习。
- en: Note
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: In case you would like to explore additional details about Postman, you can
    explore the learning resources provided at https://learning.getpostman.com/docs/postman/launching_postman/installation_and_updates/.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你想要探索关于Postman的更多细节，你可以查看在https://learning.getpostman.com/docs/postman/launching_postman/installation_and_updates/提供的资源。
- en: 'After you download and install Postman for your system, you can test the API
    endpoint by pasting it in the input window, as shown in the following screenshot:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装Postman到你的系统后，你可以通过粘贴到输入窗口来测试API端点，如下面的截图所示：
- en: '![Figure 8.1: Plumber UI'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.1：Plumber UI'
- en: '](img/C12624_08_01.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_08_01.jpg)'
- en: 'Figure 8.1: Plumber UI'
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.1：Plumber UI
- en: We can execute the API by clicking on the **Send** button, and the results are
    displayed in the highlighted area of the previous screenshot. Observing the output
    from Postman, we can see that our machine learning model has been deployed successfully
    as an API endpoint.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过点击**发送**按钮来执行API，结果将显示在上一张截图的高亮区域。通过观察Postman的输出，我们可以看到我们的机器学习模型已成功部署为API端点。
- en: Challenges in Deploying Models with plumber
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用plumber部署模型的挑战
- en: 'We can see that deploying the model as an API using plumber is simple and can
    be done easily with a few additional lines of code. The `plumber` package provides
    additional features that we have not explored in this exercise. Some important
    topics that might be interesting to explore are as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，使用plumber将模型部署为API非常简单，只需添加几行额外的代码即可轻松完成。`plumber`包提供了我们在本次练习中未探索的额外功能。以下是一些可能感兴趣的重要主题：
- en: '**Filters**: Filters can be used to define a *pipeline* with a flow of incoming
    requests. This functionality helps to further modularize the deployment logic
    and workflow. You can read more at https://www.rplumber.io/docs/routing-and-input.html#filters.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤器**：可以使用过滤器定义一个带有请求流量的*管道*。此功能有助于进一步模块化部署逻辑和工作流程。您可以在https://www.rplumber.io/docs/routing-and-input.html#filters了解更多信息。'
- en: '**Error handling**: With larger applications, the code base and the complexity
    of applications increase exponentially. It becomes increasingly important to add
    exception handlers and ease the process of debugging applications. You can read
    more about it at https://www.rplumber.io/docs/rendering-and-output.html#error-handling.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误处理**：随着应用程序规模的扩大，代码库和应用程序的复杂性呈指数级增长。添加异常处理程序并简化应用程序的调试过程变得越来越重要。您可以在https://www.rplumber.io/docs/rendering-and-output.html#error-handling了解更多信息。'
- en: These methods have a major drawback. While it is relatively easy to set up an
    endpoint in a single host, there might be issues faced when deploying the same
    solution on a different system. These issues might arise due to the difference
    in the system architecture, software version, operating system, and so on. To
    mitigate the conflicts that you may face when deploying the endpoint, one technique
    is to make the process environment-agnostic, that is, a solution developed in
    one host system can be deployed without any issues in any other host with a different
    architecture, platform, or operating system. This can be achieved using **Docker
    containers** along with plumber for deployment instead of directly using plumber.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法有一个主要的缺点。虽然在一个单一的主机上设置端点相对容易，但在不同的系统上部署相同的解决方案时可能会遇到问题。这些问题可能由于系统架构、软件版本、操作系统等方面的差异而产生。为了减轻在部署端点时可能遇到的冲突，一种技术是使过程与环境无关，也就是说，在一个主机系统上开发的解决方案可以在任何具有不同架构、平台或操作系统的其他主机上无任何问题地部署。这可以通过使用**Docker容器**和plumber进行部署来实现，而不是直接使用plumber。
- en: A Brief History of the Pre-Docker Era
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预Docker时代的简史
- en: Before diving deep into the Docker tool, let's understand some background and
    history.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨Docker工具之前，让我们了解一些背景和历史。
- en: The challenge of deploying an application in an environment-agnostic framework
    was achieved earlier using virtualization, that is, the entire application, dependencies,
    libraries, necessary frameworks, and the operating system itself was virtualized
    and packaged as a solution that could be deployed on a host. Multiple virtual
    environments could run on an infrastructure (called a **hypervisor**), and applications
    became environment-agnostic. However, this approach has a major trade-off. Packaging
    the entire operating system into the **virtual machine** (**VM**) of an application
    made the package heavy and often resulted in wasting memory and computing resources.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在环境无关的框架中部署应用程序的挑战之前是通过虚拟化实现的，也就是说，整个应用程序、依赖项、库、必要的框架以及操作系统本身都被虚拟化并打包成一个可以在主机上部署的解决方案。多个虚拟环境可以在基础设施（称为**虚拟机管理程序**）上运行，应用程序变得与环境无关。然而，这种方法有一个主要的权衡。将整个操作系统打包到应用程序的**虚拟机**（**VM**）中使得包变得很重，通常会导致内存和计算资源的浪费。
- en: 'A more intuitive approach to this problem was to exclude the operating system
    from the package and only include the application-related libraries and dependencies.
    Additionally, enable a mechanism such that the package becomes infrastructure-agnostic,
    keeping the app lightweight. This is when Docker was introduced. The following
    visual sheds light on the high-level view of how Docker was improvised to solve
    problems previously solved by virtual machines:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的更直观的方法是排除操作系统包，只包含与应用程序相关的库和依赖项。此外，启用一种机制，使包成为基础设施无关的，保持应用程序轻量。这就是Docker被引入的时候。以下视觉图展示了Docker是如何被改进来解决以前由虚拟机解决的问题：
- en: '![Figure 8.2: The architectural difference between a virtual machine and a
    Docker container'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2：虚拟机和Docker容器之间的架构差异'
- en: '](img/C12624_08_02.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/C12624_08_02.jpg]'
- en: 'Figure 8.2: The architectural difference between a virtual machine and a Docker
    container'
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.2：虚拟机和Docker容器之间的架构差异
- en: Let's now understand Docker containers in more detail.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在更详细地了解Docker容器。
- en: Docker
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker
- en: Docker is a simple tool that eases the process of developing, deploying, and
    executing software applications using containers. A **container** is analogous
    to a shipping industry container, and allows a developer to package an entire
    application with its dependencies, and ship it all out as one package. Once built
    on a system, the package will work on any other system as well, regardless of
    the differences in the infrastructure.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Docker是一个简单的工具，它简化了使用容器开发、部署和执行软件应用程序的过程。**容器**类似于航运行业的集装箱，允许开发者将整个应用程序及其依赖项打包，并作为一个包发送出去。一旦在一个系统上构建，这个包就可以在任何其他系统上工作，无论基础设施有何差异。
- en: With Docker, we can create a single document (called a **Dockerfile**) that
    defines a simplified step for setting up the required environment for the application.
    The Dockerfile is then used to build a **Docker image**. A container is an instance
    of a Docker image. For the same application, we might sometimes have multiple
    containers that will help in load balancing for high-traffic applications.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker，我们可以创建一个单独的文档（称为**Dockerfile**），它定义了设置应用程序所需环境的简化步骤。然后使用Dockerfile构建**Docker镜像**。容器是Docker镜像的一个实例。对于同一个应用程序，我们有时可能会有多个容器，这有助于高流量应用程序的负载均衡。
- en: Deploying the ML Model Using Docker and plumber
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Docker和plumber部署ML模型
- en: We will leverage the same plumber application with Docker for environment- and
    infrastructure-agnostic deployment. First, we will need to download and install
    Docker on our system. It's free and easy. Create an account and download Docker
    for your system from https://www.docker.com/get-started. Once installed, you can
    verify whether Docker is running by executing the `docker` command in the terminal
    or Windows PowerShell.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用相同的plumber应用程序，通过Docker进行环境无关和基础设施无关的部署。首先，我们需要在我们的系统上下载并安装Docker。它是免费且易于使用的。从https://www.docker.com/get-started创建一个账户并下载适合您系统的Docker。安装完成后，您可以通过在终端或Windows
    PowerShell中执行`docker`命令来验证Docker是否正在运行。
- en: 'Exercise 99: Create a Docker Container for the R plumber Application'
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习99：为R plumber应用程序创建一个Docker容器
- en: In this exercise, we will extend the previously created plumber application
    as a Docker container. In order to develop environment-agnostic models that can
    be deployed to any production system without any issues, we can deploy a plumber
    app using Docker containers. These containers can then be deployed on any other
    machine that supports Docker Engine.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将扩展之前创建的plumber应用程序作为Docker容器。为了开发可以在任何生产系统上部署且无任何问题的环境无关模型，我们可以使用Docker容器部署plumber应用程序。这些容器然后可以部署在支持Docker
    Engine的任何其他机器上。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: 'Define a Dockerfile, as illustrated here:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个Dockerfile，如下所示：
- en: '[PRE14]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, install the libraries for the `plumber` package using the following command:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令安装`plumber`包的库：
- en: '[PRE15]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, install the `plumber` package, as shown:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，按照以下所示安装`plumber`包：
- en: '[PRE16]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, use the following command to copy all files from the current directory
    into the current folder for the container. This will copy our `model.R` and `plumber.R`
    file into a container:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令将当前目录中的所有文件复制到容器的当前文件夹中。这将把我们的`model.R`和`plumber.R`文件复制到容器中：
- en: '[PRE17]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, define a port to be exposed where the container will be deployed:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义一个要公开的端口，容器将部署在该端口上：
- en: '[PRE18]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Define the first script to run when the container starts after the build:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义在构建后容器启动时运行的第一个脚本：
- en: '[PRE19]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We now have three files in our project folder, as shown in the following diagram.
    Note that the Dockerfile is a simple text file with no extensions. On running
    a `build` command from the terminal within this folder, **Docker Engine** searches
    for the Dockerfile and prepares the environment based on the instructions provided
    within the document:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在在项目文件夹中有三个文件，如下所示图所示。请注意，Dockerfile是一个没有扩展名的简单文本文件。在文件夹内从终端运行`build`命令时，**Docker引擎**会查找Dockerfile并根据文档中提供的说明准备环境：
- en: '![Figure 8.3: Project files'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图8.3：项目文件]'
- en: '](img/C12624_08_03.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图8.3：项目文件](img/C12624_08_03.jpg)'
- en: 'Figure 8.3: Project files'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.3：项目文件
- en: 'The final Dockerfile with all the commands, as defined in the previous steps,
    will look like this:'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终的Dockerfile，其中包含之前步骤中定义的所有命令，将看起来像这样：
- en: '[PRE20]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can now build the Docker image from the Dockerfile using the `docker build`
    command, as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用`docker build`命令从Dockerfile构建Docker镜像，如下所示：
- en: '[PRE21]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `.` after the `r_ml_demo` indicates that the Dockerfile is present in the
    current folder. The build process takes a while as it creates the container image
    with all the necessary dependencies. Once the image is built, we can run the Docker
    image using the following command by mapping the machine's `8080` port to the
    container's published `8080` port.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`r_ml_demo`后面的`.`表示Dockerfile位于当前文件夹中。构建过程需要一段时间，因为它会创建包含所有必要依赖项的容器镜像。一旦镜像构建完成，我们可以使用以下命令运行Docker镜像，通过将机器的`8080`端口映射到容器的已发布`8080`端口。'
- en: 'Run the Docker image using the following command:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行Docker镜像：
- en: '[PRE22]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can refer to the complete code from GitHub at https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/tree/master/Lesson08/Docker.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以从GitHub上的完整代码获取更多信息：https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/tree/master/Lesson08/Docker。
- en: The container can be tested again in the same way we tested our plumber application
    using Postman, and we will get exactly the same result. We can, therefore, deploy
    an R application using plumber and Docker on any other system, regardless of the
    operating system and missing libraries.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 容器可以像我们使用Postman测试plumber应用程序一样再次进行测试，我们将得到完全相同的结果。因此，我们可以使用plumber和Docker在任何其他系统上部署R应用程序，无论操作系统如何，也不管缺少哪些库。
- en: Note
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Docker cannot be installed on Windows Home edition. Only Windows Pro editions
    support Hypervisor.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Docker不能安装在Windows家庭版上。只有Windows专业版支持虚拟机管理程序。
- en: Disadvantages of Using plumber to Deploy R Models
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用plumber部署R模型的缺点
- en: While this process comes with a few advantages of easy and fast implementation,
    it also comes with some disadvantages. The major disadvantage of plumber is scaling
    the application endpoint for large complex use cases. The scale here refers to
    the number of times the endpoint is invoked as well as the amount of data that
    can be invoked through the endpoint.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个过程带来了一些易于快速实施的优点，但也存在一些缺点。plumber的主要缺点是针对大型复杂用例扩展应用程序端点。这里的扩展指的是端点被调用的次数以及可以通过端点调用的数据量。
- en: One of the major drawbacks of using plumber is that it doesn't directly support
    passing JSON objects or arrays or lists to the endpoint. This becomes a bottleneck
    when we are dealing with bigger models with more than 20 independent variables.
    The previous use case, in *Exercise 2*, *Create a Docker Container for the R Plumber
    Application*, was a fairly small and lightweight model with three independent
    variables. Therefore, the API definition was short and sweet. However, as the
    number of parameters increases (which is definitely bound to happen for real production
    models), plumber model endpoint definitions will not be the best ones to use.
    Also, the plumber framework is not ideal for large complex software use cases.
    The small community around the framework, lack of proper documentation, and limited
    support makes it a risky choice for deploying a model into a large scale machine
    learning product or service.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用plumber的一个主要缺点是它不支持直接传递JSON对象或数组或列表到端点。当我们处理具有20个以上独立变量的较大模型时，这成为一个瓶颈。在*练习2*，*为R
    Plumber应用程序创建Docker容器*中的先前用例是一个相当小且轻量级的模型，具有三个独立变量。因此，API定义既简短又甜蜜。然而，随着参数数量的增加（这对于真正的生产模型来说肯定会发生），plumber模型端点定义可能不是最佳选择。此外，plumber框架对于大型复杂软件用例来说也不理想。围绕该框架的小型社区、缺乏适当的文档和有限的支持使其成为将模型部署到大规模机器学习产品或服务中的风险选择。
- en: Let's take a look at leveraging cloud services for deploying R ML models.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何利用云服务来部署 R ML 模型。
- en: Amazon Web Services
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Web Services
- en: '**Amazon Web Services** (**AWS**) is the leading provider of cloud services.
    With the advent of the cloud, the tech industry has seen a dramatic shift in the
    process of building large-scale enterprise applications leveraging cloud services
    rather than self-hosted services. Other prominent players in the cloud services
    market are Microsoft, Google, and IBM. While all leading cloud providers have
    an exhaustive suite of services to build all kinds of software applications, we
    will focus only on AWS for the scope of this chapter. You are highly encouraged
    to explore alternative services for similar use cases from other cloud providers
    (not restricted to Google or Microsoft).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Web Services** (**AWS**) 是领先的云服务提供商。随着云的出现，技术行业在构建大型规模企业应用程序的过程中经历了巨大的转变，从使用云服务而不是自托管服务。云服务市场的其他主要参与者包括微软、谷歌和
    IBM。虽然所有领先的云服务提供商都有一套详尽的服务来构建各种软件应用程序，但我们将仅关注 AWS，范围限于本章。我们强烈鼓励您探索其他云服务提供商提供的类似用例的替代服务（不仅限于谷歌或微软）。'
- en: AWS has a ton of services readily available that can be used to make large,
    complex enterprise applications of any scale with no upfront commitments. You
    pay as you go, and there are also a large number of services that you can explore
    and test for free for one year (with certain limits). For the scope of the set
    of experiments we will perform in the upcoming exercises, the free tier should
    suffice. In case you do not already have an AWS account, create one at https://aws.amazon.com/free/activate-your-free-tier-account/.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 提供了大量现成的服务，可以用来构建任何规模的大型、复杂企业应用程序，无需任何前期承诺。您按使用付费，还有大量服务您可以免费探索和测试一年（有一定限制）。对于我们在即将进行的实验中将要执行的实验范围，免费层应该足够了。如果您还没有
    AWS 账户，请在此处创建一个：https://aws.amazon.com/free/activate-your-free-tier-account/。
- en: You will need a valid credit/debit card for the signup process. We will only
    leverage the free tier service from AWS for the exercises.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 您在注册过程中需要一个有效的信用卡或借记卡。我们将仅利用 AWS 的免费层服务进行练习。
- en: There are several approaches that we could take to deploy a machine learning
    model using cloud services. Some may be well-suited for small applications, some
    for medium-sized and moderately complex applications, and others for large and
    very complex applications. We will explore the approach that has the least amount
    of software engineering yet provides effective flexibility and can easily scale
    into large-scale applications while easily integrating into complex applications.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采取几种方法来使用云服务部署机器学习模型。有些可能非常适合小型应用程序，有些适合中等规模和复杂程度适中的应用程序，而其他一些则适合大型和非常复杂的应用程序。我们将探索那种软件工程量最少，但提供有效灵活性，并且可以轻松扩展到大规模应用程序，同时易于集成到复杂应用程序中的方法。
- en: The use of an API and delivering the machine learning model as an API makes
    the entire process of integrating the service into other applications fairly straightforward.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 API 并将机器学习模型作为 API 提供使得将服务集成到其他应用程序中的整个过程相当直接。
- en: Introducing AWS SageMaker
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍 AWS SageMaker
- en: '**Amazon SageMaker** is a cloud service that provides developers and data scientists
    with a platform to build, train, and deploy machine learning models quickly. It
    is an extremely effective service in aiding data scientists with limited development
    knowledge to deploy highly scalable ML models while abstracting the entire complexities
    of the infrastructure and underlying services.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker** 是一种云服务，为开发人员和数据科学家提供了一个平台，可以快速构建、训练和部署机器学习模型。它是一种极其有效的服务，可以帮助那些开发知识有限的数据科学家部署高度可扩展的
    ML 模型，同时抽象出整个基础设施和底层服务的复杂性。'
- en: SageMaker automates the entire process of deploying a model as an API with the
    defined resources and creates an *endpoint* that can be used for inferencing within
    the other AWS services. To enable the endpoint to be inferenced by other external
    applications, we would need to orchestrate the flow of requests using two other
    AWS services, called **AWS API Gateway** and **AWS Lambda**. We will explore these
    new services later in the chapter.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 自动将模型作为 API 部署，并使用定义的资源创建一个可用于在其他 AWS 服务中进行推理的 *端点*。为了使端点能够被其他外部应用程序进行推理，我们需要使用另外两个
    AWS 服务来编排请求流，这两个服务被称为 **AWS API Gateway** 和 **AWS Lambda**。我们将在本章后面探索这些新服务。
- en: Now, let's begin deploying our model using AWS SageMaker.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始使用 AWS SageMaker 部署我们的模型。
- en: Deploying an ML Model Endpoint Using SageMaker
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 SageMaker 部署 ML 模型端点
- en: SageMaker, by default, doesn't provide a direct way to create R models, but
    there is an easy alternative provided by Amazon. AWS provides the functionality
    of **Infrastructure as Code** with **AWS CloudFormation**, that is, a service
    where we can codify the entire flow of provisioning and the setup of infrastructure
    resources for a project. With CloudFormation templates, we can automate the process
    of provisioning a tech stack as per our needs and reuse it any number of times.
    Amazon has provided a lucid and elaborate guide to get started with R notebooks
    on SageMaker using the CloudFormation template.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，SageMaker 不提供直接创建 R 模型的途径，但 Amazon 提供了一个简单的替代方案。AWS 通过 **AWS CloudFormation**
    提供了 **基础设施即代码** 的功能，即一个服务，我们可以将项目的基础设施资源配置和设置整个流程编码化。使用 CloudFormation 模板，我们可以根据我们的需求自动化技术栈的配置过程，并且可以多次重用它。Amazon
    提供了一份清晰且详尽的指南，指导您使用 CloudFormation 模板在 SageMaker 上开始使用 R 笔记本。
- en: To find out more, you can refer to the guide at https://aws.amazon.com/blogs/machine-learning/using-r-with-amazon-sagemaker/
    for a detailed understanding of the process.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多信息，您可以参考 https://aws.amazon.com/blogs/machine-learning/using-r-with-amazon-sagemaker/
    上的指南，以详细了解该过程。
- en: 'Exercise 100: Deploy the ML Model as a SageMaker Endpoint'
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 100：将 ML 模型作为 SageMaker 端点部署
- en: In this exercise, we will deploy an ML model as a SageMaker endpoint.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将部署一个 ML 模型作为 SageMaker 端点。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Log in to your AWS account and launch the CloudFormation script to create an
    R notebook.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录您的 AWS 账户并启动 CloudFormation 脚本来创建一个 R 笔记本。
- en: Now, access the CloudFormation template from https://amzn.to/2ZzUM28 to create
    the R Notebook on SageMaker.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，从 https://amzn.to/2ZzUM28 访问 CloudFormation 模板以在 SageMaker 上创建 R 笔记本。
- en: Next, we will create and launch the stack in AWS using the previous CloudFormation
    template.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将使用之前的 CloudFormation 模板在 AWS 中创建和启动堆栈。
- en: 'Click on the template; it directly navigates you to the CloudFormation service,
    as shown in the following screenshot. The cloud formation template (which is a
    YAML file) is hosted in a public S3 bucket and has already been added to the input
    box under **Specify an Amazon S3 template URL**. Click on the **Next** button
    and navigate to the **Details** page:![Figure 8.4: CloudFormation—Create Stack
    page'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击模板；它将直接导航到 CloudFormation 服务，如下面的截图所示。云配置模板（这是一个 YAML 文件）托管在公共 S3 存储桶中，并且已经添加到
    **指定 Amazon S3 模板 URL** 下的输入框中。点击 **下一步** 按钮并导航到 **详细信息** 页面：![图 8.4：CloudFormation—创建堆栈页面
- en: '](img/C12624_08_04.jpg)'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/C12624_08_04.jpg]'
- en: 'Figure 8.4: CloudFormation—Create Stack page'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.4：CloudFormation—创建堆栈页面
- en: 'On the next page, specify the SSH key pair that you will use to log in to the
    EC2 instance. This is a secure way to access the cloud instance or virtual machine
    that we provision in the cloud. If you do not have a key already created for your
    account, you can create one using the steps provided on the Amazon website: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，指定您将用于登录 EC2 实例的 SSH 密钥对。这是访问我们在云中配置的云实例或虚拟机的一种安全方式。如果您尚未为您的账户创建密钥，您可以使用
    Amazon 网站上提供的步骤创建一个：https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair。
- en: 'Once the key pair is created or if you already have a pair, it will appear
    in the dropdown in the highlighted box, as shown in the following screenshot.
    Select your key pair and click on the **Next** button:![Figure 8.5: Creating a
    key pair'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦创建密钥对或如果您已经有了密钥对，它将出现在高亮框中的下拉菜单中，如下面的截图所示。选择您的密钥对并点击 **下一步** 按钮：![图 8.5：创建密钥对
- en: '](img/C12624_08_05.jpg)'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/C12624_08_05.jpg]'
- en: 'Figure 8.5: Creating a key pair'
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.5：创建密钥对
- en: On the next **Option** page, we can directly click on the **Next** button and
    navigate to the next page.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页 **选项** 页面上，我们可以直接点击 **下一步** 按钮并导航到下一页。
- en: Lastly, on the review page, select the **I acknowledge that AWS CloudFormation
    might create IAM resources with custom names** checkbox and click on the **Next**
    button.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在审查页面上，选中 **我承认 AWS CloudFormation 可能会创建具有自定义名称的 IAM 资源** 复选框，然后点击 **下一步**
    按钮。
- en: 'The process will create the stack (it might take a while to show on the screen—refresh
    the screen after 1-2 minutes). Once created, you will see the stack ready under
    CloudFormation, as shown in the following screenshot. The output tabs will have
    the SSH command to be used to log in; copy the value in the highlighted section
    and run the command in a terminal or Command Prompt:![Figure 8.6: Stacks—SSH key'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此过程将创建堆栈（它可能需要一段时间才能在屏幕上显示——1-2分钟后刷新屏幕）。一旦创建，您将在CloudFormation下看到堆栈已准备好，如图所示。输出选项卡将包含用于登录的SSH命令；复制高亮部分中的值，然后在终端或命令提示符中运行该命令：![图8.6：堆栈—SSH密钥
- en: '](img/C12624_08_06.jpg)'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 C12624_08_06.jpg]'
- en: 'Figure 8.6: Stacks—SSH key'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.6：堆栈—SSH密钥
- en: 'On running the SSH command from the terminal, it forwards port `8787` to your
    computer while connecting to the new instance. Once connected, open a browser
    window and type `https://127.0.0.1:8787` in the address bar to open the RStudio
    login page. The default username and password is set to `rstudio`. Enter the username
    and password and click on the **Sign In** button:![Figure 8.7: RStudio—Sign In
    page'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端运行SSH命令时，它将端口`8787`转发到您的计算机，同时连接到新实例。一旦连接，打开浏览器窗口并在地址栏中输入`https://127.0.0.1:8787`以打开RStudio登录页面。默认用户名和密码设置为`rstudio`。输入用户名和密码，然后点击**登录**按钮：![图8.7：RStudio—登录页面
- en: '](img/C12624_08_07.jpg)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 C12624_08_07.jpg]'
- en: 'Figure 8.7: RStudio—Sign In page'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.7：RStudio—登录页面
- en: 'Log in to RStudio and create a new R script with any name, say `Sagemaker.R`,
    load the necessary libraries, and get the SageMaker session ready:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到RStudio并创建一个名为`Sagemaker.R`的新R脚本，加载必要的库，并准备好SageMaker会话：
- en: '[PRE23]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Start the SageMaker session and define the default bucket as well as the role
    to be used for the session:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动SageMaker会话并定义会话中使用的默认存储桶以及角色：
- en: '[PRE24]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Install the `mlbench` package and load the data for our use case. In the following
    command, we''ll first set the `seed` for reproducibility:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`mlbench`包并加载数据用于我们的用例。在以下命令中，我们首先设置`seed`以确保可重复性：
- en: '[PRE25]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To explore SageMaker''s automated hyperparameter tuning, we will be developing
    an XGBoost model instead of a logistic regression model on the same use case as
    the previous one. Therefore, we need the target variable and all the independent
    variables in a numeric type. Also, SageMaker expects the data in a form where
    the first column is the target variable:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要探索SageMaker的自动超参数调整，我们将开发一个XGBoost模型，而不是在之前用例上的逻辑回归模型。因此，我们需要目标变量和所有独立变量都是数值类型的。此外，SageMaker期望数据以第一列为目标变量的形式：
- en: '[PRE26]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Place the target variable as the first column in the dataset:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目标变量放在数据集的第一列：
- en: '[PRE27]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Create 70% train and 30% test datasets using the following command:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建70%的培训和30%的测试数据集：
- en: '[PRE28]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Write the train and test data created from the `df` DataFrame into memory and
    upload the CSV files into an S3 bucket on AWS. The session has been defined with
    a default bucket, therefore, we can directly use the `upload_data` command with
    the path and the required constructs to upload the dataset on our default S3 bucket:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将从`df`数据框创建的培训和测试数据写入内存，并将CSV文件上传到AWS上的S3存储桶。由于会话已定义了默认存储桶，因此我们可以直接使用`upload_data`命令和路径以及所需的构造来上传数据集到我们的默认S3存储桶：
- en: '[PRE29]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Define the train and test dataset (validation data) for the SageMaker session:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义SageMaker会话的培训和测试数据集（验证数据）：
- en: '[PRE30]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: SageMaker provides AWS optimized pre-configured containers that can be leveraged
    directly for model training. We would need to choose a container base from the
    same region that our resources are hosted in. In this case, it is **us-east-1**.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SageMaker提供了AWS优化的预配置容器，可以直接用于模型训练。我们需要从与我们的资源托管在同一区域的容器基础中选择一个。在这种情况下，是**us-east-1**。
- en: 'Define the container for the estimator and the output folder in S3:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义估计器的容器和S3中的输出文件夹：
- en: '[PRE31]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Select the container for the estimator using the following command:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令选择用于估计器的容器：
- en: '[PRE32]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Define the output folder as illustrated here:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输出文件夹，如图所示：
- en: '[PRE33]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Define the SageMaker estimator, the job, and the input data. Here, we would
    need to provide the type of instance that we would like to use for the model training
    process, and we will choose `ml.m5.large`:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义SageMaker估计器、作业和输入数据。在这里，我们需要提供我们希望用于模型训练过程的实例类型，我们将选择`ml.m5.large`：
- en: '[PRE34]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Set the hyperparameters of interest for the model and define the training and
    validation datasets for the model as a list:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置模型感兴趣的超参数，并将培训和验证数据集定义为列表：
- en: '[PRE35]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can read more about the different types of instances that can be used for
    the purpose of model training at https://aws.amazon.com/sagemaker/pricing/instance-types/.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在https://aws.amazon.com/sagemaker/pricing/instance-types/上了解更多关于可用于模型训练的不同类型实例的信息。
- en: 'Train/fit the model we defined. The model training process will take a while
    (~10-12 minutes). In the background, SageMaker will provision an instance that
    was defined by us in the model definition, trigger the necessary background operations
    to orchestrate the training process, and finally, train the model:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练/拟合我们定义的模型。模型训练过程将花费一些时间（约10-12分钟）。在后台，SageMaker将提供我们在模型定义中定义的实例，触发必要的后台操作以编排训练过程，并最终训练模型：
- en: '[PRE36]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Deploy the train model as an endpoint. We will have to, again, provide the
    type of instance we would want SageMaker to provision for the model inference.
    Since this is just a sample model, we can choose the instance with the lowest
    configuration. This process will also take some time, as SageMaker will orchestrate
    a series of services in the background to deploy the model as an endpoint:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练模型部署为端点。我们再次需要提供我们希望SageMaker为模型推理提供的实例类型。由于这是一个示例模型，我们可以选择配置最低的实例。这个过程也将花费一些时间，因为SageMaker将在后台编排一系列服务以将模型作为端点部署：
- en: '[PRE37]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: After the model endpoint is created, we can test it by invoking it with the
    right form of test data. Since we are saving the test data as CSV files, we will
    pass comma-separated text to be serialized into JSON format. Therefore, we specify
    `text/csv` and `csv_serializer` for the endpoint. Let's prepare a sample test
    data feed for a quick test.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型端点创建后，我们可以通过使用正确的测试数据形式来测试它。由于我们将测试数据保存为CSV文件，因此我们将传递以逗号分隔的文本以序列化为JSON格式。因此，我们为端点指定`text/csv`和`csv_serializer`。让我们准备一个用于快速测试的样本测试数据馈送。
- en: 'First, make a copy of the test dataset using the following command:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用以下命令复制测试数据集：
- en: '[PRE38]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Next, delete the target variable:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，删除目标变量：
- en: '[PRE39]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create a single test sample using the following command:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建单个测试样本：
- en: '[PRE40]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, delete the column names:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，删除列名：
- en: '[PRE41]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Make a prediction using the model endpoint on the sample data that we created
    in the previous step. Invoke the SageMaker endpoint and pass the test data:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在上一步创建的样本数据，通过模型端点进行预测。调用SageMaker端点并传递测试数据：
- en: '[PRE42]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now, print the result using the `print` command:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`print`命令打印结果：
- en: '[PRE43]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output is as follows:'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE44]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This output helps us to understand that the model has been correctly deployed
    and is functioning as expected. We can check whether the endpoint is created by
    navigating to the SageMaker service in the AWS account and opening the *Endpoint*
    section from the right-hand-side sidebar:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出有助于我们了解模型已正确部署并按预期运行。我们可以通过导航到AWS账户中的SageMaker服务并从右侧侧边栏打开*端点*部分来检查端点是否已创建：
- en: '![Figure 8.8: Endpoint page'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.8：端点页面'
- en: '](img/C12624_08_08.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_08_08.jpg)'
- en: 'Figure 8.8: Endpoint page'
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.8：端点页面
- en: This endpoint can be used directly by other services within AWS to invoke and
    get predictions. The only requirement is that the input data should be provided
    as expected. To enable our model endpoint to be accessible by other services outside
    AWS, we would need to orchestrate the API request using AWS API Gateway and AWS
    Lambda.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 此端点可以直接由AWS内的其他服务调用并获取预测。唯一的要求是输入数据应按预期提供。为了使我们的模型端点可由AWS外的其他服务访问，我们需要使用AWS
    API Gateway和AWS Lambda编排API请求。
- en: Note
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can access the complete code file on GitHub at https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson08/RStudio_SageMaker.R.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上访问完整的代码文件，网址为https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson08/RStudio_SageMaker.R。
- en: Now, let's study these services a bit before delving into the solution.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们深入研究解决方案之前，让我们研究一下这些服务。
- en: What is Amazon Lambda?
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊Lambda是什么？
- en: '**AWS Lambda** is an event-driven, serverless computing platform provided by
    Amazon as a part of Amazon Web Services. It is a computing service that runs code
    in response to events and automatically manages the computing resources required
    by that code. The service enables us to develop serverless applications. The term
    serverless indicates that we do not actually need to manage and provision the
    infrastructure resources; instead, they are managed by the cloud service provider,
    and we only pay for what we use, say, pay per event or execution. AWS Lambda can
    be configured to execute a defined function in response to a specific event, say,
    when someone uploads a new file to a defined S3 bucket or invokes another function
    or another service in AWS.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '**AWS Lambda** 是亚马逊作为 Amazon Web Services 的一部分提供的一个事件驱动的无服务器计算平台。它是一种响应事件运行代码的计算服务，并自动管理该代码所需的计算资源。该服务使我们能够开发无服务器应用程序。术语无服务器表示我们实际上不需要管理和配置基础设施资源；相反，它们由云服务提供商管理，我们只需为使用的资源付费，例如按事件或执行付费。AWS
    Lambda 可以配置为在响应特定事件时执行定义的函数，例如，当有人将新文件上传到定义的 S3 桶或调用 AWS 中的另一个函数或另一个服务时。'
- en: What is Amazon API Gateway?
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 Amazon API Gateway？
- en: '**Amazon API Gateway** is a fully managed service that makes it easy for developers
    to create, publish, maintain, monitor, and secure APIs at any scale. With this
    service, we can develop REST as well as WebSocket APIs that act as a *front door*
    for applications to access data, business logic, or functionality from other backend
    services, while protecting the backend services within the private network. These
    backend services could be any applications that are running on AWS.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon API Gateway** 是一个全面管理的服务，它使开发者能够轻松地在任何规模上创建、发布、维护、监控和保障 API。使用此服务，我们可以开发
    REST 以及 WebSocket API，这些 API 作为应用程序访问来自其他后端服务的数据、业务逻辑或功能的“前门”。同时，它还保护了私有网络内的后端服务。这些后端服务可以是运行在
    AWS 上的任何应用程序。'
- en: 'The overall flow of our service can be represented as in the following diagram:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们服务的整体流程可以用以下图表表示：
- en: '![Figure 8.9: Workflow of API Gateway, AWS Lambda, and SageMaker'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.9：API Gateway、AWS Lambda 和 SageMaker 的工作流程'
- en: '](img/C12624_08_09.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_08_09.jpg)'
- en: 'Figure 8.9: Workflow of API Gateway, AWS Lambda, and SageMaker'
  id: totrans-233
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.9：API Gateway、AWS Lambda 和 SageMaker 的工作流程
- en: The client (say, a web browser), calls an Amazon API Gateway's defined action
    and passes the appropriate parameter values. API Gateway passes the request to
    AWS Lambda, while it also seals the backend so that AWS Lambda stays and executes
    in a protected private network.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端（例如，一个网页浏览器），调用 Amazon API Gateway 的定义动作并传递适当的参数值。API Gateway 将请求传递给 AWS
    Lambda，同时它也封闭了后端，以便 AWS Lambda 在受保护的私有网络中停留并执行。
- en: In our case, we will use Lambda to help us tailor the data received from API
    Gateway into an appropriate form that can be consumed by the SageMaker endpoint.
    This is necessary because there is a difference between the structure of data
    passed through a REST API and that of what SageMaker expects. The SageMaker model
    performs the prediction and returns the predicted value to AWS Lambda. The Lambda
    function parses the returned value and sends it back to API Gateway, after which
    API Gateway responds to the client with the result. This entire flow is orchestrated
    without us actually provisioning any infrastructure; it is entirely managed by
    AWS.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们将使用 Lambda 来帮助我们调整从 API Gateway 收到的数据，使其以适当的形式被 SageMaker 端点消费。这是必要的，因为通过
    REST API 传递的数据结构与 SageMaker 所期望的结构之间存在差异。SageMaker 模型执行预测并将预测值返回给 AWS Lambda。Lambda
    函数解析返回的值并将其发送回 API Gateway，然后 API Gateway 使用结果响应客户端。整个流程完全由 AWS 管理而无需我们实际配置任何基础设施。
- en: Note
  id: totrans-236
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This workflow is explained in further detail in a blog post by Amazon. You can
    read more at https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 此工作流程在亚马逊的一篇博客文章中有更详细的解释。您可以在 https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/
    上了解更多信息。
- en: There is one additional challenge that we will need to tackle. As of today,
    AWS Lambda doesn't support R for defining functions. It supports Python, Java,
    Go, and a few others, but R is not on the list as of now. The lambda function
    will be in charge of transforming the data passed by the API into the required
    form. We will leverage Python scripts for this task. In the future, we can expect
    R to be supported by AWS Lambda.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要解决一个额外的挑战。截至目前，AWS Lambda 不支持 R 语言来定义函数。它支持 Python、Java、Go 以及一些其他语言，但 R
    语言目前不在支持列表中。Lambda 函数将负责将 API 传递的数据转换为所需的形式。我们将利用 Python 脚本来完成这项任务。未来，我们可以期待 AWS
    Lambda 支持R语言。
- en: Now that we have the required context about the necessary services, let's deploy
    our model on a serverless application.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了所需服务的必要背景，让我们将我们的模型部署到无服务器应用程序上。
- en: Building Serverless ML Applications
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建无服务器机器学习应用程序
- en: Serverless computing is the new paradigm within cloud computing. It allows us
    to build and run applications and services without thinking about servers. In
    reality, the application we build still runs on a cloud server, but the entire
    process for server management is done by the cloud service provider, such as AWS.
    By leveraging the serverless platform, we can build and deploy robust, large-scale,
    complex applications by only focusing on our application code instead of worrying
    about provisioning, configuring, and managing servers.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '无服务器计算是云计算中的新范式。它允许我们构建和运行应用程序和服务，而无需考虑服务器。实际上，我们构建的应用程序仍然运行在云服务器上，但整个服务器管理过程由云服务提供商，如
    AWS，来完成。通过利用无服务器平台，我们只需关注应用程序代码，就可以构建和部署强大、大规模、复杂的应用程序，而无需担心配置、管理和提供服务器。 '
- en: We have explored some important components of the AWS serverless platform such
    as AWS Lambda in this chapter, and we can now leverage these solutions to build
    a machine learning application where we can only focus on the core ML code and
    forget about provisioning infrastructure and scaling applications.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了 AWS 无服务器平台的一些重要组件，例如 AWS Lambda，现在我们可以利用这些解决方案来构建一个机器学习应用程序，我们只需关注核心
    ML 代码，而无需担心基础设施的配置和应用程序的扩展。
- en: 'Exercise 101: Building a Serverless Application Using API Gateway, AWS Lambda,
    and SageMaker'
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 101：使用 API Gateway、AWS Lambda 和 SageMaker 构建无服务器应用程序
- en: In this exercise, we will build a machine learning model using AWS SageMaker
    and deploy it as an endpoint (using automated SageMaker functions). To enable
    the model endpoint to be invoked by any service (within or outside AWS) we define
    an AWS Lambda function and expose the endpoint to public networks through API
    Gateway.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用 AWS SageMaker 构建一个机器学习模型，并将其作为端点（使用自动化的 SageMaker 函数）部署。为了使模型端点能够被任何服务（在
    AWS 内部或外部）调用，我们定义了一个 AWS Lambda 函数，并通过 API Gateway 将端点暴露给公共网络。
- en: The aim of this exercise is to create a serverless application that will use
    the SageMaker model endpoint we created in the previous exercise.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的目的是创建一个无服务器应用程序，该应用程序将使用我们在上一个练习中创建的 SageMaker 模型端点。
- en: 'Perform the following steps:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤：
- en: 'Create an IAM role in AWS that will allow Lambda to execute endpoints from
    the SageMaker service. From the AWS dashboard, search for `IAM`, and click on
    the **Roles** option on the IAM page:![Figure 8.10: Creating IAM roles'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 中创建一个 IAM 角色，以便 Lambda 能够执行 SageMaker 服务的端点。从 AWS 控制台，搜索 `IAM`，然后在 IAM
    页面上点击 **Roles** 选项：![图 8.10：创建 IAM 角色
- en: '](img/C12624_08_10.jpg)'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12624_08_10.jpg)'
- en: 'Figure 8.10: Creating IAM roles'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.10：创建 IAM 角色
- en: Once the **Roles** page loads, click on the **Create role** option.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 **角色** 页面加载，点击 **创建角色** 选项。
- en: 'On the **Create role** page, select **AWS Service** as the type of trusted
    entity and **Lambda** as the service that will use this role. Click on the **Next:
    Permissions** button to proceed:![Figure 8.11: Selecting the AWS service option'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **创建角色** 页面上，选择 **AWS Service** 作为受信任实体的类型，并将 **Lambda** 作为将使用此角色的服务。点击 **下一步：权限**
    按钮继续：![图 8.11：选择 AWS 服务选项
- en: '](img/C12624_08_11.jpg)'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12624_08_11.jpg)'
- en: 'Figure 8.11: Selecting the AWS service option'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.11：选择 AWS 服务选项
- en: 'On the `sagemaker` keyword, select the `AmazonSageMakerFullAccess` policy,
    and click on the **Next: Tags** option:![Figure 8.12: The Create role screen'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `sagemaker` 关键字上，选择 `AmazonSageMakerFullAccess` 策略，并点击 **下一步：标签** 选项：![图 8.12：创建角色屏幕
- en: '](img/C12624_08_12.jpg)'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12624_08_12.jpg)'
- en: 'Figure 8.12: The Create role screen'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8.12：创建角色屏幕
- en: On the **Tags** page, you can directly click on **Next** and proceed to the
    final page to name the **Role**.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **标签** 页面上，您可以直接点击 **下一步** 并进入最后一页来命名 **角色**。
- en: 'Now, on the final page, add a suitable name (say, `lambda_sagemaker_execution`)
    and click on **Create role**. The role will be created for us to use:![Figure
    8.13: Review page—creating role'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在最后一页，添加一个合适的名称（例如，`lambda_sagemaker_execution`）并点击**创建角色**。角色将为我们创建以供使用：![图8.13：审查页面—创建角色
- en: '](img/C12624_08_13.jpg)'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图C12624_08_13.jpg](img/C12624_08_13.jpg)'
- en: 'Figure 8.13: Review page—creating role'
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.13：审查页面—创建角色
- en: In the AWS console, search for AWS Lambda and click on the **Create function**
    button. The create function page will have some inputs that need to be defined.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台中，搜索AWS Lambda并点击**创建函数**按钮。创建函数页面将有一些需要定义的输入。
- en: Select the `lambda_sagemaker_connection`).
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`lambda_sagemaker_connection`）。
- en: 'Next, select `lambda_sagemaker_execution`. Click on the **Create function**
    button:![Figure 8.14: Creating a function form'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，选择`lambda_sagemaker_execution`。点击**创建函数**按钮：![图8.14：创建函数表单
- en: '](img/C12624_08_14.jpg)'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图C12624_08_14.jpg](img/C12624_08_14.jpg)'
- en: 'Figure 8.14: Creating a function form'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.14：创建函数表单
- en: 'Define a Python function that will accept the input request from the API, parse
    the payload, and invoke the SageMaker endpoint:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个Python函数，该函数将接受API的输入请求，解析有效载荷，并调用SageMaker端点：
- en: '[PRE45]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The endpoint name will be available in the SageMaker page under the endpoint
    section.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 端点名称将在SageMaker页面下的端点部分可用。
- en: 'We will additionally define the environment variable for the function that
    will store the SageMaker endpoint:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将为函数定义一个环境变量，该变量将存储SageMaker端点：
- en: '[PRE46]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Note
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can refer to the complete code on GitHub at https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson08/Amazon_Lambda_Function.py.
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以在GitHub上查看完整的代码：https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson08/Amazon_Lambda_Function.py。
- en: 'Click on `API Gateway` in the AWS console, and create a new API function by
    selecting the following highlighted options in the screenshot. Give the API a
    suitable name, say, `api_lambda_connect`:![Figure 8.15: Amazon API Gateway'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台中点击`API Gateway`，通过选择截图中的以下突出显示选项创建一个新的API函数。为API提供一个合适的名称，例如`api_lambda_connect`：![图8.15：Amazon
    API网关
- en: '](img/C12624_08_15.jpg)'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图C12624_08_15.jpg](img/C12624_08_15.jpg)'
- en: 'Figure 8.15: Amazon API Gateway'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.15：Amazon API网关
- en: 'From the **Actions** dropdown, select **Create Resource**, add a suitable resource
    name, and then click on the **Create Resource** button:![Figure 8.16: Creating
    a new child resource'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从**操作**下拉菜单中选择**创建资源**，添加一个合适的资源名称，然后点击**创建资源**按钮：![图8.16：创建新的子资源
- en: '](img/C12624_08_16.jpg)'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图C12624_08_16.jpg](img/C12624_08_16.jpg)'
- en: 'Figure 8.16: Creating a new child resource'
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.16：创建新的子资源
- en: Again, from the **Actions** dropdown, select **Create Method** and select the
    method type as **POST**.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，从**操作**下拉菜单中选择**创建方法**，并选择方法类型为**POST**。
- en: 'Select the **Integration Type** as **Lambda Function** and mention the **Lambda
    Function** name in the input label, as shown in the following screenshot. Next,
    click on the **Save** button:![Figure 8.17: Creating a Lambda function'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**集成类型**为**Lambda函数**，并在输入标签中指定**Lambda函数**名称，如以下截图所示。然后，点击**保存**按钮：![图8.17：创建Lambda函数
- en: '](img/C12624_08_17.jpg)'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图C12624_08_17.jpg](img/C12624_08_17.jpg)'
- en: 'Figure 8.17: Creating a Lambda function'
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.17：创建Lambda函数
- en: Next, select `test`) and click on the **Deploy** option. The API will now be
    deployed and will be ready to use.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，选择`test`)并点击**部署**选项。API现在将被部署并准备好使用。
- en: Once the API is deployed, we can find the URL of the API to be invoked by navigating
    to the `https://****amazonaws.com/[deployment-stage]/[resource-name]/`.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦API部署完成，我们可以通过导航到`https://****amazonaws.com/[deployment-stage]/[resource-name]/`找到要调用的API的URL。
- en: 'Call the API from Postman. Open Postman, select a **POST** call, and paste
    the URL we copied from the API Gateway stage. Then, click on **Body** and add
    raw data, that is, the JSON formatted test data, in the body, as shown in the
    following screenshot:![Figure 8.19: Calling the API via Postman'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Postman调用API。打开Postman，选择一个**POST**调用，并将我们从API网关阶段复制的URL粘贴进去。然后，点击**正文**并添加原始数据，即JSON格式的测试数据，如以下截图所示：![图8.19：通过Postman调用API
- en: '](img/C12624_08_19.jpg)'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图C12624_08_19.jpg](img/C12624_08_19.jpg)'
- en: 'Figure 8.19: Calling the API via Postman'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.19：通过Postman调用API
- en: Click on the **Send** button to invoke the API with the provided raw data. The
    result is showcased in the lower window.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**发送**按钮以使用提供的原始数据调用API。结果将在下面的窗口中展示。
- en: We received a prediction of "no," which indicates that the model has been successfully
    deployed as a serverless application. We can now invoke the API from anywhere
    in the world in a browser or Postman and get predictions for the model. This API
    call be integrated with other services in a larger product and can be scaled as
    and when there is more demand.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收到了“否”的预测，这表明模型已成功部署为无服务器应用程序。现在我们可以从世界任何地方的浏览器或Postman调用API并获取模型的预测。此API调用可以集成到更大的产品中的其他服务，并且可以根据需求进行扩展。
- en: Deleting All Cloud Resources to Stop Billing
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除所有云资源以停止计费
- en: 'All the resources we have provisioned will need to be deleted/terminated to
    ensure that they are no longer billed. The following steps will need to be performed
    to ensure that all resources created in the book of the exercise are deleted:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已配置的所有资源都需要被删除/终止，以确保它们不再计费。为了确保在练习书中创建的所有资源都被删除，需要执行以下步骤：
- en: Log in to CloudFormation and click on **Delete** stack (the one we provisioned
    for RStudio).
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录CloudFormation并点击**删除堆栈**（我们为RStudio提供的那个）。
- en: Log in to SageMaker, open Endpoints from the right-hand-side sidebar, check
    the endpoint we created for the exercise, and delete it.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录SageMaker，从右侧侧边栏打开端点，检查我们为练习创建的端点，并删除它。
- en: Log in to AWS Lambda and delete the Lambda function we created for the exercise.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录AWS Lambda，删除我们为练习创建的Lambda函数。
- en: Log in to AWS API Gateway and delete the API we created for the exercise.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录AWS API Gateway并删除我们为练习创建的API。
- en: '**Further notes on AWS SageMaker**'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于AWS SageMaker的进一步说明**'
- en: We leveraged the existing containers of the algorithm provided by Amazon to
    train the model. This step was followed to keep things simple. We can bring our
    own custom trained algorithms to SageMaker and leverage the platform to deploy
    the model as a service. SageMaker takes care of the entire process of orchestrating
    the background resources to provision instances, configure model artefacts, and
    build the endpoint. We would, however, need to provide the data and model artifacts
    in a specific format for SageMaker to deploy it.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用Amazon提供的现有算法容器来训练模型。这一步骤是为了使事情简单。我们可以将我们自己的自定义训练算法带到SageMaker，并利用该平台将模型作为服务部署。SageMaker负责整个过程，包括协调后台资源以提供实例、配置模型工件和构建端点。然而，我们需要以特定格式提供数据和模型工件，以便SageMaker可以部署它。
- en: Note
  id: totrans-299
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Additional details on the process of building custom models can be found at
    https://docs.aws.amazon.com/sagemaker/latest/dg/build-model.html.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 关于构建自定义模型过程的更多详细信息可以在https://docs.aws.amazon.com/sagemaker/latest/dg/build-model.html找到。
- en: 'Activity 13: Deploy an R Model Using plumber'
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动13：使用plumber部署R模型
- en: In this activity, we will develop a regression model in R and deploy it as an
    API endpoint using plumber. We will be using another use case for supervised learning
    in R, and we will build a regression model using a different dataset, that is,
    **Boston Housing**. The dataset is available within R's Mlbench library, which
    we already installed and provides information on the median price of a house within
    Boston when given a number of house attributes.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们将使用R开发回归模型，并使用plumber将其作为API端点部署。我们将使用R的另一个监督学习用例，并使用不同的数据集构建回归模型，即**波士顿住房**。该数据集包含在R的Mlbench库中，我们已安装，并提供在给定房屋属性数量时波士顿房屋的中位价格信息。
- en: 'We will write two R scripts: `model.r` to house the regression model as well
    as the prediction function and `plumber.R` to house the necessary functions to
    deploy the model as an API endpoint.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写两个R脚本：`model.r`用于存放回归模型以及预测函数，`plumber.R`用于存放部署模型为API端点所需的功能。
- en: Note
  id: totrans-304
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Additional details about the dataset can be explored at https://www.rdocumentation.org/packages/mlbench/versions/2.1-1/topics/BostonHousing.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据集的更多详细信息可以在https://www.rdocumentation.org/packages/mlbench/versions/2.1-1/topics/BostonHousing找到。
- en: 'Perform the following steps:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤：
- en: Create a `model.r` script, which will load the required libraries, data, and
    fit a regression model and the necessary functions to make predictions on unseen
    data.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`model.r`脚本，该脚本将加载所需的库、数据和拟合回归模型以及必要的函数，以便对未见数据做出预测。
- en: Load the `mlbench` library, which has the data for this activity.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`mlbench`库，其中包含此活动的数据。
- en: Load the `BostonHousing` data into a DataFrame, `df`.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`BostonHousing`数据加载到DataFrame，`df`中。
- en: Create a train dataset using the first `400` rows of `df` and test with the
    remaining.
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`df`的前`400`行创建训练数据集，并使用剩余的数据进行测试。
- en: Fit a logistic regression model using the `lm` function with the dependent variable
    as `medv` (median value) and `10` independent variables, such as, `crim`, `zn`,
    `indus`, `chas`, `nox`, `rm`, `age`, `dis`, `rad`, and `tax`.
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `lm` 函数拟合逻辑回归模型，其中因变量为 `medv`（中值）和 `10` 个自变量，例如 `crim`、`zn`、`indus`、`chas`、`nox`、`rm`、`age`、`dis`、`rad`
    和 `tax`。
- en: Define a model endpoint as `predict_data`; this will be used as the API endpoint
    for plumber.
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个模型端点为 `predict_data`；这将被用作 plumber 的 API 端点。
- en: Within the function, convert the parameters to `numeric` and **factor** (since
    the API call will pass them as a string only).
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在函数内部，将参数转换为 `numeric` 和 **factor**（因为 API 调用只会将它们作为字符串传递）。
- en: Wrap the 10 independent features for the model as a DataFrame named `sample`,
    with the same name for the columns.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型的 10 个独立特征作为名为 `sample` 的 DataFrame 包装，列名保持一致。
- en: Pass the `sample` DataFrame to the predict function with the model (created
    in step 4), and return the predictions.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `sample` DataFrame 传递给步骤 4 中创建的模型预测函数，并返回预测结果。
- en: Load the `plumber` library.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 `plumber` 库。
- en: Create a plumber object using the `plumb` function and pass the `model.r` file
    (created in part 1).
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `plumb` 函数创建一个 plumber 对象，并传递步骤 1 中创建的 `model.r` 文件。
- en: Run the plumber object by passing the hostname as `localhost` or `127.0.0.1`
    and a port, say `8080`.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过传递主机名 `localhost` 或 `127.0.0.1` 和端口号，例如 `8080`，来运行 plumber 对象。
- en: Test the deployed model using the browser or Postman and invoke the API.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用浏览器或 Postman 测试部署的模型，并调用 API。
- en: 'API invocation:'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: API 调用：
- en: http://127.0.0.1:8080/predict_data?crim=0.01&zn=18&indus=2.3&chas=0&nox=0.5&rm=6&age=65&dis=4&rad=1&tax=242
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: http://127.0.0.1:8080/predict_data?crim=0.01&zn=18&indus=2.3&chas=0&nox=0.5&rm=6&age=65&dis=4&rad=1&tax=242
- en: 'The final output is as follows:'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终输出如下：
- en: '[PRE47]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Note
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 463.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第 463 页找到。
- en: Summary
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we studied how to deploy our machine learning models with traditional
    server-based deployment strategies using R's plumber, and enhanced approaches
    using plumber for R with Docker containers. We then studied how serverless applications
    can be built using cloud services and how we can easily scale applications as
    needed with minimal code.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用 R 的 plumber 工具以及 Docker 容器等增强方法，通过传统的基于服务器的部署策略来部署我们的机器学习模型。然后，我们研究了如何使用云服务构建无服务器应用程序，以及如何通过最少的代码轻松地按需扩展应用程序。
- en: We explored various web services, such as Amazon Lambda, Amazon SageMaker, and
    Amazon API Gateway, and studied how services can be orchestrated to deploy our
    machine learning model as a serverless application.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了各种网络服务，例如 Amazon Lambda、Amazon SageMaker 和 Amazon API Gateway，并研究了如何编排服务以将我们的机器学习模型作为无服务器应用程序部署。
- en: In the next chapter, we will work on a capstone project by taking up one of
    the latest research papers based on a real-world problem and reproducing the result.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过基于现实世界问题的最新研究论文来开展一个综合项目，并重现其结果。
