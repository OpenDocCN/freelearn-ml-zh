["```py\n{\n    \"aggr_ip\": \"localhost\",\n    \"db_ip\": \"localhost\",\n    \"reg_socket\": \"8765\",\n    \"exch_socket\": \"7890\",\n    \"recv_socket\": \"4321\",\n    \"db_socket\": \"9017\",\n    \"round_interval\": 5,\n    \"aggregation_threshold\": 1.0,\n    \"polling\": 1\n}\n```", "```py\nimport asyncio, logging, time, numpy as np\nfrom typing import List, Dict, Any\nfrom fl_main.lib.util.communication_handler import init_fl_server, send, send_websocket, receive \nfrom fl_main.lib.util.data_struc import convert_LDict_to_Dict\nfrom fl_main.lib.util.helpers import read_config, set_config_file\nfrom fl_main.lib.util.messengers import generate_db_push_message, generate_ack_message, generate_cluster_model_dist_message, generate_agent_participation_confirmation_message\nfrom fl_main.lib.util.states import ParticipateMSGLocation, ModelUpMSGLocation, PollingMSGLocation, ModelType, AgentMsgType\nfrom .state_manager import StateManager\nfrom .aggregation import Aggregator\n```", "```py\nclass Server:\n    \"\"\"\n    FL Server class defining the functionalities of \n    agent registration, global model synthesis, and\n    handling mechanisms of messages by agents. \n    \"\"\"\n```", "```py\ndef __init__(self):\n    config_file = set_config_file(\"aggregator\")\n    self.config = read_config(config_file)\n    self.sm = StateManager()\n    self.agg = Aggregator(self.sm)\n    self.aggr_ip = self.config['aggr_ip']\n    self.reg_socket = self.config['reg_socket']\n    self.recv_socket = self.config['recv_socket']\n    self.exch_socket = self.config['exch_socket']\n    self.db_ip = self.config['db_ip']\n    self.db_socket = self.config['db_socket']\n    self.round_interval = self.config['round_interval']\n    self.is_polling = bool(self.config['polling'])\n    self.sm.agg_threshold = \n                     self.config['aggregation_threshold']\n```", "```py\nasync def register(self, websocket: str, path):        \n    msg = await receive(websocket)\n    es = self._get_exch_socket(msg)\n    agent_nm = msg[int(ParticipateMSGLocation.agent_name)]\n    agent_id = msg[int(ParticipateMSGLocation.agent_id)]\n    ip = msg[int(ParticipateMSGLocation.agent_ip)]\n    id, es = self.sm.add_agent(agent_nm, agent_id, ip, es)\n    if self.sm.round == 0:\n        await self._initialize_fl(msg)\n    await self._send_updated_global_model( \\\n        websocket, id, es)\n```", "```py\ndef _get_exch_socket(self, msg):\n    if msg[int(ParticipateMSGLocation.sim_flag)]:\n        es = msg[int(ParticipateMSGLocation.exch_socket)]\n    else:\n        es = self.exch_socket\n    return es\n```", "```py\nasync def _initialize_fl(self, msg):\n    agent_id = msg[int(ParticipateMSGLocation.agent_id)]\n    model_id = msg[int(ParticipateMSGLocation.model_id)]\n    gene_time = msg[int(ParticipateMSGLocation.gene_time)]\n    lmodels = msg[int(ParticipateMSGLocation.lmodels)] \n    perf_val = msg[int(ParticipateMSGLocation.meta_data)]\n    init_flag = \\\n        bool(msg[int(ParticipateMSGLocation.init_flag)])\n    self.sm.initialize_model_info(lmodels, init_flag)\n    await self._push_local_models( \\\n        agent_id, model_id, lmodels, gene_time, perf_val)\n    self.sm.increment_round()\n```", "```py\nasync def _send_updated_global_model( \\\n                   self, websocket, agent_id, exch_socket):\n    model_id = self.sm.cluster_model_ids[-1]\n    cluster_models = \\\n       convert_LDict_to_Dict(self.sm.cluster_models)\n    reply = generate_agent_participation_confirm_message(\n       self.sm.id, model_id, cluster_models, self.sm.round,\n       agent_id, exch_socket, self.recv_socket)\n    await send_websocket(reply, websocket)\n```", "```py\nasync def receive_msg_from_agent(self, websocket, path):\n    msg = await receive(websocket)\n    if msg[int(ModelUpMSGLocation.msg_type)] == \\\n                                       AgentMsgType.update:\n        await self._process_lmodel_upload(msg)\n    elif msg[int(PollingMSGLocation.msg_type)] == \\\n                                      AgentMsgType.polling:\n        await self._process_polling(msg, websocket)  \n```", "```py\nasync def _process_lmodel_upload(self, msg):\n    lmodels = msg[int(ModelUpMSGLocation.lmodels)]\n    agent_id = msg[int(ModelUpMSGLocation.agent_id)]\n    model_id = msg[int(ModelUpMSGLocation.model_id)]\n    gene_time = msg[int(ModelUpMSGLocation.gene_time)]\n    perf_val = msg[int(ModelUpMSGLocation.meta_data)]\n    await self._push_local_models( \\ \n        agent_id, model_id, lmodels, gene_time, perf_val)\n    self.sm.buffer_local_models( \\ \n        lmodels, participate=False, meta_data=perf_val)\n```", "```py\nasync def _process_polling(self, msg, websocket):\n    if self.sm.round > \\\n                   int(msg[int(PollingMSGLocation.round)]):\n        model_id = self.sm.cluster_model_ids[-1]\n        cluster_models = \\\n            convert_LDict_to_Dict(self.sm.cluster_models)\n        msg = generate_cluster_model_dist_message( \\\n            self.sm.id, model_id, self.sm.round, \\\n            cluster_models)\n        await send_websocket(msg, websocket)\n    else:\n        msg = generate_ack_message()\n        await send_websocket(msg, websocket)  \n```", "```py\nasync def model_synthesis_routine(self):\n    while True:\n        await asyncio.sleep(self.round_interval)\n        if self.sm.ready_for_local_aggregation():  \n            self.agg.aggregate_local_models()\n            await self._push_cluster_models()\n            if self.is_polling == False:\n                await self._send_cluster_models_to_all()\n            self.sm.increment_round()\n```", "```py\nasync def _send_cluster_models_to_all(self):\n    model_id = self.sm.cluster_model_ids[-1]\n    cluster_models = \\\n        convert_LDict_to_Dict(self.sm.cluster_models)\n    msg = generate_cluster_model_dist_message( \\\n        self.sm.id, model_id, self.sm.round, \\\n        cluster_models)\n    for agent in self.sm.agent_set:\n        await send(msg, agent['agent_ip'], agent['socket'])\n```", "```py\nasync def _push_local_models(self, agent_id: str, \\\n        model_id: str, local_models: Dict[str, np.array], \\\n        gene_time: float, performance: Dict[str, float]) \\\n        -> List[Any]:\n    return await self._push_models(\n        agent_id, ModelType.local, local_models, \\\n        model_id, gene_time, performance)\n```", "```py\nasync def _push_cluster_models(self) -> List[Any]:\n    model_id = self.sm.cluster_model_ids[-1] \n    models = convert_LDict_to_Dict(self.sm.cluster_models)\n    meta_dict = dict({ \\\n        \"num_samples\" : self.sm.own_cluster_num_samples})\n    return await self._push_models( \\\n        self.sm.id, ModelType.cluster, models, model_id, \\\n        time.time(), meta_dict)\n```", "```py\nasync def _push_models(\n    self, component_id: str, model_type: ModelType,\n    models: Dict[str, np.array], model_id: str,\n    gene_time: float, performance_dict: Dict[str, float])\n    -> List[Any]:\n    msg = generate_db_push_message(component_id, \\\n        self.sm.round, model_type, models, model_id, \\\n        gene_time, performance_dict)\n    resp = await send(msg, self.db_ip, self.db_socket)\n    return resp\n```", "```py\nimport numpy as np\nimport logging\nimport time\nfrom typing import Dict, Any\nfrom fl_main.lib.util.data_struc import LimitedDict\nfrom fl_main.lib.util.helpers import generate_id, generate_model_id\nfrom fl_main.lib.util.states import IDPrefix\n```", "```py\nclass StateManager:\n    \"\"\"\n    StateManager instance keeps the state of an aggregator.\n    Functions are listed with this indentation.\n    \"\"\"\n```", "```py\ndef __init__(self):\n    self.id = generate_id()\n    self.agent_set = list()\n    self.mnames = list()\n    self.round = 0\n    self.local_model_buffers = LimitedDict(self.mnames)\n    self.local_model_num_samples = list()\n    self.cluster_models = LimitedDict(self.mnames)\n    self.cluster_model_ids = list()\n    self.initialized = False\n    self.agg_threshold = 1.0\n```", "```py\ndef initialize_model_info(self, lmodels, \\\n                          init_weights_flag):\n    for key in lmodels.keys():\n        self.mnames.append(key)\n    self.local_model_buffers = LimitedDict(self.mnames)\n    self.cluster_models = LimitedDict(self.mnames)\n    self.clear_lmodel_buffers()\n    if init_weights_flag:\n        self.initialize_models(lmodels, \\\n                            weight_keep=init_weights_flag)\n    else:\n        self.initialize_models(lmodels, weight_keep=False)\n```", "```py\ndef initialize_models(self, models: Dict[str, np.array], \\\n                                weight_keep: bool = False):\n    self.clear_saved_models()\n    for mname in self.mnames:\n        if weight_keep:\n            m = models[mname]\n        else:\n            m = np.zeros_like(models[mname])\n        self.cluster_models[mname].append(m)\n        id = generate_model_id(IDPrefix.aggregator, \\\n                 self.id, time.time())\n        self.cluster_model_ids.append(id)\n        self.initialized = True\n```", "```py\ndef ready_for_local_aggregation(self) -> bool:\n    if len(self.mnames) == 0:\n            return False\n    num_agents = int(self.agg_threshold * \\\n                                       len(self.agent_set))\n    if num_agents == 0: num_agents = 1\n    num_collected_lmodels = \\\n        len(self.local_model_buffers[self.mnames[0]])\n    if num_collected_lmodels >= num_agents:\n        return True\n    else:\n        return False            \n```", "```py\ndef buffer_local_models(self, models: Dict[str, np.array], \n        participate=False, meta_data: Dict[Any, Any] = {}):\n    if not participate:  \n        for key, model in models.items():\n            self.local_model_buffers[key].append(model)\n        try:\n            num_samples = meta_data[\"num_samples\"]\n        except:\n            num_samples = 1\n        self.local_model_num_samples.append( \\\n                int(num_samples))\n    else:  \n        pass\n    if not self.initialized:\n        self.initialize_models(models)\n```", "```py\ndef clear_saved_models(self):\n    for mname in self.mnames:\n        self.cluster_models[mname].clear()\n```", "```py\ndef clear_lmodel_buffers(self):\n    for mname in self.mnames:\n        self.local_model_buffers[mname].clear()\n    self.local_model_num_samples = list()\n```", "```py\ndef add_agent(self, agent_name: str, agent_id: str, \\\n                               agent_ip: str, socket: str):\n    for agent in self.agent_set:\n        if agent_name == agent['agent_name']:\n            return agent['agent_id'], agent['socket']\n    agent = {\n        'agent_name': agent_name,\n        'agent_id': agent_id,\n        'agent_ip': agent_ip,\n        'socket': socket\n    }\n    self.agent_set.append(agent)\n    return agent_id, socket\n```", "```py\ndef increment_round(self):\n    self.round += 1\n```", "```py\nimport logging\nimport time\nimport numpy as np\nfrom typing import List\nfrom .state_manager import StateManager\nfrom fl_main.lib.util.helpers import generate_model_id\nfrom fl_main.lib.util.states import IDPrefix\n```", "```py\nclass Aggregator:\n    \"\"\"\n    Aggregator class instance provides a set of \n    mathematical functions to compute aggregated models.\n    \"\"\"\n```", "```py\ndef __init__(self, sm: StateManager):\n    self.sm = sm\n```", "```py\ndef aggregate_local_models(self):\n    for mname in self.sm.mnames:\n        self.sm.cluster_models[mname][0] \\\n            = self._average_aggregate( \\\n                self.sm.local_model_buffers[mname], \\\n                self.sm.local_model_num_samples)\n    self.sm.own_cluster_num_samples = \\\n        sum(self.sm.local_model_num_samples)\n    id = generate_model_id( \\\n        IDPrefix.aggregator, self.sm.id, time.time())\n    self.sm.cluster_model_ids.append(id)\n    self.sm.clear_lmodel_buffers()\n```", "```py\ndef _average_aggregate(self, buffer: List[np.array], \n                       num_samples: List[int]) -> np.array:\n    denominator = sum(num_samples)\n    model = float(num_samples[0])/denominator * buffer[0]\n    for i in range(1, len(buffer)):\n        model += float(num_samples[i]) / \n                                    denominator * buffer[i]\n    return model\n```", "```py\nif __name__ == \"__main__\":\n    s = Server()\n    init_fl_server(s.register, \n                   s.receive_msg_from_agent, \n                   s.model_synthesis_routine(), \n                   s.aggr_ip, s.reg_socket, s.recv_socket)\n```", "```py\n{\n    \"db_ip\": \"localhost\",\n    \"db_socket\": \"9017\",\n    \"db_name\": \"sample_data\",\n    \"db_data_path\": \"./db\",\n    \"db_model_path\": \"./db/models\"\n}\n```", "```py\nimport pickle, logging, time, os\nfrom typing import Any, List\nfrom .sqlite_db import SQLiteDBHandler\nfrom fl_main.lib.util.helpers import generate_id, read_config, set_config_file\nfrom fl_main.lib.util.states import DBMsgType, DBPushMsgLocation, ModelType\nfrom fl_main.lib.util.communication_handler import init_db_server, send_websocket, receive\n```", "```py\nclass PseudoDB:\n    \"\"\"\n    PseudoDB class instance receives models and their data\n    from an aggregator, and pushes them to database\n    \"\"\"\n```", "```py\ndef __init__(self):\n    self.id = generate_id()\n    self.config = read_config(set_config_file(\"db\"))\n    self.db_ip = self.config['db_ip']\n    self.db_socket = self.config['db_socket']\n    self.data_path = self.config['db_data_path']\n    if not os.path.exists(self.data_path):\n        os.makedirs(self.data_path)\n    self.db_file = \\\n        f'{self.data_path}/model_data{time.time()}.db'\n    self.dbhandler = SQLiteDBHandler(self.db_file)\n    self.dbhandler.initialize_DB()\n    self.db_model_path = self.config['db_model_path']\n    if not os.path.exists(self.db_model_path):\n        os.makedirs(self.db_model_path)\n```", "```py\nasync def handler(self, websocket, path):\n    msg = await receive(websocket)\n    msg_type = msg[DBPushMsgLocation.msg_type]\n    reply = list()\n    if msg_type == DBMsgType.push:\n        self._push_all_data_to_db(msg)\n        reply.append('confirmation')\n    else:\n        raise TypeError(f'Undefined DB Message Type: \\\n                                              {msg_type}.')\n    await send_websocket(reply, websocket)\n```", "```py\ndef _push_all_data_to_db(self, msg: List[Any]):\n    pm = self._parse_message(msg)\n    self.dbhandler.insert_an_entry(*pm)\n    model_id = msg[int(DBPushMsgLocation.model_id)]\n    models = msg[int(DBPushMsgLocation.models)]\n    fname = f'{self.db_model_path}/{model_id}.binaryfile'\n    with open(fname, 'wb') as f:\n        pickle.dump(models, f)\n```", "```py\ndef _parse_message(self, msg: List[Any]):\n    component_id = msg[int(DBPushMsgLocation.component_id)]\n    r = msg[int(DBPushMsgLocation.round)]\n    mt = msg[int(DBPushMsgLocation.model_type)]\n    model_id = msg[int(DBPushMsgLocation.model_id)]\n    gene_time = msg[int(DBPushMsgLocation.gene_time)]\n    meta_data = msg[int(DBPushMsgLocation.meta_data)]\n    local_prfmc = 0.0\n    if mt == ModelType.local:\n        try: local_prfmc = meta_data[\"accuracy\"]\n        except: pass\n    num_samples = 0\n    try: num_samples = meta_data[\"num_samples\"]\n    except: pass\n    return component_id, r, mt, model_id, gene_time, \\\n                                   local_prfmc, num_samples\n```", "```py\nimport sqlite3\nimport datetime\nimport logging\nfrom fl_main.lib.util.states import ModelType\n```", "```py\nclass SQLiteDBHandler:\n    \"\"\"\n    SQLiteDB Handler class that creates and initialize\n    SQLite DB, and inserts models to the SQLiteDB\n    \"\"\"\n```", "```py\ndef __init__(self, db_file):\n    self.db_file = db_file\n```", "```py\ndef initialize_DB(self):\n    conn = sqlite3.connect(f'{self.db_file}')\n    c = conn.cursor()\n    c.execute('''CREATE TABLE local_models(model_id, \\\n        generation_time, agent_id, round, performance, \\\n        num_samples)''')\n    c.execute('''CREATE TABLE cluster_models(model_id, \\\n        generation_time, aggregator_id, round, \\\n        num_samples)''')\n    conn.commit()\n    conn.close()\n```", "```py\ndef insert_an_entry(self, component_id: str, r: int, mt: \\\n    ModelType, model_id: str, gtime: float, local_prfmc: \\\n    float, num_samples: int):\n    conn = sqlite3.connect(self.db_file)\n    c = conn.cursor()\n    t = datetime.datetime.fromtimestamp(gtime)\n    gene_time = t.strftime('%m/%d/%Y %H:%M:%S')\n    if mt == ModelType.local:\n        c.execute('''INSERT INTO local_models VALUES \\\n        (?, ?, ?, ?, ?, ?);''', (model_id, gene_time, \\\n        component_id, r, local_prfmc, num_samples))\n    elif mt == ModelType.cluster:\n        c.execute('''INSERT INTO cluster_models VALUES \\\n        (?, ?, ?, ?, ?);''', (model_id, gene_time, \\\n        component_id, r, num_samples))\n    conn.commit()\n    conn.close()\n```", "```py\nif __name__ == \"__main__\":\n    pdb = PseudoDB()\n    init_db_server(pdb.handler, pdb.db_ip, pdb.db_socket)\n```"]