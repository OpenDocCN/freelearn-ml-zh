- en: 'Chapter 10: Exploring Time Series Analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed using deep learning and its robust applicability
    when it comes to unstructured data in the form of natural language – a type of
    sequential data. Another type of sequential data that we will now turn our attention
    to is time series data. We can think of time series data as being standard datasets
    yet containing a time-based feature, thus unlocking a new set of possibilities
    when it comes to developing predictive models.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most common applications in time series data is a process known as
    time series analysis. We can define time series analysis as an area of data **exploration**
    and **forecasting** in which datasets are ordered or indexed using a particular
    **time interval** or **timestamp**. There are many examples of time series data
    that we encounter in the biotechnology and life sciences industries daily. Some
    of the more laboratory-based areas of focus include gene expression and chromatography,
    as well as non-lab areas such as demand forecasting and stock price analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we will explore several different areas when it comes
    to gaining a better understanding of the analysis of time series data, as well
    as developing a model capable of consuming this data and developing a robust,
    predictive model.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we explore these areas, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding time series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the components of a time series dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tutorial – forecasting product demand using Prophet and LSTM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that in mind, let’s go ahead and get started!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding time series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to using **time series** data, there are endless ways to visualize
    and display data to effectively communicate a thought or idea. In most of the
    data we have used so far, we have handled features and labels in which a certain
    set of features generally corresponded to a label of interest. When it comes to
    time series data, we tend to forego the idea of a class or label and focus more
    on trends within the data instead. One of the most common applications of time
    series data is the idea of **demand forecasting**. Demand forecasting, as its
    name suggests, comprises the many methods and tools available to help predict
    demand for a given good or service ahead of time. Throughout this section, we
    will learn about the many aspects of time series analysis using a dataset concerning
    the demand forecasting of a given biotechnology product.
  prefs: []
  type: TYPE_NORMAL
- en: Treating time series data as a structured dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many different biotechnology products on the market today, ranging
    from agricultural genetically modified crops, all the way to monoclonal antibody
    therapeutics. In this section, we will investigate the sales data of a human therapeutic
    by using the `dataset_demand-forecasting_ts.csv` dataset, which belongs to a small
    biotech start-up:'
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, let’s go ahead and dive into the data. We will begin by
    importing the libraries of interest, importing the `CSV` file, and taking a glance
    at the first few rows of data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.1 – The first few rows of the forecasting dataset ](img/B17761_10_001.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.1 – The first few rows of the forecasting dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Relative to the many other datasets we have worked with in the past, this one
    seems much simpler in the sense that we are working with only two columns: `Date`
    and the number of `Sales` for any given day. We can also see that the sales have
    been aggregated by day, starting on `2014-01-01`. If we check the end of the dataset
    using the `tail()` function, we will see that the dataset ends on `2020-12-23`
    – essentially providing us with 6 years’ worth of sales data to work with.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can visualize the time series data using the `Plotly` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon executing the `fig.show()` function, we will receive the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Time series plot of the sales dataset ](img/B17761_10_002.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.2 – Time series plot of the sales dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can immediately make a few initial observations regarding the dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There is a significant amount of noise and variability within the data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sales gradually increase over time (I should have invested in them!).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: There seems to be an element of seasonality in which sales peak around December.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To explore these ideas a bit more and dive deeper into the data, we will need
    to deconstruct the time series aspect. Using the `Date` column, we can break the
    dataset down into years, months, and days to get a better sense of the repetitive
    or **seasonal** nature of this data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Seasonality** within datasets refers to the seasonal characteristics relating
    to that time of the year. For example, datasets relating to the flu shot often
    show increased rates in the fall relative to the spring or summer in preparation
    for the winter (flu season).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'First, we will need to use the `to_datetime()` function to convert `string`
    into the `date` type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon executing this command, we will receive the following DataFrame as output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.3 – The first five rows of the sales dataset showing new features
    ](img/B17761_10_003.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.3 – The first five rows of the sales dataset showing new features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here, we can see that we were able to break down the time series aspect and
    yield a little more data than we originally started with. Let’s go ahead and plot
    the data by `year`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After plotting our data, we will receive the following boxplot, which shows
    the sales for each given year. From a statistical perspective, we can confirm
    our initial observation that the sales are gradually increasing every year:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Boxplot showing the increasing sales every year ](img/B17761_10_004.png.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.4 – Boxplot showing the increasing sales every year
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s go ahead and plot the same graph for each given `month` instead:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon changing the *x*-axis from years to months, we will receive the following
    graph, confirming our observation that the sales data tends to peak around the
    January (**1**)/December (**12**) timeframes:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Boxplot showing the seasonal sales for every month ](img/B17761_10_005.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.5 – Boxplot showing the seasonal sales for every month
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Earlier, we noted that the dataset contained a great deal of noise in the sense
    that there was a great deal of fluctuation within the data. We can address this
    noise and normalize the data by taking a **rolling average** (**moving average**)
    – a calculation that’s used to help us analyze data points by creating a series
    of average values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can implement this directly in our DataFrame using the `rolling()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Notice that in the preceding code, we used two examples to demonstrate the
    idea of a rolling average by using window values of 20 and 100\. Using `Plotly
    Go`, we can plot the original raw data and the two rolling averages onto a single
    plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon executing this code, we will receive the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.6 – Boxplot showing the rolling average of the sales data ](img/B17761_10_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – Boxplot showing the rolling average of the sales data
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the raw dataset is plotted faintly in the background, overlayed
    by the dashed curve representing the `window` value of 20, as well as the solid
    curve in the foreground representing the `window` value of 100\. Using rolling
    averages can be useful when you’re trying to visualize and understand your data,
    as well as building forecasting models, as we will see later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A **rolling average** (**moving average**) is a calculation that’s used to smoothen
    out a noisy dataset by taking the moving mean throughout a particular range. The
    range, which is often referred to as the window, is generally the last *x* number
    of data points.
  prefs: []
  type: TYPE_NORMAL
- en: Time series data is very different from much of the datasets we have explored
    so far within this book. Unlike other datasets, time series data is generally
    thought to be consistent with several **components**, all of which we will explore
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the components of a time series dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore the four main items that are generally regarded
    as the components of a time series dataset and visualize them. With that in mind,
    let’s go ahead and get started!
  prefs: []
  type: TYPE_NORMAL
- en: 'Time series datasets generally consist of four main components: **level**,
    **long-term** **trends**, **seasonality**, and **irregular noise**, which we can
    break down into a method known as time series **decomposition**. The main purpose
    behind decomposition is to gain a better perspective of the dataset by thinking
    about the data more abstractly. We can think of time series components as being
    either additive or multiplicative:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761_10_001.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B17761_10_002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can define each of the components as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Level**: Average values of a dataset over time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long-term Trends**: General direction of the data showing an increase or
    decrease'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seasonal Trends**: Short-term repetitive nature (days, weeks, months)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Irregular Trends**: The noise within the data showing random fluctuations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can explore and visualize these compounds a little more closely using the
    `statsmodels` library in conjunction with our dataset by performing the following
    simple steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will need to reshape our dataset by only keeping the sales column,
    dropping any missing values, and setting the date column as the DataFrame’s **index**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can check the first few rows to see that the date is now our index:![Figure
    10.7 – First few rows of the reshaped dataset ](img/B17761_10_007.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.7 – First few rows of the reshaped dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we will import the `seasonal_decompose` function from the `statsmodels`
    library and apply it to our `dataframe`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can plot the result using the built-in `plot()` function and view
    the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the `show()` function will give us the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Results of the seasonal decomposition function ](img/B17761_10_008.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – Results of the seasonal decomposition function
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the four components we spoke of earlier in this section. In
    the first plot, we can see the rolling average we calculated in the previous section.
    This is then followed by the **long-term trend**, which shows a steady increase
    throughout the dataset. We can then see the **seasonality** behind the dataset,
    confirming that sales tend to increase around the December and January timeframes.
    Finally, we can see the **residual** data or **noise** within the dataset. We
    can define this noise as items that did not contribute to the other main categories.
  prefs: []
  type: TYPE_NORMAL
- en: Decomposing a dataset is generally done to gain a better sense of the data and
    some of its main characteristics, which can often reshape how you think of the
    dataset and any given forecasting model that can be developed. We will learn how
    to develop two common forecasting models in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial – forecasting demand using Prophet and LSTM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this tutorial, we will use the sales dataset from the previous section to
    develop two robust demand forecasting models. Our main objective will be to use
    the sales data to predict demand at a future date. **Demand forecasting** is generally
    done to predict the number of units to be sold on either a given date or location.
    Companies around the world, especially those that handle temperature-sensitive
    or time-sensitive medications, rely on models such as these to optimize their
    supply chains and ensure patient needs are met.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will explore Facebook’s famous **Prophet** library, followed by developing
    a custom **Long Short-term Memory** (**LSTM**) deep learning model. With this
    in mind, let’s go ahead and investigate how to use the Prophet model.
  prefs: []
  type: TYPE_NORMAL
- en: Using Prophet for time series modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prophet is a model that gained a great deal of traction within the data science
    community when it was first released in 2017\. As an open source library available
    in both **R** and **Python**, the model was quickly adopted and widely used as
    one of the main forecasting models for time series data. One of the greatest benefits
    behind this model is also one of its consequences – its high-level nature of abstraction,
    allowing users to make a forecast with only a few lines of code. This limited
    variability can be a great way to make a quick forecast but can hinder the model
    development process, depending on the dataset at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Over the next few pages, we will develop a Prophet model that’s been fitted
    with our data to forecast future sales and validate the results by comparing them
    to the actual sales data. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, let’s go ahead and use the `rolling()` function to get a rolling
    average of our dataset. Then, we can overlay this value on the raw values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will result in the following output:![Figure 10.9 – The rolling average
    relative to the raw dataset ](img/B17761_10_009.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.9 – The rolling average relative to the raw dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here, we can see that the dataset is now far less **noisy** and easier to work
    with. We can use the **Prophet** library with our dataset to create a forecast
    in four basic steps:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'First, we will need to reshape the DataFrame to integrate it with the `Prophet`
    library. The library expects the DataFrame to contain two columns – `ds` and `y`
    – in which `ds` is the date stamp and `y` is the value that we are working with.
    We can reshape this DataFrame into a new DataFrame using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similar to the implementation of the `sklearn` library, we can create an instance
    of the Prophet model and `fit` that to our dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we can call the `make_future_dataframe()` function and the number of
    periods of interest. This will yield a DataFrame containing a column of dates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can use the `predict()` function to make a forecast using the future
    variable as an input parameter. This will return a number of different statistical
    values related to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can limit the scope of the dataset to a few of the columns and retrieve
    the following DataFrame:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.10 – The output of the forecasting function from Prophet ](img/B17761_10_010.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.10 – The output of the forecasting function from Prophet
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we can visualize our predictions using the built-in `plot()` function
    from our **Prophet** instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output, which shows the original raw dataset,
    the future forecasting, as well as some upper and lower boundaries:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Graphical representation of the forecasted data ](img/B17761_10_011.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.11 – Graphical representation of the forecasted data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Alternatively, we can test the model’s capabilities by training the model using
    a portion of the data – for example, everything up to 2018\. We can then use the
    forecasting model to predict the remaining time to compare the output with the
    actual data. Upon completing this, we will receive the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Graphical representation of the training and testing data
    ](img/B17761_10_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.12 – Graphical representation of the training and testing data
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the dashed line, which represents the forecasted sales,
    was quite close to the actual values. We can also see that the model did not forecast
    the extremes of the curve, so it likely needs additional tuning to reach a more
    realistic forecast. However, the high-level nature of **Prophet** can be limiting
    in this area.
  prefs: []
  type: TYPE_NORMAL
- en: From this, we can see that preparing the data and implementing the model was
    quite fast and that we were able to complete this in only a few lines of code.
    In the next section, we will learn how to develop an **LSTM** using **Keras**.
  prefs: []
  type: TYPE_NORMAL
- en: Using LSTM for time series modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**LSTM** models first gained their popularity in 1997, and then again in recent
    years with the increase in computational capabilities. As you may recall, LSTMs
    are a type of **Recurrent Neural Network** (**RNN**) that can remember and forget
    patterns within a dataset. One of the main benefits of this model is its mid to
    low-level nature in the sense that more code is required for a full implementation,
    relative to that of **Prophet**. Users gain a great deal of control over the model
    development process, enabling them to cater the model to almost any type of dataset,
    and any type of use case. With that in mind, let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the same dataset, we can go ahead and create a rolling average using
    a `window` of `20` to reduce the noise in our dataset. Then, we can remove the
    missing values that result from this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `MinMaxScaler` from the `sklearn` library, we can go ahead and scale
    our dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will need to split the data into our training and testing sets. Remember
    that our objective here is to provide the model with some sample historical data
    and see if we can accurately forecast future demand. Let’s go ahead and use 75%
    of the dataset to train the model and see if we can forecast the remaining 25%:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Given that we are working with time series data, we will need to use a `lookback`
    to train the model in iterations. Let’s go ahead and select a `lookback` value
    of `100` and use our `dataset_generator` function to create our training and testing
    sets. We can think of a `lookback` value as the range of how far back in the data
    the model should look to train:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As you may recall from our previous implementation of an LSTM model, we needed
    to `reshape` our data prior to using the data as input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, with the data prepared, we can go ahead and prepare the model itself.
    Given that we are only working with a single feature, we can keep our model relatively
    simple. First, we will use the `Sequential` class from Keras, and then add an
    `LSTM` layer with two nodes, followed by a `Dense` layer with a single output
    value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we can use an `Adam` optimizer with a learning rate of `0.001` and compile
    the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Recall that we can use the `summary()` function to take a look at the compiled
    model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output, which provides a glimpse into the
    inner workings of the model:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.13 – Summary of the Keras model ](img/B17761_10_013.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.13 – Summary of the Keras model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With the model compiled, we can go ahead and begin the training process. We
    can call the `fit()` function to fit the model on the training dataset for 10
    epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The model training process should be relatively quick. Once it’s been completed,
    we can take a look at the `loss` value by visualizing the results in a graph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output, showing the progressive decrease
    in loss over time:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Model loss over time ](img/B17761_10_014.png.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 10.14 – Model loss over time
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, we can see that the `loss` value decreases quite consistently, finally
    plateauing at around the 9-10 epoch marker. Notice that we specified a learning
    rate of `0.001` in the optimizer. Had we increased this value to 0.01, or decreased
    the value to 0.0001, the output of this graph would be very different. We can
    use the learning rate as a powerful parameter to optimize the performance of our
    model. Go ahead and give this a try to see what the graphical output of the loss
    would be.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With the model training complete, we can go ahead and use the model to forecast
    the values of interest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the data all set, we can visualize the data by plotting the results using
    `matplotlib`. First, let’s plot the original dataset using `lightgrey`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we can plot the training values using `blue`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can plot the forecasted values using `darkorange` and a dashed
    line to distinguish it from its two counterparts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon executing this code, we will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.15 – Training and testing datasets using the LSTM model ](img/B17761_10_015.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.15 – Training and testing datasets using the LSTM model
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that this relatively simple **LSTM** model was quite effective
    in making a forecast using the training dataset we provided. The model was not
    only able to capture the general direction of the values, but also managed to
    capture the seasonality of the values as well.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we attempted to analyze and understand time series data, as
    well as developing two predictive forecasting models in less than 15 pages. We
    began our journey by exploring and decomposing time series data into smaller features
    that can generally be used with shallow machine learning models. We then investigated
    the components of a time series dataset to understand the underlying makeup. Finally,
    we developed two of the most common forecasting models that are used in the industry
    – the Prophet model, by Facebook, and an LSTM model using Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the last few chapters, we have developed various technical solutions
    to solve common business problems. In the next chapter, we will explore the first
    step in making models such as these available to end users using the Flask framework.
  prefs: []
  type: TYPE_NORMAL
