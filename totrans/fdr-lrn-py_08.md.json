["```py\ngit clone https://github.com/intel/openfl.git \ncd openfl\npip install .\n```", "```py\ngit clone https://github.com/IBM/federated-learning-lib.git\ncd federated-learning-lib\npip install federated_learning_lib-*-py3-none-any.whl\n```", "```py\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nimport tensorflow_text\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\n```", "```py\nclass SSTModel(keras.Model):\n    def __init__(self):\n        super(SSTModel, self).__init__()\n        self.preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n        self.small_bert = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n        self.small_bert.trainable = False\n        self.fc1 = layers.Dense(512, activation='relu')\n        self.fc2 = layers.Dense(64, activation='relu')\n        self.fc3 = layers.Dense(1, activation='sigmoid')\n```", "```py\n    def call(self, inputs):\n        input_dict = self.preprocessor(inputs)\n        bert_output = self.small_bert(input_dict)['pooled_output']\n        output = self.fc1(keras.activations.relu(bert_output, alpha=0.2))\n        scores = self.fc3(self.fc2(output))\n\n        return scores\n```", "```py\ndef load_sst_data(client_idx=None, num_clients=1):\n    x_train = []\n    y_train = []\n    for d in tfds.load(name=\"glue/sst2\", split=\"train\"):\n        x_train.append(d['sentence'].numpy())\n        y_train.append(d['label'].numpy())\n    x_train = np.array(x_train)\n    y_train = np.array(y_train)\n```", "```py\n    x_test = []\n    y_test = []\n    for d in tfds.load(name=\"glue/sst2\", split=\"validation\"):\n        x_test.append(d['sentence'].numpy())\n        y_test.append(d['label'].numpy())\n    x_test = np.array(x_test)\n    y_test = np.array(y_test)\n```", "```py\n    if (client_idx is not None):\n        shard_size = int(x_train.size / num_clients)\n        x_train = x_train[client_idx*shard_size:(client_idx+1)*shard_size]\n        y_train = x_train[client_idx*shard_size:(client_idx+1)*shard_size]\n    return (x_train, y_train), (x_test, y_test)\n```", "```py\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sst_model import SSTModel, load_sst_data\n```", "```py\n(x_train,y_train), (x_test,y_test) = load_sst_data()\n```", "```py\nmodel.compile(\n    optimizer = keras.optimizers.Adam(learning_rate=0.0005, amsgrad=False),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\nmodel.fit(x_train, y_train, batch_size=64, epochs=3)\n```", "```py\n_, acc = model.evaluate(x_test, y_test, batch_size=64)\nprint(f\"Accuracy of model on test set: {(100*acc):.2f}%\")\n```", "```py\nimport nest_asyncio\nnest_asyncio.apply()\nimport tensorflow_federated as tff\nNUM_CLIENTS = 3\nNUM_ROUNDS = 3\n```", "```py\nclient_datasets = [load_sst_data(idx, NUM_CLIENTS)[0] for idx in range(NUM_CLIENTS)]\n```", "```py\ndef sst_model_fn():\n    sst_model = SSTModel()\n    sst_model.build(input_shape=(None,64))\n    return tff.learning.from_keras_model(\n        sst_model,\n        input_spec=tf.TensorSpec(shape=(None), dtype=tf.string),\n        loss=keras.metrics.BinaryCrossentropy()\n    )\n```", "```py\nfed_avg_process = tff.learning.algorithms.build_unweighted_fed_avg(\n    model_fn = sst_model_fn,\n    client_optimizer_fn = lambda: keras.optimizers.Adam(learning_rate=0.001),\n    server_optimizer_fn = lambda: keras.optimizers.SGD(learning_rate=1.0)\n)\n```", "```py\nstate = fed_avg_process.initialize()\nfor round in range(NUM_ROUNDS):\n    state = fed_avg_process.next(state, client_datasets).state\n```", "```py\nfed_weights = fed_avg_process.get_model_weights(state)\nfed_sst_model = SSTModel()\nfed_sst_model.build(input_shape=(None, 64))\nfed_sst_model.compile(\n    optimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\nfed_weights.assign_weights_to(fed_sst_model)\n_, (x_test, y_test) = load_sst_data()\n_, acc = fed_sst_model.evaluate(x_test, y_test, batch_size=64)\nprint(f\"Accuracy of federated model on test set: {(100*acc):.2f}%\")\n```", "```py\ndef get_sst_full(preprocessor, bert, classification_head):\n    sst_input = keras.Input(shape=(), batch_size=64, dtype=tf.string)\n    scores = classification_head(bert(preprocessor(sst_input))['pooled_output'])\n    return keras.Model(inputs=sst_input, outputs=scores, name='sst_model')\ndef get_classification_head():\n    classification_head = keras.Sequential([\n        layers.Dense(512, activation='relu', input_shape=(768,)),\n        layers.Dense(64, activation='relu', input_shape=(512,)),\n        layers.Dense(1, activation='sigmoid', input_shape=(64,))\n    ])\n    return classification_head\n```", "```py\nfrom openfl.interface.interactive_api.shard_descriptor import ShardDescriptor\nfrom openfl.interface.interactive_api.experiment import DataInterface\nimport tensorflow as tf\nfrom sst_model import load_sst_data\n```", "```py\nclass SSTShardDescriptor(ShardDescriptor):\n    def __init__(\n            self,\n            rank_worldsize: str = '1, 1',\n            **kwargs\n    ):\n        self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))\n        (x_train,y_train), (x_test,y_test) = load_sst_data(self.rank-1, self.worldsize)\n        self.data_by_type = {\n            'train': tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64),\n            'val': tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64)\n        }\n```", "```py\n    def get_shard_dataset_types(self):\n        return list(self.data_by_type)\n    def get_dataset(self, dataset_type='train'):\n        if dataset_type not in self.data_by_type:\n            raise Exception(f'Wrong dataset type: {dataset_type}')\n        return self.data_by_type[dataset_type]\n```", "```py\n    @property\n    def sample_shape(self):\n        return [\"1\"]\n    @property\n    def target_shape(self):\n        return [\"1\"]\n    @property\n    def dataset_description(self) -> str:\n        return (f'SST dataset, shard number {self.rank}'\n                f' out of {self.worldsize}')\n```", "```py\nclass SSTFedDataset(DataInterface):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n    @property\n    def shard_descriptor(self):\n        return self._shard_descriptor\n    @shard_descriptor.setter\n    def shard_descriptor(self, shard_descriptor):\n        self._shard_descriptor = shard_descriptor\n\n        self.train_set = shard_descriptor.get_dataset('train')\n        self.valid_set = shard_descriptor.get_dataset('val')\n```", "```py\n    def get_train_loader(self):\n        return self.train_set\n    def get_valid_loader(self):\n        return self.valid_set\n    def get_train_data_size(self):\n        return len(self.train_set) * 64\n    def get_valid_data_size(self):\n        return len(self.valid_set) * 64\n```", "```py\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_hub as hub\nfrom openfl.interface.interactive_api.experiment import TaskInterface\nfrom openfl.interface.interactive_api.experiment import ModelInterface\nfrom openfl.interface.interactive_api.experiment import FLExperiment\nfrom openfl.interface.interactive_api.federation import Federation\nfrom sst_model import get_classification_head, get_sst_full\nfrom sst_fl_dataset import SSTFedDataset\n```", "```py\nclient_id = 'api'\ndirector_node_fqdn = 'localhost'\ndirector_port = 50051\nfederation = Federation(\n    client_id=client_id,\n    director_node_fqdn=director_node_fqdn,\n    director_port=director_port, \n    tls=False\n)\n```", "```py\nclassification_head = get_classification_head()\noptimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False)\nloss = keras.losses.BinaryCrossentropy()\nframework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\nMI = ModelInterface(model=classification_head, optimizer=optimizer, framework_plugin=framework_adapter)\n```", "```py\nTI = TaskInterface()\n@TI.register_fl_task(model='model', data_loader='train_data', device='device', optimizer='optimizer')\ndef train(model, train_data, optimizer, device):\n    preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n    small_bert = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n    small_bert.trainable = False\n    full_model = get_sst_full(preprocessor, small_bert, model)\n    full_model.compile(loss=loss, optimizer=optimizer)\n    history = full_model.fit(train_data, epochs=1)\n    return {'train_loss':history.history['loss'][0]}\n```", "```py\n@TI.register_fl_task(model='model', data_loader='val_data', device='device')\ndef validate(model, val_data, device):\n    preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n    small_bert = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n    small_bert.trainable = False\n    full_model = get_sst_full(preprocessor, small_bert, model)\n    full_model.compile(loss=loss, optimizer=optimizer)\n    loss, acc = full_model.evaluate(val_data, batch_size=64)\n    return {'val_acc':acc, 'val_loss':loss,}\n```", "```py\nfed_dataset = SSTFedDataset()\nfl_experiment = FLExperiment(federation=federation, experiment_name='sst_experiment')\nfl_experiment.start(\n    model_provider=MI,\n    task_keeper=TI,\n    data_loader=fed_dataset,\n    rounds_to_train=3,\n    opt_treatment='CONTINUE_LOCAL'\n)\n```", "```py\nsettings:\n  listen_host: localhost\n  listen_port: 50051\n  sample_shape: [\"1\"]\n  target_shape: [\"1\"]\n```", "```py\nparams:\n  cuda_devices: []\noptional_plugin_components: {}\nshard_descriptor:\n  template: sst_fl_dataset.SSTShardDescriptor\n  params:\n    rank_worldsize: 1, 3\n```", "```py\nfx director start --disable-tls -c director_config.yaml\n```", "```py\nfx envoy start -n envoy_1 -–disable-tls --envoy-config-path envoy_config_1.yaml -dh localhost -dp 50051\nfx envoy start -n envoy_2 -–disable-tls --envoy-config-path envoy_config_2.yaml -dh localhost -dp 50051\nfx envoy start -n envoy_3 -–disable-tls --envoy-config-path envoy_config_3.yaml -dh localhost -dp 50051\n```", "```py\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sst_model import SSTModel\nsst_model = SSTModel()\noptimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False)\nloss = keras.losses.BinaryCrossentropy(),\nsst_model.compile(loss=loss, optimizer=optimizer)\nsst_input = keras.Input(shape=(), dtype=tf.string)\nsst_model(sst_input)\nsst_model.save('sst_model_save_dir')\n```", "```py\nfrom ibmfl.data.data_handler import DataHandler\nimport tensorflow as tf\nfrom sst_model import load_sst_data\n```", "```py\nclass SSTDataHandler(DataHandler):\n    def __init__(self, data_config=None):\n        super().__init__()\n        if (data_config is not None):\n            if ('client_id' in data_config):\n                self.client_id = int(data_config['client_id'])\n            if ('num_clients' in data_config):\n                self.num_clients = int(data_config['num_clients'])\n        train_data, val_data = load_sst_data(self.client_id-1, self.num_clients)\n        self.train_dataset = tf.data.Dataset.from_tensor_slices(train_data).batch(64)\n        self.val_dataset = tf.data.Dataset.from_tensor_slices(val_data).batch(64)\n```", "```py\n    def get_data(self):\n        return self.train_dataset, self.val_dataset\n```", "```py\n{\n    \"connection\": {\n        \"info\": {\n            \"ip\": \"127.0.0.1\",\n            \"port\": 5000,\n            \"tls_config\": {\n                \"enable\": \"false\"\n            }\n        },\n        \"name\": \"FlaskConnection\",\n        \"path\": \"ibmfl.connection.flask_connection\",\n        \"sync\": \"False\"\n    },\n```", "```py\n    \"fusion\": {\n        \"name\": \"IterAvgFusionHandler\",\n        \"path\": \"ibmfl.aggregator.fusion.iter_avg_fusion_handler\"\n    },\n```", "```py\n    \"hyperparams\": {\n        \"global\": {\n            \"max_timeout\": 10800,\n            \"num_parties\": 1,\n            \"perc_quorum\": 1,\n            \"rounds\": 3\n        },\n        \"local\": {\n            \"optimizer\": {\n                \"lr\": 0.0005\n            },\n            \"training\": {\n                \"epochs\": 1\n            }\n        }\n    },\n```", "```py\n    \"protocol_handler\": {\n        \"name\": \"ProtoHandler\",\n        \"path\": \"ibmfl.aggregator.protohandler.proto_handler\"\n    }\n}\n```", "```py\n{\n    \"aggregator\":\n        {\n            \"ip\": \"127.0.0.1\",\n            \"port\": 5000\n        },\n    \"connection\": {\n        \"info\": {\n            \"ip\": \"127.0.0.1\",\n            \"port\": 8085,\n            \"id\": \"party\",\n            \"tls_config\": {\n                \"enable\": \"false\"\n            }\n        },\n        \"name\": \"FlaskConnection\",\n        \"path\": \"ibmfl.connection.flask_connection\",\n        \"sync\": \"false\"\n    },\n```", "```py\n    \"data\": {\n        \"info\": {\n            \"client_id\": 0,\n            \"num_clients\": 3\n        },\n        \"name\": \"SSTDataHandler\",\n        \"path\": \"sst_data_handler\"\n    },\n    \"local_training\": {\n        \"name\": \"LocalTrainingHandler\",\n        \"path\": \"ibmfl.party.training.local_training_handler\"\n    },\n```", "```py\n    \"model\": {\n        \"name\": \"TensorFlowFLModel\",\n        \"path\": \"ibmfl.model.tensorflow_fl_model\",\n        \"spec\": {\n            \"model-name\": \"sst_model\",\n            \"model_definition\": \"sst_model_save_dir\"\n        }\n    },\n```", "```py\n    \"protocol_handler\": {\n        \"name\": \"PartyProtocolHandler\",\n        \"path\": \"ibmfl.party.party_protocol_handler\"\n    }\n}\n```", "```py\nimport argparse\nimport json\nfrom ibmfl.party.party import Party\n```", "```py\nparser = argparse.ArgumentParser()\nparser.add_argument(\"party_id\", type=int)\nargs = parser.parse_args()\nparty_id = args.party_id\nwith open('party_config.json') as cfg_file:\n    party_config = json.load(cfg_file)\nparty_config['connection']['info']['port'] += party_id\nparty_config['connection']['info']['id'] += f'_{party_id}'\nparty_config['data']['info']['client_id'] = party_id\n```", "```py\nparty = Party(config_dict=party_config)\nparty.start()\nparty.register_party()\n```", "```py\npython -m ibmfl.aggregator.aggregator agg_config.json\n```", "```py\npython fl_sim.py 1\npython fl_sim.py 2\npython fl_sim.py 3\n```", "```py\nimport argparse\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sst_model import SSTModel, load_sst_data\nimport flwr as fl\n```", "```py\nparser = argparse.ArgumentParser()\nparser.add_argument(\"client_id\", type=int)\nargs = parser.parse_args()\nclient_id = args.client_id\nNUM_CLIENTS = 3\n```", "```py\n(x_train,y_train), (x_test,y_test) = load_sst_data(client_id-1, NUM_CLIENTS)\n```", "```py\nsst_model = SSTModel()\nsst_model.compile(\n    optimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\nsst_input = keras.Input(shape=(), dtype=tf.string)\nsst_model(sst_input)\n```", "```py\nclass SSTClient(fl.client.NumPyClient):\n    def get_parameters(self, config):\n        return sst_model.get_weights()\n    def fit(self, parameters, config):\n        sst_model.set_weights(parameters)\n        history = sst_model.fit(x_train, y_train, epochs=1)\n        return sst_model.get_weights(), len(x_train), {'train_loss':history.history['loss'][0]}\n```", "```py\n    def evaluate(self, parameters, config):\n        sst_model.set_weights(parameters)\n        loss, acc = sst_model.evaluate(x_test, y_test, batch_size=64)\n        return loss, len(x_train), {'val_acc':acc, 'val_loss':loss}\n```", "```py\nfl.client.start_numpy_client(server_address=\"[::]:8080\", client=SSTClient())\n```", "```py\nimport flwr as fl\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sst_model import SSTModel\nMAX_ROUNDS = 3\n```", "```py\nclass SaveKerasModelStrategy(fl.server.strategy.FedAvg):\n    def aggregate_fit(self, server_round, results, failures):\n        agg_weights = super().aggregate_fit(server_round, results, failures)\n        if (server_round == MAX_ROUNDS):\n            sst_model = SSTModel()\n            sst_input = keras.Input(shape=(), dtype=tf.string)\n            sst_model(sst_input)\n\n            sst_model.set_weights(fl.common.parameters_to_ndarrays(agg_weights[0]))\n            sst_model.save('final_agg_sst_model')\n        return agg_weights\n```", "```py\nfl.server.start_server(strategy=SaveKerasModelStrategy(), config=fl.server.ServerConfig(num_rounds=MAX_ROUNDS))\n```", "```py\npython fl_sim.py 1\npython fl_sim.py 2\npython fl_sim.py 3\n```", "```py\n{\n    \"model_path\": \"./data/agent\",\n    \"aggr_ip\": \"localhost\",\n    \"reg_port\": \"8765\",\n    \"token\": \"stadle12345\",\n    \"base_model\": {\n        \"model_fn\": \"SSTModel\",\n        \"model_fn_src\": \"sst_model\",\n        \"model_format\": \"Keras\",\n        \"model_name\": \"Keras-SST-Model\"\n    }\n}\n```", "```py\nimport argparse\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sst_model import SSTModel, load_sst_data\nfrom stadle import BasicClient\n```", "```py\nparser = argparse.ArgumentParser()\nparser.add_argument(\"client_id\", type=int)\nargs = parser.parse_args()\nclient_id = args.client_id\nNUM_CLIENTS = 3\n(x_train,y_train), (x_test,y_test) = load_sst_data(client_id-1, NUM_CLIENTS)\n```", "```py\nstadle_client = BasicClient(config_file=\"config_agent.json\", agent_name=f\"sst_agent_{client_id}\")\n```", "```py\nfor round in range(3):\n    sst_model = stadle_client.wait_for_sg_model()\n    history = sst_model.fit(x_train, y_train, epochs=1)\n    loss = history.history['loss'][0]\n    stadle_client.send_trained_model(sst_model, {'loss_training': loss})\nstadle_client.disconnect()\n```", "```py\nstadle upload_model --config_path config_agent.json\n```", "```py\npython fl_sim.py 1\npython fl_sim.py 2\npython fl_sim.py 3\n```", "```py\nclasses = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck')\nclass_id_map = {\n    1: classes[:3],\n    2: classes[3:6],\n    3: classes[6:]\n}\nsel_count = 1.0, def_count = 0.2\n```", "```py\nclass_counts = int(def_count * 5000) * np.ones(len(classes))\nfor c in classes:\n    if c in class_rank_map[self.rank]:\n        class_counts[trainset.class_to_idx[c]] = int(sel_count * 5000)\nclass_counts_ref = np.copy(class_counts)\nimbalanced_idx = []\nfor i,img in enumerate(trainset):\n    c = img[1]\n    if (class_counts[c] > 0):\n        imbalanced_idx.append(i)\n        class_counts[c] -= 1\ntrainset = torch.utils.data.Subset(trainset, imbalanced_idx)\n```", "```py\n        train_dataset, val_dataset = self.load_cifar_data()\n        self.data_by_type = {\n            'train': train_dataset,\n            'val': val_dataset\n        }\n```", "```py\n    @property\n    def sample_shape(self):\n        return [\"32\", \"32\"]\n    @property\n    def target_shape(self):\n        return [\"10\"] \n```", "```py\nmodel = vgg16()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\ncriterion = nn.CrossEntropyLoss()\nframework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\nMI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n```", "```py\nsettings:\n  listen_host: localhost\n  listen_port: 50051\n  sample_shape: [\"32\",\"32\"]\n  target_shape: [\"10\"]\n```", "```py\nimport torch\nfrom torchvision.models import vgg16\nmodel = vgg16()\ntorch.save(model, 'saved_vgg_model.pt')\n```", "```py\n    \"model\": {\n        \"name\": \"PytorchFLModel\",\n        \"path\": \"ibmfl.model.pytorch_fl_model\",\n        \"spec\": {\n            \"model-name\": \"vgg_model\",\n            \"model_definition\": \"saved_vgg_model.pt\",\n            \"optimizer\": \"optim.SGD\",\n            \"criterion\": \"nn.CrossEntropyLoss\"\n        }\n    },\n```", "```py\nclass CifarClient(fl.client.NumPyClient):\n    def get_parameters(self, config):\n        return [val.numpy() for _, val in model.state_dict().items()]\n    def set_parameters(self, parameters):\n        params_dict = zip(model.state_dict().keys(), parameters)\n        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n        model.load_state_dict(state_dict)\n```", "```py\nfl.client.start_numpy_client(\n    server_address=\"[::]:8080\",\n    client=CifarClient(),\n    grpc_max_message_length=1024**3\n)\n```", "```py\n        if (server_round == MAX_ROUNDS):\n            vgg_model = vgg16()\n\n            np_weights = fl.common.parameters_to_ndarrays(agg_weights[0])\n            params_dict = zip(vgg_model.state_dict().keys(), np_weights)\n            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n\n            torch.save(state_dict, \"final_agg_vgg_model.pt\")\n```", "```py\nfl.server.start_server(\n    strategy=SavePyTorchModelStrategy(),\n    config=fl.server.ServerConfig(num_rounds=MAX_ROUNDS),\n    grpc_max_message_length=1024**3\n)\n```", "```py\n{\n    \"model_path\": \"./data/agent\",\n    \"aggr_ip\": \"localhost\",\n    \"reg_port\": \"8765\",\n    \"token\": \"stadle12345\",\n    \"base_model\": {\n        \"model_fn\": \"vgg16\",\n        \"model_fn_src\": \"torchvision.models\",\n        \"model_format\": \"PyTorch\",\n        \"model_name\": \"PyTorch-VGG-Model\"\n    }\n}\n```", "```py\n    stadle_client = BasicClient(config_file=\"config_agent.json\")\n    for epoch in range(num_epochs):\n        state_dict = stadle_client.wait_for_sg_model().state_dict()\n        model.load_state_dict(state_dict)\n        # Normal training code...\n        if (epoch % 2 == 0):\n            stadle_client.send_trained_model(model)\n```"]