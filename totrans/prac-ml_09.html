<html><head></head><body><div class="chapter" title="Chapter&#xA0;9.&#xA0;Bayesian learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch09"/>Chapter 9. Bayesian learning</h1></div></div></div><p>In this chapter, we will go back to covering an important, statistical-based method of learning called the Bayesian method learning, and in particular, the Naïve Bayes algorithm among others. The statistical models generally have an explicit probability model, which reveals the probability of an instance belonging to a particular class rather than just classification while solving a classification problem. Before taking a deep dive into the Bayesian learning, you will learn some important concepts under statistics such as probability distribution and the Bayes theorem which is the heart of Bayesian learning.</p><p>Bayesian learning is a supervised learning technique where the goal is to build a model of the distribution of class labels that have a concrete definition of the target attribute. Naïve Bayes is based on applying Bayes' theorem with the <span class="emphasis"><em>naïve</em></span> assumption of independence between each and every pair of features.</p><p>You will learn the basics and advanced concepts of this technique and get hands-on implementation guidance in using Apache Mahout, R, Julia, Apache Spark, and Python to implement the means - clustering algorithm.</p><p>The following figure depicts different learning models covered in this book, and the technique highlighted will be dealt with in detail in this chapter:</p><div class="mediaobject"><img src="graphics/B03980_09_01.jpg" alt="Bayesian learning"/></div><p>The topics listed here are covered in depth in this chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An overview of Bayesian statistics and core principles or concepts of probability, distribution, and other relevant statistical measures</li><li class="listitem" style="list-style-type: disc">Bayes' theorem and its mechanics</li><li class="listitem" style="list-style-type: disc">Deep dive into the Naïve Bayes algorithm and variations of Naïve Bayes classifiers like multinomial and Bernoulli classifiers</li><li class="listitem" style="list-style-type: disc">A detailed explanation of some real-world problems or use cases that the Bayesian learning technique can address</li><li class="listitem" style="list-style-type: disc">Sample implementation using Apache Mahout, R, Apache Spark, Julia, and Python (scikit-learn) libraries and modules</li></ul></div><div class="section" title="Bayesian learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec45"/>Bayesian learning</h1></div></div></div><p>Under supervised <a id="id916" class="indexterm"/>learning techniques, the learning models that are categorized under statistical methods are instance-based learning methods and the Bayesian learning method. Before we understand the Bayesian learning method, we will first cover an overview of concepts of probabilistic modeling and Bayesian statistics that are relevant in the context of Machine learning. The core concepts of statistics are very deep, and what will be covered in the next few sections is primarily focused on equipping you with a basic understanding of the dynamic and diverse field of probabilistic Machine learning, which is sufficient to interpret the functioning of the Bayesian learning methods.</p><div class="section" title="Statistician's thinking"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec105"/>Statistician's thinking</h2></div></div></div><p>The objective of statisticians<a id="id917" class="indexterm"/> is to answer questions asked by people from various domains using data. The typical engineering methods use some subjective/objective methods that do not require data to answer the questions. But, statisticians always look at the data to answer questions. They also incorporate variability (the probability that measurements taken on the exact quantity at two different times will slightly differ) in all their models.</p><p>Let's take an example: <span class="emphasis"><em>was M.F. Hussain a good painter?</em></span> One method of answering this question measures the paintings based on some accepted norms (by the person or community) of the quality of paintings. The answer in such a case may be based on creative expression, color usage, form, and shape. <span class="emphasis"><em>I believe M.F. Hussain is a good painter.</em></span> In this case, this response can be fairly subjective (which means that the response you get from one person can be very different from the response you get from another). The statistician's method of answering this is very different. They first collect the data from a sample of people who are considered experts in assessing the quality of paintings (university professors of art, other artists, art collectors, and more). Then, after analyzing the data, they will come up with a conclusion such as: "75% of the university professors of arts, 83% of the professional artists, and 96% of the art collectors from the data of 3000 participants of the survey (with equal number of participants from each category) opined that Mr. M.F. Hussain is <a id="id918" class="indexterm"/>a good painter". Hence, it can be stated that he is considered a good painter by most. Very obviously, this is a very objective measure.</p><div class="section" title="Important terms and definitions"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec94"/>Important terms and definitions</h3></div></div></div><p>The following are the essential parameters and concepts that are used to assess and understand the data. They are explained as definitions in some cases and with examples and formulae in others. They are classified as "vocabulary" and "statistical quantities". You will come across some of these terms in the next sections of this chapter:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Term</p>
</th><th style="text-align: left" valign="bottom">
<p>Definition</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Population</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the<a id="id919" class="indexterm"/> universe of data. Typically, statisticians want to make a prediction about a group of objects (Indians, galaxies, countries, and more). All the members of the group are called the population.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Sample</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>Most of the times, it is not feasible to work on the entire population. So, statisticians collect a representative sample from the population and do all their calculations on them. The subset of the population that is chosen for the analysis is called<a id="id920" class="indexterm"/> a <span class="strong"><strong>sample</strong></span>. It is always cheaper to compile the sample compared to the population or census. There are several techniques to collect samples:</p>
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Stratified sampling</strong></span>: This is<a id="id921" class="indexterm"/> defined as<a id="id922" class="indexterm"/> the process of dividing the members of the population into homogeneous subgroups before sampling. Each subgroup should be mutually exclusive, and every element of the population should be assigned to a subgroup.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Cluster sampling</strong></span>: This method of sampling ensure n unique clusters where each cluster has elements with no repetition.</li></ul></div>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Sample size</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>This is an<a id="id925" class="indexterm"/> obvious dilemma that every statistician has been through. How big should be the size of the sample? The bigger the sample, the higher will be the accuracy. However, the cost of collection and analysis also rise accordingly. So, the challenge is to find an optimum sample size where the results are accurate, and the costs are lower.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Sampling Bias</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>Bias is a <a id="id926" class="indexterm"/>systematic error that impacts the outcome in some way. Sampling bias is a consistent error that arises due to the sample selection.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Variable</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>It is <a id="id927" class="indexterm"/>one of the measurements of the sample or population. If we are taking all the members of a class, then their age, academic background, gender, height, and so on, become the variables. Some variables are independent. This means they do not depend on any other variable. Some are dependent.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Randomness</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>An <a id="id928" class="indexterm"/>event is called random if its outcome is uncertain before it happens. An example of a random event is the value of the price of gold tomorrow afternoon at 1 P.M.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Mean</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>It is equal to<a id="id929" class="indexterm"/> the sum of all the values in the sample divided by the total number of observations in the sample.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Median</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>Median <a id="id930" class="indexterm"/>is a midpoint value between the lowest and highest value of a data set. This is also called the second quartile (designated Q2) = cuts data set in half = 50<sup>th</sup> percentile. If there is no exact midpoint (that is, the observations in the sample are even), then the median is the average of the two points in the middle.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Mode</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the <a id="id931" class="indexterm"/>most frequently occurring value of the variable. A data can be unimodal (single mode), or multimodal (frequent multiple values). If the data obeys normal distribution (about which you will learn later), the mode is obtained using the empirical formula:</p>
<p>
<span class="emphasis"><em>mean – mode = 3 x (mean - median)</em></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Standard deviation</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>It is an <a id="id932" class="indexterm"/>average measure of how much each measurement in the sample deviates from the mean. Standard deviation is also called the standard deviation of the mean.</p>
<div class="mediaobject"><img src="graphics/B03980_09_15.jpg" alt="Important terms and definitions"/></div>
</td></tr></tbody></table></div></div><div class="section" title="Probability"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec95"/>Probability</h3></div></div></div><p>Before we start understanding the <a id="id933" class="indexterm"/>probability, let's first look at why we need to consider uncertainty in the first place. Any real-life action is always associated with the uncertainty of the result or the outcome. Let's take some examples; will I be able to catch the train on time today? Will the sales of our top-selling product continue to be in the top position this quarter? If I toss a coin, will I get a heads or tails? Will I be able to go to the airport in <span class="emphasis"><em>t</em></span> minutes?</p><p>There can be many <a id="id934" class="indexterm"/>sources of uncertainty:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Uncertainty due to lack of knowledge, as a result of insufficient data, incomplete analysis, and inaccurate measurements</li><li class="listitem" style="list-style-type: disc">Otherwise, uncertainty can also be due to complexity, as a result of incomplete processing conditions</li></ul></div><p>In the real world, we need to use probabilities and uncertainties to summarize our lack of knowledge and ability to predict an outcome.</p><p>Let's elaborate on the last previous example.</p><p>Can I go to the airport in 25 minutes? There could be many problems, such as incomplete observations on the road conditions, noisy sensors (traffic reports), or uncertainty in action, say a flat tire or complexity in modeling the traffic. To predict the outcome, there should definitely be some assumptions made, and we need to deal with uncertainty in a principled way; this is called <a id="id935" class="indexterm"/>
<span class="strong"><strong>probability</strong></span>. In short, probability is a study of randomness and uncertainty.</p><p>In probability, an experiment is something that can be repeated and has uncertainty in the result. A single outcome of an experiment is referred to as a single event, and an event is a collection of outcomes. A <span class="strong"><strong>sample space</strong></span> probability<a id="id936" class="indexterm"/> is a list of all the possible outcomes of an experiment.</p><p>The probability of the event <span class="emphasis"><em>E</em></span> is represented as <span class="emphasis"><em>P(E)</em></span> and is defined as the likelihood of this event occurring.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note06"/>Note</h3><p>The Probability of an Event P(E) = the number of ways an event can happen / the number of possible outcomes</p></div></div><p>For example, for a coin that is tossed, there are two possibilities: heads or tails.</p><p>The probability of heads is <span class="emphasis"><em>P(H) = ½ = 0.5</em></span>
</p><p>When a dice is thrown, there are six possibilities, which are 1, 2, 3, 4, 5, and 6.</p><p>The probability of 1 is <span class="emphasis"><em>P(1) = 1/6 = 0.16667</em></span>
</p><p>The probability of rolling any event, <span class="emphasis"><em>E</em></span>, <span class="emphasis"><em>P(E)</em></span>, must be between <span class="emphasis"><em>0</em></span> and <span class="emphasis"><em>1</em></span> (inclusive).</p><p>0 ≤ P(E) ≤ 1</p><p>The value of <span class="emphasis"><em>0</em></span> for probability indicates that an event is impossible, and the value of <span class="emphasis"><em>1</em></span> indicates the certainty of the event. If there are <span class="emphasis"><em>n</em></span> events, then the summation of the probability of each event is <span class="emphasis"><em>1</em></span>. This can be represented as:</p><p>If <span class="emphasis"><em>S = {e1, e2, ….en}</em></span> then <span class="emphasis"><em>P(e1) +P(e2)+…P(en) = 1</em></span>
</p><p>There are many ways to<a id="id937" class="indexterm"/> determine the probability:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Classical method</strong></span>: This is the<a id="id938" class="indexterm"/> method that we used to define probability in the previous section. This method requires equally likely outcomes. So, if an experiment has equally likely <span class="emphasis"><em>n</em></span> events and there are <span class="emphasis"><em>m</em></span> possibilities, the event <span class="emphasis"><em>E</em></span> can then occur.<p>P(E) = the number of ways the event E can occur / the number of possible outcomes = m/n.</p><p>For example, a bag of chocolates contains five brown covered chocolates, six yellow covered chocolates, two red covered chocolates, eight orange covered chocolates, two blue covered chocolates, and seven green covered chocolates. Suppose that a candy is randomly selected. What is the probability of a candy being brown?</p><p>
<span class="emphasis"><em>P (B) = 5/30</em></span>
</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Empirical method</strong></span>: The empirical method<a id="id939" class="indexterm"/> of probability computation is also called relative frequency, as this formula requires the number of times an experiment is repeated. This method defines the probability of the event <span class="emphasis"><em>E</em></span>, which is the number of times an event is observed over the total number of times the experiment is repeated. The basis on which the probability is computed in this case is<a id="id940" class="indexterm"/> either observations or experiences.<p>P(E) = Frequency of E / the number of trials of the experiment.</p><p>For example, we want to compute the probability of a grad student to pick medicine as their major. We pick, let's say, a sample of 200 students and 55 of them pick medicine as majors, then:</p><p>
<span class="emphasis"><em>P(someone picking medicine) = 55/200 = 0.275</em></span>
</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Subjective method</strong></span>: This method<a id="id941" class="indexterm"/> of probability uses some fair and computed, or educated assumptions. It usually describes an individual's perception of the likelihood of an event to occur. This means the individual's degree of belief in the event is considered, and thus can be biased. For example, there is a 40% probability that the physics professor would not turn up to take the class.</li></ul></div><div class="section" title="Types of events"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec27"/>Types of events</h4></div></div></div><p>Events can be mutually <a id="id942" class="indexterm"/>exclusive, independent, or dependent in nature.</p><div class="section" title="Mutually exclusive or disjoint events"><div class="titlepage"><div><div><h5 class="title"><a id="ch09lvl5sec10"/>Mutually exclusive or disjoint events</h5></div></div></div><p>Mutually exclusive <a id="id943" class="indexterm"/>events <a id="id944" class="indexterm"/>are the events that<a id="id945" class="indexterm"/> cannot happen at the same time. In <a id="id946" class="indexterm"/>short, the probability of the two events occurring at the same time is <span class="emphasis"><em>0</em></span>. <span class="emphasis"><em>P(1)</em></span> and <span class="emphasis"><em>P(5)</em></span>. When a dice is rolled, there are mutually exclusive events. A Venn diagram representation of mutually exclusive events is depicted here:</p><div class="mediaobject"><img src="graphics/B03980_09_02.jpg" alt="Mutually exclusive or disjoint events"/></div><p>For mutually<a id="id947" class="indexterm"/> exclusive <a id="id948" class="indexterm"/>events A and<a id="id949" class="indexterm"/> B the Addition rule is:</p><p>P(A or B) = P(A) + P(B)</p><p>For mutually exclusive events <a id="id950" class="indexterm"/>A and B the Multiplication rule is:</p><p>P(A and B) = P(A) x P(B)</p></div><div class="section" title="Independent events"><div class="titlepage"><div><div><h5 class="title"><a id="ch09lvl5sec11"/>Independent events</h5></div></div></div><p>If the outcome of one <a id="id951" class="indexterm"/>event does not impact the outcome of another event, the two events are called <a id="id952" class="indexterm"/>independent events. For example, event A is that it rained on Sunday, and event B is the car having a flat tire. These two events are not related and the probability of one does not impact the other. An independent event can be mutually exclusive but not vice versa.</p><p>Multiplication rule in the case of independent events A and B is:</p><p>P(A and B) = P(A) x P(B)</p></div><div class="section" title="Dependent events"><div class="titlepage"><div><div><h5 class="title"><a id="ch09lvl5sec12"/>Dependent events</h5></div></div></div><p>Dependent <a id="id953" class="indexterm"/>events are the<a id="id954" class="indexterm"/> events where the occurrence of one event can influence the occurrence of another event. For example, a student who takes English as their first major can take political science as the second major. The Venn representation of dependent events is depicted here:</p><div class="mediaobject"><img src="graphics/B03980_09_03.jpg" alt="Dependent events"/></div><p>Addition rule for dependent event A and B is:</p><p>P(A or B) = P(A) + P(B) – P(A and B)</p><p>Multiplication <a id="id955" class="indexterm"/>rule for <a id="id956" class="indexterm"/>dependent event A and B is:</p><p>P(A and B) = P(A) x P(B)</p></div></div></div><div class="section" title="Types of probability"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec96"/>Types of probability</h3></div></div></div><p>In this section, we will take a look at<a id="id957" class="indexterm"/> the different types of probabilities, which are listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Prior and posterior probability</strong></span>: Prior probability<a id="id958" class="indexterm"/> is the<a id="id959" class="indexterm"/> probability that an event <a id="id960" class="indexterm"/>E occurs without any prior information or knowledge of any assumptions in the problem context.<p>Let's take an example. If your friend was travelling by air and you were asked if they have a man or a woman as their neighbor, as the basis formula of probability works, there is a 0.5 (50%) probability that it can be a man and a 0.5 (50%) probability that it can be a woman. These values can change when more information is provided, and the probability that is measured then is called the<a id="id961" class="indexterm"/> posterior probability.</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Conditional probability</strong></span>: Conditional probability<a id="id962" class="indexterm"/> is defined as <a id="id963" class="indexterm"/>the probability that an event occurs, given another event already occurred. <span class="emphasis"><em>P(B|A)</em></span> is interpreted as the probability of event B, given event A.<p>For example, let's compute the probability that a person will be hit by a car while walking on the road. Let <span class="emphasis"><em>H</em></span> be a discrete random variable describing the probability of a person being hit by a car, taking the hit as 1 and not as 0.</p><p>Let <span class="emphasis"><em>L</em></span> be a discrete random variable describing the probability of the cross traffic's traffic light state at a given moment, taking one from <span class="emphasis"><em>{red, yellow, green}</em></span>:</p><p>
<span class="emphasis"><em>P(L=red) = 0.7,</em></span>
</p><p>
<span class="emphasis"><em>P(L=yellow) = 0.1,</em></span>
</p><p>
<span class="emphasis"><em>P(L=green) = 0.2.</em></span>
</p><p>
<span class="emphasis"><em>P(H=1|L=R) = 0.99,</em></span>
</p><p>
<span class="emphasis"><em>P(H|L=Y) = 0.9 and</em></span>
</p><p>
<span class="emphasis"><em>P(H|L=G) = 0.2.</em></span>
</p><p>Using the <a id="id964" class="indexterm"/>conditional probability formulae, we get the following:</p><p>
<span class="emphasis"><em>P(H=1 and L=R) = P(L=R)*P(H|L=R) = 0.693;</em></span>
</p><p>
<span class="emphasis"><em>P(H=1 and L=Y) = 0.1*0.9 = 0.09</em></span>
</p><p>Similarly, if the <a id="id965" class="indexterm"/>probability of getting hit while red is on is 0.99, the probability of not getting hit is 0.01. So, <span class="emphasis"><em>P(H=0|L=R) = 0.01</em></span>. From these, we can compute the probability of <span class="emphasis"><em>H=0</em></span> and <span class="emphasis"><em>L=R</em></span>.</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Joint probability</strong></span>: Joint probability<a id="id966" class="indexterm"/> is the probability of two or more things <a id="id967" class="indexterm"/>happening together. In a two variable case, <span class="emphasis"><em>f(x,y|θ)</em></span> is the joint probability distribution, where <span class="emphasis"><em>f</em></span> is the probability of <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> together as a pair, given the distribution parameters—<span class="emphasis"><em>θ</em></span>. For discrete random variables, the joint probability mass function is:<p>P(X and Y) = P(X).P(Y|X) =P(Y).P(X|Y)</p><p>You already saw this while studying the conditional probability. Since these are probabilities, we have the following:</p><div class="mediaobject"><img src="graphics/B03980_09_16.jpg" alt="Types of probability"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Marginal probability</strong></span>: Marginal probability<a id="id968" class="indexterm"/> is <a id="id969" class="indexterm"/>represented by <span class="emphasis"><em>f(x|θ)</em></span> where <span class="emphasis"><em>f</em></span> is the probability density of <span class="emphasis"><em>x</em></span> for all the possible values of <span class="emphasis"><em>y</em></span>, given the distribution parameters—<span class="emphasis"><em>θ</em></span>. The marginal probability in a random distribution is determined from the joint distribution of <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> by summing over all the values of <span class="emphasis"><em>y</em></span>. In a continuous distribution, it is determined by integrating over all the values of <span class="emphasis"><em>y</em></span>. This is called<a id="id970" class="indexterm"/> <span class="strong"><strong>integrating out</strong></span> the variable <span class="emphasis"><em>y</em></span>. For discrete random variables, the marginal <a id="id971" class="indexterm"/>probability mass function can be written as <span class="emphasis"><em>P(X = x)</em></span>. This is as follows:<div class="mediaobject"><img src="graphics/B03980_09_17.jpg" alt="Types of probability"/></div><p>From the above <a id="id972" class="indexterm"/>equation, <span class="emphasis"><em>P(X = x,Y = y)</em></span> is the <a id="id973" class="indexterm"/>joint distribution of <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span>, and <span class="emphasis"><em>P(X = x|Y = y)</em></span> is the conditional distribution of <span class="emphasis"><em>X</em></span>, given <span class="emphasis"><em>Y</em></span>. The variable <span class="emphasis"><em>Y</em></span> is marginalized out. These bivariate marginal and joint probabilities for discrete random variables are often displayed as two-way tables (as illustrated next). We will show the computations in a worked out problem in the next section.</p><p>For example, suppose two dices are rolled, and the sequence of scores <span class="emphasis"><em>(X1, X2)</em></span> is recorded. Let <span class="emphasis"><em>Y=X1+X2</em></span> and <span class="emphasis"><em>Z=X1−X2</em></span> denote the sum and difference of the scores respectively. Find the probability density function of <span class="emphasis"><em>(Y, Z)</em></span>. Find the probability density function of <span class="emphasis"><em>Y</em></span>. Find the probability density function of <span class="emphasis"><em>Z</em></span>. Are <span class="emphasis"><em>Y</em></span> and <span class="emphasis"><em>Z</em></span> independent?</p><p>Assuming that <span class="emphasis"><em>X1</em></span> and <span class="emphasis"><em>X2</em></span> are independent, they can take 36 possibilities, as shown in the table here:</p><div class="mediaobject"><img src="graphics/B03980_09_04.jpg" alt="Types of probability"/></div></li></ul></div><p>Let's now construct the<a id="id974" class="indexterm"/> joint, marginal, and conditional table. In this, we <a id="id975" class="indexterm"/>will have values of <span class="emphasis"><em>Z</em></span> as rows and <span class="emphasis"><em>Y</em></span> as columns. <span class="emphasis"><em>Y</em></span> varies from 2 to 12 and <span class="emphasis"><em>Z</em></span> varies from -5 to 5. We can fill all the conditional distributions just by counting. For example, take <span class="emphasis"><em>Z=-1</em></span>; we see that this happens when <span class="emphasis"><em>Y=3, 5, 7, 9, 11</em></span>. We also note that the probability of each one of them (say, the conditional probability that <span class="emphasis"><em>Z=-1</em></span>, given <span class="emphasis"><em>Y=3</em></span>) is <span class="emphasis"><em>1/36</em></span>. We can fill the table like this for all the values:</p><div class="mediaobject"><img src="graphics/B03980_09_05.jpg" alt="Types of probability"/></div><p>So, the bottom row is the <a id="id976" class="indexterm"/>marginal distribution of <span class="emphasis"><em>Y</em></span>. The right-most column <a id="id977" class="indexterm"/>is the marginal distribution of <span class="emphasis"><em>Z</em></span>. The total table is the joint distribution. Clearly, they are dependent.</p></div><div class="section" title="Distribution"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec97"/>Distribution</h3></div></div></div><p>Distributions<a id="id978" class="indexterm"/> are either discrete or continuous probability distributions, depending on whether they define probabilities associated with discrete variables or continuous variables:</p><div class="mediaobject"><img src="graphics/B03980_09_06.jpg" alt="Distribution"/></div><p>We will cover a few of the previously mentioned distributions here.</p><p>In this section, our<a id="id979" class="indexterm"/> major emphasis is on modeling and describing a given property of the data. To understand how crucial this skill is, let's look at a few examples:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A bank wants to look at the amount of cash withdrawn per transaction in an ATM machine over a period of time to determine the limits of transaction</li><li class="listitem" style="list-style-type: disc">A retailer wants to understand the number of broken toys that he is getting in every shipment</li><li class="listitem" style="list-style-type: disc">A manufacturer wants to understand how the diameter of a probe is varying between various manufacturing cycles</li><li class="listitem" style="list-style-type: disc">A pharmaceutical company wants to understand how the blood pressures of millions of patients are impacted by its new drug</li></ul></div><p>In all these cases, we need to come up with some precise quantitative description of how the observed quantity is behaving. This section is all about this. Anyway, intuitively, what do you think are the qualities that you would like to measure to gain an understanding?</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">What are all the values that a given variable is taking?</li><li class="listitem" style="list-style-type: disc">What is the probability of taking a given value and what values have the highest probability?</li><li class="listitem" style="list-style-type: disc">What is the mean/median, and how much is the variance?</li><li class="listitem" style="list-style-type: disc">Given a value, can we tell how many observations fall into it and how many fall away from it?</li><li class="listitem" style="list-style-type: disc">Can we give a range of values where we can tell 90% of the data lies?</li></ul></div><p>Actually, if we can answer these questions, and more importantly if we develop a technique to describe such quantities, we are more or less unstoppable as far as this property is considered!</p><p>There are two prime observations to be made here. First, a property when distributed the way it is has all the qualities it takes to be a random variable (knowing one value of the quantity does not help us know the next value). Then, if we know the probability mass function or the distribution function of this random variable, we can compute all the previous matter. This is why it is so important to understand mathematics. In general, we follow (for that matter, almost anybody interested in analyzing the data that follows) a systematic process in describing a quantity:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">We will first understand the random variable.</li><li class="listitem">Next, we will compute the probability mass (or distribution) function.</li><li class="listitem">Then, we will predict the all-important parameters (mean and variance).</li><li class="listitem">Then, we will check with experimental data to see how good our approximations are.</li></ol></div><p>For example, the <a id="id980" class="indexterm"/>number of vans that have been requested for rental at a car rental agency during a 50-day period is identified in the following table. The observed frequencies have been converted into probabilities for this 50-day period in the last column of the table:</p><div class="mediaobject"><img src="graphics/B03980_09_07.jpg" alt="Distribution"/></div><p>The expected value is 5.66 vans, as shown here:</p><div class="mediaobject"><img src="graphics/B03980_09_08.jpg" alt="Distribution"/></div><p>Similarly, variance computation is given next:</p><div class="mediaobject"><img src="graphics/B03980_09_09.jpg" alt="Distribution"/></div><p>The standard <a id="id981" class="indexterm"/>deviation is a square root of variance and is equal to 1.32 vans. Let's systematically analyze various distributions.</p></div><div class="section" title="Bernoulli distribution"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec98"/>Bernoulli distribution</h3></div></div></div><p>This is the simplest<a id="id982" class="indexterm"/> distribution that one<a id="id983" class="indexterm"/> can think of. Many a times, a property takes only discrete values; like a coin toss, a roll of the dice, the gender of people, and so on. Even if they are not exactly discrete, we can transform them by binning in some cases. For example, when we look at the net worth of individuals, we can redivide them as rich and<a id="id984" class="indexterm"/> poor (<span class="strong"><strong>discrete quantity</strong></span>) based on the exact wealth they<a id="id985" class="indexterm"/> have (<span class="strong"><strong>continuous quantity</strong></span>). Let's say that the probability of the property taking a given value is <span class="emphasis"><em>p</em></span> (of course, the probability of it not taking is <span class="emphasis"><em>(1-p)</em></span>). If we collect the large sample sufficiently, then how does the dataset look? Well, there will be some positives (where the variable took the value) and negatives (where the variable does not take the value). Assume that we denote positive with 1 and negative with 0.</p><p>Then, we have the following:</p><p>The mean = weighted average of probabilities = 1*p +0*(1-p) = p</p></div><div class="section" title="Binomial distribution"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec99"/>Binomial distribution</h3></div></div></div><p>This is an <a id="id986" class="indexterm"/>extension of the <a id="id987" class="indexterm"/>Bernoulli idea. Let's take a specific example. You are working in a population bureau and have the data of all the families in a state. Let's say you want to identify the probability of having two male children in families that have exactly two children. As you can see, a family can have two children in only four different ways: MM, MF, FM, and FF. As we consider having a male child as the event of interest, then the probability that there are only male children is <span class="emphasis"><em>0.25 (1/4)</em></span>. The probability of there being one male child is <span class="emphasis"><em>0.5 (0.25+0.25) (1/4+1/4),</em></span> and no male child is <span class="emphasis"><em>0.25 (1/4)</em></span>.</p><p>So, if you <a id="id988" class="indexterm"/>look at 100 families, what is the probability that <a id="id989" class="indexterm"/>20 families have exactly two male children? We will come to the solution later. Let's extend the argument to find the probability of having all the males in families with three children: The total possibilities are FFF, FFM, FMF, FMM, MFM, MMF, MFF, and MMM (eight total possibilities). The probability for all three to be male is <span class="emphasis"><em>1/8</em></span>. The probability for two of the three being male is <span class="emphasis"><em>3/8</em></span>. The probability for one of the three to be male is <span class="emphasis"><em>3/8</em></span>. The probability for none to be male is <span class="emphasis"><em>1/8</em></span>. Note that the total probability of all the events is always equal to 1.</p><div class="section" title="Poisson probability distribution"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec28"/>Poisson probability distribution</h4></div></div></div><p>Now, let's try to extend the<a id="id990" class="indexterm"/> Binomial theorem to infinite <a id="id991" class="indexterm"/>trials, but with a catch. The examples that we have taken (coin toss and more) have an interesting property. The probability of the event occurring in a trial does not change even if we increase the number of trials. However, there are a great number of examples, whereas the number of trials (or its equivalent) increases, the corresponding probability of the event decreases. So, we need to reduce the time interval to zero, or the number of observations to infinity to ensure that we see only a single success or failure in any trial. In this limiting case, the probability that we see <span class="emphasis"><em>r</em></span> successes in <span class="emphasis"><em>n</em></span> observations can be computed as follows:</p><div class="mediaobject"><img src="graphics/B03980_09_18.jpg" alt="Poisson probability distribution"/></div><p>The probability distribution of a Poisson random variable <span class="emphasis"><em>X</em></span> is as given below. This considers representing the number of successes occurring in a given time interval:</p><div class="mediaobject"><img src="graphics/B03980_09_19.jpg" alt="Poisson probability distribution"/></div><p>Here, <span class="emphasis"><em>r</em></span> is the <span class="emphasis"><em>r</em></span><sup>th</sup> trial <a id="id992" class="indexterm"/>and <span class="emphasis"><em>λ</em></span> = a mean number of<a id="id993" class="indexterm"/> successes in the given time interval or the region of space.</p></div><div class="section" title="Exponential distribution"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec29"/>Exponential distribution</h4></div></div></div><p>Let's now look at the Poisson <a id="id994" class="indexterm"/>example and ask ourselves <a id="id995" class="indexterm"/>a different question. What is the probability that the inspector does not see the first car until <span class="emphasis"><em>t</em></span> hours? In this case, it may not be relevant, but when we work on the failure of a component, it makes sense to understand what time the probability of not seeing the failure is high. So, let's say the sighting of the car (or first failure) follows the Poisson process. Then, let's define <span class="emphasis"><em>L</em></span>, a random variable that is the probability that the inspector will not see the first car until time <span class="emphasis"><em>t</em></span> as the time before the first sighting of the car. From the Poisson distribution, the probability that she will not see the first car in 1 hour is as follows:</p><div class="mediaobject"><img src="graphics/B03980_09_20.jpg" alt="Exponential distribution"/></div><p>The probability that that she will not see a car in the second hour also is the same, and the probability that she will not see the car in <span class="emphasis"><em>t</em></span> hours is <span class="emphasis"><em>e</em></span><sup>−λt</sup><span class="emphasis"><em> (e</em></span><sup>−λ</sup> *<span class="emphasis"><em> e</em></span><sup>−λ</sup> *<span class="emphasis"><em>…times)</em></span>. The probability that she will see the car in the first <span class="emphasis"><em>t</em></span> hours then is <span class="emphasis"><em>1-e</em></span><sup>-λt</sup>.</p><p>The applications of exponential distribution are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Time to the first failure in a Poisson process</li><li class="listitem" style="list-style-type: disc">Distance of the dispersion of seeds from the parent plant</li><li class="listitem" style="list-style-type: disc">The expected lifetime of an organism, ignoring the aging process (where the end occurs due to accidents, infections, and more)</li></ul></div></div><div class="section" title="Normal distribution"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec30"/>Normal distribution</h4></div></div></div><p>Normal <a id="id996" class="indexterm"/>distribution <a id="id997" class="indexterm"/>is a very widely used class of continuous distribution. It is also often called the bell curve<a id="id998" class="indexterm"/> because the graph of its probability density resembles a bell. Most of the real-life data such as weights, heights, and more (particularly when there are large collections) can be well approximated by a normal distribution.</p><div class="mediaobject"><img src="graphics/B03980_09_10.jpg" alt="Normal distribution"/></div><p>Once we know the<a id="id999" class="indexterm"/> values of the heights, the number of <a id="id1000" class="indexterm"/>samples that have this value can be mathematically described as follows:</p><div class="mediaobject"><img src="graphics/B03980_09_21.jpg" alt="Normal distribution"/></div><p>Here, σ is the standard deviation and µ is the mean. To describe a normal distribution, we just need to know two concepts (average and SD).</p><p>Every normal curve adheres to the following <span class="emphasis"><em>rule</em></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">About 68% of the area under the curve falls within one standard deviation of the mean</li><li class="listitem" style="list-style-type: disc">About 95% of the area under the curve falls within two standard deviations of the mean</li><li class="listitem" style="list-style-type: disc">About 99.7% of the area under the curve falls within three standard deviations of the mean</li></ul></div><p>Collectively, these <a id="id1001" class="indexterm"/>points are known as the <span class="strong"><strong>empirical rule</strong></span> or <a id="id1002" class="indexterm"/>the <span class="strong"><strong>68-95-99.7 rule</strong></span>.</p></div><div class="section" title="Relationship between the distributions"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec31"/>Relationship between the distributions</h4></div></div></div><p>While we know that more or<a id="id1003" class="indexterm"/> less everything converges to a normal distribution, it is best to understand where each one fits. The following chart helps in this:</p><div class="mediaobject"><img src="graphics/B03980_09_11.jpg" alt="Relationship between the distributions"/></div></div></div></div><div class="section" title="Bayes' theorem"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec106"/>Bayes' theorem</h2></div></div></div><p>Before we go into the <a id="id1004" class="indexterm"/>Bayes' theorem, we mentioned at the beginning of this chapter what is at the Bayesian learning is the Bayes theorem.</p><p>Let's start with an example. Assume that there are two bowls of nuts; the first bowl contains 30 cashew nuts and 10 pistachios and the second bowl contains 20 of each. Let's choose one bowl randomly and pick a nut with eyes closed. The nut is cashew. Now, what is the probability that the bowl chosen is the first bowl? This is a conditional probability.</p><p>So, <span class="emphasis"><em>p(Bowl 1|cashew)</em></span> or the probability that it is bowl 1, given the nut is cashew, is not an easy and obvious one to crack.</p><p>If the question was to put the other way, <span class="emphasis"><em>p(cashew|bowl1)</em></span> or the probability that the nut is cashew, given bowl 1 is easy, <span class="emphasis"><em>p(cashew|Bowl 1) = ¾</em></span>.</p><p>As we know, <span class="emphasis"><em>p(cashew|Bowl 1)</em></span> is not the same as <span class="emphasis"><em>p(Bowl 1|cashew), </em></span>but we can use one value to get another value, and this is what Bayes' theorem is all about.</p><p>The first step of defining the Bayes' theorem conjunction is commutative; following are the steps:</p><p>
<span class="emphasis"><em>p (A and B) =p (B and A),</em></span>
</p><p>Further, the probability <a id="id1005" class="indexterm"/>of A and B is the probability of A and the probability of B, given A:</p><p>
<span class="emphasis"><em>p (A and B) = p (A) p (B|A)</em></span>, similarly</p><p>
<span class="emphasis"><em>p (B and A) = p (B) p (A|B)</em></span>
</p><p>so,</p><p>
<span class="emphasis"><em>p (A) p (B|A) = p (B) p (A|B)</em></span> and</p><div class="mediaobject"><img src="graphics/B03980_09_32.jpg" alt="Bayes' theorem"/></div><p>And that's Bayes' theorem!</p><p>It might not be very obvious, but it is a very powerful definition.</p><p>Now, let's apply this to solve the previous <span class="emphasis"><em>nut</em></span> problem to find <span class="emphasis"><em>p(bowl1 cashew)</em></span>, and we can derive it if we can get <span class="emphasis"><em>p(cashew|bowl 1)</em></span>:</p><p>
<span class="emphasis"><em>p (bowl1 cashew) = (p(bowl1) p(cashew|bowl1)) / p (cashew)</em></span>
</p><p>
<span class="emphasis"><em>p (bowl1) = ½</em></span>
</p><p>
<span class="emphasis"><em>p (cashew|bowl1) = ¾</em></span>
</p><p>
<span class="emphasis"><em>p (cashew) = total cashews / total nuts (between bowl1 and bowl2) = 50/80 = 5/8</em></span>
</p><p>Putting it together, we have the following:</p><p>
<span class="emphasis"><em>p (bowl1 cashew) = ((1/2) (3/4))/(5/8)= 3/5 = 0.6</em></span>
</p><p>The additional aspect that needs to be considered now is how to feature in the changes that come over time as the new data comes in. This way, the probability of a hypothesis can be measured in the context of the data at a given point in time. This is called the diachronic interpretation of the Bayes' theorem.</p><p>Following is the restating Bayes' theorem with the hypothesis (<span class="emphasis"><em>H</em></span>) for the given data (<span class="emphasis"><em>D</em></span>):</p><div class="mediaobject"><img src="graphics/B03980_09_22.jpg" alt="Bayes' theorem"/></div><p>
<span class="emphasis"><em>p (H)</em></span> is the probability of the hypothesis <span class="emphasis"><em>H</em></span> before seeing the data <span class="emphasis"><em>D</em></span>.</p><p>
<span class="emphasis"><em>p (D)</em></span> is the probability<a id="id1006" class="indexterm"/> of data <span class="emphasis"><em>D</em></span> under any hypothesis, which is usually constant.</p><p>
<span class="emphasis"><em>p (H|D)</em></span> is the probability of the hypothesis <span class="emphasis"><em>H</em></span> after seeing the data <span class="emphasis"><em>D</em></span>.</p><p>
<span class="emphasis"><em>p (D|H)</em></span> is the probability of data <span class="emphasis"><em>D</em></span> given the hypothesis <span class="emphasis"><em>H</em></span>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note07"/>Note</h3><p>
<span class="emphasis"><em>p (H)</em></span> is called prior probability; <span class="emphasis"><em>p (H|D)</em></span> is posterior probability; <span class="emphasis"><em>p (D|H)</em></span> is the likelihood; and <span class="emphasis"><em>p (D)</em></span> is the evidence:</p><div class="mediaobject"><img src="graphics/B03980_09_12.jpg" alt="Bayes' theorem"/></div></div></div></div><div class="section" title="Naïve Bayes classifier"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec107"/>Naïve Bayes classifier</h2></div></div></div><p>In this section, we will look at the <a id="id1007" class="indexterm"/>Naïve Bayes classifiers and how they are used to solve the classification problems. The Naïve Bayes classifier technique is based on the Bayes' theorem and assumes the predictors to be independent, which means knowing the value of one attribute does influence the value of any other attribute. The independence assumption is what makes Naïve Bayes <span class="emphasis"><em>naïve</em></span>.</p><p>Naïve Bayes classifiers are easy to build, do not involve any iterative process, and work very well with large datasets. Despite its simplicity, Naïve Bayes is known to have often outperformed other classification methods.</p><p>We need to compute the probability of an assumption given a class.</p><p>That is, <span class="emphasis"><em>P(x</em></span><sub>1</sub><span class="emphasis"><em>, x</em></span><sub>2</sub><span class="emphasis"><em>, ….x</em></span><sub>n|y</sub><span class="emphasis"><em>)</em></span>. Obviously, there are multiple pieces of evidence represented by <span class="emphasis"><em>x</em></span><sub>1</sub>, <span class="emphasis"><em>x</em></span><sub>2</sub>, <span class="emphasis"><em>….x</em></span><sub>n</sub>.</p><p>Hence, we start with an assumption that <span class="emphasis"><em>x</em></span><sub>1</sub>,<span class="emphasis"><em> x</em></span><sub>2</sub>, <span class="emphasis"><em>….x</em></span><sub>n</sub> are conditionally independent, given <span class="emphasis"><em>y</em></span>. Another simple way of defining this is that we need to predict an outcome given multiple evidence as against a single evidence. To simplify, we uncouple these multiple pieces of evidence:</p><p>
<span class="emphasis"><em>P(Outcome|Multiple Evidence) = [P(Evidence1|Outcome) x P(Evidence2|outcome) x ... x P(EvidenceN|outcome)] x P(Outcome) / P(Multiple Evidence)</em></span>
</p><p>This is also written as follows:</p><p>
<span class="emphasis"><em>P(Outcome|Evidence) = P(Likelihood of Evidence) x Prior probability of outcome / P(Evidence)</em></span>
</p><p>In order to apply<a id="id1008" class="indexterm"/> Naïve Bayes to predict an outcome, the previously mentioned formula will need to be run for every outcome. Just run this formula for each possible outcome, and in the case of a classification problem, the outcome will be a class. We will look at the famous fruit problem to help you understand this easily.</p><p>Given any three important characteristics of a fruit, we will need to predict what fruit it is. To simplify the case, let's take three attributes—long, sweet, and yellow; and three classes of fruit—banana, orange, and others. Let there be 1,000 data points in the training set, and this is how the available information looks like:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Type</p>
</th><th style="text-align: left" valign="bottom">
<p>Long</p>
</th><th style="text-align: left" valign="bottom">
<p>Not long</p>
</th><th style="text-align: left" valign="bottom">
<p>Sweet</p>
</th><th style="text-align: left" valign="bottom">
<p>Not sweet</p>
</th><th style="text-align: left" valign="bottom">
<p>Yellow</p>
</th><th style="text-align: left" valign="bottom">
<p>Not yellow</p>
</th><th style="text-align: left" valign="bottom">
<p>Total </p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Banana</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>400</p>
</td><td style="text-align: left" valign="top">
<p>100</p>
</td><td style="text-align: left" valign="top">
<p>350</p>
</td><td style="text-align: left" valign="top">
<p>150</p>
</td><td style="text-align: left" valign="top">
<p>450</p>
</td><td style="text-align: left" valign="top">
<p>50</p>
</td><td style="text-align: left" valign="top">
<p> 500</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Orange</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p>300</p>
</td><td style="text-align: left" valign="top">
<p>150</p>
</td><td style="text-align: left" valign="top">
<p>150</p>
</td><td style="text-align: left" valign="top">
<p>300</p>
</td><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p>300</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Others</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>100</p>
</td><td style="text-align: left" valign="top">
<p>100</p>
</td><td style="text-align: left" valign="top">
<p>150</p>
</td><td style="text-align: left" valign="top">
<p>50</p>
</td><td style="text-align: left" valign="top">
<p>50</p>
</td><td style="text-align: left" valign="top">
<p>150</p>
</td><td style="text-align: left" valign="top">
<p>200</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Total</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>500</p>
</td><td style="text-align: left" valign="top">
<p>500</p>
</td><td style="text-align: left" valign="top">
<p>650</p>
</td><td style="text-align: left" valign="top">
<p>350</p>
</td><td style="text-align: left" valign="top">
<p>800</p>
</td><td style="text-align: left" valign="top">
<p>200</p>
</td><td style="text-align: left" valign="top">
<p>1000</p>
</td></tr></tbody></table></div><p>Some derived values/prior probabilities from the previous table are as follows:</p><p>Probability of Class</p><p>
<span class="emphasis"><em>p (Banana)= 0.5 (500/1000)</em></span>
</p><p>
<span class="emphasis"><em>p (Orange)= 0.3</em></span>
</p><p>
<span class="emphasis"><em>p (Others) = 0.2</em></span>
</p><p>Probability of Evidence</p><p>
<span class="emphasis"><em>p (Long)= 0.5</em></span>
</p><p>
<span class="emphasis"><em>p (Sweet)= 0.65</em></span>
</p><p>
<span class="emphasis"><em>p (Yellow) = 0.8</em></span>
</p><p>Probability of Likelihood</p><p>
<span class="emphasis"><em>p (Long|Banana) = 0.8</em></span>
</p><p>
<span class="emphasis"><em>p (Long/Orange) = 0 P(Yellow/Other Fruit) =50/200 = 0.25</em></span>
</p><p>
<span class="emphasis"><em>p (Not Yellow|Other Fruit)= 0.75</em></span>
</p><p>Now, given a fruit, let's <a id="id1009" class="indexterm"/>classify it based on attributes. First, we run probability for each of the three outcomes, take the highest probability, and then classify it:</p><p>
<span class="emphasis"><em>p (Banana|/Long, Sweet and Yellow) = p (Long|Banana) x p (Sweet|Banana) x p (Yellow|Banana) x p (banana) /p (Long) xp (Sweet) x. p (Yellow)</em></span>
</p><p>
<span class="emphasis"><em>p (Banana||Long, Sweet and Yellow) =0.8 x 0.7 x 0.9 x 0.5 / p (evidence)</em></span>
</p><p>
<span class="emphasis"><em>p (Banana||Long, Sweet and Yellow) =0.252/ p (evidence)</em></span>
</p><p>
<span class="emphasis"><em>p (Orange||Long, Sweet and Yellow) = 0</em></span>
</p><p>
<span class="emphasis"><em>p (Other Fruit/Long, Sweet and Yellow) = p (Long/Other fruit) x p (Sweet/Other fruit) x p (Yellow/Other fruit) x p (Other Fruit)</em></span>
</p><p>
<span class="emphasis"><em> = (100/200 x 150/200 x 50/150 x 200/1000) / p (evidence)</em></span>
</p><p>
<span class="emphasis"><em> = 0.01875/ p (evidence)</em></span>
</p><p>With the largest margin of <span class="emphasis"><em>0.252 &gt;&gt; 0.01875</em></span>, we can now classify this Sweet/Long/Yellow fruit as likely to be a <span class="emphasis"><em>Banana</em></span>.</p><p>As Naïve Bayes assumes a gaussian distribution for each of the features, it is also called the Gaussian Naïve Bayes classifier.</p><p>Naïve Bayes is particularly good when there is missing data. In the next sections, let's look at different types of Naïve Bayes classifiers.</p><div class="section" title="Multinomial Naïve Bayes classifier"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec100"/>Multinomial Naïve Bayes classifier</h3></div></div></div><p>As we have seen in the <a id="id1010" class="indexterm"/>previous section, Naïve Bayes assumes <a id="id1011" class="indexterm"/>independence of the model against the distribution for a feature. In the case of a multinomial Naïve Bayes, the <span class="emphasis"><em>p(x</em></span><sub>i</sub><span class="emphasis"><em>|y)</em></span> is a multinomial distribution; in short, a multinomial distribution is assumed for each of the features. The case that fits this variant is that of a document where we need to compute the word count. A simple algorithm of multinomial Naïve Bayes is given here:</p><div class="mediaobject"><img src="graphics/B03980_09_13.jpg" alt="Multinomial Naïve Bayes classifier"/></div></div><div class="section" title="The Bernoulli Naïve Bayes classifier"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec101"/>The Bernoulli Naïve Bayes classifier</h3></div></div></div><p>The<a id="id1012" class="indexterm"/> Bernoulli Naïve Bayes classifier attaches a Boolean <a id="id1013" class="indexterm"/>indicator to a word as one if it belongs to a document under examination and zero if it does not. The focus of this variation is that it considers the count of occurrence or non-occurrence of a word in a specific document under consideration. The non-occurrence of a word is an important value as it is used in the computation of the conditional probabilities of the <a id="id1014" class="indexterm"/>occurrence of a word. The Bernoulli Naïve Bayes algorithm is detailed here:</p><div class="mediaobject"><img src="graphics/B03980_09_14.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom"> </th><th style="text-align: left" valign="bottom">
<p>Multinomial Naïve Bayes</p>
</th><th style="text-align: left" valign="bottom">
<p>Bernoulli Naïve Bayes</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Model Variable</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>Here, a token is generated and</p>
<p>checked for <a id="id1015" class="indexterm"/>occurrence in a position</p>
</td><td style="text-align: left" valign="top">
<p>Here, a document is generated</p>
<p>and checked for occurrence in a document</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Document</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<div class="mediaobject"><img src="graphics/B03980_09_23.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div>
</td><td style="text-align: left" valign="top">
<p> </p><div class="mediaobject"><img src="graphics/B03980_09_24.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><p>
</p>
<p> </p><div class="mediaobject"><img src="graphics/B03980_09_25.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><p>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Estimation of the parameter</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p> </p><div class="mediaobject"><img src="graphics/B03980_09_26.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><p>
</p>
</td><td style="text-align: left" valign="top">
<p> </p><div class="mediaobject"><img src="graphics/B03980_09_27.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><p>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Rule</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p> </p><div class="mediaobject"><img src="graphics/B03980_09_28.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><p>
</p>
</td><td style="text-align: left" valign="top">
<p> </p><div class="mediaobject"><img src="graphics/B03980_09_29.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><p>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Occurrences</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>This considers multiple occurrences</p>
</td><td style="text-align: left" valign="top">
<p>This considers single occurrences</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Size of the document</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>Large <a id="id1016" class="indexterm"/>documents are handled</p>
</td><td style="text-align: left" valign="top">
<p>Good with smaller documents</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Features</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>This supports<a id="id1017" class="indexterm"/> handling more features</p>
</td><td style="text-align: left" valign="top">
<p>This is good with lesser features</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Estimation of a term</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p> </p><div class="mediaobject"><img src="graphics/B03980_09_30.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div><p>
</p>
</td><td style="text-align: left" valign="top">
<div class="mediaobject"><img src="graphics/B03980_09_31.jpg" alt="The Bernoulli Naïve Bayes classifier"/></div>
</td></tr></tbody></table></div></div></div></div></div>
<div class="section" title="Implementing Na&#xEF;ve Bayes algorithm"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec46"/>Implementing Naïve Bayes algorithm</h1></div></div></div><p>Refer to the source <a id="id1018" class="indexterm"/>code provided for this chapter for implementing Naïve Bayes classifier (source code path <code class="literal">.../chapter9/...</code> under each of the folders for the technology).</p><div class="section" title="Using Mahout"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec108"/>Using Mahout</h2></div></div></div><p>Refer <a id="id1019" class="indexterm"/>to<a id="id1020" class="indexterm"/> the folder <code class="literal">.../mahout/chapter9/naivebayesexample/</code>.</p></div><div class="section" title="Using R"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec109"/>Using R</h2></div></div></div><p>Refer<a id="id1021" class="indexterm"/> to<a id="id1022" class="indexterm"/> the folder <code class="literal">.../r/chapter9/naivebayesexample/</code>.</p></div><div class="section" title="Using Spark"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec110"/>Using Spark</h2></div></div></div><p>Refer <a id="id1023" class="indexterm"/>to the<a id="id1024" class="indexterm"/> folder <code class="literal">.../spark/chapter9/naivebayesexample/</code>.</p></div><div class="section" title="Using scikit-learn"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec111"/>Using scikit-learn</h2></div></div></div><p>Refer<a id="id1025" class="indexterm"/> to the <a id="id1026" class="indexterm"/>folder <code class="literal">.../python-scikit-learn/chapter9/naivebayesexample/</code>.</p></div><div class="section" title="Using Julia"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec112"/>Using Julia</h2></div></div></div><p>Refer<a id="id1027" class="indexterm"/> to the<a id="id1028" class="indexterm"/> folder <code class="literal">.../julia/chapter9/naivebayesexample/</code>.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec47"/>Summary</h1></div></div></div><p>In this chapter, you have learned Bayesian Machine learning and how to implement Naïve Bayes classifiers association rule-based learning with Mahout, R, Python, Julia, and Spark. Additionally, we covered all the core concepts of statistics, starting from basic nomenclature to various distributions. We have covered the Bayes' theorem in depth with examples to understand how to apply it to the real-world problems.</p><p>In the next chapter, we will be covering the regression-based learning techniques and in specific, the implementation for linear and logistic regression.</p></div></body></html>