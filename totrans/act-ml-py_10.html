<html><head></head><body>
<div id="book-content" class="calibre2">
<div id="sbo-rt-content" class="calibre3"><div id="_idContainer094" class="calibre4">
			<h1 id="_idParaDest-87" class="calibre8"><a id="_idTextAnchor089" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>7</h1>
			<h1 id="_idParaDest-88" class="calibre8"><a id="_idTextAnchor090" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Utilizing Tools and Packages for Active ML</h1>
			<p class="calibre6">In this chapter, we will discuss a range of Python libraries, frameworks, and tools commonly used in active ML. These resources are instrumental to implementing a variety of active ML techniques. The content of this chapter is structured to be informative and useful for individuals at different levels of expertise, from beginners to experienced programmers. The aim is to provide a solid understanding of the tools we will cover in order to effectively incorporate active ML techniques into <span>your projects.</span></p>
			<p class="calibre6">Throughout this chapter, the focus will be on understanding Python packages for active ML. We will use the popular Python libraries <strong class="source-inline">scikit-learn</strong> and <strong class="source-inline">modAL</strong>. You’ll learn about their functionalities and how they can be applied to active ML scenarios. We will also explore a range of active ML tools. In addition to the tools covered in previous sections of the book, this chapter will introduce some additional active ML tools. Each tool will be presented with an overview of its features and potential applications, helping you to understand how they fit into different active <span>ML contexts.</span></p>
			<p class="calibre6">In this chapter, we will discuss the <span>following topics:</span></p>
			<ul class="calibre16">
				<li class="calibre20">Mastering Python packages for enhanced <span>active ML</span></li>
				<li class="calibre20">Getting familiar with the active <span>ML tools</span></li>
			</ul>
			<h1 id="_idParaDest-89" class="calibre8"><a id="_idTextAnchor091" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Technical requirements</h1>
			<p class="calibre6">For the exercises in this chapter, you will need to install <span>these packages:</span></p>
			<pre class="source-code">
pip install scikit-learn
pip install modAL-python</pre>			<p class="calibre6">And you will need the <span>following imports:</span></p>
			<pre class="source-code">
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from sklearn.utils import shuffle
import numpy as np
import random
from modAL.models import ActiveLearner, Committee
from sklearn.ensemble import RandomForestClassifier
from modAL.uncertainty import uncertainty_sampling
import os
from PIL import Image
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from modAL.disagreement import vote_entropy_sampling</pre>			<h1 id="_idParaDest-90" class="calibre8"><a id="_idTextAnchor092" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Mastering Python packages for enhanced active ML</h1>
			<p class="calibre6">This section offers a comprehensive overview of two popular Python packages known for their capabilities in facilitating <a id="_idIndexMarker337" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>active ML: <strong class="bold">scikit-learn</strong> and <strong class="bold">modAL</strong>. <strong class="source-inline">scikit-learn</strong>, a versatile and user-friendly library, is <a id="_idIndexMarker338" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>foundational in the ML community for its extensive array of traditional ML tools. On the other hand, <strong class="source-inline">modAL</strong>, specifically designed for active ML, builds upon <strong class="source-inline">scikit-learn</strong>’s robust framework to introduce more dynamic, data-efficient learning techniques. Together, these packages represent a powerful toolkit for anyone looking to leverage the strengths of active <span>ML methodologies.</span></p>
			<h2 id="_idParaDest-91" class="calibre9"><a id="_idTextAnchor093" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>scikit-learn</h2>
			<p class="calibre6">While not <a id="_idIndexMarker339" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>exclusively for active ML, <strong class="bold">scikit-learn</strong> (<a href="https://scikit-learn.org/stable/index.html" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://scikit-learn.org/stable/index.html</a>) is a <a id="_idIndexMarker340" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>foundational package in Python’s machine learning ecosystem. It offers a broad range of algorithms and tools that are often used in conjunction with active ML packages – a vast collection of algorithms for classification, regression, clustering, and dimensionality reduction. It also provides tools for model evaluation and <span>data preprocessing.</span></p>
			<p class="calibre6"><strong class="source-inline">scikit-learn</strong> is typically used as a base for model development and is often integrated with active ML packages for model training <span>and evaluation.</span></p>
			<p class="calibre6">For instance, <strong class="source-inline">scikit-learn</strong> can <a id="_idIndexMarker341" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>be used to perform customer segmentation in marketing by clustering customers based on purchasing behavior, demographics, and engagement metrics. K-means clustering, a popular algorithm in <strong class="source-inline">scikit-learn</strong>, helps in identifying distinct customer groups for targeted marketing campaigns. Active ML can be incorporated by iteratively refining the clustering model. For instance, marketing analysts can label ambiguous cases where the clustering algorithm is uncertain, improving the model’s accuracy <span>over time.</span></p>
			<p class="calibre6">Let’s illustrate this with a <span>simulated example.</span></p>
			<p class="calibre6">First, we perform the initial clustering with <strong class="source-inline">KMeans</strong>. We start by defining some mock customer data (age, <span>annual income):</span></p>
			<pre class="source-code">
X = np.array([[34, 20000], [42, 30000], [23, 25000], [32, 45000], 
    [38, 30000]])</pre>			<p class="calibre6">Then we use <strong class="source-inline">KMeans</strong> <span>for clustering:</span></p>
			<pre class="source-code">
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)</pre>			<p class="calibre6">And we predict the cluster for <span>each customer:</span></p>
			<pre class="source-code">
clusters = kmeans.predict(X)</pre>			<p class="calibre6">We have segmented our customers into two clusters based on age and <span>annual income.</span></p>
			<p class="calibre6">Next, we set up the active ML section. Let’s assume that we have a larger, unlabeled dataset of customer features called <strong class="source-inline">X_unlabeled</strong>. In the context of our customer segmentation scenario using <strong class="source-inline">KMeans</strong>, unlabeled data would consist of customer records with the same features we used for clustering (in our case, age and annual income), but without any assigned cluster labels. This data is what we’ll use to apply and refine our clustering and classification models in an active <span>ML framework:</span></p>
			<pre class="source-code">
X_unlabeled = np.array([[28, 22000], [45, 55000], [37, 35000], 
    [50, 48000], [29, 27000], [41, 32000]])</pre>			<p class="calibre6">We need a model (a classifier) to make predictions on this unlabeled data. Let’s use a simple classifier called <strong class="source-inline">LogisticRegression</strong> for illustration. We initialize this classifier and use the clusters as labels to train it on our initial <span>dataset (</span><span><strong class="source-inline">X</strong></span><span>):</span></p>
			<pre class="source-code">
classifier = LogisticRegression()
classifier.fit(X, clusters)</pre>			<p class="calibre6">Then we implement the active ML loop. In each iteration, the classifier predicts labels for the unlabeled data. First, we need to create a <strong class="source-inline">obtain_labels</strong> placeholder function where we obtain the true labels for the selected data points. In a real-world scenario, this function would involve a process to acquire the actual labels, such as conducting surveys or expert analysis. Since we’re creating a simulated example, we design this function to randomly assign labels based on some <span>assumed logic:</span></p>
			<pre class="source-code">
def obtain_labels(data):
    return np.random.choice([0, 1], size=len(data))</pre>			<p class="calibre6">For our active ML <a id="_idIndexMarker342" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>loop, we need to choose how many iterations we want to go through and how many samples will be labeled in <span>each iteration:</span></p>
			<pre class="source-code">
num_iterations = 10
num_to_label = 2</pre>			<p class="calibre6">We can now create our active ML loop that will do <span>the following:</span></p>
			<ol class="calibre16">
				<li class="calibre17">Select instances for which the classifier is <span>least confident.</span></li>
				<li class="calibre17">Obtain true labels for these instances (in practice, this might involve manual labeling or additional <span>data collection).</span></li>
				<li class="calibre17">Update the classifier with these <span>new labels.</span></li>
				<li class="calibre17">Periodically update the <strong class="source-inline">KMeans</strong> model with the newly labeled data to refine the <span>customer segments.</span></li>
			</ol>
			<p class="calibre6">The following is a code snippet that helps us to <span>achieve this:</span></p>
			<pre class="source-code">
for iteration in range(num_iterations):
    if len(X_unlabeled) == 0:
        break  # No more data to label
    # Predict on unlabeled data
    predictions = classifier.predict_proba(X_unlabeled)
    uncertainty = np.max(predictions, axis=1)
    # Select num_to_label instances with least confidence
    uncertain_indices = np.argsort(uncertainty)[:num_to_label]
    # Obtain labels for these instances
    new_labels = obtain_labels(X_unlabeled[uncertain_indices])
    # Update our dataset
    X = np.vstack([X, X_unlabeled[uncertain_indices]])
    clusters = np.hstack([clusters, new_labels])
    # Re-train classifier and KMeans
    classifier.fit(X, clusters)
    kmeans.fit(X)
    print(f"Iteration {iteration+1}, Labeled Data: {
        X_unlabeled[uncertain_indices]} with Labels: {new_labels}")
    # Remove labeled instances from unlabeled data
    X_unlabeled = np.delete(X_unlabeled, uncertain_indices, axis=0)
    # Shuffle unlabeled data to avoid any order bias
    X_unlabeled = shuffle(X_unlabeled)</pre>			<p class="calibre6">The preceding code returns <span>the following:</span></p>
			<pre class="source-code">
Iteration 1, Labeled Data: [[45 55000] [29 27000]] with Labels: [0 1]
Iteration 2, Labeled Data: [[37 35000] [28 22000]] with Labels: [1 1]
Iteration 3, Labeled Data: [[41 32000] [50 48000]] with Labels: [0 0]</pre>			<p class="calibre6">Our active ML<a id="_idIndexMarker343" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> loop iterates a specified number of times, each time selecting the least confident predictions made by the classifier, obtaining labels for these instances, and then updating the classifier and <strong class="source-inline">KMeans</strong> model with the new data. Remember, the <strong class="source-inline">obtain_labels</strong> function is a simplification. In a real application, obtaining labels would involve an oracle manually labeling the samples as we described in <a href="B21789_03.xhtml#_idTextAnchor040" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"><span><em class="italic">Chapter 3</em></span></a>,<em class="italic"> Managing the Human in </em><span><em class="italic">the Loop</em></span><span>.</span></p>
			<h2 id="_idParaDest-92" class="calibre9"><a id="_idTextAnchor094" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>modAL</h2>
			<p class="calibre6"><strong class="bold">modAL</strong> (<a href="https://modal-python.readthedocs.io/en/latest/" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://modal-python.readthedocs.io/en/latest/</a>) is a modular and flexible active ML <a id="_idIndexMarker344" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>framework <a id="_idIndexMarker345" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>built on top of <strong class="source-inline">scikit-learn</strong>. It allows for easy integration of active learning strategies into existing ML workflows. It provides various active ML strategies such as uncertainty sampling and query by committee. It also supports custom query strategies and easy integration with <span><strong class="source-inline">scikit-learn</strong></span><span> models.</span></p>
			<p class="calibre6">For example, it is <a id="_idIndexMarker346" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>ideal for tasks such as image classification and regression where active ML can efficiently select informative samples <span>for annotation.</span></p>
			<p class="calibre6">Let’s take a look at an example where we classify images from the popular <strong class="bold">CIFAR10</strong> dataset. This dataset can be loaded from built-in <strong class="source-inline">torchvision</strong> datasets. Given the large volume of images, active ML can help prioritize which images should be labeled manually. We will use the <strong class="source-inline">modAL</strong> framework’s uncertainty sampling query strategy. It will be able to identify the most informative images (those where the classifier is most uncertain) and query them <span>for labeling.</span></p>
			<p class="calibre6">We <a id="_idIndexMarker347" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>implement a <strong class="source-inline">load_images</strong> function to read images from the dataset directory, then we convert them to grayscale and flatten the images for training. Indeed, we need to transform the image data into a format compatible with <strong class="source-inline">RandomForest</strong>, so each image, which is a 2D array, is <em class="italic">flattened</em> into a 1D array. This means converting the image into a long vector of pixel values. For our grayscale images of size 32x32 pixels, the flattened form will be a vector of 1,024 <span>elements (32x32):</span></p>
			<pre class="source-code">
def load_data():
    # Define the transformation
    transform = transforms.Compose([
        transforms.ToTensor(),  # Convert images to PyTorch tensors
    ])
        # Load the CIFAR10 dataset
    dataset = CIFAR10(root='data', train=True, download=True, 
        transform=transform)
    # Load all data into memory (for small datasets)
    dataloader = DataLoader(dataset, batch_size=len(dataset), 
        shuffle=False)
    data_iter = iter(dataloader)
    images, labels = next(data_iter)
    # Convert images and labels to numpy arrays
    X_all = images.numpy()
    y_all = np.array(labels)
    # Convert images from 3D to 1D (batch_size, 3, 32, 32) -&gt; (batch_size, 3072) for RandomForest
    X_all = X_all.reshape(X_all.shape[0], -1)
    # Map numerical labels to string labels
    class_names = dataset.classes
    y_all = np.array([class_names[label] for label in y_all])
    return X_all, y_all</pre>			<p class="calibre6">Next, for our <a id="_idIndexMarker348" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>example, we split the dataset into initial labeled data with the images stored in <strong class="source-inline">X_initial</strong> and the labels stored in <strong class="source-inline">y_initial</strong> and unlabeled data <span>as </span><span><strong class="source-inline">X_unlabeled</strong></span><span>:</span></p>
			<pre class="source-code">
X_initial, X_unlabeled, y_initial, _ = train_test_split(X_all, y_all, 
    test_size=0.75, random_state=42)</pre>			<p class="calibre6">We are starting our example with 12,500 labeled images and 37,500 <span>unlabeled images.</span></p>
			<p class="calibre6">Then we initialize the <strong class="source-inline">modAL</strong> <span>active learner:</span></p>
			<pre class="source-code">
learner = ActiveLearner(
    estimator=RandomForestClassifier(),
    query_strategy=uncertainty_sampling,
    X_training=X_initial_flat, y_training=y_initial
)</pre>			<p class="calibre6">In the preceding code snippet, an <strong class="source-inline">ActiveLearner</strong> object is created. This learner uses <strong class="source-inline">RandomForestClassifier</strong> as its estimator. <strong class="source-inline">RandomForest</strong> is a popular ensemble learning method for classification, which operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes of the individual trees. The query strategy <a id="_idIndexMarker349" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>is set to <strong class="bold">uncertainty sampling</strong>. In uncertainty sampling, the <a id="_idIndexMarker350" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>model queries the instances about which it is least certain about classifying and aims at querying the most informative samples, as we saw in <a href="B21789_02.xhtml#_idTextAnchor027" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"><span><em class="italic">Chapter 2</em></span></a><em class="italic">, Designing Query Strategy Frameworks</em>. Finally, the <strong class="source-inline">X_initial_flat</strong> initial training data and <strong class="source-inline">y_training</strong> labels are provided to <span>the learner.</span></p>
			<p class="calibre6">Finally, we simulate the querying of the labels with the following <span>five-iteration loop:</span></p>
			<pre class="source-code">
for i in range(5):
    query_idx, _ = learner.query(X_unlabeled)
    actual_label = y_all[query_idx[0]] 
    print(f"Selected unlabeled query is sample number {query_idx[0]}. Actual label: {actual_label}")
    learner.teach(X_unlabeled[query_idx].reshape(1, -1), actual_label.reshape(1,))
    X_unlabeled = np.delete(X_unlabeled, query_idx, axis=0)
    y_all = np.delete(y_all, query_idx)</pre>			<p class="calibre6">The preceding loop returns <span>the following:</span></p>
			<pre class="source-code">
Selected unlabeled query is sample number 3100. Actual label: cat
Selected unlabeled query is sample number 7393. Actual label: deer
Selected unlabeled query is sample number 4728. Actual label: horse
Selected unlabeled query is sample number 447. Actual label: deer
Selected unlabeled query is sample number 17968. Actual label: bird</pre>			<p class="calibre6">The loop<a id="_idIndexMarker351" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> represents five iterations of active ML. In each iteration, the model queries the dataset to label new instances. The learner queries the <strong class="source-inline">X_unlabeled</strong> training data and returns the <strong class="source-inline">query_idx</strong> index and <strong class="source-inline">query_instance</strong> instance of the sample it is most uncertain about. Then, the learner is taught using the instance it queried. In a real-world scenario, this step would involve obtaining the label for the queried instance from an oracle (such as a human annotator). However, in this simulated example, the label is directly taken from the <span><strong class="source-inline">y_all</strong></span><span> dataset.</span></p>
			<p class="calibre6">This example illustrates the process of active ML using <strong class="source-inline">modAL</strong>, where the model actively queries specific instances to learn from, rather than passively learning from a <span>static dataset.</span></p>
			<p class="calibre6"><strong class="source-inline">modAL</strong> is a great Python package that allows us to implement complex active ML methods easily. For example, let’s create a use case of active ML using the <strong class="source-inline">modAL</strong> package, specifically focusing <a id="_idIndexMarker352" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>on <strong class="bold">committee-based</strong> algorithms. In this example, we’ll use a committee of classifiers to query the most informative samples from an unlabeled dataset. As a reminder, we defined the <em class="italic">query-by-committee approaches</em> in <a href="B21789_02.xhtml#_idTextAnchor027" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"><span><em class="italic">Chapter 2</em></span></a><em class="italic">, Designing Query </em><span><em class="italic">Strategy Frameworks</em></span><span>.</span></p>
			<p class="calibre6">For this example, let’s use the Iris dataset (<em class="italic">Fisher, R. A.. (1988). Iris. UCI Machine Learning Repository</em>. <a href="https://doi.org/10.24432/C56C76" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://doi.org/10.24432/C56C76</a>), a common choice for classification tasks. The Iris dataset is a classic dataset in machine learning and statistics, often used for demonstrating classification algorithms. The dataset contains 150 samples of iris flowers. Each sample has four features: sepal length, sepal width, petal length, and petal width. These features are measurements in centimeters of the respective parts of the iris plant. There are three species (classes) of iris plants in the dataset: Iris setosa, Iris virginica, and Iris versicolor. Each class has 50 samples, making the dataset evenly balanced among the three classes. The typical task with the Iris dataset is a multiclass classification problem. The goal is to predict the species of an iris plant based on measurements of its sepals <span>and petals.</span></p>
			<p class="calibre6">We will use a committee of K-Nearest Neighbors classifiers. The committee will use the <strong class="bold">query-by-committee (QBC) strategy</strong> to select<a id="_idIndexMarker353" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> data points about which it has the <span>most disagreement.</span></p>
			<p class="calibre6">We start by loading the Iris dataset (from the datasets available with <strong class="source-inline">scikit-learn</strong>) and creating an initial small labeled dataset and a larger <span>unlabeled dataset:</span></p>
			<pre class="source-code">
X, y = load_iris(return_X_y=True)
X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(
    X, y, test_size=0.9, random_state=42)</pre>			<p class="calibre6">We initialize <a id="_idIndexMarker354" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>twenty <strong class="source-inline">ActiveLearner</strong> instances, each with a <strong class="source-inline">RandomForestClassifier</strong>, and combine them into <span>a </span><span><strong class="source-inline">Committee</strong></span><span>:</span></p>
			<pre class="source-code">
n_learners = 20
learners = [ActiveLearner(
        estimator=RandomForestClassifier(), X_training=X_labeled, \
        y_training=y_labeled
    ) for _ in range(n_learners)]
committee = Committee(learner_list=learners, 
    query_strategy=vote_entropy_sampling)</pre>			<p class="calibre6">The active ML loop uses the <strong class="source-inline">vote_entropy_sampling</strong> strategy to select the sample about which the committee members disagree <span>the most.</span></p>
			<p class="calibre6">Here is how our active ML loop looks like for <span>five iterations:</span></p>
			<pre class="source-code">
n_queries = 5
for idx in range(n_queries):
    query_idx, query_instance = committee.query(X_unlabeled)
    print(f"\nSelected unlabeled query is sample number {query_idx}. We simulate labeling this sample which is labeled as: {y_unlabeled[query_idx]}")
    committee.teach(X_unlabeled[query_idx], y_unlabeled[query_idx])
    # Remove the queried instance from the pool
    X_unlabeled = np.delete(X_unlabeled, query_idx, axis=0)
    y_unlabeled = np.delete(y_unlabeled, query_idx)
    print(f"Number of unlabeled samples is {len(X_unlabeled)}")
    # Calculate and print committee score
    committee_score = committee.score(X, y)
    print(f"Iteration {idx+1}, Committee Score: {committee_score}")</pre>			<p class="calibre6">The <strong class="source-inline">query</strong> method <a id="_idIndexMarker355" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>of the <strong class="source-inline">Committee</strong> object is used to select the most informative sample from the unlabeled <strong class="source-inline">X_unlabeled</strong> dataset. The committee, consisting of multiple learners, uses its internal query strategy, <strong class="source-inline">vote_entropy_sampling</strong>, to determine which instance in <strong class="source-inline">X_unlabeled</strong> it finds most valuable <span>for learning.</span></p>
			<p class="calibre6">The selected sample in each iteration is used to teach (retrain) all the committee’s learners. After each query, the performance of the committee <span>is evaluated:</span></p>
			<pre class="source-code">
Selected unlabeled query is sample number [8]. We simulate labeling this sample which is labeled as: [0]
Number of unlabeled samples is 129
Iteration 1, Committee Score: 0.96
Selected unlabeled query is sample number [125]. We simulate labeling this sample which is labeled as: [2]
Number of unlabeled samples is 128
Iteration 2, Committee Score: 0.9466666666666667
Selected unlabeled query is sample number [42]. We simulate labeling this sample which is labeled as: [2]
Number of unlabeled samples is 127
Iteration 3, Committee Score: 0.9466666666666667
Selected unlabeled query is sample number [47]. We simulate labeling this sample which is labeled as: [1]
Number of unlabeled samples is 126
Iteration 4, Committee Score: 0.9733333333333334
Selected unlabeled query is sample number [95]. We simulate labeling this sample which is labeled as: [1]
Number of unlabeled samples is 125
Iteration 5, Committee Score: 0.9733333333333334</pre>			<p class="calibre6">This example demonstrates how to use a committee of learners with <strong class="source-inline">modAL</strong> to actively improve model performance by querying the most informative samples. The committee’s diverse opinions help in selecting samples that are more informative for learning, thus improving the overall model more efficiently. We observe in our output, for example, that the committee score improved from 0.96 <span>to 0.973.</span></p>
			<p class="calibre6">In active ML, especially <a id="_idIndexMarker356" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>when using a committee-based approach as in the preceding example, the expectation is generally that the performance of the model (or in this case, the committee of models) will improve over the iterations. This improvement is expected because the committee is being trained on increasingly informative samples, which are selected based on the committee’s uncertainty <span>or disagreement.</span></p>
			<p class="calibre6">However, a few points are <span>worth noting:</span></p>
			<ul class="calibre16">
				<li class="calibre20"><strong class="bold">Incremental improvement</strong>: The increase in performance might not be linear or consistent across all iterations. In some iterations, the model may improve significantly, while in others, the improvement might be minimal or even stagnant. We can see this in our example, where the committee score went from 0.96 to 0.94, and then back up <span>to 0.973.</span></li>
				<li class="calibre20"><strong class="bold">Depends on data and model</strong>: The rate and consistency of improvement depend on the nature of the data and the effectiveness of the learning algorithm. For some datasets or configurations, the improvement might be rapid and consistent, while for others, it might be slower or <span>less predictable.</span></li>
				<li class="calibre20"><strong class="bold">Diminishing returns</strong>: As the most informative samples are added to the training set, the remaining unlabeled samples may become less informative, leading to diminishing returns in terms of performance improvement in <span>later iterations.</span></li>
				<li class="calibre20"><strong class="bold">Performance metric</strong>: The committee score (be it accuracy or another metric; in our case, the <strong class="source-inline">modAL</strong> function uses the accuracy by default) is a measure of how well the committee’s combined prediction aligns with the true labels. As the committee is exposed to more representative samples of the data, its predictions should become <span>more accurate.</span></li>
				<li class="calibre20"><strong class="bold">Evaluation method</strong>: The method of evaluating the committee’s performance can also affect perceived improvements. If the evaluation is done on a static test set, the improvements may be more evident. However, if the evaluation is on the training set (including newly added samples), the improvements might be less pronounced due to increasing complexity or variance in <span>the data.</span></li>
			</ul>
			<p class="calibre6">In summary, while an<a id="_idIndexMarker357" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> increase in the committee’s performance score over a number of iterations is a common expectation in active ML, the actual pattern of improvement can vary based on various factors. Regular monitoring and adjustments might be necessary to ensure the active ML process is yielding the desired results, as we saw in <a href="B21789_06.xhtml#_idTextAnchor078" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"><span><em class="italic">Chapter 6</em></span></a>,<em class="italic"> Evaluating and </em><span><em class="italic">Enhancing Efficiency</em></span><span>.</span></p>
			<p class="calibre6">The choice of the right Python package for active ML depends on the specific requirements of the task at hand, including the type of data, the ML model being used, and the desired active learning strategy. Integrating these packages effectively can lead to more efficient data labeling, faster model convergence, and overall better performance of <span>ML models.</span></p>
			<p class="calibre6">Next, we will explore tools that can be easily used to perform active ML on unlabeled data such as Encord Active, Lightly, Cleanlab, Voxel51, <span>and UBIAI.</span></p>
			<h1 id="_idParaDest-93" class="calibre8"><a id="_idTextAnchor095" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Getting familiar with the active ML tools</h1>
			<p class="calibre6">Throughout this book, we’ve introduced and discussed several key active ML tools and labeling platforms, including Lightly, Encord, LabelBox, Snorkel AI, Prodigy, <strong class="source-inline">modAL</strong>, and Roboflow. To further enhance your understanding and assist you in selecting the most suitable tool for your specific project needs, let’s revisit these tools with expanded insights and introduce a few <span>additional ones:</span></p>
			<ul class="calibre16">
				<li class="calibre20"><strong class="bold">modAL</strong> (<a href="https://modal-python.readthedocs.io/en/latest/" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://modal-python.readthedocs.io/en/latest/</a>): This is a flexible and modular active ML framework<a id="_idIndexMarker358" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> in Python, designed to seamlessly <a id="_idIndexMarker359" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>integrate with <strong class="source-inline">scikit-learn</strong>. It stands out for its extensive range of query strategies, which can be tailored to various active ML scenarios. Whether you are dealing with classification, regression, or clustering tasks, <strong class="source-inline">modAL</strong> provides a robust and intuitive interface for implementing active <span>learning workflows.</span></li>
				<li class="calibre20"><strong class="bold">Label </strong><span><strong class="bold">Studio </strong></span><span>(</span><a href="https://docs.humansignal.com/guide/active_learning.html?__hstc=90244869.a32555b92661e36e5f4b3b8a0f2cc99a.1706210819596.1706210819596.1706210819596.1&amp;__hssc=90244869.2.1706210819596&amp;__hsfp=3755259113&amp;_gl=1*1i1r2ib*_ga*MTE1NzM0NDQ4Ny4xNzA2MjEwODE5*_ga_NQELN45JRH*MTcwNjIxMDgxOS4xLjEuMTcwNjIxMDgzNC4wLjAuMA" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"><span>https://docs.humansignal.com/guide/active_learning.</span> <span>html?__hstc=90244869.a32555b92661e36e5f4b3b8a0f2cc99a.170621 0819596.1706210819596.1706210819596.1&amp;__hssc=90244869.2.1706</span> <span>210819596&amp;__hsfp=3755259113&amp;_gl=1*1i1r2ib*_ga*MTE1NzM0NDQ4Ny 4xNzA2MjEwODE5*_ga_NQELN45JRH*MTcwNjIxMDgxOS4xLjEuMTcwNj</span> IxMDgzNC4wLjAuMA</a>): An open<a id="_idIndexMarker360" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> source, multi-type data labeling tool, Label Studio <a id="_idIndexMarker361" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>excels in its adaptability to different forms of data, including text, images, and audio. It allows for the integration of ML models into the labeling process, thereby enhancing labeling efficiency through active ML. Its flexibility extends to customizable labeling interfaces, making it suitable for a broad range of applications in <span>data annotation.</span></li>
				<li class="calibre20"><strong class="bold">Prodigy </strong>(<a href="https://prodi.gy/" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://prodi.gy/</a>): Prodigy<a id="_idIndexMarker362" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> offers a unique blend of active <a id="_idIndexMarker363" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>ML and human-in-the-loop approaches. It’s a highly efficient annotation tool, particularly for refining training data for NLP models. Its real-time feedback loop allows for rapid iteration and model improvement, making it an ideal choice for projects that require quick adaptation and precision in <span>data annotation.</span></li>
				<li class="calibre20"><strong class="bold">Lightly</strong>(<a href="https://www.lightly.ai/" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://www.lightly.ai/</a>): Specializing in image datasets, Lightly<a id="_idIndexMarker364" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> uses active ML to identify the <a id="_idIndexMarker365" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>most representative and diverse set of images for training. This ensures that models are trained on a balanced and varied dataset, leading to improved generalization and performance. Lightly is particularly useful for projects where data is abundant but labeling resources <span>are limited.</span></li>
				<li class="calibre20"><strong class="bold">Encord Active</strong> (<a href="https://encord.com/active" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://encord.com/active</a>): Focused on active ML for image and video data, Encord Active<a id="_idIndexMarker366" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> is integrated within a comprehensive labeling<a id="_idIndexMarker367" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> platform. It streamlines the labeling process by identifying and prioritizing the most informative samples, thereby enhancing efficiency and reducing the manual annotation workload. This platform is particularly beneficial for large-scale computer <span>vision projects.</span></li>
				<li class="calibre20"><strong class="bold">Cleanlab </strong>(<a href="https://cleanlab.ai/" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://cleanlab.ai/</a>): Cleanlab<a id="_idIndexMarker368" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> stands out for its ability to detect, quantify, and<a id="_idIndexMarker369" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> rectify label errors in datasets. This capability is invaluable for active ML, where the quality of the labeled data directly impacts model performance. It offers a systematic approach to ensuring data integrity, which is crucial for training robust and <span>reliable models.</span></li>
				<li class="calibre20"><strong class="bold">Voxel51</strong> (<a href="https://voxel51.com/blog/supercharge-your-annotation-workflow-with-active-learning" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://voxel51.com/blog/supercharge-your-annotation-workflow-with-active-learning</a>): With a focus on video and image data, Voxel51 provides an active ML platform <a id="_idIndexMarker370" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>that prioritizes the most informative data for <a id="_idIndexMarker371" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>labeling. This enhances the annotation workflow, making it more efficient and effective. The platform is particularly adept at handling complex, large-scale video datasets, offering powerful tools for video analytics <span>and ML</span></li>
				<li class="calibre20"><strong class="bold">UBIAI</strong> (<a href="https://ubiai.tools/active-learning-2" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://ubiai.tools/active-learning-2</a>): UBIAI<a id="_idIndexMarker372" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> is a tool that specializes in text annotation and supports active ML. It simplifies the process of training and deploying NLP <a id="_idIndexMarker373" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>models by streamlining the annotation workflow. Its active ML capabilities ensure that the most informative text samples are prioritized for annotation, thus improving model accuracy with fewer <span>labeled examples.</span></li>
				<li class="calibre20"><strong class="bold">Snorkel AI</strong> (<a href="https://snorkel.ai" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://snorkel.ai</a>): Renowned for<a id="_idIndexMarker374" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> its novel approach to <a id="_idIndexMarker375" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>creating, modeling, and managing training data, Snorkel AI uses a technique called weak supervision. This method combines various labeling sources to reduce the dependency on large labeled datasets, complementing active ML strategies to create efficient training <span>data pipelines.</span></li>
				<li class="calibre20"><strong class="bold">Deepchecks</strong> (<a href="https://deepchecks.com/importance-of-active-learning-in-machine-learning" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://deepchecks.com/importance-of-active-learning-in-machine-learning</a>): Deepchecks<a id="_idIndexMarker376" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> offers a comprehensive suite of validation<a id="_idIndexMarker377" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> checks that are essential in an active ML context. These checks ensure the quality and diversity of datasets and models, thereby facilitating the development of more accurate and robust ML systems. It’s an essential tool for maintaining data integrity and model reliability throughout the <span>ML lifecycle.</span></li>
				<li class="calibre20"><strong class="bold">LabelBox</strong> (<a href="https://labelbox.com/guides/the-guide-to-getting-started-with-active-learning" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://labelbox.com/guides/the-guide-to-getting-started-with-active-learning</a>): As a <a id="_idIndexMarker378" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>comprehensive data labeling platform, LabelBox<a id="_idIndexMarker379" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> excels in managing the entire data labeling process. It provides a suite of tools for creating, managing, and iterating on labeled data, applicable to a wide range of data types such as images, videos, and text. Its support for active learning methodologies further enhances the efficiency of the labeling process, making it an ideal choice for large-scale <span>ML projects.</span></li>
				<li class="calibre20"><strong class="bold">Roboflow</strong> (<a href="https://docs.roboflow.com/api-reference/active-learning" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3">https://docs.roboflow.com/api-reference/active-learning</a>): Designed for computer<a id="_idIndexMarker380" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> vision projects, Roboflow streamlines the<a id="_idIndexMarker381" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> process of preparing image data. It is especially valuable for tasks involving image recognition and object detection. Roboflow’s focus on easing the preparation, annotation, and management of image data makes it a key resource for teams and individuals working in the field of <a id="_idIndexMarker382" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/><span>computer vision.</span></li>
			</ul>
			<p class="calibre6">Each tool in this extended list brings unique capabilities to the table, addressing specific challenges in ML projects. From image and video annotation to text processing and data integrity checks, these tools provide the necessary functionalities to enhance project efficiency and efficacy through active <span>ML strategies.</span></p>
			<h1 id="_idParaDest-94" class="calibre8"><a id="_idTextAnchor096" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Summary</h1>
			<p class="calibre6">This chapter has provided a comprehensive exploration of the various Python libraries, frameworks, and tools essential for active ML. By navigating through the intricacies of popular libraries such as <strong class="source-inline">scikit-learn</strong> and <strong class="source-inline">modAL</strong>, we have explored their capabilities and how they can be effectively applied in active ML scenarios. Additionally, this chapter has expanded your toolkit by introducing a range of other active ML tools, each with its own unique features and <span>potential applications.</span></p>
			<p class="calibre6">Whether you are a beginner taking your first steps in active ML or an experienced programmer seeking to refine your skills, this chapter aimed to equip you with a solid foundation in the tools and techniques of active ML. The knowledge gained here is not just theoretical; it is a practical guide to help you master Python packages for enhanced active ML and to familiarize yourself with a broad spectrum of active ML tools. This understanding will enable you to select and apply the most appropriate tools for your specific ML projects, enhancing the efficiency and effectiveness of <span>your models.</span></p>
			<p class="calibre6">Congratulations! You have reached the end of the book. But remember you have just started your journey in the world of active ML. As you move forward in your ML journey, remember that the field of active ML is continually evolving. Staying informed about new developments, tools, and techniques will be key to maintaining a cutting-edge approach in your work. The tools and concepts covered in this chapter provide a strong basis for further exploration and innovation in the exciting and dynamic field of <span>active ML.</span></p>
		</div>
	</div>
</div>
</body></html>