["```py\nfrom sagemaker.model import Model \nmodel = Model(model_data=model_data, ...)\nmodel.deploy(<insert configuration parameters>)\n```", "```py\nestimator = Estimator(...)\nestimator.set_hyperparameters(...)\nhyperparameter_ranges = {...}\nobjective_metric_name = \"<insert target metric>\"\nhyperparameter_tuner = HyperparameterTuner(\n    estimator, \n    objective_metric_name, \n    hyperparameter_ranges, \n    max_jobs=20, \n    max_parallel_jobs=3\n)\nhyperparameter_tuner.fit(...)\n```", "```py\n    Good day, \n    ```", "```py\n    I am planning to run a SageMaker training job using 2 x ml.p2.xlarge instances to train an Image Classification model. After this I am planning to use Managed Spot Training to run a similar example and will need 2 x ml.p2.xlarge (spot) instances. Hope these 2 limit increase requests can be processed as soon as possible in the Oregon (us-west-2) region.\n    ```", "```py\n    You can find the relevant notebooks here: https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS\n    ```", "```py\n    print('Hello')\n    ```", "```py\n    !rm -rf tmp && mkdir -p tmp\n    ```", "```py\n    !wget -O tmp/batch1.zip https://bit.ly/37zmQeb\n    ```", "```py\n    %%time\n    ```", "```py\n    !cd tmp && unzip batch1.zip && rm batch1.zip\n    ```", "```py\n    !ls -RF\n    ```", "```py\n    !pip3 install ipyplot\n    ```", "```py\n    import ipyplot\n    ```", "```py\n    import glob\n    ```", "```py\n    for i in range(0,10):    \n    ```", "```py\n        image_files = glob.glob(f\"tmp/train/{i}/*.png\")\n    ```", "```py\n        print(f'---{i}---')\n    ```", "```py\n        ipyplot.plot_images(image_files, \n    ```", "```py\n                            max_images=5, \n    ```", "```py\n                            img_width=128)\n    ```", "```py\n    s3_bucket = \"<INSERT S3 BUCKET NAME HERE>\"\n    ```", "```py\n    prefix = \"ch06\"\n    ```", "```py\n    training_samples = glob.glob(f\"tmp/train/*/*.png\")\n    ```", "```py\n    len(training_samples)\n    ```", "```py\n    !aws s3 mb s3://{s3_bucket}\n    ```", "```py\n    %%time\n    ```", "```py\n    !aws s3 cp tmp/.  s3://{s3_bucket}/{prefix}/ --recursive\n    ```", "```py\n    import sagemaker\n    ```", "```py\n    import boto3\n    ```", "```py\n    session = sagemaker.Session()\n    ```", "```py\n    role = sagemaker.get_execution_role()\n    ```", "```py\n    region_name = boto3.Session().region_name\n    ```", "```py\n    image = sagemaker.image_uris.retrieve(\n    ```", "```py\n        \"image-classification\", \n    ```", "```py\n        region_name, \n    ```", "```py\n        \"1\"\n    ```", "```py\n    )\n    ```", "```py\n    image\n    ```", "```py\n    def map_path(source):\n    ```", "```py\n        return 's3://{}/{}/{}'.format(\n    ```", "```py\n            s3_bucket, \n    ```", "```py\n            prefix, \n    ```", "```py\n            source\n    ```", "```py\n        )\n    ```", "```py\n    def map_input(source):\n    ```", "```py\n        path = map_path(source)\n    ```", "```py\n        return sagemaker.inputs.TrainingInput(\n    ```", "```py\n            path, \n    ```", "```py\n            distribution='FullyReplicated', \n    ```", "```py\n            content_type='application/x-image', \n    ```", "```py\n            s3_data_type='S3Prefix'\n    ```", "```py\n        )\n    ```", "```py\n    data_channels = {}\n    ```", "```py\n    channels = [\"train\", \n    ```", "```py\n                \"validation\",\n    ```", "```py\n                \"train_lst\",\n    ```", "```py\n                \"validation_lst\"]\n    ```", "```py\n    for channel in channels:\n    ```", "```py\n        data_channels[channel] = map_input(channel)\n    ```", "```py\n    output_path = map_path(\"output\")\n    ```", "```py\n    output_path\n    ```", "```py\n    estimator = sagemaker.estimator.Estimator(\n    ```", "```py\n        image,\n    ```", "```py\n        role, \n    ```", "```py\n        instance_count=2, \n    ```", "```py\n        instance_type='ml.p2.xlarge',\n    ```", "```py\n        output_path=output_path,\n    ```", "```py\n        sagemaker_session=session,\n    ```", "```py\n        enable_network_isolation=True\n    ```", "```py\n    )\n    ```", "```py\n    hyperparameters = {\n    ```", "```py\n        'num_training_samples': len(training_samples),\n    ```", "```py\n        'num_layers': 18,\n    ```", "```py\n        'image_shape': \"1,28,28\",\n    ```", "```py\n        'num_classes': 10,\n    ```", "```py\n        'mini_batch_size': 100,\n    ```", "```py\n        'epochs': 3,\n    ```", "```py\n        'learning_rate': 0.01,\n    ```", "```py\n        'top_k': 5,\n    ```", "```py\n        'precision_dtype': 'float32'    \n    ```", "```py\n    }\n    ```", "```py\n    estimator.set_hyperparameters(**hyperparameters)\n    ```", "```py\nestimator.set_hyperparameters(\n    num_training_samples=len(training_samples),\n    num_layers=18,\n    image_shape=\"1,28,28\",\n    ...\n)\n```", "```py\n    %%time\n    ```", "```py\n    estimator.fit(inputs=data_channels, logs=True)\n    ```", "```py\n    estimator.model_data\n    ```", "```py\n    model_data = estimator.model_data\n    ```", "```py\n    job_name = estimator.latest_training_job.name\n    ```", "```py\n    %store model_data\n    ```", "```py\n    %store job_name\n    ```", "```py\n    %store role\n    ```", "```py\n    %store region_name\n    ```", "```py\n    %store image\n    ```", "```py\n    endpoint = estimator.deploy(\n    ```", "```py\n        initial_instance_count = 1,\n    ```", "```py\n        instance_type = 'ml.m5.xlarge'\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.serializers import IdentitySerializer\n    ```", "```py\n    endpoint.serializer = IdentitySerializer(\n    ```", "```py\n        content_type=\"application/x-image\"\n    ```", "```py\n    )\n    ```", "```py\n    import json\n    ```", "```py\n    def get_class_from_results(results):\n    ```", "```py\n        results_prob_list = json.loads(results)\n    ```", "```py\n        best_index = results_prob_list.index(\n    ```", "```py\n            max(results_prob_list)\n    ```", "```py\n        )\n    ```", "```py\n        return {\n    ```", "```py\n            0: \"ZERO\",\n    ```", "```py\n            1: \"ONE\",\n    ```", "```py\n            2: \"TWO\",\n    ```", "```py\n            3: \"THREE\",\n    ```", "```py\n            4: \"FOUR\",\n    ```", "```py\n            5: \"FIVE\",\n    ```", "```py\n            6: \"SIX\",\n    ```", "```py\n            7: \"SEVEN\",\n    ```", "```py\n            8: \"EIGHT\",\n    ```", "```py\n            9: \"NINE\"\n    ```", "```py\n        }[best_index]\n    ```", "```py\n    from IPython.display import Image, display\n    ```", "```py\n    def predict(filename, endpoint=endpoint):\n    ```", "```py\n        byte_array_input = None\n    ```", "```py\n        with open(filename, 'rb') as image:\n    ```", "```py\n            f = image.read()\n    ```", "```py\n            byte_array_input = bytearray(f)\n    ```", "```py\n        display(Image(filename))\n    ```", "```py\n        results = endpoint.predict(byte_array_input)\n    ```", "```py\n        return get_class_from_results(results)\n    ```", "```py\n    results = !ls -1 tmp/test\n    ```", "```py\n    for filename in results:\n    ```", "```py\n        print(predict(f\"tmp/test/{filename}\"))\n    ```", "```py\n    endpoint.delete_endpoint()\n    ```", "```py\n    s3_bucket = \"<INSERT S3 BUCKET NAME HERE>\"\n    ```", "```py\n    prefix = \"ch06\"\n    ```", "```py\n    %store -r role\n    ```", "```py\n    %store -r region_name\n    ```", "```py\n    %store -r job_name\n    ```", "```py\n    %store -r image\n    ```", "```py\n    job_name\n    ```", "```py\n    import sagemaker\n    ```", "```py\n    from sagemaker.estimator import Estimator\n    ```", "```py\n    session = sagemaker.Session()\n    ```", "```py\n    previous = Estimator.attach(job_name)\n    ```", "```py\n    previous.logs()\n    ```", "```py\n    model_data = previous.model_data\n    ```", "```py\n    model_data\n    ```", "```py\n    import string \n    ```", "```py\n    import random\n    ```", "```py\n    def generate_random_string():\n    ```", "```py\n        return ''.join(\n    ```", "```py\n            random.sample(\n    ```", "```py\n            string.ascii_uppercase,12)\n    ```", "```py\n        )\n    ```", "```py\n    base_job_name = generate_random_string()\n    ```", "```py\n    base_job_name\n    ```", "```py\n    checkpoint_folder=\"checkpoints\"\n    ```", "```py\n    checkpoint_s3_bucket=\"s3://{}/{}/{}\".format(s3_bucket, base_job_name, checkpoint_folder)\n    ```", "```py\n    checkpoint_local_path=\"/opt/ml/checkpoints\"\n    ```", "```py\n    !rm -rf tmp2 && mkdir -p tmp2\n    ```", "```py\n    %%time\n    ```", "```py\n    !wget -O tmp2/batch2.zip https://bit.ly/3KyonQE\n    ```", "```py\n    %%time\n    ```", "```py\n    !cd tmp2 && unzip batch2.zip && rm batch2.zip\n    ```", "```py\n    import glob\n    ```", "```py\n    training_samples = glob.glob(f\"tmp2/train/*/*.png\")\n    ```", "```py\n    len(training_samples)\n    ```", "```py\n    !aws s3 mb s3://{s3_bucket}\n    ```", "```py\n    %%time\n    ```", "```py\n    !aws s3 cp tmp2/.  s3://{s3_bucket}/{prefix}/ --recursive\n    ```", "```py\n    def map_path(source):\n    ```", "```py\n        return 's3://{}/{}/{}'.format(\n    ```", "```py\n            s3_bucket, \n    ```", "```py\n            prefix, \n    ```", "```py\n            source\n    ```", "```py\n        )\n    ```", "```py\n    def map_input(source):\n    ```", "```py\n        path = map_path(source)\n    ```", "```py\n        return sagemaker.inputs.TrainingInput(\n    ```", "```py\n            path, \n    ```", "```py\n            distribution='FullyReplicated', \n    ```", "```py\n            content_type='application/x-image', \n    ```", "```py\n            s3_data_type='S3Prefix'\n    ```", "```py\n        )\n    ```", "```py\n    data_channels = {}\n    ```", "```py\n    channels = [\"train\", \n    ```", "```py\n                \"validation\",\n    ```", "```py\n                \"train_lst\",\n    ```", "```py\n                \"validation_lst\"]\n    ```", "```py\n    for channel in channels:\n    ```", "```py\n        data_channels[channel] = map_input(channel)\n    ```", "```py\n    output_path = map_path(\"output\")\n    ```", "```py\n    estimator = sagemaker.estimator.Estimator(\n    ```", "```py\n        image,\n    ```", "```py\n        role, \n    ```", "```py\n        instance_count=2, \n    ```", "```py\n        instance_type='ml.p2.xlarge',\n    ```", "```py\n        output_path=output_path,\n    ```", "```py\n        sagemaker_session=session,\n    ```", "```py\n        enable_network_isolation=True,\n    ```", "```py\n        model_uri=model_data,\n    ```", "```py\n        use_spot_instances=True,\n    ```", "```py\n        max_run=1800,\n    ```", "```py\n        max_wait=3600,\n    ```", "```py\n        base_job_name=base_job_name,\n    ```", "```py\n        checkpoint_s3_uri=checkpoint_s3_bucket,\n    ```", "```py\n        checkpoint_local_path=checkpoint_local_path\n    ```", "```py\n    )\n    ```", "```py\n    hyperparameters = {\n    ```", "```py\n        'num_training_samples': len(training_samples),\n    ```", "```py\n        'num_layers': 18,\n    ```", "```py\n        'image_shape': \"1,28,28\",\n    ```", "```py\n        'num_classes': 10,\n    ```", "```py\n        'mini_batch_size': 100,\n    ```", "```py\n        'epochs': 3,\n    ```", "```py\n        'learning_rate': 0.01,\n    ```", "```py\n        'top_k': 5,\n    ```", "```py\n        'precision_dtype': 'float32'    \n    ```", "```py\n    }\n    ```", "```py\n    estimator.set_hyperparameters(**hyperparameters)\n    ```", "```py\n    %%time\n    ```", "```py\n    estimator.fit(inputs=data_channels, logs=True)\n    ```", "```py\n    estimator.model_data\n    ```", "```py\n    !aws s3 ls {estimator.checkpoint_s3_uri} --recursive\n    ```"]