- en: '6'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '6'
- en: Clustering
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Summarize the basics of clustering
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总结聚类的要点
- en: Perform flat clustering with the k-means algorithm
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用k-means算法执行平面聚类
- en: Perform hierarchical clustering with the mean shift algorithm
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用均值漂移算法执行层次聚类
- en: In this chapter, you will learn about the fundamentals of clustering, which
    will be illustrated with two unsupervised learning algorithms.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解聚类的原理，这将通过两个无监督学习算法进行说明。
- en: Introduction to Clustering
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚类简介
- en: In the previous chapters, we dealt with supervised learning algorithms to perform
    classification and regression. We used training data to train our classification
    or regression model, and then we validated our model using testing data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们处理了监督学习算法以执行分类和回归。我们使用训练数据来训练我们的分类或回归模型，然后我们使用测试数据来验证我们的模型。
- en: In this chapter, we will perform unsupervised learning by using clustering algorithms.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过使用聚类算法进行无监督学习。
- en: 'We may use clustering to analyze data to find certain patterns and create groups.
    Apart from that, clustering can be used for many purposes:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用聚类来分析数据，以找到某些模式和创建组。除此之外，聚类还可以用于许多目的：
- en: Market segmentation detects the best stocks in the market you should be focusing
    on fundamentally. We can detect trends, segment customers, or recommend certain
    products to certain customer types using clustering.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 市场细分检测你在基本面应该关注的最佳股票。我们可以使用聚类检测趋势、细分客户或向特定客户类型推荐某些产品。
- en: In computer vision, image segmentation is performed using clustering, where
    we find different objects in an image that a computer processes.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在计算机视觉中，使用聚类进行图像分割，我们可以在图像中找到计算机处理的不同对象。
- en: Clustering can be combined with classification, where clustering may generate
    a compact representation of multiple features, which can then be fed to a classifier.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类可以与分类相结合，其中聚类可以生成多个特征的紧凑表示，然后将其输入到分类器中。
- en: Clustering may also filter data points by detecting outliers.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类还可以通过检测异常值来过滤数据点。
- en: Regardless of whether we are applying clustering to genetics, videos, images,
    or social networks, if we analyze data using clustering, we may find similarities
    between data points that are worth treating uniformly.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们是将聚类应用于遗传学、视频、图像还是社交网络，如果我们使用聚类分析数据，我们可能会发现数据点之间的相似性，这些相似性值得统一处理。
- en: We perform clustering without specified labels. Clustering defines clusters
    based on the distance between their data points. While; in classification, we
    define exact label classes to group classified data points, in clustering, there
    are no labels. We just give the machine learning model the features, and the model
    has to figure out the clusters in which those feature sets are grouped.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行聚类而不指定标签。聚类根据数据点之间的距离定义聚类。而在分类中，我们定义精确的标签类别以分组分类数据点，在聚类中则没有标签。我们只是给机器学习模型提供特征，模型必须找出这些特征集所属的聚类。
- en: Defining the Clustering Problem
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义聚类问题
- en: Suppose you are a store manager who's responsible for ensuring the profitability
    of your store. Your products are divided into categories. Different customers
    of the store prefer different items.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你是一位负责确保商店盈利性的商店经理。你的产品被分为不同的类别。不同顾客的商店偏好不同的商品。
- en: For instance, a customer interested in bio products tends to select products
    that are bio in nature. If you check out Amazon, you will also find suggestions
    for different groups of products. This is based on what users are likely to be
    interested in.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对生物产品感兴趣的顾客倾向于选择天然生物产品。如果你查看亚马逊，你也会找到针对不同产品组的建议。这是基于用户可能感兴趣的内容。
- en: We will define the clustering problem in such a way that we will be able to
    find these similarities between our data points. Suppose we have a dataset that
    consists of points. Clustering helps us understand this structure by describing
    how these points are distributed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义聚类问题，以便我们能够找到数据点之间的这些相似性。假设我们有一个由点组成的数据集。聚类帮助我们通过描述这些点的分布来理解这种结构。
- en: 'Let''s look at an example of data points in a two-dimensional space:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看二维空间中数据点的例子：
- en: '![](img/Image00055.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/Image00055.jpg)'
- en: 'Figure 6.1: Data points in a two-dimensional space'
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.1：二维空间中的数据点
- en: 'In this example, it is evident that there are three clusters:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，很明显有三个聚类：
- en: '![](img/Image00056.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/Image00056.jpg)'
- en: 'Figure 6.2: Three clusters formed using the data points in a two-dimensional
    space'
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.2：使用二维空间中的数据点形成的三个簇
- en: The three clusters were easy to detect because the points are close to one another.
    Clustering determines data points that are close to each other. There are also
    some outlier points that do not belong to any cluster. The clustering algorithm
    should be prepared to treat these outlier points properly, without moving them
    into a cluster.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于点彼此靠近，因此三个簇很容易检测到。聚类确定彼此靠近的数据点。还有一些不属于任何簇的异常点。聚类算法应该准备好适当处理这些异常点，而不会将它们移动到簇中。
- en: While it is easy to recognize clusters in a two-dimensional space, we normally
    have multidimensional data points. Therefore, it is important to know which data
    points are close to one other. Also, it is important to define distance metrics
    that detect whether data points are close to each other. One well-known distance
    metric is the Euclidean distance. In mathematics, we often use Euclidean distance
    to measure the distance between two points. Therefore, Euclidean distance is an
    intuitive choice when it comes to clustering algorithms so that we can determine
    the proximity of data points when locating clusters.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在二维空间中识别簇很容易，但我们通常有多维数据点。因此，了解哪些数据点彼此靠近很重要。同样，定义检测数据点彼此接近的距离度量也很重要。一个著名的距离度量是欧几里得距离。在数学中，我们经常使用欧几里得距离来测量两点之间的距离。因此，当涉及到聚类算法时，欧几里得距离是一个直观的选择，这样我们就可以确定数据点在定位簇时的邻近程度。
- en: 'There is one drawback to most distance metrics, including Euclidean distance:
    the more we increase the dimensions, the more uniform these distances will become
    compared to each other. Therefore, getting rid of features that act as noise rather
    than useful information may greatly increase the accuracy of the clustering model.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数距离度量（包括欧几里得距离）有一个缺点：当我们增加维度时，这些距离相对于彼此将变得更加均匀。因此，去除作为噪声而不是有用信息的特征可能会大大提高聚类模型的准确性。
- en: Clustering Approaches
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类方法
- en: 'There are two types of clustering: **flat** and **hierarchical** .'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类有两种类型：**平面**和**层次**。
- en: In flat clustering, we specify the number of clusters we would like the machine
    to find. One example of flat clustering is the k-means algorithm, where K specifies
    the number of clusters, we would like the algorithm to use.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在平面聚类中，我们指定机器要找到的簇数量。平面聚类的一个例子是k-means算法，其中K指定了算法要使用的簇数量。
- en: In hierarchical clustering, the machine learning algorithm finds out the number
    of clusters that are needed.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在层次聚类中，机器学习算法找出所需的簇数量。
- en: 'Hierarchical clustering also has two approaches:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类也有两种方法：
- en: '**Bottom-up hierarchical clustering** treats each point as a cluster. This
    approach unites clusters that are close to each other.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自底向上的层次聚类**将每个点视为一个簇。这种方法将彼此靠近的簇合并在一起。'
- en: '**Top-down hierarchical clustering** treats data points as if they were in
    one cluster spanning the whole state space. Then, the clustering algorithm splits
    our clusters into smaller ones.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自顶向下的层次聚类**将数据点视为一个覆盖整个状态空间的簇。然后，聚类算法将我们的簇分割成更小的簇。'
- en: '**Point assignment clustering** assigns new data points to existing clusters
    based on how close the new data point is to these clusters.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点分配聚类**根据新数据点到现有簇的接近程度将新数据点分配给现有簇。'
- en: Clustering Algorithms Supported by scikit-learn
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: scikit-learn支持的聚类算法
- en: 'In this chapter, we will learn about two clustering algorithms supported by
    scikit-learn: the **k-means** algorithm and the **mean shift** algorithm.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习scikit-learn支持的两种聚类算法：**k-means**算法和**均值漂移**算法。
- en: '**k-means** is an example of flat clustering, where we have to specify the
    number of clusters in advance. k-means is a generic purpose clustering algorithm
    that performs well if the number of clusters is not too high and the size of the
    clusters is even.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**k-means**是平面聚类的例子，我们必须提前指定簇的数量。k-means是一种通用目的的聚类算法，如果簇的数量不是太高且簇的大小均匀，则表现良好。'
- en: '**Mean-shift** is an example of hierarchical clustering, where the clustering
    algorithm determines the number of clusters. Mean shift is used when we don''t
    know the number of clusters in advance. In contrast with k-means, mean shift supports
    use cases where many clusters are present, even if the size of the clusters greatly
    differs.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**均值漂移**是层次聚类的一个例子，其中聚类算法确定簇的数量。当事先不知道簇的数量时，使用均值漂移。与k-means相比，均值漂移支持存在许多簇的用例，即使簇的大小差异很大。'
- en: 'scikit-learn provides other clustering algorithms. These are as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn提供了其他聚类算法。这些如下：
- en: '**Affinity Propagation** : Performs similarly to Mean Shift'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**亲和传播**：与均值漂移表现相似'
- en: '**Spectral clustering** : Performs better if only a few clusters are present,
    with even cluster sizes'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谱聚类**：如果只有少数簇存在，且簇的大小均匀，则表现更好'
- en: '**Ward hierarchical clustering** : Used when many clusters are expected'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ward层次聚类**：当预期有许多簇时使用'
- en: '**Agglomerative clustering** : Used when many clusters are expected'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层次聚类**：当预期有许多簇时使用'
- en: '**DBSCAN clustering** : Supports uneven cluster sizes and non-flat geometry
    of point distributions'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DBSCAN聚类**：支持不均匀的簇大小和点分布的非平面几何'
- en: '**Gaussian mixtures** : Uses flat geometry, which is good for density estimations'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高斯混合**：使用平面几何，这对于密度估计很有用'
- en: '**Birch clustering** : Supports large datasets, removes outliers, and supports
    data reduction'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Birch聚类**：支持大型数据集，去除异常值，并支持数据降维'
- en: For a complete description of clustering algorithms, including performance comparisons,
    visit the clustering page of scikit-learn at [http://scikit-learn.org/stable/modules/clustering.html](http://scikit-learn.org/stable/modules/clustering.html)
    .
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要完整描述聚类算法，包括性能比较，请访问scikit-learn的聚类页面，网址为[http://scikit-learn.org/stable/modules/clustering.html](http://scikit-learn.org/stable/modules/clustering.html)。
- en: The k-means Algorithm
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k-means算法
- en: 'The k-means algorithm is a flat clustering algorithm. It works as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法是一种平面聚类算法。它的工作原理如下：
- en: Set the value of K.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置K的值。
- en: Choose K data points from the dataset that are initial centers of the individual
    clusters.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据集中选择K个数据点作为各个簇的初始中心。
- en: Calculate the distance of each data point to the chosen center points, and group
    each point in the cluster whose initial center is the closest to the data point.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算每个数据点到所选中心点的距离，并将每个点分组到其初始中心点最接近的数据点所在的簇中。
- en: Once all of the points are in one of the K clusters, calculate the center point
    of each cluster. This center point does not have to be an existing data point
    in the dataset; it is just an average.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当所有点都位于K个簇之一中时，计算每个簇的中心点。这个中心点不必是数据集中的现有数据点；它只是一个平均值。
- en: Repeat this process of assigning each data point into the cluster that has a
    center closest to the data point. Repetition continues until the center points
    no longer move.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复将每个数据点分配到中心点最接近数据点的簇的过程。重复进行，直到中心点不再移动。
- en: 'To make sure that the k-means algorithm terminates, we need the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保k-means算法终止，我们需要以下条件：
- en: A maximum level of tolerance when we exit in case the centroids move less than
    the tolerance value
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当质心移动小于容差值时，我们退出时的最大容差级别
- en: A maximum number of repetitions of shifting the moving points
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动点的最大重复次数
- en: Due to the nature of the k-means algorithm, it will have a hard time dealing
    with clusters that greatly differ in size.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于k-means算法的性质，它将很难处理大小差异很大的簇。
- en: 'The k-means algorithm has many use cases that are part of our everyday lives:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法有许多用例，这些都是我们日常生活中的一部分：
- en: '**Market segmentation:** Companies gather all sorts of data from their customer
    base. Performing k-means clustering analysis on the customer base of a company
    reveals market segments that have defined characteristics. Customers belonging
    to the same segment can be treated similarly. Different segments receive different
    treatment.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**市场细分**：公司从其客户群中收集各种数据。对公司客户群进行k-means聚类分析可以揭示具有定义特性的市场细分。属于同一细分市场的客户可以类似对待。不同的细分市场将接受不同的处理。'
- en: '**Classification of books, movies, or other documents:** When influencers build
    their personal brand, authors write books and create books, or a company manages
    its social media accounts, content is king. Content is often described by hashtags
    and other data. This data can be used as a basis for clustering to locate groups
    of documents that are similar in nature.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**书籍、电影或其他文档的分类**：当影响者建立他们的个人品牌时，作者会写书并创作书籍，或者公司管理其社交媒体账户，内容为王。内容通常由标签和其他数据描述。这些数据可以用作聚类的依据，以定位性质相似的文档组。'
- en: '**Detection of fraud and criminal activities:** Fraudsters often leaves clues
    in the form of unusual customer or visitor behavior. For instance, car insurance
    protects drivers from theft and damage arising from accidents. Real theft and
    fake theft are characterized by different feature values. Similarly, wrecking
    a car on purpose leaves different traces than wrecking a car by accident. Clustering
    can often detect fraud, helping industry professionals understand the behavior
    of their worst customers better.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**欺诈和犯罪活动的检测**：欺诈者经常以异常的客户或访客行为的形式留下线索。例如，汽车保险保护驾驶者免受盗窃和事故造成的损害。真实盗窃和虚假盗窃具有不同的特征值。同样，故意撞毁汽车留下的痕迹与意外撞毁汽车留下的痕迹不同。聚类通常可以检测欺诈，帮助行业专业人士更好地了解他们最差的客户的行为。'
- en: 'Exercise 19: k-means in scikit-learn'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习19：scikit-learn中的k-means
- en: 'To plot data points in a two-dimensional plane and execute the k-means algorithm
    on them to perform clustering, execute the following steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要在二维平面上绘制数据点并对其执行k-means算法以进行聚类，请执行以下步骤：
- en: 'We will create an artificial dataset as a NumPy Array to demonstrate the k-means
    algorithm:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个NumPy Array的人工数据集来演示k-means算法：
- en: '[PRE0]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can plot these data points in the two-dimensional plane using `matplotlib.pyplot`
    :'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以使用`matplotlib.pyplot`在二维平面上绘制这些数据点：
- en: '[PRE1]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is as follows:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/Image00057.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/Image00057.jpg)'
- en: 'Figure 6.3: Graph showing the data points on a two-dimensional plane using
    matplotlib.pyplot'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.3：使用matplotlib.pyplot在二维平面上显示数据点的图表
- en: Note
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'We used the `transpose array` method to get the values of the first feature
    and the second feature. This is in alignment with the previous chapters. We could
    also use proper array indexing to access these columns: `dataPoints[:,0]` is equivalent
    to `dataPoints.transpose()[0]` .'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用了`transpose array`方法来获取第一个特征和第二个特征值。这与前面的章节一致。我们也可以使用适当的数组索引来访问这些列：`dataPoints[:,0]`等同于`dataPoints.transpose()[0]`。
- en: 'Now that we have the data points, it''s time to execute the k-means algorithm
    on them. If we define K as `3` in the k-means algorithm, we expect a cluster on
    the bottom-left, top-left, and bottom-right corner of the graph:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了数据点，是时候对它们执行k-means算法了。如果我们把k-means算法中的K定义为`3`，我们期望在图表的左下角、右上角和右下角有一个簇：
- en: '[PRE2]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the clustering is done, we can access the center point of each cluster:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚类完成后，我们可以访问每个簇的中心点：
- en: '[PRE3]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output will be as follows:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE4]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Indeed, the center points of the clusters appear to be in the bottom-left, top-left,
    and bottom-right corners of the graph. The X-coordinate of the top-left cluster
    is 3.1, most likely because it contains our outlier data point [10, 10].
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 事实上，簇的中心点似乎位于图表的左下角、右上角和右下角。右上角簇的X坐标是3.1，这很可能是由于它包含了我们的异常数据点[10, 10]。
- en: 'Let''s plot the clusters with different colors and their center points. To
    know which data point belongs to which cluster, we have to query the `labels_`
    property of the k-means classifier:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们用不同的颜色绘制簇及其中心点。要知道哪个数据点属于哪个簇，我们必须查询k-means分类器的`labels_`属性：
- en: '[PRE5]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output will be as follows:'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE6]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output array shows which data point belongs to which cluster. This is all
    we need to plot the data:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出数组显示了哪些数据点属于哪个簇。这是我们绘制数据所需的所有信息：
- en: '[PRE7]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/Image00058.jpg)'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/Image00058.jpg)'
- en: 'Figure 6.4: Graph showing the data points in red, green, and blue while selecting
    three clusters'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.4：显示红色、绿色和蓝色数据点并选择三个簇的图表
- en: The blue center points are indeed inside their clusters, which are represented
    by the red points, the green points, and the yellow points.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 蓝色的中心点确实位于它们的簇中，这些簇由红色点、绿色点和黄色点表示。
- en: 'Let''s see what happens if we choose only two clusters instead of three:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看如果我们选择两个簇而不是三个簇会发生什么：
- en: '[PRE8]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output is as follows:'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/Image00059.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/Image00059.jpg)'
- en: 'Figure 6.5: Graph showing the datapoints in red, blue, and green while selecting
    two clusters'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.5：显示在选择两个簇时红色、蓝色和绿色数据点的图形
- en: This time, we only have red and green points, and we have a bottom cluster and
    a top cluster. Interestingly, the top red cluster in the second example contains
    the same points as the top cluster in the first example. The bottom cluster of
    the second example consists of the data points joining the bottom-left and the
    bottom-right clusters of the first example.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次，我们只有红色和绿色点，我们有一个底部簇和一个顶部簇。有趣的是，第二个示例中的顶部红色簇包含与第一个示例中顶部簇相同的点。第二个示例的底部簇由第一个示例的底部左簇和底部右簇的数据点组成。
- en: 'We can also use the k-means model for prediction. The output is an array containing
    the cluster numbers belonging to each data point:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用 k-means 模型进行预测。输出是一个包含每个数据点所属簇编号的数组：
- en: '[PRE9]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE10]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameterization of the k-means Algorithm in scikit-learn
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: scikit-learn 中 k-means 算法的参数化
- en: Like the classification and regression models in Chapters 3, 4, and 5, the k-means
    algorithm can also be parameterized. The complete list of parameters can be found
    at [http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    .
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与第 3、4 和 5 章中的分类和回归模型一样，k-means 算法也可以参数化。完整的参数列表可以在[http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    找到。
- en: 'Some examples are as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些示例：
- en: '`n_clusters` : The number of clusters in which the data points are separated.
    The default value is **8** .'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_clusters`：数据点被分离的簇的数量。默认值是 **8**。'
- en: '`max_iter` : The maximum number of iterations.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_iter`：最大迭代次数。'
- en: '`tol` : The tolerance for checking whether we can exit the k-means algorithm.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tol`：检查我们是否可以退出 k-means 算法的容差。'
- en: 'In the previous section, we used two attributes to retrieve the cluster center
    points and the clusters themselves:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用了两个属性来检索簇中心点和簇本身：
- en: '`cluster_centers_` : This returns the coordinates of the cluster center points.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`cluster_centers_`：这返回簇中心点的坐标。'
- en: '`labels_` : This returns an array of integers symbolizing the number of clusters
    the data point belongs to. Numbering starts from zero.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`labels_`：这返回一个表示数据点所属簇编号的整数数组。编号从零开始。'
- en: 'Exercise 20: Retrieving the Center Points and the Labels'
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 20：检索中心点和标签
- en: 'To understand the usage of `cluster_centers_` and `labels_` , perform the following
    steps:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解 `cluster_centers_` 和 `labels_` 的用法，请执行以下步骤：
- en: 'Recall the example that we had from executing the k-means algorithm in scikit-learn.
    We had 12 data points and three clusters:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回想一下我们从 scikit-learn 中执行 k-means 算法时的示例。我们有 12 个数据点和三个簇：
- en: '[PRE11]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE12]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Apply the **labels_** property on the cluster:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在簇上应用 **labels_** 属性：
- en: '[PRE13]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE14]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output of the **cluster_centers_** property is obvious: it shows the X
    and Y coordinates of the center points. The **labels_** property is an array of
    length 12, showing the cluster of each of the 12 data points it belongs to. The
    first cluster is associated with the number 0, the second is associated with 1,
    the third is associated with 2, and so on.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**cluster_centers_** 属性的输出很明显：它显示了中心点的 X 和 Y 坐标。**labels_** 属性是一个长度为 12 的数组，显示了它所属的
    12 个数据点的簇。第一个簇与数字 0 相关联，第二个与 1 相关联，第三个与 2 相关联，以此类推。'
- en: k-means Clustering of Sales Data
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 销售数据的 k-means 聚类
- en: In the upcoming activity, we will be considering sales data and we will perform
    k-means clustering on that sales data.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在即将进行的活动过程中，我们将考虑销售数据，并将在这些销售数据上执行 k-means 聚类。
- en: 'Activity 12: k-means Clustering of Sales Data'
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 12：销售数据的 k-means 聚类
- en: In th is section, we will detect product sales that perform similarly to recognize
    trends in product sales.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检测表现相似的产品销售，以识别产品销售趋势。
- en: 'We will be using the Sales Transactions Weekly Dataset, found at the following
    URL:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下 URL 中的销售交易周数据集：
- en: '[https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly](https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly)
    Perform clustering on the dataset using the k-means algorithm. Make sure that
    you prepare your data for clustering based on what you have learned in the previous
    chapters.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly](https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly)
    使用 k-means 算法对数据集进行聚类。确保你根据之前章节中学到的知识准备你的聚类数据。'
- en: 'Use the default settings for the k-means algorithm:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 k-means 算法的默认设置：
- en: Load the dataset using pandas. If you examine the data in the CSV file, you
    will realize that the first column contains product ID strings. These values just
    add noise to the clustering process. Also, notice that for weeks 0 to 51, there
    is a W-prefixed label and a normalized label. Using the normalized label makes
    more sense so that we can drop the regular weekly labels from the dataset.Create
    a k-means clustering model and fit the data points into 8 clusters.Retrieve the
    center points and the labels from the clustering algorithm.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 加载数据集。如果你检查 CSV 文件中的数据，你会意识到第一列包含产品 ID 字符串。这些值只是给聚类过程添加噪声。此外，请注意，对于第
    0 周到第 51 周，存在带有 W 前缀的标签和归一化标签。使用归一化标签更有意义，这样我们就可以从数据集中删除常规的每周标签。创建一个 k-means 聚类模型，并将数据点拟合到
    8 个聚类中。从聚类算法中检索中心点和标签。
- en: The labels belonging to each data point can be retrieved using the **labels_**
    property. These labels determine the clustering of the rows of the original data
    frame. How are these labels beneficial?
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **labels_** 属性可以检索每个数据点的标签。这些标签决定了原始数据框中行的聚类。这些标签有什么好处？
- en: Suppose that, in the original data frame, the product names are given. You can
    easily recognize the fact that similar types of products sell similarly. There
    are also products that fluctuate a lot, and products that are seasonal in nature.
    For instance, if some products promote fat loss and getting into shape, they tend
    to sell during the first half of the year, before the beach season.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，在原始数据框中，产品名称是给出的。你可以很容易地认识到类似类型的产品销售情况相似。也有一些产品波动很大，还有一些季节性产品。例如，如果某些产品宣传减肥和塑形，它们往往在年初的销售，在海滩季节之前。
- en: Note
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity is available at page 291.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在第 291 页找到。
- en: Mean Shift Algorithm
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 均值漂移算法
- en: Mean shift is a hierarchical clustering algorithm. Unlike the k-means algorithm,
    in mean shift, the clustering algorithm determines how many clusters are needed,
    and also performs the clustering. This is advantageous because we rarely know
    how many clusters we are looking for.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移是一种层次聚类算法。与 k-means 算法不同，在均值漂移中，聚类算法确定需要多少个聚类，并执行聚类。这有优势，因为我们很少知道我们正在寻找多少个聚类。
- en: This algorithm also has many use cases in our everyday lives. For instance,
    the Xbox Kinect device detects human body parts using the mean shift algorithm.
    Some mobile phones also use the Mean Shift algorithm to detect faces. With the
    growth of social media platforms, image segmentation is a feature that many users
    have gotten used to. As image segmentation is also a basis of computer vision,
    some applications can be found there. The mean shift algorithm may also save lives,
    as it is built into the car detection software of many modern cars. Imagine that
    someone emergency brakes in front of you. The image segmentation software of your
    car detects that the car in front of you is getting alarmingly close to you and
    applies the emergency brake before you even realize the emergency situation. These
    driver aids are widespread in modern cars. Self-driving cars are just one step
    away.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法在我们的日常生活中也有许多应用场景。例如，Xbox Kinect 设备使用均值漂移算法检测人体部位。一些手机也使用均值漂移算法来检测人脸。随着社交媒体平台的增长，图像分割已成为许多用户习惯的功能。由于图像分割也是计算机视觉的基础，因此在该领域可以找到一些应用。均值漂移算法甚至可能拯救生命，因为它被集成到许多现代汽车的车辆检测软件中。想象一下，如果有人在你面前紧急刹车。你的汽车图像分割软件会检测到你前面的车辆正危险地接近你，并在你意识到紧急情况之前施加紧急制动。这些驾驶辅助系统在现代汽车中很常见。自动驾驶汽车仅一步之遥。
- en: 'Exercise 21: Illustrating Mean Shift in 2D'
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 21：在 2D 中展示均值漂移
- en: 'To learn clustering by using the mean shift algorithm, execute the following
    steps:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过使用均值漂移算法学习聚类，请执行以下步骤：
- en: 'Let''s recall the data points from the previous topic:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们回顾一下之前主题中的数据点：
- en: '[PRE15]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Our task now is to find a point P (x, y), for which the number of data points
    within a radius R from point P is maximized. The points are distributed as follows:![](img/Image00060.jpg)
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在的任务是找到一个点P (x, y)，使得从点P出发，半径R内的数据点数量最大化。点分布如下：![](img/Image00060.jpg)
- en: 'Figure 6.6: Graph showing the data points from the data_points array'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.6：显示data_points数组数据点的图表
- en: 'Suppose we initially equate point P to the first data point, [1, 1]:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们最初将点P等同于第一个数据点，[1, 1]：
- en: '[PRE16]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let''s find the points that are within a distance of R from this point:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们找到距离这个点R距离内的点：
- en: '[PRE17]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output will be as follows:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE18]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s calculate the mean of the data points:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算数据点的平均值：
- en: '[PRE19]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output will be as follows:'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE20]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now that the new mean has been calculated, we can retrieve the points within
    the given radius again:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在新的平均值已经计算出来，我们可以再次检索给定半径内的点：
- en: '[PRE21]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output will be as follows:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE22]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: These are the same three points, so we can stop here. Three points have been
    found around the mean of `[1.3333333333333333, 1.5]` . The points around this
    center within a radius of 2 form a cluster.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些是相同的三个点，所以我们在这里可以停止。已经找到了围绕平均值[1.3333333333333333, 1.5]的三个点。在这个中心半径为2的点形成了一个簇。
- en: 'If we examined the data points [1, 1.5] and [2, 2], we would get the same result.
    Let''s continue with the fourth point in our list, [8, 1]:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们检查数据点[1, 1.5]和[2, 2]，我们会得到相同的结果。让我们继续处理列表中的第四个点，[8, 1]：
- en: '[PRE23]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output will be as follows:'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE24]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This time, all four points in the area were found. Therefore, we can simply
    calculate their mean:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这次，我们找到了该区域的所有四个点。因此，我们可以简单地计算它们的平均值：
- en: '[PRE25]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output will be as follows:'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE26]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This mean will not change, as in the next iteration, we will find the same data
    points.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个平均值不会改变，因为在下一次迭代中，我们会找到相同的数据点。
- en: 'Notice that we got lucky with the selection of the point [8, 1]. If we started
    with `P = [8, 0]` or `P = [8.5, 1]` , we would only find three points instead
    of four:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，我们在选择点[8, 1]时很幸运。如果我们从`P = [8, 0]`或`P = [8.5, 1]`开始，我们只会找到三个点而不是四个：
- en: '[PRE27]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output will be as follows:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE28]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'After calculating the mean of these three points, we would have to rerun the
    distance calculation with the shifted mean:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算这三个点的平均值后，我们必须重新运行距离计算，使用偏移的平均值：
- en: '[PRE29]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output will be as follows:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE30]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output for point P = [8.5, 1] is the following array:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点P = [8.5, 1]的输出如下数组：
- en: '[PRE31]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We only found the same three points again. This means that starting from [8,1],
    we got a larger cluster than starting from [8, 0] or [8.5, 1]. Therefore, we have
    to take the center point that contains the maximum number of data points.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们只又找到了相同的三个点。这意味着从[8,1]开始，我们得到的簇比从[8, 0]或[8.5, 1]开始要大。因此，我们必须选择包含最多数据点的中心点。
- en: 'Now, let''s examine what would happen if we started the discovery from the
    fourth data point, **[6, 1]** :'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看如果我们从第四个数据点开始发现会发生什么，**[6, 1]**：
- en: '[PRE32]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output will be as follows:'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE33]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We successfully found the data point [8, 1]. Therefore, we have to shift the
    mean from [6, 1] to the calculated new mean, [7, 1]:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们成功找到了数据点[8, 1]。因此，我们必须将平均值从[6, 1]移动到计算出的新平均值[7, 1]：
- en: '[PRE34]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output will be as follows:'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE35]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s check if we found more points:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查是否找到了更多的点：
- en: '[PRE36]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output will be as follows:'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE37]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Yes – we successfully found all four points! Therefore, we have successfully
    defined a cluster of size 4\. The mean will be the same as before: `[7.625, 0.75]`
    .'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 是的——我们成功找到了所有四个点！因此，我们成功地定义了一个大小为4的簇。平均值将与之前相同：[7.625, 0.75]。
- en: 'This was a simple clustering example that applied the mean shift algorithm.
    We only provided an illustration of what the algorithm considers to find the clusters.
    There is one remaining question, though: the value of the radius.'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个简单的聚类示例，应用了均值漂移算法。我们只提供了算法考虑用于找到聚类的说明。尽管如此，还有一个问题：半径的值。
- en: Note that if the radius of 2 was not set, we could simply start either with
    a huge radius including all data points and then reduce the radius or start with
    a very small radius, making sure that each data point is in its own cluster, and
    then increase the radius until we get the desired result.
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，如果半径为2没有设置，我们可以简单地从一个包含所有数据点的巨大半径开始，然后减小半径，或者从一个非常小的半径开始，确保每个数据点都在它自己的簇中，然后增加半径，直到我们得到期望的结果。
- en: Mean Shift Algorithm in scikit-learn
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: scikit-learn中的均值漂移算法
- en: 'Let''s use the same data points as in the k-means algorithm:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用与k-means算法相同的数据点：
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The syntax of the mean shift clustering algorithm is similar to the k-means
    clustering algorithm.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移聚类算法的语法与k-means聚类算法类似。
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Once clustering is done, we can access the center point of each cluster:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成聚类，我们可以访问每个聚类的中心点：
- en: '[PRE40]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output will be as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE41]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The Mean Shift model found 5 clusters with the centers shown in the preceding
    code.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移模型找到了5个聚类，其中心点在前面代码中显示。
- en: 'Similar to k-means,, we can also get the labels:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 与k-means类似，我们也可以获取标签：
- en: '[PRE42]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output will be as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE43]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output array shows which data point belongs to which cluster. This is all
    we need to plot the data:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 输出数组显示了哪些数据点属于哪个聚类。这是我们绘制数据所需的所有信息：
- en: '[PRE44]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output will be as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '![](img/Image00061.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image00061.jpg)'
- en: 'Figure 6.7: Graph based on k-means,'
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.7：基于k-means的图，
- en: The three blue points are the center points of the red, green, and yellow clusters.
    There are two more single dot clusters in the coordinate system, belonging to
    the points (6,1) and (10,10).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 三个蓝色点分别是红色、绿色和黄色聚类的中心点。在坐标系中还有两个单独的点聚类，分别属于点(6,1)和(10,10)。
- en: Image Processing in Python
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python中的图像处理
- en: To solve the upcoming activity, you need to know how to process images in Python.
    We will use the SciPy library for this.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决即将到来的活动，你需要知道如何在Python中处理图像。我们将使用SciPy库来完成这项工作。
- en: There are multiple ways that you can read an image file from a path.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从路径读取图像文件有多种方式。
- en: 'The easiest one is the **Image** interface from the Python Imaging Library
    (PIL):'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的一种方法是来自Python Imaging Library (PIL)的**Image**接口：
- en: '[PRE45]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The preceding code assumes that the file path specified in the string argument
    of the **open** method points to a valid image file.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码假设在**open**方法的字符串参数中指定的文件路径指向一个有效的图像文件。
- en: 'We can get the size of the image by querying the size property:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查询大小属性来获取图像的大小：
- en: '[PRE46]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The output will be as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE47]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We can create a two-dimensional NumPy array from the image containing the RGB
    values of each pixel:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从包含每个像素RGB值的图像创建一个二维NumPy数组：
- en: '[PRE48]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Once the pixel array has been constructed, we can easily retrieve and manipulate
    each pixel:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦构建了像素数组，我们就可以轻松地检索和操作每个像素：
- en: '[PRE49]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output will be as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE50]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The pixels of the image can also be made accessible using the `load()` method
    of the image. Once we get access to these pixels, we can get the RGB or RGBA values
    of each pixel, depending on the file format:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过图像的`load()`方法使图像的像素可访问。一旦我们获得了对这些像素的访问权限，我们可以根据文件格式获取每个像素的RGB或RGBA值：
- en: '[PRE51]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output will be as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE52]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Notice that the order of pixel coordinates is the opposite, that is, `pixel_array[411][740]`
    when reading from left to right. We are reading the exact same pixel, but we have
    to supply the coordinates differently.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，像素坐标的顺序是相反的，即从左到右读取时为`pixel_array[411][740]`。我们正在读取完全相同的像素，但我们必须以不同的方式提供坐标。
- en: 'We can also set pixels to a new value:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将像素设置为新的值：
- en: '[PRE53]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'If you want to save changes, use the `save()` method of the image:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要保存更改，请使用图像的`save()`方法：
- en: '[PRE54]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'To perform clustering analysis on the pixels of the image, we need to convert
    the image to a data frame. This implies that we have to convert the pixels of
    the image to a tuple or array of `[''x'', ''y'', ''red'', ''green'', ''blue'']`
    values. Once we have a one-dimensional array of these values, we can convert them
    to a pandas DataFrame:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 要对图像的像素进行聚类分析，我们需要将图像转换为数据框。这意味着我们必须将图像的像素转换为`['x', 'y', 'red', 'green', 'blue']`值的元组或数组。一旦我们有一个这些值的单维数组，我们可以将它们转换为pandas
    DataFrame：
- en: '[PRE55]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output will be as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下：
- en: '[PRE56]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: This is all you need to know to complete the activity on processing images using
    the Mean Shift algorithm.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这是完成使用均值漂移算法处理图像活动所需了解的所有内容。
- en: 'Activity 13: Shape Recognition with the Mean Shift Algorithm'
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动第13项：使用均值漂移算法进行形状识别
- en: In this section, we will learn how images can be clustered. Imagine you are
    working for a company that detects human emotions from photos. Your task is to
    extract pixels making up a face in an avatar photo.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何对图像进行聚类。想象一下，你正在为一家公司工作，该公司从照片中检测人类情绪。你的任务是提取头像照片中构成脸部的像素。
- en: Create a clustering algorithm with Mean Shift to cluster pixels of images. Examine
    the results of the Mean Shift algorithm and check whether any of the clusters
    contain a face when used on avatar images.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个使用均值漂移进行图像像素聚类的聚类算法。检查均值漂移算法的结果，并检查在用于头像图像时，是否有任何聚类包含面部。
- en: 'Then, apply the k-means, algorithm with a fixed default number of clusters
    (8, in this case). Compare your results with the Mean Shift clustering algorithm:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，应用具有固定默认聚类数（在这种情况下为8）的k均值算法。将你的结果与均值漂移聚类算法进行比较：
- en: Select an image you would like to cluster and load the image.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择你想要聚类的图像并加载图像。
- en: Transform the pixels into a data frame to perform clustering. Perform Mean Shift
    clustering on the image using scikit-learn. Note that, this time, we will skip
    normalizing the features, because the proximity of the pixels and the proximity
    of the color components are represented in a close to equal weight. The algorithm
    will find two clusters.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将像素转换为数据帧以执行聚类。使用scikit-learn在图像上执行均值漂移聚类。请注意，这次，我们将跳过特征归一化，因为像素的邻近性和颜色成分的邻近性以几乎相等的权重表示。算法将找到两个聚类。
- en: Depending on the image you use, notice how the Mean Shift algorithm treats human
    skin color, and what other parts of the image are placed in the same cluster.
    The cluster containing most of the skin in the avatar often includes data points
    that are very near and/or have a similar color as the color of the skin.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据你使用的图像，注意均值漂移算法如何处理人类肤色，以及图像的哪些其他部分被放置在同一个聚类中。包含头像中大部分肤色的聚类通常包括非常接近和/或与肤色颜色相似的数据点。
- en: Let's use the k-means algorithm to formulate eight clusters on the same data.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用K均值算法在相同的数据上形成八个聚类。
- en: You will see that the clustering algorithm indeed located data points that are
    close and contain similar colors.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到聚类算法确实定位了接近且颜色相似的数据点。
- en: Note
  id: totrans-255
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity is available at page 293.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在第293页找到。
- en: Summary
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how clustering works. Clustering is a form of unsupervised
    learning, where the features are given, and the clustering algorithm finds the
    labels.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了聚类是如何工作的。聚类是一种无监督学习形式，其中特征是给定的，聚类算法找到标签。
- en: 'There are two types of clustering: flat and hierarchical.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类有两种类型：平面和层次。
- en: The k-means algorithm is a flat clustering algorithm, where we determine K center
    points for our K clusters, and the algorithm finds the data points.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: K均值算法是一种平面聚类算法，其中我们为我们的K个聚类确定K个中心点，算法找到数据点。
- en: Mean Shift is an example of a hierarchical clustering algorithm, where the number
    of distinct label values is to be determined by the algorithm.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移是层次聚类算法的一个例子，其中要确定的唯一标签值的数量由算法决定。
- en: The final chapter will introduce a field that has become popular this decade
    due to the explosion of computation power and cheap, scalable online server capacity.
    This field is the science of neural networks and deep learning.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一章将介绍一个由于计算能力的爆炸式增长和廉价、可扩展的在线服务器容量而成为本十年热门领域的科学——神经网络和深度学习。
