["```py\nestimator = Estimator(...) \nestimator.set_hyperparameters(...)\nestimator.fit(...)\n```", "```py\nstep_train = TrainingStep(\n    name=\"TrainModel\",\n    estimator=estimator,\n    inputs=...\n)\n```", "```py\npipeline = Pipeline(\n    name=...,\n    parameters=...,\n    steps=[\n        ..., \n        step_train,\n        ...\n    ],\n)\n# create (or update) the ML pipeline\npipeline.upsert(...)\n```", "```py\nexecution = pipeline.start()\n```", "```py\n    !wget -O processing.py https://bit.ly/3QiGDQO\n    ```", "```py\n    !mkdir -p tmp\n    ```", "```py\n    !wget -O tmp/bookings.all.csv https://bit.ly/3BUcMK4\n    ```", "```py\n    s3_bucket = '<INSERT S3 BUCKET NAME HERE>'\n    ```", "```py\n    prefix = 'pipeline'\n    ```", "```py\n!aws s3 mb s3://{s3_bucket}\n```", "```py\n    source_path = f's3://{s3_bucket}/{prefix}' + \\\n    ```", "```py\n                   '/source/dataset.all.csv'\n    ```", "```py\n    !aws s3 cp tmp/bookings.all.csv {source_path}\n    ```", "```py\n    import boto3\n    ```", "```py\n    import sagemaker\n    ```", "```py\n    from sagemaker import get_execution_role\n    ```", "```py\n    from sagemaker.sklearn.processing import (\n    ```", "```py\n        SKLearnProcessor\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.workflow.steps import (\n    ```", "```py\n        ProcessingStep, \n    ```", "```py\n        TrainingStep\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.workflow.step_collections import (\n    ```", "```py\n        RegisterModel\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.processing import (\n    ```", "```py\n        ProcessingInput, \n    ```", "```py\n        ProcessingOutput\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.workflow.parameters import (\n    ```", "```py\n        ParameterString\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.inputs import TrainingInput\n    ```", "```py\n    from sagemaker.estimator import Estimator\n    ```", "```py\n    from sagemaker.workflow.pipeline import Pipeline\n    ```", "```py\n    role = get_execution_role()\n    ```", "```py\n    session = sagemaker.Session()\n    ```", "```py\n    input_data = ParameterString(\n    ```", "```py\n        name=\"RawData\",\n    ```", "```py\n        default_value=source_path, \n    ```", "```py\n    )\n    ```", "```py\n    input_raw = ProcessingInput(\n    ```", "```py\n        source=input_data,\n    ```", "```py\n        destination='/opt/ml/processing/input/'\n    ```", "```py\n    )\n    ```", "```py\n    output_split = ProcessingOutput(\n    ```", "```py\n        output_name=\"split\",\n    ```", "```py\n        source='/opt/ml/processing/output/', \n    ```", "```py\n        destination=f's3://{s3_bucket}/{prefix}/output/'\n    ```", "```py\n    )\n    ```", "```py\n    processor = SKLearnProcessor(\n    ```", "```py\n        framework_version='0.20.0',\n    ```", "```py\n        role=role,\n    ```", "```py\n        instance_count=1,\n    ```", "```py\n        instance_type='ml.m5.large'\n    ```", "```py\n    )\n    ```", "```py\n    step_process = ProcessingStep(\n    ```", "```py\n        name=\"PrepareData\",  \n    ```", "```py\n        processor=processor,\n    ```", "```py\n        inputs=[input_raw],\n    ```", "```py\n        outputs=[output_split],\n    ```", "```py\n        code=\"processing.py\",\n    ```", "```py\n    )\n    ```", "```py\n    model_path = f\"s3://{s3_bucket}/{prefix}/model/\"\n    ```", "```py\n    model_id = \"autogluon-classification-ensemble\"\n    ```", "```py\n    region_name = \"us-west-2\"\n    ```", "```py\n    from sagemaker import image_uris\n    ```", "```py\n    train_image_uri = image_uris.retrieve(\n    ```", "```py\n        region=region_name,\n    ```", "```py\n        framework=None,\n    ```", "```py\n        model_id=model_id,\n    ```", "```py\n        model_version=\"*\",\n    ```", "```py\n        image_scope=\"training\",\n    ```", "```py\n        instance_type=\"ml.m5.xlarge\",\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker import script_uris\n    ```", "```py\n    train_source_uri = script_uris.retrieve(\n    ```", "```py\n        model_id=model_id, \n    ```", "```py\n        model_version=\"*\", \n    ```", "```py\n        script_scope=\"training\"\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker import model_uris\n    ```", "```py\n    train_model_uri = model_uris.retrieve(\n    ```", "```py\n        model_id=model_id, \n    ```", "```py\n        model_version=\"*\", \n    ```", "```py\n        model_scope=\"training\"\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.estimator import Estimator\n    ```", "```py\n    estimator = Estimator(\n    ```", "```py\n        image_uri=train_image_uri,\n    ```", "```py\n        source_dir=train_source_uri,\n    ```", "```py\n        model_uri=train_model_uri,\n    ```", "```py\n        entry_point=\"transfer_learning.py\",\n    ```", "```py\n        instance_count=1,\n    ```", "```py\n        instance_type=\"ml.m5.xlarge\",\n    ```", "```py\n        max_run=900,\n    ```", "```py\n        output_path=model_path,\n    ```", "```py\n        session=session,\n    ```", "```py\n        role=role\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.hyperparameters import retrieve_default\n    ```", "```py\n    hyperparameters = retrieve_default(\n    ```", "```py\n        model_id=model_id, \n    ```", "```py\n        model_version=\"*\"\n    ```", "```py\n    )\n    ```", "```py\n    hyperparameters[\"verbosity\"] = \"3\"\n    ```", "```py\n    estimator.set_hyperparameters(**hyperparameters) \n    ```", "```py\n    s3_data = step_process         \\\n    ```", "```py\n        .properties                \\\n    ```", "```py\n        .ProcessingOutputConfig    \\\n    ```", "```py\n        .Outputs[\"split\"]          \\\n    ```", "```py\n        .S3Output.S3Uri            \\\n    ```", "```py\n    step_train = TrainingStep(\n    ```", "```py\n        name=\"TrainModel\",\n    ```", "```py\n        estimator=estimator,\n    ```", "```py\n        inputs={\n    ```", "```py\n            \"training\": TrainingInput(\n    ```", "```py\n                s3_data=s3_data,\n    ```", "```py\n            )\n    ```", "```py\n        },\n    ```", "```py\n    )\n    ```", "```py\n{'step_name': 'PrepareData',\n 'path':  \"ProcessingOutputConfig.Outputs['split']\n           .S3Output.S3Uri\",\n '_shape_names': ['S3Uri'],\n '__str__': 'S3Uri'} \n```", "```py\n    deploy_image_uri = image_uris.retrieve(\n    ```", "```py\n        region=region_name,\n    ```", "```py\n        framework=None,\n    ```", "```py\n        image_scope=\"inference\",\n    ```", "```py\n        model_id=model_id,\n    ```", "```py\n        model_version=\"*\",\n    ```", "```py\n        instance_type=\"ml.m5.xlarge\",\n    ```", "```py\n    )\n    ```", "```py\n    deploy_source_uri = script_uris.retrieve(\n    ```", "```py\n        model_id=model_id, \n    ```", "```py\n        model_version=\"*\", \n    ```", "```py\n        script_scope=\"inference\"\n    ```", "```py\n    )\n    ```", "```py\n    !aws s3 cp {deploy_source_uri} tmp/sourcedir.tar.gz\n    ```", "```py\n    updated_source_uri = f's3://{s3_bucket}/{prefix}' + \\\n    ```", "```py\n                          '/sourcedir/sourcedir.tar.gz'\n    ```", "```py\n    !aws s3 cp tmp/sourcedir.tar.gz {updated_source_uri}\n    ```", "```py\n    import uuid\n    ```", "```py\n    def random_string():\n    ```", "```py\n        return uuid.uuid4().hex.upper()[0:6]\n    ```", "```py\n    from sagemaker.model import Model\n    ```", "```py\n    from sagemaker.workflow.pipeline_context import \\\n    ```", "```py\n        PipelineSession\n    ```", "```py\n    pipeline_session = PipelineSession()\n    ```", "```py\n    model_data = step_train    \\\n    ```", "```py\n        .properties            \\\n    ```", "```py\n        .ModelArtifacts        \\\n    ```", "```py\n        .S3ModelArtifacts      \\\n    ```", "```py\n    model = Model(image_uri=deploy_image_uri, \n    ```", "```py\n                  source_dir=updated_source_uri,\n    ```", "```py\n                  model_data=model_data,\n    ```", "```py\n                  role=role,\n    ```", "```py\n                  entry_point=\"inference.py\",\n    ```", "```py\n                  sagemaker_session=pipeline_session,\n    ```", "```py\n                  name=random_string())\n    ```", "```py\n    from sagemaker.workflow.model_step import ModelStep\n    ```", "```py\n    model_package_group_name = \"AutoGluonModelGroup\"\n    ```", "```py\n    register_args = model.register(\n    ```", "```py\n        content_types=[\"text/csv\"],\n    ```", "```py\n        response_types=[\"application/json\"],\n    ```", "```py\n        inference_instances=[\"ml.m5.xlarge\"],\n    ```", "```py\n        transform_instances=[\"ml.m5.xlarge\"],\n    ```", "```py\n        model_package_group_name=model_package_group_name,\n    ```", "```py\n        approval_status=\"Approved\",\n    ```", "```py\n    )\n    ```", "```py\n    step_model_create = ModelStep(\n    ```", "```py\n        name=\"CreateModel\",\n    ```", "```py\n        step_args=register_args\n    ```", "```py\n    )\n    ```", "```py\n    pipeline_name = f\"PARTIAL-PIPELINE\"\n    ```", "```py\n    partial_pipeline = Pipeline(\n    ```", "```py\n        name=pipeline_name,\n    ```", "```py\n        parameters=[\n    ```", "```py\n            input_data\n    ```", "```py\n        ],\n    ```", "```py\n        steps=[\n    ```", "```py\n            step_process, \n    ```", "```py\n            step_train,\n    ```", "```py\n            step_model_create,\n    ```", "```py\n        ],\n    ```", "```py\n    )\n    ```", "```py\n    partial_pipeline.upsert(role_arn=role)\n    ```", "```py\nexecution = partial_pipeline.start()\n```", "```py\nexecution = partial_pipeline.start(\n    parameters=dict(\n        RawData=\"<INSERT NEW SOURCE PATH>\",\n    )\n)\n```", "```py\n    execution = partial_pipeline.start()\n    ```", "```py\n    execution.describe()\n    ```", "```py\n    execution.wait()\n    ```", "```py\n    steps = execution.list_steps()\n    ```", "```py\n    steps[0]['Metadata']['RegisterModel']['Arn']\n    ```", "```py\n    execution.list_steps()\n    ```", "```py\n    import json\n    ```", "```py\n    from utils import (\n    ```", "```py\n        create_model, \n    ```", "```py\n        create_endpoint_config, \n    ```", "```py\n        create_endpoint, \n    ```", "```py\n        random_string,\n    ```", "```py\n        block\n    ```", "```py\n    )\n    ```", "```py\n    def lambda_handler(event, context):\n    ```", "```py\n        role = event['role']\n    ```", "```py\n        endpoint_name = event['endpoint_name']\n    ```", "```py\n        package_arn = event['package_arn']\n    ```", "```py\n        model_name = 'model-' + random_string()\n    ```", "```py\n        with block('CREATE MODEL'):\n    ```", "```py\n            create_model(\n    ```", "```py\n                model_name=model_name,\n    ```", "```py\n                package_arn=package_arn,\n    ```", "```py\n                role=role\n    ```", "```py\n            )\n    ```", "```py\n        with block('CREATE ENDPOINT CONFIG'):\n    ```", "```py\n            endpoint_config_name = create_endpoint_config(\n    ```", "```py\n                model_name\n    ```", "```py\n            )\n    ```", "```py\n        with block('CREATE ENDPOINT'):\n    ```", "```py\n            create_endpoint(\n    ```", "```py\n                endpoint_name=endpoint_name, \n    ```", "```py\n                endpoint_config_name=endpoint_config_name\n    ```", "```py\n            )\n    ```", "```py\n        return {\n    ```", "```py\n            'statusCode': 200,\n    ```", "```py\n            'body': json.dumps(event),\n    ```", "```py\n            'model': model_name\n    ```", "```py\n        }\n    ```", "```py\n    {\n    ```", "```py\n      \"role\": \"<INSERT SAGEMAKER EXECUTION ROLE ARN>\",\n    ```", "```py\n      \"endpoint_name\": \"AutoGluonEndpoint\",\n    ```", "```py\n      \"package_arn\": \"<INSERT MODEL PACKAGE ARN>\"\n    ```", "```py\n    }\n    ```", "```py\n    import boto3\n    ```", "```py\n    sm_client = boto3.client('sagemaker')\n    ```", "```py\n    def endpoint_exists(endpoint_name):\n    ```", "```py\n        response = sm_client.list_endpoints(\n    ```", "```py\n            NameContains=endpoint_name\n    ```", "```py\n        )\n    ```", "```py\n        results = list(\n    ```", "```py\n            filter(\n    ```", "```py\n                lambda x: \\\n    ```", "```py\n                x['EndpointName'] == endpoint_name, \n    ```", "```py\n                response['Endpoints']\n    ```", "```py\n            )\n    ```", "```py\n        )\n    ```", "```py\n        return len(results) > 0\n    ```", "```py\n    def lambda_handler(event, context):\n    ```", "```py\n        endpoint_name = event['endpoint_name']\n    ```", "```py\n        return {\n    ```", "```py\n            'endpoint_exists': endpoint_exists(\n    ```", "```py\n                endpoint_name=endpoint_name\n    ```", "```py\n            )\n    ```", "```py\n        }\n    ```", "```py\n    {\n    ```", "```py\n      \"endpoint_name\": \"AutoGluonEndpoint\"\n    ```", "```py\n    }\n    ```", "```py\n    {\n    ```", "```py\n      \"endpoint_exists\": true\n    ```", "```py\n    }\n    ```", "```py\n    import json\n    ```", "```py\n    from utils import (\n    ```", "```py\n        create_model, \n    ```", "```py\n        create_endpoint_config, \n    ```", "```py\n        update_endpoint, \n    ```", "```py\n        random_string,\n    ```", "```py\n        block\n    ```", "```py\n    )\n    ```", "```py\n    def lambda_handler(event, context):\n    ```", "```py\n        role = event['role']\n    ```", "```py\n        endpoint_name = event['endpoint_name']\n    ```", "```py\n        package_arn = event['package_arn']\n    ```", "```py\n        model_name = 'model-' + random_string()\n    ```", "```py\n        with block('CREATE MODEL'):\n    ```", "```py\n            create_model(\n    ```", "```py\n                model_name=model_name,\n    ```", "```py\n                package_arn=package_arn,\n    ```", "```py\n                role=role\n    ```", "```py\n            )\n    ```", "```py\n        with block('CREATE ENDPOINT CONFIG'):\n    ```", "```py\n            endpoint_config_name = create_endpoint_config(\n    ```", "```py\n                model_name\n    ```", "```py\n            )\n    ```", "```py\n        with block('UPDATE ENDPOINT'):\n    ```", "```py\n            update_endpoint(\n    ```", "```py\n                endpoint_name=endpoint_name, \n    ```", "```py\n                endpoint_config_name=endpoint_config_name\n    ```", "```py\n            )\n    ```", "```py\n        return {\n    ```", "```py\n            'statusCode': 200,\n    ```", "```py\n            'body': json.dumps(event),\n    ```", "```py\n            'model': model_name\n    ```", "```py\n        } \n    ```", "```py\n    {\n    ```", "```py\n      \"role\": \"<INSERT SAGEMAKER EXECUTION ROLE ARN>\",\n    ```", "```py\n      \"endpoint_name\": \"AutoGluonEndpoint\",\n    ```", "```py\n      \"package_arn\": \"<INSERT MODEL PACKAGE ARN>\"\n    ```", "```py\n    }\n    ```", "```py\n    s3_bucket = '<INSERT S3 BUCKET HERE>'\n    ```", "```py\n    from sklearn.metrics import accuracy_score\n    ```", "```py\n    accuracy_score(actual_list, predicted_list)\n    ```", "```py\n    input_endpoint_name = ParameterString(\n    ```", "```py\n        name=\"EndpointName\",\n    ```", "```py\n        default_value=f'AutoGluonEndpoint', \n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.workflow.lambda_step import (\n    ```", "```py\n        LambdaStep, \n    ```", "```py\n        LambdaOutput, \n    ```", "```py\n        LambdaOutputTypeEnum\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.lambda_helper import (\n    ```", "```py\n        Lambda\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.workflow.conditions import (\n    ```", "```py\n        ConditionEquals\n    ```", "```py\n    )\n    ```", "```py\n    from sagemaker.workflow.condition_step import (\n    ```", "```py\n        ConditionStep, \n    ```", "```py\n        JsonGet\n    ```", "```py\n    )\n    ```", "```py\n    output_endpoint_exists = LambdaOutput(\n    ```", "```py\n        output_name=\"endpoint_exists\", \n    ```", "```py\n        output_type=LambdaOutputTypeEnum.Boolean\n    ```", "```py\n    )\n    ```", "```py\n    package_arn = step_model_create \\\n    ```", "```py\n        .properties.ModelPackageArn\n    ```", "```py\n    endpoint_exists_lambda = LambdaStep(\n    ```", "```py\n        name=\"CheckIfEndpointExists\",\n    ```", "```py\n        lambda_func=Lambda(\n    ```", "```py\n            function_arn=\"<INSERT FUNCTION ARN>\"\n    ```", "```py\n        ),\n    ```", "```py\n        inputs={\n    ```", "```py\n            \"endpoint_name\": input_endpoint_name,\n    ```", "```py\n            \"package_arn\": package_arn\n    ```", "```py\n        },\n    ```", "```py\n        outputs=[output_endpoint_exists]\n    ```", "```py\n    )\n    ```", "```py\n    step_lambda_deploy_to_existing_endpoint = LambdaStep(\n    ```", "```py\n        name=\"DeployToExistingEndpoint\",\n    ```", "```py\n        lambda_func=Lambda(\n    ```", "```py\n            function_arn=\"<INSERT FUNCTION ARN>\"\n    ```", "```py\n        ),\n    ```", "```py\n        inputs={\n    ```", "```py\n            \"role\": role,\n    ```", "```py\n            \"endpoint_name\": input_endpoint_name,\n    ```", "```py\n            \"package_arn\": package_arn\n    ```", "```py\n        },\n    ```", "```py\n        outputs=[]\n    ```", "```py\n    )\n    ```", "```py\n    step_lambda_deploy_to_new_endpoint = LambdaStep(\n    ```", "```py\n        name=\"DeployToNewEndpoint\",\n    ```", "```py\n        lambda_func=Lambda(\n    ```", "```py\n            function_arn=\"<INSERT FUNCTION ARN>\"\n    ```", "```py\n        ),\n    ```", "```py\n        inputs={\n    ```", "```py\n            \"role\": role,\n    ```", "```py\n            \"endpoint_name\": input_endpoint_name,\n    ```", "```py\n            \"package_arn\": package_arn\n    ```", "```py\n        },\n    ```", "```py\n        outputs=[]\n    ```", "```py\n    )\n    ```", "```py\n    left = endpoint_exists_lambda \\\n    ```", "```py\n        .properties               \\\n    ```", "```py\n        .Outputs['endpoint_exists']\n    ```", "```py\n    cond_equals = ConditionEquals(\n    ```", "```py\n        left=left,\n    ```", "```py\n        right=True\n    ```", "```py\n    )\n    ```", "```py\n    if_steps = [step_lambda_deploy_to_existing_endpoint]\n    ```", "```py\n    else_steps = [step_lambda_deploy_to_new_endpoint]\n    ```", "```py\n    step_endpoint_exists_condition = ConditionStep(\n    ```", "```py\n        name=\"EndpointExists\",\n    ```", "```py\n        conditions=[cond_equals],\n    ```", "```py\n        if_steps=if_steps,\n    ```", "```py\n        else_steps=else_steps\n    ```", "```py\n    )\n    ```", "```py\n    pipeline_name = f\"COMPLETE-PIPELINE\"\n    ```", "```py\n    complete_pipeline = Pipeline(\n    ```", "```py\n        name=pipeline_name,\n    ```", "```py\n        parameters=[\n    ```", "```py\n            input_data,\n    ```", "```py\n            input_endpoint_name\n    ```", "```py\n        ],\n    ```", "```py\n        steps=[\n    ```", "```py\n            step_process, \n    ```", "```py\n            step_train,\n    ```", "```py\n            step_model_create,\n    ```", "```py\n            endpoint_exists_lambda, \n    ```", "```py\n            step_endpoint_exists_condition\n    ```", "```py\n        ],\n    ```", "```py\n    )\n    ```", "```py\n    complete_pipeline.upsert(role_arn=role)\n    ```", "```py\nexecution = complete_pipeline.start(\n    parameters=dict(\n        EndpointName=\"<INSERT NEW ENDPOINT NAME>\",\n    )\n)\n```", "```py\n    execution = complete_pipeline.start()\n    ```", "```py\n    execution.describe()\n    ```", "```py\n    execution.wait()\n    ```", "```py\n    from sklearn.metrics import accuracy_score\n    ```", "```py\n    accuracy_score(actual_list, predicted_list)\n    ```"]