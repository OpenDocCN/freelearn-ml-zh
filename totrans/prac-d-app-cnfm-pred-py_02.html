<html><head></head><body>
<div id="_idContainer012">
<h1 class="chapter-number" id="_idParaDest-26"><a id="_idTextAnchor024"/><span class="koboSpan" id="kobo.1.1">2</span></h1>
<h1 id="_idParaDest-27"><a id="_idTextAnchor025"/><span class="koboSpan" id="kobo.2.1">Overview of Conformal Prediction</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In today’s world, where data plays a crucial role in decision making, it has become increasingly important to measure uncertainty in predictions. </span><span class="koboSpan" id="kobo.3.2">To achieve this, a relatively new framework </span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.4.1">called </span><strong class="bold"><span class="koboSpan" id="kobo.5.1">conformal p</span></strong><strong class="bold"><span class="koboSpan" id="kobo.6.1">rediction</span></strong><span class="koboSpan" id="kobo.7.1"> is gaining popularity. </span><span class="koboSpan" id="kobo.7.2">This framework provides probabilistic predictions that are not only robust and reliable but also trustworthy. </span><span class="koboSpan" id="kobo.7.3">It is a powerful tool that offers measures of confidence, accuracy, and reliability for a given prediction, allowing users to make informed choices with </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">more certainty.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">This chapter will provide an overview of </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">conformal prediction.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1">It will explain why conformal prediction is a valuable tool for quantifying the uncertainty of predictions, especially in critical settings such as healthcare, self-driving cars, and finance. </span><span class="koboSpan" id="kobo.11.2">We will also discuss the concept of </span><strong class="bold"><span class="koboSpan" id="kobo.12.1">uncertainty quantification</span></strong><span class="koboSpan" id="kobo.13.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.14.1">UQ</span></strong><span class="koboSpan" id="kobo.15.1">) and how the conformal prediction framework has successfully addressed the challenge of quantifying uncertainty. </span><span class="koboSpan" id="kobo.15.2">By the end of this chapter, you will have a better understanding of conformal prediction and its potential applications in </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">various fields.</span></span></p>
<p><span class="koboSpan" id="kobo.17.1">In this chapter, we’ll cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.19.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">uncertainty quantification</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Different ways to </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">quantify uncertainty</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">Quantifying uncertainty using </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">conformal prediction</span></span></li>
</ul>
<h1 id="_idParaDest-28"><a id="_idTextAnchor026"/><span class="koboSpan" id="kobo.25.1">Understanding uncertainty quantification</span></h1>
<p><span class="koboSpan" id="kobo.26.1">Uncertainty is an</span><a id="_idIndexMarker027"/><span class="koboSpan" id="kobo.27.1"> inherent part of any prediction, as there are always factors that are unknown or difficult to measure. </span><span class="koboSpan" id="kobo.27.2">Predictions are typically made based on incomplete data or models that are unable to capture the full complexity of the real world. </span><span class="koboSpan" id="kobo.27.3">As a result, the predictions are subject to various sources of uncertainty, including randomness, bias, and </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">model errors.</span></span></p>
<p><span class="koboSpan" id="kobo.29.1">To mitigate the risks associated with uncertainty, it is essential to quantify it accurately. </span><span class="koboSpan" id="kobo.29.2">By quantifying uncertainty, we can estimate the range of possible outcomes and assess the degree of confidence we can have in our predictions. </span><span class="koboSpan" id="kobo.29.3">This information can be used to make informed decisions and to identify areas where further research or data collection </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">is needed.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.31.1">UQ</span></strong><span class="koboSpan" id="kobo.32.1"> is a field of study that helps us measure how much we don’t know when we make predictions. </span><span class="koboSpan" id="kobo.32.2">UQ tries to estimate the probability of outcomes even if some aspects of the system under study are not </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">known exactly.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">Uncertainty is often broken down into two types: </span><strong class="bold"><span class="koboSpan" id="kobo.35.1">aleatoric</span></strong><span class="koboSpan" id="kobo.36.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.37.1">epistemic</span></strong><span class="koboSpan" id="kobo.38.1">. </span><span class="koboSpan" id="kobo.38.2">Aleatoric uncertainty is caused by</span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.39.1"> the inherent randomness and unpredictability of the system being studied, while epistemic uncertainty arises from our lack of knowledge about </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">the system.</span></span></p>
<h2 id="_idParaDest-29"><a id="_idTextAnchor027"/><span class="koboSpan" id="kobo.41.1">Aleatoric uncertainty</span></h2>
<p><span class="koboSpan" id="kobo.42.1">Aleatoric uncertainty </span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.43.1">refers to the type of</span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.44.1"> uncertainty that is caused by inherent randomness and unpredictability in a system. </span><span class="koboSpan" id="kobo.44.2">Here are a few examples of </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">aleatoric uncertainty:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.46.1">Rolling a dice</span></strong><span class="koboSpan" id="kobo.47.1">: The outcome </span><a id="_idIndexMarker031"/><span class="koboSpan" id="kobo.48.1">of rolling a dice is inherently random and unpredictable. </span><span class="koboSpan" id="kobo.48.2">You cannot predict with certainty what number will come up on the dice, so there is aleatoric uncertainty associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">this process.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.50.1">Weather forecasting</span></strong><span class="koboSpan" id="kobo.51.1">: Weather is a complex system that is influenced by many factors, some of which are inherently random and difficult to predict. </span><span class="koboSpan" id="kobo.51.2">For example, the exact path and strength of a storm system may be difficult to predict due to </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">aleatoric uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.53.1">Stock market fluctuations</span></strong><span class="koboSpan" id="kobo.54.1">: The stock market is a complex system that is influenced by many factors, including human behavior, economic conditions, and news events. </span><span class="koboSpan" id="kobo.54.2">Some of these factors are inherently unpredictable and may cause fluctuations in stock prices, leading to </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">aleatoric uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.56.1">Traffic flow</span></strong><span class="koboSpan" id="kobo.57.1">: Traffic flow is a complex system that is influenced by many factors, including the number of vehicles on the road, road conditions, and driver behavior. </span><span class="koboSpan" id="kobo.57.2">The exact flow of traffic at any given time is difficult to predict with certainty, leading</span><a id="_idIndexMarker032"/><span class="koboSpan" id="kobo.58.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">aleatoric uncertainty.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.60.1">Let’s cover epistemic </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">uncertainty next.</span></span></p>
<h2 id="_idParaDest-30"><a id="_idTextAnchor028"/><span class="koboSpan" id="kobo.62.1">Epistemic uncertainty</span></h2>
<p><span class="koboSpan" id="kobo.63.1">Epistemic uncertainty</span><a id="_idIndexMarker033"/><span class="koboSpan" id="kobo.64.1"> refers to the type of</span><a id="_idIndexMarker034"/><span class="koboSpan" id="kobo.65.1"> uncertainty that arises from a lack of knowledge or understanding about a system. </span><span class="koboSpan" id="kobo.65.2">Here are a few examples of </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">epistemic uncertainty:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.67.1">Medical diagnosis</span></strong><span class="koboSpan" id="kobo.68.1">: Diagnosing</span><a id="_idIndexMarker035"/><span class="koboSpan" id="kobo.69.1"> a medical condition involves making predictions based on available data, such as symptoms, medical history, and test results. </span><span class="koboSpan" id="kobo.69.2">However, there may be epistemic uncertainty associated with the diagnosis if there is incomplete or unreliable data, or if the medical condition is not </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">well understood.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.71.1">Financial forecasting</span></strong><span class="koboSpan" id="kobo.72.1">: Predicting future economic conditions is a complex task that involves making predictions based on a wide range of factors, including interest rates, inflation, and political events. </span><span class="koboSpan" id="kobo.72.2">However, there is always epistemic uncertainty associated with these predictions due to our limited understanding of the </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">economic system.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.74.1">Natural disaster prediction</span></strong><span class="koboSpan" id="kobo.75.1">: Predicting the likelihood and severity of natural disasters, such as earthquakes or hurricanes, involves making predictions based on data from past events and current environmental conditions. </span><span class="koboSpan" id="kobo.75.2">However, there may be epistemic uncertainty associated with these predictions if we do not have a complete understanding of the underlying physical </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">processes involved.</span></span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer010">
<span class="koboSpan" id="kobo.77.1"><img alt="Figure 2.1 – Illustration of aleatoric and epistemic uncertainty" src="image/B19925_02_001.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.78.1">Figure 2.1 – Illustration of aleatoric and epistemic uncertainty</span></p>
<p><span class="koboSpan" id="kobo.79.1">The preceding diagram delineates two distinct point regions. </span><span class="koboSpan" id="kobo.79.2">The left region exhibits pronounced randomness, while the right region showcases a structured data pattern, evident from a straight line that can be drawn through its clustered points. </span><span class="koboSpan" id="kobo.79.3">The left cluster demonstrates high aleatoric uncertainty, in contrast to the low aleatoric uncertainty in the right</span><a id="_idIndexMarker036"/><span class="koboSpan" id="kobo.80.1"> cluster, attributed to its </span><a id="_idIndexMarker037"/><span class="koboSpan" id="kobo.81.1">data regularities. </span><span class="koboSpan" id="kobo.81.2">Additionally, three areas manifesting high epistemic uncertainty correspond to the voids in data, indicating gaps in our understanding or knowledge of </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">the system.</span></span></p>
<p><span class="koboSpan" id="kobo.83.1">Let’s move on to cover different ways to </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">quantify uncertainty.</span></span></p>
<h1 id="_idParaDest-31"><a id="_idTextAnchor029"/><span class="koboSpan" id="kobo.85.1">Different ways to quantify uncertainty</span></h1>
<p><span class="koboSpan" id="kobo.86.1">There are several different</span><a id="_idIndexMarker038"/><span class="koboSpan" id="kobo.87.1"> approaches to quantify uncertainty, each with its own strengths and limitations. </span><span class="koboSpan" id="kobo.87.2">Here are a </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">few examples:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.89.1">Statistical methods</span></strong><span class="koboSpan" id="kobo.90.1">: Statistical methods are widely used for UQ and involve using probability distributions to model the uncertainty in data and predictions. </span><span class="koboSpan" id="kobo.90.2">These methods are widely used in fields such as finance, engineering, and physics and involve tools such as confidence intervals, regression analysis, Monte Carlo simulations and </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">hypothesis testing.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.92.1">Bayesian methods</span></strong><span class="koboSpan" id="kobo.93.1">: Bayesian methods involve using prior knowledge and data to update our beliefs about the uncertainty in predictions. </span><span class="koboSpan" id="kobo.93.2">These methods are widely used in machine learning, natural language processing, and image processing. </span><span class="koboSpan" id="kobo.93.3">Bayesian tools include Bayesian inference – statistical methods to update beliefs about the uncertainty of predictions based on new data – and Bayesian networks – graphical models that represent probability relationships between the variables that can be used to model various systems and calculate the probabilities of different outcomes. </span><span class="koboSpan" id="kobo.93.4">Bayesian tools also include </span><strong class="bold"><span class="koboSpan" id="kobo.94.1">Markov Chain Monte Carlo</span></strong><span class="koboSpan" id="kobo.95.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.96.1">MCMC</span></strong><span class="koboSpan" id="kobo.97.1">) – a computational method used to sample from complex probability distributions – as well as Bayesian optimization – methods used to optimize a function that is expensive </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">to evaluate.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.99.1">Fuzzy logic methods</span></strong><span class="koboSpan" id="kobo.100.1">: Fuzzy logic involves using sets and membership functions to represent uncertainty in a system. </span><span class="koboSpan" id="kobo.100.2">This approach is widely used in control systems, robotics, and artificial intelligence. </span><span class="koboSpan" id="kobo.100.3">Fuzzy logic includes fuzzy sets – that is, sets that allow partial membership. </span><span class="koboSpan" id="kobo.100.4">Rather than a binary classification of an element as either a member or non-member of a set, fuzzy sets allow elements to have degrees of membership. </span><span class="koboSpan" id="kobo.100.5">This allows uncertainty to be represented in a </span><a id="_idIndexMarker039"/><span class="koboSpan" id="kobo.101.1">more </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">nuanced way.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.103.1">We will now talk about quantifying uncertainty using </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">conformal prediction.</span></span></p>
<h1 id="_idParaDest-32"><a id="_idTextAnchor030"/><span class="koboSpan" id="kobo.105.1">Quantifying uncertainty using conformal prediction</span></h1>
<p><span class="koboSpan" id="kobo.106.1">Quantifying the </span><a id="_idIndexMarker040"/><span class="koboSpan" id="kobo.107.1">uncertainty of </span><a id="_idIndexMarker041"/><span class="koboSpan" id="kobo.108.1">machine learning predictions is becoming increasingly important as machine learning is used more widely in critical applications such as healthcare, finance, and self-driving cars. </span><span class="koboSpan" id="kobo.108.2">In these applications, the consequences of incorrect predictions can be severe, making it essential to understand the uncertainty associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1">each prediction.</span></span></p>
<p><span class="koboSpan" id="kobo.110.1">For example, in healthcare, machine learning models are used to make predictions about patient outcomes, such as the likelihood of a disease or the effectiveness of a treatment. </span><span class="koboSpan" id="kobo.110.2">These predictions can have a significant impact on patient care and treatment decisions. </span><span class="koboSpan" id="kobo.110.3">However, if the model is unable to produce an estimate of its own confidence, it may not be useful and could potentially be risky to </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">rely upon.</span></span></p>
<p><span class="koboSpan" id="kobo.112.1">In contrast, if the model can provide a measure of its own uncertainty, clinicians can use this information to make more informed decisions about patient care </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">and treatment.</span></span></p>
<p><span class="koboSpan" id="kobo.114.1">Consider a situation where a doctor has obtained a patient’s MRI scan and has to deduce whether the patient has cancer. </span><span class="koboSpan" id="kobo.114.2">In this application, high accuracy is not enough, as the doctor’s diagnosis has to rule out (or not) a patient having such a critical, life-changing disease </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">as cancer.</span></span></p>
<p><span class="koboSpan" id="kobo.116.1">Similarly, in finance, machine learning models are used to make predictions about market trends, stock prices, and risk assessments. </span><span class="koboSpan" id="kobo.116.2">These predictions can have a significant impact on investment decisions and portfolio management. </span><span class="koboSpan" id="kobo.116.3">However, if the model is unable to produce an estimate of its own confidence, it may not be useful and could potentially </span><a id="_idIndexMarker042"/><span class="koboSpan" id="kobo.117.1">lead </span><a id="_idIndexMarker043"/><span class="koboSpan" id="kobo.118.1">to poor investment decisions. </span><span class="koboSpan" id="kobo.118.2">On the other hand, if the model can provide a measure of its own uncertainty, investors can use this information to make more informed decisions and reduce the risks associated </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">with uncertainty.</span></span></p>
<p><span class="koboSpan" id="kobo.120.1">Quantifying uncertainty is a prerequisite for explainability and trust in machine learning models. </span><span class="koboSpan" id="kobo.120.2">If a model cannot provide an estimate of its own confidence, it may be difficult to explain why it made a certain prediction or to gain the trust </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">of stakeholders.</span></span></p>
<p><span class="koboSpan" id="kobo.122.1">In contrast, if the model can provide a measure of its own uncertainty, stakeholders can better understand how the model arrived at its predictions and can have more confidence in the </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">model’s performance.</span></span></p>
<p><span class="koboSpan" id="kobo.124.1">Conformal prediction is a relatively new framework for quantifying uncertainty in predictions that offers several advantages over traditional statistical, Bayesian, and fuzzy </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">logic methods.</span></span></p>
<p><span class="koboSpan" id="kobo.126.1">Here are some advantages </span><a id="_idIndexMarker044"/><span class="koboSpan" id="kobo.127.1">of using conformal prediction </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">for UQ:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.129.1">Probabilistic predictions</span></strong><span class="koboSpan" id="kobo.130.1">: Conformal prediction provides probabilistic predictions that include measures of confidence, accuracy, and reliability for each prediction. </span><span class="koboSpan" id="kobo.130.2">This allows users to make informed choices and to estimate the range of </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">possible outcomes.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.132.1">Coverage guarantees</span></strong><span class="koboSpan" id="kobo.133.1">: Unlike other methods, prediction regions generated by conformal prediction models (prediction sets for classification tasks/predictive intervals for regression tasks) come with rigorous statistical validity guarantees. </span><span class="koboSpan" id="kobo.133.2">This valuable information can be used to assess the reliability of the model, mitigate the risks, and identify areas where further research or data collection </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">is needed.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.135.1">Non-parametric</span></strong><span class="koboSpan" id="kobo.136.1">: Conformal prediction does not require assumptions about the underlying probability distributions, making it applicable to a wide range of problems and </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">data types.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.138.1">Distribution agnostic</span></strong><span class="koboSpan" id="kobo.139.1">: Conformal prediction models work for any data distribution as long as exchangeability assumptions can be maintained. </span><span class="koboSpan" id="kobo.139.2">However, conformal prediction models have recently been extended to contexts where the exchangeability assumption is no longer met, including successful applications in time </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">series forecasting.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.141.1">No restrictions on dataset size</span></strong><span class="koboSpan" id="kobo.142.1">: Unlike statistical and Bayesian models, conformal prediction models are not concerned with dataset size – the validity of predictions is maintained</span><a id="_idIndexMarker045"/><span class="koboSpan" id="kobo.143.1"> regardless of the size of the dataset. </span><span class="koboSpan" id="kobo.143.2">However, prediction intervals are usually narrower where there is a larger amount of data. </span><span class="koboSpan" id="kobo.143.3">This is due to the general pattern of machine learning models being able to learn more effectively from </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">more data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.145.1">Robustness</span></strong><span class="koboSpan" id="kobo.146.1">: Conformal prediction is robust to outliers and noisy data, making it particularly useful in settings where the data may be imperfect </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">or incomplete.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.148.1">Wide application</span></strong><span class="koboSpan" id="kobo.149.1">: Conformal prediction has been successfully applied to a wide variety of problem classes, including classification, regression, time series and forecasting, computer vision, NLP, reinforcement learning, and </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">much more.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.151.1">Low computation cost</span></strong><span class="koboSpan" id="kobo.152.1">: Conformal prediction models, while offering very rigorous prediction regions for UQ, maintain computational efficiency and don’t heavily burden system resources, making them ideal for real-time</span><a id="_idIndexMarker046"/><span class="koboSpan" id="kobo.153.1"> applications and </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">large datasets.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.155.1">In contrast to alternative approaches, conformal prediction offers robust and non-parametric probabilistic predictions with assured validity. </span><span class="koboSpan" id="kobo.155.2">This becomes especially beneficial in scenarios where analytical modeling of uncertainty is challenging and probabilistic predictions are needed for </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">decision making.</span></span></p>
<p><span class="koboSpan" id="kobo.157.1">Conformal prediction quantifies uncertainty by offering a probability measure that indicates the likelihood</span><a id="_idIndexMarker047"/><span class="koboSpan" id="kobo.158.1"> of a prediction </span><a id="_idIndexMarker048"/><span class="koboSpan" id="kobo.159.1">being accurate. </span><span class="koboSpan" id="kobo.159.2">This uncertainty measure is rooted in the notion of validity, which denotes the expected ratio of </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">correct predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.161.1">In classification tasks, a machine learning model typically produces class scores and assigns the label with the highest score. </span><span class="koboSpan" id="kobo.161.2">However, this can pose issues when the prediction certainty </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">is low.</span></span></p>
<p><span class="koboSpan" id="kobo.163.1">Consider the following images from a </span><em class="italic"><span class="koboSpan" id="kobo.164.1">Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty</span></em><span class="koboSpan" id="kobo.165.1"> (</span><a href="https://arxiv.org/abs/2107.07511"><span class="koboSpan" id="kobo.166.1">https://arxiv.org/abs/2107.07511</span></a><span class="koboSpan" id="kobo.167.1">) by Anastasios N. </span><span class="koboSpan" id="kobo.167.2">Angelopoulos and Stephen Bates. </span><span class="koboSpan" id="kobo.167.3">A trained deep learning model will output class scores for new images just like the three in the </span><span class="No-Break"><span class="koboSpan" id="kobo.168.1">following figure.</span></span></p>
<p><span class="koboSpan" id="kobo.169.1">We can see that these three examples do not produce the </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">same results</span></span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<span class="koboSpan" id="kobo.172.1"><img alt="Figure 2.2 – Uncertainty in a classification problem" src="image/B19925_02_002.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.173.1">Figure 2.2 – Uncertainty in a classification problem</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.174.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.175.1">The preceding figure is sourced from </span><em class="italic"><span class="koboSpan" id="kobo.176.1">Angelopoulos and Bates, 2023</span></em><span class="koboSpan" id="kobo.177.1"> (used with permission by </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">the authors).</span></span></p>
<p><span class="koboSpan" id="kobo.179.1">The left-hand picture is easy to predict – the model would have seen a lot of examples of squirrels and is rather certain about its prediction. </span><span class="koboSpan" id="kobo.179.2">As a result, the prediction set contains just one potential label – </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">fox squirrel.</span></span></p>
<p><span class="koboSpan" id="kobo.181.1">The middle picture has a medium level of uncertainty associated with it – while there are additional objects in the background, the model is still quite sure that it is most likely a fox squirrel. </span><span class="koboSpan" id="kobo.181.2">However, to hedge its predictions, the model now outputs additional labels such as </span><em class="italic"><span class="koboSpan" id="kobo.182.1">gray fox, bucket, and </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.183.1">rain barrel</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.185.1">The picture on the right is the hardest to classify as there is a lot of uncertainty in the dataset; the head of the animal is partially occluded and the background is unusual. </span><span class="koboSpan" id="kobo.185.2">To account for this prediction uncertainty, the model has not only reduced the probability of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.186.1">fox squirrel</span></strong><span class="koboSpan" id="kobo.187.1"> class but also introduced the possibility that the animal is in fact a marmot. </span><span class="koboSpan" id="kobo.187.2">In addition, the model has extended the prediction set by leaving open the possibility that this animal can in fact also be </span><em class="italic"><span class="koboSpan" id="kobo.188.1">a mink, weasel, beaver, or even </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.189.1">a polecat</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.191.1">Note how the </span><a id="_idIndexMarker049"/><span class="koboSpan" id="kobo.192.1">conformal </span><a id="_idIndexMarker050"/><span class="koboSpan" id="kobo.193.1">prediction model extended the point prediction of the deep neural network as, instead of generating a point prediction, it produced a prediction set given the specified 95% confidence level. </span><span class="koboSpan" id="kobo.193.2">The prediction set produced by the conformal prediction model provides much more information to improve downstream </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">decision making.</span></span></p>
<p><span class="koboSpan" id="kobo.195.1">The conformal prediction framework is based on the idea of constructing a set of predictions that includes the true value with a certain degree of confidence. </span><span class="koboSpan" id="kobo.195.2">This set is known as a conformal prediction set and is constructed based on a set of </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">training data.</span></span></p>
<p><span class="koboSpan" id="kobo.197.1">To construct a conformal prediction set, the framework uses a non-conformity function that measures how well a prediction fits the </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">training data.</span></span></p>
<p><span class="koboSpan" id="kobo.199.1">The non-conformity measure is used to rank the predictions in order of how well they fit the training data. </span><span class="koboSpan" id="kobo.199.2">The most similar predictions are included in the conformal prediction set, along with a set of additional predictions that have a certain degree of confidence based on the non-conformity measure. </span><span class="koboSpan" id="kobo.199.3">By following this approach, the conformal prediction model can provide a measure of its own uncertainty. </span><span class="koboSpan" id="kobo.199.4">This allows both the modelers and</span><a id="_idIndexMarker051"/><span class="koboSpan" id="kobo.200.1"> the </span><a id="_idIndexMarker052"/><span class="koboSpan" id="kobo.201.1">stakeholders to better understand how the model arrived at its predictions and can engender more confidence in the </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">model’s performance.</span></span></p>
<h1 id="_idParaDest-33"><a id="_idTextAnchor031"/><span class="koboSpan" id="kobo.203.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.204.1">In this chapter, we have provided an overview of conformal prediction and explained why conformal prediction is a valuable tool for quantifying the uncertainty of predictions, especially in critical settings such as healthcare, self-driving cars, and finance. </span><span class="koboSpan" id="kobo.204.2">We also discussed the concept of UQ and how the conformal prediction framework has successfully addressed the challenge of </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">quantifying uncertainty.</span></span></p>
<p><span class="koboSpan" id="kobo.206.1">In the next chapter, we will dive deeper into the fundamentals of conformal prediction and apply it to binary classification problems. </span><span class="koboSpan" id="kobo.206.2">We will illustrate how you can apply conformal prediction to your own binary classification problems by computing non conformity scores and p-values and then using the p-values to decide which class labels should be included in your </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">prediction sets.</span></span></p>
</div>


<div class="Content" id="_idContainer013">
<h1 id="_idParaDest-34" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor032"/><span class="koboSpan" id="kobo.1.1">Part 2: Conformal Prediction Framework</span></h1>
<p><span class="koboSpan" id="kobo.2.1">This part will explain the fundamentals of conformal prediction. </span><span class="koboSpan" id="kobo.2.2">You will learn about the types of conformal prediction models and the critical concepts of conformal prediction, including validity, efficiency, and </span><span class="No-Break"><span class="koboSpan" id="kobo.3.1">non-conformity measures.</span></span></p>
<p><span class="koboSpan" id="kobo.4.1">This section has the </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1">following chapters</span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.6.1">:</span></em></span></p>
<ul>
<li><a href="B19925_03.xhtml#_idTextAnchor033"><em class="italic"><span class="koboSpan" id="kobo.7.1">Chapter 3</span></em></a><em class="italic"><span class="koboSpan" id="kobo.8.1">, Fundamentals of Conformal Prediction</span></em></li>
<li><a href="B19925_04.xhtml#_idTextAnchor040"><em class="italic"><span class="koboSpan" id="kobo.9.1">Chapter 4</span></em></a><em class="italic"><span class="koboSpan" id="kobo.10.1">, Validity and Efficiency of Conformal Prediction</span></em></li>
<li><a href="B19925_05.xhtml#_idTextAnchor046"><em class="italic"><span class="koboSpan" id="kobo.11.1">Chapter 5</span></em></a><em class="italic"><span class="koboSpan" id="kobo.12.1">, Types of Conformal Predictors</span></em></li>
</ul>
</div>
<div>
<div id="_idContainer014">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer015">
</div>
</div>
</body></html>