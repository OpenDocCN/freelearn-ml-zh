<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer135">
<h1 class="chapter-number" id="_idParaDest-123"><a id="_idTextAnchor124"/>10</h1>
<h1 id="_idParaDest-124"><a id="_idTextAnchor125"/>Examples and Case Studies</h1>
<p>This chapter embarks on a journey into the realm of machine learning, exploring practical applications and real-world examples that demonstrate its power and potential. In the previous chapters, we have learned all the essential skills required to build a good machine learning solution. In this chapter, we will utilize all the knowledge gained and build the following examples <span class="No-Break">from scratch:</span></p>
<ul>
<li>Linear <span class="No-Break">regression example</span></li>
<li>Customer <span class="No-Break">churn example</span></li>
</ul>
<h1 id="_idParaDest-125"><a id="_idTextAnchor126"/>Linear regression example</h1>
<p>In this<a id="_idIndexMarker604"/> example, we will create a linear regression model to predict the value of a house in the California area. Letâ€™s begin by getting familiar with the dataset. We will use a common California house values dataset. This is a collection of data related to residential real estate properties in various regions of California, USA. It is commonly used in machine learning and data analysis tasks for predicting house prices based on <span class="No-Break">various features.</span></p>
<p>The dataset we will use contains the <span class="No-Break">following fields:</span></p>
<ul>
<li><strong class="source-inline">medianIncome</strong>: The median income of households in a <span class="No-Break">specific block.</span></li>
<li><strong class="source-inline">housingMedianAge</strong>: The median age of houses in <span class="No-Break">a block.</span></li>
<li><strong class="source-inline">totalRooms</strong>: The total number of rooms in the houses in <span class="No-Break">a block.</span></li>
<li><strong class="source-inline">totalBedrooms</strong>: The total number of bedrooms in the houses in <span class="No-Break">a block.</span></li>
<li><strong class="source-inline">population</strong>: The total population of <span class="No-Break">the block.</span></li>
<li><strong class="source-inline">households</strong>: The total number of households (a group of people residing within a home unit) within <span class="No-Break">a block.</span></li>
<li><strong class="source-inline">latitude</strong>: The latitude of the geographical location of <span class="No-Break">the house.</span></li>
<li><strong class="source-inline">longitude</strong>: The longitude of the geographical location of <span class="No-Break">the house.</span></li>
<li><strong class="source-inline">medianHouseValue</strong>: The median value of houses in <span class="No-Break">the block.</span></li>
<li><strong class="source-inline">oceanProximity</strong>: Categorical description of the distance to <span class="No-Break">the ocean</span></li>
</ul>
<p>Here is a <a id="_idIndexMarker605"/>sample of <span class="No-Break">the data:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer117">
<img alt="Figure 10.1: Sample data from a California housing dataset" height="550" src="image/B19863_10_01.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1: Sample data from a California housing dataset</p>
<p class="callout-heading">Note</p>
<p class="callout">The example dataset can be found in the GitHub repository of this book. A good place to find other datasets is, for <span class="No-Break">example, </span><a href="https://www.kaggle.com/datasets"><span class="No-Break">https://www.kaggle.com/datasets</span></a><span class="No-Break">.</span></p>
<p>The first step in our machine learning project is to define a question we want to answer using our model. In this case, we are using a rather simple historical dataset and therefore the framework used is modified a bit. Letâ€™s determine the following characteristics <span class="No-Break">to start:</span></p>
<ul>
<li><strong class="bold">Trigger</strong>: A new house data is inserted into <span class="No-Break">the dataset</span></li>
<li><strong class="bold">Target</strong>: The value of the house in <span class="No-Break">US dollars</span></li>
<li><strong class="bold">Features</strong>: Latitude, longitude, median age, total rooms, total bedrooms, population, households, median income, <span class="No-Break">ocean proximity</span></li>
<li><strong class="bold">Machine learning question</strong>: Predicting what will the house value be in the <span class="No-Break">California area?</span></li>
</ul>
<p>To begin our actual work, letâ€™s first upload <strong class="source-inline">housing_test.csv</strong> and <strong class="source-inline">housing_train.csv</strong> into our Qlik cloud tenant. These files can be found in the GitHub repository of this book. As you can see, the dataset is already split into train and <span class="No-Break">test datasets.</span></p>
<p>In a normal <a id="_idIndexMarker606"/>machine learning project, we would need to take care of encoding the categorical fields, handling null values, scaling and so on, but in our case, Qlik AutoML takes care of all these steps. Our next task is to create a new machine learning experiment (<strong class="bold">Add New</strong> ðŸ¡ª <strong class="bold">New </strong><span class="No-Break"><strong class="bold">ML Experiment</strong></span><span class="No-Break">).</span></p>
<p>Give a name to your experiment, define a space you want to use, and press <strong class="bold">Create</strong>. The first step to starting our new experiment is to define the dataset used. Select <strong class="source-inline">housing_train.csv</strong>, which we uploaded earlier. You should see <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer118">
<img alt="Figure 10.2: Housing prices experiment â€“ target selection" height="830" src="image/B19863_10_02.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2: Housing prices experiment â€“ target selection</p>
<p>Next, we will select our target variable. We can also select the features to be used in our experiment. Select <strong class="source-inline">median_house_value</strong> as the target and all other fields should be automatically selected to be included in our experiment. You should see something like <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer119">
<img alt="Figure 10.3: Target and features selected" height="433" src="image/B19863_10_03.jpg" width="1321"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3: Target and features selected</p>
<p>In the <a id="_idIndexMarker607"/>previous image, we have also marked the feature type of <strong class="source-inline">total_bedrooms</strong> with a red square. Qlik has recognized this field as a string and forms a categorical feature by default. Change that to <strong class="bold">Numeric</strong> using the small arrow sign on the field. Once you have done the target selection and changed the feature type for <strong class="source-inline">total_bedrooms</strong>, we can select <strong class="bold">Run Experiment</strong> from the bottom right corner. After a while, you should see <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer120">
<img alt="Figure 10.4: Housing prices experiment â€“ first results" height="539" src="image/B19863_10_04.jpg" width="1054"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.4: Housing prices experiment â€“ first results</p>
<p>When looking at the SHAP diagrams for our first version of the experiment, we can see that the <strong class="source-inline">median_income</strong> field has a rather high correlation with the predicted house values. Letâ€™s try to configure a second version of our experiment without <span class="No-Break">that field.</span></p>
<p>Select <strong class="bold">Configure v2</strong> from the lower right corner. A panel similar to what we saw during our initial configuration will show up. Under the <strong class="bold">Features</strong> tab, deselect <strong class="source-inline">median_income</strong> as in <a id="_idIndexMarker608"/>the <span class="No-Break">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer121">
<img alt="Figure 10.5: Features reconfiguration" height="539" src="image/B19863_10_05.jpg" width="398"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.5: Features reconfiguration</p>
<p>Select <strong class="bold">Run v2</strong> and you should see updated SHAP and Permutation importance graphs after the experiment has finished. We can now see that <strong class="source-inline">total_rooms</strong> is the most determining feature, but our R2 score has also dropped. In this case, we will go with the first version of our experiment since it gave us better accuracy. You can try to configure multiple versions and experiment with the models to get a <span class="No-Break">better model.</span></p>
<p>In the list <a id="_idIndexMarker609"/>at the top part of the screen, scroll down until you see the top-performing model of the first run and select it. Your screen should look like <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer122">
<img alt="Figure 10.6: The model selected for deployment." height="776" src="image/B19863_10_06.jpg" width="1606"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.6: The model selected for deployment.</p>
<p>Select <strong class="bold">Deploy</strong> from the bottom right corner. Enter  a name and define the space for your newly deployed model. Make sure that <strong class="bold">Enable real-time API access</strong> is selected and press <strong class="bold">Deploy</strong>. Our model is now deployed and ready <span class="No-Break">for use.</span></p>
<p>As we have learned in previous chapters, the deployed model itself provides information about the required schema, algorithm deployed, and some metadata from the experiment. You can open the deployed model and have a closer look at this information at <span class="No-Break">this point.</span></p>
<p>Our next task to get the predicted results into a finalized application is to create a new Qlik <span class="No-Break">analytics application.</span></p>
<p>For the data in our application, we will import <strong class="source-inline">housing_test.csv</strong>. After that, we will create a new data connection for the Qlik AutoML model that we deployed in the <span class="No-Break">earlier step.</span></p>
<p>Create a new Qlik AutoML connection under <strong class="bold">Data connections</strong>. From the <strong class="bold">ML deployment</strong> field, select the model deployed earlier from the drop-down menu. Select the SHAP-values and errors <a id="_idIndexMarker610"/>to be included in the returned dataset and set the <strong class="bold">Association Field</strong> to <strong class="source-inline">Id</strong>. The connector settings should look similar to <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer123">
<img alt="Figure 10.7: Connector settings" height="647" src="image/B19863_10_07.jpg" width="689"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.7: Connector settings</p>
<p>Test the connection and save it after that. Next, we will select the data to load. In the <strong class="bold">Resident </strong><strong class="bold">T</strong><strong class="bold">able</strong> field, insert the name of the table containing our <strong class="source-inline">housing_test.csv</strong> and select <strong class="source-inline">housing_predictions</strong> to be included. You should see <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer124">
<img alt="Figure 10.8: The Select data to load window." height="647" src="image/B19863_10_08.jpg" width="1121"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.8: The Select data to load window.</p>
<p>Select <strong class="bold">Insert script</strong> and<a id="_idIndexMarker611"/> load the data into the application. You are now ready to create the <span class="No-Break">actual dashboard.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">If you run into problems during the application creation, there is a sample application in the Github repository of this book for <span class="No-Break">your reference.</span></p>
<p>We will not cover the dashboard creation part in detail to give you a chance to play with the different visualization options. The following image represents a sample dashboard that shows predicted house values on a map using a gradient color scheme, a histogram to show the distribution of prices, and a waterfall diagram to visualize SHAP values. Use the skills acquired from previous chapters and create a dashboard of your own to visualize <span class="No-Break">the data.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer125">
<img alt="Figure 10.9: Housing prices â€“ sample dashboard" height="733" src="image/B19863_10_09.jpg" width="1430"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.9: Housing prices â€“ sample dashboard</p>
<p>You can create <a id="_idIndexMarker612"/>multiple dashboards and try to cross-reference the data from multiple models if you re-run the experiment with different parameters. Try to play with the different settings and graph types to find an <span class="No-Break">effective visualization.</span></p>
<p>Now that we have implemented a linear regression example, it is time to move on to another example with a slightly more complex scenario. We will investigate the customer churn <span class="No-Break">example next.</span></p>
<h1 id="_idParaDest-126"><a id="_idTextAnchor127"/>Customer churn example</h1>
<p>In our second <a id="_idIndexMarker613"/>example, we will create a binary model to predict customer churn for a bank. We are going to use a dataset that contains the <span class="No-Break">following fields:</span></p>
<ul>
<li><strong class="source-inline">customer_id</strong>: A unique identifier for <span class="No-Break">each customer.</span></li>
<li><strong class="source-inline">credit_score</strong>: A numerical representation of a <span class="No-Break">customerâ€™s creditworthiness.</span></li>
<li><strong class="source-inline">country</strong>: The country where the <span class="No-Break">customer resides.</span></li>
<li><strong class="source-inline">gender</strong>: The gender of <span class="No-Break">the customer.</span></li>
<li><strong class="source-inline">age</strong>: The age of <span class="No-Break">the customer.</span></li>
<li><strong class="source-inline">tenure</strong>: The duration of the customerâ€™s relationship with <span class="No-Break">the company.</span></li>
<li><strong class="source-inline">balance</strong>: The current balance in the <span class="No-Break">customerâ€™s account.</span></li>
<li><strong class="source-inline">products_number</strong>: The number of products the customer has brought from <span class="No-Break">the company.</span></li>
<li><strong class="source-inline">credit_card</strong>: A binary indicator showing whether the customer holds a credit card with <span class="No-Break">the company.</span></li>
<li><strong class="source-inline">active_member</strong>: A binary indicator indicating whether the customer is currently an active member of <span class="No-Break">the company.</span></li>
<li><strong class="source-inline">estimated_salary</strong>: An approximate estimation of the <span class="No-Break">customerâ€™s salary.</span></li>
<li><strong class="source-inline">churn</strong>: A binary indicator showing whether the customer has churned (<strong class="source-inline">1</strong>) or not (<strong class="source-inline">0</strong>). Churning refers to customers who have ended their relationship with <span class="No-Break">the company.</span></li>
</ul>
<p>Here is a sample<a id="_idIndexMarker614"/> of <span class="No-Break">the dataset:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer126">
<img alt="Figure 10.10: Customer churn â€“ sample data" height="417" src="image/B19863_10_10.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.10: Customer churn â€“ sample data</p>
<p>To start with our machine learning project, we will first upload <strong class="source-inline">Bank Customer Churn Prediction.csv</strong> into Qlik Cloud. This data file can be found in the GitHub repository of this book. We also must split the dataset. Qlik AutoML splits the dataset during the experiment phase, but we will also create separate training and test datasets to get a better understanding of the modelâ€™s performance. To split the dataset, we will use the training and test data in a ratio <span class="No-Break">of 70:30.</span></p>
<p>Splitting the dataset<a id="_idIndexMarker615"/> can be done in Qlik. To do that, we will first create a new analytics application and name it <strong class="source-inline">Churn Data Prep</strong>. Next, create a data connection to the location that contains the previously uploaded <strong class="source-inline">Bank Customer Churn Prediction.csv</strong> file. You can use the following code to do <span class="No-Break">the splitting:</span></p>
<pre class="source-code">
banking_churn_data:
LOAD
Â Â Â Â RowNo() as row,
Â Â Â Â customer_id,
Â Â Â Â credit_score,
Â Â Â Â country,
Â Â Â Â gender,
Â Â Â Â "age",
Â Â Â Â tenure,
Â Â Â Â balance,
Â Â Â Â products_number,
Â Â Â Â credit_card,
Â Â Â Â active_member,
Â Â Â Â estimated_salary,
Â Â Â Â churn
FROM [lib://&lt;connection&gt;/Bank Customer Churn Prediction.csv]
(txt, codepage is 28599, embedded labels, delimiter is ',', msq);
banking_churn_train:
NoConcatenate Load *
Resident banking_churn_data
Where row &lt;= (NoOfRows('banking_churn_data')*0.7);
banking_churn_test:
NoConcatenate Load *
Resident banking_churn_data
Where row &gt; (NoOfRows('banking_churn_data')*0.7);
drop Fields row From banking_churn_train, banking_churn_test;
Store banking_churn_train into [lib:// &lt;connection&gt;/banking_churn_train.qvd] (qvd);
Store banking_churn_test into [lib:// &lt;connection&gt;/banking_churn_test.qvd] (qvd);</pre> <p>The <a id="_idIndexMarker616"/>preceding code reads <strong class="source-inline">Bank Customer Churn.csv</strong> using the file data connection and adds a row number to each row. Then, two subsets (training and test) are created using this row number and are stored in QVD files. The <strong class="source-inline">Row number</strong> field is dropped before storing because we donâ€™t need it in our machine learning project. As a result of the script, the new data files (<strong class="source-inline">banking_churn_train.qvd</strong> and <strong class="source-inline">banking_churn_test.qvd</strong>) are stored in the same location as the original <span class="No-Break">data file.</span></p>
<p>Next, we will start to investigate the data to form a machine learning question. Data exploration can be done in the same Qlik application where you split the data. Remember to drop the test and train tables before continuing with the visualizations. An example of an analysis view is represented in the <span class="No-Break">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer127">
<img alt="Figure 10.11: Customer churn example - Initial analysis" height="636" src="image/B19863_10_11.jpg" width="1382"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.11: Customer churn example - Initial analysis</p>
<p>If we plot the <a id="_idIndexMarker617"/>values using a histogram, we can see that <strong class="source-inline">credit_score</strong> and <strong class="source-inline">age</strong> follow a normal distribution. If we look at the balance, there are lot of zero values, but the rest of the data is normally distributed. If we look at the tenure, there are only a few customers with 1 year of tenure and 95 of those have been churned. This is important information when defining our prediction window. We can also see that there are no issues in the data. You can play with different visualizations when getting familiar with the data. An example can be found in the GitHub repository of <span class="No-Break">this book.</span></p>
<p>After investigating the data, we can use the following framework to form our machine <span class="No-Break">learning question:</span></p>
<ul>
<li><strong class="bold">Event trigger</strong>: When a new <span class="No-Break">customer subscribes</span></li>
<li><strong class="bold">Target</strong>: When a customer leaves the company <span class="No-Break">services (churn)</span><ul><li>Binary outcome: Yes <span class="No-Break">or No</span></li><li>The horizon is based on the average churned customer tenure length (around <span class="No-Break">five years)</span></li></ul></li>
<li><strong class="bold">Features</strong>: <strong class="source-inline">active_member</strong>, <strong class="source-inline">age</strong>, <strong class="source-inline">balance</strong>, <strong class="source-inline">country</strong>, <strong class="source-inline">credit_card</strong>, <strong class="source-inline">credit_score</strong>, <strong class="source-inline">estimated_salary</strong>, <strong class="source-inline">gender</strong>, <strong class="source-inline">products_number</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">tenure</strong></span></li>
<li><strong class="bold">Prediction point</strong>: One year <span class="No-Break">after subscription</span></li>
<li><strong class="bold">Machine learning question</strong>: After one year of activity as a customer, will the customer churn during the first <span class="No-Break">five years?</span></li>
</ul>
<p>By defining <a id="_idIndexMarker618"/>our model using the framework, we have defined that after a new customer has signed, we will collect data during the first year and then predict whether the customer will churn during the first five years. We can re-calculate the predictions periodically after the initial results when we get new data (for example, every six months after the initial results). Since we had a minimal number of customers that churned during the first year, our data accumulation window (the time between the event trigger and the prediction point) is not <span class="No-Break">too long.</span></p>
<p>Letâ€™s now create the actual machine learning experiment using our training dataset. Start by creating a new experiment and select the correct dataset (<strong class="source-inline">banking_churn_train.qvd</strong>). Select <strong class="source-inline">churn</strong> as the target and all the other fields except <strong class="source-inline">customer_id</strong> as features. The following figure represents the first <span class="No-Break">experiment setup:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer128">
<img alt="Figure 10.12: Experiment setup" height="521" src="image/B19863_10_12.jpg" width="1462"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.12: Experiment setup</p>
<p>We can see that Qlik AutoML recognized the categorical features and will automatically apply one-hot encoding to these fields. You can now run the experiment. After the first run, the experiment<a id="_idIndexMarker619"/> returns the <span class="No-Break">following results:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer129">
<img alt="Figure 10.13: First results from the experiment" height="553" src="image/B19863_10_13.jpg" width="1382"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.13: First results from the experiment</p>
<p>As we can see from the confusion matrix, the rate of false negatives is quite large and our ROC curve indicates that our model is not performing well. From the permutation and SHAP importance graphs we can see that <strong class="source-inline">age</strong> and <strong class="source-inline">products_number</strong> correlate highly with the result. Letâ€™s try to make another run without these variables and see if we will get more accurate results. Select <strong class="bold">Configure v2</strong> from the lower right corner. Under the <strong class="bold">Features</strong> panel, deselect <strong class="source-inline">age</strong> and <strong class="source-inline">products_number</strong> and press <strong class="bold">Run v2</strong>. You should see the <span class="No-Break">following results:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer130">
<img alt="Figure 10.14: Results after modification" height="691" src="image/B19863_10_14.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.14: Results after modification</p>
<p>As we can see, the <a id="_idIndexMarker620"/>accuracy of the model dropped so our changes were not beneficial. After a few iterations, we will find the best combination of features. After that, it is possible to finetune the model even more by enabling hyperparameter optimization from the settings and defining a time window for that. You can try different combinations and investigate the model performance. Once you are done, configure the new version and select the following fields: <strong class="source-inline">age</strong>, <strong class="source-inline">products_number</strong>, <strong class="source-inline">active_member</strong>, <strong class="source-inline">gender</strong>, <strong class="source-inline">balance</strong>, and <strong class="source-inline">country</strong>. Also, enable hyperparameter optimization and set the window to one hour. You should see the <span class="No-Break">following results:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer131">
<img alt="Figure 10.15: Results from the optimized experiment" height="690" src="image/B19863_10_15.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.15: Results from the optimized experiment</p>
<p>We can see <a id="_idIndexMarker621"/>that the accuracy of our final model is 84.4% and the F1 score is 0.623. The model is not a top performer but will give us relatively good results. Select the top-performing model and press <strong class="bold">Deploy</strong>. This will create a machine learning deployment for us. You can open the deployed model. Verify that you see the <span class="No-Break">following schema:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer132">
<img alt="Figure 10.16: Banking churn schema" height="433" src="image/B19863_10_16.jpg" width="818"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.16: Banking churn schema</p>
<p>We can now create a new analytics application and load <strong class="source-inline">banking_churn_test.qvd</strong> into it as a data table. You should do this in script view. We should also create a data connection to our newly deployed model. To create the correct data connection, select Qlik AutoML from the connection list and select the model from the dropdown menu. Give a name to the returned table and select SHAP -values and <a id="_idIndexMarker622"/>errors to be included. Type <strong class="source-inline">customer_id</strong> into <strong class="bold">Association Field</strong>. Your settings should look similar to <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer133">
<img alt="Figure 10.17: Connection settings" height="649" src="image/B19863_10_17.jpg" width="643"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.17: Connection settings</p>
<p>Next, add the predictions to the script. Enter the name of the <strong class="source-inline">banking_churn_test</strong> table into the <strong class="bold">Resident Table</strong> field and select the result set. Select <strong class="bold">Insert script</strong>. Your code should look <span class="No-Break">as follows:</span></p>
<pre class="source-code">
banking_churn_test:
LOAD
Â Â Â Â customer_id,
Â Â Â Â credit_score,
Â Â Â Â country,
Â Â Â Â gender,
Â Â Â Â "age",
Â Â Â Â tenure,
Â Â Â Â balance,
Â Â Â Â products_number,
Â Â Â Â credit_card,
Â Â Â Â active_member,
Â Â Â Â estimated_salary,
Â Â Â Â churn
FROM [lib://ML demos:DataFiles/banking_churn_test.qvd]
(qvd);
[churn_predicted]:
LOAD * EXTENSION endpoints.ScriptEval('{"RequestType":"endpoint", "endpoint":{"connectionname":"ML demos:Banking churn"}}', banking_churn_test);</pre> <p>We will load the test dataset in the<a id="_idIndexMarker623"/> preceding code, and then call the model endpoint through the data connector. After you complete the script, select <strong class="bold">Load data</strong>. Open <strong class="bold">Data model viewer</strong> and verify that you can see two tables connected. Next, we will focus on creating the actual application. You should try different visualization<a id="_idIndexMarker624"/> types and connect to the model using the <strong class="bold">server-side extension</strong> (<strong class="bold">SSE</strong>) syntax. An example dashboard may look like <span class="No-Break">the following:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer134">
<img alt="Figure 10.18: Churn analysis example" height="754" src="image/B19863_10_18.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.18: Churn analysis example</p>
<p>We will not <a id="_idIndexMarker625"/>cover the creation of every visualization in this chapter since you should experiment with the data and visualizations. A sample application is provided as part of the materials in the GitHub repository. We have now successfully implemented two different machine learning solutions with different use cases and studied how to form a machine learning question to be answered. We have also learned how to optimize and finetune <span class="No-Break">a model.</span></p>
<h1 id="_idParaDest-127"><a id="_idTextAnchor128"/>Summary</h1>
<p>In this chapter, we utilized the skills learned during the previous chapters by implementing two different use cases. In our first example, we studied the data of houses in California and created a model to predict their prices based on house-related variables. We created an application to utilize our model and learned about the iterations and how to interpret the <span class="No-Break">experiment results.</span></p>
<p>In our second example, we learned how to form a customer churn model and utilize it in multiple ways. We also learned how to create different datasets from our original data file and how to form a machine learning question using a framework. We visualized the results using native visualizations in <span class="No-Break">Qlik Sense.</span></p>
<p>In our next and last chapter, we will look into the future. We will investigate current trends in machine learning and artificial intelligence and try to predict how these might evolve in the future. We will also investigate megatrends and get familiar with the characteristics of a megatrend. We will also think about the evaluation of possible megatrends. Understanding megatrends is a crucial skill in being able to compete <span class="No-Break">and evolve.</span></p>
</div>
</div></body></html>