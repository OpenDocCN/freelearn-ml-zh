- en: Classifying with scikit-learn Estimators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scikit-learn library is a collection of data mining algorithms, written
    in Python and using a. This library allows users to easily try different algorithms
    as well as utilize standard tools for doing effective testing and parameter searching.
    There are many algorithms and utilities in scikit-learn, including many of the
    commonly used algorithms in modern machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we focus on setting up a good framework for running data mining
    procedures. We will use this framework in later chapters, which focus on applications
    and techniques to use in those situations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key concepts introduced in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Estimators:** This is to perform classification, clustering, and regression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transformers**: This is to perform pre-processing and data alterations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pipelines**: This is to put together your workflow into a replicable format'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: scikit-learn estimators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Estimators** that allows for the standardized implementation and testing
    of algorithms a common, lightweight interface for classifiers to follow. By using
    this interface, we can apply these tools to arbitrary classifiers, without needing
    to worry about how the algorithms work.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Estimators must have the following two important functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fit()`: This function performs the training of the algorithm - setting the
    values of internal parameters. The `fit()` takes two inputs, the training sample
    dataset and the corresponding classes for those samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict()`: This the class of the testing samples that we provide as the only
    input. This function returns a `NumPy` array with the predictions of each input
    testing sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most scikit-learn estimators use `NumPy` arrays or a related format for input
    and output. However this is by convention and not required to use the interface.
  prefs: []
  type: TYPE_NORMAL
- en: There are many estimators implemented in scikit-learn and more in other open
    source projects that use the same interface. These (SVM), random forests. We will
    use many
  prefs: []
  type: TYPE_NORMAL
- en: of these algorithms in later chapters. In this chapter, we will use the nearest
    neighbor
  prefs: []
  type: TYPE_NORMAL
- en: algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, you will need to install a new library called `matplotlib`.
    The easiest way to install it is to use `pip3`, as you did in [Chapter 1](3dc86298-cd8c-4d02-a373-6cd303d5c558.xhtml),
    *Getting Started with Data Mining*, to install scikit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**$pip3 install matplotlib**`'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have `matplotlib`, seek the official installation instructions at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://matplotlib.org/users/installing.html](http://matplotlib.org/users/installing.html%22http://matplotlib.org/users/installing.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Nearest neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Nearest neighbors** algorithm is our new sample. We take the most similar
    samples
  prefs: []
  type: TYPE_NORMAL
- en: and predict the same class that most of these nearby samples have. This vote
    is often simply a simple count,although more complicated methods do exist such
    as weighted voting.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example in the below diagram, we wish to predict the class of the triangle,
    based on which class it is more like (represented here by having similar objects
    closer together). We seek the three nearest neighbors, which are the two diamonds
    and one square within the drawn circle. There are more diamonds than circles,
    and the predicted class for the triangle is, therefore, a diamond:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_001-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Nearest neighbors are used for nearly any dataset - however, it can be computationally
    expensive to compute the distance between all pairs of samples. For example, if
    there are ten samples in the dataset, there are 45 unique distances to compute.
    However, if there are 1000 samples, there are nearly 500,000! Various methods
    exist for improving this speed, such as the use of tree structures for distance
    computation. Some of these algorithms can be quite complex, but thankfully a version
    is implemented in scikit-learn already, enabling us to classify on larger datasets.
    As these tree structures are the default in scikit-learn, we do not need to configure
    anything to use it.
  prefs: []
  type: TYPE_NORMAL
- en: Nearest neighbors can do poorly in **categorical-based datasets**, with categorical
    features, and another algorithm should be used for these instead. Nearest Neighbor's
    issue is due to the difficulty in comparing differences in categorical values,
    something better left to an algorithm that gives weight to each feature's importance.
    Comparing categorical features can be done with some distance metrics or pre-processing
    steps such as one hot encoding that we use in later chapters. Choosing the correct
    algorithm for the task is one of the difficult issues in data mining, often it
    can be easiest to test a set of algorithms and see which performs best on your
    task.
  prefs: []
  type: TYPE_NORMAL
- en: Distance metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key underlying concept in data mining is that of **distance**. If we have
    two samples, we need to answer questions such as *are these two samples more similar
    than the other two? *Answering questions like these is important to the outcome
    of the data mining exercise.
  prefs: []
  type: TYPE_NORMAL
- en: The most common use is **Euclidean** distance, which is the *real-world* distance
    between two objects. If you were to plot the points on a graph and measure the
    distance with a ruler, the result would be the Euclidean distance.
  prefs: []
  type: TYPE_NORMAL
- en: A little more formally, the Euclidean distances between points a and b is the
    square root of the sum of the squared distances for each feature.
  prefs: []
  type: TYPE_NORMAL
- en: Euclidean distance is intuitive but provides poor accuracy if some features
    have larger values than a value of 0, known as a sparse matrix.
  prefs: []
  type: TYPE_NORMAL
- en: There are other distance metrics in use; two commonly employed ones are the
    Manhattan and Cosine distance.
  prefs: []
  type: TYPE_NORMAL
- en: The **Manhattan** distance is the sum of the absolute differences in each feature
    (with no use of square distances).
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively we can imagine Manhattan distance of as the number of moves a Rook
    piece
  prefs: []
  type: TYPE_NORMAL
- en: (also called a Castle) in if it were limited to moving one square at a time.
    While the Manhattan distance does suffer if some features have larger values than
    others, the effect is not as dramatic as in the case of Euclidean points if it
    were limited to moving one square at a time. While the Manhattan distance does
    suffer if some features have larger values than others, the effect is not as dramatic
    as in the case of Euclidean.
  prefs: []
  type: TYPE_NORMAL
- en: The **Cosine** distance is better suited to cases where some features are larger
    than others and when there are lots of zeros in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Intuitively, we draw a line from the origin to each of the samples and measure
    the angle between those lines. We can observe the differences between the algorithms
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_002-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this example, each of the gray circles is exactly the same distance from
    the white circle. In (a), the distances are Euclidean, and therefore, similar
    distances fit around a circle. This distance can be measured using a ruler. In
    (b), the distances are Manhattan, also called City Block. We compute the distance
    by moving across rows and columns, like how a Rook (Castle) in Chess moves. Finally,
    in (c), we have the Cosine distance that is measured by computing the angle between
    the lines drawn from the sample to the vector and ignore the actual length of
    the line.
  prefs: []
  type: TYPE_NORMAL
- en: The distance metric chosen can have a large impact on the final performance.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you have many features, the Euclidean distance between random
    samples converges (due to the famous *curse of dimensionality*). Euclidean distances
    in high dimension have a hard time comparing samples, as the distances are always
    nearly the same!
  prefs: []
  type: TYPE_NORMAL
- en: Manhattan distance can be more stable in these circumstances, but if some features
    have very large values, this can *overrule* lots similarity in other features.
    For example, if feature A has values between 1 and 2, and another feature B has
    values between 1000 and 2000, in such a case feature A is unlikely to have any
    impact on the result. This problem can be addressed through normalization, which
    makes Manhattan (and Euclidean) distance more reliable with different features,
    which we will see later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Cosine distance is a good metric for comparing items with many features,
    but it discards some information about the length of the vector, which is useful
    in some applications. We would often use Cosine distance in text mining due to
    the large number of features inherent in text mining (see [Chapter 6](ea7ae888-e2aa-46b5-ba45-b8c685cc5fe2.xhtml),
    *Social Media Insight Using Naive Bayes*).
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, either a theoretical approach is needed to determine which distance
    method is needed, or an empirical evaluation is needed to see which performed
    more effectively. I prefer the empirical approach, but either approach can yield
    good results.
  prefs: []
  type: TYPE_NORMAL
- en: For this chapter, we will stay with Euclidean distance, using other metrics
    in later chapters. If you'd like to experiment, then try setting the metric to
    Manhattan and see how that affects the results.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The dataset `Ionosphere`, which high-frequency antennas. The aim of the antennas
    is to determine whether there is a structure in the ionosphere and a region in
    the upper atmosphere. We consider readings with a structure to be good, while
    those that do not have structure are deemed bad. The aim of this application is
    to build a data mining classifier that can determine whether an image is good
    or bad.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_003.png)'
  prefs: []
  type: TYPE_IMG
- en: '(Image Credit: https://www.flickr.com/photos/geckzilla/16149273389/)'
  prefs: []
  type: TYPE_NORMAL
- en: You can download this dataset  for different data mining applications. Go to
    [http://archive.ics.uci.edu/ml/datasets/Ionosphere](http://archive.ics.uci.edu/ml/datasets/Ionosphere) 
    and click on Data Folder. Download the `ionosphere.data` and `ionosphere.names`
    files to a folder on your computer. For this example, I'll assume that you have
    put the dataset in a directory called `Data` in your `home` folder. You can place
    the data in another folder, just be sure to update your data folder (here, and
    in all other chapters).
  prefs: []
  type: TYPE_NORMAL
- en: 'The location of your home folder depends on your operating system. For Windows,
    it is usually at `C:Documents` and `Settingsusername`. For Mac or Linux machines,
    it is usually at `/home/username`. You can get your home folder by running this
    python code inside a Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For each row in the dataset, there are 35 values. The first 34 are measurements
    taken from the 17 antennas (two values for each antenna). The last is either 'g'
    or 'b'; that stands for good and bad, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Start the Jupyter Notebook server and create a new notebook called Ionosphere
    Nearest Neighbors. To start with, we load up the `NumPy` and `csv` libraries that
    we will need for our code, and set the data's filename that we will need for our
    code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create the `X` and `y` `NumPy` arrays to store the dataset in. The
    sizes of these arrays are known from the dataset. Don''t worry if you don''t know
    the size of future datasets - we will use other methods to load the dataset in
    future chapters and you won''t need to know this size beforehand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The dataset is in a **Comma-Separated Values** (**CSV**) format, which is a
    commonly used format for datasets. We are going to use the `csv` module to load
    this file. Import it and set up a `csv` reader object, then loop through the file,
    setting the appropriate row in `X` and class value in `y` for every line in our
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We now have a dataset of samples and features in `X` as well as the corresponding
    classes in `y`, as we did in the classification example in [Chapter 1](3dc86298-cd8c-4d02-a373-6cd303d5c558.xhtml),
    Getting Started with Data Mining.
  prefs: []
  type: TYPE_NORMAL
- en: To begin with, try applying the OneR algorithm from [Chapter 1](3dc86298-cd8c-4d02-a373-6cd303d5c558.xhtml),
    *Getting Started with Data Mining* to this dataset. It won't work very well, as
    the information in this dataset is spread out within the correlations of certain
    features. OneR is only interested in the values of a single feature and cannot
    pick up information in more complex datasets very well. Other algorithms, including
    Nearest Neighbor, merge information from multiple features, making them applicable
    in more scenarios. The downside is that they are often more computationally expensive
    to compute.
  prefs: []
  type: TYPE_NORMAL
- en: Moving towards a standard workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Estimators scikit-learn have two and `predict()`. We train the algorithm using
    the
  prefs: []
  type: TYPE_NORMAL
- en: '`predict()` method on our testing set. We evaluate it using the `predict()`
    method on our testing set.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create these training and testing sets. As before, import
    and run the `train_test_split` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we import the `nearest neighbor` class and create an instance for it.
    We leave the parameters as defaults for now and will test other values later in
    this chapter. By default, the algorithm will choose the five nearest neighbors
    to predict the class of a testing sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating our `estimator`, we must then fit it on our training dataset.
    For the `nearest neighbor` class, this training step simply records our dataset,
    allowing us to find the nearest neighbor for a new data point, by comparing that
    point to the training dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We then train the algorithm with our test set and evaluate with our testing
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This model scores 86.4 percent accuracy, which is impressive for a default algorithm
    and just a few lines of code! Most scikit-learn default parameters are chosen
    deliberately to work well with a range of datasets. However, you should always
    aim to choose parameters based on knowledge of the application experiment. We
    will use strategies for doing this **parameter search** in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Running the algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous results are quite good, based on our testing set of data, based
    on the testing set. However, what happens if we get lucky and choose an easy testing
    set? Alternatively, what if it was particularly troublesome? We can discard a
    good model due to poor results resulting from such an *unlucky* split of our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **cross-fold validation** framework is a way to address the problem of
    choosing a single testing set and is a standard *best-practice *methodology in
    data mining. The process works by doing many experiments with different training
    and testing splits, but using each sample in a testing set only once. The procedure
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the entire dataset into several sections called folds.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each fold in the data, execute the following steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set that fold aside as the current testing set
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the algorithm on the remaining folds
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate on the current testing set
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Report on all the evaluation scores, including the average score.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this process, each sample is used in the testing set only once, reducing
    (but not eliminating) the likelihood of choosing lucky testing sets.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, the code examples build upon each other within a chapter.
    Each chapter's code should be entered into the same Jupyter Notebook unless otherwise
    specified in-text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scikit-learn library contains a few cross-fold validation methods. A `helper`
    function is given that performs the preceding procedure. We can import it now
    in our Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: By `cross_val_score` uses a specific methodology called **Stratified K-Fold**
    to create folds that have approximately the same proportion of classes in each
    fold, again reducing the likelihood of choosing poor folds. Stratified K-Fold
    is a great default -we won't mess with it right now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use this new function to evaluate our model using cross-fold validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Our new code returns a slightly more modest result of 82.3 percent, but it is
    still quite good considering we have not yet tried setting better parameters.
    In the next section, we will see how we would go about changing the parameters
    to achieve a better outcome.
  prefs: []
  type: TYPE_NORMAL
- en: It is quite natural for variation in results when performing data mining, and
    attempting to repeat experiments. This is due to variations in how the folds are
    created and randomness inherent in some classification algorithms. We can deliberately
    choose to replicate an experiment exactly by setting the random state (which we
    will do in later chapters). In practice, it's a good idea to rerun experiments
    multiple times to get a sense of the average result and the spread of the results
    (the mean and standard deviation) across all experiments.
  prefs: []
  type: TYPE_NORMAL
- en: Setting parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Almost all parameters that the user can set, letting algorithms focus more on
    the specific dataset, rather than only being applicable across a small and specific
    range of problems. Setting these parameters can be quite difficult, as choosing
    good parameter values is often highly reliant on features of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The nearest neighbor algorithm has several parameters, but the most important
    one is that of the number of nearest neighbors to use when predicting the class
    of an unseen attribution. In `-learn`, this parameter is called `n_neighbors`.
    In the following figure, we show that when this number is too low, a randomly
    labeled sample can cause an error. In contrast, when it is too high, the actual
    nearest neighbors have a lower effect on the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_004-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In figure (a), on the left-hand side, we would usually expect to classify the
    test sample (the triangle) as a circle. However, if `n_neighbors` is 1, the single
    red diamond in this area (likely a noisy sample) causes the sample to be predicted
    as a diamond. In figure (b), on the right-hand side, we would usually expect to
    classify the test sample as a diamond. However, if `n_neighbors` is 7, the three
    nearest neighbors (which are all diamonds) are overridden by a large number of
    circle samples. Nearest neighbors a difficult problem to solve, as the parameter
    can make a huge difference. Luckily, most of the time the specific parameter value
    does not greatly affect the end result, and the standard values (usually 5 or
    10) are often *near enough*.
  prefs: []
  type: TYPE_NORMAL
- en: With that in mind, we can test out a range of values, and investigate the impact
    that this parameter has on performance. If we want to test a number of values
    for the `n_neighbors` parameter, for example, each of the values from 1 to 20,
    we can rerun the experiment many times by setting `n_neighbors` and observing
    the result. The code below does this, storing the values in the `avg_scores` and
    `all_scores` variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then plot the relationship between the value of `n_neighbors` and the
    accuracy. First, we tell the Jupyter Notebook that we want to show plots `inline`
    in the notebook itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We then import `pyplot` from the `matplotlib` library and plot the parameter
    values alongside average scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/image_02_005.png)'
  prefs: []
  type: TYPE_IMG
- en: While there is a lot of variance, the plot shows a decreasing trend as the number
    of neighbors increases. With regard to the variance, you can expect large amounts
    of variance whenever you do evaluations of this nature. To compensate, update
    the code to run 100 tests, per value of `n_neighbors`.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When taking measurements of real-world objects, we can often get features in
    different ranges. For instance, if we measure the qualities of an animal, we might
    have several features, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Number of legs**: This is between the range of 0-8 for most animals, while
    some have more! more! more!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weight**: This is between the ranges of only a few micrograms, all the way
    to a blue whale with a weight of 190,000 kilograms!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of hearts**: This can be between zero to five, in the case of the
    earthworm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a mathematical-based algorithm to compare each of these features, the differences
    in the scale, range, and units can be difficult to interpret. If we used the above
    features in many algorithms, the weight would probably be the most influential
    feature due to only the larger numbers and not anything to do with the actual
    effectiveness of the feature.
  prefs: []
  type: TYPE_NORMAL
- en: One of the possible strategies *normalizes* the features so that they all have
    the same range, or the values are turned into categories like *small*, *medium*
    and *large*. Suddenly, the large differences in the types of features have less
    of an impact on the algorithm and can lead to large increases in the accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing can also be used to choose only the more effective features,
    create new features, and so on. Pre-processing in scikit-learn is done through
    `Transformer` objects, which take a dataset in one form and return an altered
    dataset after some transformation of the data. These don't have to be numerical,
    as Transformers are also used to extract features-however, in this section, we
    will stick with pre-processing.
  prefs: []
  type: TYPE_NORMAL
- en: We can show an example of the problem by *breaking* the `Ionosphere` dataset.
    While this is only an example, many real-world datasets have problems of this
    form.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a copy of the array so that we do not alter the original dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we *break* the dataset by dividing every second feature by `10`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In theory, this should not have a great effect on the result. After all, the
    values of these features are still relatively the same. The major issue is that
    the scale has changed and the odd features are now *larger* than the even features.
    We can see the effect of this by computing the accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This testing methodology gives a score of 82.3 percent for the original dataset,
    which drops down to 71.5 percent on the broken dataset. We can fix this by scaling
    all the features to the range `0` to `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Standard pre-processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pre-processing we will perform for this experiment is called feature-based
    normalization, which we perform using scikit-learn''s `MinMaxScaler` class. Continuing
    with the Jupyter Notebook from the rest of this chapter, first, we import this
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This class takes each feature and scales it to the range `0` to `1`. This pre-processor
    replaces the minimum value with `0`, the maximum with `1`, and the other values
    somewhere in between based on a linear mapping.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply our pre-processor, we run the `transform` function on it. Transformers
    often need to be trained first, in the same way that the classifiers do. We can
    combine these steps by running the `fit_transform` function instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here, `X_transformed` will have the same shape as `*X*`. However, each column
    will have a maximum of `1` and a minimum of `0`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various other forms of normalizing in this way, which is effective
    for other applications and feature types:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure the sum of the values for each sample equals to 1, using `sklearn.preprocessing.Normalizer`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Force each feature to have a zero mean and a variance of 1, using `sklearn.preprocessing.StandardScaler`,
    which is a commonly used starting point for normalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turn numerical features into binary features, where any value above a threshold
    is 1 and any below is 0, using `sklearn.preprocessing.Binarizer`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use combinations of these pre-processors in later chapters, along with
    other types of `Transformers` object.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing is a critical step in the data mining pipeline and one that can
    mean the difference between a bad and great result.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now create a workflow by combining the code from the previous sections,
    using the broken dataset previously calculated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We now recover our original score of 82.3 percent accuracy. The `MinMaxScaler`
    resulted in features of the same scale, meaning that no features overpowered others
    by simply being bigger values. While the Nearest Neighbor algorithm can be confused
    with larger features, some algorithms handle scale differences better. In contrast,
    some are much worse!
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As experiments grow, so does the complexity of the operations. We may split
    up our dataset, binarize features, perform feature-based scaling, perform sample-based
    scaling, and many more operations.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping track of these operations can get quite confusing and can result in
    being unable to replicate the result. Problems include forgetting a step, incorrectly
    applying a transformation, or adding a transformation that wasn't needed.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue is the order of the code. In the previous section, we created
    our `X_transformed` dataset and then created a new estimator for the cross validation.If
    we had multiple steps, we would need to track these changes to the dataset in
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pipelines are a construct that addresses these problems (and others, which
    we will see in the next chapter). Pipelines store the steps in your data mining
    workflow. They can take your raw data in, perform all the necessary transformations,
    and then create a prediction. This allows us to use pipelines in functions such
    as `cross_val_score`, where they expect an estimator. First, import the `Pipeline`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Pipelines take a list of steps as input, representing the chain of the data
    mining application. The last step needs to be an Estimator, while all previous
    steps are Transformers. The input dataset is altered by each Transformer, with
    the output of one step being the input of the next step. Finally, we classify
    the samples by the last step''s estimator. In our pipeline, we have two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Use `MinMaxScaler` to scale the feature values from 0 to 1
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `KNeighborsClassifier` as the classification algorithms
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then represent each step using a tuple `(''name'',` `step)`. We can then
    create our pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The key here is the list of tuples. The first tuple is our scaling step and
    the second tuple is the predicting step. We give each step a name: the first we
    call `scale` and the second we call `predict`, but you can choose your own names.
    The second part of the tuple is the actual `Transformer` or `estimator` object.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this pipeline is now very easy, using the cross-validation code from
    before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This gives us the same score as before (82.3 percent), which is expected, as
    we are running exactly the same steps, just with an improved interface.
  prefs: []
  type: TYPE_NORMAL
- en: In later chapters, we will use more advanced testing methods and setting up
    pipelines is a great way to ensure that the code complexity does not grow unmanageably.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used several of scikit-learn's methods for building a standard
    workflow to run and evaluate data mining models. We introduced the Nearest Neighbors
    algorithm, which is implemented in scikit-learn as an estimator. Using this class
    is quite easy; first, we call the `fit` function on our training data, and second,
    we use the `predict` function to predict the class of testing samples.
  prefs: []
  type: TYPE_NORMAL
- en: We then looked at pre-processing by fixing poor feature scaling. This was done
    using a `Transformer` object and the `MinMaxScaler` class. These functions also
    have a `fit` method and then a transform, which takes data of one form as an input
    and returns a transformed dataset as an output.
  prefs: []
  type: TYPE_NORMAL
- en: To investigate these transformations further, try swapping out the `MinMaxScaler`
    with some of the other mentioned transformers. Which is the most effective and
    why would this be the case?
  prefs: []
  type: TYPE_NORMAL
- en: Other transformers also exist in scikit-learn, which we will use later in this
    book, such as PCA. Try some of these out as well, referencing scikit-learn's excellent
    documentation at [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will use these concepts in a larger example, predicting
    the outcome of sports matches using real-world data.
  prefs: []
  type: TYPE_NORMAL
