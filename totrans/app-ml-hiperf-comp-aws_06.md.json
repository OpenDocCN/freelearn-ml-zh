["```py\n...\nfrom sagemaker.pytorch import PyTorch\nestimator = PyTorch(entry_point='train.py',\n                    source_dir='src',\n                    role=role,\n                    instance_count=1,\n                    instance_type='ml.p3.2xlarge',\n                    framework_version='1.8.0',\n                    py_version='py3',\n                    sagemaker_session=sagemaker_session,\n                    hyperparameters={'epochs':10,\n                                     'batch_size':32,\n                                     'lr':3e-5,\n                                     'gamma': 0.7},\n                   )\n...\n```", "```py\n...\nfrom sagemaker.inputs import TrainingInput\ntrain = TrainingInput(s3_train_data,\n                      content_type='image/png',\n                      input_mode='File')\nval = TrainingInput(s3_val_data,\n                    content_type='image/png',\n                    input_mode='File')\n...\n```", "```py\n...\nestimator.fit({'train':train, 'val': val})\n...\n```", "```py\n...\nfrom sagemaker.pytorch import PyTorch\nestimator = PyTorch(entry_point='train.py',\n                    source_dir='src',\n                    role=role,\n                    instance_count=1,\n                    instance_type='ml.p3.16xlarge',\n                    framework_version='1.8.0',\n                    py_version='py3',\n                    sagemaker_session=sagemaker_session,\n                    hyperparameters={'epochs':10,\n                                     'batch_size':32,\n                                     'lr':3e-5,\n                                     'gamma': 0.7},\n                   )\n...\n```", "```py\n...\nfrom sagemaker.pytorch import PyTorch\nestimator = PyTorch(entry_point='train.py',\n                    source_dir='src',\n                    role=role,\n                    instance_count=2,\n                    instance_type='ml.p3.2xlarge',\n                    framework_version='1.8.0',\n                    py_version='py3',\n                    sagemaker_session=sagemaker_session,\n                    hyperparameters={'epochs':10,\n                                     'batch_size':32,\n                                     'lr':3e-5,\n                                     'gamma': 0.7},\n                   )\n...\n```", "```py\n...\nimport zipfile\nwith zipfile.ZipFile(\"train.zip\",\"r\") as train_zip_ref:\n    train_zip_ref.extractall(\"data/train\")\nwith zipfile.ZipFile(\"validation.zip\",\"r\") as val_zip_ref:\n    val_zip_ref.extractall(\"data/validation\")\n...\n```", "```py\n...\nfrom super_image import EdsrModel, ImageLoader\nfrom PIL import Image\nimport requests\nimport os\nfrom os import listdir\nfolder_dir = \"data/validation/\"\nmodel = EdsrModel.from_pretrained('eugenesiow/edsr-base', scale=4)\nfor folder in os.listdir(folder_dir):\n    folder_path = f'{folder_dir}{folder}'\n    for image_file in os.listdir(folder_path):\n        path = f'{folder_path}/{image_file}'\n        image = Image.open(path)\n        inputs = ImageLoader.load_image(image)\n        preds = model(inputs)\n        ImageLoader.save_image(preds, path)\nfile_size = os.path.getsize(path)\nprint(\"File Size is :\", file_size/1000000, \"MB\")\n...\n```", "```py\n...\nimport sagemaker\nfrom sagemaker import get_execution_role\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.s3 import S3Uploader\nimport boto3\nsagemaker_session = sagemaker.Session()\nbucket = sagemaker_session.default_bucket()\nprefix = 'horse-or-human'\nrole = get_execution_role()\nclient = boto3.client('sts')\naccount = client.get_caller_identity()['Account']\nprint(f'AWS account:{account}')\nsession = boto3.session.Session()\nregion = session.region_name\nprint(f'AWS region:{region}')\ns3_train_data = S3Uploader.upload('data/train',f's3://{bucket}/{prefix}/data/train')\ns3_val_data = S3Uploader.upload('data/validation',f's3://{bucket}/{prefix}/data/validation')\nprint('s3 train data path: ', s3_train_data)\nprint('s3 validation data path: ', s3_val_data)\n...\n```", "```py\n...\nestimator = PyTorch(entry_point='train.py',\n                    source_dir='src',\n                    role=role,\n                    instance_count=1,\n                    instance_type='ml.p3.16xlarge',\n                    framework_version='1.8.0',\n                    py_version='py3',\n                    sagemaker_session=sagemaker_session,\n                    hyperparameters={'epochs':10,\n                                     'batch_size':32,\n                                     'lr':3e-5,\n                                     'gamma': 0.7},\n                    distribution={\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}},\n                    debugger_hook_config=False,\n                    metric_definitions=metric_definitions,\n                   )\n...\n```", "```py\n...\nfrom sagemaker.inputs import TrainingInput\ntrain = TrainingInput(s3_train_data,\n                      content_type='image/png',\n                      input_mode='File')\nval = TrainingInput(s3_val_data,\n                    content_type='image/png',\n                    input_mode='File')\nestimator.fit({'train':train, 'val': val})\n...\n```", "```py\n    ...\n    ```", "```py\n    from smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n    ```", "```py\n    import smdistributed.dataparallel.torch.distributed as dist\n    ```", "```py\n    dist.init_process_group()\n    ```", "```py\n    ...\n    ```", "```py\n    ...\n    ```", "```py\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n    ```", "```py\n            train_dataset, num_replicas=world_size, rank=rank\n    ```", "```py\n    )\n    ```", "```py\n    ...\n    ```", "```py\n    ...\n    ```", "```py\n    world_size = dist.get_world_size()\n    ```", "```py\n    rank = dist.get_rank()\n    ```", "```py\n    ...\n    ```", "```py\n    ...\n    ```", "```py\n    args.batch_size //= world_size // 8\n    ```", "```py\n    args.batch_size = max(args.batch_size, 1)\n    ```", "```py\n    ...\n    ```", "```py\n...\n                    distribution={\n                        \"smdistributed\": {\"modelparallel\": smp_options},\n                        \"mpi\": mpi_options\n                    },\n...\n```", "```py\n...\nsmp_options = {\n    \"enabled\":True,\n    \"parameters\": {\n        \"partitions\": 1,\n        \"placement_strategy\": \"spread\",\n        \"pipeline\": \"interleaved\",\n        \"optimize\": \"speed\",\n        \"ddp\": True,\n    }\n}\nmpi_options = {\n    \"enabled\" : True,\n    \"processes_per_host\" : 8,\n}\n...\n```", "```py\n    ...\n    ```", "```py\n    import smdistributed.modelparallel\n    ```", "```py\n    import smdistributed.modelparallel.torch as smp\n    ```", "```py\n    smp.init()\n    ```", "```py\n    ...\n    ```", "```py\n    ...\n    ```", "```py\n    model = smp.DistributedModel(model)\n    ```", "```py\n    ...\n    ```", "```py\n    ...\n    ```", "```py\n    optimizer = smp.DistributedOptimizer(\n    ```", "```py\n        optim.Adam(model.parameters(), lr=args.lr))\n    ```", "```py\n    ...\n    ```", "```py\n    ...\n    ```", "```py\n    @smp.step\n    ```", "```py\n    def train_step(model, data, label):\n    ```", "```py\n        output = model(data)\n    ```", "```py\n        loss = F.nll_loss(F.log_softmax(output), label,\n    ```", "```py\n                          reduction=\"mean\")\n    ```", "```py\n        # replace loss.backward() with model.backward in the train_step function.\n    ```", "```py\n        model.backward(loss)\n    ```", "```py\n        return output, loss\n    ```", "```py\n    @smp.step\n    ```", "```py\n    def test_step(model, data, label):\n    ```", "```py\n        val_output = model(data)\n    ```", "```py\n        val_loss = F.nll_loss(F.log_softmax(val_output),\n    ```", "```py\n                              label, reduction=\"mean\")\n    ```", "```py\n        return val_loss\n    ```", "```py\n    ...\n    ```", "```py\n    ...\n    ```", "```py\n        if smp.rank() == 0:\n    ```", "```py\n            model_save = model.module if hasattr(model, \"module\") else model\n    ```", "```py\n            save_model(model_save, args.model_dir)\n    ```", "```py\n    ...\n    ```"]