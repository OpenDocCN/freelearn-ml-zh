- en: Unlocking Production Issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Handling unstructured data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying machine learning models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping track of changes into production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking accuracy to optimize model scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To address the recipes in this chapter, you will need the following files (available
    on GitHub):'
  prefs: []
  type: TYPE_NORMAL
- en: '`UNData.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TextFile.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we have extensively covered the main algorithms that
    are used in machine learning. We have seen how many and which tools the Python
    programmer has at their disposal to construct algorithms that are capable of predicting
    or classifying specific information. The next step is to create software that
    can be made available for production and subsequent marketing.
  prefs: []
  type: TYPE_NORMAL
- en: This is not a small challenge, given that making software available for marketing
    involves the resolution of considerable problems that include hardware and software
    aspects. In fact, we must first determine which types of devices will host the
    software and then select the programming platform that is most suitable for that
    type of technology.
  prefs: []
  type: TYPE_NORMAL
- en: Handling unstructured data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have highlighted the importance of input data in the creation of
    a model based on automatic learning. In particular, we have seen how important
    it is to adequately process this data before providing it in our algorithm. Another
    challenge that we must face before starting our production work is to learn how
    to deal with unstructured data. By unstructured data, we mean data that is stored
    without any scheme. An example is files containing text that has been produced
    by one of the most popular text editing software or a multimedia file, but this
    unstructured data could also take the form of emails, PDFs, and so on. Unstructured
    data differs from databases due to the fact that they may have irregularities
    that do not allow you to catalog or store them in a particular process.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a source, I used a passage from the novel *The Adventures of Huckleberry
    Finn*, by Mark Twain, which can be viewed on GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, it is an unstructured text. We will handle this text and remove
    the unnecessary elements before saving the result in a structured form.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to handle unstructured data. Follow these
    steps to begin:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    in the `UNData.py` file already provided):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define the input filename:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to initialize the dictionary that will contain the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can load and print the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s convert the data into lowercase:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s remove any punctuation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s remove the numbers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s remove any extra blank spaces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will print and save the results in a `.csv` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the input file (left) and the results that were
    obtained (right):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e3cd6e5-5037-4101-90a9-5f4efe8c91bb.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we learned how to handle unstructured data. To do this, a piece
    of text from Mark Twain's novel was used. After loaded the text, punctuation,
    numbers, and extra blank spaces were removed. Also, all of the text was transformed into
    lowercase. Finally, the results was stored in a `.csv` file.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we have addressed the problem of text analysis, which represents
    the process of converting the unstructured text into meaningful data for a subsequent
    analysis phase. Several techniques can be used for text analysis, and we dealt
    with several in [Chapter 7](fc31e304-3301-4ebf-80e4-404ac6e26606.xhtml),* Analyzing
    Text Data*.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to [Chapter 7](fc31e304-3301-4ebf-80e4-404ac6e26606.xhtml), *Analyzing
    Text Data*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to *Unstructured Data* (from Stanford University): [https://web.stanford.edu/class/cs102/lecturenotes/UnstructuredData.pdf](https://web.stanford.edu/class/cs102/lecturenotes/UnstructuredData.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying machine learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bringing into production a project based on machine learning isn't easy. In
    fact, there are only a few companies that have managed to do it, at least for
    large projects. The difficulties lie in the fact that artificial intelligence
    is not something that is produced with finished software. A starting platform
    is needed to implement its own software model encountering problems that are not
    analogous to those that the developers usually encounter. The classic approach
    of software engineering leads to abstraction so that you arrive at simple code
    that can be modified and improved. Unfortunately, it is difficult to pursue abstraction
    in machine learning applications, just as it is difficult to control the complexity
    of machine learning. The best thing to do is focus on a platform that has the
    functions you need and, at the same time, allows you to withdraw from the mathematical
    foundations of machine learning. In this recipe, we will present the Amazon SageMaker
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon SageMaker is a paid service, but thanks to the AWS free usage plan, you
    can start using Amazon SageMaker for free for the first two months after registration. For
    further information on the available tariff plans, check out the following link: [https://aws.amazon.com](https://aws.amazon.com).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can make use of Amazon SageMaker:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to log in to the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1883d625-2090-43ce-9f27-b67a21b43b85.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Launch a notebook instance with one of the example notebooks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2974153a-5048-4638-a883-c695d3a719ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Change that instance by connecting to custom data sources.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Follow the examples to create, form, and validate the models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4c18d353-cf11-4b3b-b14b-fc8e30507c24.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, distribute the result in production by following the on-screen steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon SageMaker is a fully managed service for the creation, training, and
    distribution of models based on machine learning. Amazon SageMaker comes with
    three modules—**Build**, **Train**, and **Deploy**. The Build module allows us
    to work with data, experiment with algorithms, and view the output. The Train
    module trains the model and optimizes it on a large scale. Finally, there is the
    Deploy module, which allows us to easily test the inference of the model with
    low latency.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon SageMaker allows us to create machine learning models for use in intelligent
    and predictive apps. From a security standpoint, Amazon SageMaker encrypts all
    scripts based on machine learning. Requests to the API and the Amazon SageMaker
    console are forwarded via a **secure connection** (**SSL**). We can use AWS Identity
    and Access Management to automatically assign access permissions to training and
    distribution resources. We can also use Bucket S3, an Amazon SageMaker KMS key,
    to notebook training processes and endpoints to encrypt storage volumes.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the official documentation of Amazon SageMaker: [https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/whatis.html](https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/whatis.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping track of changes into production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The distribution of the model is not the end—it's only the beginning. The real
    problems start from here. We have no control over the data in the real environment.
    Changes may occur and we must be ready to detect and update our model before it
    becomes obsolete. Monitoring is important to ensure the reliability, availability,
    and performance of our machine learning application. In this recipe, we will discuss
    some tools that we can use to keep track of changes that occur in the model.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following tools are available to monitor an Amazon SageMaker application:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon CloudWatch**: This tool, which is available in AWS, monitors the resources
    and applications that run in real time. Parameters can be collected and tracked,
    custom control panels can be created, and alerts can be set to notify or take
    action when a specified parameter reaches a specified threshold. The following
    screenshot shows an overview of Amazon CloudWatch:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/c38d2062-0e36-40ff-b71d-8bd2f17c6e0e.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Amazon CloudWatch Logs**: This tool, which is available in AWS, allows you
    to monitor, store, and access log files from EC2, AWS CloudTrail instances, and
    other sources. The CloudWatch logs monitor information in the log files and allow
    us to send notifications when certain thresholds are reached.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS CloudTrail**: This tool, which is available in AWS, retrieves API calls
    and related events that are created by our account and returns a log file to a
    specified Amazon S3 bucket. We can also retrieve useful information about the
    users and accounts that have called the services, and we can trace the IP address
    from which the calls were made and when they occurred.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To monitor Amazon SageMaker, we can use Amazon CloudWatch, which collects raw
    data and transforms it into readable parameters in real time. These statistics
    are kept for a period of 15 months so that you can access historical information
    and offer a better perspective on the performance of the service or web application.
    However, the Amazon CloudWatch console limits the search to the parameters that
    have been updated in the last two weeks. This limitation allows you to view the
    most up-to-date processes in the namespace. It is also possible to set alarms
    that control certain thresholds and send notifications or take action when these
    thresholds are reached.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A machine learning model is based on a set of input training data with various
    attributes. Therefore, it is important to check whether the input data that the
    model was trained on still applies to the actual data in the real environment.
    The data change could be sudden, or it could change gradually over time. Therefore,
    it is essential to identify patterns of change and correct the model in advance. Once
    the model has been distributed in a production environment, it is necessary to
    follow the steps mentioned in the next recipe to keep our models healthy and useful
    for their end users.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the official documentation of Amazon CloudWatch: [https://docs.aws.amazon.com/cloudwatch/index.html](https://docs.aws.amazon.com/cloudwatch/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the official documentation of Amazon CloudWatch Logs: [https://docs.aws.amazon.com/en_us/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html](https://docs.aws.amazon.com/en_us/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the official documentation of Amazon CloudTrail: [https://docs.aws.amazon.com/cloudtrail/index.html](https://docs.aws.amazon.com/cloudtrail/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking accuracy to optimize model scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in [Chapter 15](8bc48ed3-a991-49e8-8c04-148505fac009.xhtml), *Automated
    Machine Learning and Transfer Learning*, most machine learning algorithms employ
    a series of parameters that control the functionality of the underlying algorithm.
    These parameters are generally called hyperparameters; their values influence
    the quality of trained models. Automatic model optimization is the process of
    finding a set of hyperparameters of an algorithm that offer an optimal model. In
    this recipe, we will learn how to use the Amazon SageMaker tools to optimize our
    model automatically.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To perform an automatic optimization of our model, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Amazon SageMaker console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Endpoint item in the navigation pane at the bottom-left.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1e6a5090-7a69-438a-9a22-c183352cbd6e.png)'
  prefs: []
  type: TYPE_IMG
- en: Select the endpoint you want to configure from those available.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the variant you want to configure and configure automatic scaling. Do
    this for the Endpoint runtime settings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the average number of invocations per instance, per minute for the variant.
    Do this for the target value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the number of seconds for each cooling period.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To prevent the scaling policy from deleting variant instances, select the Disable
    scale option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Save.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The hyperparameter optimization procedure represents a special case of regression.
    The problem can be framed as follows: a set of input features is available, and
    then this procedure optimizes a model for the adopted parameters. The choice of
    parameters is free as long as it is defined by the algorithm we are using. In
    the Amazon hyperparameter optimization procedure, SageMaker tries to find out
    what hyperparameter combinations are more likely to produce the best results,
    and tries to execute the training processes to test these attempts. To do this, the
    first set of values for those hyperparameters is tested, and then the procedure
    uses regression to choose the next set of values to be tested.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you choose the best hyperparameters for the next training process, hyperparameter
    optimization takes into consideration everything you know about the problem, up
    to the present time. In some cases, the hyperparameter optimization procedure
    can choose a point that produces an incremental improvement in the best result
    that's been found so far. In this way, the procedure uses already known results.
    In other cases, you can choose a set of hyperparameters far from those you have
    already tested. In this way, the procedure explores the space and searches for
    new areas that haven't been fully analyzed yet. The compromise between exploration
    and exploitation is common in many machine learning problems.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to *Automatically Scale Amazon SageMaker Models*: [https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/endpoint-auto-scaling.html](https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/endpoint-auto-scaling.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
