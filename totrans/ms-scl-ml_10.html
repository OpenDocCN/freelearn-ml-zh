<html><head></head><body><div id="sbo-rt-content"><div class="chapter" title="Chapter 10. Advanced Model Monitoring"><div class="titlepage"><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Advanced Model Monitoring</h1></div></div></div><p>Even though this is the last chapter of the book, it can hardly be an afterthought even though monitoring in general often is in practical situations, quite unfortunately. Monitoring is a vital deployment component for any long execution cycle component and thus is part of the finished product. Monitoring can significantly enhance product experience and define future success as it improves problem diagnostic and is essential to determine the improvement path.</p><p>One of the primary rules of successful software engineering is to create systems as if they were targeted for personal use when possible, which fully applies to monitoring, diagnostic, and debugging—quite hapless name for fixing existing issues in software products. Diagnostic and debugging of complex systems, particularly distributed systems, is hard, as the events often can be arbitrary interleaved and program executions subject to race conditions. While there is a lot of research going in the area of distributed system devops and maintainability, this chapter will scratch the service and provide guiding principle to design a maintainable complex distributed system.</p><p>To start with, a pure functional approach, which Scala claims to follow, spends a lot of time avoiding side effects. While this idea is useful in a number of aspects, it is hard to imagine a useful program that has no effect on the outside world, the whole idea of a data-driven application is to have a positive effect on the way the business is conducted, a well-defined side effect.</p><p>Monitoring clearly falls in the side effect category. Execution needs to leave a trace that the user can later parse in order to understand where the design or implementation went awry. The trace of the execution can be left by either writing something on a console or into a file, usually called a log, or returning an object that contains the trace of the program execution, and the intermediate results. The latter approach, which is actually more in line with functional programming and monadic philosophy, is actually more appropriate for the distributed programming but often overlooked. This would have been an interesting topic for research, but unfortunately the space is limited and I have to discuss the practical aspects of monitoring in contemporary systems that is almost always done by logging. Having the monadic approach of carrying an object with the execution trace on each call can certainly increase the overhead of the interprocess or inter-machine communication, but saves a lot of time in stitching different pieces of information together.</p><p>Let's list the naive approaches to debugging that everyone who needed to find a bug in the code tried:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Analyzing program output, particularly logs produced by simple print statements or built-in logback, java.util.logging, log4j, or the slf4j façade</li><li class="listitem" style="list-style-type: disc">Attaching a (remote) debugger</li><li class="listitem" style="list-style-type: disc">Monitoring CPU, disk I/O, memory (to resolve higher level resource-utilization issues)</li></ul></div><p>More or less, all these approaches fail if we have a multithreaded or distributed system—and Scala is inherently multithreaded as Spark is inherently distributed. Collecting logs over a set of nodes is not scalable (even though a few successful commercial systems exist that do this). Attaching a remote debugger is not always possible due to security and network restrictions. Remote debugging can also induce substantial overhead and interfere with the program execution, particularly for ones that use synchronization. Setting the debug level to the <code class="literal">DEBUG</code> or <code class="literal">TRACE</code> level helps sometimes, but leaves you at the mercy of the developer who may or may not have thought of a particular corner case you are dealing with right at the moment. The approach we take in this book is to open a servlet with enough information to glean into program execution and application methods real-time, as much as it is possible with the current state of Scala and Scalatra.</p><p>Enough about the overall issues of debugging the program execution. Monitoring is somewhat different, as it is concerned with only high-level issue identification. Intersection with issue investigation or resolution happens, but usually is outside of monitoring. In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding major areas for monitoring and monitoring goals</li><li class="listitem" style="list-style-type: disc">Learning OS tools for Scala/Java monitoring to support issue identification and debugging</li><li class="listitem" style="list-style-type: disc">Learning about MBeans and MXBeans</li><li class="listitem" style="list-style-type: disc">Understanding model performance drift</li><li class="listitem" style="list-style-type: disc">Understanding A/B testing</li></ul></div><div class="section" title="System monitoring"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec70"/>System monitoring</h1></div></div></div><p>While there <a id="id719" class="indexterm"/>are other types of monitoring dealing specifically with ML-targeted tasks, such as monitoring the performance of the models, let me start with basic system monitoring. Traditionally, system monitoring is a subject of operating system maintenance, but it is becoming a vital component of any complex application, specifically running over a set of distributed workstations. The primary components of the OS are CPU, disk, memory, network, and energy on battery-powered machines. The <a id="id720" class="indexterm"/>traditional OS-like tools for monitoring system performance are provided in the following table. We limit them to Linux tools as this is the platform for most Scala applications, even though other OS vendors provide OS monitoring tools<a id="id721" class="indexterm"/> such as <span class="strong"><strong>Activity Monitor</strong></span>. As Scala runs in Java JVM, I also added Java-specific monitoring tools that are specific to JVMs:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Area</p>
</th><th style="text-align: left" valign="bottom">
<p>Programs</p>
</th><th style="text-align: left" valign="bottom">
<p>Comments</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>CPU</p>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">htop,</code> <code class="literal">top</code>, <code class="literal">sar-u</code>
</p>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">top</code> has been the most often used performance diagnostic tool, as CPU and memory have been the most constraint resources. With the advent of distributed programming, network and disk tend to be the most constraint.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Disk</p>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">iostat</code>, <code class="literal">sar -d</code>, <code class="literal">lsof</code>
</p>
</td><td style="text-align: left" valign="top">
<p>The number of open files, provided by <code class="literal">lsof</code>, is often a constraining resource as many big data applications and daemons tend to keep multiple files open.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Memory</p>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">top</code>, <code class="literal">free</code>, <code class="literal">vmstat</code>, <code class="literal">sar -r</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Memory is used by OS in multiple ways, for example to maintain disk I/O buffers so that having extra buffered and cached memory helps performance.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Network</p>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">ifconfig</code>, <code class="literal">netstat</code>, <code class="literal">tcpdump</code>, <code class="literal">nettop</code>, <code class="literal">iftop</code>, <code class="literal">nmap</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Network is how the distributed systems talk and is an important OS component. From the application point of view, watch for errors, collisions, and dropped packets as an indicator of problems.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Energy</p>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">powerstat</code>
</p>
</td><td style="text-align: left" valign="top">
<p>While power consumption is traditionally not a part of OS monitoring, it is nevertheless a shared resource, which recently became one of the major costs for maintaining a working system.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Java</p>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">jconsole</code>, <code class="literal">jinfo</code>, <code class="literal">jcmd</code>, <code class="literal">jmc</code>
</p>
</td><td style="text-align: left" valign="top">
<p>All these tools allow you to examine configuration and run-time properties of an application. <span class="strong"><strong>Java Mission Control</strong></span> (<span class="strong"><strong>JMC</strong></span>) is shipped with<a id="id722" class="indexterm"/> JDK starting with version 7u40.</p>
</td></tr></tbody></table></div><div class="blockquote"><blockquote class="blockquote"><p>Table 10.1. Common Linux OS monitoring tools</p></blockquote></div><p>In many cases, the tools are redundant. For example, the CPU and memory information can be obtained with <code class="literal">top</code>, <code class="literal">sar</code>, and <code class="literal">jmc</code> commands.</p><p>There are a <a id="id723" class="indexterm"/>few tools for collecting this information over a set of distributed nodes. Ganglia<a id="id724" class="indexterm"/> is a BSD-licensed scalable distributed monitoring <a id="id725" class="indexterm"/>system (<a class="ulink" href="http://ganglia.info">http://ganglia.info</a>). It is based on a hierarchical design and is very careful about data structure and algorithm designs. It is known to scale to 10,000s of nodes. It consists of a gmetad daemon that is collects information from multiple hosts and presents it in a web interface, and gmond daemons running on each individual host. The communication happens on the 8649 port by default, which spells Unix. By default, gmond sends information about CPU, memory, and network, but multiple plugins exist for other metrics (or can be created). Gmetad can aggregate the information and pass it up the hierarchy chain to another gmetad daemon.  Finally, the data is presented in a Ganglia web interface.</p><p>Graphite is another monitoring tool that stores numeric time-series data and renders graphs of this data on demand. The web app provides a /render endpoint to generate graphs and retrieve raw data via a RESTful API. Graphite has a pluggable backend (although it has it's own default implementation). Most of the modern metrics implementations, including scala-metrics used in this chapter, support sending data to Graphite.</p><div class="section" title="Process monitoring"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl1sec71"/>Process monitoring</h2></div></div></div><p>The tools described in<a id="id726" class="indexterm"/> the previous section are not application-specific. For a long-running process, it often necessary to provide information about the internal state to either a monitoring a graphing solution such as Ganglia or Graphite, or just display it in a servlet. Most of these solutions are read-only, but in some cases, the commands give the control to the users to modify the state, such as log levels, or to trigger garbage collection.</p><p>Monitoring, in general is supposed to do the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Provide high-level information about program execution and application-specific metrics</li><li class="listitem" style="list-style-type: disc">Potentially, perform health-checks for critical components</li><li class="listitem" style="list-style-type: disc">Might incorporate alerting and thresholding on some critical metrics</li></ul></div><p>I have also seen monitoring to include update operations to either update the logging parameters or test components, such as trigger model scoring with predefined parameters. The latter can be considered as a part of parameterized health check.</p><p>Let's see how it <a id="id727" class="indexterm"/>works on the example of a simple <code class="literal">Hello World</code> web application that accepts REST-like requests and assigns a unique ID for different users written in the <a id="id728" class="indexterm"/>Scalatra framework (<a class="ulink" href="http://scalatra.org">http://scalatra.org</a>), a lightweight web-application development framework in Scala. The application is supposed to respond to CRUD HTTP requests to create a unique numeric ID for a user. To implement the service in Scalatra, we need just to provide a <code class="literal">Scalate</code> template. The full <a id="id729" class="indexterm"/>documentation can be found at <a class="ulink" href="http://scalatra.org/2.4/guides/views/scalate.html">http://scalatra.org/2.4/guides/views/scalate.html</a>, the source code is provided with the book and can be found in <code class="literal">chapter10</code> subdirectory:</p><div class="informalexample"><pre class="programlisting">class SimpleServlet extends Servlet {
  val logger = LoggerFactory.getLogger(getClass)
  var hwCounter: Long = 0L
  val hwLookup: scala.collection.mutable.Map[String,Long] = scala.collection.mutable.Map() 
  val defaultName = "Stranger"
  def response(name: String, id: Long) = { "Hello %s! Your id should be %d.".format(if (name.length &gt; 0) name else defaultName, id) }
  get("/hw/:name") {
    val name = params("name")
    val startTime = System.nanoTime
    val retVal = response(name, synchronized { hwLookup.get(name) match { case Some(id) =&gt; id; case _ =&gt; hwLookup += name -&gt; { hwCounter += 1; hwCounter } ; hwCounter } } )
    logger.info("It took [" + name + "] " + (System.nanoTime - startTime) + " " + TimeUnit.NANOSECONDS)
    retVal
  }
}</pre></div><p>First, the code gets the <code class="literal">name</code> parameter from the request (REST-like parameter parsing is also supported). Then, it checks the internal HashMap for existing entries, and if the entry does not exist, it creates a new index using a synchronized call to increment <code class="literal">hwCounter</code> (in a real-world application, this information should be persistent in a database such as HBase, but I'll skip this layer in this section for the purpose of simplicity). To run the application, one needs to download the code, start <code class="literal">sbt</code>, and type <code class="literal">~;jetty:stop;jetty:start</code> to enable continuous run/compilation as in <a class="link" href="ch07.xhtml" title="Chapter 7. Working with Graph Algorithms">Chapter 7</a>, <span class="emphasis"><em>Working with Graph Algorithms</em></span>. The modifications to the file will be immediately picked up by the<a id="id730" class="indexterm"/> build tool and the jetty server will restart:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>[akozlov@Alexanders-MacBook-Pro chapter10]$ sbt</strong></span>
<span class="strong"><strong>[info] Loading project definition from /Users/akozlov/Src/Book/ml-in-scala/chapter10/project</strong></span>
<span class="strong"><strong>[info] Compiling 1 Scala source to /Users/akozlov/Src/Book/ml-in-scala/chapter10/project/target/scala-2.10/sbt-0.13/classes...</strong></span>
<span class="strong"><strong>[info] Set current project to Advanced Model Monitoring (in build file:/Users/akozlov/Src/Book/ml-in-scala/chapter10/)</strong></span>
<span class="strong"><strong>&gt; ~;jetty:stop;jetty:start</strong></span>
<span class="strong"><strong>[success] Total time: 0 s, completed May 15, 2016 12:08:31 PM</strong></span>
<span class="strong"><strong>[info] Compiling Templates in Template Directory: /Users/akozlov/Src/Book/ml-in-scala/chapter10/src/main/webapp/WEB-INF/templates</strong></span>
<span class="strong"><strong>SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".</strong></span>
<span class="strong"><strong>SLF4J: Defaulting to no-operation (NOP) logger implementation</strong></span>
<span class="strong"><strong>SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.</strong></span>
<span class="strong"><strong>[info] starting server ...</strong></span>
<span class="strong"><strong>[success] Total time: 1 s, completed May 15, 2016 12:08:32 PM</strong></span>
<span class="strong"><strong>1. Waiting for source changes... (press enter to interrupt)</strong></span>
<span class="strong"><strong>2016-05-15 12:08:32.578:INFO::main: Logging initialized @119ms</strong></span>
<span class="strong"><strong>2016-05-15 12:08:32.586:INFO:oejr.Runner:main: Runner</strong></span>
<span class="strong"><strong>2016-05-15 12:08:32.666:INFO:oejs.Server:main: jetty-9.2.1.v20140609</strong></span>
<span class="strong"><strong>2016-05-15 12:08:34.650:WARN:oeja.AnnotationConfiguration:main: ServletContainerInitializers: detected. Class hierarchy: empty</strong></span>
<span class="strong"><strong>2016-15-05 12:08:34.921: [main] INFO  o.scalatra.servlet.ScalatraListener - The cycle class name from the config: ScalatraBootstrap</strong></span>
<span class="strong"><strong>2016-15-05 12:08:34.973: [main] INFO  o.scalatra.servlet.ScalatraListener - Initializing life cycle class: ScalatraBootstrap</strong></span>
<span class="strong"><strong>2016-15-05 12:08:35.213: [main] INFO  o.f.s.servlet.ServletTemplateEngine - Scalate template engine using working directory: /var/folders/p1/y7ygx_4507q34vhd60q115p80000gn/T/scalate-6339535024071976693-workdir</strong></span>
<span class="strong"><strong>2016-05-15 12:08:35.216:INFO:oejsh.ContextHandler:main: Started o.e.j.w.WebAppContext@1ef7fe8e{/,file:/Users/akozlov/Src/Book/ml-in-scala/chapter10/target/webapp/,AVAILABLE}{file:/Users/akozlov/Src/Book/ml-in-scala/chapter10/target/webapp/}</strong></span>
<span class="strong"><strong>2016-05-15 12:08:35.216:WARN:oejsh.RequestLogHandler:main: !RequestLog</strong></span>
<span class="strong"><strong>2016-05-15 12:08:35.237:INFO:oejs.ServerConnector:main: Started ServerConnector@68df9280{HTTP/1.1}{0.0.0.0:8080}</strong></span>
<span class="strong"><strong>2016-05-15 12:08:35.237:INFO:oejs.Server:main: Started @2795ms2016-15-05 12:03:52.385: [main] INFO  o.f.s.servlet.ServletTemplateEngine - Scalate template engine using working directory: /var/folders/p1/y7ygx_4507q34vhd60q115p80000gn/T/scalate-3504767079718792844-workdir</strong></span>
<span class="strong"><strong>2016-05-15 12:03:52.387:INFO:oejsh.ContextHandler:main: Started o.e.j.w.WebAppContext@1ef7fe8e{/,file:/Users/akozlov/Src/Book/ml-in-scala/chapter10/target/webapp/,AVAILABLE}{file:/Users/akozlov/Src/Book/ml-in-scala/chapter10/target/webapp/}</strong></span>
<span class="strong"><strong>2016-05-15 12:03:52.388:WARN:oejsh.RequestLogHandler:main: !RequestLog</strong></span>
<span class="strong"><strong>2016-05-15 12:03:52.408:INFO:oejs.ServerConnector:main: Started ServerConnector@68df9280{HTTP/1.1}{0.0.0.0:8080}</strong></span>
<span class="strong"><strong>2016-05-15 12:03:52.408:INFO:oejs.Server:main: Started @2796mss</strong></span>
</pre></div><p>When the <a id="id731" class="indexterm"/>servlet is started on port 8080, issue a browser request:</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip10"/>Tip</h3><p>I pre-created the project for this book, but if you want to create a Scalatra project from scratch, there is a <code class="literal">gitter</code> command in <code class="literal">chapter10/bin/create_project.sh</code>. Gitter will create a <code class="literal">project/build.scala</code> file with a Scala object, extending build that will set project parameters and enable the Jetty plugin for the SBT.</p></div></div><p>
<code class="literal">http://localhost:8080/hw/Joe</code>. </p><p>The output should look similar to the following screenshot:</p><div class="mediaobject"><img src="Images/B04935_10_01.jpg" alt="Process monitoring" width="900" height="105"/><div class="caption"><p>Figure 10-1: The servlet web page.</p></div></div><p>If you call the servlet with a different name, it will assign a distinct ID, which will be persistent across the lifetime of the application.</p><p>As we also enabled console logging, you will also see something similar to the following command on the console:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>2016-15-05 13:10:06.240: [qtp1747585824-26] INFO  o.a.examples.ServletWithMetrics - It took [Joe] 133225 NANOSECONDS</strong></span>
</pre></div><p>While retrieving and analyzing logs, which can be redirected to a file, is an option and there are multiple systems to collect, search, and analyze logs from a set of distributed servers, it is often also important to have a simple way to introspect the running code. One way to accomplish this is to create a separate template with metrics, however, Scalatra provides metrics and health support to enable basic implementations for counts, histograms, rates, and so on.</p><p>I will use the Scalatra metrics support. The <code class="literal">ScalatraBootstrap</code> class has to implement the <code class="literal">MetricsBootstrap</code> trait. The <code class="literal">org.scalatra.metrics.MetricsSupport</code> and <code class="literal">org.scalatra.metrics.HealthChecksSupport</code> traits provide templating similar to the Scalate<a id="id732" class="indexterm"/> templates, as shown in the following code.</p><p>The following is the content of the <code class="literal">ScalatraTemplate.scala</code> file:</p><div class="informalexample"><pre class="programlisting">import org.akozlov.examples._

import javax.servlet.ServletContext
import org.scalatra.LifeCycle
import org.scalatra.metrics.MetricsSupportExtensions._
import org.scalatra.metrics._
 
class ScalatraBootstrap extends LifeCycle with MetricsBootstrap {
  override def init(context: ServletContext) = {
    context.mount(new ServletWithMetrics, "/")
    context.mountMetricsAdminServlet("/admin")
    context.mountHealthCheckServlet("/health")
    context.installInstrumentedFilter("/*")
  }
}</pre></div><p>The following is the content of the <code class="literal">ServletWithMetrics.scala</code> file:</p><div class="informalexample"><pre class="programlisting">package org.akozlov.examples

import org.scalatra._
import scalate.ScalateSupport
import org.scalatra.ScalatraServlet
import org.scalatra.metrics.{MetricsSupport, HealthChecksSupport}
import java.util.concurrent.atomic.AtomicLong
import java.util.concurrent.TimeUnit
import org.slf4j.{Logger, LoggerFactory}

class ServletWithMetrics extends Servlet with MetricsSupport with HealthChecksSupport {
  val logger = LoggerFactory.getLogger(getClass)
  val defaultName = "Stranger"
  var hwCounter: Long = 0L
  val hwLookup: scala.collection.mutable.Map[String,Long] = scala.collection.mutable.Map()  val hist = histogram("histogram")
  val cnt =  counter("counter")
  val m = meter("meter")
  healthCheck("response", unhealthyMessage = "Ouch!") { response("Alex", 2) contains "Alex" }
  def response(name: String, id: Long) = { "Hello %s! Your id should be %d.".format(if (name.length &gt; 0) name else defaultName, id) }

  get("/hw/:name") {
    cnt += 1
    val name = params("name")
    hist += name.length
    val startTime = System.nanoTime
    val retVal = response(name, synchronized { hwLookup.get(name) match { case Some(id) =&gt; id; case _ =&gt; hwLookup += name -&gt; { hwCounter += 1; hwCounter } ; hwCounter } } )s
    val elapsedTime = System.nanoTime - startTime
    logger.info("It took [" + name + "] " + elapsedTime + " " + TimeUnit.NANOSECONDS)
    m.mark(1)
    retVal
  }</pre></div><p>If you run the <a id="id733" class="indexterm"/>server again, the <code class="literal">http://localhost:8080/admin</code> page will show a set of links for operational information, as shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B04935_10_02.jpg" alt="Process monitoring" width="600" height="382"/><div class="caption"><p>Figure 10-2: The admin servlet web page</p></div></div><p>The <span class="strong"><strong>Metrics</strong></span> link will lead to the metrics servlet depicted in <span class="emphasis"><em>Figure 10-3</em></span>. The <code class="literal">org.akozlov.exampes.ServletWithMetrics.counter</code> will have a global count of requests, and <code class="literal">org.akozlov.exampes.ServletWithMetrics.histogram</code> will show the distribution <a id="id734" class="indexterm"/>of accumulated values, in this case, the name lengths. More importantly, it will compute <code class="literal">50</code>, <code class="literal">75</code>, <code class="literal">95</code>, <code class="literal">98</code>, <code class="literal">99</code>, and <code class="literal">99.9</code> percentiles. The meter counter will show rates for the last <code class="literal">1</code>, <code class="literal">5</code>, and <code class="literal">15</code> minutes:</p><div class="mediaobject"><img src="Images/B04935_10_03.jpg" alt="Process monitoring" width="900" height="694"/><div class="caption"><p>Figure 10-3: The metrics servlet web page</p></div></div><p>Finally, one can <a id="id735" class="indexterm"/>write health checks. In this case, I will just check whether the result of the response function contains the string that it has been passed as a parameter. Refer to the following <span class="emphasis"><em>Figure 10.4</em></span>:</p><div class="mediaobject"><img src="Images/B04935_10_04.jpg" alt="Process monitoring" width="800" height="146"/><div class="caption"><p>Figure 10-4: The health check servlet web page.</p></div></div><p>The metrics <a id="id736" class="indexterm"/>can be configured to report to Ganglia or Graphite data collection servers or periodically dump information into a log file.</p><p>Endpoints do not have to be read-only. One of the pre-configured components is the timer, which measures the time to complete a task—which can be used for measuring scoring performance. Let's put the code in the <code class="literal">ServletWithMetrics</code> class:</p><div class="informalexample"><pre class="programlisting">  get("/time") {
    val sleepTime = scala.util.Random.nextInt(1000)
    val startTime = System.nanoTime
    timer("timer") {
      Thread.sleep(sleepTime)
      Thread.sleep(sleepTime)
      Thread.sleep(sleepTime)
    }
    logger.info("It took [" + sleepTime + "] " + (System.nanoTime - startTime) + " " + TimeUnit.NANOSECONDS)
    m.mark(1)
  }</pre></div><p>Accessing <code class="literal">http://localhost:8080/time</code> will trigger code execution, which will be timed with a timer in metrics.</p><p>Analogously, the put operation, which can be created with the <code class="literal">put()</code> template, can be used to either adjust the run-time parameters or execute the code in-situ—which, depending on the code, might need to be secured in production environments.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note15"/>Note</h3><p>
<span class="strong"><strong>JSR 110</strong></span>
</p><p>JSR 110 is <a id="id737" class="indexterm"/>another <span class="strong"><strong>Java Specification Request</strong></span> (<span class="strong"><strong>JSR</strong></span>), commonly<a id="id738" class="indexterm"/> known as <span class="strong"><strong>Java Management Extensions</strong></span> (<span class="strong"><strong>JMX</strong></span>). JSR 110 specifies a number of APIs and protocols in <a id="id739" class="indexterm"/>order to be able to monitor the JVM executions remotely. A common way to access JMX Services is via the <code class="literal">jconsole</code> command that will connect to one of the local processes by default. To connect to a remote host, you need to provide the <code class="literal">-Dcom.sun.management.jmxremote.port=portNum</code> property on the Java command line. It is also advisable to enable security (SSL or password-based authentication). In practice, other monitoring tools use JMX for monitoring, as well as managing the JVM, as JMX allows callbacks to manage the system state.</p><p>You can provide your own metrics that are exposed via JMX. While Scala runs in JVM, the implementation of JMX (via MBeans) is very Java-specific, and it is not clear how well the mechanism will play with Scala. JMX Beans can certainly be exposed as a servlet in Scala though.</p></div></div><p>The<a id="id740" class="indexterm"/> JMX MBeans can usually be examined in JConsole, but we can also expose it as <code class="literal">/jmx servlet</code>, the code provided in the book repository (<a class="ulink" href="https://github.com/alexvk/ml-in-scala">https://github.com/alexvk/ml-in-scala</a>).</p></div><div class="section" title="Model monitoring"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl1sec72"/>Model monitoring</h2></div></div></div><p>We have covered basic<a id="id741" class="indexterm"/> system and application metrics. Lately, a new direction evolved for using monitoring components to monitor statistical model performance. The statistical model performance covers the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">How the model performance evolved over time</li><li class="listitem" style="list-style-type: disc">When is the time to retire the model</li><li class="listitem" style="list-style-type: disc">Model health check</li></ul></div><div class="section" title="Performance over time"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec55"/>Performance over time</h3></div></div></div><p>ML models deteriorate with time, or 'age': While this process is not still well understood, the model performance tends to change<a id="id742" class="indexterm"/> with time, if even due to concept drift, where the definition of the attributes change, or the changes in the underlying dependencies. Unfortunately, model performance rarely improves, at least in my practice. Thus, it is imperative to keep track of models. One way to do this is by monitoring the metrics that the model is intended to optimize, as in many cases, we do not have a ready-labeled set of data.</p><p>In many cases, the model performance deterioration is not related directly to the quality of the statistical modeling, even though simpler models such as linear and logistic regression tend to be more stable than more complex models such as decision trees. Schema evolution or unnoticed renaming of attributes may cause the model to not perform well.</p><p>Part of model monitoring should be running the health check, where a model periodically scores either a few records or a known scored set of data.</p></div><div class="section" title="Criteria for model retiring"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec56"/>Criteria for model retiring</h3></div></div></div><p>A very<a id="id743" class="indexterm"/> common case in practical deployments is that data scientists come with better sets of models every few weeks. However, if this does not happen, one needs come up with a set of criteria to retire a model. As real-world traffic rarely comes with the scored data, for example, the data that is already scored, the usual way to measure model performance is via a proxy, which is the metric that the model is supposed to improve.</p></div><div class="section" title="A/B testing"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec57"/>A/B testing</h3></div></div></div><p>A/B testing is a<a id="id744" class="indexterm"/> specific case of controlled experiment in e-commerce setting. A/B testing is usually applied to versions of a web page where we<a id="id745" class="indexterm"/> direct completely independent subset of users to each of the versions. The dependent variable to test is usually the response rate. Unless any specific information is available about users, and in many cases, it is not unless a cookie is placed in the computer, the split is random. Often the split is based on unique userID, but this is known not to work too well across multiple devices. A/B testing is subject to the same assumptions the controlled experiments are subject to: the tests should be completely independent and the distribution of the dependent variable should be <code class="literal">i.i.d.</code>. Even though it is hard to imagine that all people are truly <code class="literal">i.i.d.</code>, the A/B test has been shown to work for practical problems.</p><p>In modeling, we split the traffic to be scored into two or multiple channels to be scored by two or multiple models. Further, we need to measure the cumulative performance metric for each of the channels together with estimated variance. Usually, one of the models is treated as a baseline and is associated with the null hypothesis, and for the rest of the models, we run a t-test, comparing the ratio of the difference to the standard deviation.</p></div></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec73"/>Summary</h1></div></div></div><p>This chapter described system, application, and model monitoring goals together with the existing monitoring solutions for Scala, and specifically Scalatra. Many metrics overlap with standard OS or Java monitoring, but we also discussed how to create application-specific metrics and health checks. We talked about a new emerging field of model monitoring in an ML application, where statistical models are subject to deterioration, health, and performance monitoring. I also touched on monitoring distributed systems, a topic that really deserves much more space, which unfortunately, I did not have.</p><p>This is the end of the book, but in no way is it the end of the journey. I am sure, new frameworks and applications are being written as we speak. Scala has been a pretty awesome and succinct development tool in my practice, with which I've been able to achieve results in hours instead of days, which is the case with more traditional tools, but it is yet to win the popular support, which I am pretty sure it. We just need to emphasize its advantages in the modern world of interactive analysis, complex data, and distributed processing.</p></div></div>



  </body></html>