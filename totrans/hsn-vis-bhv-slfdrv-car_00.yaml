- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Self-driving cars will soon be among us. The improvements seen in this field
    have been nothing short of extraordinary. The first time I heard about self-driving
    cars, it was in 2010, when I tried one in the Toyota showroom in Tokyo. The ride
    cost around a dollar. The car was going very slowly, and it was apparently dependent
    on sensors embedded in the road.
  prefs: []
  type: TYPE_NORMAL
- en: Fast forward a few years, lidar and advancements in computer vision and deep
    learning have made that technology look primitive and unnecessarily invasive and
    expensive.
  prefs: []
  type: TYPE_NORMAL
- en: In the course of this book, we will use OpenCV for a variety of tasks, including
    pedestrian detection and lane detection; you will discover deep learning and learn
    how to leverage it for image classification, object detection, and semantic segmentation,
    using it to identify pedestrians, cars, roads, sidewalks, and crossing lights,
    while learning about some of the most influential neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: You will get comfortable using the CARLA simulator, which you will use to control
    a car using behavioral cloning and a PID controller; you will learn about network
    protocols, sensors, cameras, and how to use lidar to map the world around you
    and to find your position.
  prefs: []
  type: TYPE_NORMAL
- en: But before diving into these amazing technologies, please take a moment and
    try to imagine the future in 20 years. What are the cars like? They can drive
    by themselves. But can they also fly? Are there still crossing lights? How fast,
    heavy, and expensive are those cars? How do we use them, and how often? What about
    self-driving buses and trucks?
  prefs: []
  type: TYPE_NORMAL
- en: We cannot know the future, but it is conceivable that self-driving cars, and
    self-driving things in general, will shape our daily lives and our cities in new
    and exciting ways.
  prefs: []
  type: TYPE_NORMAL
- en: Do you want to play an active role in defining this future? If so, keep reading.
    This book can be the first step of your journey.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The book covers several aspects of what is necessary to build a self-driving
    car and is intended for programmers with a basic knowledge of any programming
    language, preferably Python. No previous experience with deep learning is required;
    however, to fully understand the most advanced chapters, it might be useful to
    take a look at some of the suggested reading. The optional source code associated
    with [*Chapter 11*](B16322_11_Final_NM_ePUB.xhtml#_idTextAnchor250), *Mapping
    Our Environments*, is in C++.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B16322_01_Final_NM_ePUB.xhtml#_idTextAnchor017), *OpenCV Basics
    and Camera Calibration*, is an introduction to OpenCV and NumPy; you will learn
    how to manipulate images and videos, and how to detect pedestrians using OpenCV;
    in addition, it explains how a camera works and how OpenCV can be used to calibrate
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B16322_02_Final_NM_ePUB.xhtml#_idTextAnchor046), *Understanding
    and Working with Signals*, describes the different types of signals: serial, parallel,
    digital, analog, single-ended, and differential, and explains some very important
    protocols: CAN, Ethernet, TCP, and UDP.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B16322_03_Final_NM_ePUB.xhtml#_idTextAnchor066), *Lane Detection*,
    teaches you everything you need to know to detect the lanes in a road using OpenCV.
    It covers color spaces, perspective correction, edge detection, histograms, the
    sliding window technique, and the filtering required to get the best detection.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, is a practical introduction to neural networks, designed
    to quickly teach how to write a neural network. It describes neural networks in
    general and convolutional neural networks in particular. It introduces Keras,
    a deep learning module, and it shows how to use it to detect handwritten digits
    and to classify some images.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B16322_05_Final_NM_ePUB.xhtml#_idTextAnchor118), *Deep Learning
    Workflow*, ideally complements [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091),
    *Deep Learning with Neural Networks*, as it describes the theory of neural networks
    and the steps required in a typical workflow: obtaining or creating a dataset,
    splitting it into training, validation, and test sets, data augmentation, the
    main layers used in a classifier, and how to train, do inference, and retrain.
    The chapter also covers underfitting and overfitting and explains how to visualize
    the activations of the convolutional layers.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142), *Improving Your
    Neural Network*, explains how to optimize a neural network, reducing its parameters,
    and how to improve its accuracy using batch normalization, early stopping, data
    augmentation, and dropout.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B16322_07_Final_NM_ePUB.xhtml#_idTextAnchor158), *Detecting Pedestrians
    and Traffic Lights*, introduces you to CARLA, a self-driving car simulator, which
    we will use to create a dataset of traffic lights. Using a pre-trained neural
    network called SSD, we will detect pedestrians, cars, and traffic lights, and
    we will use a powerful technique called transfer learning to train a neural network
    to classify the traffic lights according to their colors.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B16322_08_Final_NM_ePUB.xhtml#_idTextAnchor182), *Behavioral
    Cloning*, explains how to train a neural network to drive CARLA. It explains what
    behavioral cloning is, how to build a driving dataset using CARLA, how to create
    a network that''s suitable for this task, and how to train it. We will use saliency
    maps to get an understanding of what the network is learning, and we will integrate
    it with CARLA to help it self-drive!'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B16322_09_Final_JM_ePUB.xhtml#_idTextAnchor198), *Semantic Segmentation*,
    is the final and most advanced chapter about deep learning, and it explains what
    semantic segmentation is. It details an extremely interesting architecture called
    DenseNet, and it shows how to adapt it to semantic segmentation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B16322_10_Final_NM_ePUB.xhtml#_idTextAnchor221), *Steering,
    Throttle, and Brake Control*, is about controlling a self-driving car. It explains
    what a controller is, focusing on PID controllers and covering the basics of MPC
    controllers. Finally, we will implement a PID controller in CARLA.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B16322_11_Final_NM_ePUB.xhtml#_idTextAnchor250), *Mapping Our
    Environments*, is the final chapter. It discusses maps, localization, and lidar,
    and it describes some open source mapping tools. You will learn what Simultaneous
    Localization and Mapping (SLAM) is and how to implement it using the Ouster lidar
    and Google Cartographer.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We assume that you have basic knowledge of Python and that you are familiar
    with the shell of your operating system. You should install Python and possibly
    use a virtual environment to match the versions of the software used in the book.
    It is recommended to use a GPU, as training can be very demanding without one.
    Docker will be helpful for [*Chapter 11*](B16322_11_Final_NM_ePUB.xhtml#_idTextAnchor250),
    *Mapping Our Environments*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the following table for the software used in the book:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16322_Preface_Table_NM.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If you are using the digital version of this book, we advise you to type the
    code yourself or access the code via the GitHub repository (link available in
    the next section). Doing so will help you avoid any potential errors related to
    the copying and pasting of code.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars).
    In case there's an update to the code, it will be updated on the existing GitHub
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Code in Action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Code in Action videos for this book can be viewed at [https://bit.ly/2FeZ5dQ](https://bit.ly/2FeZ5dQ).
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://static.packt-cdn.com/downloads/9781800203587_ColorImages.pdf](_ColorImages.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: "Keras offers a method in the model to get the probability,
    `predict()`, and one to get the label, `predict_classes()`."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "The **reference trajectory** is the desired trajectory of the
    controlled variable; for example, the lateral position of the vehicle in the lane."'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    mention the book title in the subject of your message and email us at [customercare@packtpub.com](mailto:customercare@packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  prefs: []
  type: TYPE_NORMAL
- en: For more information about Packt, please visit [packt.com](http://packt.com).
  prefs: []
  type: TYPE_NORMAL
