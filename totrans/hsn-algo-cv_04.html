<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Drawing, Filtering, and Transformation</h1>
                
            
            <article>
                
<p class="calibre2">We started the previous chapter with nothing but the basics and fundamental concepts used in computer vision, and we ended up learning about many algorithms and functions used to perform a wide range of operations on matrices and images. First, we learned all about the functions that are embedded into the <kbd class="calibre13">Mat</kbd> class for convenience, such as cloning (or getting a full and independent copy) a matrix, calculating the cross and the dot product of two matrices, getting the transpose or inverse of a matrix, and producing an identity matrix. Then we moved on to learn about various element-wise operations in OpenCV. Element-wise operations, as we already know, are parallelizable algorithms that perform the same process on all individual pixels (or elements) of an image. During the process, we also experimented with the effect of such operations on actual image files. We completed the previous chapter by learning about operations and functions that treat images as a whole, unlike element-wise operations, but they are still considered matrix operations in terms of computer vision.</p>
<p class="calibre2">Now, we're ready to dig even deeper and learn about numerous powerful algorithms that are used in computer vision applications for tasks such as drawing, filtering, and the transformation of images. As mentioned in the previous chapters, these categories of algorithms as a whole are considered image-processing algorithms. In this chapter, we're going to start by learning about drawing shapes and text on empty images (similar to canvases) or existing images and video frames. The examples in the first section of this chapter will also include a tutorial about adding trackbars to OpenCV windows, for easily adjusting required parameters. After that, we'll move on to learn about image filtering techniques, such as blurring an image, dilation, and erosion. The filtering algorithms and functions that we'll learn about in this chapter include many popular and widely used algorithms, especially by professional photo-editing applications. This chapter will include a comprehensive section about image-transformation algorithms, including algorithms such as the simple resizing of photos, or complex algorithms such as remapping pixels. We'll end this chapter by learning how to apply colormaps to images to transform their colors.</p>
<p class="calibre2">In this chapter, we'll learn about the following:</p>
<ul class="calibre10">
<li class="calibre11">Drawing shapes and text on images</li>
<li class="calibre11">Applying smoothening filters to images</li>
<li class="calibre11">Applying dilation, erosion, and various other filters to images</li>
<li class="calibre11">Remapping pixels and performing geometric transformation algorithms on images</li>
<li class="calibre11">Applying colormaps to images</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Technical requirements</h1>
                
            
            <article>
                
<ul class="calibre10">
<li class="calibre11">An IDE to develop C++ or Python applications</li>
<li class="calibre11">The OpenCV library</li>
</ul>
<p class="calibre2">Refer to <span class="calibre12"><a target="_blank" href="part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4" class="calibre9">Chapter 2</a>, <em class="calibre7">Getting Started with OpenCV</em>,</span> for more information about how to set up a personal computer and make it ready for developing computer vision applications using the OpenCV library.</p>
<p class="calibre2">You can use the following URL to download the source codes and examples for this chapter:</p>
<p class="calibre2"><a href="https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter04" class="calibre9"><span>https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter04</span></a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Drawing on images</h1>
                
            
            <article>
                
<p class="calibre2">Without a doubt, one of the most important tasks when developing computer vision applications is drawing on images. Imagine you want to print the timestamp on pictures or draw a rectangle or ellipse around some areas in an image, and many similar examples that would require you to draw text and digits on images or shapes (rectangles and so on). As you can see, the examples that can be pointed out are quite obvious and countless, so without further ado, let's start with the functions and algorithms in OpenCV that can be used for drawing.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Printing text on images</h1>
                
            
            <article>
                
<p class="calibre2">OpenCV contains a very easy-to-use function named <kbd class="calibre13">putText</kbd> to draw, or print, text on images. This function requires an image as the input/output parameter, which means the source image itself will be updated. So, be sure to make a copy of your original image in memory before calling this function. You also need to provide this function with an origin point, which is simply the point where the text will be printed. The font of the text must be one of the entries in the <kbd class="calibre13">HersheyFonts</kbd> enum, which can take one (or a combination) of the following values:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_SIMPLEX</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_PLAIN</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_DUPLEX</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_COMPLEX</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_TRIPLEX</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_COMPLEX_SMALL</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_SCRIPT_SIMPLEX</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_HERSHEY_SCRIPT_COMPLEX</kbd></li>
<li class="calibre11"><kbd class="calibre13">FONT_ITALIC</kbd></li>
</ul>
<p class="calibre2">For details of how each entry looks when printed, you can check out OpenCV or simply search online for more information about Hershey fonts.</p>
<p class="calibre2">Apart from the parameters we just mentioned, you also need a few additional parameters, such as the scale, color, thickness, and line type of the text. Let's break them all down with a simple example.</p>
<p class="calibre2">Here's an example code that demonstrates the usage of the <kbd class="calibre13">putText</kbd> function:</p>
<pre class="calibre33">string text = "www.amin-ahmadi.com"; 
int offset = 25; 
Point origin(offset, image.rows - offset); 
HersheyFonts fontFace = FONT_HERSHEY_COMPLEX; 
double fontScale = 1.5; 
Scalar color(0, 242, 255); 
int thickness = 2; 
LineTypes lineType = LINE_AA; 
bool bottomLeftOrigin = false; 
 
putText(image, 
        text, 
        origin, 
        fontFace, 
        fontScale, 
        color, 
        thickness, 
        lineType, 
        bottomLeftOrigin); </pre>
<p class="calibre2">When executed on our example picture from the previous chapters, the following result will be created:</p>
<div class="cdpaligncenter"><img src="../images/00035.jpeg" class="calibre58"/></div>
<p class="calibre2">Obviously, increasing or decreasing <kbd class="calibre13">scale</kbd> will result in an increased or decreased text size. The <kbd class="calibre13">thickness</kbd> parameter corresponds to the thickness of the printed text and so on. The only parameter that is worth discussing more is <kbd class="calibre13">lineType</kbd>, which was <strong class="calibre4">LINE_AA</strong> in our example, but it can take any value from the <kbd class="calibre13">LineTypes</kbd> enum. Here are the most important line types along with their differences, demonstrated with a printed <kbd class="calibre13">W</kbd> character on a white background:</p>
<div class="cdpaligncenter"><img src="../images/00036.gif" class="calibre59"/></div>
<p class="calibre2"><strong class="calibre4">LINE_4</strong> stands for four-connected line types, and <strong class="calibre4">LINE_8</strong> stands for eight-connected line types. <strong class="calibre4">LINE_AA</strong> though, which is the anti-aliased line type, is slower to draw than the other two, but, as can be seen in the preceding diagram, it also provides a much better quality.</p>
<div class="packt_infobox">The <kbd class="calibre29">LineTypes</kbd> enum also includes a <kbd class="calibre29">FILLED</kbd> entry, which is used for filling the shapes drawn on an image with the given color. It's important to note that almost all drawing functions in OpenCV (not just <kbd class="calibre29">putText</kbd>) require a line type parameter.</div>
<p class="calibre2">OpenCV provides two more functions that are related to handling texts, but not exactly for drawing them. The first one is called <kbd class="calibre13">getFontScaleFromHeight</kbd>, which is used to get the required scale value based on a font type, height (in pixels), and thickness. Here's an example:</p>
<pre class="calibre33">double fontScale = getFontScaleFromHeight(fontFace, 
                           50, // pixels for height 
                           thickness); </pre>
<p class="calibre2">We could have used the preceding code instead of providing a constant value for <kbd class="calibre13">scale</kbd> in our previous example usage of the <kbd class="calibre13">putText</kbd> function. Obviously, we need to replace <kbd class="calibre13">50</kbd> with any desired pixel height value for our text.</p>
<p class="calibre2">Besides <kbd class="calibre13">getFontScaleFromHeight</kbd>, OpenCV also includes a function named <kbd class="calibre13">getTextSize</kbd> that can be used to retrieve the width and height that is required for printing a specific text on an image. Here's an example code that shows how we can find out the width and height in pixels required for printing the <kbd class="calibre13">"Example"</kbd> word with the <kbd class="calibre13">FONT_HERSHEY_PLAIN</kbd> font type, a scale of <kbd class="calibre13">3.2</kbd>, and a thickness of <kbd class="calibre13">2</kbd> on an image using the <kbd class="calibre13">getTextSize</kbd> function:</p>
<pre class="calibre33">int baseLine; 
Size size = getTextSize("Example", 
                        FONT_HERSHEY_PLAIN, 
                        3.2, 
                        2, 
                        &amp;baseLine); 
 
cout &lt;&lt; "Size = " &lt;&lt; size.width &lt;&lt; " , " &lt;&lt; size.height &lt;&lt; endl; 
cout &lt;&lt; "Baseline = " &lt;&lt; baseLine &lt;&lt; endl; </pre>
<p class="calibre2">The results should look like the following:</p>
<pre class="calibre33">Size = 216 , 30 
Baseline = 17 </pre>
<p class="calibre2">This means the text will need <kbd class="calibre13">216</kbd> by <kbd class="calibre13">30</kbd> pixels of space to be printed and the baseline will be <kbd class="calibre13">17</kbd> pixels farther from the bottom of the text.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Drawing shapes</h1>
                
            
            <article>
                
<p class="calibre2">You can use a set of very simple OpenCV functions to draw various types of shapes on images. These functions are all included in the <kbd class="calibre13">imgproc</kbd> module, just like the <kbd class="calibre13">putText</kbd> function, and they can be used to draw markers, lines, arrowed lines, rectangles, ellipses and circles, polylines, and so on in given points.</p>
<p class="calibre2">Let's start with the <kbd class="calibre13">drawMarker</kbd> function, which is used to draw a marker with a given type on an image. Here's how this function is used to print a marker at the center of a given image:</p>
<pre class="calibre33">Point position(image.cols/2, 
               image.rows/2); 
Scalar color = Scalar::all(0); 
MarkerTypes markerType = MARKER_CROSS; 
int markerSize = 25; 
int thickness = 2; 
int lineType = LINE_AA; 
drawMarker(image, 
           position, 
           color, 
           markerType, 
           markerSize, 
           thickness, 
           lineType); </pre>
<p class="calibre2"><kbd class="calibre13">position</kbd> is the central point of the marker, and the rest of the parameters are almost exactly what we saw in the <kbd class="calibre13">putText</kbd> function previously. This is the same pattern of parameters for most (if not all) of the drawing functions in OpenCV. The only parameters that are specific to the <kbd class="calibre13">drawMarker</kbd> function are <kbd class="calibre13">markerSize</kbd>, which is simply the size of the marker, and <kbd class="calibre13">markerType</kbd>, which can take one of the following values from the <kbd class="calibre13">MarkerTypes</kbd> enum:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">MARKER_CROSS</kbd></li>
<li class="calibre11"><kbd class="calibre13">MARKER_TILTED_CROSS</kbd></li>
<li class="calibre11"><kbd class="calibre13">MARKER_STAR</kbd></li>
<li class="calibre11"><kbd class="calibre13">MARKER_DIAMOND</kbd></li>
<li class="calibre11"><kbd class="calibre13">MARKER_SQUARE</kbd></li>
<li class="calibre11"><kbd class="calibre13">MARKER_TRIANGLE_UP</kbd></li>
<li class="calibre11"><kbd class="calibre13">MARKER_TRIANGLE_DOWN</kbd></li>
</ul>
<p class="calibre2">The following diagram depicts all possible marker types mentioned in the previous list when they are printed on a white background, from left to right:</p>
<div class="cdpaligncenter"><img src="../images/00037.gif" class="calibre60"/></div>
<p class="calibre2">Drawing lines in OpenCV is possible using the <kbd class="calibre13">line</kbd> function. This function requires two points and it will draw a line connecting the given points. Here's an example:</p>
<pre class="calibre33">Point pt1(25, image.rows/2); 
Point pt2(image.cols/2 - 25, image.rows/2); 
Scalar color = Scalar(0,255,0); 
int thickness = 5; 
int lineType = LINE_AA; 
int shift = 0; 
 
<span><span>line(</span></span>image, 
     pt1, 
     pt2, 
     color, 
     thickness, 
     lineType, 
     shift); </pre>
<p class="calibre2">The <kbd class="calibre13">shift</kbd> parameter corresponds to the number of fractional bits in the given points. You can omit or simply pass zero to make sure it has no effect on your results.</p>
<p class="calibre2">Similar to the <kbd class="calibre13">line</kbd> function, <kbd class="calibre13">arrowedLine</kbd> can be used to draw an arrowed line. Obviously, the order of the given points determines the direction of the arrow. The only parameter that this function needs is the <kbd class="calibre13">tipLength</kbd> parameter, which corresponds to the percentage of the line length that will be used to create the tip of the arrow. Here is an example:</p>
<pre class="calibre33">double tipLength = 0.2; 
 
arrowedLine(image, 
            pt1, 
            pt2, 
            color, 
            thickness, 
            lineType, 
            shift, 
            tipLength); </pre>
<p class="calibre2">To be able to draw a circle on an image, we can use the <kbd class="calibre13">circle</kbd> function. Here's how this function is used to draw a circle right at the center of an image:</p>
<pre class="calibre33">Point center(image.cols/2, 
             image.rows/2); 
int radius = 200; 
circle(image, 
       center, 
       radius, 
       color, 
       thickness, 
       lineType, 
       shift); </pre>
<p class="calibre2">Apart from <kbd class="calibre13">center</kbd> and <kbd class="calibre13">radius</kbd>, which are obviously the center point and radius of the circle, the rest of the parameters are the same as the functions and examples we learned about in this section.</p>
<p class="calibre2">Drawing a rectangle or square on an image is possible using the <kbd class="calibre13">rectangle</kbd> function. This function is very similar to the <kbd class="calibre13">line</kbd> function in that it requires only two points. The difference is that the points given to the <kbd class="calibre13">rectangle</kbd> function correspond to the top-left and bottom-right corner points of a rectangle or square. Here's an example:</p>
<pre class="calibre33">rectangle(image, 
          pt1, 
          pt2, 
          color, 
          thickness, 
          lineType, 
          shift); </pre>
<p class="calibre2">Instead of two separate <kbd class="calibre13">Point</kbd> objects, this function can also be provided with a single <kbd class="calibre13">Rect</kbd> object. Here's how:</p>
<pre class="calibre33">Rect rect(pt1,pt2); 
rectangle(image, 
          color, 
          thickness, 
          lineType, 
          shift); </pre>
<p class="calibre2">Similarly, an ellipse can be drawn by using the <kbd class="calibre13">ellipse</kbd> function. This function requires the size of the axes along with the angle of the ellipse to be provided. Additionally, you can use start and ending angles to draw all or part of an ellipse, or, in others, an arc instead of an ellipse. You can guess that passing <kbd class="calibre13">0</kbd> and <kbd class="calibre13">360</kbd> as the start and ending angles will result in a full ellipse being drawn. Here's an example:</p>
<pre class="calibre33">Size axes(200, 100); 
double angle = 20.0; 
double startAngle = 0.0; 
double endAngle = 360.0; 
ellipse(image, 
        center, 
        axes, 
        angle, 
        startAngle, 
        endAngle, 
        color, 
        thickness, 
        lineType, 
        shift);</pre>
<p class="calibre2">Another way of calling the <kbd class="calibre13">ellipse</kbd> function is by using a <kbd class="calibre13">RotatedRect</kbd> object. In this version of the same function, you must first create a <kbd class="calibre13">RotatedRect</kbd> with a given width and height (or, in other words, size) and an <kbd class="calibre13">angle</kbd>, and then call the <kbd class="calibre13">ellipse</kbd> function as seen here:</p>
<pre class="calibre33">Size size(150, 300); 
double angle = 45.0; 
RotatedRect rotRect(center, 
                    axes, 
                    angle); 
ellipse(image, 
        rotRect, 
        color, 
        thickness, 
        lineType); </pre>
<p class="calibre2">Note that with this method, you can't draw an arc, and this is only used for drawing full ellipses.</p>
<p class="calibre2">We're down to the last type of shapes that can be drawn using OpenCV drawing functions, and that is polyline shapes. You can draw polyline shapes by using the <kbd class="calibre13">polylines</kbd> function. You must make sure to create a vector of points that corresponds to the vertices required for drawing a polyline. Here's an example:</p>
<pre class="calibre33">vector&lt;Point&gt; pts; 
pts.push_back(Point(100, 100)); 
pts.push_back(Point(50, 150)); 
pts.push_back(Point(50, 200)); 
pts.push_back(Point(150, 200)); 
pts.push_back(Point(150, 150)); 
bool isClosed = true; 
polylines(image, 
          pts, 
          isClosed, 
          color, 
          thickness, 
          lineType, 
          shift); </pre>
<p class="calibre2">The <kbd class="calibre13">isClosed</kbd> parameter is used to determine whether the polyline must be closed, by connecting the last vertex to the first one or not.</p>
<p class="calibre2">The following image depicts the result of the <kbd class="calibre13">arrowedLine</kbd>, <kbd class="calibre13">circle</kbd>, <kbd class="calibre13">rectangle</kbd>, and <kbd class="calibre13">polylines</kbd> functions that we used in the preceding code snippets, when they are used to draw on our example image:</p>
<div class="cdpaligncenter"><img src="../images/00038.jpeg" class="calibre61"/></div>
<p class="calibre2">Before proceeding with the next section and learning about algorithms used for image filtering, we're going to learn about adjusting parameters at runtime by using trackbars added to OpenCV display windows. This is a very useful method in order to try out a wide range of different parameters at runtime when you are experimenting with different values to see their effect, and it allows the value of a variable to be changed by simply readjusting a trackbar (or slider) position.</p>
<p class="calibre2">Let's first see an example and then further break down the code and learn how trackbars are handled using OpenCV functions. The following complete example shows how we can use a trackbar to adjust the radius of a circle drawn on an image at runtime:</p>
<pre class="calibre15">string window = "Image"; // Title of the image output window<br class="title-page-name"/>string trackbar = "Radius"; // Label of the trackbar
Mat image = imread("Test.png"); 
Point center(image.cols/2, image.rows/2); // A Point object that points to the center of the image
int radius = 25;<br class="title-page-name"/>Scalar color = Scalar(0, 255, 0); // Green color in BGR (OpenCV default) color space
int thickness = 2; LineTypes lineType = LINE_AA; int shift = 0; 
<br class="title-page-name"/>// Actual callback function where drawing and displaying happens
void drawCircle(int, void*) 
{ 
    Mat temp = image.clone(); 
 
    circle(temp, 
           center, 
           radius, 
           color, 
           thickness, 
           lineType, 
           shift); 
 
    imshow(window, temp); 
} 
 
int main() 
{     
    namedWindow(window); // create a window titled "Image" (see above)
 
    createTrackbar(trackbar, // label of the trackbar
                   window, // label of the window of the trackbar
                   &amp;radius, // the value that'll be changed by the trackbar
                   min(image.rows, image.cols) / 2, // maximum accepted value
                   drawCircle); 
 
    setTrackbarMin(trackbar, window, 25); // set min accespted value by trackbar
    setTrackbarMax(trackbar, window, min(image.rows, image.cols) / 2); // set max again
 
    drawCircle(0,0); // call the callback function and wait
    waitKey(); 
 
    return 0; 
} </pre>
<p class="calibre2">In the preceding code, <kbd class="calibre13">window</kbd> and <kbd class="calibre13">trackbar</kbd> are <kbd class="calibre13">string</kbd> objects that are used to identify and access a specific trackbar on a specific window. <kbd class="calibre13">image</kbd> is a <kbd class="calibre13">Mat</kbd> object containing the source image. <kbd class="calibre13">center</kbd>, <kbd class="calibre13">radius</kbd>, <kbd class="calibre13">color</kbd>, <kbd class="calibre13">thickness</kbd>, <kbd class="calibre13">lineType</kbd>, and <kbd class="calibre13">shift</kbd> are parameters required for drawing a circle, as we learned previously in this chapter. <kbd class="calibre13">drawCircle</kbd> is the name of the function (the callback function, to be precise) that will be called back when the trackbar is used to update the <kbd class="calibre13">radius</kbd> value for the circle we want to draw. This function must have the signature that is used in this example, which has an <kbd class="calibre13">int</kbd> and a <kbd class="calibre13">void</kbd> pointer as its parameters. This function is quite simple; it just clones the original image, draws a circle on it, and then displays it.</p>
<p class="calibre2">The <kbd class="calibre13">main</kbd> function is where we actually create the window and the trackbar. First, the <kbd class="calibre13">namedWindow</kbd> function must be called to create a window with the window name that we want. The <kbd class="calibre13">createTrackbar</kbd> function can then be called, as seen in the example, to create a trackbar on that window. Note that the trackbar itself has a name that is used to access it. This name will also be printed next to the trackbar to display its purpose to the user when the application is running. <kbd class="calibre13">setTrackbarMin</kbd> and <kbd class="calibre13">setTrackbarMax</kbd> are called to make sure our trackbar doesn't allow <kbd class="calibre13">radius</kbd> values less than 25 or greater than the width or height of the image (whichever is smaller), divided by 2 (since we're talking radius, not diameter).</p>
<p class="calibre2">The following is a screenshot that demonstrates the output of our <kbd class="calibre13">window</kbd> along with <kbd class="calibre13">trackbar</kbd> on it that can be used to adjust the <kbd class="calibre13">radius</kbd> of the circle:</p>
<div class="cdpaligncenter"><img src="../images/00039.jpeg" class="calibre62"/></div>
<p class="calibre2">Try adjusting to see for yourself how the radius of the circle changes according to the position of the trackbar. Make sure to use this method when you want to experiment with the parameters of a function or algorithms that you learn in this book. Note that you can add as many trackbars as you need. However, adding more trackbars will use more space on your window, which might lead to a poor user interface and experience and, consequently, a hard-to-use program instead of a simplified one, so try to make use of trackbars wisely.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Filtering images</h1>
                
            
            <article>
                
<p class="calibre2">It really doesn't matter whether you are trying to build a computer vision application to perform highly complex tasks, such as object detection in real-time, or simply modifying an input image in one way or another. Almost inevitably, you'll have to apply a certain type of filter to your input or output images. The reason for this is quite simple—not all pictures are ready to be processed out of the box, and most of the time, applying filters to make images smoother is one of the ways to make sure they can be fed into our algorithms.</p>
<p class="calibre2">The variety of filters that you can apply to your images in computer vision is huge, but in this section, we're going to be learning about some of the most important filters and especially the ones with an implementation in the OpenCV library that we can use.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Blurring/smoothening filters</h1>
                
            
            <article>
                
<p class="calibre2">Blurring an image is one of the most important image filtering tasks, and there are many algorithms that can perform it, each one with their own pros and cons, which we'll be talking about in this section.</p>
<p class="calibre2">Let's start with the simplest filter used for smoothening images, which is called the median filter, and it can be done by using the <kbd class="calibre13">medianBlur</kbd> function, as seen in the following example:</p>
<pre class="calibre33">int ksize = 5; // must be odd 
medianBlur(image, result, ksize); </pre>
<p class="calibre2">This filter simply finds the median value of the neighboring pixels of each pixel in an image. <kbd class="calibre13">ksize</kbd>, or the kernel size parameter, decides how big the kernel used for blurring is, or, in other words, how far the neighboring pixels will be considered in the blurring algorithm. The following image depicts the result of increasing the kernel size from 1 to 7:</p>
<div class="cdpaligncenter"><img src="../images/00040.jpeg" class="calibre63"/></div>
<p class="calibre2">Note that the kernel size must be an odd value, and a kernel size of 1 will produce the exact same image as the input. So, in the previous images, you can see the increase in blurring level from the original image (the leftmost) until the kernel size of 7.</p>
<p class="calibre2">Note that you can use extremely high kernel sizes if you need, but it is rarely necessary and would usually be needed in case you need to de-noise an extremely noisy image. Here's an example image depicting the result of a kernel size of 21:</p>
<div class="cdpaligncenter"><img src="../images/00041.jpeg" class="calibre64"/></div>
<p class="calibre2">Another method of blurring an image is by using the <kbd class="calibre13">boxFilter</kbd> function. Let's see how it's done with an example code and then break it down further to better understand its behavior:</p>
<pre class="calibre33">int ddepth = -1; 
Size ksize(7,7); 
Point anchor(-1, -1); 
bool normalize = true; 
BorderTypes borderType = BORDER_DEFAULT; 
 
boxFilter(image, 
          result, 
          ddepth, 
          ksize, 
          anchor, 
          normalize, 
          borderType); </pre>
<p class="calibre2">Box filtering is referred to as a blurring method in which a matrix of ones with the given <kbd class="calibre13">ksize</kbd> and <kbd class="calibre13">anchor</kbd> point is used for blurring an image. The major difference here, when compared with the <kbd class="calibre13">medianBlur</kbd> function, is that you can actually define the <kbd class="calibre13">anchor</kbd> point to be anything other than the center point in any neighborhood. You can also define the border type used in this function, whereas in the <kbd class="calibre13">medianBlur</kbd> function, <kbd class="calibre13">BORDER_REPLICATE</kbd> is used internally and cannot be changed. For more information about border types, you might want to refer to <span class="calibre12"><a target="_blank" href="part0048.html#1DOR00-15c05657f8254d318ea883ef10fc67f4" class="calibre9">Chapter 3</a>, <em class="calibre7">Array and Matrix Operations</em></span>. Finally, the <kbd class="calibre13">normalize</kbd> parameter allows us to normalize the result to the displayable result.</p>
<div class="packt_infobox">The <kbd class="calibre29">ddepth</kbd> parameter can be used to change the depth of the result. However, you can use -1 to make sure the result has the same depth as the source. Similarly, <kbd class="calibre29">anchor</kbd> can be supplied with -1 values to make sure the default anchor point is used.</div>
<p class="calibre2">The following image depicts the result of the previous example code. The image on the right is the box-filtered result of the image on the left-hand side:</p>
<div class="cdpaligncenter"><img src="../images/00042.jpeg" class="calibre65"/></div>
<p class="calibre2">We can perform the exact same task, in other words, the normalized box filter, by using the <kbd class="calibre13">blur</kbd> function, as seen in the following example code:</p>
<pre class="calibre15">Size ksize(7,7); 
Point anchor(-1, -1); 
BorderTypes borderType = BORDER_DEFAULT; 
 
blur(image, 
     result, 
     ksize, 
     anchor, 
     borderType); </pre>
<p class="calibre2">The result of this sample code is exactly the same as calling <kbd class="calibre13">boxFilter</kbd>, as we saw previously. The obvious difference here is that this function does not allow us to change the depth of the result and applies normalization by default.</p>
<p class="calibre2">In addition to the standard box filter, you can also apply a square box filter with the <kbd class="calibre13">sqrBoxFilter</kbd> function. In this method, instead of calculating the sum of the neighboring pixels, the sum of their square values is calculated. Here is an example, which is incredibly similar to calling the <kbd class="calibre13">boxFilter</kbd> function:</p>
<pre class="calibre33">int ddepth = -1; 
Size ksize(7,7); 
Point anchor(-1, -1); 
bool normalize = true; 
BorderTypes borderType = BORDER_DEFAULT; 
 
sqrBoxFilter(image, 
             result, 
             ddepth, 
             ksize, 
             anchor, 
             normalize, 
             borderType); </pre>
<div class="packt_infobox">The unnormalized versions of the <kbd class="calibre29">boxFilter</kbd> and <kbd class="calibre29">sqrBoxFilter</kbd> functions can also be used to find statistical information about the neighboring areas of all pixels in an image, and their use case is not limited to just blurring an image.</div>
<p class="calibre2">One of the most popular blurring methods in computer vision is the <strong class="calibre4">Gaussian blur</strong> algorithm, and it can be performed in OpenCV by using the <kbd class="calibre13">GaussianBlur</kbd> function. This function, similar to the previous blur functions that we learned about, requires a kernel size, along with standard deviation values in the <em class="calibre7">X</em> and <em class="calibre7">Y</em> direction, called <kbd class="calibre13">sigmaX</kbd> and <kbd class="calibre13">sigmaY</kbd>, respectively. Here's an example of how this function is used:</p>
<pre class="calibre33">Size ksize(7,7); 
double sigmaX = 1.25; 
double sigmaY = 0.0; 
BorderTypes borderType = BORDER_DEFAULT; 
 
GaussianBlur(image, 
             result, 
             ksize, 
             sigmaX, 
             sigmaY, 
             borderType); </pre>
<p class="calibre2">Note that a value of zero for <kbd class="calibre13">sigmaY</kbd> means the value of <kbd class="calibre13">sigmaX</kbd> will also be used in the <em class="calibre7">Y</em> direction. For more information about Gaussian blur, you can read about the Gaussian function in general and the <kbd class="calibre13">GaussianBlur</kbd> function in the OpenCV documentation pages.</p>
<p class="calibre2">The last smoothening filter that we'll learn about in this section is called the <strong class="calibre4">bilateral filter</strong>, and it can be achieved by using the <kbd class="calibre13">bilateralFilter</kbd> function. Bilateral filtering is a powerful method of de-noising and smoothening an image, while preserving edges. This function is also much slower and more CPU-intensive in comparison with the blur algorithms that we saw previously. Let's see how <kbd class="calibre13">bilateralFilter</kbd> is used with an example and then break down the required parameters:</p>
<pre class="calibre33">int d = 9; 
double sigmaColor = 250.0; 
double sigmaSpace = 200.0; 
BorderTypes borderType = BORDER_DEFAULT; 
 
bilateralFilter(image, 
                result, 
                d, 
                sigmaColor, 
                sigmaSpace, 
                borderType); </pre>
<p class="calibre2"><kbd class="calibre13">d</kbd>, or the filter size, is the diameter of the pixel neighborhood that will participate in the filter. The <kbd class="calibre13">sigmaColor</kbd> and <kbd class="calibre13">sigmaSpace</kbd> values are both used to define the effect of the color and coordinate the pixels nearer or farther from the pixel whose filtered value is being calculated. Here's a screenshot that demonstrates the effect of the <kbd class="calibre13">bilateralFilter</kbd> function when executed on our example image:</p>
<div class="cdpaligncenter"><img src="../images/00043.jpeg" class="calibre66"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Morphological filters</h1>
                
            
            <article>
                
<p class="calibre2">Similar to smoothening filters, morphology filters are the algorithms that change the value of each pixel based on the value of the neighboring pixels, although the obvious difference is that they do not have a blurring effect and are mostly used to produce some form of erosion or dilation effect on images. This will be clarified with a few hands-on examples further in this section, but for now, let's see how morphological operations (also called <strong class="calibre4">transformations</strong>) are performed using OpenCV functions.</p>
<p class="calibre2">You can use the <kbd class="calibre13">morphologyEx</kbd> function to perform morphological operations on images. This function can be provided with an entry from the <kbd class="calibre13">MorphTypes</kbd> enum to specify the morphological operation. Here are the values that can be used:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">MORPH_ERODE</kbd>: For erosion operation</li>
<li class="calibre11"><kbd class="calibre13">MORPH_DILATE</kbd>: For dilation operation</li>
<li class="calibre11"><kbd class="calibre13">MORPH_OPEN</kbd>: For opening operation, or the dilation of eroded images</li>
<li class="calibre11"><kbd class="calibre13">MORPH_CLOSE</kbd>: For closing operation, or the erosion of dilated images</li>
<li class="calibre11"><kbd class="calibre13">MORPH_GRADIENT</kbd>: For morphological gradient operation, or subtraction of the eroded image from the dilated image</li>
<li class="calibre11"><kbd class="calibre13">MORPH_TOPHAT</kbd>: For Top-hat operation, or subtraction of the opening operation result from the source image</li>
<li class="calibre11"><kbd class="calibre13">MORPH_BLACKHAT</kbd>: For Black-hat operation, or subtraction of the source image from the result of the closing operation</li>
</ul>
<p class="calibre2">To understand all of the possible morphological operations mentioned in the previous list, it's important to first understand the effect of erosion and dilation (the first two entries in the list) since the rest are simply different combinations of these two morphological operations. Let's first try erosion with an example and, at the same time, learn how the <kbd class="calibre13">morphologyEx</kbd> function is used:</p>
<pre class="calibre15">MorphTypes op = MORPH_ERODE; 
<a class="calibre67">MorphShapes </a>shape = MORPH_RECT; 
Size ksize(3,3); 
Point anchor(-1, -1); 
Mat kernel = getStructuringElement(shape, 
                                   ksize, 
                                   anchor); 
int iterations = 3; 
BorderTypes borderType = BORDER_CONSTANT; 
Scalar borderValue = morphologyDefaultBorderValue(); 
morphologyEx(image, 
             result, 
             op, 
             kernel, 
             anchor, 
             iterations, 
             borderType, 
             borderValue); </pre>
<p class="calibre2"><kbd class="calibre13">op</kbd>, or the operation, is an entry from the <kbd class="calibre13">MorphTypes</kbd> enum, as mentioned before. <kbd class="calibre13">kernel</kbd>, or the structuring element, is the kernel matrix used for the morphological operation, which itself is either created manually or by using the <kbd class="calibre13">getStructuringElement</kbd> function. You must provide the <kbd class="calibre13">getStructuringElement</kbd> with a <kbd class="calibre13">shape</kbd> morph, kernel size (<kbd class="calibre13">ksize</kbd>), and <kbd class="calibre13">anchor</kbd>. <kbd class="calibre13">shape</kbd> can be a rectangle, cross, or ellipse, and is simply an entry from the <kbd class="calibre13">MorphShapes</kbd> enum. The <kbd class="calibre13">iterations</kbd> variable refers to the number of times the morphological operation is performed on an image. <kbd class="calibre13">borderType</kbd> is interpreted exactly the same way as with all the functions we've seen so far for the extrapolation of pixels. In case a constant border type value is used, the <kbd class="calibre13">morphologyEx</kbd> function must also be provided with a border value, which can be retrieved by using the <kbd class="calibre13">morphologyDefaultBorderValue</kbd> function, or specified manually.</p>
<p class="calibre2">Here is the result of our preceding code (for erosion), when executed on our sample image:</p>
<div class="cdpaligncenter"><img src="../images/00044.jpeg" class="calibre68"/></div>
<p class="calibre2">Dilation, on the other hand, is performed by simply replacing the <kbd class="calibre13">op</kbd> value with <kbd class="calibre13">MORPH_DILATE</kbd> in the previous example. Here's the result of the dilation operation:</p>
<div class="cdpaligncenter"><img src="../images/00045.jpeg" class="calibre68"/></div>
<p class="calibre2">A highly simplified description of what erosion and dilation operations do is that they cause the neighboring pixels of darker pixels to become darker (in case of erosion) or the neighboring pixels of brighter pixels to become brighter (in case of dilations), which, after more iterations, will cause a stronger and easily visible effect.</p>
<p class="calibre2">As was mentioned before, all of the other morphological operations are simply a combination of erosion and dilation. Here are the results of opening and closing operations when they are executed on our example images:</p>
<div class="cdpaligncenter"><img src="../images/00046.jpeg" class="calibre69"/></div>
<p class="calibre2">Make sure you try the rest of the morphological operations by yourself to see their effects. Create user interfaces that have trackbars on them and try changing the value of <kbd class="calibre13">iteration</kbd> and other parameters to see how they affect the result of morphological operations. If used carefully and wisely, morphological operations can have very interesting results and further simplify an operation that you want to perform on an image.</p>
<p class="calibre2">Before proceeding to the next section, it is worth noting that you can also use the <kbd class="calibre13">erode</kbd> and <kbd class="calibre13">dilate</kbd> functions to perform exactly the same operation. Although these functions do not require an operation parameter (since the operation is in their name already), the rest of the parameters are exactly the same as with the <kbd class="calibre13">morphologyEx</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Derivative-based filters</h1>
                
            
            <article>
                
<p class="calibre2">In this section, we're going to learn about filtering algorithms that are based on calculating and using the derivatives of an image. To understand the concept of derivatives in an image, you can recall the fact that images are matrices, so you can calculate the derivatives (of any order) in <em class="calibre7">X</em> or <em class="calibre7">Y</em> directions, for instance, which, in the simplest case, would be the same as finding the change across the pixels in a direction.</p>
<p class="calibre2">Let's start with the <kbd class="calibre13">Sobel</kbd> function, which is used to calculate the derivative of an image using a <kbd class="calibre13">Sobel</kbd> operator. Here's how this function is used in practice:</p>
<pre class="calibre15">int ddepth = -1; 
int dx = 1; 
int dy = 1; 
int ksize = 5; 
double scale = 0.3; 
double delta = 0.0; 
 
BorderTypes borderType = BORDER_DEFAULT; 
Sobel(image, 
      result, 
      ddepth, 
      dx, 
      dy, 
      ksize, 
      scale, 
      delta, 
      borderType); </pre>
<p class="calibre2"><kbd class="calibre13">ddepth</kbd>, similar to what we saw in previous examples throughout this chapter, is used to define the depth of the output, and using <kbd class="calibre13">-1</kbd> makes sure the result has the same depth as the input. <kbd class="calibre13">dx</kbd> and <kbd class="calibre13">dy</kbd> are used to set the order of the derivative in both the <em class="calibre7">X</em> and <em class="calibre7">Y</em> directions. <kbd class="calibre13">ksize</kbd> is the size of the <kbd class="calibre13">Sobel</kbd> operator, which can be 1, 3, 5, or 7. <kbd class="calibre13">scale</kbd> is used as the <kbd class="calibre13">scale</kbd> factor for the result, and delta is added to the <kbd class="calibre13">result</kbd>.</p>
<p class="calibre2">The following images depict the result of the <kbd class="calibre13">Sobel</kbd> function when called with the parameter values from the preceding example code, but for a <kbd class="calibre13">delta</kbd> value of zero (on the left) and 255 (on the right):</p>
<div class="cdpaligncenter"><img src="../images/00047.jpeg" class="calibre20"/></div>
<p class="calibre2">Try setting different <kbd class="calibre13">delta</kbd> and <kbd class="calibre13">scale</kbd> values and experiment with the results. Also try different derivative orders and see the effects for yourself. As you can see from the preceding output images, calculating the derivative of an image is a method for calculating the edges in an image.</p>
<p class="calibre2">You can also use the <kbd class="calibre13">spatialGradient</kbd> function to calculate the first-order derivative of an image in both the <em class="calibre7">X</em> and <em class="calibre7">Y</em> directions using the <kbd class="calibre13">Sobel</kbd> operator, at the same time. In other words, calling <kbd class="calibre13">spatialGradient</kbd> once is like calling the <kbd class="calibre13">Sobel</kbd> function twice, for the first-order derivative in both directions. Here's an example:</p>
<pre class="calibre33">Mat resultDX, resultDY; 
int ksize = 3; 
BorderTypes borderType = BORDER_DEFAULT; 
spatialGradient(image, 
                resultDX, 
                resultDY, 
                ksize, 
                borderType); </pre>
<p class="calibre2">Note that the <kbd class="calibre13">ksize</kbd> parameter must be <kbd class="calibre13">3</kbd> and the input image type must be grayscale, otherwise this function will fail to execute, although this might change in an upcoming OpenCV version.</p>
<p class="calibre2">Similar to the way we used the <kbd class="calibre13">Sobel</kbd> function, you can use the <kbd class="calibre13">Laplacian</kbd> function to calculate the Laplacian of an image. It's important to note that this function essentially sums up the second derivatives in the <em class="calibre7">X</em> and <em class="calibre7">Y</em> directions calculated using the <kbd class="calibre13">Sobel</kbd> operator. Here's an example that demonstrates the usage of the <kbd class="calibre13">Laplacian</kbd> function:</p>
<pre class="calibre33">int ddepth = -1; 
int ksize = 3; 
double scale = 1.0; 
double delta = 0.0; 
BorderTypes borderType = BORDER_DEFAULT; 
Laplacian(image, 
          result, 
          ddepth, 
          ksize, 
          scale, 
          delta, 
          borderType); </pre>
<p class="calibre2">All of the parameters used in the <kbd class="calibre13">Laplacian</kbd> function are already described in previous examples, and especially the <kbd class="calibre13">Sobel</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Arbitrary filtering</h1>
                
            
            <article>
                
<p class="calibre2">OpenCV supports the application of arbitrary filters on images by using the <kbd class="calibre13">filter2D</kbd> function. This function is capable of creating the result of many algorithms we already learned, but it requires a <kbd class="calibre13">kernel</kbd> matrix to be provided. This function simply convolves the whole image with the given <kbd class="calibre13">kernel</kbd> matrix. Here's an example of applying an arbitrary filter on an image:</p>
<pre class="calibre15">int ddepth = -1; 
Mat kernel{+1, -1, +1, 
           -1, +2, -1, 
           +1, -1, +1}; 
Point anchor(-1, -1); 
double delta = 0.0; 
BorderTypes borderType = BORDER_DEFAULT; 
filter2D(image, 
         result, 
         ddepth, 
         kernel, 
         anchor, 
         delta, 
         borderType); </pre>
<p class="calibre2">Here is the result of this arbitrary filter. You can see the original image on the left, and the result of the filtering operation on the right-hand side:</p>
<div class="cdpaligncenter"><img src="../images/00048.jpeg" class="calibre70"/></div>
<p class="calibre2">There is absolutely no limit to the number of possible filters you can create and use using the <kbd class="calibre13">filter2D</kbd> function. Make sure you try different kernel matrices and experiment with the <kbd class="calibre13">filter2D</kbd> function. You can also search online for popular filter kernel matrices and apply them using the <kbd class="calibre13">filter2D</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Transforming images</h1>
                
            
            <article>
                
<p class="calibre2">In this section, we'll learn about computer vision algorithms that are used to transform images in one way or another. The algorithms that we'll be learning in this section cover algorithms that change the content of an image, or the way its contents is interpreted.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Thresholding algorithms</h1>
                
            
            <article>
                
<p class="calibre2">Thresholding algorithms are used to apply a threshold value to the pixels of an image. These algorithms can be used to effectively create masks from images that have possible regions or pixels of interest in them that pass a certain threshold value.</p>
<p class="calibre2">You can use the <kbd class="calibre13">threshold</kbd> function to apply a threshold value on all pixels of an image. The <kbd class="calibre13">threshold</kbd> function must be provided with the type of threshold that is desired, and it can be an entry from the <kbd class="calibre13">ThresholdTypes</kbd> enum. The following is an example that can be used to find the brightest areas in an image using the <kbd class="calibre13">threshold</kbd> function:</p>
<pre class="calibre15">double thresh = 175.0; 
double maxval = 255.0; 
ThresholdTypes type = THRESH_BINARY; 
threshold(image, 
          result, 
          thresh, 
          maxval, 
          type); </pre>
<p class="calibre2"><kbd class="calibre13">thresh</kbd> is the minimum threshold value, and <kbd class="calibre13">maxval</kbd> is the maximum allowed value. Simply put, all pixel values between <kbd class="calibre13">thresh</kbd> and <kbd class="calibre13">maxval</kbd> are allowed to pass and so the <kbd class="calibre13">result</kbd> is created. The following is the result of the preceding <kbd class="calibre13">threshold</kbd> operation demonstrated with an example image:</p>
<div class="cdpaligncenter"><img src="../images/00049.jpeg" class="calibre71"/></div>
<p class="calibre2">Increase the <kbd class="calibre13">thresh</kbd> parameter (or the threshold value) and you'll notice that fewer pixels are allowed to pass. Setting a correct threshold value requires experience and knowledge about the scene. In some cases, however, you can develop programs that set the threshold automatically for you, or adaptively. Note that the threshold type completely affects the result of the <kbd class="calibre13">threshold</kbd> function. For instance, <kbd class="calibre13">THRESH_BINARY_INV</kbd> will produce the inverted result of <kbd class="calibre13">THRESH_BINARY</kbd> and so on. Make sure to try different threshold types and experiment for yourself with this interesting and powerful function.</p>
<p class="calibre2">Another, more sophisticated, way of applying thresholds to images is by using the <kbd class="calibre13">adaptiveThreshold</kbd> function, which works with grayscale images. This function assigns the given <kbd class="calibre13">maxValue</kbd> parameter to the pixels that pass the threshold criteria. Besides that, you must provide a threshold type, an adaptive <kbd class="calibre13">threshold</kbd> method, a block size defining the diameter in the pixel neighborhood, and a constant value that is subtracted from the mean (depending on the adaptive <kbd class="calibre13">threshold</kbd> method). Here is an example:</p>
<pre class="calibre15">double maxValue = 255.0; 
AdaptiveThresholdTypes adaptiveMethod =  
                             ADAPTIVE_THRESH_GAUSSIAN_C; 
ThresholdTypes thresholdType = THRESH_BINARY; 
int blockSize = 5; 
double c = 0.0; 
adaptiveThreshold(image, 
                  result, 
                  maxValue, 
                  adaptiveMethod, 
                  thresholdType, 
                  blockSize, 
                  c); </pre>
<p class="calibre2">Note that <kbd class="calibre13">adaptiveMethod</kbd> can take any of the following examples:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">ADAPTIVE_THRESH_MEAN_C</kbd></li>
<li class="calibre11"><kbd class="calibre13">ADAPTIVE_THRESH_GAUSSIAN_C</kbd></li>
</ul>
<p class="calibre2">The higher the <kbd class="calibre13">blockSize</kbd> parameter value, the more pixels are used in the adaptive <kbd class="calibre13">threshold</kbd> method. The following is an example image that depicts the result of the <kbd class="calibre13">adaptiveThreshold</kbd> method called with the values in the preceding example code:</p>
<div class="cdpaligncenter"><img src="../images/00050.jpeg" class="calibre20"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Color space and type conversion</h1>
                
            
            <article>
                
<p class="calibre2">Converting various color spaces and types to each other is extremely important, especially when it comes to dealing with images from different device types or intending to display them on different devices and formats. Let's see what this means with a very simple example. You'll need grayscale images for various OpenCV functions and computer vision algorithms, while some will require RGB color images. In such cases, you can use the <kbd class="calibre13">cvtColor</kbd> function to convert between various color spaces and formats.</p>
<p class="calibre2">The following is an example that converts a color image to grayscale:</p>
<pre class="calibre15">ColorConversionCodes code = COLOR_RGB2GRAY; 
cvtColor(image, 
         result, 
         code); </pre>
<p class="calibre2"><kbd class="calibre13">code</kbd> can take a conversion code, which must be an entry from the <kbd class="calibre13">ColorConversionCodes</kbd> enum. The following are some examples of the most popular color-conversion codes, that can be used with the <kbd class="calibre13">cvtColor</kbd> function:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">COLOR_BGR2RGB</kbd></li>
<li class="calibre11"><kbd class="calibre13">COLOR_RGB2GRAY</kbd></li>
<li class="calibre11"><kbd class="calibre13">COLOR_BGR2HSV</kbd></li>
</ul>
<p class="calibre2">The list goes on and on. Make sure to check the <kbd class="calibre13">ColorConversionCodes</kbd> enum for all possible color-conversion codes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Geometric transformation</h1>
                
            
            <article>
                
<p class="calibre2">This section is dedicated to geometric transformation algorithms and OpenCV functions. It's important to note that the name, Geometric transformation, is based on the fact that the algorithms falling in this category do not change the content of an image, they simply deform the existing pixels, while using an extrapolation and interpolation method to calculate the pixels that fall outside the area of the existing pixels, or over each other, respectively.</p>
<p class="calibre2">Let's start with the simplest geometric transformation algorithm, which is used for resizing an image. You can use the <kbd class="calibre13">resize</kbd> function to resize an image. Here is how this function is used:</p>
<pre class="calibre15">Size dsize(0, 0); 
double fx = 1.8; 
double fy = 0.3; 
InterpolationFlags interpolation = INTER_CUBIC; 
resize(image, 
       result, 
       dsize, 
       fx, 
       fy, 
       interpolation); </pre>
<p class="calibre2">If the <kbd class="calibre13">dsize</kbd> parameter is set to a non-zero size, the <kbd class="calibre13">fx</kbd> and <kbd class="calibre13">fy</kbd> parameters are used to scale the input image. Otherwise, if <kbd class="calibre13">fx</kbd> and <kbd class="calibre13">fy</kbd> are both zero, the input image is resized to the given <kbd class="calibre13">dsize</kbd>. The <kbd class="calibre13">interpolation</kbd> parameter, on the other hand, is used to set the <kbd class="calibre13">interpolation</kbd> method used for the resize algorithm, and it must be one of the entries in the <kbd class="calibre13">InterpolationFlags</kbd> enum. Here are some of the possible values for the <kbd class="calibre13">interpolation</kbd> parameter:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">INTER_NEAREST</kbd></li>
<li class="calibre11"><kbd class="calibre13">INTER_LINEAR</kbd></li>
<li class="calibre11"><kbd class="calibre13">INTER_CUBIC</kbd></li>
<li class="calibre11"><kbd class="calibre13">INTER_AREA</kbd></li>
<li class="calibre11"><kbd class="calibre13">INTER_LANCZOS4</kbd></li>
</ul>
<p class="calibre2">Make sure to check out the OpenCV documentation pages for <kbd class="calibre13">InterpolationFlags</kbd> to find out about the details of each possible method.</p>
<p class="calibre2">The following image depicts the result of the previous example code that was used for resizing an image:</p>
<div class="cdpaligncenter"><img src="../images/00051.jpeg" class="calibre20"/></div>
<p class="calibre2">Probably the most important geometric transformation algorithm, which is able to perform most of the other geometric transformations, is the remapping algorithm, and it can be achieved by calling the <kbd class="calibre13">remap</kbd> function.</p>
<p class="calibre2">The <kbd class="calibre13">remap</kbd> function must be provided with two mapping matrices, one for <em class="calibre7">X</em> and another one for the <em class="calibre7">Y</em> direction. Besides that, an interpolation and extrapolation (border type) method, along with a border value in case of constant border type, must be provided to the <kbd class="calibre13">remap</kbd> function. Let's first see how this function is called and then try a couple of different remaps. Here's an example that shows how the <kbd class="calibre13">remap</kbd> function is called:</p>
<pre class="calibre15">Mat mapX(image.size(), CV_32FC1); 
Mat mapY(image.size(), CV_32FC1); 
// Create maps here... 
InterpolationFlags interpolation = INTER_CUBIC; 
BorderTypes borderMode = BORDER_CONSTANT; 
Scalar borderValue = Scalar(0, 0, 0); 
remap(image, 
      result, 
      mapX, 
      mapY, 
      interpolation, 
      borderMode, 
      borderValue); </pre>
<p class="calibre2">You can create an infinite number of different mappings and use them with the <kbd class="calibre13">remap</kbd> function to resize, flip, warp, and do many other transformations on images. For instance, the following code can be used to create a remapping that will cause a vertical flip of the resulting image:</p>
<pre class="calibre15">for(int i=0; i&lt;image.rows; i++) 
    for(int j=0; j&lt;image.cols; j++) 
    { 
        mapX.at&lt;float&gt;(i,j) = j; 
        mapY.at&lt;float&gt;(i,j) = image.rows-i; 
    } </pre>
<p class="calibre2">Replace the code in the preceding <kbd class="calibre13">for</kbd> loop with the following and the result of the <kbd class="calibre13">remap</kbd> function call will be a horizontally flipped image:</p>
<pre class="calibre15">mapX.at&lt;float&gt;(i,j) = image.cols - j; 
mapY.at&lt;float&gt;(i,j) = i; </pre>
<p class="calibre2">Besides simple flipping, you can use the <kbd class="calibre13">remap</kbd> function to perform many interesting pixel deformations. Here's an example:</p>
<pre class="calibre15">Point2f center(image.cols/2,image.rows/2); 
for(int i=0; i&lt;image.rows; i++) 
    for(int j=0; j&lt;image.cols; j++) 
    { 
        // find i,j in the standard coordinates 
        double x = j - center.x; 
        double y = i - center.y; 
 
        // Perform any mapping for X and Y 
        x = x*x/750; 
        y = y; 
 
        // convert back to image coordinates 
        mapX.at&lt;float&gt;(i,j) = x + center.x; 
        mapY.at&lt;float&gt;(i,j) = y + center.y; 
    } </pre>
<p class="calibre2">As can be seen from the inline comments of the preceding example code, it is common to convert the OpenCV <kbd class="calibre13">i</kbd> and <kbd class="calibre13">j</kbd> values (row and column number) to a standard coordinate system and use <em class="calibre7">X</em> and <em class="calibre7">Y</em> with known mathematical and geometrical functions, and then convert them back to the OpenCV image coordinates. The following image demonstrates the result of the preceding example code:</p>
<div class="cdpaligncenter"><img src="../images/00052.jpeg" class="calibre72"/></div>
<p class="calibre2">The <kbd class="calibre13">remap</kbd> function is incredibly powerful and efficient as long as the calculation of <kbd class="calibre13">mapX</kbd> and <kbd class="calibre13">mapY</kbd> are handled efficiently. Make sure to experiment with this function to learn about more remapping possibilities.</p>
<p class="calibre2">There are a huge number of geometric transformation algorithms in computer vision and in the OpenCV library, and covering all of them would need a book of its own. So, we'll leave the rest of the geometric transformation algorithms for you to explore and try on your own. Refer to the <em class="calibre7">Geometric Image Transformations</em> section in the OpenCV <kbd class="calibre13">imgproc</kbd> (Image Processing) module documentation for more geometric transformation algorithms and functions. In particular, make sure to learn about functions including <kbd class="calibre13">getPerspectiveTransform</kbd> and <kbd class="calibre13">getAffineTransform</kbd>, which are used to find the perspective and affine transformation between two sets of points. Such functions return transformation matrices that can be used to apply perspective and affine transformation to images by using the <kbd class="calibre13">warpPerspective</kbd> and <kbd class="calibre13">warpAffine</kbd> functions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Applying colormaps</h1>
                
            
            <article>
                
<p class="calibre2">We'll end this chapter by learning about applying colormaps to images. This is a fairly simple but powerful method that can be used to modify the colors of an image or its tone in general. This algorithm simply replaces the colors of an input image using a colormap and creates a result. A <strong class="calibre4">colormap</strong> is a 256-element array of color values, in which each element represents the color that must be used for the corresponding pixel values in the source image. We will break this down further with a couple of examples, but before that, let's see how colormaps are applied to images.</p>
<p class="calibre2">OpenCV contains a function named <kbd class="calibre13">applyColorMap</kbd> that can be used to either apply predefined colormaps or custom ones created by the user. In case predefined colormaps are used, <kbd class="calibre13">applyColorMap</kbd> must be provided with a colormap type, which must be an entry from the <kbd class="calibre13">ColormapTypes</kbd> enum. Here's an example:</p>
<pre class="calibre15">ColormapTypes colormap = COLORMAP_JET; 
applyColorMap(image, 
              result, 
              colormap); </pre>
<p class="calibre2">The following image depicts the result of various predefined colormaps that can be applied using the <kbd class="calibre13">applyColorMap</kbd> function:</p>
<div class="cdpaligncenter"><img src="../images/00053.jpeg" class="calibre20"/></div>
<p class="calibre2">As mentioned earlier, you can also create your own custom colormaps. You just need to make sure you follow the instructions for creating a colormap. Your colormap must have a size of <kbd class="calibre13">256</kbd> elements (a <kbd class="calibre13">Mat</kbd> object with <kbd class="calibre13">256</kbd> rows and <kbd class="calibre13">1</kbd> column) and it must contain color or grayscale values, depending on the type of image you are planning to apply the colormap to. The following is an example that shows how to create a custom colormap by simply inverting the green channel color:</p>
<pre class="calibre15">Mat userColor(256, 1, CV_8UC3); 
for(int i=0; i&lt;=255; i++) 
    userColor.at&lt;Vec3b&gt;(i,0) = Vec3b(i, 255-i, i); 
applyColorMap(image, 
              result, 
              userColor); </pre>
<p class="calibre2">Here is the result of the preceding example code:</p>
<div class="cdpaligncenter"><img src="../images/00054.jpeg" class="calibre73"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">Even though we tried to cover the most important topics of image-processing algorithms in computer vision, we still have a long way to go and many more algorithms to learn. The reason is quite simple, and that is the variety of applications that these algorithms can be used for. We learned a great deal of widely used computer vision algorithms in this chapter, but it should also be noted that whatever we learned in this chapter is also meant to ease your way when you start exploring the rest of the image-processing algorithms by yourself.</p>
<p class="calibre2">We started this chapter by learning about drawing functions that can be used to draw shapes and text on images. Then we moved on to learn about one of the most important computer vision topics: image filtering. We learned how to use smoothening algorithms, we experimented with morphological filters, and learned about erosion, dilation, opening, and closing. We also got to try some simple edge detection algorithms, or, in other words, derivative-based filters. We learned about thresholding images and changing their color spaces and types. The final sections of this chapter introduced us to geometric transformations and applying colormaps on images. We even created a custom colormap of our own. You can easily find the trace of the algorithms that we learned in this chapter, in many professional photo-editing or social-networking and photo-sharing applications.</p>
<p class="calibre2">In the next chapter, we'll learn all about histograms, how they are calculated, and how they are used in computer vision. We'll cover the algorithms that are crucial when working on certain object detection and tracking algorithms that we'll be exploring in the upcoming chapters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Questions</h1>
                
            
            <article>
                
<ol class="calibre14">
<li value="1" class="calibre11">Write a program that draws a cross mark over the whole image, with a thickness of 3 pixels and in the color red.</li>
<li value="2" class="calibre11">Create a window with a trackbar to change the <kbd class="calibre13">ksize</kbd> of a <kbd class="calibre13">medianBlur</kbd> function. The possible range for the <kbd class="calibre13">kszise</kbd> value should be between 3 and 99.</li>
<li value="3" class="calibre11">Perform a gradient morphological operation on an image, considering a kernel size of 7 and a rectangular  morphological shape for the structuring element.</li>
<li value="4" class="calibre11">Using <kbd class="calibre13">cvtColor</kbd>, convert a color image to grayscale and make sure only the darkest 100 shades of gray are filtered out using the <kbd class="calibre13">threshold</kbd> function. Make sure that filtered pixels are set to white in the result image and the rest of the pixels are set to black.</li>
<li value="5" class="calibre11">Use the <kbd class="calibre13">remap</kbd> function to resize an image to half of its original width and height, thus preserving the aspect ratio of the original image. Use a default border type for the extrapolation.</li>
<li value="6" class="calibre11">a) Use colormaps to convert an image to grayscale. b) Convert an image to grayscale and invert its pixels at the same time.</li>
<li value="7" class="calibre11">Did you read about perspective transformation functions? Which OpenCV function covers all similar transformations in one single function?</li>
</ol>


            </article>

            
        </section>
    </body></html>