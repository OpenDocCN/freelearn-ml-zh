- en: Data Science Process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the past decade, organizations have seen a rapid growth in data. Harnessing
    insight from that data is crucial to the growth and sustenance of these organizations.
    Yet, groups chartered with extracting value from data fail for various reasons.
    In this chapter, we will cover how organizations can avoid the potential pitfalls
    of data science.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a larger discussion about the quality and governance of data, which
    we will not be covering here. Experienced data scientists recognize the challenges
    with data and account for them in their processes. In general, some of these challenges
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Poor data quality and consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silos of data driven by individual business teams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technologies that are hard ...
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TDSP stages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Team Data Science Process** (**TDSP**) is a methodology created by Microsoft
    to guide the full life cycle of data science projects in organizations. It is
    not meant to be a complete solution, but simply a framework by which teams can
    add structure to their processes and achieve the full business value of their
    analytics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides TDSP, the other prevalent methodology that organizations have been
    adopting is called **CRISP-DM** (short for **Cross-Industry Standard Process for
    Data Mining**). This methodology has been around since the mid-1990s. There were
    several attempts to update it in the 2000s, but they were abandoned. The primary
    focus of CRISP-DM was data mining, but its principles can be extended to data
    science as well. The major steps listed in CRISP-DM are as follows: business understanding,
    data understanding, data preparation, modeling, evaluation, and deployment. For
    practitioners, these steps may seem redundant, but for organizations that are
    new to deriving value from data, this is a great framework to build a process
    around. In fact, a lot of the data science tools released on the market by various
    vendors inherently have functionality that drives users through these steps.'
  prefs: []
  type: TYPE_NORMAL
- en: There are several gaps in the CRISP-DM methodology when applied to data science.
    The most glaring one is the need to connect business outcomes with every step
    of the process. Challenges in data quality, data sources, biases, algorithm quality,
    and scalability need to be addressed beyond what is listed here.
  prefs: []
  type: TYPE_NORMAL
- en: TDSP is not an alternative to CRISP-DM, but can be viewed as an additional framework
    that can be augmented to include existing workflows around data. TDSP is more
    task-focused, but shares some of the same concepts at a high level with CRISP-DM.
  prefs: []
  type: TYPE_NORMAL
- en: One of the core tenets of TDSP is that the outcome of the data science life
    cycle as shown in the following diagram is intelligent applications that deliver
    value to the business. New data science projects can leverage portions of TDSP
    with the expectation that they will graduate as they become more mature and leverage
    the other steps of the process. In that sense, TDSP is meant to be iterative and
    agile. Depending on the nature and maturity of the project, some processes can
    be eliminated.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cfc4ea6a-af97-4bc1-be15-49e0882fd254.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are five broad stages defined in TDSP, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Business understanding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data acquisition and understanding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer acceptance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this stage of TDSP, there are two tasks that drive its goals:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining objectives
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying data sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's break down and analyze each of these tasks and look at how they help derive
    business understanding.
  prefs: []
  type: TYPE_NORMAL
- en: 'The defining objectives task includes the following factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model targets**: The success of the project is driven by the business goal,
    which is, in turn, driven by some variable(s) tracked during the analysis. These
    variables are called **model targets**, and there may be multiple metrics associated
    with the model targets that predicate their success. An example of frequently
    used model targets are revenue forecasts, or the probability of a transaction
    being fraudulent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Relevant questions**: You can define ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deliverable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The deliverable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Charter document**: This document is used to keep track of the various aspects
    of the project. These include business background, scope, personnel, plan, architecture,
    metrics, and communication. A template for this document is provided here: [https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data sources**: This document describes all the data sources and any required
    transformations to incorporate them into the project. Any processed data or engineered
    features are also kept track of. A template of this deliverable is shown here: [https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Data_Report/Data%20Defintion.md](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Data_Report/Data%20Defintion.md).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data dictionaries**: This document provides detailed descriptions for each
    of the data sources. This may include table schemas and data types with examples.
    A template for this deliverable is provided here: [https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Data_Dictionaries](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Data_Dictionaries).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data acquisition and understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this stage of TDSP, there are three tasks that drive its goals:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ingest data**: To make the exploration and modeling of the data easier, it
    is ideal to have the source data moved into a single analytics system as much
    as possible. Within Azure, the ability to move data across the different services
    is made easy through various tools, keeping these kinds of use cases in mind.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explore data**: Understanding the nature of the data is key to successful
    analytics projects. In most organizations, data comes with a lot of flaws: outliers,
    missing values, bad values, and so on. Visualizing the data and analyzing the
    characteristics of the data is a prerequisite for successful data science projects.
    This is also ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deliverable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The deliverable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data quality report**: The IDEAR tool can help create reports that summarize
    the source data and target variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Solution architecture**: At this stage of the project, a diagram or description
    of the data flow can be drawn to show the scoring and retraining (if needed) of
    pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Checkpoint decision**: Based on the initial evaluation of the data, you can
    make a decision regarding whether to pursue the project beyond this phase. If
    the expected business value is not clear at this stage, a decision can be made
    on getting additional data or discontinuing the project. In some cases, the stakeholders
    might consider reframing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this stage, there are three main tasks that deliver its goals:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature engineering**: In many use cases, the raw data by itself may not
    be a good indicator of the target variable. Depending on the algorithms being
    used, it may be necessary to transform some data features into new features that
    allow its effective use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This task is considered part of the art of effective data science projects.
    It requires an effective combination of the insights obtained from the data exploration
    task and domain expertise. There is also the predicament of picking the correct
    number of features to build the model. Using too many variables may add unnecessary
    noise to the model, while choosing too few may not accurately predict the target
    variable(s). ...
  prefs: []
  type: TYPE_NORMAL
- en: Deliverable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The deliverable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature sets**: The features chosen to build the model are recorded as part
    of the Data Definition report. If any of the features are generated from the raw
    data, the code to generate the features is recorded in this report.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model report**: A standard report will show how each model performed against
    the various metrics. These metrics may include accuracy metrics, as well as the
    speed and efficiency of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Checkpoint**: Evaluate the performance of the model and determine whether
    it is good enough to deploy to production systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main tasks involved in this stage are to deploy the model and the data pipeline
    into a production-like environment for consumption by an application.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have a model or collection of models that deliver the required business
    metrics, you can operationalize them for different applications. Models are typically
    exposed by some API interface that allows the application to interact with them
    and generate predictions for various inputs. These APIs can typically handle batch
    or real-time, or a hybrid of these two, for its input data. The web service itself
    will be typically resilient, robust, and scalable. This is achieved by keeping
    track of various metrics of the web service to keep track of the load on the service
    and help ...
  prefs: []
  type: TYPE_NORMAL
- en: Deliverable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The deliverable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A dashboard that shows the health and key metrics of the prediction system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A modeling report that shows the deployment details
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A solution architecture document capturing the various components of the solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer acceptance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The main tasks involved in this stage are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**System validation**: Confirming that the deployed model and data pipeline
    meet the stakeholders needs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Project hand-off**: Hand the system off to the group that is going to run
    the system in production'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The customer should verify that the end-to-end solution meets the business needs
    as defined in the initial business understanding phase. Does the system make timely
    predictions that satisfy the metrics chosen for the application?
  prefs: []
  type: TYPE_NORMAL
- en: All the documentation is reviewed and finalized and handed off to the group
    in charge of running operations. This group will be responsible for taking the
    work done thus far and maintaining it over its life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Deliverable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An exit report for the project is delivered at the end of this stage. It contains
    all the details of the project that are required to operate and maintain the system
    to its full design potential. A template of the exit report is provided here: [https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md).
  prefs: []
  type: TYPE_NORMAL
- en: Tools for TDSP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microsoft has released a set of tools that make it easier for organizations
    to follow the TDSP process. One of those tools is the IDEAR utility released for
    CRAN-R, Microsoft R, and Python. Another tool is the **Automated Modeling and
    Reporting** (**AMAR**) utility. In this section, we will look into how we can
    leverage these tools in the TDSP process.
  prefs: []
  type: TYPE_NORMAL
- en: IDEAR tool for R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To install this tool, navigate to [https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils/R/Run-IDEAR.R](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils/R/Run-IDEAR.R) in
    order to retrieve the code required for this tool. Download the GitHub repository
    to make it easier to navigate the different files required for this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open R Studio on your computer, navigate to the preceding file, and open it.
    In the top-right corner of the code tab, click on Source to execute the package,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/683781cb-40c2-4c95-a371-57cd37c25c63.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, the following prompt will be shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b75f3c9-9cdc-4fd2-ac92-aca93dd2faf0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An example `.yaml` file can be loaded from the following location. Select `para-adult.yaml` as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fbfbbfb7-3925-40b1-8900-175631dbe2dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This will open a data quality report for the data example described in the
    YAML file, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9a2d7744-d074-4baf-b883-7a5ae352fef9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can use the menu on the left-hand side to navigate through the different
    sections of the output. The first section is the Task Summary, which gives a summary
    of the file read by listing the file location, the names of the different types
    of variables, and the data science task type (for example, classification):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f8377493-c0fa-4cd5-b74c-6804265c2232.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on Data Summary to get to the next section. Under 2.1 in the following
    screenshot, you can see a sample of the data by picking the top n number of rows
    desired:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d573a0f-259c-41c2-95bd-e0848150721e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is a great way to visually examine the data that is loaded for discrepancies.
    Section 2.2 of the following screenshot shows a summary of the data by counting
    the number of rows and columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/385d97ee-8ae4-47ae-aa59-6f5e54d7bf06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 2.3, the report displays the names and types of the columns, indicating
    whether they are numeric or categorical:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9254bdff-b9ac-4f68-8b9e-ca22205d7465.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Section 2.4 of the report examines the quality of the data. This report maps
    the percentage of missing data for each of the variables. The heat map formatting
    helps to detect any missing data pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c3f7855-a778-42d4-97c2-bb4c4801b7b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Section 2.5 summarizes the basic statistics of the data by showing the percentiles
    for the numeric data and the frequency count for the categorical data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66b52eb6-c4e1-419b-a710-ba73b019913b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we move on to Section 3, where we dive deeper into each of the individual
    variables to investigate them further. In Section 3.1, you can see more detailed
    statistics of each variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f1eecfd2-e544-4242-a3fc-2d53685af2ad.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 3.2, you can visualize the target variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe0b7459-cd7b-4f9a-938e-09c63214f727.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 3.3, you can visualize any of the numerical variables and look at
    quantiles and the distribution of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ca646959-ec01-47b0-b3cf-d6d54518cc7b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 3.4, you can visualize the categorical variables, showing the frequency
    of the distinct categories within them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2afe3a8a-4cf2-4aba-9708-497394e4fa09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 4, the report helps you to analyze the relationship between the
    different variables. This is important for understanding which variables are important
    for building the model, and which can be dropped. In Section 4.1, you can rank
    the impact of the variables relative to a reference variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ad08159-539b-47a5-a99c-67efc00ba918.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 4.2, you can examine the correlation between two categorical variables.
    For example, in the following plot, we see that males have more income than females:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d134c73b-99c2-4113-8bbc-c7e76c94c36d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, in Section 4.3, you can see the interaction between two numerical
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2783e63c-09ce-408b-9fd5-e2a4f04ceb1a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 4.4, you can use different correlation methods to calculate the
    correlation between numerical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/952259a7-a935-4a40-8a68-24664e5ce2ce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 4.5, you can visualize the interactions between numerical and categorical
    variables using box plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/37e71ad1-3d5c-4842-b5e1-63b476ee4691.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The next three sections focus on multivariate statistics. Section 4.6 leverages
    **Principal Component Analysis** (**PCA**) to look at the distribution of data
    in a reduced variable space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/adb63ce8-389f-4810-9b35-4f2337a775dc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Section 4.7, you can project numerical variables to 2D space using the t-SNE
    method. In Section 4.8, you can project both numerical and categorical variables
    to PCA and visualize them simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d915a61d-ce98-43f2-a66d-3fba6f17fc82.png)'
  prefs: []
  type: TYPE_IMG
- en: In Section 5, if you click on the Generate Report button, it will create a summary
    report with all the summaries from the preceding sections.
  prefs: []
  type: TYPE_NORMAL
- en: Automated modeling and reporting (AMAR) in R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The AMR tool is a customizable, semi-automated utility built into R to train
    and evaluate single or multiple machine learning models. It has features such
    as parameter sweeping to find the model that fits the desired metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the report is generated, it contains the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: A model description
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A model evaluation and comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A ranking of the features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In general, the information described in the report can help increase the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The quality of the feature variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The level of difficulty for the machine learning task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guidance for subsequent feature engineering and modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AMAR tool is available at the following GitHub location: [https://github.com/Azure/Azure-TDSP-Utilities/tree/master/DataScienceUtilities/Modeling
    ...](https://github.com/Azure/Azure-TDSP-Utilities/tree/master/DataScienceUtilities/Modeling)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, we have introduced you to the TDSP in this chapter and covered
    each of the different steps that are involved in detail. This process is meant
    to augment other existing processes rather than replace them. We also looked at
    various TDSP utilities that Microsoft has provided that make it easier to build
    some structure into the data science life cycle. In the next few chapters, we
    will look at each of the options available within Azure to build AI solutions
    for your business needs.
  prefs: []
  type: TYPE_NORMAL
