<html><head></head><body>
		<div id="_idContainer208">
			<h1 class="chapter-number" id="_idParaDest-120"><a id="_idTextAnchor297"/>6</h1>
			<h1 id="_idParaDest-121"><a id="_idTextAnchor298"/>Searching for a Signal</h1>
			<p>In this chapter, we’ll cover how to use data science to search for a signal hidden in the noise <span class="No-Break">of data.</span></p>
			<p>We will leverage the features we created within the Databricks platform during the previous chapter. We start by using <strong class="bold">automated machine learning</strong> (<strong class="bold">AutoML</strong>) for a basic modeling approach, which provides autogenerated code and quickly enables data scientists to establish a baseline model to beat. When searching for a signal, we experiment with different features, hyperparameters, and models. Historically, tracking these configurations and their corresponding evaluation metrics is a time-consuming project in and of itself. A low-overhead tracking mechanism, such as the tracking provided by MLflow, an open source platform for managing data science projects and supporting <strong class="bold">ML operations</strong> (<strong class="bold">MLOps</strong>) will<a id="_idIndexMarker399"/> reduce the burden of manually capturing configurations. More specifically, we’ll introduce MLflow Tracking, an MLflow component that significantly improves tracking each permutation’s many outputs. However, that is only the beginning. As data science teams are being pressed to<a id="_idIndexMarker400"/> leverage <strong class="bold">generative artificial intelligence</strong> (<strong class="bold">GenAI</strong>), we will also showcase how to leverage a <strong class="bold">large language model</strong> (<strong class="bold">LLM</strong>) to <a id="_idIndexMarker401"/>create a SQL bot and a <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) model<a id="_idIndexMarker402"/> utilizing PyTorch. These examples demonstrate that in addition to building our own solutions, we can integrate external innovative solutions into our workflows. This openness allows us to pick from the best of <span class="No-Break">both worlds.</span></p>
			<p>Here is what you will learn as part of <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Baselining <span class="No-Break">with AutoML</span></li>
				<li>Classifying beyond <span class="No-Break">the basic</span></li>
				<li>Applying <span class="No-Break">our learn<a id="_idTextAnchor299"/>ing</span></li>
			</ul>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor300"/>Technical requirements</h1>
			<p>Here are the technical requirements needed to complete the hands-on examples in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Databricks <span class="No-Break">ML Runtime:</span><ul><li><span class="No-Break">AutoML</span></li><li><span class="No-Break">MLflow</span></li><li><span class="No-Break"><strong class="source-inline">Pandas</strong></span></li><li><span class="No-Break"><strong class="source-inline">Sklearn</strong></span></li><li><span class="No-Break"><strong class="source-inline">Torch</strong></span></li></ul></li>
				<li>For our LLM model, we will integrate with the <strong class="bold">ChatGPT</strong> model from <span class="No-Break"><strong class="bold">OpenAI</strong></span><span class="No-Break"> (</span><a href="https://openai.com/"><span class="No-Break">https://openai.com/</span></a><span class="No-Break">)</span></li>
				<li>We will use the <strong class="bold">PyTorch Lightning AI</strong> Python package (<a href="https://www.pytorchlightning.ai/index.html">https://www.pytorchlightning.ai/index.html</a>) and <strong class="bold">TorchMetrics</strong> (<a href="https://torchmetrics.readthedocs.io/en/stable/">https://torchmetrics.readthedocs.io/en/stable/</a>) while building the classification model for the Parkinson’s <strong class="bold">Freezing of Gait</strong> (<span class="No-Break"><strong class="bold">FOG</strong></span><span class="No-Break">) prob<a id="_idTextAnchor301"/>lem</span></li>
			</ul>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor302"/>Baselining with AutoML</h1>
			<p>A baseline model is a <a id="_idIndexMarker403"/>simple model used as a starting point for ML. Data scientists often use a baseline model to compare the performance of more complex models. Baseline models are typically simple or common algorithms, such as the majority class classifier or a <span class="No-Break">random forest.</span></p>
			<p>Baseline models are valuable for several reasons, some of which are <span class="No-Break">listed here:</span></p>
			<ul>
				<li>They can help you understand the difficulty of finding a signal given your current dataset. If even the best baseline model performs poorly, it may indicate that more complex models will also struggle to find useful patterns (that is, garbage data in, garbage <span class="No-Break">models out).</span></li>
				<li>Baseline models can help you to identify features that are most important for the ML task. If a baseline model performs well, it may be because it can learn from the most <span class="No-Break">salient features.</span></li>
				<li>Baseline models can help you avoid overfitting. Overfitting is a frequent problem with more complex models. It occurs when a model learns the training data too well and cannot generalize to new data. You can determine whether the more complex model is overfitting by comparing its performance to the baseline model. If the complex model performs better than the baseline on training data but worse on unseen test data, you know <span class="No-Break">you’ve overfit.</span></li>
			</ul>
			<p>There are multiple ways to create a baseline model. One straightforward approach is to use a random model. A random model is created by randomly assigning labels to the data. This type of model helps you evaluate how other models perform compared to random guessing. Another common approach is to use the majority class classifier. The majority class classifier always predicts the most common class in the training data and gives you another simplistic algorithm against which you can compare more <span class="No-Break">complex models.</span></p>
			<p>In the lakehouse, we<a id="_idIndexMarker404"/><a id="_idTextAnchor303"/> have AutoML, which is another straightforward way to get a baseline. This is our personal favorite way to start an ML task because it gives us a head start on model selection compared to the simpler baseline options. Recall that we used AutoML in <a href="B16865_04.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic">Chapter 4</em></span></a> to explore the <em class="italic">Favorita sales</em> data. While generating that exploration notebook, AutoML also generated model experiments, which is what we are focusing <span class="No-Break">on now.</span></p>
			<p>AutoML rapidly explores many model/hyperparameter permutations to find the best baseline model for your data, along with evaluation metrics and actual code. Once you have created a baseline model, you can evaluate its performance using accuracy, precision, recall, confusion<a id="_idIndexMarker405"/> matrices, <strong class="bold">receiver operating characteristic</strong> (<strong class="bold">ROC</strong>) curves, and more to choose the best experiment. However, it is essential to remember that AutoML is not a magic bullet. It can remove some of the overhead of coding multiple algorithms for experimentation, but you are still in charge of where to go next. Luckily, AutoML automatically tracks these model artifacts in MLflow, which is where MLflow shines. Tracking <a id="_idIndexMarker406"/>the many features, models, hyperparameters, and evaluation metrics is a real headache. Using MLflow to track everything natively is a lifesaver, so let’s explore <span class="No-Break">tha<a id="_idTextAnchor304"/>t next.</span></p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor305"/>Tracking experiments with MLflow</h2>
			<p>MLflow is an open <a id="_idIndexMarker407"/>source <a id="_idIndexMarker408"/>platform developed by Databricks for managing data science projects through the entire ML life cycle, from the experimentation phase to packaging code to model deployment in production. We’ll cover deployment in a later chapter. For now, let’s focus on the <strong class="bold">Tracking</strong> component of MLflow (<a href="https://mlflow.org/docs/latest/tracking.html#tracking">https://mlflow.org/docs/latest/tracking.html#tracking</a>). Before we had MLflow Tracking, ML experiments required a lot of work outside of actual experimentation. MLflow Tracking handles the overhead of capturing configurations of features, algorithms, and hyperparameters during testing. Additionally, using MLflow in the lakehouse gives you access to Managed MLflow, which is built on top of MLflow. Databricks notebooks have built-in integrations that make it easy to manage and compare experiment results both programmatically via Mlflow’s lightweight APIs or through <strong class="bold">user interfaces</strong> (<strong class="bold">UIs</strong>). For example, <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.1</em> shows how we can view our experiment runs while still in <span class="No-Break">our notebook:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer180">
					<img alt="Figure 6.1 – The in-notebook UI for viewing the experiment runs" src="image/B16865_06_01.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – The in-notebook UI for viewing the experiment runs</p>
			<p>In MLflow Tracking lingo, the<a id="_idIndexMarker409"/> execution <a id="_idIndexMarker410"/>of data science code is <a id="_idIndexMarker411"/>called a <strong class="bold">run</strong>. Each run can record <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Parameters</strong>: Key-value pairs of input parameters, such as the features used for a given run or the number of trees in a <span class="No-Break">random forest.</span></li>
				<li><strong class="bold">Metrics</strong>: Evaluation <a id="_idIndexMarker412"/>metrics<a id="_idIndexMarker413"/> such as <strong class="bold">Root Mean Squared Error</strong> (<strong class="bold">RMSE</strong>) or <strong class="bold">Area Under the ROC </strong><span class="No-Break"><strong class="bold">Curve</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">AUC</strong></span><span class="No-Break">).</span></li>
				<li><strong class="bold">Artifacts</strong>: Arbitrary output files in any format. This can include images, pickled models, and <span class="No-Break">data files.</span></li>
				<li><strong class="bold">Source</strong>: The code that originally ran the experiment and a reference to the exact version of the data used <span class="No-Break">for training.</span></li>
			</ul>
			<p>When you train models in the notebook, model training information is automatically tracked with MLflow Tracking. To customize the auto-logging configuration, call <strong class="source-inline">mlflow.autolog()</strong> before your training code. Please note that although many common libraries have auto-logging support (such as Scikit-learn, XGBoost, and Keras), check the documentation for a full <span class="No-Break">list: </span><a href="https://mlflow.org/docs/latest/models.html#built-in-model-flavors"><span class="No-Break">https://mlflow.org/docs/latest/models.html#built-in-model-flavors</span></a><span class="No-Break">.</span></p>
			<p>When working on a particular ML task, it’s helpful to group your runs into “experiments.” This is an easy way to compare runs, either programmatically or via the Databricks <span class="No-Break">Experiments UI.</span></p>
			<p>In <a href="B16865_04.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic">Chapter 4</em></span></a> and <a href="B16865_05.xhtml#_idTextAnchor244"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, we used AutoML for traditional regression <a id="_idIndexMarker414"/>and classification <a id="_idIndexMarker415"/>models. In the next session, we will lean into more advanced classification techniques for more complex <span class="No-Break">bus<a id="_idTextAnchor306"/>iness problems.</span></p>
			<h1 id="_idParaDest-125"><a id="_idTextAnchor307"/>Classifying beyond the basic</h1>
			<p>The Databricks AutoML<a id="_idIndexMarker416"/> product is a solid starting point for classification, regression, and forecasting models. There are more advanced classification techniques beyond tree-based models, gradient boost models, and logistic regression that you can use with the lakehouse, as it is designed to work with virtually any open source <span class="No-Break">ML model.</span></p>
			<p>The Databricks ML runtimes include pre-built DL infrastructure and libraries such as PyTorch, TensorFlow, and Hugging Face transformers. DL models are computationally intensive, and <strong class="bold">distributed DL</strong> (<strong class="bold">DDL</strong>) frameworks <a id="_idIndexMarker417"/>such as Horovod also work in conjunction with these DL libraries for more efficient DDL. Be sure to check out the new PyTorch on Databricks! There is a <em class="italic">PyTorch on Databricks – Introducing the Spark PyTorch Distributor</em> blog that is useful if you are working with <span class="No-Break">PyTorch (</span><a href="https://www.databricks.com/blog/2023/04/20/pytorch-databricks-introducing-spark-pytorch-distributor.html"><span class="No-Break">https://www.databricks.com/blog/2023/04/20/pytorch-databricks-introducing-spark-pytorch-distributor.html</span></a><span class="No-Break">).</span></p>
			<p>Another exciting type of ML<a id="_idIndexMarker418"/> is <strong class="bold">generative adversarial networks</strong> (<strong class="bold">GANs</strong>). A quick introduction for those not familiar: GANs are a type of generative model that consists of two <strong class="bold">neural networks</strong> (<strong class="bold">NNs</strong>) – a <a id="_idIndexMarker419"/>generator and a discriminator. The generator network learns to generate synthetic data, such as images or text, that is similar to the real data, while the discriminator network tries to distinguish between the real and synthetic data. GANs have been used for image synthesis, data augmentation, and generating realistic deepfake videos. We used GANs in the past to thwart image classification algorithms. The goal was to alter an image just enough to confuse the DL algorithms but not so much that the human eye would recognize the image was altered. To see other applications of GANs, watch <a id="_idIndexMarker420"/>this awesome talk from <em class="italic">Data + AI Summit 2023</em>: <em class="italic">Generative AI at Scale Using GAN and Stable </em><span class="No-Break"><em class="italic">Diffusion</em></span><span class="No-Break"> (</span><a href="https://www.youtube.com/watch?v=YsWZDCsM9aE"><span class="No-Break">https://www.youtube.com/w<span id="_idTextAnchor308"/>atch?v=YsWZDCsM9aE</span></a><span class="No-Break">).</span></p>
			<h2 id="_idParaDest-126"><a id="_idTextAnchor309"/>Integrating innovation</h2>
			<p>The world of data <a id="_idIndexMarker421"/>science and ML moves very fast. You will likely come across projects that will benefit from innovations outside the standard ML libraries. For example, if you want to work on a project using text data, you will want to explore LLMs. LLMs are a type of advanced language model trained using DL techniques on massive amounts of text data. Fortunately, the Databricks platform makes it easy to integrate with projects such as OpenAI’s ChatGPT and other available options from <span class="No-Break">Hugging Face.</span></p>
			<p>Next, let’s look at an example of using an LLM to help business users or analysts get information from their tables without knowing SQL. We will build a chatbot using OpenAI’s <strong class="bold">Generative Pre-trained Transformer 4</strong> (<strong class="bold">GPT-4</strong>) as a data analyst. In this example, you <a id="_idIndexMarker422"/>create instructions on how it can ask for a list of tables, get information from those tables, and sample data from the tables. The chatbot is able to build a SQL query and then interpret the results. To run these notebooks in the example, you will need an account with OpenAI at the OpenAI developer site (<a href="https://platform.openai.com">https://platform.openai.com</a>) and must request a key for the <span class="No-Break">OpenAI API.</span></p>
			<p>In the first notebook, <strong class="source-inline">sql_resource</strong>, we will create instructions and references for <span class="No-Break">the chatbot.</span></p>
			<p>The notebook starts with commented text with tips on responses and response format, as <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer181">
					<img alt="Figure 6.2 – Instruction text for response and response format for this chatbot" src="image/B16865_06_02.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Instruction text for response and response format for this chatbot</p>
			<p>The next lines are where <a id="_idIndexMarker423"/>you create text for invalid responses and the response format for your chatbot to share <span class="No-Break">its output:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer182">
					<img alt="Figure 6.3 – Text for invalid responses and the chatbot response format" src="image/B16865_06_03.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Text for invalid responses and the chatbot response format</p>
			<p>For your chatbot to understand the landscape of data, you will need to create a catalog an<a id="_idTextAnchor310"/>d define functions to identify your list of tables, table definitions, and schemas <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer183">
					<img alt="Figure 6.4 – Defining tables and table locations for the chatbot" src="image/B16865_06_04.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4 – Defining tables and table locations for the chatbot</p>
			<p>Now, your chatbot <a id="_idIndexMarker424"/>knows where to get information. To communicate with your chatbot, we need to teach it how to have a conversation. To do this, we define a log for a conversation and conversation function and the function to send the conversation to the OpenAI GPT-4 model. This is also where you can change which model your <span class="No-Break">chatbot uses:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer184">
					<img alt="Figure 6.5 – Defining function to submit conversation to OpenAI API" src="image/B16865_06_05.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.5 – Defining function to submit conversation to OpenAI API</p>
			<p>We want our chatbot<a id="_idIndexMarker425"/> to build SQL queries to get data from our tables, so we create a function to teach it how to build a Spark <span class="No-Break">SQL query:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer185">
					<img alt="Figure 6.6 – Function to process SQL" src="image/B16865_06_06.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.6 – Function to process SQL</p>
			<p>The function we created in <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.6</em> is just a few lines of code, but it enables the chatbot to effectively build SQL queries against the tables defined in <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.4</em>. Now, we need to tie it all together by defining how to process the conversation and create <span class="No-Break">a response:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer186">
					<img alt="Figure 6.7 – Function to process request and response" src="image/B16865_06_07.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.7 – Function to process request and response</p>
			<p>We have now constructed the chatbot, created the initial language for the chatbot to interact with <a id="_idIndexMarker426"/>prompts, designated the data and tables available, and showed it how to assemble queries and respond to prompts. In the next section, we start working with <span class="No-Break">the chatbot.</span></p>
			<p>Our next notebook is where we interact with the chatbot, and it starts by installing the <span class="No-Break">OpenAI library:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer187">
					<img alt="Figure 6.8 – Installing OpenAI library" src="image/B16865_06_08.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.8 – Installing OpenAI library</p>
			<p>Next, we will pull in the functions that we defined in our <span class="No-Break"><strong class="source-inline">sql_resource</strong></span><span class="No-Break"> file:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer188">
					<img alt="Figure 6.9 – Importing functions from sql_resources" src="image/B16865_06_09.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.9 – Importing functions from sql_resources</p>
			<p>With the library installed and the functions loaded, we have all of the parts assembled that are needed to interact. We start by using the <strong class="source-inline">startConversation()</strong> function to initiate a conversation with <span class="No-Break">our chatbot:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer189">
					<img alt="Figure 6.10 – Starting a conversation with the chatbot" src="image/B16865_06_10.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.10 – Starting a conversation with the chatbot</p>
			<p>One thing that we have all experienced when interacting with chatbots is they don’t always give you the information you want the first time, so with our chatbot, we can have a back-and-forth conversation. In the preceding conversation, we wanted to know which customer<a id="_idIndexMarker427"/> ordered the most, but we don’t know how many orders the customer ordered, so in <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.11</em>, we ask the question in a <span class="No-Break">different way:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer190">
					<img alt="Figure 6.11 – Continuing the conversation with the chatbot" src="image/B16865_06_11.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.11 – Continuing the conversation with the chatbot</p>
			<p>As new versions of OpenAI’s GPT model are released, the results and behavior of your chatbot may change. In this case, GPT-3.5 asked more questions than the GPT-4 version, but the GPT-4 version was better at using the commands to list tables and request table definitions. As new models and approaches become available, it is good practice to test them and see how the changes impact your work and the results of your chatbot. Leveraging MLflow with your chatbot experiment will help you track and compare different features and c<a id="_idIndexMarker428"/>onfigurations and assist in your <span class="No-Break">production process.</span></p>
			<p>In this next section, we will combine the features created in <a href="B16865_05.xhtml#_idTextAnchor244"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> to create models for our <span class="No-Break">d<a id="_idTextAnchor311"/>ifferent datasets.</span></p>
			<h1 id="_idParaDest-127"><a id="_idTextAnchor312"/>Applying our learning</h1>
			<p>In this chapter, we <a id="_idIndexMarker429"/>have learned how to create baseline models using AutoML, tracking our MLOps with MLflow, and even using more advanced language models in order to extract more information and ultimately business value from our data. Now, let’s take what we have learned and apply it to our datasets that we cleaned in <a href="B16865_04.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic">Chapter 4</em></span></a> and featurized in <a href="B16865_05.xhtml#_idTextAnchor244"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><span class="No-Break">.</span></p>
			<p>We will start with creating and training a classification model for our Parkinson’s data so that, ultimately, we can classify hesitation using the patie<a id="_idTextAnchor313"/>nts’ <span class="No-Break">tracking data.</span></p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor314"/>Parkinson’s FOG</h2>
			<p>As mentioned<a id="_idIndexMarker430"/> in the <em class="italic">Technical requirements</em> section, we <a id="_idIndexMarker431"/>are using PyTorch. To use this, either install the packages in your notebook using <strong class="source-inline">pip</strong> or add it to your cluster configuration <span class="No-Break">under </span><span class="No-Break"><strong class="source-inline">libraries</strong></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer191">
					<img alt="Figure 6.12 – Installing the PyTorch library" src="image/B16865_06_12.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.12 – Installing the PyTorch library</p>
			<p>Once you have your libraries loaded, we import all the libraries <span class="No-Break">we use:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer192">
					<img alt="Figure 6.13 – Importing libraries" src="image/B16865_06_13.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.13 – Importing libraries</p>
			<p>For simplicity, we create a model focused on one target label, namely <strong class="source-inline">StartHesitation</strong>. For ease of reuse, define feature and <span class="No-Break">target variables:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer193">
					<img alt="Figure 6.14 – Defining measures and target variable" src="image/B16865_06_14.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.14 – Defining measures and target variable</p>
			<p>Next, we create a<a id="_idIndexMarker432"/> custom <strong class="source-inline">FogDataset</strong> class. The<a id="_idIndexMarker433"/> class is used by PyTorch and requires three specific class methods: <strong class="source-inline">__init__</strong>, <span class="No-Break"><strong class="source-inline">__len__</strong></span><span class="No-Break">, </span><span class="No-Break"><strong class="source-inline">__getitem__</strong></span><span class="No-Break">.</span></p>
			<p>For the <strong class="source-inline">LightningModel</strong> class, as earlier, the <strong class="source-inline">__init__</strong> class method sets the labels and converts the features to tensors. The <strong class="source-inline">__len__</strong> class method returns the total amount of samples in your dataset. The <strong class="source-inline">__getitem__</strong> class method returns, given an index, the i-th sample <span class="No-Break">and label:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer194">
					<img alt="Figure 6.15 – Creating custom FogDataset class" src="image/B16865_06_15.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.15 – Creating custom FogDataset class</p>
			<p>Next, we are going <a id="_idIndexMarker434"/>to define the PyTorch model with functions. In the PyTorch model definitions, we call <strong class="source-inline">self.log</strong>, defining a <strong class="source-inline">forward</strong> and <strong class="source-inline">test set()</strong> function to surface scalars in TensorBoard. This will then be directly usable with PyTorch Lightning to make a <span class="No-Break">lightning-fast model:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer195">
					<img alt="Figure 6.16 – Defining the PyTorch model up to the training step definition" src="image/B16865_06_16.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.16 – Defining the PyTorch model up to the training step definition</p>
			<p><span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.16</em> defines the<a id="_idIndexMarker435"/> PyTorch model, the<a id="_idIndexMarker436"/> forward feed, and the training step details. In the second half of the model code, we define test and validation steps, as <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer196">
					<img alt="Figure 6.17 – The second half of the PyTorch model definition" src="image/B16865_06_17.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.17 – The second half of the PyTorch model definition</p>
			<p>We are creating training <a id="_idIndexMarker437"/>data using<a id="_idIndexMarker438"/> SQL to join the <strong class="source-inline">tdcsfog</strong> data and <strong class="source-inline">tdcsfog_metadata</strong>. We check the label count and then convert the training data to Pandas to prepare it for the <span class="No-Break">Sklearn library:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer197">
					<img alt="Figure 6.18 – Creating Parkinson’s training dataset" src="image/B16865_06_18.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.18 – Creating Parkinson’s training dataset</p>
			<p>We will stratify the training data by subject, printing the label distribution to look for the most representative <span class="No-Break">train/test split:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer198">
					<img alt="Figure 6.19 – Stratifying the training dataset" src="image/B16865_06_19.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.19 – Stratifying the training dataset</p>
			<p>The following is a snippet of the output to illustrate why examining the folds is a necessary step in the process. There are some folds where there is a notable difference between the label <a id="_idIndexMarker439"/>distribution in the<a id="_idIndexMarker440"/> test and <span class="No-Break">training data:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer199">
					<img alt="Figure 6.20 – Reviewing the test and train labels of the folds" src="image/B16865_06_20.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.20 – Reviewing the test and train labels of the folds</p>
			<p>We now implement our splits with <span class="No-Break">fold </span><span class="No-Break"><strong class="source-inline">0</strong></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer200">
					<img alt="Figure 6.21 – Implementing the splits at fold 3" src="image/B16865_06_21.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.21 – Implementing the splits at fold 3</p>
			<p>Now that we have train test indices, we can clean our DataFrames by resetting <span class="No-Break">the indices:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer201">
					<img alt="Figure 6.22 – Resetting the indices after training" src="image/B16865_06_22.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.22 – Resetting the indices after training</p>
			<p>Improperly indexed <a id="_idIndexMarker441"/>DataFrames cause<a id="_idIndexMarker442"/> issues with the <strong class="source-inline">__getitem__</strong> method in our <strong class="source-inline">FogDataset</strong> class. Now, we create <span class="No-Break">custom datasets:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer202">
					<img alt="Figure 6.23 – Creating customer train, test, and validation datasets" src="image/B16865_06_23.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.23 – Creating customer train, test, and validation datasets</p>
			<p>Now, we build the model with the custom datasets we created and train using <span class="No-Break">PyTorch’s </span><span class="No-Break"><strong class="source-inline">Trainer</strong></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer203">
					<img alt="Figure 6.24 – Building and﻿ training the model" src="image/B16865_06_24.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.24 – Building and<a id="_idTextAnchor315"/> training the model</p>
			<p>We have now used <a id="_idIndexMarker443"/>our Parkinson’s FOG data to build and train a classification PyTorch model to predict hesita<a id="_idTextAnchor316"/>tion in <span class="No-Break">our dataset.</span></p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor317"/>Forecasting Favorita sales</h2>
			<p>In <a href="B16865_04.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, we used <a id="_idIndexMarker444"/>AutoML to jump-start<a id="_idIndexMarker445"/> our <strong class="bold">exploratory data analysis</strong> (<strong class="bold">EDA</strong>). Now, we’ll use AutoML to create a <span class="No-Break">baseline model.</span></p>
			<p>To get started, we create an aggregated table to feed into AutoML. This is not required but is an easy way to <span class="No-Break">get started:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer204">
					<img alt="Figure 6.25 – Creating a table of aggregated sales data" src="image/B16865_06_25.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.25 – Creating a table of aggregated sales data</p>
			<p>Note that the code creates a <strong class="source-inline">favorita_autoML_agg</strong> table, which includes the lag features we created in <a href="B16865_05.xhtml#_idTextAnchor244"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><span class="No-Break">.</span></p>
			<p>We create our AutoML experiment similarly to our previous one. See the experiment configurations in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer205">
					<img alt="Figure 6.26 – AutoML experiment configuration for the Favorita forecasting sales example" src="image/B16865_06_26.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.26 – AutoML experiment configuration for the Favorita forecasting sales example</p>
			<p>Notice that during this<a id="_idIndexMarker446"/> experiment, we are treating the forecasting problem like a regression problem by selecting the ML problem type as <strong class="bold">Regression</strong>. As a result, we also must include the <strong class="source-inline">date</strong> variable in the <strong class="bold">Advanced Configuration</strong> section as the <strong class="source-inline">time</strong> column; see <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.27</em></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer206">
					<img alt="Figure 6.27 – AutoML advanced configuration for the Favorita forecasting sales example" src="image/B16865_06_27.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.27 – AutoML advanced configuration for the Favorita forecasting sales example</p>
			<p>The experiment created <a id="_idIndexMarker447"/>about 100 runs before reaching the point where it was no longer making progress against the metric of choice – in our case, <strong class="bold">R-squared</strong>, as shown in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.27</em></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer207">
					<img alt="Figure 6.28 – AutoML advanced configuration for the Favorita forecasting sales example" src="image/B16865_06_28.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.28 – AutoML advanced configuration for the Favorita forecasting sales example</p>
			<p>Out of the 100 combinations, only 6 have an R-squared value of 0.85 or higher. Using AutoML is saving us considerable time and effort. During the experiment, MLflow tried many model types and hyperparameter tuning <a id="_idIndexMarker448"/>utilizing <strong class="bold">Hyperopt</strong>. This experiment is also distributed with the power of Spark, meaning we have a solid model that was tuned efficiently. We have a baseline model, and we are sure a signal can be found. From here forward, we want to aim to beat the model. Beating the model at this point is done by brute force. We improve performance by creating new features, gathering more data points, or enriching the dataset. This point is brute force. We improve performance by creating new <a id="_idIndexMarker449"/>features, gathering more data points, or <a id="_idTextAnchor318"/>enriching <span class="No-Break">the dataset.</span></p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor319"/>Summary</h1>
			<p>In this chapter, we discussed quick ways to create a baseline model and demonstrated how that <span class="No-Break">increases productivity.</span></p>
			<p>We demonstrated MLflow functionality that supports MLOps and helps track model training and tuning. We also covered more complex classification frameworks that can be used in the lakehouse. Access to these frameworks made it possible to implement a DL model in PyTorch for the Parkinson’s FOG example. The openness of Databricks opens the doors for open source and proprietary innovations with API integrations, as shown by the SQL bot LLM. This integration saved time by not recreating the wheel and putting the SQL tool in the hands of our <span class="No-Break">analysts sooner.</span></p>
			<p> The next chapter will focus on moving our m<a id="_idTextAnchor320"/>odels <span class="No-Break">into production.</span></p>
			<h1 id="_idParaDest-131"><a id="_idTextAnchor321"/>Questions</h1>
			<p>The following questions solidify key points to remember and tie the content back to <span class="No-Break">your experience:</span></p>
			<ol>
				<li>Why would you use a <span class="No-Break">baseline model?</span></li>
				<li>What are examples of more advanced <span class="No-Break">classification techniques?</span></li>
				<li>When would you use LLM models, such as OpenAI’s ChatGPT or <strong class="bold">Dolly</strong>, in <span class="No-Break">your lakehouse?</span></li>
			</ol>
			<h1 id="_idParaDest-132"><a id="_idTextAnchor322"/>Answers</h1>
			<p>After putting thought into the questions, compare your answers <span class="No-Break">to ours:</span></p>
			<ol>
				<li>Use a baseline model to have a simple model as a starting point to compare later and more <span class="No-Break">complex models.</span></li>
				<li>Some examples of more advanced classification techniques include DL <span class="No-Break">and GANs.</span></li>
				<li>I would use an LLM model in my lakehouse if I needed to have more advanced language techniques with my da<a id="_idTextAnchor323"/>ta, such as <span class="No-Break">a chatbot.</span></li>
			</ol>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor324"/>Further reading</h1>
			<p>In this chapter, we pointed out specific technologies, technical features, and options. Please take a look at these resources to get deeper into areas that interest <span class="No-Break">you most:</span></p>
			<ul>
				<li><em class="italic">Introducing AI Functions: Integrating Large Language Models with Databricks </em><span class="No-Break"><em class="italic">SQL</em></span><span class="No-Break">: </span><a href="https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html"><span class="No-Break">https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html</span></a></li>
				<li><em class="italic">PyTorch on Databricks – Introducing the Spark PyTorch </em><span class="No-Break"><em class="italic">Distributor</em></span><span class="No-Break">:</span><span class="No-Break"><em class="italic"> </em></span><a href="https://www.databricks.com/blog/2023/04/20/pytorch-databricks-introducing-spark-pytorch-distributor.html"><span class="No-Break">https://www.databricks.com/blog/2023/04/20/pytorch-databricks-introducing-spark-pytorch-distributor.html</span></a></li>
				<li><em class="italic">Free Dolly: Introducing the World’s First Truly Open Instruction-Tuned </em><span class="No-Break"><em class="italic">LLM</em></span><span class="No-Break">: </span><a href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm"><span class="No-Break">https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm</span></a></li>
				<li><em class="italic">Ray 2.3 release (</em><span class="No-Break"><em class="italic">PyPI)</em></span><span class="No-Break">: </span><a href="https://pypi.org/project/ray/"><span class="No-Break">https://pypi.org/project/ray/</span></a></li>
				<li><em class="italic">Ray on Spark Databricks </em><span class="No-Break"><em class="italic">docs</em></span><span class="No-Break">: </span><a href="https://docs.databricks.com/machine-learning/ray-integration.html"><span class="No-Break">https://docs.databricks.com/machine-learning/ray-integration.html</span></a></li>
				<li><em class="italic">Announcing Ray support on Databricks and Apache Spark </em><span class="No-Break"><em class="italic">Clusters</em></span><span class="No-Break">: </span><a href="https://www.databricks.com/blog/2023/02/28/announcing-ray-support-databricks-and-apache-spark-clusters.html"><span class="No-Break">https://www.databricks.com/blog/2023/02/28/announcing-ray-support-databricks-and-apache-spark-clusters.html</span></a></li>
				<li><em class="italic">Ray </em><span class="No-Break"><em class="italic">docs</em></span><span class="No-Break">: </span><a href="https://docs.ray.io/en/latest/cluster/vms/user-guides/community/spark.html#deploying-on-spark-standalone-cluster"><span class="No-Break">https://docs.ray.io/en/latest/cluster/vms/user-guides/community/spark.html#deploying-on-spark-standalone-cluster</span></a></li>
			</ul>
		</div>
	</body></html>