["```py\npip install mlflow\n```", "```py\nmlflow server --backend-store-uri file:////samples/Chapter13/mlruns\n```", "```py\n    class MLFlow {\n     public:\n      MLFlow(const std::string& host, size_t port);\n      void set_experiment(const std::string& name);\n      void start_run();\n      void end_run();\n      void log_metric(const std::string& name, float value,\n                      size_t epoch);\n      void log_param(const std::string& name, \n                     const std::string& value);\n      template <typename T>\n      void log_param(const std::string& name, T value) {\n        log_param(name, std::to_string(value));\n      }\n     private:\n      httplib::Client http_client_;\n      std::string experiment_id_;\n      std::string run_id_;\n    }\n    ```", "```py\n    MLFlow::MLFlow(const std::string& host, size_t port)\n         : http_client_(host, port) {\n    }\n    ```", "```py\n    void MLFlow::set_experiment(const std::string& name) {\n      auto res = http_client_.Get(\n          \"/api/2.0/mlflow/experiments/\"\n          \"get-by-name?experiment_name=\" +\n          name);\n      if (check_result(res, 404)) {\n        // Create a new experiment\n        nlohmann::json request;\n        request[\"name\"] = name;\n        res = http_client_.Post(\n            \"/api/2.0/mlflow/experiments/create\",\n            request.dump(), \"application/json\");\n        handle_result(res);\n        // Remember experiment ID\n        auto json = nlohmann::json::parse(res->body);\n        experiment_id_ =\n            json[\"experiment_id\"].get<std::string>();\n      } else if (check_result(res, 200)) {\n        // Remember experiment ID\n        auto json = nlohmann::json::parse(res->body);\n        experiment_id_ = json[\"experiment\"][\"experiment_id\"]\n                             .get<std::string>();\n      } else {\n        handle_result(res);\n      }\n    }\n    ```", "```py\n    auto res = http_client_.Get(\n        \"/api/2.0/mlflow/experiments/get-byname?experiment_name=\" + \n        name)\n    ```", "```py\n      nlohmann::json request;\n      request[\"name\"] = name;\n    ```", "```py\n    res = http_client_.Post(\"/api/2.0/mlflow/experiments/create\",\n                            request.dump(), \"application/json\");\n    handle_result(res);\n    ```", "```py\n      auto json = nlohmann::json::parse(res->body);\n      experiment_id_ = json[\"experiment_id\"].get<std::string>();\n    ```", "```py\n    bool check_result(const httplib::Result& res, int code) {\n      if (!res) {\n        throw std::runtime_error(\n          \"REST error: \" + httplib::to_ string(res.error()));\n        }\n        return res->status == code;\n    }\n    ```", "```py\n    void handle_result(const httplib::Result& res) {\n      if (check_result(res, 200))\n        return;\n      std::ostringstream oss;\n      oss << \"Request error status: \" << res->status << \" \"\n          << httplib::detail::status_message(res->status);\n      oss << \", message: \" << std::endl\n          << res->body;\n      throw std::runtime_error(oss.str());\n    }\n    ```", "```py\n    void MLFlow::start_run() {\n      nlohmann::json request;\n      request[\"experiment_id\"] = experiment_id_;\n      request[\"start_time\"] =\n          std::chrono::duration_ cast<std::chrono::milliseconds>(\n              std::chrono::system_ clock::now().time_since_epoch())\n              .count();\n      auto res =\n          http_client_.Post(\"/api/2.0/mlflow/runs/create\",\n                            request.dump(), \"application/json\");\n      handle_result(res);\n      auto json = nlohmann::json::parse(res->body);\n      run_id_ = json[\"run\"][\"info\"][\"run_id\"];\n    }\n    ```", "```py\n    void MLFlow::end_run() {\n      nlohmann::json request;\n      request[\"run_id\"] = run_id_;\n      request[\"status\"] = \"FINISHED\";\n      request[\"end_time\"] =\n          std::chrono::duration_cast<std::chrono::milliseconds>(\n              std::chrono::system_clock::now()\n                  .time_since_epoch())\n              .count();\n      auto res = http_client_.Post(\n          \"/api/2.0/mlflow/runs/update\", request.dump(),\n          \"application/json\");\n      handle_result(res);\n    }\n    ```", "```py\nvoid MLFlow::log_metric(const std::string& name,\n                        float value, size_t epoch) {\n  nlohmann::json request;\n  request[\"run_id\"] = run_id_;\n  request[\"key\"] = name;\n  request[\"value\"] = value;\n  request[\"step\"] = epoch;\n  request[\"timestamp\"] =\n      std::chrono::duration_\n      cast<std::chrono::milliseconds>(\n          std::chrono::system_clock::now()\n              .time_ since_epoch())\n          .count();\n  auto res = http_client_.Post(\n      \"/api/2.0/mlflow/runs/log-metric\", request.dump(),\n      \"application/json\");\n  handle_result(res);\n}\n```", "```py\ntemplate <typename T>\nvoid log_param(const std::string& name, T value) {\n  log_param(name, std::to_string(value));\n}\n```", "```py\nvoid MLFlow::log_param(const std::string& name,\n                       const std::string& value) {\n  nlohmann::json request;\n  request[\"run_id\"] = run_id_;\n  request[\"key\"] = name;\n  request[\"value\"] = value;\n  auto res = http_client_.Post(\"/api/2.0/mlflow/runs/log-parameter\", \n                               request.dump(), \"application/json\");\n  handle_result(res);\n}\n```", "```py\nfl::init();\nMLFlow mlflow(\"127.0.0.1\",\"5000\");\nmlflow.set_experiment(\"Linear regression\");\n```", "```py\nint batch_size = 64;\nfloat learning_rate = 0.0001;\nfloat momentum = 0.5;\nint epochs = 100;\nmlflow.start_run();\n```", "```py\n// load datasets\nauto train_dataset = make_dataset(/*n=*/10000, batch_size);\nauto test_dataset = make_dataset(/*n=*/1000, batch_size);\n// Define a model\nfl::Sequential model;\nmodel.add(fl::View({1, 1, 1, -1}));\nmodel.add(fl::Linear(1, 1));\n// define MSE loss\nauto loss = fl::MeanSquaredError();\n// Define optimizer\nauto sgd = fl::SGDOptimizer(model.params(), learning_rate, momentum);\n// Metrics meter\nfl::AverageValueMeter meter;\n```", "```py\nfor (int epoch_i = 0; epoch_i < epochs; ++epoch_i) {\n  meter.reset();\n  model.train();\n  for (auto& batch : *train_dataset) {\n    sgd.zeroGrad();\n    // Forward propagation\n    auto predicted = model(fl::input(batch[0]));\n    // Calculate loss\n    auto local_batch_size = batch[0].shape().dim(0);\n    auto target =\n        fl::reshape(batch[1], {1, 1, 1, local_batch_ size});\n    auto loss_value = loss(predicted, fl::noGrad(target));\n    // Backward propagation\n    loss_value.backward();\n    // Update parameters\n    sgd.step();\n    meter.add(loss_value.scalar<float>());\n  }\n  // Train metrics logging\n  // ...\n  // Calculate and log test metrics\n  // ...\n}\n```", "```py\n// train metrics logging\nauto avr_loss_value = meter.value()[0];\nmlflow.log_metric(\"train loss\", avr_loss_value, epoch_i);\n```", "```py\n// Every 10th epoch calculate test metric\nif (epoch_i % 10 == 0) {\n  fl::AverageValueMeter test_meter;\n  model.eval();\n  for (auto& batch : *test_dataset) {\n    // Forward propagation\n    auto predicted = model(fl::input(batch[0]));\n    // Calculate loss\n    auto local_batch_size = batch[0].shape().dim(0);\n    auto target =\n        fl::reshape(batch[1], {1, 1, 1, local_batch_ size});\n    auto loss_value = loss(predicted, fl::noGrad(target));\n    // Add loss value to test meter\n    test_meter.add(loss_value.scalar<float>());\n  }\n  // Logging the test metric\n  // ...\n}\n```", "```py\n// logging the test metric\nauto avr_loss_value = test_meter.value()[0];\nmlflow.log_metric(\"test loss\", avr_loss_value, epoch_i);\n```", "```py\nmlflow.end_run();\nmlflow.log_param(\"epochs\", epochs);\nmlflow.log_param(\"batch_size\", batch_size);\nmlflow.log_param(\"learning_rate\", learning_rate);\nmlflow.log_param(\"momentum\", momentum);\n```"]