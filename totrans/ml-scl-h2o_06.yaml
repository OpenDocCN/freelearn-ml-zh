- en: '*Chapter 4*: H2O Model Building at Scale – Capability Articulation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have learned the fundamental workflow of how to build H2O models
    at scale, but that was done using H2O at its barest minimum. In this chapter,
    we will survey the extremely broad capability set of H2O model building at scale.
    We will then use our knowledge from this chapter and move on to part two, *Building
    State-of-the-Art Models on Large Data Volumes Using H2O*, where we will get down
    to business and use advanced techniques to build and explain highly predictive
    models at scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'To conduct this survey, we will break down the chapter into the following main
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Articulating the H2O data capabilities during model building
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overviewing the H2O machine learning algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the H2O modeling capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2O data capabilities during model building
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recall that H2O model building at scale is performed by using H2O 3 or its
    extension, Sparkling Water, which wraps H2O 3 with Spark capabilities. The H2O
    3 API has extensive data capabilities used in the model building process, and
    the Sparkling Water API inherits these and adds additional capabilities from Spark.
    These capabilities are broken down into the following three broad categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ingesting data** from the source to the H2O cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manipulating data** on the H2O cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exporting data** from the H2O cluster to an external destination'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As emphasized in previous chapters, the H2O cluster architecture (H2O 3 or Sparkling
    Water) allows model building at an unlimited scale but is abstracted from the
    data scientist who builds models by coding H2O in the IDE.
  prefs: []
  type: TYPE_NORMAL
- en: 'H2O data capabilities are overviewed in the following diagram and elaborated
    subsequently:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17065_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – The H2O data capabilities
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with data ingestion.
  prefs: []
  type: TYPE_NORMAL
- en: Ingesting data from the source to the H2O cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following data sources are supported:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local file**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remote file**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS S3**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MinIO cloud storage**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Blob and Data Lake**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Cloud Storage**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDFS**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDFS-like**: Alluxio FS and IBM HDFS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hive** (via Metastore/HDFS or JDBC)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**JDBC**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The supported file formats of source data are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CSV** (a file with any delimiter, auto-detected or specified)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GZipped CSV**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**XLS** or **XLSX**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ORC**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parquet**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Avro**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ARFF**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SVMLight**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some important characteristics of data ingestion to H2O are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Data is ingested directly from the source to the H2O cluster memory and does
    not pass through the IDE client.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all cases, data is partitioned in-memory across the H2O cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Except for the local file, the remote file, and JDBC sources, data is ingested
    in parallel to each partition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data on the H2O cluster is represented to the user in the IDE as a two-dimensional
    **H2OFrame**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now see how we can manipulate data now that it is ingested into H2O and
    represented as an H2OFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating data in the H2O cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The H2O 3 API provides extensive data manipulation capabilities. As mentioned
    in the previous bullet list, datasets in memory are distributed on the H2O cluster
    and represented in the IDE specifically as an H2OFrame after data load and subsequent
    data manipulations.
  prefs: []
  type: TYPE_NORMAL
- en: H2OFrames have an extensive list of methods to perform mathematical, logical,
    and introspection operations at the value, column, row, and full dataset levels.
    An H2OFrame is similar in experience to the **pandas DataFrame** or **R data frame**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following examples are just a few data manipulations that can be done on
    H2Oframes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Operations on **data columns**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the data type (for example, integers from 0 to 7 as categorical values).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregate a column (group by) by applying mathematical functions.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Display column names and use as features in a model.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Operations on **data rows**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combine rows from one or more datasets.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Slice out (filter) rows of a dataset by specifying the row index, the range
    of rows, or the logical condition.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Operations on **datasets**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Merge two datasets on common values of shared column names.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Transform a dataset by pivoting on a column.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Split a dataset into two or more datasets (for example, train, validate, and
    test).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Operations on **data values**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fill missing values forward or backward with adjacent row or column values.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fill missing values by imputing with aggregate results (for example, the mean
    for the column).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace numerical values based on logical conditions.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Trim values, manipulate strings, return a numerical value sign, and test whether
    a value is N/A.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature engineering** operations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Date parsing, for example, parsing one date column into separate columns for
    year, month, day.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Derive a new column mathematically and conditionally from other columns, including
    the use of lambda expressions.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform target encoding (that is, replace a categorical value with the mean
    of the target variable).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For **Natural Language Processing (NLP)** problems, perform **string tokenizing**,
    **Term Frequency-Inverse Document Frequency (TF-IDF)** calculations, and convert
    a **Word2vec** model into an H2OFrame for data manipulations.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For full details of H2O data manipulation possibilities, see the H2O Python
    documentation ([http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html))
    or R documentation ([http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/index.html](http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/index.html)).
    Also, refer to the fourth section of *Machine Learning with Python and H2O* ([http://h2o-release.s3.amazonaws.com/h2o/rel-wheeler/2/docs-website/h2o-docs/booklets/PythonBooklet.pdf](http://h2o-release.s3.amazonaws.com/h2o/rel-wheeler/2/docs-website/h2o-docs/booklets/PythonBooklet.pdf))
    for examples of data manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating data is key for preparing it as an input for model building. We
    may also want to export our manipulated data for future use. The next section
    lists the H2O data export capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting data out of the H2O cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'H2OFrames in memory can be exported to external targets. These target systems
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local client memory**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local filesystem**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS S3**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MinIO cloud storage**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Blob and Data Lake**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Cloud Storage**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDFS**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDFS-like**: Alluxio FS and IBM HDFS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hive tables** (CSV or Parquet, via JDBC)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The volume of exported data must, of course, be considered. Large volumes of
    data will not, for example, fit into a local client memory or filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now see what additional data capabilities Sparkling Water adds.
  prefs: []
  type: TYPE_NORMAL
- en: Additional data capabilities provided by Sparkling Water
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sparkling Water inherits all data capabilities from H2O 3\. Importantly, Sparkling
    Water adds additional data capabilities by leveraging the Spark DataFrame and
    Spark SQL APIs, and thus can import, manipulate, and export data accordingly.
    See the following reference for full Spark DataFrame and Spark SQL capabilities:
    [https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html).'
  prefs: []
  type: TYPE_NORMAL
- en: A key pattern in using Sparkling Water is to leverage Spark for advanced data
    munging capabilities, then convert the resulting Spark DataFrame to an H2Oframe,
    and then build state-of-the-art models using H2O's machine learning algorithms,
    as covered in the next section. These algorithms can be used in either H2O 3 or
    Sparkling Water.
  prefs: []
  type: TYPE_NORMAL
- en: H2O machine learning algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'H2O has extensive **unsupervised** and **supervised** learning algorithms with
    similar reusable API constructs – for example, similar ways to set hyperparameters
    or invoke explainability capabilities. These algorithms are identical from an
    H2O 3 or Sparkling Water perspective and are overviewed in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17065_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – H2O algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Each algorithm has an extensive set of parameters and hyperparameters to set
    or leverage as defaults. The algorithms accept H2OFrames as data inputs. Remember
    that an H2OFrame is simply a handle on the IDE client to the distributed in-memory
    data on the remote H2O cluster where the algorithm processes it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at H2O's distributed machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: H2O unsupervised learning algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Unsupervised algorithms do not predict but rather attempt to find clusters
    and anomalies in data, or to reduce the dimensionality of a dataset. H2O has the
    following unsupervised learning algorithms to run at scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Aggregator**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalized Low Rank Models (GLRM)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolation Forest**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extended Isolation Forest**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**K-Means Clustering**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Principal Component Analysis (PCA)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2O supervised learning algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Supervised learning algorithms predict outcomes by learning from a training
    dataset labeled with those outcomes. H2O has the following supervised learning
    algorithms to run at scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cox Proportional Hazards (CoxPH)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deep Learning (Artificial Neural Network, or ANN)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed Random Forest (DRF)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalized Linear Model (GLM)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximum R Square Improvements (MAXR)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalized Additive Models (GAM)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ANOVA GLM**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gradient Boosting Machine (GBM)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Naïve Bayes Classifier**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RuleFit**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support Vector Machine (SVM)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**XGBoost**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameters and hyperparameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each algorithm has a deep set of parameters and hyperparameters for configuration
    and tuning. Specifying most parameters is optional; if not specified, the default
    will be used. Parameters include the specification of cross-validation parameters,
    learning rates, tree depths, weights columns, ignored columns, early stopping
    parameters, the distribution of response column (for example, Bernoulli), categorical
    encoding schemes, and many other specifications.
  prefs: []
  type: TYPE_NORMAL
- en: You can dive deeper into H2O's algorithms and their parameters in H2O's documentation
    at [http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html#algorithms](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html#algorithms).
    The H2O website also lists tutorials and booklets for its algorithms at [http://docs.h2o.ai/#h2o](http://docs.h2o.ai/#h2o).
    A full list of algorithm parameters, each with a description, status as a hyperparameter
    or not, and mapping to algorithms that use the parameter, are found in H2O's documentation
    [*Appendix*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268) at [http://docs.h2o.ai/h2o/latest-stable/h2o-docs/parameters.html](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/parameters.html).
  prefs: []
  type: TYPE_NORMAL
- en: H2O extensions of supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: H2O extends its supervised learning algorithms by providing **Automatic Machine
    Learning (AutoML)** and **Stacked Ensemble** capabilities. We will take a closer
    look` at these in the next section, where we will place H2O algorithms in the
    larger context of model capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Miscellaneous
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: H2O provides utilities to enhance work with its algorithms. **Target encoding**
    helps you handle categorical values and has many configurable parameters to make
    this easy. **TF-IDF** and **Word2vec** are commonly used in NLP problems, and
    they also are nicely configurable. Finally, **permutation variable importance**
    is a method to help understand how strongly your features contribute to the model
    and can help in evaluating which features to use in your final training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: H2O modeling capabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'H2O''s supervised learning algorithms are used to train models on training
    data, tune them on validation data, and score or predict with them on test or
    live production data. H2O has extensive capabilities to train, evaluate, explain,
    score, and inspect models. These are summarized in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – The H2O supervised learning capabilities'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17065_04_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 – The H2O supervised learning capabilities
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a closer look at the model training capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: H2O model training capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Algorithms are at the heart of model training, but there are a larger set of
    capabilities to consider beyond the algorithms themselves. H2O provides the following
    model training capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AutoML**: An easy-to-use interface and parameter set that automates the process
    of training and tuning many different models, using multiple algorithms, to create
    a large number of models in a short amount of time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cross-validation**: K-fold validation is used to generate performance metrics
    against folds of the validation split, and parameters such as the number of folds
    can be specified in the algorithm''s training parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Checkpointing**: A new model is built as a continuation from a previously
    trained, checkpointed model as opposed to building the model from scratch; this
    is useful, for example, in retraining a model with new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Early stopping**: The parameters to define when an algorithm stops model
    building early, determined by which of many stopping metrics is specified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grid search**: Build models for each combination of a range of hyperparameters
    that are specified and sort the resulting models by a performance metric.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regularization**: Most algorithms have parameter settings to specify regularization
    techniques to prevent overfitting and increase explainability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Segmented training**: Training data is partitioned into segments based on
    the same column values, and a separate model is built for each segment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stacked ensembles**: Combines the results of multiple base models that use
    the same or different algorithms into a better-performing single model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After training a model, we want to evaluate it to determine whether its predictive
    performance meets our needs. Let's see what H2O offers in this regard.
  prefs: []
  type: TYPE_NORMAL
- en: H2O model evaluation capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'H2O exposes many model attributes to evaluate model performance. These are
    summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **leaderboard for AutoML**: The AutoML model results ranked by configured
    performance metrics or other attributes, such as average prediction speed, with
    additional metrics shown.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance metrics for classification problems**: For classification problems,
    H2O calculates **GINI coefficient**, **Absolute Matthew Correlation Coefficient
    (MCC)**, **F1,** **F0.5**, **F2**, **Accuracy**, **Logloss**, **Area Under the
    ROC Curve (AUC)**, **Area Under the Precision-Recall Curve (AUCPR)**, and **Kolmogorov-Smirnov
    (KS)** metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance metrics for regression problems**: For regression problems, H2O
    calculates **R Squared (R²)**, **Mean Squared Error (MSE)**, **Root Mean Squared
    Error (RMSE)**, **Root Mean Squared Logarithmic Error (RMSLE)**, and **Mean Absolute
    Error (MAE)** metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prediction metrics**: After a model is built, H2O allows you to predict a
    leaf node assignment (tree-based models), feature contributions, class probabilities
    for each stage (GBM models), and feature frequencies on a prediction path (GBM
    and DRF).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning curve plot**: This shows a model performance metric as learning
    progresses to help diagnose overfitting or underfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now explore ways to explain H2O models.
  prefs: []
  type: TYPE_NORMAL
- en: H2O model explainability capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: H2O presents a simple and uniform interface to explain either single models
    or multiple models, which can be a list of separately built models or a reference
    to those generated from AutoML. On top of that, H2O allows you to generate global
    (that is, model-level) and local (row- or individual-level) explanations. H2O's
    explainability capabilities are configurable to your specifications. Output is
    tabular, graphical, or both, depending on the explanation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will dedicate all of *Chapter 6*, *Advanced Model Building – Part II*, to
    explore this important topic in greater detail, but for now, here is a quick list
    of capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Residual analysis for regression**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Confusion matrix for classification**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variable importance table and heatmap**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model correlation heatmap**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shapley values**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Partial Dependency Plots (PDPs)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Individual Conditional Expectation (ICE)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now complete our survey of H2O's capabilities for modeling at scale by
    seeing what we can do once our model is trained, evaluated, and explained.
  prefs: []
  type: TYPE_NORMAL
- en: H2O trained model artifacts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once a model is trained, it can be exported and saved as a scoring artifact.
    The larger topic of deploying your artifact for production scoring will be treated
    in *Part 3: Deploying Your Model to Production Environments*. Here are the fundamental
    capabilities of the exported scoring artifact:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Predicting with a MOJO**: Models can be saved as self-contained binary Java
    objects called MOJOs that can be flexibly implemented as low-latency production
    scoring artifacts on diverse systems (for example, a REST server, batch database
    scoring, and Hive UDFs). MOJOs also can be reimported into H2O clusters for purposes
    described in the next bullet point.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inspecting the model with a MOJO**: An exported MOJO can be re-imported into
    the H2O cluster and used to score against a dataset, inspect hyperparameters used
    to train the original model, see the scoring history, and show feature importances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A MOJO compared to a POJO**: The POJO is the precursor to the MOJO and is
    being deprecated by H2O but is still required for some algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we conducted a wide survey of H2O capabilities for model building
    at scale. We learned about the data sources we can ingest into our H2O clusters
    and the file formats that are supported. We learned how this data moves from the
    source to the H2O cluster, and how the H2OFrame API provides a single handle in
    the IDE to represent the distributed in-memory data on the H2O cluster as a single
    two-dimensional data structure. We then learned the many ways in which we can
    manipulate data through the H2OFrame API and how to export it to external systems
    if need be.
  prefs: []
  type: TYPE_NORMAL
- en: We then surveyed the core of H2O model building at scale – H2O's many state-of-the-art
    distributed unsupervised and supervised learning algorithms. Then, we put those
    into context by surveying model capabilities around them, from training, evaluating,
    and explaining the models, to using model artifacts to retrain, score and inspect
    models.
  prefs: []
  type: TYPE_NORMAL
- en: With this map of the landscape firmly in hand, we can now roll up our sleeves
    and start building state-of-the-art H2O models at scale. In the next chapter,
    we will start by implementing the advanced model building topics one by one, before
    later putting it all together in a fully developed use case.
  prefs: []
  type: TYPE_NORMAL
