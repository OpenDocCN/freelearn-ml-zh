- en: Number Plate Recognition using SVM and Neural Network
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SVM和神经网络进行车牌识别
- en: This chapter introduces us to the steps needed to create an application for
    **Automatic Number Plate Recognition** (**ANPR**). There are different approaches
    and techniques based on different situations, for example, IR camera, fixed car
    position, light conditions, and so on. We can proceed to construct an ANPR application
    to detect automobile license plates in a photograph taken between 2 or 3 meters
    from a car, in ambiguous light condition and with non-parallel ground with minor
    perspective distortions in the automobile's plate.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向我们介绍了创建**自动车牌识别**（**ANPR**）应用程序所需的步骤。根据不同的情况，有不同方法和技巧，例如红外摄像头、固定车辆位置、光照条件等。我们可以继续构建一个ANPR应用程序，以检测从2或3米远的车上拍摄的模糊光照条件下、非平行地面带有轻微透视畸变的汽车车牌。
- en: 'The main purpose of this chapter is to introduce us to image segmentation and
    feature extraction, pattern recognition basics, and two important pattern recognition
    algorithms: that are **Support Vector Machine** (**SVM**) and **Artificial Neural
    Network** (**ANN**). In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要目的是向我们介绍图像分割和特征提取、模式识别基础以及两个重要的模式识别算法：**支持向量机**（**SVM**）和**人工神经网络**（**ANN**）。在本章中，我们将涵盖以下主题：
- en: ANPR
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ANPR
- en: Plate detection
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 车牌检测
- en: Plate recognition
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 车牌识别
- en: Introduction to ANPR
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ANPR简介
- en: Automatic Number Plate Recognition, or known by other terms such as **Automatic
    License-Plate Recognition** (**ALPR**), **Automatic Vehicle Identification** (**AVI**),
    or **Car Plate Recognition** (**CPR**), is a surveillance method that uses **Optical
    Character Recognition** (**OCR**) and other methods such as segmentations and
    detection to read vehicle registration plates.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 自动车牌识别，或称为**自动牌照识别**（**ALPR**）、**自动车辆识别**（**AVI**）或**汽车牌照识别**（**CPR**），是一种使用**光学字符识别**（**OCR**）和其他方法（如分割和检测）来读取车辆登记牌的监控方法。
- en: 'The best results in an ANPR system can be obtained with an **Infrared** (**IR**)
    camera, because the segmentation steps for detection and OCR segmentation are
    easy, and clean, and they minimize errors. This is due to the laws of light, the
    basic one being that the angle of incidence equals the angle of reflection. We
    can see this basic reflection when we see a smooth surface such as a plane mirror.
    Reflection off of rough surfaces such as paper, leads to a type of reflection
    known as diffuse or scatter reflection. However, the majority of country plates
    have special characteristics named retro-reflection, that is, the surface of the
    plate is made with a material that is covered with thousands of tiny hemispheres
    that cause light to be reflected back to the source, as we can see in the following
    figure:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在ANPR系统中，使用**红外**（**IR**）摄像头可以获得最佳结果，因为检测和OCR分割的分割步骤既简单又干净，并且它们最小化了错误。这是由于光的基本定律，其中最基本的定律是入射角等于反射角。当我们看到像平面镜这样的光滑表面时，我们可以看到这种基本的反射。从像纸张这样的粗糙表面反射会导致一种称为漫反射或散射反射的类型。然而，大多数国家车牌具有特殊特性，称为反光，即车牌的表面是用覆盖有数千个微小半球体的材料制成的，这些半球体使光线反射回光源，正如我们可以在以下图中看到的那样：
- en: '![](img/image_04_001.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_001.png)'
- en: 'If we use a camera with filter-coupled, structured infrared light projector,
    we can retrieve just the Infrared light, and then, we have a very high quality
    image to segment, with which we can subsequently detect and recognize the plate
    number that is independent of any light environment, as shown in the following
    image:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用带有滤波耦合结构红外光投影仪的摄像头，我们可以仅检索红外光，然后，我们有一个非常高质量的图像进行分割，我们可以用这个图像随后检测和识别车牌号码，它不受任何光照环境的影响，如图所示：
- en: '![](img/image_04_002.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_002.png)'
- en: We will not use IR photographs in this chapter; we will use regular photographs
    so that we do not obtain the best results, and we get a higher level of detection
    errors and higher false recognition rate, as opposed to if we used an IR camera.
    However, the steps for both are the same.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们不会使用红外照片；我们将使用普通照片，这样我们不会获得最佳结果，并且检测错误率和误识别率更高，与使用红外摄像头相比。然而，两种方法的步骤是相同的。
- en: Each country has different license plate sizes and specifications. It is useful
    to know these specifications in order to get the best results and reduce errors.
    Algorithms used in every chapter are designed for explaining the basics of ANPR
    and concrete for license plates used in Spain, but we can extend it to any country
    or specification.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 每个国家都有不同的车牌尺寸和规格。了解这些规格对于获得最佳结果和减少错误是有用的。每章中使用的算法都是为了解释ANPR的基本原理，具体针对西班牙使用的车牌，但我们也可以将其扩展到任何国家或规格。
- en: In this chapter, we will work with license plates from Spain. In Spain, there
    are three different sizes and shapes of license plates, but we will only use the
    most common (large) license plate, which has a 520 mm width by a 110 mm height.
    Two groups of characters are separated by a 41 mm space, and a 14 mm width separates
    each individual character. The first group of characters have four numeric digits,
    and the second group has three letters without the vowels A, E, I, O, U, or the
    letters N or Q. All characters have dimensions of 45 mm by 77 mm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用西班牙的车牌。在西班牙，车牌有三种不同的尺寸和形状，但我们只会使用最常见的（大型）车牌，其宽度为520毫米，高度为110毫米。两组字符之间有一个41毫米的间隔，每个单独字符之间有一个14毫米的间隔。第一组字符有四个数字，第二组有三个字母，没有元音A、E、I、O、U，也没有字母N或Q。所有字符的尺寸为45毫米乘以77毫米。
- en: 'This data is important for character segmentation since we can check both the
    character and blank spaces to verify that we get a character and no other image
    segment:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据对于字符分割很重要，因为我们既可以检查字符，也可以检查空白空间，以验证我们得到的是字符而不是其他图像块：
- en: '![](img/image_04_003.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_003.png)'
- en: ANPR algorithm
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ANPR算法
- en: 'Before explaining the ANPR code, we need to define the main steps and tasks
    in the ANPR algorithm. ANPR is divided in two main steps: plate detection and
    plate recognition. Plate detection has the purpose of detecting the location of
    the plate in the whole camera frame. When a plate is detected in an image, the
    plate segment is passed to the second step (plate recognition), which uses an
    OCR algorithm to determine the alphanumeric characters on the plate.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释ANPR代码之前，我们需要定义ANPR算法中的主要步骤和任务。ANPR分为两个主要步骤：车牌检测和车牌识别。车牌检测的目的是检测车牌在相机整个帧中的位置。当在图像中检测到车牌时，车牌段被传递到第二步（车牌识别），该步骤使用OCR算法来确定车牌上的字母数字字符。
- en: 'In the following diagram, we can see the two main algorithm steps: plate detection
    and plate recognition. After these steps, the program draws over the camera frame
    the plate''s characters that have been detected. The algorithms can return bad
    results or may not return any result:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到两个主要算法步骤：车牌检测和车牌识别。在这些步骤之后，程序会在相机帧上绘制检测到的车牌字符。算法可能会返回错误的结果，或者可能不返回任何结果：
- en: '![](img/image_04_004.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_004.png)'
- en: 'In each step shown in the previous figure, we will define three additional
    steps that are commonly used in pattern recognition algorithms. These steps are
    as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在前图中显示的每个步骤中，我们将定义三个在模式识别算法中常用的附加步骤。这些步骤如下：
- en: '**Segmentation**: This step detects and removes each patch/region of interest
    in the image.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分割**：这一步检测并移除图像中的每个块/感兴趣区域。'
- en: '**Feature extraction**: This step extracts from each patch a set of characteristics.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征提取**：这一步从每个块中提取一组特征。'
- en: '**Classification**: This step extracts each character from the plate recognition-step
    or classifies each image patch into *plate* or *no plate* in the plate-detection
    step.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类**：这一步从车牌识别步骤中提取每个字符，或者在车牌检测步骤中将每个图像块分类为“车牌”或“无车牌”。'
- en: 'In the following diagram, we can see these pattern recognition steps in the
    whole algorithm application:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到整个算法应用中的这些模式识别步骤：
- en: '![](img/image_04_005.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_005.png)'
- en: 'Aside from the main application, whose purpose is to detect and recognize a
    car plate number, we will briefly explain two more tasks that are usually not
    explained:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了主要应用，其目的是检测和识别车牌号码之外，我们还将简要解释两个通常不会被解释的任务：
- en: How to train a pattern recognition system
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何训练一个模式识别系统
- en: How to evaluate it
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何评估它
- en: These tasks, however, can be more important than the main application, because
    if we do not train the pattern recognition system correctly, our system can fail
    and not work correctly; different patterns need different training's and evaluation.
    We need to evaluate our system in different environments, conditions, and features
    to get the best results. These two tasks are sometimes used together, since different
    features can produce different results that we can see in the evaluation section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些任务可能比主要应用更重要，因为我们如果不正确训练模式识别系统，我们的系统可能会失败并且无法正确工作；不同的模式需要不同的训练和评估。我们需要在不同的环境、条件和特征中评估我们的系统以获得最佳结果。这两个任务有时会一起使用，因为不同的特征可以产生我们在评估部分可以看到的不同结果。
- en: Plate detection
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 车牌检测
- en: 'In this step, we have to detect all the plates in a current camera frame. To
    do this task, we divide it in two main steps: segmentation and segment classification.
    The feature step is not explained because we use the image patch as a vector feature.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们必须检测当前相机帧中的所有车牌。为了完成这个任务，我们将它分为两个主要步骤：分割和分割分类。特征步骤没有解释，因为我们使用图像块作为向量特征。
- en: In the first step (segmentation), we will apply different filters, morphological
    operations, contour algorithms, and validations to retrieve parts of the image
    that could have a plate.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步（分割）中，我们将应用不同的过滤器、形态学操作、轮廓算法和验证来检索可能包含车牌的图像部分。
- en: 'In the second step (classification), we will apply a **Support Vector Machine**
    (**SVM**) classifier to each image patch, our feature. Before creating our main
    application, we will train with two different classes: *plate* and *non-plate*.
    We will work with parallel frontal view color images having 800 pixels of width
    and taken between 2 and 4 meters from a car. These requirements are important
    for correct segmentations. We can get perform detection if we create a multi-scale
    image algorithm.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步（分类）中，我们将对每个图像块，即我们的特征，应用**支持向量机**（**SVM**）分类器。在创建我们的主要应用程序之前，我们将使用两个不同的类别进行训练：*车牌*和*非车牌*。我们将处理具有800像素宽度的并行正面视图彩色图像，这些图像是从2到4米远的车上拍摄的。这些要求对于正确的分割非常重要。如果我们创建一个多尺度图像算法，我们可以得到性能检测。
- en: 'In the next image, we will shown all process involved in plate detection:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一张图像中，我们将展示所有涉及车牌检测的过程：
- en: Sobel filter
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sobel滤波器
- en: Threshold operation
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阈值操作
- en: Close morphologic operation
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 形态学闭运算
- en: Mask of one of filled area
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充区域之一的掩码
- en: In red possible detected plates (features images)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 红色表示可能检测到的车牌（特征图像）
- en: Detected plates after SVM classifier
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM分类器检测到的车牌
- en: '![](img/image_04_006.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_006.png)'
- en: Segmentation
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分割
- en: Segmentation is the process of dividing an image into multiple segments. This
    process is to simplify the image for analysis and make feature extraction easier.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 分割是将图像分割成多个段的过程。这个过程是为了简化图像以便分析，并使特征提取更容易。
- en: One important feature of plate segmentation is the high number of vertical edges
    in a license plate, assuming that the image was taken frontally and the plate
    is not rotated and without perspective distortion. This feature can be exploited
    during the first segmentation step to eliminate regions that don't have any vertical
    edges.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 车牌分割的一个重要特征是车牌中垂直边缘的数量很高，假设图像是正面拍摄的，车牌没有旋转且没有透视失真。这个特征可以在第一个分割步骤中利用，以消除没有任何垂直边缘的区域。
- en: 'Before finding vertical edges, we need to convert the color image to a grayscale
    image (because color can''t help us in this task) and remove possible noise generated
    from the camera or other ambient noise. We will apply a 5x5 Gaussian blur and
    remove noise. If we don''t apply a noise removal method, we can get a lot of vertical
    edges that produce fail detection:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在找到垂直边缘之前，我们需要将彩色图像转换为灰度图像（因为颜色在这个任务中帮不上忙）并移除来自相机或其他环境噪声产生的可能噪声。我们将应用5x5高斯模糊并去除噪声。如果我们不应用噪声去除方法，我们可以得到很多垂直边缘，这会导致检测失败：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To find the vertical edges, we will use a Sobel filter and find the first horizontal
    derivate. The derivate is a mathematic function that allows us to find vertical
    edges on an image. The definition of Sobel function in OpenCV is as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到垂直边缘，我们将使用Sobel滤波器并找到第一个水平导数。导数是一个数学函数，它允许我们在图像上找到垂直边缘。OpenCV中Sobel函数的定义如下：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, `ddepth` is the destination image depth; `xorder` is the order of the
    derivate by x; `yorder` is the order of the derivate by y; `ksize` is the kernel
    size of 1, 3, 5, or 7; `scale` is an optional factor for computed derivative values;
    `delta` is an optional value added to the result; and `borderType` is the pixel
    interpolation method.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`ddepth`是目标图像深度；`xorder`是x导数的阶数；`yorder`是y导数的阶数；`ksize`是1、3、5或7的核大小；`scale`是计算导数值的可选因子；`delta`是可选的值，添加到结果中；`borderType`是像素插值方法。
- en: 'Then, for our case, we can use `xorder=1`, `yorder=0,` and `ksize=3`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在我们的情况下，我们可以使用`xorder=1`、`yorder=0`和`ksize=3`：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'After applying a Sobel filter, we will apply a threshold filter to obtain a
    binary image with a threshold value obtained through Otsu''s method. Otsu''s algorithm
    needs an 8-bit input image, and Otsu''s method automatically determines the optimal
    threshold value:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用Sobel滤波器之后，我们将应用阈值滤波器以获得一个二值图像，阈值值是通过Otsu方法获得的。Otsu算法需要一个8位输入图像，并且Otsu方法自动确定最佳阈值值：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To define Otsu's method in threshold function, we will combine the type parameter
    with the `CV_THRESH_OTSU` value and the threshold value parameter is ignored.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要在阈值函数中定义Otsu方法，我们将类型参数与`CV_THRESH_OTSU`值组合，并且阈值值参数被忽略。
- en: When the `CV_THRESH_OTSU` value is defined, the threshold function returns the
    optimal threshold value obtained by Otsu's algorithm.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当定义`CV_THRESH_OTSU`值时，阈值函数返回Otsu算法获得的最佳阈值值。
- en: By applying a close morphological operation, we can remove blank spaces between
    each vertical edge line and connect all regions that have a high number of edges.
    In this step, we have possible regions that can contain plates.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用闭形态学操作，我们可以移除每个垂直边缘线之间的空白空间，并连接所有具有高边缘数目的区域。在这个步骤中，我们有可能包含车牌的区域。
- en: 'First, we will define our structural element to use in our morphological operation.
    We will use the `getStructuringElement` function to define a structural rectangular
    element with a 17x3 dimension size in our case; this may be different in other
    image sizes:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将定义我们在形态学操作中使用的结构元素。我们将使用`getStructuringElement`函数定义一个具有17x3维度的矩形结构元素；在其他图像大小中可能不同：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we will use this structural element in a close morphological operation
    using the `morphologyEx` function:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用这个结构元素在`morphologyEx`函数中执行闭形态学操作：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After applying these functions, we have regions in the image that could contain
    a plate; however, most of the regions do not contain license plates. These regions
    can be split with a connected component analysis or using the `findContours` function.
    This last function retrieves the contours of a binary image with different methods
    and results. We only need to get the external contours with any hierarchical relationship
    and any polygonal approximation results:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 应用这些函数后，图像中将有可能包含车牌的区域；然而，大多数区域并不包含车牌。这些区域可以通过连通分量分析或使用`findContours`函数来分割。这个最后的函数以不同的方法和结果检索二值图像的轮廓。我们只需要获取具有任何层次关系和任何多边形逼近结果的轮廓：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For each contour detected, extract the bounding rectangle of minimal area.
    OpenCV brings up the `minAreaRect` function for this task. This function returns
    a rotated `RotatedRect` rectangle class. Then, using a vector iterator over each
    contour, we can get the rotated rectangle and make some preliminary validations
    before we classify each region:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个检测到的轮廓，提取最小面积的边界矩形。OpenCV提供了`minAreaRect`函数来完成这个任务。这个函数返回一个旋转的`RotatedRect`矩形类。然后，使用向量迭代器遍历每个轮廓，我们可以获取旋转矩形并在对每个区域进行分类之前进行一些初步验证：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We make basic validations about the regions detected based on their area and
    aspect ratio. We will consider that a region can be a plate if the aspect ratio
    is approximately *520/110 = 4.727272* (plate width divided by plate height) with
    an error margin of 40 percent and an area based on a minimum of 15 pixels and
    maximum of 125 pixels for the height of plate. These values are calculated depending
    on the image size and camera position:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据检测到的区域的面积和宽高比进行基本验证。如果宽高比大约为*520/110 = 4.727272*（板宽除以板高），误差范围为40%，并且板的高度基于至少15像素和最多125像素的面积，我们将考虑该区域可以是一个板。这些值取决于图像大小和相机位置：
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can make even more improvements using the license plate's white background
    property. All plates have the same background color, and we can use a flood fill
    algorithm to retrieve the rotated rectangle for precise cropping.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用车牌的白色背景属性进行更多改进。所有车牌都有相同的背景颜色，我们可以使用填充算法来检索旋转矩形以进行精确裁剪。
- en: The first step to crop the license plate is to get several seeds near the last
    rotated rect center. Then, we will get the minimum size of plate between the width
    and height, and use it to generate random seeds near the patch center.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 裁剪车牌的第一步是获取靠近最后旋转矩形中心的几个种子。然后，我们将获取车牌在宽度和高度之间的最小尺寸，并使用它来生成靠近修补中心附近的随机种子。
- en: 'We want to select the white region, and we need several seeds to touch at least
    one white pixel. Then, for each seed, we use a `floodFill` function to draw a
    new mask image to store the new closest cropping region:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要选择白色区域，并且我们需要几个种子至少接触一个白色像素。然后，对于每个种子，我们使用`floodFill`函数来绘制一个新的掩码图像以存储新的最近裁剪区域：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `floodfill` function fills a connected component with a color into a mask
    image starting from a point seed, and sets maximal lower and upper brightness/color
    difference between the pixel to fill and the pixel neighbors or pixel seed:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`floodfill`函数从点种子开始填充一个连通组件的颜色到掩码图像中，并设置填充像素与像素邻居或像素种子之间的最大亮度/颜色差异：'
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `newval` parameter is the new color we want to put into the image when filling.
    Parameters `loDiff` and `upDiff` are the maximal lower and maximal upper brightness/color
    difference between the pixel to fill and the pixel neighbors or pixel seed.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`newval`参数是我们希望在填充图像时放入的新颜色。参数`loDiff`和`upDiff`是填充像素与相邻像素或像素种子之间的最大亮度/颜色差异。'
- en: 'The parameter `flag` is a combination of the following bits:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数`flag`是以下位组合：
- en: '**Lower bits**: These bits contain connectivity value, 4 (by default) or 8,
    used within the function. Connectivity determines which neighbors of a pixel are
    considered'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低位位**：这些位包含连接值，默认为4或8，在函数中使用。连接性决定了哪些像素邻居被认为是'
- en: '**Upper bits**: These can be 0 or a combination of the following values-`CV_FLOODFILL_FIXED_RANGE`
    and `CV_FLOODFILL_MASK_ONLY`.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高位位**：这些可以是0或以下值的组合-`CV_FLOODFILL_FIXED_RANGE`和`CV_FLOODFILL_MASK_ONLY`。'
- en: '`CV_FLOODFILL_FIXED_RANGE` sets the difference between the current pixel and
    the seed pixel. `CV_FLOODFILL_MASK_ONLY` will only fill the image mask and not
    change the image itself.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`CV_FLOODFILL_FIXED_RANGE`设置当前像素和种子像素之间的差异。`CV_FLOODFILL_MASK_ONLY`将只填充图像掩码而不会更改图像本身。'
- en: 'Once we have a crop mask, we will get a minimal area rectangle from the image
    mask points and check the validity size again. For each mask, a white pixel gets
    the position and uses the `minAreaRect` function for retrieving the closest crop
    region:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了裁剪掩码，我们将从图像掩码点获取最小面积矩形，并再次检查有效尺寸。对于每个掩码，白色像素获取位置并使用`minAreaRect`函数来检索最近的裁剪区域：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The segmentation process is finished, and we have valid regions. Now, we can
    crop each detected region, remove possible rotation, crop the image region, resize
    the image, and equalize the light of the cropped image regions.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 分割过程已完成，并且我们有有效区域。现在，我们可以裁剪每个检测区域，去除可能的旋转，裁剪图像区域，调整图像大小，并均衡裁剪图像区域的光线。
- en: 'First, we need to generate the transform matrix with `getRotationMatrix2D`
    to remove possible rotations in the detected region. We need to pay attention
    to height, because `RotatedRect` can be returned and rotated at 90 degrees. So,
    we have to check the rectangle aspect, and if it is less than `1`, we need to
    rotate it by 90 degrees:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用`getRotationMatrix2D`生成变换矩阵以去除检测区域中可能存在的旋转。我们需要注意高度，因为`RotatedRect`可以返回并旋转90度。因此，我们必须检查矩形纵横比，如果它小于`1`，我们需要将其旋转90度：
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the transform matrix, we now can rotate the input image by an affine transformation
    (affine transformation in geometry is a transformation that takes parallel lines
    to parallel lines) with the `warpAffine` function where we set the input and destination
    images, the transform matrix, the output size (same as input in our case), and
    the interpolation method to use. We can define the border method and border value
    if needed:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用变换矩阵，我们现在可以使用`warpAffine`函数通过仿射变换（在几何中，仿射变换是一种将平行线映射为平行线的变换）来旋转输入图像。在这里，我们设置输入和目标图像、变换矩阵、输出大小（在我们的情况下与输入相同）以及要使用的插值方法。如果需要，我们可以定义边界方法和边界值：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'After we rotate the image, we will crop the image with `getRectSubPix` which
    crops and copies an image portion of width and height centered in a point. If
    the image is rotated, we need to change the width and height sizes with the C++
    `swap` function:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对图像进行旋转后，我们将使用`getRectSubPix`裁剪图像，该函数裁剪并复制一个以点为中心的图像部分。如果图像已旋转，我们需要使用C++的`swap`函数更改宽度和高度大小：
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Cropped images are not good for use in training and classification since they
    do not have the same size. Also, each image contains different light conditions,
    making them more different. To resolve this, we resize all the images to same
    width and height, and apply a light histogram equalization:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 裁剪的图像不适合用于训练和分类，因为它们的大小不同。此外，每张图像都包含不同的光照条件，使它们更加不同。为了解决这个问题，我们将所有图像调整到相同的宽度和高度，并应用光直方图均衡化：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For each detected region, we store the cropped image and its position in a
    vector:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个检测到的区域，我们将裁剪的图像及其位置存储在一个向量中：
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Classification
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: After we preprocess and segment all possible parts of an image, we now need
    to decide whether each segment is (or is not) a license plate. To do this, we
    will use a **Support Vector Machine** (**SVM**) algorithm.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在预处理和分割图像的所有可能部分之后，我们现在需要决定每个部分是否是（或不是）车牌。为此，我们将使用**支持向量机**（**SVM**）算法。
- en: A Support Vector Machine is a pattern recognition algorithm included in a family
    of supervised learning algorithms that was originally created for binary classification.
    Supervised learning is the machine learning algorithm technique that is trained
    with labeled data. We need to train the algorithm with an amount of data that
    is labeled; each data set needs to have a class.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机是包含在最初为二元分类而创建的监督学习算法家族中的模式识别算法。监督学习是使用标记数据进行训练的机器学习算法技术。我们需要用一定数量的标记数据进行算法训练；每个数据集都需要有一个类别。
- en: The SVM creates one or more hyperplanes, which is used to discriminate each
    class of data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: SVM创建一个或多个超平面，用于区分每个数据类别。
- en: 'A classic example is a 2D point set that defines two classes; the SVM searches
    the optimal line that differentiates each class:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经典的例子是定义两个类别的2D点集；SVM搜索区分每个类的最佳直线：
- en: '![](img/image_04_007.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_007.png)'
- en: The first task before any classification is to train our classifier; this is
    a job before the main application and it's named "offline training". This is not
    an easy job because it requires a sufficient amount of data to train the system,
    but a bigger dataset does not always imply the best results. In our case, we do
    not have enough data due to the fact that there are no public license plate databases.
    Because of this, we need to take hundreds of car photos, and then preprocess and
    segment all of it.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何分类之前的首要任务是训练我们的分类器；这是主应用之前的工作，被称为“离线训练”。这不是一项容易的工作，因为它需要足够的数据来训练系统，但更大的数据集并不总是意味着最好的结果。在我们的情况下，由于没有公开的车牌数据库，我们数据不足。因此，我们需要拍摄数百张汽车照片，然后对它们进行预处理和分割。
- en: 'We trained our system with 75 license plate images and 35 images without license
    plates, containing a 144x33 pixel resolution. We can see a sample of this data
    in the following image. This is not a large dataset, but sufficient enough to
    get decent results for our chapter. In a real application, we would need to train
    with more data:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用75张车牌图像和35张无车牌图像训练了我们的系统，这些图像具有144x33像素的分辨率。我们可以在以下图像中看到这些数据的样本。这不是一个大型数据集，但对于我们这一章来说已经足够了。在实际应用中，我们需要使用更多数据进行训练：
- en: '![](img/image_04_008.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_008.png)'
- en: To easily understand how machine learning works, we will proceed to use image
    pixel features of the classifier algorithm (keep in mind that there are better
    methods and features to train an SVM, such as **Principal Components Analysis**
    (**PCA**), Fourier transform, texture analysis, and so on).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了轻松理解机器学习的工作原理，我们将使用分类算法的图像像素特征（记住，有更好的方法和特征来训练SVM，例如**主成分分析**（**PCA**）、傅里叶变换、纹理分析等等）。
- en: 'We need to create the images to train our system using the `DetectRegions`
    class and set the `savingRegions` variable to "true" in order to save the images.
    We can use the `segmentAllFiles.sh` bash script to repeat the process on all image
    files under a folder. This can be taken from the source code of the book:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用`DetectRegions`类创建训练我们系统的图像并设置`savingRegions`变量为"true"以保存图像，我们需要这样做。我们可以使用`segmentAllFiles.sh`bash脚本来对文件夹下的所有图像文件重复此过程。这可以从本书的源代码中获取：
- en: To make this easier, we will store all image training data that is processed
    and prepared into an XML file for use directly with the SVM function. The `trainSVM.cpp`
    application creates this file using the folders and number of image files.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个过程更容易，我们将所有处理和准备好的图像训练数据存储到一个XML文件中，以便直接与SVM函数一起使用。`trainSVM.cpp`应用程序使用文件夹和图像文件的数量创建这个文件。
- en: Training data for a machine learning OpenCV algorithm is stored in an *N*x*M*
    matrix, with *N* samples and *M* features. Each dataset is saved as a row in the
    training matrix.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习OpenCV算法的训练数据存储在一个*N*x*M*矩阵中，其中*N*是样本数，*M*是特征数。每个数据集作为训练矩阵中的一行保存。
- en: The classes are stored in another matrix with *n*x1 size, where each class is
    identified by a float number.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 类别存储在另一个大小为*n*x1的矩阵中，其中每个类别由一个浮点数标识。
- en: 'OpenCV has an easy way to manage a data file in the XML or YAML format with
    the `FileStorage` class. This class lets us store and read OpenCV variables and
    structures or our custom variables. With this function, we can read the training
    data matrix and training classes and save it in `SVM_TrainingData` and `SVM_Classes`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV通过`FileStorage`类提供了一个简单的方式来管理XML或YAML格式的数据文件。这个类允许我们存储和读取OpenCV变量和结构或我们的自定义变量。使用这个函数，我们可以读取训练数据矩阵和训练类别，并将其保存到`SVM_TrainingData`和`SVM_Classes`中：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we have the training data in the `SVM_TrainingData` variable and labels
    in `SVM_Classes`. Then, we only have to create the training data object that connects
    data and labels to use in our machine learning algorithm. To do this, we will
    use the `TrainData` class as a OpenCV pointer `Ptr` class as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经有了`SVM_TrainingData`变量中的训练数据，以及`SVM_Classes`中的标签。然后，我们只需要创建一个训练数据对象，将数据和标签连接起来，以便在我们的机器学习算法中使用。为此，我们将使用`TrainData`类作为OpenCV指针`Ptr`类，如下所示：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We will create the classifier object using the `SVM` class using the `Ptr`OpenCV
    class:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`SVM`类和`Ptr`OpenCV类来创建分类器对象：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we need to set the SVM parameters that define the basic parameters to
    use in an SVM algorithm. To do this, we only have to change some object variables.
    After different experiments, we will choose the next parameter''s setup:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要设置SVM参数，这些参数定义了在SVM算法中使用的基本参数。为此，我们只需要更改一些对象变量。经过不同的实验后，我们将选择下一个参数设置：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We chose a 1000 iterations for training, a C param variable optimization of
    0.1, and finally, a kernel function.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为训练选择了1000次迭代，C参数变量优化为0.1，最后使用核函数。
- en: 'We only need train our classifier with the`train` function and the train data:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要使用`train`函数和训练数据来训练我们的分类器：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Our classifier is ready to predict a possible cropped image using the `predict`
    function of our SVM class; this function returns the class identifier `i`. In
    our case, we will label a plate class with 1 and no plate class with 0\. Then,
    for each detected region that can be a plate, we will use SVM to classify it as
    plate or no plate, and save only the correct responses. The following code is
    a part of a main application called online processing:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分类器已经准备好使用我们的SVM类的`predict`函数来预测一个可能裁剪的图像；这个函数返回类标识符`i`。在我们的情况下，我们将车牌类标记为1，无车牌类标记为0。然后，对于每个可能为车牌的检测区域，我们将使用SVM将其分类为车牌或无车牌，并仅保存正确的响应。以下代码是主应用程序中在线处理的一部分：
- en: '[PRE22]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Plate recognition
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 车牌识别
- en: The second step in License Plate Recognition aims to retrieve the characters
    of the license plate with Optical Character Recognition. For each detected plate,
    we proceed to segment the plate for each character and use an Artificial Neural
    Network machine learning algorithm to recognize the character. Also, in this section,
    you will learn how to evaluate a classification algorithm.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 许可证识别的第二步旨在使用光学字符识别技术检索车牌上的字符。对于每个检测到的车牌，我们将对每个字符进行分割，并使用人工神经网络机器学习算法来识别字符。在本节中，你还将学习如何评估分类算法。
- en: OCR segmentation
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OCR分割
- en: 'First, we will obtain a plate image patch as an input to the OCR segmentation
    function with an equalized histogram. We then need to apply only a threshold filter
    and use this threshold image as the input of a Find Contours algorithm. We can
    observe this process in the following image:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将获取一个车牌图像块作为输入，传递给具有均衡直方图的OCR分割函数。然后，我们只需要应用一个阈值滤波器，并使用这个阈值图像作为Find Contours算法的输入。我们可以在以下图像中观察到这个过程：
- en: '![](img/image_04_009.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_04_009.png)'
- en: 'This segmentation process is coded as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分割过程如下所示：
- en: '[PRE23]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We used the `CV_THRESH_BINARY_INV` parameter to invert the threshold output
    by turning the white input values black and the black input values white. This
    is needed to get the contours of each character, because the contours algorithm
    looks for white pixels.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`CV_THRESH_BINARY_INV`参数来通过将白色输入值转换为黑色和黑色输入值转换为白色来反转阈值输出。这是获取每个字符轮廓所必需的，因为轮廓算法寻找白色像素。
- en: 'For each detected contour, we can make a size verification and remove all regions
    where the size is smaller or the aspect is not correct. In our case, the characters
    have a 45/77 aspect, and we can accept a 35 percent error of aspect for rotated
    or distorted characters. If an area is higher than 80 percent, we will consider
    that region to be a black block and not a character. For counting the area, we
    can use the `countNonZero` function that counts the number of pixels with a value
    higher than 0:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个检测到的轮廓，我们可以进行大小验证并移除所有大小较小或纵横比不正确的区域。在我们的情况下，字符的纵横比为45/77，我们可以接受旋转或扭曲字符的35%纵横比误差。如果一个区域高于80%，我们将考虑该区域为黑色块而不是字符。对于计数面积，我们可以使用`countNonZero`函数，该函数计算值高于0的像素数量：
- en: '[PRE24]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If a segmented character is verified, we have to preprocess it to set the same
    size and position for all characters, and save it in a vector with the auxiliary
    `CharSegment` class. This class saves the segmented character image and the position
    that we need to order the characters, because the Find Contour algorithm does
    not return the contours in the correct and needed order.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个分割的字符被验证，我们必须对其进行预处理，以设置所有字符相同的大小和位置，并使用辅助`CharSegment`类将其保存为向量。这个类保存了分割字符图像和我们需要按顺序排列字符的位置，因为Find
    Contour算法不会以正确和所需的顺序返回轮廓。
- en: Feature extraction
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取
- en: The next step for each segmented character is to extract the features for training
    and classify the Artificial Neural Network algorithm.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个分割的字符，下一步是提取用于训练的特征并对人工神经网络算法进行分类。
- en: 'Unlike plate detection, the feature extraction step used in SVM doesn''t use
    all of the image pixels. We will apply more common features used in OCR that contain
    horizontal and vertical accumulation histograms and low-resolution image samples.
    We can see this feature more graphically in the next image, as each image has
    a low resolution 5x5 image and the histogram accumulations:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 与车牌检测不同，用于SVM的特征提取步骤不使用所有图像像素。我们将应用在OCR中更常见的特征，这些特征包含水平和垂直累积直方图以及低分辨率图像样本。我们可以在下一张图像中更直观地看到这个特征，因为每个图像都有一个低分辨率的5x5图像和直方图累积：
- en: '![](img/image_04_010.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_010.png)'
- en: 'For each character, we will count the number of pixels in a row or column with
    a nonzero value using the `countNonZero` function and store it in a new data matrix
    called `mhist`. We will normalize it by looking for the maximum value in the data
    matrix using the `minMaxLoc` function and divide all elements of `mhist` by the
    maximum value with the `convertTo` function. We will create the `ProjectedHistogram`
    function to create the accumulation histograms that have a binary image and a
    type of histogram that we need, horizontal or vertical, as input:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个字符，我们将使用`countNonZero`函数计算具有非零值的行或列中的像素数量，并将其存储在名为`mhist`的新数据矩阵中。我们将使用`minMaxLoc`函数查找数据矩阵中的最大值，并使用`convertTo`函数将`mhist`的所有元素除以最大值来归一化。我们将创建`ProjectedHistogram`函数来创建具有二值图像和所需类型的直方图累积，该直方图累积以二进制图像和水平或垂直类型为输入：
- en: '[PRE25]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Other features use a low-resolution sample image. Instead of using the whole
    character image, we will create a low-resolution character, for example, a character
    of 5x5\. We will train the system with 5x5, 10x10, 15x15, and 20x20 characters
    and then evaluate which one returns the best result to use it in our system. Once
    we have all features, we will create a matrix of *M* columns by one row where
    the columns are the features:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 其他特征使用低分辨率样本图像。我们不会使用整个字符图像，而是创建一个低分辨率的字符，例如，一个5x5的字符。我们将使用5x5、10x10、15x15和20x20的字符来训练系统，然后评估哪个返回最佳结果以用于我们的系统。一旦我们有了所有特征，我们将创建一个由一行的*M*列组成的矩阵，其中列是特征：
- en: '[PRE26]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: OCR classification
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OCR分类
- en: In the classification step, we used an Artificial Neural Network machine learning
    algorithm, more specifically, a **Multi-Layer Perceptron** (**MLP**) which is
    the most commonly used ANN algorithm.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类步骤中，我们使用了人工神经网络机器学习算法，更具体地说，是一个**多层感知器**（**MLP**），这是最常用的ANN算法。
- en: MLP consists of a network of neurons with an input layer, output layer, and
    one or more hidden layers. Each layer has one or more neurons connected with the
    previous and next layers.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: MLP由一个包含输入层、输出层和一层或更多隐藏层的神经元网络组成。每一层都通过前一层和后一层的神经元连接。
- en: 'The following example represents a three-layer perceptron (is a binary classifier
    that maps a real-valued vector input to a single binary value output) with three
    inputs, two outputs, and the hidden layer including five neurons:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例表示一个三层感知器（是一个将实值向量输入映射到单个二进制值输出的二分类器），有三个输入、两个输出，隐藏层包含五个神经元：
- en: '![](img/image_04_011.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_011.png)'
- en: 'All neurons in an MLP are similar, and each one has several inputs (the previous
    linked neurons) and several output links with the same value (the next linked
    neurons). Each neuron calculates the output value as a sum of the weighted inputs
    plus a bias term and is transformed by a selected activation function:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: MLP中的所有神经元都是相似的，每个神经元都有几个输入（前一个连接的神经元）和几个具有相同值的输出链接（下一个连接的神经元）。每个神经元通过加权输入的总和加上一个偏置项来计算输出值，并通过选定的激活函数进行转换：
- en: '![](img/image_04_012.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_012.png)'
- en: 'There are three widely used activation functions: Identity, Sigmoid, and Gaussian.
    The most common and default activation function is the Sigmoid function; it has
    an alpha and beta value set to 1:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种广泛使用的激活函数：恒等函数、Sigmoid和高斯。最常见和默认的激活函数是Sigmoid函数；它将alpha和beta值设置为1：
- en: '![](img/image_04_013.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_013.png)'
- en: An ANN-trained network has a vector of input with features; it passes the values
    to the hidden layer and computes the results with the weights and activation function.
    It passes outputs further downstream until it gets the output layer that has the
    number of neurons classes.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 经过训练的ANN网络有一个具有特征的输入向量；它将值传递到隐藏层，并通过权重和激活函数计算结果。它将输出进一步传递到下游，直到它到达具有类别神经元数量的输出层。
- en: 'The weight of each layer, synapses, and neuron is computed and learned by training
    the ANN algorithm. To train our classifier, we will create two matrices of data,
    as we did in the SVM training, but the training labels are a bit different. Instead
    of an *N*x1 matrix, where *N* stands for training data rows and 1 is the column,
    we will use the label number identifier. We have to create an *N*x*M* matrix,
    where *N* is the training/samples data and *M* are the classes (10 digits + 20
    letters in our case), and set 1 in a position *i*, *j* if the data row *i* is
    classified with class *j*:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层的权重、突触和神经元是通过训练ANN算法来计算和学习的。为了训练我们的分类器，我们将创建两个数据矩阵，就像我们在SVM训练中所做的那样，但训练标签略有不同。而不是一个*N*x1的矩阵，其中*N*代表训练数据行数，1是列，我们将使用标签编号标识符。我们必须创建一个*N*x*M*的矩阵，其中*N*是训练/样本数据，*M*是类别（在我们的情况下是10个数字和20个字母），并在位置*i*，*j*处设置1，如果数据行*i*被分类为类别*j*：
- en: '![](img/image_04_014.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_04_014.png)'
- en: We will create an `OCR::train` function to create all needed matrix and train
    our system, with the training data matrix, classes matrix, and the number of hidden
    neurons in the hidden layers. The training data is loaded from an XML file, just
    as we did in SVM training.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个`OCR::train`函数来创建所有需要的矩阵并训练我们的系统，包括训练数据矩阵、类别矩阵和隐藏层中的隐藏神经元数量。训练数据从XML文件中加载，就像我们在SVM训练中所做的那样。
- en: We have to define the number of neurons in each layer to initialize the ANN
    class. For our sample, we will use only one hidden layer. Then, we will define
    a matrix of one row and three columns. The first column position is the number
    of features, the second column position is the number of hidden neurons on the
    hidden layer, and the third column position is the number of classes.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须定义每一层的神经元数量来初始化ANN类。在我们的示例中，我们将只使用一个隐藏层。然后，我们将定义一个一行三列的矩阵。第一列位置是特征数量，第二列位置是隐藏层上的隐藏神经元数量，第三列位置是类别数量。
- en: 'OpenCV defines an `ANN_MLP` class for ANN. With the `create` function, we can
    initiate the class pointer and later define the number of layers and neurons and
    the activation function. We can thencreate the training data like SVM, and `alpha`
    and `beta` parameters of training method:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV定义了一个`ANN_MLP`类用于ANN。使用`create`函数，我们可以初始化类指针，然后定义层数、神经元数量和激活函数。然后我们可以创建像SVM一样的训练数据，以及训练方法的`alpha`和`beta`参数：
- en: '[PRE27]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After training, we can classify any segmented plate features using the `OCR::classify`
    function:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后，我们可以使用`OCR::classify`函数对任何分割的牌照特征进行分类：
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `ANN_MLP` class uses the `predict` function for classifying a feature vector
    in a class. Unlike the SVM `classify` function, the ANN predict function returns
    a row with the size of equal to the number of classes, with the probability of
    belonging the input feature to each class.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`ANN_MLP`类使用`predict`函数对类中的特征向量进行分类。与SVM的`classify`函数不同，ANN预测函数返回一个行大小等于类数量的行，其中包含输入特征属于每个类的概率。'
- en: 'To get the best result, we can use the `minMaxLoc` function to get the max
    and min response, and the position in the matrix. The class of our character is
    specified by the *x* position of higher value:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得最佳结果，我们可以使用`minMaxLoc`函数获取最大和最小响应及其在矩阵中的位置。我们的字符类别由较高值的*x*位置指定：
- en: '![](img/image_04_015.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_04_015.png)'
- en: 'To finish each plate detected, we order its characters and return a string
    with the `str()` function of the `Plate` class, and we can draw it on the original
    image:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成每个检测到的车牌，我们对其字符进行排序，并使用`Plate`类的`str()`函数返回一个字符串，我们可以在原始图像上绘制它：
- en: '[PRE29]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Evaluation
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: Our project is finished. However, when we train a machine learning algorithm
    like OCR, for example, we need to know the best features and parameters to use
    and how to correct the classification, recognition, and detection errors in our
    system.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的项目已经完成。然而，当我们训练像OCR这样的机器学习算法时，例如，我们需要知道最佳特征和参数以及如何纠正系统中的分类、识别和检测错误。
- en: We need to evaluate our system with different situations and parameters and
    evaluate the errors produced in order to get the best parameters that minimize
    those errors.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要用不同的情况和参数评估我们的系统，并评估产生的错误，以便获得最小化这些错误的最佳参数。
- en: 'In this chapter, we evaluated the OCR task with variables: size of low-level
    resolution image feature and the number of hidden neurons in the hidden layer.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用变量评估了OCR任务：低级分辨率图像特征的大小和隐藏层中隐藏神经元的数量。
- en: 'We created the `evalOCR.cpp` application where we uses the XML training data
    file generated by the `trainOCR.cpp` application. The `OCR.xml` file contains
    the training data matrix for 5x5, 10x10, 15x15, and 20x20 downsampled image features:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了`evalOCR.cpp`应用程序，其中我们使用由`trainOCR.cpp`应用程序生成的XML训练数据文件。`OCR.xml`文件包含5x5、10x10、15x15和20x20下采样图像特征的训练数据矩阵：
- en: '[PRE30]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The evaluation application gets each downsampled matrix feature and gets 100
    random rows for traning, as well as other rows for testing the ANN algorithm and
    checking the error.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 评估应用程序获取每个下采样矩阵特征，并为训练获取100个随机行，以及用于测试ANN算法和检查错误的其它行。
- en: 'Before training the system, we will test each random sample and check whether
    the response is correct. If the response is not correct, we increment the error
    counter variable and then divide by the number of samples to evaluate. This indicates
    the error ratio between 0 and 1 for training with random data:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练系统之前，我们将测试每个随机样本并检查其响应是否正确。如果响应不正确，我们将错误计数器变量增加，然后除以样本数量以评估。这表示使用随机数据进行训练的错误率在0到1之间：
- en: '[PRE31]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The application returns output command-line error ratio for each sample size.
    For a good evaluation, we need to train the application with different random
    training rows. This produces different test error values. Then, we can add up
    all the errors and obtain an average. To do this task, we will create the bash
    UNIX script to automate it:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序为每个样本大小返回输出命令行错误率。为了进行良好的评估，我们需要用不同的随机训练行训练应用程序。这会产生不同的测试错误值。然后，我们可以将所有错误加起来并得到平均值。为此任务，我们将创建bash
    UNIX脚本来自动化它：
- en: '[PRE32]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This script saves a `data.txt` file that contains all results for each size
    and neuron hidden layer number. This file can be used for plotting with *gnuplot*.
    We can see the result in the following image:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本保存一个`data.txt`文件，其中包含每个大小和神经元隐藏层数量的所有结果。此文件可用于与*gnuplot*绘图。我们可以在以下图像中看到结果：
- en: '![](img/image_04_016.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_04_016.png)'
- en: We can see that the lowest error is over 8 percent and is using 20 neurons in
    hidden layer and character's features extracted from a downscaled to 10x10 image
    patch.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，最低的错误率超过8%，使用了隐藏层中的20个神经元和从下采样到10x10图像块中提取的字符特征。
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, you learned how an Automatic Plate License Recognition program
    works and its two important steps: plate localization and plate recognition.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了自动车牌识别程序的工作原理及其两个重要步骤：车牌定位和车牌识别。
- en: In the first step, you learned how to segment an image looking for patches where
    we can have a plate, and use a simple heuristics and SVM algorithm to make a binary
    classification for patches with *plates* and *no plates*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，你学习了如何通过寻找可以放置牌照的区域来分割图像，并使用简单的启发式方法和SVM算法对带有*牌照*和*无牌照*的区块进行二分类。
- en: In the second step, you learned how to segment with the Find Contours algorithm,
    extract feature vector from each character, and use an ANN to classify each feature
    in a character class.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，你学习了如何使用查找轮廓算法进行分割，从每个字符中提取特征向量，并使用人工神经网络（ANN）对字符类中的每个特征进行分类。
- en: You also learned how to evaluate a machine algorithm with training with random
    samples, and using different parameters and features.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 你还学习了如何通过随机样本训练和不同的参数及特征来评估机器算法。
- en: In the next chapter, you will learn how to create a face-recognition application
    using eigenfaces.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何使用特征脸创建人脸识别应用程序。
