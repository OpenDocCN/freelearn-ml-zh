<html><head></head><body>
		<div id="_idContainer131">
			<h1 id="_idParaDest-103"><em class="italic"><a id="_idTextAnchor104"/>Chapter 6</em>: Model Building with DataRobot</h1>
			<p>In this chapter, we will see how DataRobot is used to build models. Much of the model-building process has been automated, and DataRobot offers many capabilities to explore a wide range of algorithms automatically, as well as allowing data scientists to fine-tune what they want to build. This results in significant time savings for data science teams and leads to the exploration of many more models than would otherwise be possible. It also leads to better adherence to best practices and hence fewer chances of making mistakes.</p>
			<p>By the end of this chapter, you will have learned how to utilize DataRobot to build a wide range of models. In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Configuring a modeling project</li>
				<li>Building models and the model leaderboard</li>
				<li>Understanding model blueprints</li>
				<li>Building ensemble models</li>
			</ul>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor105"/>Configuring a modeling project</h1>
			<p>In the previous chapter, we created a project and performed data analysis. We also saw that DataRobot automatically<a id="_idIndexMarker288"/> built several models for us. To build these models, we used default project settings.</p>
			<p>In this section, we will cover what DataRobot did for us by default and look at how we can fine-tune that behavior. If you remember, once we click the <strong class="bold">Start</strong> button on the project page (see <em class="italic">Figure 5.1</em> in <a href="B17159_05_Final_NM_ePub.xhtml#_idTextAnchor097"><em class="italic">Chapter 5</em></a>, <em class="italic">Exploratory Data Analysis with DataRobot</em>), we cannot make any changes to the project options. We will therefore create a new project to review and select the options we want. </p>
			<p>For this, let's go into DataRobot and select the <strong class="bold">Create New Project</strong> menu option. Just as before, we will now upload the same automobile dataset file that we used before. This time, you can name the project <strong class="source-inline">Automobile Example 2</strong>, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="image/Figure_6.1_B17159.jpg" alt="Figure 6.1 – Uploading the dataset for a new project&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1 – Uploading the dataset for a new project</p>
			<p>You can select the same<a id="_idIndexMarker289"/> target feature (price) as we did previously. Now, instead of clicking the <strong class="bold">Start</strong> button, please click on <strong class="bold">Show advanced options</strong> at the bottom of the screen. You will now see the <strong class="bold">Advanced Options</strong> screen, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/Figure_6.2_B17159.jpg" alt="Figure 6.2 – Advanced Options&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – Advanced Options</p>
			<p>Here, you can see the partitioning options. You can see the default settings and can change them as needed. Since<a id="_idIndexMarker290"/> the amount of data we have is very limited, I have reduced the number of cross-validation folds to <strong class="source-inline">3</strong> and the holdout percentage to 15%. You can easily change these values and run with a different setup as needed. Next, we click on the <strong class="bold">Smart Downsampling</strong> tab, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/Figure_6.3_B17159.jpg" alt="Figure 6.3 – Smart Downsampling&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.3 – Smart Downsampling</p>
			<p>Given that this is not a classification problem, we need not worry about downsampling here. If you have an imbalanced<a id="_idIndexMarker291"/> dataset for a classification problem, you can use this option to downsample. Let's now look at the <strong class="bold">Feature Constraints</strong> tab, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer106" class="IMG---Figure">
					<img src="image/Figure_6.4_B17159.jpg" alt="Figure 6.4 – Feature Constraints&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.4 – Feature Constraints</p>
			<p>Here, you can set up constraints on features such as monotonicity—that is, whether the target values move in the same direction as the value of a feature increases. At this point, we do not foresee<a id="_idIndexMarker292"/> a need to set such constraints.  Such constraints could be part of regulatory requirements in certain use cases. If they are, they can be specified here. Most use cases do not require such a constraint. Let's now click on the <strong class="bold">Additional</strong> tab, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/Figure_6.5_B17159.jpg" alt="Figure 6.5 – Additional options&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5 – Additional options</p>
			<p>Here, we see an option to change the <strong class="bold">optimization metric</strong> to be used for modeling. I have<a id="_idIndexMarker293"/> found DataRobot's recommendations<a id="_idIndexMarker294"/> to be very good and you should use this option unless you have a compelling business reason to select a different metric. Given that we are in the early stages of modeling and we are interested in understanding our data, we will select the <strong class="bold">Search for interactions</strong> option, unselect the <strong class="bold">Create blenders from top models</strong> option, and select the <strong class="bold">Include only models with SHAP value support</strong> option. As discussed in <a href="B17159_02_Final_NM_ePub.xhtml#_idTextAnchor039"><em class="italic">Chapter 2</em></a>, <em class="italic">Machine Learning Basics</em>, <strong class="bold">SHapley Additive exPlanations</strong> (<strong class="bold">SHAP</strong>) values are helpful for understanding the models and will provide additional insights<a id="_idIndexMarker295"/> into our problem. This might come<a id="_idIndexMarker296"/> at the cost of model accuracy, but we will worry about improving accuracy later. If you scroll down further on this page, you will see even more options, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/Figure_6.6_B17159.jpg" alt="Figure 6.6 – More options&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.6 – More options</p>
			<p>Here, you can set options<a id="_idIndexMarker297"/> to place an upper bound on running time, cap the value of target variable predictions, set a random seed, or add a weighting for a specific feature. For now, we do not see a need to change any of these defaults.</p>
			<p>This completes the configuration process, and we are now ready to build the models.</p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor106"/>Building models and the model leaderboard</h1>
			<p>Once we are done making any changes<a id="_idIndexMarker298"/> to the configuration settings, we can scroll<a id="_idIndexMarker299"/> up and click the <strong class="bold">Start</strong> button. DataRobot will now start automatically building the models, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/Figure_6.7_B17159.jpg" alt="Figure 6.7 – Automated building of models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.7 – Automated building of models</p>
			<p>You can see which models DataRobot is building and how much training data is being used. You will notice that DataRobot will first build quick models with smaller datasets, learn which one performs better, and then selectively build models with more data. In the present case, you<a id="_idIndexMarker300"/> might not see this because there is very little data to begin with. Once DataRobot<a id="_idIndexMarker301"/> is done building the models, it will show the model leaderboard, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/Figure_6.8_B17159.jpg" alt="Figure 6.8 – Model leaderboard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.8 – Model leaderboard</p>
			<p>In the preceding screenshot, you will see which models rise to the top based on the metric you have selected for cross-validations. You can also choose different metrics from the dropdown to see how the models compare for different metrics. You can clearly see which models rose to the top. It is not uncommon to see gradient boosted models in the top tier. You will also notice that the model rankings change a bit based on the metric selected. You will see that once DataRobot has selected a model for deployment, it has unlocked the holdout results and trained the model with 100% data to prepare for deployment. For now, we will ignore that as we are not yet ready to discuss deployment. Another<a id="_idIndexMarker302"/> thing to notice is the feature list used for the top models. You will see that a new <strong class="bold">Informative Features +</strong> feature list has been used. This is a feature<a id="_idIndexMarker303"/> list that DataRobot created for these models. Let's take a look at what this list contains, as follows:</p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/Figure_6.9_B17159.jpg" alt="Figure 6.9 – New feature list&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.9 – New feature list</p>
			<p>As you can see, this list contains a subset of the features, and it also contains a new feature that DataRobot created automatically: <strong class="source-inline">(bore) DIVIDED BY (length)</strong>. This ratio might have<a id="_idIndexMarker304"/> significance for an engine, and you should discuss its role with <strong class="bold">subject-matter experts</strong> (<strong class="bold">SMEs</strong>). If not previously known, this could<a id="_idIndexMarker305"/> represent a new insight for your business team. It turns out that this is called <strong class="bold">stroke ratio</strong> and is considered an important<a id="_idIndexMarker306"/> parameter for engines. The next step in the modeling process is to<a id="_idIndexMarker307"/> see if there is a need to further refine this feature list. Let's go back to the model leaderboard, select the top-performing model <strong class="bold">eXtreme Gradient Boosted Trees Regressor (Gamma Loss)</strong>, go to the <strong class="bold">Understand</strong> tab and select the <strong class="bold">Feature Impact</strong> sub-tab, as illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/Figure_6.10_B17159.jpg" alt="Figure 6.10 – Understand and Feature Impact tabs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.10 – Understand and Feature Impact tabs</p>
			<p>You will see that feature impacts are not computed for every model, so go ahead and click on the <strong class="bold">Enable Feature Impact</strong> button to let DataRobot compute it. Once clicked, DataRobot will start computing the impacts and show you the results, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/Figure_6.11_B17159.jpg" alt="Figure 6.11 – Feature impacts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.11 – Feature impacts</p>
			<p>You will notice that<a id="_idIndexMarker308"/> the feature impacts are computed using SHAP values, which we discussed previously. By default, it shows the top 25 features. We will discuss<a id="_idIndexMarker309"/> the details of the features and the model later on. For now, we want to look at the entire feature set. For this, we will click on the <strong class="bold">Export</strong> button in the bottom-right corner. We will now see the <strong class="bold">Export</strong> option, as illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/Figure_6.12_B17159.jpg" alt="Figure 6.12 – Exporting feature impacts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.12 – Exporting feature impacts</p>
			<p>You can download this information as a <strong class="source-inline">.csv</strong> file to explore it in more detail. Let's use Excel to open the <strong class="source-inline">.csv</strong> file to review the feature impacts, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/Figure_6.13_B17159.jpg" alt="Figure 6.13 – Feature impacts of the entire set&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.13 – Feature impacts of the entire set</p>
			<p>As you can see, the last seven features don't add much, and we can try removing them and see the impact. One<a id="_idIndexMarker310"/> of the benefits of a tool such as DataRobot is that running these<a id="_idIndexMarker311"/> experiments is very quick and easy. Now that we know what we want to do, let's go back to the <strong class="bold">Feature Impact</strong> screen. Notice the <strong class="bold">+ Create feature list</strong> button on the bottom left. Clicking on that button brings up a dialog box for creating a new feature list, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/Figure_6.14_B17159.jpg" alt="Figure 6.14 – Creating a new feature list&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.14 – Creating a new feature list</p>
			<p>Here, we can give the feature list a new name, <strong class="source-inline">FL1 top23</strong>, and specify that we want the 23 best features. Now, we can<a id="_idIndexMarker312"/> click the <strong class="bold">Create feature list</strong> button to save this new feature list. Now that<a id="_idIndexMarker313"/> a new feature list has been created, we can now click on <strong class="bold">Configure Modeling Settings</strong> in the column on the right side of the page. This will bring up the configuration dialog box, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/Figure_6.15_B17159.jpg" alt="Figure 6.15 – Configure Modeling Settings&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.15 – Configure Modeling Settings</p>
			<p>We can now select the new feature list, <strong class="source-inline">FL1 top23</strong>, from the dropdown. We can modify the other settings if we need<a id="_idIndexMarker314"/> and click the <strong class="bold">Run</strong> button. DataRobot will now start building models<a id="_idIndexMarker315"/> with the new feature list and when the process completes, you can see the new models in the leaderboard, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/Figure_6.16_B17159.jpg" alt="Figure 6.16 – Leaderboard with new models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.16 – Leaderboard with new models</p>
			<p>As you can see, the model built with the new feature list did better and is now at the top of the leaderboard (ignore the deployment-ready model, as it uses the entire dataset). As we can see, removing features<a id="_idIndexMarker316"/> that did not contribute much actually helped the model (even if just a little). Given that this model uses a smaller set of features, it is a more desirable<a id="_idIndexMarker317"/> model. We can continue this process as needed. At this point, we also start looking more deeply at the model's details and the results it is producing. We will come back to that topic in the next chapter. For now, we want to look at the model blueprints or the steps DataRobot takes to build a model.</p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor107"/>Understanding model blueprints</h1>
			<p>DataRobot performs a lot<a id="_idIndexMarker318"/> of data transformations and hyperparameter tuning while building a model. It leverages a lot of best practices to build a specific type of model, and these best practices are codified in the form of blueprints. You can inspect these blueprints to gain insights into these best practices and also to better understand which steps were taken to build a model. To inspect the blueprint for a model, you can click on a model, go to the <strong class="bold">Describe</strong> tab, and then select the <strong class="bold">Blueprint</strong> tab, as illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/Figure_6.17_B17159.jpg" alt="Figure 6.17 – Model blueprint&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.17 – Model blueprint</p>
			<p>Here, you can see the workflow steps. As you can see, this blueprint is fairly simple. This is because gradient boost methods are very flexible and do not require a lot of preprocessing. Let's look at another model that did pretty well, the <strong class="bold">Generalized Additive2 Model (Gamma Loss)</strong> blueprint, as illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/Figure_6.18_B17159.jpg" alt="Figure 6.18 – Model blueprint for Generalized Additive2 Model (Gamma Loss)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.18 – Model blueprint for Generalized Additive2 Model (Gamma Loss)</p>
			<p>Here, you can see that preprocessing<a id="_idIndexMarker319"/> was required for categorical variables<a id="_idIndexMarker320"/> and also for missing values. Let's now look at another blueprint for a <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) model. Select the <strong class="bold">Keras Slim Residual Neural Network Regressor using Training Schedule</strong> model and select the <strong class="bold">Blueprint</strong> tab, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/Figure_6.19_B17159.jpg" alt="Figure 6.19 – Model blueprint for Keras&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.19 – Model blueprint for Keras</p>
			<p>You can see that for Keras, we need to perform data cleansing, scaling, and one-hot encoding for categorical<a id="_idIndexMarker321"/> variables. You can inspect the details of each of these steps by clicking on the model box, as illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="image/Figure_6.20_B17159.jpg" alt="Figure 6.20 – Process step details&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.20 – Process step details</p>
			<p>You can now see an explanation of which tasks were performed and which hyperparameter settings were used for building the model. There is also a link to additional details about the method used. After inspecting the blueprints, you might see that one of your favorite algorithms<a id="_idIndexMarker322"/> was not used by DataRobot, and you might wonder what the performance of that algorithm or model might look like. To do this, you can click on the <strong class="bold">Repository</strong> tab at the top left of the page, as illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer123" class="IMG---Figure">
					<img src="image/Figure_6.21_B17159.jpg" alt="Figure 6.21 – Repository of blueprints&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.21 – Repository of blueprints</p>
			<p>Here, you will see all the blueprints DataRobot has to offer that are relevant to this project. As you can see, this is a pretty comprehensive list. Please note that this list will vary for projects of different types (for example, a time-series project). You can select any one of these blueprints and build a model. The new model will be shown on the leaderboard, where you can assess its relative performance. For now, we are not interested in doing that for this particular project.</p>
			<p>We are interested at this point<a id="_idIndexMarker323"/> in comparing some of the models to see how well they compare at a more detailed level. For this, let's click on the rightmost tab at the top, called <strong class="bold">Model Comparison</strong>. This brings up a page where you can select any two models to see how they match up, as illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/Figure_6.22_B17159.jpg" alt="Figure 6.22 – Model Comparison&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.22 – Model Comparison</p>
			<p>Here, we have selected the XGBoost model and the <strong class="bold">generalized additive model</strong> (<strong class="bold">GAM</strong>) model for comparison across multiple<a id="_idIndexMarker324"/> metrics. We can see that the two models are not too far apart, and you can select either one depending on other factors. As we discussed previously, GAMs have the advantage of being easy<a id="_idIndexMarker325"/> to explain to business users and can be presented as a factor <strong class="bold">lookup table</strong> (<strong class="bold">LUT</strong>), sometimes called a rating table. There might also be regulatory reasons to select a GAM model. Let's explore a bit further by clicking on the <strong class="bold">Compute dual lift data</strong> button, to take us to the following screen:</p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/Figure_6.23_B17159.jpg" alt="Figure 6.23 – Dual lift chart&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.23 – Dual lift chart</p>
			<p><strong class="bold">Dual lift charts</strong> are used to compare the results of two models. For a dual lift chart, the results are sorted<a id="_idIndexMarker326"/> by the difference between the two models as opposed to the target value. The values are then binned to display the results for each bin. The shaded area depicts the difference<a id="_idIndexMarker327"/> between the two models. Here, again, we see that the two models are very similar in their performance.</p>
			<p>If two models have overall good scores but show large deviations in values in this chart, then these models will be good candidates for creating an ensemble model.</p>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor108"/>Building ensemble models</h1>
			<p>It is well known that ensembles of models tend to perform better and also tend to be more robust. DataRobot<a id="_idIndexMarker328"/> provides the capability to automatically build ensemble models; however, this does require some trade-offs. For example, ensemble models take more time and computational resources to build and deploy, and they also tend to be more opaque. This is the reason we did not start off by building ensemble models. Once you have built several models and you are interested in ways of improving your model accuracy, you can decide to build ensembles. As we saw in the previous sections, we have to explicitly select the option to build ensembles, and that also means that we cannot compute SHAP values. Let's look at how this is done. Let's first go to the project list page, which shows all of your current projects, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/Figure_6.24_B17159.jpg" alt="Figure 6.24 – Project list&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.24 – Project list</p>
			<p>Here, we will select the <strong class="bold">Actions</strong> icon for the project that we have been working on, which is <strong class="source-inline">Automobile Example 2</strong>. From the menu, we will select the <strong class="bold">Duplicate</strong> option. You will now see the <strong class="bold">Duplicate</strong> dialog box, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/Figure_6.25_B17159.jpg" alt="Figure 6.25 – Duplicating a project&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.25 – Duplicating a project</p>
			<p>We can give it a new name, <strong class="source-inline">Automobile Example 3</strong>, and we will select <strong class="bold">Copy dataset only</strong>. This way, we can<a id="_idIndexMarker329"/> apply new project settings. Let's click <strong class="bold">Confirm</strong>. This will create a new project. We can select the target as price, and now we click on the <strong class="bold">Advanced Options</strong> tab, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/Figure_6.26_B17159.jpg" alt="Figure 6.26 – Advanced options for ensembles (blenders)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.26 – Advanced options for ensembles (blenders)</p>
			<p>This time, we will select the <strong class="bold">Create blenders from top models</strong> option and uncheck the <strong class="bold">Include only models with SHAP value support</strong> option. Now, we can click the <strong class="bold">Start</strong> button to let DataRobot<a id="_idIndexMarker330"/> build the models. Once DataRobot has finished building the models, we can inspect the leaderboard, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/Figure_6.27_B17159.jpg" alt="Figure 6.27 – Leaderboard with ensemble models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.27 – Leaderboard with ensemble models</p>
			<p>You will notice the DataRobot has built an <strong class="bold">AVG Blender</strong> model that seems to be the top model, but not by much. Blended<a id="_idIndexMarker331"/> models can sometimes produce substantial lift over individual models, so it is worthwhile exploring this option. We can select this model and click on the <strong class="bold">Describe</strong> tab and then the <strong class="bold">Blueprint</strong> tab, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/Figure_6.28_B17159.jpg" alt="Figure 6.28 – Blueprint for AVG Blender&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.28 – Blueprint for AVG Blender</p>
			<p>We can now see that the blender has selected two XGBoost models, and hence it is not surprising that the lift<a id="_idIndexMarker332"/> is not much better. In this case, we will not select the blended model, and we go back to the previous project.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor109"/>Summary</h1>
			<p>In this chapter, we learned how to build and compare models by leveraging DataRobot's capabilities. As you saw, DataRobot makes it very easy to build many models quickly and helps us compare those models. As you experienced, we tried many things and built dozens of models. This rapid model exploration is DataRobot's key capability, and its importance to a data science team cannot be overstated. If you were to build these models on your own in Python, it would have taken a lot more time and effort. Instead, we used that time and thinking to experiment with different ideas and put more energy toward understanding the problem. We also learned about blueprints that encode best practices. These blueprints can be useful learning tools for new and experienced data scientists alike. We also learned how DataRobot can build ensemble or blended models for us.</p>
			<p>It might be tempting to jump ahead and start deploying one of these models, but it is important to not directly jump into that without doing some analysis. We are now ready to dig deeper into the models, understand them, and see if we can gain more insights from them.</p>
		</div>
	</body></html>