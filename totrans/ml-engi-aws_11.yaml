- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Machine Learning Pipelines with SageMaker Pipelines
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Pipelines 的机器学习流水线
- en: In [*Chapter 10*](B18638_10.xhtml#_idTextAnchor215), *Machine Learning Pipelines
    with Kubeflow on Amazon EKS*, we used **Kubeflow**, **Kubernetes**, and **Amazon
    EKS** to build and run an end-to-end **machine learning** (**ML**) pipeline. Here,
    we were able to automate several steps in the ML process inside a running Kubernetes
    cluster. If you are wondering whether we can also build ML pipelines using the
    different features and capabilities of **SageMaker**, then the quick answer to
    that would be *YES*!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 10 章*](B18638_10.xhtml#_idTextAnchor215) 中，*使用 Amazon EKS 上的 Kubeflow
    的机器学习流水线*，我们使用了 **Kubeflow**、**Kubernetes** 和 **Amazon EKS** 来构建和运行一个端到端的 **机器学习**（**ML**）流水线。在这里，我们能够在运行的
    Kubernetes 集群中自动化 ML 过程中的几个步骤。如果你想知道我们是否也可以使用 **SageMaker** 的不同特性和功能来构建 ML 流水线，那么对这个问题的快速回答将是
    *YES*！
- en: In this chapter, we will use **SageMaker Pipelines** to build and run automated
    ML workflows. In addition to this, we will demonstrate how we can utilize **AWS
    Lambda** functions to deploy trained models to new (or existing) ML inference
    endpoints during pipeline execution.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 **SageMaker Pipelines** 来构建和运行自动化的机器学习工作流程。此外，我们还将演示如何在流水线执行期间利用
    **AWS Lambda** 函数将训练好的模型部署到新的（或现有的）机器学习推理端点。
- en: 'That said, in this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，在本章中，我们将涵盖以下主题：
- en: Diving deeper into SageMaker Pipelines
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入了解 SageMaker Pipelines
- en: Preparing the essential prerequisites
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备基本先决条件
- en: Running our first pipeline with SageMaker Pipelines
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SageMaker Pipelines 运行第一个流水线
- en: Creating Lambda functions for deployment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用于部署的 Lambda 函数
- en: Testing our ML inference endpoint
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试我们的机器学习推理端点
- en: Completing the end-to-end ML pipeline
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成端到端的机器学习流水线
- en: Cleaning up
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理
- en: Recommended strategies and best practices
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐策略和最佳实践
- en: After completing the hands-on solutions in this chapter, we should be equipped
    with the skills required to build more complex ML pipelines and workflows on AWS
    using the different capabilities of **Amazon SageMaker**!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章的动手实践解决方案后，我们应该具备使用 **Amazon SageMaker** 的不同功能构建更复杂的机器学习流水线和工作流程的技能！
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Before we start, it is important that we have the following ready:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，重要的是我们以下准备工作已经就绪：
- en: A web browser (preferably Chrome or Firefox)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一款网络浏览器（最好是 Chrome 或 Firefox）
- en: Access to the AWS account and the **SageMaker Studio** domain used in the previous
    chapters of this book
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问本书前几章中使用的 AWS 账户和 **SageMaker Studio** 域
- en: A text editor (for example, **VS Code**) on your local machine that we will
    use for storing and copying string values for later use in this chapter
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你的本地机器上安装一个文本编辑器（例如，**VS Code**），我们将用它来存储和复制字符串值，以便在本章的后续使用中
- en: The Jupyter notebooks, source code, and other files used for each chapter are
    available in the repository at [https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 每章使用的 Jupyter 笔记本、源代码和其他文件可在以下存储库中找到：[https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS)。
- en: Important Note
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It is recommended that you use an IAM user with limited permissions instead
    of the root account when running the examples in this book. If you are just starting
    out with using AWS, you can proceed with using the root account in the meantime.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 建议在运行本书中的示例时，使用具有有限权限的 IAM 用户，而不是根账户。如果你刚开始使用 AWS，你可以暂时使用根账户。
- en: Diving deeper into SageMaker Pipelines
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解 SageMaker Pipelines
- en: 'Often, data science teams start by performing ML experiments and deployments
    manually. Once they need to standardize the workflow and enable **automated model
    retraining** to refresh the deployed models regularly, these teams would then
    start considering the use of ML pipelines to automate a portion of their work.
    In [*Chapter 6*](B18638_06.xhtml#_idTextAnchor132), *SageMaker Training and Debugging
    Solutions*, we learned how to use the **SageMaker Python SDK** to train an ML
    model. Generally, training an ML model with the SageMaker Python SDK involves
    running a few lines of code similar to what we have in the following block of
    code:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据科学团队会从手动执行 ML 实验和部署开始。一旦他们需要标准化工作流程并启用 **自动模型重新训练** 以定期刷新已部署的模型，这些团队就会开始考虑使用
    ML 流水线来自动化他们工作的一部分。在 [*第 6 章*](B18638_06.xhtml#_idTextAnchor132) 中，*SageMaker
    训练和调试解决方案*，我们学习了如何使用 **SageMaker Python SDK** 训练一个 ML 模型。通常，使用 SageMaker Python
    SDK 训练 ML 模型涉及运行几行代码，类似于以下代码块：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*What if we wanted to prepare an automated ML pipeline and include this as
    one of the steps?* You would be surprised that all we need to do is add a few
    lines of code to convert this into a step that can be included in a pipeline!
    To convert this into a step using `TrainingStep` object similar to what we have
    in the following block of code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果我们想准备一个自动化的ML管道并将其作为步骤之一包含在内，会怎么样？* 您可能会惊讶，我们只需要添加几行代码就可以将其转换为可以包含在管道中的步骤！要将此转换为使用`TrainingStep`对象（类似于以下代码块中的内容）的步骤：'
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Wow! Isn’t that amazing?* This would mean that existing notebooks using the
    **SageMaker Python SDK** for manually training and deploying ML models can easily
    be converted into using SageMaker Pipelines using a few additional lines of code!
    *What about the other steps?* We have the following classes, as well:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*哇！这不是很神奇吗？* 这意味着使用**SageMaker Python SDK**手动训练和部署ML模型的现有笔记本可以很容易地通过添加几行代码转换为使用SageMaker管道！*其他步骤呢？*
    我们还有以下类：'
- en: '`ProcessingStep` – This is for processing data using **SageMaker Processing**.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProcessingStep` – 这是为了使用**SageMaker处理**处理数据。'
- en: '`TuningStep` – This is for creating a hyperparameter tuning job using the **Automatic
    Model Tuning** capability of SageMaker.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TuningStep` – 这是为了使用SageMaker的**自动模型调优**功能创建超参数调优作业。'
- en: '`ModelStep` – This is for creating and registering a SageMaker model to the
    **SageMaker Model Registry**.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ModelStep` – 这是为了创建并将SageMaker模型注册到**SageMaker模型注册表**。'
- en: '`TransformStep` – This is for running inference on a dataset using the **Batch
    Transform** capability of SageMaker.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TransformStep` – 这是为了使用SageMaker的**批量转换**功能在数据集上运行推理。'
- en: '`ConditionStep` – This is for the conditional branching support of the execution
    of pipeline steps.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ConditionStep` – 这是为了支持执行管道步骤的条件分支。'
- en: '`CallbackStep` – This is for incorporating custom steps not directly available
    or supported in SageMaker Pipelines.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CallbackStep` – 这是为了在SageMaker管道中包含不直接可用或受支持的定制步骤。'
- en: '`LambdaStep` – This is for running an **AWS Lambda** function.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LambdaStep` – 这是为了运行**AWS Lambda**函数。'
- en: Note
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Note that this is not an exhaustive list of steps as there are other steps that
    can be used for more specific use cases. You can find the complete list of **SageMaker
    Pipeline Steps** at [https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.xhtml).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这并不是步骤的完整列表，因为还有其他步骤可以用于更具体的用例。您可以在[https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.xhtml)找到**SageMaker管道步骤**的完整列表。
- en: 'In [*Chapter 4*](B18638_04.xhtml#_idTextAnchor079), *Serverless Data Management
    on AWS*, we stored and queried our data inside a Redshift cluster and in an Athena
    table. If we need to directly query data from these data sources, we can use `ProcessingStep`
    object, which will be added later on to the pipeline. Once the processing job
    completes, it stores the output files in S3, which can then be picked up and processed
    by a training job or an automatic model tuning job. If we need to convert this
    into a step, we can create a corresponding `TrainingStep` object (if we will be
    running a training job) or a `TuningStep` object (if we will be running an automatic
    model tuning job), which would then be added later to the pipeline. *What happens
    after the training (or tuning) job completes?* We have the option to store the
    resulting model inside the `ModelStep` object that would then be added later to
    the pipeline, too. Let’s refer to *Figure 11.1* to help us visualize how this
    all works once we’ve prepared the different steps of the pipeline:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B18638_04.xhtml#_idTextAnchor079) *AWS上的无服务器数据管理*中，我们在Redshift集群和Athena表中存储和查询我们的数据。如果我们需要直接从这些数据源查询数据，我们可以使用`ProcessingStep`对象，该对象稍后将添加到管道中。一旦处理作业完成，它将输出文件存储在S3中，然后可以被训练作业或自动模型调优作业拾取和处理。如果我们需要将其转换为步骤，我们可以创建相应的`TrainingStep`对象（如果我们将运行训练作业）或`TuningStep`对象（如果我们将运行自动模型调优作业），然后稍后将其添加到管道中。*训练（或调优）作业完成后会发生什么？*
    我们可以选择将生成的模型存储在随后将添加到管道中的`ModelStep`对象中。让我们参考*图11.1*来帮助我们可视化一旦我们准备好了管道的不同步骤，这一切是如何工作的：
- en: '![Figure 11.1 – Using SageMaker Pipelines ](img/B18638_11_001.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图11.1 – 使用SageMaker管道](img/B18638_11_001.jpg)'
- en: Figure 11.1 – Using SageMaker Pipelines
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 – 使用SageMaker管道
- en: 'In *Figure 11.1*, we can see that `Pipeline` object, which maps to the ML pipeline
    definition:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图11.1*中，我们可以看到`Pipeline`对象，它映射到ML管道定义：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, to run the pipeline, all we need to do is call the `start()` method:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，要运行管道，我们只需要调用 `start()` 方法：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Once the pipeline starts, we would have to wait for all steps to finish executing
    (one step at a time) or for the pipeline to stop if an error occurs in one of
    the steps. To debug and troubleshoot running pipelines, we can easily navigate
    to the **SageMaker Resources** pane of **SageMaker Studio** and locate the corresponding
    pipeline resource. We should see a diagram corresponding to the pipeline execution
    that is similar to what we have in *Figure 11.2*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦管道开始，我们就必须等待所有步骤完成执行（一次一个步骤）或如果某个步骤发生错误，则停止管道。要调试和故障排除正在运行的管道，我们可以轻松地导航到 **SageMaker
    Studio** 的 **SageMaker 资源** 选项卡，并找到相应的管道资源。我们应该看到一个与 *图 11.2* 中类似的管道执行图。
- en: '![Figure 11.2 – Pipeline execution ](img/B18638_11_002.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – 管道执行](img/B18638_11_002.jpg)'
- en: Figure 11.2 – Pipeline execution
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – 管道执行
- en: Here, we can see that all steps in the pipeline have been completed successfully,
    and the model we trained has been registered to the SageMaker Model Registry,
    too. If we wish to run the pipeline again (for example, using a different input
    dataset), we can simply trigger another pipeline execution and pass a different
    pipeline parameter value that points to where the new input dataset is stored.
    *Pretty cool, huh?* In addition to this, we can also dive deeper into what’s happening
    (or what happened) in each of the steps by clicking on the corresponding rounded
    rectangle of the step we wish to check, and then reviewing the input parameters,
    the output values, the ML metric values, the hyperparameters used to train the
    model, and the logs generated during the execution of the step. This allows us
    to understand what’s happening during the execution of the pipeline and troubleshoot
    issues when errors are encountered in the middle of a pipeline execution.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到管道中的所有步骤都已成功完成，我们训练的模型也已注册到 SageMaker 模型注册表中。如果我们希望再次运行管道（例如，使用不同的输入数据集），我们只需触发另一个管道执行，并传递一个不同的管道参数值，该参数值指向新输入数据集的存储位置。*真酷，不是吗？*
    此外，我们还可以通过单击我们想要检查的步骤对应的圆形矩形，深入了解每个步骤中发生的情况（或已发生的情况），然后查看输入参数、输出值、机器学习指标值、用于训练模型的超参数以及步骤执行期间生成的日志。这使我们能够了解管道执行期间发生的情况，并在管道执行过程中遇到错误时进行故障排除。
- en: 'So far, we’ve been talking about a relatively simple pipeline involving three
    or four steps executed sequentially. Additionally, **SageMaker Pipelines** allows
    us to build more complex ML pipelines that utilize conditional steps similar to
    what we have in *Figure 11.3*:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在讨论一个相对简单的管道，该管道包含三个或四个步骤，这些步骤是顺序执行的。此外，**SageMaker Pipelines** 允许我们构建更复杂的机器学习管道，这些管道利用类似于我们在
    *图 11.3* 中的条件步骤：
- en: '![](img/B18638_11_003.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18638_11_003.jpg)'
- en: Figure 11.3 – An ML pipeline with a conditional step
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – 带有条件步骤的机器学习管道
- en: 'Here, using a `ConditionStep`, the pipeline checks whether an ML inference
    endpoint exists already (given the endpoint name) and performs one of the following
    steps depending on the existence of the endpoint:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用 `ConditionStep`，管道检查是否存在机器学习推理端点（给定端点名称），并根据端点的存在与否执行以下步骤之一：
- en: '*Deploy model to a new endpoint* – Using `LambdaStep`, which maps to an **AWS
    Lambda** function that deploys the ML model to a new ML inference endpoint if
    the endpoint does not exist yet'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*部署模型到新端点* – 使用 `LambdaStep`，它映射到一个 **AWS Lambda** 函数，如果端点尚不存在，则将机器学习模型部署到新的机器学习推理端点'
- en: '*Deploy model to an existing endpoint* – Using a `LambdaStep`, which maps to
    an **AWS Lambda** function that deploys the ML model to an existing ML inference
    endpoint if the endpoint already exists (with **zero downtime deployment**)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*部署模型到现有端点* – 使用 `LambdaStep`，它映射到一个 **AWS Lambda** 函数，如果端点已经存在（**零停机时间部署**），则将机器学习模型部署到现有的机器学习推理端点'
- en: '*Cool right?* *What’s cooler is that this is the pipeline we will build in
    this chapter!* Building an ML pipeline might seem intimidating at first. However,
    as long as we iteratively build and test the pipeline and use the right set of
    tools, we should be able to come up with the ML pipeline we need to automate the
    manual processes.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*酷吧？* *更酷的是，这正是本章我们将要构建的管道!* 构建机器学习管道可能一开始会让人感到害怕。然而，只要我们迭代地构建和测试管道，并使用正确的工具集，我们就应该能够构建出我们需要的机器学习管道，以自动化手动流程。'
- en: Now that we have a better understanding of how **SageMaker Pipelines** works,
    let’s proceed with the hands-on portion of this chapter.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们对 **SageMaker Pipelines** 的工作原理有了更好的理解，让我们继续进行本章的动手部分。
- en: Note
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: At this point, you might be wondering why we should use **SageMaker Pipelines**
    instead of **Kubeflow** and **Kubernetes**. One of the major differences between
    SageMaker Pipelines and Kubeflow is that the instances used to train ML models
    in SageMaker automatically get deleted after the training step completes. This
    helps reduce the overall cost since these training instances are only expected
    to run when models need to be trained. On the other hand, the infrastructure required
    by Kubeflow needs to be up and running before any of the training steps can proceed.
    Note that this is just one of the differences, and there are other things to consider
    when choosing the “right” tool for the job. Of course, there are scenarios where
    a data science team would choose Kubeflow instead since the members are already
    comfortable with the usage of Kubernetes (or they are running production Kubernetes
    workloads already). To help you and your team assess these tools properly, I would
    recommend that, first, you try building sample ML pipelines using both of these
    options.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你可能想知道为什么我们应该使用 **SageMaker Pipelines** 而不是 **Kubeflow** 和 **Kubernetes**。SageMaker
    Pipelines 与 Kubeflow 之间的一个主要区别是，在 SageMaker 中用于训练 ML 模型的实例在训练步骤完成后会自动删除。这有助于降低总体成本，因为这些训练实例仅在需要训练模型时才运行。另一方面，Kubeflow
    所需的基础设施需要在任何训练步骤开始之前就绪。请注意，这只是其中之一的不同之处，在选择“正确”的工具时还有其他需要考虑的事项。当然，在某些情况下，数据科学团队可能会选择
    Kubeflow，因为团队成员已经熟悉 Kubernetes 的使用（或者他们已经在运行生产 Kubernetes 工作负载）。为了帮助您和您的团队正确评估这些工具，我建议首先尝试使用这两种选项构建示例
    ML 管道。
- en: Preparing the essential prerequisites
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备基本先决条件
- en: 'In this section, we will ensure that the following prerequisites are ready:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将确保以下先决条件已准备就绪：
- en: The SageMaker Studio Domain execution role with the `AWSLambda_FullAccess` AWS
    managed permission policy attached to it – This will allow the Lambda functions
    to run without issues in the *Completing the end-to-end ML pipeline* section of
    this chapter.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 附有 `AWSLambda_FullAccess` AWS 管理权限策略的 SageMaker Studio 域执行角色 – 这将允许 Lambda 函数在本章的
    *完成端到端 ML 管道* 部分中无问题地运行。
- en: The IAM role (`pipeline-lambda-role`) – This will be used to run the Lambda
    functions in the *Creating Lambda Functions for Deployment* section of this chapter.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IAM 角色 (`pipeline-lambda-role`) – 这将在本章的 *创建部署 Lambda 函数* 部分中用于运行 Lambda 函数。
- en: The `processing.py` file – This will be used by the **SageMaker Processing**
    job to process the input data and split it into training, validation, and test
    sets.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processing.py` 文件 – 这将由 **SageMaker 处理** 作业用于处理输入数据并将其分割成训练集、验证集和测试集。'
- en: The `bookings.all.csv` file – This will be used as the input dataset for the
    ML pipeline.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bookings.all.csv` 文件 – 这将作为 ML 管道的输入数据集。'
- en: Important Note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In this chapter, we will create and manage our resources in the `us-west-2`)
    region. Make sure that you have set the correct region before proceeding with
    the next steps.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将创建并管理我们在 `us-west-2` 区域的资源。在继续下一步之前，请确保您已设置正确的区域。
- en: 'Preparing these essential prerequisites is critical to ensure that we won’t
    encounter unexpected blockers while preparing and running the ML pipelines in
    this chapter. That said, let’s proceed with preparing the prerequisites in the
    next set of steps:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 准备这些基本先决条件对于确保我们在本章准备和运行 ML 管道时不会遇到意外的阻碍至关重要。话虽如此，让我们继续在下一组步骤中准备这些先决条件：
- en: Let’s start by navigating to the `sagemaker studio` in the search bar of the
    AWS Management Console, hovering over the search result box for **Amazon SageMaker**,
    and then clicking on the **SageMaker Studio** link under **Top features**.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从在 AWS 管理控制台的搜索栏中导航到 `sagemaker studio` 开始，将鼠标悬停在搜索结果框的 **Amazon SageMaker**
    上，然后点击 **Top features** 下的 **SageMaker Studio** 链接。
- en: 'On the SageMaker Studio **Control Panel** page, locate the **Execution role**
    section attached to the **Domain** box (as highlighted in *Figure 11.4*):'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio **控制面板** 页面上，找到附着在 **域** 框旁边的 **执行角色** 部分（如图 11.4 所示）：
- en: '![Figure 11.4 – Copying the Execution role name ](img/B18638_11_004.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – 复制执行角色名称](img/B18638_11_004.jpg)'
- en: Figure 11.4 – Copying the Execution role name
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 复制执行角色名称
- en: 'Locate and copy the following values into a text editor on your local machine:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 定位并复制以下值到您的本地机器上的文本编辑器中：
- en: '`arn:aws:iam::<ACCOUNT ID>:role/service-role/`). The execution role name might
    follow the `AmazonSageMaker-ExecutionRole-<DATETIME>` format similar to what we
    have in *Figure 11.4*. Make sure that you exclude `arn:aws:iam::<ACCOUNT ID>:role/service-role/`
    when copying the execution role name.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`arn:aws:iam::<ACCOUNT ID>:role/service-role/`。执行角色名称可能遵循类似于图11.4中的`AmazonSageMaker-ExecutionRole-<DATETIME>`格式。确保在复制执行角色名称时排除`arn:aws:iam::<ACCOUNT
    ID>:role/service-role/`。'
- en: '`arn:aws:iam::<ACCOUNT ID>:role/service-role/`). The execution role ARN should
    follow the `arn:aws:iam::<ACCOUNT ID>:role/service-role/AmazonSageMaker-ExecutionRole-<DATETIME>`
    format.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`arn:aws:iam::<ACCOUNT ID>:role/service-role/`。执行角色ARN应遵循`arn:aws:iam::<ACCOUNT
    ID>:role/service-role/AmazonSageMaker-ExecutionRole-<DATETIME>`格式。'
- en: Note
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We will use the Execution role ARN when testing the Lambda functions in the
    *Creating Lambda functions for deployment* section of this chapter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的**创建用于部署的Lambda函数**部分测试Lambda函数时使用执行角色ARN。
- en: Navigate to the `iam` into the search bar of the AWS Management Console, hovering
    over the search result box for **IAM**, and then clicking on the **Roles** link
    under **Top features**.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到AWS管理控制台的搜索栏中的`iam`，将鼠标悬停在**IAM**的搜索结果框上，然后单击**角色**链接下的**顶级功能**。
- en: 'On the **Roles** page, search and locate the execution role by typing the execution
    role name (which is copied to the text editor on your local machine) into the
    search box (as highlighted in *Figure 11.5*):'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**角色**页面，通过在搜索框中输入执行角色名称（该名称已复制到您的本地机器上的文本编辑器中）来搜索并定位执行角色（如图11.5所示）：
- en: '![Figure 11.5 – Navigating to the specific role page ](img/B18638_11_005.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图11.5 – 导航到特定角色页面](img/B18638_11_005.jpg)'
- en: Figure 11.5 – Navigating to the specific role page
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 – 导航到特定角色页面
- en: This should filter the results and display a single row that is similar to what
    we have in *Figure 11.5*. Click on the link under the **Role name** column to
    navigate to the page where we can modify the permissions of the role.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会过滤结果并显示一行类似于图11.5中的行。单击**角色名称**列下的链接以导航到可以修改角色权限的页面。
- en: Locate the **Permissions policies** table (inside the **Permissions** tab),
    and then click on **Add permissions** to open a drop-down menu of options. Select
    **Attach policies** from the list of available options. This should redirect us
    to the page where we can see the **Current permissions policies** section and
    attach additional policies under **Other permissions policies**.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定位到**权限策略**表（在**权限**选项卡内），然后单击**添加权限**以打开一个选项的下拉菜单。从可用选项中选择**附加策略**。这应该会带我们到可以查看**当前权限策略**部分的页面，并在**其他权限策略**下附加额外的策略。
- en: Locate the `AWSLambda_FullAccess` AWS managed permission policy using the search
    bar (under `AWSLambda_FullAccess` policy. After that, click on the **Attach policies**
    button.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用搜索栏（在`AWSLambda_FullAccess`策略下）查找`AWSLambda_FullAccess` AWS托管权限策略。之后，单击**附加策略**按钮。
- en: Note
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You should see the following success notification message after clicking on
    the **Attach policies** button, **Policy was successfully attached to role**.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在单击**附加策略**按钮后，您应该会看到以下成功通知消息：**策略已成功附加到角色**。
- en: Now, let’s create the IAM role that we will use later when creating the Lambda
    functions. Navigate to the **Roles** page (using the sidebar) and then click on
    the **Create role** button.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建我们将用于创建Lambda函数的IAM角色。导航到**角色**页面（使用侧边栏）然后单击**创建角色**按钮。
- en: 'On the **Select trusted entity** page (*step 1*), perform the following steps:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**选择受信任实体**页面（*步骤1*），执行以下步骤：
- en: Under **Trusted entity type**, choose **AWS service** from the list of options
    available.
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**受信任实体类型**下，从可用选项中选择**AWS服务**。
- en: Under **Use case**, select **Lambda** under **Common use cases**.
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**用例**下，从**常用用例**中选择**Lambda**。
- en: Afterward, click on the **Next** button.
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 之后，单击**下一步**按钮。
- en: In the `AmazonSageMakerFullAccess` policy.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`AmazonSageMakerFullAccess`策略中。
- en: Search and select the `AWSLambdaExecute` policy.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索并选择`AWSLambdaExecute`策略。
- en: After toggling on the radio buttons for the two policies, click on the **Next**
    button.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在切换两个策略的单选按钮后，单击**下一步**按钮。
- en: On the `pipeline-lambda-role` under **Role name**.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**角色名称**下的`pipeline-lambda-role`。
- en: Scroll down to the bottom of the page, and then click on the **Create role**
    button.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到页面底部，然后单击**创建角色**按钮。
- en: Note
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You should see the following success notification message after clicking on
    the **Create role** button: **Role pipeline-lambda-role created**.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在点击**创建角色**按钮后，您应该会看到以下成功通知消息：**角色pipeline-lambda-role已创建**。
- en: Navigate back to the `sagemaker studio` into the search bar of the AWS Management
    Console and then clicking on the **SageMaker Studio** link under **Top features**
    (after hovering over the search result box for **Amazon SageMaker**).
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航回AWS管理控制台的搜索栏中的`sagemaker studio`，然后点击**顶级功能**下的**SageMaker Studio**链接（在悬停于**Amazon
    SageMaker**搜索结果框上方时）。
- en: Click on **Launch app** and then select **Studio** from the list of drop-down
    options.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**启动应用**，然后从下拉选项中选择**Studio**。
- en: Note
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This will redirect you to **SageMaker Studio**. Wait for a few seconds for the
    interface to load.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将带您进入**SageMaker Studio**。等待几秒钟，直到界面加载完成。
- en: 'Now, let’s proceed with creating the `CH11` folder where we will store the
    files relevant to our ML pipeline in this chapter. Right-click on the empty space
    in the **File Browser** sidebar pane to open a context menu that is similar to
    what is shown in *Figure 11.6*:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们继续创建`CH11`文件夹，我们将在这个文件夹中存储本章中与我们的机器学习管道相关的文件。在**文件浏览器**侧边栏的空白区域右键单击以打开一个类似于*图11.6*所示的下拉菜单：
- en: '![Figure 11.6 – Creating a new folder ](img/B18638_11_006.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图11.6 – 创建新文件夹](img/B18638_11_006.jpg)'
- en: Figure 11.6 – Creating a new folder
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6 – 创建新文件夹
- en: Select `CH11`. After that, navigate to the `CH11` directory by double-clicking
    on the corresponding folder name in the sidebar.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 选择`CH11`。然后，通过在侧边栏中双击相应的文件夹名称来导航到`CH11`目录。
- en: Create a new notebook by clicking on the `.ipynb` file inside the `CH11` directory
    where we can run our Python code.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在`CH11`目录中点击`.ipynb`文件创建一个新的笔记本，我们可以在其中运行我们的Python代码。
- en: In the `Data Science` (option found under Sagemaker image)
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`数据科学`（在Sagemaker映像下找到的选项）
- en: '`Python 3`'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Python 3`'
- en: '`No script`'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`无脚本`'
- en: Afterward, click on the **Select** button.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，点击**选择**按钮。
- en: Note
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Wait for the kernel to start. This step could take around 3–5 minutes while
    an ML instance is being provisioned to run the Jupyter notebook cells. Make sure
    that you stop this instance after finishing all the hands-on solutions in this
    chapter (or if you’re not using it). For more information, feel free to check
    the *Cleaning up* section near the end of this chapter.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 等待内核启动。这一步可能需要3-5分钟，在此期间正在配置一个机器学习实例以运行Jupyter笔记本单元格。确保在完成本章的所有动手练习后（或如果您不再使用它）停止此实例。有关更多信息，请随时查看本章末尾附近的*清理*部分。
- en: Right-click on the tab name and then select `Machine Learning Pipelines with
    SageMaker Pipelines.ipynb`.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击标签名称，然后选择`Machine Learning Pipelines with SageMaker Pipelines.ipynb`。
- en: 'In the first cell of the `Machine Learning Pipelines with SageMaker Pipelines.ipynb`
    notebook, run the following command:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Machine Learning Pipelines with SageMaker Pipelines.ipynb`笔记本的第一个单元格中，运行以下命令：
- en: '[PRE4]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This should download a `processing.py` file that does the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会下载一个`processing.py`文件，该文件执行以下操作：
- en: Loads the `dataset.all.csv` file and stores the data inside a DataFrame
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载`dataset.all.csv`文件并将数据存储在一个DataFrame中。
- en: Performs the **train-test split**, which would divide the DataFrame into three
    DataFrames (containing the training, validation, and test sets)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行**训练-测试分割**，这将把DataFrame分割成三个DataFrame（包含训练集、验证集和测试集）。
- en: Ensures that the output directories have been created before saving the output
    CSV files
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保在保存输出CSV文件之前已经创建了输出目录。
- en: Saves the DataFrames containing the training, validation, and test sets into
    their corresponding CSV files inside the output directories
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将包含训练集、验证集和测试集的DataFrames保存到输出目录中相应的CSV文件中。
- en: Note
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Feel free to check the contents of the downloaded `processing.py` file. Additionally,
    you can find a copy of the `processing.py` script file at [https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/processing.py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/processing.py).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 随意检查下载的`processing.py`文件的内容。此外，您可以在[https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/processing.py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/processing.py)找到`processing.py`脚本文件的副本。
- en: 'Next, let’s use the `mkdir` command to create a `tmp` directory if it does
    not exist yet:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们使用`mkdir`命令创建一个`tmp`目录，如果它还不存在的话：
- en: '[PRE5]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After that, download the `bookings.all.csv` file using the `wget` command:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，使用`wget`命令下载`bookings.all.csv`文件：
- en: '[PRE6]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we download a clean(er) version of the synthetic `bookings.all.csv` file
    similar to what we used in [*Chapter 1*](B18638_01.xhtml#_idTextAnchor017), *Introduction
    to ML Engineering on AWS*. However, this time, multiple data cleaning and transformation
    steps have been applied already to produce a higher quality model.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们下载了一个更干净版本的合成 `bookings.all.csv` 文件，类似于我们在 [*第 1 章*](B18638_01.xhtml#_idTextAnchor017)，*AWS
    上的机器学习工程导论* 中使用的版本。然而，这次已经应用了多个数据清洗和转换步骤，以产生更高品质的模型。
- en: 'Specify a unique S3 bucket name and prefix. Make sure that you replace the
    value of `<INSERT S3 BUCKET NAME HERE>` with a unique S3 bucket name before running
    the following block of code:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定一个唯一的 S3 桶名称和前缀。在运行以下代码块之前，请确保将 `<INSERT S3 BUCKET NAME HERE>` 的值替换为唯一的 S3
    桶名称：
- en: '[PRE7]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You could use one of the S3 buckets created in the previous chapters and update
    the value of `s3_bucket` with the S3 bucket name. If you are planning to create
    and use a new S3 bucket, make sure that you update the value of `s3_bucket` with
    a name for a bucket that does not exist yet. After that, run the following command:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用上一章中创建的 S3 桶之一，并将 `s3_bucket` 的值更新为 S3 桶名称。如果您计划创建并使用新的 S3 桶，请确保将 `s3_bucket`
    的值更新为一个尚未存在的桶名称。之后，运行以下命令：
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that this command should only be executed if we are planning to create
    a new S3 bucket.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此命令仅在计划创建新的 S3 桶时才应执行。
- en: Note
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Copy the S3 bucket name to the text editor on your local machine. We will use
    this later in the *Testing our ML inference endpoint* section of this chapter.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 将 S3 桶名称复制到您本地机器上的文本编辑器。我们将在本章的 *测试我们的机器学习推理端点* 部分中使用它。
- en: 'Let’s prepare the path where we will upload our CSV file:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们准备上传 CSV 文件的路径：
- en: '[PRE10]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, let’s upload the `bookings.all.csv` file to the S3 bucket using the
    `aws s3 cp` command:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们使用 `aws s3 cp` 命令将 `bookings.all.csv` 文件上传到 S3 桶：
- en: '[PRE12]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, the CSV file gets renamed to `dataset.all.csv` file upon uploading it
    to the S3 bucket (since we specified this in the `source_path` variable).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，CSV 文件在上传到 S3 桶时被重命名为 `dataset.all.csv` 文件（因为我们已经在 `source_path` 变量中指定了这一点）。
- en: With the prerequisites ready, we can now proceed with running our first pipeline!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好先决条件后，我们现在可以开始运行我们的第一个管道了！
- en: Running our first pipeline with SageMaker Pipelines
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Pipelines 运行我们的第一个管道
- en: In [*Chapter 1*](B18638_01.xhtml#_idTextAnchor017), *Introduction to ML Engineering
    on AWS*, we installed and used **AutoGluon** to train multiple ML models (with
    **AutoML**) inside an AWS Cloud9 environment. In addition to this, we performed
    the different steps of the ML process manually using a variety of tools and libraries.
    In this chapter, we will convert these manually executed steps into an automated
    pipeline so that all we need to do is provide an input dataset and the ML pipeline
    will do the rest of the work for us (and store the trained model in a model registry).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 1 章*](B18638_01.xhtml#_idTextAnchor017)，*AWS 上的机器学习工程导论* 中，我们安装并使用了 **AutoGluon**
    在 AWS Cloud9 环境中训练多个机器学习模型（使用 **AutoML**）。此外，我们还使用各种工具和库手动执行了机器学习过程的各个步骤。在本章中，我们将将这些手动执行的步骤转换为自动化管道，这样我们只需要提供输入数据集，机器学习管道就会为我们完成剩余的工作（并将训练好的模型存储在模型注册表中）。
- en: Note
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Instead of preparing a custom Docker container image to use AutoGluon for training
    ML models, we will use the built-in **AutoGluon-Tabular** algorithm instead. With
    a built-in algorithm available for use, all we need to worry about would be the
    hyperparameter values and the additional configuration parameters we will use
    to configure the training job.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用内置的 **AutoGluon-Tabular** 算法而不是准备一个定制的 Docker 容器镜像来使用 AutoGluon 训练机器学习模型。有了可用的内置算法，我们只需要担心超参数值和我们将用于配置训练作业的附加配置参数。
- en: 'That said, this section is divided into two parts:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，本节分为两部分：
- en: '*Defining and preparing our first ML pipeline* – This is where we will define
    and prepare a pipeline with the following steps:'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义和准备我们的第一个机器学习管道* – 这是我们将定义并准备一个包含以下步骤的管道的地方：'
- en: '`PrepareData` – This utilizes a **SageMaker Processing** job to process the
    input dataset and splits it into training, validation, and test sets.'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PrepareData` – 这利用 **SageMaker Processing** 作业处理输入数据集并将其分割为训练、验证和测试集。'
- en: '`TrainModel` – This utilizes the **AutoGluon-Tabular** built-in algorithm to
    train a classification model.'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TrainModel` – 这利用内置的 **AutoGluon-Tabular** 算法来训练一个分类模型。'
- en: '`RegisterModel` – This registers the trained ML model to the **SageMaker Model
    Registry**.'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RegisterModel` – 这将训练的机器学习模型注册到 **SageMaker 模型注册表**。'
- en: '*Running our first ML pipeline* – This is where we will use the `start()` method
    to execute our pipeline.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*运行我们的第一个机器学习流水线* – 这是我们将使用`start()`方法来执行流水线的地方。'
- en: With these in mind, let’s start by preparing our ML pipeline.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些，让我们开始准备我们的机器学习流水线。
- en: Defining and preparing our first ML pipeline
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义和准备我们的第一个机器学习流水线
- en: 'The first pipeline we will prepare would be a relatively simple pipeline with
    three steps—including the data preparation step, the model training step, and
    the model registration step. To help us visualize what our first ML pipeline using
    **SageMaker Pipelines** will look like, let’s quickly check *Figure 11.7*:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将准备的第一条流水线将是一个相对简单的流水线，包括三个步骤——包括数据准备步骤、模型训练步骤和模型注册步骤。为了帮助我们可视化使用**SageMaker
    Pipelines**的第一个机器学习流水线将是什么样子，让我们快速查看*图11.7*：
- en: '![Figure 11.7 – Our first ML pipeline using SageMaker Pipelines ](img/B18638_11_007.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图11.7 – 使用SageMaker Pipelines的我们的第一个机器学习流水线](img/B18638_11_007.jpg)'
- en: Figure 11.7 – Our first ML pipeline using SageMaker Pipelines
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7 – 使用SageMaker Pipelines的我们的第一个机器学习流水线
- en: Here, we can see that our pipeline accepts an input dataset and splits this
    dataset into training, validation, and test sets. Then, the training and validation
    sets are used to train an ML model, which then gets registered to the **SageMaker
    Model Registry**.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们的流水线接受一个输入数据集，并将该数据集分为训练集、验证集和测试集。然后，使用训练集和验证集来训练一个机器学习模型，该模型随后被注册到**SageMaker模型注册表**。
- en: 'Now that we have a good idea of what our pipeline will look like, let’s run
    the following blocks of code in our `Machine Learning Pipelines with SageMaker
    Pipelines.ipynb` Jupyter notebook in the next set of steps:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对我们的流水线有了很好的了解，让我们在下一个步骤中在`Machine Learning Pipelines with SageMaker Pipelines.ipynb`
    Jupyter笔记本中运行以下代码块：
- en: 'Let’s start by importing the building blocks from `boto3` and `sagemaker`:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先从`boto3`和`sagemaker`导入构建块：
- en: '[PRE13]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Store the SageMaker execution role ARN inside the `role` variable:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将SageMaker执行角色的ARN存储在`role`变量中：
- en: '[PRE36]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Note
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `get_execution_role()` function should return the ARN of the IAM role we
    modified in the *Preparing the essential prerequisites* section of this chapter.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_execution_role()`函数应返回我们在本章*准备基本先决条件*部分修改的IAM角色的ARN。'
- en: 'Additionally, let’s prepare the SageMaker `Session` object:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，让我们准备SageMaker的`Session`对象：
- en: '[PRE37]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let’s initialize a `ParameterString` object that maps to the `Pipeline` parameter
    pointing to where the input dataset is stored:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们初始化一个`ParameterString`对象，该对象映射到指向存储输入数据集的`Pipeline`参数：
- en: '[PRE38]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let’s prepare the `ProcessingInput` object that contains the configuration
    of the input source of the `ProcessingOutput` object that maps to the configuration
    for the output results of the **SageMaker Processing** job:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们准备包含映射到**SageMaker Processing**作业输出结果配置的`ProcessingOutput`对象输入源配置的`ProcessingInput`对象：
- en: '[PRE42]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let’s initialize the `SKLearnProcessor` object along with the corresponding
    `ProcessingStep` object:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们初始化`SKLearnProcessor`对象以及相应的`ProcessingStep`对象：
- en: '[PRE51]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'To help us visualize how we configured the `ProcessingStep` object, let’s quickly
    check *Figure 11.8*:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们可视化我们如何配置`ProcessingStep`对象，让我们快速查看*图11.8*：
- en: '![Figure 11.8 – Configuring and preparing the ProcessingStep ](img/B18638_11_008.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图11.8 – 配置和准备ProcessingStep](img/B18638_11_008.jpg)'
- en: Figure 11.8 – Configuring and preparing the ProcessingStep
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8 – 配置和准备ProcessingStep
- en: Here, we initialized the `ProcessingStep` object using the configured `SKLearnProcessor`
    object along with the parameter values for the `inputs`, `outputs`, and `code`
    parameters.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用配置的`SKLearnProcessor`对象以及`inputs`、`outputs`和`code`参数的参数值初始化了`ProcessingStep`对象。
- en: 'Next, let’s prepare the `model_path` variable to point to where the model will
    be uploaded after the SageMaker training job has finished (when the ML pipeline
    is executed during a later step):'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们准备`model_path`变量，使其指向模型在SageMaker训练作业完成后（在后续步骤中执行机器学习流水线时）上传的位置：
- en: '[PRE64]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Additionally, let’s prepare the `model_id` variable to store the ID of the
    ML model we’ll use:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，让我们准备`model_id`变量以存储我们将使用的机器学习模型的ID：
- en: '[PRE65]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Let’s specify the region we are using inside `region_name`:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们指定我们正在使用的区域，并将其存储在`region_name`变量中：
- en: '[PRE66]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Use `image_uris.retrieve()` to get the ECR container image URI of our training
    image:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`image_uris.retrieve()`获取我们的训练图像的ECR容器镜像URI：
- en: '[PRE67]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'If you are wondering what the value of `train_image_uri` is, it should have
    a string value equal (or similar to): `''763104351884.dkr.ecr.us-west-2.amazonaws.com/autogluon-training:0.4.0-cpu-py38''.`'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `script_uris.retrieve()` to get the script S3 URI associated with the model
    (given the values of `model_id`, `model_version`, and `script_scope`):'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Note that `train_source_uri` should have a string value equal (or similar) to
    `'s3://jumpstart-cache-prod-us-west-2/source-directory-tarballs/autogluon/transfer_learning/classification/v1.0.1/sourcedir.tar.gz'`.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: What’s inside this `sourcedir.tar.gz` file? If the `script_scope` value used
    when calling `script_uris.retrieve()` is `"training"`, the `sourcedir.tar.gz`
    file should contain code that uses `autogluon.tabular.TabularPredictor` when training
    the ML model. Note that the contents of `sourcedir.tar.gz` change depending on
    the arguments specified when calling `script_uris.retrieve()`.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `model_uris.retrieve()` to get the model artifact S3 URI associated with
    the model (given the values of `model_id`, `model_version`, and `model_scope`):'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Note that `train_model_uri` should have a string value equal (or similar) to
    `'s3://jumpstart-cache-prod-us-west-2/autogluon-training/train-autogluon-classification-ensemble.tar.gz'`.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'With the values for `train_image_uri`, `train_source_uri`, `train_model_uri`,
    and `model_path` ready, we can now initialize the `Estimator` object:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Here, the `entry_point` value points to the `transfer_learning.py` script file
    stored inside `sourcedir.tar.gz` containing the relevant scripts for training
    the model.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s use the `retrieve_default()` function to retrieve the default set
    of hyperparameters for our **AutoGluon** classification model:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Prepare the `TrainingStep` object that uses the `Estimator` object as one of
    the parameter values during initialization:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'Here, `s3_data` contains a `Properties` object that points to the path where
    the output files of the `s3_data` using `s3_data.__dict__`, we should get a dictionary
    similar to the following:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'To help us visualize how we configured the `TrainingStep` object, let’s quickly
    check *Figure 11.9*:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Configuring and preparing the TrainingStep object ](img/B18638_11_009.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – Configuring and preparing the TrainingStep object
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Here, we initialize the `TrainingStep` object using the configured `Estimator`
    object along with the parameter values for the `name` and `inputs` parameters.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s use `image_uris.retrieve()` and `script_uris.retrieve()` to retrieve
    the container image URI and script URI for the deployment of AutoGluon classification
    models:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '[PRE132]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'Use the `aws s3 cp` command to download the `sourcedir.tar.gz` file to the
    `tmp` directory:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'Next, upload the `sourcedir.tar.gz` file from the `tmp` directory to your S3
    bucket:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '[PRE139]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE139]'
- en: 'Let’s define the `random_string()` function:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE142]'
- en: This function should return a random alphanumeric string (with 6 characters).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: 'With the values for `deploy_image_uri`, `updated_source_uri`, and `model_data`
    ready, we can now initialize the `Model` object:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '[PRE146]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '[PRE147]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '[PRE149]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[PRE151]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE152]'
- en: '[PRE153]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '[PRE154]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE154]'
- en: '[PRE155]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE157]'
- en: Here, we use the `random_string()` function that we defined in the previous
    step for the name identifier of the `Model` object.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s prepare the `ModelStep` object that uses the output of `model.register()`
    during initialization:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE158]'
- en: '[PRE159]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE160]'
- en: '[PRE161]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '[PRE163]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '[PRE164]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '[PRE165]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE165]'
- en: '[PRE166]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '[PRE167]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE168]'
- en: '[PRE169]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE169]'
- en: '[PRE170]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE170]'
- en: '[PRE171]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE171]'
- en: 'Now, let’s initialize the `Pipeline` object using the different step objects
    we prepared in the previous steps:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE172]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE172]'
- en: '[PRE173]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE173]'
- en: '[PRE174]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE178]'
- en: '[PRE179]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: '[PRE182]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '[PRE183]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: 'Finally, let’s use the `upsert()` method to create our ML pipeline:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE184]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: Note
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `upsert()` method can be used to update an existing ML pipeline,
    too.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: Now that our initial pipeline is ready, we can proceed with running the ML pipeline!
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: Running our first ML pipeline
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once the `Pipeline` object has been initialized and created, we can run it
    right away using the `start()` method, which is similar to what we have in the
    following line of code:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE185]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE185]'
- en: 'If we wish to override the default parameters of the pipeline inputs (for example,
    the input data used), we can specify parameter values when calling the `start()`
    method similar to what we have in the following block of code:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE186]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: Once the pipeline execution starts, we can then use `execution.wait()` to wait
    for the pipeline to finish running.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, let’s run our ML pipeline in the next set of steps:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: 'With everything ready, let’s run the (partial) ML pipeline using the `start()`
    method:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE187]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE187]'
- en: '[PRE188]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE188]'
- en: 'Let’s use the `wait()` method to wait for the pipeline to complete before proceeding:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE189]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE189]'
- en: Note
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: This should take around 10–15 minutes to complete. Feel free to grab a cup of
    coffee or tea while waiting!
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following block of code to get the resulting model package ARN:'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE190]'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE190]'
- en: '[PRE191]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE191]'
- en: This should yield an ARN with a format similar to `arn:aws:sagemaker:us-west-2:<ACCOUNT
    ID>:model-package/autogluonmodelgroup/1`. Copy this value into your text editor.
    We will use this model package ARN later when testing our Lambda functions in
    the *Creating Lambda functions for deployment* section of this chapter.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: 'Locate and click on the triangle icon (**SageMaker resources**) near the bottom
    of the left-hand sidebar of SageMaker Studio (as highlighted in *Figure 11.10*):'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Opening the SageMaker resources pane  ](img/B18638_11_010.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – Opening the SageMaker resources pane
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: This should open the **SageMaker resources** pane where we can view and inspect
    a variety of SageMaker resources.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Select **Pipelines** from the list of options available in the drop-down menu
    in the **SageMaker resources** pane.
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After that, double-click on the row that maps to the `PARTIAL-PIPELINE` pipeline
    we just created. After that, double-click on the row that maps to the pipeline
    execution we triggered after calling `partial_pipeline.start()`.
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the execution has finished, you should see a graph that is similar to
    what is shown in *Figure 11.11*:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Completed pipeline execution ](img/B18638_11_011.jpg)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – Completed pipeline execution
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: 'Feel free to click on the rounded rectangles to check the following details
    of each of the steps:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: '**Input** – The input files, parameters, and configuration'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output** – The output files and metrics (if any)'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs** – The generated logs'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information** – Any additional information/metadata'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Navigate back to the tab corresponding to the **Machine Learning Pipelines with
    SageMaker Pipelines.ipynb** notebook.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s review the steps executed during the (partial) pipeline run using the
    `list_steps()` method:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE192]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE192]'
- en: This should return a list of dictionaries that map to the executed steps of
    the pipeline.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: We are not yet done! At this point, we have only finished half of our ML pipeline.
    Make sure that you do not turn off the running apps and instances in SageMaker
    Studio, as we will be running more blocks of code inside the `Machine Learning
    Pipelines with SageMaker Pipelines.ipynb` notebook later to complete our pipeline.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: If you need to take a break, you may turn off the running instances and apps
    (to manage costs), and then run all the cells again in the `Machine Learning Pipelines
    with SageMaker Pipelines.ipynb` notebook before working on the *Completing the
    end-to-end ML pipeline* section of this chapter.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: Creating Lambda functions for deployment
  id: totrans-415
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our second (and more complete pipeline) will require a few additional resources
    to help us deploy our ML model. In this section, we will create the following
    Lambda functions:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '`check-if-endpoint-exists` – This is a Lambda function that accepts the name
    of the ML inference endpoint as input and returns `True` if the endpoint exists
    already.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deploy-model-to-new-endpoint` – This is a Lambda function that accepts the
    model package ARN as input (along with the role and the endpoint name) and deploys
    the model into a new inference endpoint'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deploy-model-to-existing-endpoint` – This is a Lambda function that accepts
    the model package ARN as input (along with the role and the endpoint name) and
    deploys the model into an existing inference endpoint (by updating the deployed
    model inside the ML instance)'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use these functions later in the *Completing the end-to-end ML pipeline*
    section to deploy the ML model we will register in the SageMaker Model Registry
    (using `ModelStep`).
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the Lambda function for deploying a model to a new endpoint
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first **AWS Lambda** function we will create will be configured and programmed
    to deploy a model to a new endpoint. To help us visualize how our function will
    work, let’s quickly check *Figure 11.12*:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Deploying a model to a new endpoint ](img/B18638_11_012.jpg)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – Deploying a model to a new endpoint
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: 'This function will accept the following input parameters: an IAM role, the
    endpoint name, and the model package ARN. After receiving these input parameters,
    the function will create the corresponding set of resources needed to deploy the
    model (from the model package) to a new ML inference endpoint.'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next set of steps, we will create a Lambda function that we will use
    to deploy an ML model to a new inference endpoint:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `lambda` in the search bar of the AWS Management Console, and
    then clicking on the **Lambda** link from the list of search results.
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will create and manage our resources in the `us-west-2`)
    region. Make sure that you have set the correct region before proceeding with
    the next steps.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: Locate and click on the `deploy-model-to-new-endpoint`
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3.9`'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Permissions** > **Change default execution role**'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Use an existing role`'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`pipeline-lambda-role`'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll down to the bottom of the page and then click on the **Create function**
    button.
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see the following success notification after clicking on the **Create
    function** button: **Successfully created the function deploy-model-to-new-endpoint**.You
    can now change its code and configuration. To invoke your function with a test
    event, choose **Test**.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `1024` MB
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`15` min `0` sec'
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Afterward, click on the **Save** button.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the following link in another browser tab: [https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/main/chapter11/utils.py](https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/main/chapter11/utils.py).
    Copy the contents of the page into your clipboard using *Ctrl* + *A* and then
    *Ctrl* + *C* (or, alternatively, *CMD* + *A* and then *CMD* + *C* if you are using
    a Mac).'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Back in the browser tab showing the Lambda console, navigate to the `Untitled1`.
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the new tab (containing no code), paste the code copied to the clipboard.
    Open the `utils.py` as the **Filename** field value, and then click on **Save**.
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the tab where we can modify the code inside `lambda_function.py`.
    Delete the boilerplate code currently stored inside `lambda_function.py` before
    proceeding.
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: Type (or copy) the code blocks in the succeeding set of steps inside `lambda_function.py`.
    You can find a copy of the code for the Lambda function at [https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/deploy-model-to-new-endpoint.py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/deploy-model-to-new-endpoint.py).
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `lambda_function.py` file, import the functions we will need for deploying
    a trained ML model to a new ML inference endpoint:'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE193]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: '[PRE195]'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: '[PRE196]'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '[PRE197]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE197]'
- en: '[PRE198]'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE198]'
- en: '[PRE199]'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '[PRE200]'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE200]'
- en: 'Now, let’s define the `lambda_handler()` function:'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE201]'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE201]'
- en: '[PRE202]'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE202]'
- en: '[PRE203]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE203]'
- en: '[PRE204]'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE204]'
- en: '[PRE205]'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE205]'
- en: '[PRE206]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE206]'
- en: '[PRE207]'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE207]'
- en: '[PRE208]'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE208]'
- en: '[PRE209]'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE209]'
- en: '[PRE210]'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE210]'
- en: '[PRE211]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE211]'
- en: '[PRE212]'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: '[PRE213]'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '[PRE214]'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE214]'
- en: '[PRE215]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE215]'
- en: '[PRE216]'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE216]'
- en: '[PRE217]'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE217]'
- en: '[PRE218]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE218]'
- en: '[PRE219]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE219]'
- en: '[PRE220]'
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE220]'
- en: '[PRE221]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE221]'
- en: '[PRE222]'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE222]'
- en: '[PRE223]'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE223]'
- en: '[PRE224]'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE224]'
- en: '[PRE225]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE225]'
- en: Click on the **Deploy** button.
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Test** button.
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `test` under **Event name**, and then specify the following JSON value
    under **Event JSON**:'
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE226]'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE226]'
- en: '[PRE227]'
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE227]'
- en: '[PRE228]'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE228]'
- en: '[PRE229]'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE229]'
- en: '[PRE230]'
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE230]'
- en: 'Make sure that you replace the following values:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: '`<INSERT SAGEMAKER EXECUTION ROLE ARN>` – Replace this placeholder value with
    the `arn:aws:iam::1234567890:role/service-role/AmazonSageMaker-ExecutionRole-20220000T000000`.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<INSERT MODEL PACKAGE ARN>` – Replace this placeholder value with the `arn:aws:sagemaker:us-west-2:1234567890:model-package/autogluonmodelgroup/1`.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy this test event JSON value to the text editor on your local machine. We
    will use this test event JSON again later when testing our `deploy-model-to-existing-endpoint`
    Lambda function.
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Afterward, click on the **Save** button.
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With everything ready, let’s click on the **Test** button. This should open
    a new tab that should show the execution results after a few minutes.
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: This step might take 5–15 minutes to complete. Feel free to grab a cup of coffee
    or tea!
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: While waiting, scroll up and locate the **Function overview** pane. Copy the
    **Function ARN** value to your text editor. We will use this **Function ARN**
    value later in the *Completing the end-to-end ML pipeline* section of this chapter.
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the `deploy-model-to-new-endpoint` Lambda function has finished running,
    we should have our ML model deployed already in an ML inference endpoint. Note
    that we are just testing the Lambda function, and we will delete the ML inference
    endpoint (launched by the `deploy-model-to-new-endpoint` Lambda function) in a
    later step before running the complete ML pipeline.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the Lambda function for checking whether an endpoint exists
  id: totrans-500
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The second **AWS Lambda** function we will create will be configured and programmed
    to check whether an endpoint exists already (given the endpoint name). To help
    us visualize how our function will work, let’s quickly check *Figure 11.13*:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.13 – Check whether an endpoint exists already ](img/B18638_11_013.jpg)'
  id: totrans-502
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 – Check whether an endpoint exists already
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: This function will accept one input parameter—the name of the ML inference endpoint.
    After receiving the input parameter, the function will use the `boto3` library
    to list all running endpoints in the region and check whether the name of one
    of these endpoints matches the input parameter value.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next set of steps, we will create a Lambda function that we will use
    to check whether an ML inference endpoint exists already:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: Open a new browser tab and navigate to the **Functions** page of the Lambda
    Management console.
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Locate and click on the **Create function** button (located in the upper-left
    corner of the **Functions** page), and then specify the following configuration
    values:'
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Author from scratch**'
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`check-if-endpoint-exists`'
  id: totrans-509
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Python 3.9`'
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Permissions** > **Change default execution role**'
  id: totrans-511
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Use an existing role`'
  id: totrans-512
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline-lambda-role`'
  id: totrans-513
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Scroll down to the bottom of the page, and then click on the **Create function**
    button.
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: Type (or copy) the code blocks into the succeeding set of steps inside `lambda_function.py`.
    You can find a copy of the code for the Lambda function here at [https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/check-if-endpoint-exists.py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/check-if-endpoint-exists.py).
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `lambda_function.py` file, import `boto3` and initialize the client
    for the SageMaker service:'
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE231]'
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE231]'
- en: '[PRE232]'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE232]'
- en: 'Next, let’s define the `endpoint_exists()` function:'
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE233]'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE233]'
- en: '[PRE234]'
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE234]'
- en: '[PRE235]'
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE235]'
- en: '[PRE236]'
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE236]'
- en: '[PRE237]'
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE237]'
- en: '[PRE238]'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE238]'
- en: '[PRE239]'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE239]'
- en: '[PRE240]'
  id: totrans-528
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE240]'
- en: '[PRE241]'
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE241]'
- en: '[PRE242]'
  id: totrans-530
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE242]'
- en: '[PRE243]'
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE243]'
- en: '[PRE244]'
  id: totrans-532
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE244]'
- en: 'Now, let’s define the `lambda_handler()` function that makes use of the `endpoint_exists()`
    function to check whether an ML inference endpoint exists or not (given the endpoint
    name):'
  id: totrans-533
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE245]'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE245]'
- en: '[PRE246]'
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE246]'
- en: '[PRE247]'
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE247]'
- en: '[PRE248]'
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE248]'
- en: '[PRE249]'
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE249]'
- en: '[PRE250]'
  id: totrans-539
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE250]'
- en: '[PRE251]'
  id: totrans-540
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE251]'
- en: Click on the **Deploy** button.
  id: totrans-541
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the `test` under **Event name** and then specify the following JSON
    value under **Event JSON**:'
  id: totrans-542
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE252]'
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE252]'
- en: '[PRE253]'
  id: totrans-544
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE253]'
- en: '[PRE254]'
  id: totrans-545
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE254]'
- en: Afterward, click on the **Save** button.
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With everything ready, let’s click on the **Test** button. This should open
    a new tab that will show the execution results after a few seconds. We should
    get the following response value after testing the Lambda function:'
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE255]'
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE255]'
- en: '[PRE256]'
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE256]'
- en: '[PRE257]'
  id: totrans-550
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE257]'
- en: Finally, scroll up and locate the **Function overview** pane. Copy the **Function
    ARN** value to your text editor. We will use this **Function ARN** value later
    in the *Completing the end-to-end ML pipeline* section of this chapter.
  id: totrans-551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have finished preparing and testing the `check-if-endpoint-exists`
    Lambda function, we can proceed with creating the last Lambda function (`deploy-model-to-existing-endpoint`).
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the Lambda function for deploying a model to an existing endpoint
  id: totrans-553
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The third **AWS Lambda** function we will create will be configured and programmed
    to deploy a model to an existing endpoint. To help us visualize how our function
    will work, let’s quickly check *Figure 11.14*:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.14 – Deploying a model to an existing endpoint ](img/B18638_11_014.jpg)'
  id: totrans-555
  prefs: []
  type: TYPE_IMG
- en: Figure 11.14 – Deploying a model to an existing endpoint
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: This function will accept three input parameters—an IAM role, the endpoint name,
    and the model package ARN. After receiving these input parameters, the function
    will perform the necessary steps to update the model deployed in an existing ML
    inference endpoint with the model from the model package provided.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next set of steps, we will create a Lambda function that we will use
    to deploy an ML model to an existing inference endpoint:'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: Open a new browser tab and navigate to the **Functions** page of the Lambda
    Management console.
  id: totrans-559
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Locate and click on the **Create function** button (located in the upper-left
    corner of the **Functions** page), and then specify the following configuration
    values:'
  id: totrans-560
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Author from scratch**'
  id: totrans-561
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deploy-model-to-existing-endpoint`'
  id: totrans-562
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Python 3.9`'
  id: totrans-563
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Permissions** > **Change default execution role**'
  id: totrans-564
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Use an existing role`'
  id: totrans-565
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline-lambda-role`'
  id: totrans-566
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Scroll down to the bottom of the page and then click on the **Create function**
    button.
  id: totrans-567
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the `1024` MB
  id: totrans-568
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`15` min `0` sec'
  id: totrans-569
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Afterward, click on the **Save** button.
  id: totrans-570
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the following link in another browser tab: [https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/main/chapter11/utils.py](https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/main/chapter11/utils.py).
    Copy the contents of the page into your clipboard using *Ctrl* + *A* and then
    *Ctrl* + *C* (or, alternatively, *CMD* + *A* and then *CMD* + *C* if you are using
    a Mac).'
  id: totrans-571
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Back in the browser tab showing the Lambda console, navigate to the `Untitled1`.
    In the new tab (containing no code), paste the code copied to the clipboard.
  id: totrans-572
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `utils.py` as the **Filename** field value and then click on **Save**.
  id: totrans-573
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the tab where we can modify the code inside `lambda_function.py`.
    Delete the boilerplate code currently stored inside `lambda_function.py` before
    proceeding.
  id: totrans-574
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: Type (or copy) the code blocks in the succeeding set of steps inside `lambda_function.py`.
    You can find a copy of the code for the Lambda function at [https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/deploy-model-to-existing-endpoint.py](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter11/deploy-model-to-existing-endpoint.py).
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `lambda_function.py` file, import the functions we will need to update
    the deployed model of an existing endpoint:'
  id: totrans-577
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE258]'
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE258]'
- en: '[PRE259]'
  id: totrans-579
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE259]'
- en: '[PRE260]'
  id: totrans-580
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE260]'
- en: '[PRE261]'
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE261]'
- en: '[PRE262]'
  id: totrans-582
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE262]'
- en: '[PRE263]'
  id: totrans-583
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE263]'
- en: '[PRE264]'
  id: totrans-584
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE264]'
- en: '[PRE265]'
  id: totrans-585
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE265]'
- en: 'Now, let’s define the `lambda_handler()` function using the following block
    of code:'
  id: totrans-586
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE266]'
  id: totrans-587
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE266]'
- en: '[PRE267]'
  id: totrans-588
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE267]'
- en: '[PRE268]'
  id: totrans-589
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE268]'
- en: '[PRE269]'
  id: totrans-590
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE269]'
- en: '[PRE270]'
  id: totrans-591
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE270]'
- en: '[PRE271]'
  id: totrans-592
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE271]'
- en: '[PRE272]'
  id: totrans-593
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE272]'
- en: '[PRE273]'
  id: totrans-594
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE273]'
- en: '[PRE274]'
  id: totrans-595
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE274]'
- en: '[PRE275]'
  id: totrans-596
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE275]'
- en: '[PRE276]'
  id: totrans-597
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE276]'
- en: '[PRE277]'
  id: totrans-598
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE277]'
- en: '[PRE278]'
  id: totrans-599
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE278]'
- en: '[PRE279]'
  id: totrans-600
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE279]'
- en: '[PRE280]'
  id: totrans-601
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE280]'
- en: '[PRE281]'
  id: totrans-602
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE281]'
- en: '[PRE282]'
  id: totrans-603
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE282]'
- en: '[PRE283]'
  id: totrans-604
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE283]'
- en: '[PRE284]'
  id: totrans-605
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE284]'
- en: '[PRE285]'
  id: totrans-606
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE285]'
- en: '[PRE286]'
  id: totrans-607
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE286]'
- en: '[PRE287]'
  id: totrans-608
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE287]'
- en: '[PRE288]'
  id: totrans-609
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE288]'
- en: '[PRE289]'
  id: totrans-610
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE289]'
- en: '[PRE290]'
  id: totrans-611
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE290]'
- en: Click on the **Deploy** button.
  id: totrans-612
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the `test` under **Event name** and then specify the following JSON
    value under **Event JSON**:'
  id: totrans-613
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE291]'
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE291]'
- en: '[PRE292]'
  id: totrans-615
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE292]'
- en: '[PRE293]'
  id: totrans-616
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE293]'
- en: '[PRE294]'
  id: totrans-617
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE294]'
- en: '[PRE295]'
  id: totrans-618
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE295]'
- en: 'Make sure that you replace the following values:'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
- en: '`<INSERT SAGEMAKER EXECUTION ROLE ARN>` – Replace this placeholder value with
    the **Execution Role ARN** copied to your text editor in the *Preparing the essential
    prerequisites* section of this chapter.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<INSERT MODEL PACKAGE ARN>` – Replace this placeholder value with the **model
    package ARN** copied to your text editor in the *Running our first pipeline with
    SageMaker Pipelines* section of this chapter.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, you can use the same test event JSON value that we copied to our
    text editor while testing our `deploy-model-to-new-endpoint` Lambda function.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
- en: Afterward, click on the **Save** button.
  id: totrans-623
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With everything ready, let’s click on the **Test** button. This should open
    a new tab that should show the execution results after a few minutes.
  id: totrans-624
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
- en: This step may take 5–15 minutes to complete. Feel free to grab a cup of coffee
    or tea!
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
- en: While waiting, scroll up and locate the **Function overview** pane. Copy the
    **Function ARN** value to your text editor. We will use this **Function ARN**
    value later in the *Completing the end-to-end ML pipeline* section of this chapter.
  id: totrans-627
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With all the Lambda functions ready, we can now proceed with testing our ML
    inference endpoint (before completing the end-to-end ML pipeline).
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we should have 3 x `check-if-endpoint-exists` Lambda function,
    the `deploy-model-to-new-endpoint` Lambda function, and the `deploy-model-to-existing-endpoint`
    Lambda function. We will use these ARN values later in the *Completing the end-to-end
    ML pipeline* section of this chapter.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
- en: Testing our ML inference endpoint
  id: totrans-631
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Of course, we need to check whether the ML inference endpoint is working! In
    the next set of steps, we will download and run a Jupyter notebook (named `Test
    Endpoint and then Delete.ipynb`) that tests our ML inference endpoint using the
    test dataset:'
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by opening the following link in another browser tab: [https://bit.ly/3xyVAXz](https://bit.ly/3xyVAXz)'
  id: totrans-633
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on any part of the page to open a context menu, and then choose
    `Test Endpoint then Delete.ipynb`, and then download it to the `Downloads` folder
    (or similar) on your local machine.
  id: totrans-634
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Navigate back to your `CH11` folder similar to what we have in *Figure 11.15*:'
  id: totrans-635
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.15 – Uploading the test endpoint and then the Delete.ipynb file
    ](img/B18638_11_015.jpg)'
  id: totrans-636
  prefs: []
  type: TYPE_IMG
- en: Figure 11.15 – Uploading the test endpoint and then the Delete.ipynb file
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
- en: Click on the upload button (as highlighted in *Figure 11.15*), and then select
    the `Test Endpoint then Delete.ipynb` file that we downloaded in an earlier step.
  id: totrans-638
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
- en: This should upload the `Test Endpoint then Delete.ipynb` notebook file from
    your local machine to the SageMaker Studio environment (in the `CH11` folder).
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
- en: Double-click on the `Test Endpoint then Delete.ipynb` file in the **File tree**
    to open the notebook in the **Main work area** (which contains tabs of the open
    notebooks, files, and terminals).
  id: totrans-641
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Update the first cell with the name of the S3 bucket used in the `Machine Learning
    Pipelines with SageMaker Pipelines.ipynb` notebook:'
  id: totrans-642
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE296]'
  id: totrans-643
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE296]'
- en: Make sure to replace `<INSERT S3 BUCKET HERE>` with the S3 bucket name we copied
    to our text editor earlier in the *Preparing the essential prerequisites* section
    of this chapter.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
- en: Open the `Test Endpoint then Delete.ipynb` notebook.
  id: totrans-645
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
- en: It should take around 1–2 minutes to run all the cells in the Jupyter notebook.
    Feel free to grab a cup of coffee or tea while waiting!
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
- en: 'Once all the cells in the `Test Endpoint then Delete.ipynb` notebook have been
    executed, locate the cell containing the following block of code (along with the
    returned output):'
  id: totrans-648
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE297]'
  id: totrans-649
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE297]'
- en: '[PRE298]'
  id: totrans-650
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE298]'
- en: Verify that the model got an accuracy score equal to or close to `0.88` (or
    88%).
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
- en: At this point, the ML inference endpoint should be in a deleted state since
    the `Test``Endpoint then Delete.ipynb` Jupyter notebook also runs the `predictor.delete_endpoint()`
    line after computing for the ML model metrics.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
- en: Completing the end-to-end ML pipeline
  id: totrans-653
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will build on top of the (partial) pipeline we prepared
    in the *Running our first pipeline with SageMaker Pipelines* section of this chapter.
    In addition to the steps and resources used to build our partial pipeline, we
    will also utilize the Lambda functions we created (in the *Creating Lambda functions
    for deployment* section) to complete our ML pipeline.
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
- en: Defining and preparing the complete ML pipeline
  id: totrans-655
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The second pipeline we will prepare would be slightly longer than the first
    pipeline. To help us visualize how our second ML pipeline using **SageMaker Pipelines**
    will look like, let’s quickly check *Figure 11.16*:'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.16 – Our second ML pipeline using SageMaker Pipelines ](img/B18638_11_016.jpg)'
  id: totrans-657
  prefs: []
  type: TYPE_IMG
- en: Figure 11.16 – Our second ML pipeline using SageMaker Pipelines
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that our pipeline accepts two input parameters—the input dataset
    and the endpoint name. When the pipeline runs, the input dataset is first split
    into training, validation, and test sets. The training and validation sets are
    then used to train an ML model, which then gets registered to the **SageMaker
    Model Registry**. After that, the pipeline checks whether an ML inference endpoint
    with the provided endpoint name exists already. If the endpoint does not exist
    yet, the model is deployed to a new endpoint. Otherwise, the model of an existing
    endpoint (with the provided endpoint name) is updated using the model trained
    during the pipeline execution.
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next set of steps, we will create a new ML pipeline using the steps
    and resources configured in the `Machine Learning Pipelines with SageMaker Pipelines.ipynb`
    notebook:'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
- en: Navigate back to the tab corresponding to the `Machine Learning Pipelines with
    SageMaker Pipelines.ipynb` notebook.
  id: totrans-661
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
- en: We will run the blocks of code in the succeeding set of steps inside the `Machine
    Learning Pipelines with SageMaker Pipelines.ipynb` notebook (after the existing
    set of cells). If you turned off the kernel and/or the SageMaker Studio instance
    after running the commands in the *Running our first pipeline with SageMaker Pipelines*
    section, make sure that you run all the cells again (and wait for the pipeline
    to finish running) by selecting **Run All Cells** from the list of options under
    the **Run** menu.
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s initialize the `ParameterString` object that maps to the `Pipeline` parameter
    for the name of the ML inference endpoint (which will be created or updated after
    the ML pipeline has finished running):'
  id: totrans-664
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE299]'
  id: totrans-665
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE299]'
- en: '[PRE300]'
  id: totrans-666
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE300]'
- en: '[PRE301]'
  id: totrans-667
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE301]'
- en: '[PRE302]'
  id: totrans-668
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE302]'
- en: 'Next, let’s import the classes we will need to complete the end-to-end ML pipeline:'
  id: totrans-669
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE303]'
  id: totrans-670
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE303]'
- en: '[PRE304]'
  id: totrans-671
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE304]'
- en: '[PRE305]'
  id: totrans-672
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE305]'
- en: '[PRE306]'
  id: totrans-673
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE306]'
- en: '[PRE307]'
  id: totrans-674
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE307]'
- en: '[PRE308]'
  id: totrans-675
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE308]'
- en: '[PRE309]'
  id: totrans-676
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE309]'
- en: '[PRE310]'
  id: totrans-677
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE310]'
- en: '[PRE311]'
  id: totrans-678
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE311]'
- en: '[PRE312]'
  id: totrans-679
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE312]'
- en: '[PRE313]'
  id: totrans-680
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE313]'
- en: '[PRE314]'
  id: totrans-681
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE314]'
- en: '[PRE315]'
  id: totrans-682
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE315]'
- en: '[PRE316]'
  id: totrans-683
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE316]'
- en: '[PRE317]'
  id: totrans-684
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE317]'
- en: 'Prepare the `LambdaOutput` object that will map (later) to the output of a
    `LambdaStep` object:'
  id: totrans-685
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE318]'
  id: totrans-686
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE318]'
- en: '[PRE319]'
  id: totrans-687
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE319]'
- en: '[PRE320]'
  id: totrans-688
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE320]'
- en: '[PRE321]'
  id: totrans-689
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE321]'
- en: 'Initialize the `LambdaStep` object, which maps to the Lambda function that
    checks whether a specified ML inference endpoint exists already (given the endpoint
    name):'
  id: totrans-690
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE322]'
  id: totrans-691
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE322]'
- en: '[PRE323]'
  id: totrans-692
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE323]'
- en: '[PRE324]'
  id: totrans-693
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE324]'
- en: '[PRE325]'
  id: totrans-694
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE325]'
- en: '[PRE326]'
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE326]'
- en: '[PRE327]'
  id: totrans-696
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE327]'
- en: '[PRE328]'
  id: totrans-697
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE328]'
- en: '[PRE329]'
  id: totrans-698
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE329]'
- en: '[PRE330]'
  id: totrans-699
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE330]'
- en: '[PRE331]'
  id: totrans-700
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE331]'
- en: '[PRE332]'
  id: totrans-701
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE332]'
- en: '[PRE333]'
  id: totrans-702
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE333]'
- en: '[PRE334]'
  id: totrans-703
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE334]'
- en: Make sure to replace `<INSERT FUNCTION ARN>` with the ARN of the `check-if-endpoint-exists`
    Lambda function we copied into our text editor. It should have a format that is
    similar to `arn:aws:lambda:us-west-2:<ACCOUNT ID>:function:check-if-endpoint-exists`.
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, initialize the `LambdaStep` object, which maps to the Lambda function
    that deploys the trained ML model to an existing ML inference endpoint:'
  id: totrans-705
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE335]'
  id: totrans-706
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE335]'
- en: '[PRE336]'
  id: totrans-707
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE336]'
- en: '[PRE337]'
  id: totrans-708
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE337]'
- en: '[PRE338]'
  id: totrans-709
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE338]'
- en: '[PRE339]'
  id: totrans-710
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE339]'
- en: '[PRE340]'
  id: totrans-711
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE340]'
- en: '[PRE341]'
  id: totrans-712
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE341]'
- en: '[PRE342]'
  id: totrans-713
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE342]'
- en: '[PRE343]'
  id: totrans-714
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE343]'
- en: '[PRE344]'
  id: totrans-715
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE344]'
- en: '[PRE345]'
  id: totrans-716
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE345]'
- en: '[PRE346]'
  id: totrans-717
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE346]'
- en: Make sure that you replace `<INSERT FUNCTION ARN>` with the ARN of the `deploy-model-to-existing-endpoint`
    Lambda function we copied into our text editor. It should have a format similar
    to `arn:aws:lambda:us-west-2:<ACCOUNT ID>:function:` `deploy-model-to-existing-endpoint`.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, initialize the `LambdaStep` object, which maps to the Lambda function
    that deploys the trained ML model to a new ML inference endpoint:'
  id: totrans-719
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE347]'
  id: totrans-720
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE347]'
- en: '[PRE348]'
  id: totrans-721
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE348]'
- en: '[PRE349]'
  id: totrans-722
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE349]'
- en: '[PRE350]'
  id: totrans-723
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE350]'
- en: '[PRE351]'
  id: totrans-724
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE351]'
- en: '[PRE352]'
  id: totrans-725
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE352]'
- en: '[PRE353]'
  id: totrans-726
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE353]'
- en: '[PRE354]'
  id: totrans-727
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE354]'
- en: '[PRE355]'
  id: totrans-728
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE355]'
- en: '[PRE356]'
  id: totrans-729
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE356]'
- en: '[PRE357]'
  id: totrans-730
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE357]'
- en: '[PRE358]'
  id: totrans-731
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE358]'
- en: 'Make sure that you replace `<INSERT FUNCTION ARN>` with the ARN of the `deploy-model-to-new-endpoint`
    Lambda function we copied into our text editor. It should have a format that is
    similar to `arn:aws:lambda:us-west-2:<ACCOUNT ID>:function: deploy-model-to-new-endpoint`.'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
- en: 'With the three `LambdaStep` objects ready, let’s prepare the `ConditionStep`
    object, which checks whether an endpoint exists already (using the output of the
    `endpoint_exists_lambda` `LambdaStep` object):'
  id: totrans-733
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE359]'
  id: totrans-734
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE359]'
- en: '[PRE360]'
  id: totrans-735
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE360]'
- en: '[PRE361]'
  id: totrans-736
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE361]'
- en: '[PRE362]'
  id: totrans-737
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE362]'
- en: '[PRE363]'
  id: totrans-738
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE363]'
- en: '[PRE364]'
  id: totrans-739
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE364]'
- en: '[PRE365]'
  id: totrans-740
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE365]'
- en: '[PRE366]'
  id: totrans-741
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE366]'
- en: '[PRE367]'
  id: totrans-742
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE367]'
- en: '[PRE368]'
  id: totrans-743
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE368]'
- en: '[PRE369]'
  id: totrans-744
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE369]'
- en: '[PRE370]'
  id: totrans-745
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE370]'
- en: '[PRE371]'
  id: totrans-746
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE371]'
- en: '[PRE372]'
  id: totrans-747
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE372]'
- en: '[PRE373]'
  id: totrans-748
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE373]'
- en: 'This step tells the ML pipeline to do the following:'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
- en: Deploy the model to a new endpoint if the endpoint does not exist yet.
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy the model to an existing endpoint if the endpoint exists already.
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To help us visualize how we configured the `ConditionStep` object, let’s quickly
    check *Figure 11.17*:'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.17 – Configuring and preparing the ConditionStep object ](img/B18638_11_017.jpg)'
  id: totrans-753
  prefs: []
  type: TYPE_IMG
- en: Figure 11.17 – Configuring and preparing the ConditionStep object
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the `ConditionStep` object is initialized with several
    parameters—`conditions`, `if_steps`, and `else_steps` (in addition to `name` of
    the endpoint). If `EndpointExists` `LambdaStep` returns `True`, then `DeployToExistingEndpoint`
    `LambdaStep` is executed. Otherwise, `DeployToNewEndpoint` `LambdaStep` is executed
    instead.
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
- en: 'With all of the steps ready, let’s initialize a new `Pipeline` object using
    the different step objects we prepared:'
  id: totrans-756
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE374]'
  id: totrans-757
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE374]'
- en: '[PRE375]'
  id: totrans-758
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE375]'
- en: '[PRE376]'
  id: totrans-759
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE376]'
- en: '[PRE377]'
  id: totrans-760
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE377]'
- en: '[PRE378]'
  id: totrans-761
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE378]'
- en: '[PRE379]'
  id: totrans-762
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE379]'
- en: '[PRE380]'
  id: totrans-763
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE380]'
- en: '[PRE381]'
  id: totrans-764
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE381]'
- en: '[PRE382]'
  id: totrans-765
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE382]'
- en: '[PRE383]'
  id: totrans-766
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE383]'
- en: '[PRE384]'
  id: totrans-767
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE384]'
- en: '[PRE385]'
  id: totrans-768
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE385]'
- en: '[PRE386]'
  id: totrans-769
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE386]'
- en: '[PRE387]'
  id: totrans-770
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE387]'
- en: '[PRE388]'
  id: totrans-771
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE388]'
- en: '[PRE389]'
  id: totrans-772
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE389]'
- en: Note that this pipeline is different and separate from the (partial) pipeline
    we prepared in the *Running our first pipeline with SageMaker Pipelines* section
    of this chapter. We should see that this pipeline has a few more additional steps
    once we run it in the next section.
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
- en: Running the complete ML pipeline
  id: totrans-774
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With everything ready, we can now run our end-to-end ML pipeline. Compared
    to the (partial) pipeline we executed in the *Running our first pipeline with
    SageMaker Pipelines* section of this chapter, our (complete) pipeline allows us
    to specify an optional name of the ML inference endpoint (*Note: Do not run the
    following block of code*):'
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE390]'
  id: totrans-776
  prefs: []
  type: TYPE_PRE
  zh: '[PRE390]'
- en: If the endpoint name is not specified, the pipeline proceeds with using the
    default endpoint name value (that is, `AutoGluonEndpoint`) during pipeline execution.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next set of steps, we will run our pipeline, wait for it to deploy a
    trained ML model to a new inference endpoint, and then test the deployed model
    using the test dataset:'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing where we left off after running the last block of code in the `Machine
    Learning Pipelines with SageMaker Pipelines.ipynb` notebook, let’s run the end-to-end
    ML pipeline using the following block of code:'
  id: totrans-779
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE391]'
  id: totrans-780
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE391]'
- en: '[PRE392]'
  id: totrans-781
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE392]'
- en: 'Next, let’s use the `wait()` method to wait for the entire pipeline to complete:'
  id: totrans-782
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE393]'
  id: totrans-783
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE393]'
- en: Note
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline execution should take around 15–30 minutes to complete. Feel free
    to grab a cup of coffee or tea while waiting!
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
- en: While waiting, locate and click on the triangle icon (**SageMaker resources**)
    near the bottom of the left-hand sidebar of SageMaker Studio. This should open
    the **SageMaker resources** pane where we can view and inspect a variety of SageMaker
    resources.
  id: totrans-786
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Pipelines** from the list of options available in the drop-down menu
    of the **SageMaker resources** pane.
  id: totrans-787
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After that, double-click on the row that maps to the `COMPLETE-PIPELINE` pipeline
    we just created. After that double-click on the row that maps to the pipeline
    execution we triggered. You should see a graph similar to what is shown in *Figure
    11.18*:'
  id: totrans-788
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.18 – The ML pipeline is currently running the TrainModel step ](img/B18638_11_018.jpg)'
  id: totrans-789
  prefs: []
  type: TYPE_IMG
- en: Figure 11.18 – The ML pipeline is currently running the TrainModel step
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the `COMPLETE-PIPELINE` pipeline has more steps compared
    to the `PARTIAL-PIPELINE` pipeline we executed in the *Running our first pipeline
    with SageMaker Pipelines* section of this chapter.
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few minutes, the graph should have more steps completed similar to
    what we have in *Figure 11.19*:'
  id: totrans-792
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.19 – The ML pipeline proceeds with running the DeployToNewEndpoint
    step  ](img/B18638_11_019.jpg)'
  id: totrans-793
  prefs: []
  type: TYPE_IMG
- en: Figure 11.19 – The ML pipeline proceeds with running the DeployToNewEndpoint
    step
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that since the ML endpoint does not exist yet (since we deleted
    it earlier while running the `Test Endpoint then Delete.ipynb` notebook), the
    ML pipeline proceeded with running the **DeployToNewEndpoint** step. Note that
    for succeeding runs, if the ML endpoint exists already, the **DeployToExistingEndpoint**
    step should run instead.
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure that the execution role (attached to the `AWSLambda_FullAccess` permission
    policy attached if you encounter the following error while running the Lambda
    functions: **ClientError: User: <ARN> is not authorized to perform: lambda:InvokeFunction
    on resource: <arn> because no identity-based policy allows the lambda:InvokeFunction
    action**. Feel free to check the *Preparing the essential prerequisites* section
    of this chapter for step-by-step instructions on how to update the permissions
    of the execution role.'
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
- en: Wait for the pipeline execution to finish. Once the pipeline has finished running,
    our AutoGluon model should be deployed inside an ML inference endpoint (named
    `AutoGluonEndpoint`).
  id: totrans-798
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate back to the tab corresponding to the `Test Endpoint then Delete.ipynb`
    notebook. Open the `Test Endpoint then Delete.ipynb` notebook. Note that running
    all the cells in the notebook would also delete the existing ML inference endpoint
    (named `AutoGluonEndpoint`) after all cells have finished running.
  id: totrans-799
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
- en: It should take 1–2 minutes to run all the cells in the Jupyter notebook. Feel
    free to grab a cup of coffee or tea while waiting!
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
- en: 'Once all the cells in the `Test Endpoint then Delete.ipynb` notebook have been
    executed, locate the cell containing the following block of code (along with the
    output returned):'
  id: totrans-802
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE394]'
  id: totrans-803
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE394]'
- en: '[PRE395]'
  id: totrans-804
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE395]'
- en: Verify that our model obtained an accuracy score equal to or close to `0.88`
    (or 88%). Note that this should be similar to what we obtained earlier in the
    *Testing our ML inference endpoint* section of this chapter.
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
- en: '*What can we do with this pipeline?* With this pipeline, by specifying different
    endpoint names for each pipeline run, we would be able to train and deploy a model
    to multiple endpoints. This should help us handle scenarios where we would need
    to manage dedicated ML inference endpoints for different environments (such as
    the `production` and `staging` environments). For example, we can have two running
    ML inference endpoints at the same time—`AutoGluonEndpoint-production` and `AutoGluonEndpoint-staging`.
    If we wish to generate a new model from a new dataset, we can trigger a pipeline
    run and specify the endpoint name for the `staging` environment instead of the
    `production` environment. This will help us test and verify the quality of the
    new model deployed in the `staging` environment and ensure that the `production`
    environment is always in a stable state. Once we need to update the `production`
    environment, we can simply trigger another pipeline run and specify the endpoint
    name associated with the `production` environment when training and deploying
    the new model.'
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to manage these types of deployments, and this is one
    of the options available for ML engineers and data scientists.
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
- en: That’s pretty much it! Congratulations on being able to complete a relatively
    more complex ML pipeline! We were able to accomplish a lot in this chapter, and
    we should be ready to design and build our own custom pipelines.
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  id: totrans-810
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have completed working on the hands-on solutions of this chapter,
    it is time we clean up and turn off the resources we will no longer use. In the
    next set of steps, we will locate and turn off any remaining running instances
    in **SageMaker Studio**:'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to check and delete all running inference endpoints under **SageMaker
    resources** (if any). To check whether there are running inference endpoints,
    click on the **SageMaker resources** icon and then select **Endpoints** from the
    list of options in the drop-down menu.
  id: totrans-812
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the **File** menu and select **Shut down** from the list of available options.
    This should turn off all running instances inside SageMaker Studio.
  id: totrans-813
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is important to note that this cleanup operation needs to be performed after
    using **SageMaker Studio**. These resources are not turned off automatically by
    SageMaker even during periods of inactivity. Make sure to review whether all delete
    operations have succeeded before proceeding to the next section.
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to clean up and delete all the other resources in the AWS account
    (for example, the Cloud9 environment and the VPCs and Lambda functions we created),
    too.
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
- en: Recommended strategies and best practices
  id: totrans-817
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we end this chapter (and this book), let’s quickly discuss some of the
    recommended strategies and best practices when using SageMaker Pipelines to prepare
    automated ML workflows. *What improvements can we make to the initial version
    of our pipeline?* Here are some of the possible upgrades we can implement to make
    our setup more scalable, more secure, and more capable of handling different types
    of ML and ML engineering requirements:'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
- en: Configure and set up **autoscaling** (automatic scaling) of the ML inference
    endpoint upon creation to dynamically adjust the number of resources used to handle
    the incoming traffic (of ML inference requests).
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allow ML models to also be deployed in **serverless** and **asynchronous** endpoints
    (depending on the value of an additional pipeline input parameter) to help provide
    additional model deployment options for a variety of use cases.
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add an additional step (or steps) in the pipeline that automatically evaluates
    the trained ML model using the test set and rejects the deployment of the model
    if the target metric value falls below a specified threshold score.
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add an additional step in the pipeline that uses **SageMaker Clarify** to check
    for biases and drifts.
  id: totrans-822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trigger a pipeline execution once an event happens through **Amazon EventBridge**
    (such as a file being uploaded in an Amazon S3 bucket).
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cache specific pipeline steps to speed up repeated pipeline executions.
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilize **Retry policies** to automatically retry specific pipeline steps when
    exceptions and errors occur during pipeline executions.
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use **SageMaker Pipelines** with **SageMaker Projects** for building complete
    ML workflows, which may involve CI/CD capabilities (using AWS services such as
    **AWS CodeCommit** and **AWS CodePipeline**).
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update the IAM roles used in this chapter with a more restrictive set of permissions
    to improve the security of the setup.
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To manage the long-term costs of running SageMaker resources, we can utilize
    the **Machine Learning Savings Plans**, which involves reducing the overall cost
    of running resources after making a long-term commitment (for example, a 1-year
    or 3-year commitment)
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s more we can add to this list, but these should do for now! Make sure
    that you review and check the recommended solutions and strategies shared in [*Chapter
    9*](B18638_09.xhtml#_idTextAnchor187), *Security, Governance, and Compliance Strategies*,
    too.
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-830
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used **SageMaker Pipelines** to build end-to-end automated
    ML pipelines. We started by preparing a relatively simple pipeline with three
    steps—including the data preparation step, the model training step, and the model
    registration step. After preparing and defining the pipeline, we proceeded with
    triggering a pipeline execution that registered a newly trained model to the **SageMaker
    Model Registry** after the pipeline execution finished running.
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
- en: Then, we prepared three AWS Lambda functions that would be used for the model
    deployment steps of the second ML pipeline. After preparing the Lambda functions,
    we proceeded with completing the end-to-end ML pipeline by adding a few additional
    steps to deploy the model to a new or existing ML inference endpoint. Finally,
    we discussed relevant best practices and strategies to secure, scale, and manage
    ML pipelines using the technology stack we used in this chapter.
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
- en: You’ve finally reached the end of this book! Congratulations on completing all
    the chapters including the hands-on examples and solutions discussed in this book.
    It has been an amazing journey from start to finish, and it would be great if
    you can share this journey with others, too.
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-834
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, you might want to dive deeper into the relevant subtopics discussed
    by checking the references listed in the *Further reading* section of each of
    the previous chapters. In addition to these, you can check the following resources,
    too:'
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
- en: '*Amazon SageMaker Model Building Pipelines – Pipeline Steps* ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.xhtml))'
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Boto3 – SageMaker Client* ([https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.xhtml](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.xhtml))'
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Amazon SageMaker – AutoGluon-Tabular Algorithm* ([https://docs.aws.amazon.com/sagemaker/latest/dg/autogluon-tabular.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/autogluon-tabular.xhtml))'
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Automate MLOps with SageMaker Projects* ([https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects.xhtml))'
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Machine Learning Savings Plans* ([https://aws.amazon.com/savingsplans/ml-pricing/](https://aws.amazon.com/savingsplans/ml-pricing/))'
  id: totrans-840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*SageMaker – Amazon EventBridge Integration* ([https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.xhtml))'
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
