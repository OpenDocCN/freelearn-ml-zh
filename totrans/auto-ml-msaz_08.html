<html><head></head><body>
		<div id="_idContainer077">
			<h1 id="_idParaDest-79"><em class="italic"><a id="_idTextAnchor081"/>Chapter 6</em>: Building an AutoML Forecasting Solution</h1>
			<p>Having built an AutoML regression and classification solution, you are now ready to tackle a more complicated problem: <strong class="bold">forecasting</strong>. Forecasting is inherently a much more complex technique than either classification or regression. Those two <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) problem types assume that time is irrelevant. Regardless of how much time passes, your diabetes model will always be able to accurately predict whose condition worsens over time. Your Titanic model will always be able to predict who lives and who dies. In contrast, with forecasting problems, you are always trying to predict future events based on past events; time will always be a factor in your model.</p>
			<p>You will begin this chapter similarly to how you began <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, and <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>. First, you will navigate to your Jupyter environment, load in data, train a model, and evaluate the results. You will learn two inherently different ways to train forecasting models with AutoML. One way uses only the <strong class="bold">ARIMA</strong> and <strong class="bold">Prophet</strong> algorithms; the other way uses all other available algorithms. </p>
			<p>At the end of this chapter, you will learn tips and tricks on how to fine-tune your forecasting models by adjusting AutoML settings; there are a lot of settings specific to forecasting, so you will spend a lot of time covering their various use cases. </p>
			<p>By the end of his chapter, you will be able to train forecasting models using AutoML without making mistakes. Relative to other techniques, forecasting problems are much easier to screw up, so this is quite an accomplishment. You will understand how to transform and arrange your data for forecasting and how to adjust AutoML settings to produce more accurate, more trustworthy models, solidifying your expertise in Azure AutoML.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Prepping data for AutoML forecasting</li>
				<li>Training an AutoML forecasting model</li>
				<li>Registering your trained forecasting model</li>
				<li>Fine-tuning your AutoML forecasting model</li>
			</ul>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor082"/>Technical requirements</h1>
			<p>Like <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, you will be creating and training models with Python code in a Jupyter notebook running on an Azure compute instance. As such, you will require a working internet connection, an <strong class="bold">Azure Machine Learning Service</strong> (<strong class="bold">AMLS</strong>) <strong class="bold">workspace</strong>, and a compute instance. Likewise, you will need to have a working compute cluster to train models remotely while you continue to work on your notebook. The full list of requirements is as follows:</p>
			<ul>
				<li>Access to the internet.</li>
				<li>A web browser, preferably Google Chrome or Microsoft Edge Chromium.</li>
				<li>A Microsoft Azure account.</li>
				<li>You should have created an AMLS workspace.</li>
				<li>You should have created a compute instance. </li>
				<li>You should have created the compute cluster in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service.</em></li>
				<li>You should understand how to navigate to the Jupyter environment from an Azure compute instance as demonstrated in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution.</em></li>
			</ul>
			<p>The code for this chapter is available here: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter06">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter06</a>. </p>
			<h1 id="_idParaDest-81"><a id="_idTextAnchor083"/>Prepping data for AutoML forecasting</h1>
			<p>Forecasting<a id="_idIndexMarker279"/> is very different from either classification or regression. ML models <a id="_idIndexMarker280"/>for regression or classification predict <a id="_idIndexMarker281"/>some output based on some input data. ML models for forecasting, on the other hand, predict a future state based on patterns found in the past. This means that there are key time-related details you need to pay attention to while shaping your data.</p>
			<p>For this<a id="_idIndexMarker282"/> exercise, you are going to use the <strong class="source-inline">OJ Sales Simulated Data</strong> Azure Open <a id="_idIndexMarker283"/>Dataset for forecasting. Similar to the <strong class="source-inline">Diabetes Sample</strong> Azure Open Dataset you used for regression, <strong class="source-inline">OJ Sales Simulated Data</strong> is available simply by having an Azure account. You will use this data to create a model to predict future orange juice sales across different brands and stores. </p>
			<p>There is <a id="_idIndexMarker284"/>one additional key difference; <strong class="source-inline">OJ Sales Simulated Data</strong> is a <strong class="bold">file dataset</strong> instead of a <strong class="bold">tabular dataset</strong>. While tabular datasets consist of one file containing columns and <a id="_idIndexMarker285"/>rows, file datasets consist of many files, tabular or otherwise. </p>
			<p>Like all the other coding work you have performed in your AMLS workspace, you will begin by opening up Jupyter from your compute instance and creating a new Jupyter notebook. Then, you will load in your data, transform it into a pandas dataframe, and register it as a dataset, enabling you to use it to train an ML model with AutoML.</p>
			<h2 id="_idParaDest-82"><a id="_idTextAnchor084"/>Navigating to your Jupyter environment</h2>
			<p>You will <a id="_idIndexMarker286"/>begin by creating a new Jupyter notebook<a id="_idIndexMarker287"/> with the following steps:</p>
			<ol>
				<li>First, open up<a id="_idIndexMarker288"/> your <strong class="bold">Azure Machine Learning</strong> (<strong class="bold">AML</strong>) <strong class="bold">studio</strong> by navigating to <a href="http://ml.azure.com">http://ml.azure.com</a>. </li>
				<li>Click <strong class="bold">Compute</strong> from the left-hand panel.</li>
				<li>Select your compute instance. Click <strong class="bold">Start</strong> if it's not running. <p class="callout-heading">Important tip</p><p class="callout">To save money while working on Azure, turn off your compute instance when you are not using it. Compute instances are paid for on an hourly basis.</p></li>
				<li>Click <strong class="bold">Jupyter</strong> to enter your Jupyter environment.</li>
				<li>Create a new Jupyter notebook by clicking <strong class="bold">New</strong> on the right-hand side of your screen and select <strong class="bold">Python 3.6 – AzureML</strong>. The version of Python may be different due to updates.</li>
				<li>Rename<a id="_idIndexMarker289"/> your Jupyter notebook to <strong class="source-inline">OJ Forecasting_AutoML</strong>. If you need a refresher as to how to do so, please review <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>.</li>
			</ol>
			<p>With your notebook created, you are now ready to load in the orange juice sales data and transform it with Python. </p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor085"/>Loading and transforming your data</h2>
			<p>Now it's time to<a id="_idIndexMarker290"/> work with your data, following the patterns<a id="_idIndexMarker291"/> you used in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, and <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>. The purpose of this section is to take a file dataset with many files, combine all the files together, and create a new tabular dataset. Perform the following steps:</p>
			<ol>
				<li value="1">Load in all of the Azure libraries you will need with the following code:<p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment</p><p class="source-code">from azureml.core.compute import ComputeTarget</p><p class="source-code">from azureml.train.automl import AutoMLConfig</p><p class="source-code">from azureml.train.automl.run import AutoMLRun</p><p class="source-code">from azureml.widgets import RunDetails</p><p class="source-code">from azureml.opendatasets import OjSalesSimulated</p><p class="source-code">from azureml.automl.core.forecasting_parameters import ForecastingParameters</p><p>You should recognize <strong class="source-inline">Workspace</strong>, <strong class="source-inline">Dataset</strong>, <strong class="source-inline">Datastore</strong>, <strong class="source-inline">Experiment</strong>, <strong class="source-inline">ComputeTarget</strong>, <strong class="source-inline">AutoMLConfig</strong>, <strong class="source-inline">AutoMLRun</strong>, and <strong class="source-inline">RunDetails</strong> from <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>. </p><p><strong class="source-inline">OjSalesSimulated</strong> lets you directly <a id="_idIndexMarker292"/>access the <strong class="source-inline">OJ Sales Simulated Data</strong> Azure Open Dataset via the <strong class="bold">AzureML Python SDK</strong>. <strong class="source-inline">ForecastingParameters</strong> is necessary for AutoML forecasting tasks, as you cannot simply<a id="_idIndexMarker293"/> pass in forecasting-specific parameters <a id="_idIndexMarker294"/>to an <strong class="source-inline">AutoMLConfig</strong> object. You must first assign them to <strong class="source-inline">ForecastingParameters</strong> and then pass those parameters into your AutoML configurations.</p><p class="callout-heading">Important note</p><p class="callout">If you are having trouble loading any Azure libraries, update the Azure ML SDK by running the <strong class="source-inline">Update</strong> <strong class="source-inline">AzureML</strong> <strong class="source-inline">SDK.ipynb</strong> notebook found here: https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb.</p></li>
				<li>Load in <strong class="source-inline">pandas</strong>, <strong class="source-inline">numpy</strong>, <strong class="source-inline">os</strong>, and <strong class="source-inline">path</strong> with the following code:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">import os</p><p class="source-code">from pathlib import Path</p><p>You should recognize <strong class="source-inline">pandas</strong> and <strong class="source-inline">numpy</strong> from <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>. <strong class="source-inline">os</strong> and <strong class="source-inline">Path</strong> will be new to you. These packages let you create and manipulate files and folders in your Jupyter environment from within a Jupyter notebook. Moreover, they are necessary when working with file datasets such as <strong class="source-inline">OjSimulatedSales</strong> to turn them into tabular datasets for AutoML training.</p></li>
				<li>Connect your Jupyter notebook to your AMLS workspace:<p class="source-code">ws = Workspace.from_config()</p><p>If you are prompted to log in, do so by following the instructions.</p></li>
				<li>Set your compute cluster: <p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p><p>You created this compute cluster in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em>.</p></li>
				<li>Set your<a id="_idIndexMarker295"/> datastore. For this exercise, we will use the <a id="_idIndexMarker296"/>default datastore that comes with your AMLS workspace:<p class="source-code">datastore = Datastore.get_default(ws)</p></li>
				<li>Pull in a subset of <strong class="source-inline">10</strong> files from <strong class="source-inline">OJ Sales Simulated Data</strong> with this code:<p class="source-code">oj_sales_files = OjSalesSimulated.get_file_dataset()</p><p class="source-code">oj_sales = oj_sales_files.take(10)</p><p class="callout-heading">Important tip</p><p class="callout">There are over 4,000 files in the <strong class="source-inline">OJ Sales Simulated Data</strong> Azure Open Dataset. Pulling all of them can result in extended training times.</p></li>
				<li>Make a folder to download the files to your Jupyter environment with the following code: <p class="source-code">folder_name = "OJ_Sales"</p><p class="source-code">os.makedirs(folder_name, exist_ok=True)</p><p>In order to use file datasets, you first need to download them to your local Jupyter environment. Then, you can read them in as a pandas dataframe by concatenating the files.</p></li>
				<li>Download the 10 files to your newly created <strong class="source-inline">OJ_Sales</strong> folder with the following code: <p class="source-code">oj_sales.download(folder_name, overwrite=True)</p><p>If you navigate to the <strong class="source-inline">OJ Sales</strong> folder on your Jupyter environment, you should see the files there after running this code.</p></li>
				<li>Read in the 10 files as a single pandas dataframe with the following code:<p class="source-code">OJ_file_path = Path('OJ_Sales').rglob('*.csv')</p><p class="source-code">OJ_files = [x for x in OJ_file_path]</p><p class="source-code">df = pd.concat((pd.read_csv(f) for f in OJ_files))</p><p>For this, we <a id="_idIndexMarker297"/>will need to use the <strong class="source-inline">Path</strong> package to <a id="_idIndexMarker298"/>indicate the folder and file extension, as well as <strong class="source-inline">pandas</strong> to concatenate the 10 files into a single dataframe. Please note that this code will read everything in your <strong class="source-inline">OJ Sales</strong> folder. Do not place additional files in this folder or this will corrupt this portion of the code.</p></li>
				<li>View the first 10 rows of your data. Make sure that it looks correct:<p class="source-code">df.head(10)</p><p>The orange juice sales data has seven columns: <strong class="source-inline">WeekStarting</strong>, <strong class="source-inline">Store</strong>, <strong class="source-inline">Brand</strong>, <strong class="source-inline">Quantity</strong>, <strong class="source-inline">Advert</strong>, <strong class="source-inline">Price</strong>, and <strong class="source-inline">Revenue</strong>. <strong class="source-inline">Advert</strong> indicates whether there was an advertising campaign for that brand of orange juice for that week. The other columns are self-explanatory. The first 10 rows of data appear as follows:</p><div id="_idContainer072" class="IMG---Figure"><img src="image/Figure_6.1_B16595.jpg" alt="Figure 6.1 – Viewing your Orange Juice Sales dataset "/></div><p class="figure-caption">Figure 6.1 – Viewing your Orange Juice Sales dataset</p></li>
				<li>Register your <a id="_idIndexMarker299"/>pandas dataframe as a dataset:<p class="source-code">Dataset.Tabular.register_pandas_dataframe(df, datastore,</p><p class="source-code">                            "OJ Sales Sample")</p><p>While it may seem <a id="_idIndexMarker300"/>strange to register a file dataset as a tabular dataset, tabular datasets are inherently easier to work with. File datasets are simply pointers to a folder containing a lot of files; lots of data preprocessing work must be performed on the files before you can use them. Tabular datasets, on the other hand, are formatted and ready for immediate use with AutoML.</p></li>
			</ol>
			<p>Here, it's important to note the main differences <a id="_idIndexMarker301"/>between <strong class="bold">time series data</strong> and normal data. Time series data always has a time column, in this case, <strong class="source-inline">WeekStarting</strong>. The time column needs to be on some sort of regular cadence, for example, every day, week, month, or year. In this case, it's every week on a Thursday. </p>
			<p>Certain algorithms, such as <em class="italic">Prophet</em> and <em class="italic">ARIMA</em>, require <a id="_idIndexMarker302"/>you to have a time column with no gaps. Other AutoML <a id="_idIndexMarker303"/>algorithms can work with gaps, but only if you do not enable certain features, such as time lags, in your target column.</p>
			<p class="callout-heading">Important tip</p>
			<p class="callout">Gaps in your time column also prevent you from using certain features specific to forecasting, specifically lags of your target column and moving averages of those lags. These features often improve performance. Carefully study your data to remove gaps for best performance in forecasting solutions.</p>
			<p>The other essential element of time series data are<a id="_idIndexMarker304"/> your <strong class="bold">Grain</strong> columns. Grain columns indicate different time series within your data. This is best illustrated by means of an example. In the orange juice data, <strong class="source-inline">Store</strong> and <strong class="source-inline">Brand</strong> are your grain columns; there are separate time series for each combination of store and brand. </p>
			<p>If AutoML detects multiple time series on a single grain, it will automatically fail. In other words, you cannot have duplicate dates for a single grain. For this reason, carefully study your data to remove duplicate dates across the same grain when using AutoML forecasting. </p>
			<p>With these things in mind, you are now ready to train an AutoML forecasting model. First, you will train a model without using <em class="italic">ARIMA</em> and <em class="italic">Prophet</em>. Then, you will train a model using these two algorithms.</p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor086"/>Training an AutoML forecasting model</h1>
			<p>Training an <a id="_idIndexMarker305"/>AutoML forecasting is most similar to training an AutoML regression model. Like regression and unlike classification, you are trying to predict a number. Unlike regression, this number is always in the future based on patterns found in the past. Also, unlike regression, you can predict a whole series of numbers into the future. For example, you can choose to predict one month out into the future or you can choose to predict 6, 12, 18, or even 24 months out.</p>
			<p class="callout-heading">Important tip</p>
			<p class="callout">The further out you try to predict, the less accurate your forecasting model will be.</p>
			<p>Follow the <a id="_idIndexMarker306"/>same steps you have seen in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, and <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>. First, begin by setting a name for your experiment. Then, set your target column and your AutoML configurations.</p>
			<p>For forecasting, there is an additional step: setting your <strong class="bold">forecasting parameters</strong>. This is where you will set things such as your time column, grain<a id="_idIndexMarker307"/> columns, and lag settings. These settings then need to be passed into your AutoML configurations as a single forecasting parameters object. Once this is done, only then can you use AutoML to train a forecasting model. </p>
			<p>In this section, you will repeat this process twice, first by training a model as normal using the standard algorithms available for forecasting in AutoML, and second, you will repeat this process using slightly different settings to enable ARIMA and Prophet and to compare the performance of the two AutoML models. </p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor087"/>Training a forecasting model with standard algorithms</h2>
			<p>To<a id="_idIndexMarker308"/> train your forecasting model using AutoML, follow <a id="_idIndexMarker309"/>these steps, continuing in the <strong class="source-inline">OJ Forecasting AutoML</strong> Jupyter notebook:</p>
			<ol>
				<li value="1">Set your experiment and give it a name with the following code:<p class="source-code">experiment_name = 'OJ-Sales-Forecasting'</p><p class="source-code">exp = Experiment(workspace=ws, name=experiment_name)</p><p>One important thing to remember is that an experiment can be a set of multiple training runs and not just a single training run. In other words, we can train multiple models with different settings under the same experiment name.</p></li>
				<li>Retrieve your <strong class="source-inline">OJ Sales Sample</strong> dataset with the following code:<p class="source-code">dataset_name = "OJ Sales Sample"</p><p class="source-code">dataset = Dataset.get_by_name(ws, dataset_name, version='latest')</p></li>
				<li>Set your target column to <strong class="source-inline">Quantity</strong>:<p class="source-code">target_column = 'Quantity'</p><p>Capitalization matters with Python; keep that in mind.</p></li>
				<li>Create a<a id="_idIndexMarker310"/> variable for your AutoML task. <strong class="source-inline">task</strong> is<a id="_idIndexMarker311"/> the type of AutoML model you are trying to train. To predict future numbers, enter <strong class="source-inline">forecasting</strong>: <p class="source-code">task = 'forecasting'</p><p class="callout-heading">Important note</p><p class="callout">It is always incorrect to train a forecasting problem as a regression problem. Even though they both nominally do the same thing, predicting a number, forecasting requires a much more careful approach to not include future values when training a model. Standard cross-validation methods that are used for regression do not apply to forecasting problems, so be sure to set <strong class="source-inline">task</strong> to <strong class="source-inline">forecasting</strong>.</p></li>
				<li>Create a variable for your<a id="_idIndexMarker312"/> primary metric. <strong class="bold">The primary metric</strong> is how your model will be scored. Use <strong class="bold">normalized root mean squared error</strong> (<strong class="bold">normalized RMSE</strong>). This <a id="_idIndexMarker313"/>metric takes the prediction and subtracts it from the actual value for each observation, squares it, and averages the score across all observations. The lower the score, the better your model. Other options for<a id="_idIndexMarker314"/> forecasting <a id="_idIndexMarker315"/>include <strong class="bold">R2 score</strong>, <strong class="bold">Spearman correlation</strong>, and <strong class="bold">normalized mean absolute error</strong> (<strong class="bold">normalized MAE</strong>). Note that <a id="_idIndexMarker316"/>these are identical to regression metrics:<p class="source-code">primary_metric = 'normalized_root_mean_squared_error'</p></li>
				<li>Create a variable for <strong class="source-inline">featurization</strong>. You can set <strong class="source-inline">featurization</strong> to <strong class="source-inline">auto</strong> or <strong class="source-inline">off</strong>. Set it to <strong class="source-inline">auto</strong>: <p class="source-code">featurization = 'auto'</p><p>If you set <strong class="source-inline">featurization</strong> to <strong class="source-inline">off</strong>, you will have to drop high cardinality features, impute null values, one-hot encode your data, and generate additional features yourself. AutoML handles these for you automatically when featurization is set to <strong class="source-inline">auto</strong>.</p></li>
				<li>With <a id="_idIndexMarker317"/>forecasting, featurization also<a id="_idIndexMarker318"/> creates a variety of date/time features from your time column, including year, month, week, day of week, A.M./P.M., and hour of day. Always set <strong class="source-inline">featurization</strong> to <strong class="source-inline">auto</strong> unless you are an expert data scientist who can do everything yourself. <p>Set your forecasting parameters. There are a lot of these and we will go over them one by one as follows:</p><p>a) <strong class="source-inline">country_or_region_for_holidays</strong> determines which country to use to generate columns indicating different national holidays. You can set this parameter to either nothing, a single country, or a list of countries. Set it to <strong class="source-inline">US</strong> for United States. You will get a separate column for each holiday.</p><p>b) <strong class="source-inline">drop_columns_names</strong> lets you input a list of columns to drop before training your forecasting model. Drop the <strong class="source-inline">Revenue</strong> column here, as it's partially derived from your target column, <strong class="source-inline">Quantity</strong>. </p><p class="callout-heading">Important note </p><p class="callout">Any time you have a column that's derived partially or wholly from your target column, drop it. This is true for all types of ML problems and is not specific to forecasting. Leaving it in will falsely give you a highly performing model. Furthermore, any time you produce an ML model that has nearly zero error, it's highly likely that you passed in a derived column.</p><p>c) <strong class="source-inline">forecast_horizon</strong> is the number of periods you want to predict into the future. It is always based on the cadence of your time column. Set this feature to <strong class="source-inline">6</strong> to predict sales 6 weeks out. If your time column was in months and not weeks, setting it to <strong class="source-inline">6</strong> would predict sales 6 months out into the future.</p><p>d) <strong class="source-inline">target_rolling_window_size</strong> creates features based on averaging lagged <a id="_idIndexMarker319"/>versions of the target column. For<a id="_idIndexMarker320"/> example, if you set it to <strong class="source-inline">2</strong>, this will create a feature that is the average of the last 2 weeks' worth of data. In this case, set it to <strong class="source-inline">auto</strong> for AutoML to automatically determine how large this window should be.</p><p>e) <strong class="source-inline">target_lags</strong> creates features based on lagged versions of the target column. If you set it to <strong class="source-inline">2</strong>, it will create two features, one feature for last week's sales, and another feature for sales 2 weeks previous. Set it to <strong class="source-inline">auto</strong> for AutoML to automatically determine how many lagged features you should use.</p><p>f) <strong class="source-inline">feature_lags</strong> creates features based on lagged versions of numeric columns in your dataset other than your target column. It works similarly to <strong class="source-inline">target_lags</strong>, except that it will lag every other column that is not a target column, grain column, or time column. Set it to <strong class="source-inline">auto</strong> for AutoML to automatically determine how many lagged features to use.</p><p>g) <strong class="source-inline">seasonality</strong> infers the seasonality in your time series data. It looks for repeating patterns that happen in a predictable way based on time. Set this feature to <strong class="source-inline">auto</strong> for AutoML to detect seasonal patterns in your data.</p><p>h) <strong class="source-inline">short_series_handling</strong> enables AutoML to continue running even if some of your time series are too short to model given your forecast horizon and lags. An example would be if one of your grains only had 1 time period worth of data. Set this to <strong class="source-inline">true</strong>. </p><p class="callout-heading">Important tip</p><p class="callout">Whenever you have multiple grains in your data and new grains can enter your dataset at any time, always set <strong class="source-inline">short_series_handling</strong> to <strong class="source-inline">true</strong>. It's very likely that new grains will not have enough data to train a model, and setting this to <strong class="source-inline">false</strong> will cause your entire AutoML run to fail.</p><p>i) <strong class="source-inline">use_stl</strong> refers to <strong class="bold">Season and Trend Decomposition using Loess</strong>. Use this feature to <a id="_idIndexMarker321"/>generate either season or season and trend components for your time series. To generate both season and trend components, enter <strong class="source-inline">season_trend</strong>. Most forecasts do have some <strong class="bold">seasonal component</strong> to them, patterns that show up in the data year after year. As such, it's a good idea to set <a id="_idIndexMarker322"/>this to <strong class="source-inline">season_trend</strong>.</p><p>j) <strong class="source-inline">time_column_name</strong> indicates your time column. Specify <strong class="source-inline">WeekStarting</strong>.</p><p>k) <strong class="source-inline">time_series_id_column_names</strong> indicates your grain columns. All columns that correspond to different time series need to be included in this list. AutoML will fail if it finds duplicate dates on what it thinks should be a single grain. Specify <strong class="source-inline">Store</strong> and <strong class="source-inline">Brand</strong> to ensure that AutoML handles your data correctly.</p><p>l) <strong class="source-inline">Short_series_handling_configuration</strong> simply indicates whether or not short series should be padded. Set this to <strong class="source-inline">auto</strong> to pad short time series.</p><p>m) <strong class="source-inline">validate_params</strong> ensures that you are using acceptable forecasting parameters. Always set this to <strong class="source-inline">true</strong>.</p><p>With all of this in mind, set your forecasting parameters with the following code: </p><p class="source-code">params=\</p><p class="source-code">ForecastingParameters.from_parameters_dict( </p><p class="source-code">{'country_or_region_for_holidays':'US',\</p><p class="source-code">                'drop_columns_names':'Revenue',\</p><p class="source-code">                'forecast_horizon': 6,\</p><p class="source-code">                'target_rolling_window_size': 'auto',\</p><p class="source-code">                'target_lags': 'auto',\</p><p class="source-code">                'feature_lags': 'auto',\</p><p class="source-code">                'seasonality': 'auto',\</p><p class="source-code">                'short_series_handling': True,\</p><p class="source-code">                'use_stl': 'season_trend',\</p><p class="source-code">                'time_column_name':'WeekStarting',\</p><p class="source-code">                'time_series_id_column_names':\</p><p class="source-code">                ['Store','Brand'],\</p><p class="source-code">               'short_series_handling_configuration':\</p><p class="source-code">                'auto'},\</p><p class="source-code">                validate_params=True)</p><p class="callout-heading">Important note</p><p class="callout">There are quite a large number of parameters specific to forecasting. Take your time to understand these settings in depth by reading the <em class="italic">Azure AutoML ForecastingParameters</em> documentation here: <a href="https://docs.microsoft.com/en-us/python/api/azureml-automl-core/azureml.automl.core.forecasting_parameters.forecastingparameters?view=azure-ml-py">https://docs.microsoft.com/en-us/python/api/azureml-automl-core/azureml.automl.core.forecasting_parameters.forecastingparameters?view=azure-ml-py</a>.</p></li>
				<li>Configure<a id="_idIndexMarker323"/> your AutoML run. Here, you will pass in your task, primary metric, featurization settings, compute target, dataset, target column, and forecasting parameters. All of these you have previously created. You will also pass in how long the experiment will run for, whether it will stop early if model performance does not improve, the number of cross-validations, and model explainability settings.<p>Additionally, you<a id="_idIndexMarker324"/> will pass in whether or not you want to <a id="_idIndexMarker325"/>use <strong class="bold">ensemble models</strong>, models that are combinations of other models. For forecasting, set your cross-validation setting to <strong class="source-inline">3</strong> splits; unlike classification or regression, forecasting<a id="_idIndexMarker326"/> runs are more accurate when you set cross-validation to a lower number. This is due to the nature of how AutoML splits the data into different sets for the purpose of scoring performance:</p><p class="source-code">config = AutoMLConfig(task=task,</p><p class="source-code">                     primary_metric=primary_metric,</p><p class="source-code">                     featurization=featurization,</p><p class="source-code">                     compute_target=compute_target,</p><p class="source-code">                     training_data=dataset,</p><p class="source-code">                     label_column_name=target_column,</p><p class="source-code">                     experiment_timeout_minutes=15,</p><p class="source-code">                     enable_early_stopping=True,</p><p class="source-code">                     n_cross_validations=3,</p><p class="source-code">                     model_explainability=True,</p><p class="source-code">                     enable_stack_ensemble=False,</p><p class="source-code">                     enable_voting_ensemble=True,</p><p class="source-code">                     forecasting_parameters=params)</p><p class="callout-heading">Important note</p><p class="callout"><strong class="bold">Stack ensembles</strong> can<a id="_idIndexMarker327"/> lead to overfitting when used for forecasting problems. As a result, it's recommended to set it to <strong class="source-inline">False</strong>. This is not the case for regression or classification.</p></li>
				<li>Train <a id="_idIndexMarker328"/>your model and watch the<a id="_idIndexMarker329"/> results in real time:<p class="source-code">AutoML_run = exp.submit(config, show_output = True)</p><p class="source-code">RunDetails(AutoML_run).show()</p></li>
			</ol>
			<p>As before, kick off your AutoML run, make yourself some coffee, then come back and watch your models get trained in real time. You will<a id="_idIndexMarker330"/> see a <strong class="bold">data guardrails</strong> check, as seen in <em class="italic">Figure 6.2</em>. Notice how it has changed for forecasting: </p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/Figure_6.2_B16595.jpg" alt="Figure 6.2 – Data guardrails check for forecasting "/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – Data guardrails check for forecasting</p>
			<p>First, data guardrails will check your time column to make sure that all data points are aligned with the correct frequency. For your <strong class="source-inline">OJ Sales Sample</strong> data, this means making sure that each data point falls on a Thursday and is separated by 1 week. </p>
			<p>Then, data guardrails <a id="_idIndexMarker331"/>will impute missing values the same way it did for classification and regression. Here, there are no missing values in any of the columns. Lastly, it will look for time series that are too short to train with your settings. In the case that AutoML detects short series, it will create simpler models to handle these cases.</p>
			<p>After completing the data guardrails check, AutoML will start training models with different combinations of feature transformations, algorithms, and hyperparameters. If there are no features other than the time column, grain columns, and target column, it will train ARIMA and Prophet <a id="_idIndexMarker332"/>models in addition to its standard suite of forecasting models. Your <a id="_idIndexMarker333"/>output should resemble <em class="italic">Figure 6.3</em>:</p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/Figure_6.3_B16595.jpg" alt="Figure 6.3 – AutoML results for forecasting "/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.3 – AutoML results for forecasting</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor088"/>Training a forecasting model with Prophet and ARIMA</h2>
			<p>One <a id="_idIndexMarker334"/>important difference between forecasting and the other two types of<a id="_idIndexMarker335"/> AutoML problems are the<a id="_idIndexMarker336"/> Prophet and ARIMA algorithms. Prophet and <a id="_idIndexMarker337"/>ARIMA are inherently different from all of the other algorithms in that, in order to train them, all you need are the grain columns, the target column, and the time column. That's it. Adding any other columns will restrict AutoML from using these algorithms.</p>
			<p>What's different about Prophet and ARIMA is that they only use patterns found in the target column to make predictions. Other variables are ignored. Sometimes, they will outperform other algorithms; other times, they will not. It's hard to know when without trying. </p>
			<p>Because it's hard to know how well ARIMA and Prophet will perform relative to other algorithms, it's recommended to always try training them if you can. That is, if you have time series data without gaps in your time column, always train ARIMA and Prophet models first as your baseline. They take a longer time to train, so it's recommended that you increase your experiment timeout, especially with larger datasets. </p>
			<p>To build an AutoML forecasting solution using ARIMA and Prophet, follow these steps:</p>
			<ol>
				<li value="1">Copy <em class="italic">steps 1-6</em> from the previous section until you get to forecasting parameters.</li>
				<li>Within forecasting parameters, remove all of your feature columns, leaving only your time, grain, and target columns. Also, turn off all AutoML generated features, such as holidays, feature lags, and targets lags, by setting them to <strong class="source-inline">None</strong>, as seen in the following code block:<p class="source-code">params=\</p><p class="source-code">ForecastingParameters.from_parameters_dict(\</p><p class="source-code">{'country_or_region_for_holidays':None,\</p><p class="source-code">                  'drop_columns_names':\</p><p class="source-code">                  ['Revenue','Price','Advert'],\</p><p class="source-code">                  'forecast_horizon': 6,\</p><p class="source-code">                  'target_rolling_window_size': None,\</p><p class="source-code">                  'target_lags': None,\</p><p class="source-code">                  'feature_lags': None,\</p><p class="source-code">                  'seasonality': 'auto',\</p><p class="source-code">                  'short_series_handling': True,\</p><p class="source-code">                  'use_stl': 'season_trend',\</p><p class="source-code">                  'time_column_name':'WeekStarting',\</p><p class="source-code">                  'time_series_id_column_names':\</p><p class="source-code">                  ['Store','Brand'],</p><p class="source-code">               'short_series_handling_configuration':\</p><p class="source-code">                  'auto'},\</p><p class="source-code">                  validate_params=True)</p><p>Feature <a id="_idIndexMarker338"/>lags and target lags work by <a id="_idIndexMarker339"/>creating additional variables. This is <a id="_idIndexMarker340"/>why they need to be removed from<a id="_idIndexMarker341"/> your data in order for AutoML to run Prophet and ARIMA.</p></li>
				<li>Configure your AutoML run as you did in <em class="italic">Step 8</em>, passing in your updated forecasting parameters.</li>
				<li>Train your model and watch the results in real time:<p class="source-code">Prophet_ARIMA_run = exp.submit(config, show_output = True)</p><p class="source-code">RunDetails(Prophet_ARIMA_run).show()</p></li>
			</ol>
			<p>Once you rerun AutoML with these settings, your results should resemble <em class="italic">Figure 6.4</em>. Notice that, for this problem, ARIMA and Prophet did not return better results, and that the voting ensemble outperformed all models as usual:</p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/Figure_6.4_B16595.jpg" alt="Figure 6.4 – AutoML forecasting results with ARIMA and Prophet "/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.4 – AutoML forecasting results with ARIMA and Prophet</p>
			<p>You have now trained two sets of models with your <strong class="source-inline">OJ Sales Sample</strong> data and have achieved a pretty low normalized RMSE. You can now move on to the next section to register your model. Registered models are necessary for later use in scoring new data through ML pipelines or real-time endpoints. </p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor089"/>Registering your trained forecasting model</h1>
			<p>The code to register <a id="_idIndexMarker342"/>forecasting models is identical to the code you used in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, in order to register your regression model, and in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>, in order to register your classification models. Always register new models, as you will use them in either real-time scoring endpoints or batch execution inference pipelines depending on your business scenario. Likewise, always add tags and descriptions for easier tracking: </p>
			<ol>
				<li value="1">First, give your model a name, a description, and some tags. <strong class="bold">Tags</strong> let <a id="_idIndexMarker343"/>you easily search for models, so think carefully as you implement them: <p class="source-code">description = 'Best AutoML Forecasting Run using OJ Sales Sample Data.' </p><p class="source-code">tags = {'project' : "OJ Sales", "creator" : "your name"} </p><p class="source-code">model_name = 'OJ-Sales-Sample-Forecasting-AutoML' </p></li>
				<li>Next, register your model to your AMLS workspace, passing in your model name, tags, and description. Use the <strong class="source-inline">AutoML_run</strong> model you trained with in the <em class="italic">Training an AutoML forecasting model</em> section:<p class="source-code">AutoML_run.register_model(model_name=model_name, description=description, tags=tags)</p></li>
				<li>Try registering <a id="_idIndexMarker344"/>a different model based on R2 score. Give it a slightly different name, add an additional tag, and use an identical description:<p class="source-code">description = 'Best AutoML Forecasting Run using OJ Sales Sample Data.'</p><p class="source-code">tags = {'project' : "OJ Sales", "creator" : "your name", "metric" : "R2 Score"} </p><p class="source-code">model_name = 'OJ-Sales-Sample-Forecasting-AutoML-R2'</p><p class="source-code">AutoML_run.register_model(model_name=model_name, description=description, tags=tags, metric = 'r2_score')</p></li>
			</ol>
			<p>In some situations, you will perform an AutoML training run, but you will forget to register the model. Do not fret. You can retrieve AutoML training runs using the experiment name and run ID and register the model from there. Use the following code:</p>
			<p class="source-code">experiment_name = 'OJ-Sales-Forecasting'</p>
			<p class="source-code">exp = Experiment(workspace=ws, name=experiment_name) </p>
			<p class="source-code">AutoML_run = AutoMLRun(experiment = exp, run_id = 'your_run_id') </p>
			<p class="source-code">description = 'Retrieved AutoML Forecasting Run for OJ Sales Data.'</p>
			<p class="source-code">tags = {'project' : "OJ Sales", "creator" : "your name"} </p>
			<p class="source-code">model_name = 'OJ-Sales-Sample-Forecasting-AutoML-Retrieved'</p>
			<p class="source-code">AutoML_run.register_model(model_name=model_name, description=description, tags=tags)</p>
			<p>You have now registered your forecasting model and it is ready for use. You can use it to predict the demand for orange juice across a variety of stores and brands over the next 6 weeks. You can modify it in numerous ways too, such as predicting 3 weeks', 12 weeks', or simply next weeks' sales. </p>
			<p>Forecasting is an art, much <a id="_idIndexMarker345"/>more so than classification or regression, and that makes the next section much more important: tips and tricks for fine-tuning AutoML forecasting models. </p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor090"/>Fine-tuning your AutoML forecasting model</h1>
			<p>In this <a id="_idIndexMarker346"/>section, you will first review tips and tricks for improving your AutoML forecasting models and then review the algorithms used by AutoML for forecasting.</p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor091"/>Improving AutoML forecasting models </h2>
			<p>Forecasting is very easy to get<a id="_idIndexMarker347"/> wrong. It's easy to produce a model that seems to work in development, but fails to make accurate predictions once deployed to production. Many data scientists, even experienced ones, make mistakes. While AutoML will help you avoid some of the common mistakes, there are others that require you to exercise caution. In order to sidestep these pitfalls and make the best models possible, follow these tips and tricks:</p>
			<ul>
				<li>Any feature column that you train with has to be available in the future when you make a prediction. With <strong class="source-inline">OJ Sales Sample</strong>, this means that, if you want to predict the quantity of sales 6 weeks out and include price as an input variable, you need to know the price of each product 6 weeks out. <p>Please confirm with your business partners and IT staff to see which data you will have available to make predictions. If you are not able to know the value of a feature column in the time frame over which you are trying to predict, drop that column from your training dataset.</p></li>
				<li>Standard cross-validation techniques do not work with forecasting. AutoML uses <strong class="bold">rolling forward validation</strong>. This<a id="_idIndexMarker348"/> technique takes the first <em class="italic">X</em> data points of your dataset in order of the time column and uses them to predict the next <em class="italic">Y</em> data points. Then, it takes another set of <em class="italic">X</em> data points further into the future and uses those to make predictions, repeating the process until all data points are used. <p>Cross-validation, on the other hand, ignores the time component and splits your data randomly. This is why you must always set the <strong class="source-inline">task</strong> to <strong class="source-inline">forecasting</strong> if you are trying to make future-state predictions. Setting it to regression may give you results, but they will be meaningless since they ignore the time component.</p></li>
				<li>Become familiar<a id="_idIndexMarker349"/> with all of the different AutoML configuration options for forecasting. You can find them at this link: <a href="https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py">https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py</a>.</li>
				<li>Always try building a forecasting model using only ARIMA and Prophet first. These two models provide a good baseline as they only use your time column and target column to build an ML model. If models using additional features do not outperform ARIMA and Prophet, you know those additional features aren't relevant to your business problem. Drop these features from your dataset.</li>
				<li>Think carefully when deciding your forecast horizon. Usually, forecasting algorithms perform better when forecasting short horizons, either the next one or two time periods. When forecasting longer horizons, expect less accuracy the further out you go. Knowing this, please push back against your business partners when they ask you to forecast many time periods out. <p>Generally speaking, people always want to know the future, and the further out you can predict, the happier they will be. Please explain that they should put more trust in short-term forecasts than they should in longer-term forecasts.</p></li>
				<li>Forecasting the future works best when the present situation resembles the past. Shock events will often disrupt even well-performing forecast models. When this happens, try training a model using only recent data points. This is an iterative process, as it's often difficult to tell which training points are still relevant. <p>In some cases, the best thing you can do is start training models using data only from the onset of the shock event. For example, many stores experienced wildly different product demand during the coronavirus pandemic compared to pre-pandemic conditions.</p></li>
				<li>When shock events <a id="_idIndexMarker350"/>pass and things return to normal, try training forecasting models using the weighted column feature in AutoML. Set time periods during the shock event to <strong class="source-inline">0</strong>. <p>Remember that AutoML forecasting models should not be trained with gaps in the time column. However, data points that occurred during shock events are not relevant to normal situations. By using the weighted column and setting weights to <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong>, you can train a forecasting model that effectively ignores shock events without violating the no gap rule.</p></li>
				<li>Likewise, use the weight column to weight the recent past more heavily than the further past. For many problems, recent data is more relevant than past data. Interview your business partners to find key dates when your industry changed.</li>
				<li>Furthermore, more data only helps forecasting models if the past situation resembles the present situation. Forecasting models often produce better results when you train models using only recent, relevant data. Do not be afraid to drop data points that are too far in the past to help predict the current situation. <p>Once again, interview business partners to find key dates when your industry underwent massive change. Dropping data that occurred prior to the massive change will often produce superior models.</p></li>
				<li>Forecasting is finicky, much more finicky than regression or classification problems. This is because the types of things companies like to forecast are driven by market demand and what people want often changes. What's popular in the marketplace can change quickly with little warning, and, as a result, forecast models need to be retrained all of the time whenever you get the latest data.</li>
				<li>When you make <a id="_idIndexMarker351"/>predictions using an AutoML-trained forecasting model, it always starts by predicting values for the next time period out. Because of this, when you score data, your data must begin with that next time period. For example, if you trained a daily forecasting model on data that ends on January 5, your scoring data must begin on January 6. </li>
				<li>If your time column is on a monthly cadence that ends with February and you are predicting two time periods out, AutoML will make predictions for March and April. You cannot use that model to make predictions for May or June. In order to do so, you must retrain the model with training data that ends at a later date. As a result, you need to keep retraining AutoML forecasting models to make sure your predictions are up-to-date.</li>
				<li>To determine seasonality, plot your target column to look for any recurring seasonal patterns before using AutoML. This will let you know if you should use seasonality features or not.</li>
				<li>When you're trying to make forecasts on a global basis, be sure to include all countries when generating holiday features. Holidays tend to be very important when forecasting demand and market trends. Think of how Christmas affects sales in the United States of America or how the Chinese New Year affects travel patterns in China.</li>
			</ul>
			<p>This ends the list of tips and tricks. It is by no means complete; you should only think of it as a start. Forecasting is a rich and interesting field with many caveats. Still, keeping these things in mind will enable you to produce accurate, reliable forecasts and avoid many of the mistakes made by novice data scientists. </p>
			<p>More than anything, remember that forecasting is its own art, separate from other types of ML problems, and approach it as such. Lastly, you will learn which algorithms AutoML uses to forecast.</p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor092"/>Understanding AutoML forecasting algorithms</h2>
			<p>AutoML forecasting algorithms<a id="_idIndexMarker352"/> are nearly identical to <a id="_idIndexMarker353"/>AutoML regression <a id="_idIndexMarker354"/>algorithms. Forecasting uses all the same <strong class="bold">tree</strong>, <strong class="bold">standard regression</strong>, <strong class="bold">gradient boosting</strong>, and <strong class="bold">nearest neighbor</strong> algorithms <a id="_idIndexMarker355"/>as regression, and also uses <strong class="bold">stochastic gradient descent</strong>. For<a id="_idIndexMarker356"/> reference, please <a id="_idIndexMarker357"/>refer to <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>.</p>
			<p>In addition to these algorithms, there are three forecasting-specific algorithms: Auto-ARIMA, Prophet, and <a id="_idIndexMarker358"/>ForecastTCN. You learned about certain key differences that make ARIMA and Prophet different from the other algorithms earlier in this chapter. ForecastTCN is a <strong class="bold">temporal convolutional network</strong>, a type<a id="_idIndexMarker359"/> of neural network. </p>
			<p><strong class="bold">Auto-ARIMA</strong> (<strong class="bold">Auto-Regressive Integrated Moving Average</strong>) uses<a id="_idIndexMarker360"/> moving averages of the target column to make predictions. Unlike standard ARIMA, Auto-ARIMA optimizes ARIMA parameters to create the best model possible. It performs extremely well with univariate time series where you only have reliable information about your target column.</p>
			<p><strong class="bold">Prophet</strong> is <a id="_idIndexMarker361"/>similar to Auto-ARIMA in that it is specialized for univariate time series. Moreover, it performs extremely well when your data has strong seasonal patterns. Unlike many forecasting algorithms, Prophet is robust to outliers and wild swings in your dataset. Like Auto-ARIMA, you should always use Prophet to establish a baseline model at the onset of any forecasting project.</p>
			<p><strong class="bold">ForecastTCN</strong> is a <a id="_idIndexMarker362"/>deep learning neural network algorithm. Enable it by setting <strong class="source-inline">enable_dnn</strong> to <strong class="source-inline">True</strong> in your AutoML forecasting parameters. This algorithm is great for the most complex forecasting tasks as it can capture extremely complex nonlinear trends in your data. Deep learning is a complex topic and would be difficult to explain in even a single chapter, and is thus outside the scope of this book. ForecastTCN, like other deep learning models, performs best when trained with very large amounts of data.</p>
			<p>A summary of these 13 algorithms is provided in <em class="italic">Figure 6.5</em>:</p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/Figure_6.5_B16595.jpg" alt="Figure 6.5 – AutoML forecasting algorithms"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5 – AutoML forecasting algorithms</p>
			<p>Like <a id="_idIndexMarker363"/>regression, AutoML <a id="_idIndexMarker364"/>performs <strong class="bold">model ensembling</strong> at the end of each AutoML training run. <strong class="bold">Voting ensembles</strong> take a <a id="_idIndexMarker365"/>weighted average of your forecasting models and use that to make a prediction. <strong class="bold">Stack ensembles</strong>, in<a id="_idIndexMarker366"/> contrast, train an elastic net model using the output of other models. There is a danger of overfitting when using a stack ensemble with forecasting; for that reason, it's recommended to turn it off. </p>
			<p>For more information on these models, please consult the AutoML documentation found at <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings</a>.</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor093"/>Summary</h1>
			<p>You have now successfully trained all three types of AutoML models – classification, regression, and forecasting. Not only can you train a simple forecasting model, but you also know how to improve models with the various forecasting parameters and how to build high-performing baseline models with ARIMA and Prophet. </p>
			<p>Moreover, you've acquired a lot of knowledge regarding how forecasting differs from other problems and how to avoid common pitfalls. By utilizing the forecast horizon feature wisely, you can forecast days, months or years into the future, and now it's time to add a powerful tool to your repertoire.</p>
			<p>In <a href="B16595_07_ePub.xhtml#_idTextAnchor094"><em class="italic">Chapter 7</em></a>, <em class="italic">Using the Many Models Solution Accelerator</em>, you will be able to build individual models for each time series grain. Instead of building one forecasting model, you can build thousands of models all at the same time and score them as if they were one model. You will find that this approach can vastly enhance your model's performance and it is possible only with cloud-native technology.</p>
		</div>
</body></html>