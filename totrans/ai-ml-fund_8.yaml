- en: '>'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '>'
- en: Appendix
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: About
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于
- en: This section is included to assist the students to perform the activities in
    the book. It includes detailed steps that are to be performed by the students
    to achieve the objectives of the activities.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包含以帮助学生执行书中活动的内容。它包括学生为实现活动目标需要执行的详细步骤。
- en: 'Chapter 1: Principles of AI'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一章：人工智能原理
- en: In the code, backslash (\) indicates a line break, where the code does not fit
    a line. A backslash at the end of the line escapes the newline character. This
    means that the content in the line following the backslash should be read as if
    it started where the backslash character is.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，反斜杠（\）表示换行，当代码一行放不下时使用。行尾的反斜杠会转义换行符。这意味着在反斜杠后面的内容应该被读取为从反斜杠字符开始的内容。
- en: 'Activity 1: Generating All Possible Sequences of Steps in the tic-tac-toe Game'
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动一：生成井字棋游戏中所有可能的步骤序列
- en: 'This section will explore the combinatoric explosion possible when two players
    play randomly. We will be using a program, building on the previous results that
    generate all possible sequences of moves between a computer player and a human
    player. Determine the number of different wins, losses, and draws in terms of
    action sequences. Assume that the human player may make any possible move. In
    this example, given that the computer player is playing randomly, we will examine
    the wins, losses, and draws belonging to two randomly playing players:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨当两位玩家随机出牌时可能出现的组合爆炸。我们将使用一个程序，基于之前的结果生成计算机玩家和人类玩家之间所有可能的移动序列。确定根据行动序列的不同，胜负和平局的数量。假设人类玩家可以做出任何可能的移动。在这个例子中，由于计算机玩家是随机出牌，我们将检查两个随机出牌玩家的胜负和平局：
- en: 'Create a function that maps the `all_moves_from_board` function on each element
    of a list of boards. This way, we will have all of the nodes of a decision tree
    in each depth:'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，将 `all_moves_from_board` 函数映射到每个棋盘列表的元素上。这样，我们将在每个深度上拥有决策树的全部节点：
- en: '[PRE0]'
  id: totrans-9
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The decision tree starts with `[ EMPTY_SIGN * 9 ]` , and expands after each
    move:'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树从 `[ EMPTY_SIGN * 9 ]` 开始，并在每一步之后扩展：
- en: '[PRE1]'
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is as follows:'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE2]'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s create a `filter_wins` function that takes the ended games out from
    the list of moves and appends them in an array containing the board states won
    by the AI player and the opponent player:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个 `filter_wins` 函数，它从移动列表中移除结束的游戏，并将包含AI玩家和对手玩家赢得的棋盘状态的数组附加到其中：
- en: '[PRE3]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this function, the three lists can be considered as reference types. This
    means that the function does not return a value, instead but it manipulating these
    three lists without returning them.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个函数中，三个列表可以被视为引用类型。这意味着函数不返回值，而是操作这三个列表而不返回它们。
- en: 'Let''s finish this section. Then with a `count_possibilities` function that
    prints the number of decision tree leaves that ended with a draw, won by the first
    player, and won by the second player:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们完成这一节。然后使用一个 `count_possibilities` 函数，打印出以平局结束、第一玩家获胜和第二玩家获胜的决策树叶子的数量：
- en: '[PRE4]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have up to 9 steps in each state. In the 0th, 2nd, 4th, 6th, and 8th iteration,
    the AI player moves. In all other iterations, the opponent moves. We create all
    possible moves in all steps and take out the ended games from the move list.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个状态下，我们最多有9步。在0th、2nd、4th、6th和8th次迭代中，AI玩家移动。在所有其他迭代中，对手移动。我们在所有步骤中创建所有可能的移动，并从移动列表中移除结束的游戏。
- en: Then execute the number of possibilities to experience the combinatoric explosion.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后执行可能性数量以体验组合爆炸。
- en: '[PRE5]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output is as follows:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE6]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, the tree of board states consists of 266,073 leaves. The `count_possibilities`
    function essentially implements a breadth first search algorithm to traverse all
    the possible states of the game. Notice that we do count these states multiple
    times, because placing an X on the top-right corner on step 1 and placing an X
    on the top-left corner on step 3 leads to similar possible states as starting
    with the top-left corner and then placing an X on the top-right corner. If we
    implemented a detection of duplicate states, we would have to check less nodes.
    However, at this stage, due to the limited depth of the game, we omit this step.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，棋盘状态的树由266,073个叶子组成。`count_possibilities`函数本质上实现了一个广度优先搜索算法来遍历游戏的所有可能状态。请注意，我们确实多次计算了这些状态，因为第1步在右上角放置X，第3步在左上角放置X，会导致与从左上角开始然后放置右上角X相似的可能状态。如果我们实现了重复状态的检测，我们就需要检查更少的节点。然而，在这个阶段，由于游戏的深度有限，我们省略了这个步骤。
- en: 'Chapter 2: AI with Search Techniques and Games'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二章：具有搜索技术和游戏的AI
- en: 'Activity 2: Teach the agent realize situations when it defends against losses'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动二：教会智能体识别它防守损失的情况
- en: 'Follow these steps to complete the activity:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成活动：
- en: Create a function `player_can_win` such that it takes all moves from the board
    using the `all_moves_from_board` function and iterates over it using a variable
    `next_move` . On each iteration, it checks if the game can be won by the sign,
    then it return true else false.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`player_can_win`的函数，它使用`all_moves_from_board`函数从棋盘上获取所有移动，并使用变量`next_move`遍历它。在每次迭代中，它检查游戏是否可以通过标记获胜，然后返回true否则返回false。
- en: '[PRE7]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We will extend the AI move such that it prefers making safe moves. A move is
    safe if the opponent cannot win the game in the next step.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将扩展AI的移动，使其更喜欢安全的移动。一个移动是安全的，如果对手在下一步不能赢得比赛。
- en: '[PRE8]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You can test our new application. You will find the AI has made the correct
    move.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以测试我们的新应用程序。您会发现AI已经做出了正确的移动。
- en: We will now place this logic in the state space generator and check how well
    the computer player is doing by generating all the possible games.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将这个逻辑放入状态空间生成器中，并通过生成所有可能的比赛来检查计算机玩家的表现。
- en: '[PRE9]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We will now place this logic in the state space generator and check how well
    the computer player is doing by generating all the possible games.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将这个逻辑放入状态空间生成器中，并通过生成所有可能的比赛来检查计算机玩家的表现。
- en: '[PRE10]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Count the possibilities that as possible.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有可能的情况。
- en: '[PRE11]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE12]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We are doing better than before. We not only got rid of almost 2/3 of possible
    games again, but most of the time, the AI player either wins or settles for a
    draw. Despite our effort to make the AI better, it can still lose in 962 ways.
    We will eliminate all these losses in the next activity.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的表现比以前更好。我们不仅又消除了几乎三分之二的可能游戏，而且大多数时候，AI玩家要么获胜，要么接受平局。尽管我们努力使AI变得更好，但它仍然有962种方式会输掉比赛。我们将在下一个活动中消除所有这些损失。
- en: 'Activity 3: Fix the first and second moves of the AI to make it invincible'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动三：固定AI的前两个移动使其无敌
- en: 'Follow these steps to complete the activity:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成活动：
- en: We will count the number of empty fields in the board and make a hard-coded
    move in case there are 9 or 7 empty fields. You can experiment with different
    hard coded moves. We found that occupying any corner, then occupying the opposite
    corner leads to no losses. If the opponent occupied the opposite corner, making
    a move in the middle results in no losses.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将计算棋盘上空格的数量，并在有9个或7个空格的情况下进行硬编码的移动。您可以尝试不同的硬编码移动。我们发现占据任何角落，然后占据对角角落会导致没有损失。如果对手占据了对角角落，然后在中间移动会导致没有损失。
- en: '[PRE14]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Let's verify the state space
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们验证状态空间
- en: '[PRE16]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE17]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: After fixing the first two steps, we only need to deal with 8 possibilities
    instead of 504\. We also guided the AI into a state, where the hard-coded rules
    were sufficient for never losing a game.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在固定前两个步骤之后，我们只需要处理8种可能性，而不是504种。我们还引导AI进入一个状态，其中硬编码的规则足以确保永远不会输掉比赛。
- en: Fixing the steps is not important because we would give the AI hard coded steps
    to start with, but it is important, because it is a tool to evaluate and compare
    each step.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 固定步骤并不重要，因为我们将会给AI提供硬编码的步骤作为起始点，但它是重要的，因为它是一个评估和比较每个步骤的工具。
- en: After fixing the first two steps, we only need to deal with 8 possibilities
    instead of 504\. We also guided the AI into a state, where the hard-coded rules
    were sufficient for never losing a game.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在修复了前两步之后，我们只需要处理8种可能性，而不是504种。我们还引导AI进入一个状态，其中硬编码的规则足以确保永远不会输掉游戏。
- en: 'Activity 4: Connect Four'
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动4：四子棋
- en: 'This section will practice using the `EasyAI` library and develop a heuristic.
    We will be using connect four game. The game board is seven cells wide and cells
    high. When you make a move, you can only select the column in which you drop your
    token. Then gravity pulls the token down to the lowest possible empty cell. Your
    objective is to connect four of your own tokens horizontally, vertically, or diagonally,
    before your opponent does this, or you run out of empty spaces. The rules of the
    game can be found at: [https://en.wikipedia.org/wiki/Connect_Four](https://en.wikipedia.org/wiki/Connect_Four)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将练习使用`EasyAI`库并开发启发式方法。我们将使用四子棋游戏。游戏板宽度为7个单元格，高度为6个单元格。当你移动时，你只能选择放下你的标记的列。然后重力将标记拉到最低的空单元格。你的目标是先于对手水平、垂直或对角线连接四个自己的标记，或者你用完所有空位。游戏规则可以在[https://en.wikipedia.org/wiki/Connect_Four](https://en.wikipedia.org/wiki/Connect_Four)找到。
- en: 'Let''s set up the TwoPlayersGame framework:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置TwoPlayersGame框架：
- en: '[PRE18]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can leave a few functions from the definition intact. We have to implement
    the following methods:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以保留定义中的一些函数不变。我们必须实现以下方法：
- en: '[PRE19]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We will reuse the basic scoring function from tic-tac-toe. Once you test out
    the game, you will see that the game is not unbeatable, but plays surprisingly
    well, even though we are only using basic heuristics.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将重用tic-tac-toe中的基本评分函数。一旦你测试了游戏，你会发现游戏并非不可战胜，尽管我们只使用了基本的启发式方法，但游戏表现却出人意料地好。
- en: 'Let''s write the init method. We will define the board as a one-dimensional
    list, similar to the tic-tac-toe example. We could use a two-dimensional list
    too, but modeling will not get much easier or harder. Beyond making initializations
    like we did in the tic-tac-toe game, we will work a bit ahead. We will generate
    all of the possible winning combinations in the game and save them for future
    use:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编写init方法。我们将定义棋盘为一个一维列表，类似于tic-tac-toe示例。我们也可以使用二维列表，但建模不会变得容易或困难很多。除了像tic-tac-toe游戏中那样进行初始化之外，我们还会稍微提前工作。我们将生成游戏中所有可能的获胜组合，并将它们保存供将来使用：
- en: '[PRE20]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Let's handle the moves. The possible moves function is a simple enumeration.
    Notice we are using column indices from 1 to 7 in the move names, because it is
    more convenient to start column indexing with 1 in the human player interface
    than with zero. For each column, we check if there is an unoccupied field. If
    there is one, we will make the column a possible move.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们处理移动。可能的移动函数是一个简单的枚举。注意我们在移动名称中使用从1到7的列索引，因为在人类玩家界面中从1开始列索引比从0开始更方便。对于每一列，我们检查是否存在未占用的字段。如果有一个，我们将该列设为可能的移动。
- en: '[PRE22]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Making a move is similar to the possible moves function. We check the column
    of the move, and find the first empty cell starting from the bottom. Once we find
    it, we occupy it. You can also read the implementation of the dual of the make_move
    function: unmake_move. In the unmake_move function, we check the column from top
    to down, and we remove the move at the first non-empty cell. Notice we rely on
    the internal representation of easyAi so that it does not undo moves that it had
    not made. Otherwise, this function would remove a token of the other player without
    checking whose token got removed.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行移动与可能的移动函数类似。我们检查移动的列，并从底部开始找到第一个空单元格。一旦找到，我们就占据它。你也可以阅读make_move函数的逆函数：unmake_move的实现。在unmake_move函数中，我们从顶部到底部检查列，并在第一个非空单元格处移除移动。注意我们依赖于easyAi的内部表示，这样它就不会撤销它没有做出的移动。否则，这个函数会移除其他玩家的标记，而不会检查是哪个玩家的标记被移除。
- en: '[PRE23]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As we already have the tuples that we have to check, we can mostly reuse the
    lose function from the tic-tac-toe example.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经有了需要检查的元组，因此我们可以大部分重用tic-tac-toe示例中的lose函数。
- en: '[PRE24]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Our last task is the show method that prints the board. We will reuse the tic-tac-toe
    implementation, and just change the variables.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们最后一个任务是show方法，它将打印出棋盘。我们将重用tic-tac-toe的实现，并仅更改变量。
- en: '[PRE25]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Now that all functions are complete, you can try out the example. Feel free
    to play a round or two against the opponent. You can see that the opponent is
    not perfect, but it plays reasonably well. If you have a strong computer, you
    can increase the parameter of the Negamax algorithm. I encourage you to come up
    with a better heuristic.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在所有函数都已完成，你可以尝试一下示例。请随意与对手玩几轮。你可以看到对手并不完美，但它的表现相当不错。如果你有一台强大的计算机，你可以增加 Negamax
    算法的参数。我鼓励你提出更好的启发式方法。
- en: 'Chapter 3: Regression'
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 3 章：回归
- en: 'Activity 5: Predicting Population'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 5：预测人口
- en: 'You are working at the government office of Metropolis, trying to forecast
    the need for elementary school capacity. Your task is to figure out a 2025 and
    2030 prediction for the number of children starting elementary school. Past data
    are as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你在 Metropolis 政府办公室工作，试图预测小学容量需求。你的任务是确定 2025 年和 2030 年开始上小学的儿童数量预测。以下为历史数据：
- en: '![](img/Image00073.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image00073.jpg)'
- en: Figure 3.21 Data of Elementary School
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.21：小学数据
- en: Plot tendencies on a two-dimensional chart. Use linear regression.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在二维图表上绘制趋势。使用线性回归。
- en: Our features are the years ranging from 2001 to 2018\. For simplicity, we can
    indicate 2001 as year 1, and 2018 as year 18.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的特征是 2001 年至 2018 年的年份。为了简单起见，我们可以将 2001 年表示为第 1 年，2018 年表示为第 18 年。
- en: '[PRE26]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Use np.polyfit to determine the coefficients of the regression line.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `np.polyfit` 来确定回归线的系数。
- en: '[PRE27]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Plot the results using matplotlib.pyplot to determine future tendencies.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 matplotlib.pyplot 绘制结果以确定未来的趋势。
- en: '[PRE28]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Activity 6: Stock Price Prediction with Quadratic and Cubic Linear Polynomial
    Regression with Multiple Variables'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 6：使用多元二次和三次线性多项式回归预测股价
- en: This section will discuss how to perform linear, polynomial, and support vector
    regression with scikit-learn. We will also learn to predict the best fit model
    for a given task. We will be assuming that you are a software engineer at a financial
    institution and your employer wants to know whether linear regression, or support
    vector regression is a better fit for predicting stock prices. You will have to
    load all data of the S&P 500 from a data source. Then build a regressor using
    linear regression, cubic polynomial linear regression, and a support vector regression
    with a polynomial kernel of degree 3\. Then separate training and test data. Plot
    the test labels and the prediction results and compare them with the `y` =`x`
    line. And finally, compare how well the three models score.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论如何使用 scikit-learn 执行线性、多项式和支持向量回归。我们还将学习预测给定任务的最佳拟合模型。我们将假设你是金融机构的一名软件工程师，你的雇主想知道线性回归或支持向量回归哪个更适合预测股价。你必须从数据源中加载所有
    S&P 500 的数据。然后使用线性回归、三次多项式线性回归和具有三次多项式核的支持向量回归构建回归器。然后分离训练数据和测试数据。绘制测试标签和预测结果，并与
    `y` = `x` 线进行比较。最后，比较三个模型的得分情况。
- en: Let's load the S&P 500 index data using `Quandl` , then prepare the data for
    prediction. You can read the process in the Predicting the Future section of the
    topic Linear Regression with Multiple Variables.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `Quandl` 加载 S&P 500 指数数据，然后准备预测数据。你可以在“多元线性回归”主题的“预测未来”部分中阅读这个过程。
- en: '[PRE29]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Let's first use a polynomial of degree 1 for the evaluation of the model and
    for the prediction. We are still recreating the main example from the second topic.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先使用一次多项式来评估模型并进行预测。我们仍在重新创建第二个主题中的主要示例。
- en: '[PRE30]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output is as follows:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE31]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The output always depends on the test data, so the values may differ after each
    run.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出始终取决于测试数据，因此每次运行后的值可能不同。
- en: '[PRE32]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](img/Image00074.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image00074.jpg)'
- en: 'Fig 3.22: Graph showing the output'
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.22：显示输出的图表
- en: The closer the dots are to the y=x line, the less error the model works with.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 点越接近 y=x 线，模型的误差就越小。
- en: '[PRE33]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The model is performing surprisingly well on test data. Therefore, we can already
    suspect our polynomials are overfitting for scenarios used in training and testing.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在测试数据上的表现令人惊讶。因此，我们可以怀疑我们的多项式在训练和测试场景中过度拟合。
- en: We will now perform a Support Vector regression with a polynomial kernel of
    degree 3.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将执行一个具有三次多项式核的支持向量回归。
- en: '[PRE34]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![](img/Image00075.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image00075.jpg)'
- en: 'Fig 3.23: Graph showing the output'
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.23：显示输出的图表
- en: '[PRE35]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The output will be `0.06388628722032952` .
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是 `0.06388628722032952`。
- en: We will now perform a Support Vector regression with a polynomial kernel of
    degree 3.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将执行一个具有三次多项式核的支持向量回归。
- en: 'Chapter 4: Classification'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四章：分类
- en: 'Activity 7: Preparing Credit Data for Classification'
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动7：为分类准备信用数据
- en: This section will discuss how to prepare data for a classifier. We will be using
    german.data from [https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/)
    , as an example and prepare the data for training and testing a classifier. Make
    sure all your labels are numeric, and the values are prepared for classification.
    Use 80% of the data points as training data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论如何为分类器准备数据。我们将使用german.data从[https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/)作为示例，并为训练和测试分类器准备数据。确保所有标签都是数值的，并且值已准备好进行分类。使用80%的数据点作为训练数据。
- en: 'Save german.data from [https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/)
    , and open it in a text editor like Sublime Text or Atom. Add the following first
    row to it:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/)保存german.data，并在Sublime
    Text或Atom等文本编辑器中打开它。向其中添加以下第一行：
- en: '[PRE36]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Import the data file using pandas and replace NA values with an outlier value:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas导入数据文件，并用异常值替换NA值：
- en: '[PRE37]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Perform label encoding. We need to transform all labels in the data frame to
    integers. We could create all labels in a one dimensional array. However, this
    would be highly ineffective, because each label occurs in exactly one column.
    It makes a lot more sense to group our labels per column:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行标签编码。我们需要将数据框中的所有标签转换为整数。我们可以在一维数组中创建所有标签。然而，这将非常低效，因为每个标签恰好出现在一个列中。按列分组我们的标签更有意义：
- en: '[PRE38]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s create a label encoder for each column and encode the values:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为每一列创建一个标签编码器并编码值：
- en: '[PRE39]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let''s verify that we did everything correctly:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们验证我们是否一切都做对了：
- en: '[PRE40]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: All the 21 columns are available, and the label encoders have been saved in
    an object too. Our data are now pre-processed.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 所有21列都可用，标签编码器也已保存到对象中。我们的数据现在已预处理。
- en: You don't need to save these label encoders if you don't wish to decode the
    encoded values. We just saved them for the sake of completeness.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不想解码编码后的值，则不需要保存这些标签编码器。我们只是为了完整性而保存了它们。
- en: 'It is time to separate features from labels. We can apply the same method as
    the one we saw in the theory section:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候将特征与标签分开。我们可以应用我们在理论部分看到的方法：
- en: '[PRE41]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Our features are not yet scaled. This is a problem, because the credit amount
    distances can be significantly higher than the differences in age for instance.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的特征尚未缩放。这是一个问题，因为信用金额的距离可能比年龄的差异显著更高。
- en: We must perform scaling of the training and testing data together, therefore,
    the latest step when we can still perform scaling is before we split training
    data from testing data.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们必须一起对训练数据和测试数据进行缩放，因此，我们可以在将训练数据从测试数据中分割出来之前进行缩放的最新步骤。
- en: 'Let''s use a Min-Max scaler from scikit''s Preprocessing library:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用scikit的预处理库中的Min-Max缩放器：
- en: '[PRE42]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The final step is cross-validation. We will shuffle our data, and use 80% of
    all data for training, 20% for testing.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是交叉验证。我们将打乱我们的数据，并使用所有数据的80%进行训练，20%进行测试。
- en: '[PRE43]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Activity 8: Increase the accuracy of credit scoring'
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动8：提高信用评分的准确性
- en: 'This section will learn how the parametrization of the k-nearest neighbor classifier
    affects the end result. The accuracy of credit scoring is currently quite low:
    66.5%. Find a way to increase it by a few percentage points. And to ensure that
    it happens correctly, you will need to do the previous exercises.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将学习k最近邻分类器的参数化如何影响最终结果。信用评分的准确性目前相当低：66.5%。找到一种方法将其提高几个百分点。并且为了确保它正确发生，您需要完成之前的练习。
- en: There are many ways to accomplish this exercise. In this solution, I will show
    you one way to increase the credit score by changing the parametrization.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这个练习有很多方法。在这个解决方案中，我将向您展示一种通过改变参数化来提高信用评分的方法。
- en: You must have completed Exercise 13, to be able to complete this activity.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须完成第13项练习，才能完成此活动。
- en: 'Increase the K-value of the k-nearest neighbor classifier from the default
    5 to 10, 15, 25, and 50\. Evaluate the results:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将k最近邻分类器的K值从默认的5增加到10、15、25和50。评估结果：
- en: '[PRE44]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'After running these lines for all four `n_neighbors` values, I got the following
    results:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在为所有四个`n_neighbors`值运行这些行之后，我得到了以下结果：
- en: '[PRE45]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Higher K values do not necessarily mean better score. In this example though,
    `K=50` yielded a better result than `K=5` .
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 较高的K值并不一定意味着更好的分数。然而，在这个例子中，`K=50`比`K=5`得到了更好的结果。
- en: 'Activity 9: Support Vector Machine Optimization in scikit-learn'
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动9：在scikit-learn中进行支持向量机优化
- en: This section will discuss how to use the different parameters of a Support Vector
    Machine classifier. We will be using comparing and contrasting the different support
    vector regression classifier parameters you learned and find a set of parameters
    resulting in the highest classification data on the training and testing data
    loaded and prepared in previous activity. And to ensure that it happens correctly,
    you will need to have completed the previous activities and exercises.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论如何使用支持向量机分类器的不同参数。我们将通过比较和对比你之前学习过的不同支持向量回归分类器参数，找到一组在之前活动中加载和准备好的训练和测试数据上产生最高分类数据的参数。为确保正确执行，你需要完成之前的活动和练习。
- en: We will try out a few combinations. You may choose different parameters, that
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试几种组合。你可以选择不同的参数，例如
- en: Linear kernel
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性核
- en: '[PRE46]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Polynomial kernel of degree 4, C=2, gamma=0.05
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 四次方多项式核，C=2，gamma=0.05
- en: '[PRE47]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows: 0.705.'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：0.705。
- en: Polynomial kernel of degree 4, C=2, gamma=0.25
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 四次方多项式核，C=2，gamma=0.25
- en: '[PRE48]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output is as follows: 0.76.'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：0.76。
- en: Polynomial kernel of degree 4, C=2, gamma=0.5
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 四次方多项式核，C=2，gamma=0.5
- en: '[PRE49]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows: 0.72.'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：0.72。
- en: Sigmoid kernel
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Sigmoid核
- en: '[PRE50]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output is as follows: 0.71.'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：0.71。
- en: Default kernel with a gamma of 0.15
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认核，gamma为0.15
- en: '[PRE51]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output is as follows: 0.76.'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：0.76。
- en: 'Chapter 5: Using Trees for Predictive Analysis'
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5章：使用树进行预测分析
- en: 'Activity 10: Car Data Classification'
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动10：汽车数据分类
- en: 'This section will discuss how to build a reliable decision tree model capable
    of aiding your company in finding cars clients are likely to buy. We will be assuming
    that you are employed by a car rental agency focusing on building a lasting relationship
    with its clients. Your task is to build a decision tree model classifying cars
    into one of four categories: unacceptable, acceptable, good, very good.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论如何构建一个可靠的决策树模型，以帮助你的公司在寻找可能购买汽车的客户方面发挥作用。我们将假设你受雇于一家汽车租赁代理机构，专注于与客户建立长期关系。你的任务是构建一个决策树模型，将汽车分类为以下四个类别之一：不可接受、可接受、好、非常好。
- en: 'The data set can be accessed here: [https://archive.ics.uci.edu/ml/datasets/Car+Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation)
    . Click the Data Folder link to download the data set. Click the Data Set Description
    link to access the description of the attributes.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以通过以下链接访问：[https://archive.ics.uci.edu/ml/datasets/Car+Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation)。点击数据文件夹链接下载数据集。点击数据集描述链接以访问属性描述。
- en: Evaluate the utility of your decision tree model.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 评估你的决策树模型的效用。
- en: 'Download the car data file from here: [https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data](https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data)
    . Add a header line to the front of the CSV file to reference it in Python more
    easily:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这里下载汽车数据文件：[https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data](https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data)。在CSV文件的前面添加一个标题行，以便在Python中更容易引用：
- en: '`Buying,Maintenance,Doors,Persons,LuggageBoot,Safety,Class`'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Buying,Maintenance,Doors,Persons,LuggageBoot,Safety,Class`'
- en: We simply call the label Class. We named the six features after their descriptions
    in [https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names](https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names)
    .
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们简单地将标签称为Class。我们根据[https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names](https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names)中的描述命名了六个特征。
- en: Load the data set into Python
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集加载到Python中
- en: '[PRE52]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let''s check if the data got loaded correctly:'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们检查数据是否正确加载：
- en: '[PRE53]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: As classification works with numeric data, we have to perform label encoding
    as seen in previous chapter.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于分类与数值数据一起工作，我们必须执行标签编码，如前一章所示。
- en: '[PRE54]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Let''s separate features from labels:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们分离特征和标签：
- en: '[PRE55]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'It is time to separate training and testing data with the cross-validation
    (in newer versions model-selection) featue of scikit-learn. We will use 10% test
    data:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候使用scikit-learn的交叉验证（在新版本中为模型选择）功能来分离训练数据和测试数据了。我们将使用10%的测试数据：
- en: '[PRE56]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Note that the train_test_split method will be available in model_selection module,
    not in the cross_validation module starting in scikit-learn 0.20\. In previous
    versions, model_selection already contains the train_test_split method.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，train_test_split方法将在model_selection模块中可用，而不是从scikit-learn 0.20版本开始在cross_validation模块中可用。在之前的版本中，model_selection已经包含了train_test_split方法。
- en: 'We have everything to build the decision tree classifier:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经拥有了构建决策树分类器所需的一切：
- en: '[PRE57]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output of the fit method is as follows:'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: fit方法的输出如下：
- en: '[PRE58]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: You can see the parametrization of the decision tree classifier. There are quite
    a few options we could set to tweak the performance of the classifier model.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以看到决策树分类器的参数化。我们可以设置很多选项来调整分类器模型的性能。
- en: 'Let''s score our model based on the test data:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们根据测试数据对我们的模型进行评分：
- en: '[PRE59]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output is as follows:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE60]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'This is the point where your knowledge up until chapter 4 would take you on
    model evaluation. We will now go a bit further and create a deeper evaluation
    of the model based on the classification_report feature we learned in this topic:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这就是您在第四章之前的知识将如何帮助您进行模型评估的时刻。现在，我们将进一步深入，基于我们在这个主题中学到的classification_report特征创建一个更深入的模型评估：
- en: '[PRE61]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output is as follows:'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE62]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The model has been proven to be quite accurate. In case of such a high accuracy
    score, suspect the possibility of overfitting.
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该模型已被证明相当准确。在这种情况下，高分可能表明存在过拟合的可能性。
- en: 'Activity 11: Random Forest Classification for your Car Rental Company'
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动11：为您的租车公司进行随机森林分类
- en: This section will optimize your classifier to satisfy your clients better when
    selecting future cars for your car fleet. We will be performing random forest
    and extreme random forest classification on your car dealership data set you worked
    on in Activity 1 of this chapter. Suggest further improvements to the model to
    improve the performance of the classifier.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本节将优化您的分类器，以便在选择未来车队车辆时更好地满足客户需求。我们将对您在本章活动1中处理过的汽车经销商数据集执行随机森林和极端随机森林分类。建议进一步改进模型以提高分类器的性能。
- en: 'We can reuse Steps 1 – 5 of Activity 1\. The end of Step 5 looks as follows:'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以重用活动1的第1步至第5步。第5步的结束看起来如下：
- en: '[PRE63]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: If you are using IPython, your variables may already be accessible in your console.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您使用IPython，您的变量可能已经在您的控制台中可用。
- en: Let's create a Random Forest and an Extremely Randomized Trees classifier and
    train the models.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个随机森林和一个极端随机化树分类器，并训练这些模型。
- en: '[PRE64]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let''s estimate how well the two models perform on the test data:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来评估这两个模型在测试数据上的表现：
- en: '[PRE65]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output for model 1 is as follows:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型1的输出如下：
- en: '[PRE66]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The output for model 1 is as follows:'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型1的输出如下：
- en: '[PRE67]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We can also calculate the accuracy scores:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们也可以计算准确度分数：
- en: '[PRE69]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output is as follows:'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE70]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The output for `extraTreesClassifier` is as follows:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`extraTreesClassifier`的输出如下：'
- en: '[PRE71]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The output is as follows:'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE72]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: We can see that the random forest classifier is performing slightly better than
    the extra trees classifier.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到，随机森林分类器在性能上略优于额外树分类器。
- en: As a first optimization technique, let's see which features are more important
    and which features are less important. Due to randomization, removing the least
    important features may reduce the random noise in the model.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为一种初步的优化技术，让我们看看哪些特征更重要，哪些特征不太重要。由于随机化，移除不太重要的特征可能会减少模型中的随机噪声。
- en: '[PRE73]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The output is as follows:'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE74]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The output for `extra_trees_classifier` is as follows:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`extra_trees_classifier`的输出如下：'
- en: '[PRE75]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The output is as follows:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE76]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Both classifiers treats the third and the fifth attributes quite unimportant.
    We may not be sure about the fifth attribute, as the importance score is more
    than 5% in both models. However, we are quite certain that the third attribute
    is the least significant attribute in the decision. Let's see the feature names
    once again.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 两个分类器都认为第三个和第五个属性相当不重要。我们可能对第五个属性不太确定，因为两个模型中的重要性分数都超过5%。然而，我们可以相当确定第三个属性是决策中最不重要的属性。让我们再次查看特征名称。
- en: '[PRE77]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The output is as follows:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE78]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The least important feature is Doors. It is quite evident in hindsight: the
    number of doors doesn''t have as big of an influence in the car''s rating than
    the safety rating for instance.'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最不重要的特征是车门。事后看来很明显：车门数量对汽车评分的影响不如安全评级大。
- en: Remove the third feature from the model and retrain the classifier.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从模型中移除第三个特征并重新训练分类器。
- en: '[PRE79]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Let''s compare how well the new models fare compared to the original ones:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们比较新模型与原始模型的表现如何：
- en: '[PRE80]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The output is as follows:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE81]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Second Model:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个模型：
- en: '[PRE82]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The output is as follows:'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE83]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Although we did improve a few percentage points, note that a direct comparison
    is not possible, because of following reasons. First, the train-test split selects
    different data for training and testing. A few badly selected data points may
    easily cause a few percentage point increase or decrease in the scores. Second,
    the way how we train the classifiers also has random elements. This randomization
    may also shift the performance of the classifiers a bit. Always use best judgement
    when interpreting results and measure your results multiple times on different
    train-test splits if needed.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然我们确实提高了几个百分点，但请注意，由于以下原因，直接的比较是不可能的。首先，训练-测试分割选择了不同的数据用于训练和测试。一些错误选择的数据点可能会轻易导致分数的几个百分点增加或减少。其次，我们训练分类器的方式也有随机元素。这种随机化也可能稍微改变分类器的性能。在解释结果时，始终使用最佳判断，并在必要时在多个训练-测试分割上多次测量你的结果。
- en: 'Let''s tweak the parametrization of the classifiers a bit more. The following
    set of parameters increase the F1 Score of the Random Forest Classifier to 97%:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们进一步调整分类器的参数。以下参数集将随机森林分类器的F1分数提高到97%：
- en: '[PRE84]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'The output is as follows:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE85]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Using the same parameters on the Extra Trees Classifier, we also get surprisingly
    good results:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Extra Trees分类器上使用相同的参数，我们也得到了令人惊讶的好结果：
- en: '[PRE86]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The output is as follows:'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE87]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Chapter 6: Clustering'
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第六章：聚类
- en: 'Activity 12: k-means Clustering of Sales Data'
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动12：销售数据的k-means聚类
- en: This section will detect product sales that perform similarly in nature to recognize
    trends in product sales.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将检测在本质上表现相似的产品销售，以识别产品销售趋势。
- en: 'We will be using the Sales Transactions Weekly Dataset from this URL:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下URL的Sales Transactions Weekly数据集：
- en: '[https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly](https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly)
    Perform clustering on the dataset using the k-means Algorithm. Make sure you prepare
    your data for clustering based on what you have learned in the previous chapters.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly](https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly)
    使用k-means算法对数据集进行聚类。确保你根据前几章学到的知识准备你的聚类数据。'
- en: Use the default settings for the k-means algorithm.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 使用k-means算法的默认设置。
- en: Load the dataset using pandas.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas加载数据集。
- en: '[PRE88]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: If you examine the data in the CSV file, you can realize that the first column
    contains product id strings. These values just add noise to the clustering process.
    Also notice that for weeks 0 to 51, there is a W-prefixed label and a Normalized
    label. Using the normalized label makes more sense, so we can drop the regular
    weekly labels from the data set.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你检查CSV文件中的数据，你可以意识到第一列包含产品ID字符串。这些值只是给聚类过程添加噪声。同时请注意，对于第0周到第51周，有一个以W为前缀的标签和一个归一化标签。使用归一化标签更有意义，因此我们可以从数据集中删除常规的每周标签。
- en: '[PRE89]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Our data points are normalized except for the min and max
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的数据点已归一化，除了最小值和最大值
- en: '[PRE90]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Create a k-means clustering model and fit the data points into 8 clusters.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个k-means聚类模型，并将数据点拟合到8个聚类中。
- en: '[PRE91]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: The labels belonging to each data point can be retrieved using the labels_ property.
    These labels determine the clustering of the rows of the original data frame.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用labels_属性检索每个数据点的标签。这些标签决定了原始数据框中行的聚类。
- en: '[PRE92]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Retrieve the center points and the labels from the clustering algorithm:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从聚类算法中检索中心点和标签：
- en: '[PRE93]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'The output will be as follows:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE94]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: How are these labels beneficial?
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标签有什么好处？
- en: Suppose that in the original data frame, the product names are given. You can
    easily recognize that similar types of products sell similarly. There are also
    products that fluctuate a lot, and products that are seasonal in nature. For instance,
    if some products promoted fat loss and getting into shape, they tend to sell during
    the first half of the year, before the beach season.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 假设原始数据框中给出了产品名称。你可以轻松地认识到相似类型的产品销售情况相似。也有一些波动很大的产品，以及具有季节性的产品。例如，如果某些产品推广减肥和塑形，它们往往在一年中的前半段销售，在海滩季节之前。
- en: 'Activity 13: Shape Recognition with the Mean Shift algorithm'
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动13：使用Mean Shift算法进行形状识别
- en: This section will learn how images can be clustered. We will be assuming that
    you are working for a company detecting human emotions from photos. Your task
    is to extract pixels making up a face in an avatar photo.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将学习如何对图像进行聚类。我们将假设你正在为一家公司工作，该公司从照片中检测人类情绪。你的任务是提取头像照片中构成面部的像素。
- en: Create a clustering algorithm with Mean Shift to cluster pixels of images. Examine
    the results of the Mean Shift algorithm and check if any of the clusters contains
    a face when used on avatar images.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用均值漂移算法创建一个聚类算法来聚类图像的像素。检查均值漂移算法的结果，并检查在应用于头像图像时，是否有任何聚类包含面部。
- en: 'Then apply the k-means algorithm with a fixed default number of clusters: 8\.
    Compare your results with the Mean Shift clustering algorithm.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用固定默认数量的聚类数：8，应用 k-means 算法。将你的结果与均值漂移聚类算法进行比较。
- en: Select an image you would like to cluster and load the image.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择你想要聚类的图像并加载图像。
- en: We chose this image from the Author's Youtube channel:![](img/Image00076.jpg)
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从作者的 YouTube 频道选择了这张图片![img/Image00076.jpg](img/Image00076.jpg)
- en: 'Fig 7.13: An image with the Author''s picture'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.13：包含作者图片的图像
- en: The image size has been significantly reduced so that our algorithm would terminate
    more quickly.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像大小已经显著减小，以便我们的算法能够更快地终止。
- en: '[PRE95]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Transform the pixels into a data frame to perform clustering
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将像素转换成数据框以执行聚类
- en: '[PRE96]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Perform Mean Shift clustering on the image using scikit-learn. Note that this
    time we will skip normalization of the features, because proximity of the pixels
    and proximity of color components are represented in close to equal weight. The
    largest difference in pixels distance is 750, while the largest difference in
    a color component is 256.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 在图像上执行均值漂移聚类。请注意，这次我们将跳过特征归一化，因为像素的邻近性和颜色成分的邻近性几乎以相同的权重表示。像素距离的最大差异是
    750，而颜色成分的最大差异是 256。
- en: '[PRE97]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: The algorithm found the following two clusters:![](img/Image00077.jpg)
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法找到了以下两个聚类![img/Image00077.jpg](img/Image00077.jpg)
- en: 'Fig 7.14: Images after performing k-means Clustering'
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.14：执行 k-means 聚类后的图像
- en: The Mean Shift algorithm treated my skin and the yellow JavaScript and Destructuring
    text close enough to each other to form the same cluster.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 均值漂移算法将我的皮肤和黄色 JavaScript 以及解构文本处理得足够接近，以至于形成了相同的聚类。
- en: Let's use the k-means algorithm to formulate eight clusters on the same data.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 k-means 算法在相同的数据上形成八个聚类。
- en: '[PRE98]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The 8 clusters are the following:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下 8 个聚类如下：
- en: 'The output for the first is as follows:'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个输出的结果如下：
- en: '![Images after performing K-means Clustering](img/Image00078.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![执行 K-means 聚类后的图像](img/Image00078.jpg)'
- en: 'Fig 7.15: Images after performing k-means Clustering'
  id: totrans-291
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.15：执行 k-means 聚类后的图像
- en: 'The output for the second is as follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个输出的结果如下：
- en: '![Fig 7.16: Images after performing K-means Clustering](img/Image00079.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.16：执行 K-means 聚类后的图像](img/Image00079.jpg)'
- en: 'Fig 7.16: Images after performing k-means Clustering'
  id: totrans-294
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.16：执行 K-means 聚类后的图像
- en: 'The output for the third is as follows:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个输出的结果如下：
- en: '![Fig 7.17: Images after performing K-means Clustering](img/Image00080.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.17：执行 K-means 聚类后的图像](img/Image00080.jpg)'
- en: 'Fig 7.17: Images after performing k-means Clustering'
  id: totrans-297
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.17：执行 k-means 聚类后的图像
- en: 'The output for the fourth is as follows:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个输出的结果如下：
- en: '![Fig 7.18: Images after performing K-means Clustering](img/Image00081.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.18：执行 K-means 聚类后的图像](img/Image00081.jpg)'
- en: 'Fig 7.18: Images after performing k-means Clustering'
  id: totrans-300
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.18：执行 K-means 聚类后的图像
- en: 'The output for the fifth is as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 第五个输出的结果如下：
- en: '![Fig 7.19: Images after performing K-means Clustering](img/Image00082.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.19：执行 K-means 聚类后的图像](img/Image00082.jpg)'
- en: 'Fig 7.19: Images after performing k-means Clustering'
  id: totrans-303
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.19：执行 K-means 聚类后的图像
- en: 'The output for the sixth is as follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 第六个输出的结果如下：
- en: '![Fig 7.20: Images after performing K-means Clustering](img/Image00083.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.20：执行 K-means 聚类后的图像](img/Image00083.jpg)'
- en: 'Fig 7.20: Images after performing k-means Clustering'
  id: totrans-306
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.20：执行 K-means 聚类后的图像
- en: 'The output for the seventh is as follows:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 第七个输出的结果如下：
- en: '![Fig 7.21: Images after performing K-means Clustering](img/Image00084.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.21：执行 K-means 聚类后的图像](img/Image00084.jpg)'
- en: 'Fig 7.21: Images after performing k-means Clustering'
  id: totrans-309
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.21：执行 K-means 聚类后的图像
- en: 'The output for the eighth is as follows:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 第八个输出的结果如下：
- en: '![Fig 7.22: Images after performing K-means Clustering](img/Image00085.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.22：执行 K-means 聚类后的图像](img/Image00085.jpg)'
- en: 'Fig 7.22: Images after performing k-means Clustering'
  id: totrans-312
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.22：执行 K-means 聚类后的图像
- en: As you can see, the fifth cluster recognized my face quite well. The clustering
    algorithm indeed located data points that are close and contain similar colors.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，第五个簇很好地识别了我的脸。聚类算法确实定位了接近且颜色相似的数据点。
- en: 'Chapter 7: Deep Learning with Neural Networks'
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第七章：使用神经网络的深度学习
- en: 'Activity 14: Written digit detection'
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 14：手写数字检测
- en: This section will discuss how to provide more security for the cryptocurrency
    traders via the detection of hand-written digits. We will be using assuming that
    you are a software developer at a new Cryptocurrency trader platform. The latest
    security measure you are implementing requires the recognition of hand-written
    digits. Use the MNIST library to train a neural network to recognize digits. You
    can read more about this dataset on [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)
    .
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本节将讨论如何通过检测手写数字为加密货币交易者提供更多安全性。我们将假设你是新加密货币交易平台的一名软件开发者。你正在实施的最新安全措施需要识别手写数字。使用
    MNIST 库训练一个神经网络来识别数字。你可以在 [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)
    上了解更多关于这个数据集的信息。
- en: Improve the accuracy of the model as much as possible. And to ensure that it
    happens correctly, you will need to complete the previous topic.
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽可能提高模型的准确度。为了确保正确发生，你需要完成前面的主题。
- en: Load the dataset and format the input
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集并格式化输入
- en: '[PRE99]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Set up the Tensorflow graph. Instead of the `sigmoid` function, we will now
    use the `relu` function.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 Tensorflow 图。现在我们将使用 `relu` 函数而不是 `sigmoid` 函数。
- en: '[PRE100]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Train the model.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。
- en: '[PRE101]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: Test the model
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试模型
- en: '[PRE102]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'The output is as follows:'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE103]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'Calculate the accuracy score:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算准确度分数：
- en: '[PRE104]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'The output is as follows:'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE105]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'By re-running the code segment responsible for training the data set, we can
    improve the accuracy:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过重新运行负责训练数据集的代码段，我们可以提高准确度：
- en: '[PRE106]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Second run: 0.5107'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二次运行：0.5107
- en: 'Third run: 0.5276'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第三次运行：0.5276
- en: 'Fourth run: 0.5683'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第四次运行：0.5683
- en: 'Fifth run: 0.6002'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第五次运行：0.6002
- en: 'Sixth run: 0.6803'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第六次运行：0.6803
- en: 'Seventh run: 0.6989'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第七次运行：0.6989
- en: 'Eighth run: 0.7074'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第八次运行：0.7074
- en: 'Ninth run: 0.713'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第九次运行：0.713
- en: 'Tenth run: 0.7163'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第十次运行：0.7163
- en: 'Twentieth run: 0.7308'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二十次运行：0.7308
- en: 'Thirtieth run: 0.8188'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第三十次运行：0.8188
- en: 'Fortieth run: 0.8256'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第四十次运行：0.8256
- en: 'Fiftieth run: 0.8273'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第五十次运行：0.8273
- en: 'At the end of the fiftieth run, the improved confusion matrix looks as follows:'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第五十次运行的末尾，改进后的混淆矩阵如下：
- en: '[PRE107]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Not a bad result. More than 8 out of 10 digits are accurately recognized.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 结果还不错。超过 8 个数字被准确识别。
- en: 'Activity 15 : Written Digit Detection with Deep Learning'
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 15：使用深度学习进行手写数字检测
- en: This section will discuss how deep learning improves the performance of your
    model. We will be assuming that your boss is not satisfied with the results you
    presented in previous activity and asks you to consider adding two hidden layers
    to your original model and determine whether new layers improve the accuracy of
    the model. And to ensure that it happens correctly, you will need to have knowledge
    of Deep Learning.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论深度学习如何提高你模型的性能。我们将假设你的老板对你之前活动中展示的结果不满意，要求你考虑在你的原始模型中添加两个隐藏层，并确定新层是否提高了模型的准确度。为了确保正确发生，你需要了解深度学习。
- en: Execute the code of previous Activity and measure the accuracy of the model.
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行前一个活动的代码并测量模型的准确度。
- en: 'Change the neural network by adding new layers. We will combine the `relu`
    and `softmax` activator functions:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加新层来改变神经网络。我们将结合 `relu` 和 `softmax` 激活函数：
- en: '[PRE108]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: Retrain the model
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新训练模型
- en: '[PRE109]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Evaluate the model
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型
- en: '[PRE110]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'The output is as follows:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE111]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Calculating the accuracy score.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算准确度分数。
- en: '[PRE112]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: The output is `0.4516` .
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 输出为 `0.4516` 。
- en: The accuracy did not improve.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度没有提高。
- en: Let's see if further runs improve the accuracy of the model.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看进一步的运行是否能提高模型的准确度。
- en: 'Second run: 0.5216'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次运行：0.5216
- en: 'Third run: 0.5418'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次运行：0.5418
- en: 'Fourth run: 0.5567'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 第四次运行：0.5567
- en: 'Fifth run: 0.564'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 第五次运行：0.564
- en: 'Sixth run: 0.572'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 第六次运行：0.572
- en: 'Seventh run: 0.5723'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 第七次运行：0.5723
- en: 'Eighth run: 0.6001'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 第八次运行：0.6001
- en: 'Ninth run: 0.6076'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 第九次运行：0.6076
- en: 'Tenth run: 0.6834'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 第十次运行：0.6834
- en: 'Twentieth run: 0.7439'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 第二十次运行：0.7439
- en: 'Thirtieth run: 0.7496'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 第三十次运行：0.7496
- en: 'Fortieth run: 0.7518'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 第四十次运行：0.7518
- en: 'Fiftieth run: 0.7536'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 第五十次运行：0.7536
- en: 'Afterwards, we got the following results: 0.755, 0.7605, 0.7598, 0.7653'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，我们得到了以下结果：0.755，0.7605，0.7598，0.7653
- en: 'The final confusion matrix:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的混淆矩阵：
- en: '[PRE113]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: This deep neural network behaves even more chaotically than the single layer
    one. It took 600 iterations of 200 samples to get from an accuracy of 0.572 to
    0.5723\. Not long after this iteration, we jumped from 0.6076 to 0.6834 in that
    number of iterations.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这个深度神经网络的行为甚至比单层网络更加混沌。它需要经过600次迭代，每次迭代200个样本，才能将准确率从0.572提升到0.5723。在这个迭代过程不久之后，我们就在同样的迭代次数内将准确率从0.6076提升到了0.6834。
