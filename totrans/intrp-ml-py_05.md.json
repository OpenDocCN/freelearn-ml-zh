["```py\nimport math\nimport mldatasets\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn import metrics, svm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport shap\nimport lime\nimport lime.lime_tabular\nfrom lime.lime_text import LimeTextExplainer \n```", "```py\nchocolateratings_df = mldatasets.load(\"chocolate-bar-ratings_v2\") \n```", "```py\nchocolateratings_df \n```", "```py\ntastes_df = chocolateratings_df[\n    ['first_taste', 'second_taste', 'third_taste', 'fourth_taste']\n]\nchocolateratings_df = chocolateratings_df.drop(\n    ['first_taste', 'second_taste',\n     'third_taste', 'fourth_taste'],axis=1\n)\ntastes_df.head(90).tail(90) \n```", "```py\nchocolateratings_df = mldatasets.make_dummies_with_limits(\n    chocolateratings_df, 'company_location', 0.03333\n)\nchocolateratings_df = mldatasets.make_dummies_with_limits(\n    chocolateratings_df, 'country_of_bean_origin', 0.03333\n) \n```", "```py\ntastes_s = tastes_df.replace(\n    np.nan, '', regex=True).agg(' '.join, axis=1).str.strip() \n```", "```py\n0          cocoa blackberry robust\n1             cocoa vegetal savory\n2                rich fatty bready\n3              fruity melon roasty\n4                    vegetal nutty\n                   ...            \n2221       muted roasty accessible\n2222    fatty mild nuts mild fruit\n2223            fatty earthy cocoa\nLength: 2224, dtype: object \n```", "```py\ntastewords_fdist = FreqDist(\n    word for word in word_tokenize(tastes_s.str.cat(sep=' '))\n)\ntastewords_df = pd.DataFrame.from_dict(\n    tastewords_fdist, orient='index').rename(columns={0:'freq'}\n)\ncommontastes_l = tastewords_df[\n    tastewords_df.freq > 74].index.to_list()\nprint(commontastes_l) \n```", "```py\n['cocoa', 'rich', 'fatty', 'roasty', 'nutty', 'sweet', 'sandy', 'sour', 'intense', 'mild', 'fruit', 'sticky', 'earthy', 'spice', 'molasses', 'floral', 'spicy', 'woody', 'coffee', 'berry', 'vanilla', 'creamy'] \n```", "```py\nchocolateratings_df['tastes'] = tastes_s\nchocolateratings_df = mldatasets.make_dummies_from_dict(\n    chocolateratings_df, 'tastes', commontastes_l) \n```", "```py\nRangeIndex: 2224 entries, 0 to 2223\nData columns (total 46 columns):\n#   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n0   company                     2224 non-null   object\n1   review_date                 2224 non-null   int64  \n2   cocoa_percent               2224 non-null   float64\n:        :                         :     :        :\n43  tastes_berry                2224 non-null   int64  \n44  tastes_vanilla              2224 non-null   int64  \n45  tastes_creamy               2224 non-null   int64  \ndtypes: float64(2), int64(30), object(1), uint8(13) \n```", "```py\nrand = 9\ny = chocolateratings_df['rating'].\\\napply(lambda x: 1 if x >= 3.5 else 0)\nX = chocolateratings_df.drop(['rating','company'], axis=1).copy()\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=rand) \n```", "```py\nX_train_nlp = tastes_s[X_train.index]\nX_test_nlp = tastes_s[X_test.index] \n```", "```py\nsvm_mdl = svm.SVC(probability=True, gamma='auto', random_state=rand)\nfitted_svm_mdl = svm_mdl.fit(X_train, y_train)\ny_train_svc_pred, y_test_svc_prob, y_test_svc_pred =\\\n    mldatasets.evaluate_class_mdl(\n    fitted_svm_mdl, X_train, X_test, y_train, y_test\n) \n```", "```py\nnp.random.seed(rand)\nX_train_summary = shap.kmeans(X_train, 10)\nshap_svm_explainer = shap.KernelExplainer(\n    fitted_svm_mdl.predict_proba, X_train_summary\n)\nshap_svm_values_test = shap_svm_explainer.shap_values(\n    X_test, nsamples=200, l1_reg=\"num_features(20)\"\n)\nshap.summary_plot(shap_svm_values_test[1], X_test, plot_type=\"dot\") \n```", "```py\nsample_test_idx = X_test.index.get_indexer_for(\n    [5,6,7,18,19,21,24,25,27]\n) \n```", "```py\nexpected_value = shap_svm_explainer.expected_value[1]\ny_test_shap_pred =\\\n    (shap_svm_values_test[1].sum(1) + expected_value) > 0.5\nprint(np.array_equal(y_test_shap_pred, y_test_svc_pred)) \n```", "```py\nFN = (~y_test_shap_pred[sample_test_idx]) &\n    (y_test.iloc[sample_test_idx] == 1).to_numpy() \n```", "```py\nshap.decision_plot(\n    expected_value, shap_svm_values_test[1][sample_test_idx],\\\n    X_test.iloc[sample_test_idx], highlight=FN) \n```", "```py\nshap.decision_plot(\n    expected_value, shap_svm_values_test[1][696],\n    X_test.iloc[696],highlight=0\n) \n```", "```py\neval_idxs = (X_test.index==5) | (X_test.index==24)\nX_test_eval = X_test[eval_idxs]\neval_compare_df = pd.concat([\n    chocolateratings_df.iloc[X_test[eval_idxs].index].rating,\n    pd.DataFrame({'y':y_test[eval_idxs]}, index=[5,24]),\n    pd.DataFrame({'y_pred':y_test_svc_pred[eval_idxs]},\n    index=[24,5]), X_test_eval], axis=1).transpose()\neval_compare_df \n```", "```py\nshap.force_plot(\n    expected_value,\n    shap_svm_values_test[1][X_test.index==5],\\\n    X_test[X_test.index==5],\n    matplotlib=True\n) \n```", "```py\nshap.force_plot(expected_value,\\  \n                shap_svm_values_test[1][X_test.index==24],\\\n                X_test[X_test.index==24], matplotlib=True) \n```", "```py\nlime_svm_explainer = lime.lime_tabular.LimeTabularExplainer(\n    X_test.values,\n    feature_names=X_test.columns,\n    categorical_features=list(range(3,44)),\n    class_names=['Not Highly Recomm.', 'Highly Recomm.']\n) \n```", "```py\nlime_svm_explainer.explain_instance(\n    X_test[X_test.index==5].values[0],\n    fitted_svm_mdl.predict_proba,\n    num_features=8\n).show_in_notebook(predict_proba=True) \n```", "```py\nlime_svm_explainer.explain_instance(\n    X_test[X_test.index==24].values[0],\n    fitted_svm_mdl.predict_proba,\n    num_features=8\n).show_in_notebook(predict_proba=True) \n```", "```py\nprint(X_test_nlp) \n```", "```py\n1194                 roasty nutty rich\n77      roasty oddly sweet marshmallow\n121              balanced cherry choco\n411                sweet floral yogurt\n1259           creamy burnt nuts woody\n                     ...              \n327          sweet mild molasses bland\n1832          intense fruity mild sour\n464              roasty sour milk note\n2013           nutty fruit sour floral\n1190           rich roasty nutty smoke\nLength: 734, dtype: object \n```", "```py\nvectorizer = TfidfVectorizer(lowercase=False)\nX_train_nlp_fit = vectorizer.fit_transform(X_train_nlp)\nX_test_nlp_fit = vectorizer.transform(X_test_nlp) \n```", "```py\npd.DataFrame(\n    {\n        'taste':vectorizer.get_feature_names_out(),\n        'tf-idf': np.asarray(\n            X_test_nlp_fit[X_test_nlp.index==5].todense())[0]\n    }\n).sort_values(by='tf-idf', ascending=False) \n```", "```py\nlgb_mdl = lgb.LGBMClassifier(\n    max_depth=13,\n    learning_rate=0.05,\n    n_estimators=100,\n    objective='binary',\n    random_state=rand\n)\nfitted_lgb_mdl = lgb_mdl.fit(X_train_nlp_fit, y_train)\ny_train_lgb_pred, y_test_lgb_prob, y_test_lgb_pred =\\\n    mldatasets.evaluate_class_mdl(\n        fitted_lgb_mdl, X_train_nlp_fit, X_test_nlp_fit, y_train, y_test\n    ) \n```", "```py\nlgb_pipeline = make_pipeline(vectorizer, lgb_mdl) \n```", "```py\nlime_lgb_explainer = LimeTextExplainer(\n    class_names=['Not Highly Recomm.', 'Highly Recomm.']\n) \n```", "```py\nlime_lgb_explainer.explain_instance(\n    X_test_nlp[X_test_nlp.index==5].values[0],\n    lgb_pipeline.predict_proba, num_features=4\n).show_in_notebook(text=True) \n```", "```py\nlime_lgb_explainer.explain_instance(\n    X_test_nlp[X_test_nlp.index==24].values[0],\n    lgb_pipeline.predict_proba, num_features=4\n).show_in_notebook(text=True) \n```", "```py\nlime_lgb_explainer.explain_instance(\n    'creamy rich complex fruity',\n    lgb_pipeline.predict_proba, num_features=4\n).show_in_notebook(text=True)\nlime_lgb_explainer.explain_instance(\n    'sour bitter roasty molasses',\n    lgb_pipeline.predict_proba, num_features=4\n).show_in_notebook(text=True)\nlime_lgb_explainer.explain_instance(\n    'nasty disgusting gross stuff',\n    lgb_pipeline.predict_proba, num_features=4\n).show_in_notebook(text=True) \n```", "```py\npredict_fn = lambda X: lgb_mdl.predict_proba(X)[:,1] \n```", "```py\nX_test_nlp_samp_df = pd.DataFrame(\n    shap.sample(X_test_nlp_fit, 50).todense()\n)\nshap_lgb_explainer = shap.KernelExplainer(\n    predict_fn, shap.kmeans(X_train_nlp_fit.todense(), 10)\n)\nshap_lgb_values_test = shap_lgb_explainer.shap_values(\n    X_test_nlp_samp_df, l1_reg=\"num_features(20)\"\n)\nshap.summary_plot(\n    shap_lgb_values_test,\n    X_test_nlp_samp_df,\n    plot_type=\"dot\",\n    feature_names=vectorizer.get_feature_names_out()\n) \n```", "```py\nprint(shap.sample(X_test_nlp, 50).to_list()[18]) \n```", "```py\nwoody earthy medicinal \n```", "```py\nshap.force_plot(\n    shap_lgb_explainer.expected_value,\n    shap_lgb_values_test[18,:],\n    X_test_nlp_samp_df.iloc[18,:], \n    feature_names=vectorizer.get_feature_names_out()\n) \n```", "```py\nprint(shap.sample(X_test_nlp, 50).to_list()[9]) \n```", "```py\nintense spicy floral \n```"]