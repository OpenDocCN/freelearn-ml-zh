- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numerical Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our daily lives, while running errands and doing chores, the human mind is
    always carrying out some form of optimization. For example, the mind might be
    optimizing the route to take for single or multiple destinations that we need
    to visit. It can also be optimizing the cost of items that we need to buy on a
    trip to a grocery store, or, for example, budgeting our income and expenses on
    a weekly or monthly basis. Another example is to try to optimize the amount of
    sleep so that our mind is fresh the following day to work on our projects. In
    short, we are optimizing multiple tasks and schedules every single day without
    even knowing or thinking about it. Similarly, nature also optimizes its processes.
    For example, the Earth goes around the Sun in an optimal path to keep a balance
    between the various gravitational forces.
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimization** also plays a big role in the technology industry. Several
    large-scale optimization problems are being solved by small and large corporations.
    For example, a courier delivering packages to our home follows the route and schedule
    assigned by an optimization problem that solved an equation (either numerically
    or analytically) under several constraints to come up with that optimal route.
    Similarly, stock trading is another example, where the action can be to sell,
    hold, or buy stocks of a particular company to maximize long-term or short-term
    gains.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to discuss optimization in general while focusing
    more on numerical optimization, its examples, and use cases, along with its application
    in applied machine learning. The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common numerical optimization algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example use cases of large-scale numerical optimization problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numerical optimization using high-performance compute on AWS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning and numerical optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in the introduction to this chapter, optimization is an important
    tool for making decisions related to a large set of problems in our daily lives
    and various fields of science. There are various components to an optimization
    problem, as we are going to discuss in the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Goal or objective function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The process of optimization starts with defining a goal or an objective, such
    as monetary gain, a route or path, a schedule, items, and so on. Selecting the
    goal or objective depends heavily on the problem domain, as well as the specific
    problem we are trying to solve. In addition to the objective function, we also
    need to know whether we are maximizing or minimizing the objective function. Again,
    this also depends on the specific problem domain, as well as the objective function.
    For an optimization problem with cost as the objective function, our goal will
    most likely be to minimize it, whereas if our objective function is revenue or
    profit, we would like to maximize it.
  prefs: []
  type: TYPE_NORMAL
- en: For our route optimization example, one organization might be focused on solving
    the problem to maximize the number of delivered items, while another organization
    might want to minimize fuel cost per delivery. So, even though the problem domain
    is the same for both problems, the objective is different. Many times, the objectives
    may be related or dependent on each other. For example, in the route optimization
    problem, the number of delivered items and the fuel cost per delivery seem to
    be dependent on each other. Trying to deliver the maximum number of items in a
    given amount of time also means that the route needs to be defined in such a way
    that the distance from one location to the next is short. This means the vehicle
    is going to travel short distances to deliver items and hence fuel cost per delivery
    will be less.
  prefs: []
  type: TYPE_NORMAL
- en: Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The objective function for any optimization problem is generally a function
    of several variables. By changing the values of these variables, the value of
    the objective function also changes. For example, for the route optimization problem,
    one of the variables can be the speed of the vehicle. If the vehicle speed is
    increased, the number of deliveries made by the vehicle will increase, thereby
    improving the objective function’s value. Numerical optimization problems vary
    the values of these variables in an attempt to arrive at the optimal value of
    the optimization function. Mathematically, we can define the objective function,
    ![](img/f.png), which maps some set of variables, *X*, to real space, ![](img/Formula_14.02.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_14.03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Our objective or goal is to find the values, *X**, of the *X* variable that
    minimize or maximize (depending on the problem) our objective function, ![](img/f1.png).
    So, for the maximization case, the optimization problem can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_14.05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For the minimization case, the optimization problem can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_14.06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Constraints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the route optimization problem discussed previously, there will be an upper
    limit on the speed of a vehicle based on the maximum speed allowed on a road.
    The vehicle should not exceed that speed limit. This will be a constraint on the
    optimization objective function. Any optimization problem will either have constraints
    (constrained optimization) or not (unconstrained optimization). Generally, a large-scale
    numerical optimization problem has several constraints. The goal of the optimization
    problem in the presence of constraints then becomes finding the best value of
    the objective function while satisfying all the constraints. A few example constraints
    are defined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear constraints**: The ![](img/X1.png) and ![](img/X2.png) variables are
    greater than or equal to zero and their sum is less than 100:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_14.09.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_14.10.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_14.11.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Non-linear constraints**: The square of the ![](img/X1.png) variable is greater
    than ![](img/X2.png):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_14.14.png)'
  prefs: []
  type: TYPE_IMG
- en: A real-world large-scale numerical optimization problem will generally have
    both linear as well as non-linear constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling an optimization problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the hardest and most important tasks in any optimization problem is formulating
    or modeling the problem itself. This process involves identifying the variables,
    constraints, and objective function. Knowledge of the problem domain as well as
    a good understanding of the business problem that we are trying to solve are very
    important to have a good formulation of the optimization problem. Having a very
    simplistic formulation will not help us achieve good results with the problem,
    whereas having a too complicated formulation of the problem might result in giving
    us no solution or a bad solution while taking a very long time to numerically
    solve the problem, even on modern-day machines.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After formulating the problem, the next step is to pick an optimization algorithm
    and then use a software tool to run it on the data containing our variables and
    constraints. No one algorithm solves all the optimization problems. Picking the
    right algorithm is a big factor in getting a good solution in a reasonable amount
    of time. Similarly, there are several open source as well as commercial tools
    with implementations of optimization algorithms. Depending on our budget and the
    resources available, we should pick the right software tool to solve the optimization
    problem. Once the algorithm has been executed and we have the results, the next
    step is to make sure that all the constraints, as well as optimality conditions,
    are satisfied. We can also carry out sensitivity analysis on the solution, if
    it is not an optimal solution, to improve upon it.
  prefs: []
  type: TYPE_NORMAL
- en: Local and global optima
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The objective function that our optimization problem is attempting to solve
    usually has more than one optimum value. For example, if our optimization problem
    is a minimization problem and our objective function is convex, then it will have
    only one minimum value, called the **global minimum**, which can be found using
    methods based on calculus or well-known algorithms such as gradient descent, hill
    climbing, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.1* shows the case of a convex objective function of one variable
    with a global minimum value, while *Figure 14**.2* shows a convex objective function
    of two variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – A convex objective function of one variable with a global minimum](img/B18493_14_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.1 – A convex objective function of one variable with a global minimum
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 14.2 – A convex objective function of two variables with a global
    minimum](img/B18493_14_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – A convex objective function of two variables with a global minimum
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the optimization problems that we encounter and process in our daily
    lives have non-convex objective functions. These objective functions have more
    than one optimum value, referred to as **local optima**. *Figure 14**.3* and *Figure
    14**.4* show examples of objective functions with one variable with multiple local
    minima:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.3 ­– Objective function with multiple local minima](img/B18493_14_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 ­– Objective function with multiple local minima
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 14.4 – Objective function with multiple local minima](img/B18493_14_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.4 – Objective function with multiple local minima
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.5* and *Figure 14**.6* show examples of objective functions with
    two variables with multiple local minima:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.5 – Non-convex objective function showing multiple local minima](img/B18493_14_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Non-convex objective function showing multiple local minima
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.6 – Another example of a non-convex objective function showing
    multiple local minima](img/B18493_14_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.6 – Another example of a non-convex objective function showing multiple
    local minima
  prefs: []
  type: TYPE_NORMAL
- en: For optimization problems with non-convex objective functions, it is not easy
    to find the global minimum. No matter which algorithm we use, chances are that
    we will get a local minimum as the solution. There are, however, algorithms that
    perform iterative procedures to find good local minimum values. Random restart
    hill climbing and simulated annealing are examples of such algorithms. These iterative
    algorithms can be run on multiple machines or processors – not only to find a
    good local optimum solution in a short amount of time but also to be able to search
    multiple locations in the search space for the objective function concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discover some of the commonly used numerical optimization
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Common numerical optimization algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Several numerical optimization algorithms are implemented in open source and
    commercially sold optimization software tools. A lot of these algorithms are based
    on heuristic search, which is a technique based on solving problems quickly compared
    to classic methods. Heuristics-based algorithms attempt to find an approximate
    solution since the exact solution is very hard to find. The solutions provided
    by heuristics-based methods are considered good enough to solve the problem; however,
    it is generally not the best solution. In this section, we will briefly discuss
    a few of these algorithms. For detailed discussions on these algorithms and their
    mathematical formulation, you can refer to the articles and texts cited in the
    *Further reading* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Random restart hill climbing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In **hill climbing**, we start from a point, ![](img/Formula_14.15.png), and
    search in the neighborhood of ![](img/X.png). If the value of the objective function,
    ![](img/f2.png), increases in any direction in the neighborhood of ![](img/X.png),
    then we move in the direction of the increment. We stop when the value of the
    objective function does not increase in any direction. This is the local optimum
    value of the objective function relative to our starting point. This method is
    also called **steepest ascent hill climbing**. The algorithm is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_14.19.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Image94631.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_14.21.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 14**.7* shows an example of hill climbing to a local maximum value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.7 – Example of hill climbing to a local optimum in the objective
    function](img/B18493_14_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.7 – Example of hill climbing to a local optimum in the objective function
  prefs: []
  type: TYPE_NORMAL
- en: For the case of minimization problems, the algorithm searches for a valley (or
    local minimum value) in the objective function. Note that the optimum value found
    in *Figure 14**.7* is a local optimum value and it depends on where we started
    the search from.
  prefs: []
  type: TYPE_NORMAL
- en: '**Random restart hill climbing** is an extension of the hill climbing method,
    in which, after finding an optimum value, the algorithm starts again at a different
    location in the variable space. This will often result in arriving at a different
    optimum value, as shown in *Figure 14**.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.8 – Random restart hill climbing starting at two different variable
    values and then using hill climbing to get to the optimum value in the vicinity](img/B18493_14_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.8 – Random restart hill climbing starting at two different variable
    values and then using hill climbing to get to the optimum value in the vicinity
  prefs: []
  type: TYPE_NORMAL
- en: Even though the algorithm arrives at the global optimum value in *Figure 14**.8*,
    this will not always be the case. However, if we run random restart hill climbing
    several times, chances are that our resulting local optimum value at the end will
    be better than just trying hill climbing only once. Since random restart hill
    climbing starts with different values of the variables, which are chosen randomly
    each time, each iteration can be run on separate processors and threads to speed
    up the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Simulated annealing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In random restart hill climbing, we only move in one direction – the direction
    toward a local maximum (or minimum, depending on the problem type). This means
    that the algorithm only exploits the information and is not exploring outside
    of its immediate neighborhood. By not exploring at all, there is a good chance
    that the algorithm will get stuck in a local optimum value and will stay there.
    In **simulated annealing**, the algorithm also explores. It is not always trying
    to improve upon the current objective function value (to move in the direction
    of the local optimum), but it also sometimes moves in the direction where the
    objective function value gets worse (opposite to the direction of the local optimum).
    The simulated annealing algorithm is described as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a finite set of iterations, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Sample the new point, ![](img/Formula_14.22.png), in the neighborhood, ![](img/Formula_14.23.png)
    of the current point, ![](img/Formula_14.24.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Jump to the new point with the probability given by an acceptance probability
    function, ![](img/Formula_14.25.png), where *T* is the temperature parameter that
    controls how often we jump, and *f* is the objective function value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/Formula_14.26.png)'
  prefs: []
  type: TYPE_IMG
- en: Decrease temperature, ![](img/Formula_14.27.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the preceding expression, if the objective function value for the new point
    is greater than the current value, then we make the jump to the new point. If
    the objective function value for the new point is less than the current value,
    we make the jump to the new point with the following probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_14.28.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, let’s look at the effects of temperature on simulated annealing.
  prefs: []
  type: TYPE_NORMAL
- en: Effects of temperature, T
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are the effects of temperature, *T*, in simulated annealing:'
  prefs: []
  type: TYPE_NORMAL
- en: If *T* is large, the exponential will be close to 1, and we would make the jump
    with high probability, regardless of the objective function value at the new point,
    ![](img/Formula_14.30.png). This is very similar to random walk when ![](img/Formula_14.31.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If *T* is small, the exponential will be very small and we would rarely make
    the jump to the new point. This is very similar to hill climbing when ![](img/Formula_14.33.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'During the algorithm run, *T* is generally decreased slowly. When *T* is large,
    we jump around in the objective function space quite often and there is a good
    chance that we will end up somewhere close to the global optimum value or a good
    local optimum value for the objective function. By the time we have reduced *T*
    to a small value, we are probably very close to the global optimum and hence looking
    only in its vicinity. The probability of ending at a point, ![](img/X.png), is
    given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_14.38.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_14.39.png) scales the probabilities between 0 and 1\.
    As we can see from this expression, the larger the value of the objective function
    (in the case of the global maximum), the larger the probability that we will end
    at that point, ![](img/X.png). The same holds for the case of minimization tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.9* demonstrates the concept of simulated annealing, along with
    the probabilities of moving to the new point, depending on whether the newly selected
    points improve the objective function or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.9 – Probability of moving to a new point in simulated annealing
    when a neighboring point is selected to be the next point](img/B18493_14_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.9 – Probability of moving to a new point in simulated annealing when
    a neighboring point is selected to be the next point
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss Tabu search next.
  prefs: []
  type: TYPE_NORMAL
- en: Tabu search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Tabu search** is another heuristic-based numerical optimization method conceptually
    similar to simulated annealing. Just like simulated annealing, we are allowed
    to move to a solution where our objective function value worsens. In Tabu search,
    local search is carried out and it is prohibited to come back to previously visited
    solutions. A Tabu list is maintained that consists of rules and solutions that
    are not allowed to be explored during the local search, giving this method the
    name Tabu search.'
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Evolutionary algorithms are population-based algorithms that use candidate solutions
    along with some fitness function to evolve/improve the solution using mutation
    and recombination. Evolutionary methods are used quite often in numerical optimization
    problems and can find a good local optimum generally within a few iterations.
    Genetic algorithms are a very well-known and used class of evolutionary algorithms.
    Genetic algorithms have several applications in the domain of numerical optimization,
    as well as machine learning. They can be used with binary as well as non-binary
    representations. Genetic algorithms generally use two solutions and apply a crossover
    operator to these solutions to arrive at a better solution.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss the various applications and use cases
    of large-scale numerical optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Example use cases of large-scale numerical optimization problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we discussed a few of the commonly used numerical
    optimization methods. There are several others that we did not touch upon, and
    we recommend you check the *References* section for some great texts on several
    numerical optimization methods. Several very common large-scale optimization problems
    are implemented and solved in verticals, such as logistics, manufacturing, telecommunications,
    health care and life sciences, financial services, and so on. In this section,
    we are going to discuss a few of the very common practical large-scale numerical
    optimization use cases and applications. We will discuss the following use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: The traveling salesperson problem of determining the best route for a salesperson
    going from one city to the next
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dispatch optimization problem for technicians traveling via vehicles and carrying
    out various jobs in a geographic location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assembly line optimization to allocate the optimal type and number of parts
    to be manufactured on an assembly line
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will begin by discussing one of the oldest and most commonly studied numerical
    optimization problems, known as the traveling salesperson problem.
  prefs: []
  type: TYPE_NORMAL
- en: Traveling salesperson optimization problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The traveling salesperson problem is one of the most studied combinational
    optimization problems, first formulated in 1930\. It belongs to the class of NP-hard
    problems; the decision version of this problem belongs to the class of NP-complete
    problems. In the traveling salesperson problem, we are given a set of cities (or
    locations), and we start from a city, travel to each city exactly once, and return
    to the origin city to find the shortest route to accomplish this task. For example,
    as shown in *Figure 14**.10*, in the US map, we want to start from city A, travel
    through all the cities marked, and then return to city A while following the shortest
    possible route:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.10 – A map of the US showing arbitrary cities A through O](img/B18493_14_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.10 – A map of the US showing arbitrary cities A through O
  prefs: []
  type: TYPE_NORMAL
- en: Even though this problem seems simple to solve, it is an NP-hard problem. There
    are several combinations that the traveling salesperson can take to visit each
    city exactly once, but there is generally only one solution that accomplishes
    this with the shortest possible route. The traveling salesperson problem can be
    formulated in a few different ways. It can be formulated as an undirected weighted
    graph with cities being the vertices of the graph, the route connecting the cities
    being the edges, and weighted by the distance between the cities. It can then
    be solved as a minimization problem that starts and finishes at a given vertex,
    with each vertex being visited exactly once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to model the traveling salesperson problem is as an integer linear
    program. Several formulations can be used, such as the Miller-Tucker-Zemlin formulation
    and the Dantzig-Fulkerson-Johnson formulation. When the number of cities is small
    and only a small set of paths exists between the cities, the exact solution can
    be found in a small amount of time. However, as the number of cities and routes
    between the cities become large, finding the exact solution in a reasonable amount
    of time becomes almost impossible. In such situations, numerical methods attempt
    to find approximate or suboptimal solutions for the problem. *Figure 14**.11*
    shows one such example of a route found between the cities shown in *Figure 14**.10*.
    There may be possible shortest routes that exist for this problem, but the route
    shown in *Figure 14**.11* is reasonably good and is quite possibly either the
    shortest possible route or very close to the shortest possible route:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.11 – Example of the traveling salesperson problem showing a very
    good route (possibly the shortest possible route) between the cities marked from
    A through O on the map](img/B18493_14_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.11 – Example of the traveling salesperson problem showing a very good
    route (possibly the shortest possible route) between the cities marked from A
    through O on the map
  prefs: []
  type: TYPE_NORMAL
- en: The traveling salesperson problem has several applications in various fields,
    such as planning, logistics, manufacturing, DNA sequencing, and so on. There are
    also several open source and commercially sold software tools available for finding
    a solution for the traveling salesperson problem, as well as extending it to additional
    similar problems that exist in the industry. One of the most common practical
    extensions of the traveling salesperson problem is the vehicle routing problem.
    In the following section, we will discuss a more complex extension of the vehicle
    routing problem, called the worker dispatch optimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: Worker dispatch optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The vehicle routing problem attempts to find the optimal set of routes for a
    fleet of vehicles to make deliveries to customers. This is a very common problem
    in logistics where organizations such as the **United States Postal Service**
    (**USPS**), **United Parcel Service** (**UPS**), FedEx Corporation, and others,
    have to deliver several packages to a set of customers in various geographic locations
    daily. This problem can be formulated using various business objectives, such
    as delivering the packages promptly while maximizing the number of deliveries
    assigned to a driver/vehicle and minimizing the total fuel cost. These organizations
    generally formulate this problem as an optimization problem and then solve it
    daily (and often multiple times a day) to make the delivery to customers while
    also maximizing their profitability within certain constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the traveling person problem, finding a solution for the vehicle
    routing problem is also NP-hard. However, several numerical optimization software
    tools find a very good local optimum solution in a reasonable amount of time.
    Furthermore, using high-performance and distributed computing, the software can
    be written to start searching for various solutions at the same time on multiple
    processors and machines and then aggregate and find the best one out of the various
    local optima found.
  prefs: []
  type: TYPE_NORMAL
- en: Often, the vehicle routing problem is also extended with a few modifications
    to solve even more complex problems. One such example is the technician or worker
    dispatch optimization problem. In a worker dispatch optimization problem, the
    goal is to send technicians or workers to a customer location and carry out some
    task that requires time to complete. This is a very common problem for service-providing
    organizations such as electricity, gas, internet, telecommunication, and so on.
    These organizations have several worker/technician hubs or garages based on the
    home location of the worker. The jobs that arrive each day need to be assigned
    to these workers based on their schedules, as well as their skills and skill competency
    levels, since not all jobs are always the same. All workers have the same skill
    level for different types of jobs. Furthermore, in all such jobs, there is a committed
    time window to the customer that needs to be met for customer satisfaction. In
    addition, different jobs take a different amount of time to complete, and there
    is also the time required to travel a distance to the customer location, which
    may vary based on the time of day.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.12* shows an example where there is a worker hub in the center
    and several customer locations that need to be serviced by workers/technicians
    on a given day:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.12 – An example of the worker/technician optimization problem](img/B18493_14_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.12 – An example of the worker/technician optimization problem
  prefs: []
  type: TYPE_NORMAL
- en: We will now outline these constraints formally and also discuss a few objective
    functions that can be used to solve this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Possible objective metrics for the worker optimization problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The worker optimization problem can have several objective functions/metrics
    based on the requirements of the business. We will list a few of these here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Minimize total fuel cost**: With this objective function, the goal is to
    find a non-trivial solution that minimizes the total fuel cost per job of all
    the vehicles on any given day. Fuel costs will depend on the number of workers
    and vehicles, the number of jobs, the location of jobs, the routes that were taken
    to get to the jobs, the order of the jobs, and the worker’s schedules. Often,
    minimizing fuel costs is an indirect consequence of finishing the maximum number
    of jobs on a given day, because if the algorithm can pack a large number of jobs
    for a given worker, then the fuel cost per job for that particular vehicle will
    be low and hence the total fuel cost per job will be low as well for all the workers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximize the number of jobs done on a given day**: To maximize profit and
    also to keep the customers happy, service organizations need to maximize the number
    of jobs completed on a given day with as few jobs as possible being carried over
    to the next day. This also depends on the number of workers available on a given
    day, worker skills, and the route taken to carry out the jobs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximize worker efficiency**: This objective is dependent on maximizing the
    number of jobs done on a given day. The goal of this objective function is to
    maximize the number of jobs carried out by each worker on a given day, which also
    depends on the technician’s schedule, skills, level of competency, starting location,
    and the distance needed to travel by the technician.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Composite objective function**: In a composite objective function, the goal
    is to explicitly optimize a combination of objective functions, such as maximizing
    worker efficiency and minimizing distance or fuel cost. Sometimes, the various
    terms in a composite objective function may also be opposite to each other. For
    example, increasing one may result in decreasing the other, and so on. In such
    cases, we may have penalty terms associated with the different objective functions
    comprising the composite function and optimize the resulting combination of penalized
    terms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s look at some of the constraints that can be important for formulating
    the worker dispatch optimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: Important constraints for the worker dispatch optimization problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are some of the important constraints for the worker dispatch
    optimization problem. While constraints cover the most common ones, there can
    be additional constraints, depending on the individual use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The number of jobs**: The total number of jobs for a given worker hub on
    any given day is important and affects the worker efficiency number, as well as
    the distance traveled, and hence the fuel cost. How many jobs can be feasibly
    completed on any given day is also heavily dependent on the number of jobs on
    a given day.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The number of workers available on a given day**: How many workers are available
    on a given day to carry out the jobs is another important constraint and it has
    a significant impact on worker efficiency, as well as distance traveled and fuel
    cost.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Worker schedule**: In addition to the number of workers available, the schedule
    of each worker is also an important constraint. Some workers may start their shift
    at 8 A.M. and some at 10 A.M., and so on. Similarly, the number of hours each
    worker may work each day might be different. Some may work for 8 hours, and others
    for 6 hours. In addition, generally, workers also have break times, such as lunch
    and other periodic breaks. These breaks may also be at different times, adding
    further schedule-related constraints to the optimization problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Job types**: There are generally several different job types. For example,
    for a telecommunication organization, there might be new service installations
    or old service repair jobs. In addition, several service-providing organizations
    offer multiple products and services. For example, a telecommunication organization
    generally offers internet, cable/TV services, and home phone services. These different
    job types add another dimension to the optimization problem, further complicating
    it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Worker skills and skills-related competency levels**: Just like the different
    job types mentioned previously, different workers and technicians have different
    skill types as well as expertise levels in the skill. Using the same telecommunication
    use case example again, some workers might be dedicated to installing new services
    and others to repairing old services. In addition, some technicians can be experts
    in internet service installation and others in telephone service installation.
    This results in different workers taking different amounts of time to install
    the same service or debug and repair the same problem. This also adds an interesting
    dilemma when formulating the problem from a business point of view.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The business may want to maximize the total number of jobs completed on a given
    day, which is generally accomplished if the algorithm matches the skill levels
    of workers with the jobs appropriately. On the other hand, if the business follows
    this approach, then the workers may not be able to learn new skills or get practical
    experience related to services and problems that they are not already an expert
    at. This parameter regarding skill level should be modeled appropriately in the
    formulation of the problem to achieve the best results.
  prefs: []
  type: TYPE_NORMAL
- en: '**Job locations**: Where each job is located in a geographical location is
    also important for deciding the route assigned by the optimization solution to
    each worker.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customer time windows**: Service-providing companies also commit to a specific
    time window in which the worker should arrive at the customer/job location. These
    time windows may also vary based on the type of job, the number of workers available,
    as well as geographical locations. These time windows also have a significant
    effect on the final objective function value. For example, there might be a new
    service install job at a customer location with a committed time window of 8–10
    A.M. on a particular day. At the same time, there might be another customer very
    close by with a repair request. Now, even though the jobs are physically very
    close to each other, because of the promised time window, the organization will
    probably need to dispatch multiple workers to adhere to the times committed to
    the customer. Due to this, several modernized organizations are also formulating
    the worker dispatch problem jointly with the scheduling problem; when there is
    a request for a repair or an installation, the scheduler should take into account
    all these constraints while committing to a time window with the customer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Job durations**: Different jobs take different amounts of time to complete.
    There is generally an average time for a particular job for all the workers in
    a worker hub, and also, individual times are taken by each worker to complete
    that job. All these are also modeled as constraints in the optimization problem
    to get the best results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximum travel time and distance**: Generally, there is also a maximum limit
    on how much total distance or time a worker may travel on a given day, as well
    as the farthest a worker may travel from the garage hub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to these constraints, there may be additional constraints too (for
    example, the weather: rain, snow, storm, and so on), depending on the particular
    organization working on the use case. As we can imagine, all these constraints
    make the worker dispatch optimization problem very complicated. Generally, for
    any organization using this approach to assign jobs to its workers, this problem
    is solved on multiple higher-performance computation machines every morning in
    a distributed fashion. For example, for the same geographic location, the random
    restart approach for hill climbing and other similar algorithms can be used, with
    each restart iteration being executed on a different processor and/or machine.
    There are several open source and commercially available optimization software
    that formulate and solve this problem very efficiently in a reasonable amount
    of time.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.13* shows an example of three worker hubs with three workers each
    following an optimized route to the job locations and back to the worker hub:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 14.13 – Example showing three worker hubs and nine workers \uFEFF\
    in total\uFEFF, with three workers each starting from a worker hub and following\
    \ an optimized route to the job locations](img/B18493_14_013.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 14.13 – Example showing three worker hubs and nine workers in total,
    with three workers each starting from a worker hub and following an optimized
    route to the job locations
  prefs: []
  type: TYPE_NORMAL
- en: By using numerical optimization algorithms to solve this optimization problem,
    service companies can improve worker efficiency, cut down on fuel costs, and improve
    customer satisfaction significantly. Next, we will discuss another example of
    numerical optimization for allocating items to an assembly line to maximize the
    number of produced items on a given day.
  prefs: []
  type: TYPE_NORMAL
- en: Assembly line optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In manufacturing industries such as electronics manufacturing, there are usually
    several assembly lines or belts on which various items are being built and assembled
    to build a final product, such as a desktop/laptop computer, cell phone, tablet,
    and so on. On these assembly lines, human workers are manually working on assembling
    the items. Different assembly lines can assemble different products, with some
    overlap. Furthermore, the workers assembling the products also vary in some skills
    and skill levels, just like the worker dispatch optimization problem. Let’s discuss
    the various optimization metrics that can be used for this problem based on the
    business use case.
  prefs: []
  type: TYPE_NORMAL
- en: Objective metrics for assembly line optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following objective metrics are some of the common ones used for the assembly
    line optimization problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Maximize the number of items produced on a given day**: Using this metric,
    the goal is to maximize the total number of items assembled on any given day.
    Generally, it also depends on the number of orders, as well as the forecast for
    the number of items needed in near future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimize the number of items stored in storage**: With this metric, the goal
    is to minimize the number of excessive items manufactured and stored in the storage
    for future sales. This metric also depends on the forecast of items to be manufactured,
    as well as the storage capacity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to these metrics, other metrics can be used based on the business
    use case and goals. Furthermore, like the worker dispatch optimization problem,
    objective metrics comprised of multiple metrics can also be used. Let’s look at
    some of the constraints for this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Constraints for the assembly line optimization problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following constraints are important for the assembly line optimization
    problem:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of different items needed to be assembled each day. This constraint
    depends on the sales forecast, as well as the number of pre-ordered items.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of workers available to work on a given day, as well as the schedule
    of each worker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The skills of various individual workers, as well as the skill competency level
    of each worker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Skills needed to assemble various items.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The capacity of each belt to assemble different items.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage capacity of the factory and/or warehouse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum number of items that can be stored (surplus) for a specific amount
    of time, such as a day, a week, or a month.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While these are some of the common constraints being considered while formulating
    the assembly line optimization problem, there can be additional constraints as
    well, depending on the specific business use case and various other conditions
    and requirements. By formulating this problem as an optimization problem and then
    solving it on a daily, weekly, monthly, or quarterly schedule, manufacturing companies
    generally improve their yield, profit, and efficiency while reducing waste and
    the number of surplus items.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discussed a few applications and use cases of numerical
    optimization being used in the industry. In the next section, we are going to
    discuss the high-performance compute options available on AWS for solving these
    numerical optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Numerical optimization using high-performance compute on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the previous sections, most of the numerical optimization problems
    are NP-hard and highly compute-intensive for finding a reasonable solution. The
    software tool employing these algorithms has to carry out a large-scale search
    over a very complicated multidimensional objective function in search of the global
    optimum. Because of the complexity, the number of dimensions, non-convexity, and
    sometimes discontinuities present in these objective functions, it is almost impossible
    to find the global optimum in a finite amount of time, even with today’s compute
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: However, for most of these problems, several commercially available and open
    source software tools find a very good solution (local optimum) in a reasonable
    amount of time. These tools can be run on the infrastructure and compute resources
    provided by AWS. Let’s discuss some of the common commercial and open source tools
    that can be installed and run on various AWS resources to solve numerical optimization
    problems in almost every industry domain.
  prefs: []
  type: TYPE_NORMAL
- en: Commercial optimization solvers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following commercial solvers are some of the most popular and common ones
    used on AWS compute infrastructure:'
  prefs: []
  type: TYPE_NORMAL
- en: IBM ILOG CPLEX Optimization Studio (commonly known as **CPLEX**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gurobi Optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FICO Xpress Optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A Mathematical Programming** **Language** (**AMPL**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open source optimization solvers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to the commercially sold optimization solver tools, the following
    open source optimization solvers can be easily run on AWS compute infrastructure
    as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '**GNU Linear Programming** **Kit** (**GLPK**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computational Infrastructure for Operations** **Research** (**COIN-OR**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pyomo
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convex Over and Under ENvelopes for Nonlinear** **Estimation** (**Couenne**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PuLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google OR-Tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SCIP Optimization Suite
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These commercially available and open source software tools can be run on AWS
    infrastructure using a variety of different architecture patterns, as outlined
    in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Numerical optimization patterns on AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Various architecture patterns can be employed to run the previously mentioned
    optimization software tools on AWS resources.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.14* shows various tools and resources from the AWS stack that
    can be used to help with solving numerical optimization problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.14 ­– Various AWS resources and tools that can be used to solve
    numerical optimization problems](img/B18493_14_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.14 ­– Various AWS resources and tools that can be used to solve numerical
    optimization problems
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss a few architecture patterns employing these AWS resources and
    tools and see how they can help with solving numerical optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: EC2 instances
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can install and run these optimization tools on Amazon EC2 instances in
    a container. The optimization software suite, along with all the required libraries,
    can be built into a container that can then utilize EC2 instances, which can also
    be used in a distributed manner to run several parallel searches at the same time
    (for example, random restart hill climbing). By running multiple iterations of
    these algorithms in parallel, there is a better chance of arriving at the global
    optimum value or a very good local optimum. *Figure 14**.15* shows the architecture
    for running these optimization tools on EC2 instances using containers:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 14.15 – Example architecture showing numerical optimization software\
    \ running on a containe\uFEFFr on an Amazon EC2 compute instance](img/B18493_14_015.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 14.15 – Example architecture showing numerical optimization software
    running on a container on an Amazon EC2 compute instance
  prefs: []
  type: TYPE_NORMAL
- en: Using a serverless architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In addition to using EC2 instances, we can also run the optimization software
    in a serverless manner on AWS. One example of using a serverless architecture
    is shown in *Figure 14**.16*, where AWS Lambda is used to launch multiple optimization
    tasks on AWS Fargate. These tasks can be run in parallel and then aggregated to
    get the best solution for an optimization problem. These tasks can also be different
    optimization packages and libraries attempting to solve the same problem, with
    the best result being used at the end. The data consisting of constraints and
    variables can be read from Amazon S3, as also shown in *Figure 14**.16*. Amazon
    CloudWatch is also used in this pattern to output the necessary steps and status
    messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.16 – An example of a serverless architecture using AWS Lambda and
    AWS Fargate to run various optimization tasks in parallel](img/B18493_14_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.16 – An example of a serverless architecture using AWS Lambda and
    AWS Fargate to run various optimization tasks in parallel
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of using this approach over that of EC2 instances is cost and
    scalability. We can start as many optimization tasks as needed without having
    to worry about managing EC2 instances. In addition, since we are using a serverless
    architecture, we only need to pay for the compute for the duration that our optimization
    tasks are running. As an example, for our worker dispatch optimization problem,
    the job and worker-related data can arrive in an Amazon S3 bucket every morning.
    Then, using AWS Lambda, various optimization tasks can be launched on AWS Fargate,
    with each task for a particular worker hub attempting to find the optimal route
    and schedule for every worker in the worker hub.
  prefs: []
  type: TYPE_NORMAL
- en: Using Amazon SageMaker processing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In addition to using dedicated EC2 instances and a serverless architecture,
    we can also carry out numerical optimization on Amazon SageMaker using SageMaker
    processing jobs. *Figure 14**.17* shows an example of this architecture pattern,
    where data consisting of constraints and various variables is residing in an Amazon
    S3 bucket. AWS Lambda and an AWS Step function are used to launch a SageMaker
    processing job that reads the data from the S3 bucket and runs the optimization
    task in a container with all the required packages and software needed to run
    the optimization job. This optimization job is run on an ephemeral EC2 instance;
    once the job is completed, the instance is released and no more cost for the instance
    is incurred. The results are written in S3 and also in Amazon DynamoDB after some
    post-processing by an AWS Lambda function. A few other AWS resources are shown
    in *Figure 14**.17*, such as for authentication and caching, which may or may
    not be necessary, depending on the specific use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.17 – An example of running numerical optimization using Amazon
    SageMaker processing](img/B18493_14_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.17 – An example of running numerical optimization using Amazon SageMaker
    processing
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked at a few ways numerical optimization problems can
    be solved using AWS high-performance compute resources and tools. While these
    are good examples of architectural patterns that can be employed for a variety
    of use cases, these can also be modified and extended, depending on the use case
    and business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we are going to look at how numerical optimization is important
    for solving machine learning problems as well.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning and numerical optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have discussed numerical optimization and its use cases from an optimization
    problems perspective. Whereas numerical optimization has several standalone industry
    use cases and applications, it is also very commonly used in several machine learning
    algorithms and use cases. Whether it’s supervised learning, unsupervised learning,
    or reinforcement, we are always solving some form of optimization problem using
    iterative processes at the very core of a machine learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In supervised learning, for example, let’s look at the case of linear regression.
    In linear regression, we are minimizing a cost function consisting generally of
    the mean squared error between the actual value of a target variable and the value
    predicted via the model.
  prefs: []
  type: TYPE_NORMAL
- en: Our algorithm arrives at the minimum value of the cost function (convex function
    with a global minimum if it is mean squared error, non-convex with local minima
    in most other cases) using an iterative algorithm, such as gradient descent. Gradient
    descent looks at the gradient of the cost function and then modifies the linear
    regression parameters in the direction of the gradient. This way, after a certain
    number of iterations, the algorithm arrives at the global or local minimum value
    of the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, in logistic regression, we use an objective function consisting of
    logarithm terms. This objective function is again convex and we use gradient descent
    again to arrive at the minimum value of the objective function. Hence, once again,
    we are solving a numerical optimization problem at the core of the problem, with
    the higher-level goal of building a machine learning model for a classification
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: In neural networks, including deep neural networks, we have several parameters
    for which we need to find the optimal value so that some error is minimized at
    the output layer. In the field of deep learning, we often have very large machine
    learning models consisting of millions or even billions of weights or parameters,
    especially for natural language processing and computer vision problems. Each
    neuron or unit in the neural network has some activation function, which is a
    function of a few of these parameters. To build a model that fits the data well
    and does good predictions on tests or new data, we need to find the optimal value
    of neural network parameters/weights. This, again, is achieved by using gradient
    descent or some other optimization algorithm to solve this numerical optimization
    problem consisting of a very large number of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to supervised learning, numerical optimization is also used in unsupervised
    learning problems. For example, in clustering methods such as K-means clustering,
    we are trying to minimize the distance between the cluster center and associated
    points in the cluster. Similarly, in expectation maximization (a soft clustering
    method), we are maximizing the likelihood of each data point being generated by
    a Gaussian distribution, whose mean we are attempting to find.
  prefs: []
  type: TYPE_NORMAL
- en: In reinforcement learning, numerical optimization is also quite often used.
    For example, in most reinforcement learning methods, the goal of the algorithm
    is to maximize some form of long-term reward using actions and rewards, while
    simulating the scenario repeatedly to learn the optimal policy that maximizes
    long-term reward. In deep reinforcement learning, we use the neural network weights
    to approximate the policy. These weights are, again, learned using numerical optimization
    algorithms such as gradient descent. In short, no matter which type of machine
    learning problem we are trying to solve, there is a strong connection with numerical
    optimization, and for most of these machine learning problems, we are solving
    some form of optimization problem to get the answer for our machine learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s summarize what we’ve learned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed numerical optimization and its applications. We
    started with a discussion about numerical optimization and its necessary ingredients.
    Next, we discussed a few of the common numerical optimization methods. We also
    discussed a few large-scale applications and use cases of numerical optimization.
    These use cases are very well known in academia as well as in the industry and
    are implemented by several organizations in their businesses. In addition, we
    talked about how AWS high-performance compute options and resources can be used
    to solve numerical optimization methods, and also discussed a few architectural
    patterns to accomplish this.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we ended with a short discussion about how various categories of machine
    learning algorithms employ numerical optimization at their core to build good
    models. The topics covered in this chapter will help you understand and formulate
    numerical optimization use cases, how numerical optimization is important for
    machine learning, and how high-performance computing can help with solving numerical
    optimization use cases. In addition, you should have an idea of the tools and
    software available for solving numerical optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, in this book, we have discussed the fundamentals of high-performance
    computing, followed by the data management, transfer, compute, networking, and
    storage aspects of high-performance computing. We also talked about applied modeling
    and its examples, such as data analysis, preprocessing, visualization, distributed
    training of machine learning models, optimizing models and their deployment, along
    with scaling machine learning models. Furthermore, we looked at various applications
    of high-performance computing, such as computational fluid dynamics, genomics,
    autonomous vehicles, and numerical optimization. The material presented in this
    text will introduce you to all these concepts and enable you to explore further
    and solve interesting use cases in high-performance computing and associated fields.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*An Interactive Tutorial on Numerical* *Optimization*: [https://www.benfrederickson.com/numerical-optimization/](https://www.benfrederickson.com/numerical-optimization/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'El-Ghazali Talbi. 2009\. *Metaheuristics: From Design to Implementation*. Wiley
    Publishing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refs on NP-hard and completeness:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The traveling salesperson problem: [https://en.wikipedia.org/wiki/Travelling_salesman_problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The vehicle routing problem: [https://www.sciencedirect.com/topics/economics-econometrics-and-finance/vehicle-routing-problem](https://www.sciencedirect.com/topics/economics-econometrics-and-finance/vehicle-routing-problem)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'IBM ILOG CPLEX Optimization Studio: [https://www.ibm.com/analytics/cplex-optimizer](https://www.ibm.com/analytics/cplex-optimizer)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gurobi Optimization: [www.gurobi.com](http://www.gurobi.com)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FICO Xpress Optimization: [https://www.fico.com/en/products/fico-xpress-optimization](https://www.fico.com/en/products/fico-xpress-optimization)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AMPL: [https://ampl.com/](https://ampl.com/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GNU Linear Programming Kit: [https://www.gnu.org/software/glpk/](https://www.gnu.org/software/glpk/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Computational Infrastructure for Operations Research: [https://www.coin-or.org/](https://www.coin-or.org/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pyomo: [http://www.pyomo.org/](http://www.pyomo.org/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Convex Over and Under ENvelopes for Nonlinear Estimation: [https://github.com/coin-or/Couenne](https://github.com/coin-or/Couenne)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PuLP: [https://pypi.org/project/PuLP/](https://pypi.org/project/PuLP/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google OR-Tools: [https://developers.google.com/optimization](https://developers.google.com/optimization)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SCIP Optimization Suite: [https://www.scipopt.org/](https://www.scipopt.org/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
