- en: Implementing Recommender Systems with Julia
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we took a deep dive into data mining and web development
    with Julia. I hope you enjoyed a few relaxing rounds of *Six Degrees of Wikipedia* while
    discovering some interesting articles. Randomly poking through the millions of
    Wikipedia articles as part of a game is a really fun way to stumble upon interesting
    new content. Although I'm sure that, at times, you've noticed that not all the
    articles are equally good—maybe they're stubs, or subjective, or not so well written,
    or simply irrelevant to you. If we were able to learn about each player's individual
    interests, we could filter out certain Wikipedia articles, which would turn each
    game session into a wonderful journey of discovery.
  prefs: []
  type: TYPE_NORMAL
- en: It turns out that we're not the only ones struggling with this—information discovery
    is a multibillion-dollar problem, regardless of whether it's articles, news, books,
    music, movies, hotels, or really any kind of product or service that can be sold
    over the internet. As consumers, we are exposed to an immense variety of choices,
    while at the same time, we have less and less time to review them—and our attention
    span is getting shorter and shorter. Making relevant recommendations instantly
    is a key feature of all successful online platforms, from Amazon to Booking.com,
    to Netflix, to Spotify, to Udemy. All of these companies have invested in building
    powerful recommender systems, literally inventing new business models together
    with the accompanying data collection and recommendation algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll learn about recommender systems—the most common and
    successful algorithms that are used in the wild for addressing a wide variety
    of business needs. We''ll look at the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What recommender systems are and how are they used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content-based versus collaborative filtering recommender systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-based and item-based recommender systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More advanced data analysis using `DataFrames` and statistical functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to roll out our own recommender systems using content-based and collaborative
    filtering algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Julia package ecosystem is under continuous development and new package
    versions are released on a daily basis. Most of the times this is great news,
    as new releases bring new features and bug fixes. However, since many of the packages
    are still in beta (version 0.x), any new release can introduce breaking changes.
    As a result, the code presented in the book can stop working. In order to ensure
    that your code will produce the same results as described in the book, it is recommended
    to use the same package versions. Here are the external packages used in this
    chapter and their specific versions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to install a specific version of a package you need to run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively you can install all the used packages by downloading the `Project.toml`
    file provided with the chapter and using `pkg>` instantiate as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Understanding recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In its broadest definition, a **recommender system** (**RS**) is a technique
    that's used for providing suggestions for items that are useful to a person. These
    suggestions are meant to help in various decision-making processes, usually related
    to buying or consuming a certain category of products or services. They can be
    about buying a book, listening to a song, watching a movie, eating out at a certain
    restaurant, reading a news article, or picking the hotel for your next holiday.
  prefs: []
  type: TYPE_NORMAL
- en: People have relied on recommendations pretty much since the beginning of history.
    Some RS researchers talk about the first recommendations as being the first orally
    transmitted information about dangerous plants, animals, or places. Others think
    that recommendations systems functioned even before language, by simply observing
    the effects on other humans of consuming plants or unwisely confronting dangerous
    creatures (that could count as an extreme and possibly violent example of implicit
    ratings, as we'll see in the following paragraphs).
  prefs: []
  type: TYPE_NORMAL
- en: But we don't have to go that far into human history. In more recent (and less
    dangerous) times, we can find some great examples of highly successful recommender
    systems, such as librarians suggesting books based on your tastes and interests,
    the butcher presenting meat products for your Sunday recipe, your friends' opinion
    of the latest blockbuster, your neighbor's stories about the kindergarten across
    the street, and even your MD recommending what treatment to follow to alleviate
    the symptoms and eliminate the cause of your disease. Other recommender systems
    are more formal, but equally pervasive and familiar, such as the star category
    ranking of hotels or the blue flags on top beaches around the world.
  prefs: []
  type: TYPE_NORMAL
- en: For a very long time, the experts in various fields played the part of recommenders,
    using their expertise in combination with their understanding of our tastes and
    interests, skillfully probing us for details. However, the rise of the internet
    and online platforms (e-commerce websites, online radios, movie streaming platforms,
    and social networks) has replaced the traditional models by making a huge catalog
    of items (products) available to a potentially very large consumer base (now called
    **users**). Due to considerations like 24-hour availability, language barriers,
    and sheer volume, personal recommendations were no longer a feasible option (although
    in the last couple of years, there was a certain recurrence of human-curated recommendations,
    from music, to books, to luxury products—but that's a different discussion).
  prefs: []
  type: TYPE_NORMAL
- en: This expansion in the number of choices made finding the right product a very
    difficult task. At that point, software-based recommender systems entered the
    stage.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon.com is credited as being the first online business that deployed software
    recommender systems at scale, with extraordinary business benefits. Later on,
    Netflix became famous for awarding a one million dollar prize to the team that
    came up with a recommendation algorithm better than theirs. Nowadays, automated
    recommender systems power all major platforms, from Spotify's *Discover Weekly* playlists
    to Udemy's recommended courses.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Different business needs—from suggesting related products after buying your
    new laptop, to compiling the perfect driving playlist, to helping you reconnect
    with long lost schoolmates—led to the development of different recommendation
    algorithms. A key part of rolling out a recommender system is picking the right
    approach for the problem at hand to fully take advantage of the data available.
    We'll take a look at the most common and most successful algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about non-personalized, stereotyped, and personalized recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest types of recommendations, from a technical and algorithmic perspective,
    are the non-personalized ones. That is, they are not customized to take into account
    specific user preferences. Such recommendations can include best-selling products,
    various top 10 songs, blockbuster movies, or the most downloaded apps of the week.
  prefs: []
  type: TYPE_NORMAL
- en: Non-personalized recommendations are less challenging technically, but also
    considerably less powerful. They can be good approximations in certain cases,
    especially when the product catalog is not very large (there are not that many
    Hollywood releases, for example). But for an e-commerce retailer like Amazon,
    with millions of products available at any given time, the chances of getting
    it right using generic recommendations are slim.
  prefs: []
  type: TYPE_NORMAL
- en: 'An improvement in non-personalized recommendations comes from combining them
    with a classification strategy. By stereotyping, we can make the recommended items
    more relevant, especially when we can identify significantly different user demographics.
    A good example of this is app store recommendations, which are broken down by
    country. Take, for instance, the following list of recommended new games. This
    is what it looks like if you are a user accessing the app store from the US:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/65f54a74-a4ab-4792-b873-dd2077dd5775.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is what it looks like for a user in Romania, at the exact same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5dc64b59-1d9e-438f-842a-6573e4dfeb3a.png)'
  prefs: []
  type: TYPE_IMG
- en: You can easily notice that the top selections vary widely. This is driven by
    both cultural differences and preferences, but also by availability (copyright
    and distribution) issues.
  prefs: []
  type: TYPE_NORMAL
- en: We won't focus on non-personalized recommendations in this chapter, since implementing
    them is quite straightforward. All that is needed for making such recommendations
    is to identify the relevant metrics and the best performing items, such as the
    number of downloads for apps, copies sold for a book, volume of streams for a
    song or movie, and so on. However, non-personalized recommendations, as a business
    solution, should not be dismissed, as they can be useful when dealing with users
    that don't present any relevant personal preferences—usually new users.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding personalized recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both from a business and a technical perspective, the most interesting recommender
    systems are the ones that take into account the user's preferences (or user's
    ranking).
  prefs: []
  type: TYPE_NORMAL
- en: Explicit and implicit ratings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When looking for personalization features, we must take into account both explicit
    data that's willingly provided by the user, as well as relevant information that's
    generated by their behavior in the app or on the website (or anywhere else where
    we're tracking user behavior really, since the boundary between the online and
    physical realms is becoming more blurry, for example, with the introduction of
    smart cars and autonomous shop checkouts, to name just a few). The explicit rating
    includes actions such as grading a product or an experience, awarding stars to
    a movie or purchase, and retweeting or liking a post. On the other hand, not bouncing
    back to the search results page, sharing a song, or watching a video until the
    end are all examples of an implicit positive rating, while returning a product,
    canceling a subscription, or not finishing an online training course or an eBook
    are instances of negative implicit ranking.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding content-based recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most common and successful types of recommendations are content-based.
    The core idea is that if I expressed a preference for a certain set of items,
    I will most likely be interested in more items that share the same attributes.
    For example, the fact that I watched `Finding Nemo (2003)` can be used as an indication
    that I will be interested in other movies from the animation and comedy genres.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, watching one of the original *Star Wars* movie can be interpreted
    as a signal that I like other movies from the franchise, or movies with Harrison
    Ford, or directed by George Lucas, or science fiction in general. Indeed, Netflix
    employs such an algorithm, except at a more granular level. Per a recent article,
    Netflix has a large team that's tasked with watching and tagging movies in detail—later
    on, matching movie features with users groups. The users themselves are equally
    carefully classified into thousands of categories.
  prefs: []
  type: TYPE_NORMAL
- en: More advanced content-based recommender systems also take into account the relative
    weight of the different tags. In the case of the previously mentioned `Finding
    Nemo (2003)`, the suggestions should be less about movies with fish and sharks
    and more about the fact that it's a funny, light-hearted family movie, so hopefully,
    the recommendation will be more `Finding Dory (2016)` and less *Jaws*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how we can build a basic movie recommender using a content-based
    algorithm. To keep things simple, I have set up a table with the top 10 movies
    of 2016 and their genres. You can find this file in this book''s GitHub repository,
    as `top_10_movies.tsv`, at [https://github.com/PacktPublishing/Julia-Programming-Projects/blob/master/Chapter06/top_10_movies.tsv](https://github.com/PacktPublishing/Julia-Programming-Projects/blob/master/Chapter06/top_10_movies.tsv):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b432b80-4e1f-413f-a382-b89e3c79d870.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, you can see how we use a binary system to represent
    whether a movie belongs to a genre (encoded by a `1`) or not (a `0`).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily load such a table from a CSV/TSV file into Julia by using the
    `readdlm` function, which is available in the `DelimitedFiles` module. This module
    comes with the default Julia installation, so there''s no need to add it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'There is also the option of letting `readdlm` know that the first row is the
    header, passing `header = true`. However, this would change the return type of
    the function invocation to a tuple of `(data_cells, header_cells)`, which is not
    pretty-printed in interactive environments. At this exploratory phase, we''re
    better off with a table-like representation of the data. The result is a tabular
    data structure that contains our movie titles and their genres:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see what movie from the top 10 list we could recommend to a user who
    watched the aforementioned movie, `Finding Nemo (2003)`. Rotten Tomatoes classifies
    `Finding Nemo (2003)` under the *Animation*, *Comedy,* and *Kids* genres. We can
    encode this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: To make a movie recommendation based on genre, all we have to do is find the
    ones that are the most similar, that is, the movies that share the most genres
    with our `Finding Nemo (2003)`.
  prefs: []
  type: TYPE_NORMAL
- en: There is a multitude of algorithms for computing the similarity (or on the contrary,
    the distance) between items—in our case, as we're dealing with binary values only,
    the Hamming distance looks like a good choice. The Hamming distance is a number
    that's used to denote the difference between two binary strings. This distance
    is calculated by comparing two binary values and taking into account the number
    of positions at which the corresponding bits are different. We'll compare each
    bit in succession and record either `1` or `0`, depending on whether or not the
    bits are different or the same. If they are the same, we record a `0`. For different
    bits, we record a `1`. Then, we add all the 1s and 0s in the record to obtain
    the Hamming distance.
  prefs: []
  type: TYPE_NORMAL
- en: 'A function for calculating the Hamming distance is available in the `Distances`
    package. This is a third-party Julia package that provides access to a multitude
    of functions for evaluating distances between vectors, including Euclidian, Jaccard,
    Hemming, Cosine, and many others. All we need to do to access this treasure of
    functionality is run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to iterate over our movies matrix and compute the Hamming distance
    between each movie and `Finding Nemo (2003)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the end result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Since we're computing distances, the most similar movies are the ones within
    the shortest distance. So, according to our recommender, a user who watched `Finding
    Nemo (2003)` should next watch `Finding Dory (2016)` or `Zootopia (2016)` (distance
    `2`) and when done, should move on to `The Jungle Book (2016)` and `Moana (2016)` (both
    at a distance of `3`). If you haven't watched all of these recommended movies
    already, I can tell you that the suggestions are quite appropriate. Similarly,
    the least recommended movie is `Arrival (2016)`, which although is an excellent
    science fiction drama, has nothing in common with cute Nemo and forgetful Dory.
  prefs: []
  type: TYPE_NORMAL
- en: Beginning with association-based recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although content-based recommender systems can produce great results, they do
    have limitations. For starters, they can't be used to recommend new items. Based
    on my initial `Finding Nemo (2003)` ranking alone, I would be stuck getting suggestions
    for animated movies alone and I'd never get the chance to hear about any new documentaries
    or car or cooking shows that I sometimes enjoy.
  prefs: []
  type: TYPE_NORMAL
- en: Also, it works best for categories of items that can be purchased repeatedly,
    like books, apps, songs, or movies, to name a few. But if I'm on Amazon and purchase
    a new dishwasher from the *Home and kitchen* category, it doesn't make a lot of
    sense to get recommendations about products within the same group, such as a fridge
    or a washing machine, as chances are I'm not replacing all of the expensive kitchen
    appliances at the same time. However, I will most likely need the corresponding
    joints and taps and pipes and whatever else is needed to install the dishwasher,
    together with the recommended detergent and maybe other accessories. Since the
    e-commerce platform is selling all of these products as well, it's beneficial
    to order them together and receive them at the same time, saving on transport
    too.
  prefs: []
  type: TYPE_NORMAL
- en: These bundles of products can form the foundation of a RS based on product association.
    These types of recommendations are quite common, and are usually presented as
    *frequently bought together* on e-commerce platforms. For physical stores, this
    type of data analysis—also known as **market basket analysis**—is used to place
    products that are purchased together in close physical proximity. Think, for example,
    about pasta being side by side with sauces, or shampoo with conditioners.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most popular algorithms used for association based recommendations
    is the `Apriori` algorithm. It is used to identify items that frequently occur
    together in different scenarios (shopping baskets, web browsing, adverse drug
    reactions, and so on). The `Apriori` algorithm helps us identify correlations
    through data mining by employing association rules.
  prefs: []
  type: TYPE_NORMAL
- en: Space constraints don't allow us to get into the details of building such as
    system, but if you would like to dive deeper into this topic, there are many free
    resources to get you started. I recommend beginning with *Movie Recommendation
    with Market Basket Analysis* ([https://rpubs.com/vitidN/203264](https://rpubs.com/vitidN/203264))
    as it builds a movie recommender that's very similar to ours.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Collaborative filtering** (**CF**) is another very successful and widely
    used recommendation algorithm. It is based on the idea that people with similar
    preferences will have similar interests. If two customers, let''s call them Annie
    and Bob, give `Finding Nemo (2003)` a good rating and Annie also highly ranks
    `Finding Dory (2016)`, then chances are that Bob will also like `Finding Dory
    (2016)`. Of course, comparing two users and two products may not seem like much, but
    applied to very large datasets representing both users and products, the recommendations
    become highly relevant.'
  prefs: []
  type: TYPE_NORMAL
- en: If you're confused as to what the difference between CF and content filtering
    is, since both can be used to infer `Finding Dory (2016)` based on `Finding Nemo
    (2003)`, the key point is that CF does not care about item attributes. Indeed,
    when using CF, we don't need the movie genre information, nor any other tags.
    The algorithm is not concerned with the classification of the items. It pretty
    much states that if, for whatever reason, the items were ranked highly by a subset
    of users, then other items that are highly ranked by the same subset of users
    will be relevant for our target user, hence making for a good recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding user-item CF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This was the basic idea, and with the advent of big data, the CF technique has
    become quite powerful. As it's been applied to different business needs and usage
    scenarios, the algorithm was refined to better address the problems it was attempting
    to solve. As a consequence, a few other approaches emerged, and the original one
    became known as **user-item CF**.
  prefs: []
  type: TYPE_NORMAL
- en: It's gotten this name because it takes as its input user data (user preferences,
    rankings) and outputs item data (item recommendations). It's also known as **user-based
    CF**.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see it illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b242774a-f1e2-4b9c-8641-6c93227d1fc8.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows that **Annie** likes **A**, **B**, and **E**, while
    **Bob** likes **A**, **B**, **C**, and **D**.
  prefs: []
  type: TYPE_NORMAL
- en: The `recommender` algorithm established that, between **Annie** and **Bob**,
    there's a high degree of similarity because they both like items **A** and **B**.
    Next, it will assume that **Annie** will also like other items from Bob's list
    of preferences that she hasn't discovered yet, and the reverse for **Bob**—he'll
    like items from Annie's list that he hasn't discovered yet. Thus, since Annie
    also likes item E, we can recommend it to **Bob**, and since Bob's very fond of
    **C** and **D** and Annie has no knowledge about these yet, we can confidently
    suggest that she checks them out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take another very simple example, also from the realm of movie recommendations.
    Sticking to our previous list of top 10 movies for the year 2016 on Rotten Tomatoes,
    this time, let''s ignore the classification by genre and imagine that we have
    user ratings data instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/855a1095-b43b-486b-9f0a-06ae20a0db88.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows a table of movie titles and users and their corresponding
    ratings. As it happens in real life, not all of the users have rated all of the
    moves—the absence of a rating is indicated by an empty cell.
  prefs: []
  type: TYPE_NORMAL
- en: You will notice in the preceding screenshot that by a strange twist of faith,
    the user's names provide a hint as to what kind of movies they prefer. Acton is
    very much into action movies, while Annie loves animations. Comey's favorites
    are the comedies, while Dean enjoys good dramas. Kit's highest rankings went to
    kids movies, Missie loves mystery movies, while musical's are Musk reasons for
    binge watching. Finally, Sam is a science fiction fan.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is provided in this chapter's files under the name `top_10_movies_user_rankings.csv`.
    Please download it from [https://github.com/PacktPublishing/Julia-Programming-Projects/blob/master/Chapter06/top_10_movies_user_rankings.csv](https://github.com/PacktPublishing/Julia-Programming-Projects/blob/master/Chapter06/top_10_movies_user_rankings.csv)
    and place it somewhere on your hard drive where you can easily access it from
    Julia's REPL.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can load it into memory using the same `readdlm` Julia function as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This file uses the `;` char as the column separator, so we need to pass that
    into the `readdlm` function call. Remember that in Julia, `";"` is different from
    `':'`. The first is a `String` of length one, while the second is a `Char`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the result of the `.csv` file being read—a matrix containing movies
    on rows and people on columns, with each person''s rating at the corresponding
    intersection between rows and columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f400846a-c6c9-4597-b0c1-cabaf04cd836.png)'
  prefs: []
  type: TYPE_IMG
- en: It works, but the data doesn't look too good. As usually happens with data in
    real life, we don't always have ratings from all the users. The `missing` values
    were imported as empty strings `""`, and the headers were interpreted as entries
    in the matrix. Julia's `readdlm` is great for quick data imports, but for more
    advanced data wrangling, we can benefit considerably from using Julia's powerful
    `DataFrames` package.
  prefs: []
  type: TYPE_NORMAL
- en: '`DataFrames` is a third-party Julia package that exposes a rich set of functions
    for manipulating tabular data. You should remember it from our introduction in
    [Chapter 1](90a7f09d-d63b-45d7-baf5-576470d0910f.xhtml),* Getting Started with
    Julia Programming*—if not, please take a few minutes to review that part. The
    rest of our discussion will assume that you have a basic understanding of `DataFrames`
    so that we can now focus on the more advanced features and use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If, for some reason, you no longer have the `DataFrames` package, `pkg> add
    DataFrames` is all we need. While we''re at it, let''s also install the `CSV`
    package—it''s a powerful utility library for handling delimited text files. We
    can add both in one step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll use `CSV` to load the comma-separated file and produce a `DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `DataFrame` should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/073d60f6-3d89-4c40-b5c9-94f99efdca91.png)'
  prefs: []
  type: TYPE_IMG
- en: We get a beautifully rendered tabular data structure, with the missing ratings
    correctly represented as `missing` data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get a quick summary of our data by using the `describe` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7c3d11a-25f8-43f4-a6b2-a9ea4484c01f.png)'
  prefs: []
  type: TYPE_IMG
- en: Multiple columns have `missing` values. A `missing` value represents a value
    that is absent in the dataset. It is defined in the `Missings` package ([https://github.com/JuliaData/Missings.jl](https://github.com/JuliaData/Missings.jl)),
    and it's the singleton instance of the `Missing` type. If you're familiar with `NULL`
    in SQL or `NA` in R, `missing` is the same in Julia.
  prefs: []
  type: TYPE_NORMAL
- en: Missing values are problematic when working with real-life datasets as they
    can affect the accuracy of the computations. For this reason, common operations
    that involve `missing` values usually propagate `missing`. For example, `1 + missing`
    and `cos(missing)` will both return `missing`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check if a value is missing by using the `ismissing` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In many cases, `missing` values will have to be skipped or replaced with a valid
    value. What value is appropriate for replacing `missing` will depend from case
    to case, as dictated by the business logic. In our case, for the missing ratings,
    we can use the value `0`. By convention, we can agree that valid ratings range
    from `1` to `10`, and that a rating of `0` corresponds to no rating at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to do the replacement is to iterate over each column except `Movie
    title` and then over each cell, and if the corresponding value is missing, replace
    it with `0`. Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re all done—our data is now clean, with zeroes replacing all the previously
    missing values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2e5355cc-0f4a-4ab9-adf0-4ae0f421eb30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It would help if you saved this clean version of our data as a *Tab* separated
    file, for future reference, with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our ratings loaded into Julia, the next step is to compute
    the similarity between the various users. The Hamming distance, the formula that
    we used when computing content based recommendations, would not be a good choice
    for numerical data. A much better alternative is Pearson's correlation coefficient.
    This coefficient, also known as ***Pearson's r* or bivariate correlation**, is
    a measure of the linear correlation between two variables. It has a value between
    `+1` and `−1`. A value of `1` indicates total positive linear correlation (both
    values increase together), while `-1` represents total negative linear correlation
    (one value decreases while the other increases). The value `0` means that there's
    no linear correlation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few examples of scatter diagrams with different visualizations of
    the correlation coefficient (By Kiatdd—Own work, CC BY-SA 3.0, [https://commons.wikimedia.org/w/index.php?curid=37108966](https://commons.wikimedia.org/w/index.php?curid=37108966)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c9c0a1a-64df-47c0-92e8-6bf2d380b65d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how we would calculate the similarity between `Acton` and `Annie`,
    based on the movie ratings they provided. Let''s make things simpler and focus
    strictly on their data by extracting the `Movie title` column, together with the
    `Acton` and `Annie` columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c61080ab-a58f-4399-89de-7547b64085bd.png)'
  prefs: []
  type: TYPE_IMG
- en: This returns another `DataFrame`, referenced as `acton_and_annie`, which corresponds
    to the columns one to three of the `movies` `DataFrame`, representing Acton's
    and Annie's ratings for each of the movies.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is good, but we''re only interested in the movies that were rated by both
    users. If you remember from our discussion of `DataFrame` in [Chapter 1](90a7f09d-d63b-45d7-baf5-576470d0910f.xhtml), *Getting
    Started with Julia Programming, *we can select rows (and columns) by passing a
    Boolean value—`true` to select it, `false` to skip it. We can use this in combination
    with the dot syntax for element-wise operations to check if the values in the
    `:Acton` and `:Annie` columns are greater than `0`. The code will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we apply the bitwise `&` operator, which is also element-wise, to the
    resulting arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4914a5e5-29d2-4d42-9de2-050e2270d142.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's plot the ratings. Julia comes with quite a few options for plotting. We
    saw some in [Chapter 1](90a7f09d-d63b-45d7-baf5-576470d0910f.xhtml), *Getting
    Started with Julia Programming*, and we'll look at plotting in more detail in
    [Chapter 9](11df7c94-2e9a-4cc5-aba1-b9c9c93800a0.xhtml), *Working with Dates,
    Time, and Time Series*. For now, we'll use the appropriately named `Plots` library
    to quickly visualize our data.
  prefs: []
  type: TYPE_NORMAL
- en: '`Plots` is designed as a higher-level interface to other plotting libraries
    (named *backends* in `Plots` language), such as `GR` or `PyPlot`. It basically
    unifies multiple lower-level plotting packages (backends) under a common API.'
  prefs: []
  type: TYPE_NORMAL
- en: As always, start with `pkg> add Plots` and continue with `using Plots`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re now ready to generate the visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/2d60606a-81f7-4823-b621-b1df752e6245.png)'
  prefs: []
  type: TYPE_IMG
- en: By the looks of it, there is a good correlation between the user's movie preferences.
    But we can do even better.
  prefs: []
  type: TYPE_NORMAL
- en: Julia's ecosystem provides access to yet another powerful package that combines
    both plotting and statistical features. It's called `StatPlots` and actually works
    on top of the `Plots` package, providing statistical plotting recipes for `Plots`.
    It also supports `DataFrame` visualizations out of the box, so it's a perfect
    match for our needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add it with `pkg> add StatPlots` and bring it into scope (`using StatPlots`).
    We can now use the `@df` macro that''s exposed by `StatPlots` to generate a scatter
    plot of our data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will produce the following visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bce24b5e-1b1e-4b77-8f99-5269aeb0c174.png)'
  prefs: []
  type: TYPE_IMG
- en: This new plot shows the correlation between the movies, despite the outlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compute the Pearson correlation between Acton''s and Annie''s ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Pretty much any value over `0.6` indicates a good similarity, so it looks like
    we're onto something.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can recommend to Annie some of Acton''s favorites that she hasn''t
    seen, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll get a `DataFrame` with four rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ef28b302-ae0d-4be7-9449-b9460bd13885.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, there''s a small glitch. We assumed that all the ratings indicate
    a strong preference, but in this case, many of Acton''s ratings are rather an
    indication of a dislike. With the exception of `Captain America: Civil War (2016)`,
    all the possible recommendations have bad ratings. Luckily, that is easy to fix—we
    just need to recommend movies that have a high rating, let''s say, of at least
    `7`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This leaves us with only one movie, `Captain America: Civil War (2016)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9266d9fe-9059-42d3-981d-07ec37e7fe1d.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we understand the logic of user-based recommender systems, let's put
    all of these steps together to create a simple recommender script.
  prefs: []
  type: TYPE_NORMAL
- en: We'll analyze our users' rating matrix in a script that will take advantage
    of all the available data to generate recommendations for all of our users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a possible implementation—please create a u`ser_based_movie_recommendations.jl`
    file with the following code. Do make sure that the `top_10_movies_user_rankings.tsv`
    file is in the same folder (or update the path in the code to match your location).
    Here''s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `user_similarity` function computes the similarity of our target user (the
    one passed into the function as the argument) with all the other users and returns
    a dictionary of the form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `dict` represents Annie's similarity with all the other users.
  prefs: []
  type: TYPE_NORMAL
- en: We use the similarities in the recommendations function to pick the relevant
    users and make recommendations based on their favorite movies, which were not
    already rated by our target user.
  prefs: []
  type: TYPE_NORMAL
- en: I've also added a little twist to make the recommendations more relevant—a weight
    factor. This is computed by multiplying the user's rating with the user's similarity.
    If, say, `Comey` gives a movie an 8 and is 100% similar to `Missie` (correlation
    coefficient equals 1), the weight of the recommendation will also be *8 (8 * 1)*.
    But if Comey is only 50% similar to Musk (0.5 correlation coefficient), then the
    weight of the recommendation (corresponding to the estimated rating) will be just
    *4 (8 * 0.5)*.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the file, we bootstrap the whole process by looping through an
    array of all the users, and we produce and print the movie recommendations for
    each of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this will output movie recommendations, together with their weights
    for each of our users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The data looks quite good, considering that this is a toy example. A production
    quality recommender system should be based on millions of such ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if you look closely, you might notice that something''s not quite
    right—the `Recommendations for Kit`. Kit likes kids movies—light-hearted animated
    comedies. Our system recommends him, with quite a lot of weight, a lot of dramas!
    What gives? If we look at the similarity data for Kit, we''ll see that he''s very
    well correlated with Dean and Dean likes drama. That might sound weird, but it''s
    actually correct if we check the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/55770a5d-31dc-478e-8e62-acd08f85223d.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice how the only movies they both watched are `The Jungle Book (2016)` and
    `Finding Dory (2016)`, and how the ratings are correlated since both give higher
    ratings to `Finding Dory (2016)`. Therefore, there is a strong positive correlation
    between Dean and Kit. But what our algorithm doesn't take into account is that
    even if Dean likes `Finding Dory (2016)` more than `The Jungle Book (2016)`, he
    still doesn't really like either, as indicated by the low ratings of `4` and `2`,
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is quite simple, though—we just need to remove ratings that don''t
    indicate a strong positive preference. Again, we can use a rating equal to or
    larger than `7` to count as a like. So, in the `user_similarity` function, please
    look for the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace `ratings[user] .> 0` with `ratings[user] .> 7` so that the whole line
    now reads as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: What this does is now compute similarity only based on favorites. As a result,
    `Kit` is no longer similar to `Dean` (the correlation coefficient is `0`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another consequence of the fact that our recommendations are more targeted
    is that we no longer have recommendations for all the users—but this is, again,
    caused by the fact that we''re working with a very small example dataset. Here
    are the final recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We only have suggestions for Acton, Comey, and Dean, but they are now much more
    accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Item-item CF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: User-based CF works quite well and is widely used in production in the wild,
    but it does have a few considerable downsides. First, it's difficult to get enough
    preference information from users, leaving many of them without a solid base for
    relevant recommendations. Second, as the platform and the underlying business
    grows, the number of users will grow much faster than the number of items. Netflix,
    for example, to keep the discussion in the familiar area of movies, grows its
    user base massively by expanding into new countries, while the production of movies
    stays pretty much the same on a yearly basis. Finally, the user's data does change
    quite a lot, so the rating matrix would have to be updated often, which is a resource-intensive
    and time-consuming process.
  prefs: []
  type: TYPE_NORMAL
- en: These problems became painfully obvious at Amazon, some 10 years ago. They realized
    that since the number of products grows at a much slower rate than the number
    of users, instead of computing user similarity, they could compute item similarity
    and make recommendations stemming from the list of related items.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram should help you understand the difference between item-based
    (or item-item) and user-based (or user-item) CF:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cfd88d93-1653-4b45-aa1e-324b48177322.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows that **Annie** purchased **A**, **B**, and **E**,
    **Bob** purchased **A**, **B**, and **D**, and **Charley** purchased **A** and
    **C**. The purchasing behavior of **Annie** and **Bob** will indicate a correlation
    between **A** and **B**, and since **Charley** already purchased **A** but not
    **B**, we can recommend **Charley** to take a look at **B**.
  prefs: []
  type: TYPE_NORMAL
- en: From an implementation perspective, there are similarities to user-item CF,
    but it is more involved as it includes an extra layer of analysis. Let's try this
    out with our imaginary movie rankings. Let's create a new file called `item_based_recommendations.jl`
    to host our code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the complete implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: To keep the code simpler, we're only generating recommendations for a single
    movie—but it should be relatively simple to extend it to come up with recommendations
    for each movie in our list (you can try this as an exercise). We'll only suggest
    similar movies to the users that have watched `Finding Dory (2016)`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take it apart and see how the script works.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, I've added some `println` and `@show` calls that output extra
    debug information—they're commented out, but feel free to uncomment them when
    running the file to help you better understand what each section does and what
    the workflow of the code is.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our data matrix is more difficult now. We need to transpose our initial
    dataset, that is, rotate it. The `setup_data` function is dedicated to this task
    alone—loading the data file, transposing the matrix, and setting up the data into
    a `DataFrame`. It's a proper **extract, transform, load** (**ETL**) process in
    just a few lines of code, which is pretty cool! Let's look at this closely—it's
    quite a common day-to-day data science task.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first line of the function, we load the data into a Julia matrix. The
    `readdlm` function is not as powerful as `DataFrames`, so it has no knowledge
    of headers, gobbling everything into an `Array`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll end up with the following matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21550340-67d6-4f77-afaf-7dfd21684eb9.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the headings are mixed with the actual data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to transpose the matrix. Unfortunately, transposing doesn''t work
    smoothly for all kinds of matrices in Julia yet, and the recommended way is to
    do this via `permutedims`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98126d1d-de90-4aed-a074-3d811562d948.png)'
  prefs: []
  type: TYPE_IMG
- en: We're getting closer!
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we convert it into a `DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d83bebec-1537-4045-af08-2594af140382.png)'
  prefs: []
  type: TYPE_IMG
- en: If you run the previous code yourself, you might notice that the REPL will omit
    some of the `DataFrame` columns, since the output is too wide. To get Julia to
    display all the columns, like in this snippet, you can use the `showall` function,
    as in `showall(movies)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It looks good, but we need to give the columns proper names, using the data
    that is now on the first row. Let''s extract all the columns names into a `Vector`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use it to name the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4f684580-a0ec-4773-9c5c-f1b37e44829c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Our `DataFrame` looks better already. The only things left to do are to remove
    the extra row with the headers and change the `Movie title` header to `User`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2db2e1c8-55e2-46f4-aa4d-a354f54c782a.png)'
  prefs: []
  type: TYPE_IMG
- en: All done—our ETL process is complete!
  prefs: []
  type: TYPE_NORMAL
- en: 'We start our recommender by invoking the `recommendations` function, passing
    in the name of the movie, `Finding Dory (2016)`, as a `Symbol`. The first thing
    this function does is invoke the `movie_similarity` function, which computes which
    other movies are similar to `Finding Dory (2016)` based on the users'' ratings.
    For our target movie, we''ll get the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We can see here that there's an almost perfect negative correlation with `La
    La Land (2016)` (so users that like `La La Land (2016)` do not like `Finding Dory
    (2016)`). There is also a very strong positive correlation with `The Jungle Book
    (2016)`, `Zootopia (2016)`, and `Moana (2016)`, which makes sense, since they're
    all animations.
  prefs: []
  type: TYPE_NORMAL
- en: Here is where the logic gets a bit more complicated. Now, we have a list of
    movies that are similar to `Finding Dory (2016)`. To make recommendations, we
    want to look at all the users that have watched `Finding Dory (2016)` (and gave
    it a good enough rating), and suggest similar movies that they haven't watched
    yet (movies that have a rating of 0). This time, we'll be using a minimum rating
    of 5 instead of the previous 7, since given our very limited dataset, 7 would
    be too restrictive and would yield no recommendations. We'll compute the weight
    of the suggestions as the product between the user's rating of `Finding Dory (2016)` and
    the correlation coefficient between `Finding Dory (2016)` and the recommended
    movie. Makes sense? Let's see it in action!
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run the script, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The only user that would be (kind of) interested in watching movies similar
    to `Finding Dory (2016)` in our small dataset is `Comey`—but the recommendations
    won't be great. The algorithm estimates a weight (and thus, a rating) of `4.38693`
    for `The Jungle Book (2016)` and `4.66799` for `Moana (2016)`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This concludes the first part of our journey into recommender systems. They
    are an extremely important part of today's online business models and their usefulness
    is ever-growing, in direct relation to the exponential growth of data generated
    by our connected software and hardware. Recommender systems are a very efficient
    solution to the information overload problem—or rather, an information filter
    problem. Recommenders provide a level of filtering that's appropriate for each
    user, turning information, yet again, into a vector of customer empowerment.
  prefs: []
  type: TYPE_NORMAL
- en: Although it's critical to understand how the various types of recommender systems
    work, in order to be able to choose the right algorithm for the types of problems
    you'll solve in your work as a data scientist, implementing production-grade systems
    by hand is not something most people do. As with almost everything in the realm
    of software development, it's best to use stable, powerful, and mature existing
    libraries when they're available.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll learn how to build a more powerful recommender system
    using existing Julia libraries. We'll generate recommendations for a dating site,
    taking advantage of publicly available and anonymized dating data. In the process,
    we'll learn about yet another type of recommender system, called model-based (as
    a side note, all of the algorithms that were discussed in this chapter were memory-based,
    but don't worry—I'll explain everything in a minute).
  prefs: []
  type: TYPE_NORMAL
