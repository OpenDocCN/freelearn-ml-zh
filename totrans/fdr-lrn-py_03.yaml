- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Workings of the Federated Learning System
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦学习系统的工作原理
- en: This chapter will provide an overview of the architecture, procedure flow, sequence
    of messages, and basics of model aggregation of the **federated learning** (**FL**)
    system. As discussed in [*Chapter 2*](B18369_02.xhtml#_idTextAnchor037), *What
    Is Federated Learning?*, the conceptual basics of the FL framework are quite simple
    and easy to understand. However, the real implementation of the FL framework needs
    to come with a good understanding of both AI and distributed systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将概述联邦学习系统（**FL**）的架构、流程流程、消息序列和模型聚合的基本原理。如[*第二章*](B18369_02.xhtml#_idTextAnchor037)“什么是联邦学习？”中讨论的，FL框架的概念基础非常简单且易于理解。然而，FL框架的真正实现需要具备对AI和分布式系统的良好理解。
- en: The content of this chapter is based on the most standard foundation of FL systems,
    which is used in hands-on exercises later in the book. First, we will introduce
    the building blocks of FL systems, such as an aggregator with an FL server, an
    agent with an FL client, a database server, and communication between these components.
    The architecture introduced in this chapter is designed in a decoupled way so
    that further enhancement to the system will be relatively easier than with an
    FL system that contains everything on one machine. Then, an explanation of the
    flow of the operation of FL from initialization to aggregation will follow.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容基于联邦学习系统最标准的基石，这些基石将在本书后面的实际练习中使用。首先，我们将介绍联邦学习系统的构建块，例如带有联邦学习服务器的聚合器、带有联邦学习客户端的代理、数据库服务器以及这些组件之间的通信。本章介绍的架构以解耦的方式设计，以便对系统的进一步增强将比包含所有内容在一个机器上的联邦学习系统更容易。然后，我们将解释从初始化到聚合的联邦学习操作流程。
- en: Finally, we will examine the way an FL system is scaled with a horizontal design
    of decentralized FL setups.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将探讨如何通过横向设计去中心化的联邦学习设置来扩展联邦学习系统的规模。
- en: 'This chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: FL system architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联邦学习系统架构
- en: Understanding the FL system flow – from initialization to continuous operation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解联邦学习系统流程——从初始化到持续运行
- en: Basics of model aggregation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型聚合的基本原理
- en: Furthering scalability with horizontal design
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过横向设计进一步扩展可伸缩性
- en: FL system architecture
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦学习系统架构
- en: 'FL systems are distributed systems that are dispersed into servers and distributed
    clients. Here, we will define a representative architecture of an FL system with
    the following components: an aggregator with an FL server, an agent with an FL
    client, and a database:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习系统是分散到服务器和分布式客户端的分布式系统。在这里，我们将定义一个具有以下组件的联邦学习系统的代表性架构：带有联邦学习服务器的聚合器、带有联邦学习客户端的代理和数据库：
- en: '**Cluster aggregator** (or **aggregator**): A system with an FL server that
    collects and aggregates **machine learning** (**ML**) models that are trained
    at multiple distributed agents (defined shortly) and creates global ML models
    that are sent back to the agents. This system serves as a *cluster aggregator*,
    or more simply, an *aggregator* of FL systems.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群聚合器**（或**聚合器**）：一个带有联邦学习服务器的系统，它收集和聚合在多个分布式代理（稍后定义）上训练的机器学习模型，并创建全局机器学习模型，这些模型被发送回代理。该系统作为*集群聚合器*，或者更简单地说，作为*联邦学习系统聚合器*。'
- en: '**Distributed agent** (or **agent**): A distributed learning environment with
    an FL client such as a local edge device, mobile application, tablet, or any distributed
    cloud environment where ML models are trained in a distributed manner and sent
    to an aggregator. The agent can be connected to an FL server of the aggregator
    through the FL client-side communications module. The FL client-side codes contain
    a collection of libraries that can be integrated into the local ML application,
    which is designed and implemented by individual ML engineers and data scientists.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式代理**（或**代理**）：一个带有联邦学习客户端（如本地边缘设备、移动应用、平板电脑或任何分布式云环境）的分布式学习环境，在这些环境中以分布式方式训练机器学习模型并将其发送到聚合器。代理可以通过聚合器的联邦学习客户端通信模块连接到聚合器的联邦学习服务器。联邦学习客户端端的代码包含一系列库，这些库可以集成到由个别机器学习工程师和数据科学家设计和实现的本地机器学习应用中。'
- en: '**Database server** (or **database**): A database and its server to store the
    data related to the aggregators, agents, and global and local ML models and their
    performance metrics. The database server handles the incoming queries from the
    aggregators and sends the necessary data back to the aggregators. Agents do not
    have to be connected to the database server directly for the simplicity of the
    FL system design.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库服务器**（或**数据库**）：用于存储与聚合器、代理、全局和本地机器学习模型及其性能指标相关的数据的数据库及其服务器。数据库服务器处理来自聚合器的查询，并将必要的数据发送回聚合器。为了简化联邦学习系统设计，代理不需要直接连接到数据库服务器。'
- en: '*Figure 3.1* shows the typical overall architecture consisting of a single
    cluster aggregator and a database server, as well as multiple distributed agents:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.1*展示了典型的整体架构，包括单个集群聚合器和数据库服务器，以及多个分布式代理：'
- en: '![Figure 3.1 – Overall architecture of an FL system'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.1 – 联邦学习系统的整体架构'
- en: '](img/B18369_03_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_03_01.jpg](img/B18369_03_01.jpg)'
- en: Figure 3.1 – Overall architecture of an FL system
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 联邦学习系统的整体架构
- en: One advantage of the FL system’s architecture is that users do not have to send
    private raw data to the server, especially that owned by a third party. Instead,
    they only have to send locally trained models to the aggregator. The locally trained
    models can be in a variety of formats such as the weights of the entire ML models,
    the changes of weights (gradients), or even a subset of them. Another advantage
    includes reducing the communication load because the users only have to exchange
    models that are usually much lighter than raw data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习系统架构的一个优点是用户不需要将私有原始数据发送到服务器，尤其是第三方拥有的数据。相反，他们只需将本地训练的模型发送给聚合器。本地训练的模型可以有多种格式，例如整个机器学习模型的权重、权重的变化（梯度），甚至它们的子集。另一个优点是减少通信负载，因为用户只需交换通常比原始数据轻得多的模型。
- en: Cluster aggregators
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚类聚合器
- en: A cluster aggregator consists of an FL server module, FL state manager module,
    and model aggregation module, as in *Figure 3.1*. We just call a cluster aggregator
    with an FL server an aggregator. While these modules are the foundation of the
    aggregator, advanced modules can be added to ensure further security and flexibility
    of the aggregation of ML models. Some of the advanced modules are not implemented
    in the `simple-fl` GitHub repository provided with this book with exercises because
    the main purpose of this book is to understand the basic structure and system
    flow of the FL system. In the aggregator system, the following modules related
    to the FL server, the state manager of FL, and model aggregation are the keys
    to implementing the aggregator-side functionalities.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 集群聚合器由联邦学习服务器模块、联邦学习状态管理模块和模型聚合模块组成，如*图3.1*所示。我们只称带有联邦学习服务器的集群聚合器为聚合器。虽然这些模块是聚合器的基础，但可以添加高级模块以确保进一步的安全性和灵活性。由于本书的主要目的是理解联邦学习系统的基本结构和系统流程，因此本书提供的`simple-fl`
    GitHub仓库中未实现一些高级模块。在聚合器系统中，与联邦学习服务器、联邦学习状态管理和模型聚合相关的以下模块是实现聚合器端功能的关键。
- en: '**FL server module**: There are three primary functionalities for the FL server
    module, which include the communication handler, system configuration handler,
    and model synthesis routine:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**联邦学习服务器模块**：联邦学习服务器模块有三个主要功能，包括通信处理程序、系统配置处理程序和模型合成例程：'
- en: '**Communication handler**: Serves as a module of the aggregator that supports
    *communications with agents and the database*. Usually, this module accepts polling
    messages from agents and sends responses back to them. The types of messages they
    receive include the registration of agents themselves with secure credentials
    and authentication mechanisms, the initialization of the ML model that serves
    as an *initial model* for the future aggregation process, confirmation about whether
    or not agents participate in a round, and local ML models that are retrained at
    distributed agents such as mobile devices and local edge machines. The communication
    handler can also query the database server in order to access the system data
    and ML models in the database, as well as push and store this data and those models
    once the aggregator receives or creates new models. This module can utilize HTTP,
    WebSocket, or any other communication framework for its implementation.'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通信处理器**：作为聚合器的一个模块，支持与代理和数据库的*通信*。通常，此模块接受来自代理的轮询消息并向它们发送响应。他们接收的消息类型包括使用安全凭证和认证机制进行代理注册、初始化作为未来聚合过程*初始模型*的ML模型、确认代理是否参与某一轮次以及重新训练于分布式代理（如移动设备和本地边缘机器）的本地ML模型。通信处理器还可以查询数据库服务器，以访问系统数据以及数据库中的ML模型，并在聚合器接收或创建新模型后推送和存储这些数据和模型。此模块可以使用HTTP、WebSocket或任何其他通信框架来实现其实现。'
- en: '**System configuration handler**: Deals with the *registration of agents* and
    tracking the connected agents and their statuses. The aggregator needs to be aware
    of the connections and registration statuses of the agents. If the agents are
    registered with an established authentication mechanism, they will accept the
    messages and process them accordingly. Otherwise, this module will go through
    the authentication process, such as validating the token sent from the agent,
    so that next time this agent is connected to the FL server, the system will recognize
    the agent properly.'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统配置处理器**：处理代理的*注册*和跟踪连接的代理及其状态。聚合器需要了解代理的连接和注册状态。如果代理使用已建立的认证机制进行注册，它们将接受消息并相应地处理它们。否则，此模块将执行认证过程，例如验证从代理发送的令牌，以便下次此代理连接到FL服务器时，系统能够正确识别该代理。'
- en: '**Model synthesis routine**: Supports checking the collection status of the
    local ML models and aggregating them once the collection criteria are satisfied.
    Collection criteria include the number of local models collected by the connected
    agents. For example, aggregation can happen when 80% of the connected agents send
    the trained local models to the aggregator. One of the design patterns to do so
    is to periodically check the number of ML models uploaded by the agents, which
    keep running while the FL server is up and running. The model synthesis routine
    will access the database or local buffer periodically to check the status of the
    local model collection and aggregate those models, to produce the global model
    that will be stored in the database server and sent back to the agents.'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型合成例程**：支持检查本地ML模型的收集状态，并在满足收集标准后进行聚合。收集标准包括连接的代理收集的本地模型数量。例如，当80%的连接代理将训练好的本地模型发送到聚合器时，就会发生聚合。实现这一目标的设计模式之一是定期检查代理上传的ML模型数量，这些操作在FL服务器运行时持续进行。模型合成例程将定期访问数据库或本地缓冲区，以检查本地模型收集的状态并聚合这些模型，以生成将存储在数据库服务器中并发送回代理的全局模型。'
- en: '**FL state manager**: A state manager keeps track of the state information
    of an aggregator and connected agents. It stores volatile information for an aggregator,
    such as local and global models delivered by agents, cluster models pulled from
    the database, FL round information, or agents connected to the aggregator. The
    buffered local models are used by the model aggregation module to generate a global
    model that is sent back to each active agent connected to the aggregator.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FL状态管理器**：状态管理器跟踪聚合器和连接的代理的状态信息。它存储聚合器的易失性信息，例如代理提供的本地和全局模型、从数据库拉取的集群模型、FL轮次信息或连接到聚合器的代理。缓冲的本地模型由模型聚合模块使用，以生成发送回连接到聚合器的每个活动代理的全局模型。'
- en: '**Model aggregation module**: The model aggregation module is a collection
    of the model aggregation algorithms introduced in the *Basics of model aggregation*
    section in this chapter and [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176), *Model
    Aggregation*, in further depth. The most typical aggregation algorithm is *federated
    averaging*, which averages the weights of the collected ML models, considering
    the number of samples that each model has used for its local training.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型聚合模块**：模型聚合模块是本章“模型聚合基础”部分和[第7章](B18369_07.xhtml#_idTextAnchor176)“模型聚合”中介绍的模型聚合算法的集合。最典型的聚合算法是*联邦平均*，它平均收集到的ML模型的权重，考虑到每个模型用于其本地训练的样本数量。'
- en: Distributed agents
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式代理
- en: 'A distributed agent consists of an FL client module that includes the communication
    handler and client libraries as well as local ML applications connected to the
    FL system through the FL client libraries:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式代理由一个FL客户端模块组成，该模块包括通信处理程序和客户端库，以及通过FL客户端库连接到FL系统的本地ML应用程序：
- en: '**FL client module**: There are primarily four key functionalities for the
    FL client module, which include a communication handler, agent participation handler,
    model exchange routine, and client libraries:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FL客户端模块**：FL客户端模块主要有四个关键功能，包括通信处理程序、代理参与处理程序、模型交换例程和客户端库：'
- en: '**Communication handler**: Serves as a channel to communicate with the aggregator
    that is assigned to the agent. The message sent to the aggregator includes the
    registration payload of the agent itself and an initial model that will be the
    basis of aggregated models. The message also contains locally trained models together
    with the performance data of those models. This module supports both *push* and
    *polling* mechanisms and can utilize HTTP or WebSocket frameworks for its implementation.'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通信处理程序**：作为与分配给代理的聚合器通信的通道。发送给聚合器的消息包括代理本身的注册有效载荷和一个将成为聚合模型基础的初始模型。该消息还包含本地训练的模型及其性能数据。此模块支持*推送*和*轮询*机制，并可以利用HTTP或WebSocket框架来实现其实现。'
- en: '**FL participation handler**: Deals with the agent participation in the FL
    process and cycle by sending an aggregator a message including the agent information
    itself to be registered in the FL platform and initialize the FL process if needed.
    The response message will set the agent up for the continuous and ongoing FL process
    and often includes the most updated global model for the agent to utilize and
    train locally.'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FL参与处理程序**：通过向聚合器发送包含要注册在FL平台上的代理信息本身的消息来处理代理在FL过程和周期中的参与。响应消息将设置代理以进行持续和持续的FL过程，并且通常包括代理可以利用和本地训练的最新全局模型。'
- en: '**Model exchange routine**: Supports a synchronizing functionality that constantly
    checks whether a new global model is available or not. If the new global model
    is available, this module downloads the global model from the aggregator and the
    global model replaces the local model if needed. This module also checks the client
    state and sends the retrained model if the local training process is done.'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型交换例程**：支持一个同步功能，该功能不断检查是否有新的全局模型可用。如果新的全局模型可用，此模块将从聚合器下载全局模型，并在需要时用全局模型替换本地模型。此模块还会检查客户端状态，并在本地训练过程完成后发送重新训练的模型。'
- en: '**Client libraries**: Include administrative libraries and general FL client
    libraries:'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端库**：包括管理库和通用FL客户端库：'
- en: The administrative libraries are used when registering the initial model that
    will be used by other agents. Any configuration changes for FL systems can be
    also requested by administrative agents that have higher control capabilities.
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当注册其他代理将使用的初始模型时使用管理库。也可以由具有更高控制能力的行政代理请求FL系统的任何配置更改。
- en: General FL client libraries provide basic functionalities such as starting FL
    client core threads, sending local models to an aggregator, saving models in some
    specific location on the local machine, manipulating the client state, and downloading
    the global models. This book mainly talks about this general type of library.
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用FL客户端库提供基本功能，例如启动FL客户端核心线程、将本地模型发送到聚合器、在本地机器的特定位置保存模型、操作客户端状态以及下载全局模型。本书主要讨论这种通用类型的库。
- en: '**Local ML engine and data pipelines**: These parts are designed by individual
    ML engineers and scientists and can be independent of the FL client functionalities.
    This module has an ML model itself that can be put into play immediately by the
    user for potentially more accurate inference, a training and testing environment
    that can be plugged into the FL client libraries, and for the implementation of
    data pipelines. While the aforementioned module and libraries can be generalized
    and provided as **application programming interfaces** (**APIs**) or libraries
    for any ML applications, this module is unique depending on the requirements of
    AI applications to be developed.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地ML引擎和数据管道**：这些部分由个别ML工程师和科学家设计，可以独立于FL客户端功能。此模块本身有一个ML模型，用户可以立即使用它进行更准确的推理，一个可以插入FL客户端库的培训和测试环境，以及数据管道的实现。虽然上述模块和库可以通用并提供为任何ML应用程序的**应用程序编程接口**（**API**）或库，但此模块根据要开发的AI应用程序的需求是独特的。'
- en: Database servers
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库服务器
- en: 'A database server consists of a database query handler and a database, as storage.
    The database server can reside on the server side, such as on the cloud, and is
    tied closely to aggregators, while the recommended design is to separate this
    database server from aggregator servers to decouple the functionalities to enhance
    the system’s simplicity and resilience. The functionality of the database query
    handler and sample database tables are as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库服务器由数据库查询处理器和数据库组成，作为存储。数据库服务器可以位于服务器端，例如在云上，并且与聚合器紧密相连，而推荐的设计是将此数据库服务器与聚合器服务器分开，以解耦功能，增强系统的简单性和弹性。数据库查询处理器和示例数据库表的功能如下：
- en: '**Database query handler**: Accepts the incoming requests from an aggregator
    and sends the requested data and ML models back to the aggregator.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库查询处理器**：接受来自聚合器的传入请求，并将所需数据和ML模型发送回聚合器。'
- en: '**Database**: Stores all the related information to FL processes. We list some
    potential entries for the database here:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库**：存储所有与FL过程相关的信息。我们在此列出数据库的一些潜在条目：'
- en: '**Aggregator information**: This aggregator-related information includes the
    ID of the aggregator itself, the IP address and various port numbers, system registered
    and updated times, and system status. In addition, this entry can include model
    aggregation-related information, such as the round of FL and its information and
    aggregation criteria.'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合器信息**：此聚合器相关信息包括聚合器本身的ID、IP地址和各种端口号、系统注册和更新时间以及系统状态。此外，此条目还可以包括模型聚合相关信息，例如FL的轮次及其信息以及聚合标准。'
- en: '**Agent information**: This agent-related information includes the ID of the
    agent itself, the IP address and various port numbers, system registered and updated
    times, and system status. This entry can also contain the opt-in/out status that
    is used for synchronous FL (explained in the *Synchronous and asynchronous FL*
    section in this chapter) and a flag to record whether the agent has been a bad
    actor in the past (for example, involved in poisoning attacks, or very slow at
    returning results).'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理信息**：此代理相关信息包括代理本身的ID、IP地址和各种端口号、系统注册和更新时间以及系统状态。此条目还可以包含用于同步FL（在本章的*同步和异步FL*部分中解释）的opt-in/out状态，以及一个标志来记录代理是否在过去有过不良行为（例如，参与投毒攻击，或返回结果非常慢）。'
- en: '**Base model information**: Base model information is used for the registration
    of initial ML models whose architecture and information are used for the entire
    process of FL rounds.'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础模型信息**：基础模型信息用于注册初始ML模型，其架构和信息用于FL轮次的整个流程。'
- en: '**Local models**: The information of local models includes the model ID that
    is unique to individual ML models, generated time of the model, agent ID that
    uploaded the model, aggregator ID that received the model from the agent, and
    so on. Usually, the model ID is uniquely mapped to the location of the actual
    ML model file that can be stored in the database server or in some cloud storage
    services such as S3 buckets of Amazon Web Services, and so on.'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地模型**：本地模型的信息包括唯一标识个别ML模型的模型ID、模型的生成时间、上传模型的代理ID、从代理接收模型的聚合器ID等。通常，模型ID唯一映射到实际ML模型文件的存储位置，这些文件可以存储在数据库服务器或某些云存储服务中，例如亚马逊网络服务的S3存储桶等。'
- en: '**Cluster global models**: The information of the cluster global models is
    similar to what local models could record in the database including the model
    ID, aggregator ID, generated time of the model, and so on. Once the aggregated
    model is created by an aggregator, the database server will accept the global
    models and store them in the database server or any cloud storage services. Any
    global model can be requested by an aggregator.'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群全局模型**：集群全局模型的信息类似于本地模型可以在数据库中记录的信息，包括模型ID、聚合器ID、模型的生成时间等。一旦聚合器创建了一个聚合模型，数据库服务器将接受全局模型并将它们存储在数据库服务器或任何云存储服务中。任何全局模型都可以由聚合器请求。'
- en: '**Performance data**: The performance of the local and global models can be
    tracked, as metadata attached to those models. This performance data will be used
    to ensure that the aggregated model performs well enough before it is actually
    deployed to the user ML application.'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能数据**：本地和全局模型的表现可以追踪，作为附加到这些模型的元数据。这些性能数据将被用于确保在将聚合模型实际部署到用户ML应用之前，聚合模型的表现足够好。'
- en: Note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In the code sample of the `simple-fl` repository, only the database tables related
    to the local models and cluster models are covered to simplify the explanation
    of the entire FL process.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在`simple-fl`存储库的代码示例中，仅覆盖了与本地模型和集群模型相关的数据库表，以简化整个FL过程的解释。
- en: Now that the basic architecture of the FL system has been introduced, next,
    we will talk about how to enhance the FL system’s architecture if the computation
    resources are limited on the agent-side devices.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在FL系统的基本架构已经介绍完毕，接下来我们将讨论如果代理端设备计算资源有限时，如何增强FL系统的架构。
- en: Intermediate servers for low computational agent devices
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中间服务器用于低计算能力的代理设备
- en: Sometimes, the computational capability of local user devices is limited – ML
    training may be difficult in those devices, but inference or predictions can be
    made possible by just downloading the global model. In these cases, an FL platform
    may be able to set up an additional intermediate server layer, such as with smartphones,
    tablets, or edge servers. For example, in a healthcare AI application, users manage
    their health information on their smart watches, which can be transferred to their
    smart tablets or synched with laptops. In those devices, it is easy to retrain
    ML models and integrate the distributed agent functionalities.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，本地用户设备的计算能力有限 – 在这些设备上可能难以进行ML训练，但仅通过下载全局模型就可以进行推理或预测。在这些情况下，FL平台可能能够设置一个额外的中间服务器层，例如使用智能手机、平板电脑或边缘服务器。例如，在医疗AI应用中，用户可以在他们的智能手表上管理他们的健康信息，这些信息可以传输到他们的智能平板电脑或与笔记本电脑同步。在这些设备上，重新训练ML模型和集成分布式代理功能都很简单。
- en: Therefore, the system architecture needs to be modified or redesigned depending
    on the applications into which the FL system is integrated, and the concept of
    intermediate servers can be applied using distributed agents to realize FL processes.
    We do not have to modify the interactions and communication mechanisms between
    the aggregators and the intermediate servers. Just by implementing APIs between
    the user devices and the intermediate servers, FL will be possible in most use
    cases.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，系统架构需要根据FL系统集成的应用进行修改或重新设计，并且可以使用分布式代理应用中间服务器概念来实现FL过程。我们不需要修改聚合器与中间服务器之间的交互和通信机制。只需在用户设备和中间服务器之间实现API，大多数情况下就可以实现FL。
- en: '*Figure 3.2* illustrates the interaction between the aggregators, intermediate
    servers, and user devices:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.2* 展示了聚合器、中间服务器和用户设备之间的交互：'
- en: '![Figure 3.2 – An FL system with intermediate servers'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.2 – An FL system with intermediate servers](img/B18369_03_02.jpg)'
- en: '](img/B18369_03_02.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_03_02.jpg](img/B18369_03_02.jpg)'
- en: Figure 3.2 – An FL system with intermediate servers
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 带有中间服务器的FL系统
- en: Now that we have learned about the basic architecture and components of an FL
    system, let us look into how an FL system operates in the following section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了FL系统的基本架构和组件，接下来我们将探讨在下一节中FL系统是如何运行的。
- en: Understanding the FL system flow – from initialization to continuous operation
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解FL系统流程 – 从初始化到持续运行
- en: Each distributed agent belongs to an aggregator that is managed by an FL server,
    where ML model aggregation is conducted to synthesize a global model that is going
    to be sent back to the agents. An agent uses its local data to train an ML model
    and then uploads the trained model to the corresponding aggregator. The concept
    sounds straightforward, so we will look into a bit more detail to realize the
    entire flow of those processes.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 每个分布式代理都属于一个由FL服务器管理的聚合器，在那里进行ML模型聚合，以合成一个将要发送回代理的全局模型。这个概念听起来很简单，因此我们将更详细地探讨这些过程的整个流程。
- en: We also define a **cluster global model**, which we simply call a **cluster
    model** or **global model**, which is an aggregated ML model of local models collected
    from distributed agents.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了一个**集群全局模型**，我们简单地称之为**集群模型**或**全局模型**，它是从分布式代理收集的本地模型的聚合ML模型。
- en: Note
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In the next two chapters, we will guide you on how to implement the procedure
    and sequence of messages discussed in this chapter. However, some of the system
    operation perspectives, such as an aggregator or agent system registration in
    the database, are not introduced in the code sample of the `simple-fl` repository
    in order to simplify the explanation of the entire FL process.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两个章节中，我们将指导您如何实现本章讨论的程序和消息序列。然而，一些系统操作视角，如聚合器或代理在数据库中的系统注册，在`simple-fl`存储库的代码示例中没有介绍，以简化整个FL过程的解释。
- en: Initialization of the database, aggregator, and agent
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库、聚合器和代理的初始化
- en: 'The sequence of the initialization processes is quite simple. The initialization
    and registration processes need to happen in the order of database, aggregator,
    and agents. The overall registration sequence of an aggregator and an agent with
    a database is depicted in *Figure 3.3* as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化过程的顺序相当简单。初始化和注册过程需要按照数据库、聚合器和代理的顺序进行。聚合器和代理在数据库中的整体注册顺序如图3.3所示：
- en: '![Figure 3.3 – The process of aggregator and agent registration in the database
    server'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.3 – 数据库服务器中聚合器和代理注册的过程](img/B18369_03_03.jpg)'
- en: '](img/B18369_03_03.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_03_03.jpg](img/B18369_03_03.jpg)'
- en: Figure 3.3 – The process of aggregator and agent registration in the database
    server
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 数据库服务器中聚合器和代理注册的过程
- en: 'Here is the initialization and registration procedure of each component in
    the FL system:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是FL系统中每个组件的初始化和注册过程：
- en: '**Database server initialization**: The first step of the operation of an FL
    system is to initiate the database server. There are some simple frameworks that
    are provided by multiple organizations that do not include databases or database
    servers. However, in order to maintain the process of federating the ML models,
    it is recommended that you use a database, even a lightweight one such as an SQLite
    database.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库服务器初始化**：FL系统操作的第一步是启动数据库服务器。多个组织提供了一些简单的框架，这些框架不包括数据库或数据库服务器。然而，为了维护联邦ML模型的过程，建议您使用数据库，即使是一个轻量级的数据库，如SQLite数据库。'
- en: '**Aggregator initialization and registration**: An aggregator should be set
    up and running before any agents start running and uploading the ML models. When
    the aggregator starts running and first gets connected to the database server,
    the registration process happens automatically by also checking whether the aggregator
    is safe to be connected. If it fails to go through the registration process, it
    receives the registration failure message sent back from the database. Also, in
    case the aggregator is trying to connect to the database again after losing the
    connection to the database, the database server always checks whether the aggregator
    has already been registered or not. If this is the case, the response from the
    database server includes the system information of the registered aggregator so
    that the aggregator can start from the point where it left off. The aggregator
    may need to publish an IP address and port number for agents to be connected if
    it uses HTTP or WebSocket.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合器初始化和注册**：在代理开始运行并上传机器学习模型之前，应该设置并运行聚合器。当聚合器开始运行并首次连接到数据库服务器时，注册过程会自动进行，同时也会检查聚合器是否安全连接。如果注册过程失败，它会收到数据库发送回来的注册失败消息。此外，如果聚合器在失去与数据库的连接后再次尝试连接到数据库，数据库服务器会检查聚合器是否已经注册。如果是这种情况，数据库服务器响应中会包含已注册聚合器的系统信息，以便聚合器可以从它停止的地方开始。如果聚合器使用HTTP或WebSocket，它可能需要发布IP地址和端口号以便代理连接。'
- en: '**Agent initialization and registration**: Usually, if an agent knows the aggregator
    that the agent wants to connect to, the registration is similar to how an aggregator
    connects to a database server. The connection process should be straightforward
    enough to just send a participation message to that aggregator using an IP address,
    the port number of the aggregator (if we are using some frameworks such as HTTP
    or WebSocket), and an authentication token. In case the agent is trying to connect
    to the aggregator again after losing the connection to the aggregator, the database
    server always checks whether the agent already has been registered or not. If
    the agent is already registered, the response from the database server includes
    the system information of the registered agent so that the agent can start from
    the point where it was disconnected from the aggregator.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理初始化和注册**：通常情况下，如果代理知道它想要连接的聚合器，注册过程类似于聚合器连接到数据库服务器的方式。连接过程应该足够简单，只需使用IP地址、聚合器的端口号（如果我们使用某些框架，如HTTP或WebSocket）以及一个认证令牌向该聚合器发送一个参与消息。如果代理在失去与聚合器的连接后再次尝试连接到聚合器，数据库服务器会检查代理是否已经注册。如果代理已经注册，数据库服务器响应中会包含已注册代理的系统信息，以便代理可以从与聚合器断开连接的点开始。'
- en: In particular, when it receives the participation message from the agent, the
    aggregator goes through the following procedure, as in *Figure 3.4*. The key process
    after receiving the participation request is (i) checking whether the agent is
    trusted or not, or whether the agent is already registered or not, and (ii) checking
    whether the initial global model is already registered or not. If (i) is met,
    the registration process keeps going. If the (initial) global model is already
    registered, the agent will be able to receive the global model and start using
    that global model for the local training process on the agent side.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，当它收到代理的参与消息时，聚合器会按照*图3.4*中的流程进行操作。接收参与请求后的关键过程是（i）检查代理是否可信，或者代理是否已经注册，以及（ii）检查初始全局模型是否已经注册。如果（i）成立，注册过程将继续。如果（初始）全局模型已经注册，代理将能够接收全局模型并开始使用该全局模型在代理端进行本地训练过程。
- en: 'The agent participation and registration process at an aggregator side is depicted
    in *Figure 3.4*:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚合器端，代理的参与和注册过程如*图3.4*所示：
- en: '![Figure 3.4 – The registration process of an agent by an aggregator'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.4 – 代理通过聚合器的注册过程'
- en: '](img/B18369_03_04_New.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_03_04_New.jpg]'
- en: Figure 3.4 – The registration process of an agent by an aggregator
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 代理通过聚合器的注册过程
- en: Now that we understand the initialization and registration process of the FL
    system components, let us move on to the basic configuration of the ongoing FL
    process, which is about uploading the initial ML model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了FL系统组件的初始化和注册过程，让我们继续到正在进行的FL过程的基本配置，这涉及到上传初始机器学习模型。
- en: Initial model upload process by initial agent
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始代理的初始模型上传过程
- en: The next step in running an FL process is to register the initial ML model whose
    architecture will be used in the entire and continuous process of FL by all the
    aggregators and agents. The initial model can be distributed by the company that
    owns the ML application and FL servers. They’ll likely provide the initial base
    model as part of the aggregator configuration.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 运行FL过程的下一步是注册初始机器学习模型，该模型的架构将被FL的所有聚合器和代理在整个连续过程中使用。初始模型可以由拥有机器学习应用程序和FL服务器的公司分发。他们可能会将初始基模型作为聚合器配置的一部分提供。
- en: 'We call the initial ML model used as a reference for model aggregation a **base
    model**. We also call the agent that uploads the initial base model an *initial
    agent*. The base model info could include the ML model itself as well as the time
    it was generated and the initial performance data. That being said, the process
    of initializing the base model can be seen in *Figure 3.5*:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用作模型聚合参考的初始机器学习模型称为**基模型**。我们还将上传初始基模型的代理称为*初始代理*。基模型信息可能包括机器学习模型本身以及生成时间和初始性能数据。因此，初始化基模型的过程可以在*图3.5*中看到：
- en: '![Figure 3.5 – Base model upload process for the initial agent'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.5 – 初始代理的基模型上传过程](img/B18369_03_05.jpg)'
- en: '](img/B18369_03_05.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18369_03_05.jpg)'
- en: Figure 3.5 – Base model upload process for the initial agent
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 初始代理的基模型上传过程
- en: Now, the FL process is ready to be conducted. Next, we will learn about the
    FL cycle, which is a very core part of the FL process.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，FL过程已准备好进行。接下来，我们将了解FL周期，这是FL过程的核心部分。
- en: Overall FL cycle and process of the FL system
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FL系统的整体循环和过程
- en: 'In this section, we will only give an example with a single agent and aggregator,
    but in real cases and operations, the agent environments are various and dispersed
    into distributed devices. The following is the list of the processes for how the
    local models are uploaded, aggregated, stored, and sent back to agents as a global
    model:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们只提供一个单代理和聚合器的示例，但在实际案例和操作中，代理环境是多样的，分散到分布式设备中。以下是如何上传、聚合、存储本地模型并将其作为全局模型发送回代理的流程列表：
- en: The agents other than the initial agent will request the global model, which
    is an updated aggregated ML model, in order to deploy it to their own applications.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了初始代理之外的其他代理将请求全局模型，这是一个更新的聚合机器学习模型，以便将其部署到自己的应用程序中。
- en: Once the agent gets the updated model from the aggregator and deploys it, the
    agent retrains the ML model locally with new data that is obtained afterward to
    reflect the freshness and timeliness of the data. An agent can also participate
    in multiple rounds with different data to absorb its local examples and tendencies.
    Again, this local data will not be shared with the aggregator and stays local
    to the distributed devices.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦代理从聚合器获取更新后的模型并部署它，代理将使用随后获得的新数据在本地重新训练机器学习模型，以反映数据的最新性和时效性。代理还可以参与多个轮次，使用不同的数据来吸收其本地示例和倾向。再次强调，这些本地数据不会与聚合器共享，并保持在分布式设备上本地。
- en: After retraining the local ML model (which, of course, has the same architecture
    as the global or base model of the FL), the agent calls an FL client API to send
    the model to the aggregator.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在重新训练本地机器学习模型（当然，该模型与FL的全局或基模型具有相同的架构）之后，代理调用FL客户端API将模型发送到聚合器。
- en: The aggregator receives the local ML model and pushes the model to the database.
    The aggregator keeps track of the number of collected local models and will keep
    accepting the local models as long as the federation round is open. The round
    can be closed with any defined criteria, such as the aggregator receiving enough
    ML models to be aggregated. When the criteria are met, the aggregator aggregates
    the local models and produces an updated global model that is ready to be sent
    back to the agent.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚合器接收本地机器学习模型并将模型推送到数据库。聚合器跟踪收集到的本地模型数量，只要联盟轮次开放，就会继续接受本地模型。轮次可以通过任何定义的标准关闭，例如聚合器接收足够多的机器学习模型以进行聚合。当满足标准时，聚合器将聚合本地模型并生成一个更新的全局模型，该模型已准备好发送回代理。
- en: During that process, agents constantly poll the aggregator on whether the global
    model is ready or not, or in some cases, the aggregator may push the global model
    to the agents that are connected to the aggregator, depending on the communications
    system design and network constraints. Then, the updated model is sent back to
    the agent.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此过程中，代理会不断查询聚合器，以确定全局模型是否已准备好，或者在某些情况下，根据通信系统设计和网络约束，聚合器可能会将全局模型推送到连接到聚合器的代理。然后，更新的模型被发送回代理。
- en: After receiving the updated global model, the agent deploys and retrains the
    global model locally whenever it is ready. The whole process described is repeated
    until the termination criteria are met for the FL to end. In some cases, there
    are no termination conditions to stop this FL cycle and retraining process so
    that the global model constantly keeps learning about the latest phenomena, current
    trends, or user-related tendencies. FL rounds can just be stopped manually in
    preparation for some evaluation before a rollout.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在收到更新的全局模型后，代理在准备好时在本地部署和重新训练全局模型。描述的整个过程会重复进行，直到满足联邦学习的终止条件。在某些情况下，没有终止条件来停止这个联邦学习循环和重新训练过程，以便全局模型持续学习最新的现象、当前趋势或与用户相关的倾向。联邦学习回合可以通过手动停止来为一些评估做准备，在部署之前。
- en: '*Figure 3.6* shows the overall process of how FL is continuously conducted
    between an agent, an aggregator, and a database typically:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.6* 展示了联邦学习在代理、聚合器和数据库之间持续进行的过程的总体情况：'
- en: '![Figure 3.6 – Overview of the continuous FL cycle'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.6 – 联邦学习连续循环概述'
- en: '](img/B18369_03_06.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.6](img/B18369_03_06.jpg)'
- en: Figure 3.6 – Overview of the continuous FL cycle
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – 联邦学习连续循环概述
- en: 'Now that we understand the overall procedure of the FL process, we will look
    into the different round management approaches in the FL process next: synchronous
    FL and asynchronous FL.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了联邦学习过程的整体流程，我们将探讨联邦学习过程中的不同回合管理方法：同步联邦学习和异步联邦学习。
- en: Synchronous and asynchronous FL
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同步和异步联邦学习
- en: When the model aggregation happens at the aggregator, there are multiple criteria
    related to how many local models it needs to collect from which agents. In this
    section, we will briefly talk about the differences between synchronous and asynchronous
    FL, which have been discussed in a lot of literature, such as https://iqua.ece.toronto.edu/papers/ningxinsu-iwqos22.pdf,
    so please refer to it to learn about these concepts further.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型聚合发生在聚合器时，存在多个与从哪些代理收集多少本地模型相关的标准。在本节中，我们将简要讨论同步和异步联邦学习之间的差异，这些差异已在许多文献中讨论过，例如
    https://iqua.ece.toronto.edu/papers/ningxinsu-iwqos22.pdf，因此请参阅以进一步了解这些概念。
- en: Synchronous FL
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 同步联邦学习
- en: Synchronous FL requires the aggregator to select the agents that need to send
    the local models for each round in order to proceed with the model aggregation.
    This synchronous FL approach is simple to design and implement and suitable for
    FL applications that require a clear selection of agents. However, if the number
    of agents becomes too large, the aggregator may have to wait for a long time to
    wrap up the current round, as the computational capability of the agents could
    vary and some of them may have problems uploading or fail to upload their local
    models. Thus, some of the agents can become slow or totally dysfunctional when
    sending their models to the aggregator. These slow agents are known as *stragglers*
    in distributed ML, which motivates us to use the asynchronous FL mode.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 同步联邦学习要求聚合器在每个回合中选择需要发送本地模型的代理，以便进行模型聚合。这种同步联邦学习方法设计简单，易于实现，适用于需要明确选择代理的联邦学习应用。然而，如果代理的数量变得太多，聚合器可能需要等待很长时间才能完成当前回合，因为代理的计算能力可能不同，其中一些可能存在上传问题或未能上传其本地模型。因此，一些代理在向聚合器发送模型时可能会变得缓慢或完全无法工作。这些缓慢的代理在分布式机器学习中被称为
    *拖沓者*，这促使我们使用异步联邦学习模式。
- en: Asynchronous FL
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步联邦学习
- en: Asynchronous FL does not require the aggregator to select the agents that have
    to upload their local models. Instead, it opens the door for any trusted agents
    to upload the model anytime. Furthermore, it is fine to wrap up the federation
    round whenever the aggregator wants to generate the global model, with or without
    criteria such as the minimum number of local models that needs to be collected,
    or some predefined interval or deadline for which the aggregator needs to wait
    to receive the local models from the agents until the aggregation for that round
    happens. This asynchronous FL approach gives the FL system much more flexibility
    for model aggregation for each FL round, but the design may be more complicated
    than the simple synchronous aggregation framework.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 异步FL不需要聚合器选择必须上传其本地模型的代理。相反，它为任何受信任的代理在任何时候上传模型打开了大门。此外，聚合器想要生成全局模型时，无论是否有收集所需的最小数量本地模型的标准，或者聚合器需要等待接收来自代理的本地模型直到该轮次聚合发生的一些预定义间隔或截止日期，都可以结束联盟轮次。这种异步FL方法为每个FL轮次的模型聚合提供了FL系统更多的灵活性，但设计可能比简单的同步聚合框架更复杂。
- en: When managing the FL rounds, you need to consider the practicalities of running
    rounds, such as scheduling and dealing with delayed responses, the minimum levels
    of participation required, the details of example stores, using the downloaded
    or trained models for improved inference in the applications on the edge devices,
    and dealing with bad or slow agents.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理FL轮次时，需要考虑运行轮次的实际操作，例如调度和处理延迟响应，所需的最小参与水平，示例存储的细节，使用下载或训练的模型在边缘设备上的应用中进行改进推理，以及处理不良或缓慢的代理。
- en: We will look into the FL process and procedure flow next, focusing on the aggregator
    side.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨FL过程和流程，重点关注聚合器端。
- en: The aggregator-side FL cycle and process
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合器端的FL周期和流程
- en: An aggregator has two threads running to accept and cache the local models and
    aggregate the collected local ML models. In this section, we describe those procedures.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合器运行两个线程来接受和缓存本地模型，并聚合收集到的本地机器学习模型。在本节中，我们将描述这些过程。
- en: Accepting and caching local ML models
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 接受和缓存本地机器学习模型
- en: 'The aggregator side process of accepting and caching local ML models is depicted
    in *Figure 3.7* and explained as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合器端接受和缓存本地机器学习模型的流程在*图3.7*中展示，并如下解释：
- en: The aggregator will wait for a local ML model to be uploaded by an agent. This
    method sounds like asynchronous FL. However, if the aggregator has already decided
    which agents to accept models from, it just needs to exclude the model uploads
    sent by undesired agents. Some other system or module may have already told the
    undesired agents not to participate in the round as well.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚合器将等待代理上传本地机器学习模型。这种方法听起来像是异步FL。然而，如果聚合器已经决定接受哪些代理上传模型，它只需排除来自不受欢迎的代理的模型上传即可。其他系统或模块可能已经告知不受欢迎的代理不要参与这一轮。
- en: Once an ML model is received, the aggregator checks whether the model is uploaded
    by the trusted agents or not. Also, if the agent that uploads the local model
    is not listed in the agents that the FL operator wants to accept, the aggregator
    will discard the model. Furthermore, an aggregator needs to have a mechanism to
    only filter the valid models – otherwise, there is a risk of poisoning the global
    model and messing up the entire FL process.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦收到机器学习模型，聚合器会检查该模型是否由受信任的代理上传。此外，如果上传本地模型的代理不在FL操作员希望接受的代理列表中，聚合器将丢弃该模型。此外，聚合器需要有一种机制来仅过滤有效模型——否则，存在毒害全局模型并搞乱整个FL过程的危险。
- en: If the uploaded local ML model is valid, the aggregator will push the model
    to the database. If the database resides on a different server, the aggregator
    will package the model and send it to the database server.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果上传的本地机器学习模型有效，聚合器将把模型推送到数据库。如果数据库位于不同的服务器上，聚合器将打包模型并发送到数据库服务器。
- en: While the uploaded models are stored in the database, they should be buffered
    in the memory of the state manager of the aggregator in an appropriate format,
    such as NumPy arrays.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当上传的模型存储在数据库中时，它们应在聚合器状态管理器的内存中以适当的格式（如NumPy数组）进行缓冲。
- en: 'This procedure keeps running until the termination conditions are satisfied
    or the operator of the FL system opts to stop the process. *Figure 3.7* depicts
    the procedure of accepting and caching local ML models:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 此流程会一直运行，直到满足终止条件或FL系统的操作员选择停止该过程。*图3.7* 描述了接受和缓存本地机器学习模型的流程：
- en: '![Figure 3.7 – Procedure for accepting and caching local ML models'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.7 – 接受和缓存本地机器学习模型的流程'
- en: '](img/B18369_03_07.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_03_07.jpg](img/B18369_03_07.jpg)'
- en: Figure 3.7 – Procedure for accepting and caching local ML models
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – 接受和缓存本地机器学习模型的流程
- en: 'Once the local ML models are accepted and cached, the FL system moves on to
    the next procedure: aggregating the local models.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦本地机器学习模型被接受并缓存，FL系统继续进行下一个流程：聚合本地模型。
- en: Aggregating local ML models
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚合本地机器学习模型
- en: 'The aggregator-side procedure of aggregating local ML models depicted in *Figure
    3.8* is as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图3.8* 所示的聚合器端聚合本地机器学习模型的流程如下：
- en: 'The aggregator constantly checks whether the aggregation criteria are satisfied.
    The typical aggregation criteria are as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚合器持续检查聚合标准是否满足。典型的聚合标准如下：
- en: The number of local models collected so far in this FL round. For example, if
    the number of agents is 10 nodes, after 8 nodes (meaning 80% nodes) report the
    locally trained models, the aggregator starts aggregating the models.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在此FL轮次中迄今为止收集到的本地模型数量。例如，如果代理的数量是10个节点，在8个节点（意味着80%的节点）报告了本地训练的模型后，聚合器开始聚合模型。
- en: The combination of the number of collected models and the time that the FL round
    has spent. This can automate the aggregation process and prevent systems from
    getting stuck.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集到的模型数量和FL轮次所花费的时间的组合。这可以自动化聚合过程，防止系统陷入停滞。
- en: Once the aggregation criteria are met, the aggregator starts a model aggregation
    process. Usually, federated averaging is a very typical but powerful aggregation
    method. Further explanation of the model aggregation methods is in the *Basics
    of model aggregation* section of this chapter and in [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176),
    *Model Aggregation*. The aggregated model is defined as a global model in this
    FL round.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦满足聚合标准，聚合器开始模型聚合过程。通常，联邦平均是一种非常典型但强大的聚合方法。关于模型聚合方法的进一步解释见本章的 *模型聚合基础* 部分，以及
    [*第7章*](B18369_07.xhtml#_idTextAnchor176)，*模型聚合*。在本FL轮次中，聚合的模型被定义为全局模型。
- en: In a case where time for the FL round has expired and not enough agents that
    participated in the round have uploaded a model, the round can be abandoned or
    forced to conduct aggregation for the local models collected so far.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在FL轮次的时间已过期且参与轮次的代理中上传的模型不足的情况下，该轮次可以被放弃或强制对迄今为止收集到的本地模型进行聚合。
- en: Once the model aggregation is complete, the aggregator pushes the aggregated
    global model to the database. If the database resides on a different server, the
    aggregator will package the global model and send it to the database server.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型聚合完成，聚合器将聚合的全局模型推送到数据库。如果数据库位于不同的服务器上，聚合器将打包全局模型并将其发送到数据库服务器。
- en: Then, the aggregator sends the global model to all the agents, or when the agents
    poll to check whether the global model is ready, the aggregator will notify the
    agent that the global model is ready and put it in the response message to the
    agents.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，聚合器将全局模型发送给所有代理，或者当代理轮询检查全局模型是否准备就绪时，聚合器将通知代理全局模型已准备就绪，并将其放入对代理的响应消息中。
- en: After the whole process of model aggregation, the aggregator updates the number
    of the FL round by just incrementing it.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型聚合的整个过程中，聚合器仅通过递增来更新FL轮次的数量。
- en: '*Figure 3.8* shows the aggregator’s process from checking the aggregation criteria
    to synthesizing the global model when enough models are collected:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.8* 显示了在收集到足够的模型后，聚合器从检查聚合标准到合成全局模型的流程：'
- en: '![Figure 3.8 – Model synthesis routine: aggregating local ML models'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.8 – 模型合成流程：聚合本地机器学习模型'
- en: '](img/B18369_03_08.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_03_08.jpg](img/B18369_03_08.jpg)'
- en: 'Figure 3.8 – Model synthesis routine: aggregating local ML models'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 – 模型合成流程：聚合本地机器学习模型
- en: Aggregating local models to generate the global model has been explained. Now,
    let us look into the agent-side FL cycle, including the retraining process of
    the local ML models.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 已经解释了如何聚合本地模型以生成全局模型。现在，让我们看看代理端的FL周期，包括本地机器学习模型的重新训练过程。
- en: The agent-side local retraining cycle and process
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理端本地重训练周期和过程
- en: 'In the distributed agent, the following state transition happens and is repeated
    for the continuous operation of the FL cycle:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式智能体中，以下状态转换发生，并且为了FL循环的持续运行而重复：
- en: In the state of `waiting_gm`, the agent polls the aggregator to receive any
    updates related to the global model. Basically, a polling method is used to regularly
    query the updated global model. However, under some specific settings, an aggregator
    can push the updated global model to all agents.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`等待_gm`状态，智能体轮询聚合器以接收与全局模型相关的任何更新。基本上，使用轮询方法定期查询更新的全局模型。然而，在某些特定设置下，聚合器可以将更新的全局模型推送到所有智能体。
- en: '`gm_ready` is the state after the global model is formed by the aggregator
    and downloaded by the agent. The model parameters are cached in the agent device.
    The agent replaces its local ML model with the downloaded global model. Before
    completely replacing the local model with the downloaded model, the agent can
    check whether the output of the global model is sufficiently performant for the
    local ML engine. If the performance is not what is expected, the user can keep
    using the old model locally until it receives the global model that has the desired
    performance.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`gm_ready`是聚合器形成全局模型并由智能体下载后的状态。模型参数在智能体设备中缓存。智能体用下载的全局模型替换其本地机器学习模型。在完全用下载的模型替换本地模型之前，智能体可以检查全局模型的输出是否足够高效以供本地机器学习引擎使用。如果性能不符合预期，用户可以继续使用本地旧模型，直到接收到具有所需性能的全局模型。'
- en: Next, in the `training` state, the agent can locally train the model in order
    to maximize its performance. The trained model is saved in a local data storage
    where training examples are kept. The FL client libraries of the agent ascertain
    its readiness to manipulate the local model that can be protected with asynchronous
    function access.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在`训练`状态中，智能体可以本地训练模型以最大化其性能。训练好的模型保存在一个本地数据存储中，其中包含训练示例。智能体的FL客户端库确认其准备就绪，可以操作可以异步函数访问保护的本地区域模型。
- en: After the local model is trained, the agent checks whether the new global model
    has been sent to the agent or not. If the global model has arrived, then the locally
    trained ML model is discarded and goes back to the `gm_ready` state.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地模型训练完成后，智能体检查新的全局模型是否已发送给智能体。如果全局模型已到达，则丢弃本地训练的机器学习模型，并返回到`gm_ready`状态。
- en: After local training, the agent proceeds with the `sending` state to send the
    updated local model back to the aggregator, and then, the agent goes back to the
    `waiting_gm` state.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地训练完成后，智能体进入`发送`状态，将更新后的本地模型发送回聚合器，然后，智能体返回到`等待_gm`状态。
- en: '*Figure 3.9* depicts the state transition of an agent to adapt and update the
    ML model:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.9* 描述了智能体适应和更新机器学习模型的状态转换：'
- en: '![Figure 3.9 – Agent-side state transition to adapt and update the ML model'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.9 – 智能体侧状态转换以适应和更新机器学习模型'
- en: '](img/B18369_03_09.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18369_03_09.jpg)'
- en: Figure 3.9 – Agent-side state transition to adapt and update the ML model
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 – 智能体侧状态转换以适应和更新机器学习模型
- en: Next, we touch on a model interpretation based on deviation from the baseline
    outputs that are used for anomaly detection and preventing model degradation.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论基于基线输出的偏差的模型解释，这些基线输出用于异常检测和防止模型退化。
- en: Model interpretation based on deviation from baseline outputs
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于基线输出偏差的模型解释
- en: 'We can also provide an interpretation framework by looking at the output of
    each local model. The following procedure can be considered to ensure the local
    model is always good to use and can be deployed in production:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过查看每个本地模型的输出提供解释框架。以下程序可以被认为是确保本地模型始终可用并且可以部署到生产中的方法：
- en: Obtain the most recent ML output generated by an agent as well as a baseline
    output that can be a typical desired output prepared by users. The baseline output
    could include an average output based on the past windows or reference points
    defined by an operator, subject expert, or rule-based algorithm.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取智能体生成的最新机器学习输出以及一个基线输出，该输出可以是用户准备的一个典型期望输出。基线输出可能包括基于过去窗口或操作员、主题专家或基于规则的算法定义的参考点的平均值输出。
- en: The deviation between the output of the local model and the baseline output
    is computed.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算本地模型输出与基线输出之间的偏差。
- en: An anomaly or performance degradation can be detected by checking whether the
    deviation exceeds the operator-specified threshold. If an anomaly is detected,
    an alarm can be sent to an operator to indicate a fault or that the ML model is
    in an anomalous state.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过检查偏差是否超过操作员指定的阈值，可以检测到异常或性能下降。如果检测到异常，可以向操作员发送警报，指示故障或机器学习模型处于异常状态。
- en: Now that the process of the FL has been explained, let us look into the basics
    of model aggregation, which comprise the critical part of FL.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 既然联邦学习的过程已经解释清楚，让我们来看看模型聚合的基本概念，它是联邦学习的关键部分。
- en: Basics of model aggregation
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型聚合的基本概念
- en: Aggregation is a core concept within FL. In fact, the strategies employed to
    aggregate models are the key theoretical driver for the performance of FL systems.
    The purpose of this section is to introduce the high-level concepts of aggregation
    within the context of an FL system – the underlying theory and examples of advanced
    aggregation strategies will be discussed in greater depth in [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176),
    *Model Aggregation*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合是联邦学习（FL）中的一个核心概念。实际上，用于聚合模型的策略是联邦学习系统性能的关键理论驱动因素。本节的目的在于介绍在联邦学习系统背景下聚合的高级概念——更深入地讨论高级聚合策略的理论和示例将在[*第7章*](B18369_07.xhtml#_idTextAnchor176)
    *模型聚合*中进行。
- en: What exactly does it mean to aggregate models?
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型聚合究竟意味着什么？
- en: Let’s revisit the aggregator-side cycle discussed in the *Understanding the
    FL system flow – from initialization to continuous operation* section, at the
    point in the process where the agents assigned to a certain aggregator have finished
    training locally and have transmitted these models back to this aggregator. The
    goal of any aggregation strategy, or any way of aggregating these models together,
    is to produce new models that gradually increase in performance across all of
    the data collected by the constituent agents.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下在*理解联邦学习系统流程——从初始化到持续运行*章节中讨论的聚合器端周期，在过程中分配给某个聚合器的代理完成本地训练并将这些模型传回该聚合器时。任何聚合策略，或任何聚合这些模型的方式，的目标是产生新的模型，这些模型在构成代理收集的所有数据上逐渐提高性能。
- en: An important point to remember is that FL is, by definition, a restricted version
    of the distributed learning setting, in which the data collected locally by each
    agent cannot be directly accessed by other agents. If this restriction were not
    in place, a model could be made to perform well trivially on all of the data by
    collecting the data from each agent and training on the joint dataset; thus, it
    makes sense to treat this *centrally-trained* model as the target model for an
    FL approach. At a high level, we can consider this unrestricted distributed learning
    scenario as aggregation before model training (where in this case, aggregation
    refers to combining the data from each agent). Because FL does not allow data
    to be accessed by other agents, we consider the scenario as aggregation after
    model training instead; in this context, aggregation refers to the combination
    of the intelligence captured by each of the trained models from their differing
    local datasets. To summarize, the goal of an aggregation strategy is to combine
    models in a way that eventually leads to a generalized model whose performance
    approaches that of the respective centrally trained model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的一个重要观点是，按照定义，联邦学习是一种受限的分布式学习设置版本，其中每个代理收集的本地数据不能被其他代理直接访问。如果这种限制不存在，可以通过从每个代理收集数据并在联合数据集上训练来使模型在所有数据上简单地表现良好；因此，将这种*集中训练*的模型作为联邦学习方法的靶模型是有意义的。从高层次来看，我们可以将这种不受限制的分布式学习场景视为模型训练前的聚合（在这种情况下，聚合指的是结合每个代理的数据）。由于联邦学习不允许数据被其他代理访问，我们将这种情况视为模型训练后的聚合；在这种情况下，聚合指的是结合每个训练模型从其不同的本地数据集中捕获的智能。总结来说，聚合策略的目标是以一种最终导致泛化模型性能接近相应集中训练模型性能的方式结合模型。
- en: FedAvg – Federated averaging
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FedAvg – 联邦平均
- en: 'To make some of these ideas more concrete, let’s take an initial look into
    one of the most well-known and straightforward aggregation strategies, known as
    **Federated Averaging** (**FedAvg**). The FedAvg algorithm is performed as follows:
    let ![](img/B18369_03_F01.png) be the parameters of the models from ![](img/B18369_03_F02.png)
    agents, each with a local dataset size of ![](img/B18369_03_F03.png). Also, ![](img/B18369_03_F04.png)
    is the total dataset size defined as ![](img/B18369_03_F05.png). Then, FedAvg
    returns the following ML model as the aggregated model:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使一些想法更加具体，让我们先看看最著名且最直接的聚合策略之一，即**联邦平均**（**FedAvg**）。FedAvg算法的执行过程如下：设![](img/B18369_03_F01.png)为来自![](img/B18369_03_F02.png)个代理的模型的参数，每个代理拥有一个本地数据集大小为![](img/B18369_03_F03.png)。此外，![](img/B18369_03_F04.png)是定义为![](img/B18369_03_F05.png)的总数据集大小。然后，FedAvg返回以下机器学习模型作为聚合模型：
- en: '![](img/B18369_03_F06.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18369_03_F06.jpg)'
- en: Essentially, we perform FedAvg over a set of models by taking the weighted average
    of the models, with weights proportional to the size of the dataset used to train
    the model. As a result, the types of models to which FedAvg can be applied are
    models that can be represented as some set of parameter values. Deep neural networks
    are currently the most notable of these kinds of models – most of the results
    analyzing the performance of FedAvg work with deep learning models.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们通过对一组模型进行加权平均来执行FedAvg，权重与用于训练模型的本地数据集大小成比例。因此，FedAvg可以应用到的模型类型是那些可以表示为一些参数值集合的模型。深度神经网络是目前这类模型中最引人注目的——大多数分析FedAvg性能的结果都是与深度学习模型一起工作的。
- en: 'It is rather surprising that this relatively simple approach can lead to generalization
    in the resulting model. We can visually examine what FedAvg looks like within
    a toy two-dimensional parameter space to observe the benefits of the aggregation
    strategy:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 真是令人惊讶，这种相对简单的方法竟然能导致最终模型产生泛化。我们可以通过在玩具二维参数空间中观察FedAvg的样子，来直观地检验聚合策略的好处：
- en: '![Figure 3.10 – Two-dimensional parameter space with local models from two
    agents (the circle and square) and a target model (the black x)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.10 – 来自两个代理（圆形和方形）和目标模型（黑色x）的二维参数空间中的本地模型'
- en: '](img/B18369_03_10.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18369_03_10.jpg)'
- en: Figure 3.10 – Two-dimensional parameter space with local models from two agents
    (the circle and square) and a target model (the black x)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – 来自两个代理（圆形和方形）和目标模型（黑色x）的二维参数空间中的本地模型
- en: 'Let’s consider a case where we have two newly initialized models (the circle
    and square points) belonging to separate agents. The space in the preceding figure
    represents the parameter space of the models, where each toy model is defined
    by two parameters. As the models are trained, these points will move in the parameter
    space – the goal is to approach a local optimum in the parameter space, generally
    corresponding to the aforementioned centrally trained model:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个有两个新初始化的模型（圆形和方形点）属于不同代理的情况。前面图中的空间代表模型的参数空间，其中每个玩具模型由两个参数定义。随着模型的训练，这些点将在参数空间中移动——目标是接近参数空间中的局部最优解，通常对应于上述集中训练的模型：
- en: '![Figure 3.11 – Change in local model parameters without aggregation'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.11 – 没有聚合的本地模型参数变化'
- en: '](img/B18369_03_11.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18369_03_11.jpg)'
- en: Figure 3.11 – Change in local model parameters without aggregation
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 – 没有聚合的本地模型参数变化
- en: 'Each model converges to separate dataset-specific optima (two x points from
    the circle and square) that do not generalize. Because each agent only has access
    to a subset of the data, the local optima reached by training each model locally
    will differ from the true local optima; this difference depends on how similar
    the underlying data distributions are for each agent. If the models are only trained
    locally, the resulting models will likely not generalize over all of the data:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型都收敛到各自数据集特定的最优解（来自圆形和方形的两个x点），这些最优解不具有泛化能力。因为每个代理只能访问数据的一个子集，所以通过本地训练每个模型所达到的局部最优解将与真实的局部最优解不同；这种差异取决于每个代理的底层数据分布的相似程度。如果模型仅在本地进行训练，那么得到的模型可能无法泛化到所有数据：
- en: '![Figure 3.12 – Adding aggregation moves the local model parameters to the
    average for both models at each step, leading to convergence at the target model'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12 – 添加聚合将本地模型参数移动到每个步骤中两个模型的平均值，导致收敛到目标模型'
- en: '](img/B18369_03_12.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18369_03_12.jpg)'
- en: Figure 3.12 – Adding aggregation moves the local model parameters to the average
    for both models at each step, leading to convergence at the target model
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – 添加聚合将局部模型参数移动到每个步骤中两个模型的平均值，导致在目标模型上收敛
- en: Applying FedAvg at each movement step allows us to create an aggregate model
    that eventually comes close to the true local optima in the parameter space.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步应用FedAvg允许我们创建一个聚合模型，该模型最终在参数空间中接近真实局部最优。
- en: This example displays the basic capability of FedAvg to produce generalized
    models. However, working with real models (such as highly parameterized deep learning
    models) introduces additional complexity that is handled by FedAvg but not by
    simpler approaches. For example, we might wonder why we don’t simply fully train
    each local model and only average at the end; while this approach would work in
    this toy case, it has been observed that only averaging once with real models
    leads to poor performance across all of the data. The FedAvg process allows for
    a more robust way to reach the generalized model within high-dimension parameter
    spaces.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了FedAvg产生泛化模型的基本能力。然而，与真实模型（如高度参数化的深度学习模型）一起工作引入了额外的复杂性，这由FedAvg处理，但不是更简单的方法。例如，我们可能会想知道为什么我们不是简单地完全训练每个本地模型，只在最后平均；虽然这种方法在这个玩具案例中可以工作，但观察到仅对真实模型进行一次平均会导致所有数据上的性能较差。FedAvg过程允许在高度维参数空间内以更稳健的方式达到泛化模型。
- en: This section only aims to give an overview of aggregation in FL; [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176),
    *Model Aggregation*, contains more detailed explanations and examples for aggregation
    in different scenarios.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 本节仅旨在概述联邦学习中的聚合；[第7章](B18369_07.xhtml#_idTextAnchor176)，*模型聚合*，包含对不同场景中聚合的更详细解释和示例。
- en: We now understand the entire process of how the FL system works with basic model
    aggregation. In some applications, the FL system may have to support a huge number
    of agents to realize its scalability. The following section will give you some
    idea about how to scale more smoothly, especially with a decentralized horizontal
    design.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经理解了FL系统如何与基本模型聚合工作的整个过程。在某些应用中，FL系统可能需要支持大量的代理以实现其可扩展性。下一节将为您提供一些关于如何更平滑地扩展的想法，特别是在去中心化的横向设计中。
- en: Furthering scalability with horizontal design
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步通过横向设计提高可扩展性
- en: In this section, we will look into how to further scalability when we need to
    support a large number of devices and users.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨在需要支持大量设备和用户时如何进一步提高可扩展性。
- en: There are practical cases where control, ease of maintenance and deployment,
    and low communication overhead are provided by centralized FL. If the number of
    agents is not large, it makes more sense to stick to centralized FL than decentralized
    FL. However, when the number of participating agents becomes quite large, it may
    be worth looking into horizontal scaling with a decentralized FL architecture.
    The latest developments of auto-scaling frameworks these days, such as the **Kubernetes**
    framework (https://kubernetes.io/), can be a nice integration with the topic that
    is discussed in this section, although actual integration and implementation with
    Kubernetes is beyond the scope of this book.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际案例中，集中式联邦学习提供了控制、易于维护和部署以及低通信开销。如果代理数量不是很大，坚持集中式联邦学习比去中心化联邦学习更有意义。然而，当参与代理的数量变得相当大时，可能值得考虑使用去中心化FL架构的横向扩展。如今自动扩展框架的最新发展，如**Kubernetes**框架（https://kubernetes.io/），可以很好地与本章讨论的主题相结合，尽管与Kubernetes的实际集成和实现超出了本书的范围。
- en: Horizontal design with semi-global model
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有半全局模型的横向设计
- en: 'There will be some use cases where many aggregators are needed to cluster groups
    of agents and create a global model on top of those many aggregators. Google uses
    a centralized approach for this, as in the paper *Towards Federated Learning at
    Scale*, while setting up a centralized node for managing multiple aggregators
    may have some resilience issues. The idea is simple: periodically aggregate all
    the cluster models at some central master node.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些用例中，需要许多聚合器来聚类一组代理并在这许多聚合器之上创建一个全局模型。谷歌采用集中式方法来实现这一点，正如在论文《迈向大规模联邦学习》中所述，而为管理多个聚合器设置一个集中式节点可能存在一些弹性问题。其想法很简单：定期在某个中央主节点上聚合所有聚类模型。
- en: 'On the other hand, we can realize the decentralized way of aggregating cluster
    models created by multiple aggregators. The architecture for that is based on
    two crucial ideas:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们可以实现由多个聚合器创建的集群模型的去中心化聚合方式。这种架构基于两个关键思想：
- en: Model aggregation conducted among individual cluster aggregators without master
    nodes
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在没有主节点的情况下，在单个集群聚合器之间进行的模型聚合
- en: Semi-global model synthesis to aggregate cluster models generated by other aggregators
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半全局模型综合以聚合由其他聚合器生成的集群模型
- en: To create semi-global models, decentralized cluster aggregators exchange their
    aggregated cluster models with each other and approximate optimal global models.
    The cluster aggregators can also use a database to periodically collect other
    cluster models to generate the semi-global models. This framework allows for the
    absorption of training results from diverse sets of users dispersed across many
    aggregators by synthesizing the most updated global models without a master node
    concept.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建半全局模型，去中心化的集群聚合器相互交换它们聚合的集群模型，并近似最优的全局模型。集群聚合器还可以使用数据库定期收集其他集群模型以生成半全局模型。这个框架允许通过综合最新的全局模型来吸收来自分散在许多聚合器上的不同用户集的训练结果，而不需要主节点概念。
- en: Based on this decentralized architecture, the robustness of the entire FL system
    can be enhanced, as the semi-global model can be independently computed at each
    cluster aggregator. The FL system can be scaled further, as each cluster aggregator
    is responsible for creating its own semi-global model by itself – not via the
    master node of those aggregators – and therefore, decentralized semi-global model
    formation comes with resiliency and mobility.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这种去中心化架构，整个 FL 系统的鲁棒性可以得到增强，因为半全局模型可以在每个集群聚合器独立计算。FL 系统可以进一步扩展，因为每个集群聚合器都负责自己创建自己的半全局模型——不是通过这些聚合器的主节点——因此，去中心化的半全局模型形成具有弹性和移动性。
- en: We can even decouple the database that stores the uploaded local models, cluster
    global models, and semi-global models. By introducing a distributed database into
    the FL system, the entire system could be made more scalable, resilient, and secure
    together with some failover mechanism.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以将存储上传的本地模型、集群全局模型和半全局模型的数据库解耦。通过将分布式数据库引入 FL 系统，整个系统可以变得更加可扩展、弹性，并且安全，同时还有一些故障转移机制。
- en: For example, each cluster aggregator stores the cluster model in a distributed
    database. The cluster aggregators can retrieve cluster models of other aggregators
    by pulling the models periodically from the databases. At each cluster aggregator,
    a semi-global ML model is generated by synthesizing the pulled models.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，每个集群聚合器将集群模型存储在分布式数据库中。集群聚合器可以通过定期从数据库中拉取模型来检索其他聚合器的集群模型。在每个集群聚合器，通过综合拉取的模型生成一个半全局
    ML 模型。
- en: '*Figure 3.13* illustrates the overall architecture of the decentralized horizontal
    design of a multi-aggregator FL system:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.13* 展示了多聚合器 FL 系统去中心化水平设计的整体架构：'
- en: '![Figure 3.13 – Architecture of a decentralized FL system with multiple aggregators
    (horizontal design)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.13 – 具有多个聚合器的去中心化 FL 系统架构（水平设计）]'
- en: '](img/B18369_03_13_New.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18369_03_13_New.jpg)'
- en: Figure 3.13 – Architecture of a decentralized FL system with multiple aggregators
    (horizontal design)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13 – 具有多个聚合器的去中心化 FL 系统架构（水平设计）
- en: Now that we have discussed how to enhance the FL system with a horizontal design
    using the semi-global model concept, next, we will look at distributed database
    frameworks to further ensure scalability and resiliency.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了如何通过半全局模型概念使用水平设计来增强 FL 系统，接下来，我们将探讨分布式数据库框架以进一步确保可扩展性和弹性。
- en: Distributed database
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式数据库
- en: Furthermore, the accountability of the model updates can be provided by storing
    historical model data in a data-driven distributed database. The **InterPlanetary
    File System** (**IPFS**) and Blockchain are well-known distributed databases that
    ensure the accountability of global model updates. After a cluster aggregator
    generates a semi-global model based on other cluster models, the semi-global model
    is stored in a distributed database. The distributed database manages the information
    of those models with a unique identifier. To maintain all the models consistently,
    including local, cluster, and semi-global models, each ML model is assigned a
    globally unique identifier, such as a hash value, which could be realized using
    the concept of a **Chord Distributed Hash Table** (**Chord DHT**). The Chord DHT
    is a scalable peer-to-peer lookup protocol for internet applications.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，可以通过在数据驱动的分布式数据库中存储历史模型数据来提供模型更新的问责制。**星际文件系统**（**IPFS**）和区块链是众所周知的分布式数据库，它们确保了全局模型更新的问责制。当一个集群聚合器基于其他集群模型生成半全局模型后，该半全局模型被存储在分布式数据库中。分布式数据库使用唯一标识符管理这些模型的信息。为了保持所有模型的一致性，包括本地、集群和半全局模型，每个机器学习模型都被分配了一个全局唯一的标识符，例如哈希值，这可以通过使用**Chord分布式哈希表**（**Chord
    DHT**）的概念来实现。Chord DHT是一个用于互联网应用的可扩展的P2P查找协议。
- en: The cluster aggregator can store metadata on the cluster models, such as timestamps
    and hash identifiers. This gives us further accountability for model synthesis
    by ensuring the cluster models haven't been altered. It is also possible to identify
    a set of aggregators that are sending harmful cluster models to destroy the semi-global
    models once the malicious models are detectable. These models can be filtered
    by analyzing the patterns of the weights of the cluster model or deviation from
    the other cluster models when the difference is too big to rely on.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 集群聚合器可以在集群模型上存储元数据，例如时间戳和哈希标识符。这为我们提供了对模型合成的进一步问责制，确保集群模型没有被更改。一旦恶意模型可检测，还可以识别出一组发送有害集群模型以破坏半全局模型的聚合器。这些模型可以通过分析集群模型权重的模式或与其他集群模型的偏差来过滤，当差异太大而无法依赖时。
- en: The nature of the distributed database is to store all the volatile state information
    of the distributed FL system. The FL system can restore from the distributed database
    in the case of failure. The cluster aggregators also exchange their cluster models
    based on a certain interval defined by the system operator. Therefore, the mapping
    table between cluster models and aggregators needs to be logged in the database
    together with meta-information on the local, cluster, and semi-global models,
    such as the generation time of those models and the size of training samples.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式数据库的本质是存储分布式FL系统所有易变的状态信息。在发生故障的情况下，FL系统可以从分布式数据库中恢复。集群聚合器也会根据系统操作员定义的某个间隔交换它们的集群模型。因此，集群模型和聚合器之间的映射表需要与本地、集群和半全局模型上的元信息一起记录在数据库中，例如这些模型的生成时间和训练样本的大小。
- en: Asynchronous agent participation in a multiple-aggregator scenario
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在多聚合器场景中的异步代理参与
- en: 'Distributed agents can broadcast participation messages to connectable aggregators
    when they want to join their FL process. The participation messages can contain
    the unique ID of the agent. One of the cluster aggregators then returns a cluster
    aggregator ID, potentially the value generated based on a common hash function,
    to which the agent should belong. *Figure 3.14* depicts how the agent is assigned
    to a certain cluster aggregator using a hash function:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式代理可以在他们想要加入FL过程时向可连接的聚合器广播参与消息。参与消息可以包含代理的唯一ID。然后，集群聚合器之一会返回一个集群聚合器ID，这可能是基于一个共同哈希函数生成的值，代理应该属于该值。*图3.14*展示了如何使用哈希函数将代理分配给特定的集群聚合器：
- en: '![Figure 3.14 – The sequence of an agent joining one of the cluster aggregators
    in an FL system'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.14 – 代理加入FL系统中一个集群聚合器的序列'
- en: '](img/B18369_03_14.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18369_03_14.jpg)'
- en: Figure 3.14 – The sequence of an agent joining one of the cluster aggregators
    in an FL system
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 – 代理加入FL系统中一个集群聚合器的序列
- en: In the following section, we will look into how the semi-global model is generated
    based on aggregating the multiple cluster global models.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何基于聚合多个集群全局模型来生成半全局模型。
- en: Semi-global model synthesis
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 半全局模型合成
- en: 'After the agent is assigned to a specific cluster aggregator, the agent starts
    to participate in the FL process. It requests a base ML model if it is registered
    – otherwise, it needs to upload the base model to start local training. The procedure
    of uploading local models and generating cluster and semi-global models will continue
    until the agent or aggregator is disconnected from the system. The sequence of
    the local and cluster model upload process, aggregation process, and semi-global
    model synthesis and pulling is illustrated in *Figure 3.15*:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在代理被分配到特定的集群聚合器后，代理开始参与FL过程。如果它已注册，则请求基础ML模型；否则，它需要上传基础模型以开始本地训练。上传本地模型、生成集群和半全局模型的过程将继续，直到代理或聚合器从系统中断开连接。本地和集群模型上传过程、聚合过程以及半全局模型合成和拉取的序列在*图3.15*中说明：
- en: '![Figure 3.15 – The sequence of the semi-global model synthesis processes from
    uploading local models to pulling semi-global models'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.15 – 从上传本地模型到拉取半全局模型合成过程的序列'
- en: '](img/B18369_03_15.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18369_03_15.jpg)'
- en: Figure 3.15 – The sequence of the semi-global model synthesis processes from
    uploading local models to pulling semi-global models
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 – 从上传本地模型到拉取半全局模型合成过程的序列
- en: Let’s look at semi-global model synthesis using the flowchart between the agent,
    aggregator, and distributed database.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用代理、聚合器和分布式数据库之间的流程图来查看半全局模型合成。
- en: The aggregator receives a local model from an agent. When receiving the local
    model, the model filtering process will decide whether to accept the uploaded
    model or not. This framework can be implemented using many different methods,
    such as a basic scheme of checking the difference between the weights of the global
    and local models. If the model is not valid, just discard the local model.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合器从代理那里接收一个本地模型。在接收本地模型时，模型过滤过程将决定是否接受上传的模型。此框架可以使用许多不同的方法实现，例如检查全局和本地模型权重差异的基本方案。如果模型无效，则简单地丢弃本地模型。
- en: Then, a cluster model is created by aggregating all the accepted local models.
    The aggregator stores the cluster model in a database, as well as simultaneously
    retrieving the cluster models generated by other cluster aggregators. A semi-global
    model is then synthesized from those cluster models and will be used in the agents
    that are assigned to the cluster aggregator.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过聚合所有接受的本地模型创建一个集群模型。聚合器将集群模型存储在数据库中，同时检索其他集群聚合器生成的集群模型。然后从这些集群模型中合成一个半全局模型，并将用于分配给集群聚合器的代理。
- en: '*Figure 3.16* shows how the cluster aggregator proceeds with cluster and semi-global
    model synthesis using a distributed database:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.16*展示了集群聚合器如何使用分布式数据库进行集群和半全局模型合成：'
- en: '![Figure 3.16 – The procedure and flow of semi-global model synthesis'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.16 – 半全局模型合成的流程和流程图'
- en: '](img/B18369_03_16.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18369_03_16.jpg)'
- en: Figure 3.16 – The procedure and flow of semi-global model synthesis
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 – 半全局模型合成的流程和流程图
- en: An aggregator does not need to retrieve all the cluster models generated at
    each round to create a semi-global model. To synthesize a semi-global model, the
    global model can eventually converge based on the subset of models randomly selected
    by each aggregator. Using this approach, the robustness and independence of aggregators
    will be enhanced by compromising on the conditions to create the global model
    at every update. This framework can also resolve the bottlenecks in terms of computation
    and communication typical to centralized FL systems.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合器不需要检索每一轮生成的所有集群模型来创建半全局模型。为了合成一个半全局模型，全局模型可以最终基于每个聚合器随机选择的模型子集收敛。采用这种方法，通过在每次更新时妥协创建全局模型的条件，可以增强聚合器的鲁棒性和独立性。此框架还可以解决集中式FL系统典型的计算和通信瓶颈。
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the potential architecture, procedure flow, and
    message sequences within an FL system. The typical FL system architecture consists
    of an aggregator, agents, and a database server. These three components are constantly
    communicating with each other to exchange system information and ML models to
    achieve model aggregation.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了FL系统内的潜在架构、流程流程和消息序列。典型的FL系统架构包括一个聚合器、代理和数据库服务器。这三个组件不断相互通信以交换系统信息和ML模型，以实现模型聚合。
- en: The key to implementing a good FL system is decoupling the critical components
    and carefully designing the interfaces between them. We focused on the aspect
    of the simplicity of its design so that further enhancement can be achieved by
    just adding additional components to the systems. Horizontal decentralized design
    can also help implement a scalable FL system.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 实现良好的FL系统的关键是解耦关键组件并仔细设计它们之间的接口。我们专注于其设计的简单性，以便只需向系统中添加额外的组件即可实现进一步的增强。水平分布式设计也有助于实现可扩展的FL系统。
- en: In the following chapter, we will discuss the implementation details of achieving
    FL on the server side. As some critical aspects of the functionalities have been
    introduced in this chapter, you will be able to implement the basic system and
    smoothly run the simulation with some ML applications.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论在服务器端实现FL的实现细节。由于本章已介绍了功能的一些关键方面，您将能够实现基本系统并使用一些机器学习应用程序顺利运行模拟。
- en: Further reading
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Some of the concepts discussed in this chapter can be explored further by reading
    the following papers:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论的一些概念可以通过阅读以下论文进一步探索：
- en: 'Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman,
    Vladimir Ivanov, Chloe Kiddon, et al. *Towards Federated Learning at Scale: System
    Design.* Proceedings of Machine Learning and Systems 1 (2019): 374–388, ([https://arxiv.org/abs/1902.01046](https://arxiv.org/abs/1902.01046)).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman,
    Vladimir Ivanov, Chloe Kiddon等. *迈向大规模联邦学习：系统设计.* 机器学习与系统会议论文集 1 (2019): 374–388,
    ([https://arxiv.org/abs/1902.01046](https://arxiv.org/abs/1902.01046)).'
- en: 'Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A.
    N., and Zhao, S. (2021). *Advances and Open Problems in Federated Learning*. *Foundations
    and Trends in Machine Learning*, *14 (1 and 2): 1–210*, ([https://arxiv.org/abs/1912.04977](https://arxiv.org/abs/1912.04977)).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A.
    N.，以及Zhao, S. (2021). *联邦学习中的进展和开放问题.* *机器学习基础与趋势*, *14 (1和2): 1–210*, ([https://arxiv.org/abs/1912.04977](https://arxiv.org/abs/1912.04977)).'
- en: 'Stoica, I., Morris, R., Liben-Nowell, D., Karger, D., Kaashoek, M., Dabek,
    F., Balakrishnan, H. (2003). Chord: *A Scalable Peer-to-Peer Lookup Protocol for
    Internet Applications*, IEEE/ACM Transactions on Networking., Vol. 11, No. 1,
    pp 17–32, ([https://resources.mpi-inf.mpg.de/d5/teaching/ws03_04/p2p-data/11-18-writeup1.pdf](https://resources.mpi-inf.mpg.de/d5/teaching/ws03_04/p2p-data/11-18-writeup1.pdf)).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Stoica, I., Morris, R., Liben-Nowell, D., Karger, D., Kaashoek, M., Dabek,
    F.，以及Balakrishnan, H. (2003). Chord: *一个用于互联网应用的可扩展对等查找协议*, IEEE/ACM Transactions
    on Networking., 第11卷，第1期，第17–32页，([https://resources.mpi-inf.mpg.de/d5/teaching/ws03_04/p2p-data/11-18-writeup1.pdf](https://resources.mpi-inf.mpg.de/d5/teaching/ws03_04/p2p-data/11-18-writeup1.pdf)).'
- en: Juan Benet. (2014). *IPFS – Content Addressed, Versioned, P2P File System*,
    ([https://arxiv.org/abs/1407.3561](https://arxiv.org/abs/1407.3561)).
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Juan Benet. (2014). *IPFS – 基于内容寻址、版本化、P2P文件系统*, ([https://arxiv.org/abs/1407.3561](https://arxiv.org/abs/1407.3561)).
- en: Part 2 The Design and Implementation of the Federated Learning System
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分 联邦学习系统的设计与实现
- en: In this part, we will explain the implementation principle of the **federated
    learning** (**FL**) system using Python. You will learn how to design the software
    components and code the essential functionalities of both the FL server and the
    client. In addition, you will be able to integrate your own machine learning process
    into the FL system and run and analyze your FL-based applications.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分，我们将使用Python解释**联邦学习**（**FL**）系统的实现原理。您将学习如何设计软件组件并编写FL服务器和客户端的基本功能代码。此外，您还能够将您自己的机器学习过程集成到FL系统中，并运行和分析基于FL的应用程序。
- en: 'This part comprises the following chapters:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 4*](B18369_04.xhtml#_idTextAnchor085), *Federated Learning Server
    Implementation with Python*'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B18369_04.xhtml#_idTextAnchor085), *使用Python实现联邦学习服务器*'
- en: '[*Chapter 5*](B18369_05.xhtml#_idTextAnchor130), *Federated Learning Client-Side
    Implementation*'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B18369_05.xhtml#_idTextAnchor130), *联邦学习客户端实现*'
- en: '[*Chapter 6*](B18369_06.xhtml#_idTextAnchor156), *Running the Federated Learning
    System and Analyzing the Results*'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B18369_06.xhtml#_idTextAnchor156), *运行联邦学习系统并分析结果*'
- en: '[*Chapter 7*](B18369_07.xhtml#_idTextAnchor176), *Model Aggregation*'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B18369_07.xhtml#_idTextAnchor176), *模型聚合*'
