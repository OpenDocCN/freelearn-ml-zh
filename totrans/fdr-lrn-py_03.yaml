- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Workings of the Federated Learning System
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦学习系统的工作原理
- en: This chapter will provide an overview of the architecture, procedure flow, sequence
    of messages, and basics of model aggregation of the **federated learning** (**FL**)
    system. As discussed in [*Chapter 2*](B18369_02.xhtml#_idTextAnchor037), *What
    Is Federated Learning?*, the conceptual basics of the FL framework are quite simple
    and easy to understand. However, the real implementation of the FL framework needs
    to come with a good understanding of both AI and distributed systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将概述联邦学习系统（**FL**）的架构、流程流程、消息序列和模型聚合的基本原理。如[*第二章*](B18369_02.xhtml#_idTextAnchor037)“什么是联邦学习？”中讨论的，FL框架的概念基础非常简单且易于理解。然而，FL框架的真正实现需要具备对AI和分布式系统的良好理解。
- en: The content of this chapter is based on the most standard foundation of FL systems,
    which is used in hands-on exercises later in the book. First, we will introduce
    the building blocks of FL systems, such as an aggregator with an FL server, an
    agent with an FL client, a database server, and communication between these components.
    The architecture introduced in this chapter is designed in a decoupled way so
    that further enhancement to the system will be relatively easier than with an
    FL system that contains everything on one machine. Then, an explanation of the
    flow of the operation of FL from initialization to aggregation will follow.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容基于联邦学习系统最标准的基石，这些基石将在本书后面的实际练习中使用。首先，我们将介绍联邦学习系统的构建块，例如带有联邦学习服务器的聚合器、带有联邦学习客户端的代理、数据库服务器以及这些组件之间的通信。本章介绍的架构以解耦的方式设计，以便对系统的进一步增强将比包含所有内容在一个机器上的联邦学习系统更容易。然后，我们将解释从初始化到聚合的联邦学习操作流程。
- en: Finally, we will examine the way an FL system is scaled with a horizontal design
    of decentralized FL setups.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将探讨如何通过横向设计去中心化的联邦学习设置来扩展联邦学习系统的规模。
- en: 'This chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: FL system architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联邦学习系统架构
- en: Understanding the FL system flow – from initialization to continuous operation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解联邦学习系统流程——从初始化到持续运行
- en: Basics of model aggregation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型聚合的基本原理
- en: Furthering scalability with horizontal design
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过横向设计进一步扩展可伸缩性
- en: FL system architecture
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦学习系统架构
- en: 'FL systems are distributed systems that are dispersed into servers and distributed
    clients. Here, we will define a representative architecture of an FL system with
    the following components: an aggregator with an FL server, an agent with an FL
    client, and a database:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习系统是分散到服务器和分布式客户端的分布式系统。在这里，我们将定义一个具有以下组件的联邦学习系统的代表性架构：带有联邦学习服务器的聚合器、带有联邦学习客户端的代理和数据库：
- en: '**Cluster aggregator** (or **aggregator**): A system with an FL server that
    collects and aggregates **machine learning** (**ML**) models that are trained
    at multiple distributed agents (defined shortly) and creates global ML models
    that are sent back to the agents. This system serves as a *cluster aggregator*,
    or more simply, an *aggregator* of FL systems.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群聚合器**（或**聚合器**）：一个带有联邦学习服务器的系统，它收集和聚合在多个分布式代理（稍后定义）上训练的机器学习模型，并创建全局机器学习模型，这些模型被发送回代理。该系统作为*集群聚合器*，或者更简单地说，作为*联邦学习系统聚合器*。'
- en: '**Distributed agent** (or **agent**): A distributed learning environment with
    an FL client such as a local edge device, mobile application, tablet, or any distributed
    cloud environment where ML models are trained in a distributed manner and sent
    to an aggregator. The agent can be connected to an FL server of the aggregator
    through the FL client-side communications module. The FL client-side codes contain
    a collection of libraries that can be integrated into the local ML application,
    which is designed and implemented by individual ML engineers and data scientists.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式代理**（或**代理**）：一个带有联邦学习客户端（如本地边缘设备、移动应用、平板电脑或任何分布式云环境）的分布式学习环境，在这些环境中以分布式方式训练机器学习模型并将其发送到聚合器。代理可以通过聚合器的联邦学习客户端通信模块连接到聚合器的联邦学习服务器。联邦学习客户端端的代码包含一系列库，这些库可以集成到由个别机器学习工程师和数据科学家设计和实现的本地机器学习应用中。'
- en: '**Database server** (or **database**): A database and its server to store the
    data related to the aggregators, agents, and global and local ML models and their
    performance metrics. The database server handles the incoming queries from the
    aggregators and sends the necessary data back to the aggregators. Agents do not
    have to be connected to the database server directly for the simplicity of the
    FL system design.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 3.1* shows the typical overall architecture consisting of a single
    cluster aggregator and a database server, as well as multiple distributed agents:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Overall architecture of an FL system'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.1 – Overall architecture of an FL system
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: One advantage of the FL system’s architecture is that users do not have to send
    private raw data to the server, especially that owned by a third party. Instead,
    they only have to send locally trained models to the aggregator. The locally trained
    models can be in a variety of formats such as the weights of the entire ML models,
    the changes of weights (gradients), or even a subset of them. Another advantage
    includes reducing the communication load because the users only have to exchange
    models that are usually much lighter than raw data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Cluster aggregators
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A cluster aggregator consists of an FL server module, FL state manager module,
    and model aggregation module, as in *Figure 3.1*. We just call a cluster aggregator
    with an FL server an aggregator. While these modules are the foundation of the
    aggregator, advanced modules can be added to ensure further security and flexibility
    of the aggregation of ML models. Some of the advanced modules are not implemented
    in the `simple-fl` GitHub repository provided with this book with exercises because
    the main purpose of this book is to understand the basic structure and system
    flow of the FL system. In the aggregator system, the following modules related
    to the FL server, the state manager of FL, and model aggregation are the keys
    to implementing the aggregator-side functionalities.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '**FL server module**: There are three primary functionalities for the FL server
    module, which include the communication handler, system configuration handler,
    and model synthesis routine:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Communication handler**: Serves as a module of the aggregator that supports
    *communications with agents and the database*. Usually, this module accepts polling
    messages from agents and sends responses back to them. The types of messages they
    receive include the registration of agents themselves with secure credentials
    and authentication mechanisms, the initialization of the ML model that serves
    as an *initial model* for the future aggregation process, confirmation about whether
    or not agents participate in a round, and local ML models that are retrained at
    distributed agents such as mobile devices and local edge machines. The communication
    handler can also query the database server in order to access the system data
    and ML models in the database, as well as push and store this data and those models
    once the aggregator receives or creates new models. This module can utilize HTTP,
    WebSocket, or any other communication framework for its implementation.'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通信处理器**：作为聚合器的一个模块，支持与代理和数据库的*通信*。通常，此模块接受来自代理的轮询消息并向它们发送响应。他们接收的消息类型包括使用安全凭证和认证机制进行代理注册、初始化作为未来聚合过程*初始模型*的ML模型、确认代理是否参与某一轮次以及重新训练于分布式代理（如移动设备和本地边缘机器）的本地ML模型。通信处理器还可以查询数据库服务器，以访问系统数据以及数据库中的ML模型，并在聚合器接收或创建新模型后推送和存储这些数据和模型。此模块可以使用HTTP、WebSocket或任何其他通信框架来实现其实现。'
- en: '**System configuration handler**: Deals with the *registration of agents* and
    tracking the connected agents and their statuses. The aggregator needs to be aware
    of the connections and registration statuses of the agents. If the agents are
    registered with an established authentication mechanism, they will accept the
    messages and process them accordingly. Otherwise, this module will go through
    the authentication process, such as validating the token sent from the agent,
    so that next time this agent is connected to the FL server, the system will recognize
    the agent properly.'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统配置处理器**：处理代理的*注册*和跟踪连接的代理及其状态。聚合器需要了解代理的连接和注册状态。如果代理使用已建立的认证机制进行注册，它们将接受消息并相应地处理它们。否则，此模块将执行认证过程，例如验证从代理发送的令牌，以便下次此代理连接到FL服务器时，系统能够正确识别该代理。'
- en: '**Model synthesis routine**: Supports checking the collection status of the
    local ML models and aggregating them once the collection criteria are satisfied.
    Collection criteria include the number of local models collected by the connected
    agents. For example, aggregation can happen when 80% of the connected agents send
    the trained local models to the aggregator. One of the design patterns to do so
    is to periodically check the number of ML models uploaded by the agents, which
    keep running while the FL server is up and running. The model synthesis routine
    will access the database or local buffer periodically to check the status of the
    local model collection and aggregate those models, to produce the global model
    that will be stored in the database server and sent back to the agents.'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型合成例程**：支持检查本地ML模型的收集状态，并在满足收集标准后进行聚合。收集标准包括连接的代理收集的本地模型数量。例如，当80%的连接代理将训练好的本地模型发送到聚合器时，就会发生聚合。实现这一目标的设计模式之一是定期检查代理上传的ML模型数量，这些操作在FL服务器运行时持续进行。模型合成例程将定期访问数据库或本地缓冲区，以检查本地模型收集的状态并聚合这些模型，以生成将存储在数据库服务器中并发送回代理的全局模型。'
- en: '**FL state manager**: A state manager keeps track of the state information
    of an aggregator and connected agents. It stores volatile information for an aggregator,
    such as local and global models delivered by agents, cluster models pulled from
    the database, FL round information, or agents connected to the aggregator. The
    buffered local models are used by the model aggregation module to generate a global
    model that is sent back to each active agent connected to the aggregator.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FL状态管理器**：状态管理器跟踪聚合器和连接的代理的状态信息。它存储聚合器的易失性信息，例如代理提供的本地和全局模型、从数据库拉取的集群模型、FL轮次信息或连接到聚合器的代理。缓冲的本地模型由模型聚合模块使用，以生成发送回连接到聚合器的每个活动代理的全局模型。'
- en: '**Model aggregation module**: The model aggregation module is a collection
    of the model aggregation algorithms introduced in the *Basics of model aggregation*
    section in this chapter and [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176), *Model
    Aggregation*, in further depth. The most typical aggregation algorithm is *federated
    averaging*, which averages the weights of the collected ML models, considering
    the number of samples that each model has used for its local training.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型聚合模块**：模型聚合模块是本章“模型聚合基础”部分和[第7章](B18369_07.xhtml#_idTextAnchor176)“模型聚合”中介绍的模型聚合算法的集合。最典型的聚合算法是*联邦平均*，它平均收集到的ML模型的权重，考虑到每个模型用于其本地训练的样本数量。'
- en: Distributed agents
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式代理
- en: 'A distributed agent consists of an FL client module that includes the communication
    handler and client libraries as well as local ML applications connected to the
    FL system through the FL client libraries:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式代理由一个FL客户端模块组成，该模块包括通信处理程序和客户端库，以及通过FL客户端库连接到FL系统的本地ML应用程序：
- en: '**FL client module**: There are primarily four key functionalities for the
    FL client module, which include a communication handler, agent participation handler,
    model exchange routine, and client libraries:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FL客户端模块**：FL客户端模块主要有四个关键功能，包括通信处理程序、代理参与处理程序、模型交换例程和客户端库：'
- en: '**Communication handler**: Serves as a channel to communicate with the aggregator
    that is assigned to the agent. The message sent to the aggregator includes the
    registration payload of the agent itself and an initial model that will be the
    basis of aggregated models. The message also contains locally trained models together
    with the performance data of those models. This module supports both *push* and
    *polling* mechanisms and can utilize HTTP or WebSocket frameworks for its implementation.'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通信处理程序**：作为与分配给代理的聚合器通信的通道。发送给聚合器的消息包括代理本身的注册有效载荷和一个将成为聚合模型基础的初始模型。该消息还包含本地训练的模型及其性能数据。此模块支持*推送*和*轮询*机制，并可以利用HTTP或WebSocket框架来实现其实现。'
- en: '**FL participation handler**: Deals with the agent participation in the FL
    process and cycle by sending an aggregator a message including the agent information
    itself to be registered in the FL platform and initialize the FL process if needed.
    The response message will set the agent up for the continuous and ongoing FL process
    and often includes the most updated global model for the agent to utilize and
    train locally.'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FL参与处理程序**：通过向聚合器发送包含要注册在FL平台上的代理信息本身的消息来处理代理在FL过程和周期中的参与。响应消息将设置代理以进行持续和持续的FL过程，并且通常包括代理可以利用和本地训练的最新全局模型。'
- en: '**Model exchange routine**: Supports a synchronizing functionality that constantly
    checks whether a new global model is available or not. If the new global model
    is available, this module downloads the global model from the aggregator and the
    global model replaces the local model if needed. This module also checks the client
    state and sends the retrained model if the local training process is done.'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型交换例程**：支持一个同步功能，该功能不断检查是否有新的全局模型可用。如果新的全局模型可用，此模块将从聚合器下载全局模型，并在需要时用全局模型替换本地模型。此模块还会检查客户端状态，并在本地训练过程完成后发送重新训练的模型。'
- en: '**Client libraries**: Include administrative libraries and general FL client
    libraries:'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端库**：包括管理库和通用FL客户端库：'
- en: The administrative libraries are used when registering the initial model that
    will be used by other agents. Any configuration changes for FL systems can be
    also requested by administrative agents that have higher control capabilities.
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当注册其他代理将使用的初始模型时使用管理库。也可以由具有更高控制能力的行政代理请求FL系统的任何配置更改。
- en: General FL client libraries provide basic functionalities such as starting FL
    client core threads, sending local models to an aggregator, saving models in some
    specific location on the local machine, manipulating the client state, and downloading
    the global models. This book mainly talks about this general type of library.
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用FL客户端库提供基本功能，例如启动FL客户端核心线程、将本地模型发送到聚合器、在本地机器的特定位置保存模型、操作客户端状态以及下载全局模型。本书主要讨论这种通用类型的库。
- en: '**Local ML engine and data pipelines**: These parts are designed by individual
    ML engineers and scientists and can be independent of the FL client functionalities.
    This module has an ML model itself that can be put into play immediately by the
    user for potentially more accurate inference, a training and testing environment
    that can be plugged into the FL client libraries, and for the implementation of
    data pipelines. While the aforementioned module and libraries can be generalized
    and provided as **application programming interfaces** (**APIs**) or libraries
    for any ML applications, this module is unique depending on the requirements of
    AI applications to be developed.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地ML引擎和数据管道**：这些部分由个别ML工程师和科学家设计，可以独立于FL客户端功能。此模块本身有一个ML模型，用户可以立即使用它进行更准确的推理，一个可以插入FL客户端库的培训和测试环境，以及数据管道的实现。虽然上述模块和库可以通用并提供为任何ML应用程序的**应用程序编程接口**（**API**）或库，但此模块根据要开发的AI应用程序的需求是独特的。'
- en: Database servers
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库服务器
- en: 'A database server consists of a database query handler and a database, as storage.
    The database server can reside on the server side, such as on the cloud, and is
    tied closely to aggregators, while the recommended design is to separate this
    database server from aggregator servers to decouple the functionalities to enhance
    the system’s simplicity and resilience. The functionality of the database query
    handler and sample database tables are as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库服务器由数据库查询处理器和数据库组成，作为存储。数据库服务器可以位于服务器端，例如在云上，并且与聚合器紧密相连，而推荐的设计是将此数据库服务器与聚合器服务器分开，以解耦功能，增强系统的简单性和弹性。数据库查询处理器和示例数据库表的功能如下：
- en: '**Database query handler**: Accepts the incoming requests from an aggregator
    and sends the requested data and ML models back to the aggregator.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库查询处理器**：接受来自聚合器的传入请求，并将所需数据和ML模型发送回聚合器。'
- en: '**Database**: Stores all the related information to FL processes. We list some
    potential entries for the database here:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库**：存储所有与FL过程相关的信息。我们在此列出数据库的一些潜在条目：'
- en: '**Aggregator information**: This aggregator-related information includes the
    ID of the aggregator itself, the IP address and various port numbers, system registered
    and updated times, and system status. In addition, this entry can include model
    aggregation-related information, such as the round of FL and its information and
    aggregation criteria.'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合器信息**：此聚合器相关信息包括聚合器本身的ID、IP地址和各种端口号、系统注册和更新时间以及系统状态。此外，此条目还可以包括模型聚合相关信息，例如FL的轮次及其信息以及聚合标准。'
- en: '**Agent information**: This agent-related information includes the ID of the
    agent itself, the IP address and various port numbers, system registered and updated
    times, and system status. This entry can also contain the opt-in/out status that
    is used for synchronous FL (explained in the *Synchronous and asynchronous FL*
    section in this chapter) and a flag to record whether the agent has been a bad
    actor in the past (for example, involved in poisoning attacks, or very slow at
    returning results).'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理信息**：此代理相关信息包括代理本身的ID、IP地址和各种端口号、系统注册和更新时间以及系统状态。此条目还可以包含用于同步FL（在本章的*同步和异步FL*部分中解释）的opt-in/out状态，以及一个标志来记录代理是否在过去有过不良行为（例如，参与投毒攻击，或返回结果非常慢）。'
- en: '**Base model information**: Base model information is used for the registration
    of initial ML models whose architecture and information are used for the entire
    process of FL rounds.'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础模型信息**：基础模型信息用于注册初始ML模型，其架构和信息用于FL轮次的整个流程。'
- en: '**Local models**: The information of local models includes the model ID that
    is unique to individual ML models, generated time of the model, agent ID that
    uploaded the model, aggregator ID that received the model from the agent, and
    so on. Usually, the model ID is uniquely mapped to the location of the actual
    ML model file that can be stored in the database server or in some cloud storage
    services such as S3 buckets of Amazon Web Services, and so on.'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地模型**：本地模型的信息包括唯一标识个别ML模型的模型ID、模型的生成时间、上传模型的代理ID、从代理接收模型的聚合器ID等。通常，模型ID唯一映射到实际ML模型文件的存储位置，这些文件可以存储在数据库服务器或某些云存储服务中，例如亚马逊网络服务的S3存储桶等。'
- en: '**Cluster global models**: The information of the cluster global models is
    similar to what local models could record in the database including the model
    ID, aggregator ID, generated time of the model, and so on. Once the aggregated
    model is created by an aggregator, the database server will accept the global
    models and store them in the database server or any cloud storage services. Any
    global model can be requested by an aggregator.'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance data**: The performance of the local and global models can be
    tracked, as metadata attached to those models. This performance data will be used
    to ensure that the aggregated model performs well enough before it is actually
    deployed to the user ML application.'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: In the code sample of the `simple-fl` repository, only the database tables related
    to the local models and cluster models are covered to simplify the explanation
    of the entire FL process.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Now that the basic architecture of the FL system has been introduced, next,
    we will talk about how to enhance the FL system’s architecture if the computation
    resources are limited on the agent-side devices.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Intermediate servers for low computational agent devices
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, the computational capability of local user devices is limited – ML
    training may be difficult in those devices, but inference or predictions can be
    made possible by just downloading the global model. In these cases, an FL platform
    may be able to set up an additional intermediate server layer, such as with smartphones,
    tablets, or edge servers. For example, in a healthcare AI application, users manage
    their health information on their smart watches, which can be transferred to their
    smart tablets or synched with laptops. In those devices, it is easy to retrain
    ML models and integrate the distributed agent functionalities.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the system architecture needs to be modified or redesigned depending
    on the applications into which the FL system is integrated, and the concept of
    intermediate servers can be applied using distributed agents to realize FL processes.
    We do not have to modify the interactions and communication mechanisms between
    the aggregators and the intermediate servers. Just by implementing APIs between
    the user devices and the intermediate servers, FL will be possible in most use
    cases.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.2* illustrates the interaction between the aggregators, intermediate
    servers, and user devices:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – An FL system with intermediate servers'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_02.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.2 – An FL system with intermediate servers
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned about the basic architecture and components of an FL
    system, let us look into how an FL system operates in the following section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the FL system flow – from initialization to continuous operation
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each distributed agent belongs to an aggregator that is managed by an FL server,
    where ML model aggregation is conducted to synthesize a global model that is going
    to be sent back to the agents. An agent uses its local data to train an ML model
    and then uploads the trained model to the corresponding aggregator. The concept
    sounds straightforward, so we will look into a bit more detail to realize the
    entire flow of those processes.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: We also define a **cluster global model**, which we simply call a **cluster
    model** or **global model**, which is an aggregated ML model of local models collected
    from distributed agents.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: In the next two chapters, we will guide you on how to implement the procedure
    and sequence of messages discussed in this chapter. However, some of the system
    operation perspectives, such as an aggregator or agent system registration in
    the database, are not introduced in the code sample of the `simple-fl` repository
    in order to simplify the explanation of the entire FL process.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Initialization of the database, aggregator, and agent
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The sequence of the initialization processes is quite simple. The initialization
    and registration processes need to happen in the order of database, aggregator,
    and agents. The overall registration sequence of an aggregator and an agent with
    a database is depicted in *Figure 3.3* as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – The process of aggregator and agent registration in the database
    server'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_03.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.3 – The process of aggregator and agent registration in the database
    server
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the initialization and registration procedure of each component in
    the FL system:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '**Database server initialization**: The first step of the operation of an FL
    system is to initiate the database server. There are some simple frameworks that
    are provided by multiple organizations that do not include databases or database
    servers. However, in order to maintain the process of federating the ML models,
    it is recommended that you use a database, even a lightweight one such as an SQLite
    database.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aggregator initialization and registration**: An aggregator should be set
    up and running before any agents start running and uploading the ML models. When
    the aggregator starts running and first gets connected to the database server,
    the registration process happens automatically by also checking whether the aggregator
    is safe to be connected. If it fails to go through the registration process, it
    receives the registration failure message sent back from the database. Also, in
    case the aggregator is trying to connect to the database again after losing the
    connection to the database, the database server always checks whether the aggregator
    has already been registered or not. If this is the case, the response from the
    database server includes the system information of the registered aggregator so
    that the aggregator can start from the point where it left off. The aggregator
    may need to publish an IP address and port number for agents to be connected if
    it uses HTTP or WebSocket.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合器初始化和注册**：在代理开始运行并上传机器学习模型之前，应该设置并运行聚合器。当聚合器开始运行并首次连接到数据库服务器时，注册过程会自动进行，同时也会检查聚合器是否安全连接。如果注册过程失败，它会收到数据库发送回来的注册失败消息。此外，如果聚合器在失去与数据库的连接后再次尝试连接到数据库，数据库服务器会检查聚合器是否已经注册。如果是这种情况，数据库服务器响应中会包含已注册聚合器的系统信息，以便聚合器可以从它停止的地方开始。如果聚合器使用HTTP或WebSocket，它可能需要发布IP地址和端口号以便代理连接。'
- en: '**Agent initialization and registration**: Usually, if an agent knows the aggregator
    that the agent wants to connect to, the registration is similar to how an aggregator
    connects to a database server. The connection process should be straightforward
    enough to just send a participation message to that aggregator using an IP address,
    the port number of the aggregator (if we are using some frameworks such as HTTP
    or WebSocket), and an authentication token. In case the agent is trying to connect
    to the aggregator again after losing the connection to the aggregator, the database
    server always checks whether the agent already has been registered or not. If
    the agent is already registered, the response from the database server includes
    the system information of the registered agent so that the agent can start from
    the point where it was disconnected from the aggregator.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理初始化和注册**：通常情况下，如果代理知道它想要连接的聚合器，注册过程类似于聚合器连接到数据库服务器的方式。连接过程应该足够简单，只需使用IP地址、聚合器的端口号（如果我们使用某些框架，如HTTP或WebSocket）以及一个认证令牌向该聚合器发送一个参与消息。如果代理在失去与聚合器的连接后再次尝试连接到聚合器，数据库服务器会检查代理是否已经注册。如果代理已经注册，数据库服务器响应中会包含已注册代理的系统信息，以便代理可以从与聚合器断开连接的点开始。'
- en: In particular, when it receives the participation message from the agent, the
    aggregator goes through the following procedure, as in *Figure 3.4*. The key process
    after receiving the participation request is (i) checking whether the agent is
    trusted or not, or whether the agent is already registered or not, and (ii) checking
    whether the initial global model is already registered or not. If (i) is met,
    the registration process keeps going. If the (initial) global model is already
    registered, the agent will be able to receive the global model and start using
    that global model for the local training process on the agent side.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，当它收到代理的参与消息时，聚合器会按照*图3.4*中的流程进行操作。接收参与请求后的关键过程是（i）检查代理是否可信，或者代理是否已经注册，以及（ii）检查初始全局模型是否已经注册。如果（i）成立，注册过程将继续。如果（初始）全局模型已经注册，代理将能够接收全局模型并开始使用该全局模型在代理端进行本地训练过程。
- en: 'The agent participation and registration process at an aggregator side is depicted
    in *Figure 3.4*:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚合器端，代理的参与和注册过程如*图3.4*所示：
- en: '![Figure 3.4 – The registration process of an agent by an aggregator'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.4 – 代理通过聚合器的注册过程'
- en: '](img/B18369_03_04_New.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_03_04_New.jpg]'
- en: Figure 3.4 – The registration process of an agent by an aggregator
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 代理通过聚合器的注册过程
- en: Now that we understand the initialization and registration process of the FL
    system components, let us move on to the basic configuration of the ongoing FL
    process, which is about uploading the initial ML model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了FL系统组件的初始化和注册过程，让我们继续到正在进行的FL过程的基本配置，这涉及到上传初始机器学习模型。
- en: Initial model upload process by initial agent
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next step in running an FL process is to register the initial ML model whose
    architecture will be used in the entire and continuous process of FL by all the
    aggregators and agents. The initial model can be distributed by the company that
    owns the ML application and FL servers. They’ll likely provide the initial base
    model as part of the aggregator configuration.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'We call the initial ML model used as a reference for model aggregation a **base
    model**. We also call the agent that uploads the initial base model an *initial
    agent*. The base model info could include the ML model itself as well as the time
    it was generated and the initial performance data. That being said, the process
    of initializing the base model can be seen in *Figure 3.5*:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Base model upload process for the initial agent'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_05.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.5 – Base model upload process for the initial agent
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Now, the FL process is ready to be conducted. Next, we will learn about the
    FL cycle, which is a very core part of the FL process.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Overall FL cycle and process of the FL system
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will only give an example with a single agent and aggregator,
    but in real cases and operations, the agent environments are various and dispersed
    into distributed devices. The following is the list of the processes for how the
    local models are uploaded, aggregated, stored, and sent back to agents as a global
    model:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: The agents other than the initial agent will request the global model, which
    is an updated aggregated ML model, in order to deploy it to their own applications.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the agent gets the updated model from the aggregator and deploys it, the
    agent retrains the ML model locally with new data that is obtained afterward to
    reflect the freshness and timeliness of the data. An agent can also participate
    in multiple rounds with different data to absorb its local examples and tendencies.
    Again, this local data will not be shared with the aggregator and stays local
    to the distributed devices.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After retraining the local ML model (which, of course, has the same architecture
    as the global or base model of the FL), the agent calls an FL client API to send
    the model to the aggregator.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The aggregator receives the local ML model and pushes the model to the database.
    The aggregator keeps track of the number of collected local models and will keep
    accepting the local models as long as the federation round is open. The round
    can be closed with any defined criteria, such as the aggregator receiving enough
    ML models to be aggregated. When the criteria are met, the aggregator aggregates
    the local models and produces an updated global model that is ready to be sent
    back to the agent.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: During that process, agents constantly poll the aggregator on whether the global
    model is ready or not, or in some cases, the aggregator may push the global model
    to the agents that are connected to the aggregator, depending on the communications
    system design and network constraints. Then, the updated model is sent back to
    the agent.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After receiving the updated global model, the agent deploys and retrains the
    global model locally whenever it is ready. The whole process described is repeated
    until the termination criteria are met for the FL to end. In some cases, there
    are no termination conditions to stop this FL cycle and retraining process so
    that the global model constantly keeps learning about the latest phenomena, current
    trends, or user-related tendencies. FL rounds can just be stopped manually in
    preparation for some evaluation before a rollout.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 3.6* shows the overall process of how FL is continuously conducted
    between an agent, an aggregator, and a database typically:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Overview of the continuous FL cycle'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_06.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.6 – Overview of the continuous FL cycle
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we understand the overall procedure of the FL process, we will look
    into the different round management approaches in the FL process next: synchronous
    FL and asynchronous FL.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous and asynchronous FL
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the model aggregation happens at the aggregator, there are multiple criteria
    related to how many local models it needs to collect from which agents. In this
    section, we will briefly talk about the differences between synchronous and asynchronous
    FL, which have been discussed in a lot of literature, such as https://iqua.ece.toronto.edu/papers/ningxinsu-iwqos22.pdf,
    so please refer to it to learn about these concepts further.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous FL
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Synchronous FL requires the aggregator to select the agents that need to send
    the local models for each round in order to proceed with the model aggregation.
    This synchronous FL approach is simple to design and implement and suitable for
    FL applications that require a clear selection of agents. However, if the number
    of agents becomes too large, the aggregator may have to wait for a long time to
    wrap up the current round, as the computational capability of the agents could
    vary and some of them may have problems uploading or fail to upload their local
    models. Thus, some of the agents can become slow or totally dysfunctional when
    sending their models to the aggregator. These slow agents are known as *stragglers*
    in distributed ML, which motivates us to use the asynchronous FL mode.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous FL
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Asynchronous FL does not require the aggregator to select the agents that have
    to upload their local models. Instead, it opens the door for any trusted agents
    to upload the model anytime. Furthermore, it is fine to wrap up the federation
    round whenever the aggregator wants to generate the global model, with or without
    criteria such as the minimum number of local models that needs to be collected,
    or some predefined interval or deadline for which the aggregator needs to wait
    to receive the local models from the agents until the aggregation for that round
    happens. This asynchronous FL approach gives the FL system much more flexibility
    for model aggregation for each FL round, but the design may be more complicated
    than the simple synchronous aggregation framework.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: When managing the FL rounds, you need to consider the practicalities of running
    rounds, such as scheduling and dealing with delayed responses, the minimum levels
    of participation required, the details of example stores, using the downloaded
    or trained models for improved inference in the applications on the edge devices,
    and dealing with bad or slow agents.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: We will look into the FL process and procedure flow next, focusing on the aggregator
    side.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: The aggregator-side FL cycle and process
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An aggregator has two threads running to accept and cache the local models and
    aggregate the collected local ML models. In this section, we describe those procedures.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Accepting and caching local ML models
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The aggregator side process of accepting and caching local ML models is depicted
    in *Figure 3.7* and explained as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: The aggregator will wait for a local ML model to be uploaded by an agent. This
    method sounds like asynchronous FL. However, if the aggregator has already decided
    which agents to accept models from, it just needs to exclude the model uploads
    sent by undesired agents. Some other system or module may have already told the
    undesired agents not to participate in the round as well.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once an ML model is received, the aggregator checks whether the model is uploaded
    by the trusted agents or not. Also, if the agent that uploads the local model
    is not listed in the agents that the FL operator wants to accept, the aggregator
    will discard the model. Furthermore, an aggregator needs to have a mechanism to
    only filter the valid models – otherwise, there is a risk of poisoning the global
    model and messing up the entire FL process.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the uploaded local ML model is valid, the aggregator will push the model
    to the database. If the database resides on a different server, the aggregator
    will package the model and send it to the database server.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While the uploaded models are stored in the database, they should be buffered
    in the memory of the state manager of the aggregator in an appropriate format,
    such as NumPy arrays.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This procedure keeps running until the termination conditions are satisfied
    or the operator of the FL system opts to stop the process. *Figure 3.7* depicts
    the procedure of accepting and caching local ML models:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – Procedure for accepting and caching local ML models'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_07.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.7 – Procedure for accepting and caching local ML models
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the local ML models are accepted and cached, the FL system moves on to
    the next procedure: aggregating the local models.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Aggregating local ML models
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The aggregator-side procedure of aggregating local ML models depicted in *Figure
    3.8* is as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'The aggregator constantly checks whether the aggregation criteria are satisfied.
    The typical aggregation criteria are as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of local models collected so far in this FL round. For example, if
    the number of agents is 10 nodes, after 8 nodes (meaning 80% nodes) report the
    locally trained models, the aggregator starts aggregating the models.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The combination of the number of collected models and the time that the FL round
    has spent. This can automate the aggregation process and prevent systems from
    getting stuck.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the aggregation criteria are met, the aggregator starts a model aggregation
    process. Usually, federated averaging is a very typical but powerful aggregation
    method. Further explanation of the model aggregation methods is in the *Basics
    of model aggregation* section of this chapter and in [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176),
    *Model Aggregation*. The aggregated model is defined as a global model in this
    FL round.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a case where time for the FL round has expired and not enough agents that
    participated in the round have uploaded a model, the round can be abandoned or
    forced to conduct aggregation for the local models collected so far.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Once the model aggregation is complete, the aggregator pushes the aggregated
    global model to the database. If the database resides on a different server, the
    aggregator will package the global model and send it to the database server.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, the aggregator sends the global model to all the agents, or when the agents
    poll to check whether the global model is ready, the aggregator will notify the
    agent that the global model is ready and put it in the response message to the
    agents.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the whole process of model aggregation, the aggregator updates the number
    of the FL round by just incrementing it.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 3.8* shows the aggregator’s process from checking the aggregation criteria
    to synthesizing the global model when enough models are collected:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – Model synthesis routine: aggregating local ML models'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_08.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.8 – Model synthesis routine: aggregating local ML models'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Aggregating local models to generate the global model has been explained. Now,
    let us look into the agent-side FL cycle, including the retraining process of
    the local ML models.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: The agent-side local retraining cycle and process
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the distributed agent, the following state transition happens and is repeated
    for the continuous operation of the FL cycle:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: In the state of `waiting_gm`, the agent polls the aggregator to receive any
    updates related to the global model. Basically, a polling method is used to regularly
    query the updated global model. However, under some specific settings, an aggregator
    can push the updated global model to all agents.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`gm_ready` is the state after the global model is formed by the aggregator
    and downloaded by the agent. The model parameters are cached in the agent device.
    The agent replaces its local ML model with the downloaded global model. Before
    completely replacing the local model with the downloaded model, the agent can
    check whether the output of the global model is sufficiently performant for the
    local ML engine. If the performance is not what is expected, the user can keep
    using the old model locally until it receives the global model that has the desired
    performance.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, in the `training` state, the agent can locally train the model in order
    to maximize its performance. The trained model is saved in a local data storage
    where training examples are kept. The FL client libraries of the agent ascertain
    its readiness to manipulate the local model that can be protected with asynchronous
    function access.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the local model is trained, the agent checks whether the new global model
    has been sent to the agent or not. If the global model has arrived, then the locally
    trained ML model is discarded and goes back to the `gm_ready` state.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After local training, the agent proceeds with the `sending` state to send the
    updated local model back to the aggregator, and then, the agent goes back to the
    `waiting_gm` state.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 3.9* depicts the state transition of an agent to adapt and update the
    ML model:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 – Agent-side state transition to adapt and update the ML model'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_09.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.9 – Agent-side state transition to adapt and update the ML model
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Next, we touch on a model interpretation based on deviation from the baseline
    outputs that are used for anomaly detection and preventing model degradation.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Model interpretation based on deviation from baseline outputs
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can also provide an interpretation framework by looking at the output of
    each local model. The following procedure can be considered to ensure the local
    model is always good to use and can be deployed in production:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Obtain the most recent ML output generated by an agent as well as a baseline
    output that can be a typical desired output prepared by users. The baseline output
    could include an average output based on the past windows or reference points
    defined by an operator, subject expert, or rule-based algorithm.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The deviation between the output of the local model and the baseline output
    is computed.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An anomaly or performance degradation can be detected by checking whether the
    deviation exceeds the operator-specified threshold. If an anomaly is detected,
    an alarm can be sent to an operator to indicate a fault or that the ML model is
    in an anomalous state.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that the process of the FL has been explained, let us look into the basics
    of model aggregation, which comprise the critical part of FL.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Basics of model aggregation
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Aggregation is a core concept within FL. In fact, the strategies employed to
    aggregate models are the key theoretical driver for the performance of FL systems.
    The purpose of this section is to introduce the high-level concepts of aggregation
    within the context of an FL system – the underlying theory and examples of advanced
    aggregation strategies will be discussed in greater depth in [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176),
    *Model Aggregation*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: What exactly does it mean to aggregate models?
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s revisit the aggregator-side cycle discussed in the *Understanding the
    FL system flow – from initialization to continuous operation* section, at the
    point in the process where the agents assigned to a certain aggregator have finished
    training locally and have transmitted these models back to this aggregator. The
    goal of any aggregation strategy, or any way of aggregating these models together,
    is to produce new models that gradually increase in performance across all of
    the data collected by the constituent agents.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: An important point to remember is that FL is, by definition, a restricted version
    of the distributed learning setting, in which the data collected locally by each
    agent cannot be directly accessed by other agents. If this restriction were not
    in place, a model could be made to perform well trivially on all of the data by
    collecting the data from each agent and training on the joint dataset; thus, it
    makes sense to treat this *centrally-trained* model as the target model for an
    FL approach. At a high level, we can consider this unrestricted distributed learning
    scenario as aggregation before model training (where in this case, aggregation
    refers to combining the data from each agent). Because FL does not allow data
    to be accessed by other agents, we consider the scenario as aggregation after
    model training instead; in this context, aggregation refers to the combination
    of the intelligence captured by each of the trained models from their differing
    local datasets. To summarize, the goal of an aggregation strategy is to combine
    models in a way that eventually leads to a generalized model whose performance
    approaches that of the respective centrally trained model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: FedAvg – Federated averaging
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To make some of these ideas more concrete, let’s take an initial look into
    one of the most well-known and straightforward aggregation strategies, known as
    **Federated Averaging** (**FedAvg**). The FedAvg algorithm is performed as follows:
    let ![](img/B18369_03_F01.png) be the parameters of the models from ![](img/B18369_03_F02.png)
    agents, each with a local dataset size of ![](img/B18369_03_F03.png). Also, ![](img/B18369_03_F04.png)
    is the total dataset size defined as ![](img/B18369_03_F05.png). Then, FedAvg
    returns the following ML model as the aggregated model:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18369_03_F06.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: Essentially, we perform FedAvg over a set of models by taking the weighted average
    of the models, with weights proportional to the size of the dataset used to train
    the model. As a result, the types of models to which FedAvg can be applied are
    models that can be represented as some set of parameter values. Deep neural networks
    are currently the most notable of these kinds of models – most of the results
    analyzing the performance of FedAvg work with deep learning models.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'It is rather surprising that this relatively simple approach can lead to generalization
    in the resulting model. We can visually examine what FedAvg looks like within
    a toy two-dimensional parameter space to observe the benefits of the aggregation
    strategy:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – Two-dimensional parameter space with local models from two
    agents (the circle and square) and a target model (the black x)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_10.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.10 – Two-dimensional parameter space with local models from two agents
    (the circle and square) and a target model (the black x)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider a case where we have two newly initialized models (the circle
    and square points) belonging to separate agents. The space in the preceding figure
    represents the parameter space of the models, where each toy model is defined
    by two parameters. As the models are trained, these points will move in the parameter
    space – the goal is to approach a local optimum in the parameter space, generally
    corresponding to the aforementioned centrally trained model:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – Change in local model parameters without aggregation'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_11.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.11 – Change in local model parameters without aggregation
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'Each model converges to separate dataset-specific optima (two x points from
    the circle and square) that do not generalize. Because each agent only has access
    to a subset of the data, the local optima reached by training each model locally
    will differ from the true local optima; this difference depends on how similar
    the underlying data distributions are for each agent. If the models are only trained
    locally, the resulting models will likely not generalize over all of the data:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12 – Adding aggregation moves the local model parameters to the
    average for both models at each step, leading to convergence at the target model'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_12.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.12 – Adding aggregation moves the local model parameters to the average
    for both models at each step, leading to convergence at the target model
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Applying FedAvg at each movement step allows us to create an aggregate model
    that eventually comes close to the true local optima in the parameter space.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: This example displays the basic capability of FedAvg to produce generalized
    models. However, working with real models (such as highly parameterized deep learning
    models) introduces additional complexity that is handled by FedAvg but not by
    simpler approaches. For example, we might wonder why we don’t simply fully train
    each local model and only average at the end; while this approach would work in
    this toy case, it has been observed that only averaging once with real models
    leads to poor performance across all of the data. The FedAvg process allows for
    a more robust way to reach the generalized model within high-dimension parameter
    spaces.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: This section only aims to give an overview of aggregation in FL; [*Chapter 7*](B18369_07.xhtml#_idTextAnchor176),
    *Model Aggregation*, contains more detailed explanations and examples for aggregation
    in different scenarios.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: We now understand the entire process of how the FL system works with basic model
    aggregation. In some applications, the FL system may have to support a huge number
    of agents to realize its scalability. The following section will give you some
    idea about how to scale more smoothly, especially with a decentralized horizontal
    design.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Furthering scalability with horizontal design
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look into how to further scalability when we need to
    support a large number of devices and users.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: There are practical cases where control, ease of maintenance and deployment,
    and low communication overhead are provided by centralized FL. If the number of
    agents is not large, it makes more sense to stick to centralized FL than decentralized
    FL. However, when the number of participating agents becomes quite large, it may
    be worth looking into horizontal scaling with a decentralized FL architecture.
    The latest developments of auto-scaling frameworks these days, such as the **Kubernetes**
    framework (https://kubernetes.io/), can be a nice integration with the topic that
    is discussed in this section, although actual integration and implementation with
    Kubernetes is beyond the scope of this book.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal design with semi-global model
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There will be some use cases where many aggregators are needed to cluster groups
    of agents and create a global model on top of those many aggregators. Google uses
    a centralized approach for this, as in the paper *Towards Federated Learning at
    Scale*, while setting up a centralized node for managing multiple aggregators
    may have some resilience issues. The idea is simple: periodically aggregate all
    the cluster models at some central master node.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, we can realize the decentralized way of aggregating cluster
    models created by multiple aggregators. The architecture for that is based on
    two crucial ideas:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Model aggregation conducted among individual cluster aggregators without master
    nodes
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-global model synthesis to aggregate cluster models generated by other aggregators
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To create semi-global models, decentralized cluster aggregators exchange their
    aggregated cluster models with each other and approximate optimal global models.
    The cluster aggregators can also use a database to periodically collect other
    cluster models to generate the semi-global models. This framework allows for the
    absorption of training results from diverse sets of users dispersed across many
    aggregators by synthesizing the most updated global models without a master node
    concept.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Based on this decentralized architecture, the robustness of the entire FL system
    can be enhanced, as the semi-global model can be independently computed at each
    cluster aggregator. The FL system can be scaled further, as each cluster aggregator
    is responsible for creating its own semi-global model by itself – not via the
    master node of those aggregators – and therefore, decentralized semi-global model
    formation comes with resiliency and mobility.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: We can even decouple the database that stores the uploaded local models, cluster
    global models, and semi-global models. By introducing a distributed database into
    the FL system, the entire system could be made more scalable, resilient, and secure
    together with some failover mechanism.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: For example, each cluster aggregator stores the cluster model in a distributed
    database. The cluster aggregators can retrieve cluster models of other aggregators
    by pulling the models periodically from the databases. At each cluster aggregator,
    a semi-global ML model is generated by synthesizing the pulled models.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.13* illustrates the overall architecture of the decentralized horizontal
    design of a multi-aggregator FL system:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.13 – Architecture of a decentralized FL system with multiple aggregators
    (horizontal design)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_13_New.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.13 – Architecture of a decentralized FL system with multiple aggregators
    (horizontal design)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have discussed how to enhance the FL system with a horizontal design
    using the semi-global model concept, next, we will look at distributed database
    frameworks to further ensure scalability and resiliency.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Distributed database
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Furthermore, the accountability of the model updates can be provided by storing
    historical model data in a data-driven distributed database. The **InterPlanetary
    File System** (**IPFS**) and Blockchain are well-known distributed databases that
    ensure the accountability of global model updates. After a cluster aggregator
    generates a semi-global model based on other cluster models, the semi-global model
    is stored in a distributed database. The distributed database manages the information
    of those models with a unique identifier. To maintain all the models consistently,
    including local, cluster, and semi-global models, each ML model is assigned a
    globally unique identifier, such as a hash value, which could be realized using
    the concept of a **Chord Distributed Hash Table** (**Chord DHT**). The Chord DHT
    is a scalable peer-to-peer lookup protocol for internet applications.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: The cluster aggregator can store metadata on the cluster models, such as timestamps
    and hash identifiers. This gives us further accountability for model synthesis
    by ensuring the cluster models haven't been altered. It is also possible to identify
    a set of aggregators that are sending harmful cluster models to destroy the semi-global
    models once the malicious models are detectable. These models can be filtered
    by analyzing the patterns of the weights of the cluster model or deviation from
    the other cluster models when the difference is too big to rely on.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: The nature of the distributed database is to store all the volatile state information
    of the distributed FL system. The FL system can restore from the distributed database
    in the case of failure. The cluster aggregators also exchange their cluster models
    based on a certain interval defined by the system operator. Therefore, the mapping
    table between cluster models and aggregators needs to be logged in the database
    together with meta-information on the local, cluster, and semi-global models,
    such as the generation time of those models and the size of training samples.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous agent participation in a multiple-aggregator scenario
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Distributed agents can broadcast participation messages to connectable aggregators
    when they want to join their FL process. The participation messages can contain
    the unique ID of the agent. One of the cluster aggregators then returns a cluster
    aggregator ID, potentially the value generated based on a common hash function,
    to which the agent should belong. *Figure 3.14* depicts how the agent is assigned
    to a certain cluster aggregator using a hash function:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.14 – The sequence of an agent joining one of the cluster aggregators
    in an FL system'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_14.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.14 – The sequence of an agent joining one of the cluster aggregators
    in an FL system
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will look into how the semi-global model is generated
    based on aggregating the multiple cluster global models.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Semi-global model synthesis
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After the agent is assigned to a specific cluster aggregator, the agent starts
    to participate in the FL process. It requests a base ML model if it is registered
    – otherwise, it needs to upload the base model to start local training. The procedure
    of uploading local models and generating cluster and semi-global models will continue
    until the agent or aggregator is disconnected from the system. The sequence of
    the local and cluster model upload process, aggregation process, and semi-global
    model synthesis and pulling is illustrated in *Figure 3.15*:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.15 – The sequence of the semi-global model synthesis processes from
    uploading local models to pulling semi-global models'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_15.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.15 – The sequence of the semi-global model synthesis processes from
    uploading local models to pulling semi-global models
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at semi-global model synthesis using the flowchart between the agent,
    aggregator, and distributed database.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: The aggregator receives a local model from an agent. When receiving the local
    model, the model filtering process will decide whether to accept the uploaded
    model or not. This framework can be implemented using many different methods,
    such as a basic scheme of checking the difference between the weights of the global
    and local models. If the model is not valid, just discard the local model.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Then, a cluster model is created by aggregating all the accepted local models.
    The aggregator stores the cluster model in a database, as well as simultaneously
    retrieving the cluster models generated by other cluster aggregators. A semi-global
    model is then synthesized from those cluster models and will be used in the agents
    that are assigned to the cluster aggregator.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.16* shows how the cluster aggregator proceeds with cluster and semi-global
    model synthesis using a distributed database:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.16 – The procedure and flow of semi-global model synthesis'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_03_16.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.16 – The procedure and flow of semi-global model synthesis
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: An aggregator does not need to retrieve all the cluster models generated at
    each round to create a semi-global model. To synthesize a semi-global model, the
    global model can eventually converge based on the subset of models randomly selected
    by each aggregator. Using this approach, the robustness and independence of aggregators
    will be enhanced by compromising on the conditions to create the global model
    at every update. This framework can also resolve the bottlenecks in terms of computation
    and communication typical to centralized FL systems.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the potential architecture, procedure flow, and
    message sequences within an FL system. The typical FL system architecture consists
    of an aggregator, agents, and a database server. These three components are constantly
    communicating with each other to exchange system information and ML models to
    achieve model aggregation.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: The key to implementing a good FL system is decoupling the critical components
    and carefully designing the interfaces between them. We focused on the aspect
    of the simplicity of its design so that further enhancement can be achieved by
    just adding additional components to the systems. Horizontal decentralized design
    can also help implement a scalable FL system.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will discuss the implementation details of achieving
    FL on the server side. As some critical aspects of the functionalities have been
    introduced in this chapter, you will be able to implement the basic system and
    smoothly run the simulation with some ML applications.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the concepts discussed in this chapter can be explored further by reading
    the following papers:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman,
    Vladimir Ivanov, Chloe Kiddon, et al. *Towards Federated Learning at Scale: System
    Design.* Proceedings of Machine Learning and Systems 1 (2019): 374–388, ([https://arxiv.org/abs/1902.01046](https://arxiv.org/abs/1902.01046)).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A.
    N., and Zhao, S. (2021). *Advances and Open Problems in Federated Learning*. *Foundations
    and Trends in Machine Learning*, *14 (1 and 2): 1–210*, ([https://arxiv.org/abs/1912.04977](https://arxiv.org/abs/1912.04977)).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stoica, I., Morris, R., Liben-Nowell, D., Karger, D., Kaashoek, M., Dabek,
    F., Balakrishnan, H. (2003). Chord: *A Scalable Peer-to-Peer Lookup Protocol for
    Internet Applications*, IEEE/ACM Transactions on Networking., Vol. 11, No. 1,
    pp 17–32, ([https://resources.mpi-inf.mpg.de/d5/teaching/ws03_04/p2p-data/11-18-writeup1.pdf](https://resources.mpi-inf.mpg.de/d5/teaching/ws03_04/p2p-data/11-18-writeup1.pdf)).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Juan Benet. (2014). *IPFS – Content Addressed, Versioned, P2P File System*,
    ([https://arxiv.org/abs/1407.3561](https://arxiv.org/abs/1407.3561)).
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Part 2 The Design and Implementation of the Federated Learning System
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, we will explain the implementation principle of the **federated
    learning** (**FL**) system using Python. You will learn how to design the software
    components and code the essential functionalities of both the FL server and the
    client. In addition, you will be able to integrate your own machine learning process
    into the FL system and run and analyze your FL-based applications.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'This part comprises the following chapters:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B18369_04.xhtml#_idTextAnchor085), *Federated Learning Server
    Implementation with Python*'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18369_05.xhtml#_idTextAnchor130), *Federated Learning Client-Side
    Implementation*'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18369_06.xhtml#_idTextAnchor156), *Running the Federated Learning
    System and Analyzing the Results*'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18369_07.xhtml#_idTextAnchor176), *Model Aggregation*'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
