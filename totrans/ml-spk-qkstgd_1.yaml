- en: The Big Data Ecosystem
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据生态系统
- en: 'Modern technology has transformed the very essence of what we mean by data.
    Whereas previously, data was traditionally thought of as text and numbers confined
    to spreadsheets or relational databases, today, it is an organic and evolving
    asset in its own right, being created and consumed on a mass scale by anyone that
    owns a smartphone, TV, or bank account. In this chapter, we will explore the new
    ecosystem of cutting-edge tools, technologies, and frameworks that allow us to
    store, process, and analyze massive volumes of data in order to deliver actionable
    insights and solve real-world problems. By the end of this chapter, you will have
    gained a high-level understanding of the following cutting-edge technology classes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现代技术已经彻底改变了我们对数据的理解。以前，数据传统上被认为是限制在电子表格或关系数据库中的文本和数字，而如今，它是一种有机且不断发展的资产，由任何拥有智能手机、电视或银行账户的人大规模创建和消费。在本章中，我们将探讨新的生态系统，其中包括前沿的工具、技术和框架，使我们能够存储、处理和分析大量数据，以便提供可操作的见解并解决现实世界的问题。到本章结束时，你将获得以下前沿技术类别的深入了解：
- en: Distributed systems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式系统
- en: NoSQL databases
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NoSQL数据库
- en: Artificial intelligence and machine learning frameworks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能和机器学习框架
- en: Cloud computing platforms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云计算平台
- en: Big data platforms and reference architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据平台和参考架构
- en: A brief history of data
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据简史
- en: If you worked in the mainstream IT industry between the 1970s and early 2000s,
    it is likely that your organization's data was held either in text-based delimited
    files, spreadsheets, or nicely structured relational databases. In the case of
    the latter, data is modeled and persisted in pre-defined, and possibly related,
    tables representing the various entities found within your organization's data
    model, for example, according to employee or department. These tables contain
    rows of data across multiple columns representing the various attributes making
    up that entity; for example, in the case of employee, typical attributes include
    first name, last name, and date of birth.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在1970年代到2000年代初的主流IT行业工作，那么你组织的数据库可能存储在基于文本的定界文件、电子表格或结构良好的关系数据库中。在后一种情况下，数据被建模并持久化在预定义的、可能相关的表中，这些表代表组织中数据模型中找到的各种实体，例如，根据员工或部门。这些表包含跨越多个列的数据行，代表构成该实体的各种属性；例如，在员工的情况下，典型的属性包括名字、姓氏和出生日期。
- en: Vertical scaling
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垂直扩展
- en: As both your organization's data estate and the number of users requiring access
    to that data grew, high-performance remote servers would have been utilized, with
    access provisioned over the corporate network. These remote servers would typically
    either act as remote filesystems for file sharing or host **relational database
    management systems** (**RDBMSes**) in order to store and manage relational databases.
    As data requirements grew, these remote servers would have needed to scale vertically,
    meaning that additional CPU, memory, and/or hard disk space would have been installed.
    Typically, these relational databases would have stored anything between hundreds
    and potentially tens of millions of records.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着贵组织的数据资产和需要访问这些数据的使用者数量的增长，高性能的远程服务器将被利用，通过企业网络提供访问权限。这些远程服务器通常要么作为远程文件系统用于文件共享，要么托管**关系数据库管理系统**（**RDBMSes**）以存储和管理关系数据库。随着数据需求的增长，这些远程服务器将需要垂直扩展，这意味着将安装额外的CPU、内存和/或硬盘空间。通常，这些关系数据库将存储从数百到可能数千万条记录。
- en: Master/slave architecture
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主/从架构
- en: 'As a means of providing resilience and load balancing read requests, potentially,
    a master/slave architecture would have been employed whereby data is automatically
    copied from the master database server to physically distinct slave database server(s)
    utilizing near real-time replication. This technique requires that the master
    server be responsible for all write requests, while read requests could be offloaded
    and load balanced across the slaves, where each slave would hold a full copy of
    the master data. That way, if the master server ever failed for some reason, business-critical
    read requests could still be processed by the slaves while the master was being
    brought back online. This technique does have a couple of major disadvantages,
    however:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提供弹性和负载均衡读取请求的手段，可能已经采用了主/从架构，其中数据通过近实时复制自动从主数据库服务器复制到物理上不同的从数据库服务器。这项技术要求主服务器负责所有写请求，而读取请求可以卸载并在从服务器之间进行负载均衡，其中每个从服务器都持有主数据的完整副本。这样，如果主服务器因某种原因失败，业务关键性的读取请求仍然可以由从服务器处理，同时主服务器正在恢复在线。然而，这项技术确实有几个主要的缺点：
- en: '**Scalability**: The master server, by being solely responsible for processing
    write requests, limits the ability for the system to be scalable as it could quickly
    become a bottleneck.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：由于主服务器仅负责处理写请求，这限制了系统的可扩展性，因为它可能很快成为瓶颈。'
- en: '**Consistency and data loss**: Since replication is near real-time, it is not
    guaranteed that the slaves would have the latest data at the point in time that
    the master server goes offline and transactions may be lost. Depending on the
    business application, either not having the latest data or losing data may be
    unacceptable.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性和数据丢失**：由于复制几乎是实时的，不能保证在主服务器离线且事务可能丢失的那个时间点，从服务器会有最新的数据。根据业务应用的不同，没有最新数据或丢失数据可能都是不可接受的。'
- en: Sharding
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分片
- en: To increase throughput and overall performance, and as single machines reached
    their capacity to scale vertically in a cost-effective manner, it is possible
    that sharding would have been employed. This is one method of horizontal scaling
    whereby additional servers are provisioned and data is physically split over separate
    database instances residing on each of the machines in the cluster, as illustrated
    in *Figure 1.1*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高吞吐量和整体性能，并且随着单机在以成本效益的方式垂直扩展其容量时达到极限，可能已经采用了分片。这是一种水平扩展的方法，其中额外的服务器被配置，数据在集群中每台机器上的独立数据库实例之间物理分割，如图*1.1*所示。
- en: This approach would have allowed organizations to scale linearly to cater for
    increased data sizes while reusing existing database technologies and commodity
    hardware, thereby optimizing costs and performance for small- to medium-sized
    databases.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法允许组织线性扩展以适应增加的数据量，同时重用现有的数据库技术和通用硬件，从而优化小型到中型数据库的成本和性能。
- en: 'Crucially, however, these separate databases are standalone instances and have
    no knowledge of one another. Therefore, some sort of broker would be required
    that, based on a partitioning strategy, would keep track of where data was being
    written to for each write request and, thereafter, retrieve data from that same
    location for read requests. Sharding subsequently introduced further challenges,
    such as processing data queries, transformations, and joins that spanned multiple
    standalone database instances across multiple servers (without denormalizing data),
    thereby maintaining referential integrity and the repartitioning of data:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关键的是，这些独立的数据库是独立的实例，彼此之间没有了解。因此，需要某种类型的代理，基于分区策略，跟踪每个写请求数据写入的位置，之后从相同的位置检索数据以处理读取请求。分片随后引入了进一步挑战，如处理跨越多个独立数据库实例和多个服务器的数据查询、转换和连接（不进行数据规范化），从而保持引用完整性和数据的重新分区：
- en: '![](img/f8b2397e-82c6-4050-9657-f29f64135575.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f8b2397e-82c6-4050-9657-f29f64135575.png)'
- en: 'Figure 1.1: A simple sharding partitioning strategy'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：简单的分片分区策略
- en: Data processing and analysis
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理和分析
- en: Finally, in order to transform, process, and analyze the data sitting in these
    delimited text-based files, spreadsheets or relational databases, typically an
    analyst, data engineer or software engineer would have written some code.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了转换、处理和分析存储在这些基于文本的文件、电子表格或关系型数据库中的数据，通常需要一个分析师、数据工程师或软件工程师编写一些代码。
- en: 'This code, for example, could take the form of formulas or **Visual Basic for
    Applications** (**VBA**) for spreadsheets, or **Structured Query Language** (**SQL**)
    for relational databases, and would be used for the following purposes:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，此代码可以是电子表格的公式或**Visual Basic for Applications**（**VBA**），或者关系数据库的**结构化查询语言**（**SQL**），并用于以下目的：
- en: Loading data, including batch loading and data migration
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据，包括批量加载和数据迁移
- en: Transforming data, including data cleansing, joins, merges, enrichment, and
    validation
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换数据，包括数据清理、连接、合并、丰富和验证
- en: Standard statistical aggregations, including computing averages, counts, totals,
    and pivot tables
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准的统计汇总，包括计算平均值、计数、总和和交叉表
- en: Reporting, including graphs, charts, tables, and dashboards
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 报告，包括图表、图表、表格和仪表板
- en: To perform more complex statistical calculations, such as generating predictive
    models, advanced analysts could utilize more advanced programming languages, including Python,
    R, SAS, or even Java.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行更复杂的统计计算，例如生成预测模型，高级分析师可以利用更高级的编程语言，包括Python、R、SAS，甚至Java。
- en: Crucially, however, this data transformation, processing, and analysis would
    have either been executed directly on the server in which the data was persisted
    (for example, SQL statements executed directly on the relational database server
    in competition with other business-as-usual read and write requests), or data
    would be moved over the network via a programmatic query (for example, an ODBC
    or JDBC connection), or via flat files (for example, CSV or XML files) to another
    remote analytical processing server. The code could then be executed on that data,
    assuming, of course, that the remote processing server had sufficient CPUs, memory
    and/or disk space in its single machine to execute the job in question. In other
    words, the data would have been moved to the code in some way or another.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关键的是，这种数据转换、处理和分析要么是在数据持久化的服务器上直接执行（例如，在关系数据库服务器上直接执行SQL语句，与其他常规的读写请求竞争），要么是通过程序性查询通过网络移动数据（例如，通过ODBC或JDBC连接），或者通过平面文件（例如，CSV或XML文件）到另一个远程分析处理服务器。当然，假设远程处理服务器在其单台机器上具有足够的CPU、内存和/或磁盘空间来执行相关任务，代码可以随后在该数据上执行。换句话说，数据以某种方式被移动到代码中。
- en: Data becomes big
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据变得庞大
- en: Fast forward to today—spreadsheets are still commonplace, and relational databases
    containing nicely structured data, whether partitioned across shards or not, are
    still very much relevant and extremely useful. In fact, depending on the use case,
    the data volumes, structure, and the computational complexity of the required
    processing, it could still be faster and more efficient to store and manage data
    via an RDBMS and process that data directly on the remote database server using
    SQL. And, of course, spreadsheets are still great for very small datasets and
    for simple statistical aggregations. What has changed, however, since the 1970s
    is the availability of more powerful and more cost-effective technology coupled
    with the introduction of the internet!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 快进到今天——电子表格仍然很常见，包含结构良好数据的关联数据库，无论是否跨分片，仍然非常相关且极其有用。实际上，根据用例、数据量、结构和所需处理的计算复杂性，通过关系数据库管理系统（RDBMS）存储和管理数据，并在远程数据库服务器上直接使用SQL处理这些数据，可能仍然更快、更高效。当然，对于非常小的数据集和简单的统计汇总，电子表格仍然很棒。然而，自1970年代以来，变化的是更强大、更经济的技术的可用性，以及互联网的引入！
- en: The internet has transformed the very essence of what we mean by data. Whereas
    before, data was thought of as text and numbers confined to spreadsheets or relational
    databases, it is now an organic and evolving asset in its own right being created
    and consumed on a mass scale by anyone that owns a smartphone, TV, or bank account.
    Data is being created every second around the world in virtually any format you
    can think of, from social media posts, images, videos, audio, and music to blog
    posts, online forums, articles, computer log files, and financial transactions.
    All of this structured, semi-structured, and unstructured data being created in
    both batche and real time can no longer be stored and managed by nicely organized,
    text-based delimited files, spreadsheets, or relational databases, nor can it
    *all* be physically moved to a remote processing server every time some analytical
    code is to be executed—a new breed of technology is required.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网已经改变了我们对数据的本质理解。以前，数据被认为是局限于电子表格或关系型数据库中的文本和数字，而现在它已经成为一种有机且不断发展的资产，由任何拥有智能手机、电视或银行账户的人大规模创建和消费。全球每秒钟都在以几乎任何你能想到的格式创建数据，从社交媒体帖子、图片、视频、音频和音乐到博客文章、在线论坛、文章、计算机日志文件和金融交易。所有这些结构化、半结构化和非结构化数据，无论是批量还是实时创建的，都无法再通过组织良好的基于文本的定界文件、电子表格或关系型数据库来存储和管理，也无法每次执行一些分析代码时都将其物理移动到远程处理服务器——需要一种新的技术。
- en: Big data ecosystem
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据生态系统
- en: 'If you work in almost any mainstream industry today, chances are that you may
    have heard of some of the following terms and phrases:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你今天在几乎任何主流行业中工作，你可能会听到以下一些术语和短语：
- en: Big data
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据
- en: Distributed, scalable, and elastic
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式、可扩展和弹性
- en: On-premise versus the cloud
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地部署与云
- en: SQL versus NoSQL
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQL与NoSQL
- en: Artificial intelligence, machine learning, and deep learning
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能、机器学习和深度学习
- en: But what do all these terms and phrases actually mean, how do they all fit together,
    and where do you start? The aim of this section is to answer all of those questions
    in a clear and concise manner.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 但所有这些术语和短语实际上意味着什么，它们是如何相互关联的，你从哪里开始？本节的目标是以清晰简洁的方式回答所有这些问题。
- en: Horizontal scaling
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 水平扩展
- en: First of all, let's return to some of the data-centric problems that we described
    earlier. Given the huge explosion in the mass creation and consumption of data
    today, clearly we cannot continue to keep adding CPUs, memory, and/or hard drives
    to a single machine (in other words, vertical scaling). If we did, there would
    very quickly come a point where migrating to more powerful hardware would lead
    to diminishing returns while incurring significant costs. Furthermore, the ability
    to scale would be physically bounded by the biggest machine available to us, thereby
    limiting the growth potential of an organization.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回到我们之前描述的一些以数据为中心的问题。鉴于今天数据的大规模创建和消费的爆炸性增长，显然我们不能再继续向单台机器添加CPU、内存和/或硬盘（换句话说，垂直扩展）。如果我们这样做，很快就会达到一个点，迁移到更强大的硬件将导致收益递减，同时产生显著的成本。此外，可扩展性将受到我们所能获得的最大机器的物理限制，从而限制组织的增长潜力。
- en: 'Horizontal scaling, of which sharding is an example, is the process by which
    we can increase or decrease the amount of computational resources available to
    us via the addition or removal of hardware and/or software. Typically, this would
    involve the addition (or removal) of servers or nodes to a cluster of nodes. Crucially,
    however, the cluster acts as a single logical unit at all times, meaning that
    it will still continue to function and process requests regardless of whether
    resources were being added to it or taken away. The difference between horizontal
    and vertical scaling is illustrated in *Figure 1.2*:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 水平扩展，以分片为例，是我们通过添加或移除硬件和/或软件来增加或减少可用计算资源的过程。通常，这会涉及向节点集群中添加（或移除）服务器或节点。然而，关键的是，集群始终作为一个单一的逻辑单元运行，这意味着无论是否向其添加资源或从中移除资源，它都将继续运行并处理请求。水平扩展和垂直扩展之间的区别在*图1.2*中得到了说明：
- en: '![](img/fe463d90-f107-4ce3-8734-684a3f23c2c1.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fe463d90-f107-4ce3-8734-684a3f23c2c1.png)'
- en: 'Figure 1.2: Vertical scaling versus horizontal scaling'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：垂直扩展与水平扩展
- en: Distributed systems
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式系统
- en: Horizontal scaling allows organizations to become much more cost efficient when
    data and processing requirements grow beyond a certain point. But simply adding
    more machines to a cluster would not be of much value by itself. What we now need
    are systems that are capable of taking advantage of horizontal scalability and
    that work across multiple machines seamlessly, irrespective of whether the cluster
    contains one machine or 10,000 machines.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 水平扩展允许组织在数据和处理需求超过一定点时变得更加高效。但是，仅仅向集群中添加更多机器本身并不会带来太多价值。我们现在需要的是能够利用水平可伸缩性并且能够在多台机器上无缝工作的系统，无论集群包含一台机器还是10,000台机器。
- en: 'Distributed systems do precisely that—they work seamlessly across a cluster
    of machines and automatically deal with the addition (or removal) of resources
    from that cluster. Distributed systems can be broken down into the following types:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统正是如此——它们在机器集群中无缝工作，并自动处理从该集群中添加（或移除）资源的情况。分布式系统可以分为以下类型：
- en: Distributed filesystems
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式文件系统
- en: Distributed databases
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式数据库
- en: Distributed processing
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式处理
- en: Distributed messaging
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式消息
- en: Distributed streaming
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式流
- en: Distributed ledgers
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式账本
- en: Distributed data stores
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式数据存储
- en: Let's return to the problems faced by a single-machine RDBMS. We have seen how
    sharding can be employed as one method to scale relational databases horizontally
    in order to optimize costs as data grows for small- to medium-sized databases.
    However, the issue with sharding is that each node acts in a standalone manner
    with no knowledge of the other nodes in the cluster, meaning that a custom broker
    is required to both partition the data across the shards and to process read and
    write requests.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到单机RDBMS面临的问题。我们已经看到，分片可以作为扩展关系数据库水平以优化成本的一种方法，适用于从小型到中型数据库的数据增长。然而，分片的问题在于每个节点以独立的方式运行，对集群中的其他节点一无所知，这意味着需要一个自定义代理来分区数据并在分片之间处理读写请求。
- en: Distributed data stores, on the other hand, work out of the box as a single
    logical unit spanning a cluster of nodes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，分布式数据存储作为单个逻辑单元，直接在节点集群中运行，无需额外配置即可使用。
- en: Note that a data store is just a general term used to describe any type of repository
    used to persist data. Distributed data stores extend this by storing data on more
    than one node, and often employ replication.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，数据存储只是一个通用术语，用来描述任何用于持久化数据的存储库。分布式数据存储通过在多个节点上存储数据来扩展这一概念，并且通常采用复制机制。
- en: Client applications view the distributed data store as a single entity, meaning
    that no matter which node in the cluster physically handles the client request,
    the same results will be returned. Distributed filesystems, such as the **Apache
    Hadoop Distributed File System** (**HDFS**) discussed in the next section, belong
    to the class of distributed data stores and are used to store files in their raw
    format. When data needs to be modeled in some manner, then distributed databases
    can be used. Depending on the type of distributed database, it can either be deployed
    on top of a distributed filesystem or not.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端应用程序将分布式数据存储视为一个单一实体，这意味着无论集群中的哪个节点实际处理客户端请求，都会返回相同的结果。下一节中讨论的分布式文件系统，如**Apache
    Hadoop分布式文件系统（HDFS**），属于分布式数据存储类别，用于以原始格式存储文件。当数据需要以某种方式建模时，可以使用分布式数据库。根据分布式数据库的类型，它可以在分布式文件系统之上部署，也可以不部署。
- en: Distributed filesystems
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式文件系统
- en: Think of the hard drive inside your desktop, laptop, smartphone, or other personal
    device you own. Files are written to and stored on local hard drives and retrieved
    as and when you need them. Your local operating system manages read and write
    requests to your local hard drive by maintaining a local filesystem—a means by
    which the operating system keeps track of how the disk is organized and where
    files are located.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你桌面、笔记本电脑、智能手机或其他个人设备中的硬盘。文件被写入并存储在本地硬盘上，并在需要时检索。你的本地操作系统通过维护本地文件系统来管理对本地硬盘的读写请求——这是操作系统跟踪磁盘组织方式和文件位置的一种方式。
- en: As your personal data footprint grows, you take up more and more space on your
    local hard drive until it reaches its capacity. At this time, you may seek to
    purchase a larger capacity hard drive to replace the one inside your device, or
    you may seek to purchase an extra hard drive to complement your existing one.
    In the case of the latter, you personally manage which of your personal files
    reside on which hard drive, or perhaps use one of them to archive files you rarely
    use to free up space on your primary drive. Hopefully, you also maintain backups
    of your personal files should the worse happen and your device or primary hard
    drive malfunctions!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您个人数据足迹的增长，您在本地硬盘上占用的空间越来越多，直到达到其容量。在此时刻，您可能寻求购买一个更大容量的硬盘来替换设备内部的硬盘，或者您可能寻求购买一个额外的硬盘来补充现有的硬盘。在后一种情况下，您个人管理哪些个人文件存储在哪个硬盘上，或者可能使用其中一个来存档很少使用的文件，以释放主硬盘的空间。希望您也维护个人文件的备份，以防最坏的情况发生，您的设备或主硬盘出现故障！
- en: A **distributed filesystem** (**DFS**) extends the notion of local filesystems,
    while offering a number of useful benefits. In a distributed filesystem within
    the context of our big data ecosystem, data is physically split across the nodes
    and disks in a cluster. Like distributed data stores in general, a distributed
    filesystem provides a layer of abstraction and manages read and write requests
    across the cluster itself, meaning that the physical split is invisible to requesting
    client applications which view the distributed filesystem as one logical entity
    just like a conventional local filesystem.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**分布式文件系统**（DFS）扩展了本地文件系统的概念，同时提供了一系列有用的好处。在我们的大数据生态系统中，分布式文件系统将数据物理分割到集群中的节点和磁盘上。就像一般分布式数据存储一样，分布式文件系统提供了一层抽象，并管理跨集群的读写请求，这意味着物理分割对请求客户端应用程序来说是不可见的，它们将分布式文件系统视为一个逻辑实体，就像传统的本地文件系统一样。'
- en: 'Furthermore, distributed filesystems provide useful benefits out of the box,
    including the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，分布式文件系统提供了开箱即用的有用好处，包括以下内容：
- en: Data replication, where data can be configured to be automatically replicated
    across the cluster for fault tolerance in the event one or more of the nodes or
    disks should fail
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据复制，其中数据可以被配置为在集群中自动复制，以实现容错，以防一个或多个节点或磁盘出现故障
- en: Data integrity checking
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据完整性检查
- en: The ability to persist huge files, typically **gigabytes** (**GB**) to **terabytes**
    (**TB**) in size, which would not normally be possible on conventional local filesystems
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够持久化巨大的文件，通常大小为**千兆字节**（GB）到**太字节**（TB），这在传统的本地文件系统中通常是不可能的
- en: The HDFS is a well-known example of a distributed filesystem within the context
    of our big data ecosystem. In the HDFS, a master/slave architecture is employed,
    consisting of a single NameNode that manages the distributed filesystem, and multiple
    DataNodes, which typically reside on each node in the cluster and manage the physical
    disks attached to that node as well as where the data is physically persisted
    to. Just as with traditional filesystems, HDFS supports standard filesystem operations,
    such as opening and closing files and directories. When a client application requests
    a file to be written to the HDFS, it is split into one or more blocks that are
    then mapped by the NameNode to the DataNodes, where they are physically persisted.
    When a client application requests a file to be read from the HDFS, the DataNodes
    fulfill this request.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS（Hadoop分布式文件系统）是我们大数据生态系统中的一个知名分布式文件系统示例。在HDFS中，采用主/从架构，包括一个负责管理分布式文件系统的单个NameNode，以及多个DataNode，这些DataNode通常位于集群中的每个节点上，并管理连接到该节点的物理磁盘以及数据物理存储的位置。就像传统的文件系统一样，HDFS支持标准文件系统操作，例如打开和关闭文件和目录。当客户端应用程序请求将文件写入HDFS时，该文件被分割成一个或多个块，然后由NameNode映射到DataNode，在那里它们被物理存储。当客户端应用程序请求从HDFS读取文件时，DataNode满足这一请求。
- en: One of the core benefits of HDFS is that it provides fault tolerance inherently
    through its distributed architecture, as well as through data replication. Since
    typically there will be multiple nodes (potentially thousands) in an HDFS cluster,
    it is resilient to hardware failure as operations can be automatically offloaded
    to the healthy parts of the cluster while the non-functional hardware is being
    recovered or replaced. Furthermore, when a file is split into blocks and mapped
    by the NameNode to the DataNodes, these blocks can be configured to automatically
    replicate across the DataNodes, taking into account the topology of the HDFS cluster.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS的一个核心优势是它通过其分布式架构以及数据复制提供固有的容错性。由于通常HDFS集群中会有多个节点（可能成千上万），它对硬件故障具有弹性，因为操作可以自动卸载到集群的健康部分，同时非功能硬件正在恢复或更换。此外，当文件被分割成块并由NameNode映射到DataNode时，这些块可以配置为自动在DataNode之间复制，考虑到HDFS集群的拓扑结构。
- en: 'Therefore, if a failure did occur, for example, a disk failure on one of the
    DataNodes, data would still be available to client applications. The high-level
    architecture of an HDFS cluster is illustrated in *Figure 1.3*:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果确实发生了故障，例如，DataNode上的磁盘故障，数据仍然可供客户端应用程序使用。HDFS集群的高级架构在*图1.3*中说明：
- en: '![](img/fa782415-9b56-43a6-bde2-5fa3af0aa816.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fa782415-9b56-43a6-bde2-5fa3af0aa816.png)'
- en: 'Figure 1.3: Apache Hadoop distributed filesystem high-level architecture'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：Apache Hadoop分布式文件系统高级架构
- en: To learn more about the Apache Hadoop framework, please visit [http://hadoop.apache.org/](http://hadoop.apache.org/).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Apache Hadoop框架的信息，请访问 [http://hadoop.apache.org/](http://hadoop.apache.org/)。
- en: Distributed databases
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式数据库
- en: Distributed filesystems, like conventional filesystems, are used to store files.
    In the case of distributed filesystems such as the HDFS, these files can be very
    large. Ultimately, however, they are used to store files. When data requires modeling,
    we need something more than just a filesystem; we need a database.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式文件系统，就像传统文件系统一样，用于存储文件。在分布式文件系统（如HDFS）的情况下，这些文件可以非常大。然而，最终它们用于存储文件。当数据需要建模时，我们需要的不仅仅是文件系统；我们需要数据库。
- en: Distributed databases, just like single-machine databases, allow us to model
    our data. Unlike single-machine databases, however, the data, and the data model
    itself, spans, and is preserved across, all the nodes in a cluster acting as a
    single logical database. This means that not only can we take advantage of the
    increased performance, throughput, fault tolerance, resilience, and cost-effectiveness
    offered by distributed systems, but we can also model our data and thereafter
    query that data efficiently, no matter how large it is or how complex the processing
    requirements are. Depending on the type of distributed database, it can either
    be deployed on top of a distributed filesystem (such as Apache HBase deployed
    on top of the HDFS) or not.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式数据库，就像单机数据库一样，允许我们建模我们的数据。然而，与单机数据库不同的是，数据和数据模型本身跨越并保存在充当单个逻辑数据库的集群中的所有节点。这意味着我们不仅可以利用分布式系统提供的增加的性能、吞吐量、容错性、弹性和成本效益，而且我们可以有效地建模我们的数据，然后高效地查询这些数据，无论其大小如何或处理要求有多复杂。根据分布式数据库的类型，它可以在分布式文件系统（如部署在HDFS之上的Apache
    HBase）之上部署，也可以不部署。
- en: In our big data ecosystem, it is often the case that distributed filesystems
    such as the HDFS are used to host **data lakes**. A data lake is a centralized
    data repository where data is persisted in its original raw format, such as files
    and object BLOBs. This allows organizations to consolidate their disparate raw
    data estate, including structured and unstructured data, into a central repository
    with no predefined schema, while offering the ability to scale over time in a
    cost-effective manner.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的大数据生态系统中，通常使用分布式文件系统，如HDFS，来托管**数据湖**。数据湖是一个集中式数据存储库，其中数据以原始的原始格式持久化，例如文件和对象BLOB。这使得组织能够将它们分散的原始数据资产，包括结构化和非结构化数据，整合到一个没有预定义模式的中央存储库中，同时提供在成本效益的方式下随时间扩展的能力。
- en: Thereafter, in order to actually deliver business value and actionable insight
    from this vast repository of schema-less data, data processing pipelines are engineered
    to transform this raw data into meaningful data conforming to some sort of data
    model that is then persisted into serving or analytical data stores typically
    hosted by distributed databases. These distributed databases are optimized, depending
    on the data model and type of business application, to efficiently query the large
    volumes of data held within them in order to serve user-facing **business intelligence**
    (**BI**), data discovery, advanced analytics, and insights-driven applications
    and APIs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，为了从大量无模式数据中实际交付业务价值和可操作见解，数据处理管道被设计出来，将原始数据转换为符合某种数据模型的有意义数据，然后持久化到由分布式数据库托管的服务或分析数据存储中。这些分布式数据库根据数据模型和业务应用类型进行了优化，以有效地查询它们内部存储的大量数据，以服务于面向用户的**商业智能**（**BI**）、数据发现、高级分析和以洞察力驱动的应用程序和
    API。
- en: 'Examples of distributed databases include the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式数据库的例子包括以下内容：
- en: Apache HBase: [https://hbase.apache.org/](https://hbase.apache.org/)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache HBase: [https://hbase.apache.org/](https://hbase.apache.org/)
- en: Apache Cassandra: [http://cassandra.apache.org/](http://cassandra.apache.org/)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Cassandra: [http://cassandra.apache.org/](http://cassandra.apache.org/)
- en: Apache CouchDB: [http://couchdb.apache.org/](http://couchdb.apache.org/)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache CouchDB: [http://couchdb.apache.org/](http://couchdb.apache.org/)
- en: Apache Ignite: [https://ignite.apache.org/](https://ignite.apache.org/)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Ignite: [https://ignite.apache.org/](https://ignite.apache.org/)
- en: Greenplum Database: [https://greenplum.org/](https://greenplum.org/)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greenplum Database: [https://greenplum.org/](https://greenplum.org/)
- en: MongoDB: [https://www.mongodb.com/](https://www.mongodb.com/)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MongoDB: [https://www.mongodb.com/](https://www.mongodb.com/)
- en: '**Apache Cassandra** is an example of a distributed database that employs a
    masterless architecture with no single point of failure that supports high throughput
    in processing huge volumes of data. In Cassandra, there is no master copy of the
    data. Instead, data is automatically partitioned, based on partitioning keys and
    other features inherent to how Cassandra models and stores data, and replicated,
    based on a configurable replication factor, across other nodes in the cluster.
    Since the concept of master/slave does not exist, a gossip protocol is employed
    so that the nodes in the Cassandra cluster may dynamically learn about the state
    and health of other nodes.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache Cassandra** 是一个采用无主架构的分布式数据库示例，该架构没有单点故障，支持处理大量数据的高吞吐量。在 Cassandra
    中，没有数据的主副本。相反，数据根据分区键和其他固有的 Cassandra 模型和存储数据的方式自动分区，并根据可配置的复制因子在其他节点上复制。由于不存在主/从的概念，因此采用
    Gossip 协议，以便 Cassandra 集群中的节点可以动态地了解其他节点的状态和健康情况。'
- en: 'In order to process read and write requests from a client application, Cassandra
    will automatically elect a coordinator node from the available nodes in the cluster,
    a process that is invisible to the client. To process write requests, the coordinator
    node will, based on the partitioning features of the underlying distributed data
    model employed by Cassandra, contact all applicable nodes where the write request
    and replicas should be persisted to. To process read requests, the coordinator
    node will contact one or more of the replica nodes where it knows the data in
    question has been written to, again based on the partitioning features of Cassandra.
    The underlying architecture employed by Cassandra can therefore be visualized
    as a ring, as illustrated in *Figure 1.4*. Note that although the topology of
    a Cassandra cluster can be visualized as a ring, that does not mean that a failure
    in one node results in the failure of the entire cluster. If a node becomes unavailable
    for whatever reason, Cassandra will simply continue to write to the other applicable
    nodes that should persist the requested data, while maintaining a queue of operations
    pertaining to the failed node. When the non-functional node is brought back online,
    Cassandra will automatically update it:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理来自客户端应用程序的读写请求，Cassandra将自动从集群中可用的节点中选举一个协调节点，这个过程对客户端来说是不可见的。为了处理写请求，协调节点将根据Cassandra所采用的底层分布式数据模型的分区特性，联系所有应持久化写请求和副本的适用节点。为了处理读请求，协调节点将联系一个或多个副本节点，这些节点已知数据已被写入，同样基于Cassandra的分区特性。因此，Cassandra所采用的底层架构可以可视化为一个环，如图*图1.4*所示。请注意，尽管Cassandra集群的拓扑可以可视化为一个环，但这并不意味着一个节点的故障会导致整个集群的故障。如果某个节点因任何原因变得不可用，Cassandra将简单地继续向其他应持久化请求数据的适用节点写入，同时维护一个有关失败节点的操作队列。当非功能节点重新上线时，Cassandra将自动更新它：
- en: '![](img/d5ceaf7b-3b2b-4db1-a2a4-c919269b397e.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d5ceaf7b-3b2b-4db1-a2a4-c919269b397e.png)'
- en: 'Figure 1.4: Cassandra topology illustrating a write request with a replication
    factor of 3'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：Cassandra拓扑图，展示了具有3个复制因子的写请求
- en: NoSQL databases
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NoSQL数据库
- en: Relational Database Management Systems, such as Microsoft SQL Server, PostgreSQL,
    and MySQL, allow us to model our data in a structured manner across tables that
    represent the entities found in our data model that may be identified by primary
    keys and linked to other entities via foreign keys. These tables are pre-defined,
    with a schema consisting of columns of various data types that represent the attributes
    of the entity in question.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 关系数据库管理系统（如Microsoft SQL Server、PostgreSQL和MySQL）允许我们在表示数据模型中实体的表格中，以结构化的方式建模我们的数据。这些表格是预定义的，其模式由各种数据类型的列组成，这些列代表所讨论实体的属性。
- en: 'For example, *Figure 1.5* describes a very simple relational schema that could
    be utilized by an e-commerce website:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*图1.5* 描述了一个非常简单的关系模式，这种模式可以被一个电子商务网站所利用：
- en: '![](img/9a8e266c-690a-4fa0-98e3-db8bc467f221.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9a8e266c-690a-4fa0-98e3-db8bc467f221.png)'
- en: 'Figure 1.5: A simple relational database model for an e-commerce website'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：一个电子商务网站的简单关系数据库模型
- en: NoSQL, on the other hand, simply refers to the class of databases where data
    is not modeled in a conventional relational manner. So, if data is not modeled relationally,
    how is it modeled in NoSQL databases? The answer is that there are various types
    of NoSQL databases depending on the use case and business application in question.
    These various types are summarized in the following sub-sections.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，NoSQL仅仅指的是一类数据库，其中数据不是以传统的关系方式建模。因此，如果数据不是以关系方式建模，那么在NoSQL数据库中是如何建模的呢？答案是，根据具体的使用案例和业务应用，存在各种类型的NoSQL数据库。这些不同类型在以下小节中进行了总结。
- en: It is a common, but mistaken, assumption that NoSQL is a synonym for distributed
    databases. In fact, there is an ever increasing list of RDBMS vendors whose products
    are designed to be scalable and distributed to accommodate huge volumes of structured
    data. The reason that this mistaken assumption arose is because it is often the
    case in real-world implementations that NoSQL databases are used to persist huge
    amounts of structured, semi-structured, and unstructured data in a distributed
    manner, hence the reason they have become synonymous with distributed databases.
    However, like relational databases, NoSQL databases are designed to work even
    on a single machine. It is the way that data is modeled that distinguishes relational,
    or SQL, databases from NoSQL databases.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 人们通常有一个常见的但错误的假设，即NoSQL是分布式数据库的同义词。实际上，有一个不断增长的RDBMS供应商列表，他们的产品被设计成可扩展和分布式，以适应大量结构化数据。这种错误假设产生的原因是因为在现实世界的实现中，NoSQL数据库通常用于以分布式方式持久化大量结构化、半结构化和非结构化数据，因此它们与分布式数据库同义。然而，与关系型数据库一样，NoSQL数据库也被设计成即使在单台机器上也能工作。区分关系型（或SQL）数据库和NoSQL数据库的是数据建模的方式。
- en: Document databases
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文档数据库
- en: 'Document databases, such as **Apache CouchDB** and **MongoDB**, employ a document
    data model to store semi-structured and unstructured data. In this model, a document
    is used to encapsulate all the information pertaining to an object, usually in
    **JavaScript Object Notation** (**JSON**) format, meaning that a single document
    is self-describing. Since they are self-describing, different documents may have
    different schema. For example a document describing a movie item, as illustrated
    in the following JSON file, would have a different schema from a document describing
    a book item:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 文档数据库，如**Apache CouchDB**和**MongoDB**，采用文档数据模型来存储半结构化和非结构化数据。在这个模型中，文档用于封装与对象相关的所有信息，通常以**JavaScript对象表示法**（**JSON**）格式，这意味着单个文档是自我描述的。由于它们是自我描述的，不同的文档可能有不同的模式。例如，以下JSON文件中描述电影项目的文档将具有与描述图书项目的文档不同的模式：
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Because documents are self-contained representations of objects, they are particularly
    useful for data models in which individual objects are updated frequently, thereby
    avoiding the need to update the entire database schema, as would be required with
    relational databases. Therefore, document databases tend to be ideal for use cases
    involving catalogs of items, for example e-commerce websites, and content management
    systems such as blogging platforms.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文档是对象的自我包含表示，因此它们对于涉及单个对象频繁更新的数据模型特别有用，从而避免了需要更新整个数据库模式的需求，这在关系型数据库中是必需的。因此，文档数据库通常非常适合涉及商品目录的使用案例，例如电子商务网站和内容管理系统，如博客平台。
- en: Columnar databases
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列式数据库
- en: Relational databases traditionally persist each row of data contiguously, meaning
    that each row will be stored in sequential blocks on disk. This type of database
    is referred to as *row-oriented*. For operations involving typical statistical
    aggregations such as calculating the average of a particular attribute, the effect
    of row-oriented databases is that every attribute in that row is read during processing,
    regardless of whether they are relevant to the query or not. In general, row-oriented
    databases are best suited for transactional workloads, also known as **online
    transaction processing** (**OLTP**), where individual rows are frequently written
    to and where the emphasis is on processing a large number of relatively simple
    queries, such as short inserts and updates, quickly. Examples of use cases include
    retail and financial transactions where database schemas tend to be highly normalized.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 关系型数据库传统上连续存储每行数据，这意味着每行数据都会存储在磁盘上的连续块中。这种类型的数据库被称为*行式数据库*。对于涉及典型统计聚合操作，如计算特定属性的均值，行式数据库的效果是在处理过程中会读取该行中的每个属性，无论它们是否与查询相关。一般来说，行式数据库最适合事务型工作负载，也称为**在线事务处理**（**OLTP**），在这种工作负载中，单个行经常被写入，并且重点在于快速处理大量相对简单的查询，例如短插入和更新。使用案例包括零售和金融交易，其中数据库模式往往高度规范化。
- en: 'On the other hand, columnar databases such as **Apache Cassandra** and **Apache
    HBase** are *column-oriented*, meaning that each column is persisted in sequential
    blocks on disk. The effect of column-oriented databases is that individual attributes
    can be accessed together as a group, rather than individually by row, thereby
    reducing disk I/O for analytical queries since the amount of data that is loaded
    from disk is reduced. For example, consider the following table:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '| **Product ID** | **Name** | **Category** | **Unit price** |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
- en: '| 1001 | USB drive 64 GB | Storage | 25.00 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '| 1002 | SATA HDD 1 TB | Storage | 50.00 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: '| 1003 | SSD 256 GB | Storage | 60.00 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: 'In a row-oriented database, the data is persisted to disk as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: (1001, USB drive 64 GB, storage, 25.00), (1002, SATA HDD 1 TB, storage, 50.00),
    (1003, SSD 256 GB, storage, 60.00)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in a column-oriented database, the data is persisted to disk as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: (1001, 1002, 1003), (USB drive 64 GB, SATA HDD 1 TB, SSD 256 GB), (storage,
    storage, storage), (25.00, 50.00, 60.00)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: In general, column-oriented databases are best suited for analytical workloads,
    also known as **online analytical processing** (**OLAP**), where the emphasis
    is on processing a low number of complex analytical queries typically involving
    aggregations. Examples of use cases include data mining and statistical analysis,
    where database schemas tend to be either denormalized or follow a star or snowflake
    schema design.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Key-value databases
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Key-value databases, such as **Redis**, **Oracle Berkley DB**, and **Voldemort**,
    employ a simple key-value data model to store data as a collection of unique keys
    mapped to value objects. This is illustrated in the following table that maps
    session IDs for web applications to session data:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '| **Key (session ID)** | **Value (session data)** |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| `ab2e66d47a04798` | `{userId: "user1", ip: "75.100.144.28", date: "2018-09-28"}`
    |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| `62f6nhd47a04dshj` | `{userId: "user2", ip: "77.189.90.26", date: "2018-09-29"}`
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| `83hbnndtw3e6388` | `{userId: "user3", ip: "73.43.181.201", date: "2018-09-30"}`
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: Key-value data structures are found in many programming languages where they
    are commonly referred to as *dictionaries* or *hash maps*. Key-value databases
    extend these data structures through their ability to partition and scale horizontally
    across a cluster, thereby effectively providing huge distributed dictionaries.
    Key-value databases are particularly useful as a means to improve the performance
    and throughput of systems that are required to handle potentially millions of
    requests per second. Examples of use cases include popular e-commerce websites,
    storing session data for web applications, and facilitating caching layers.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Graph databases
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Graph databases, such as **Neo4j** and **OrientDB**, model data as a collection
    of vertices (also called nodes) linked together by one or more edges (also called
    relationships or links). In real-world graph implementations, vertices are often
    used to represent real-world entities such as individuals, organizations, vehicles,
    and addresses. Edges are then used to represent relationships between vertices.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图数据库，如 **Neo4j** 和 **OrientDB**，将数据建模为由一个或多个边（也称为关系或链接）连接在一起的顶点（也称为节点）集合。在现实世界的图实现中，顶点通常用于表示现实世界的实体，如个人、组织、车辆和地址。然后使用边来表示顶点之间的关系。
- en: 'Both vertices and edges can have an arbitrary number of key-value pairs, called
    *properties*, associated with them. For example, properties associated with an
    individual vertex may include a name and date of birth. Properties associated
    with an edge linking an individual vertex with another individual vertex may include
    the nature and length of the personal relationship. The collection of vertices,
    edges, and properties together form a data structure called a **property graph**.
    *Figure 1.6* illustrates a simple property graph representing a small social network:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 顶点和边都可以有任意数量的键值对，称为 *属性*，与它们相关联。例如，与单个顶点相关的属性可能包括姓名和出生日期。与连接两个个人顶点的边相关的属性可能包括个人关系的性质和长度。顶点、边和属性的集合共同形成一个称为
    **属性图** 的数据结构。*图 1.6* 展示了一个简单的属性图，它表示一个小型社交网络。
- en: '![](img/1f5837a2-9b5d-4b9a-a99a-8b94bb928b1d.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1f5837a2-9b5d-4b9a-a99a-8b94bb928b1d.png)'
- en: 'Figure 1.6: A simple property graph'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6：一个简单的属性图
- en: Graph databases are employed in a wide variety of scenarios where the emphasis
    is on analyzing the relationships between objects rather than just the object's
    data attributes themselves. Common use cases include social network analysis,
    fraud detection, combating serious organized crime, customer recommendation systems,
    complex reasoning, pattern recognition, blockchain analysis, cyber security, and
    network intrusion detection.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图数据库在各种场景中被使用，在这些场景中，重点在于分析对象之间的关系，而不仅仅是对象的数据属性本身。常见的用例包括社交网络分析、欺诈检测、打击严重有组织犯罪、客户推荐系统、复杂推理、模式识别、区块链分析、网络安全和网络入侵检测。
- en: '**Apache TinkerPop** is an example of a graph computing framework that provides
    a layer of abstraction between the graph data model and the underlying mechanisms
    used to store and process graphs. For example, Apache TinkerPop can be used in
    conjunction with an underlying Apache Cassandra or Apache HBase database to store
    huge distributed graphs containing billions of vertices and edges partitioned
    across a cluster. A graph traversal language called **Gremlin**, a component of
    the Apache TinkerPop framework, can then be used to traverse and analyze the distributed
    graph using one of the Gremlin language variants including Gremlin Java, Gremlin
    Python, Gremlin Scala, and Gremlin JavaScript. To learn more about the Apache
    TinkerPop framework, please visit [http://tinkerpop.apache.org/](http://tinkerpop.apache.org/).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache TinkerPop** 是一个图计算框架的例子，它提供了一个抽象层，位于图数据模型和用于存储和处理图的底层机制之间。例如，Apache
    TinkerPop 可以与底层的 Apache Cassandra 或 Apache HBase 数据库结合使用，以存储包含数十亿个顶点和边的巨大分布式图，这些顶点和边在集群中分区。Apache
    TinkerPop 框架的一个组件，称为 **Gremlin** 的图遍历语言，可以用来遍历和分析分布式图，使用 Gremlin 语言的各种变体，包括 Gremlin
    Java、Gremlin Python、Gremlin Scala 和 Gremlin JavaScript。要了解更多关于 Apache TinkerPop
    框架的信息，请访问 [http://tinkerpop.apache.org/](http://tinkerpop.apache.org/)。'
- en: CAP theorem
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CAP 定理
- en: 'As discussed previously, distributed data stores allow us to store huge volumes
    of data while providing the ability to horizontally scale as a single logical
    unit at all times. Inherent to many distributed data stores are the following
    features:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，分布式数据存储使我们能够存储大量数据，同时始终以单个逻辑单元的水平扩展能力提供。许多分布式数据存储固有的以下特性：
- en: '**Consistency** refers to the guarantee that every client has the same view
    of the data. In practice, this means that a read request to any node in the cluster
    should return the results of the most recent successful write request. Immediate
    consistency refers to the guarantee that the most recent successful write request
    should be immediately available to any client.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性** 指的是每个客户端对数据的视图都相同。在实践中，这意味着对集群中任何节点的读取请求都应该返回最近成功写入请求的结果。即时一致性指的是最近成功写入请求应立即对任何客户端可用。'
- en: '**Availability** refers to the guarantee that the system responds to every
    request made by a client, whether that request was successful or not. In practice,
    this means that every client request receives a response regardless of whether
    individual nodes are non-functional.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性**指的是系统对客户端提出的每个请求做出响应的保证，无论该请求是否成功。在实践中，这意味着每个客户端请求都会收到响应，无论单个节点是否非功能性。'
- en: '**Partition tolerance** refers to the guarantee of resilience given a failure
    in inter-node network communication. In other words, in the event that there is
    a network failure between a particular node and another set of nodes, referred
    to as a network partition, the system will continue to function. In practice,
    this means that the system should have the ability to replicate data across the
    functional parts of the cluster to cater for intermittent network failures and
    in order to guarantee that data is not lost. Thereafter, the system should heal
    gracefully once the partition has been resolved.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分区容错**指的是在节点间网络通信失败时提供的弹性保证。换句话说，如果在特定节点和另一组节点之间存在网络故障，称为网络分区，系统将继续运行。在实践中，这意味着系统应该有能力在集群的功能部分之间复制数据，以应对间歇性网络故障并确保数据不会丢失。然后，系统应该在分区解决后优雅地恢复。'
- en: 'The CAP theorem simply states that a distributed system cannot simultaneously
    be immediately consistent, available, and partition-tolerant. A distributed system
    can simultaneously only ever offer any two of the three. This is illustrated in
    *Figure 1.7*:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: CAP 定理简单地说，分布式系统不能同时立即一致、可用和分区容错。分布式系统可以同时只提供三个中的任意两个。这如图 *图 1.7* 所示：
- en: '![](img/a860264a-cc96-400f-81ec-2f1dcf2d5c13.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a860264a-cc96-400f-81ec-2f1dcf2d5c13.png)'
- en: 'Figure 1.7: The CAP theorem'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7：CAP 定理
- en: '**CA** distributed systems offer immediate consistency and high availability,
    but are not tolerant to inter-node network failure, meaning that data could be
    lost. **CP** distributed systems offer immediate consistency and are resilient
    to network failure, with no data loss. However, they may not respond in the event
    of an inter-node network failure. **AP** distributed systems offer high availability
    and resilience to network failure with no data loss. However, read requests may
    not return the most recent data.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**CA** 分布式系统提供立即一致性和高可用性，但不能容忍节点间网络故障，这意味着数据可能会丢失。**CP** 分布式系统提供立即一致性和对网络故障的弹性，没有数据丢失。然而，在节点间网络故障发生时，它们可能不会响应。**AP**
    分布式系统提供高可用性和对网络故障的弹性，没有数据丢失。然而，读请求可能不会返回最新数据。'
- en: Distributed systems, such as Apache Cassandra, allow for the configuration of
    the level of consistency required. For example, let's assume we have provisioned
    an Apache Cassandra cluster with a replication factor of 3\. In Apache Cassandra,
    a consistency configuration of **ONE** means that a write request is considered
    successful as soon as *one* copy of the data is persisted, without the need to
    wait for the other two replicas to be written. In this case, the system is said
    to be eventually consistent, as the other two replicas will eventually be persisted.
    A subsequent and immediate read request may either return the latest data if it
    is processed by the updated replica, or it may return outdated data if it is processed
    by one of the other two replicas that have yet to be updated (but will eventually
    be). In this scenario, Cassandra is an AP distributed system exhibiting eventual
    consistency and the tolerance of all but one of the replicas failing. It also
    provides the fastest performing system in this context.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统，例如 Apache Cassandra，允许配置所需的一致性级别。例如，假设我们为 Apache Cassandra 集群配置了 3 个副本因子。在
    Apache Cassandra 中，一致性配置为 **ONE** 表示只要 *一个* 数据副本被持久化，写请求就被认为是成功的，无需等待其他两个副本被写入。在这种情况下，系统被认为是最终一致的，因为其他两个副本最终会被持久化。后续的即时读请求可能返回最新数据，如果它是由更新的副本处理的，或者它可能返回过时数据，如果它是由尚未更新的其他两个副本之一处理的（但最终会更新）。在这种情况下，Cassandra
    是一个 AP 分布式系统，表现出最终一致性和对除了一个副本之外的所有副本失败的容忍性。它还提供了在此上下文中性能最快的系统。
- en: A consistency configuration of **ALL** in Apache Cassandra means that a write
    request is considered successful only if all replicas are persisted successfully.
    A subsequent and immediate read request will always return the latest data. In
    this scenario, Cassandra is a CA distributed system exhibiting immediate consistency,
    but with no tolerance of failure. It also provides the slowest performing system
    in this context.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在Apache Cassandra中，**ALL**的一致性配置意味着只有当所有副本都成功持久化后，写请求才被认为是成功的。随后的立即读取请求将始终返回最新的数据。在这种情况下，Cassandra是一个表现出即时一致性的CA分布式系统，但没有对失败的容忍度。它还提供了在此背景下性能最慢的系统。
- en: Finally, a consistency configuration of **QUORUM** in Apache Cassandra means
    that a write request is considered successful only when a strict majority of replicas
    are persisted successfully. A subsequent and immediate read request also using
    QUORUM consistency will wait until data from two replicas (in the case of a replication
    factor of 3) is received and, by comparing timestamps, will always return the
    latest data. In this scenario, Cassandra is also a CA distributed system exhibiting
    immediate consistency, but with the tolerance of a minority of the replicas failing.
    It also provides a median-performing system in this context.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在Apache Cassandra中，**QUORUM**的一致性配置意味着只有当严格多数的副本成功持久化后，写请求才被认为是成功的。随后的立即读取请求也使用QUORUM一致性，将等待从两个副本（在副本因子为3的情况下）接收数据，并通过比较时间戳，总是返回最新的数据。在这种情况下，Cassandra也是一个表现出即时一致性的CA分布式系统，但具有对少数副本失败的容忍度。它还提供了在此背景下性能中等的系统。
- en: Ultimately, in the real world, however, data loss is not an option for most
    business critical systems and a trade-off between performance, consistency and
    availability is required. Therefore, the choice tends to come down to either CP
    or AP distributed systems, with the winner driven by business requirements.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现实世界中，数据丢失对于大多数业务关键系统来说不是可接受的，需要在性能、一致性和可用性之间进行权衡。因此，选择往往归结为CP或AP分布式系统，胜者由业务需求驱动。
- en: Distributed search engines
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式搜索引擎
- en: Distributed search engines, such as **Elasticsearch** based on **Apache Lucene**,
    transform data into highly-optimized data structures for quick and efficient searching
    and analysis. In Apache Lucene, data is indexed into documents containing one
    or more fields representing analyzed data attributes of various data types. A
    collection of documents forms an index, and it is this index that is searched
    when queries are processed, returning the relevant documents that fulfill the
    query. A suitable analogy would be when trying to find pages relating to a specific
    topic in a textbook. Instead of searching every page one by one, the reader may
    instead use the index at the back of the book to find relevant pages quicker.
    To learn more about Apache Lucene, please visit [http://lucene.apache.org/](http://lucene.apache.org/).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Apache Lucene的分布式搜索引擎，如**Elasticsearch**，将数据转换为高度优化的数据结构，以实现快速和高效的搜索和分析。在Apache
    Lucene中，数据被索引到包含一个或多个字段（代表各种数据类型的数据属性）的文档中。文档的集合形成一个索引，当处理查询时，搜索的就是这个索引，返回满足查询的相关文档。一个合适的类比是在教科书试图找到与特定主题相关的页面时。读者不必逐页搜索，而是可以使用书后的索引更快地找到相关页面。要了解更多关于Apache
    Lucene的信息，请访问[http://lucene.apache.org/](http://lucene.apache.org/)。
- en: Elasticsearch extends Apache Lucene by offering the ability to partition and
    horizontally scale search indexes and analytical queries over a distributed cluster,
    coupled with a RESTful search engine and HTTP web interface for high-performance
    searching and analysis. To learn more about Elasticsearch, please visit [https://www.elastic.co/products/elasticsearch](https://www.elastic.co/products/elasticsearch).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch通过提供在分布式集群上分区和水平扩展搜索索引和分析查询的能力，扩展了Apache Lucene，并配备了RESTful搜索引擎和HTTP网络界面，以实现高性能的搜索和分析。要了解更多关于Elasticsearch的信息，请访问[https://www.elastic.co/products/elasticsearch](https://www.elastic.co/products/elasticsearch)。
- en: Distributed processing
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式处理
- en: We have seen how distributed data stores such as the HDFS and Apache Cassandra
    allow us to store and model huge volumes of structured, semi-structured, and unstructured
    data partitioned over horizontally scalable clusters providing fault tolerance,
    resilience, high availability, and consistency. But in order to provide actionable
    insights and to deliver meaningful business value, we now need to be able to process
    and analyze all that data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，如HDFS和Apache Cassandra这样的分布式数据存储如何使我们能够在水平可扩展的集群上存储和建模大量结构化、半结构化和非结构化数据，提供容错、弹性、高可用性和一致性。但是，为了提供可操作的见解并实现有意义的商业价值，我们现在需要能够处理和分析所有这些数据。
- en: Let's return to the traditional data processing scenario we described near the
    start of this chapter. Typically, the data transformation and analytical programming
    code written by an analyst, data engineer or software engineer (for example, in
    SQL, Python, R or SAS) would rely upon the input data to be physically moved to
    the remote processing server or machine where the code to be executed resided.
    This would often take the form of a programmatic query embedded inside the code
    itself, for example, a SQL statement via an ODBC or JDBC connection, or via flat
    files such as CSV and XML files moved to the local filesystem. Although this approach
    works fine for small- to medium-sized datasets, there is a physical limit bounded
    by the computational resources available to the single remote processing server.
    Furthermore, the introduction of flat files such as CSV or XML files, introduces
    an additional, and often unnecessary, intermediate data store that requires management
    and increases disk I/O.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到本章开头描述的传统数据处理场景。通常，分析师、数据工程师或软件工程师（例如，在SQL、Python、R或SAS中）编写的数据转换和分析编程代码会依赖于将输入数据物理移动到远程处理服务器或机器，该机器上驻留着要执行的代码。这通常以程序查询的形式嵌入在代码本身中，例如，通过ODBC或JDBC连接的SQL语句，或者通过将CSV和XML等平面文件移动到本地文件系统。尽管这种方法对于小型到中型数据集来说效果不错，但它受限于单个远程处理服务器可用的计算资源，存在物理限制。此外，引入平面文件如CSV或XML文件，引入了一个额外的、通常不必要的中间数据存储，需要管理并增加磁盘I/O。
- en: The major problem with this approach, however, is that the data needs to be
    moved to the code every time a job is executed. This very quickly becomes impractical
    when dealing with increased data volumes and frequencies, such as the volumes
    and frequencies we associate with big data.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法的主要问题是每次执行作业时都需要将数据移动到代码。当处理增加的数据量和频率时，如我们与大数据相关联的数据量和频率，这种方法很快就会变得不切实际。
- en: We therefore need another data processing and programming paradigm—one where
    code is moved to the data and that works across a distributed cluster. In other
    words, we require distributed processing!
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要另一种数据处理和编程范式——一种将代码移动到数据并能在分布式集群中工作的范式。换句话说，我们需要分布式处理！
- en: The fundamental idea behind distributed processing is the concept of splitting
    a computational processing task into smaller tasks. These smaller tasks are then
    distributed across the cluster and process specific partitions of the data. Typically,
    the computational tasks are co-located on the same nodes as the data itself to
    increase performance and reduce network I/O. The results from each of the smaller
    tasks are then aggregated in some manner before the final result is returned.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式处理背后的基本思想是将计算处理任务分割成更小的任务。这些较小的任务随后在集群中分散，并处理数据的具体分区。通常，计算任务会与数据本身位于同一节点上，以提高性能并减少网络I/O。然后以某种方式汇总每个较小任务的结果，在返回最终结果之前。
- en: MapReduce
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MapReduce
- en: MapReduce is an example of a distributed data processing paradigm capable of
    processing big data in parallel across a cluster of nodes. A MapReduce job splits
    a large dataset into independent chunks and consists of two stages—the first stage
    is the Map function that creates a map task for each range in the input, outputting
    a partitioned group of key-value pairs. The output of the map tasks then act as
    inputs to reduce tasks, whose job it is to combine and condense the relevant partitions
    in order to solve the analytical problem. Before beginning the map stage, data
    is often sorted or filtered based on some condition pertinent to the analysis
    being undertaken. Similarly, the output of the reduce function may be subject
    to a finalization function to further analyze the data.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 是一种分布式数据处理范例，能够在节点集群上并行处理大数据。MapReduce 作业将大型数据集分割成独立的块，并包括两个阶段——第一个阶段是
    Map 函数，它为输入中的每个范围创建一个映射任务，输出一个分区的键值对组。映射任务的输出随后作为减少任务的输入，其任务是合并和压缩相关的分区，以解决分析问题。在开始映射阶段之前，数据通常根据与正在进行的分析相关的条件进行排序或过滤。同样，减少函数的输出可能需要最终化函数来进一步分析数据。
- en: 'Let''s consider a simple example to bring this rather abstract definition to
    life. The example that we will consider is that of a word count. Suppose that
    we have a text file containing millions of lines of text, and we wish to count
    the number of occurrences of each unique word in this text file as a whole. *Figure
    1.8* illustrates how this analysis may be undertaken using the MapReduce paradigm:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个简单的例子，以使这个相当抽象的定义变得生动。我们将考虑的例子是单词计数。假设我们有一个包含数百万行文本的文本文件，我们希望计算整个文本文件中每个唯一单词的出现次数。*图
    1.8* 展示了如何使用 MapReduce 范式进行这种分析：
- en: '![](img/56eea471-4324-4c85-a595-f429c70cdb2e.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/56eea471-4324-4c85-a595-f429c70cdb2e.png)'
- en: 'Figure 1.8: Word count MapReduce program'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8：单词计数 MapReduce 程序
- en: In this example, the original text file containing millions of lines of text
    is split up into its individual lines. Map tasks are applied to ranges of those
    individual lines, splitting them into individual word tokens, in this case, using
    a whitespace tokenizer, and thereafter emitting a collection of key-value pairs
    where the key is the word.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，原始文本文件包含数百万行文本，被分割成单独的行。将映射任务应用于这些单独行的范围，将它们分割成单独的单词标记，在这种情况下，使用空格分词器，然后输出一组键值对，其中键是单词。
- en: A *shuffling* process is undertaken that transfers the partitioned key-value
    pairs emitted by the map tasks to the reduce tasks. Sorting of the key-value pairs,
    grouped by key, is also undertaken. This helps to identify when a new reduce task
    should start. To reduce the amount of data transferred from the map tasks to the
    reduce tasks during shuffling, an optional combiner may be specified that implements
    a local aggregation function. In this example, a combiner is specified that sums,
    locally, the number of occurrences of each key or word for each map output.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 执行一个 *洗牌*过程，将映射任务输出的分区键值对转移到减少任务。根据键对键值对进行排序，也有助于确定何时应该开始新的减少任务。为了在洗牌期间减少从映射任务到减少任务传输的数据量，可以指定一个可选的合并器，该合并器实现一个本地聚合函数。在这个例子中，指定了一个合并器，它对每个映射输出本地地计算每个键或单词的出现次数的总和。
- en: The reduce tasks then take those partitioned key-value pairs and reduce those
    values that share the same key, outputting new (but unsorted) key-value pairs
    unique by key. In this example, the reduce tasks simply sum the number of occurrences
    of that key. The final output of the MapReduce job in this case is simply a count
    of the number occurrences of each word across the whole original text file.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 减少任务随后接收那些分区的键值对，并减少具有相同键的值，输出新的（但未排序的）键值对，键是唯一的。在这个例子中，减少任务简单地计算该键的出现次数。在这种情况下，MapReduce
    作业的最终输出只是整个原始文本文件中每个单词出现次数的计数。
- en: In this example, we used a simple text file that had been split up by a newline
    character that is then mapped to key-value pairs based on a whitespace tokenizer.
    But the same paradigm can easily be extended to distributed data stores, where
    large volumes of data have already been partitioned across a cluster, thereby
    allowing us to perform data processing on a huge scale.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了一个简单的文本文件，该文件已被换行符分割，然后基于空格分词器映射到键值对。但同样的范式可以轻松扩展到分布式数据存储，其中大量数据已经跨集群分区，从而允许我们在巨大规模上进行数据处理。
- en: Apache Spark
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark
- en: Apache Spark is a well-known example of a general-purpose distributed processing
    engine capable of handling **petabytes** (**PB**) of data. Because it is a general-purpose
    engine, it is suited to a wide variety of use cases at scale, including the engineering
    and execution of **Extract-Transform-Load** (**ETL**) pipelines using its **Spark
    SQL** library, interactive analytics, stream processing using its **Spark Streaming**
    library, graph-based processing using its `GraphX` library, and machine learning
    using its `MLlib` library. We will be employing Apache Spark's machine learning
    library in later chapters. For now, however, it is important to get an overview
    of how Apache Spark works under the hood.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'Apache Spark software services run in **Java Virtual Machines** (**JVM**),
    but that does not mean Spark applications must be written in Java. In fact, Spark
    exposes its API and programming model to a variety of language variants, including
    Java, Scala, Python, and R, any of which may be used to write a Spark application.
    In terms of its logical architecture, Spark employs a master/worker architecture
    as illustrated in *Figure 1.9*:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8f95bcce-08c8-4907-9d89-9d1b86919efd.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.9: Apache Spark logical architecture'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Every application written in Apache Spark consists of a **Driver Program**.
    The driver program is responsible for splitting a Spark application into tasks,
    which are then partitioned across the **Worker** nodes in the distributed cluster
    and scheduled to execute by the driver. The driver program also instantiates a
    **SparkContext**, which tells the application how to connect to the Spark cluster
    and its underlying services.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: The worker nodes, also known as slaves, are where the computational processing
    physically occurs. Typically, Spark worker nodes are co-located on the same nodes
    as where the underlying data is also persisted to improve performance. Worker
    nodes spawn processes called **Executors**, and it is these executors that are
    responsible for executing the computational tasks and storing any locally-cached
    data. Executors communicate with the driver program in order to receive scheduled
    functions, such as map and reduce functions, which are then executed. The **Cluster
    Manager** is responsible for scheduling and allocating resources across the cluster
    and must therefore be able to communicate with every worker node, as well as the
    driver. The driver program requests executors from the cluster manager (since
    the cluster manager is aware of the resources available) so that it may schedule
    tasks.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark is bundled with its own simple cluster manager which, when used,
    is referred to as Spark Standalone mode. Spark applications deployed to a standalone
    cluster will, by default, utilize all nodes in the cluster and are scheduled in
    a **First-In-First-Out** (**FIFO**) manner. Apache Spark also supports other cluster
    managers, including **Apache Mesos** and **Apache Hadoop YARN**, both of which
    are beyond the scope of this book.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: RDDs, DataFrames, and datasets
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So how does Spark store and partition data during its computational processing?
    Well, by default, Spark holds data in-memory, which helps to make it such a quick
    processing engine. In fact, as of Spark 2.0 and onward, there are three sets of
    APIs used to hold data— **resilient distributed datasets** (**RDDs**), DataFrames,
    and Datasets.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: RDDs
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'RDDs are an immutable and distributed collection of records partitioned across
    the worker nodes in a Spark cluster. They offer fault tolerance since, in the
    event of non-functional nodes or damaged partitions, RDD partitions can be recomputed,
    since all the dependency information needed to replicate each of its partitions
    is stored by the RDD itself. They also provide consistency, since each partition
    is immutable. RDDs are commonly used in Spark today in situations where you do
    not need to impose a schema when processing the data, such as when unstructured
    data is processed. Operations may be executed on RDDs via a low-level API that
    provides two broad categories of operation:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '**Transformations**: These are operations that return another RDD. Narrow transformations,
    for example, map operations, are operations that can be executed on arbitrary
    partitions of data without being dependent on other partitions. Wide transformations,
    for example, sorting, joining, and grouping, are operations that require the data
    to be repartitioned across the cluster. Certain transformations, such as sorting
    and grouping, require the data to be redistributed across partitions, a process
    known as *shuffling*. Because data needs to be redistributed, wide transformations
    requiring shuffling are expensive operations and should be minimized in Spark
    applications where possible.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Actions**: These are computational operations that return a value back to
    the driver, not another RDD. RDDs are said to be lazily evaluated, meaning that
    transformations are only computed when an action is called.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataFrames
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like RDDs, they are an immutable and distributed collection of records partitioned
    across the worker nodes in a Spark cluster. However, unlike RDDs, data is organized
    into named columns conceptually similar to tables in relational databases and
    tabular data structures found in other programming languages, such as Python and
    R. Because DataFrames offer the ability to impose a schema on distributed data,
    they are more easily exposed to more familiar programming languages such as SQL,
    which makes them a popular and arguably easier data structure to work with and
    manipulate, as well as being more efficient than RDDs.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'The main disadvantage of DataFrames however is that, similar to Spark SQL string
    queries, analysis errors are only caught at runtime and not during compilation.
    For example, imagine a DataFrame called `df` with the named columns `firstname`,
    `lastname`, and `gender`. Now imagine that we coded the following statement:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This statement attempts to filter the DataFrame based on a missing and unknown
    column called `age`. Using the DataFrame API, this error would not be caught at
    compile time but instead only at runtime, which could be costly and time-consuming
    if the Spark application in question involved multiple transformations and aggregations
    prior to this statement.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Datasets
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Datasets extend DataFrames by providing type safety. This means that in the
    preceding example of the missing column, the Dataset API will throw a compile
    time error. In fact, DataFrames are actually an alias for `Dataset[Row]` where
    a Row is an untyped object that you may see in Spark applications written in Java.
    However, because R and Python have no compile-time type safety, this means that
    Datasets are not currently available to these languages.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous advantages to using the DataFrame and Dataset APIs over RDDs,
    including better performance and more efficient memory usage. The high-level APIs
    offered by DataFrame and Dataset also make it easier to perform standard operations
    such as filtering, grouping, and calculating statistical aggregations such as
    totals and averages. RDDs, however, are still useful because of the greater degree
    of control offered by its low-level API, including low-level transformations and
    actions. They also provide analysis errors at compile time and are well suited
    to unstructured data.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Jobs, stages, and tasks
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we know how Spark stores data during computational processing, let's
    return to its logical architecture to understand how Spark applications are logically
    broken down into smaller units for distributed processing.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Job
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When an action is called in a Spark application, Spark will use a dependency
    graph to ascertain the datasets on which that action depends and thereafter formulate
    an execution plan. An execution plan is essentially a chain of datasets, beginning
    with the dataset furthest back all the way through to the final dataset, that
    are required to be computed in order to calculate the value to return to the driver
    program as a result of that action. This process is called a Spark job, with each
    job corresponding to one action.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Stage
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the Spark job and, hence, the action that resulted in the launching of that
    job, involves the shuffling of data (that is, the redistribution of data), then
    that job is broken down into stages. A new stage begins when network communication
    is required between the worker nodes. An individual stage is therefore defined
    as a collection of tasks processed by an individual executor with no dependency
    on other executors.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Tasks
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tasks are the smallest unit of execution in Spark, with a single task being
    executed on one executor; in other words, a single task cannot span multiple executors.
    All the tasks making up one stage share the same code to be executed, but act
    on different partitions of the data. The number of tasks that can be processed
    by an executor is bounded by the number of cores associated with that executor.
    Therefore, the total number of tasks that can be executed in parallel across an
    entire Spark cluster can be calculated by multiplying the number of cores per
    executor by the number of executors. This value then provides a quantifiable measure
    of the level of parallelism offered by your Spark cluster.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 2](673f253e-c30f-41af-b5e0-e5fd301f829c.xhtml),* Setting Up a Local
    Development Environment*, we will discuss how to install, configure, and administer
    a single-node standalone Spark cluster for development purposes, as well as discussing
    some of the basic configuration options exposed by Spark. Then, in [Chapter 3](a2def916-85c5-4a3a-b239-d2b2de09e199.xhtml), *Artificial
    Intelligence and Machine Learning*, and onward, we will take advantage of Spark's
    machine learning library, `MLlib`, so that we may employ Spark as a distributed
    advanced analytics engine. To learn more about Apache Spark, please visit [http://spark.apache.org/](http://spark.apache.org/).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Distributed messaging
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuing our journey through distributed systems, the next category that we
    will discuss is distributed messaging systems. Typically, real-world IT systems
    are, in fact, a collection of distinct applications, potentially written in different
    languages using different underlying technologies and frameworks, that are integrated
    with one another. In order for messages to be sent between distinct applications,
    developers could potentially code the consumption logic into each individual application.
    This is a bad idea however—what happens if the type of message sent by an upstream
    application changes? In this case, the consumption logic would have to be rewritten,
    relevant applications updated, and the whole system retested.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'Messaging systems, such as **Apache ActiveMQ** and **RabbitMQ**, overcome this
    problem by providing a middleman called a message broker. *Figure 1.10* illustrates
    how message brokers work at a high level:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4979adfe-632b-4eae-8027-e835cda0ed07.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.10: Message broker high-level overview'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, **Producers** are applications that generate and send messages
    required for the functionality of the system. The **Message Broker** receives
    these messages and stores them inside queue data structures or buffers. **Consumer** applications,
    which are applications designed to process messages, subscribe to the message
    broker. The message broker then delivers these messages to the **Consumer** applications
    which consume and process them. Note that a single application can be a producer,
    consumer, or both.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Distributed messaging systems, which is one use case of **Apache Kafka**, extend
    traditional messaging systems by being able to partition and scale horizontally,
    while offering high throughput, high performance, fault tolerance, and replication,
    like many other distributed systems. This means that messages are never lost,
    while offering the ability to load balance requests and provide ordering guarantees.
    We will discuss Apache Kafka in more detail next, but in the context of a distributed
    streaming platform for real-time data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Distributed streaming
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine processing the data stored in a traditional spreadsheet or text-based
    delimited files such as a CSV file. The type of processing that you will typically
    execute when using these types of data stores is referred to as **batch processing**.
    In batch processing, data is collated into some sort of group, in this case, the
    collection of lines in our spreadsheet or CSV file, and processed together as
    a group at some future time and date. Typically, these spreadsheets or CSV files
    will be refreshed with updated data at some juncture, at which point the same,
    or similar, processing will be undertaken, potentially all managed by some sort
    of schedule or timer. Traditionally, data processing systems would have been developed
    with batch processing in mind, including conventional data warehouses.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Today, however, batch processing alone is not enough. With the advent of the
    internet, social media, and more powerful technology, coupled with the demand
    for mass data consumption as soon as possible (ideally immediately), real-time
    data processing and analytics are no longer a luxury for many businesses but instead
    a necessity. Examples of use cases where real-time data processing is vital include
    processing financial transactions and real-time pricing, real-time fraud detection
    and combating serious organized crime, logistics, travel, robotics, and artificial
    intelligence.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '**Micro-batch processing** extends standard batch processing by executing at
    smaller intervals (typically seconds or milliseconds) and/or on smaller batches
    of data. However, like batch processing, data is still processed a batch at a
    time.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '**Stream processing** differs from micro-batch and batch processing in the
    fact that data processing is executed as and when individual data units arrive.
    Distributed streaming platforms, such as **Apache Kafka**, provide the ability
    to safely and securely move real-time data between systems and applications. Thereafter,
    distributed streaming engines, such as Apache Spark''s Streaming library, **Spark
    Streaming**, and **Apache Storm**, allow us to process and analyze real-time data.
    In [Chapter 8](cad17bf3-6d9d-4486-a405-3d5103b072c5.xhtml),* Real-Time Machine
    Learning Using Apache Spark*, we will discuss Spark Streaming in greater detail,
    where we will develop a real-time sentiment analysis model by combining Apache
    Kafka with Spark Streaming and Apache Spark''s machine learning library, `MLlib`.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 'In the meantime, let''s quickly take a look into how Apache Kafka works under
    the hood. Take a moment to think about what kind of things you would need to consider
    in order to engineer a real-time streaming platform:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '**Fault tolerance**: The platform must not lose real-time streams of data and
    have some way to store them in the event of partial system failure.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ordering**: The platform must provide a means to guarantee that streams can
    be processed in the order that they are received, which is especially important
    to business applications where order is critical.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliability**: The platform must provide a means to reliably and efficiently
    move streams between various distinct applications and systems.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apache Kafka provides all of these guarantees through its distributed streaming
    logical architecture, as illustrated in *Figure 1.11*:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b0eadee8-c500-45e1-af50-4285102a8848.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.11: Apache Kafka logical architecture'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: In Apache Kafka, a *topic* refers to a stream of records belonging to a particular
    category. Kafka's Producer API allows producer applications to publish streams
    of records to one or more Kafka topics, and its Consumer API allows consumer applications
    to subscribe to one or more topics and thereafter receive and process the stream
    of records belonging to those topics. Topics in Kafka are said to be multi-subscriber,
    meaning that a single topic may have zero, one, or more consumers subscribed to
    it. Physically, a Kafka topic is stored as a sequence of ordered and immutable
    records that can only be appended to and are partitioned and replicated across
    the Kafka cluster, thereby providing scalability and fault tolerance for large
    systems. Kafka guarantees that producer messages are appended to a topic partition
    in the order that they are sent, with the producer application responsible for
    identifying which partition to assign records to, and that consumer applications
    can access records in the order in which they are persisted.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Kafka has become synonymous with real-time data because of its logical architecture
    and the guarantees that it provides when moving real-time streams of data between
    systems and applications. But Kafka can also be used as a stream processing engine
    as well in its own right via its Streams API, not just as a messaging system.
    By means of its Streams API, Kafka allows us to consume continual streams of data
    from input topics, process that data in some manner or other, and thereafter produce
    continual streams of data to output topics. In other words, Kafka allows us to
    transform input streams of data into output streams of data, thereby facilitating
    the engineering of real-time data processing pipelines in competition with other
    stream processing engines such as Apache Spark and Apache Storm.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 8](cad17bf3-6d9d-4486-a405-3d5103b072c5.xhtml), *Real-Time Machine
    Learning Using Apache Spark*, we will use Apache Kafka to reliably move real-time
    streams of data from their source systems to Apache Spark. Apache Spark will then
    act as our stream processing engine of choice in conjunction with its machine
    learning library. In the meantime, however, to learn more about Apache Kafka,
    please visit [https://kafka.apache.org/](https://kafka.apache.org/).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Distributed ledgers
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To finish our journey into distributed systems, let's talk about a particular
    type of distributed system that could potentially form the basis of a large number
    of exciting cutting-edge technologies in the future. Distributed ledgers are a
    special class within distributed databases made famous recently by the prevalence
    of blockchain and subsequent cryptocurrencies such as Bitcoin.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, when you make a purchase using your credit or debit card, the
    issuing bank acts as the centralized authority. As part of the transaction, a
    request is made to the bank to ascertain whether you have sufficient funds to
    complete the transaction. If you do, the bank keeps a record of the new transaction
    and deducts the amount from your balance, allowing you to complete the purchase.
    The bank keeps a record of this and all transactions on your account. If you ever
    wish to view your historic transactions and your current overall balance, you
    can access your account records online or via paper statements, all of which are
    managed by the trusted and central source—your bank.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Distributed ledgers, on the other hand, have no single trusted central authority.
    Instead, records are independently created and stored on separate nodes forming
    a distributed network, in other words, a distributed database, but data is never
    created nor passed through a central authority or master node. Every node in the
    distributed network processes every transaction. If you make a purchase using
    a cryptocurrency such as Bitcoin based on Blockchain technology, which is one
    form of distributed ledger, the nodes vote on the update. Once a majority consensus
    is reached, the distributed ledger is updated and the latest version of the ledger
    is saved on each node separately.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: As described, Blockchain is one form of a distributed ledger. As well as sharing
    the fundamental features of distributed ledgers, in blockchain, data is grouped
    into blocks that are secured using cryptography. Records in blockchain cannot
    be altered or deleted once persisted, but can only be appended to, making blockchain
    particularly well suited to use cases where maintaining a secure historical view
    is important, such as financial transactions and cryptocurrencies including Bitcoin.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence and machine learning
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have discussed how distributed systems can be employed to store, model, and
    process huge amounts of structured, semi-structured, and unstructured data, while
    providing horizontal scalability, fault tolerance, resilience, high availability,
    consistency, and high throughput. However, other fields of study have become prevalent
    today, seemingly in conjunction with the rise of big data—artificial intelligence
    and machine learning.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: But why have these fields of study, the underlying mathematical theories of
    which have been around for decades, and even centuries in some cases, risen to
    prominence at the same time as big data? The answer to this question lies in understanding
    the benefits offered by this new breed of technology.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Distributed systems allow us to consolidate, aggregate, transform, process,
    and analyze vast volumes of previously disparate data. The process of consolidating
    these disparate datasets allows us to infer insights and uncover hidden relationships
    that would have been impossible previously. Furthermore, cluster computing, such
    as that offered by distributed systems, exposes more powerful and numerous hardware
    and software working together as a single logical unit that can be assigned to
    solve complex computational tasks such as those inherent to artificial intelligence
    and machine learning. Today, by combining these features, we can efficiently run
    advanced analytical algorithms to ultimately provide actionable insights, the
    level and breadth of which have never been seen before in many mainstream industries.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark's machine learning library, `MLlib`, and `TensorFlow` are examples
    of libraries that have been developed to allow us to quickly and efficiently engineer
    and execute machine learning algorithms as part of analytical processing pipelines.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 3](a2def916-85c5-4a3a-b239-d2b2de09e199.xhtml), *Artificial Intelligence
    and Machine Learning*, we will discuss some of the high-level concepts behind
    common artificial intelligence and machine learning algorithms, as well as the
    logical architecture behind Apache Spark's machine learning library `MLlib`. Thereafter,
    in [Chapter 4](ea16659b-adfc-4cab-8e71-99c155b07a46.xhtml), *Supervised Learning
    Using Apache Spark*, through to [Chapter 8](cad17bf3-6d9d-4486-a405-3d5103b072c5.xhtml), *Real-Time
    Machine Learning Using Apache Spark*, we will develop advanced analytical models
    with `MLlib` using real-world use cases, while exploring their underlying mathematical
    theory.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about `MLlib` and `TensorFlow`, please visit [https://spark.apache.org/mllib/](https://spark.apache.org/mllib/)
    and [https://www.tensorflow.org/](https://www.tensorflow.org/) respectively.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Cloud computing platforms
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditionally, many large organizations have invested in expensive data centers
    to house their business-critical computing systems. These data centers are integrated
    with their corporate networks, allowing users to access both the data stored in
    these centers and increased processing capacity. One of the main advantages of
    large organizations maintaining their own data centers is that of security—both
    data and processing capacity is kept on-premise under their control and administration
    within largely closed networks.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: However, with the advent of big data and more accessible artificial intelligence
    and machine learning-driven analytics, the need to store, model, process, and
    analyze huge volumes of data requiring scalable hardware, software, and potentially
    distributed clusters containing hundreds or thousands of physical or virtual nodes
    quickly makes maintaining your own 24/7 data centers less and less cost-effective.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Cloud computing platforms, such as **Amazon Web Services** (**AWS**), **Microsoft
    Azure**, and the **Google Cloud Platform** (**GCP**), provide a means to offload
    some or all of an organization's data storage, management, and processing requirements
    to remote platforms managed by technology companies and that are accessible over
    the internet. Today, these cloud computing platforms offer much more than just
    a place to remotely store an organization's ever-increasing data estate. They
    offer scalable storage, computational processing, administration, data governance,
    and security software services, as well as access to artificial intelligence and
    machine learning libraries and frameworks. These cloud computing platforms also
    tend to offer a **Pay-As-You-Go** (**PAYG**) pricing model, meaning that you only
    pay for the storage and processing capacity that you actually use, which can also
    be easily scaled up or down depending on requirements.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Organizations that are weary of storing their sensitive data on remote platforms
    accessible over the internet tend to instead architect and engineer hybrid systems,
    whereby sensitive data remains on-premise, but computational processing on anonymized
    or unattributable data is offloaded to the cloud, for example.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: A well-architected and well-engineered system should provide a layer of abstraction
    between its infrastructure and its end users, including data analysts and data
    scientists—that is, the fact as to whether the data storage and processing infrastructure
    is on-premise or cloud-based should be invisible to these types of user. Furthermore,
    many of the distributed technologies and processing engines that we have discussed
    so far tend to be written in Java or C++, but expose their API or programming
    model to other language variants, such as Python, Scala, and R. This therefore
    makes them accessible to a wide range of end users, deployable on any machines
    that can run a JVM or compile C++ code. A significant number of cloud services
    offered by cloud computing platforms are, in fact, commercial service wrappers
    built around open source technologies guaranteeing availability and support. Therefore,
    once system administrators and end users become familiar with a particular class
    of technology, migrating to cloud computing platforms actually becomes a matter
    of configuration to optimize performance rather than learning an entirely new
    way to store, model, and process data. This is important, since a significant
    cost for many organizations is the training of its staff—if underlying technologies
    and frameworks can be reused as much as possible, then this is preferable to migrating
    to entirely new storage and processing paradigms.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Data insights platform
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have discussed the various systems, technologies, and frameworks available
    today to allow us to store, aggregate, manage, transform, process, and analyze
    vast volumes of structured, semi-structured, and unstructured data in both batch
    and real time in order to provide actionable insights and deliver real business
    value. We will conclude this chapter by discussing how all of these systems and
    technologies can fully integrate with one another to deliver a consolidated, high-performance,
    secure, and reliable data insights platform accessible to all parts of your organization.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Reference logical architecture
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can represent a data insights platform as a series of logical layers, where
    each layer provides a distinct functional capability. When we combine these layers,
    we form a reference logical architecture for a data insights platform, as illustrated
    in *Figure 1.12*:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c20d0d33-9783-4cad-aa90-fbc4fd6c9821.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.12: Data insights platform reference logical architecture'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: The logical layers in this data insights platform reference architecture are
    described in further detail in the following sub-sections.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Data sources layer
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data sources layer represents the various disparate data stores, datasets,
    and other source data systems that will provide the input data into the data insights
    platform. These disparate source data providers may contain either structured
    (for example, delimited text files, CSVs, and relational databases), semi-structured
    (for example, JSON and XML files) or unstructured (for example, images, videos,
    and audio) data.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Ingestion layer
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ingestion layer is responsible for consuming and thereafter moving the
    source data, no matter what their format and frequency, to either a persistent
    data store, or directly to a downstream data processing engine. The ingestion
    layer should be capable of supporting both batch data and stream-based event data.
    Examples of open source technologies used to implement the ingestion layer include
    the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Apache Sqoop
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Kafka
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Flume
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Persistent data storage layer
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The persistent data storage layer is responsible for consuming and persisting
    the raw source data provided by the ingestion layer. Little or no transformation
    of the raw source data takes place before it is persisted to ensure that the raw
    data remains in its original format. A data lake is a class of persistent data
    store that is often implemented to store raw data in this manner. Example technologies
    used to implement the persistent data storage layer include the following:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Traditional network-based stores, such as **Storage Area Networks** (**SAN**)
    and **Network Attached Storage** (**NAS**)
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open source technologies, such as the HDFS
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud-based technologies, such as **AWS S3** and **Azure BLOBs**
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data processing layer
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data processing layer is responsible for the transformation, enrichment,
    and validation of the raw data gathered from either the persistent data store
    or directly from the ingestion layer. The data processing layer models the data
    according to downstream business and analytical requirements and prepares it for
    either persistence in the serving data storage layer, or for processing by data
    intelligence applications. Again, the data processing layer must be capable of
    processing both batch data and stream-based event data. Examples of open source
    technologies used to implement the data processing layer include the following:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Apache Hive
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Spark, including Spark Streaming (DStreams) and Structured Streaming
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Kafka
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Storm
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serving data storage layer
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The serving analytical data storage layer is responsible for persisting the
    transformed, enriched, and validated data produced by the data processing layer
    in data stores that maintain the data model structures so that they are ready
    to serve downstream data intelligence and data insight applications. This minimizes
    or removes the need for further data transformations since the data is already
    persisted in highly-optimized data structures relevant to the type of processing
    required. The types of data stores provisioned in the serving analytical data
    storage layer are dependent on business and analytical requirements, and may include
    any, or a combination of, the following (stated along with examples of open source
    implementations):'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Relational databases, such as **PostgreSQL** and **MySQL**
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document databases, such as **Apache CouchDB** and **MongoDB**
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Columnar databases, such as **Apache Cassandra** and **Apache HBase**
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key-value databases, such as **Redis** and **Voldemort**
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph databases and frameworks, such as **Apache TinkerPop**
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search engines, such as **Apache Lucene** and **Elasticsearch**
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data intelligence layer
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data intelligence layer is responsible for executing advanced analytical
    pipelines, both predictive and prescriptive, on both the transformed batch data
    and stream-based event data. Advanced analytical pipelines may include artificial
    intelligence services such as image and speech analysis, cognitive computing,
    and complex reasoning, as well as machine learning models and natural language
    processing. Examples of open source, advanced analytical libraries and frameworks
    used to implement the data intelligence layer include the following:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '**Apache Spark MLlib** (API accessible via Python, R, Java, and Scala)'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TensorFlow** (API accessible via Python, Java, C++, Go, and JavaScript, with
    third-party bindings available in C#, R, Haskell, Ruby, and Scala)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unified access layer
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The unified access layer is responsible for providing access to both the serving
    analytical data storage layer and third-party APIs exposed by the data intelligence
    layer. The unified access layer should provide universal, scalable, and secure
    access to any downstream applications and systems that require it, and typically
    involves the architecting and engineering of APIs and/or implementations of data
    federation and virtualization patterns. Examples of open source technologies used
    to implement the unified access layer include the following:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Spring framework
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Drill
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data insights and reporting layer
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data insights and reporting layer is responsible for exposing the data
    insights platform to end users, including data analysts and data scientists. Data
    discovery, self-service business intelligence, search, visualization, data insights,
    and interactive analytical applications can all be provisioned in this layer and
    can access both the transformed data in the serving analytical data storage layer
    and third-party APIs in the data intelligence layer, all via the unified access
    layer. The fundamental purpose of the data insights and reporting layer is to
    deliver actionable insights and business value derived from all the structured,
    semi-structured, and unstructured data available to the data insights platform
    in both batch and real time. Examples of open source technologies used to implement
    the data insights and reporting layer that are also accessible to end users include
    the following:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Apache Zeppelin
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jupyter Notebook
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elastic Kibana
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BIRT Reporting
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom JavaScript-based web applications for search and visualization
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples of commercial technologies include the following business intelligence
    applications for creating dashboards and reporting:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Tableau
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Power BI
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SAP Lumira
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: QlikView
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Platform governance, management, and administration
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, since the data insights platform is designed to be accessible by all
    areas of an organization, and will store sensitive data leading to the generation
    of actionable insights, the systems it contains must be properly governed, managed,
    and administered. Therefore, the following additional logical layers are required
    in order to provision a secure enterprise and production-grade platform:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '**Governance and Security**: This layer includes **identity and access management**
    (**IDAM**) and data governance tooling. Open source technologies used to implement
    this layer include the following:'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Knox (Hadoop Authentication Gateway)
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Metron (Security Analytics Framework)
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Ranger (Monitor Data Security)
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenLDAP (Lightweight Directory Access Protocol Implementation)
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Management, Administration, and Orchestration**: This layer includes DevOps
    processes (such as version control, automated builds, and deployment), cluster
    monitoring and administration software, and scheduling and workflow management
    tooling. Open source technologies used to implement this layer include the following:'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jenkins (Automation Server)
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Git (Version Control)
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Ambari (Administration, Monitoring, and Management)
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Oozie (Workflow Scheduling)
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network and Access Middleware**: This layer handles network connectivity
    and communication, and includes network security, monitoring, and intrusion detection
    software.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hardware and Software**: This layer contains the physical storage, compute,
    and network infrastructure on which the data insights platform is deployed. The
    physical components may be on-premise, cloud-based, or a hybrid combination of
    the two.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open source implementation
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Figure 1.13* illustrates an example implementation of the reference data insights
    platform using only open source technologies and frameworks:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/357bfc33-5fa1-4e8c-923a-c2821e7ff8c7.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.13: Example of open source implementation of the data insights platform'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have explored a new breed of distributed and scalable technologies
    that allow us to reliably and securely store, manage, model, transform, process,
    and analyze huge volumes of structured, semi-structured, and unstructured data
    in both batch and real time in order to derive real actionable insights using
    advanced analytics.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will guide you through how to install, configure, deploy,
    and administer a single-node analytical development environment utilizing a subset
    of these technologies, including Apache Spark, Apache Kafka, Jupyter Notebook,
    Python, Java, and Scala!
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
