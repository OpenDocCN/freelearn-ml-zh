<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Natural Language Processing in Practice</h1>
                </header>
            
            <article>
                
<p>Natural language processing is the science (and art) of parsing, analyzing, and reconstructing natural language, such as written or spoken English, French, or German. It's not an easy task; <strong>natural language processing</strong> (<strong>NLP</strong>) is an entire field of research with a vibrant academic research community and significant financial backing from major tech firms. Every time companies such as Google, Apple, Amazon, and Microsoft invest in their Google Assistant, Siri, Alexa, and Cortana products, the field of NLP gets a little more funding. In short, NLP is why you can talk to your phone and your phone can talk back to you.</p>
<p>Siri is a lot more than NLP. We, as consumers, like to criticize our <strong>artificial intelligence</strong> (<strong>AI</strong>) assistants when they get something laughably wrong. But they are truly marvels of engineering, and the fact that they get <em>anything </em>right is a wonder!</p>
<p>If I look at my phone and say, <em>Ok Google, give me directions to 7-Eleven</em>, my phone will automatically wake up and respond to me, <em>Ok, going to 7-Eleven on Main Ave, make the next right</em>. Let's think about what that takes to accomplish:</p>
<ul>
<li>My sleeping phone is monitoring for my pre-trained OK Google catchphrase.</li>
<li>The audio buffer gets an audio hash match on the OK Google soundwaves that I trained, and wakes up the phone.</li>
<li>The phone starts capturing audio, which is just a time-series vector of numbers (representing sound wave intensity).</li>
<li>The speech audio is decoded to phonemes, or textual representation of phonetic sounds. Several candidates for each utterance are generated.</li>
</ul>
<ul>
<li>The candidate phonemes are combined together to try to make words. The algorithm uses a max-likelihood or other estimator to figure out which of the combinations is most likely to be a real sentence that would be used in the current context.</li>
<li>The resultant sentence must be parsed for meaning, so many types of preprocessing are performed, and each word is tagged with its possible <strong>parts of speech</strong> (<strong>POS</strong>).</li>
<li>A learning system (typically an ANN) will try to determine intent given the phrase's subject, object, and verb.</li>
<li>The actual intent must be carried out by a subroutine.</li>
<li>A response to the user must be formulated. In the case where the response can't be scripted, it must be generated algorithmically.</li>
<li>A text-to-speech algorithm decodes the response into phonemes and must then synthesize natural-sounding speech, which then plays over your phone's speakers.</li>
</ul>
<p>Congratulations, you're on your way to getting your Slurpee! Your experience is powered by several ANNs, many different uses of various NLP tools, giant corpuses of data, and millions of engineer-hours of effort to build and maintain. This experience also explains the close relationship between NLP and ML—they are not the same thing, but they're partnered together at the forefront of technology.</p>
<p>Obviously, there's more to NLP than the topics we can cover in 25 pages. This chapter doesn't aim to be comprehensive; its aim is to familiarize you with the most common tactics you'll employ when solving ML problems that involve natural language. We'll take a whirlwind tour of seven NLP-related concepts:</p>
<ul>
<li>Measuring string distance</li>
<li>The TF-IDF metric</li>
<li>Tokenizing text</li>
<li>Stemming words</li>
<li>Phonetics</li>
<li>Parts of speech tagging</li>
<li>Word embedding with Word2vec</li>
</ul>
<p>Don't worry if those topics look daunting. We'll introduce each one in turn and show lots of examples. There's a lot of jargon involved in NLP, and many edge cases, so the topic seems unapproachable at first glance. But the topic is <em>natural language</em> after all: we speak it every day! Once we learn the jargon, the topic becomes quite intuitive, because we all have a very strong intuitive understanding of language.</p>
<p>We'll start our discussion with a simple question: how do you measure the distance between <em>quit </em>and <em>quote</em>? We already know that we can measure the distance between two points in space, so now let's take a look at measuring the distance between two words.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">String distance</h1>
                </header>
            
            <article>
                
<p>It is always convenient to be able to measure some form of distance between two points. In previous chapters, we used the distance between points to aid in clustering and classification. We can do the same for words and passages in NLP. The problem, of course, is that words are made up of letters, and distances are made up of numbers—so how do we make a number out of two words?</p>
<p>Enter Levenshtein distance<em>—</em>a simple metric that measures the number of single-character edits it would take to transform one string into the other. The Levenshtein distance allows insertions, deletions, and substitutions. A modification of the Levenshtein distance, called the <strong>Damerau-Levenshtein distance</strong>, also allows transpositions, or the swapping of two neighboring letters.</p>
<p>To illustrate this concept with an example, let's try transforming the word <strong>crate</strong> into the word <strong>plate</strong>:</p>
<ul>
<li>Replace the <strong>r</strong> with <strong>l </strong>to get <strong>clate</strong></li>
<li>Replace the <strong>c </strong>with a <strong>p </strong>to get <strong>plate</strong></li>
</ul>
<p>The Levenshtein distance between crate and plate is therefore 2.</p>
<p>The distance between <strong>plate</strong> and <strong>laser</strong> is 3:</p>
<ul>
<li>Delete the <strong>p</strong> to get <strong>late</strong></li>
<li>Insert an <strong>r</strong> to get <strong>later</strong></li>
<li>Replace the <strong>t</strong> with an <strong>s</strong> to get <strong>laser</strong></li>
</ul>
<p>Let's confirm these examples in code. Create a new directory called <kbd>Ch10-NLP</kbd> and add the following <kbd>package.json</kbd> file:</p>
<pre>{<br/>  <span>"name"</span>: <span>"Ch10-NLP"</span>,<br/>  <span>"version"</span>: <span>"1.0.0"</span>,<br/>  <span>"description"</span>: <span>"ML in JS Example for Chapter 10 - NLP"</span>,<br/>  <span>"main"</span>: <span>"src/index.js"</span>,<br/>  <span>"author"</span>: <span>"Burak Kanber"</span>,<br/>  <span>"license"</span>: <span>"MIT"</span>,<br/>  <span>"scripts"</span>: {<br/>    <span>"start"</span>: <span>"node src/index.js"<br/></span><span>  </span>},<br/>  <span>"dependencies"</span>: {<br/>    <span>"compromise"</span>: <span>"^11.7.0"</span>,<br/>    <span>"natural"</span>: <span>"^0.5.6"</span>,<br/>    <span>"wordnet-db"</span>: <span>"^3.1.6"<br/></span><span>  </span>}<br/>}</pre>
<p>Then issue <kbd>yarn install</kbd> from the command line to install the dependencies. This <kbd>package.json</kbd> file is a little different from the one in previous chapters, because the <kbd>wordnet-db</kbd> dependency is not compatible with the Browserify bundler. We will therefore have to omit some advanced JavaScript features in this chapter.</p>
<p>Create a directory called <kbd>src</kbd> and add to it an <kbd>index.js</kbd> file to which you'll add the following:</p>
<pre><span>const </span><span>compromise </span>= <span>require</span>(<span>'compromise'</span>);<br/><span>const </span><span>natural </span>= <span>require</span>(<span>'natural'</span>);</pre>
<p>You'll use these imports for the rest of the chapter, so keep them in the <kbd>index.js</kbd> file. However, the rest of the code we use in this chapter will be fungible; you may delete old irrelevant code as you work through the examples in this chapter if you wish.</p>
<p>Let's take a look at Levenshtein distance using the <kbd>natural.js</kbd> library:</p>
<pre>[<br/>    [<span>'plate'</span>, <span>'laser'</span>],<br/>    [<span>'parachute'</span>, <span>'parasail'</span>],<br/>    [<span>'parachute'</span>, <span>'panoply'</span>]<br/>]<br/>    .<span>forEach</span>(<span>function</span>(pair) {<br/>        <span>console</span>.<span>log</span>(<span>"Levenshtein distance between '"</span>+pair[<span>0</span>]+<span>"' and '"</span>+pair[<span>1</span>]+<span>"': "<br/></span><span>            </span>+ <span>natural</span>.<span>LevenshteinDistance</span>.<span>apply</span>(<span>null</span>, pair)<br/>        );<br/>    });</pre>
<p>Run <kbd>yarn start</kbd> from the command line and you'll see the following output:</p>
<pre><strong>Levenshtein distance between 'plate' and 'laser': 3</strong><br/><strong>Levenshtein distance between 'parachute' and 'parasail': 5</strong><br/><strong>Levenshtein distance between 'parachute' and 'panoply': 7</strong></pre>
<p>Try experimenting with a few pairs of words and see if you can calculate the distances in your head to get an intuitive feel for it.</p>
<p>The Levenshtein distance has many uses, since it is a metric and not any specific tool. Other systems, such as spellcheckers, suggester's, and fuzzy matcher's, use Levenshtein, or edit distance metrics in their own algorithms.</p>
<p>Let's take a look at a more advanced metric: the TF-IDF score, which represents how interesting or important a particular word is among a set of documents.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Term frequency - inverse document frequency</h1>
                </header>
            
            <article>
                
<p>One of the most popular metrics used in search relevance, text mining, and information retrieval is the <strong>term frequency-inverse document frequency</strong> (<strong>TF-IDF</strong>) score. In essence, TF-IDF measures how significant a word is to a particular document. <span>The TF-IDF metric therefore only makes sense in the context of a word in a document that's part of a larger corpus of documents.</span></p>
<p>Imagine you have a corpus of documents, such as blog posts on varying topics, that you want to make searchable. The end user of your application runs a search query for <em>fashion style</em>. How do you then find matching documents and rank them by relevance?</p>
<p>The TF-IDF score is made of two separate but related components. The first is <em>term frequency</em>, or the relative frequency of a specific term in a given document. If a 100-word blog post contains the word <em>fashion </em>four times, then the term frequency of the word <em>fashion</em> is 4% for that one document.</p>
<div class="packt_infobox">Note that term frequency only requires a single term and a single document as parameters; the full corpus of documents is not required for the term frequency component of TF-IDF.</div>
<p>Term frequency by itself is not sufficient to determine relevance, however. Words such as <em>this</em> and <em>the</em> appear very frequently in most text and will have high term frequencies, but those words are not typically relevant to any search.</p>
<p>We therefore introduce a second metric to our calculation: inverse document frequency. This metric is essentially the inverse of the percentage of documents that a given word appears in. If you have 1,000 blog posts, and the word <em>fashion</em> appears in 50 of them, the (non-inverse) document frequency of that word is 5%. The inverse document frequency is an extension of this concept, given by taking the log of the inverse document frequency.</p>
<p>If n<sub>fashion </sub>is the number of documents containing the word <em>fashion</em> and <em>N</em> is the total number of documents, then the inverse document frequency is given by <em>log(N / n<sub>fashion</sub>)</em>. In our example, the inverse document frequency of the word <em>fashion</em> is roughly 1.3.</p>
<p>If we now consider the word <em>the</em>, which may appear in 90% of documents, we find that the inverse document frequency of <em>the</em> is 0.0451, much smaller than the 1.3 we got for <em>fashion</em>. The inverse document frequency therefore measures how rare or unique a given word is across a set of documents; higher values mean the word is more rare. The parameters required to calculate inverse document frequency are the term itself and the corpus of documents (unlike term frequency, which only requires one document).</p>
<p>The TF-IDF score is calculated by multiplying the term frequency and inverse document frequency together. The result is a single metric that encapsulates how significant or interesting a single term is to a specific document, considered across all documents that you've seen. Words such as <em>the</em> and <em>that</em> may have high term frequencies in any one document, but because they are prevalent across all documents, their overall TF-IDF score will be very low. Words, such as <em>fashion</em>, that exist only in a subset of documents will have a higher TF-IDF score. When comparing two separate documents that both contain the word <em>fashion</em>, the document that uses it more often will have a higher TF-IDF score, as the inverse document frequency portion will be the same for both documents.</p>
<p>When scoring search results for relevance, the most common approach is to calculate the TF-IDF scores for each term in the search query and for each document in the corpus. The individual TF-IDF scores for each query term can be added together, and the resultant sum can be called the <strong>relevance score</strong> of that particular document. Once all matching documents are scored in this manner, you can sort by relevance and display them in that order. Most full-text search systems, such as Lucene and Elasticsearch, use this sort of approach to relevance scoring.</p>
<p>Let's see this in practice, using the <kbd>natural.js</kbd> TF-IDF tool. Add the following to <kbd>index.js</kbd>:</p>
<pre><span>const </span><span>fulltextSearch </span>= (query, documents) =&gt; {<br/>    <span>const </span><span>db </span>= <span>new </span><span>natural</span>.<span>TfIdf</span>();<br/>    documents.<span>forEach</span>(document =&gt; <span>db</span>.<span>addDocument</span>(document));<br/>    <span>db</span>.<span>tfidfs</span>(query, (docId, score) =&gt; {<br/>        <span>console</span>.<span>log</span>(<span>"DocID " </span>+ docId + <span>" has score: " </span>+ score);<br/>    });<br/>};<br/><br/><span>fulltextSearch</span>(<span>"fashion style"</span>, [<br/>    <span>"i love cooking, it really relaxes me and makes me feel at home"</span>,<br/>    <span>"food and restaurants are basically my favorite things"</span>,<br/>    <span>"i'm not really a fashionable person"</span>,<br/>    <span>"that new fashion blogger has a really great style"</span>,<br/>    <span>"i don't love the cinematic style of that movie"<br/></span>]);</pre>
<p>This code defines a <kbd>fulltextSearch</kbd> function that accepts a search query and an array of documents to be searched. Each document is added to the TF-IDF database object, where it is automatically tokenized by <kbd>natural.js</kbd>. Run the program with <kbd>yarn start</kbd> and you'll see the following output:</p>
<pre><strong>DocID 0 has score: 0</strong><br/><strong>DocID 1 has score: 0</strong><br/><strong>DocID 2 has score: 0</strong><br/><strong>DocID 3 has score: 3.4271163556401456</strong><br/><strong>DocID 4 has score: 1.5108256237659907</strong></pre>
<p>The first two documents, which have nothing to do with fashion or style, return scores of zero. The term frequency component for both <em>fashion</em> and <em>style</em> in those documents is zero, so the overall score becomes zero. The third document also has a score of zero. This document does make a reference to fashion, however, the tokenizer was not able to reconcile the word <em>fashionable</em> with <em>fashion</em>, as no stemming has been performed. We'll discuss both tokenization and stemming in depth in the later sections of this chapter, but for now it's sufficient to know that <em>stemming </em>is an operation that reduces a word to its root form.</p>
<p>Documents three and four have non-zero scores. Document three has a higher score because it includes both the words <em>fashion</em> and <em>style</em>, whereas document four only includes the word <em>style</em>. This simple metric has done a surprisingly good job of capturing relevance, which is why it's so widely used.</p>
<p>Let's update our code to add a stemming operation. After applying stemming to the text, we would expect document two to also have a non-zero relevance score, since <em>fashionable</em> should be transformed to <em>fashion</em> by the stemmer. Add the following code to <kbd>index.js</kbd>:</p>
<pre><span>const </span><span>stemmedFulltextSearch </span>= (query, documents) =&gt; {<br/>    <span>const </span><span>db </span>= <span>new </span><span>natural</span>.<span>TfIdf</span>();<br/>    <span>const </span><span>tokenizer </span>= <span>new </span><span>natural</span>.<span>WordTokenizer</span>();<br/>    <span>const </span><span>stemmer </span>= <span>natural</span>.<span>PorterStemmer</span>.<span>stem</span>;<br/>    <span>const </span><span>stemAndTokenize </span>= text =&gt; <span>tokenizer</span>.<span>tokenize</span>(text).<span>map</span>(token =&gt; <span>stemmer</span>(token));<br/><br/>    documents.<span>forEach</span>(document =&gt; <span>db</span>.<span>addDocument</span>(<span>stemAndTokenize</span>(document)));<br/>    <span>db</span>.<span>tfidfs</span>(<span>stemAndTokenize</span>(query), (docId, score) =&gt; {<br/>        <span>console</span>.<span>log</span>(<span>"DocID " </span>+ docId + <span>" has score: " </span>+ score);<br/>    });<br/>};<br/><br/><span>stemmedFulltextSearch</span>(<span>"fashion style"</span>, [<br/>    <span>"i love cooking, it really relaxes me and makes me feel at home"</span>,<br/>    <span>"food and restaurants are basically my favorite things"</span>,<br/>    <span>"i'm not really a fashionable person"</span>,<br/>    <span>"that new fashion blogger has a really great style"</span>,<br/>    <span>"i don't love the cinematic style of that movie"<br/></span>]);</pre>
<p>We have added a <kbd>stemAndTokenize</kbd> helper method and applied it both to the documents added to the database and to the search query. Run the code with <kbd>yarn start</kbd> and you'll see the updated output:</p>
<pre><strong>DocID 0 has score: 0</strong><br/><strong>DocID 1 has score: 0</strong><br/><strong>DocID 2 has score: 1.5108256237659907</strong><br/><strong>DocID 3 has score: 3.0216512475319814</strong><br/><strong>DocID 4 has score: 1.5108256237659907</strong></pre>
<p>As expected, document two now has a non-zero score because the stemmer was able to transform the word <em>fashionable</em> into <em>fashion</em>. Documents two and four have the same score, but only because this is a very simple example; with a much larger corpus we would not expect the inverse document frequencies of the terms <em>fashion</em> and <em>style</em> to be equivalent.</p>
<p>Search relevance and ranking is not the only application for TF-IDF. This metric is widely used across many use cases and problem domains. One interesting use for TF-IDF is article summarization. In article summarization, the goal is to reduce a written passage to only a few sentences that effectively summarize the passage.</p>
<p>One approach to the article summarization problem is to consider each sentence or paragraph in an article to be a separate document. After indexing each sentence for TF-IDF, you then evaluate each individual word's TF-IDF score and use that to score each sentence as a whole. Pick the top three or five sentences and display them in their original order, and you will have a decent summary.</p>
<p>Let's see this in action, using both <kbd>natural.js</kbd> and <kbd>compromise.js</kbd>. Add the following code to <kbd>index.js</kbd>:</p>
<pre><span>const </span><span>summarize </span>= (article, maxSentences = <span>3</span>) =&gt; {<br/>    <span>const </span><span>sentences </span>= <span>compromise</span>(article).<span>sentences</span>().<span>out</span>(<span>'array'</span>);<br/>    <span>const </span><span>db </span>= <span>new </span><span>natural</span>.<span>TfIdf</span>();<br/>    <span>const </span><span>tokenizer </span>= <span>new </span><span>natural</span>.<span>WordTokenizer</span>();<br/>    <span>const </span><span>stemmer </span>= <span>natural</span>.<span>PorterStemmer</span>.<span>stem</span>;<br/>    <span>const </span><span>stemAndTokenize </span>= text =&gt; <span>tokenizer</span>.<span>tokenize</span>(text).<span>map</span>(token =&gt; <span>stemmer</span>(token));<br/>    <span>const </span><span>scoresMap </span>= {};<br/><br/>    <span>// Add each sentence to the document<br/></span><span>    </span><span>sentences</span>.<span>forEach</span>(sentence =&gt; <span>db</span>.<span>addDocument</span>(<span>stemAndTokenize</span>(sentence)));<br/><br/>    // Loop over all words in the document and add that word's score to an overall score for each sentence<br/>    <span>stemAndTokenize</span>(article).<span>forEach</span>(token =&gt; {<br/>        <span>db</span>.<span>tfidfs</span>(token, (sentenceId, score) =&gt; {<br/>            <span>if </span>(!<span>scoresMap</span>[sentenceId]) <span>scoresMap</span>[sentenceId] = <span>0</span>;<br/>            <span>scoresMap</span>[sentenceId] += score;<br/>        });<br/>    });<br/><br/>    <span>// Convert our scoresMap into an array so that we can easily sort it<br/></span><span>    </span><span>let </span><span>scoresArray </span>= Object.<span>entries</span>(<span>scoresMap</span>).<span>map</span>(item =&gt; ({<span>score</span>: item[<span>1</span>], <span>sentenceId</span>: item[<span>0</span>]}));<br/>    <span>// Sort the array by descending score<br/></span><span>    </span><span>scoresArray</span>.<span>sort</span>((a, b) =&gt; a.<span>score </span>&lt; b.<span>score </span>? <span>1 </span>: -<span>1</span>);<br/>    <span>// Pick the top maxSentences sentences<br/></span><span>    </span><span>scoresArray </span>= <span>scoresArray</span>.<span>slice</span>(<span>0</span>, maxSentences);<br/>    <span>// Re-sort by ascending sentenceId<br/></span><span>    </span><span>scoresArray</span>.<span>sort</span>((a, b) =&gt; <span>parseInt</span>(a.<span>sentenceId</span>) &lt; <span>parseInt</span>(b.<span>sentenceId</span>) ? -<span>1 </span>: <span>1</span>);<br/>    <span>// Return sentences<br/></span><span>    </span><span>return </span><span>scoresArray<br/></span><span>        </span>.<span>map</span>(item =&gt; <span>sentences</span>[item.<span>sentenceId</span>])<br/>        .<span>join</span>(<span>'. '</span>);<br/><br/>};</pre>
<p>The preceding <kbd>summarize</kbd> method implements the following procedure:</p>
<ul>
<li>Use <kbd>compromise.js</kbd> to extract sentences from the article</li>
<li>Add each individual sentence to the TF-IDF database</li>
<li>For each word in the article, calculate its TF-IDF score for each sentence</li>
<li>Add each word's TF-IDF score to a list of total scores for each sentence (the <kbd>scoresMap</kbd> object)</li>
<li>Convert <kbd>scoresMap</kbd> into an array to make sorting easier</li>
<li>Sort <kbd>scoresArray</kbd> by descending relevance score</li>
<li>Remove all but the top-scoring sentences</li>
<li>Re-sort <kbd>scoresArray</kbd> by the chronological order of sentences</li>
<li>Build the summary by joining the top sentences together</li>
</ul>
<p>Let's add a simple article to the code and try out both a three-sentence and a five-sentence summary. In this example, I'll use the first few paragraphs of this section, but you can replace the text with anything you like. Add the following to <kbd>index.js</kbd>:</p>
<pre><span>const </span><span>summarizableArticle </span>= <span>"One of the most popular metrics used in search relevance, text mining, and information retrieval is the term frequency - inverse document frequency score, or tf-idf for short. In essence, tf-idf measures how significant a word is to a particular document. The tf-idf metric therefore only makes sense in the context of a word in a document that's part of a larger corpus of documents. Imagine you have a corpus of documents, like blog posts on varying topics, that you want to make searchable. The end user of your application runs a search query for fashion style. How do you then find matching documents and rank them by relevance? The tf-idf score is made of two separate but related components. The first is term frequency, or the relative frequency of a specific term in a given document. If a 100-word blog post contains the word fashion four times, then the term frequency of the word fashion is 4% for that one document. Note that term frequency only requires a single term and a single document as parameters; the full corpus of documents is not required for the term frequency component of tf-idf. Term frequency by itself is not sufficient to determine relevance, however. Words like this and the appear very frequently in most text and will have high term frequencies, but those words are not typically relevant to any search."</span>;<br/><br/><span>console</span>.<span>log</span>(<span>"3-sentence summary:"</span>);<br/><span>console</span>.<span>log</span>(<span>summarize</span>(<span>summarizableArticle</span>, <span>3</span>));<br/><span>console</span>.<span>log</span>(<span>"5-sentence summary:"</span>);<br/><span>console</span>.<span>log</span>(<span>summarize</span>(<span>summarizableArticle</span>, <span>5</span>));</pre>
<p>When you run the code with <kbd>yarn start</kbd>, you'll see the following output:</p>
<pre>3-sentence summary:<br/> the tf idf metric therefore only makes sense in the context of a word in a document that's part of a larger corpus of documents. if a 100-word blog post contains the word fashion four times then the term frequency of the word fashion is 4% for that one document. note that term frequency only requires a single term and a single document as parameters the full corpus of documents is not required for the term frequency component of tf idf<br/><br/> 5-sentence summary:<br/> one of the most popular metrics used in search relevance text mining and information retrieval is the term frequency inverse document frequency score or tf idf for short. the tf idf metric therefore only makes sense in the context of a word in a document that's part of a larger corpus of documents. the first is term frequency or the relative frequency of a specific term in a given document. if a 100-word blog post contains the word fashion four times then the term frequency of the word fashion is 4% for that one document. note that term frequency only requires a single term and a single document as parameters the full corpus of documents is not required for the term frequency component of tf idf</pre>
<p>The quality of these summaries illustrates both the power and flexibility of the <kbd>tf-idf metric</kbd>, while also highlighting the fact that you don't always need advanced ML or AI algorithms to accomplish interesting tasks. There are many other uses of TF-IDF, so you should consider using this metric any time you need the relevance of a word or term as it pertains to a document in a corpus.</p>
<p>In this section, we made use of tokenizers and stemmers without formally introducing them. These are core concepts in NLP, so let's now introduce them formally.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tokenizing</h1>
                </header>
            
            <article>
                
<p>Tokenizing is the act of transforming an input string, such as a sentence, paragraph, or even an object such as an email, into individual <em>tokens</em>. A very simple tokenizer might take a sentence or paragraph and split it by spaces, thus generating tokens that are individual words. However, tokens do not necessarily need to be words, nor does every word in an input string need to be returned by the tokenizer, nor does every token generated by the tokenizer need to be present in the original text, nor does a token need to represent only one word. We therefore use the term <em>token</em> rather than <em>word</em> to describe the output of a tokenizer, as tokens are not always words.</p>
<p>The manner in which you tokenize text before processing it with an ML algorithm has a major effect on the performance of the algorithm. Many NLP and ML applications use a <em>bag-of-words</em> approach, in which only the words or tokens matter but their order does not, as in the Naive Bayes classifier we explored in <a href="8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml" target="_blank">Chapter 5</a>, <em>Classification Algorithms</em>. However, a tokenizer that generates <em>bigrams</em>, or pairs of words found next to each other, will actually preserve some of the positional and semantic meaning of the original text even when used with a bag-of-words algorithm.</p>
<p>There are many ways to tokenize text. As mentioned, the simplest method is to split a sentence by spaces to generate a <em>token stream </em>of individual words. There are numerous problems with the simple approach, however. For one, the algorithm will treat capitalized words as being distinct from their lowercase versions; Buffalo and buffalo are considered two separate words or tokens. Sometimes this is desirable, other times it's not. Oversimplified tokenization will also treat contractions such as <em>won't</em> as being distinct and separate from the words <em>will not</em>, which will get split into two separate tokens, <em>will and not</em>.</p>
<p>In most cases, that is, in 80% of applications, the simplest tokenization that one should consider is a tokenizer that converts all text to lowercase, removes punctuation and newlines, removes formatting and markup such as HTML, and even removes <em>stopwords</em> or common words such as <em>this</em> or <em>the</em>. In other cases, more advanced tokenization is necessary, and in some cases, simpler tokenization is desired.</p>
<p>In this section, I've been describing the act of tokenization as a compound process, including case transformations, removing non-alphanumeric characters, and stopword filtering. However, tokenizer libraries will each have their own opinion as to what the roles and responsibilities of the tokenizer are. You may need to combine a library's tokenization tool with other tools in order to achieve the desired effect.</p>
<p>First, let's build our own simple tokenizer. This tokenizer will convert a string to lowercase, remove non-alphanumeric characters, and also remove words that are fewer than three characters in length. Add the following to your <kbd>index.js</kbd> file, either replacing the Levenshtein distance code or adding beneath it:</p>
<pre><span>const </span><span>tokenizablePhrase </span>= <span>"I've not yet seen 'THOR: RAGNAROK'; I've heard it's a great movie though. What'd you think of it?"</span>;<br/><br/><span>const </span><span>simpleTokenizer </span>= (text) =&gt;<br/>    text.<span>toLowerCase</span>()<br/>        .<span>replace</span>(<span>/(\w)'(\w)/g</span>, <span>'$1$2'</span>)<br/>        .<span>replace</span>(<span>/\W/g</span>, <span>' '</span>)<br/>        .<span>split</span>(<span>' '</span>)<br/>        .<span>filter</span>(token =&gt; token.<span>length </span>&gt; <span>2</span>);<br/><br/><span>console</span>.<span>log</span>(<span>simpleTokenizer</span>(<span>tokenizablePhrase</span>));</pre>
<p>This <kbd>simpleTokenizer</kbd> will convert the string to lowercase, remove apostrophes in the middle of a word (so that <em>won't</em> becomes <em>wont</em>), and filter out all other non-word characters by replacing them with spaces. It then splits the string by the space character, returning an array, and finally removes any items that have fewer than three characters.</p>
<p>Run <kbd>yarn start</kbd> and you'll see the following:</p>
<pre><strong>[ 'ive', 'not', 'yet', 'seen', 'thor',</strong><br/><strong> 'ragnarok', 'ive', 'heard', 'its',</strong><br/><strong> 'great', 'movie', 'though',</strong><br/><strong> 'whatd', 'you', 'think' ]</strong></pre>
<p>This token stream can then be given to an algorithm, either in an ordered or unordered fashion. A classifier, such as Naive Bayes, will ignore the order and analyze each word as if it were independent.</p>
<p>Let's compare our simple tokenizer to two tokenizers provided by <kbd>natural.js</kbd> and <kbd>compromise.js</kbd>. Add the following to your <kbd>index.js</kbd> file:</p>
<pre><span>console</span>.<span>log</span>(<span>"Natural.js Word Tokenizer:"</span>);<br/><span>console</span>.<span>log</span>((<span>new </span><span>natural</span>.<span>WordTokenizer</span>()).<span>tokenize</span>(<span>tokenizablePhrase</span>));</pre>
<p>Running the code with <kbd>yarn start</kbd> will yield the following output:</p>
<pre><strong>Natural.js Word Tokenizer:</strong><br/><strong> [ 'I', 've', 'not', 'yet', 'seen',</strong><br/><strong> 'THOR', 'RAGNAROK', 'I', 've',</strong><br/><strong> 'heard', 'it', 's', 'a', 'great', 'movie',</strong><br/><strong> 'though', 'What', 'd', 'you', 'think',</strong><br/><strong> 'of', 'it' ]</strong></pre>
<p>As you can see, short words have been preserved, and contractions, such as <em>I've</em>, have been split up into separate tokens. Additionally, capitalization has been preserved.</p>
<p>Let's try another one of <kbd>natural.js</kbd> tokenizers:</p>
<pre><span>console</span>.<span>log</span>(<span>"Natural.js WordPunct Tokenizer:"</span>);<br/><span>console</span>.<span>log</span>((<span>new </span><span>natural</span>.<span>WordPunctTokenizer</span>()).<span>tokenize</span>(<span>tokenizablePhrase</span>));</pre>
<p>This will result in:</p>
<pre><strong>Natural.js WordPunct Tokenizer:</strong><br/><strong> [ 'I', '\'', 've', 'not', 'yet', 'seen',</strong><br/><strong> '\'', 'THOR', ': ', 'RAGNAROK', '\'', '; ',</strong><br/><strong> 'I', '\'', 've', 'heard', 'it', '\'', 's',</strong><br/><strong> 'a', 'great', 'movie', 'though', '.', 'What',</strong><br/><strong> '\'', 'd', 'you', 'think', 'of',</strong><br/><strong> 'it', '?' ]</strong></pre>
<p>This tokenizer continues to split on punctuation, however, the punctuation itself is preserved. In applications where punctuation is important, this may be desired.</p>
<p>Other tokenizer libraries, such as the one in <kbd>compromise.js</kbd>, take a more intelligent approach and even perform POS tagging in order to parse and understand the sentence while tokenizing. Let's try a number of <kbd>compromise.js</kbd> tokenizing techniques:</p>
<pre><span>console</span>.<span>log</span>(<span>"Compromise.js Words:"</span>);<br/><span>console</span>.<span>log</span>(<span>compromise</span>(<span>tokenizablePhrase</span>).<span>words</span>().<span>out</span>(<span>'array'</span>));<br/><span>console</span>.<span>log</span>(<span>"Compromise.js Adjectives:"</span>);<br/><span>console</span>.<span>log</span>(<span>compromise</span>(<span>tokenizablePhrase</span>).<span>adjectives</span>().<span>out</span>(<span>'array'</span>));<br/><span>console</span>.<span>log</span>(<span>"Compromise.js Nouns:"</span>);<br/><span>console</span>.<span>log</span>(<span>compromise</span>(<span>tokenizablePhrase</span>).<span>nouns</span>().<span>out</span>(<span>'array'</span>));<br/><span>console</span>.<span>log</span>(<span>"Compromise.js Questions:"</span>);<br/><span>console</span>.<span>log</span>(<span>compromise</span>(<span>tokenizablePhrase</span>).<span>questions</span>().<span>out</span>(<span>'array'</span>));<br/><span>console</span>.<span>log</span>(<span>"Compromise.js Contractions:"</span>);<br/><span>console</span>.<span>log</span>(<span>compromise</span>(<span>tokenizablePhrase</span>).<span>contractions</span>().<span>out</span>(<span>'array'</span>));<br/><span>console</span>.<span>log</span>(<span>"Compromise.js Contractions, Expanded:"</span>);<br/><span>console</span>.<span>log</span>(<span>compromise</span>(<span>tokenizablePhrase</span>).<span>contractions</span>().<span>expand</span>().<span>out</span>(<span>'array'</span>));</pre>
<p>Run the new code with <kbd>yarn start</kbd> and you'll see the following:</p>
<pre><strong>Compromise.js Words:</strong><br/><strong> [ 'i\'ve', '', 'not', 'yet', 'seen',</strong><br/><strong> 'thor', 'ragnarok', 'i\'ve', '', 'heard',</strong><br/><strong> 'it\'s', '', 'a', 'great', 'movie', 'though',</strong><br/><strong> 'what\'d', '', 'you', 'think', 'of', 'it' ]</strong><br/><strong> Compromise.js Adjectives:</strong><br/><strong> [ 'great' ]</strong><br/><strong> Compromise.js Nouns:</strong><br/><strong> [ 'thor', 'ragnarok', 'movie' ]</strong><br/><strong> Compromise.js Questions:</strong><br/><strong> [ 'what\'d you think of it' ]</strong><br/><strong> Compromise.js Contractions:</strong><br/><strong> [ 'i\'ve', 'i\'ve', 'it\'s', 'what\'d' ]</strong><br/><strong> Compromise.js Contractions, Expanded:</strong><br/><strong> [ 'i have', 'i have', 'it is', 'what did' ]</strong></pre>
<p>The <kbd>words()</kbd> tokenizer does not split contractions apart like the <kbd>natural.js</kbd> tokenizer did. Additionally, <kbd>compromise.js</kbd> gives you the capability to extract specific entity types from the text. We can separately extract adjectives, nouns, verbs, questions, contractions (even with the capability to expand contractions); we can also use <kbd>compromise.js</kbd> to extract dates, hashtags, lists, clauses, and numerical values.</p>
<p>It is also not a requirement that your tokens must map directly to words and phrases in the input text. For instance, when developing a spam filter for an email system, you might find that including some data from the email header in the token stream gives you a huge accuracy improvement. Whether the email passes SPF and DKIM checks may be a very strong signal to your spam filter. You might also find that differentiating body text from the subject line is also advantageous; it may also be the case that words that appear as hyperlinks are stronger signals than plaintext.</p>
<p>Often, the simplest way to tokenize this type of semi-structured data is to prefix the tokens with a character or set of characters that normally would not be allowed by the tokenizer. For example, tokens in the subject line of an email may be prefixed by <kbd>_SUBJ:</kbd> and tokens that appear in hyperlinks may be prefixed by <kbd>_LINK:</kbd>. To illustrate this, here's an example of what a token stream might look like for an email:</p>
<pre><strong>['_SPF:PASS',</strong><br/><strong> '_DKIM:FAIL',</strong><br/><strong> '_SUBJ:buy',</strong><br/><strong> '_SUBJ:pharmaceuticals',</strong><br/><strong> '_SUBJ:online',</strong><br/><strong> '_LINK:pay',</strong><br/><strong> '_LINK:bitcoin',</strong><br/><strong> 'are',</strong><br/><strong> 'you',</strong><br/><strong> 'interested',</strong><br/><strong> 'buying',</strong><br/><strong> 'medicine',</strong><br/><strong> 'online']</strong></pre>
<p>Even if a Naive Bayes classifier has never seen references to pharmaceuticals before, it may see that most spam emails have failed their DKIM check and still flag this message as spam. Or perhaps you work closely with the accounting department and they often get emails about payments, but almost never receive a legitimate email with the word <kbd>pay</kbd> in a hyperlink to an external site; the differentiation of the <em>pay</em> token appearing in plaintext versus the <kbd>_LINK:pay</kbd> token appearing in a hyperlink may make all the difference between an email being classified as spam or not.</p>
<p>In fact, one of the earliest spam filtering breakthroughs, developed by Paul Graham, of Y Combinator fame, used this approach of annotated email tokens to mark a significant improvement in the accuracy of early spam filters.</p>
<p>Another approach to tokenization is <em>n-gram</em> tokenization, which splits an input string into N-sized groups of neighboring tokens. In fact, all tokenization is n-gram tokenization, however, in the preceding examples, N is set to 1. More typically, n-gram tokenization refers to schemes where N &gt; 1. Most commonly, you'll encounter <em>bigram</em> and <em>trigram</em> tokenization.</p>
<p>The purpose of bigram and trigram tokenization is to preserve some context around individual words. An example related to sentiment analysis is an easy visualization. The phrase <em>I did not love the movie</em> will be tokenized (with a <em>unigram</em> tokenizer, or n-gram tokenizer where N = 1) to <em>I</em>, <em>did</em>, <em>not</em>, <em>love</em>, <em>the</em>, <em>movie</em>. When using a bag-of-words algorithm, such as Naive Bayes, the algorithm will see the word <em>love</em> and guess that the sentence has a positive sentiment, as bag-of-words algorithms do not consider the relationships between words.</p>
<p>A bigram tokenizer, on the other hand, can trick a naive algorithm into considering the relationships between words, because every <em>pair</em> of words becomes a token. The preceding phrase, processed with a bigram tokenizer, will become <em>I did</em>, <em>did not</em>, <em>not love</em>, <em>love the</em>, <em>the movie</em>. Even though each token is composed of two individual words, the algorithm operates on tokens and therefore will treat <em>not love</em> differently from <em>I love</em>. A sentiment analyzer will therefore have more context around each word and will be able to distinguish negations (<em>not love</em>) from positive phrases.</p>
<p>Let's try out the <kbd>natural.js</kbd> bigram tokenizer on our earlier example sentence. Add the following code to <kbd>index.js</kbd>:</p>
<pre><span>console</span>.<span>log</span>(<span>"Natural.js bigrams:"</span>);<br/><span>console</span>.<span>log</span>(<span>natural</span>.<span>NGrams</span>.<span>bigrams</span>(<span>tokenizablePhrase</span>));</pre>
<p>Running the code with <kbd>yarn start</kbd> will yield:</p>
<pre><strong>Natural.js bigrams:</strong><br/><strong> [ [ 'I', 've' ],</strong><br/><strong> [ 've', 'not' ],</strong><br/><strong> [ 'not', 'yet' ],</strong><br/><strong> [ 'yet', 'seen' ],</strong><br/><strong> [ 'seen', 'THOR' ],</strong><br/><strong> [ 'THOR', 'RAGNAROK' ],</strong><br/><strong> [ 'RAGNAROK', 'I' ],</strong><br/><strong> [ 'I', 've' ],</strong><br/><strong> [ 've', 'heard' ],</strong><br/><strong> [ 'heard', 'it' ],</strong><br/><strong> [ 'it', 's' ],</strong><br/><strong> [ 's', 'a' ],</strong><br/><strong> [ 'a', 'great' ],</strong><br/><strong> [ 'great', 'movie' ],</strong><br/><strong> [ 'movie', 'though' ],</strong><br/><strong> [ 'though', 'What' ],</strong><br/><strong> [ 'What', 'd' ],</strong><br/><strong> [ 'd', 'you' ],</strong><br/><strong> [ 'you', 'think' ],</strong><br/><strong> [ 'think', 'of' ],</strong><br/><strong> [ 'of', 'it' ] ]</strong></pre>
<p>The biggest issue with n-gram tokenization is that it dramatically increases the entropy of the data domain. When training an algorithm on n-grams, you're not just on the hook for making sure the algorithm learns all the significant words, but also all the significant <em>pairs </em>of words. There are many more pairs of words than there are unique words, so n-gram tokenization will only work when you have a very large and comprehensive training set.</p>
<p>One clever way around the n-gram entropy issue, particularly for dealing with negations in sentiment analysis, is to transform the token immediately following the negation in the same way we handled email headers and subject lines. For example, the phrase <em>not love</em> can be tokenized as <em>not</em>, <em>_NOT:love</em>, or <em>not</em>, <em>!love</em>, or even just <em>!love</em> (discarding <em>not</em> as an individual token).</p>
<p>Under this scheme, the phrase <em>I did not love the movie</em> will get tokenized as <em>I</em>, <em>did</em>, <em>not</em>, <em>_NOT:love</em>, <em>the</em>, <em>movie</em>. The advantage of this approach is that the contextual negation still gets preserved, but in general we are still using low-entropy unigrams that can be trained with a smaller dataset.</p>
<p>There are many ways to tokenize text, and each has its advantages and disadvantages. As always, the approach you choose will depend on the task at hand, the training data available, and the problem domain itself.</p>
<p>Keep the topic of tokenization in mind throughout the next few sections, as those topics can also be applied to the tokenization process. For example, you can stem words after tokenizing to further reduce entropy, or you can filter your tokens by their TF-IDF score, therefore only using the most interesting words in a document.</p>
<p>In order to continue our discussion about entropy, let's take a moment to discuss <em>stemming</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Stemming</h1>
                </header>
            
            <article>
                
<p>Stemming is a type of transformation that can be applied to a single word, though typically the stemming operation occurs right after tokenizing. Stemming after tokenizing is so common that <kbd>natural.js</kbd> offers a <kbd>tokenizeAndStem</kbd> convenience method that can be attached to the <kbd>String</kbd> class prototype.</p>
<p>Specifically, stemming reduces a word to its root form, for instance by transforming <em>running</em> to <em>run</em>. Stemming your text after tokenizing can significantly reduce the entropy of your dataset, because it essentially de-duplicates words with similar meanings but different tenses or inflections. Your algorithm will not need to learn the words <em>run</em>, <em>runs</em>, <em>running</em>, and <em>runnings</em> separately, as they will all get transformed into <em>run</em>.</p>
<p>The most popular stemming algorithm, the <em>Porter</em> <em>stemmer</em>, is a heuristic algorithm that defines a number of staged rules for the transformation. But, in essence, it boils down to cutting the standard verb and noun inflections off the end of the word and dealing with specific edge cases and common irregular forms as they arise.</p>
<p>In one sense, stemming is a sort of compression algorithm that discards information about inflections and specific word forms, but retains the conceptual information left behind by the word root. Stemming should therefore not be used in cases where the inflection or form of the language itself is important.</p>
<p>For the same reason, stemming excels in situations where the conceptual information is more important than the form. Topic extraction is a good example: it doesn't matter if someone is writing about their own experiences as a runner versus their experience watching track races—they're still writing about running.</p>
<p>Because stemming reduces data entropy, it is very effectively employed when the dataset is small or modest in size. Stemming cannot be applied carelessly, however. A very large dataset may incur an accuracy penalty if you use stemming unnecessarily. You destroy information when you stem text, and models with very large training sets may have been able to use that extra information to generate better predictions.</p>
<p>In practice, you should never have to guess whether your model will perform better with or without stemming: you should try both ways and see which performs better. I can't tell you <em>when </em>to use stemming, I can only tell you why it works and why it sometimes doesn't.</p>
<p>Let's try out the <kbd>natural.js</kbd> Porter stemmer, and we'll combine it with our tokenization from earlier. Add the following to <kbd>index.js</kbd>:</p>
<pre><span>console</span>.<span>log</span>(<span>"Tokenized and stemmed:"</span>);<br/><span>console</span>.<span>log</span>(<br/>    (<span>new </span><span>natural</span>.<span>WordTokenizer</span>())<br/>        .<span>tokenize</span>(<br/>            <span>"Writing and write, lucky and luckies, part parts and parted"<br/></span><span>        </span>)<br/>        .<span>map</span>(<span>natural</span>.<span>PorterStemmer</span>.<span>stem</span>)</pre>
<p>Run the code with <kbd>yarn start</kbd> and you'll see the following:</p>
<pre><strong>Tokenized and stemmed:</strong><br/><strong> [ 'write', 'and', 'write',</strong><br/><strong> 'lucki', 'and', 'lucki',</strong><br/><strong> 'part', 'part', 'and', 'part' ]</strong></pre>
<p>This simple example illustrates how words with different forms get reduced into their conceptual meanings. It also illustrates that there is no guarantee that the stemmer will create <em>real </em>words (you won't find <kbd>lucki</kbd> in the dictionary), only that it will reduce entropy for a set of similarly constructed words.</p>
<p>There are other stemmer algorithms that try to approach the problem more linguistically. That type of stemming is called <strong>lemmatization</strong>, and the analog to stems is called the <strong>lemma</strong>, or the dictionary form of a word. In essence, a lemmatizer is a stemmer that first determines the part of speech of the word (typically requiring a dictionary, such as <em>WordNet</em>), and then applies in-depth rules for that specific part of speech, potentially involving more lookup tables. As an example, the word <em>better</em> is unchanged by stemming, but it is transformed into the word <em>good</em> by lemmatization. Lemmatization is not necessary in most everyday tasks, but may be useful when your problem requires more precise linguistic rules or drastically reduced entropy.</p>
<p>We can't discuss NLP or linguistics without also discussing the most common mode of communication: speech. How does a speech-to-text or text-to-speech system actually know how to say the hundreds of thousands of defined words in the English language, plus an arbitrary amount of names? The answer is <em>phonetics</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Phonetics</h1>
                </header>
            
            <article>
                
<p>Speech detection, such as those used in speech-to-text systems, is a surprisingly difficult problem. There are so many variations in styles of speaking, pronunciation, dialect, and accent, as well as variations in rhythm, tone, speed, and elocution, plus the fact that audio is a simple one-dimensional time-domain signal, that it's no surprise that even today's state-of-the-art smartphone tech is <em>good, not great</em>.</p>
<p>While modern speech-to-text goes much deeper than what I'll present here, I would like to show you the concept of <em>phonetic algorithms</em>. These algorithms transform a word into something resembling a phonetic hash, such that it is easy to identify words that sound similar to one another.</p>
<p>The <em>metaphone</em> algorithm is one such phonetic algorithm. Its aim is to reduce a word down to a simplified phonetic form, with the ultimate goal of being able to index similar pronunciations. Metaphone uses an alphabet of 16 characters: <span>0BFHJKLMNPRSTWXY. The 0 character represents the <em>th</em> sound, <em>X</em> represents a <em>sh</em> or <em>ch</em> sound, and the other letters are pronounced as usual. Nearly all vowel information is lost in the transformation, though some are preserved if they are the first sound in a word.</span></p>
<p>A simple example illustrates where phonetic algorithms can be useful. Imagine that you're in charge of a search engine and people keep searching for <em>knowledge is power, France is bacon</em>. You, having familiarity with art history, would understand that it was actually Francis Bacon who said <em>knowledge is power</em>, and that your users have simply misheard the quote. You'd like to add a <em>Did you mean: <strong>Francis Bacon </strong></em>link to your search results, but don't know how to approach the problem.</p>
<p>Let's take a look at how the Metaphone algorithm would phoneticize the terms <kbd>France is Bacon</kbd> and <kbd>Francis Bacon</kbd>. Add the following to <kbd>index.js</kbd>:</p>
<pre><span>console</span>.<span>log</span>(<br/>    (<span>new </span><span>natural</span>.<span>WordTokenizer</span>())<br/>        .<span>tokenize</span>(<span>"Francis Bacon and France is Bacon"</span>)<br/>        .<span>map</span>(t =&gt; <span>natural</span>.<span>Metaphone</span>.<span>process</span>(t))<br/>);</pre>
<p>When you run the code with <kbd>yarn start</kbd>, you'll see the following:</p>
<pre><strong>[ 'FRNSS', 'BKN', 'ANT', 'FRNS', 'IS', 'BKN' ]</strong></pre>
<p>Francis has transformed into <kbd>FRNSS</kbd>, France has transformed into <kbd>FRNS</kbd>, and Bacon has transformed into <kbd>BKN</kbd>. Intuitively, these strings represent the most distinguishable sounds used to pronounced the word.</p>
<p>After phoneticizing, we can use the Levenshtein distance to measure the similarity between two words. If you ignore the space, <em>FRNSS BKN</em> and <em>FRNS IS BKN</em> only have a Levenshtein distance of one between them (the addition of the <em>I</em>); these two phrases therefore sound very similar. You can use this information, combined with the rest of the search term and a reverse lookup, to determine that <kbd>France is Bacon</kbd> is a plausible mispronunciation of <kbd>Francis Bacon</kbd>, and that <kbd>Francis Bacon</kbd> is actually the correct topic to present in your search results. Phonetic misspellings and misunderstandings, such as <kbd>France is Bacon</kbd>, are so common that we even use them in some spellchecker tools.</p>
<p>A similar approach is used in speech-to-text systems. The recording system does its best to capture the specific vowel and consonant sounds you make and uses a phonetic index (a reverse lookup of phonetics mapped to various dictionary words) to come up with a set of candidate words. Typically, a neural network will then determine which is the most likely combination of words considering both the confidence of the phonetic form and the semantic meaningfulness or meaninglessness of the resultant statements. The set of words that makes the most sense is what is presented to you.</p>
<p>The <kbd>natural.js</kbd> library also provides a convenience method to compare two words, returning <em>true </em>if they sound alike. Try the following code:</p>
<pre><span>console</span>.<span>log</span>(<span>natural</span>.<span>Metaphone</span>.<span>compare</span>(<span>"praise"</span>, <span>"preys"</span>));<br/><span>console</span>.<span>log</span>(<span>natural</span>.<span>Metaphone</span>.<span>compare</span>(<span>"praise"</span>, <span>"frays"</span>));</pre>
<p>When run, this will return <kbd>true</kbd> and then <kbd>false</kbd>.</p>
<p>You should consider using phonetic algorithms any time your problem involves pronunciation or working with similar-sounding words and phrases. This is usually restricted to more specialized fields, but speech-to-text and text-to-speech systems are becoming very popular, and you may find yourself needing to update your search algorithm for phonetic sound-alikes if users start interacting with your service by speech in the future.</p>
<p>Speaking of speech systems, let's now take a look at POS tagging and how it can be used to extract semantic information from phrases—such as commands you might issue to your smartphone assistant.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Part of speech tagging</h1>
                </header>
            
            <article>
                
<p>A <strong>part of speech</strong> (<strong>POS</strong>) tagger analyzes a piece of text, such as a sentence, and determines each individual word's POS in the context of the sentence. The only way to accomplish this is with a dictionary lookup, so it is not an algorithm that can be developed from first principles alone.</p>
<p>A great use case for POS tagging is intent extraction from commands. For instance, when you say <em>Siri, please order me a pizza from John's pizzeria</em>, the AI system will tag the command with parts of speech in order to extract the subject, verb, object, and any other relevant details from the command.</p>
<p>Additionally, POS tagging is often used as a supporting tool for other NLP operations. Topic extraction, for instance, makes heavy use of POS tagging in order to separate people, places, and topics from verbs and adjectives.</p>
<p>Keep in mind that POS tagging is never perfect, due to the ambiguity of the English language in particular. Many words can be used both as a noun and a verb, so many POS taggers will return a list of candidate parts of speech for a given word. Libraries that perform POS tagging have a wide range of sophistication, ranging from simple heuristics, to dictionary lookups, to advanced models that attempt to determine the POS based on context.</p>
<p>The <kbd>compromise.js</kbd> library has a flexible POS tagger and matching/extraction system. The <kbd>compromise.js</kbd> library is unique in that it aims to be <em>good enough</em> but not comprehensive; it is trained on only the most common words in the English language, which is enough to give 80-90% accuracy for most cases while still being a fast and small library.</p>
<p>Let's see the <kbd>compromise.js</kbd> POS tagging and matching in action. Add the following code to <kbd>index.js</kbd>:</p>
<pre><span>const </span><span>siriCommand </span>= <span>"Hey Siri, order me a pizza from John's pizzeria"</span>;<br/><span>const </span><span>siriCommandObject </span>= <span>compromise</span>(<span>siriCommand</span>);<br/><br/><span>console</span>.<span>log</span>(<span>siriCommandObject</span>.<span>verbs</span>().<span>out</span>(<span>'array'</span>));<br/><span>console</span>.<span>log</span>(<span>siriCommandObject</span>.<span>nouns</span>().<span>out</span>(<span>'array'</span>));</pre>
<p>Using <kbd>compromise.js</kbd> allows us to extract just the verbs, or just the nouns (and other parts of speech) from the command. Running the code with <kbd>yarn start</kbd> will yield:</p>
<pre><strong>[ 'order' ]</strong><br/><strong>[ 'siri', 'pizza', 'john\'s pizzeria' ]</strong></pre>
<p>The POS tagger has identified <kbd>order</kbd> as the sole verb in the sentence; this information can then be used to load up the correct subroutine for making orders that's built into Siri's AI system. The extracted nouns can then be sent to the subroutine in order to determine what type of order to make and from where.</p>
<p>Impressively, the POS tagger has also identified <kbd>John's pizzeria</kbd> as a single noun, rather than considering the words <kbd>John's</kbd> and <kbd>pizzeria</kbd> to be separate nouns. The tagger has understood that <kbd>John's</kbd> is a possessive, and therefore applies to the word following it.</p>
<p>We can also use <kbd>compromise.js</kbd> to write parsing and extraction rules for common commands. Let's try one out:</p>
<pre><span>console</span>.<span>log</span>(<br/>    <span>compromise</span>(<span>"Hey Siri, order me a pizza from John's pizzeria"</span>)<br/>        .<span>match</span>(<span>"#Noun [#Verb me a #Noun+ *+ #Noun+]"</span>).<span>out</span>(<span>'text'</span>)<br/>);<br/><br/><span>console</span>.<span>log</span>(<br/>    <span>compromise</span>(<span>"OK Google, write me a letter to the congressman"</span>)<br/>        .<span>match</span>(<span>"#Noun [#Verb me a #Noun+ *+ #Noun+]"</span>).<span>out</span>(<span>'text'</span>)<br/>);</pre>
<p>Running the code with <kbd>yarn start</kbd> will yield:</p>
<pre><strong>order me a pizza from John's</strong><br/><strong>write me a letter to the congressman</strong></pre>
<p>The same matching selector is able to capture both of these commands, ignoring the addressee of the command (Siri or Google) through match groups (denoted with <kbd>[]</kbd>). Because both commands follow the verb-noun-noun pattern, both will match the selector.</p>
<p>Of course, this selector by itself is not enough to build a full AI system such as Siri or Google Assistant. This tool would be used near the beginning of the AI system process in order to determine the user's overall intent, based on predefined but flexible command formats. You could program a system to respond to phrases such as <em>Open my #Noun</em>, where the noun can be <kbd>calendar</kbd> or <kbd>email</kbd> or <kbd>Spotify</kbd>, or <em>Write an email to #Noun</em>, and so on. This tool can be used as a first step toward building your own speech or natural language command system, as well as for various topic-extraction applications.</p>
<p>Throughout this chapter, we've discussed the foundational tools used in NLP. Many advanced NLP tasks use an ANN as part of the learning process, but for many novice practitioners, it's unclear exactly how words and natural language should be sent to the input layer of an ANN. In the next section, we will discuss <em>word embedding</em>, particularly the Word2vec algorithm, which can be used to feed words into an ANN and other systems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Word embedding and neural networks</h1>
                </header>
            
            <article>
                
<p>Throughout this chapter, we've discussed various NLP techniques, particularly with regards to preprocessing text. In many use cases, we will need to interact with an ANN to perform the final analysis. The type of analysis is not relevant to this section, but imagine you're developing a sentiment analysis ANN. You appropriately tokenize and stem your training text, then, as you attempt to train your ANN on your preprocessed text, you realize you have no idea how to get words into a neural network.</p>
<p>The simplest approach is to map each input neuron in the network to an individual unique word. When processing a document, you can set the input neuron's value to the term frequency (or absolute count) of that word in the document. You'll have a network where one input neuron responds to the word <em>fashion</em>, another neuron responds to <em>technology</em>, another neuron responds to <em>food</em>, and so on.</p>
<p>This approach will work, but it has several drawbacks. The topology of an ANN must be defined in advance, so you must know how many unique words are in your training set before you start training the network; this will become the size of the input layer. This also means that your network is not capable of learning new words after it has been trained. To add a new word to the network, you must essentially build and train a new network from scratch.</p>
<p>Additionally, throughout a corpus of documents, you may encounter tens of thousands of unique words. This has a huge negative impact on the efficiency of the ANN, as you will need an input layer with, say, 10,000 neurons. This will dramatically increase the training time required by the network as well as the memory and processing requirements of the system.</p>
<p>The approach of one-word-per-neuron also intuitively feels inefficient. While your corpus contains 10,000 unique words, most of them will be rare and only appear in a few documents. For most documents, only a few hundred input neurons will be activated, with the others set to zero. This amounts to what is called a <strong>sparse matrix</strong> or <strong>sparse vector</strong>, or a vector where most of the values are zero.</p>
<p>A more evolved approach is therefore required when natural language interacts with ANNs. A family of techniques called <em>word embedding</em> can analyze a corpus of text and transform each word into a fixed-length vector of numerical values. The vector is a fixed-length representation of a word in much the same way that a hash (such as md5 or sha1) is a fixed-length representation of arbitrary data.</p>
<p>Word embedding confers several advantages, particularly when used with ANNs. Because the word vectors are fixed in length, the topology of the network can be decided beforehand and can also handle the appearance of new words after the initial training.</p>
<p>The word vectors are also <em>dense vectors</em>, meaning that you don't need 10,000 input neurons in your network. A good value for the size of a word vector (and the size of the input layer) is somewhere between 100-300 items. This factor alone significantly reduces the dimensionality of your ANN and will allow for much faster training and convergence of the model.</p>
<p>There are many word embedding algorithms to choose from, but the current state-of-the-art choice is the Word2vec algorithm, developed at Google. This particular algorithm also has another desirable trait: similar words will be clustered close to one another in terms of their vector representations.</p>
<p>Earlier in this chapter, we saw that we can use string distance to measure the typographical distance between two words. We can also use the string distance between two phonetic representations of words to measure how similar they sound. When using Word2vec, you can measure the distance between two word vectors to get the <em>conceptual </em>distance between two words.</p>
<p>The Word2vec algorithm is itself a shallow neural network that trains itself on your corpus of text. The algorithm uses n-grams to develop a sense of the context between words. If the words <em>fashion</em> and <em>blogger</em> often appear next to each other in your corpus, Word2vec will assign similar vectors to those words. If <em>fashion</em> and <em>mathematics</em> rarely appear together, their resultant vectors will be separated by some distance. The distance between two word vectors therefore represents their conceptual and contextual distance, or how alike two words are in terms of their semantic content and context.</p>
<p>This trait of the Word2vec algorithm also confers its own efficiency and accuracy advantage to the ANN that ultimately processes the data, as the word vectors will activate similar input neurons for similar words. The Word2vec algorithm has not only reduced the dimensionality of the problem, but it has also added contextual information to the word embedding's. This additional contextual information is exactly the type of signal that ANNs are highly proficient at picking up on.</p>
<p>The following is an example of a common workflow involving both natural language and ANNs:</p>
<ul>
<li>Tokenize and stem all text</li>
<li>Remove stopwords from text</li>
<li>Determine the appropriate ANN input layer size; use this value both for the input layer and the Word2vec dimensionality</li>
<li>Use Word2vec to generate word embedding's for your text</li>
<li>Use the word embedding's to train the ANN on your task</li>
<li>When evaluating a new document, tokenize, stem, and vectorize the document before passing it to the ANN</li>
</ul>
<p>Using a word-embedding algorithm such as Word2vec will not only improve the speed and memory performance of your model, but it will likely also increase the accuracy of your model due to the contextual information that the Word2vec algorithm preserves. It should also be noted that Word2vec is, like n-gram tokenization, one possible way to trick a naive bag-of-words algorithm into taking word context into account, as the Word2vec algorithm itself uses n-grams to develop the embedding's.</p>
<p>While word embedding is used primarily in NLP, the same approach can be used in other fields, such as genetics and biochemistry. In those fields, it is sometimes advantageous to be able to vectorize sequences of proteins or amino acids such that similar structures will have similar vector embedding's.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Natural language processing is a rich field of study with many advanced techniques and wide applications in ML, computational linguistics, and artificial intelligence. In this chapter, however, we focused on the specific tools and tactics that are most prevalent in everyday ML tasks.</p>
<p>The techniques presented in this chapter are building blocks that can be mixed and matched in order to achieve many different outcomes. Using the information in this chapter alone, you can build a simple full-text search engine, an intent extractor for spoken or written commands, an article summarizer, and many other impressive tools. However, the most impressive applications of NLP arise when these techniques are combined with advanced learning models, such as ANNs and RNNs.</p>
<p>In particular, you learned about w<span>ord metrics, such as string distance and TF-IDF relevance scoring; p</span><span>reprocessing and dimensionality reduction techniques, such as tokenization and stemming; </span><span>phonetic algorithms, such as the Metaphone algorithm; p</span><span>art of speech extraction and phrase parsing; and c</span><span>onverting words to vectors using word embedding algorithms.</span></p>
<p>You have also been introduced, through numerous examples, to two excellent JavaScript libraries, <kbd>natural.js</kbd> and <kbd>compromise.js</kbd>, which can be used to easily accomplish most of the NLP tasks relevant to ML. You were even able to write an article summarizer in 20 lines of code!</p>
<p>In the next chapter, we'll discuss how everything you've learned so far can be put together in a real-time, user-facing JavaScript application.</p>


            </article>

            
        </section>
    </body></html>