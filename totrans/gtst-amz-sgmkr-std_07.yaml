- en: '*Chapter 5*: Building and Training ML Models with SageMaker Studio IDE'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*: 使用 SageMaker Studio IDE 构建和训练 ML 模型'
- en: Building and training a **machine learning** (**ML**) model can be easy with
    SageMaker Studio. It is an **integrated development environment** (**IDE**) designed
    for ML developers for building and training ML models at scale and efficiently.
    In order to train an ML model, you may previously have dealt with the cumbersome
    overhead of managing compute infrastructure for yourself or for your team to train
    ML models properly. You may also have experienced compute resource constraints,
    either on desktop machines or with cloud resources, where you are given a fixed-size
    instance. When you develop in SageMaker Studio, there is no more frustration with
    provisioning and managing compute infrastructure because you can easily make use
    of elastic compute in SageMaker Studio and its wide support of sophisticated ML
    algorithms and frameworks for your ML use case.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SageMaker Studio 构建和训练一个 **机器学习**（**ML**）模型可以变得简单。它是一个 **集成开发环境**（**IDE**），专为
    ML 开发者设计，用于大规模和高效地构建和训练 ML 模型。为了训练一个 ML 模型，你可能之前已经处理过自己或团队管理计算基础设施的繁琐开销，以正确地训练
    ML 模型。你也可能经历过计算资源限制，无论是在桌面机器上还是在云资源中，你被分配了一个固定大小的实例。当你使用 SageMaker Studio 进行开发时，不再有配置和管理计算基础设施的挫折，因为你可以轻松地利用
    SageMaker Studio 中的弹性计算以及其对复杂 ML 算法和框架的广泛支持，以满足你的 ML 用例。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Training models with SageMaker's built-in algorithms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SageMaker 内置算法训练模型
- en: Training with code written in popular frameworks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用流行框架编写的代码进行训练
- en: Developing and collaborating using SageMaker Notebook
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SageMaker Notebook 进行开发和协作
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you need to access the code provided at [https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你需要访问提供的代码，代码位于 [https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05)。
- en: Training models with SageMaker's built-in algorithms
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker 内置算法训练模型
- en: 'When you want to build an ML model from a notebook in SageMaker Studio for
    your ML use case and data, one of the easiest approaches is to use one of SageMaker''s
    built-in algorithms. There are two advantages of using built-in algorithms:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想要在 SageMaker Studio 的笔记本中构建一个针对你的 ML 用例和数据的 ML 模型时，最简单的方法之一是使用 SageMaker
    的内置算法。使用内置算法有两个优点：
- en: The built-in algorithms do not require you to write any sophisticated ML code.
    You only need to provide your data, make sure the data format matches the algorithms'
    requirements, and specify the hyperparameters and compute resources.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置算法不需要你编写任何复杂的 ML 代码。你只需要提供你的数据，确保数据格式符合算法的要求，并指定超参数和计算资源。
- en: The built-in algorithms are optimized for AWS compute infrastructure and are
    scalable out of the box. It is easy to perform distributed training across multiple
    compute instances and/or enable GPU support to speed up training time.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置算法针对 AWS 计算基础设施进行了优化，并且开箱即用即可扩展。轻松地在多个计算实例上执行分布式训练，并/或启用 GPU 支持，以加快训练时间。
- en: 'SageMaker''s built-in algorithm suite offers algorithms that are suitable for
    the most common ML use cases. There are algorithms for the following categories:
    **supervised learning**, **unsupervised learning**, **image analysis**, and **textual
    analysis**. Most notably, there is **XGBoost** and **k-means** for tabular data
    for supervised learning and unsupervised learning, respectively, as well as **image
    classification**, **object detection**, and **semantic segmentation** for image
    analysis. For textual analysis, we have the **word2vec**, **text classification**,
    and **sequence-to-sequence** algorithms. These are just example algorithms for
    each category we''ve mentioned. There are more useful algorithms available but
    I am not listing them exhaustively. You can visit [https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html)
    to see a full list and further details.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker内置算法套件提供了适用于最常见机器学习用例的算法。以下类别中都有算法：**监督学习**、**无监督学习**、**图像分析**和**文本分析**。最值得注意的是，对于监督学习和无监督学习，分别有**XGBoost**和**k-means**用于表格数据，以及用于图像分析的**图像分类**、**目标检测**和**语义分割**。对于文本分析，我们有**word2vec**、**文本分类**和**序列到序列**算法。这些只是我们提到的每个类别的示例算法。还有更多有用的算法可供选择，但我不一一列举。您可以访问[https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html)查看完整列表和更多详细信息。
- en: Note
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: GPU support and distributed training capability for algorithms vary. Please
    visit [https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html](https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html)
    for GPU and distributed training support for each algorithm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的GPU支持和分布式训练能力各不相同。请访问[https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html](https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html)以了解每个算法的GPU和分布式训练支持。
- en: Let's take a use case and an algorithm to demonstrate how to use SageMaker's
    built-in algorithms.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个用例和一个算法来展示如何使用SageMaker的内置算法。
- en: Training an NLP model easily
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简易训练NLP模型
- en: Training an ML model does not require writing any ML codes with SageMaker's
    built-in algorithms. We will look at an NLP use case to classify sentences into
    categories using the DBpedia Ontology Dataset from *DBpedia* ([https://www.dbpedia.org/](https://www.dbpedia.org/)),
    which consists of 560,000 training samples and 70,000 testing samples of the titles
    and abstracts of Wikipedia articles. Please open the notebook in `chapter05/01-built_in_algorithm_text_classification.ipynb`
    from the repository using the **Python 3 (Data Science)** kernel and the **ml.t3.medium**
    instance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SageMaker的内置算法训练ML模型不需要编写任何ML代码。我们将通过一个NLP用例来查看如何使用来自*DBpedia*（[https://www.dbpedia.org/](https://www.dbpedia.org/)）的DBpedia本体数据集将句子分类到类别中，该数据集包含560,000个训练样本和70,000个测试样本的维基百科文章的标题和摘要。请使用**Python
    3 (Data Science**)内核和**ml.t3.medium**实例打开存储库中的`chapter05/01-built_in_algorithm_text_classification.ipynb`笔记本。
- en: 'In the notebook, we first download the dataset and inspect it to understand
    how we need to process the data, as shown in the following snippet:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中，我们首先下载数据集并检查它，以了解我们需要如何处理数据，如下面的代码片段所示：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We see that the data, `dbpedia_csv/train.csv`, is formatted as `<class index>,<title>,<abstract>`.
    There is also a file called `dbpedia_csv/classes.txt` documenting the classes
    in an order that corresponds to the class index seen in `dbpedia_csv/train.csv`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到数据，`dbpedia_csv/train.csv`，格式为`<类别索引>,<标题>,<摘要>`。还有一个名为`dbpedia_csv/classes.txt`的文件，记录了类别，其顺序与`dbpedia_csv/train.csv`中看到的类别索引相对应。
- en: 'This is a text classification problem: given the abstract of an article, we
    want to build a model to predict and classify the classes this abstract belong
    to. This is a common use case when working with a large number of text documents,
    such as articles on the Wikipedia site from which this dataset is sourced. It
    is almost impossible to use human review to organize all the documents.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个文本分类问题：给定一篇文章的摘要，我们想要构建一个模型来预测和分类这个摘要所属的类别。当处理大量文本文档时，这是一个常见的用例，例如来自维基百科网站的数据集，其中包含来自维基百科文章的标题和摘要。几乎不可能使用人工审查来组织所有文档。
- en: One of the built-in algorithms that is suitable for this use case is **BlazingText**.
    BlazingText has highly optimized implementations for both Word2vec (unsupervised)
    and text classification (supervised). The Word2vec algorithm can convert text
    into a vector representation, or **word embedding**, for any downstream NLP usage,
    such as sentiment analysis or named entity recognition. Text classification can
    classify documents into categories. This is perfect for our use case and dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting the data ready for training is key when using SageMaker''s built-in
    algorithm. Using BlazingText for text classification requires each data point
    to be formatted as `__label__<class> text…`. Here''s an example:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We use a `preprocess` function, which calls the `transform_text` function to
    tokenize each row of the abstract. We use a sentence tokenizer, `punkt`, from
    the `nltk` library inside the `transform_text` function. We preprocess both train
    and test files. To keep the processing time manageable, we use only 20% of the
    training data, as shown in the following code snippet:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can see that now we have the data in the expected format. Feel free to expand
    the training set to a higher percentage using the `keep` argument in `preprocess`.
    After preprocessing, we are ready to invoke the built-in algorithm.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'SageMaker''s built-in algorithms are fully managed containers that can be accessed
    with a simple SDK call. The following code allows us to use the BlazingText algorithm
    for text classification:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After execution, we get a string in a variable called `image`. You may be wondering,
    what is this string that looks like a URL path? How is this an algorithm for model
    training?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '**Container technology** is the core of SageMaker managed training. Container
    technology allows SageMaker the flexibility to work with algorithms from any framework
    and any runtime requirements. Instead of using the runtime setup in the notebook
    and using the compute resource behind the notebook for model training, SageMaker
    takes the data you supply and a container image that has the runtime setup and
    the code base to a separate SageMaker-managed compute infrastructure to conduct
    model training.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The path in `image` points to a container image stored in **Amazon Elastic Container
    Registry** (**ECR**) that has the BlazingText ML algorithm. We can use it to start
    a model training job with a SageMaker estimator.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'SageMaker estimator is a key construct for the fully managed model training
    that enables us to command various aspects of a model training job with a simple
    API. The following snippet is how we set up a training job with SageMaker''s BlazingText
    algorithm:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Most notably, the arguments that go into the estimator are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm as a container, `image`
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hyperparameters` for the training job'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The compute resources needed for the job, `instance_type`, `instance_count`,
    and `volume_size`
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The IAM execution role, `role`
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, not only do we specify algorithmic options, but also instruct
    SageMaker what cloud compute resources we need for this model training run. We
    request one `ml.c5.2xlarge` instance, a compute-optimized instance that has high-performance
    processors, with 30 GB storage for this training job. It allows us to use a lightweight,
    cheap instance type (`ml.t3.medium`) for the notebook environment during prototyping
    and do full-scale training on a more powerful instance type to get the job done
    faster.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'We have set up the algorithm and the compute resource; next, we need to associate
    the estimator with the training data. After we have prepared the data, we need
    to upload the data into an S3 bucket so that the SageMaker training job can access
    the `ml.c5.4xlarge` instance. We start the training by simply calling `estimator.fit()`
    with the data:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can see the job log in the notebook and observe the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker spins up one `ml.c5.2xlarge` instance for this training job.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SageMaker downloads the data from S3 and the BlazingText container image from
    ECR.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SageMaker runs the model training and logs the training and validation accuracy
    in the cell output shown here:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The cell output from the training job is also available in `estimator(…, enable_sagemaker_metrics=True)`,
    are sent to **Amazon CloudWatch Metrics** automatically. This gives us governance
    of the training jobs even if the notebooks are accidentally deleted.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the training job finishes, you can access the trained model in `estimator.model_data`,
    which can later be used for hosting and inferencing either in the cloud, which
    is a topic we will explore in depth in the next chapter, or on a computer with
    the `fastText` program. You can access the model with the following code block:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: BlazingText is a GPU-accelerated version of FastText. FastText ([https://fasttext.cc/](https://fasttext.cc/))
    is an open source library that can perform both word embedding generation (unsupervised)
    and text classification (supervised). The models created by BlazingText and FastText
    are compatible with each other.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: We have just created a sophisticated text classification model that is capable
    of classifying the category of documents from DBpedia at an accuracy of 0.9766
    on the validation data with minimal ML code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Let's also set up an ML experiment management framework, **SageMaker Experiments**,
    to keep track of jobs we launch in this chapter.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Managing training jobs with SageMaker Experiments
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As data scientists, we might have all encountered a tricky situation where the
    number of model training runs can grow very quickly to such a degree that it becomes
    difficult to track the best model in various experiment settings, such as dataset
    versions, hyperparameters, and algorithms. In SageMaker Studio, you can easily
    track the experiments among the training runs with **SageMaker Experiments** and
    visualize them in the experiments and trials component UI. SageMaker Experiments
    is an open source project ([https://github.com/aws/sagemaker-experiments](https://github.com/aws/sagemaker-experiments))
    and can be accessed programmatically through the Python SDK.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，我们可能都遇到过一种棘手的情况，即模型训练运行的次数可以非常快地增长到难以追踪最佳模型的各种实验设置的程度，例如数据集版本、超参数和算法。在SageMaker
    Studio中，您可以使用**SageMaker Experiments**轻松跟踪训练运行中的实验，并在实验和试验组件UI中可视化它们。SageMaker
    Experiments是一个开源项目([https://github.com/aws/sagemaker-experiments](https://github.com/aws/sagemaker-experiments))，可以通过Python
    SDK编程访问。
- en: In SageMaker Experiments, an **Experiment** is a collection of **trial** runs
    that are executions of an ML workflow that can contain **trial components** such
    as data processing and model training.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker Experiments中，**实验**是一系列**试验**运行集合，这些运行是ML工作流的执行，可能包含**试验组件**，如数据处理和模型训练。
- en: 'Let''s continue with the `chapter05/01-built_in_algorithm_text_classification.ipynb`
    notebook and see how we can set up an experiment and trial with SageMaker Experiments
    to track training jobs with different learning rates in the following snippet
    so that we can compare the performance from the trials easily in SageMaker Studio:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用`chapter05/01-built_in_algorithm_text_classification.ipynb`笔记本，看看我们如何使用SageMaker
    Experiments设置实验和试验，以跟踪具有不同学习率的训练作业，以便我们可以在SageMaker Studio中轻松比较试验的性能，以下是一个片段：
- en: 'First, we install the `sagemaker-experiments` SDK in the notebook kernel:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们在笔记本内核中安装`sagemaker-experiments` SDK：
- en: '[PRE8]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We then create an experiment named `dbpedia-text-classification` that we can
    use to store all the jobs related to this model training use case using the `smexperiments`
    library:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一个名为`dbpedia-text-classification`的实验，我们可以使用`smexperiments`库来存储与此模型训练用例相关的所有作业：
- en: '[PRE9]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then we create a utility function, `create_estimator()`, with an input argument,
    `learning_rate`, for ease of use later when we iterate over various learning rates:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一个名为`create_estimator()`的实用函数，它有一个输入参数`learning_rate`，以便在以后迭代各种学习率时使用方便：
- en: '[PRE10]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s run three training jobs in a `for` loop with varying learning rates
    in order to understand how the accuracy changes:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在`for`循环中运行三个具有不同学习率的训练作业，以便了解准确率如何变化：
- en: '[PRE11]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the `for` loop, we create unique training job names, `dbpedia-blazingtext-{exp_datetime}`,
    to be associated with a trial, `exp_trial`, and an experiment configuration, `experiment_config`,
    to store information. Then we pass `experiment_config` into the `estimator.fit()`
    function and SageMaker will track the experiments for us automatically.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在`for`循环中，我们创建唯一的训练作业名称`dbpedia-blazingtext-{exp_datetime}`，将其与一个试验`exp_trial`和一个实验配置`experiment_config`相关联，以存储信息。然后我们将`experiment_config`传递给`estimator.fit()`函数，SageMaker将自动为我们跟踪实验。
- en: Note
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We put `wait=False` in the `estimator.fit()` call. This allows the training
    job to run asynchronously, meaning that the cell is returned immediately as opposed
    to being held by the process until the training is completed. In effect, our jobs
    with different learning rates are run in parallel, each using its own separate
    SageMaker-managed instances for training.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`estimator.fit()`调用中放置`wait=False`。这允许训练作业异步运行，这意味着单元格会立即返回，而不是被进程持有直到训练完成。实际上，我们的具有不同学习率的作业是并行运行的，每个作业都使用自己的SageMaker管理的实例进行训练。
- en: 'In SageMaker Studio, you can easily compare the results of these training jobs
    with SageMaker Experiments. We can create a chart to compare the accuracies of
    the three jobs with varying learning rates in the SageMaker Studio UI:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker Studio中，您可以使用SageMaker Experiments轻松比较这些训练作业的结果。我们可以在SageMaker Studio
    UI中创建一个图表来比较三个作业在不同学习率下的准确率：
- en: 'Click on the **SageMaker Components and registries** in the left sidebar, as
    shown in *Figure 5.1*:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如*图5.1*所示，点击左侧边栏中的**SageMaker组件和注册表**：
- en: '![Figure 5.1 – Viewing experiments and trials from the left sidebar'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 – 从左侧边栏查看实验和试验'
- en: '](img/B17447_06_01.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_06_01.jpg)'
- en: Figure 5.1 – Viewing experiments and trials from the left sidebar
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 从左侧边栏查看实验和试验
- en: Select **Experiments and trials** in the drop-down menu, as shown in *Figure
    5.1*.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on the **dbpedia-text-classification** experiment entry and choose
    **Open in trial component list**.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A new view in the main working area will pop up. You can configure the columns
    to show the accuracies and learning rates as shown in *Figure 5.2*. We can see
    **validation:accuracy**, and **train:accuracy** with respect to the three **learning_rate**
    settings. With **learning_rate** set to **0.01**, we have the most balanced training
    and validation accuracies. A learning rate of 0.1 is overfitted, while a learning
    rate of 0.001 is underfitted.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Viewing and comparing training jobs'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_06_02.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 – Viewing and comparing training jobs
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: We can create a line chart of **validation:accuracy** versus **learning_rate**.
    Multi-select the three trial components and click **Add chart** in the top right.
    A new view will pop up. Configure the chart properties as shown in *Figure 5.3*.
    You will get a chart that shows the relationship between **validation:accuracy**
    and **learning_rate**.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Comparing and charting validation accuracy versus learning rate'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_06_03.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Comparing and charting validation accuracy versus learning rate
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker Experiments is useful for managing jobs and resources and comparing
    performance as you start building an ML project at scale in SageMaker Studio.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Training and processing jobs that do not have `experiment_config` will be placed
    in **Unassigned trial components**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: More often than not, you already have some ML projects that use popular frameworks
    such as TensorFlow and PyTorch to train models. You can also run them with SageMaker's
    fully managed training capability.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Training with code written in popular frameworks
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SageMaker's fully managed training works with your favorite ML frameworks too,
    thanks to the container technology we mentioned previously. You may have been
    working with `Tensorflow`, `PyTorch`, `Hugging` `Face`, `MXNet`, `scikit-learn`,
    and many more. You can easily use them with SageMaker so that you can use its
    fully managed training capabilities and benefit from the ease of provisioning
    right-sized compute infrastructure. SageMaker enables you to use your own training
    scripts for custom models and run them on prebuilt containers for popular frameworks.
    This is known as **Script Mode**. For frameworks not covered by the prebuilt containers,
    you also can use your own container for virtually any framework of your choice.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at training a sentiment analysis model written in TensorFlow as an
    example to show you how to use your own script in SageMaker to run with SageMaker's
    prebuilt TensorFlow container. Then we will describe a similar process for other
    frameworks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorFlow is an open source framework for ML, specifically for deep neural
    networks. You can run TensorFlow code using SageMaker's prebuilt TensorFlow training
    and inference containers, available through the SageMaker SDK's `sagemaker.tensorflow`.
    Please open the notebook in `chapter05/02-tensorflow_sentiment_analysis.ipynb`
    from the repository using the `ml.t3.medium` instance. The objective in this example
    is to train and predict the sentiment (positive/negative) from movie reviews from
    the IMDb movie database using a neural network built with TensorFlow layers. You
    could run the neural network training inside a notebook, but this will require
    you to have a compute instance that is capable of training a deep neural network
    with a large amount of data at all times, even when you are just exploring data
    and writing code. But with SageMaker, you can optimize the compute usage by using
    a smaller instance for code building and only using a GPU instance for full-scale
    training.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: In `chapter06/02-tensorflow_sentiment_analysis.ipynb`, we first install the
    library we need and get the Sagemaker session set up. Then we load the IMDb dataset
    from `tensorflow.python.keras.datasets`, run minimal data preprocessing, and save
    the training and test splits to the local filesystem and then to an S3 bucket.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Assuming we have previously developed a neural network architecture that works
    on this IMDb dataset, as shown in the following code block, we can easily take
    it into SageMaker to train.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'SageMaker can take a TensorFlow script into a Docker container and train the
    script with the data. To do so, SageMaker requires the script to be aware of environmental
    variables set in the container, the compute infrastructure, and, optionally, the
    script needs to be able to take inputs from the execution, such as hyperparameters.
    Here are the steps:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Create a script to put in the model architecture and data loading functions
    (`get_model`, `get_train_data`, `get_test_data`, and so on).
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create an argument parser that takes in parameters such as hyperparameters
    and training data location from script execution. SageMaker is going to run the
    script as an executable in the container with arguments specified from a SDK call.
    The training data location is passed into the script with a default from environmental
    variable SageMaker set up in the container (`SM_CHANNEL_*`). The argument parser
    is defined in a `parse_arg()` function, shown as follows:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `TRAIN` or `TEST` suffix in the `SM_CHANNEL_*` environmental variable has
    to match that of the dictionary key provided in the input data channel in the
    `estimator.fit()` call. So, later, when we specify the data channel, we need to
    create a dictionary whose keys are `TRAIN` and `TEST`, case-insensitive.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Put in the training steps as part of `if __name__ == "__main__":`:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Make sure to replace the variables in the network with that from the argument
    parser. For example, change `tf.keras.optimizers.Adam(learning_rate)` to `tf.keras.optimizers.Adam(`args.`learning_rate)`.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In our notebook, we write out the script to `code/tensorflow_sentiment.py`.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a TensorFlow estimator using `sagemaker.tensorflow.TensorFlow`, which
    is an extension of the `estimator` class we used previously to work exclusively
    with ML training written in TensorFlow:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Some of the key arguments here in TensorFlow estimator are `source_dir`, `entry_point`,
    `code_location`, `framework_version`, and `py_version`. `source_dir`, and `entry_point`
    is where we specify where the training script is located on the EFS filesystem
    (`code/tensorflow_sentiment.py`). If you need to use any additional Python libraries,
    you can include the libraries in a `requirements.txt` file, and place the text
    file in a directory specified in `source_dir` argument. SageMaker will first install
    libraries listed in the `requirements.txt` before executing the training script.
    `code_location` is where the script will be staged in S3\. `framework_version`
    and `py_version` allow us to specify the TensorFlow version and Python version
    that the training script is developed in.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: You can find supported versions of TensorFlow at [https://github.com/aws/deep-learning-containers/blob/master/available_images.md](https://github.com/aws/deep-learning-containers/blob/master/available_images.md).
    You can find the TensorFlow estimator API at [https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a data channel dictionary:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a new experiment in SageMaker Experiments:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Call the `estimator.fit()` function with data and experiment configurations:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The training on one ml.p3.2xlarge instance, which has one high-performance
    NVIDIA® V100 Tensor Core GPU, takes about 3 minutes. Once the training job finishes,
    you can access the trained model from `model_dir` on S3\. This model is a Keras
    model and can be loaded in by Keras'' `load_model` API. You can then evaluate
    the model the same way you would in TensorFlow:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We have successfully trained a custom TensorFlow model to predict IMDb review
    sentiment using SageMaker''s fully managed training infrastructure. For other
    frameworks, it is rather a similar process to adopt a custom script to SageMaker.
    We will take a look at the estimator API for PyTorch, Hugging Face, MXNet, and
    scikit-learn, which share the same base class: `sagemaker.estimator.Framework`.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PyTorch is a popular open source deep learning framework that is analogous to
    TensorFlow. Similar to how SageMaker supports TensorFlow, SageMaker has an estimator
    dedicated to PyTorch. You can access it with the `sagemaker.pytorch.PyTorch` class.
    The API's documentation is available at [https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html).
    Follow *steps* *1-9* in the *TensorFlow* section to use your PyTorch training
    script, but instead of `framework_version`, you would specify the PyTorch version
    to access the specific SageMaker-managed PyTorch training container image.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hugging Face is an ML framework dedicated to natural language processing use
    cases. It helps you train complex NLP models easily with pre-built architecture
    and pre-trained models. It is compatible with both TensorFlow and PyTorch, so
    you can train with the framework that you are most familiar with. You can access
    the estimator with the `sagemaker.huggingface.HuggingFace` class. The API's documentation
    is available at [https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html).
    Follow *steps* *1-9* in the *TensorFlow* section to use your scripts. The major
    difference compared with TensorFlow/PyTorch estimators is that there is an additional
    argument, `transformers_version`, for the `pytorch_version` or `tensorflow_version`
    instead of `framework_version`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: MXNet
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MXNet is a popular open source deep learning framework that is analogous to
    TensorFlow. You can access the MXNet estimator with the `sagemaker.mxnet.MXNet`
    class. The API documentation is available at [https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html).
    Follow *steps* *1-9* in the *TensorFlow* section to use your MXNet training script,
    but instead of `framework_version`, you need to specify the MXNet version to access
    the specific SageMaker-managed container image.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-learn
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`sagemaker.sklearn.SKLearn` class. The API''s documentation is available at
    https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html.
    Follow *steps* *1-9* in the *TensorFlow* section to use your sklearn training
    script, but instead of `framework_version`, you need to specify the sklearn version
    to access the specific SageMaker-managed container image.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: While developing in SageMaker Studio, it is common that you need to be able
    to collaborate with your colleague and be able to run ML and data science code
    with diverse Python libraries. Let's see how we can enrich our model-building
    experience in SageMaker Studio.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Developing and collaborating using SageMaker Notebook
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The SageMaker Studio IDE makes collaboration and customization easy. Besides
    the freedom of choosing the kernel and instance backing a SageMaker notebook,
    you could also manage Git repositories, compare notebooks, and share notebooks.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'Users can interact with a Git repository easily in SageMaker Studio, and you
    may have already done so to clone the sample repository from GitHub for this book.
    Not only can you clone a repository from a system terminal, you can also use the
    Git integration in the left sidebar in the UI to graphically interact with your
    code base, as shown in *Figure 5.4*. You can conduct actions you would normally
    do in Git with the UI: switching branches, pull, commit, and push.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Graphical interface of Git integration in the SageMaker Studio
    IDE'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_06_04.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.4 – Graphical interface of Git integration in the SageMaker Studio
    IDE
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also perform *notebook diff* on a changed file by right-clicking on
    the changed file and selecting `$ git diff`. For example, in *Figure 5.5*, we
    can see clearly that `instance_type` has been changed since the last commit:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Visualizing changes in a notebook in Git'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_06_05.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.5 – Visualizing changes in a notebook in Git
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Another powerful collaboration feature in SageMaker Studio is sharing a notebook
    with your colleagues so that they can directly work on the notebook you created.
    You can share a notebook with output and Git repository information with a click
    of the **Share** button in the top right of a notebook, as shown in *Figure 5.6*:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Sharing a notebook in SageMaker Studio with another user'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_06_06.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.6 – Sharing a notebook in SageMaker Studio with another user
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be prompted to choose the level of information to be included and
    will be provided with a URL such as https://<sm-domain-id>.studio.<region>.sagemaker.aws/jupyter/default/lab?sagemaker-share-id=xxxxxxxxxxxxxxxxxxx
    for anyone who has a user profile in the same SageMaker Studio domain. Once your
    colleague opens the URL, they will see the read-only notebook, snapshot details,
    and an option to create a copy to be able to edit the notebook, as shown in *Figure
    5.7*:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Another user''s view of the shared notebook'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_06_07.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.7 – Another user's view of the shared notebook
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: The notebook-sharing feature requires configuration when the domain is created.
    Notebook sharing is enabled if you set up the domain using **Quickstart**, as
    described in [*Chapter 2*](B17447_02_ePub_RK.xhtml#_idTextAnchor025), *Introducing
    Amazon SageMaker Studio*. If you use the Standard setup, you need to explicitly
    enable notebook sharing.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explained how you can train a ML model in a notebook in
    SageMaker Studio. We ran two examples, one using SageMaker's built-in BlazingText
    algorithm to train a text classification model, and another one using TensorFlow
    as a deep learning framework to build a network architecture to train a sentiment
    analysis model to predict the sentiment in movie review data. We learned how SageMaker's
    fully managed training feature works and how to provision the right amount of
    compute resources from the SageMaker SDK for your training script.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: We demonstrated SageMaker Experiments' ability to manage and compare ML training
    runs in SageMaker Studio's UI. Besides training with TensorFlow scripts, we also
    explained how flexible SageMaker training is when working with various ML frameworks,
    such as PyTorch, MXNet, Hugging Face, and scikit-learn. Last but not least, we
    showed you how SageMaker's Git integration and notebook-sharing features can help
    boost your productivity.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about **SageMaker Clarify** and how to apply
    SageMaker Clarify to detect bias in your data and ML models and to explain how
    models make decisions. Understanding bias and model explainability is essential
    to creating a fair ML model. We will dive deep into the approaches, metrics SageMaker
    Clarify uses to measure the bias and how Clarify explains the model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
