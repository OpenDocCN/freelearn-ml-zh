- en: '*Chapter 5*: Building and Training ML Models with SageMaker Studio IDE'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*: 使用 SageMaker Studio IDE 构建和训练 ML 模型'
- en: Building and training a **machine learning** (**ML**) model can be easy with
    SageMaker Studio. It is an **integrated development environment** (**IDE**) designed
    for ML developers for building and training ML models at scale and efficiently.
    In order to train an ML model, you may previously have dealt with the cumbersome
    overhead of managing compute infrastructure for yourself or for your team to train
    ML models properly. You may also have experienced compute resource constraints,
    either on desktop machines or with cloud resources, where you are given a fixed-size
    instance. When you develop in SageMaker Studio, there is no more frustration with
    provisioning and managing compute infrastructure because you can easily make use
    of elastic compute in SageMaker Studio and its wide support of sophisticated ML
    algorithms and frameworks for your ML use case.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SageMaker Studio 构建和训练一个 **机器学习**（**ML**）模型可以变得简单。它是一个 **集成开发环境**（**IDE**），专为
    ML 开发者设计，用于大规模和高效地构建和训练 ML 模型。为了训练一个 ML 模型，你可能之前已经处理过自己或团队管理计算基础设施的繁琐开销，以正确地训练
    ML 模型。你也可能经历过计算资源限制，无论是在桌面机器上还是在云资源中，你被分配了一个固定大小的实例。当你使用 SageMaker Studio 进行开发时，不再有配置和管理计算基础设施的挫折，因为你可以轻松地利用
    SageMaker Studio 中的弹性计算以及其对复杂 ML 算法和框架的广泛支持，以满足你的 ML 用例。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Training models with SageMaker's built-in algorithms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SageMaker 内置算法训练模型
- en: Training with code written in popular frameworks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用流行框架编写的代码进行训练
- en: Developing and collaborating using SageMaker Notebook
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SageMaker Notebook 进行开发和协作
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you need to access the code provided at [https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你需要访问提供的代码，代码位于 [https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter05)。
- en: Training models with SageMaker's built-in algorithms
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker 内置算法训练模型
- en: 'When you want to build an ML model from a notebook in SageMaker Studio for
    your ML use case and data, one of the easiest approaches is to use one of SageMaker''s
    built-in algorithms. There are two advantages of using built-in algorithms:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想要在 SageMaker Studio 的笔记本中构建一个针对你的 ML 用例和数据的 ML 模型时，最简单的方法之一是使用 SageMaker
    的内置算法。使用内置算法有两个优点：
- en: The built-in algorithms do not require you to write any sophisticated ML code.
    You only need to provide your data, make sure the data format matches the algorithms'
    requirements, and specify the hyperparameters and compute resources.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置算法不需要你编写任何复杂的 ML 代码。你只需要提供你的数据，确保数据格式符合算法的要求，并指定超参数和计算资源。
- en: The built-in algorithms are optimized for AWS compute infrastructure and are
    scalable out of the box. It is easy to perform distributed training across multiple
    compute instances and/or enable GPU support to speed up training time.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置算法针对 AWS 计算基础设施进行了优化，并且开箱即用即可扩展。轻松地在多个计算实例上执行分布式训练，并/或启用 GPU 支持，以加快训练时间。
- en: 'SageMaker''s built-in algorithm suite offers algorithms that are suitable for
    the most common ML use cases. There are algorithms for the following categories:
    **supervised learning**, **unsupervised learning**, **image analysis**, and **textual
    analysis**. Most notably, there is **XGBoost** and **k-means** for tabular data
    for supervised learning and unsupervised learning, respectively, as well as **image
    classification**, **object detection**, and **semantic segmentation** for image
    analysis. For textual analysis, we have the **word2vec**, **text classification**,
    and **sequence-to-sequence** algorithms. These are just example algorithms for
    each category we''ve mentioned. There are more useful algorithms available but
    I am not listing them exhaustively. You can visit [https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html)
    to see a full list and further details.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker内置算法套件提供了适用于最常见机器学习用例的算法。以下类别中都有算法：**监督学习**、**无监督学习**、**图像分析**和**文本分析**。最值得注意的是，对于监督学习和无监督学习，分别有**XGBoost**和**k-means**用于表格数据，以及用于图像分析的**图像分类**、**目标检测**和**语义分割**。对于文本分析，我们有**word2vec**、**文本分类**和**序列到序列**算法。这些只是我们提到的每个类别的示例算法。还有更多有用的算法可供选择，但我不一一列举。您可以访问[https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html)查看完整列表和更多详细信息。
- en: Note
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: GPU support and distributed training capability for algorithms vary. Please
    visit [https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html](https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html)
    for GPU and distributed training support for each algorithm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的GPU支持和分布式训练能力各不相同。请访问[https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html](https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html)以了解每个算法的GPU和分布式训练支持。
- en: Let's take a use case and an algorithm to demonstrate how to use SageMaker's
    built-in algorithms.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个用例和一个算法来展示如何使用SageMaker的内置算法。
- en: Training an NLP model easily
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简易训练NLP模型
- en: Training an ML model does not require writing any ML codes with SageMaker's
    built-in algorithms. We will look at an NLP use case to classify sentences into
    categories using the DBpedia Ontology Dataset from *DBpedia* ([https://www.dbpedia.org/](https://www.dbpedia.org/)),
    which consists of 560,000 training samples and 70,000 testing samples of the titles
    and abstracts of Wikipedia articles. Please open the notebook in `chapter05/01-built_in_algorithm_text_classification.ipynb`
    from the repository using the **Python 3 (Data Science)** kernel and the **ml.t3.medium**
    instance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SageMaker的内置算法训练ML模型不需要编写任何ML代码。我们将通过一个NLP用例来查看如何使用来自*DBpedia*（[https://www.dbpedia.org/](https://www.dbpedia.org/)）的DBpedia本体数据集将句子分类到类别中，该数据集包含560,000个训练样本和70,000个测试样本的维基百科文章的标题和摘要。请使用**Python
    3 (Data Science**)内核和**ml.t3.medium**实例打开存储库中的`chapter05/01-built_in_algorithm_text_classification.ipynb`笔记本。
- en: 'In the notebook, we first download the dataset and inspect it to understand
    how we need to process the data, as shown in the following snippet:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中，我们首先下载数据集并检查它，以了解我们需要如何处理数据，如下面的代码片段所示：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We see that the data, `dbpedia_csv/train.csv`, is formatted as `<class index>,<title>,<abstract>`.
    There is also a file called `dbpedia_csv/classes.txt` documenting the classes
    in an order that corresponds to the class index seen in `dbpedia_csv/train.csv`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到数据，`dbpedia_csv/train.csv`，格式为`<类别索引>,<标题>,<摘要>`。还有一个名为`dbpedia_csv/classes.txt`的文件，记录了类别，其顺序与`dbpedia_csv/train.csv`中看到的类别索引相对应。
- en: 'This is a text classification problem: given the abstract of an article, we
    want to build a model to predict and classify the classes this abstract belong
    to. This is a common use case when working with a large number of text documents,
    such as articles on the Wikipedia site from which this dataset is sourced. It
    is almost impossible to use human review to organize all the documents.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个文本分类问题：给定一篇文章的摘要，我们想要构建一个模型来预测和分类这个摘要所属的类别。当处理大量文本文档时，这是一个常见的用例，例如来自维基百科网站的数据集，其中包含来自维基百科文章的标题和摘要。几乎不可能使用人工审查来组织所有文档。
- en: One of the built-in algorithms that is suitable for this use case is **BlazingText**.
    BlazingText has highly optimized implementations for both Word2vec (unsupervised)
    and text classification (supervised). The Word2vec algorithm can convert text
    into a vector representation, or **word embedding**, for any downstream NLP usage,
    such as sentiment analysis or named entity recognition. Text classification can
    classify documents into categories. This is perfect for our use case and dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此类用例，一个合适的内置算法是**BlazingText**。BlazingText对Word2vec（无监督）和文本分类（监督）都有高度优化的实现。Word2vec算法可以将文本转换为向量表示，或**词嵌入**，适用于任何下游NLP应用，如情感分析或命名实体识别。文本分类可以将文档分类到类别中。这对于我们的用例和数据集来说非常合适。
- en: 'Getting the data ready for training is key when using SageMaker''s built-in
    algorithm. Using BlazingText for text classification requires each data point
    to be formatted as `__label__<class> text…`. Here''s an example:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用SageMaker的内置算法时，准备训练数据是关键。使用BlazingText进行文本分类需要将每个数据点格式化为`__label__<class>
    text…`。以下是一个示例：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We use a `preprocess` function, which calls the `transform_text` function to
    tokenize each row of the abstract. We use a sentence tokenizer, `punkt`, from
    the `nltk` library inside the `transform_text` function. We preprocess both train
    and test files. To keep the processing time manageable, we use only 20% of the
    training data, as shown in the following code snippet:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个`preprocess`函数，该函数调用`transform_text`函数来标记化摘要的每一行。在`transform_text`函数中，我们使用`nltk`库中的`sentence
    tokenizer`，即`punkt`。我们预处理训练和测试文件。为了保持处理时间可控，我们只使用20%的训练数据，如下面的代码片段所示：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can see that now we have the data in the expected format. Feel free to expand
    the training set to a higher percentage using the `keep` argument in `preprocess`.
    After preprocessing, we are ready to invoke the built-in algorithm.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，现在我们已经有了预期的数据格式。请随意使用`preprocess`中的`keep`参数将训练集扩展到更高的百分比。预处理后，我们就可以调用内置算法了。
- en: 'SageMaker''s built-in algorithms are fully managed containers that can be accessed
    with a simple SDK call. The following code allows us to use the BlazingText algorithm
    for text classification:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker的内置算法是完全管理的容器，可以通过简单的SDK调用访问。以下代码允许我们使用BlazingText算法进行文本分类：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After execution, we get a string in a variable called `image`. You may be wondering,
    what is this string that looks like a URL path? How is this an algorithm for model
    training?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 执行后，我们得到一个名为`image`的变量中的字符串。你可能想知道，这个看起来像URL路径的字符串是什么？这如何是一个模型训练算法？
- en: '**Container technology** is the core of SageMaker managed training. Container
    technology allows SageMaker the flexibility to work with algorithms from any framework
    and any runtime requirements. Instead of using the runtime setup in the notebook
    and using the compute resource behind the notebook for model training, SageMaker
    takes the data you supply and a container image that has the runtime setup and
    the code base to a separate SageMaker-managed compute infrastructure to conduct
    model training.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器技术**是SageMaker托管训练的核心。容器技术允许SageMaker具有与任何框架和任何运行时要求的工作灵活性。SageMaker不是使用笔记本中的运行时设置和使用笔记本背后的计算资源进行模型训练，而是将您提供的数据和一个包含运行时设置和代码库的容器镜像带到SageMaker托管的计算基础设施中进行模型训练。'
- en: The path in `image` points to a container image stored in **Amazon Elastic Container
    Registry** (**ECR**) that has the BlazingText ML algorithm. We can use it to start
    a model training job with a SageMaker estimator.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在`image`路径中指向一个存储在**Amazon Elastic Container Registry**（**ECR**）中的容器镜像，其中包含BlazingText
    ML算法。我们可以使用它通过SageMaker估计器启动一个模型训练作业。
- en: 'SageMaker estimator is a key construct for the fully managed model training
    that enables us to command various aspects of a model training job with a simple
    API. The following snippet is how we set up a training job with SageMaker''s BlazingText
    algorithm:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker估计器是托管模型训练的关键构建块，它使我们能够通过简单的API命令模型训练作业的各个方面。以下是如何使用SageMaker的BlazingText算法设置训练作业的代码片段：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Most notably, the arguments that go into the estimator are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最值得注意的是，输入到估计器的参数如下：
- en: The algorithm as a container, `image`
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为容器的算法，`image`
- en: '`hyperparameters` for the training job'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练作业的`hyperparameters`
- en: The compute resources needed for the job, `instance_type`, `instance_count`,
    and `volume_size`
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作业所需的计算资源，`instance_type`、`instance_count`和`volume_size`
- en: The IAM execution role, `role`
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IAM执行角色，`role`
- en: As you can see, not only do we specify algorithmic options, but also instruct
    SageMaker what cloud compute resources we need for this model training run. We
    request one `ml.c5.2xlarge` instance, a compute-optimized instance that has high-performance
    processors, with 30 GB storage for this training job. It allows us to use a lightweight,
    cheap instance type (`ml.t3.medium`) for the notebook environment during prototyping
    and do full-scale training on a more powerful instance type to get the job done
    faster.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们不仅指定了算法选项，还指导 SageMaker 我们需要哪些云计算资源来完成这次模型训练。我们请求一个 `ml.c5.2xlarge` 实例，这是一个具有高性能处理器的计算优化实例，为此次训练作业提供
    30 GB 的存储空间。它允许我们在原型设计期间使用轻量级、廉价的实例类型（`ml.t3.medium`）进行笔记本环境，并在更强大的实例类型上完成全规模训练以更快地完成任务。
- en: 'We have set up the algorithm and the compute resource; next, we need to associate
    the estimator with the training data. After we have prepared the data, we need
    to upload the data into an S3 bucket so that the SageMaker training job can access
    the `ml.c5.4xlarge` instance. We start the training by simply calling `estimator.fit()`
    with the data:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经设置了算法和计算资源；接下来，我们需要将估计器与训练数据关联起来。在准备完数据后，我们需要将数据上传到 S3 桶中，以便 SageMaker 训练作业可以访问
    `ml.c5.4xlarge` 实例。我们通过简单地调用 `estimator.fit()` 并传入数据来启动训练：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can see the job log in the notebook and observe the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在笔记本中查看作业日志并观察以下内容：
- en: SageMaker spins up one `ml.c5.2xlarge` instance for this training job.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker 为此训练作业启动一个 `ml.c5.2xlarge` 实例。
- en: SageMaker downloads the data from S3 and the BlazingText container image from
    ECR.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker 从 S3 下载数据，并从 ECR 下载 BlazingText 容器镜像。
- en: 'SageMaker runs the model training and logs the training and validation accuracy
    in the cell output shown here:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker 运行模型训练，并将训练和验证准确率记录在下面的单元格输出中：
- en: '[PRE6]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The cell output from the training job is also available in `estimator(…, enable_sagemaker_metrics=True)`,
    are sent to **Amazon CloudWatch Metrics** automatically. This gives us governance
    of the training jobs even if the notebooks are accidentally deleted.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 训练作业的单元格输出也存在于 `estimator(…, enable_sagemaker_metrics=True)` 中，并自动发送到 **Amazon
    CloudWatch Metrics**。即使笔记本意外删除，这也为我们提供了对训练作业的治理。
- en: 'Once the training job finishes, you can access the trained model in `estimator.model_data`,
    which can later be used for hosting and inferencing either in the cloud, which
    is a topic we will explore in depth in the next chapter, or on a computer with
    the `fastText` program. You can access the model with the following code block:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练作业完成，您可以在 `estimator.model_data` 中访问训练好的模型，该模型可以用于后续的托管和推理，无论是在云中，这是我们在下一章将深入探讨的主题，还是在安装了
    `fastText` 程序的计算机上。您可以使用以下代码块访问模型：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: BlazingText is a GPU-accelerated version of FastText. FastText ([https://fasttext.cc/](https://fasttext.cc/))
    is an open source library that can perform both word embedding generation (unsupervised)
    and text classification (supervised). The models created by BlazingText and FastText
    are compatible with each other.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: BlazingText 是 FastText 的 GPU 加速版本。FastText ([https://fasttext.cc/](https://fasttext.cc/))
    是一个开源库，可以执行词嵌入生成（无监督）和文本分类（监督）。BlazingText 和 FastText 创建的模型是兼容的。
- en: We have just created a sophisticated text classification model that is capable
    of classifying the category of documents from DBpedia at an accuracy of 0.9766
    on the validation data with minimal ML code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚创建了一个复杂的文本分类模型，该模型能够在验证数据上以 0.9766 的准确率对 DBpedia 中的文档类别进行分类，且使用的 ML 代码量最少。
- en: Let's also set up an ML experiment management framework, **SageMaker Experiments**,
    to keep track of jobs we launch in this chapter.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再设置一个机器学习实验管理框架，**SageMaker Experiments**，以跟踪我们在本章中启动的作业。
- en: Managing training jobs with SageMaker Experiments
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 SageMaker Experiments 管理训练作业
- en: As data scientists, we might have all encountered a tricky situation where the
    number of model training runs can grow very quickly to such a degree that it becomes
    difficult to track the best model in various experiment settings, such as dataset
    versions, hyperparameters, and algorithms. In SageMaker Studio, you can easily
    track the experiments among the training runs with **SageMaker Experiments** and
    visualize them in the experiments and trials component UI. SageMaker Experiments
    is an open source project ([https://github.com/aws/sagemaker-experiments](https://github.com/aws/sagemaker-experiments))
    and can be accessed programmatically through the Python SDK.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，我们可能都遇到过一种棘手的情况，即模型训练运行的次数可以非常快地增长到难以追踪最佳模型的各种实验设置的程度，例如数据集版本、超参数和算法。在SageMaker
    Studio中，您可以使用**SageMaker Experiments**轻松跟踪训练运行中的实验，并在实验和试验组件UI中可视化它们。SageMaker
    Experiments是一个开源项目([https://github.com/aws/sagemaker-experiments](https://github.com/aws/sagemaker-experiments))，可以通过Python
    SDK编程访问。
- en: In SageMaker Experiments, an **Experiment** is a collection of **trial** runs
    that are executions of an ML workflow that can contain **trial components** such
    as data processing and model training.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker Experiments中，**实验**是一系列**试验**运行集合，这些运行是ML工作流的执行，可能包含**试验组件**，如数据处理和模型训练。
- en: 'Let''s continue with the `chapter05/01-built_in_algorithm_text_classification.ipynb`
    notebook and see how we can set up an experiment and trial with SageMaker Experiments
    to track training jobs with different learning rates in the following snippet
    so that we can compare the performance from the trials easily in SageMaker Studio:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用`chapter05/01-built_in_algorithm_text_classification.ipynb`笔记本，看看我们如何使用SageMaker
    Experiments设置实验和试验，以跟踪具有不同学习率的训练作业，以便我们可以在SageMaker Studio中轻松比较试验的性能，以下是一个片段：
- en: 'First, we install the `sagemaker-experiments` SDK in the notebook kernel:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们在笔记本内核中安装`sagemaker-experiments` SDK：
- en: '[PRE8]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We then create an experiment named `dbpedia-text-classification` that we can
    use to store all the jobs related to this model training use case using the `smexperiments`
    library:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一个名为`dbpedia-text-classification`的实验，我们可以使用`smexperiments`库来存储与此模型训练用例相关的所有作业：
- en: '[PRE9]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then we create a utility function, `create_estimator()`, with an input argument,
    `learning_rate`, for ease of use later when we iterate over various learning rates:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一个名为`create_estimator()`的实用函数，它有一个输入参数`learning_rate`，以便在以后迭代各种学习率时使用方便：
- en: '[PRE10]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s run three training jobs in a `for` loop with varying learning rates
    in order to understand how the accuracy changes:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在`for`循环中运行三个具有不同学习率的训练作业，以便了解准确率如何变化：
- en: '[PRE11]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the `for` loop, we create unique training job names, `dbpedia-blazingtext-{exp_datetime}`,
    to be associated with a trial, `exp_trial`, and an experiment configuration, `experiment_config`,
    to store information. Then we pass `experiment_config` into the `estimator.fit()`
    function and SageMaker will track the experiments for us automatically.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在`for`循环中，我们创建唯一的训练作业名称`dbpedia-blazingtext-{exp_datetime}`，将其与一个试验`exp_trial`和一个实验配置`experiment_config`相关联，以存储信息。然后我们将`experiment_config`传递给`estimator.fit()`函数，SageMaker将自动为我们跟踪实验。
- en: Note
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We put `wait=False` in the `estimator.fit()` call. This allows the training
    job to run asynchronously, meaning that the cell is returned immediately as opposed
    to being held by the process until the training is completed. In effect, our jobs
    with different learning rates are run in parallel, each using its own separate
    SageMaker-managed instances for training.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`estimator.fit()`调用中放置`wait=False`。这允许训练作业异步运行，这意味着单元格会立即返回，而不是被进程持有直到训练完成。实际上，我们的具有不同学习率的作业是并行运行的，每个作业都使用自己的SageMaker管理的实例进行训练。
- en: 'In SageMaker Studio, you can easily compare the results of these training jobs
    with SageMaker Experiments. We can create a chart to compare the accuracies of
    the three jobs with varying learning rates in the SageMaker Studio UI:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker Studio中，您可以使用SageMaker Experiments轻松比较这些训练作业的结果。我们可以在SageMaker Studio
    UI中创建一个图表来比较三个作业在不同学习率下的准确率：
- en: 'Click on the **SageMaker Components and registries** in the left sidebar, as
    shown in *Figure 5.1*:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如*图5.1*所示，点击左侧边栏中的**SageMaker组件和注册表**：
- en: '![Figure 5.1 – Viewing experiments and trials from the left sidebar'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 – 从左侧边栏查看实验和试验'
- en: '](img/B17447_06_01.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_06_01.jpg)'
- en: Figure 5.1 – Viewing experiments and trials from the left sidebar
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 从左侧边栏查看实验和试验
- en: Select **Experiments and trials** in the drop-down menu, as shown in *Figure
    5.1*.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下拉菜单中选择**实验和试验**，如图*图5.1*所示。
- en: Right-click on the **dbpedia-text-classification** experiment entry and choose
    **Open in trial component list**.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击**dbpedia-text-classification**实验条目并选择**在试验组件列表中打开**。
- en: A new view in the main working area will pop up. You can configure the columns
    to show the accuracies and learning rates as shown in *Figure 5.2*. We can see
    **validation:accuracy**, and **train:accuracy** with respect to the three **learning_rate**
    settings. With **learning_rate** set to **0.01**, we have the most balanced training
    and validation accuracies. A learning rate of 0.1 is overfitted, while a learning
    rate of 0.001 is underfitted.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主工作区域将弹出一个新视图。您可以配置列以显示准确率和学习率，如图*图5.2*所示。我们可以看到**验证:准确率**和**训练:准确率**与三个**学习率**设置相关。当**学习率**设置为**0.01**时，训练和验证准确率最为平衡。学习率为0.1时过拟合，而学习率为0.001时欠拟合。
- en: '![Figure 5.2 – Viewing and comparing training jobs'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 – 查看和比较训练作业'
- en: '](img/B17447_06_02.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_06_02.jpg)'
- en: Figure 5.2 – Viewing and comparing training jobs
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 查看和比较训练作业
- en: We can create a line chart of **validation:accuracy** versus **learning_rate**.
    Multi-select the three trial components and click **Add chart** in the top right.
    A new view will pop up. Configure the chart properties as shown in *Figure 5.3*.
    You will get a chart that shows the relationship between **validation:accuracy**
    and **learning_rate**.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以创建一个**验证:准确率**与**学习率**的折线图。多选三个试验组件，然后在右上角点击**添加图表**。将弹出一个新视图。按照*图5.3*所示配置图表属性。您将得到一个显示**验证:准确率**与**学习率**之间关系的图表。
- en: '![Figure 5.3 – Comparing and charting validation accuracy versus learning rate'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.3 – 比较和图表化验证准确率与学习率'
- en: '](img/B17447_06_03.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_06_03.jpg)'
- en: Figure 5.3 – Comparing and charting validation accuracy versus learning rate
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 比较和图表化验证准确率与学习率
- en: SageMaker Experiments is useful for managing jobs and resources and comparing
    performance as you start building an ML project at scale in SageMaker Studio.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Experiments 在您开始在 SageMaker Studio 中以规模构建机器学习项目时管理作业和资源以及比较性能非常有用。
- en: Note
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Training and processing jobs that do not have `experiment_config` will be placed
    in **Unassigned trial components**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 没有设置`experiment_config`的训练和处理作业将被放置在**未分配的试验组件**中。
- en: More often than not, you already have some ML projects that use popular frameworks
    such as TensorFlow and PyTorch to train models. You can also run them with SageMaker's
    fully managed training capability.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的时候，您已经有一些使用流行框架（如 TensorFlow 和 PyTorch）来训练模型的机器学习项目。您也可以使用 SageMaker 的完全托管训练功能来运行它们。
- en: Training with code written in popular frameworks
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用流行框架编写的代码进行训练
- en: SageMaker's fully managed training works with your favorite ML frameworks too,
    thanks to the container technology we mentioned previously. You may have been
    working with `Tensorflow`, `PyTorch`, `Hugging` `Face`, `MXNet`, `scikit-learn`,
    and many more. You can easily use them with SageMaker so that you can use its
    fully managed training capabilities and benefit from the ease of provisioning
    right-sized compute infrastructure. SageMaker enables you to use your own training
    scripts for custom models and run them on prebuilt containers for popular frameworks.
    This is known as **Script Mode**. For frameworks not covered by the prebuilt containers,
    you also can use your own container for virtually any framework of your choice.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们之前提到的容器技术，SageMaker 的完全托管训练与您喜欢的 ML 框架也兼容。您可能一直在使用 `Tensorflow`、`PyTorch`、`Hugging
    Face`、`MXNet`、`scikit-learn` 以及更多。您可以使用 SageMaker 轻松使用它们，以便您可以使用其完全托管的训练功能，并从配置适当规模的计算基础设施的便利性中受益。SageMaker
    允许您使用自己的训练脚本为自定义模型，并在为流行框架预构建的容器上运行它们。这被称为**脚本模式**。对于未覆盖的预构建容器框架，您也可以使用自己的容器为几乎任何您选择的框架。
- en: Let's look at training a sentiment analysis model written in TensorFlow as an
    example to show you how to use your own script in SageMaker to run with SageMaker's
    prebuilt TensorFlow container. Then we will describe a similar process for other
    frameworks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以用 TensorFlow 编写的情感分析模型为例，向您展示如何在 SageMaker 中使用自己的脚本运行 SageMaker 预构建的 TensorFlow
    容器。然后我们将描述其他框架的类似过程。
- en: TensorFlow
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow
- en: TensorFlow is an open source framework for ML, specifically for deep neural
    networks. You can run TensorFlow code using SageMaker's prebuilt TensorFlow training
    and inference containers, available through the SageMaker SDK's `sagemaker.tensorflow`.
    Please open the notebook in `chapter05/02-tensorflow_sentiment_analysis.ipynb`
    from the repository using the `ml.t3.medium` instance. The objective in this example
    is to train and predict the sentiment (positive/negative) from movie reviews from
    the IMDb movie database using a neural network built with TensorFlow layers. You
    could run the neural network training inside a notebook, but this will require
    you to have a compute instance that is capable of training a deep neural network
    with a large amount of data at all times, even when you are just exploring data
    and writing code. But with SageMaker, you can optimize the compute usage by using
    a smaller instance for code building and only using a GPU instance for full-scale
    training.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是一个开源的机器学习框架，专门用于深度神经网络。您可以使用SageMaker预构建的TensorFlow训练和推理容器运行TensorFlow代码，这些容器通过SageMaker
    SDK的`sagemaker.tensorflow`提供。请使用`ml.t3.medium`实例打开存储库中的`chapter05/02-tensorflow_sentiment_analysis.ipynb`笔记本。在这个例子中，目标是使用TensorFlow层构建的神经网络从IMDb电影数据库中的电影评论中训练和预测情感（正面/负面）。您可以在笔记本中运行神经网络训练，但这将需要您始终拥有一个能够训练大量数据的深度神经网络的计算实例，即使您只是在探索数据和编写代码时也是如此。但是，使用SageMaker，您可以通过使用较小的实例进行代码构建，仅使用GPU实例进行大规模训练来优化计算使用。
- en: In `chapter06/02-tensorflow_sentiment_analysis.ipynb`, we first install the
    library we need and get the Sagemaker session set up. Then we load the IMDb dataset
    from `tensorflow.python.keras.datasets`, run minimal data preprocessing, and save
    the training and test splits to the local filesystem and then to an S3 bucket.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在`chapter06/02-tensorflow_sentiment_analysis.ipynb`中，我们首先安装所需的库并设置Sagemaker会话。然后，我们从`tensorflow.python.keras.datasets`加载IMDb数据集，进行最小数据预处理，并将训练和测试分割保存到本地文件系统，然后保存到S3桶中。
- en: Assuming we have previously developed a neural network architecture that works
    on this IMDb dataset, as shown in the following code block, we can easily take
    it into SageMaker to train.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们之前已经开发了一个适用于此IMDb数据集的神经网络架构，如下面的代码块所示，我们可以轻松地将它带入SageMaker进行训练。
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'SageMaker can take a TensorFlow script into a Docker container and train the
    script with the data. To do so, SageMaker requires the script to be aware of environmental
    variables set in the container, the compute infrastructure, and, optionally, the
    script needs to be able to take inputs from the execution, such as hyperparameters.
    Here are the steps:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker可以将TensorFlow脚本放入Docker容器中，并使用数据训练脚本。为此，SageMaker需要脚本了解容器中设置的环境变量、计算基础设施，并且可选地，脚本需要能够从执行中获取输入，例如超参数。以下是步骤：
- en: Create a script to put in the model architecture and data loading functions
    (`get_model`, `get_train_data`, `get_test_data`, and so on).
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个脚本，用于输入模型架构和数据加载函数（`get_model`、`get_train_data`、`get_test_data`等）。
- en: 'Create an argument parser that takes in parameters such as hyperparameters
    and training data location from script execution. SageMaker is going to run the
    script as an executable in the container with arguments specified from a SDK call.
    The training data location is passed into the script with a default from environmental
    variable SageMaker set up in the container (`SM_CHANNEL_*`). The argument parser
    is defined in a `parse_arg()` function, shown as follows:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个参数解析器，从脚本执行中获取参数，例如超参数和训练数据位置。SageMaker将作为容器中的可执行文件运行脚本，并通过SDK调用指定参数。训练数据位置通过容器中SageMaker设置的环境变量（`SM_CHANNEL_*`）传递给脚本。参数解析器在`parse_arg()`函数中定义，如下所示：
- en: '[PRE13]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `TRAIN` or `TEST` suffix in the `SM_CHANNEL_*` environmental variable has
    to match that of the dictionary key provided in the input data channel in the
    `estimator.fit()` call. So, later, when we specify the data channel, we need to
    create a dictionary whose keys are `TRAIN` and `TEST`, case-insensitive.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`SM_CHANNEL_*`环境变量中的`TRAIN`或`TEST`后缀必须与`estimator.fit()`调用中输入数据通道提供的字典键匹配。因此，当我们指定数据通道时，我们需要创建一个键为`TRAIN`和`TEST`的字典，不区分大小写。'
- en: 'Put in the training steps as part of `if __name__ == "__main__":`:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练步骤作为`if __name__ == "__main__":`部分的一部分：
- en: '[PRE14]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Make sure to replace the variables in the network with that from the argument
    parser. For example, change `tf.keras.optimizers.Adam(learning_rate)` to `tf.keras.optimizers.Adam(`args.`learning_rate)`.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保将网络中的变量替换为从参数解析器中获取的变量。例如，将`tf.keras.optimizers.Adam(learning_rate)`更改为`tf.keras.optimizers.Adam(args.learning_rate)`。
- en: In our notebook, we write out the script to `code/tensorflow_sentiment.py`.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的笔记本中，我们将脚本写入到`code/tensorflow_sentiment.py`。
- en: 'Create a TensorFlow estimator using `sagemaker.tensorflow.TensorFlow`, which
    is an extension of the `estimator` class we used previously to work exclusively
    with ML training written in TensorFlow:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sagemaker.tensorflow.TensorFlow`创建一个TensorFlow估计器，它是我们之前用于专门与TensorFlow编写的ML训练一起使用的`estimator`类的扩展：
- en: '[PRE15]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Some of the key arguments here in TensorFlow estimator are `source_dir`, `entry_point`,
    `code_location`, `framework_version`, and `py_version`. `source_dir`, and `entry_point`
    is where we specify where the training script is located on the EFS filesystem
    (`code/tensorflow_sentiment.py`). If you need to use any additional Python libraries,
    you can include the libraries in a `requirements.txt` file, and place the text
    file in a directory specified in `source_dir` argument. SageMaker will first install
    libraries listed in the `requirements.txt` before executing the training script.
    `code_location` is where the script will be staged in S3\. `framework_version`
    and `py_version` allow us to specify the TensorFlow version and Python version
    that the training script is developed in.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow估计器中，一些关键的参数包括`source_dir`、`entry_point`、`code_location`、`framework_version`和`py_version`。`source_dir`和`entry_point`是我们指定训练脚本在EFS文件系统上的位置（`code/tensorflow_sentiment.py`）。如果您需要使用任何额外的Python库，可以将库包含在一个`requirements.txt`文件中，并将该文本文件放置在`source_dir`参数指定的目录中。SageMaker将首先安装`requirements.txt`中列出的库，然后再执行训练脚本。`code_location`是脚本将在S3上放置的位置。`framework_version`和`py_version`允许我们指定训练脚本开发的TensorFlow版本和Python版本。
- en: Note
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can find supported versions of TensorFlow at [https://github.com/aws/deep-learning-containers/blob/master/available_images.md](https://github.com/aws/deep-learning-containers/blob/master/available_images.md).
    You can find the TensorFlow estimator API at [https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://github.com/aws/deep-learning-containers/blob/master/available_images.md](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)找到支持的TensorFlow版本。您可以在[https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html)找到TensorFlow估计器API。
- en: 'Create a data channel dictionary:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据通道字典：
- en: '[PRE16]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a new experiment in SageMaker Experiments:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在SageMaker Experiments中创建一个新的实验：
- en: '[PRE17]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Call the `estimator.fit()` function with data and experiment configurations:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用数据和实验配置调用`estimator.fit()`函数：
- en: '[PRE18]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The training on one ml.p3.2xlarge instance, which has one high-performance
    NVIDIA® V100 Tensor Core GPU, takes about 3 minutes. Once the training job finishes,
    you can access the trained model from `model_dir` on S3\. This model is a Keras
    model and can be loaded in by Keras'' `load_model` API. You can then evaluate
    the model the same way you would in TensorFlow:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个配备一个高性能NVIDIA® V100 Tensor Core GPU的ml.p3.2xlarge实例上进行的训练大约需要3分钟。一旦训练作业完成，您可以从S3上的`model_dir`访问训练好的模型。这个模型是一个Keras模型，可以通过Keras的`load_model`
    API加载。然后，您可以以与在TensorFlow中相同的方式评估模型：
- en: '[PRE19]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We have successfully trained a custom TensorFlow model to predict IMDb review
    sentiment using SageMaker''s fully managed training infrastructure. For other
    frameworks, it is rather a similar process to adopt a custom script to SageMaker.
    We will take a look at the estimator API for PyTorch, Hugging Face, MXNet, and
    scikit-learn, which share the same base class: `sagemaker.estimator.Framework`.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功使用SageMaker的全托管训练基础设施训练了一个自定义TensorFlow模型来预测IMDb评论的情感。对于其他框架，采用自定义脚本的SageMaker过程相当类似。我们将查看PyTorch、Hugging
    Face、MXNet和scikit-learn的估计器API，它们共享相同的基类：`sagemaker.estimator.Framework`。
- en: PyTorch
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch
- en: PyTorch is a popular open source deep learning framework that is analogous to
    TensorFlow. Similar to how SageMaker supports TensorFlow, SageMaker has an estimator
    dedicated to PyTorch. You can access it with the `sagemaker.pytorch.PyTorch` class.
    The API's documentation is available at [https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html).
    Follow *steps* *1-9* in the *TensorFlow* section to use your PyTorch training
    script, but instead of `framework_version`, you would specify the PyTorch version
    to access the specific SageMaker-managed PyTorch training container image.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是一个流行的开源深度学习框架，与 TensorFlow 类似。类似于 SageMaker 支持 TensorFlow，SageMaker
    也有一个针对 PyTorch 的估计器。您可以使用 `sagemaker.pytorch.PyTorch` 类访问它。该API的文档可在 [https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html)
    查阅。按照 *步骤* *1-9* 在 *TensorFlow* 部分说明使用您的 PyTorch 训练脚本，但需要指定 PyTorch 版本以访问特定的SageMaker管理的PyTorch训练容器镜像。
- en: Hugging Face
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face
- en: Hugging Face is an ML framework dedicated to natural language processing use
    cases. It helps you train complex NLP models easily with pre-built architecture
    and pre-trained models. It is compatible with both TensorFlow and PyTorch, so
    you can train with the framework that you are most familiar with. You can access
    the estimator with the `sagemaker.huggingface.HuggingFace` class. The API's documentation
    is available at [https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html).
    Follow *steps* *1-9* in the *TensorFlow* section to use your scripts. The major
    difference compared with TensorFlow/PyTorch estimators is that there is an additional
    argument, `transformers_version`, for the `pytorch_version` or `tensorflow_version`
    instead of `framework_version`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 是一个专注于自然语言处理用例的机器学习框架。它帮助您通过预构建的架构和预训练模型轻松训练复杂的NLP模型。它与 TensorFlow
    和 PyTorch 都兼容，因此您可以使用您最熟悉的框架进行训练。您可以使用 `sagemaker.huggingface.HuggingFace` 类访问估计器。该API的文档可在
    [https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html)
    查阅。按照 *步骤* *1-9* 在 *TensorFlow* 部分说明使用您的脚本。与 TensorFlow/PyTorch 估计器相比，主要区别是有一个额外的参数
    `transformers_version`，用于 `pytorch_version` 或 `tensorflow_version`，而不是 `framework_version`。
- en: MXNet
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MXNet
- en: MXNet is a popular open source deep learning framework that is analogous to
    TensorFlow. You can access the MXNet estimator with the `sagemaker.mxnet.MXNet`
    class. The API documentation is available at [https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html).
    Follow *steps* *1-9* in the *TensorFlow* section to use your MXNet training script,
    but instead of `framework_version`, you need to specify the MXNet version to access
    the specific SageMaker-managed container image.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: MXNet 是一个流行的开源深度学习框架，与 TensorFlow 类似。您可以使用 `sagemaker.mxnet.MXNet` 类访问 MXNet
    估计器。API 文档可在 [https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html)
    查阅。按照 *步骤* *1-9* 在 *TensorFlow* 部分说明使用您的 MXNet 训练脚本，但需要指定 MXNet 版本以访问特定的SageMaker管理的容器镜像。
- en: Scikit-learn
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit-learn
- en: '`sagemaker.sklearn.SKLearn` class. The API''s documentation is available at
    https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html.
    Follow *steps* *1-9* in the *TensorFlow* section to use your sklearn training
    script, but instead of `framework_version`, you need to specify the sklearn version
    to access the specific SageMaker-managed container image.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker.sklearn.SKLearn` 类。该API的文档可在 https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html
    查阅。按照 *步骤* *1-9* 在 *TensorFlow* 部分说明使用您的sklearn训练脚本，但需要指定sklearn版本以访问特定的SageMaker管理的容器镜像，而不是使用
    `framework_version`。'
- en: While developing in SageMaker Studio, it is common that you need to be able
    to collaborate with your colleague and be able to run ML and data science code
    with diverse Python libraries. Let's see how we can enrich our model-building
    experience in SageMaker Studio.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio 中开发时，您通常需要能够与同事协作，并能够使用各种Python库运行机器学习和数据科学代码。让我们看看我们如何在
    SageMaker Studio 中丰富我们的模型构建体验。
- en: Developing and collaborating using SageMaker Notebook
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Notebook 进行开发和协作
- en: The SageMaker Studio IDE makes collaboration and customization easy. Besides
    the freedom of choosing the kernel and instance backing a SageMaker notebook,
    you could also manage Git repositories, compare notebooks, and share notebooks.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio IDE 使协作和定制变得容易。除了可以选择支持 SageMaker 笔记本的内核和实例之外，您还可以管理 Git 仓库、比较笔记本和共享笔记本。
- en: 'Users can interact with a Git repository easily in SageMaker Studio, and you
    may have already done so to clone the sample repository from GitHub for this book.
    Not only can you clone a repository from a system terminal, you can also use the
    Git integration in the left sidebar in the UI to graphically interact with your
    code base, as shown in *Figure 5.4*. You can conduct actions you would normally
    do in Git with the UI: switching branches, pull, commit, and push.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以在 SageMaker Studio 中轻松地与 Git 仓库进行交互，您可能已经为此书从 GitHub 克隆了示例仓库。您不仅可以从系统终端克隆仓库，还可以使用
    UI 左侧栏中的 Git 集成以图形方式与您的代码库进行交互，如图 *图 5.4* 所示。您可以使用 UI 执行您通常在 Git 中执行的操作：切换分支、拉取、提交和推送。
- en: '![Figure 5.4 – Graphical interface of Git integration in the SageMaker Studio
    IDE'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.4 – SageMaker Studio IDE 中 Git 集成的图形界面'
- en: '](img/B17447_06_04.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_06_04.jpg]'
- en: Figure 5.4 – Graphical interface of Git integration in the SageMaker Studio
    IDE
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – SageMaker Studio IDE 中 Git 集成的图形界面
- en: 'You can also perform *notebook diff* on a changed file by right-clicking on
    the changed file and selecting `$ git diff`. For example, in *Figure 5.5*, we
    can see clearly that `instance_type` has been changed since the last commit:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以通过在更改的文件上右键单击并选择 `$ git diff` 来对更改的文件执行 *notebook diff*。例如，在 *图 5.5* 中，我们可以清楚地看到
    `instance_type` 自上次提交以来已经发生了变化：
- en: '![Figure 5.5 – Visualizing changes in a notebook in Git'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.5 – 在 Git 中可视化笔记本中的更改'
- en: '](img/B17447_06_05.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_06_05.jpg]'
- en: Figure 5.5 – Visualizing changes in a notebook in Git
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 在 Git 中可视化笔记本中的更改
- en: 'Another powerful collaboration feature in SageMaker Studio is sharing a notebook
    with your colleagues so that they can directly work on the notebook you created.
    You can share a notebook with output and Git repository information with a click
    of the **Share** button in the top right of a notebook, as shown in *Figure 5.6*:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio 中的另一个强大协作功能是与您的同事共享笔记本，以便他们可以直接在您创建的笔记本上工作。您可以通过笔记本右上角的 **分享**
    按钮轻松地与输出和 Git 仓库信息共享笔记本，如图 *图 5.6* 所示：
- en: '![Figure 5.6 – Sharing a notebook in SageMaker Studio with another user'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.6 – 在 SageMaker Studio 中与另一用户共享笔记本'
- en: '](img/B17447_06_06.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_06_06.jpg]'
- en: Figure 5.6 – Sharing a notebook in SageMaker Studio with another user
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 在 SageMaker Studio 中与另一用户共享笔记本
- en: 'You will be prompted to choose the level of information to be included and
    will be provided with a URL such as https://<sm-domain-id>.studio.<region>.sagemaker.aws/jupyter/default/lab?sagemaker-share-id=xxxxxxxxxxxxxxxxxxx
    for anyone who has a user profile in the same SageMaker Studio domain. Once your
    colleague opens the URL, they will see the read-only notebook, snapshot details,
    and an option to create a copy to be able to edit the notebook, as shown in *Figure
    5.7*:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 您将被提示选择要包含的信息级别，并将提供一个类似 https://<sm-domain-id>.studio.<region>.sagemaker.aws/jupyter/default/lab?sagemaker-share-id=xxxxxxxxxxxxxxxxxxx
    的 URL，任何人只要在相同的 SageMaker Studio 域中有用户配置文件，就可以访问。一旦您的同事打开此 URL，他们将看到只读笔记本、快照详情以及创建副本以便编辑笔记本的选项，如图
    *图 5.7* 所示：
- en: '![Figure 5.7 – Another user''s view of the shared notebook'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.7 – 共享笔记本的另一个用户的视图'
- en: '](img/B17447_06_07.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_06_07.jpg]'
- en: Figure 5.7 – Another user's view of the shared notebook
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 共享笔记本的另一个用户的视图
- en: Note
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The notebook-sharing feature requires configuration when the domain is created.
    Notebook sharing is enabled if you set up the domain using **Quickstart**, as
    described in [*Chapter 2*](B17447_02_ePub_RK.xhtml#_idTextAnchor025), *Introducing
    Amazon SageMaker Studio*. If you use the Standard setup, you need to explicitly
    enable notebook sharing.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建域时，笔记本共享功能需要配置。如果您使用 *快速入门* 设置域，如 [*第 2 章*](B17447_02_ePub_RK.xhtml#_idTextAnchor025)
    中所述，*介绍 Amazon SageMaker Studio*，则笔记本共享被启用。如果您使用标准设置，则需要明确启用笔记本共享。
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explained how you can train a ML model in a notebook in
    SageMaker Studio. We ran two examples, one using SageMaker's built-in BlazingText
    algorithm to train a text classification model, and another one using TensorFlow
    as a deep learning framework to build a network architecture to train a sentiment
    analysis model to predict the sentiment in movie review data. We learned how SageMaker's
    fully managed training feature works and how to provision the right amount of
    compute resources from the SageMaker SDK for your training script.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们解释了您如何在SageMaker Studio的笔记本中训练机器学习模型。我们运行了两个示例，一个示例使用SageMaker内置的BlazingText算法来训练文本分类模型，另一个示例使用TensorFlow作为深度学习框架来构建网络架构，以训练情感分析模型来预测电影评论数据中的情感。我们学习了SageMaker的完全托管训练功能是如何工作的，以及如何从SageMaker
    SDK为您的训练脚本配置正确的计算资源。
- en: We demonstrated SageMaker Experiments' ability to manage and compare ML training
    runs in SageMaker Studio's UI. Besides training with TensorFlow scripts, we also
    explained how flexible SageMaker training is when working with various ML frameworks,
    such as PyTorch, MXNet, Hugging Face, and scikit-learn. Last but not least, we
    showed you how SageMaker's Git integration and notebook-sharing features can help
    boost your productivity.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了SageMaker Experiments在SageMaker Studio的UI中管理并比较机器学习训练运行的能力。除了使用TensorFlow脚本进行训练外，我们还解释了SageMaker在处理各种机器学习框架（如PyTorch、MXNet、Hugging
    Face和scikit-learn）时的灵活性。最后但同样重要的是，我们向您展示了SageMaker的Git集成和笔记本共享功能如何帮助提高您的生产力。
- en: In the next chapter, we will learn about **SageMaker Clarify** and how to apply
    SageMaker Clarify to detect bias in your data and ML models and to explain how
    models make decisions. Understanding bias and model explainability is essential
    to creating a fair ML model. We will dive deep into the approaches, metrics SageMaker
    Clarify uses to measure the bias and how Clarify explains the model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习关于**SageMaker Clarify**以及如何将SageMaker Clarify应用于检测数据集和机器学习模型中的偏差，并解释模型是如何做出决策的。理解偏差和模型可解释性对于创建公平的机器学习模型至关重要。我们将深入探讨SageMaker
    Clarify使用的测量偏差的方法、指标，以及Clarify如何解释模型。
