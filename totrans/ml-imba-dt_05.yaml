- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Cost-Sensitive Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本敏感学习
- en: So far, we have studied various sampling techniques and ways to oversample or
    undersample data. However, both of these techniques have their own unique set
    of issues. For example, oversampling can easily lead to overfitting of the model
    due to the exact or very similar examples being seen repeatedly. Similarly, with
    undersampling, we lose some information (that could have been useful for the model)
    because we discard the majority class examples to balance the training dataset.
    In this chapter, we’ll consider an alternative to the data-level techniques that
    we learned about previously.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了各种采样技术以及如何对数据进行过采样或欠采样。然而，这两种技术都有其独特的问题。例如，过采样可能会因为重复看到精确或非常相似的例子而导致模型过拟合。同样，在欠采样中，我们失去了一些信息（这些信息可能对模型有用），因为我们丢弃了大多数类别的例子来平衡训练数据集。在本章中，我们将考虑之前所学数据级技术的替代方案。
- en: Cost-sensitive learning is an effective strategy to tackle imbalanced data.
    We will go through this technique and learn why it can be useful. This will help
    us understand some of the details of cost functions and how machine learning models
    are not designed to deal with imbalanced datasets by default. While machine learning
    models aren’t equipped to handle imbalanced datasets, we will see how modern libraries
    enable this.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 成本敏感学习是一种有效的方法来处理不平衡数据。我们将介绍这项技术，并了解为什么它可能是有用的。这将帮助我们理解成本函数的一些细节以及机器学习模型默认不是设计来处理不平衡数据集的。虽然机器学习模型没有配备处理不平衡数据集的能力，但我们将看到现代库是如何实现这一点的。
- en: 'We will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: The concept of **cost-sensitive** **learning** (**CSL**)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本敏感** **学习**（CSL）的概念'
- en: Understanding costs in practice
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实践中的成本理解
- en: Cost-sensitive learning for logistic regression
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归的成本敏感学习
- en: Cost-sensitive learning for decision trees
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树的成本敏感学习
- en: Cost-sensitive learning using `scikit-learn` and XGBoost models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`scikit-learn`和XGBoost模型进行成本敏感学习
- en: MetaCost – making any classification model cost-sensitive
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MetaCost – 使任何分类模型具有成本敏感性
- en: Threshold adjustment
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阈值调整
- en: By the end of this chapter, you will understand what cost means in the context
    of classification problems, how to adjust model parameters to account for such
    costs, and how to prioritize minority class predictions to mitigate the cost of
    misclassification. We will also look at a generic meta-algorithm that can make
    any algorithm cost-sensitive and a post-processing technique for adjusting prediction
    thresholds.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将了解在分类问题中成本的含义，如何调整模型参数以考虑这些成本，以及如何优先考虑少数类别的预测以减轻误分类的成本。我们还将探讨一个通用的元算法，该算法可以使任何算法具有成本敏感性，以及一种后处理技术，用于调整预测阈值。
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Similar to prior chapters, we will continue to utilize common libraries such
    as `numpy`, `scikit-learn`, `xgboost`, and `imbalanced-learn`. The code and notebooks
    for this chapter are available on GitHub at [https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/main/chapter05](https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/main/chapter05).
    You can open this GitHub notebook using Google Colab by clicking on the **Open
    in Colab** icon at the top of this chapter’s notebook or by launching it from
    [https://colab.research.google.com](https://colab.research.google.com) using the
    GitHub URL of the notebook.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的章节类似，我们将继续使用常见的库，如`numpy`、`scikit-learn`、`xgboost`和`imbalanced-learn`。本章的代码和笔记本可在GitHub上找到，网址为[https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/main/chapter05](https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/main/chapter05)。您可以通过点击本章笔记本顶部的**在Colab中打开**图标或通过使用笔记本的GitHub
    URL在[https://colab.research.google.com](https://colab.research.google.com)启动它来打开这个GitHub笔记本。
- en: The concept of Cost-Sensitive Learning
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本敏感学习（CSL）的概念
- en: '**Cost-Sensitive Learning** (**CSL**) is a technique where the cost function
    of a machine learning model is changed to account for the imbalance in data. The
    key insight behind CSL is that we want our model’s cost function to reflect the
    relative importance of the different classes.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本敏感学习**（CSL）是一种技术，其中机器学习模型的成本函数被改变以考虑数据的不平衡。CSL背后的关键洞察是我们希望我们的模型成本函数反映不同类别的相对重要性。'
- en: Let’s try to understand cost functions in machine learning and various types
    of CSL.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试理解机器学习中的成本函数和各种类型的成本敏感学习（CSL）。
- en: Costs and cost functions
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本和成本函数
- en: 'A cost function estimates the difference between the actual outcome and the
    predicted outcome from a model. For example, the cost function of the logistic
    regression model is given by the log loss function:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 成本函数估计了实际结果与模型预测结果之间的差异。例如，逻辑回归模型的成本函数由对数损失函数给出：
- en: LogLoss = −  1 _ N * ∑ i=1  N  ( y i * log( ˆ y  i) + (1 − y i)* log(1 −  ˆ y  i))
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LogLoss = − 1 * N * ∑ i=1 N (y_i * log(ˆy_i) + (1 − y_i) * log(1 − ˆy_i))
- en: Here, N is the total number of observations, y i is the true label (0 or 1),
    and  ˆ y  i is the probability value (between 0 and 1) predicted from the model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，N 是观察的总数，y_i 是真实标签（0 或 1），ˆy_i 是从模型预测出的概率值（介于 0 和 1 之间）。
- en: One type of cost is called the cost of misclassification errors [1] – that is,
    the cost of predicting the majority class instead of the minority class or vice
    versa.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一种类型的成本被称为误分类错误成本 [1] - 即，预测多数类而不是少数类或反之的成本。
- en: 'In practice, there can be other types of costs that we may incur, such as the
    following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们可能会遇到其他类型的成本，例如以下这些：
- en: Cost of labeling the dataset
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记数据集的成本
- en: Cost of training or evaluating the model
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练或评估模型的成本
- en: Cost of training data collection
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据收集的成本
- en: 'Let’s consider the confusion matrix:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑混淆矩阵：
- en: '|  | **Predicted Negative** | **Predicted Positive** |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | **预测为负** | **预测为正** |'
- en: '| --- | --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Actual Negative** | True Negative | False Positive |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **实际为负** | 真阴性 | 假阳性 |'
- en: '| **Actual Positive** | False Negative | True Positive |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **实际为正** | 假阴性 | 真阳性 |'
- en: Table 5.1 – Confusion matrix for understanding the cost of classification errors
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.1 – 理解分类错误成本的混淆矩阵
- en: Psychological studies have suggested that loss hurts twice as much as gain.
    Similarly, in machine learning, the “cost” captures whenever the model makes a
    mistake (False Positive and False Negative) and does not worry about when it’s
    right (True Positive and True Negative). This cost is the cost of misclassification
    errors.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 心理学研究表明，损失带来的痛苦是收益的两倍。同样，在机器学习中，“成本”捕捉了模型出错（假阳性与假阴性）的时刻，而不关心它正确的时候（真阳性与真阴性）。这种成本是误分类错误的成本。
- en: Not all misclassifications are created equal. For instance, suppose we’re attempting
    to predict whether a patient has cancer. If our model incorrectly indicates that
    the patient has cancer (a false positive), this could lead to additional testing.
    However, if our model incorrectly suggests that the patient is cancer-free (a
    false negative), the consequences could be far more severe as the disease could
    progress undiagnosed. Therefore, a false negative is significantly more detrimental
    than a false positive. Our cost function should take this discrepancy into account.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有误分类都是相同的。例如，假设我们正在尝试预测患者是否患有癌症。如果我们的模型错误地指示患者患有癌症（假阳性），这可能导致额外的测试。然而，如果我们的模型错误地建议患者无病（假阴性），后果可能更为严重，因为疾病可能会未诊断而进展。因此，假阴性比假阳性更具破坏性。我们的成本函数应该考虑这种差异。
- en: Unfortunately, most models treat the majority and minority classes equally by
    default. However, modern ML frameworks such as `scikit-learn`, Keras/TensorFlow,
    and PyTorch provide a way to weigh the various classes differently across a variety
    of learning algorithms.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数模型默认将多数类和少数类同等对待。然而，现代机器学习框架如 `scikit-learn`、Keras/TensorFlow 和 PyTorch
    提供了一种方法，可以在各种学习算法中不同地权衡各种类。
- en: Types of cost-sensitive learning
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本敏感学习类型
- en: There are two major types of CSL approaches, namely weighting and meta-learning.
    In weighting approaches, we update the cost function of the machine learning model
    to reflect the importance of the different classes. In meta-learning, we can make
    the model cost-sensitive without changing its cost function.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 成本敏感学习（CSL）有两种主要方法，即加权法和元学习。在加权方法中，我们更新机器学习模型的成本函数，以反映不同类的重要性。在元学习中，我们可以使模型对成本敏感，而无需更改其成本函数。
- en: 'In MetaCost, a type of meta-learning technique, for example, we alter the labels
    of training instances to minimize expected misclassification costs. Similarly,
    in the threshold adjustment method, we determine a probability threshold that
    minimizes total misclassification costs for predictions. *Figure 5**.1* categorizes
    these methods at a high level [2][3]:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在元学习技术 MetaCost 中，例如，我们可以改变训练实例的标签，以最小化预期的误分类成本。同样，在阈值调整方法中，我们确定一个概率阈值，以最小化预测的总误分类成本。*图
    5.1* 从高层次上对这些方法进行了分类 [2][3]：
- en: '![](img/B17259_05_01.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_05_01.jpg)'
- en: Figure 5.1 – Categorization of cost-sensitive learning methods
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 成本敏感学习方法的分类
- en: Difference between CSL and resampling
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CSL与重采样的区别
- en: The key difference between previously discussed data-level techniques and CSL
    is that the data-level techniques adjust the frequency of the different error
    types, but they treat all misclassification errors the same. In certain cases,
    as we encountered earlier, the cost of misclassifying observations of different
    classes is not the same. For example, in cancer detection, the cost of misclassifying
    a patient who has cancer as healthy (False Negative) is much higher, as the patient
    is at high risk if not detected or treated early. Similarly, misclassifying a
    fraudulent booking as non-fraudulent can cost more money than wrongly classifying
    a legitimate transaction as fraud. Why? Because in the latter case, we can just
    call and verify with the user the legitimacy of the transaction. By applying resampling
    techniques such as upsampling or downsampling, we are implicitly changing the
    cost of different types of errors. So, CSL and resampling techniques can be considered
    to have an equivalent effect on the model at the end of the day.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前讨论的数据级别技术相比，CSL的关键区别在于数据级别技术调整不同错误类型的频率，但它们对待所有误分类错误都是一样的。在某些情况下，正如我们之前遇到的，不同类别的观测值被误分类的成本并不相同。例如，在癌症检测中，将患有癌症的患者误分类为健康（假阴性）的成本要高得多，因为如果未检测或未早期治疗，患者风险很高。同样，将欺诈预订误分类为非欺诈可能会比将合法交易误分类为欺诈的成本更高。为什么？因为在后一种情况下，我们只需联系用户并验证交易的合法性即可。通过应用重采样技术，如上采样或下采样，我们隐式地改变了不同类型错误的成本。因此，CSL和重采样技术最终可以对模型产生等效的影响。
- en: 'However, resampling techniques may be problematic in certain cases, as we will
    discuss in the next section. In such cases, CSL can be more practical:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，重采样技术可能存在问题，我们将在下一节讨论。在这种情况下，CSL可能更实用：
- en: '![](img/B17259_05_02.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_05_02.jpg)'
- en: Figure 5.2 – Comic re-emphasizing the idea of misclassification errors
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 漫画再次强调误分类错误的概念
- en: Problems with rebalancing techniques
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重平衡技术的缺陷
- en: 'In the previous chapters, we briefly touched on why in some cases, we would
    prefer not to apply any data sampling techniques. This could be because of the
    following reasons:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们简要地提到了为什么在某些情况下，我们可能更喜欢不应用任何数据采样技术。这可能是因为以下原因：
- en: We already have too much training data, and it might be quite expensive to deal
    with more data, or the training time can increase by many folds due to having
    more training data.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经拥有太多的训练数据，处理更多的数据可能相当昂贵，或者由于有更多的训练数据，训练时间可能增加数倍。
- en: Sometimes, we may not get the best results using sampling or data rebalancing
    techniques because of the dataset we are using.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时，由于我们使用的数据集，我们可能无法通过采样或数据重平衡技术获得最佳结果。
- en: An additional consideration is that upon rebalancing the dataset, our model’s
    predictive scores may become miscalibrated, necessitating a recalibration process.
    We will cover this topic in [*Chapter 10*](B17259_10.xhtml#_idTextAnchor279),
    *Model Calibration*, where we will learn about various model calibration techniques.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个需要考虑的因素是，在重新平衡数据集后，我们的模型的预测分数可能变得不准确，需要重新校准。我们将在[*第10章*](B17259_10.xhtml#_idTextAnchor279)“模型校准”中介绍这一主题，我们将学习各种模型校准技术。
- en: Rebalancing techniques can lead to model overfitting or underfitting issues.
    Overfitting can especially happen when using oversampling since they produce repeated
    or similar training examples. Similarly, the model may be underfitted when using
    undersampling because the model did not get trained on the data thrown away during
    undersampling.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重平衡技术可能导致模型过拟合或欠拟合问题。特别是当使用过采样时，它们会产生重复或相似的训练示例，这可能导致过拟合。同样，当使用欠采样时，模型可能欠拟合，因为模型没有在欠采样过程中丢弃的数据上进行训练。
- en: Next, let’s try to understand what costs really mean.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们尝试理解成本究竟意味着什么。
- en: Understanding costs in practice
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践中理解成本
- en: We need to understand the various types of costs involved while creating weights
    for different classes. These costs change on a case-by-case basis. Let’s discuss
    an example of cost calculations to understand what we should consider while thinking
    about cost calculations.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在为不同类别创建权重时，我们需要了解涉及的各种成本类型。这些成本根据具体情况而变化。让我们讨论一个成本计算的例子，以了解在考虑成本计算时应考虑什么。
- en: Let’s take the example of pediatric pneumonia. According to UNICEF, a child
    dies of pneumonia every 43 seconds [4]. Imagine we are creating a new test for
    pediatric pneumonia – how will we decide the cost of different errors?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以儿童肺炎为例。根据联合国儿童基金会，每43秒就有一个孩子死于肺炎[4]。想象一下，我们正在为儿童肺炎开发一个新的测试——我们将如何决定不同错误的成本？
- en: Let’s review the confusion matrix from *Table 5.1*. There will usually be no
    extra cost for True Negatives and True Positives. But using a False Negative –
    that is, when a child has pneumonia and predicting the child to be healthy – will
    have a very high cost. On the flip side, when a healthy child is predicted as
    being affected by pneumonia, there will be a cost associated with the troubles
    the family of the child may have to go through, but there will be much less cost
    than in the previous case. Furthermore, the cost of misclassification can vary
    depending on the child’s age. For example, younger kids will be at a higher risk
    than older kids. Thus, we will aim to penalize the model more if it makes an error
    in the case of younger kids.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下表5.1中的混淆矩阵。通常，对于真正的负例和真正的正例，不会有额外的成本。但是，使用错误的负例——也就是说，当一个孩子患有肺炎，却预测该孩子健康时——将会有非常高的成本。另一方面，当一个健康的儿童被预测为患有肺炎时，将会有与孩子家庭可能遇到的麻烦相关的成本，但这个成本比前一种情况要低得多。此外，误分类的成本可能因孩子的年龄而异。例如，年幼的孩子比年长的孩子风险更高。因此，如果模型在年幼孩子的案例中出错，我们将对模型进行更多的惩罚。
- en: 'The cost can vary depending on the duration of the symptoms. Consider it this
    way: if we make an error and misdiagnose a child who has only had flu symptoms
    for a day, it’s not ideal, but it’s not disastrous. However, if that child has
    been enduring flu symptoms for 2 weeks, that’s a different scenario. That mistake
    will cost us significantly more.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 成本可能因症状的持续时间而异。可以这样考虑：如果我们犯了一个错误，错误地诊断了一个只有一天流感症状的孩子，这并不理想，但也不是灾难性的。然而，如果那个孩子已经忍受了2周的流感症状，那将是一个不同的场景。这个错误将给我们带来更大的成本。
- en: 'While we’ve discussed real-world problems so far, this chapter will pivot to
    utilize a synthetic dataset. This approach is intended to reinforce concepts and
    methods in a controlled environment, thus enhancing the learning process:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们迄今为止讨论了现实世界的问题，但本章将转向使用合成数据集。这种方法旨在在受控环境中强化概念和方法，从而增强学习过程：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `make_classification` function produces some overlapping points that we
    cleaned up. To keep things simple, we’ve omitted that cleanup code here. You can
    refer to the full notebook on GitHub.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`make_classification`函数产生了一些重叠的点，我们清理了这些点。为了简化，我们在这里省略了清理代码。您可以在GitHub上的完整笔记本中查阅。'
- en: 'The preceding code produces the following output and scatter plot (*Figure
    5**.3*):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码产生了以下输出和散点图（*图5**.3*）：
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](img/B17259_05_03.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_05_03.jpg)'
- en: Figure 5.3 – Scatter plot showing the training dataset’s distribution
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 显示训练数据集分布的散点图
- en: We’ll dive into how to apply CSL to logistic regression models next.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入探讨如何将CSL应用于逻辑回归模型。
- en: Cost-Sensitive Learning for logistic regression
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归的成本敏感学习
- en: Logistic regression is a simple classification algorithm. We train a model as
    a linear combination of the features. Then, we pass the result of that linear
    combination into a sigmoid function to predict the class probabilities for different
    classes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种简单的分类算法。我们通过将特征进行线性组合来训练模型。然后，我们将线性组合的结果传递给sigmoid函数，以预测不同类别的类别概率。
- en: 'The `sigmoid` function (also called a `logit` function) is a mathematical tool
    capable of converting any real number into a value between 0 and 1\. This value
    can be interpreted as a probability estimate:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`sigmoid`函数（也称为`logit`函数）是一种可以将任何实数转换为0到1之间值的数学工具。这个值可以解释为概率估计：'
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The graph of the sigmoid function has an S-shaped curve, and it appears like
    this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid函数的图像呈S形曲线，看起来是这样的：
- en: '![](img/B17259_05_04.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_05_04.jpg)'
- en: Figure 5.4 – Sigmoid function
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – Sigmoid函数
- en: The class with the highest predicted probability is taken as the prediction
    for a given sample.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 具有最高预测概率的类别被用作给定样本的预测。
- en: 'Let’s say we have an email to be classified as spam or non-spam, and our logistic
    regression model outputs the probabilities of 0.25 for non-spam and 0.75 for spam.
    Here, the class with the highest predicted probability is “spam” (1) since 0.75
    is greater than 0.25\. Therefore, the model would predict that this email is spam
    (*Figure 5**.5*):'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个要分类为垃圾邮件或非垃圾邮件的电子邮件，并且我们的逻辑回归模型输出非垃圾邮件的概率为0.25，垃圾邮件的概率为0.75。在这里，具有最高预测概率的类别是“垃圾邮件”（1），因为0.75大于0.25。因此，模型会预测这封邮件是垃圾邮件（*图5**.5*）：
- en: '![](img/B17259_05_05.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_05_05.jpg)'
- en: Figure 5.5 – Higher class probability determining the class for binary classification
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 – 高类别概率决定二分类的类别
- en: For two-class classification, we just predict the probability of one class.
    The probability of the other class is one minus the probability of the first class.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类，我们只预测一个类别的概率。另一个类别的概率是第一个类别的概率减去1。
- en: 'The logistic regression model is trained using a loss function. The loss function
    for one example from a dataset with two classes would look like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对数逻辑回归模型使用损失函数进行训练。来自具有两个类别的数据集的一个示例的损失函数看起来像这样：
- en: cost = − y * log(classProbability) − (1 − y)* log(1 − classProbability)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: cost = − y * log(classProbability) − (1 − y)* log(1 − classProbability)
- en: 'For true positives and true negatives, this loss will be very low. For a false
    positive, y, the actual value would be 0; therefore, the first term will be 0,
    but the second term will be very high as the class probability approaches 1, and
    the term will approach negative infinity (since, log(0) → − ∞). Since there is
    a negative sign at the front, the cost will approach positive infinity. A similar
    analysis can be done for the false negative case. One part of the cost can be
    seen as the false positive part, and another part of the cost can be seen as the
    false negative part:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于真正的阳性和真正的阴性，这个损失将非常低。对于误报，y，实际值将是0；因此，第一个项将是0，但第二个项将非常高，因为类别概率接近1，这个项将接近负无穷大（因为，log(0)
    → − ∞）。由于前面有一个负号，成本将接近正无穷大。对误检情况可以进行类似的分析。成本的一部分可以看作是误报部分，另一部分可以看作是误检部分：
- en: cost = falsePositiveCost + falseNegativeCost
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: cost = falsePositiveCost + falseNegativeCost
- en: 'As discussed earlier, we don’t want to weigh the two types of costs equally.
    So, all we do is add weights, W FP and W FN, for the respective costs:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们不希望两种类型的成本同等重要。所以我们只是为各自的成本添加权重，W FP和W FN：
- en: cost = W FP * falsePositiveCost + W FN * falseNegativeCost
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: cost = W FP * falsePositiveCost + W FN * falseNegativeCost
- en: 'This is the crux of CSL with logistic regression. To get the overall costs
    of the model, we take the average cost across all the data points:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对数逻辑回归中CSL的核心。为了得到模型的总体成本，我们取所有数据点的平均成本：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When all errors are equally costly, the model’s decision boundary and the model’s
    **Precision-Recall** (**PR**) curve will look like this:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有错误成本相等时，模型的决策边界和模型的**精度-召回率**（**PR**）曲线将看起来像这样：
- en: '![](img/B17259_05_06.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_05_06.jpg)'
- en: Figure 5.6 – The decision boundary (left) and PR curve (right) of the baseline
    regression model
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 – 基线回归模型的决策边界（左）和PR曲线（右）
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The previous code outputs the following F2 score, precision, and recall values:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码输出了以下F2分数、精度和召回值：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this chapter, we will use the F2 score as our primary metric. What is the
    F2 score? In [*Chapter 1*](B17259_01.xhtml#_idTextAnchor015), *Introduction to
    Data Imbalance in Machine Learning*, we studied the F-beta score. The F2 score
    is the F-beta score with beta=2, while the F1 score is the F-beta score with beta=1\.
    It’s useful when recall is more important than precision – that is, false negatives
    are more costly (important) than false positives:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用F2分数作为我们的主要指标。F2分数是什么？在[*第1章*](B17259_01.xhtml#_idTextAnchor015)，*机器学习中数据不平衡的介绍*，我们学习了F-beta分数。F2分数是beta=2的F-beta分数，而F1分数是beta=1的F-beta分数。当召回率比精度更重要时，它很有用——也就是说，误报比误检（重要）的成本更高：
- en: F β =  (1 + β 2) × (precision × recall)  ____________________  (β 2 × precision)
    + recall  =  (5 × precision × recall)  ________________  (4 × precision) + recall
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: F β =  (1 + β 2) × (precision × recall)  ____________________  (β 2 × precision)
    + recall  =  (5 × precision × recall)  ________________  (4 × precision) + recall
- en: '`LogisticRegression` from the `scikit-learn` library provides a `class_weight`
    parameter. When the value of this parameter is set to “balanced,” the weight of
    each class is automatically computed by the following formula:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`LogisticRegression`来自`scikit-learn`库提供了一个`class_weight`参数。当此参数的值设置为“balanced”时，每个类别的权重将自动通过以下公式计算：'
- en: weightOfClass =  totalNumberOfSamples   ________________________________   numberOfClasses
    * numberOfSamplesPerClass
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: weightOfClass =  totalNumberOfSamples   ________________________________   numberOfClasses
    * numberOfSamplesPerClass
- en: 'For example, we have 100 examples in the dataset – 80 in class 0 and 20 in
    class 1\. The weights of each class are computed as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在数据集中我们有100个示例 – 80个属于类别0，20个属于类别1。每个类别的权重计算如下：
- en: Weight for class 0 = 100/(2*80) = 0.625
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别0的权重 = 100/(2*80) = 0.625
- en: Weight for class 1 = 100/(2*20) = 2.5
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别1的权重 = 100/(2*20) = 2.5
- en: Given that the number of class 0 examples is four times that of class 1, the
    weight of class 1 is 2.5, which is four times the weight of class 0 – that is,
    0.625\. This makes sense since we would want to give more weight to class 1, which
    is smaller in number.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于类别0的示例数量是类别1的四倍，类别1的权重是2.5，是类别0权重的四倍，即0.625。这很有道理，因为我们希望给类别1更多的权重，因为它的数量较少。
- en: 'We can mention `class_weight` as a dictionary as well:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将`class_weight`作为一个字典来提及：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s try to use the `class_weight` parameter in the `LogisticRegression` function:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试在`LogisticRegression`函数中使用`class_weight`参数：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](img/B17259_05_07.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_05_07.jpg)'
- en: Figure 5.7 – The decision boundary (left) and PR curve (right) of the “balanced”
    class-weighted logistic regression model
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 – “平衡”类别加权逻辑回归模型的决策边界（左）和PR曲线（右）
- en: 'Let’s calculate the F2 score, precision, and recall scores:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算F2分数、精确率和召回率分数：
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The scores of the “balanced” class-weighted logistic regression model are as
    follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: “平衡”类别加权逻辑回归模型的分数如下：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Upon analyzing the results, we can see a decision boundary that correctly classifies
    most of the positive class examples. The precision comes down while the recall
    goes up. The decline in the F2 score can be attributed to changes in the recall
    and precision values. The model exhibits an improvement in recall, indicating
    its enhanced ability to correctly identify all positive class examples. However,
    this advancement results in a simultaneous drop in precision, suggesting an increased
    rate of mistakes made on the negative class examples (which we don’t really care
    about as much!).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析结果后，我们可以看到一个决策边界，它正确地分类了大多数正类示例。精确率下降，而召回率上升。F2分数的下降可以归因于召回率和精确率值的变化。模型在召回率方面有所提高，表明其识别所有正类示例的能力得到了增强。然而，这种进步导致精确率同时下降，这表明在负类示例（我们并不特别关心）上犯错的速率增加。
- en: 'Let’s try to tune the `class_weight` parameter using a grid search that optimizes
    our F2 score. We can always try to optimize any other objective, such as average
    precision, precision, or recall, and so on. The `np.linspace(0.05, 0.95, 20)`
    function is a `numpy` function that generates an array of 20 evenly spaced numbers
    between 0.05 and 0.95:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用网格搜索调整`class_weight`参数，以优化我们的F2分数。我们始终可以尝试优化任何其他目标，例如平均精确率、精确率或召回率等。`np.linspace(0.05,
    0.95, 20)`函数是一个`numpy`函数，它生成一个介于0.05和0.95之间的20个均匀分布的数字数组：
- en: '[PRE10]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This produces the following output:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下输出：
- en: '[PRE11]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Our standard metrics are as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的标准指标如下：
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After incorporating these class weights, our decision boundary attempts to
    strike a better balance between misclassifying positive and negative class examples,
    as illustrated in *Figure 5**.8*. This results in a superior F2 score of 0.93,
    increasing the precision value while maintaining a modest recall:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在引入这些类别权重后，我们的决策边界试图在错误分类正类和负类示例之间取得更好的平衡，如图*图5**.8*所示。这导致F2分数达到0.93，提高了精确率值，同时保持适度的召回率：
- en: '![](img/B17259_05_08.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_05_08.jpg)'
- en: Figure 5.8 – The decision boundary (left) and PR curve (right) of the class-weighted
    logistic regression model
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – 类别加权逻辑回归模型的决策边界（左）和PR曲线（右）
- en: 🚀 Cost-sensitive learning in production at Microsoft
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 🚀 微软在生产中的成本敏感学习
- en: In a practical application at Microsoft, the primary objective was to improve
    the **Click-Through Rate** (**CTR**) prediction for Bing ads [5]. Achieving accurate
    CTR prediction is vital for optimizing both user experience and revenue streams.
    A marginal improvement of just 0.1% in prediction accuracy has the potential to
    elevate profits by hundreds of millions of dollars. Through rigorous testing,
    an ensemble model that combines **Neural Networks** (**NNs**) and **Gradient-Boosted
    Decision Trees** (**GBDTs**) emerged as the most effective solution.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在微软的一个实际应用中，主要目标是提高Bing广告的**点击率**（**CTR**）预测[5]。实现准确的CTR预测对于优化用户体验和收入流至关重要。预测准确率仅提高0.1%，就有可能使利润增加数亿美元。通过严格的测试，一个结合**神经网络**（**NNs**）和**梯度提升决策树**（**GBDTs**）的集成模型成为最有效的解决方案。
- en: For the training dataset, 56 million samples were randomly chosen from a month’s
    log data, each containing hundreds of statistical features. To reduce training
    expenses, non-click cases were **downsampled** by 50% and assigned a **class weight**
    of 2 to maintain the original distribution. Model performance was then assessed
    using a test dataset of 40 million samples randomly drawn from the subsequent
    week’s logs. Instead of recalibrating the model, class weighting was used to maintain
    the average CTR after downsampling.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练数据集，从一个月的日志数据中随机选择了5600万个样本，每个样本包含数百个统计特征。为了减少训练成本，非点击案例被**降采样**了50%，并分配了2的**类别权重**以保持原始分布。然后使用从随后一周日志中随机抽取的4000万个样本的测试数据集评估模型性能。而不是重新校准模型，使用了类别权重来在降采样后保持平均CTR。
- en: In the next section, we will discuss how to do CSL with decision trees.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何使用决策树进行代价敏感学习。
- en: Cost-Sensitive Learning for decision trees
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树的代价敏感学习
- en: Decision trees are binary trees that use conditional decision-making to predict
    the class of the samples. Every tree node represents a set of samples corresponding
    to a chain of conditional statements based on the features. We divide the node
    into two children based on a feature and a threshold value. Imagine a set of students
    with height, weight, age, class, and location. We can divide the set into two
    parts according to the features of age and with a threshold of 8\. Now, all the
    students with ages less than 8 will go into the left child, and all those with
    ages greater than or equal to 8 will go into the right child.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是使用条件决策来预测样本类别的二叉树。每个树节点代表一组与基于特征的连续条件语句相对应的样本。我们根据特征和阈值值将节点分为两个子节点。想象一下有一组学生，他们的身高、体重、年龄、班级和位置。我们可以根据年龄特征和8的阈值将这个集合分为两部分。现在，所有年龄小于8岁的学生将进入左子节点，而所有年龄大于或等于8岁的学生将进入右子节点。
- en: This way, we can create a tree by successively choosing features and threshold
    values. Every leaf node of the tree will contain nodes from only one class, respectively.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以通过连续选择特征和阈值值来创建树。树的每个叶节点将只包含来自一个类别的节点。
- en: 'A question often arises during the construction of a decision tree: “Which
    feature and threshold pair should be selected to partition the set of samples
    at a given node?” The answer is straightforward: we opt for the pair that produces
    the most uniform (or homogeneous) subsets of data. Ideally, the two resulting
    subsets – referred to as the left and right children – should each contain elements
    predominantly from a single class.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建决策树的过程中，经常会遇到一个问题：“应该选择哪个特征和阈值对来分割给定节点的样本集？”答案很简单：我们选择产生最均匀（或同质）数据子集的对。理想情况下，产生的两个结果子集——被称为左右子节点——应该各自主要包含来自单个类别的元素。
- en: 'The degree to which the nodes have a mixture of samples from different classes
    is known as the **impurity** of the node, which can be considered to be a measure
    of loss for decision trees. The more the impurity, the more heterogeneous the
    set of samples. Here are the two most common ways of calculating the impurity:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 节点从不同类别中混合样本的程度被称为节点的**不纯度**，这可以被视为决策树的损失度量。不纯度越高，样本集的异质性就越大。以下是计算不纯度的两种最常见方法：
- en: Gini coefficient
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gini系数
- en: Entropy
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Entropy
- en: 'Let’s look at the formula for the Gini coefficient and entropy for two classes,
    c 1 and c 2:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Gini系数和熵的两个类c1和c2的公式：
- en: Gini = 1− Proportion c1 2− Proportion c2 2
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Gini = 1− Proportion c1 2− Proportion c2 2
- en: 'We will get the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下结果：
- en: Entropy = − Proportion c1 * log (Proportion c1)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Entropy = − Proportion c1 * log (Proportion c1)
- en: − Proportion c2 * log (Proportion c2)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: − 比例c2 * log (比例c2)
- en: 'To do CSL with decision trees, we just multiply the class weights with the
    terms for each of the classes in the calculation of the Gini and entropy. If the
    weights for the two classes are W 1and W 2, Gini and entropy will look as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用决策树进行CSL，我们只需将类权重与Gini和熵计算中每个类的项相乘。如果两个类的权重是W1和W2，Gini和熵将如下所示：
- en: Gini = 1 − W 1 * Proportion c1 2 − W 2 * Proportion c2 2
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Gini = 1 − W1 * 比例c1^2 − W2 * 比例c2^2
- en: Entropy = − W 1 * Proportion c1 * log(Proportion c1)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Entropy = − W1 * 比例c1 * log(比例c1)
- en: − W 2 * Proportion c2 * log(Proportion c2)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: − W2 * 比例c2 * log(比例c2)
- en: Now, the model prioritizes the class with a higher weight over the class with
    a lower weight. If we give more weight to the minority class, the model will make
    the decision that will prioritize nodes with homogeneous minority class samples.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，模型优先考虑权重较高的类，而不是权重较低的类。如果我们给少数类更多的权重，模型将做出优先考虑具有同质少数类样本的节点的决策。
- en: In this section, we got some idea of how class weights can be accommodated into
    the loss function of decision trees to account for the misclassification error.
    In the next section, we will see how `scikit-learn` simplifies this process by
    integrating it into the model creation API, eliminating the need for us to manually
    adjust the loss function.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了一些如何将类权重纳入决策树的损失函数中，以考虑误分类错误。在下一节中，我们将看到`scikit-learn`如何通过将其集成到模型创建API中来简化此过程，从而消除我们手动调整损失函数的需要。
- en: Cost-Sensitive Learning using scikit-learn and XGBoost models
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用scikit-learn和XGBoost模型进行成本敏感学习
- en: '`scikit-learn` provides a `class_weight` hyperparameter to adjust the weights
    of various classes for most models. This parameter can be specified in various
    ways for different learning algorithms in `scikit-learn`. However, the main idea
    is that this parameter specifies the weights to use for each class in the loss
    calculation formula. For example, this parameter specifies the values of weight FP
    and weight FN mentioned previously for logistic regression.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`提供了一个`class_weight`超参数来调整大多数模型中各种类的权重。这个参数可以根据`scikit-learn`中不同学习算法的不同方式指定。然而，主要思想是这个参数指定了损失计算公式中每个类的权重。例如，这个参数指定了之前提到的逻辑回归中的权重FP和权重FN的值。'
- en: 'Similar to the `LogisticRegression` function, for `DecisionTreeClassifier`,
    we could use `DecisionTreeClassifier(class_weight=''balanced'')` or `DecisionTreeClassifier(class_weight={0:
    0.5,` `1: 0.5})`.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '与`LogisticRegression`函数类似，对于`DecisionTreeClassifier`，我们可以使用`DecisionTreeClassifier(class_weight=''balanced'')`或`DecisionTreeClassifier(class_weight={0:
    0.5, 1: 0.5})`。'
- en: 'Regarding SVM, it can even be extended to multi-class classification by specifying
    a weight value for each class label:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 关于SVM，它甚至可以通过为每个类标签指定一个权重值来扩展到多类分类：
- en: '[PRE13]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The general guidance about coming up with the `class_weight` values is to use
    the inverse of the ratio of the majority class to the minority class. We can find
    even more optimal `class_weight` values by performing hyperparameter tuning using
    the GridSearch algorithm (use the `GridSearchCV` function from `scikit-learn`).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 关于确定`class_weight`值的通用指导原则是使用多数类与少数类比例的倒数。我们可以通过使用网格搜索算法（使用`scikit-learn`中的`GridSearchCV`函数）进行超参数调整来找到更优的`class_weight`值。
- en: 'Similarly, XGBoost has the `scale_pos_weight` parameter to control the balance
    of positive and negative weights:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，XGBoost也有`scale_pos_weight`参数来控制正负权重的平衡：
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The default value of `scale_pos_weight` is 1\. A recommended `scale_pos_weight`
    value is `sum(negative_instances)/sum(positive_instances)`, which can be computed
    as `float(np.sum(label == 0)) /` `np.sum(label==1)`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`scale_pos_weight`的默认值是1。一个推荐的`scale_pos_weight`值是`sum(negative_instances)/sum(positive_instances)`，这可以计算为`float(np.sum(label
    == 0)) / np.sum(label==1)`。'
- en: XGBoost has a few other parameters, such as `max_delta_step` and `min_child_weight`,
    that can be tuned for imbalanced datasets. During the optimization process, `max_delta_step`
    determines the step size of updates, affecting learning speed and stability. `min_child_weight`
    controls overfitting and enhances generalization by influencing the size of leaf
    nodes in the decision tree. When dealing with imbalanced data scenarios, adjusting
    these parameters can strategically improve algorithm performance.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s use `DecisionTreeClassifier` to solve our classification problem:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output decision boundary is more complex than that of logistic regression
    (*Figure 5**.9*), separating the two classes better and giving an F2 score of
    0.932:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_09.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – The decision boundary (left) and PR curve (right) of the decision
    tree classifier model
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'We have reproduced the decision boundary and PR curve of the logistic regression
    model for comparison in *Figure 5**.10*:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_10.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – The decision boundary (left) and PR curve (right) of logistic
    regression (for comparison)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'Our standard metrics for the decision tree classifier are as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, let’s use the `class_weight=''balanced''` parameter:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After utilizing the code from before to plot the decision boundary, the PR
    curve, and compute the scores, the outputs are as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_11.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – The decision boundary (left) and PR curve (right) of the decision
    tree classifier model
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The tuned weights improve the F2 score and recall values.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'Popular frameworks such as `scikit-learn` also let us specify `sample_weight`
    as a list of weights for each observation in the dataset. The `sample_weight`
    and `class_weight` parameters can be quite confusing, and their purpose may not
    be very clear from their documentation on when to use what. The following table
    clarifies the difference between the two:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '|  | `sample_weight` | `class_weight` |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
- en: '| **Purpose** | Used to specify weights for individual examples.Can be useful
    when some examples are more important than others, regardless of their class.When
    some data is more trustworthy (say labeled using in-house human labelers), it
    can receive a higher weight.Can be useful when you don’t have equal confidence
    in the samples in your batch. | Used to correct class imbalance.Should be used
    when the importance of examples depends on their class. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
- en: '| **Usage** | Can be used in training as well as testing.Especially useful
    when comparing multiple models on different test sets with metrics such as AUC,
    where it’s often desirable to balance the test set:`sklearn.metrics.confusion_matrix(…,
    sample_weight)``sklearn.linear_model``.``LogisticRegression()``.``score(…,sample_weight)`
    | Mainly used during training to guide the training.Accounts for misclassification
    errors because certain classes are more important than others:`sklearn.linear_model``.``LogisticRegression(``class_weight)`
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
- en: '| **Effect of setting the value to 0 during** **model training** | Model will
    not take into account the examples for which `samples_weight=0` (irrespective
    of the example’s class). | The model will not consider any example belonging to
    the class for which `class_weight = 0`. Also, the model will never predict that
    class. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
- en: '| **Use** **case example** | When predicting customer churn, if losing certain
    customers would have a larger impact on business because they tend to purchase
    more often or spend more, we would want to give these customers a higher weight
    using `sample_weight`. | If we have a dataset where one class significantly outnumbers
    the other(s), using `class_weight` can help the model pay more attention to the
    underrepresented class(es). |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
- en: Table 5.2 – sample_weight versus class_weight in the scikit-learn library
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: If we use `sample_weight` along with `class_weight`, both will be multiplied,
    and we will see the effect of both parameters. The two can still be used together
    to balance class importance and individual instance importance with their intended
    purposes.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `numpy` makes it easier to create the list of weight values that are
    required by `sample_weight`: `sample_weight = np.where(label==1, 80, 20)`. However,
    `scikit-learn` has a function called `sklearn.utils.class_weight.compute_sample_weight()`
    that can be used to estimate the value of `sample_weight` automatically from `class_weight`.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '`class_weight` can also be a dict of values for each label or balanced. If
    we set it to balanced, class weights are determined by `n_samples/(n_classes *`
    `np.bincount(y))`.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'The returned value from `class_weight` is a dictionary: `{class_label: weight}`
    for each `class_label` value.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, you can use `sklearn.utils.class_weight.compute_sample_weight` if
    you have to do multi-label classification.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 🚀 Cost-sensitive learning in production at Airbnb
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: In a real-world application at Airbnb [6], the main problem to solve was improving
    the search and discoverability as well as personalization of their Experiences
    (handcrafted activities) platform. As the number of experiences grew, it became
    crucial to effectively rank these experiences to match user preferences and improve
    bookings.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Airbnb aimed to improve its search ranking to provide users with the most relevant
    and high-quality experiences. To promote the quality of their ranking model, they
    used sample weights (discussed in the previous section) in their objective function.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: The data imbalance in terms of quality tiers was addressed by using sample weighting
    (discussed in the previous section) in the training data. High-quality experiences
    were given higher weights, and low-quality experiences were given lower weights
    in the objective function. This was done to promote high-quality experiences in
    the search rankings, and they successfully improved the ranking of high-quality
    experiences and reduced low-quality ones without affecting overall bookings, as
    confirmed by A/B tests.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Airbnb iteratively developed and tested its machine learning model, eventually
    integrating it into its production system to rank “Experiences” in real time.
    They went through multiple stages, from building a strong baseline to personalization
    and online scoring to handle various business rules.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn about a technique that can convert any model
    into its cost-sensitive version without us knowing about its loss function or
    the inner workings of the model.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: MetaCost – making any classification model cost-sensitive
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MetaCost was first introduced in a paper by Pedro Domingos [7] in 1999\. MetaCost
    acts as a wrapper around machine learning algorithms that converts the underlying
    algorithm into a cost-sensitive version of itself. It treats the underlying algorithm
    as a black box and works best with unstable algorithms (defined below). When MetaCost
    was first proposed, CSL was in its early stages. Only a few algorithms, such as
    decision trees, had been converted into their cost-sensitive versions. For some
    models, creating a cost-sensitive version turned out to be easy while for others
    it was a non-trivial task. For algorithms where defining cost-sensitive versions
    of the model turned out to be difficult, people mostly relied upon data sampling
    techniques such as oversampling or undersampling. This was when Domingos came
    up with an approach for converting a large range of algorithms into their cost-sensitive
    versions. MetaCost can work for multi-class classification and with all types
    of cost matrices.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Unstable algorithms
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: An algorithm is called unstable [8] if a slight change in its initial conditions
    (for example, training data or initial weights) can create a big change in the
    model. Assume you are given a dataset of 1,000 items. A stable model such as a
    **K-Nearest Neighbor** (**KNN**) will not change much if you remove one item from
    the dataset. However, a model such as a decision tree might get completely restructured
    if you train it on 999 items instead of 1,000 items.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s delve into the mechanics of the MetaCost algorithm, as illustrated in
    *Figure 5**.12*:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_12.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – The MetaCost algorithm
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'MetaCost works by combining the concept of bagging with a misclassification
    cost matrix:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: First, we create multiple bootstrap samples of the original data.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We train one new copy of the given model for each bootstrap sample. So far,
    the process is the same as bagging. You can see the first two steps in *Figure
    5**.12* on the left-hand side. First, we create bootstrap samples S1, S2, and
    S3 from the original data. Then, we train models L1, L2, and L3 on the samples
    (S1, S2, and S3), respectively.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we send the original data, S, into the ensemble of L1, L2, and L3.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We multiply the misclassification costs obtained from the cost matrix with the
    class probabilities predicted by the ensemble to get the actual cost. This is
    shown on the right-hand side of *Figure 5**.12*.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we relabel the data so that the new class labels minimize the actual cost.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we train a new copy of the model on the relabeled data. This copy of
    the model is used as the final model.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can see the process of relabeling data using MetaCost in *Figure 5**.13*:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_13.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Process of relabeling data using MetaCost
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: On the left of *Figure 5**.13*, we have the original data. Stars are the minority
    class examples and squares are the majority class examples. Here, all the samples
    inside the oval are predicted as stars, and all the samples outside it are predicted
    as squares. The oval on the left is drawn by assuming the same misclassification
    cost for all errors. In the center, we create a new class boundary based on the
    actual misclassification cost drawn as an elongated oval. Notice that all the
    stars are now classified correctly. Also, notice that some squares are now misclassified
    as stars. This is expected as the misclassification cost for the stars is much
    higher than that of squares. At this point, MetaCost relabels these misclassified
    squares as stars. Finally, MetaCost trains a model on the relabeled data. Because
    the majority class examples that are easily mistaken for the minority class have
    been relabeled as belonging to the minority class, the final model is less likely
    to mislabel instances of the minority class.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: To save space, we have omitted the implementation of the MetaCost algorithm.
    You can find it in the GitHub repository for this chapter.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'We will apply the algorithm to the logistic regression model. MetaCost uses
    a cost matrix, which is a hyperparameter. The values in the cost matrix correspond
    to the weight or cost of items in the confusion matrix (the transpose of the confusion
    matrix from *Table 5.1*):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: C = (TN FN FP TP )
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say we use a cost matrix with equal costs for false positives and false
    negatives (that is, an identity matrix):'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*Figure 5**.14* shows the decision boundary and metrics, which are very close
    to the ones from the logistic regression classifier (*Figure 5**.10*):'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_14.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – The decision boundary (left) and PR curve (right) of the MetaCost
    variant of the logistic regression model with an identity cost matrix
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'We can estimate the cost matrix based on the imbalance ratio of the training
    data:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*Figure 5**.15* shows the output decision function and PR curve:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_15.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – The decision boundary (left) and PR curve (right) of the MetaCost
    variant of the logistic regression model with a more optimal cost matrix
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Although the F2 score dropped compared to the baseline, the recall did improve
    drastically.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: The various steps in the MetaCost algorithm, such as relabeling the whole training
    set, can be quite an expensive operation, and that might deter us from using this
    technique when our training dataset is large.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Cost-sensitive ensemble techniques
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: AdaCost [9], AdaUBoost [10], and AsymBoost [11] are cost-sensitive modifications
    of the AdaBoost model. AdaCost minimizes misclassification costs during iterative
    training. AdaUBoost handles imbalanced datasets by emphasizing the minority class.
    AsymBoost focuses on reducing the costliest misclassifications. They all adjust
    weights while considering misclassification costs.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: The underlying principle behind these algorithms is that besides allocating
    high initial weights to instances where the cost of misclassification is large,
    the rule for updating weights should also consider costs. This means that the
    weights of expensive misclassifications should be increased while the weights
    of correct classifications should be reduced.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn about another cost-sensitive meta-learning
    technique, called threshold adjustment.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Threshold adjustment
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The decision threshold is a very important concept to keep track of. By default,
    we have the following:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Prediction probability >= 0.5 implies Class 1
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prediction probability < 0.5 implies Class 0
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the threshold is a powerful meta-parameter that we are free to adjust.
    *Table 5.3* shows predictions from a model versus the true labels.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the default threshold of 0.5, the accuracy is 2/4 = 50%. If, on the
    other hand, the threshold chosen is 0.80, the accuracy is 100%. This shows how
    important the chosen threshold can be:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '| **Predicted Output** | **True Output** |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
- en: '| 0.65 | 0 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
- en: '| 0.75 | 0 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
- en: '| 0.85 | 1 |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
- en: '| 0.95 | 1 |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
- en: Table 5.3 – A table showing the predicted output from a model versus the true
    output (labels)
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Most of the metrics, such as accuracy, precision, recall, and F1 score, are
    all threshold-dependent metrics.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, metrics such as the ROC curve and the PR curve are threshold-independent,
    which means that these plots evaluate the performance of a model at all possible
    thresholds rather than a single, fixed threshold.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with machine learning metrics such as F1 or accuracy, it’s important
    to understand the role of the threshold value. These metrics, by default, utilize
    a threshold of 0.5\. Therefore, a misconception arises, particularly among novice
    and intermediate machine learning practitioners, that these metrics are inevitably
    linked to this particular threshold.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: However, this can lead to an inaccurate interpretation of the model’s performance,
    particularly in scenarios involving imbalanced datasets. The selection of the
    metric and the decision threshold are separate choices and should be treated as
    such. Establishing an appropriate threshold is a crucial step in the process,
    which should be considered independently of the chosen metric.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, relying solely on the default threshold of 0.5 can be misleading.
    The threshold should be set based on the specific requirements of the project
    and the nature of the data. Therefore, it’s integral that machine learning practitioners
    understand the interplay between the threshold and the selected metric to accurately
    assess the performance of their models.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: In binary classification, altering the threshold will easily change the threshold-dependent
    metrics such as accuracy, F1 score, TPR, or FPR. Many pieces of research [12][13]
    have mentioned the value of threshold adjustment, especially in the case when
    training data is imbalanced. A paper by Provost [14] states that using models
    without adjusting the output thresholds may be a critical mistake. Among deep
    learning domains, Buda et al. [15] show that using **random oversampling** (**ROS**)
    along with thresholding outperforms plain ROS on imbalanced datasets created from
    CIFAR and MNIST. Regardless of whether the data is imbalanced or not, choosing
    an optimal threshold can make a lot of difference in the performance of the model.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Many times, we would want to find the threshold that optimizes our threshold-dependent
    metric, say F1 score. Here, find the threshold at which the F1 score is the maximum
    (*Figure 5**.16*):'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_16.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
- en: Figure 5.16 – A PR curve with the best threshold that finds the max F1 score
    (see the notebook in this chapter’s GitHub repository)
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5**.17* presents a plot that illustrates the impact of modifying the
    decision threshold on various classification metrics for an imbalanced dataset:
    **True Positive Rate** (**TPR** or recall), **True Negative Rate** (**TNR**),
    **False Positive Rate** (**FPR**), and precision. The model that was used was
    logistic regression without any class weighting or sensitivity to the minority
    class. For the full notebook, please refer to the GitHub repository for this chapter:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_17.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
- en: Figure 5.17 – A plot of the different classification metrics (TPR, TNR, FPR,
    precision, F1 score, and accuracy) as a function of the decision threshold
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some observations about these plots:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision**: If the threshold is increased, precision (  TP _________________  Total
    number of positive predictions ) typically goes up as well. Why? Because as the
    threshold is increased, the total number of positive predictions would come down,
    and hence, as the denominator decreases, precision increases. Similarly, the opposite
    is true as well: if the threshold goes down, the precision goes down too.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recall**: Let’s see the impact of threshold change on recall. The recall
    is defined as  TP ____________  Total number of positives and the denominator
    is a constant value. As the threshold is lowered, TP may increase and would typically
    increase the recall.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True Negative Rate** (**TNR**): TNR measures the proportion of actual negatives
    that are correctly identified as such. In imbalanced datasets, where the negative
    class is the majority, a naive or poorly performing classifier might have a high
    TNR simply because it predicts the majority class for all or most instances. In
    such cases, the TNR could be misleadingly high.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positive Rate** (**FPR**): This is the rate at which negative instances
    are incorrectly classified as positive. In imbalanced datasets, a naive classifier
    that predicts everything as the majority (negative) class would have an FPR close
    to 0.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, we have a trade-off between TPR and TNR that must be taken into account
    while selecting an optimal decision threshold, as shown in the plot in *Figure
    5**.17*.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 🚀 Cost-sensitive learning in production at Shopify
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: In a real-world application at Shopify [16], the platform faced the challenge
    of categorizing products for millions of merchants selling a diverse array of
    items. Accurate product categorization was vital for functionalities such as enhanced
    search and discovery, as well as providing personalized marketing insights to
    merchants. Given the immense volume and variety of products, manual categorization
    was not feasible. Machine learning techniques were employed to automate the categorization
    process, adapting to the ever-expanding and diversifying product range. The dataset
    that was utilized was highly imbalanced, particularly due to the hierarchical
    structure of the **Google Product Taxonomy** (**GPT**) that Shopify employs. With
    over 5,500 categories, the GPT added complexity to an already challenging problem.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: To address the issue of data imbalance, class weights were implemented. By assigning
    the class weights, the model could impose higher penalties for incorrect predictions
    in underrepresented classes, effectively mitigating the lack of data in those
    categories. The model was fine-tuned to strike a balance between hierarchical
    precision and recall. This fine-tuning was informed by specific business use cases
    and aimed at enhancing the merchant experience by minimizing negative interactions
    and friction. Manual adjustments were made to the confidence thresholds (this
    shows that threshold tuning is so relevant in the real world!) to ensure optimal
    performance in sensitive categories such as “Religious and Ceremonial.” Various
    metrics such as hierarchical accuracy, precision, recall, and F1 score were balanced
    to tailor the model to business requirements. The model is now actively used by
    multiple internal teams and partner ecosystems to develop derivative data products.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at various ways of tuning these thresholds.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Methods for threshold tuning
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most of the time, we aim to optimize specific business metrics or standard
    machine learning metrics, requiring us to select a threshold that maximizes the
    metric of interest. In literature, various methods for threshold tuning are discussed,
    such as setting a threshold equal to the priority probability of observing a positive
    example, using the ROC curve to optimize for high TPR and low FPR, or employing
    the PR curve to maximize the F1 score or Fbeta score (see *Figure 5**.18*):'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_18.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
- en: Figure 5.18 – Popular ways of tuning the threshold
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss these methods one by one.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue to use the same dataset we created earlier. The following
    code block fits a logistic regression model and obtains predicted probabilities
    for the test set:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Threshold tuning using the prior threshold
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An obvious threshold that can be used is equal to the probability of the positive
    class in the training dataset [10]. Let’s implement this idea:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This prints the following threshold:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Threshold tuning using the ROC curve
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the ROC curve, Youden’s J statistic [17] can be used to find the optimal
    threshold. Youden’s J statistic has roots in the clinical field and is a single
    statistic that captures the performance of a diagnostic test. In the context of
    binary classification, the statistic, J, is defined as follows:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: J = Sensitivity + Specificity − 1 = TPR + TNR − 1 = TPR − FPR
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Its value can range from -1 (TPR=0 and TNR=0 – that is, always wrong results)
    to 1 (TPR=1 and FPR=0 – that is, perfect results). This is a common choice for
    selecting a threshold in an ROC analysis since it balances both sensitivity (TPR)
    and specificity (TNR). Please note that TNR = 1-FPR.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: The reason that maximizing Youden’s J is equivalent to choosing the optimal
    threshold is that it essentially finds the point on the ROC curve that is farthest
    from the line of no discrimination (the diagonal). This means that it selects
    a threshold that achieves a balance between TPR and FPR, which is often what we
    want in a classifier.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 'The “optimal” threshold can depend heavily on the cost of false positives versus
    false negatives in our specific application. The following code block identifies
    the optimal classification threshold using the Youden index, which is calculated
    from the ROC curve:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This outputs the following values:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Another threshold adjustment method that uses ROC curves that’s often used
    in literature is maximizing the geometric mean of TPR (also known as sensitivity)
    and TNR (also known as specificity):'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: G − mean = √ __________________  Sensitivity * Specificity  = √ _ TPR * TNR 
    = √ ______________  TPR * (1 − FPR)
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'Maximizing the geometric mean is equivalent to finding a good balance between
    TPR and TNR. The following code block calculates the best threshold for classification
    using the G-mean metric, along with its corresponding TPR, FPR, and TNR values.
    We import `roc_curve` from `sklearn.metrics`:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This outputs the following optimal values:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Threshold tuning using the PR curve
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we discussed in [*Chapter 1*](B17259_01.xhtml#_idTextAnchor015), *Introduction
    to Data Imbalance in Machine Learning*, the PR curve is generally preferred over
    ROC curves for imbalanced datasets when the positive class is more important than
    the negative class. As a reminder, the simple reason for this is that the PR curve
    ignores the true negatives, and hence, it can represent a stark difference between
    model performance when using imbalanced datasets in comparison to a balanced dataset.
    While ROC curves won’t change much as an imbalance in the data increases, they
    can be a preferred option if both classes are equally important.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: We want the maximum possible values for both precision and recall, ideally both
    being 1\. Thus, the point of optimality on a PR curve is (1,1).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: When we move away from this point of optimality, both the precision and recall
    values decrease, and we are less optimal.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'One measure that captures this trade-off between precision and recall is the
    F1 score. The F1 score is defined as the harmonic mean of the precision and recall:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: F1 = 2 * (Precision * Recall) / (Precision + Recall)
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: If we analyze this equation, we will see that the F1 score is highest (reaching
    its maximum at 1) when both precision and recall are 1, which is exactly the optimal
    point we defined on the PR curve.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, optimizing for the maximum F1 score would ensure that we are striving
    to maximize both precision and recall, effectively pushing us toward the optimal
    point on the PR curve.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 'Maximizing the F1 score is a common and effective method for determining the
    optimal threshold. The following code block calculates the best threshold using
    the F1 score metric derived from the PR curve:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This outputs the following optimal values:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let’s plot the PR curve with the optimal threshold value:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The PR curve looks like this:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_05_19.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
- en: Figure 5.19 – The PR curve with the best F1 score threshold value
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: General threshold tuning
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As a general method, we may have to optimize any metric, such as average precision,
    accuracy, and so on, or any other business metric. In such cases, we can write
    a function to optimize that metric directly. Let’s take the example of the **Index
    of Union** (**IU**) metric defined by I. Unal et al. in their research [18], where
    the metric is defined by the threshold value, c, at which IU(c) is minimized:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: IU(c) = (|Sensitivity(c) − ROC _ AUC| + |Specificity(c) − ROC _ AUC|)
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Here, Sensitivity(c) is the sensitivity at c, Specificity is the specificity
    at c, and ROC _ AUC is the **Area Under the Curve** (**AUC**) of the ROC plot.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement the IU metric, as defined here, as a custom metric to find
    the optimal threshold that minimizes it:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This produces the following optimal values:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This wraps up our discussion on classical modeling techniques. We are now ready
    to venture into studying data imbalance in the realm of deep learning. We’ll explore
    how the insights gained from the general techniques learned from previous chapters
    can be adapted to enhance our deep learning models when dealing with imbalanced
    data.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we delved into CSL, an alternative to oversampling and undersampling.
    Unlike data-level techniques that treat all misclassification errors equally,
    CSL adjusts the cost function of a model to account for the significance of different
    classes. It includes class weighting and meta-learning techniques.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Libraries such as `scikit-learn`, Keras/TensorFlow, and PyTorch support cost-sensitive
    learning. For instance, `scikit-learn` offers a `class_weight` hyperparameter
    to adjust class weights in loss calculation. XGBoost has a `scale_pos_weight`
    parameter for balancing positive and negative weights. MetaCost transforms any
    algorithm into its cost-sensitive version using bagging and a misclassification
    cost matrix. Additionally, threshold adjustment techniques can enhance metrics
    such as F1 score, precision, and recall by post-processing model predictions.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: Experiments with various data sampling and CSL techniques can help determine
    the best approach. We’ll extend these concepts to deep learning models in [*Chapter
    8*](B17259_08.xhtml#_idTextAnchor235), *Algorithm-Level Deep Learning Techniques*.
    This concludes our discussion of classical machine learning models, and we have
    graduated to move on to deep learning techniques. In the next chapter, we will
    briefly introduce deep learning concepts and see how imbalanced datasets could
    be a problem in the deep learning world.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apply the CSL technique to the SVM model from `scikit-learn` while utilizing
    the dataset that was used in this chapter. Use the `class_weight` and `sample_weight`
    parameters, similar to how we used them for other models in this chapter. Compare
    the performance of this model with the ones that we already encountered in this
    chapter.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: LightGBM is another gradient-boosting framework similar to XGBoost. Apply the
    cost-sensitive learning technique to a LightGBM model while utilizing the dataset
    we used in this chapter. Use the `class_weight` and `sample_weight` parameters
    similar to how we used them for other models in this chapter. Compare the performance
    of this model with the ones that we already encountered in this chapter.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AdaCost [10] is a variant of AdaBoost that combines boosting with CSL. It updates
    the training distribution for successive boosting rounds by utilizing the misclassification
    cost. Extend `AdaBoostClassifier` from `scikit-learn` to implement the AdaCost
    algorithm. Compare the performance of AdaCost with MetaCost on the dataset that
    was used in this chapter.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tune the hyperparameters, specifically `max_depth`, `max_delta_step`, and `min_child_weight`,
    for the XGBoost model using the dataset that we used in this chapter. After tuning,
    evaluate whether the weighted XGBoost model outperforms the non-weighted version.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: P. Turney, *Types of cost in inductive concept learning*, Proc. Workshop on
    CostSensitive Learning at the 17th Int. Conf. Mach. Learn., Stanford University,
    CA (2000), pp. 15–21.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: C. X. Ling and V. S. Sheng, *Cost-Sensitive Learning and the Class* *Imbalance
    Problem*.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sheng, V. S., & Ling, C. X. (2006). *Thresholding for making classifiers cost-sensitive*.
    AAAI’06: Proceedings of the 21st national conference on artificial intelligence,
    vol. 6, pp. 476–481.'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Pneumonia in Children Statistics* – UNICEF data: [https://data.unicef.org/topic/child-health/pneumonia/](https://data.unicef.org/topic/child-health/pneumonia/).'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'X. Ling, W. Deng, C. Gu, H. Zhou, C. Li, and F. Sun, Model Ensemble for Click
    Prediction in Bing Search Ads, in Proceedings of the 26th International Conference
    on World Wide Web Companion – WWW ’17 Companion, Perth, Australia: ACM Press,
    2017, pp. 689–698\. doi: 10.1145/3041021.3054192.'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Machine Learning-Powered Search Ranking of Airbnb Experiences* (2019), [https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789](https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789).'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'P. Domingos, MetaCost: A general method for making classifiers cost-sensitive,
    in Proceedings of International Conference on Knowledge Discovery and Data Mining,
    pp. 155–164, 1999.'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Unstable Learner*. In: Sammut, C., Webb, G.I. (eds) Encyclopedia of Machine
    Learning and Data Mining. Springer, Boston, MA. doi: [https://doi.org/10.1007/978-1-4899-7687-1_866](https://doi.org/10.1007/978-1-4899-7687-1_866).'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'W. Fan, S. J. Stolfo, J. Zhang, and P. K. Chan, *AdaCost: Misclassiﬁcation*
    *Cost-sensitive Boosting*.'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: G. I. Karakoulas and J. Shawe-Taylor, *Optimizing Classifiers for Imbalanced*
    *Training Sets*.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: P. Viola and M. Jones, *Fast and Robust Classification using Asymmetric AdaBoost
    and a* *Detector Cascade*.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'J. M. Johnson and T. M. Khoshgoftaar, *Output Thresholding for Ensemble Learners
    and Imbalanced Big Data*, in 2021 IEEE 33rd International Conference on Tools
    with Artificial Intelligence (ICTAI), Washington, DC, USA: IEEE, Nov. 2021, pp.
    1449–1454\. doi: 10.1109/ICTAI52525.2021.00230.'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'J. M. Johnson and T. M. Khoshgoftaar, *Deep Learning and Thresholding with
    Class-Imbalanced Big Data*, in 2019 18th IEEE International Conference On Machine
    Learning And Applications (ICMLA), Boca Raton, FL, USA, Dec. 2019, pp. 755–762\.
    doi: 10.1109/ICMLA.2019.00134.'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: F. Provost, *Machine Learning from Imbalanced Data* *Sets 101*.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'M. Buda, A. Maki, and M. A. Mazurowski, *A systematic study of the class imbalance
    problem in convolutional neural networks*, Neural Networks, vol. 106, pp. 249–259,
    Oct. 2018, doi: 10.1016/j.neunet.2018.07.011.'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Using Rich Image and Text Data to Categorize Products at Scale* (2021), [https://shopify.engineering/using-rich-image-text-data-categorize-products](https://shopify.engineering/using-rich-image-text-data-categorize-products).'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'W. J. Youden, *Index for rating diagnostic tests*, Cancer, vol. 3, no. 1, pp.
    32–35, 1950, doi: 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3.'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'I. Unal, *Defining an Optimal Cut-Point Value in ROC Analysis: An Alternative
    Approach*, Computational and Mathematical Methods in Medicine, vol. 2017, pp.
    1–14, 2017, doi: 10.1155/2017/3762651.'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'X. Ling, W. Deng, C. Gu, H. Zhou, C. Li, and F. Sun, *Model Ensemble for Click
    Prediction in Bing Search Ads*, in Proceedings of the 26th International Conference
    on World Wide Web Companion – WWW ’17 Companion, Perth, Australia: ACM Press,
    2017, pp. 689–698\. doi: 10.1145/3041021.3054192.'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
