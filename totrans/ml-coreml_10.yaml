- en: An Introduction to Create ML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Create ML 简介
- en: The intention of this book has been to explore ways to apply machine learning
    on the iPhone, specifically focusing on computer vision tasks. Even with this
    narrow focus, we have only scratched the surface of what is currently possible.
    But, hopefully, we've covered enough to spark your curiosity and provided enough
    intuition behind the details of machine learning models to help you on your journey
    to build intelligent apps.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的目的是探索在iPhone上应用机器学习的方法，特别是关注计算机视觉任务。即使这个焦点很窄，我们也只是触及了目前可能性的表面。但，希望我们已经涵盖了足够的内容来激发您的兴趣，并提供了足够的直觉来帮助您在构建智能应用的过程中理解机器学习模型的细节。
- en: This chapter is intended as a primer into continuing that journey by introducing
    **Create ML**, a tool released with Core ML 2 that provides an easy way to create
    some common models using custom data. Even though we only provide a high-level
    introduction, specifically around computer vision, it still should be enough to
    help you make use of it in your own applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在通过介绍**Create ML**，一个与Core ML 2一同发布的工具，该工具提供了一种使用自定义数据创建一些常见模型的方法，来继续这一旅程。尽管我们只提供了高级介绍，特别是关于计算机视觉，但这仍然应该足以帮助您在自己的应用中使用它。
- en: 'By the end of this chapter, you will have:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将：
- en: Revised the machine learning workflow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修订了机器学习工作流程
- en: Appreciated the importance of splitting your data into sets for training and
    validation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认识到将数据分为训练集和验证集的重要性
- en: Used Create ML to create a custom image classifier
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Create ML创建自定义图像分类器
- en: Seen other tools and frameworks to continue your journey
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看过其他工具和框架以继续您的旅程
- en: Let's begin by reviewing a typical machine learning workflow.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从回顾典型的机器学习工作流程开始。
- en: A typical workflow
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 典型的工作流程
- en: As with any project, you enter the process with some understanding of what you
    are trying to build. The better you understand this (the problem), the better
    you are able to solve it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何项目一样，您在进入过程时对您要构建的内容（问题）有一些了解。您对此了解得越清楚，您就越有能力解决它。
- en: After understanding what it is that you're trying to do, your next question
    (in the context of building a machine learning model) is *what data do I need?*
    This includes an exploration into what data is available and what data you may
    need to generate yourself.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了您要做什么之后（在构建机器学习模型的背景下），您的下一个问题（或任务）是“我需要什么数据？”这包括探索可用的数据以及您可能需要自己生成哪些数据。
- en: 'Once you''ve understood what you''re trying to do and what data you need, your
    next question/task is to decide on what algorithm (or model) is needed. This is
    obviously dependent on your task and the data you have; in some instances, you
    may be required to create your own model, but more often than not, there will
    be an adequate model available for you to use, or at least an architecture you
    can use with your own data. The following table shows some typical computer vision
    tasks and their related machine learning counterparts:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您理解了您要做什么以及您需要什么数据，您的下一个问题/任务就是决定需要什么算法（或模型）。这显然取决于您的任务和您拥有的数据；在某些情况下，您可能需要创建自己的模型，但更常见的情况是，您将可以使用一个合适的模型，或者至少是一个可以与您自己的数据一起使用的架构。以下表格显示了典型的计算机视觉任务及其相关的机器学习对应物：
- en: '| **Task** | **Machine learning algorithm** |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **任务** | **机器学习算法** |'
- en: '| Label images | Image classification |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 标注图像 | 图像分类 |'
- en: '| Recognize multiple objects and their location | Object detection and semantic
    segmentation  |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 识别多个对象及其位置 | 目标检测和语义分割 |'
- en: '| Find similar images  | Image similarity  |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 找到相似图像 | 图像相似度 |'
- en: '| Creating stylized images  | Style transfer |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 创建风格化的图像 | 风格迁移 |'
- en: The next step is to train your model; typically, this is an iterative process
    with a lot of fine-tuning until you have a model that sufficiently achieves its
    task on data it hadn't been trained on.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是训练您的模型；通常，这是一个迭代的过程，需要大量的微调，直到您有一个在未训练过的数据上足够好地完成其任务的模型。
- en: 'Finally, with a trained model, you can deploy and use your model in your application.
    This process is summarized in the following diagram:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在训练好模型后，您可以在您的应用中部署和使用您的模型。这个过程在以下图中总结：
- en: '![](img/e953380d-6b7e-4500-b2b6-46326d593c02.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e953380d-6b7e-4500-b2b6-46326d593c02.png)'
- en: The previous diagram is an oversimplification of the process; typically the
    workflow is more cyclic, with multiple iterations between training and selecting
    and tuning your model. It is also common to run multiple models (and model parameters)
    concurrently.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的图表是对过程的过度简化；通常，工作流程是更循环的，在训练、选择和调整模型之间有多个迭代。同时运行多个模型（和模型参数）也是常见的。
- en: To make the concepts of this chapter more concrete, let's work with the hypothetical
    brief of having to build a fun application to assist toddlers to learn the names
    of fruits. You and your team have come up with the concept of a game that asks
    the toddler to find a specific fruit. The toddler earns points when they correctly
    identify the fruit using the device's camera. With our task now defined, let's
    discuss what data we need.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本章的概念更加具体，让我们以一个假设的简报为例，即必须构建一个有趣的应用程序来帮助幼儿学习水果的名称。你和你的团队已经提出了一个概念，即让幼儿通过使用设备的摄像头找到特定的水果。当幼儿正确地使用设备识别出水果时，他们会获得积分。现在我们的任务已经定义，让我们讨论我们需要哪些数据。
- en: Preparing the data
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: For our task, we require a collection of labeled photos of fruits. As you may
    recall from [Chapter 1](7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml), *Introduction
    to Machine Learning*, this type of machine learning problem is known as **supervised
    learning**. We need our model to take in an image and return the label of what
    it thinks the image is, also known as **multi-class classification**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的任务，我们需要一组标注好的水果照片。如您从[第1章](7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml)，“机器学习简介”中回忆的那样，这类机器学习问题被称为**监督学习**。我们需要我们的模型接收一张图片并返回它认为图片所代表的标签，也称为**多类分类**。
- en: 'Go ahead and collect photos of fruits. Create ML allows for multiple ways of
    organizing your data, but I find that ad hoc collection is easiest done by organizing
    it in folders, as shown here:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 开始收集水果照片。创建ML允许以多种方式组织你的数据，但我发现按照以下方式在文件夹中组织是最容易的：
- en: '![](img/6438e297-85ec-4c59-972b-01cbb68c4a05.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6438e297-85ec-4c59-972b-01cbb68c4a05.png)'
- en: Source: http://www.image-net.org/
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：http://www.image-net.org/
- en: Here, we have organized our data into folders, where the folder name is used
    as a label for its contents. An alternative is labeling each image, where each
    instance of a specific class has a suffix number, for example `banana.0.jpg`,
    `banana.1.jpg`, and so on. Or you can simply pass in a dictionary of labels with
    their associated list of image URLs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经将我们的数据组织成文件夹，文件夹名称用作其内容的标签。另一种方法是给每张图片标注，例如，特定类别的每个实例都有一个后缀数字，例如 `banana.0.jpg`，`banana.1.jpg`，依此类推。或者，您可以简单地传递一个包含标签及其相关图像URL列表的字典。
- en: At this stage, you may be wondering how many images you should get. Apple has
    suggested a minimum of 10 images per class, butyou typically want to collect as
    many as possible, to help the model generalize by ensuring that it sees a lot
    of variations during training. It's also important to, wherever possible, obtain
    images that are as close as possible to the real data the model will be used on
    (in the realworld). This is because the model is not biased according to what
    it learns. It just learns what it needs to. That is, if all your apple examples
    were of red apples with a white background, then it's likely that your model will
    learn to associate these colors with apples, and any time it sees these colors,
    it will predict that the image contains an apple.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你可能想知道你应该获取多少张图片。苹果公司建议每个类别至少需要10张图片，但你通常希望收集尽可能多的图片，以帮助模型通过确保它在训练期间看到很多变化来泛化。同时，尽可能获取与模型将要使用的真实数据尽可能接近的图片也很重要（在现实世界中）。这是因为模型不会根据它学到的内容产生偏见。它只是学习它需要学习的内容。也就是说，如果你的苹果示例都是红色苹果，背景为白色，那么你的模型很可能会学会将这些颜色与苹果联系起来，每次它看到这些颜色时，它都会预测该图像包含苹果。
- en: As mentioned previously, Apple has suggested a minimum of 10 images; this should
    have somewhat surprised you. Typically, when you talk about training deep neural
    networks, you expect the dataset to be large, very large. For example, a standard
    dataset used for training image classifiers is ImageNet. This dataset consists
    of over 14 million images; and this is part of the secret. As we've discussed
    throughout this book, layers of a CNN learn how to extract meaningful features
    from images, which they then use to infer an image's class. A common practice
    for specialized classifiers, like our fruit classifier, is to borrow these learnings
    from a model that has trained on millions of images and use the features it extracts
    to train a classifier on our smaller dataset—a technique known as **transfer learning**.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，苹果公司建议至少需要10张图片；这应该让你感到有些惊讶。通常，当谈论训练深度神经网络时，你期望数据集很大，非常大。例如，用于训练图像分类器的一个标准数据集是ImageNet。这个数据集包含超过1400万张图片；这也是秘密的一部分。正如我们在整本书中讨论的那样，CNN的层学习如何从图像中提取有意义特征，然后它们使用这些特征来推断图像的类别。对于像我们的水果分类器这样的专用分类器，一个常见的做法是借鉴在数百万张图片上训练的模型的这些学习成果，并使用它提取的特征来训练我们较小的数据集上的分类器——这种技术被称为**迁移学习**。
- en: 'The following two diagrams provide an illustrative example of this, with the
    first showing a network that has been trained on a large dataset and the second
    using what it has learnt to train on a more specialized dataset:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的两个图提供了这个过程的说明性示例，第一个图显示了一个在大数据集上训练的网络，第二个图则使用它所学的知识来训练一个更专业的数据集：
- en: '![](img/a7895715-bc54-4eb0-9088-3f8d269a4548.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a7895715-bc54-4eb0-9088-3f8d269a4548.png)'
- en: 'We are interested in the feature vectors that the convolutional layers learn;
    you can think of this as an encoding of its understanding of the input image.
    This is what we want to use to train our own classifier, shown in the following
    diagrams:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对卷积层学习的特征向量感兴趣；你可以将其视为其对输入图像理解的编码。这是我们想要用来训练我们自己的分类器，如下图中所示：
- en: '![](img/9486a355-fcc1-4043-ae53-a26ba3451891.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9486a355-fcc1-4043-ae53-a26ba3451891.png)'
- en: With this approach, we forgo having to learn how to extract features and are
    left with just having to train the weights of a fully connected network for classification,
    taking advantage of the previous network's ability to extract meaningful features.
    Create ML uses this technique for its image classifiers. Using a pre-trained model
    that resides on the device and has been trained over 1,000 categories means that
    we are left just having to train a relatively small network for classification.
    This is done using the features provided by the pre-trained network. This not
    only allows us to learn from a smaller dataset but also reduces the amount of
    time required for training.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法，我们无需学习如何提取特征，只需训练一个全连接网络的权重以进行分类，利用先前网络提取有意义特征的能力。Create ML 使用这种技术为其图像分类器服务。使用驻留在设备上并已针对超过1,000个类别进行训练的预训练模型意味着我们只需训练一个相对较小的网络进行分类。这是通过使用预训练网络提供的特征来完成的。这不仅使我们能够从较小的数据集中学习，而且减少了训练所需的时间。
- en: 'Another feature Create ML offers, and performs on our behalf, to train effectively
    on small datasets is something called data augmentation.Data augmentation is simply
    a way of increasing the variance of our dataset by applying a number of random
    transformations to each image before the image is passed into the network during
    training, for example, horizontally flipping an image. The goal is that at training
    time, your model will see many variations of an image so as to improve your model''s
    ability to generalize, that is, learn meaningful features that work on data it
    hasn''t seen before. The following figure illustrates some of the transformations
    typically performed for data augmentation:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Create ML 提供的另一个功能，并且代表我们进行有效的小数据集训练的是一种称为数据增强的技术。数据增强简单来说就是通过在训练过程中对每个图像应用一系列随机变换来增加数据集的方差，例如水平翻转图像。目标是，在训练时间，你的模型将看到许多图像的变体，以提高你的模型泛化的能力，也就是说，学习对它之前未见过的数据有意义的特征。以下图展示了数据增强通常执行的一些变换：
- en: '![](img/1ea43127-3807-4955-8920-6c37ad861901.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1ea43127-3807-4955-8920-6c37ad861901.png)'
- en: Another convenience offered by Create ML out of the box is that it handles the
    typical preprocessing tasks required when working with images, such as cropping
    and resizing. They typically have fixed-size inputs and outputs, requiring you
    to either explicitly preprocess the images to match the model or use the Vision
    framework to handle this for you. An extra consequence of Create ML being built
    on top of Vision is that it handles a lot of the pipeline you would typically
    need to do manually when training models.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Create ML提供的另一个便利之处是，它处理了与图像一起工作时所需的典型预处理任务，例如裁剪和调整大小。它们通常具有固定大小的输入和输出，需要您显式地预处理图像以匹配模型，或者使用Vision框架来为您处理这些任务。Create
    ML建立在Vision之上的额外后果是，它处理了您在训练模型时通常需要手动执行的大量管道。
- en: 'There is just one more important topic I would like to highlight before moving
    on to creating and training our model; this has to do with balanced datasets,
    or the effects of imbalanced datasets. Balanced datasets refer to having an equal
    amount of examples for each class; that is, you avoid having a large variance
    between the number of examples you have in each of your classes. Why is this important?
    To answer this, let''s remind ourselves of how a model is trained and what it
    learns. The following figure illustrates the process of training, where training
    is an iterative process of performing inference (forward pass) for a given input.
    Then, small adjustments are made to the weights of the model so that they reduce
    any discrepancies between the prediction and expected value (loss):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续创建和训练模型之前，还有一个重要的话题我想强调；这与平衡数据集或不平衡数据集的影响有关。平衡数据集指的是每个类都有相同数量的示例；也就是说，您避免在您每个类中的示例数量之间有大的差异。这为什么很重要？为了回答这个问题，让我们提醒一下模型是如何训练的以及它学到了什么。以下图示了训练过程，其中训练是对给定输入进行推理（前向传递）的迭代过程。然后，对模型的权重进行小调整，以便它们减少预测值和预期值（损失）之间的任何差异：
- en: '![](img/95712ee3-0d50-4c57-88a0-d8298e4b1a79.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/95712ee3-0d50-4c57-88a0-d8298e4b1a79.png)'
- en: Put another way, overexposing a class will dominate this process of adjusting
    weights such that the weights will better fit their own class over others. This
    is especially true when training with batches, as the error is typically the average
    over all samples in the batch. So, if your model can effectively predict the dominant
    class, it's likely to achieve a reasonable loss and be unable to learn anything
    useful for the other classes.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种说法是，过度暴露一个类将主导调整权重的这个过程，使得权重将更好地适应它们自己的类而不是其他类。这在批量训练时尤其如此，因为错误通常是批集中所有样本的平均值。所以，如果您的模型能够有效地预测主导类，它很可能会实现合理的损失，并且无法为其他类学习到任何有用的东西。
- en: At this point, we know what we are trying to achieve, have our balanced training
    set, and know what machine learning task we need; we are now ready to build and
    train our model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们已经知道我们想要实现的目标，拥有我们的平衡训练集，并且知道我们需要什么机器学习任务；我们现在准备好构建和训练我们的模型了。
- en: Creating and training a model
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和训练模型
- en: Thanks to the great effort by Apple's engineers, the process of creating common
    machine learning models is incredibly easy and will no doubt spark a new wave
    of intelligent apps over the coming months.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢苹果工程师们的巨大努力，创建常见机器学习模型的过程极其简单，无疑将在接下来的几个月内引发一波新的智能应用浪潮。
- en: In this section, you will see just how easy it is as we walk through creating
    an image classifier for our application using Create ML.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将看到我们如何使用Create ML创建一个图像分类器，这将展示其有多么简单。
- en: 'Create ML is accessible using Xcode Playground, so there is a good place to
    start. Open up Xcode and create a new Playground, ensuring that you select macOS
    as the platform, as shown here:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Xcode Playground可以访问Create ML，因此这是一个很好的开始地方。打开Xcode并创建一个新的Playground，确保您选择macOS作为平台，如图所示：
- en: '![](img/e0fa97a3-d516-4921-93ad-e7a2ce12dd30.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e0fa97a3-d516-4921-93ad-e7a2ce12dd30.png)'
- en: 'Once in the playground, import `CreateML` and `Foundation` as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦进入Playground，按照以下方式导入`CreateML`和`Foundation`：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, create a `URL` that points to the directory that contains your training
    data:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个指向包含您的训练数据目录的`URL`：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The only thing left to do is to create an instance of our model, passing in
    the path to our training data (I did say it was incredibly easy):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一事情就是创建我们模型的实例，传入我们训练数据的路径（我确实说过这非常简单）：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Create ML offers you the flexibility of providing a custom dictionary of labels
    and their associated files or through the convenience of a `MLImageClassifier.DataSource`.
    This can either be a hierarchical directory structure where classes are organized
    into their respective folders, `MLImageClassifier.DataSource.labeledDirectories` (as
    we have done in this example), or one where each file has been named with respect
    to their associated class, `MLImageClassifier.DataSource.labeledFiles`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Create ML为您提供了提供自定义标签字典及其相关文件的灵活性，或者通过`MLImageClassifier.DataSource`的便利性。这可以是类组织到相应文件夹中的分层目录结构，`MLImageClassifier.DataSource.labeledDirectories`（如我们在本例中所做的那样），或者每个文件都根据其相关类命名的结构，`MLImageClassifier.DataSource.labeledFiles`。
- en: 'As soon as the model is instantiated, it will begin training. Once finished,
    it will output the accuracy achieved on your training set to the console, as shown
    in the following screenshot:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型实例化，它将开始训练。一旦完成，它将输出在您的训练集上达到的准确率到控制台，如下面的截图所示：
- en: '![](img/5f7c863b-0f7e-4108-8e93-96b0fb99fce8.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5f7c863b-0f7e-4108-8e93-96b0fb99fce8.png)'
- en: We are almost done; this tells us that our model has fit our training data well,
    but it doesn't tell us how well it will generalize, that is, how well it will
    work on images it hasn't seen before. It's possible (and common) for deep neural
    networks to remember their training data, commonly referred to as overfitting.
    To avoid overfitting, and therefore make it more likely to produce something usable
    in the real world, it's a common practice to split your data into three buckets.
    The first bucket is used to train your model. The second bucket, called validation
    data, is used during training (typically at the end of each iteration/epoch) to
    see how well the model is generalizing. It also provides clues as to when the
    model starts overfitting (when the training accuracy and validation accuracy begin
    to diverge). The last bucket is only used once you are satisfied with how your
    model performs on the validation data and is the determinant of how well your
    model actually works; this bucket is known as the test data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了；这告诉我们我们的模型很好地拟合了我们的训练数据，但它并没有告诉我们它将如何泛化，也就是说，它将如何在新未见过的图像上工作。深度神经网络记住它们的训练数据，这通常被称为过拟合。为了避免过拟合，并因此更有可能在现实世界中产生可用的东西，通常将数据分成三个桶。第一个桶用于训练模型。第二个桶，称为验证数据，在训练期间使用（通常在每个迭代/周期结束时）来查看模型泛化的程度。它还提供了有关模型何时开始过拟合的线索（当训练准确率和验证准确率开始偏离时）。最后一个桶只在您对模型在验证数据上的表现满意后使用，这是模型实际工作效果的决定因素；这个桶被称为测试数据。
- en: How much data do you reserve for validation and testing? For shallow learners,
    it was common to have a 70/20/10 (training, validation, and test) split. But deep
    learning normally implies big datasets, in which case the reserved data for validation
    and test may be excessive. So the answer really depends on how much data you have
    and what type of data it is.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您为验证和测试保留了多少数据？对于浅层学习者来说，通常有一个70/20/10（训练、验证和测试）的分割。但深度学习通常意味着大数据集，在这种情况下，为验证和测试保留的数据可能过多。因此，答案实际上取决于您有多少数据以及数据的类型。
- en: Therefore, before deploying our model, we evaluate it on a dataset it hasn't
    seen during training. Once again, collect an equal amount of data for each of
    your classes and return here once you've done so.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们部署模型之前，我们将在训练期间未见过的数据集上评估它。再次提醒，为您的每个类别收集相等数量的数据，并在完成后返回此处。
- en: 'As we had done before, create a URL that points to the directory that contains
    your validation data:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所做的那样，创建一个指向包含您的验证数据的目录的URL：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now it''s simply a matter of calling `evaluation` on the model, as shown here:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在只需在模型上调用`evaluation`即可，如下所示：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will perform inference on each of our validation samples and report the
    accuracy, which you can access via quick looks:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在我们的每个验证样本上执行推理，并报告准确率，您可以通过快速查看访问：
- en: '![](img/23aa4d83-4680-49a7-9b94-9a7ba54db124.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/23aa4d83-4680-49a7-9b94-9a7ba54db124.png)'
- en: Satisfied with our validation accuracy, we are now ready to export our model,
    but just before we do so, let's perform a prediction on an individual image.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的验证准确率感到满意后，我们现在准备导出我们的模型，但在我们这样做之前，让我们对一个单独的图像进行预测。
- en: 'You can easily do this by calling the `prediction` method of your model instance
    (or `predictions` if you have multiple samples you want to perform inference on),
    as shown in this snippet:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过调用模型实例的 `prediction` 方法（如果您有多个样本要执行推理，则为 `predictions`）轻松完成此操作，如下面的代码片段所示：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If all goes well, then `Strawberry` should be output to your console. Now, feeling
    confident with our model, it's time to export it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，那么 `Strawberry` 应该会输出到您的控制台。现在，对我们模型有了信心，是时候导出它了。
- en: 'In keeping with the nature of Create ML, exporting is simply a single line
    of code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Create ML 的本质，导出只是一行代码：
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: From here, it's just a matter of importing the Core ML model into your project,
    as we have seen many times throughout this book.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，只需将 Core ML 模型导入到您的项目中即可，正如我们在本书中多次看到的。
- en: We have almost concluded our brief introduction to Create ML; but before we
    move on, I want to quickly highlight a few things, starting with model parameters.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎结束了对 Create ML 的简要介绍；但在我们继续之前，我想快速强调一些事情，首先是模型参数。
- en: Model parameters
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型参数
- en: In the previous section, I mentioned the usefulness of data augmentation for
    small datasets. So, how do you use this during your training? The options are
    exposed to you using the  `MLImageClassifier.ModelParameters` structure, which
    you can pass an instance of when instantiating the classifier. One of the parameters
    is the `OptionSet`  `CreateML.MLImageClassifier.ImageAugmentationOptions`, which
    allows you to toggle various augmentation techniques on and off.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我提到了数据增强对于小型数据集的有用性。那么，您如何在训练期间使用它呢？选项通过 `MLImageClassifier.ModelParameters`
    结构暴露给您，您可以在实例化分类器时传递其实例。其中一个参数是 `OptionSet` `CreateML.MLImageClassifier.ImageAugmentationOptions`，它允许您打开和关闭各种增强技术。
- en: '`MLImageClassifier.ModelParameters` also allows you to specify the maximum
    number of iterations, version of the feature extraction, and validation data.
    You can learn more about these on the official web page at [https://developer.apple.com/documentation/create_ml/mlimageclassifier/modelparameters](https://developer.apple.com/documentation/create_ml/mlimageclassifier/modelparameters).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`MLImageClassifier.ModelParameters` 还允许您指定最大迭代次数、特征提取的版本和验证数据。您可以在官方网页上了解更多信息：[https://developer.apple.com/documentation/create_ml/mlimageclassifier/modelparameters](https://developer.apple.com/documentation/create_ml/mlimageclassifier/modelparameters)。'
- en: Model metadata
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型元数据
- en: When working with the Core ML Tools package in [Chapters 5](a89287b3-5c90-4f77-801f-371f7a8f2d36.xhtml), *Emotion
    Detection with CNNs,* and [Chapter 6](40971e0d-b260-42e1-a9fb-5c4a56b0ebb2.xhtml), *Creating
    Art with Style Transfer,* to convert a Keras model to Core ML, we saw how we could
    explicitly set the metadata, which is shown in Xcode. Create ML provides a way
    of explicitly setting this data by passing in an instance of `MLModelMetadata`
    when exporting the model. It provides you all the metadata we had seen when working
    with the Core ML Tools package, such as name, description and so on.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当与 [第 5 章](a89287b3-5c90-4f77-801f-371f7a8f2d36.xhtml) 中的 Core ML 工具包和 [第 6
    章](40971e0d-b260-42e1-a9fb-5c4a56b0ebb2.xhtml) 中的 *使用风格迁移创建艺术* 一起工作时，我们将 Keras
    模型转换为 Core ML，我们看到了如何显式设置元数据，这在 Xcode 中显示。Create ML 通过在导出模型时传递 `MLModelMetadata`
    的实例来提供显式设置这些数据的方法。它提供了我们在使用 Core ML 工具包时看到的全部元数据，如名称、描述等。
- en: Alternative workflow (graphical)
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 替代工作流程（图形化）
- en: 'The last point before moving on to the next section! In this chapter, we have
    walked through programmatically creating, training, and validating a model. Create
    ML offers an alternative, where, instead of using code to build your model, you
    can use a graphical interface. This is accessible via the `CreateMLUI` library,
    where you simply create an instance of `MLImageClassifierBuilder` and call its `showInLiveView`
    method:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一节之前，最后一点！在本章中，我们已经通过编程的方式创建、训练和验证了一个模型。Create ML 提供了一种替代方案，在这里，您可以使用图形界面来构建模型，而不是使用代码。这可以通过
    `CreateMLUI` 库访问，您只需创建一个 `MLImageClassifierBuilder` 的实例并调用其 `showInLiveView` 方法：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Once this runs, you will see a widget in the live view, which allows you to
    train the model simply by dragging and dropping in your training and validation
    examples. The following figure shows this widget after training and validation,
    and the panel for entering metadata:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行，您将在实时视图中看到一个小部件，它允许您通过拖放训练和验证示例来简单地训练模型。以下图显示了训练和验证后的此小部件以及输入元数据的面板：
- en: '![](img/c03a3709-578e-48fc-8b41-cb4f7284b09f.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c03a3709-578e-48fc-8b41-cb4f7284b09f.png)'
- en: This concludes this section, the chapter, and the book. We will wrap up with
    some closing thoughts, including a list of some other tools to help you on your
    journey to creating more intelligent apps.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分、这一章和这本书的内容到此结束。我们将以一些总结性的思考结束，包括一些其他工具的列表，以帮助您在创建更智能的应用程序的道路上。
- en: Closing thoughts
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结性思考
- en: 'This tool essentially democratizes machine learning by way of allowing anyone
    (who is able) to create custom models, but there is always a trade-off between
    simplicity and expressiveness. So, here is a short list of tools you may want
    to explore:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工具通过允许任何（有能力的人）创建自定义模型，实际上使机器学习民主化，但简单性和表达性之间总是存在权衡。因此，这里有一份简短的工具列表，您可能想要探索：
- en: '**Turi create**: comes from a firm acquired by Apple in 2016; it provides tight
    integration with Core ML, allowing for easy deployment and custom models. It also
    provides a more comprehensive suite of machine learning models such as Style Transfer
    and segmentation. You can learn more about Turi create here: [https://github.com/apple/turicreate](https://github.com/apple/turicreate).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Turi create**：来自2016年被苹果公司收购的公司；它提供了与Core ML的紧密集成，使得部署和定制模型变得容易。它还提供了一套更全面的机器学习模型，如风格转换和分割。您可以在[https://github.com/apple/turicreate](https://github.com/apple/turicreate)了解更多关于Turi
    create的信息。'
- en: '**IBM Watson Services for Core ML**: IBM Watson is IBM''s AI platform, exposing
    an array of common machine learning models as a service. They have recently made
    available some of these services via Core ML models, allowing your application
    to leverage IBM Watson''s services even when offline.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IBM Watson Services for Core ML**：IBM Watson是IBM的AI平台，提供了一系列常见的机器学习模型作为服务。他们最近通过Core
    ML模型提供了一些这些服务，允许您的应用程序在离线时也能利用IBM Watson的服务。'
- en: '**ML Kit**: Google announced an ML Kit in early 2018 as a platform for common
    machine learning tasks such as image labeling and optical character recognition.
    The platform also takes care of model distribution, including custom ones.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ML Kit**：谷歌在2018年初宣布了ML Kit，作为一个平台，用于常见的机器学习任务，如图像标注和光学字符识别。该平台还负责模型分发，包括自定义模型。'
- en: '**TensorFlowLite**: A lightweight version of the popular machine learning framework
    TensorFlow. Like Core ML, it enables on-device inference.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlowLite**：TensorFlow流行机器学习框架的轻量级版本。与Core ML类似，它支持设备端推理。'
- en: These are only a few of the options available to integrate machine learning
    into your application, and all this is likely to grow significantly over the coming
    years. But, as we have seen throughout this book, the machine learning algorithm
    is (literally) only one part of the equation; data is what drives the experience,
    so I encourage you to seek out and experiment with new datasets to see what unique
    experiences you can come up with using what you have learnt here.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是将机器学习集成到您应用程序中的一些选项，所有这些在未来的几年里都可能显著增长。但是，正如我们在整本书中看到的，机器学习算法只是方程的一部分；数据是推动体验的因素，所以我鼓励您寻找并尝试新的数据集，看看您能利用这里学到的知识创造出什么样的独特体验。
- en: Machine learning is evolving at an incredible pace. The website Arxiv is a popular
    repository for researchers to publish their papers; by just monitoring this site
    for over a week, you will be amazed and excited by the volume of papers being
    published and the advancements being made.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习正在以惊人的速度发展。Arxiv网站是研究人员发布论文的流行仓库；只需监测这个网站一周以上，您就会对发表的论文数量和取得的进步感到惊讶和兴奋。
- en: But, right now, there is a gap between the research community and industry practitioners,
    which in part motivated me to write this book. I hope that what you have read
    in the pages of this book has given you enough intuition behind deep neural networks
    and, more importantly, sparked enough curiosity and excitement for you to continue
    exploring and experimenting. As I mentioned at the start of this chapter, we have
    just scratched the surface of what is currently out and possible, never mind what
    will be around in 12 months.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，目前研究界和行业从业者之间存在差距，这在一定程度上促使我写这本书。我希望您在这本书的页面上所读到的内容已经给您足够关于深度神经网络的直觉，更重要的是，激发了对您继续探索和实验的足够的好奇心和兴奋感。正如我在本章开头提到的，我们刚刚触及了目前存在和可能的表面，更不用说12个月后的情况了。
- en: So, consider this as an invite or challenge to join me in creating the next
    generation of applications. I look forward to seeing what you create!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，请把这看作是邀请或挑战，加入我一起创造下一代应用程序。我期待看到您创造出的成果！
- en: Summary
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we introduced Create ML, a tool that makes it incredibly easy
    to train and deploy common machine learning models. We saw how easy it is to create
    an image classifier using a minimal amount of examples and minimal amount of code.
    We discussed how this was achieved through the use of transfer learning, and then
    covered some considerations to keep in mind with regard to your training data
    and the importance of splitting it for validation and testing.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了Create ML，这是一个使训练和部署常见机器学习模型变得极其简单的工具。我们看到了如何使用极少的示例和极少的代码创建一个图像分类器。我们讨论了这是如何通过使用迁移学习来实现的，然后介绍了一些关于您的训练数据以及将其分割用于验证和测试的重要性的注意事项。
