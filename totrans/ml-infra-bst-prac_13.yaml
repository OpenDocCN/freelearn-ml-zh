- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Training and Evaluating Classical Machine Learning Systems and Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modern machine learning frameworks are designed to be user-friendly for programmers.
    The popularity of the Python programming environment (and R) has shown that designing,
    developing, and testing machine learning models can be focused on the machine
    learning task and not on the programming tasks. The developers of the machine
    learning models can focus on developing the entire system and not on programming
    the internals of the algorithms. However, this bears a darker side – a lack of
    understanding of the internals of the models and how they are trained, evaluated,
    and validated.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I’ll dive a bit deeper into the process of training and evaluation.
    We’ll start with the basic theory behind different algorithms before learning
    how they are trained. We’ll start with the classical machine learning models,
    exemplified by decision trees. Then, we’ll gradually move toward deep learning,
    where we’ll explore both dense neural networks and more advanced types of networks.
  prefs: []
  type: TYPE_NORMAL
- en: The most important part of this chapter is understanding the difference between
    training/evaluating algorithms and testing/validating the entire machine learning
    software system. I’ll explain this by describing how machine learning algorithms
    are used as part of a production machine learning system (or what the entire machine
    learning system looks like).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Training and test processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training classical machine learning models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training deep learning models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Misleading results – problems with data leaks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and testing processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning has revolutionized the way we solve complex problems by enabling
    computers to learn from data and make predictions or decisions without being explicitly
    programmed. One crucial aspect of machine learning is training models, which involves
    teaching algorithms to recognize patterns and relationships in data. Two fundamental
    methods for training machine learning models are `model.fit()` and `model.predict()`.
  prefs: []
  type: TYPE_NORMAL
- en: The `model.fit()` function lies at the heart of training a machine learning
    model. It is the process by which a model learns from a labeled dataset to make
    accurate predictions. During training, the model adjusts its internal parameters
    to minimize the discrepancy between its predictions and the true labels in the
    training data. This iterative optimization process, often referred to as “learning,”
    allows the model to generalize its knowledge and perform well on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the training data and labels, the `model.fit()` function also
    takes various hyperparameters as arguments. These hyperparameters include the
    number of epochs (that is, the number of times the model will iterate over the
    entire dataset), the batch size (the number of samples processed before updating
    the parameters), and the learning rate (determining the step size for parameter
    updates). Properly tuning these hyperparameters is crucial to ensure effective
    training and prevent issues such as overfitting or underfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Once the training process is complete, the trained model can be used to make
    predictions on new, unseen data. This is where the `model.predict()` method comes
    into play. Given a trained model and a set of input data, the `model.predict()`
    function applies the learned weights and biases to generate predictions or class
    probabilities. The predicted outputs can then be used for various purposes, such
    as classification, regression, or anomaly detection, depending on the nature of
    the problem at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'We saw examples of this interface in previous chapters. Now, it is time to
    understand what’s under the hood of this interface and how the process of training
    works. In the previous chapter, we looked at this process as a black box, where
    the process was done once the program moved past the line with `model.fit()`.
    This is the basics of the process, but it is not only that. The process is iterative
    and depends on the algorithm/model that is being trained. As every model has different
    parameters, the fit function can take more parameters. The additional parameters
    can also be added when we instantiate the model, even before the training process.
    *Figure 10**.1* presents this process as a gray box:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Gray box for training a machine learning model](img/B19548_10_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Gray box for training a machine learning model
  prefs: []
  type: TYPE_NORMAL
- en: Before we start the training process, we split the data into training and test
    sets (which we discussed previously). At the same time, we select the parameters
    for the machine learning model that we use. These can be anything from the number
    of trees (for random forest) to the number of iterations and batch size for neural
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: The training process is iterative, where a model is trained on the data, evaluated
    internally, and then re-trained to find a better fit for the data. In this chapter,
    we’ll explore how this internal training works.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, once the model has been trained, it is set for the testing process.
    In the testing process, we use pre-defined performance measures to check how well
    the model’s learned pattern can be reproduced for new data.
  prefs: []
  type: TYPE_NORMAL
- en: Training classical machine learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ll start by training a model that lets us look inside it. We’ll use the
    CART decision tree classifier, where we can visualize the actual decision tree
    that is trained. We’ll use the same numerical data we used in the previous chapter.
    First, let’s read the data and create the train/test split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code reads an Excel file named `'chapter_6_dataset_numerical.xlsx'`
    using the `pd.read_excel()` function from pandas. The file is read into a DataFrame
    called `dfDataAnt13`. The `sheet_name` parameter specifies the sheet within the
    Excel file to read, while the `index_col` parameter sets the first column as the
    index of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: The code prepares the dataset for training a machine learning model. It assigns
    the independent variables (features) to the `X` variable by dropping the `'Defect'`
    column from the `dfDataAnt13` DataFrame using the `drop()` method. The dependent
    variable (target) is assigned to the `y` variable by selecting the `'Defect'`
    column from the `dfDataAnt13` DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: The `sklearn.model_selection.train_test_split()` function is used to split the
    dataset into training and testing sets. The `X` and `y` variables are split into
    `X_train`, `X_test`, `y_train`, and `y_test` variables. The `train_size` parameter
    is set to `0.9`, indicating that 90% of the data will be used for training and
    the remaining 10% will be used for testing. The `random_state` parameter is set
    to `42` to ensure reproducibility of the split.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the data has been prepared, we can import the decision tree library and
    train the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code fragment imports the `DecisionTreeClassifier` class from
    the `sklearn.tree` module. An empty decision tree classifier object is created
    and assigned to the `decisionTreeModel` variable. This object will be trained
    on the dataset that was prepared in the previous fragment. The `fit()` method
    is called on the `decisionTreeModel` object to train the classifier. The `fit()`
    method takes the training data (`X_train`) and the corresponding target values
    (`y_train`) as input. The classifier will learn patterns and relationships in
    the training data to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The trained decision tree classifier is used to predict the target values for
    the test dataset (`X_test`). The `predict()` method is called on the `decisionTreeModel`
    object, passing `X_test` as the input. The predicted target values are stored
    in the `y_pred_cart` variable. The predicted model needs to be evaluated, so let’s
    evaluate the accuracy, precision, and recall of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This code fragment results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The metrics show that the model is not that bad. It classified 83% of the data
    in the test set correctly. It is a bit more sensitive to the true positives (higher
    precision) than to true negatives (lower recall). This means that it tends to
    miss some of the defect-prone modules in its predictions. However, the decision
    tree model lets us take a look inside the model and explore the pattern that it
    learned from the data. The following code fragment does this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code fragment exports the decision tree in the form of text that
    we print. The `export_text()` function takes two arguments – the first one is
    the decision tree to visualize and the next one is the list of features. In our
    case, the list of features is the list of columns in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The entire decision tree is quite complex in this case, but the first decision
    path looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This decision path looks very similar to a large `if-then` statement, which
    we could write ourselves if we knew the patterns in the data. This pattern is
    not simple, which means that the data is quite complex. It can be non-linear and
    requires complex models to capture the dependencies. It can also require a lot
    of effort to find the right balance between the performance of the model and its
    ability to generalize the data.
  prefs: []
  type: TYPE_NORMAL
- en: So, here is my best practice for working with this kind of model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Best practice #54'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to understand your numerical data, use models that provide explainability.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapters, I advocated for using AutoML models as they are robust
    and save us a lot of trouble finding the right module. However, if we want to
    understand our data a bit better and understand the patterns, we can start with
    models such as decision trees. Their insight into the data provides us with a
    good overview of what we can get out of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a counter-example, let’s look at the data from another module from the same
    dataset. Let’s read it and perform the split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s train a new model for that data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, so good – no errors, no problems. Let’s check the performance of the
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The performance, however, is not as high as it was previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s print the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the results are also quite complex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If we look at the very first decision in this tree and the previous one, it
    is based on the WMC feature. **WMC** means **weighted method per class** and is
    one of the classical software metrics that was introduced in the 1990s by Chidamber
    and Kamerer. The metric captures both the complexity and the size of the class
    (in a way) and it is quite logical that large classes are more defect-prone –
    simply because there is more chance to make a mistake if there is more source
    code. In the case of this model, this is a bit more complicated as the model recognizes
    that the classes with WMC over 36 are more prone to errors than others, apart
    from classes that are over 64.5, which are less prone to errors. The latter is
    also a known phenomenon that large classes are also more difficult to test and
    therefore can contain undiscovered defects.
  prefs: []
  type: TYPE_NORMAL
- en: Here is my next best practice, which is about the explainability of models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Best practice #55'
  prefs: []
  type: TYPE_NORMAL
- en: The best models are those that capture the empirical phenomena in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Although machine learning models can capture any kind of dependencies, the best
    models are the ones that can capture logical, empirical observations. In the previous
    examples, the model could capture the software engineering empirical observations
    related to the size of the classes and their defect-proneness. Having a model
    that captures empirical relations leads to better products and explainable AI.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the training process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From the software engineer’s perspective, the training process is rather simple
    – we fit the model, validate it, and use it. We check how good the model is in
    terms of the performance metrics. If the model is good enough, and we can explain
    it, then we develop the entire product around it, or we use it in a larger software
    product.
  prefs: []
  type: TYPE_NORMAL
- en: When the model does not learn anything useful, we need to understand why this
    is the case and whether there could be another model that can. We can use the
    visualization techniques we learned about in [*Chapter 6*](B19548_06.xhtml#_idTextAnchor074)
    to explore the data and clear it from noise using the techniques from [*Chapter
    4*](B19548_04.xhtml#_idTextAnchor049).
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s explore the process of how the decision tree model learns from the
    data. The `DecisionTree` classifier learns from the provided data by recursively
    partitioning the feature space based on the values of the features in the training
    dataset. It constructs a binary tree where each internal node represents a feature
    and a decision rule based on a threshold value, and each leaf node represents
    a predicted class or outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training is done in steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selecting the best feature**: The classifier evaluates different features
    and determines the one that best separates the data into different classes. This
    is typically done using a measure of impurity or information gain, such as Gini
    impurity or entropy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Splitting the dataset**: Once the best feature has been selected, the classifier
    splits the dataset into two or more subsets based on the values of that feature.
    Each subset represents a different branch or path in the decision tree.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Repeating the process recursively**: The preceding steps are repeated for
    each subset or branch of the decision tree, treating them as separate datasets.
    The process continues until a stopping condition is met, such as reaching a maximum
    depth, a minimum number of samples at a node, or other predefined criteria.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Assigning class labels**: At the leaf nodes of the decision tree, the classifier
    assigns class labels based on the majority class of the samples in that region.
    This means that when making predictions, the classifier assigns the most frequent
    class in the leaf node to the unseen samples that fall into that region.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: During the learning process, the `DecisionTree` classifier aims to find the
    best splits that maximize the separation of classes and minimize the impurity
    within each resulting subset. By recursively partitioning the feature space based
    on the provided training data, the classifier learns decision rules that allow
    it to make predictions for unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that decision trees are prone to overfitting, meaning
    they can memorize the training data too well and not generalize well to new data.
    Techniques such as pruning, limiting the maximum depth, or using ensemble methods
    such as random forest can help mitigate overfitting and improve the performance
    of decision tree models.
  prefs: []
  type: TYPE_NORMAL
- en: We used the random forest classifier previously in this book, so we won’t dive
    into the details here. Although random forests are better at generalizing data,
    they are opaque compared to decision trees. We cannot explore what the model learned
    – we can only explore which features contribute the most to the verdict.
  prefs: []
  type: TYPE_NORMAL
- en: Random forest and opaque models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s train the random forest classifier based on the same data as in the counter-example
    and check whether the model performs better and whether the model uses similar
    features as the `DecisionTree` classifier in the original counter-example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s instantiate, train, and validate the model on the same data using the
    following fragment of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'After evaluating the model, we obtain the following performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Admittedly, these metrics are different than the metrics in the decision trees,
    but the overall performance is not that much different. The difference in accuracy
    of 0.03 is negligible. First, we can extract the important features, reusing the
    same techniques that were presented in [*Chapter 5*](B19548_05.xhtml#_idTextAnchor060):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the set of features used in the decision by executing the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This code helps us understand the importance chart shown in *Figure 10**.2*.
    Here, again, the WMC is the most important feature. This means that a lot of trees
    in the forest are using this metric to make decisions. However, we do not know
    the algorithm since the forest is an ensemble classifier – it uses voting for
    the decisions – meaning that always more than one tree is used when making the
    final call/prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Feature importance chart for the random forest classifier.](img/B19548_10_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Feature importance chart for the random forest classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the model is more complex than just a linear combination of
    these features. This chart illustrates something that is not a best practice,
    but a best experience. So, I will use it as a best practice to illustrate the
    importance of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Best practice #56'
  prefs: []
  type: TYPE_NORMAL
- en: Simple, but explainable, models can often capture data in a good way.
  prefs: []
  type: TYPE_NORMAL
- en: What I’ve learned throughout my experiments with different types of data is
    that if there is a pattern, a simple model will capture it. If there is no pattern,
    or if the data has a lot of exceptions from rules, then even the most complex
    models will have problems in finding the patterns. Therefore, if you cannot explain
    your results, do not use them in your product, as there is a chance that these
    results will make the products quite useless.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a light at the end of the tunnel here. Some models can capture
    very complex patterns, but they are opaque – neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Training deep learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Training a dense neural network involves various steps. First, we prepare the
    data. This typically involves tasks such as feature scaling, handling missing
    values, encoding categorical variables, and splitting the data into training and
    validation sets.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we define the architecture of the dense neural network. This includes
    specifying the number of layers, the number of neurons in each layer, the activation
    functions to be used, and any regularization techniques, such as dropout or batch
    normalization.
  prefs: []
  type: TYPE_NORMAL
- en: Once the model has been defined, we need to initialize it. We create an instance
    of the neural network model based on the defined architecture. This involves creating
    an instance of the neural network class or using a predefined model architecture
    available in a deep learning library. We also need to define a loss function that
    quantifies the error between the predicted output of the model and the actual
    target values. The choice of loss function depends on the nature of the problem,
    such as classification (cross-entropy) or regression (mean squared error).
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the loss function, we need an optimizer. The optimizer algorithm
    will update the weights of the neural network during training. Common optimizers
    include **stochastic gradient descent** (**SGD**), Adam, and RMSprop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we can train the model. Here, we iterate over the training data for multiple
    epochs (passes through the entire dataset). In each epoch, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Forward pass**: We feed a batch of input data into the model and compute
    the predicted output.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Compute loss**: We compare the predicted output with the actual target values
    using the defined loss function to calculate the loss.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Backward pass**: We propagate the loss backward through the network to compute
    the gradients of the weights concerning the loss using backpropagation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Update the weights**: We use the optimizer to update the weights of the neural
    network based on the computed gradients, adjusting the network parameters to minimize
    the loss.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We repeat these steps for each batch in the training data until all batches
    have been processed.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we need to perform the validation process, just like in the previous
    models. Here, we compute a validation metric (such as accuracy or mean squared
    error) to assess how well the model is generalizing to unseen data. This helps
    us monitor the model’s progress and detect overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Once the model has been trained and validated, we can evaluate its performance
    on a separate test dataset that was not used during training or validation. Here,
    we calculate relevant evaluation metrics to assess the model’s accuracy, precision,
    recall, or other desired metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s do this for our dataset. First, we must define the architecture of
    the model using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we define a class called `NeuralNetwork`, which is a subclass of `nn.Module`.
    This class represents our neural network model. It has two fully connected layers
    (`fc1` and `fc2`) with a `ReLU` activation function in between. The network looks
    something like the one shown in *Figure 10**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Neural network used for predicting defects.](img/B19548_10_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Neural network used for predicting defects.
  prefs: []
  type: TYPE_NORMAL
- en: This visualization was created using [http://alexlenail.me/NN-SVG/index.html](http://alexlenail.me/NN-SVG/index.html).
    The number of neurons in the hidden layer is 64, but in this figure, only 16 are
    shown to make it more readable. The network starts with 6 input neurons, then
    64 neurons in the hidden layer (middle), and two neurons for the decision classes
    at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can define the hyperparameters for training the network and instantiate
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we create an instance of the `NeuralNetwork` class called `model` with
    the specified input size, hidden size, and number of output classes, as we defined
    in the first code fragment. We define the loss function (cross-entropy loss) and
    the optimizer (Adam optimizer) to train the model. The data is then converted
    into PyTorch tensors using `torch.Tensor()` and `torch.LongTensor()`. Finally,
    we say that we want to train the model in 10,000 epochs (iterations) with 32 elements
    (data points) in each iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can get the predictions for the test data and obtain the performance
    metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The performance metrics are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: So, this is a bit better than the previous models, but it’s not great. The patterns
    are just not there. We could make the network larger by increasing the number
    of hidden layers, but this does not make the predictions better.
  prefs: []
  type: TYPE_NORMAL
- en: Misleading results – data leaking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the training process, we use one set of data and in the test set, we use
    another set. The best training process is when these two datasets are separate.
    If they are not, we get into something that is called a data leak problem. This
    problem is when we have the same data points in both the train and test sets.
    Let’s illustrate this with an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create a new split, where we have some data points in both
    sets. We can do that by using the split function and setting 20% of the data points
    to the test set. This means that at least 10% of the data points are in both sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use the same code to make predictions on this data and then calculate
    the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The results are better than before. However, they are only better because 10%
    of the data points were used in both the training and the test sets. This means
    that the model performs much worse than the metrics suggest. Hence, we’ve come
    to my next best practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Best practice #56'
  prefs: []
  type: TYPE_NORMAL
- en: Always make sure that the data points in both the train and test sets are separate.
  prefs: []
  type: TYPE_NORMAL
- en: Although we made this mistake on purpose here, it is quite easy to make it in
    practice. Please note the `random_state=42` parameter in the split function. Setting
    it explicitly ensures that the split is repeatable. However, if we do not do this,
    we can end up with different splits every time we make them and thus we can end
    up with the data leak problem.
  prefs: []
  type: TYPE_NORMAL
- en: The data leak problem is even more difficult to discover when we’re working
    with images or text. Just the fact that an image comes from two different files
    does not guarantee that it is different. For example, images taken one after another
    during highway driving will be different but will not be too different, and if
    they end up in test and train sets, we get a whole new dimension of the data leak
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed various topics related to machine learning and
    neural networks. We explained how to read data from an Excel file using the pandas
    library and prepare the dataset for training a machine learning model. We explored
    the use of decision tree classifiers and demonstrated how to train a decision
    tree model using scikit-learn. We also showed how to make predictions using the
    trained model.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we discussed how to switch from a decision tree classifier to a random
    forest classifier, which is an ensemble of decision trees. We explained the necessary
    code modifications and provided an example. Next, we shifted our focus to using
    a dense neural network in PyTorch. We described the process of creating the neural
    network architecture, training the model, and making predictions using the trained
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we explained the steps involved in training a dense neural network,
    including data preparation, model architecture, initializing the model, defining
    a loss function and optimizer, the training loop, validation, hyperparameter tuning,
    and evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, we covered a range of topics related to machine learning algorithms,
    including decision trees, random forests, and dense neural networks, along with
    their respective training processes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter we explore how to train more advanced machine learning models
    - for example AutoEncoders.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Chidamber, S.R. and C.F. Kemerer, A metrics suite for object oriented design.
    IEEE Transactions on Software Engineering, 1994\. 20(6):* *p. 476–493.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
