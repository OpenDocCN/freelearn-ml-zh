["```py\nimport helpers\nreload(helpers)\n```", "```py\nmodel = helpers.build_model('images/Van_Gogh-Starry_Night.jpg')\n```", "```py\nmodel.load_weights('data/van-gogh-starry-night_style.h5')\n```", "```py\nmodel.summary()\n```", "```py\n____________________________________________________________________\nLayer (type) Output Shape Param # Connected to \n====================================================================\ninput_1 (InputLayer) (None, 320, 320, 3) 0 \n____________________________________________________________________\nzero_padding2d_1 (ZeroPadding2D) (None, 400, 400, 3) 0 input_1[0][0] \n____________________________________________________________________\nconv2d_1 (Conv2D) (None, 400, 400, 64) 15616 zero_padding2d_1[0][0] \n____________________________________________________________________\nbatch_normalization_1 (BatchNorm (None, 400, 400, 64) 256 conv2d_1[0][0] \n____________________________________________________________________\nactivation_1 (Activation) (None, 400, 400, 64) 0 batch_normalization_1[0][0] \n____________________________________________________________________\n...\n...\n____________________________________________________________________\nres_crop_1 (Lambda) (None, 92, 92, 64) 0 add_1[0][0] \n____________________________________________________________________\n...\n... \n____________________________________________________________________\nrescale_output (Lambda) (None, 320, 320, 3) 0 conv2d_16[0][0] \n====================================================================\nTotal params: 552,003\nTrainable params: 550,083\nNon-trainable params: 1,920\n```", "```py\ndef res_crop(x):\n    return x[:, 2:-2, 2:-2] \n```", "```py\nres_crop_3_layer = [layer for layer in model.layers if layer.name == 'res_crop_3'][0] \n\nprint(\"res_crop_3_layer input shape {}, output shape {}\".format(\n    res_crop_3_layer.input_shape, res_crop_3_layer.output_shape))\n```", "```py\ndef rescale_output(x):\n    return (x+1)*127.5 \n```", "```py\nrescale_output_layer = [layer for layer in model.layers if layer.name == 'rescale_output'][0]\n\nprint(\"rescale_output_layer input shape {}, output shape {}\".format(\n    rescale_output_layer.input_shape, \n    rescale_output_layer.output_shape))\n```", "```py\n!pip install coremltools\n```", "```py\nimport coremltools\nfrom coremltools.proto import NeuralNetwork_pb2, FeatureTypes_pb2\n```", "```py\ncoreml_model = coremltools.converters.keras.convert(\n    model, \n    input_names=['image'], \n    image_input_names=['image'], \n    output_names=\"output\")\n```", "```py\ndef convert_lambda(layer):\n    if layer.function.__name__ == 'rescale_output':\n        params = NeuralNetwork_pb2.CustomLayerParams()\n        params.className = \"RescaleOutputLambda\"\n        params.description = \"Rescale output using ((x+1)*127.5)\"\n        return params\n    elif layer.function.__name__ == 'res_crop':\n        params = NeuralNetwork_pb2.CustomLayerParams()\n        params.className = \"ResCropBlockLambda\"\n        params.description = \"return x[:, 2:-2, 2:-2]\"\n        return params\n    else:\n        raise Exception('Unknown layer')\n    return None \n```", "```py\ncoreml_model = coremltools.converters.keras.convert(\n    model, \n    input_names=['image'], \n    image_input_names=['image'], \n    output_names=\"output\",\n    add_custom_layers=True,\n    custom_conversion_functions={ \"Lambda\": convert_lambda })\n```", "```py\ncoreml_model.author = 'Joshua Newnham'\ncoreml_model.license = 'BSD'\ncoreml_model.short_description = 'Fast Style Transfer based on the style of Van Gogh Starry Night'\ncoreml_model.input_description['image'] = 'Preprocessed content image'\ncoreml_model.output_description['output'] = 'Stylized content image' \n```", "```py\nspec = coreml_model.get_spec() \n```", "```py\noutput = [output for output in spec.description.output if output.name == 'output'][0]\n```", "```py\noutput\n```", "```py\nname: \"output\"\nshortDescription: \"Stylized content image\"\ntype {\n  multiArrayType {\n    shape: 3\n    shape: 320\n    shape: 320\n    dataType: DOUBLE\n  }\n}\n```", "```py\noutput.type.imageType.colorSpace = FeatureTypes_pb2.ImageFeatureType.ColorSpace.Value('RGB') \n\noutput.type.imageType.width = width \noutput.type.imageType.height = height\n\ncoreml_model = coremltools.models.MLModel(spec) \n```", "```py\nname: \"output\"\nshortDescription: \"Stylized content image\"\ntype {\n  imageType {\n    width: 320\n    height: 320\n    colorSpace: RGB\n  }\n}\n```", "```py\ncoreml_model.save('output/FastStyleTransferVanGoghStarryNight.mlmodel')\n```", "```py\nlazy var vanCoghModel : VNCoreMLModel = {\n    do{\n        let model = try VNCoreMLModel(for: FastStyleTransferVanGoghStarryNight().model)\n        return model\n    } catch{\n        fatalError(\"Failed to obtain VanCoghModel\")\n    }\n}()\n```", "```py\nvar model : VNCoreMLModel{\n    get{\n        if self.style == .VanCogh{\n            return self.vanCoghModel\n        }\n\n        // default\n        return self.vanCoghModel\n    }\n}\n```", "```py\nfunc getRequest() -> VNCoreMLRequest{\n    let request = VNCoreMLRequest(\n        model: self.model,\n        completionHandler: { [weak self] request, error in\n            self?.processRequest(for: request, error: error)\n        })\n    request.imageCropAndScaleOption = .centerCrop\n    return request\n}\n```", "```py\npublic func processImage(ciImage:CIImage){        \n    DispatchQueue.global(qos: .userInitiated).async {\n let handler = VNImageRequestHandler(ciImage: ciImage)\n do {\n try handler.perform([self.getRequest()])\n } catch {\n print(\"Failed to perform classification.\\n\\(error.localizedDescription)\")\n }\n    }\n}\n```", "```py\nfunc processRequest(for request:VNRequest, error: Error?){\n    guard let results = request.results else {\n        print(\"ImageProcess\", #function, \"ERROR:\",\n              String(describing: error?.localizedDescription))\n        self.delegate?.onImageProcessorCompleted(\n            status: -1,\n            stylizedImage: nil)\n        return\n    }\n\n    let stylizedPixelBufferObservations =\n        results as! [VNPixelBufferObservation]\n\n    guard stylizedPixelBufferObservations.count > 0 else {\n        print(\"ImageProcess\", #function,\"ERROR:\",\n              \"No Results\")\n        self.delegate?.onImageProcessorCompleted(\n            status: -1,\n            stylizedImage: nil)\n        return\n    }\n\n    guard let cgImage = stylizedPixelBufferObservations[0]\n        .pixelBuffer.toCGImage() else{\n        print(\"ImageProcess\", #function, \"ERROR:\",\n              \"Failed to convert CVPixelBuffer to CGImage\")\n        self.delegate?.onImageProcessorCompleted(\n            status: -1,\n            stylizedImage: nil)\n        return\n    }\n\n    DispatchQueue.main.sync {\n        self.delegate?.onImageProcessorCompleted(\n            status: 1,\n            stylizedImage:cgImage)\n    }\n}\n```", "```py\nimport Foundation\nimport CoreML\nimport Accelerate\n\n@objc(RescaleOutputLambda) class RescaleOutputLambda: NSObject, MLCustomLayer {    \n    required init(parameters: [String : Any]) throws {\n        super.init()\n    }\n\n    func setWeightData(_ weights: [Data]) throws {\n\n    }\n\n    func outputShapes(forInputShapes inputShapes: [[NSNumber]]) throws\n        -> [[NSNumber]] {\n\n    }\n\n    func evaluate(inputs: [MLMultiArray], outputs: [MLMultiArray]) throws {\n\n    }\n}\n```", "```py\nfunc outputShapes(forInputShapes inputShapes: [[NSNumber]]) throws\n    -> [[NSNumber]] {\n        return inputShapes\n}\n```", "```py\nfunc evaluate(inputs: [MLMultiArray],outputs: [MLMultiArray]) throws {    \n    let rescaleAddition = 1.0\n let rescaleMulitplier = 127.5\n\n for (i, input) in inputs.enumerated(){\n // expecting [1, 1, Channels, Kernel Width, Kernel Height]\n let shape = input.shape \n for c in 0..<shape[2].intValue{\n for w in 0..<shape[3].intValue{\n for h in 0..<shape[4].intValue{\n let index = [\n NSNumber(value: 0),\n NSNumber(value: 0),\n NSNumber(value: c),\n NSNumber(value: w),\n NSNumber(value: h)]\n let outputValue = NSNumber(\n value:(input[index].floatValue + rescaleAddition)\n * rescaleMulitplier)\n\n outputs[i][index] = outputValue\n }\n }\n }\n }\n} \n```", "```py\nimport Foundation\nimport CoreML\nimport Accelerate\n\n@objc(ResCropBlockLambda) class ResCropBlockLambda: NSObject, MLCustomLayer {\n\n    required init(parameters: [String : Any]) throws {\n        super.init()\n    }\n\n    func setWeightData(_ weights: [Data]) throws {\n    }\n\n    func outputShapes(forInputShapes inputShapes: [[NSNumber]]) throws\n        -> [[NSNumber]] {\n    }\n\n    func evaluate(inputs: [MLMultiArray], outputs: [MLMultiArray]) throws {\n    }\n}\n```", "```py\nfunc outputShapes(forInputShapes inputShapes: [[NSNumber]]) throws\n    -> [[NSNumber]] {        \n return [[NSNumber(value:inputShapes[0][0].intValue),\n NSNumber(value:inputShapes[0][1].intValue),\n NSNumber(value:inputShapes[0][2].intValue),\n NSNumber(value:inputShapes[0][3].intValue - 4),\n NSNumber(value:inputShapes[0][4].intValue - 4)]];\n}\n```", "```py\nfunc evaluate(inputs: [MLMultiArray], outputs: [MLMultiArray]) throws {\n for (i, input) in inputs.enumerated(){\n\n // expecting [1, 1, Channels, Kernel Width, Kernel Height]\n let shape = input.shape\n for c in 0..<shape[2].intValue{\n for w in 2...(shape[3].intValue-4){\n for h in 2...(shape[4].intValue-4){\n let inputIndex = [\n NSNumber(value: 0),\n NSNumber(value: 0),\n NSNumber(value: c),\n NSNumber(value: w),\n NSNumber(value: h)]\n\n let outputIndex = [\n NSNumber(value: 0),\n NSNumber(value: 0),\n NSNumber(value: c),\n NSNumber(value: w-2),\n NSNumber(value: h-2)]\n\n outputs[i][outputIndex] = input[inputIndex]\n }\n }\n }\n }\n} \n```", "```py\nfunc evaluate(inputs: [MLMultiArray], outputs: [MLMultiArray]) throws {\n    var rescaleAddition : Float = 1.0\n    var rescaleMulitplier : Float = 127.5\n\n for (i, _) in inputs.enumerated(){\n\n let input = inputs[i]\n let output = outputs[i]\n\n let count = input.count\n let inputPointer = UnsafeMutablePointer<Float>(\n OpaquePointer(input.dataPointer)\n )\n let outputPointer = UnsafeMutablePointer<Float>(\n OpaquePointer(output.dataPointer)\n )\n\n vDSP_vsadd(inputPointer, 1,\n &rescaleAddition,\n outputPointer, 1,\n vDSP_Length(count))\n\n vDSP_vsmul(outputPointer, 1,\n &rescaleMulitplier,\n outputPointer, 1,\n vDSP_Length(count))\n }\n}\n```", "```py\nvDSP_vsadd(inputPointer, 1,\n           &rescaleAddition,\n           outputPointer, 1,\n           vDSP_Length(count))\n```", "```py\nvDSP_vsmul(outputPointer, 1,\n           &rescaleMulitplier,\n           outputPointer, 1,\n           vDSP_Length(count))\n```", "```py\n#include <metal_stdlib>\nusing namespace metal;\n\nkernel void rescale(\n    texture2d_array<half, access::read> inTexture [[texture(0)]],\n    texture2d_array<half, access::write> outTexture [[texture(1)]],\n    ushort3 gid [[thread_position_in_grid]])\n{\n    if (gid.x >= outTexture.get_width() || gid.y >= outTexture.get_height())\n    {\n        return;\n    }\n\n    const float4 x = float4(inTexture.read(gid.xy, gid.z));\n    const float4 y = (1.0f + x) * 127.5f;\n\n    outTexture.write(half4(y), gid.xy, gid.z);\n}  \n```", "```py\nimport Metal\n```", "```py\n@objc(RescaleOutputLambda) class RescaleOutputLambda: NSObject, MLCustomLayer {\n\n let computePipeline: MTLComputePipelineState\n\n    required init(parameters: [String : Any]) throws {\n let device = MTLCreateSystemDefaultDevice()!\n let library = device.makeDefaultLibrary()!\n let rescaleFunction = library.makeFunction(name: \"rescale\")!\n self.computePipeline = try! device.makeComputePipelineState(function: rescaleFunction)\n\n        super.init()\n    }\n    ...\n}\n```", "```py\nfunc encode(commandBuffer: MTLCommandBuffer,\n            inputs: [MTLTexture],\n            outputs: [MTLTexture]) throws {\n\n    guard let encoder = commandBuffer.makeComputeCommandEncoder() else{\n        return\n    }\n\n    let w = computePipeline.threadExecutionWidth\n    let h = computePipeline.maxTotalThreadsPerThreadgroup / w\n    let threadGroupSize = MTLSizeMake(w, h, 1)\n\n    for i in 0..<inputs.count {\n        let threadGroups = MTLSizeMake(\n            (inputs[i].width + threadGroupSize.width - 1) /\n                threadGroupSize.width,\n            (inputs[i].height+ threadGroupSize.height - 1) /\n                threadGroupSize.height,\n            (inputs[i].arrayLength + threadGroupSize.depth - 1) /\n                threadGroupSize.depth)\n\n        encoder.setTexture(inputs[i], index: 0)\n        encoder.setTexture(outputs[i], index: 1)\n        encoder.setComputePipelineState(computePipeline)\n        encoder.dispatchThreadgroups(\n            threadGroups,\n            threadsPerThreadgroup:\n            threadGroupSize)\n        encoder.endEncoding()\n}\n```", "```py\nencoder.setTexture(inputs[i], index: 0)\nencoder.setTexture(outputs[i], index: 1)\n```", "```py\nencoder.setComputePipelineState(computePipeline)\n```", "```py\nencoder.dispatchThreadgroups(\n    threadGroups,\n    threadsPerThreadgroup:\n    threadGroupSize)\nencoder.endEncoding()\n```", "```py\ntry:\n    import coremltools\nexcept:\n    !pip install coremltools    \n    import coremltools \n```", "```py\ncoreml_model = coremltools.models.MLModel('output/FastStyleTransferVanGoghStarryNight.mlmodel')\n```", "```py\n fp16_coreml_model = coremltools.utils.convert_neural_network_weights_to_fp16(coreml_model)\n```", "```py\nfp16_coreml_model.save('output/fp16_FastStyleTransferVanGoghStarryNight.mlmodel')\n```", "```py\nfrom coremltools.models.neural_network import quantization_utils as quant_utils\n```", "```py\nlq8_coreml_model = quant_utils.quantize_weights(coreml_model, 8, 'linear')\nlq4_coreml_model = quant_utils.quantize_weights(coreml_model, 4, 'linear')\nkm8_coreml_model = quant_utils.quantize_weights(coreml_model, 8, 'kmeans')\nkm4_coreml_model = quant_utils.quantize_weights(coreml_model, 4, 'kmeans')\n```", "```py\ncoremltools.models.MLModel(lq8_coreml_model) \\\n    .save('output/lq8_FastStyleTransferVanGoghStarryNight.mlmodel')\ncoremltools.models.MLModel(lq4_coreml_model) \\\n    .save('output/lq4_FastStyleTransferVanGoghStarryNight.mlmodel')\ncoremltools.models.MLModel(km8_coreml_model) \\\n    .save('output/km8_FastStyleTransferVanGoghStarryNight.mlmodel')\ncoremltools.models.MLModel(km4_coreml_model) \\\n    .save('output/km8_FastStyleTransferVanGoghStarryNight.mlmodel')\n```"]