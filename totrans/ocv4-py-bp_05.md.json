["```py\nimport rawpy\nimport cv2\n```", "```py\ndef load_image(path, bps=16):\n```", "```py\n    if path.suffix == '.CR2':\n        with rawpy.imread(str(path)) as raw:\n            data = raw.postprocess(no_auto_bright=True,\n                                   gamma=(1, 1),\n                                   output_bps=bps)\n```", "```py\n        return cv2.cvtColor(data, cv2.COLOR_RGB2BGR)\n```", "```py\n    else:\n        return cv2.imread(str(path))\n```", "```py\ndef load_14bit_gray(path):\n    img = load_image(path, bps=16)\n    return (cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) / 4).astype(np.uint16)\n```", "```py\n    images = [load_14bit_gray(p) for p in args.images]\n    fig, axes = plt.subplots(2, len(images), sharey=False)\n    for i, gray in enumerate(images):\n        axes[0, i].imshow(gray, cmap='gray', vmax=2**14)\n        axes[1, i].hist(gray.flatten(), bins=256)\n```", "```py\n@functools.lru_cache(maxsize=None)\ndef gamma_transform(x, gamma, bps=14):\n    return np.clip(pow(x / 2**bps, gamma) * 255.0, 0, 255)\n```", "```py\ndef apply_gamma(img, gamma, bps=14):\n    corrected = img.copy()\n    for i, j in itertools.product(range(corrected.shape[0]),\n                                  range(corrected.shape[1])):\n        corrected[i, j] = gamma_transform(corrected[i, j], gamma, bps=bps)\n    return corrected\n```", "```py\n if __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('raw_image', type=Path,\n                        help='Location of a .CR2 file.')\n    parser.add_argument('--gamma', type=float, default=0.3)\n    args = parser.parse_args()\n```", "```py\n    gray = load_14bit_gray(args.raw_image)\n```", "```py\n    normal = np.clip(gray / 64, 0, 255).astype(np.uint8)\n```", "```py\n    corrected = apply_gamma(gray, args.gamma)\n```", "```py\n    fig, axes = plt.subplots(2, 2, sharey=False)\n    for i, img in enumerate([normal, corrected]):\n        axes[0, i].imshow(img, cmap='gray', vmax=255)\n        axes[1, i].hist(img.flatten(), bins=256)\n```", "```py\n    plt.show()\n```", "```py\ndef exposure_strength(path, iso_ref=100, f_stop_ref=6.375):\n```", "```py\n    with open(path, 'rb') as infile:\n        tags = exifread.process_file(infile)\n```", "```py\n    [f_stop] = tags['EXIF ApertureValue'].values\n    rel_aperture_area = 1 / (f_stop.num / f_stop.den / f_stop_ref) ** 2\n```", "```py\n    [iso_speed] = tags['EXIF ISOSpeedRatings'].values\n    iso_multiplier = iso_speed / iso_ref\n```", "```py\n    [exposure_time] = tags['EXIF ExposureTime'].values\n    exposure_time_float = exposure_time.num / exposure_time.den\n    return rel_aperture_area * exposure_time_float * iso_multipli\n```", "```py\n[0.016666666666666666, 0.004, 0.00625, 0.01, 0.025, 0.04, 0.0625\n```", "```py\nimport argparse\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    img_group = parser.add_mutually_exclusive_group(required=True)\n    img_group.add_argument('--image-dir', type=Path)\n    img_group.add_argument('--images', type=Path, nargs='+')\n    args = parser.parse_args()\n\n    if args.image_dir:\n        args.images = sorted(args.image_dir.iterdir())\n```", "```py\n    images = [load_image(p, bps=8) for p in args.images]\n```", "```py\n    times = [exposure_strength(p)[0] for p in args.images]\n    times_array = np.array(times, dtype=np.float32)\n```", "```py\n    cal_debevec = cv2.createCalibrateDebevec(int samples=200)\n    crf_debevec = cal_debevec.process(images, times=times_array)\n```", "```py\n    merge_debevec = cv2.createMergeDebevec()\n    hdr_debevec = merge_debevec.process(images, times=times_array.copy(),\n                                        response=crf_debevec)\n```", "```py\n    tonemap = cv2.createTonemap(gamma=2.2)\n    res_debevec = tonemap.process(hdr_debevec)\n```", "```py\n    res_8bit = np.clip(res_debevec * 255, 0, 255).astype('uint8')\n```", "```py\n    plt.imshow(res_8bit)\n    plt.show()\n```", "```py\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    img_group = parser.add_mutually_exclusive_group(required=True)\n    img_group.add_argument('--image-dir', type=Path)\n    img_group.add_argument('--images', type=Path, nargs='+')\n    args = parser.parse_args()\n\n    if args.image_dir:\n        args.images = sorted(args.image_dir.iterdir())\n    return args\n```", "```py\ndef largest_connected_subset(images):\n    finder = cv2.xfeatures2d_SURF.create()\n    all_img_features = [cv2.detail.computeImageFeatures2(finder, img)\n                        for img in images]\n```", "```py\n    matcher = cv2.detail.BestOf2NearestMatcher_create(False, 0.6)\n    pair_matches = matcher.apply2(all_img_features)\n    matcher.collectGarbage()\n```", "```py\n    _conn_indices = cv2.detail.leaveBiggestComponent(all_img_features, pair_matches, 0.4)\n    conn_indices = [i for [i] in _conn_indices]\n    if len(conn_indices) < 2:\n        raise RuntimeError(\"Need 2 or more connected images.\")\n\n    conn_features = np.array([all_img_features[i] for i in conn_indices])\n    conn_images = [images[i] for i in conn_indices]\n```", "```py\n    if len(conn_images) < len(images):\n        pair_matches = matcher.apply2(conn_features)\n        matcher.collectGarbage()\n\n    return conn_images, conn_features, pair_matches\n```", "```py\ndef find_camera_parameters(features, pair_matches):\n    estimator = cv2.detail_HomographyBasedEstimator()\n```", "```py\n    success, cameras = estimator.apply(features, pair_matches, None)\n    if not success:\n        raise RuntimeError(\"Homography estimation failed.\")\n```", "```py\n    for cam in cameras:\n        cam.R = cam.R.astype(np.float32)\n```", "```py\n    return cameras\n```", "```py\n    warper = cv2.PyRotationWarper('plane', 1)\n```", "```py\n    stitch_sizes, stitch_corners = [], []\n    for i, img in enumerate(conn_images):\n        sz = img.shape[1], img.shape[0]\n        K = cameras[i].K().astype(np.float32)\n        roi = warper.warpRoi(sz, K, cameras[i].R)\n        stitch_corners.append(roi[0:2])\n        stitch_sizes.append(roi[2:4])\n```", "```py\n    canvas_size = cv2.detail.resultRoi(corners=stitch_corners, sizes=stitch_sizes)\n```", "```py\n    blender = cv2.detail_MultiBandBlender()\n    blend_width = np.sqrt(canvas_size[2] * canvas_size[3]) * 5 / 100\n    blender.setNumBands((np.log(blend_width) / np.log(2.) - 1.).astype(np.int))\n    blender.prepare(canvas_size)\n```", "```py\n    for i, img in enumerate(conn_images):\n        K = cameras[i].K().astype(np.float32)\n        corner, image_wp = warper.warp(img, K, cameras[i].R,\n                                       cv2.INTER_LINEAR, cv2.BORDER_REFLECT)\n```", "```py\n        mask = 255 * np.ones((img.shape[0], img.shape[1]), np.uint8)\n        _, mask_wp = warper.warp(mask, K, cameras[i].R,\n                                 cv2.INTER_NEAREST, cv2.BORDER_CONSTANT)\n```", "```py\n        image_warped_s = image_wp.astype(np.int16)\n        blender.feed(cv2.UMat(image_warped_s), mask_wp, stitch_corners[i])\n```", "```py\n    result, result_mask = blender.blend(None, None)\n    cv2.imwrite('result.jpg', result)\n```", "```py\n    zoomx = 600.0 / result.shape[1]\n    dst = cv2.normalize(src=result, dst=None, alpha=255.,\n                        norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    dst = cv2.resize(dst, dsize=None, fx=zoomx, fy=zoomx)\n    cv2.imshow('panorama', dst)\n    cv2.waitKey()\n```", "```py\n    images = [load_image(p, bps=8) for p in args.images]\n\n    stitcher = cv2.Stitcher_create()\n    (status, stitched) = stitcher.stitch(images)\n```"]