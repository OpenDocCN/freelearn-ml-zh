<html><head></head><body><div class="chapter" title="Chapter&#xA0;3.&#xA0;Recommendation Engines Explained" id="aid-KVCC1"><div class="titlepage"><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Recommendation Engines Explained</h1></div></div></div><p>In <a class="link" title="Chapter 2. Build Your First Recommendation Engine" href="part0020.xhtml#aid-J2B82">Chapter 2</a>, <span class="emphasis"><em>Build Your First Recommendation Engine,</em></span> we learned how to build a basic recommender system using R. With introductions to various recommender systems in <a class="link" title="Chapter 1. Introduction to Recommendation Engines" href="part0014.xhtml#aid-DB7S1">Chapter 1</a>, <span class="emphasis"><em>Introduction to Recommendation Engines,</em></span> we have got a fair idea about what a recommender system is and why a recommender system is important in the current age of data explosion. In this chapter we will learn about various types of recommender systems in detail. This chapter explains Neighborhood similarity-based recommendations, personalized recommendation engines, model-based recommender systems, and hybrid recommendation engines.</p><p>The following are the different subtypes of recommender system covered in this chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Neighborhood-based recommendation engines:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">User-based collaborative filtering</li><li class="listitem">Item-based collaborative filtering</li></ul></div></li><li class="listitem">Personalized recommendation engines:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Content-based recommendation engines</li><li class="listitem">Context-aware recommendation engines</li></ul></div></li><li class="listitem">Model-based recommendation engines:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">ML-based recommendation engines</li><li class="listitem">Classification - SVM/KNN</li><li class="listitem">Matrix Factorization</li><li class="listitem">Singular value decomposition</li><li class="listitem">Alternating Least Squares</li><li class="listitem">Hybrid recommendation engines</li></ul></div></li></ul></div><div class="section" title="Evolution of recommendation engines"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec15"/>Evolution of recommendation engines</h1></div></div></div><p>Over the years, recommender systems have evolved, from basic nearest neighborhood methods to personalized recommenders to context-aware recommendations, from batch-mode recommendations to real-time recommendations, from basic heuristic approaches such as similarity calculation to more accurate, complex machine-learning approaches.</p><p>In the early stages of these recommender systems, only user ratings on products were used for generating recommendations. At this time, researchers used only the available ratings information. They simply applied heuristic approaches such as similarity calculation using Euclidean distances, the Pearson coefficient, cosine similarity, and so on. These approaches were well received and surprisingly they perform quite well even today.</p><p>This first generation of recommendation engines is called collaborative filtering or neighborhood method recommenders. Though they perform very well, these recommenders come with their own set of limitations such as cold-start problems; that is to say, they failed to recommend products to new users with no rating information and recommend new products with no ratings to the users. Also these recommenders failed to handle scenarios where the data is very sparse, so user ratings on products are much less.</p><p>In order to overcome these limitations, new approaches have been developed. For example, in order to handle very large user-rating with high data sparsity, mathematical approaches such as Matrix Factorization and singular value decomposition methods have been used.</p><p>To handle the cold-start problem, new approaches such as content-based recommendation systems have been developed. These recommender systems opened the door to many more opportunities such as personalized recommenders systems, which enabled them to recommend products to each user on an individual level. In this approach, instead of rating information, user personal preferences and product features are considered.</p><div class="mediaobject"><img src="../Images/image00227.jpeg" alt="Evolution of recommendation engines"/></div><p style="clear:both; height: 1em;"> </p><p>In the beginning, similarity calculations were used in content-based recommenders, but with advancements in technology and infrastructure more advanced methods such as machine-learning models have replaced the heuristic methods. These new machine models have improved the accuracy of the recommendations.</p><p>Though content-based recommenders have solved many of the shortcomings of collaborative filtering, these have their own inherent shortcomings such as serendipity, that is to say not being able to recommend new items outside the user's preference scope, which collaborative filtering can do.</p><p>To solve this problem, researchers started combining different recommendation models to come up with hybrid recommendation models, which are much more powerful than any of the individual models.</p><p>With personal successful implementations of personalized recommendation engines, people started extending the personalization to other dimensions called contexts, such as the addition of location, time, group, and so on, and changed the set of recommendations with each context.</p><p>With advancements in technology such as big data ecosystems, in-memory analytic tools such as Apache Spark, and recommendations in real time, the capability of handling very large databases has become possible.</p><p>Currently we are moving into more personalization of aspects such as temporal dimension and ubiquitous ways of recommendation.</p><p>In the technology aspect the recommendations are moving from machine-learning approaches to more advanced neural network deep-learning approaches.</p></div></div>
<div class="section" title="Nearest neighborhood-based recommendation engines"><div class="titlepage" id="aid-LTSU2"><div><div><h1 class="title"><a id="ch03lvl1sec16"/>Nearest neighborhood-based recommendation engines</h1></div></div></div><p>As the name suggests, neighborhood-based recommender systems considers the preferences or likes of the user community or users of the neighborhood of an active user before making suggestions or recommendations to the active user. The idea for neighborhood-based recommenders is very simple: given the ratings of a user, find all the users similar to the active user who had similar preferences in the past and then make predictions regarding all unknown products that the active user has not rated but are being rated in their neighborhood:</p><div class="mediaobject"><img src="../Images/image00228.jpeg" alt="Nearest neighborhood-based recommendation engines"/></div><p style="clear:both; height: 1em;"> </p><p>While considering the preferences or tastes of neighbors, we first calculate how similar the other users are to the active user and then unrated items from the user community are recommended to the user following predictions. Here the active user is the person to whom the system is serving recommendations. Since similarity calculations are involved, these recommender systems are also called similarity-based recommender systems. Also, since preferences or tastes are considered collaboratively from a pool of users, these recommender systems are also called collaborative filtering recommender systems. In these types of systems, the main actors are the users, products, and user's preference information such as rating/ranking/liking towards the products.</p><p>The following image is an example from Amazon showing a neighborhood case:</p><div class="mediaobject"><img src="../Images/image00229.jpeg" alt="Nearest neighborhood-based recommendation engines"/></div><p style="clear:both; height: 1em;"> </p><p>These heuristic-based methods are based on the following assumptions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">People with similar preferences in the past have similar preferences in the future</li><li class="listitem">People's preferences will remain stable and consistent in the future</li></ul></div><p>The collaborative filtering systems come in two flavors:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">User-based collaborative filtering</li><li class="listitem">Item-based collaborative filtering</li></ul></div><p>These neighborhood methods are employed when we have only the users' interaction data of the products, such as ratings, like/unlike, view/not. Unlike content-based recommendations, which will be explained in the next section, they do not consider any features of the products or personal preferences of the user for the products:</p><div class="mediaobject"><img src="../Images/image00230.jpeg" alt="Nearest neighborhood-based recommendation engines"/></div><p style="clear:both; height: 1em;"> </p><div class="section" title="User-based collaborative filtering"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec15"/>User-based collaborative filtering</h2></div></div></div><p>As previously mentioned, the basic intuition behind user-based collaborative filtering systems is that people with similar tastes in the past will like similar items in future as well. For example, if user A and user B have very similar purchase histories and if user A buys a new book which user B has not yet seen then we can suggest this book to user B as they have similar tastes.</p><p>Let us try to understand user-based collaborative filtering with an example:</p><p><span class="strong"><strong>Problem Statement:</strong></span> Imagine we have a dataset used in <a class="link" title="Chapter 2. Build Your First Recommendation Engine" href="part0020.xhtml#aid-J2B82">Chapter 2</a>, <span class="emphasis"><em>Build Your First Recommendation Engine</em></span> containing the reviewers' ratings given to movies on a movie review site. The task at hand is to recommend movies to the reviewers:</p><div class="mediaobject"><img src="../Images/image00231.jpeg" alt="User-based collaborative filtering"/></div><p style="clear:both; height: 1em;"> </p><p>Before we learn the recommendation approach, the first step is to analyze the data at hand. Let us analyze the data step-by-step as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A collection of users who have interacted with the application</li><li class="listitem">A movie catalog of all the available movies</li><li class="listitem">We have individual users' ratings of movies</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="tip4"/>Tip</h3><p>Note that each user has not rated all of the movies but only a few movies from the entire catalog.</p></div><p>The first step is to find similar users for an active user and then suggest new movies that this active user has not seen but similar users have seen.</p><p>This can be summarized in two steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Calculate the similarity between users using the rating information of the movies.</li><li class="listitem">For each active user, consider the movies that are not rated by them but rated by other users. Predict the unknown ratings for the non-rated movies for the active user.</li></ol><div style="height:10px; width: 1px"/></div><p>In the preceding tabular data, let us recommend new movies to our active user, Jack Mathews:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The first step is to look for similar users to Jack. We observe by looking at the dataset that Gene Seymour and Mick Lasalle are very similar to Jack Mathews.</li><li class="listitem">The similarity between users is calculated based on the ratings given by users. The most common approaches for calculating the similarity are Euclidean distance and the Pearson correlation coefficient.</li><li class="listitem">For now we choose Euclidean distance to find the similarity calculation given by the equation that follows:</li></ol><div style="height:10px; width: 1px"/></div><div class="mediaobject"><img src="../Images/image00232.jpeg" alt="User-based collaborative filtering"/></div><p style="clear:both; height: 1em;"> </p><p>The intuition behind using Euclidean distance is that we represent users, movies, and ratings as points in a vector space with users on the <span class="emphasis"><em>x</em></span> axis, movies on the <span class="emphasis"><em>y</em></span> axis, and ratings as points in vector space. Now that we have projected our data into vector space, similarity or closeness between two points can be calculated using Euclidean distance, and the Pearson correlation coefficient. The detailed explanation for the similarity measures will be explained in <a class="link" title="Chapter 4. Data Mining Techniques Used in Recommendation Engines" href="part0029.xhtml#aid-RL0A2">Chapter 4</a>, <span class="emphasis"><em>Data Mining Techniques Used in Recommendation Engines</em></span>.</p><div class="mediaobject"><img src="../Images/image00233.jpeg" alt="User-based collaborative filtering"/></div><p style="clear:both; height: 1em;"> </p><p>Using the previous equation we can calculate the similarity between all the reviewers as shown in the table. We observe from the table that our active user, Toby, is most similar to Lisa Rose.</p><p>As a second step we predict the ratings for the unknown movie <span class="emphasis"><em>Just My Luck</em></span> for Jack by calculating the weighted average of the ratings given by other reviewers for <span class="emphasis"><em>Just My Luck</em></span> given in the following:</p><p>The rating for Jack for the <span class="emphasis"><em>Just my Luck</em></span> movie is given by the following:</p><p><span class="emphasis"><em>(3*0.9285+1.5*0.944+3*0.755+2*0.327)/(0.8934051+0.3812464+0.9912407+0.9244735)= 2.23</em></span></p><p>In the above equation, we have multiplied the similarity values of all reviewers with Jack by the ratings given by them to the <span class="emphasis"><em>Just My Luck</em></span> movie and then summed all the values. This total sum is divided by the sum of similarity values to normalize the final rating. Similarly we can predict unknown movie ratings for all the reviews and then recommendations can be made.</p></div><div class="section" title="Item-based collaborative filtering"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec16"/>Item-based collaborative filtering</h2></div></div></div><p>In item-based collaborative filtering recommender systems, unlike user-based collaborative filtering, we use similarity between items instead of similarity between users. The basic intuition for item-based recommender systems is that if a user liked item A in the past they might like item B, which is similar to item A:</p><div class="mediaobject"><img src="../Images/image00234.jpeg" alt="Item-based collaborative filtering"/></div><p style="clear:both; height: 1em;"> </p><p>In user-based collaborative filtering, there are a few downs sides:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The system suffers with performance if the user ratings are very sparse, which is very common in the real world where users will rate only a few items from a large catalog</li><li class="listitem">The computing cost for calculating the similarity values for all the users is very high if the data is very large</li><li class="listitem">If user profiles or user inputs change quickly then we have to re-compute the similarity values that come with a high computational cost</li></ul></div><p>Item-based recommendation engines handle these shortcomings by calculating similarity between items or products instead of calculating similarity between users, thereby reducing the computational cost. Since the item catalog doesn't change rapidly, we don't have to re-compute calculations very often.</p><p>As with a user-based collaborative filtering approach there are two steps for an item-based collaborative approach:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Calculating the similarity between items.</li><li class="listitem">Predicting the ratings for the non-rated item for an active user by making use of previous ratings given to other similar items.</li></ol><div style="height:10px; width: 1px"/></div><p>The most common similarity measure used for this approach is cosine similarity. Cosine similarity calculates the similarity between two n-dimensional vectors by the angle between them in the vector space. Cosine similarity is given by the following equation:</p><div class="mediaobject"><img src="../Images/image00235.jpeg" alt="Item-based collaborative filtering"/></div><p style="clear:both; height: 1em;"> </p><p>When applying cosine similarity to recommender systems, we consider the item column as the n-dimensional vector and the similarity between two items as the angle between them. The smaller the angle, the more similar the items.</p><p>For example, in the previous dataset, if we want to predict the rating for Toby for the movie <span class="emphasis"><em>Lady in the Water</em></span>, first we have to identify movies similar to <span class="emphasis"><em>Lady in the Water</em></span>. Using the previous cosine equation we can calculate the similarity for all the items. The following table shows the similarity values for all the movies:</p><div class="note" title="Note"><h3 class="title"><a id="tip5"/>Tip</h3><p>Item-based similarity is calculated only for co-rated items.</p></div><div class="mediaobject"><img src="../Images/image00236.jpeg" alt="Item-based collaborative filtering"/></div><p style="clear:both; height: 1em;"> </p><p>From the preceding table, we see that <span class="emphasis"><em>You, me and Dupree</em></span> is the most similar to <span class="emphasis"><em>Lady in the Water (0.8897565)</em></span>.</p><p>We now predict the rating for the <span class="emphasis"><em>Lady in the Water</em></span> movie by calculating the weighted sum of ratings assigned to movies similar to <span class="emphasis"><em>Lady in the Water</em></span> by Toby. That is to say, we take the similarity score of <span class="emphasis"><em>Lady in the Water</em></span> for each movie rated by Toby, multiply it by the corresponding rating, and sum up all the scores for all the rated movies. This final sum is divided by the total sum of similarity scores of <span class="emphasis"><em>Lady in the Water</em></span> given as follows:</p><p>Rating for <span class="emphasis"><em>Lady in the Water</em></span>:</p><p><span class="emphasis"><em>(0.795*4.5 + 0.814*4 + 0.889*1)/(0.795+0.814+0.889) = 3.09</em></span></p><p>Similarly we can calculate ratings for all other users for movies using the preceding equation. In <a class="link" title="Chapter 4. Data Mining Techniques Used in Recommendation Engines" href="part0029.xhtml#aid-RL0A2">Chapter 4</a>, <span class="emphasis"><em>Data Mining Techniques Used in Recommendation Engines</em></span>, we deal with other similarity metrics that can be used in item-based recommendations.</p></div><div class="section" title="Advantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec17"/>Advantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Easy to implement</li><li class="listitem">Neither the content information of the products nor the users' profile information is required for building recommendations</li><li class="listitem">New items are recommended to users giving a surprise factor to the users</li></ul></div></div><div class="section" title="Disadvantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec18"/>Disadvantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">This approach is computationally expensive as all the user, product, and rating information is loaded into the memory for similarity calculations.</li><li class="listitem">This approach fails for new users where we do not have any information about the users. This problem is called the cold-start problem.</li><li class="listitem">This approach performs very poorly if we have little data.</li><li class="listitem">Since we do not have content information about users or products, we cannot generate recommendations accurately based on rating information only.</li></ul></div></div></div>
<div class="section" title="Content-based recommender systems"><div class="titlepage" id="aid-MSDG2"><div><div><h1 class="title"><a id="ch03lvl1sec17"/>Content-based recommender systems</h1></div></div></div><p>In the previous section, we saw that the recommendations were generated by considering only the rating or interaction information of the products by the users, that is to say that suggesting new items for the active user is based on the ratings given to those new items by similar users to the active user.</p><p>Let's take the case of a person who has given a 4-star rating to a movie. In a collaborative filtering approach we only consider this rating information for generating recommendations. In real life, a person rates a movie based on the features or content of the movie such as its genre, actor, director, story, and screenplay. Also the person watches a movie based on their personal choices. When we are building a recommendation engine to target users at a personal level, the recommendations should not be based on the tastes of other similar people but should be based on the individual users' tastes and the contents of the products.</p><p>A recommendation that is targeted at a personalized level and that considers individual preferences and contents of the products for generating recommendations is called a content-based recommender system.</p><p>Another motivation for building content-based recommendation engines is that they solve the cold-start problem that new users face in the collaborative filtering approach. When a new user comes, based on the preferences of the person we can suggest new items that are similar to their tastes.</p><p>Building content-based recommender systems involves three main steps, as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Generating content information for products.</li><li class="listitem">Generating a user profile and preferences with respect to the features of the products.</li><li class="listitem">Generating recommendations and predicting a list of items that the user might like:</li></ol><div style="height:10px; width: 1px"/></div><div class="mediaobject"><img src="../Images/image00237.jpeg" alt="Content-based recommender systems"/></div><p style="clear:both; height: 1em;"> </p><p><span class="strong"><strong>Item profile generation</strong></span>: In this step, we extract the features that represent the product. Most commonly the content of the products is represented in the vector space model with product names as rows and features as columns. Usually the content of the products will either be structured data or unstructured data. Structured data will be obtained from the databases; unstructured features would include the reviews, tags, or textual properties associated in websites. In the item profile generation step, we have to extract relevant features and their relative importance score associated with the product.</p><p>For generating the item profile we use the <span class="strong"><strong>term frequency inverse document frequency</strong></span> (<span class="strong"><strong>tf-idf</strong></span>) for calculating the feature relative importance associated with the item. Since we represent the item features in vector representation, we may use tf-idf, which will be explained in detail in <a class="link" title="Chapter 4. Data Mining Techniques Used in Recommendation Engines" href="part0029.xhtml#aid-RL0A2">Chapter 4</a>, <span class="emphasis"><em>Data Mining Techniques Used in Recommendation Engines</em></span>.</p><p>Let us try to better understand with an example. As we've already mentioned, for content-based recommendation engines, we require additional content information about Movies, as follows:</p><div class="mediaobject"><img src="../Images/image00238.jpeg" alt="Content-based recommender systems"/></div><p style="clear:both; height: 1em;"> </p><p>The first thing we have to do is to create an item profile using tf-idf, by means of the following steps:</p><p>Create a term frequency matrix containing the frequency count of each term in each document; that is to say, in our case, the presence of each genre in each movie. The number 1 represents the presence of the genre and 0 represents the absence of the genre:</p><div class="mediaobject"><img src="../Images/image00239.jpeg" alt="Content-based recommender systems"/></div><p style="clear:both; height: 1em;"> </p><p>The next step is to create inverse document frequency given by the following formula:</p><p><span class="emphasis"><em>Idf = Log(total number of documents/document frequency)</em></span></p><p>Here, the total number of documents is the number of movies, and the document frequency is the total number of times they have occurred in all the documents:</p><div class="mediaobject"><img src="../Images/image00240.jpeg" alt="Content-based recommender systems"/></div><p style="clear:both; height: 1em;"> </p><p>The final step is to create a <span class="emphasis"><em>tf-idf</em></span> matrix given by the following formula:</p><p><span class="emphasis"><em>tf*idf</em></span></p><div class="mediaobject"><img src="../Images/image00241.jpeg" alt="Content-based recommender systems"/></div><p style="clear:both; height: 1em;"> </p><div class="section" title="User profile generation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec19"/>User profile generation</h2></div></div></div><p>In this step, we build the user profile or preference matrix matching the product content. In general we build the user profile or features that are in common with the product content as it makes more sense to compare both user and item profiles and calculate the similarity between them.</p><p>Let's consider the following dataset showing the viewed history of each user. If there is a value of 1 in the matrix cell, it means that the user has seen the movie. This information gives us their preference of movies:</p><div class="mediaobject"><img src="../Images/image00242.jpeg" alt="User profile generation"/></div><p style="clear:both; height: 1em;"> </p><p>From the preceding information, we will create a user profile that can be used to compare with the item profile; that is to say, we now create a user profile that contains the user preference of the item features, to genres, in our case. Dot product between the tf-idf and user preference matrix will give the user affinity for each of the genres, as shown in the following table:</p><p><span class="emphasis"><em>dotProduct(Tf-idf, userPreference matrix)</em></span></p><div class="mediaobject"><img src="../Images/image00243.jpeg" alt="User profile generation"/></div><p style="clear:both; height: 1em;"> </p><p>With user profiles and item profiles at hand, the next step would be to estimate the degree to which the user will prefer each of the items. We can now use cosine similarity to compute the user preference for each of the items. In our example, the cosine similarity between user and item profiles gives the following results:</p><p><span class="emphasis"><em>cosineSimilarity(userProfile,ItemProfile)</em></span></p><div class="mediaobject"><img src="../Images/image00244.jpeg" alt="User profile generation"/></div><p style="clear:both; height: 1em;"> </p><p>From the preceding table we can conclude that the greater the cosine angle the more likely the user is to like a movie and hence it can be recommended to the user.</p><p>Now that we have made the recommendations, let us take a step back from gathering user preference data. Usually there are two ways of capturing user data; these are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Explicitly ask the user for their preferences regarding the product's features, and store them.</li><li class="listitem">Implicitly capture the user interaction data on products such as browsing history, rating history, and purchase history, and build the user preferences to the product features. In <a class="link" title="Chapter 4. Data Mining Techniques Used in Recommendation Engines" href="part0029.xhtml#aid-RL0A2">Chapter 4</a>, <span class="emphasis"><em>Data Mining Techniques Used in Recommendation Engines</em></span>, and <a class="link" title="Chapter 5. Building Collaborative Filtering Recommendation Engines" href="part0037.xhtml#aid-1394Q1">Chapter 5</a>, <span class="emphasis"><em>Building Collaborative Filtering Recommendation Engines,</em></span> we build recommendation engines using explicit and implicit user activity examples.</li></ul></div><p>The approach that we have followed until now for building a content-based recommendation system is based on similarity calculation. We may also apply supervised machine-learning approaches such as classification for predicting the most probable products the user might like.</p><p>Recommender systems using machine learning or any other mathematical, statistical models to generate recommendations are called model-based systems. In classification-based approaches which fall under model-based recommender systems, first we build a machine-learning model by using a user profile and item profile to predict if a user likes/dislikes an item. Supervised classification tasks such as logistic regression, KNN-classification methods, probabilistic methods, and so on, can be used. Model-based recommendation engines are discussed in the next section.</p></div><div class="section" title="Advantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec20"/>Advantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Content-based recommender systems target at an individual level</li><li class="listitem">Recommendations are generated using the user preferences alone rather than the user community as with collaborative filtering</li><li class="listitem">These approaches can be employed in real time as the recommendation model doesn't need to load all the data for processing or generating recommendations</li><li class="listitem">Accuracy is high compared to collaborative approaches as they deal with the content of the products instead of rating information alone</li><li class="listitem">The cold-start problem can be easily handled</li></ul></div></div><div class="section" title="Disadvantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec21"/>Disadvantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">As the system is more personalized the generated recommendations will become narrowed down to only user preferences when more user information comes into the system</li><li class="listitem">As a result, no new products that are not related to the user preferences will be shown to the user</li><li class="listitem">The user will not be able to look at what is happening around them or what's trending</li></ul></div></div></div>
<div class="section" title="Context-aware recommender systems"><div class="titlepage" id="aid-NQU22"><div><div><h1 class="title"><a id="ch03lvl1sec18"/>Context-aware recommender systems</h1></div></div></div><p>Over the years there has been an evolution in recommender systems from neighborhood approaches to personalized recommender systems that are targeted to individual users. These personalized recommender systems have become a huge success as this is useful at end user level, and for organizations these systems become catalysts to increase their business.</p><p>Though the personalized recommender systems were targeted at the individual user level and provided recommendations based on the personal preferences of the users, there was scope to refine the systems. For example, the same person in different places might have different requirements. Likewise, the same person has different requirements at different times:</p><div class="mediaobject"><img src="../Images/image00245.jpeg" alt="Context-aware recommender systems"/></div><p style="clear:both; height: 1em;"> </p><p>Our intelligent recommender systems should be evolved enough to cater to the needs of the users for different places, at different times. The recommender system should be robust enough to suggest cotton shirts to a person during summer and leather jackets during winter. Similarly, based on the time of day, suggesting good restaurants serving a person's personal choice of breakfast or dinner would be very helpful. These kinds of recommender systems that consider location, time, mood, and so on, that defines the context of the user and suggests personalized recommendations, are called <span class="strong"><strong>context aware recommender systems</strong></span>:</p><div class="mediaobject"><img src="../Images/image00246.jpeg" alt="Context-aware recommender systems"/></div><p style="clear:both; height: 1em;"> </p><p>The preceding image illustrates a recommendation engine suggesting coffee in cold weather.</p><div class="section" title="Context definition"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec22"/>Context definition</h2></div></div></div><p>So what exactly is context? In general, context represents the present state of the user. The context of a user can be anything such as place, time, day, season, mood, device, whether the user is alone, at the office, on vacation, with family, with friends, life events, and so on. Since people will have different needs in different contexts, the recommendation systems can capture the context information of the user and refine their suggestions accordingly.</p><p>For example, a travel vacation system may consider season, place, and time as context for refining the suggestions; an e-commerce website can consider the life event and user purchases for context aware recommendations, and a food website may consider time of day and place information while recommending restaurants.</p><p>How are context aware systems designed? Until now we have considered recommendations as a two-dimensional problem, that is to say user preferences and item representations. With the inclusion of context as a new dimension we can build context aware recommendations as a three-dimensional problem:</p><p><span class="emphasis"><em>Recommendations = User x Item x Context</em></span></p><div class="mediaobject"><img src="../Images/image00247.jpeg" alt="Context definition"/></div><p style="clear:both; height: 1em;"> </p><p>Let us revisit the same example as we did in the content-based recommendations, where we considered the user profile and the item profile to generate the user ratings for each of the items based on user preferences by computing the similarity between the user profile and the item profile. Now, in context aware systems, we include context to generate the rankings for items with respect to user preference and context.</p><p>For example, we can assume our recommendation has captured the movie watching patterns of the user for a weekday, weekend, and holiday. From this context information, we extract the affinity of each user for the movie contents. For example, consider the following preferences for TOBY for each of the contexts for the movie contents:</p><div class="mediaobject"><img src="../Images/image00248.jpeg" alt="Context definition"/></div><p style="clear:both; height: 1em;"> </p><div class="mediaobject"><img src="../Images/image00249.jpeg" alt="Context definition"/></div><p style="clear:both; height: 1em;"> </p><p>Let us first create a user profile for TOBY for each of the contexts for all the movie content. A dot product between the context matrix and user profile matrix gives us the user profile for all the contexts:</p><p><span class="emphasis"><em>Dotproduct(user profile, context matrix)</em></span> for TOBY:</p><div class="mediaobject"><img src="../Images/image00250.jpeg" alt="Context definition"/></div><p style="clear:both; height: 1em;"> </p><p>We have now calculated the preference of TOBY for each context for the movie context. The next step would be to calculate the ranking of each movie for TOBY for all the contexts.</p><p>Cosine similarity (contextual movie content preference matrix, item profile):</p><div class="mediaobject"><img src="../Images/image00251.jpeg" alt="Context definition"/></div><p style="clear:both; height: 1em;"> </p><p>Now we have the context level ranking for movies for TOBY, we can suggest movies based on the context.</p><p>From the preceding example, we understood that context-aware recommender systems are content-based recommenders with the inclusion of a new dimension called context. In context-aware systems, recommendations are generated in two steps, as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Generate a list of recommendations of the products for each user based on the user's preferences; that is, content-based recommendations.</li><li class="listitem">Filter out the recommendations that are specific to a current context.</li></ol><div style="height:10px; width: 1px"/></div><p>The most common approaches for building context-aware recommender systems are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Post-filtering approaches</li><li class="listitem">Pre-filtering approaches</li></ul></div></div><div class="section" title="Pre-filtering approaches"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec23"/>Pre-filtering approaches</h2></div></div></div><p>In the pre-filtering approach, context information is applied to the user profile and product content. This step will filter out all the non-relevant features, and final personalized recommendations are generated on the remaining feature set. Since the filtering of features is performed before generating personalized recommendations, these are called pre-filtering approaches:</p><div class="mediaobject"><img src="../Images/image00252.jpeg" alt="Pre-filtering approaches"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Post-filtering approaches"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec24"/>Post-filtering approaches</h2></div></div></div><p>In post-filtering approaches, firstly personalized recommendations are generated based on the user profile and the product catalogue, then the context information is applied to filter out the relevant products to the user for the current context:</p><div class="mediaobject"><img src="../Images/image00253.jpeg" alt="Post-filtering approaches"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Advantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec25"/>Advantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Context aware systems are much more advanced than the personalized content-based recommenders as these systems will be constantly in sync with user movements and generate recommendations as per the current context</li><li class="listitem">These systems have more of a real-time nature</li></ul></div></div><div class="section" title="Disadvantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec26"/>Disadvantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Serendipity or surprise factor, as with other personalized recommenders, will be missing in these types of recommendation as well</li></ul></div></div></div>
<div class="section" title="Hybrid recommender systems" id="aid-OPEK1"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec19"/>Hybrid recommender systems</h1></div></div></div><p>Collaborative filtering systems and content-based recommender systems are effective and cater to a wide range of needs. They have quite successful implementations but each independently has its own limitations. Research has started moving in the direction of combining both collaborative filtering and content-based recommendations. This new type of recommender system formed by combining collaborative filtering with content-based methods is called a hybrid recommender system.</p><p>The choice of combining the different recommendation approaches is up to the researcher or the person implementing the hybrid recommendation engine based on the problem statement and business needs.</p><p>The most common approaches followed for building a hybrid system are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Weighted method</li><li class="listitem">Mixed method</li><li class="listitem">Switching method</li><li class="listitem">Cascade method</li><li class="listitem">Feature combination method</li><li class="listitem">Feature augmentation</li><li class="listitem">Meta-level</li></ul></div><div class="section" title="Weighted method"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec27"/>Weighted method</h2></div></div></div><p>In this method the final recommendations would be the combination, mostly linear, of recommendation results of all the available recommendation engines. At the beginning of the deployment of this weighted hybrid recommendation engine, equal weights will be given to each of the results from available recommendation engines, and gradually the weights will be adjusted by evaluating the responses from the users to recommendations.</p></div><div class="section" title="Mixed method"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec28"/>Mixed method</h2></div></div></div><p>The mixed method is applicable in places where we can mix results from all the available recommenders. These are mostly employed in places where it is not feasible to achieve a score for a product by all the available recommender systems because of data sparsity. Hence recommendations are generated independently and are mixed before being sent to the user.</p></div><div class="section" title="Cascade method"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec29"/>Cascade method</h2></div></div></div><p>In this approach, recommendations are generated using collaborative filtering. The content-based recommendation technique is applied and then final recommendations / a ranked list will be given as the output.</p></div><div class="section" title="Feature combination method"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec30"/>Feature combination method</h2></div></div></div><p>The feature combination method, in which we combine the features of different recommender systems and final recommendation approach, is applied on the combined feature sets. In this technique, we combine both User-Item preference features extracted from content based recommender systems and, User-Item ratings information, and consider a new strategy to build Hybrid recommender systems.</p><div class="mediaobject"><img src="../Images/image00254.jpeg" alt="Feature combination method"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Advantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec31"/>Advantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Issues such as the cold-start problem and data sparsity can be handled</li><li class="listitem">These systems are much more robust and scalable than any of the individual models</li><li class="listitem">A combination of methods leads to an improvement in accuracy</li></ul></div></div></div>
<div class="section" title="Model-based recommender systems" id="aid-PNV61"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec20"/>Model-based recommender systems</h1></div></div></div><p>Till now we have been focusing on neighborhood approaches which involve similarity calculations between users or products for collaborative filtering approaches or represent the user and item contents in a vector space model, and find similarity measures to identify items similar to the preferences of the users. The main objective of the similarity-based approaches is to calculate the weights of the preferences of users for the products or product content and then use these feature weights for recommending items.</p><p>These approaches have been very successful over the years and even today. But these approaches have their own limitations. Since entire data has to be loaded into the environment for similarity calculations, these approaches were also known as memory-based models. These memory-based models are very slow to respond in real-time scenarios when the amount of data is very large as all the data has to be loaded. Another limitation is that the weights calculated are not learned automatically as with machine-learning applications. The cold-start problem is another common limitation that memory-based or neighborhood-based methods suffer from.</p><p>In order to address these limitations, researchers started to apply more advanced methods to improve the performance of the recommendation engines such as probabilistic models, machine-learning models such as supervised and unsupervised models, and matrix approaches such as Matrix Factorization and single value decomposition. In the model-based approaches, using available historical data, a model is built with weights learned automatically. New predictions regarding the products will be made using the learned weights and then the final results ranked in a specific order before making recommendations.</p><div class="section" title="Probabilistic approaches"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec32"/>Probabilistic approaches</h2></div></div></div><p>In a probabilistic approach, we build a probability model using the prior probabilities from the available data, and a ranked list of recommendations is generated by calculating the probability of liking/disliking of a product for each user. Most commonly the Naïve Bayes method is used in probabilistic approaches, which is a simple but powerful technique.</p></div><div class="section" title="Machine learning approaches"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec33"/>Machine learning approaches</h2></div></div></div><p>As explained in content-based recommender systems, we can consider a recommendation problem as a machine-learning problem. Using historical user and product data, we can extract features and output classes and then build a machine learning model. A final ranked list of product recommendations is generated using the generated model. Many machine-learning approaches such as logistic regression, KNN classification, decision trees, SVM, clustering, and so on, can be used. These machine-learning approaches are applied for collaborative, content based, context aware, and hybrid recommender systems. In <a class="link" title="Chapter 4. Data Mining Techniques Used in Recommendation Engines" href="part0029.xhtml#aid-RL0A2">Chapter 4</a>, <span class="emphasis"><em>Data Mining Techniques Used in Recommendation Engines</em></span>, we learn in detail about each of the machine-learning approaches.</p></div><div class="section" title="Mathematical approaches"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec34"/>Mathematical approaches</h2></div></div></div><p>In these approaches, we assume that the ratings or interaction information of users on products are simple matrices. On these matrices we apply mathematical approaches to predict the missing ratings for the users. The most commonly used approaches are the Matrix Factorization model and single valued decomposition models:</p><div class="mediaobject"><img src="../Images/image00255.jpeg" alt="Mathematical approaches"/></div><p style="clear:both; height: 1em;"> </p><p>By applying matrix decomposition approaches we assume that we decompose the original rating matrix (R) into two new matrices (U, V) that represent the latent features of the users and movies.</p><p>In mathematical terms, we can decompose a matrix into two low rank matrices. In the preceding example, matrix R is decomposed into matrices U and V. Now when we multiply back U and V we get the original matrix R approximately. This concept is used in recommendation engines for filling up the unknown ratings in the original rating matrix, and recommendations are then ranked and suggested to the users.</p><p>In <a class="link" title="Chapter 4. Data Mining Techniques Used in Recommendation Engines" href="part0029.xhtml#aid-RL0A2">Chapter 4</a>, <span class="emphasis"><em>Data Mining Techniques Used in Recommendation Engines</em></span> we discuss these two approaches in more detail.</p></div><div class="section" title="Advantages"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec35"/>Advantages</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Model-based recommendations are much more accurate than the heuristic-based approaches such as neighborhood methods</li><li class="listitem">In heuristic methods the weights of products / product content is more static, whereas in model-based recommendations, the weights are established through auto-learning</li><li class="listitem">The model-based approach extracts many unseen patterns using data-driven approaches</li></ul></div></div></div>
<div class="section" title="Summary" id="aid-QMFO1"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec21"/>Summary</h1></div></div></div><p>In this chapter, we have learned about popular recommendation engine techniques such as collaborative filtering, content-based recommendations, context aware systems, hybrid recommendations, and model-based recommendation systems, with their advantages and disadvantages. There are different similarity methods such as cosine similarity, Euclidean distance, and the Pearson coefficient. Subcategories within each of the recommendations are also explained.</p><p>In the next chapter, we learn about different data-mining techniques such as Neighborhood methods, machine learning methods used in recommendation engines, and their evaluation techniques such as RMSE and, Precision-Recall.</p></div></body></html>