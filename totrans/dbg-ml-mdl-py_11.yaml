- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Avoiding and Detecting Data and Concept Drifts
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We talked about the effect of data and concept drifts in machine learning modeling
    in [*Chapter 9*](B16369_09.xhtml#_idTextAnchor261), *Testing and Debugging for
    Production*. In this chapter, we want to go deeper into these concepts and practice
    detecting drifts in Python.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Here, you will learn about the importance of concepts we introduced earlier,
    such as model versioning and model monitoring, to avoid drifts and practice with
    some of the Python libraries for drift detection.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding drifts in your models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting drifts
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to detect drifts in your machine
    learning models in Python and have reliable models in production.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following requirements apply to this chapter as they help you better understand
    the concepts, allow you to use them in your projects, and to practice with the
    provided code:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Python library requirements are as follows:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` >= 1.2.2'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy` >= 1.22.4'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas` >= 1.4.4'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alibi_detect` >= 0.11.1'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lightgbm` >= 3.3.5'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`evidently` >= 0.2.8'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Understanding of the following is required:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data and concept drift
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Data and model versioning
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter11](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter11).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding drifts in your models
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data and concept drifts challenge the reliability of machine learning models
    in production. Drifts in our machine learning projects can have different characteristics.
    Some of these characteristics that could help you to detect drifts in your projects
    and plan to resolve them are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '**Magnitude**: We might face magnitudes of difference across the data distribution
    that result in drift in our machine learning models. Small changes in the data
    distribution may be difficult to detect, while large changes may be more noticeable.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequency**: Drifts might occur in different frequencies.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gradual versus sudden**: Data drift can occur gradually where changes in
    the data distribution happen slowly over time, or it can occur suddenly where
    changes happen quickly and unexpectedly.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictability**: Some types of drift may be predictable, such as changes
    that occur seasonally or due to external events. Other types of drift may be unpredictable,
    such as sudden changes in consumer behavior or market trends.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Intentionality**: Drift can be intentional, such as changes made to the data
    generation process, or unintentional, such as changes that occur naturally over
    time.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to use techniques and practices that help us avoid the occurrence and
    pile-up of drifts in our machine learning modeling projects.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding data drift
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having access to different versions of the data in different stages of the machine
    learning life cycle of our models can help us to better detect drift by comparing
    the data in training and production, assessing data processing pre-training, or
    identifying data selection criteria that could have caused drift. Model monitoring
    also helps us to identify drifts early on and avoid pile-up.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s practice drift monitoring by simply checking the mean of the distribution
    of features between versions of data used for model training, and the new data
    in production. We will first define a class to monitor for data drift. Here, we
    consider drift in a feature if the difference between the mean of the distributions
    between the two versions of the data is bigger than 0.1:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we use it to identify drift between two synthetic datasets:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This generates the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Addressing concept drift
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can similarly define classes and functions with criteria to detect concept
    drift, as we practiced for data drift detection. But we can also check, either
    programmatically or as part of quality assurance when bringing our machine learning
    models into production, for external factors that might cause concept drift such
    as environmental factors, changes in institutional or governmental policies, et
    cetera. In addition to monitoring the data, we can benefit from feature engineering
    to select features that are more robust to concept drift or ensemble models to
    be adapted dynamically in case of concept drift.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Although avoiding drift in our models is ideal, we need to be ready to detect
    and eliminate it in practice. Next, you will learn techniques to detect drift
    in your model. From a practical perspective, avoiding and detecting drifts in
    your model are very similar. But there are better techniques than simply checking
    the mean of feature distributions (as we used for avoiding data drift in this
    section) that we will practice in the next section.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Detecting drifts
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Avoiding drifts altogether in all our models is not possible, but we can aim
    to detect them early on and eliminate them. Here, we are going to practice drift
    detection with `alibi_detect` and `evidently` in Python.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Practicing with alibi_detect for drift detection
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the widely-used Python libraries for drift detection that we want to
    practice with is `alibi_detect`. We will first import the necessary Python functions
    and classes and generate a synthetic dataset with 10 features and 10,000 samples
    using `make_classification` from `scikit-learn`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we split the data into train and test sets:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we train a `LightGBM` classifier on the training data:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We now evaluate the performance of the model on the test set and define a test
    label DataFrame to use for drift detection:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we use the defined DataFrame of predictions and actual labels of the test
    data points to detect drift. We initialize the `KSDrift` detector from the `alibi_detect`
    package and fit it onto the training data. We use the `predict` method of the
    detector to calculate the drift scores and p-values on the test data. The drift
    scores indicate the level of drift for each feature, while the p-values indicate
    the statistical significance of the drift. If any of the drift scores or p-values
    are above a certain threshold, we may consider the model to be experiencing drift
    and take appropriate action, such as retraining the model with updated data:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here are the resulting drift scores and p-values. As all the p-values are greater
    than 0.1, and considering the threshold is 0.005, we can say that no drift is
    detected in this case:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Practicing with evidently for drift detection
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another widely-used Python library for drift detection that we will practice
    with here is `evidently`. After importing the necessary libraries, we load the
    diabetes dataset from `scikit-learn`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following table shows the features we want to work on from the diabetes
    dataset for drift detection and their meanings:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '| **Feature** | **Description** |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| `preg` | Number of times pregnant |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| `plas` | Plasma glucose concentration after 2 hours in an oral glucose tolerance
    test |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| `skin` | Triceps skinfold thickness (mm) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| `insu` | 2-hour serum insulin (mu U/ml) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| `mass` | Body mass index (weight in kg/(height in m)^2) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| `pedi` | Diabetes pedigree function |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| `Age` | Age (years) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: Table 11.1 – Feature names and their description in diabetes dataset used for
    drift detection (Efron et al., 2004)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'We separate two sets of datapoints called reference and current sets, then
    generate a drift report using `Report()` from the `evidently.report.Reference`
    set to include all individuals aged less than or equal to 40 years, and the current
    set to include others in the dataset aged more than 40 years:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following illustration is of the report we generated for the diabetes dataset,
    considering the selected features and separated reference and current sets:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 11.1 – Drift report for \uFEFFthe separated reference and current\
    \ data from the diabetes dataset](img/B16369_11_01.jpg)"
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – Drift report for the separated reference and current data from
    the diabetes dataset
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that `age`, `preg`, `plas`, `insu`, and `skin` are the features
    with significant differences in their distributions between the reference and
    current sets, which are specified as features with detected drift in the report
    shown in *Figure 11**.1*. In spite of the significance of the difference between
    the distributions, having complementary statistics such as difference of mean
    could be helpful to develop a more reliable drift detection strategy. We can also
    get the distribution of the features from the report, such as the distributions
    of `age` and `preg` in the reference and current sets in *Figures 11.2* and*11.3*,
    respectively:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 11.2 – Distribution of \uFEFFthe age feature in both current and reference\
    \ data](img/B16369_11_02.jpg)"
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – Distribution of the age feature in both current and reference
    data
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 11.3 – Distribution of \uFEFFthe preg feature in both current and\
    \ reference data](img/B16369_11_03.jpg)"
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 – Distribution of the preg feature in both current and reference
    data
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: When we detect drifts in our models, we might need to retrain them by ingesting
    new data or by filtering part of the data that might be the source of the drift.
    We might also need to change model training if concept drift is detected.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned about the importance of avoiding drift in your
    machine learning models, and how you can benefit from the concepts you learned
    in previous chapters such as model versioning and monitoring to do so. You also
    practiced with two libraries for drift detection in Python: `alibi_detect` and
    `evidently`. Using these or similar libraries will help you to eliminate drift
    in your models and have reliable models in production.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about different types of deep neural network
    models and how to use PyTorch to develop reliable deep learning models.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Could you explain the difference between magnitude and frequency as two characteristics
    of drift in machine learning modeling?
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an example of a statistical test we can use for data drift detection?
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ackerman, Samuel, et al. “*Detection of data drift and outliers affecting machine
    learning model performance over time*.” arXiv preprint arXiv:2012.09258 (2020).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ackerman, Samuel, et al. “*Automatically detecting data drift in machine learning
    classifiers*.” arXiv preprint arXiv:2111.05672 (2021).
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efron, Bradley, Trevor Hastie, Iain Johnstone, and Robert Tibshirani (2004)
    “*Least Angle Regression*,” Annals of Statistics (with discussion), 407-499
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gama, João, et al. “*A survey on concept drift adaptation*.” ACM computing
    surveys (CSUR) 46.4 (2014): 1-37.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu, Jie, et al. “*Learning under concept drift: A review*.” IEEE transactions
    on knowledge and data engineering 31.12 (2018): 2346-2363.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mallick, Ankur, et al. “*Matchmaker: Data drift mitigation in machine learning
    for large-scale systems*.” Proceedings of Machine Learning and Systems 4 (2022):
    77-94.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zenisek, Jan, Florian Holzinger, and Michael Affenzeller. “*Machine learning
    based concept drift detection for predictive maintenance*.” Computers & Industrial
    Engineering 137 (2019): 106031.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zenisek, Jan, Florian Holzinger, 和 Michael Affenzeller. “*基于机器学习的概念漂移检测用于预测性维护*。”
    计算机与工业工程 137 (2019): 106031。'
- en: Part 4:Deep Learning Modeling
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4部分：深度学习建模
- en: In this part of the book, we will lay the foundation with an introduction to
    the underlying theories of deep learning, and then transition to hands-on exploration
    of fully connected neural networks. We will then learn about more advanced techniques
    including convolutional neural networks, transformers, and graph neural networks.
    Concluding this part, we will spotlight the cutting-edge advancements in machine
    learning, with a keen focus on generative modeling and an introduction to reinforcement
    and self-supervised learning. Throughout these chapters, practical examples are
    provided using Python and PyTorch, ensuring that we gain both theoretical knowledge
    as well as hands-on experience.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的这一部分，我们将通过介绍深度学习的底层理论来奠定基础，然后过渡到对全连接神经网络的动手探索。接着，我们将学习更高级的技术，包括卷积神经网络、转换器和图神经网络。在本部分的结尾，我们将聚焦于机器学习的尖端进展，特别关注生成建模，并介绍强化学习和自监督学习。在这些章节中，我们将通过Python和PyTorch提供实际示例，确保我们既获得理论知识，也获得实践经验。
- en: 'This part has the following chapters:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 12*](B16369_12.xhtml#_idTextAnchor320), *Going Beyond ML Debugging
    with Deep Learning*'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B16369_12.xhtml#_idTextAnchor320), *超越机器学习调试的深度学习*'
- en: '[*Chapter 13*](B16369_13.xhtml#_idTextAnchor342), *Advanced Deep Learning Techniques*'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B16369_13.xhtml#_idTextAnchor342), *高级深度学习技术*'
- en: '[*Chapter 14*](B16369_14.xhtml#_idTextAnchor379), *Introduction to Recent Advancements
    in Machine Learning*'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第14章*](B16369_14.xhtml#_idTextAnchor379), *机器学习最新进展简介*'
