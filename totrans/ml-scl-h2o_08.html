<html><head></head><body>
		<div id="_idContainer093">
			<h1 id="_idParaDest-106"><em class="italic"><a id="_idTextAnchor106"/>Chapter 6</em>: Advanced Model Building – Part II</h1>
			<p>In the previous chapter, <a href="B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082"><em class="italic">Chapter 5</em></a>, <em class="italic">Advanced Model Building – Part I</em>, we detailed the process for building an enterprise-grade <strong class="bold">supervised learning</strong> model on the H2O platform. In this chapter, we round out our advanced model-building topics by doing the following: </p>
			<ul>
				<li>Demonstrating how to build H2O supervised learning models within an Apache Spark pipeline </li>
				<li>Introducing H2O's <strong class="bold">unsupervised learning</strong> method </li>
				<li>Discussing best practices for updating H2O models </li>
				<li>Documenting requirements to ensure H2O model reproducibility</li>
			</ul>
			<p>We begin this chapter by introducing Sparkling Water pipelines, a method for embedding H2O models natively within a Spark pipeline. In enterprise settings where Spark is heavily utilized, we have found this to be a popular method for building and deploying H2O models. We demonstrate by building a Sparkling Water pipeline for <strong class="bold">sentiment analysis</strong> using data from online reviews of Amazon food products. </p>
			<p>We then introduce the unsupervised learning methods available in H2O. Using credit card transaction data, we build an anomaly detection model using isolation forests. In this context, the unsupervised model would be used to flag suspicious credit card transactions in a financial fraud-prevention effort. </p>
			<p>We conclude this chapter by addressing issues pertinent to models built in this chapter, as well as in <a href="B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082"><em class="italic">Chapter 5</em></a><em class="italic">, Advanced Model Building – Part I</em>. These are best practices for updating H2O models and ensuring reproducibility of H2O model results. </p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>Modeling in Sparkling Water</li>
				<li>UL methods in H2O</li>
				<li>Best practices for updating H2O models</li>
				<li>Ensuring H2O model reproducibility</li>
			</ul>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor107"/>Technical requirements</h1>
			<p>The code and datasets we introduce in this chapter can be found in the GitHub repository at <a href="https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O">https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O</a>. If you have not set up your H2O environment at this point, see <a href="B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268"><em class="italic">Appendix</em></a><em class="italic"> – Alternative Methods to Launch H2O Clusters for This Book,</em> to do so.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor108"/>Modeling in Sparkling Water</h1>
			<p>We saw in <a href="B16721_02_Final_SK_ePub.xhtml#_idTextAnchor024"><em class="italic">Chapter 2</em></a>, <em class="italic">Platform Components and Key Concepts,</em> that Sparkling Water is simply H2O-3 in an Apache Spark environment. From the Python coder's point of view, H2O-3 code is virtually identical to Sparkling Water code. If the <a id="_idIndexMarker419"/>code is the same, why have a separate section for modeling in Sparkling Water? There are two important reasons, as <a id="_idIndexMarker420"/>outlined here:</p>
			<ul>
				<li>Sparkling Water enables data scientists to leverage Spark's extensive data processing capabilities. </li>
				<li>Sparkling Water provides access to production Spark pipelines. We expand upon these reasons next.</li>
			</ul>
			<p>Spark is rightly known for its data operations that effortlessly scale with increasing data volume. Since the presence of Spark in an enterprise setting is now almost a given, data scientists should add Spark to their skills toolbelt. This is not nearly as hard as it seems, since Spark can be operated from Python (using PySpark) with data operations written primarily in Spark SQL. For <a id="_idIndexMarker421"/>experienced Python and <strong class="bold">Structured Query Language</strong> (<strong class="bold">SQL</strong>) coders, this is a very easy transition indeed.</p>
			<p>In the Lending Club example from <a href="B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082"><em class="italic">Chapter 5</em></a>, <em class="italic">Advanced Model Building – Part I</em>, data munging and <strong class="bold">feature engineering</strong> tasks were carried out using native H2O commands on the H2O cluster. These H2O data commands <a id="_idIndexMarker422"/>work in Sparkling Water as well. However, in an enterprise that has invested in a Spark data infrastructure, replacing H2O data commands with their Spark equivalents makes a lot of sense. It would then pass the cleaned dataset to H2O to handle the subsequent modeling steps. This is our recommended workflow in Sparkling Water.</p>
			<p>In addition, Spark pipelines are frequently used in enterprise production settings for <strong class="bold">extract, transform, and load</strong> (<strong class="bold">ETL</strong>) and other data <a id="_idIndexMarker423"/>processing tasks. Sparkling Water's integration of H2O algorithms into Spark pipelines allows for seamless training and deployment of H2O models<a id="_idIndexMarker424"/> in a Spark environment. In the remainder of this section, we show how Spark pipelines can be combined with H2O modeling to create a Sparkling Water pipeline. This <a id="_idIndexMarker425"/>pipeline is easily promoted into production, a topic that we return to in detail in <a href="B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178"><em class="italic">Chapter 10</em></a>, <em class="italic">H2O Model Deployment Patterns</em>. </p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor109"/>Introducing Sparkling Water pipelines</h2>
			<p><em class="italic">Figure 6.1</em> illustrates the<a id="_idIndexMarker426"/> Sparkling Water pipeline training and deployment process. The pipeline starts with an input data source for model training. Data cleaning and feature engineering steps are built sequentially from Spark transformers, with the outputs of one transformer becoming the inputs of the subsequent transformer. Once the dataset is in a modeling-ready format, H2O takes over to specify and build a model. We wrap all the transformer and model steps into a pipeline that is trained and then exported for production. </p>
			<p>In the production environment, we import the pipeline and introduce new data to it (in the following diagram, we assume this happens via a data stream, but the data could be arriving in batches as well). The pipeline outputs H2O model predictions: </p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B16721_06_01.jpg" alt="Figure 6.1 – Sparkling Water pipeline train and deploy illustration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1 – Sparkling Water pipeline train and deploy illustration</p>
			<p>Next, let's create a pipeline to implement sentiment analysis.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor110"/>Implementing a sentiment analysis pipeline</h2>
			<p>We next create a Sparkling<a id="_idIndexMarker427"/> Water pipeline for an sentiment <a id="_idIndexMarker428"/>analysis classification problem. Sentiment analysis is used to model whether a customer has positive or negative feelings<a id="_idIndexMarker429"/> toward a product or company. It typically requires <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) to create predictors from text. For our example, we use a preprocessed version of the <em class="italic">Amazon Fine Food reviews</em> dataset<a id="_idIndexMarker430"/> from the <strong class="bold">Stanford Network Analysis Platform</strong> (<strong class="bold">SNAP</strong>) repository. (See <a href="https://snap.stanford.edu/data/web-FineFoods.html">https://snap.stanford.edu/data/web-FineFoods.html</a> for the original data.)</p>
			<p>Let's first verify that Spark is available on our system. </p>
			<pre class="source-code">spark</pre>
			<p>The following screenshot shows the output:</p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B16721_06_02.jpg" alt="Figure 6.2 – Spark startup in Jupyter notebook with PySparkling kernel&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – Spark startup in Jupyter notebook with PySparkling kernel</p>
			<p>You can see in the Spark output that the <strong class="bold">SparkSession</strong> has been started and the <strong class="bold">SparkContext</strong> initiated. </p>
			<p class="callout-heading">PySpark and PySparkling</p>
			<p class="callout"><strong class="bold">PySpark</strong> is Apache's Python interface for <a id="_idIndexMarker431"/>Spark. It provides a shell for interactive Spark sessions and access to Spark components such as Spark SQL, DataFrames, and Streaming. <strong class="bold">PySparkling</strong> is the<a id="_idIndexMarker432"/> H2O extension of <strong class="bold">PySpark</strong>, enabling H2O services to be started on a Spark cluster from Python. Our Jupyter notebook uses a PySpark shell.</p>
			<p>In the <em class="italic">internal backend</em> mode of Sparkling <a id="_idIndexMarker433"/>Water, H2O resources piggyback on their Spark counterparts, all within the same <strong class="bold">Java virtual machine</strong> (<strong class="bold">JVM</strong>). As illustrated in<em class="italic"> </em>the following <a id="_idIndexMarker434"/>diagram, an <strong class="bold">H2OContext</strong> that sits on top of the <strong class="bold">SparkContext</strong> is launched <a id="_idIndexMarker435"/>and H2O is<a id="_idIndexMarker436"/> initialized in each worker node of the <a id="_idIndexMarker437"/>Spark cluster:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B16721_06_03.jpg" alt="Figure 6.3 – Sparkling Water internal backend mode&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.3 – Sparkling Water internal backend mode</p>
			<p>PySparkling is used to create an H2OContext and initialize worker nodes, as follows: </p>
			<pre class="source-code">from pysparkling import *</pre>
			<pre class="source-code">hc = H2OContext.getOrCreate()</pre>
			<p>This results in the following output:</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B16721_06_04.jpg" alt="Figure 6.4 – Sparkling Water cluster immediately after launch&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.4 – Sparkling Water cluster immediately after launch</p>
			<p>After the H2O<a id="_idIndexMarker438"/> server is launched, we interact with it using Python commands. We will start by importing the<a id="_idIndexMarker439"/> raw data.</p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor111"/>Importing the raw Amazon data</h2>
			<p>We import the <a id="_idIndexMarker440"/>Amazon training<a id="_idIndexMarker441"/> data into a <strong class="source-inline">reviews_spark</strong> Spark DataFrame, as follows:</p>
			<pre class="source-code">datafile = "AmazonReviews_Train.csv"</pre>
			<pre class="source-code">reviews_spark = spark.read.load(datafile, format="csv",</pre>
			<pre class="source-code">    sep=",", inferSchema="true", header="true")</pre>
			<p>As an alternative, we could have imported the data using H2O and then converted the <strong class="source-inline">reviews_h2o</strong> H2O frame to the <strong class="source-inline">reviews_spark</strong> Spark DataFrame, like so:</p>
			<pre class="source-code">import h2o</pre>
			<pre class="source-code">reviews_h2o = h2o.upload_file(datafile)</pre>
			<pre class="source-code">reviews_spark = hc.as_spark_frame(reviews_h2o)</pre>
			<p>This approach has the advantage of allowing us to use H2O Flow for interactive data exploration, as demonstrated in <a href="B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082"><em class="italic">Chapter 5</em></a>, <em class="italic">Advanced Model Building – Part I</em>, before converting to a Spark DataFrame. </p>
			<p>Next, we print out the data <a id="_idIndexMarker442"/>schema to show the input variables and variable types. This is done with the following code: </p>
			<pre class="source-code">reviews_spark.printSchema()</pre>
			<p>The resulting data schema<a id="_idIndexMarker443"/> is shown in the following screenshot: </p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B16721_06_05.jpg" alt="Figure 6.5 – Schema for Amazon Fine Food raw data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5 – Schema for Amazon Fine Food raw data</p>
			<p>For simplicity, we use only the <strong class="source-inline">Time</strong>, <strong class="source-inline">Summary</strong>, and overall <strong class="source-inline">Score</strong> columns in this analysis. <strong class="source-inline">Time</strong> is a date-time string, <strong class="source-inline">Score</strong> is an integer value between 1 and 5, from which sentiment is derived, and <strong class="source-inline">Summary</strong> is a short text summary of the product review. Note that the <strong class="source-inline">Text</strong> column contains the actual product review. A better model choice would include <strong class="source-inline">Text</strong> in place of—or perhaps in addition to—<strong class="source-inline">Summary</strong>. </p>
			<p>Save the input data schema into the <strong class="source-inline">schema.json</strong> file using the following code:</p>
			<pre class="source-code">with open('schema.json','w') as f:</pre>
			<pre class="source-code">    f.write(str(reviews_spark.schema.json()))</pre>
			<p>Saving the input data schema<a id="_idIndexMarker444"/> will make the deployment of the Sparkling Water pipeline a very simple matter. </p>
			<p class="callout-heading">Input Data and Production Data Structure</p>
			<p class="callout">Saving the data schema for deployment presumes that production data will use the same schema. As a data scientist building a Sparkling Water pipeline, we strongly recommend that your training input data exactly follows the production data schema. It is worth the extra effort to track this information down prior to model build rather than having to reengineer something at the deployment stage. </p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor112"/>Defining Spark pipeline stages</h2>
			<p>Spark pipelines are<a id="_idIndexMarker445"/> created by stringing individual data operations or transformers together. Each transformer takes as its input the output data from the <a id="_idIndexMarker446"/>preceding stage, which makes development for a data scientist very simple. A large job can be broken down into individual tasks that are daisy-chained together. </p>
			<p>Apache Spark operates through lazy evaluation. This means that computations do not execute immediately; rather, operations are cached and execution occurs when an action of some sort is triggered. This approach has many advantages, including allowing Spark to optimize its compute. </p>
			<p>In our example, all the data cleaning and feature engineering steps will be created through Spark transformers. The pipeline is finalized by training an H2O XGBoost model. For clarity, we will define a stage number for each transformer as we proceed in building the pipeline.</p>
			<h3>Stage 1 – Creating a transformer to select required columns</h3>
			<p>The Spark <strong class="source-inline">SQLTransformer</strong> class allows us to use SQL to munge data. The fact that most data scientists are already <a id="_idIndexMarker447"/>experienced with SQL makes for smooth adoption of Spark for data operations. <strong class="source-inline">SQLTransformer</strong> will be widely used in this pipeline. Run the following code to import the class:</p>
			<pre class="source-code">from pyspark.ml.feature import SQLTransformer</pre>
			<p>Define a <strong class="source-inline">colSelect</strong> transformer, like so:</p>
			<pre class="source-code">colSelect = SQLTransformer(</pre>
			<pre class="source-code">    statement="""</pre>
			<pre class="source-code">    SELECT Score, </pre>
			<pre class="source-code">           from_unixtime(Time) as Time, </pre>
			<pre class="source-code">           Summary </pre>
			<pre class="source-code">    FROM __THIS__""")</pre>
			<p>In the preceding code, we select the <strong class="source-inline">Score</strong>, <strong class="source-inline">Time</strong>, and <strong class="source-inline">Summary</strong> columns, converting the timestamp to a readable date-time string. <strong class="source-inline">__THIS__</strong> in the <strong class="source-inline">FROM</strong> statement references the output from the previous transformer stage. Since this is the first stage, <strong class="source-inline">__THIS__</strong> refers to the input data.</p>
			<p>During development, it is helpful to check results at each stage by calling the transformer directly. This makes it easy to debug transformer code and understand which inputs will be <a id="_idIndexMarker448"/>available for the next stage. Calling the transformer will cause Spark to execute it along with all unevaluated upstream code. The following code snippet illustrates how to call the transformer:</p>
			<pre class="source-code">selected = colSelect.transform(reviews_spark)</pre>
			<pre class="source-code">selected.show(n=10, truncate=False)</pre>
			<p>The first few rows are shown in the following screenshot:</p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B16721_06_06.jpg" alt="Figure 6.6 – Results from the colSelect stage 1 transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.6 – Results from the colSelect stage 1 transformer</p>
			<p>This first transformer has taken the original data and boiled it down to three columns. We will operate on each column separately to create our modeling-ready dataset. Let's begin with the <strong class="source-inline">Time</strong> column.</p>
			<h3>Stage 2 – Defining a transformer to create multiple time features</h3>
			<p>The goal of this model is to<a id="_idIndexMarker449"/> predict sentiment: was the review positive or negative? Date and time are factors that could arguably influence sentiment. Perhaps people give better reviews on Friday evenings because there is a weekend upcoming.</p>
			<p>The <strong class="source-inline">Time</strong> column is stored internally as a timestamp. To be useful in modeling, we need to extract the date-and-time information in a format that is understandable by the predictive algorithms we employ. We define an <strong class="source-inline">expandTime</strong> transformer using SparkSQL data methods (such as <strong class="source-inline">hour</strong>, <strong class="source-inline">month</strong>, and <strong class="source-inline">year</strong>) to engineer multiple new features from the raw timestamp information, as follows:</p>
			<pre class="source-code">expandTime = SQLTransformer(</pre>
			<pre class="source-code">    statement="""</pre>
			<pre class="source-code">    SELECT Score,</pre>
			<pre class="source-code">           Summary, </pre>
			<pre class="source-code">           dayofmonth(Time) as Day, </pre>
			<pre class="source-code">           month(Time) as Month, </pre>
			<pre class="source-code">           year(Time) as Year, </pre>
			<pre class="source-code">           weekofyear(Time) as WeekNum, </pre>
			<pre class="source-code">           date_format(Time, 'EEE') as Weekday, </pre>
			<pre class="source-code">           hour(Time) as HourOfDay, </pre>
			<pre class="source-code">           IF(date_format(Time, 'EEE')='Sat' OR</pre>
			<pre class="source-code">              date_format(Time, 'EEE')='Sun', 1, 0) as</pre>
			<pre class="source-code">              Weekend, </pre>
			<pre class="source-code">        CASE </pre>
			<pre class="source-code">          WHEN month(TIME)=12 OR month(Time)&lt;=2 THEN 'Winter' </pre>
			<pre class="source-code">          WHEN month(TIME)&gt;=3 OR month(Time)&lt;=5 THEN 'Spring' </pre>
			<pre class="source-code">          WHEN month(TIME)&gt;=6 AND month(Time)&lt;=9 THEN 'Summer' </pre>
			<pre class="source-code">          ELSE 'Fall' </pre>
			<pre class="source-code">        END as Season </pre>
			<pre class="source-code">    FROM __THIS__""")</pre>
			<p>Note that <strong class="source-inline">Score</strong> and <strong class="source-inline">Summary</strong> are selected in the <strong class="source-inline">expandTime</strong> code, but we do not operate on them. This simply passes those columns along to subsequent transformers. We engineer several features from the <strong class="source-inline">Time</strong> column: <strong class="source-inline">Day</strong>, <strong class="source-inline">Month</strong>, <strong class="source-inline">Year</strong>, <strong class="source-inline">WeekNum</strong>, <strong class="source-inline">Weekday</strong>, <strong class="source-inline">HourOfDay</strong>, <strong class="source-inline">Weekend</strong>, and <strong class="source-inline">Season</strong>. And once more, <strong class="source-inline">__THIS__</strong> refers to the output from the <strong class="source-inline">colSelect</strong> stage 1 transformer. </p>
			<p>To check our progress in development and perhaps debug our code, we inspect the output of the second <a id="_idIndexMarker450"/>stage, which uses as its input the first-stage results stored in <strong class="source-inline">selected</strong>, as illustrated in the following code snippet:</p>
			<pre class="source-code">expanded = expandTime.transform(selected)</pre>
			<pre class="source-code">expanded.show(n=10)</pre>
			<p>The output is shown in the following screenshot:</p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B16721_06_07.jpg" alt="Figure 6.7 – Results from the expandTime stage 2 transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.7 – Results from the expandTime stage 2 transformer</p>
			<p>The output confirms that we have successfully replaced the <strong class="source-inline">Time</strong> column with a collection of newly created features. </p>
			<h3>Stage 3 – Creating a response from Score while removing neutral reviews</h3>
			<p>In this stage, we create our <strong class="source-inline">Sentiment</strong> response variable using values from the <strong class="source-inline">Score</strong> column. We could<a id="_idIndexMarker451"/> model <em class="italic">positive</em> versus <em class="italic">not positive</em> as the response, but we choose to remove neutral reviews (<strong class="source-inline">Score=3</strong>) and compare <strong class="source-inline">Positive</strong> with <strong class="source-inline">Negative</strong>. This is a standard approach in <strong class="bold">net promoter score</strong> (<strong class="bold">NPS</strong>) analyses<a id="_idIndexMarker452"/> and is common in sentiment analysis. It makes sense because we assume that records with a neutral response contain little information the model could learn from.</p>
			<p>We create our <strong class="source-inline">createResponse</strong> transformer like so:</p>
			<pre class="source-code">createResponse = SQLTransformer(</pre>
			<pre class="source-code">    statement="""</pre>
			<pre class="source-code">    SELECT IF(Score &lt; 3,'Negative', 'Positive') as Sentiment,</pre>
			<pre class="source-code">           Day, Month, Year, WeekNum, Weekday, HourOfDay, </pre>
			<pre class="source-code">           Weekend, Season, Summary</pre>
			<pre class="source-code">    FROM __THIS__ WHERE Score != 3""")</pre>
			<p>The <strong class="source-inline">IF</strong> statement assigns scores of 1 or 2 to <strong class="source-inline">Negative</strong> sentiment and all others to <strong class="source-inline">Positive</strong>, filtering out neutral reviews with the <strong class="source-inline">WHERE</strong> clause. Now, inspect the results of this intermediate step by running the following code:</p>
			<pre class="source-code">created = createResponse.transform(expanded)</pre>
			<pre class="source-code">created.show(n=10)</pre>
			<p>This results in the following output: </p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B16721_06_08.jpg" alt="Figure 6.8 – Results from the createResponse stage 3 transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.8 – Results from the createResponse stage 3 transformer</p>
			<p>The only remaining feature engineering steps are those replacing the text in the <strong class="source-inline">Summary</strong> column with appropriately<a id="_idIndexMarker453"/> representative numerical values. Stages 4 through 8 will leverage Spark's built-in NLP data transformation capabilities to create features based on the text in <strong class="source-inline">Summary</strong>. While this is not a formal deep dive into NLP, we will describe each transformation step in enough detail to make our model understandable.</p>
			<h3>Stage 4 – Tokenizing the summary</h3>
			<p>Tokenization breaks<a id="_idIndexMarker454"/> a text sequence into individual terms. Spark provides a simple <strong class="source-inline">Tokenizer</strong> class and a more flexible <strong class="source-inline">RegexTokenizer</strong> class, which we use here. The <strong class="source-inline">pattern</strong> parameter specifies a <strong class="source-inline">"[!,\" ]"</strong> <strong class="bold">regular expression</strong> (<strong class="bold">regex</strong>) used <a id="_idIndexMarker455"/>to indicate how to split text into words. We split text on exclamation points, commas, quotes, and spaces (note the <strong class="source-inline">\"</strong> escaped <a id="_idIndexMarker456"/>quote in the regex), and we specify <strong class="bold">input and output</strong> (<strong class="bold">I/O</strong>) columns and force all words to lowercase, so that for example—<strong class="source-inline">This</strong> and <strong class="source-inline">this</strong> will be considered identical terms upon later processing. The code is illustrated in the following snippet:</p>
			<pre class="source-code">from pyspark.ml.feature import RegexTokenizer</pre>
			<pre class="source-code">regexTokenizer = RegexTokenizer(inputCol = "Summary",</pre>
			<pre class="source-code">                                outputCol = "Tokenized",</pre>
			<pre class="source-code">                                pattern = "[!,\"]",</pre>
			<pre class="source-code">                                toLowercase = True)</pre>
			<p>Inspect the tokenized values from <strong class="source-inline">Summary</strong>, as follows:</p>
			<pre class="source-code">tokenized = regexTokenizer.transform(created)</pre>
			<pre class="source-code">tokenized.select(["Tokenized"]).show(n = 10, </pre>
			<pre class="source-code">    truncate = False)</pre>
			<p>The output is shown in the following<a id="_idIndexMarker457"/> screenshot: </p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B16721_06_09.jpg" alt="Figure 6.9 – Results from the regexTokenizer stage 4 transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.9 – Results from the regexTokenizer stage 4 transformer</p>
			<p>Phrases have now been broken up into lists of individual terms or tokens. Since our goal is to extract information from these tokens, we next filter out words that carry little information.</p>
			<h3>Stage 5 – Removing stop words</h3>
			<p>Some words occur so frequently in language that they have very little predictive value. These are termed <em class="italic">stop words</em> and we use Spark's <strong class="source-inline">StopWordsRemover</strong> transformer to delete them, as illustrated in the following <a id="_idIndexMarker458"/>screenshot:</p>
			<pre class="source-code">removeStopWords = StopWordsRemover(</pre>
			<pre class="source-code">    inputCol = regexTokenizer.getOutputCol(),</pre>
			<pre class="source-code">    outputCol = "CleanedSummary", </pre>
			<pre class="source-code">    caseSensitive = False)</pre>
			<p>Let's compare the tokenized results before and after removing stop words, as follows:</p>
			<pre class="source-code">stopWordsRemoved = removeStopWords.transform(tokenized)</pre>
			<pre class="source-code">stopWordsRemoved.select(["Tokenized", </pre>
			<pre class="source-code">                         "CleanedSummary"]).show(</pre>
			<pre class="source-code">    n = 10, truncate = False)</pre>
			<p>The results are displayed in the following screenshot: </p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B16721_06_10.jpg" alt="Figure 6.10 – Results from the removeStopWords stage 5 transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 6.10 – Results from the removeStopWords stage 5 transformer</p>
			<p>Inspecting the results in <em class="italic">Figure 6.10</em> is illustrative. For the most part, removing stop words such as <strong class="source-inline">as</strong>, <strong class="source-inline">it</strong>, or <strong class="source-inline">the</strong> has little effect on meaning: the <em class="italic">Great! Just as good as the expensive brands!</em> statement being reduced to tokens <strong class="source-inline">[great, good, expensive, brands]</strong> seems reasonable. But what about <em class="italic">Not as advertised!</em> being reduced to <strong class="source-inline">[advertised]</strong>? The <strong class="source-inline">not</strong> in the statement would seem to carry important information that is lost by its removal. This is a valid concern that could be addressed by NLP concepts such as n-grams (bigrams, trigrams, and so on). For an example demonstrating Sparkling Water pipelines, we will acknowledge this as a potential issue but move on for simplicity.</p>
			<p>NLP in predictive modeling represents information in text as numbers. A popular approach is <strong class="bold">term frequency-inverse document frequency</strong> (<strong class="bold">TF-IDF</strong>). TF is simply the number of times a term appears<a id="_idIndexMarker459"/> in a document divided by the number of words in a document. In a corpus (collection of documents), IDF measures how rare a term is across its constituent documents. A term such as <em class="italic">linear</em> may have high frequency, but its information value decreases as the number of documents it appears in increases. On the other hand, a word such as <em class="italic">motorcycle</em> may have lower frequency but also be found in fewer documents in a corpus, making its information content higher. Multiplying TF by IDF gives a rescaled TF value that has proven quite useful. TF-IDF values are maximized when a term is found frequently but only in one document (<em class="italic">Which article reviewed motorcycles?</em>).</p>
			<p>TF-IDF is widely used in<a id="_idIndexMarker460"/> information retrieval, text mining, recommender systems, and search engines, as well as in predictive modeling. The next two pipeline stages will compute the TF and IDF values, respectively.</p>
			<h3>Stage 6 – Hashing words for TF</h3>
			<p>Our preferred way to <a id="_idIndexMarker461"/>compute TF in Spark is <strong class="source-inline">CountVectorizer</strong>, which preserves the mapping from the index back to the word using an internal vocabulary. That is, <strong class="source-inline">countVectorizerModel.vocabulary[5]</strong> looks up the word stored in index 5.</p>
			<p>A trick for building better TF-IDF models is to remove terms that are too infrequent by setting the <strong class="source-inline">minDF</strong> parameter as an integer or proportion, as follows:</p>
			<ul>
				<li><strong class="source-inline">minDF = 100</strong>: Omit terms that appear in fewer than 100 documents</li>
				<li><strong class="source-inline">minDF = 0.05</strong>: Omit terms that appear in fewer than 5% of documents</li>
			</ul>
			<p>A <strong class="source-inline">maxDF</strong> parameter is also available for removing terms that occur too frequently across a corpus. For instance, setting <strong class="source-inline">maxDF = 0.95</strong> in NLP for document retrieval might improve model performance.</p>
			<p>We create a <strong class="source-inline">countVectorizer</strong> transformer, as follows:</p>
			<pre class="source-code">from pyspark.ml.feature import CountVectorizer </pre>
			<pre class="source-code">countVectorizer = CountVectorizer(</pre>
			<pre class="source-code">    inputCol = removeStopWords.getOutputCol(),</pre>
			<pre class="source-code">    outputCol = "frequencies",</pre>
			<pre class="source-code">    minDF = 100 )</pre>
			<p>Note that our corpus is the output column of the <strong class="source-inline">removeStopWords</strong> transformer, with each row as a document. We output the frequencies and set <strong class="source-inline">minDF</strong> to 100. Because <strong class="source-inline">countVectorizer</strong> is a model, it is a good idea to manually train it before executing it in the pipeline. This is a good practice for any model that is a pipeline component as it allows us to determine its behavior and perhaps fine-tune it before pipeline execution commences. The code is illustrated in the following snippet:</p>
			<pre class="source-code">countVecModel = countVectorizer.fit(stopWordsRemoved)</pre>
			<p>We can explore this model by <a id="_idIndexMarker462"/>inspecting its vocabulary size and individual terms, as well as any other appropriate due diligence. Here's the code we'd need to accomplish this:</p>
			<pre class="source-code">print("Vocabulary size is " +</pre>
			<pre class="source-code">   str(len(countVecModel.vocabulary)))</pre>
			<pre class="source-code">print(countVecModel.vocabulary[:7])</pre>
			<p>The vocabulary results are shown here:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B16721_06_11.jpg" alt="Figure 6.11 – Vocabulary size and vocabulary of the countVecModel transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.11 – Vocabulary size and vocabulary of the countVecModel transformer</p>
			<p>Our total vocabulary size shown in <em class="italic">Figure 6.11</em> is 1,431 terms. Inspect the data with the following code:</p>
			<pre class="source-code">vectorized = countVecModel.transform(stopWordsRemoved)</pre>
			<pre class="source-code">vectorized.select(["CleanedSummary", "frequencies"]).show(</pre>
			<pre class="source-code">                  n = 10, truncate = False)</pre>
			<p>The vectorized result is shown in the following screenshot:</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B16721_06_12.jpg" alt="Figure 6.12 – Intermediate results from the countVecModel transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.12 – Intermediate results from the countVecModel transformer</p>
			<p><em class="italic">Figure 6.12</em> shows the cleaned <a id="_idIndexMarker463"/>summary tokens with TF vectors side by side for each row. To describe the output for the first row, the 1431 value is the vocabulary size. The next sequence of values—<strong class="source-inline">[1,10,11,38]</strong>—refers to the indices of the <strong class="source-inline">[good, quality, dog, food]</strong> terms in the vocabulary vector. The last series of values— <strong class="source-inline">[1.0,1.0,1.0,1.0]</strong>—are the TFs for their respective terms. Thus, <strong class="source-inline">dog</strong> is referenced by index <strong class="source-inline">11</strong> and occurs once in the <strong class="source-inline">CleanedSummary</strong> column.</p>
			<h3>Stage 7 – Creating an IDF model</h3>
			<p>We use Spark's <strong class="source-inline">IDF</strong> estimator to scale frequencies from <strong class="source-inline">countVectorizer</strong>, yielding TF-IDF values. We execute the<a id="_idIndexMarker464"/> following code to accomplish this:</p>
			<pre class="source-code">from pyspark.ml.feature import IDF</pre>
			<pre class="source-code">idf = IDF(inputCol = countVectorizer.getOutputCol(),</pre>
			<pre class="source-code">          outputCol = "TFIDF",</pre>
			<pre class="source-code">          minDocFreq = 1)</pre>
			<p>Manually train the IDF model to see the results before we execute the pipeline, like so:</p>
			<pre class="source-code">idfModel = idf.fit(vectorized)</pre>
			<p>Inspect the data again, noting especially the scaled TF-IDF frequencies, as follows: </p>
			<pre class="source-code">afterIdf = idfModel.transform(vectorized)</pre>
			<pre class="source-code">afterIdf.select(["Sentiment", "CleanedSummary",</pre>
			<pre class="source-code">    "TFIDF"]).show(n = 5, truncate = False, vertical = True)</pre>
			<p>The first five rows of the<a id="_idIndexMarker465"/> resulting TF-IDF model are shown in the following screenshot:</p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B16721_06_13.jpg" alt="Figure 6.13 – TF-IDF frequencies from the Spark transformer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.13 – TF-IDF frequencies from the Spark transformer</p>
			<h3>Stage 8 – Selecting modeling dataset columns </h3>
			<p>In addition to the <strong class="source-inline">Sentiment</strong> response<a id="_idIndexMarker466"/> variable and all the features engineered from the <strong class="source-inline">Time</strong> variable, the output of <strong class="source-inline">idf</strong> includes the original <strong class="source-inline">Summary</strong> column as well as <strong class="source-inline">Tokenized</strong>, <strong class="source-inline">CleanedSummary</strong>, <strong class="source-inline">frequencies</strong>, and <strong class="source-inline">TFIDF</strong>. Of these, we wish to keep only <strong class="source-inline">TFIDF</strong>. The following code selects the desired columns:</p>
			<pre class="source-code">finalSelect = SQLTransformer(</pre>
			<pre class="source-code">    statement="""</pre>
			<pre class="source-code">    SELECT Sentiment, Day, Month, Year, WeekNum, Weekday,</pre>
			<pre class="source-code">           HourOfDay, Weekend, Season, TFIDF</pre>
			<pre class="source-code">    FROM __THIS__ """)</pre>
			<p>Now that we are finished building our model-ready data, the next step is to build a predictive model using one of H2O's supervised learning algorithms.</p>
			<h3>Stage 9 – Creating an XGBoost model using H2O</h3>
			<p>Up to this point, all our data <a id="_idIndexMarker467"/>wrangling and feature engineering efforts have used Spark methods exclusively. Now, we turn to H2O to train an XGBoost model on the <strong class="source-inline">Sentiment</strong> column. For simplicity, we train using default settings. The code is illustrated in the following snippet:</p>
			<pre class="source-code">import h2o</pre>
			<pre class="source-code">from pysparkling.ml import ColumnPruner, H2OXGBoost</pre>
			<pre class="source-code">xgboost = H2OXGBoost(splitRatio = 0.8, labelCol = "Sentiment")</pre>
			<p class="callout-heading">Note – Training Models in Sparkling Water</p>
			<p class="callout">In <a href="B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082"><em class="italic">Chapter 5</em></a>, <em class="italic">Advanced Model Building – Part I</em>, we demonstrated in detail a process for building and tuning a high-quality XGBoost model. We stop at a simple baseline model here to emphasize the utility of the overall pipeline. In a real application, much more effort should be spent on the modeling component of this pipeline.</p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor113"/>Creating a Sparkling Water pipeline</h2>
			<p>Now that we have all the <a id="_idIndexMarker468"/>transformers defined, we are ready to create a pipeline. Doing so is simple—we just name each transformer in order in the <strong class="source-inline">stages</strong> list parameter of <strong class="source-inline">Pipeline</strong>, as follows:</p>
			<pre class="source-code">from pyspark.ml import Pipeline</pre>
			<pre class="source-code">pipeline = Pipeline(stages = [</pre>
			<pre class="source-code">    colSelect, expandTime, createResponse, regexTokenizer,</pre>
			<pre class="source-code">    removeStopWords, countVectorizer, idf, finalSelect,</pre>
			<pre class="source-code">    xgboost])</pre>
			<p>Training the pipeline model is made simple by using the <strong class="source-inline">fit</strong> method. We pass as a parameter the Spark DataFrame containing the raw data, as follows: </p>
			<pre class="source-code">model = pipeline.fit(reviews_spark)</pre>
			<p>During the <strong class="source-inline">pipeline.fit</strong> process, the data munging and feature engineering stages are all applied to the raw data in the<a id="_idIndexMarker469"/> order defined before the XGBoost model is fit. These pipeline stages operate identically after deployment in production with the XGBoost stage, producing predictions.</p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor114"/>Looking ahead – a production preview</h2>
			<p>Putting the Sparkling Water <a id="_idIndexMarker470"/>pipeline into production is simply a matter of <em class="italic">saving</em> the <strong class="source-inline">pipeline</strong> model, <em class="italic">loading</em> it onto the production system, then calling the following: </p>
			<pre class="source-code">predictions = model.transform(input_data)</pre>
			<p>In <a href="B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178"><em class="italic">Chapter 10</em></a>, <em class="italic">H2O Model Deployment Patterns</em>, we show how to deploy this pipeline as a Spark streaming application, with the pipeline receiving raw streaming data and outputting predictions in real time.</p>
			<h1 id="_idParaDest-115"><a id="_idTextAnchor115"/>UL methods in H2O</h1>
			<p>H2O includes several unsupervised learning<a id="_idIndexMarker471"/> algorithms including <strong class="bold">Generalized Low Rank Models</strong> (<strong class="bold">GLRM</strong>), <strong class="bold">Principal Component Analysis</strong> (<strong class="bold">PCA</strong>), and an aggregator for dimensionality reduction. Clustering use cases can utilize k-means<a id="_idIndexMarker472"/> clustering, H2O aggregator, GLRM, or PCA. Unsupervised learning also underlies a set of useful feature transformers <a id="_idIndexMarker473"/>used in predictive modeling applications—for <a id="_idIndexMarker474"/>example, the distance of an observation to a specific data cluster identified by an unsupervised method. In addition, H2O provides an isolation forest algorithm for anomaly detection.</p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor116"/>What is anomaly detection?</h2>
			<p>Most <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) algorithms attempt, in <a id="_idIndexMarker475"/>some manner, to find patterns in data. These <a id="_idIndexMarker476"/>patterns are leveraged to make predictions in supervised learning models. Many unsupervised learning algorithms try to uncover patterns through clustering similar data or estimating boundaries between data segments. Unsupervised anomaly detection algorithms take the opposite approach: data points that do not follow known patterns are what we want to discover.</p>
			<p>In this context, the term <em class="italic">anomaly</em> is value-free. It may refer to an unusual observation because it is the first of its kind; more data could yield additional similar observations. Anomalies might be indicative of unexpected events and serve as a diagnostic. For instance, a failed sensor in a <a id="_idIndexMarker477"/>manufacturing data-collection application could yield atypical measurements. Anomalies may also indicate malicious actors or actions: security breaches and fraud are two classic examples resulting in anomalous data points. </p>
			<p>Anomaly detection approaches may include supervised, semi-supervised, or unsupervised methods. Supervised models are the gold standard in fraud detection. However, obtaining labels for each observation can be costly and is often not feasible. An unsupervised approach is required when labels are absent. Semi-supervised approaches refer to situations where only some of the data records are labeled, usually a small minority of records.</p>
			<p>Isolation forest is a unsupervised learning algorithm for anomaly detection—we'll introduce this next.</p>
			<h2 id="_idParaDest-117"><a id="_idTextAnchor117"/>Isolation forests in H2O</h2>
			<p>The isolation forest algorithm is based <a id="_idIndexMarker478"/>on decision trees and a clever observation: outliers tend to be split out very early in the building of a decision tree. But decision<a id="_idIndexMarker479"/> trees are a supervised method, so how is this unsupervised? The trick is to create a target column of random values and train a decision tree on it. We repeat this many times and record the average depth at which observations are split into their own leaf. The earlier an observation is isolated, the more likely it is to be anomalous. Depending on the use case, these anomalous points may be filtered out or escalated for further investigation.</p>
			<p>You can see a representation of an isolation forest in the following screenshot:</p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B16721_06_14.jpg" alt="Figure 6.14 – An isolation forest&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.14 – An isolation forest</p>
			<p>We show how to build an isolation forest in H2O using the Kaggle credit card transaction data (<a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">https://www.kaggle.com/mlg-ulb/creditcardfraud</a>). There are 492 fraudulent and 284,807 non-fraudulent transactions in this dataset, which makes the target class highly imbalanced. Because <a id="_idIndexMarker480"/>we are demonstrating an unsupervised anomaly detection <a id="_idIndexMarker481"/>approach, we will drop the labeled target during the model build. </p>
			<p>The H2O code for loading the data is shown here:</p>
			<pre class="source-code">df = h2o.import_file("creditcardfraud.csv")</pre>
			<p>We fit our isolation forest using the <strong class="source-inline">H2OIsolationForestEstimator</strong> method. We set the number of trees to <strong class="source-inline">100</strong> and omit the last column, which contains the target class label, as shown in the following code snippet:</p>
			<pre class="source-code">iso = h2o.estimators.H2OIsolationForestEstimator(</pre>
			<pre class="source-code">    ntrees = 100, seed = 12345)</pre>
			<pre class="source-code">iso.train(x = df.col_names[0:31], training_frame = df)</pre>
			<p>Once the model is trained, prediction is straightforward, as we can see here:</p>
			<pre class="source-code">predictions = iso.predict(df)</pre>
			<pre class="source-code">predictions</pre>
			<p>The output is shown in the following screenshot: </p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B16721_06_15.jpg" alt="Figure 6.15 – Isolation forest predictions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.15 – Isolation forest predictions</p>
			<p>The predictions in <em class="italic">Figure 6.15</em> consist of two columns: the normalized anomaly score and the average number of splits across all trees to isolate the observation. Note that the anomaly score is perfectly <a id="_idIndexMarker482"/>correlated with mean length, increasing as mean length decreases.</p>
			<p>How do we go from either<a id="_idIndexMarker483"/> an anomaly score or mean length to an actual prediction? One of the best ways is through a quantile-based threshold. If we have an idea about the prevalence of fraud, we can find the corresponding quantile value of the score and use it as a threshold for our predictions. Suppose we know that 5% of our transactions are fraudulent. Then, we estimate the correct quantile using the following H2O code:</p>
			<pre class="source-code">quantile = 0.95</pre>
			<pre class="source-code">quantile_frame = predictions.quantile([quantile])</pre>
			<pre class="source-code">quantile_frame</pre>
			<p>The resulting quantile output is shown in the following screenshot: </p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B16721_06_16.jpg" alt="Figure 6.16 – Choosing a quantile-based threshold&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.16 – Choosing a quantile-based threshold</p>
			<p>We now can use the threshold to predict the anomalous class using the following code:</p>
			<pre class="source-code">threshold = quantile_frame[0, "predictQuantiles"]</pre>
			<pre class="source-code">predictions["predicted_class"] = \</pre>
			<pre class="source-code">    predictions["predict"] &gt; threshold</pre>
			<pre class="source-code">predictions["class"] = df["class"]</pre>
			<pre class="source-code">predictions</pre>
			<p>The first 10 <a id="_idIndexMarker484"/>observations of the <strong class="source-inline">predictions</strong> frame are shown in the following screenshot: </p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B16721_06_17.jpg" alt="Figure 6.17 – Identifying anomalous values &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.17 – Identifying anomalous values </p>
			<p>The <strong class="source-inline">predict</strong> column in <em class="italic">Figure 6.17</em> has only one observation greater than 0.198324, the threshold for the 95th percentile shown in <em class="italic">Figure 6.16</em>. The <strong class="source-inline">predicted_class</strong> column indicates this <a id="_idIndexMarker485"/>with a value of <strong class="source-inline">1</strong>. Also, note that the <strong class="source-inline">mean_length</strong> value for this observation of <strong class="source-inline">6.14</strong> is less than the mean length values for the other nine observations. </p>
			<p>The <strong class="source-inline">class</strong> column contains the transaction fraud indicator that we omitted in building the unsupervised isolation forest model. For the anomalous observation, a class value of <strong class="source-inline">0</strong> indicates that the transaction was not fraudulent. When we have access to an actual target value as in this example, we could use the <strong class="source-inline">predicted_class</strong> and <strong class="source-inline">class</strong> columns to study the effectiveness of the anomaly detection algorithm in detecting fraud. We should note that the definition of fraud and anomalous in this context are not equivalent. In other words, not <a id="_idIndexMarker486"/>all frauds are anomalous and not all anomalies will indicate fraud. These two <a id="_idIndexMarker487"/>models have separate, albeit complementary, purposes. </p>
			<p>We now turn our attention to updating models.</p>
			<h1 id="_idParaDest-118"><a id="_idTextAnchor118"/>Best practices for updating H2O models</h1>
			<p>As the famous British statistician George Box stated, <em class="italic">All models are wrong, but some are useful</em>. Good modelers <a id="_idIndexMarker488"/>are aware of the purpose as well as the <a id="_idIndexMarker489"/>limitations of their models. This should be especially true for those who build enterprise models that go into production. </p>
			<p>One such limitation is that predictive models as a rule degrade over time. This is largely because, in the real world, things change. Perhaps what we are modeling—customer behavior, for example—itself changes, and the data we collect reflects that change. Even if customer behavior is static but our mix of business changes (think more teenagers and fewer retirees), our model's predictions will likely degrade. In both cases but for different reasons, the population that was sampled to create our predictive model is not the same now as it was before. </p>
			<p>Detecting model degradation and searching for its root cause is the subject of diagnostics and model monitoring, which we do not address here. Rather, once a model is no longer satisfactory, what should a data scientist do? We address retraining and checkpointing models in the following sections.</p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor119"/>Retraining models</h2>
			<p>Developing a <a id="_idIndexMarker490"/>parametric model entails: </p>
			<ol>
				<li>Finding the correct structural form for the process being modeled and then </li>
				<li>Using data to estimate the parameters of that structure. Over time, if the structure of the model remains the same but the data changes, then we could <em class="italic">refit</em> (or <em class="italic">retrain</em> or <em class="italic">re-estimate</em> or <em class="italic">update</em>) the model's parameter estimates. This is a simple and relatively straightforward procedure. </li>
			</ol>
			<p>However, if the underlying process changes in a way that means the structural form of the model is no longer valid, then modeling consists of both discovering the correct form of the model and estimating parameters. This is almost, but not quite, the same thing as starting from scratch. <em class="italic">Rebuilding</em> or <em class="italic">updating the model</em> (as opposed to <em class="italic">updating the parameter estimates</em>) are better terms for this larger activity.</p>
			<p>In the case of ML or other nonparametric models, the structural form of the model is determined by the data along with any parameter estimates. This is one of the selling points of nonparametric<a id="_idIndexMarker491"/> models: they are incredibly data-driven and nearly assumption-free. The differences between refitting or retraining and rebuilding have little meaning in this context; these terms become, in effect, synonyms. </p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor120"/>Checkpointing models</h2>
			<p>The <strong class="bold">Checkpoint</strong> option in H2O lets you save the <a id="_idIndexMarker492"/>state of a model build, allowing a new model to be built as a <em class="italic">continuation</em> of a previously generated model rather than building one from scratch. This can be used to update a model in production with additional, more current data. </p>
			<p>The checkpoint <a id="_idIndexMarker493"/>option is available for <strong class="bold">Distributed Random Forest</strong> (<strong class="bold">DRF</strong>), <strong class="bold">Gradient Boosting Machine</strong> (<strong class="bold">GBM</strong>), XGBoost, and <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) algorithms. For<a id="_idIndexMarker494"/> tree-based algorithms, the <a id="_idIndexMarker495"/>number of trees specified must be greater than the number of trees in the referenced model. That is, if the original model included 20 trees and you specify 30 trees, then 10 new trees will be built. The same concept is true for DL using epochs rather than trees.</p>
			<p>Checkpointing is feasible for these algorithms <em class="italic">only</em> when the following are the same as the checkpointed model:</p>
			<ul>
				<li>The training data model type, response type, columns, categorical factor levels, and the total number of predictors</li>
				<li>The identical validation dataset if one was used in the checkpointed model (cross-validation is not currently supported for checkpointing)</li>
			</ul>
			<p>Additional parameters that you can specify with checkpointing vary based on the algorithm that was used for model training.</p>
			<p class="callout-heading">Checkpointing Caveats</p>
			<p class="callout">Although it is technically feasible, we do not recommend checkpointing on new data for GBM or XGBoost algorithms. Recall that boosting works by fitting sequential models to the residuals of previous models. The early splits are thus the most important. By the time new data has been introduced, the structure of the model has been largely determined in its absence.</p>
			<p class="callout">Checkpointing <strong class="bold">random forest</strong> models <a id="_idIndexMarker496"/>does not suffer from these concerns due to differences between boosting and bagging. </p>
			<h1 id="_idParaDest-121"><a id="_idTextAnchor121"/>Ensuring H2O model reproducibility</h1>
			<p>In a laboratory or<a id="_idIndexMarker497"/> experimental setting, repeating a process under the same protocols and conditions should lead to similar results. Natural variability may of course occur, but this can be measured and attributed to appropriate factors. This is termed <em class="italic">repeatability</em>. The enterprise data scientist should ensure that their model builds are well coded and sufficiently documented to make the process repeatable.</p>
			<p><strong class="bold">Reproducibility</strong> in the context of model <a id="_idIndexMarker498"/>building is a much stronger condition: the results when a process is repeated must be identical. From a regulatory or compliance perspective, reproducibility may be required.</p>
			<p>At a high level, reproducibility requires the same hardware, software, data, and settings. Let's review this specifically for H2O setups. We begin with two cases depending on the H2O cluster type.</p>
			<h2 id="_idParaDest-122"><a id="_idTextAnchor122"/>Case 1 – Reproducibility in single-node clusters</h2>
			<p>A single-node cluster is the<a id="_idIndexMarker499"/> simplest H2O hardware configuration. Reproducibility can be attained if the following conditions are met:</p>
			<ul>
				<li><strong class="bold">Software requirements</strong>: The same version of H2O-3 or Sparkling Water is used.</li>
				<li><strong class="bold">Data requirements</strong>: The same training data is used (note that H2O requires files to be imported individually rather than as an entire directory to guarantee reproducibility).</li>
				<li><strong class="bold">Settings requirements</strong>:<ul><li>The same parameters are used to train the model.</li><li>If sampling is <a id="_idIndexMarker500"/>done in the algorithm, the same seed is required. This includes any of the following: <strong class="source-inline">sample_rate</strong>, <strong class="source-inline">sample_rate_per_class</strong>, <strong class="source-inline">col_sample_rate</strong>, <strong class="source-inline">col_sample_rate_per_level</strong>, <strong class="source-inline">col_sample_rate_per_tree</strong>.</li><li>If early stopping is enabled, reproducibility is only guaranteed when the <strong class="source-inline">score_tree_interval</strong> parameter is explicitly set and the same validation dataset is used.</li></ul></li>
			</ul>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor123"/>Case 2 – Reproducibility in multi-node clusters</h2>
			<p>Adding nodes to a<a id="_idIndexMarker501"/> cluster creates additional hardware conditions that must be met in order to achieve reproducibility. The software, data, and settings requirements are the same as in single-node clusters detailed previously in <em class="italic">Case 1</em>. These requirements are outlined here:</p>
			<ul>
				<li>The hardware cluster must be configured identically. Specifically, clusters must have the same number of nodes with the same number of CPU cores per node or—alternatively—the same restriction on the number of threads.</li>
				<li>The cluster's leader node must initiate model training. In Hadoop, the leader node is automatically returned to the user. In standalone deployments, the leader node must be manually identified. See the H2O documentation for more details.</li>
			</ul>
			<p>For reproducibility, you must ensure that the cluster configuration is identical. The parallelization level (number of nodes and CPU cores/threads) controls how a dataset is partitioned in memory. H2O runs its tasks in a predictable order on these partitions. If the number of partitions is different, the results will not be reproducible.</p>
			<p>In cases where the cluster configuration is not identical, it may be possible to constrain the resources of computations being reproduced. This process involves replicating data partitions in the original environment. We refer you to the H2O documentation for more information.</p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor124"/>Reproducibility for specific algorithms </h2>
			<p>The complexity of DL, GBM, and <strong class="bold">automated ML</strong> (<strong class="bold">AutoML</strong>) algorithms introduces additional<a id="_idIndexMarker502"/> constraints that must be met in order to ensure reproducibility. We will review these requirements in this section.</p>
			<h3>DL</h3>
			<p>H2O DL models are not<a id="_idIndexMarker503"/> reproducible by default for performance reasons. There is a <strong class="source-inline">reproducible</strong> option that can be enabled, but we recommend doing this only for small data. The model takes significantly more time to generate because only one thread is used for computation.</p>
			<h3>GBM</h3>
			<p>GBM is deterministic <a id="_idIndexMarker504"/>up to floating-point rounding errors when reproducibility criteria are met for single- or multi-node clusters.</p>
			<h3>AutoML</h3>
			<p>To ensure<a id="_idIndexMarker505"/> reproducibility in AutoML, the following criteria must be met:</p>
			<ul>
				<li>DL must be excluded.</li>
				<li>The <strong class="source-inline">max_models</strong> constraint rather than <strong class="source-inline">max_runtime_secs</strong> must be used. </li>
			</ul>
			<p>As a rule, time-based constraints are resource-limited. This means that AutoML may be able to train more models on one run than another if available compute resources differ between runs. Specifying the number of models to build will ensure reproducibility.</p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor125"/>Best practices for reproducibility</h2>
			<p>To ensure reproducibility, think <a id="_idIndexMarker506"/>of the four requirement categories emphasized earlier: hardware, software, data, and settings. These categories are explained in more detail here:</p>
			<ul>
				<li><strong class="bold">Hardware</strong>: You should always document the hardware resources the H2O cluster is running on—this includes the number of nodes, CPU cores, and threads. (This information can be found in the log files.)   </li>
				<li><strong class="bold">Software</strong>: You should document the version of H2O-3 or Sparkling Water used. (This information can be found in the log files.)</li>
				<li><strong class="bold">Data</strong>: Obviously, you must use the same input data. You should save all scripts that were used to process the data prior to model training. All data column modifications should be documented (for example, if you converted a numeric column to a categorical one).</li>
				<li><strong class="bold">Settings</strong>: Save the H2O<a id="_idIndexMarker507"/> logs and the H2O binary model. The logs contain a wealth of information. More importantly, the binary model contains the H2O version (software) and the parameters used to train the model (settings).</li>
			</ul>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor126"/>Summary </h1>
			<p>In this chapter, we have rounded out our advanced modeling topics by showing how to build H2O models in Spark pipelines with a hands-on sentiment analysis modeling example. We summarized the unsupervised learning methods available in H2O and showed how to build an anomaly detection model using the isolation forest algorithm for a credit card fraud transaction use case. We also reviewed how to update models, including refitting versus checkpointing, and showed requirements to ensure model reproducibility.</p>
			<p>In <a href="B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 7</em></a>, <em class="italic">Understanding ML Models,</em> we discuss approaches for understanding and reviewing our ML models.</p>
		</div>
	</body></html>