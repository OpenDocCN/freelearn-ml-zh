- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Making Use of Big Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although today’s most exciting machine learning research is found in the realm
    of big data—computer vision, natural language processing, autonomous vehicles,
    and so on—most business applications are much smaller scale, using what might
    be termed, at best, “*medium*” data. As noted in *Chapter 12*, *Advanced Data
    Preparation*, true big data work requires access to datasets and computing facilities
    generally found only at very large tech companies or research universities. Even
    then, the actual job of using these resources is often primarily a feat of data
    engineering, which simplifies the data greatly before its use in conventional
    business applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The good news is that the headline-making research conducted at big data companies
    eventually trickles down and can be applied in simpler forms to more traditional
    machine learning tasks. This chapter covers a variety of approaches for making
    use of such big data methods in R. You will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: How to borrow from the deep learning models developed at big data companies
    and apply them to conventional modeling tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategies for reducing the complexity of large and unstructured big data formats
    like text and images so that they can be used for prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cutting-edge packages and approaches for accessing and modeling big datasets
    that may be too large to fit into memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite R’s reputation for being ill equipped for big data projects, the efforts
    of the R community have gradually transformed it into a tool capable of tackling
    a surprising number of advanced tasks. The goal of this chapter is to demonstrate
    R’s ability to remain relevant in the era of deep learning and big data. Even
    though R is unlikely to be found at the heart of the biggest big data projects,
    and despite facing increasing competition from Python and cloud-based tools, R’s
    strengths keep it on the desktops of many practicing data scientists.
  prefs: []
  type: TYPE_NORMAL
- en: Practical applications of deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning has received a great deal of attention lately due to its successes
    in tackling machine learning tasks that have been notoriously difficult to solve
    with conventional methods. Using sophisticated neural networks to teach computers
    to think more like a human has allowed machines to catch up with or even surpass
    human performance on many tasks that humans once held a seemingly insurmountable
    lead. Perhaps more importantly, even if humans still perform better at certain
    tasks, the upsides of machine learning—workers that never tire, never get bored,
    and require no salary—turn even imperfect automatons into useful tools for many
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, for those of us working outside of large technology companies
    and research organizations, it is not always easy to take advantage of deep learning
    methods. Training a deep learning model generally requires not only state-of-the-art
    computing hardware but also large volumes of training data. In fact, as mentioned
    in *Chapter 12*, *Advanced Data Preparation*, most practical machine learning
    applications in the business setting are in the so-called small or medium data
    regimes, and here deep learning methods might perform no better and possibly even
    worse than conventional machine learning approaches like regression and decision
    trees. Thus, many organizations that are investing heavily in deep learning are
    doing so as a result of hype rather than true need.
  prefs: []
  type: TYPE_NORMAL
- en: Even though some of the buzz around deep learning is surely based on its novelty
    as well as excitement from business leaders with visions of artificial intelligence
    replacing costly human workers, there are in fact practical applications of the
    technique that can be used in combination with, rather than as a replacement for,
    conventional machine learning methods. The purpose of this chapter is therefore
    not to provide a start-to-finish tutorial for building deep neural networks, but
    rather to show how deep learning’s successes can be incorporated into conventional
    machine learning projects including those outside the big data regime.
  prefs: []
  type: TYPE_NORMAL
- en: 'Packt Publishing offers numerous resources on deep learning, such as *Hands-On
    Deep Learning with R: A practical guide to designing, building, and improving
    neural network models using R* (2020) by M. Pawlus and R. Devine, *Advanced Deep
    Learning with R* (2019) by B. Rai, and *Deep Learning with R Cookbook* (2020)
    by S. Gupta, R. A. Ansari, and D. Sarkar.'
  prefs: []
  type: TYPE_NORMAL
- en: Beginning with deep learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years, with a new cohort of data science practitioners having been
    trained in the age of deep learning, a form of “generation gap” has developed
    in the machine learning community. Prior to the development of deep learning,
    the field was staffed primarily by those who were trained in statistics or computer
    science. Especially in the earliest years, machine learning practitioners carried
    with them the metaphorical baggage of their prior domain, and the software and
    algorithms they used fell into camps along party lines. Statisticians typically
    preferred regression-based techniques and software like R, whereas computer scientists
    favored iterative and heuristic-based algorithms like decision trees written in
    languages like Python and Java. Deep learning has blurred the line between these
    camps, and the next generation of data scientists may seem somewhat foreign to
    the prior generations as if they speak a different language.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rift seems to have come out of nowhere, despite being able to see its origins
    clearly with the benefit of hindsight. As the famous author Ernest Hemingway once
    wrote, it happened “gradually, then suddenly.” Just as machine learning itself
    was only possible as the result of the simultaneous evolution of computing power,
    statistical methods, and available data, it makes sense that the next big evolutionary
    leap would arise out of a series of smaller evolutions in each of the same three
    components. Recalling the similar image presented in *Chapter 1*, *Introducing
    Machine Learning*, a revised cycle of advancement diagram depicting today’s state-of-the-art
    machine learning cycle illustrates the environment in which deep learning was
    developed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.1: A combination of factors in the cycle of advancement led to the
    development of deep learning'
  prefs: []
  type: TYPE_NORMAL
- en: It is no surprise that deep learning arose out of the big data era, while also
    being provided the requisite computing hardware—**graphics processing units**
    (**GPUs**) and cloud-based parallel processing tools, which will be covered later
    in this chapter—necessary to process datasets that are both very long and very
    wide. What is less obvious, and therefore easy to take for granted, is the academic
    and research environment that was also necessary for this evolution. Without a
    strong data science community comprising researchers whose expertise spans both
    statistics and computer science, in addition to applied data scientists motivated
    to solve practical business problems on large and complex real-world datasets,
    it is unlikely that deep learning would have arisen as it has. Stated differently,
    the fact that data science now exists as a focused academic discipline has undoubtedly
    accelerated the cycle of advancement. To borrow an analogy from science fiction,
    the system is much like a robot that becomes self-aware and learns much more quickly
    now that it has learned how to learn!
  prefs: []
  type: TYPE_NORMAL
- en: The rapid development of deep learning has contributed to the previously mentioned
    generation gap, but it is not the only factor. As you will soon learn, deep learning
    not only offers impressive performance on big data tasks, but it can also perform
    much like conventional learning methods on smaller tasks. This has led some to
    focus almost exclusively on the technique, much like earlier generations of machine
    learning practitioners focused exclusively on regression or decision trees. The
    fact that deep learning also utilizes specialized software tools and mathematical
    terminology to perform these tasks means that its practitioners are, in some cases,
    literally speaking another language to describe the same series of steps. As has
    been said many times before, “there is no free lunch” in the field of machine
    learning, so as you continue your machine learning journey, it is best to see
    it as one of many useful tools—and not the *only* tool for the job.
  prefs: []
  type: TYPE_NORMAL
- en: The terminology used by deep learning practitioners, even for simpler methods
    like linear regression, includes phrases like “cost function,” “gradient descent,”
    and “optimization.” This is a good reminder that although deep learning can approximate
    regression and other machine learning methods, the means by which it finds the
    solution is completely different.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing appropriate tasks for deep learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned in *Chapter 7*, *Black-Box Methods – Neural Networks and Support
    Vector Machines*, neural networks with at least one hidden layer can act as universal
    function approximators. Elaborating on this principle, one might say that given
    enough training data, a cleverly designed neural network can learn to mimic the
    output of any other function.
  prefs: []
  type: TYPE_NORMAL
- en: This implies that the conventional learning methods covered throughout this
    book can likewise be approximated by well-designed neural networks. In fact, it
    is quite trivial to design a neural network that almost exactly matches linear
    or logistic regression, and with a bit more work it is possible to approximate
    techniques like k-nearest neighbors and naive Bayes. Given enough data, a neural
    network can get closer and closer to the performance of even the best tree-based
    algorithms like random forests or gradient boosting machines.
  prefs: []
  type: TYPE_NORMAL
- en: Why not apply deep learning to every problem, then? Indeed, a neural network’s
    ability to mimic all other learning approaches appears to be a violation of the
    “no free lunch” theorem, which, put simply, suggests that there is no machine
    learning algorithm that can perform best across all potential modeling tasks.
    There are a couple of key reasons why the theorem remains safe despite deep learning’s
    magic. First, the ability of a neural network to approximate a function is related
    to how much training data it has. In the small data regime, conventional techniques
    can perform better, especially when combined with careful feature engineering.
    Second, to reduce the amount of data the neural network needs for training, the
    network must have a topology that facilitates its ability to learn the underlying
    function. Of course, if the person building the model knows what topology to use,
    then it may be preferable to use the simpler conventional model in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: People using deep learning for conventional learning tasks are likely to prefer
    the black box approach, which works in the big data regime. Big data, however,
    is not merely the presence of many rows of data, but also many features. Most
    conventional learning tasks, including those with many millions of rows of data,
    are in the medium data regime, where conventional learning algorithms still perform
    well. In this case, whether the neural network performs better will ultimately
    come down to the balance of overfitting and underfitting—a balance that is sometimes
    challenging to find with a neural network, as the method tends to somewhat easily
    overfit the training data.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps for this reason, deep learning is not well suited for racking up wins
    in machine learning competitions. If you ask a Kaggle Grandmaster, they are likely
    to tell you that neural networks don’t work on standard, real-life problems, and
    on traditional supervised learning tasks, gradient boosting wins. One can also
    see proof of this by browsing the leaderboards and noting the absence of deep
    learning. Perhaps a clever team will use neural networks for feature engineering
    and blend the deep learning model with other models in an ensemble to boost their
    performance, but even this is rare. Deep learning’s strengths are elsewhere. As
    a rule of thumb, tree-based ensemble methods win on structured, tabular data,
    while neural networks win on unstructured data, like image, sound, and text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reading recent news about research breakthroughs and technology startup companies,
    one is likely to encounter deep learning applications that utilize the method’s
    unique ability to solve unconventional tasks. In general, these unconventional
    learning tasks fall into one of three categories: computer vision, natural language
    processing, or tasks involving unusual data formats like repeated measurements
    over time or having an exceptionally large number of interrelated predictors.
    A selection of specific successes for each category is listed in the following
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Challenging machine learning tasks** | **Deep learning successes** |'
  prefs: []
  type: TYPE_TB
- en: '| Computer vision tasks involving classifying images found in still pictures
    or video data |'
  prefs: []
  type: TYPE_TB
- en: Identifying faces in security camera footage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Categorizing plants or animals for ecological monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnosing medical images such as X-rays, MRI, or CT scans
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring the activity of athletes on the sporting field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autonomous driving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Natural language applications requiring an understanding of the meaning of
    words in context |'
  prefs: []
  type: TYPE_TB
- en: Processing social media posts to filter out fake news or hate speech
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring Twitter or customer support emails for consumer sentiment or other
    marketing insights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examining electronic health records for patients at risk of adverse outcomes
    or for eligibility for new treatments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Predictive analysis involving many repeated measurements or very large numbers
    of predictors |'
  prefs: []
  type: TYPE_TB
- en: Predicting the price of goods or equities in open markets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating energy, resource, or healthcare utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecasting survival or other medical outcomes using insurance billing codes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Even though some people certainly do use deep learning for conventional learning
    problems, this chapter focuses only on tasks that cannot be solved via conventional
    modeling techniques. Deep learning is highly adept at tapping into the unstructured
    data types that characterize the big data era, such as images and text, which
    are extremely difficult to model with traditional approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Unlocking these capabilities requires the use of specialized software and specialized
    data structures, which you will learn about in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The TensorFlow and Keras deep learning frameworks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Perhaps no software tool has contributed as much to the rapid growth in deep
    learning as **TensorFlow** ([https://www.tensorflow.org](https://www.tensorflow.org)),
    an open-source mathematical library developed at Google for advanced machine learning.
    TensorFlow provides a computing interface using directed graphs that “flow” data
    structures through a sequence of mathematical operations.
  prefs: []
  type: TYPE_NORMAL
- en: Packt Publishing offers many books on TensorFlow. To search the current offerings,
    visit [https://subscription.packtpub.com/search?query=tensorflow](https://subscription.packtpub.com/search?query=tensorflow).
  prefs: []
  type: TYPE_NORMAL
- en: 'The fundamental TensorFlow data structure is unsurprisingly known as a **tensor**,
    which is an array of zero or more dimensions. Building upon the simplest 0-D and
    1-D tensors, which represent a single value and a sequence of values, respectively,
    adding additional dimensions allows more complex data structures to be represented.
    Note that because we typically analyze sets of structures, the first dimension
    is generally reserved to allow multiple objects to be stacked; the first dimension
    then refers to the batch or sample number for each structure. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A set of 1-D tensors, collecting feature values for a set of people, is a 2-D
    tensor analogous to a data frame in R: `[person_id, feature_values]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For measurements repeated over time, 2-D tensors can be stacked as a 3-D tensor:
    `[person_id, time_sequence, feature values]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2-D images are represented by a 4-D tensor, with the fourth dimension storing
    the color values for each pixel in the 2-D grid: `[image_id, row, column, color_values]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Video or animated images are represented in 5-D with an additional time dimension:
    `[image_id, time_sequence, row, column, color_values]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most tensors are rectangular matrices completely filled with numeric data, but
    more complex structures like ragged tensors and sparse tensors are available for
    use with text data.
  prefs: []
  type: TYPE_NORMAL
- en: For an in-depth look at TensorFlow’s tensor objects, the documentation is available
    at [https://www.tensorflow.org/guide/tensor](https://www.tensorflow.org/guide/tensor).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow’s graph, which can be more specifically termed a **dataflow graph**,
    uses nodes connected by directional arrows known as edges to represent dependencies
    between data structures, mathematical operations on these data structures, and
    the output. The nodes represent mathematical operations and the edges represent
    tensors flowing between operations. The graph aids in the parallelization of the
    work, since it is clear what steps must be completed in sequence versus those
    that may be completed simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'A dataflow graph can be visualized if desired, which produces something like
    the idealized graph depicted in *Figure 15.2*. Although this is a highly simplified
    representation and real-world TensorFlow graphs tend to be much more complex,
    the diagram here shows that after completing the first operation, the second and
    fourth operations can begin in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.2: A simplified representation of a TensorFlow graph'
  prefs: []
  type: TYPE_NORMAL
- en: As tensors flow through the graph, they are transformed by the series of operations
    represented by the nodes. The steps are defined by the person building the diagram,
    with each step moving closer to the end goal of accomplishing some sort of mathematical
    task. Some steps in the flow graph may apply simple mathematical transformations
    like normalization, smoothing, or bucketing to the data; others may attempt to
    train a model by iterating repeatedly while monitoring a **loss function**, which
    measures the fit of the model’s predictions to the true values.
  prefs: []
  type: TYPE_NORMAL
- en: R interfaces to TensorFlow have been developed by the team at RStudio. The `tensorflow`
    package provides access to the core API, while the `tfestimators` package provides
    access to higher-level machine learning functionality. Note that TensorFlow’s
    directed graph approach can be used to implement many different machine learning
    models, including some of those discussed in this book. However, to do so requires
    a thorough understanding of the matrix mathematics that defines each model, and
    thus is outside the scope of this text. For more information about these packages
    and RStudio’s ability to interface with TensorFlow, visit [https://tensorflow.rstudio.com](https://tensorflow.rstudio.com).
  prefs: []
  type: TYPE_NORMAL
- en: Because TensorFlow relies so heavily on complex mathematical operations that
    must be programmed carefully by hand, the **Keras** library ([https://keras.io](https://keras.io))
    was developed to provide a higher-level interface to TensorFlow and allow deep
    neural networks to be built more easily. Keras was developed in Python and is
    typically paired with TensorFlow as the back-end computing engine. Using Keras,
    it is possible to do deep learning in just a few lines of code—even for challenging
    applications such as image classification, as you will discover in the example
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Packt Publishing offers numerous books and videos to learn Keras. To search
    current offerings, visit [https://subscription.packtpub.com/search?query=keras](https://subscription.packtpub.com/search?query=keras).
  prefs: []
  type: TYPE_NORMAL
- en: The `keras` package, developed by RStudio founder J. J. Allaire, allows R to
    interface with Keras. Although there is very little code required to use the package,
    developing useful deep learning models from scratch requires extensive knowledge
    of neural networks as well as familiarity with TensorFlow and the Keras API. For
    these reasons, a tutorial is outside the scope of this book. Instead, refer to
    the RStudio TensorFlow documentation or the book *Deep Learning with R* (2018),
    which was co-authored by Francois Chollet and J. J. Allaire—the creators of Keras
    and the `keras` package, respectively. Given their credentials, there is no better
    place to begin learning about this tool.
  prefs: []
  type: TYPE_NORMAL
- en: Although the combination of Keras and TensorFlow is arguably the most popular
    deep learning toolkit, it is not the only tool for the task. The **PyTorch** framework
    developed at Facebook has rapidly gained popularity, especially in the academic
    research community, as an easy-to-use alternative. For more information, see [https://pytorch.org](https://pytorch.org).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow’s innovative idea to represent complex mathematical functions using
    a simple graph abstraction, combined with the Keras framework to make it easier
    to specify the network topology, has enabled the construction of deeper and more
    complex neural networks, such as those described in the next section. Keras even
    makes it easy to adapt pre-built neural networks to new tasks with no more than
    a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding convolutional neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Neural networks have been studied for over 60 years, and even though deep learning
    has only recently become widespread, the concept of a deep neural network has
    been known for decades. As first introduced in *Chapter 7*, *Black-Box Methods
    – Neural Networks and Support Vector Machines*, a **deep neural network** (**DNN**)
    is simply a neural network with more than one hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: This understates what deep learning is in practice, as typical DNNs are substantially
    more complex than the types of neural networks we’ve built previously. It’s not
    enough to add a few extra nodes in a new hidden layer and call it “deep learning.”
    Instead, typical DNNs use extremely complex but purposefully designed topologies
    to facilitate learning on big data, and in doing so are capable of human-like
    performance on challenging learning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: A turning point for deep learning came in 2012, when a team called SuperVision
    used deep learning to win the ImageNet Large Scale Visual Recognition Challenge.
    This annual competition tests the ability to classify a subset of 10 million hand-labeled
    images across 10,000 categories of objects. In the early years of the competition,
    humans vastly outperformed computers, but the performance of the SuperVision model
    closed the gap significantly. Today, computers are nearly as good as humans at
    visual classification, and, in some specific cases, are even better. Humans tend
    to be better at identifying small, thin, or distorted items, while computers have
    a greater ability to distinguish among specific types of items such as dog breeds.
    Before long, it is likely that computers will outperform humans on both types
    of visual tasks.
  prefs: []
  type: TYPE_NORMAL
- en: An innovative network topology designed specifically for image recognition is
    responsible for the surge in performance. A **convolutional neural network** (**CNN**)
    is a deep feed-forward network used for visual tasks that independently learns
    the important distinguishing image features rather than requiring such feature
    engineering beforehand. For example, to classify road signs like “stop” or “yield,”
    a traditional learning algorithm would require pre-engineered features like the
    shape and color of the sign. In contrast, a CNN requires only the raw data for
    each of the image pixels, and the network will learn how to distinguish important
    features like shape and color on its own.
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning features like these is made possible due to the huge increase in dimensionality
    when using raw image data. A traditional learning algorithm would use one row
    per image, in a form like (*stop sign*, *red, octagon*), while a CNN uses data
    in the form (*stop sign*, *x*, *y*, *color*), where *x* and *y* are pixel coordinates
    and *color* is the color data for the given pixel. This may seem like an increase
    of only one dimension but note that even a very small image is made of many (*x*,
    *y*) combinations and color is often specified as a combination of RGB (*red*,
    *green*, *blue*) values. This means that a more accurate representation of a single
    row of training data would be:'
  prefs: []
  type: TYPE_NORMAL
- en: (*stop sign*, *x*[1]*y*[1]*r*, *x*[1]*x*[1]*g*, *x*[1]*y*[1]*b*, *x*[2]*y*[1]*r*,
    *x*[2]*y*[1]*g*, *x*[2]*y*[1]*b*, …, *x*[n]*y*[n]*r*, *x*[n]*x*[n]*g*, *x*[n]*y*[n]*b*)
  prefs: []
  type: TYPE_NORMAL
- en: Each of the predictors refers to the level of red, green, or blue at the specified
    combination of (*x*, *y*), and *r*, *g*, or *b* values. Thus, the dimensionality
    increases greatly, and the dataset becomes much wider as the image becomes larger.
  prefs: []
  type: TYPE_NORMAL
- en: A small 100x100 pixel image would have *100x100x3 = 30,000* predictors. Even
    this is small compared to the SuperVision team, which used over 60 million parameters
    when it won the visual recognition challenge in 2012!
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 12*, *Advanced Data Preparation*, noted that if a model is overparameterized,
    it reaches an interpolation threshold at which there are enough parameters to
    memorize and perfectly classify all the training samples. The ImageNet Challenge
    dataset, which contained 10 million images, is much smaller than the 60 million
    parameters the winning team used. Intuitively, this makes sense; assuming there
    are no completely identical pictures in the database, at least one of the pixels
    will vary for every image. Thus, an algorithm could simply memorize every image
    to achieve the perfect classification of the training data. The problem is that
    the model will be evaluated on a dataset of unseen data, and thus the severe overfitting
    to the training data will lead to a massive generalization error.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The topology of a CNN prevents this from happening. We won’t be diving too
    deeply into the black box of the CNN, but we will understand it as a series of
    layers in the following categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional layers** are placed early in the network and usually comprise
    the most computationally intensive step in the network because they are the only
    layers to process the raw image data directly; we can understand convolution as
    passing the raw data through a filter creating a set of tiles that represent small,
    overlapping portions of the full area'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pooling layers**, also known as **downsampling** or **subsampling** layers,
    gather the output signals from a cluster of neurons in one layer, and summarize
    them into a single neuron for the next layer, usually by taking the maximum or
    average value among those being summarized'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fully connected layers** are much like the layers in a traditional multilayer
    perceptron, and are used near the end of the CNN to build the model that makes
    predictions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The convolutional and pooling layers in the network serve the interrelated purposes
    of identifying important features of the images to be learned, as well as reducing
    the dimensionality of the dataset before hitting the fully connected layers that
    make predictions. In other words, the early stages of the network perform feature
    engineering, while the later stages use the constructed features to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand the layers in a CNN, see *An Interactive Node-Link Visualization
    of Convolutional Neural Networks* by Adam W. Harley at [https://adamharley.com/nn_vis/](https://adamharley.com/nn_vis/).
    The interactive tool has you draw a number from zero to nine, which is then classified
    using a neural network. The 2D and 3D convolutional network visualizations clearly
    show how the digit you drew passes through the convolutional, downsampling, and
    fully connected layers before reaching the output layer where the prediction is
    made. Neural networks for general image classification work much the same way,
    but using a substantially larger and more complex network.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning and fine tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building a CNN from scratch requires a tremendous amount of data, expertise,
    and computing power. Thankfully, many large organizations that have access to
    data and computing resources have built image, text, and audio classification
    models, and have shared them with the data science community. Through a process
    of **transfer learning**, a deep learning model can be adapted from one context
    to another. Not only is it possible to apply the saved model to similar types
    of problems as it was trained on, but it may also be useful for problems outside
    the original domain. For instance, a neural network that was trained to recognize
    an endangered species of elephants in satellite photos may also be useful for
    identifying the position of tanks in infrared drone images taken above a war zone.
  prefs: []
  type: TYPE_NORMAL
- en: If the knowledge doesn’t transfer directly to the new task, it is possible to
    hone a pre-trained neural network using additional training in a process known
    as **fine tuning**. Taking a model that was trained generally, such as a general
    image classification model that can identify 10,000 classes of objects, and fine
    tuning it to be good at identifying a single type of object not only reduces the
    amount of training data and computing power needed but also may offer improved
    generalization over a model trained on a single class of images.
  prefs: []
  type: TYPE_NORMAL
- en: Keras can be used for both transfer learning and fine tuning by downloading
    neural networks with pre-trained weights. A list of available pre-trained models
    is available at [https://keras.io/api/applications/](https://keras.io/api/applications/)
    and an example of fine tuning an image processing model to better predict cats
    and dogs can be found at [https://tensorflow.rstudio.com/guides/keras/transfer_learning](https://tensorflow.rstudio.com/guides/keras/transfer_learning).
    In the next section, we will apply a pre-trained image model to real-world images.
  prefs: []
  type: TYPE_NORMAL
- en: Example – classifying images using a pre-trained CNN in R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'R may not be the right tool for the heaviest deep learning jobs, but with the
    right set of packages, we can apply pre-trained CNNs to perform tasks, such as
    image recognition, that conventional machine learning algorithms have trouble
    solving. The predictions generated by the R code can then be used directly for
    image recognition tasks like filtering obscene profile pictures, determining whether
    an image depicts a cat or a dog, or even identifying stop signs inside a simple
    autonomous vehicle. Perhaps more commonly, the predictions could be used as predictors
    in an ensemble that includes conventional machine learning models using tabular-structured
    data in addition to the deep learning neural network that consumes the unstructured
    image data. You may recall that *Chapter 14*, *Building Better Learners*, described
    a potential stacked ensemble that combined image, text, and traditional machine
    learning models in this way to predict elements of a Twitter user’s future behavior.
    The following pictures illustrate hypothetical Twitter profile pictures, which
    we will classify using a deep neural network shortly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.3: A pre-trained neural network can be used in R to identify the
    subject of images like these'
  prefs: []
  type: TYPE_NORMAL
- en: First, before using a pre-trained model, it is important to consider the dataset
    that was used to train the neural network. Most publicly available image networks
    were trained on huge image databases comprising a variety of everyday objects
    and animals, such as cars, dogs, houses, various tools, and so on. This is appropriate
    if the desired task is to distinguish among everyday objects, but more specific
    tasks may require more specific training datasets. For instance, a facial recognition
    tool or an algorithm identifying stop signs would be more effectively trained
    on datasets of faces and road signs, respectively. With transfer learning, it
    is possible to fine-tune a deep neural network trained on a variety of images
    to be better at a more specific task—it could become very good at identifying
    pictures of cats, for example—but it is hard to imagine a network trained on faces
    or road signs ever becoming very good at identifying cats, even with additional
    tuning!
  prefs: []
  type: TYPE_NORMAL
- en: For this exercise, we will classify our small set of images using a CNN called
    **ResNet-50**, which is a 50-layer deep network that has been trained on a large
    and comprehensive variety of labeled images. This model, which was introduced
    by a group of researchers in 2015 as a state-of-the-art, competition-winning computer
    vision algorithm, has since been surpassed by more sophisticated approaches, but
    continues to be extremely popular and effective due to its ease of use and integration
    with tools like R and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: For more information about ResNet-50, see *Deep Residual Learning for Image
    Recognition, He, K., Zhang, X., Ren, S., and Sun, J., 2015,* [https://arxiv.org/abs/1512.03385v1](https://arxiv.org/abs/1512.03385v1).
  prefs: []
  type: TYPE_NORMAL
- en: The **ImageNet database** ([https://www.image-net.org](https://www.image-net.org))
    that was used to train the ResNet-50 model is the same database used for the ImageNet
    Visual Recognition Challenge and has contributed greatly to computer vision since
    its introduction in 2010\. Composed of over 14 million hand-labeled images and
    consuming many gigabytes of storage (or even terabytes in the case of the full,
    academic version), it is fortunate that there is no need to download this resource
    and train the model from scratch. Instead, we simply download the neural network
    weights for the ResNet-50 model that researchers trained on the full database,
    saving us a tremendous amount of computational expense.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin the process, we’ll need to add the `tensorflow` and `keras` packages
    to R as well as the various dependencies. Most of these steps must only be performed
    once. The `devtools` package adds tools to develop R packages and use packages
    that are in active development, so we’ll begin by installing and loading this
    as usual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we’ll use the `devtools` package to obtain the latest version of the
    `tensorflow` package from GitHub. Typically, we install packages from CRAN, but
    for packages in active development, it can be better to install directly from
    the latest source code. The command to install the `tensorflow` package from its
    GitHub path is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This points R to the RStudio GitHub account, which stores the source code for
    the package. To read the documentation and see the code for yourself on the web,
    visit [https://github.com/rstudio/tensorflow](https://github.com/rstudio/tensorflow)
    in a web browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'After installing the `tensorflow` package, there are several dependencies that
    are required to begin using TensorFlow in R. In particular, the `tensorflow` package
    is merely an interface between R and TensorFlow, so we must first install TensorFlow
    itself. Perhaps ironically, Python and several of its packages are required for
    this. Thus, the R `reticulate` package ([https://rstudio.github.io/reticulate/](https://rstudio.github.io/reticulate/))
    is used to manage the interface between R and Python. As confusing as this seems,
    the complete installation process is driven by a single command from the `tensorflow`
    package as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'While the command is running, you should see R working to install a large collection
    of Python tools and packages. If all goes well, you can proceed to install the
    Keras package from GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the case of a problem, keep in mind that although the code for this example
    was tested on multiple platforms and R versions, it is quite possible for something
    to go wrong among the many dependencies required to have R interface with Python
    and TensorFlow. Don’t be afraid to search the web for a particular error message
    or check the Packt Publishing GitHub repository for the updated R code for this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the necessary packages installed, Keras can help load the ResNet-50 model
    with the weights trained on the ImageNet database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Our 50-layer deep image classification model trained on millions of everyday
    images is now ready to start making predictions; however, the ease at which we
    loaded the model conceals the work to come.
  prefs: []
  type: TYPE_NORMAL
- en: The greater challenge with using a pre-trained model is transforming our unstructured
    image data, which we hope to classify, into the same structured format that it
    saw during training. ResNet-50 used square images of 224-by-224 pixels with each
    pixel reflecting a color composed of three channels, red, green, and blue, each
    having 255 levels of brightness. All images we hope to classify must be transformed
    from their original formats, such as PNG, GIF, or JPEG, into a 3-D tensor using
    this representation. We’ll see this in practice using the previously depicted
    `cat.jpg`, `ice_cream.jpg`, and `pizza.jpg` files found in the R code folder for
    this chapter, but the process will work similarly for any image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `image_load()` function in the `keras` package will get the process started.
    Simply provide the file name and desired target dimensions as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates an image object, but we need one more command to convert it into
    a 3-D tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To prove it to ourselves, we can examine the dimensions and structure of the
    object as follows. As expected, the object is a numeric matrix with *224* x *224*
    x *3* as the dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The first few values in the matrix are all 255, which isn’t very meaningful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s do some investigation to better understand these data structures. Because
    of R’s row, column matrix format, the matrix coordinates are (*y*, *x*), with
    (*1*, *1*) representing the top-left pixel in the image and (*1*, *224*) the top-right
    pixel. To illustrate this, let’s obtain each of the three color channels for a
    couple of pixels in the ice cream image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The pixel at (*1*, *224*) has (*r*, *g*, *b*) colors of (*253*, *253*, *255*),
    which corresponds to nearly the brightest possible white, while the pixel at (*40*,
    *145*) has color values (*149*, *23*, *34*) translating to a dark red—a piece
    of strawberry in the ice cream. These coordinates are illustrated in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.4: The picture of ice cream has been reduced from a matrix of 1,000x1,000
    pixels to 224x224; each pixel in the image has three color channels'
  prefs: []
  type: TYPE_NORMAL
- en: 'One additional complication is that the ResNet-50 model expects a four-dimensional
    tensor, with the fourth dimension representing the batch. With only one image
    to classify, we have no need for this parameter, so we’ll simply assign it a constant
    value of 1 to create a matrix of *1x224x224x3*. The command `c(1, dim(x))` defines
    the new matrix in this format, and then the `array_reshape()` function fills this
    matrix with the contents of `x` using the Python-style row-by-row ordering used
    by TensorFlow rather than the R-style column-by-column filling. The full command
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To confirm that `x` has the correct dimensions, we can use the `dim()` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we run the `imagenet_preprocess_input()` function to normalize the
    color values to match the ImageNet database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The primary function of this transformation is to zero-center each color with
    respect to the database, essentially treating each color value as being greater
    than or less than the average of ImageNet images on that color. For example, the
    red pixel in the ice cream at (`40`, `145`) had color values of 149, 23, and 34
    before; now, it has very different values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Negative values indicate a color level less than the ImageNet average for that
    color, and positive values indicate higher. The preprocessing step also inverts
    the red-green-blue format to blue-green-red, so only the red channel is above
    the average ImageNet level, which is not terribly surprising, as a strawberry
    is quite red!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see what the ResNet-50 network thinks is depicted in the image.
    We’ll first use the `predict()` function on the model object and the image matrix,
    and then use the `keras` function `imagenet_decode_predictions()` to convert the
    network’s predicted probabilities to text-based labels that categorize each of
    the ImageNet images. Because there are 1,000 categories of images in the ImageNet
    database, the `preds` object contains 1,000 predicted probabilities—one for each
    possibility. The decoding function allows us to limit the output to the top *N*
    most probable possibilities—ten, in this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The `c_resnet50` object is a list which contains the top ten predictions for
    our lone image. To see the predictions, we simply type the name of the list to
    discover that the network correctly identified the image as ice cream with about
    99.6 percent probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Although none of the other potential classifications had a predicted probability
    much greater than zero, some of the other top predictions make a bit of sense;
    it is not difficult to see why they were considered as possibilities. Eggnog is
    in the correct category of foods, while an ice cream cone might look a bit like
    a cup, or a thimble.
  prefs: []
  type: TYPE_NORMAL
- en: The model even listed strawberry as the sixth most likely option, which is the
    correct flavor of ice cream.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an exercise, we’ll do the same process with the other two images. The following
    sequence of steps uses the `lapply()` function to apply the image processing steps
    to the pair of images, each time creating a new list to supply to the subsequent
    function. The last step supplies the list containing two prepared image arrays
    to the `lapply()` function, which applies the `predict()` command to each image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `sapply()` function is used to apply the decoding function to
    each of the two sets of predictions, while simplifying the result. The `lapply()`
    function would also work here, but because `imagenet_decode_predictions()` returns
    a list, the result is a sub-list of length one within a list; `sapply()` recognizes
    that this is redundant and unnecessary, and will eliminate the additional level
    of hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Typing the name of the resulting object shows the top three predictions for
    each of the two images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The ResNet-50 algorithm didn’t merely classify the images correctly; it also
    correctly identified the cat picture as a tabby. This demonstrates the ability
    of neural networks to surpass human specificity for certain tasks; many or most
    people might have simply labeled the image as a cat, whereas the computer can
    determine the specific type of cat. On the other hand, humans remain better at
    identifying objects in less-than-optimal conditions. For example, a cat obscured
    by darkness or camouflaged in the weeds would present a greater challenge to a
    computer than to a human in most cases. Even so, the computer’s ability to work
    tirelessly gives it a huge advantage for automating artificial intelligence tasks.
    As stated previously, applied to a large dataset such as Twitter profile images,
    the predictions from this type of computer vision model could be used in an ensemble
    model predicting countless different user behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning and big data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous section illustrated how a deep neural network could be used to
    classify a limitless supply of input images as an instance of everyday creatures
    or objects. From another perspective, one might also understand this as a machine
    learning task that takes the highly dimensional input of image pixel data and
    reduces it to a lower-dimensional set of image labels. It is important to note,
    however, that the deep learning neural network is a supervised learning technique,
    which means that the machine can only learn what the humans tell it to learn—in
    other words, it can only learn from something that has been previously labeled.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of this section is to present useful applications of unsupervised
    learning techniques in the context of big data. These applications are in many
    ways similar to the techniques covered in *Chapter 9*, *Finding Groups of Data
    – Clustering with k-means*. However, where previous unsupervised learning techniques
    leaned heavily on humans to interpret the results, in the context of big data,
    the machine can go a step further than before and provide a deeper, richer understanding
    of the data and the implications of the connections the algorithm discovers.
  prefs: []
  type: TYPE_NORMAL
- en: 'To put this in practical terms, imagine a deep neural network that can learn
    to identify a cat without ever having been told what a cat is. Of course, without
    being given the label beforehand, the computer may not explicitly label it a “cat”
    *per se*, but it may understand that a cat has certain consistent relationships
    to other things that appear in pictures along with the cat: people, litter boxes,
    mice, balls of yarn—but rarely or never dogs! Such associations help form a conceptualization
    of cat as something that relates closely to people, litter boxes, and yarn, but
    is perhaps in opposition to another thing with four legs and a tail. Given enough
    pictures, it is possible the neural network could eventually associate its impression
    of cats with the English-language word “cat” by identifying cats near bags of
    cat food or in the internet’s countless cat-based memes!'
  prefs: []
  type: TYPE_NORMAL
- en: Developing such a sophisticated model of cats would take more data and computing
    power than most machine learning practitioners have access to, but it is certainly
    possible to develop simpler models or to borrow from big data companies that do
    have access to such resources. These techniques provide yet another way to incorporate
    unstructured data sources into more conventional learning tasks, as the machine
    can reduce the complexity of big data into something much more digestible.
  prefs: []
  type: TYPE_NORMAL
- en: Representing highly dimensional concepts as embeddings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The things we encounter in everyday life can be described by a limitless number
    of attributes. Moreover, not only are there countless data points that can be
    used to describe each object, but the nature of human subjectivity makes it unlikely
    that any two people would describe an object in the same way. For example, if
    you ask a few people to describe typical horror films, one might say they imagine
    slasher films with blood and gore, another might think of zombie or vampire movies,
    and another one might think of spooky ghost stories and haunted houses. These
    descriptions could be represented using the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '*horror* = *killer* + *blood* + *gore*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*horror* = *creepy* + *zombies* + *vampires*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*horror* = *spooky* + *ghosts* + *haunted*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we were to program these definitions into a computer, it could substitute
    any of the representations of horror for one another and thus use a wider general
    concept of “horror” rather than the more specific features like “gore,” “creepy,”
    or “spooky” to make predictions. For instance, a learning algorithm could discover
    that a social media user that writes any of these horror-related terms is more
    likely to click on an advertisement for the new *Scream* movie.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, if a user posts “I just love a good scary movie!” or “The Halloween
    season is my favorite time of year!” then the algorithm will be unable to relate
    the text to the prior conceptualizations of horror, and thus will be unable to
    realize that a horror movie advertisement should be displayed. This is likewise
    true for any of the hundreds of horror-related keywords that the computer had
    not previously seen verbatim, including many that will seem obvious to a human
    observer, like witches, demons, graveyards, spiders, skeletons, and so on. What
    is needed is a way to generalize the concept of horror to the almost limitless
    number of ways that it can be described.
  prefs: []
  type: TYPE_NORMAL
- en: An **embedding** is a mathematical concept referring to the ability to represent
    a higher-dimensional vector using fewer dimensions; in machine learning, the embedding
    is purposefully constructed such that dimensions that are correlated in the high-dimensional
    space are positioned more closely in the lower-dimensional space.
  prefs: []
  type: TYPE_NORMAL
- en: If the embedding is constructed well, the low-dimensional space will retain
    the semantics, or meaning, of the higher dimensions while being a more compact
    representation that can be used for classification tasks. The core challenge of
    creating an embedding is the unsupervised learning task of modeling the semantic
    meaning embedded in highly dimensional unstructured or semi-structured datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Humans are quite adept at constructing low-dimensional representations of concepts,
    as we do this intuitively whenever we assign labels to objects or phenomena that
    are similar in broad strokes but may vary in the details. We do this when we label
    movies as comedy, science fiction, or horror; when we talk about categories of
    music like hip-hop, pop, or rock and roll; or when we create taxonomies of foods,
    animals, or illnesses. In *Chapter 9*, *Finding Groups of Data – Clustering with
    k-means*, we saw how the machine learning process of clustering can mimic this
    human process of labeling by grouping diverse but similar items through a process
    of “unsupervised classification.” However, even though this approach reduces the
    dimensionality of a dataset, it requires a structured dataset with the same specific
    features for each example before it can associate like-with-like. For something
    unstructured like a textual description of a movie, the features are too numerous
    and sparse to allow clustering.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, what if we wanted to mimic the human ability to learn via association?
    Specifically, a human can watch a series of movies and associate like-with-like
    without having specific measurable features for each movie; we can classify one
    set of movies as horror films without needing to see the identical clichéd storyline
    or to count the number of screams each film elicited. The trick is that a human
    doesn’t need a concrete definition of “horror” because we intuit it as a concept
    relative to the others in a set. Just like a cat suddenly jumping into frame can
    be used as slapstick humor in a comedy movie or paired with suspenseful music
    to provoke a jump scare, the semantic meaning of horror is always determined by
    its context.
  prefs: []
  type: TYPE_NORMAL
- en: In much the same way, learning algorithms can construct embeddings via context.
    Each of the thousands of movies that Hollywood has produced can be understood
    relative to others, and without studying exactly what features the movies *Halloween*
    and *Night of the Living Dead* have in common, an algorithm can observe that they
    appear in similar contexts and are somewhat substitutable for one another across
    contexts. This notion of substitutability is the basis for most embedding algorithms,
    and has indeed been used to construct embeddings for use in movie recommendation
    algorithms and other domains. In the next section, we’ll see how a popular language
    embedding algorithm uses substitutability to discover the semantic meanings of
    words.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding word embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If there are roughly a million words in the English language, the feature space
    for a language-based model would be roughly a million dimensions wide even before
    phrases and word order are considered! This clearly would be far too large and
    sparse for most conventional learning algorithms to find a meaningful signal.
    A bag-of-words approach, as described in *Chapter 4*, *Probabilistic Learning
    – Classification Using Naive Bayes*, might work with enough computing power, but
    it would also require a tremendous amount of training data to associate words
    with the desired outcome. What if, instead, we could use a language embedding
    that has been pre-trained on big data?
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the upside of this alternative approach, let’s imagine the machine
    learning task of deciding whether to display an advertisement for a lunchtime
    café to users posting on a social media website. Consider the following posts
    made by hypothetical users:'
  prefs: []
  type: TYPE_NORMAL
- en: I ate bacon and eggs in the morning for the most important meal of the day!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I am going to grab a quick sandwich this afternoon before hitting the gym.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can anyone provide restaurant recommendations for my date tonight?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a naive Bayes approach, we would first need many of these types of sentences,
    but because the algorithm is a supervised learner, we would also need a target
    feature that indicates whether or not the user writing the sentence is interested
    in purchasing lunch from the café. We could then train the model to recognize
    which words are predictive of buying lunch.
  prefs: []
  type: TYPE_NORMAL
- en: In comparison, a human reading these sentences can easily form a reasonable
    guess as to which of the three users is most likely to be interested in buying
    lunch today. The human’s guess is not based on being trained to predict lunch
    buying behavior specifically, but rather is based on an understanding of the embedded
    meaning in each of the sentences’ words. In other words, because a human understands
    the meaning of the users’ words, it becomes unnecessary to guess their behavior
    as we can instead just listen to what they are telling us they plan to do.
  prefs: []
  type: TYPE_NORMAL
- en: The most effective language models do more than merely look at the meaning of
    words; they also look at the meaning of words in relation to others. The use of
    grammar and phrasing can completely change the implications of a sentence. For
    example, the sentence “I skipped breakfast today, so I can stuff myself at lunch”
    is very different from “I stuffed myself at breakfast, so I need to skip lunch
    today” despite containing almost exactly the same words!
  prefs: []
  type: TYPE_NORMAL
- en: 'Ignoring for now how this might be constructed, suppose we have a very simple
    language embedding that captures the meaning of all English-language words in
    two dimensions: a “lunch” dimension that measures how related a term is to lunch,
    and a “food” dimension that indicates whether the term is related to food. In
    this model, the semantic meaning that was once delivered by unique and specific
    terms like “soup” and “salad” is instead represented by the position of these
    concepts in the 2-D space, as illustrated for a selection of words in *Figure
    15.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, receipt, screenshot  Description automatically
    generated](img/B17290_15_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.5: A very simple embedding reduces the highly dimensional meaning
    of various words into two dimensions that a machine can use to understand the
    subjective concepts of “food” and “lunch”'
  prefs: []
  type: TYPE_NORMAL
- en: 'The embedding itself is a mapping of a word to coordinates in a lower-dimensional
    space. Thus, a lookup function can provide the values for a specific word. For
    instance, using the 2-D word embedding above, we can obtain coordinates for a
    selection of terms that may have appeared in social media posts:'
  prefs: []
  type: TYPE_NORMAL
- en: '*f(sandwich)* = *(0.97, 0.54)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*f(bacon)* = *(-0.88, 0.75)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*f(apple)* = *(0.63, 0.25)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*f(orange)* = *(-0.38, 0.13)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terms with higher values of the first dimension are more specifically related
    to lunch (and lunch alone) while lower values indicate terms that are specifically
    not related to lunch. For example, the word “sandwich” has a high lunch value
    while “bacon” has a low lunch value, due to their close association with lunch
    and breakfast, respectively. In much the same way, terms with higher or lower
    values of the second dimension are more or less likely to be foods. The words
    “orange” and “apple” can both be foods, but the former can also represent a color
    while the latter can represent a computer, so they are near the middle of the
    food dimension. In contrast, the words “bacon” and “sandwich” are higher in this
    dimension but are lower than “burrito” or “spaghetti” due to their meanings outside
    of the culinary context; someone can “bring home the bacon” (that is, they can
    earn money) or an item can be “sandwiched” between other items.
  prefs: []
  type: TYPE_NORMAL
- en: 'An interesting and useful property of this type of embedding is that words
    can be related to one another via simple mathematics and nearest-neighbor-style
    distance calculations. In the 2-D plot, we can observe this property by examining
    the terms that are mirror images across the horizontal or vertical axis or those
    that are close neighbors. This leads to observations such as:'
  prefs: []
  type: TYPE_NORMAL
- en: An apple is a more lunch-related version of an orange
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beef is like chicken, but not as associated with lunch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pitas and tacos are somewhat similar, as are kebabs and sandwiches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Soup and salad are closely related and are the lunch versions of eggs and pasta
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heavy and light are opposites with respect to lunch, as are afternoon and evening
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The term “brown bag” is lunch-ish like “apple” but less food-ish
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although this is a simple, contrived example, the word embeddings developed
    using big data have similar mathematical properties—albeit with a much higher
    number of dimensions. As you will soon see, these additional dimensions allow
    additional aspects of word meaning to be modeled, and enrich the embedding far
    beyond the “lunch” and “food” dimensions illustrated so far.
  prefs: []
  type: TYPE_NORMAL
- en: Example – using word2vec for understanding text in R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The previous sections introduced the idea of embedding as a means of encoding
    a highly dimensional concept in a lower-dimensional space. We’ve also learned
    that, conceptually, the process involves training a computer to learn about the
    substitutability of various terms by applying a human-like process of learning
    by association. But so far, we haven’t explored the algorithm that performs this
    feat. There are several such methods, which have been developed by big data companies
    or research universities and shared with the public.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps one of the most widely used word embedding techniques is **word2vec**,
    which was published in 2013 by a team of researchers at Google and, as the name
    suggests, literally transforms words to vectors. According to the authors, it
    is not a single algorithm so much as it is a collection of methods that can be
    used for natural language processing tasks. Although there have been many new
    methods published in the time since word2vec was published, it remains popular
    and is well studied even today. Understanding the full scope of word2vec is outside
    the scope of this chapter, but understanding some of its key components will provide
    a foundation upon which many other natural language processing techniques can
    be understood.
  prefs: []
  type: TYPE_NORMAL
- en: For a deep dive into the word2vec approach, see *Efficient Estimation of Word
    Representations in Vector Space by Mikolov, T., Chen, K., Corrado, G., and Dean,
    J., 2013* at [https://arxiv.org/abs/1301.3781](https://arxiv.org/abs/1301.3781).
    Another early but widely used approach for word embeddings is called the **GloVe
    algorithm**, which was published in 2014 by a team at Stanford University and
    uses a similar set of methods. For more information on GloVe, see [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/).
  prefs: []
  type: TYPE_NORMAL
- en: Consider a computer attempting to learn from reading a large corpus of text
    such as a web page or textbook. To begin learning which words are associated and
    are substitutable for one another, the computer will need a formal definition
    of “context” to limit the scope to something more reasonable than the entire text,
    particularly if the text is large. To this end, the word2vec technique defines
    a **window size** parameter that dictates how many words of context will be used
    when attempting to understand a single word. A smaller window size guarantees
    a tight association between words in context, but because related words can appear
    much later in the sentence, making the window too small may lead to missing important
    relationships among words and ideas. Balance is required, because making the window
    too large can pull in unrelated ideas much earlier or later in the text. Typically,
    the window is set to approximately the length of a sentence, or about five to
    ten words, with useless stop words like “and,” “but,” and “the” excluded.
  prefs: []
  type: TYPE_NORMAL
- en: Given contexts comprising approximately sentence-length sets of words, the word2vec
    process proceeds with one of two methodologies. The **continuous bag-of-words**
    (**CBOW**) methodology trains a model to predict each word from its context; the
    **skip-gram** approach does the inverse and attempts to guess the surrounding
    contextual words when provided with a single input word. Although the underlying
    process is nearly identical for both approaches, there are mathematical nuances
    that lead to different results depending on which one is used.
  prefs: []
  type: TYPE_NORMAL
- en: Because we are merely understanding the methods conceptually, it suffices to
    say that the CBOW methodology tends to create embeddings favoring words that are
    nearly identical replacements or true synonyms for one another, such as “apple”
    and “apples” or “burger” and “hamburger,” while the skip-gram method favors terms
    that are conceptually similar, like “apple” and “fruit” or “burger” and “fries.”
  prefs: []
  type: TYPE_NORMAL
- en: 'For both CBOW and skip-gram, the process of developing the embedding is similar
    and can be understood as follows. Beginning from a sentence like “an apple is
    a fruit I eat for lunch,” a model is constructed that attempts to relate a word
    like “apple” to its context, like “fruit,” “eat,” and “lunch.” By iterating over
    huge volumes of such sentences—like “a banana is a fruit people eat for breakfast”
    or “an orange is both a fruit and a color” and so on—the values of the embedding
    can be determined, such that the embedding minimizes the prediction error between
    the word and its context. Words that appear consistently in similar contexts will
    thus have similar values for the embedding and can therefore be treated as similar,
    interchangeable concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_15_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.6: The word2vec process creates an embedding that relates each term
    to its context'
  prefs: []
  type: TYPE_NORMAL
- en: Technically speaking, the word2vec approach is not considered “deep learning”
    even though it is in many ways analogous to deep learning. As depicted in the
    figure that follows, the embedding itself can be imagined as a hidden layer in
    a neural network, here represented with four nodes. In the CBOW approach, the
    input layer is a one-hot encoding of the input term, with one node for each possible
    word in the vocabulary, but only a single node with a value of 1 and the remaining
    nodes set to 0 values. The output layer also has one node per term in the vocabulary
    but can have multiple “1” values—each representing a word appearing in the context
    of the input term.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that for the skip-gram approach, this arrangement would be reversed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, schematic  Description automatically generated](img/B17290_15_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.7: Developing an embedding involves training a model in a process
    analogous to deep learning'
  prefs: []
  type: TYPE_NORMAL
- en: Varying the number of nodes in the hidden layer affects the complexity of the
    network as well as the depth of the model’s semantic understanding of each term.
    A greater number of nodes leads to a richer understanding of each term in its
    context but becomes much more computationally expensive to train and requires
    much more training data. Each additional node adds an additional dimension from
    which each term can be distinguished. Too few nodes and the model will have insufficient
    dimensionality to capture the many nuances of how each term can be used—the word
    “orange” as a color versus “orange” as a food, for instance—but using too many
    dimensions may increase the risk of the model being distracted by noise, or worse,
    being useless for the embedding’s initial intended purpose of dimensionality reduction!
    As you will soon see firsthand, even though the embeddings presented so far used
    just a few dimensions for simplicity and illustrative purposes, actual word embeddings
    used in practice typically have hundreds of dimensions and require huge amounts
    of training data and computational power to train.
  prefs: []
  type: TYPE_NORMAL
- en: In R, installing the `word2vec` package by Jan Wijffels will provide a wrapper
    for the C++ implementation of the word2vec algorithm. If desired, the package
    can train a word embedding if given a corpus of text data, but it is often preferable
    to use pre-trained embeddings that can be downloaded from the web. Here, we’ll
    use an embedding that was trained using a Google News archive consisting of 100
    billion written words.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting embedding contains 300-dimensional vectors for 3 million words
    and simple phrases, and is available for download at the Google word2vec project
    page as follows: [https://code.google.com/archive/p/word2vec/](https://code.google.com/archive/p/word2vec/).
    To follow along with the example, look for the link to the `GoogleNews-vectors-negative300.bin.gz`
    file, then download, unzip, and save the file to your R project folder before
    proceeding.'
  prefs: []
  type: TYPE_NORMAL
- en: As a word of warning, the Google News embedding is quite large at about 1.5
    GB compressed (3.4 GB after unzipping) and unfortunately cannot be distributed
    with the code for this chapter. Furthermore, the file can be somewhat hard to
    find on the project website. Try a find command (*Ctrl* + *F* or *Command* + *F*)
    in your web browser to search the page for the file name if needed. Depending
    on your platform, you may need an additional program to unzip files with the Gzip
    compression algorithm (`.gz` file extension).
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the code that follows, to read the Google News embedding into R,
    we’ll load the `word2vec` package and use the `read.word2vec()` function. Ensure
    you have downloaded and installed the `word2vec` package and Google News embedding
    before attempting this step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'If the embedding loaded correctly, the `str()` command will show details about
    this pre-trained model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the embedding has 300 dimensions for each of the 3 million terms.
    We can obtain these dimensions for a term (or terms) using `predict()` as a lookup
    function on the model object. The `type = "embedding"` parameter requests the
    embedding vector for the term, as opposed to the most similar terms, which will
    be demonstrated shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we’ll request the word vectors for a few terms related to breakfast,
    lunch, and dinner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous commands created matrices named `foods` and `meals`, with rows
    reflecting the terms and columns representing the 300 dimensions of the embedding.
    We can examine the first few values of a single word vector for *cereal* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can examine the first few columns for all foods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Although we have no idea what each of the five dimensions represents (nor any
    of the remaining 295 dimensions not shown), we would expect similar, more substitutable
    foods and concepts to be closer neighbors in the 300-dimensional space. We can
    take advantage of this to measure the relatedness of the foods to the three main
    meals of the day using the `word2vec_similarity()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: In this output, higher values indicate greater similarity between the foods
    and each of the three mealtimes, according to the 300-dimension word embedding.
    Unsurprisingly, breakfast foods like cereal, bacon, and eggs are closer to the
    word *breakfast* than they are to *lunch* or *dinner*. Sandwiches and salads are
    closest to lunch, while steak and spaghetti are closest to dinner.
  prefs: []
  type: TYPE_NORMAL
- en: Although it was not used in the previous example, it is a popular convention
    to use the **cosine similarity** measure, which considers only the direction of
    the compared vectors, rather than the default Euclidean distance-like measure,
    which considers both direction and magnitude. The cosine similarity can be obtained
    by specifying `type = "cosine"` when calling the `word2vec_similarity()` function.
    Here, it is not likely to substantially affect the results because the Google
    News vectors were normalized when they were loaded into R.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more practical application of word2vec concepts, let’s revisit the hypothetical
    social media posts presented earlier and attempt to determine whether to present
    the users with a breakfast, lunch, or dinner advertisement. We’ll start by creating
    a `user_posts` character vector, which stores the raw text of each of the posts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Importantly, there is a substantial hurdle we must pass before applying word2vec
    to each of the user posts; specifically, each post is a sentence composed of multiple
    terms, and word2vec is only designed to return vectors for single words. Unfortunately,
    there is no perfect solution to this problem, and choosing the correct solution
    may depend on the desired use case. For instance, if the application is intended
    merely to identify people that post about a particular subject, it may suffice
    to iterate over each word in the post and determine whether any of the words meet
    a similarity threshold.
  prefs: []
  type: TYPE_NORMAL
- en: More complex alternative solutions exist for solving the problem of applying
    word2vec to longer strings of text. A common but somewhat crude solution involves
    simply averaging the word2vec vectors across all words in the sentence, but this
    often results in poor results for much the same reason that mixing too many colors
    of paint results in an ugly shade of brown. As sentences grow longer, averaging
    across all words creates a muddy mess due to the fact that some words will inevitably
    have vectors in opposite directions and the resulting average is meaningless.
    Moreover, as sentences grow in complexity, it is more likely that word order and
    grammar will affect the meaning of the words in the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: An approach called doc2vec attempts to address this by adapting the training
    of word2vec to longer blocks of text, called documents, which need not be full
    documents but may be paragraphs or sentences. The premise of doc2vec is to create
    an embedding for each document based on the words appearing in the document. Document
    vectors can then be compared to determine the overall similarity between two documents.
    In our case, the goal would be to compare whether two documents (that is, sentences)
    are conveying similar ideas—for instance, is a user’s post like other sentences
    that were about breakfast, lunch, or dinner?
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, we do not have access to a doc2vec model to use this more sophisticated
    approach, but we can apply the `word2vec` package’s `doc2vec()` function to create
    a document vector for each user post and treat the document vector as if it were
    a single word. As stated previously, for longer sentences this may create a muddied
    vector, but because social media posts are often short and to the point, this
    issue may be mitigated.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll begin by loading the `tm` package, which was introduced in *Chapter 4*,
    *Probabilistic Learning – Classification Using Naive Bayes*, as a collection of
    tools for processing text data. The package provides a `stopwords()` function,
    which can be combined with its `removeWords()` function to remove unhelpful terms
    from social media posts. Then, the `txt_clean_word2vec()` function is used to
    prepare the posts for use with `doc2vec`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'To see the result of this processing, let’s look at the first cleaned user
    post:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'As expected, the text has been standardized and all unhelpful words have been
    removed. We can then supply the posts to the `doc2vec()` function, along with
    the pre-trained Google News word2vec model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of this operation is a matrix with three rows (one for each document)
    and 300 columns (one for each dimension in the embedding). The `str()` command
    shows the first few values of this matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll need to compare these pseudo-document vectors to the word vectors for
    breakfast, lunch, and dinner. These vectors were created previously using the
    `predict()` function and the word2vec model, but the code is repeated here for
    clarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can compute the similarity between the two. Each row represents
    a user’s post, and the column values indicate the similarity between that post’s
    document vector and the corresponding term:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Unsurprisingly, the user post about bacon and eggs is most similar to the word
    breakfast, while the post with sandwiches is most similar to lunch, and the evening
    date is most related to dinner. We could use the maximum similarity per row to
    determine whether to display a breakfast, lunch, or dinner advertisement to each
    user.
  prefs: []
  type: TYPE_NORMAL
- en: Document vectors can also be used directly as predictors in supervised machine
    learning tasks. For example, *Chapter 14*, *Building Better Learners*, described
    a theoretical model for predicting a Twitter user’s gender or future purchasing
    behavior based on the user’s basic profile data, profile picture, and social media
    post text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter proposed ensembling a traditional machine learning model with a
    deep learning model for the image data and a naive Bayes text model for the user
    posts. Alternatively, it is possible to use document vectors as is by treating
    the 300 dimensions as 300 individual predictors that the supervised learning algorithm
    can use to determine which are relevant to predicting the user’s gender:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, device, gauge  Description automatically generated](img/B17290_15_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.8: The values for a document vector resulting from unstructured text
    data can be used in a predictive model side by side with the more conventional
    predictors'
  prefs: []
  type: TYPE_NORMAL
- en: This strategy of creating a document vector for an unstructured block of text
    and using the resultant embedding values as predictors for supervised learning
    is quite generalizable as a means of enhancing the performance of a conventional
    machine learning approach. Many datasets include unstructured text fields that
    go unused in conventional models due to their complexity or the inability to train
    a language model. However, a relatively simple transformation made possible by
    a pre-trained word embedding allows the text data to be used in the model alongside
    the other predictors. Thus, there is little excuse not to incorporate this approach
    and provide the learning algorithm with an infusion of big data the next time
    you encounter this type of machine learning task.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing highly dimensional data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data exploration is one of the five key steps involved in any machine learning
    project, and thus is not immune to the so-called curse of dimensionality—the tendency
    of a project to become increasingly challenging as the number of features increases.
    Visualization techniques that work on simpler datasets may become useless as the
    number of dimensions grows unmanageable; for example, a scatterplot matrix may
    help identify relationships for a dozen or so features, but as the number grows
    bigger to dozens or hundreds of features, then what was once a helpful visualization
    may quickly turn into information overload.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, we can interpret a 2-D or even a three-dimensional plot without too
    much difficulty, but if we hope to understand the relationship among four or more
    dimensions, an entirely different approach is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Though physics suggests there are ten or eleven dimensions of the universe,
    we only experience four, and only interact directly with three of them. Perhaps
    for this reason, our brains are attuned to understanding visuals in at most three
    dimensions; moreover, because most of our intellectual work is on 2-D surfaces
    like blackboards, whiteboards, paper, or computer screens, we are accustomed to
    seeing data represented in at most two dimensions. One day, as virtual or augmented
    reality computer interfaces become more prevalent, we may see an explosion of
    innovation in three-dimensional visualizations, but until that day comes, there
    is a need for tools that can aid the display of highly dimensional relationships
    in no more than two dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reducing the dimensionality of a highly dimensional visualization to just two
    dimensions may seem like an impossibility, but the premise guiding the process
    is surprisingly straightforward: points that are closely positioned in the highly
    dimensional space need to be positioned closely in the 2-D space. If you are thinking
    that this idea sounds somewhat familiar, you would not be wrong; this is the same
    concept that guides embeddings, as described earlier in this chapter. The key
    difference is that while an embedding technique like word2vec reduces highly dimensional
    data down to a few hundred dimensions, embeddings for visualization must reduce
    the dimensionality even further to only two dimensions.'
  prefs: []
  type: TYPE_NORMAL
- en: The limitations of using PCA for big data visualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Principal component analysis** (**PCA**), which was introduced in *Chapter
    13*, *Challenging Data – Too Much, Too Little, Too Complex*, is one approach capable
    of reducing a highly dimensional dataset to two dimensions. You may recall that
    PCA works by expressing the covariance of multiple correlated attributes as a
    single vector. In this way, from the larger set of features, a smaller number
    of new features, called components, can be synthesized. If the number of components
    is set to two, a high-dimensional dataset can then be visualized in a simple scatterplot.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll apply this visualization technique to the 36-dimension social media profile
    dataset first introduced in *Chapter 9*, *Finding Groups of Data – Clustering
    with k-means*. The first few steps are straightforward; we use the tidyverse to
    read the data and select the 36 columns of interest, set the random seed to `123456`
    to ensure your results match the book, then use the `prcomp_irlba()` function
    from the `irlba` package to find the two principal components of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The `sns_pca$x` object contains a transformed version of the original dataset
    in which the 36 original dimensions have been reduced to 2\. Because this is stored
    as a matrix, we’ll first convert it to a data frame before piping it into a `ggplot()`
    function to create a scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting visualization appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.9: Principal component analysis (PCA) can be used to create 2-D visualizations
    of highly dimensional datasets, but the results are not always especially helpful'
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this scatterplot reveals a limitation of using PCA for data exploration,
    which is that the two principal components often create little visual separation
    among the points in 2-D space. Based on our prior work in *Chapter 9*, *Finding
    Groups of Data – Clustering with k-means*, we know that there are clusters of
    social media users that use similar keywords on their social media profiles. These
    clusters ought to be visible as distinct groupings in the scatterplot, but instead,
    we see one large group of points and a scattering of apparent outliers around
    the perimeter. The disappointing result here is not specific to the dataset used
    here and is typical of PCA when used in this way. Thankfully, there is another
    algorithm that is better suited to data exploration, which will be introduced
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the t-SNE algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The underlying math of the PCA technique utilizes covariance matrices to perform
    a linear dimensionality reduction, and the resulting principal components are
    intended to capture the overall variance of the dataset. The effect is like a
    compression algorithm that reduces the dimensionality of a dataset by eliminating
    redundant information. While this is obviously an important and useful attribute
    for a dimensionality reduction technique, it is less helpful for data visualization.
    As we observed in the previous section, this tendency of PCA to “compress” the
    dimensions may obscure important relationships in the data—the exact type of relationships
    we hope to discover when performing big data exploration.
  prefs: []
  type: TYPE_NORMAL
- en: A technique called **t-Distributed Stochastic Neighbor Embedding**, or **t-SNE**
    for short, is designed precisely as a tool for the visualization of high-dimensional
    datasets and thus addresses the previously mentioned shortcomings of PCA. The
    t-SNE approach was published in 2008 by Laurens van der Maaten, and it has quickly
    become a de facto standard for big data visualization for high-dimensional real-world
    datasets. Van der Maaten and others have published and presented numerous case
    studies contrasting PCA and t-SNE, and illustrating the strengths of the latter.
    However, because the math that drives t-SNE is highly complex, we will focus on
    understanding it conceptually and comparing it to other related methods covered
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: For a deep dive into the mechanics of the t-SNE algorithm, see the original
    publication, *Visualizing Data using t-SNE, van der Maaten, L. and Hinton, G.,
    Journal of Machine Learning Research 9, 2008, pp. 2579-2606*.
  prefs: []
  type: TYPE_NORMAL
- en: Just like with any technique for visualizing highly dimensional datasets, the
    goal of t-Distributed Stochastic Neighbor Embedding is to ensure that points or
    “neighbors” that are close in the high-dimensional space are positioned closely
    in the low-dimensional (2-D or 3-D) space.
  prefs: []
  type: TYPE_NORMAL
- en: The word *embedding* in the t-SNE name highlights the close connection between
    this and the more general task of constructing an embedding, as described in prior
    sections. However, as will be apparent shortly, t-SNE uses an approach unlike
    the deep learning analogue that is used for creating a word embedding. For starters,
    the word *stochastic* in the t-SNE name describes the non-deterministic nature
    of the algorithm, which implies that there is a relatively large degree of randomness
    in the output. But there are also more fundamental differences.
  prefs: []
  type: TYPE_NORMAL
- en: To begin to understand the t-SNE algorithm, imagine if the task were merely
    to reduce from three dimensions to two. In this case, if the data points were
    somehow depicted as small balls suspended in the air in three-dimensional space,
    and the same number of data points were placed randomly as flat discs on the ground
    in 2-D space, then a human could perform the dimensionality reduction by observing
    each ball in 3-D space, identifying its set of neighbors, and then carefully moving
    the discs in 2-D space to place neighbors closer together. Of course, this is
    more challenging than it sounds, because moving discs closer together and further
    apart in the flat space may inadvertently create or eliminate groupings relative
    to the 3-D space. For instance, moving point A to be closer to its neighbor point
    B may also move A closer to point C, when A and C should be distant according
    to the higher-dimensional space. For this reason, it would be important to iterate,
    observing each 3-D point’s neighborhood and shifting its 2-D neighbors until the
    overall 2-D representation is relatively stable.
  prefs: []
  type: TYPE_NORMAL
- en: The same basic process can be performed algorithmically in a much larger number
    of dimensions using a series of mathematical steps. First, the similarity of each
    point in high-dimensional space is computed—traditionally, using the familiar
    metric of Euclidian distance as with k-means and k-nearest neighbors in earlier
    chapters. This similarity metric is used to define a conditional probability distribution
    stating that similar points are proportionally more probable to be neighbors in
    the high-dimensional space. Likewise, a similar distance metric and conditional
    probability distribution is defined for the low-dimensional space. With these
    two metrics defined, the algorithm must then optimize the entire system such that
    the overall error for the high- and low-dimensional probability distributions
    is minimized. Keep in mind that the two are inseparably linked by the fact they
    rely on the same set of examples; the coordinates are known for the high-dimensional
    space, so it is essentially solving for a way to transform the high-dimensional
    coordinates into a low-dimensional space while preserving the similarity as much
    as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that the t-SNE algorithm is so different than PCA, it is no surprise
    that there are many differences in how they perform. An overall comparison of
    the two approaches is presented in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **PCA** | **t-SNE** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Tends to compress the visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Global (overall) variance is depicted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deterministic algorithm will produce the same result each run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does not have hyperparameters to be set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relatively fast (for datasets that can fit in memory)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Involves linear transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Useful as a general dimensionality reduction technique by creating additional
    principal components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Tends to cluster the visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local variance is more apparent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stochastic algorithm introduces randomness into the result
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Result can be sensitive to hyperparameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relatively slow (but faster approximations exist)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Involves non-linear transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typically used only as a data visualization technique (two or three dimensions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, t-SNE is generally the more appropriate tool for big data
    visualization, but it is worth noting a few differences that can be weaknesses
    or present challenges in certain circumstances. First, we have observed that PCA
    can do a poor job at depicting natural clusters in the data, but t-SNE is so apt
    at presenting clusters that it can occasionally even form clusters in a dataset
    without these types of natural divisions. This fault is compounded by the fact
    that t-SNE is a non-deterministic algorithm that is often quite sensitive to the
    values of its hyperparameters; setting these parameters poorly is more likely
    to create false clusters or obscure real ones. Lastly, the t-SNE algorithm involves
    iterating repeatedly over a relatively slow process, but stopping too early often
    produces a poor result or creates a false sense of the dataset’s structure; unfortunately,
    it is also possible that too many iterations will lead to the same problems!
  prefs: []
  type: TYPE_NORMAL
- en: These challenges are not listed here to imply that t-SNE is more work than it
    is worth, but rather to encourage treating the output with a degree of skepticism
    until it has been thoroughly explored. This may mean testing various hyperparameter
    combinations, or it may involve a qualitative examination of the visualization,
    such as investigating the identified clusters by hand in order to determine what
    features the neighborhood has in common. We’ll see some of these potential pitfalls
    in practice in the next section, which applies t-SNE to a familiar real-world
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Example – visualizing data’s natural clusters with t-SNE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To illustrate the ability of t-SNE to depict a dataset’s natural clusters,
    we’ll apply the method to the same 36-dimensional social media profile dataset
    used previously with PCA. Beginning as before, we’ll read the raw data into R
    using the tidyverse, but because t-SNE is somewhat computationally expensive,
    we use the `slice_sample()` command to limit the dataset to a random sample of
    5,000 users. This is not strictly necessary but will speed up the execution time
    and make the visualization less dense and thus easier to read. Don’t forget to
    use the `set.seed(123)` command to ensure your results match those that follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Even with a relatively small sample, the standard t-SNE implementation can still
    be rather slow. Instead, we will use a faster version called the **Barnes-Hut
    implementation**. The Barnes-Hut algorithm was originally developed to simulate
    the so-called “*n*-body” problem—the complex system of gravitational relationships
    that arises among a set of *n* celestial bodies. Because every object exerts a
    force on every other object, exactly computing the net force for each body requires
    *n* *× n = n*² calculations. This becomes computationally infeasible at an astronomical
    scale due to the scope of the universe and the virtually limitless numbers of
    objects within. Barnes-Hut simplifies this problem using a heuristic that treats
    more distant objects as a group identified by its center of mass, and only performs
    the exact calculations for objects closer than a threshold represented by the
    Greek letter *theta*. Larger values of theta drastically reduce the number of
    calculations needed to perform the simulation, while setting theta to zero performs
    the exact calculation.
  prefs: []
  type: TYPE_NORMAL
- en: Because the role of t-SNE can be imagined as an *n*-body problem of positioning
    points in space, with each point’s force of attraction to other points in the
    2-D space based on how similar it is to the same points in the high-dimensional
    space, the Barnes-Hut simplification can be applied to simplify the computation
    of the system’s gravity-like forces. This provides a t-SNE implementation that
    is much faster and scales much better on large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The `Rtsne` package, which you should install if you have not done so already,
    provides a wrapper for the C++ implementation of Barnes-Hut t-SNE. It also includes
    other optimizations for use with very large-dimensional datasets. One of these
    optimizations includes an initial PCA step, which by default reduces the dataset
    to its first 50 principal components.
  prefs: []
  type: TYPE_NORMAL
- en: Admittedly, it may seem odd to use PCA as part of the t-SNE process, but the
    two have complementary strengths and weaknesses. While t-SNE tends to struggle
    with the curse of dimensionality, PCA is strong at dimensionality reduction; likewise,
    while PCA tends to obscure local variance, t-SNE highlights the data’s natural
    structures. Using PCA to reduce the dimensionality and following this with the
    t-SNE process applies both techniques’ strengths. In our case, with a dataset
    having only 36 dimensions, the PCA step does not meaningfully affect the result.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll begin by running a t-SNE process with the default parameters. After setting
    the random seed, the 5,000-row sample is piped into a `select()` command to choose
    only the 36 columns that measure the counts of various terms used on each user’s
    profile. This is then piped into the `Rtsne()` function with `check_duplicates
    = FALSE` to prevent an error message that occurs when the dataset has duplicate
    rows. Duplicate rows are found in the social media dataset chiefly because there
    are many users who have counts of zero for all 36 terms. There is no reason that
    the t-SNE method cannot handle these duplicates, but including them may lead to
    unexpected or unsightly results in the visualization when the algorithm attempts
    to arrange such a tightly clustered set of points. For social media users, seeing
    this cluster will be helpful, so we will override the `Rtsne()` function’s default
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Piping a dataset into the `distinct()` function will eliminate duplicate rows
    and can be used prior to the `Rtsne()` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 2-D representation of the 36-dimensional dataset is stored as a matrix
    named `Y` in the `sns_tsne` list object created by the `Rtsne()` function. This
    has 5,000 rows representing the social media users, and two columns representing
    the (*x*, *y*) coordinates of each user. After converting the matrix to a data
    frame, we can pipe these values into a `ggplot()` function to visualize the t-SNE
    result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Displayed side by side with the earlier PCA visualization, it’s remarkable
    to see the vast improvement in visual clarity that the t-SNE technique provides.
    Distinct clusters of users can be observed, reflecting these users’ similarities
    in the 36-dimensional space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.10: Compared to PCA, the t-SNE technique tends to create more useful
    visualizations that depict the data’s natural clusters'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, it is somewhat unusual for a t-SNE visualization to work as nicely
    as this one did on the first try. If your results are disappointing, it is possible
    that merely setting a different random seed will generate better-looking results
    due to t-SNE’s use of randomization. Additionally, the `perplexity` and `max_iter`
    parameters of the `Rtsne()` function can be adjusted to affect the size and density
    of the resulting plot. The perplexity governs the number of nearest neighbors
    to consider during the adjustment from high-to-low dimensions, and changing the
    maximum number of iterations (`max_iter`) up or down may lead the algorithm to
    arrive at a completely different solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, there are very few rules of thumb for tuning these parameters,
    and thus it often requires some trial and error to get things just right. The
    creator of t-SNE, Laurens van der Maaten, offers a few words of wisdom:'
  prefs: []
  type: TYPE_NORMAL
- en: …one could say that a larger / denser dataset requires a larger perplexity.
    Typical values for the perplexity range between 5 and 50… [seeing a “ball” with
    uniformly distributed points] usually indicates you set your perplexity way too
    high. [If you continue to see bad results after tuning] maybe there is not very
    much nice structure in your data in the first place.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Source: [https://lvdmaaten.github.io/tsne/](https://lvdmaaten.github.io/tsne/)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Be warned that the `Rtsne()` function parameters like `perplexity` and `max_iter`
    can drastically affect the amount of time it takes for the t-SNE algorithm to
    converge. If you’re not careful, you may need to force the process to quit rather
    than wait endlessly. Setting `verbose = TRUE` in the `Rtsne()` function call may
    provide insight into how the work has progressed.
  prefs: []
  type: TYPE_NORMAL
- en: For an outstanding treatment of t-SNE’s parameters and hyperparameters with
    interactive visualizations that show the impact of adjustments to each, see *How
    to Use t-SNE Effectively, Wattenberg, M., Viégas, F., and Johnson, I., 2016*,
    `https://distill.pub/2016/misread-tsne/`.
  prefs: []
  type: TYPE_NORMAL
- en: Because t-SNE is an unsupervised method, aside from the remarkably large and
    round cluster in the top right of the visualization—which we can reasonably assume
    is composed of identical users with no social media keywords in their profile—we
    have no idea what the other clusters represent. This being said, it is possible
    to probe the data to investigate the clusters by labeling points with different
    colors or shapes based on their underlying values.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we can confirm the hypothesis about the top-right cluster by creating
    a categorical measure of how many keywords were used on each user’s page. The
    following tidyverse code begins by using `bind_cols()` to append the t-SNE coordinates
    onto the original dataset. Next, it uses the `rowwise()` function to change the
    behavior of `dplyr` so that the commands work on rows rather than columns. Thus,
    we can use the `sum()` function to count the number of terms each user had on
    their profile, using `c_across()` to select the columns with word counts. After
    using `ungroup()` to remove the rowwise behavior, this count is transformed into
    a two-outcome categorical variable using the `if_else()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the result of this series of steps, we’ll again plot the t-SNE data,
    but change the shape and color of the points according to the number of terms
    used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting figure confirms our assumption, as the users with zero terms
    used in their social media profile (denoted by circles) comprise the dense cluster
    in the top right of the figure, while the users with one or more terms used (denoted
    by triangles) are scattered elsewhere in the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.11: Adding color or changing the point style can help understand
    the clusters depicted in the t-SNE visualization'
  prefs: []
  type: TYPE_NORMAL
- en: The t-SNE technique is more than just a tool to make pretty pictures, although
    it does tend to also do that well! For one, it may be helpful for determining
    the value of *k* to be used for k-means clustering. The t-SNE technique can also
    be used after clustering has been performed, with the points colored according
    to their cluster assignments to illustrate the clusters for presentation purposes.
    Stakeholders are more likely to trust a model with results that can be seen in
    a PowerPoint presentation. Similarly, t-SNE can be used to qualitatively gauge
    the performance of an embedding such as word2vec; if the embedding is meaningful,
    plotting the 300-dimensional vectors in 2-D space will reveal clusters of words
    with related meanings. With so many useful applications of t-SNE, it is no wonder
    that it has quickly become a popular tool in the data science toolkit.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a fun application using both word2vec and t-SNE in which computers learned
    the meaning of emoji, see *emoji2vec: Learning Emoji Representations from their
    Description, Eisner, B., Rocktäschel, T., Augenstein, I., Bošnjak, M., and Riedel,
    S., 2016, in Proceedings of the 4th International Workshop on Natural Language
    Processing for Social Media at EMNLP 2016*.'
  prefs: []
  type: TYPE_NORMAL
- en: While tools like word2vec and t-SNE provide means for understanding big data,
    they are of no use if R is unable to handle the workload. The remainder of this
    chapter will equip you with additional tools for loading, processing, and modeling
    such large data sources.
  prefs: []
  type: TYPE_NORMAL
- en: Adapting R to handle large datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the phrase “big data” means more than just the number of rows or the
    amount of memory a dataset consumes, sometimes working with a large volume of
    data can be a challenge in itself. Large datasets can cause computers to freeze
    or slow to a crawl when system memory runs out, or models cannot be built in a
    reasonable amount of time. Many real-world datasets are very large even if they
    are not truly “big,” and thus you are likely to encounter some of these issues
    on future projects. In doing so, you may find that the task of turning data into
    action is more difficult than it first appeared.
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, there are packages that make it easier to work with large datasets
    even while remaining in the R environment. We’ll begin by looking at the functionality
    that allows R to connect to databases and work with datasets that may exceed available
    system memory, as well as packages allowing R to work in parallel, and some that
    utilize modern machine learning frameworks in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Querying data in SQL databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large datasets are often stored in a **database management system** (**DBMS**)
    such as Oracle, MySQL, PostgreSQL, Microsoft SQL, or SQLite. These systems allow
    the datasets to be accessed using the **Structured Query Language** (**SQL**),
    a programming language designed to pull data from databases.
  prefs: []
  type: TYPE_NORMAL
- en: The tidy approach to managing database connections
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'RStudio version 1.1, which was released in 2017, introduced a graphical approach
    for connecting to databases. The **Connections** tab in the top-right portion
    of the interface provides the ability to interact with database connections found
    on your system. Upon clicking the **New Connection** button within this interface
    tab, you will see a window with the available connection options. The following
    screenshot depicts some of the possible connection types, but your own system
    is likely to have a different selection than those shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.12: The “New Connection” button in RStudio v1.1 or greater opens
    an interface that will assist you with connecting to any predefined data sources'
  prefs: []
  type: TYPE_NORMAL
- en: The creation of these connections is typically performed by a database administrator
    and is specific to the type of database as well as the operating system. For instance,
    on Microsoft Windows, you may need to install the appropriate database drivers
    as well as use the ODBC Data Source Administrator application; on macOS and Unix/Linux,
    you may need to install the drivers and edit an `odbc.ini` file. Complete documentation
    about the potential connection types and installation instructions is available
    at [https://solutions.posit.co/connections/db/](https://solutions.posit.co/connections/db/).
  prefs: []
  type: TYPE_NORMAL
- en: Behind the scenes, the graphical interface uses a variety of R packages to manage
    the connections to these data sources. At the core of this functionality is the
    `DBI` package, which provides a tidyverse-compliant front-end interface to the
    database. The `DBI` package also manages the back-end database driver, which must
    be provided by another R package. Such packages let R connect to Oracle (`ROracle`),
    MySQL (`RMySQL`), PostgreSQL (`RPostgreSQL`), and SQLite (`RSQLite`), among many
    others.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this functionality, we’ll use the `DBI` and `RSQLite` packages
    to connect to a SQLite database containing the credit dataset used previously.
    SQLite is a simple database that doesn’t require running a server. It simply connects
    to a database file on a machine, which here is named `credit.sqlite3`. Before
    starting, be sure you’ve installed both required packages and saved the database
    file into your R working directory. After doing this, you can connect to the database
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'To prove the connection has succeeded, we can list the database tables to confirm
    the credit table exists as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'From here, we can send SQL query commands to the database and return records
    as R data frames. For instance, to return the loan applicants with an age of 45
    years or greater, we would query the database as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The entire result set can be fetched as a data frame using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'To confirm that it worked, we’ll examine the summary statistics, which confirm
    that the ages begin at 45 years:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'When our work is done, it is advisable to clear the query result set and close
    the database connection to free these resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: In addition to SQLite and the database-specific R packages, the `odbc` package
    allows R to connect to many different types of databases using a single protocol
    known as the **Open Database Connectivity** (**ODBC**) standard. The ODBC standard
    can be used regardless of operating system or DBMS.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have previously connected to an ODBC database, you may have referred
    to it via its **data source name** (**DSN**). You can use the DSN to create a
    database connection with a single line of R code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have a more complicated setup, or want to specify the connection properties
    manually, you can specify a full connection string as arguments to the DBI package
    `dbConnect()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: With the connection established, queries can be sent to the ODBC database and
    tables can be returned as data frames using the same functions that were used
    for the SQLite example previously.
  prefs: []
  type: TYPE_NORMAL
- en: Due to security and firewall settings, the instructions for configuring an ODBC
    network connection are highly specific to each situation. If you are having trouble
    setting up the connection, check with your database administrator. The Posit team
    (formerly known as RStudio) also provides helpful information at [https://solutions.posit.co/connections/db/best-practices/drivers/](https://solutions.posit.co/connections/db/best-practices/drivers/).
  prefs: []
  type: TYPE_NORMAL
- en: Using a database backend for dplyr with dbplyr
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using the tidyverse’s `dplyr` functions with an external database is no more
    difficult than using it with a traditional data frame. The `dbplyr` package (short
    for “database plyr”) allows any database supported by the `DBI` package to be
    used transparently as a backend for `dplyr`. The connection allows tibble objects
    to be pulled from the database. Generally, one does not need to do more than merely
    install the `dbplyr` package, and `dplyr` can then take advantage of its functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let’s connect to the SQLite `credit.sqlite3` database used previously,
    then save its `credit` table as a tibble object using the `tbl()` function as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Because `dplyr` has been routed through a database, the `credit_tbl` object
    here is not stored as a local R object, but rather is a table within a database.
    In spite of this, `credit_tbl` will act exactly like an ordinary tibble and will
    gain all the other benefits of the `dplyr` package, with the exception that the
    computational work will occur within the database rather than in R. This means
    that if the SQLite database were replaced with a database residing across a network
    on a more traditional SQL server, work could be offloaded to machines with more
    computational power rather than being performed on your local machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to query the database and display the age summary statistics for
    credit applicants that are at least 45 years old, we can pipe the tibble through
    the following sequence of functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Note that the `dbplyr` functions are “lazy,” which means that no work is done
    in the database until it is necessary. Thus, the `collect()` function forces `dplyr`
    to retrieve the results from the “server” (in this case, a SQLite instance, but
    more typically a powerful database server) so that the summary statistics may
    be calculated. If the `collect()` statement is omitted, the code will fail as
    the `summary()` function cannot work directly with the database connection object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a database connection, most `dplyr` commands will be translated seamlessly
    into SQL on the backend. To see how this works, we can ask `dbplyr` to show the
    SQL code that is generated for a series of `dplyr` steps. Let’s build a slightly
    more complex sequence of commands to show the average loan amount after filtering
    for ages 45 and older, and grouping by loan default status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows that those that defaulted tended to request larger loan amounts
    on average:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this looks different from a normal `dplyr` output and includes information
    about the database used, since the work was performed in the database rather than
    R. To see the SQL code that was generated to perform this analysis, simply pipe
    the steps into the `show_query()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows the SQL query that was run on the SQLite database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Using the `dbplyr` functionality, the same R code that is used on smaller data
    frames can also be used to prepare larger datasets stored in SQL databases—the
    heavy lifting is done on the remote server, rather than your local laptop or desktop
    machine. In this way, learning the tidyverse suite of packages ensures your code
    will apply to any type of project from small to massive. Of course, there are
    even more ways to enable R to work with large datasets, as you will see in the
    sections that follow.
  prefs: []
  type: TYPE_NORMAL
- en: Doing work faster with parallel processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the early days of computing, computer processors always executed instructions
    in **serial**, which meant that they were limited to performing a single task
    at a time. In serial computing, the next instruction cannot be started until the
    previous instruction is complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_15_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.13: In serial computing, tasks cannot begin until prior tasks have
    been completed'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although it was widely known that many tasks could be completed more efficiently
    by completing steps simultaneously, the technology simply did not exist. This
    was addressed by the development of **parallel computing** methods, which use
    a set of two or more processors or computers to perform tasks simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_15_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.14: Parallel computing allows several tasks to occur simultaneously,
    which can speed up processing, but the results must be combined at the end'
  prefs: []
  type: TYPE_NORMAL
- en: Many modern computers are designed for parallel computing. Even in the case
    that they have a single processor, they often have two or more cores that work
    in parallel. A core is essentially a processor within a processor, which allows
    computations to occur even if the other cores are busy with another task.
  prefs: []
  type: TYPE_NORMAL
- en: Networks of multiple computers called **clusters** can also be used for parallel
    computing. A large cluster may include a variety of hardware and be separated
    over large distances. In this case, the cluster is known as a **grid**. Taken
    to an extreme, a cluster or grid of hundreds or thousands of computers running
    commodity hardware could be a very powerful system. Cloud computing systems like
    Amazon Web Services (AWS) and Microsoft Azure make it easier than ever to use
    clusters for data science projects.
  prefs: []
  type: TYPE_NORMAL
- en: The catch, however, is that not every problem can be parallelized. Certain problems
    are more conducive to parallel execution than others. One might expect that adding
    100 processors would result in 100 times the work being accomplished in the same
    amount of time (that is, the overall execution time would be 1/100), but this
    is typically not the case. The reason is that it takes effort to manage the workers.
    Work must be divided into equal, non-overlapping tasks, and each of the workers’
    results must be combined into one final answer.
  prefs: []
  type: TYPE_NORMAL
- en: So-called **embarrassingly parallel** problems are the ideal. These tasks are
    easy to reduce into non-overlapping blocks of work, and the results are easy to
    recombine. An example of an embarrassingly parallel machine learning task would
    be 10-fold cross-validation; once the 10 samples are divided, each of the 10 blocks
    of work is independent, meaning that they do not affect the others. As you will
    soon see, this task can be sped up quite dramatically using parallel computing.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring R’s execution time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Efforts to speed up R will be wasted if it is not possible to systematically
    measure how much time was saved. Although a stopwatch is one option, an easier
    solution is to wrap the offending code in a `system.time()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, on the author’s laptop, the `system.time()` function notes that
    it takes about 0.026 seconds to generate a million random numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The same function can be used to evaluate improvement in performance, obtained
    with the methods that were just described or any R function.
  prefs: []
  type: TYPE_NORMAL
- en: For what it’s worth, when the first edition of this book was published, generating
    a million random numbers took 0.130 seconds; the same took about 0.093 seconds
    for the second edition and 0.067 seconds for the third edition. Here, it takes
    only 0.026 seconds. Although I’ve used a slightly more powerful computer each
    time, this reduction of about 80 percent of the processing time over the course
    of about ten years illustrates just how quickly computer hardware and software
    are improving!
  prefs: []
  type: TYPE_NORMAL
- en: Enabling parallel processing in R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `parallel` package, included with R version 2.14.0 and later, has lowered
    the entry barrier to deploying parallel algorithms by providing a standard framework
    for setting up worker processes that can complete tasks simultaneously. It does
    this by including components of the `multicore` and `snow` packages, which each
    take a different approach to multitasking.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your computer is reasonably recent, you are likely to be able to use parallel
    processing. To determine the number of cores your machine has, use the `detectCores()`
    function as follows. Note that your output will differ depending on your hardware
    specifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: The `multicore` package was developed by Simon Urbanek and allows parallel processing
    on a single machine that has multiple processors or processor cores. It utilizes
    the multitasking capabilities of a computer’s operating system to **fork**, or
    create a copy of, additional R sessions that share the same memory, and is perhaps
    the simplest way to get started with parallel processing in R.
  prefs: []
  type: TYPE_NORMAL
- en: Note that because the Microsoft Windows operating system does not support forking,
    the `multicore` example works only on macOS or Linux machines. For a Windows-ready
    solution, skip ahead to the next section on `foreach` and `doParallel`.
  prefs: []
  type: TYPE_NORMAL
- en: 'An easy way to get started with the `multicore` functionality is to use the
    `mclapply()` function, which is a multicore version of `lapply()`. For instance,
    the following blocks of code illustrate how the task of generating 10 million
    random numbers can be divided across 1, 2, 4, and 8 cores. The `unlist()` function
    is used to combine the parallel results (a list) into a single vector after each
    core has completed its chunk of work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Notice how as the number of cores increases, the elapsed time decreases, though
    the benefit tapers off and may even be detrimental once too many cores have been
    added. Though this is a simple example, it can be adapted easily to many other
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `snow` package (Simple Network of Workstations) by Luke Tierney, A. J.
    Rossini, Na Li, and H. Sevcikova allows parallel computing on multicore or multiprocessor
    machines as well as on a network of multiple machines. It is slightly more difficult
    to use but offers much more power and flexibility. The `snow` functionality is
    included in the `parallel` package, so to set up a cluster on a single machine,
    use the `makeCluster()` function with the number of cores to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: Because `snow` communicates via network traffic, depending on your operating
    system, you may receive a message to approve access through your firewall.
  prefs: []
  type: TYPE_NORMAL
- en: 'To confirm the cluster is operational, we can ask each node to report back
    its hostname. The `clusterCall()` function executes a function on each machine
    in the cluster. In this case, we’ll define a function that simply calls the `Sys.info()`
    function and returns the `nodename` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Unsurprisingly, since all four nodes are running on a single machine, they
    report back the same hostname. To have the four nodes run a different command,
    supply them with a unique parameter via the `clusterApply()` function. Here, we’ll
    supply each node with a different letter. Each node will then perform a simple
    function on its letter in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'When we’re done with the cluster, it’s important to terminate the processes
    it spawned. This will free up the resources each node is using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Using these simple commands, it is possible to speed up many machine learning
    tasks. For the largest big data problems, much more complex `snow` configurations
    are possible. For instance, you may attempt to configure a **Beowulf cluster**—a
    network of many consumer-grade machines. In academic and industry research settings
    with dedicated computing clusters, `snow` can use the `Rmpi` package to access
    these high-performance **message-passing interface** (**MPI**) servers. Working
    with such clusters requires knowledge of network configurations and computing
    hardware outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a much more detailed introduction to `snow`, including some information
    on how to configure parallel computing on several computers over a network, see
    the following lecture by Luke Tierney: [http://homepage.stat.uiowa.edu/~luke/classes/295-hpc/notes/snow.pdf](http://homepage.stat.uiowa.edu/~luke/classes/295-hpc/notes/snow.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Taking advantage of parallel with foreach and doParallel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `foreach` package by Rich Calaway and Steve Weston provides perhaps the
    easiest way to get started with parallel computing, especially if you are running
    R on the Windows operating system, as some of the other packages are platform
    specific.
  prefs: []
  type: TYPE_NORMAL
- en: The core of the package is a `foreach` looping construct. If you have worked
    with other programming languages, this may be familiar. Essentially, it allows
    looping over a set of items, without explicitly counting the number of items;
    in other words, *for each* item in the set, *do* something.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re thinking that R already provides a set of apply functions to loop
    over sets of items (for example, `apply()`, `lapply()`, `sapply()`, and so on),
    you are correct. However, the `foreach` loop has an additional benefit: iterations
    of the loop can be completed in parallel using a very simple syntax. Let’s see
    how this works.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall the command we’ve been using to generate millions of random numbers.
    To make this more challenging, let’s increase the count to a hundred million,
    which causes the process to take about 2.5 seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'After the `foreach` package has been installed, the same task can be expressed
    with a loop that combines four sets of 25,000,000 randomly generated numbers.
    The `.combine` parameter is an optional setting that tells `foreach` which function
    it should use to combine the final set of results from each loop iteration. In
    this case, since each iteration generates a set of random numbers, we simply use
    the `c()` concatenate function to create a single, combined vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: If you noticed that this function didn’t result in a speed improvement, good
    catch! In fact, the process was slower. The reason is that by default, the `foreach`
    package runs each loop iteration in serial, and the function adds a small amount
    of computational overhead to the process. The sister package `doParallel` provides
    a parallel backend for `foreach` that utilizes the `parallel` package included
    with R, described earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before parallelizing this work, it is wise to confirm the number of cores available
    on your system as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Your results will differ depending on your system capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, after installing and loading the `doParallel` package, simply register
    the desired number of cores and swap the `%do%` command with the `%dopar%` operator.
    Here, we only need at most four cores, as there are only four groups of random
    numbers to combine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the output, this results in a performance increase, cutting the
    execution time by about 40 percent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Warning**: if the `cores` parameter is set to a number greater than the available
    cores on your system, or if the combined work exceeds the free memory on your
    computer, R may crash! In this case, the vector of random numbers is nearly a
    gigabyte of data, so systems with low RAM may be especially prone to crashing
    here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To close the `doParallel` cluster, simply type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: Though the cluster will be closed automatically at the conclusion of the R session,
    it is better form to do so explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Training and evaluating models in parallel with caret
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `caret` package by Max Kuhn (covered previously in *Chapter 10*, *Evaluating
    Model Performance*, and *Chapter 14*, *Building Better Learners*) will transparently
    utilize a parallel backend if one has been registered with R using the `foreach`
    package described previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a simple example in which we attempt to train a random forest
    model on the credit dataset. Without parallelization, the model takes about 65
    seconds to train:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, if we use the `doParallel` package to register eight cores
    to be used in parallel (be sure to lower this number if you have fewer than eight
    cores available), the model takes about 10 seconds to build—less than one-sixth
    of the time—and we didn’t need to change the remaining `caret` code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: Many of the tasks involved in training and evaluating models, such as creating
    random samples and repeatedly testing predictions for 10-fold cross-validation,
    are embarrassingly parallel and ripe for performance improvements. With this in
    mind, it is wise to always register multiple cores before beginning a `caret`
    project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuration instructions and a case study of the performance improvements
    for enabling parallel processing in `caret` are available on the project’s website:
    [https://topepo.github.io/caret/parallel-processing.html](https://topepo.github.io/caret/parallel-processing.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing specialized hardware and algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base R has a reputation for being slow and memory inefficient, a reputation
    that is at least somewhat earned. These faults are largely unnoticed on a modern
    PC for datasets of many thousands of records, but datasets with millions of records
    or more can exceed the limits of what is currently possible with consumer-grade
    hardware. The problem is worsened if the dataset contains many features or if
    complex learning algorithms are being used.
  prefs: []
  type: TYPE_NORMAL
- en: CRAN has a high-performance computing task view that lists packages pushing
    the boundaries of what is possible in R at [http://cran.r-project.org/web/views/HighPerformanceComputing.html](http://cran.r-project.org/web/views/HighPerformanceComputing.html).
  prefs: []
  type: TYPE_NORMAL
- en: Packages that extend R past the capabilities of the base package are being developed
    rapidly. These packages allow R to work faster, perhaps by spreading the work
    over additional computers or processors, by utilizing specialized computer hardware,
    or by providing machine learning optimized to big data problems.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel computing with MapReduce concepts via Apache Spark
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **MapReduce** programming model was developed at Google to process its
    data on a large cluster of networked computers. MapReduce conceptualizes parallel
    programming as a two-step process:'
  prefs: []
  type: TYPE_NORMAL
- en: A **map** step, in which a problem is divided into smaller tasks that are distributed
    across the computers in the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **reduce** step, in which the results of the small chunks of work are collected
    and synthesized into a solution to the original problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A popular open-source alternative to the proprietary MapReduce framework is
    **Apache Hadoop**. The Hadoop software comprises the MapReduce concept plus a
    distributed filesystem capable of storing large amounts of data across a cluster
    of computers. Hadoop requires somewhat specialized programming skills to take
    advantage of its capabilities and to perform even basic machine learning tasks.
    Additionally, although Hadoop is excellent at working with extremely large amounts
    of data, it may not always be the fastest option because it keeps all data on
    disk rather than utilizing available memory.
  prefs: []
  type: TYPE_NORMAL
- en: '**Apache Spark** is a cluster-computing framework for big data, offering solutions
    to these issues with Hadoop. Spark takes advantage of the cluster’s available
    memory to process data approximately 100x faster than Hadoop. Additionally, it
    provides easy-to-use libraries for many common data processing, analysis, and
    modeling tasks. These include the SparkSQL data query language, the MLlib machine
    learning library, GraphX for graph and network analysis, and the Spark Streaming
    library for processing real-time data streams. For these reasons, Spark is perhaps
    the current standard for open-source big data processing.'
  prefs: []
  type: TYPE_NORMAL
- en: Packt Publishing has published many books on Spark. To search their current
    offerings, visit [https://subscription.packtpub.com/search?query=spark](https://subscription.packtpub.com/search?query=spark).
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark is often run remotely on a cloud-hosted cluster of virtual machines,
    but its benefits can also be seen running on your own hardware. In either case,
    the `sparklyr` package connects to the cluster and provides a `dplyr` interface
    for analyzing the data using Spark.
  prefs: []
  type: TYPE_NORMAL
- en: More detailed instructions for using Spark with R can be found at [https://spark.rstudio.com](https://spark.rstudio.com),
    but the basic instructions for getting up and running are straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the fundamentals, let’s build a random forest model on the credit
    dataset to predict loan defaults. To begin, you’ll need to install and load the
    `sparklyr` package. Then, the first time you use Spark, you’ll need to run the
    `spark_install()` function, which downloads Spark onto your computer. Note that
    this is a sizeable download at about 220 megabytes, as it includes the full Spark
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, Spark itself requires a Java installation, which can be downloaded
    from `http://www.java.com` if you do not already have it. Once Spark and Java
    have been installed, you can instantiate a Spark cluster on your local machine
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we’ll load the loan dataset from the `credit.csv` file on our local machine
    into the Spark instance, then use the Spark function `sdf_random_split()` to randomly
    assign 75 and 25 percent of the data to the training and test sets, respectively.
    The `seed` parameter is the random seed to ensure the results are identical each
    time this code is run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we’ll pipe the training data into the random forest model function,
    make predictions, and use the classification evaluator to compute the AUC on the
    test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll then disconnect from the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: With just a few lines of R code, we’ve built a random forest model using Spark
    that could expand to model millions of records. If even more computing power is
    needed, the code can be run in the cloud using a massively parallel Spark cluster
    simply by pointing the `spark_connect()` function to the correct hostname. The
    code can also be easily adapted to other modeling approaches using one of the
    supervised learning functions in the Spark Machine Learning Library (MLlib) listed
    at [https://spark.rstudio.com/mlib/](https://spark.rstudio.com/mlib/).
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the easiest way to get started using Spark is with Databricks, a cloud
    platform developed by the creators of Spark that makes it easy to manage and scale
    clusters via a web-based interface. The free “Community Edition” provides a small
    cluster for you to try tutorials or even experiment with your own data. Check
    it out at [https://databricks.com](https://databricks.com).
  prefs: []
  type: TYPE_NORMAL
- en: Learning via distributed and scalable algorithms with H2O
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **H2O project** ([https://h2o.ai](https://h2o.ai)) is a big data framework
    that provides fast in-memory implementations of machine learning algorithms, which
    can also operate in a cluster-computing environment. It includes functions for
    many of the methods covered in this book, including Naive Bayes, regression, deep
    neural networks, k-means clustering, ensemble methods, and random forests, among
    many others.
  prefs: []
  type: TYPE_NORMAL
- en: H2O uses heuristics to find approximate solutions to machine learning problems
    by iterating repeatedly over smaller chunks of the data. This gives the user the
    control to determine exactly how much of a massive dataset the learner should
    use. For some problems, a quick solution may be acceptable, but for others, the
    complete set may be required, which will require additional training time.
  prefs: []
  type: TYPE_NORMAL
- en: H2O is usually substantially faster and performs better on very massive datasets
    relative to Spark’s machine learning functions, which are already much faster
    than base R. However, because Apache Spark is a commonly used cluster-computing
    and big data preparation environment, H2O can be run on Apache Spark using the
    **Sparkling Water** software. With Sparkling Water, data scientists have the best
    of both worlds—the benefits of Spark for data preparation, and the benefits of
    H2O for machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: The `h2o` package provides functionality for accessing an H2O instance from
    within the R environment. A full tutorial on H2O is outside the scope of this
    book, and documentation is available at `http://docs.h2o.ai`, but the basics are
    straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, be sure you have Java installed on your computer ([http://www.java.com](http://www.java.com))
    and install the `h2o` package in R. Then, initialize a local H2O instance using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'This starts an H2O server on your computer, which can be viewed via H2O Flow
    at `http://localhost:54321`. The H2O Flow web application allows you to administer
    and send commands to the H2O server, or even build and evaluate models using a
    simple, browser-based interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_15_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.15: H2O Flow is a web application for interacting with the H2O instance'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although you could complete an analysis within this interface, let’s go back
    to R and use H2O on the loan default data that we examined previously. First,
    we need to upload the `credit.csv` dataset to this instance using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: Note that the `.hex` extension is used to refer to an H2O data frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we’ll apply H2O’s random forest implementation to this dataset using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this command includes information on the out-of-bag estimates
    of model performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: Although the credit dataset used here is not very large, the H2O code used here
    would scale to datasets of almost any size. Additionally, the code would be virtually
    unchanged if it were to be run in the cloud—simply point the `h2o.init()` function
    to the remote host.
  prefs: []
  type: TYPE_NORMAL
- en: GPU computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An alternative to parallel processing uses a computer’s **graphics processing
    unit** (**GPU**) to increase the speed of mathematical calculations. A GPU is
    a specialized processor that is optimized for rapidly displaying images on a computer
    screen. Because a computer often needs to display complex 3D graphics (particularly
    for video games), many GPUs use hardware designed for parallel processing and
    extremely efficient matrix and vector calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'A side benefit is that they can be used to efficiently solve certain types
    of mathematical problems. As depicted in the following illustration, where a typical
    laptop or desktop computer processor may have on the order of 16 cores, a typical
    GPU may have thousands or even tens of thousands:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing shoji, building  Description automatically generated](img/B17290_15_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.16: A graphics processing unit (GPU) has many times more cores than
    the typical central processing unit (CPU)'
  prefs: []
  type: TYPE_NORMAL
- en: The downside of GPU computing is that it requires specific hardware that is
    not included with many computers. In most cases, a GPU from the manufacturer NVIDIA
    is required, as it provides a proprietary framework called **Complete Unified
    Device Architecture** (**CUDA**) that makes the GPU programmable using common
    languages such as C++.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on NVIDIA’s role in GPU computing, go to [https://www.nvidia.com/en-us/deep-learning-ai/solutions/machine-learning/](https://www.nvidia.com/en-us/deep-learning-ai/solutions/machine-learning/).
  prefs: []
  type: TYPE_NORMAL
- en: The `gputools` package by Josh Buckner, Mark Seligman, and Justin Wilson implements
    several R functions, such as matrix operations, clustering, and regression modeling
    using the NVIDIA CUDA toolkit. The package requires a CUDA 1.3 or higher GPU and
    the installation of the NVIDIA CUDA toolkit. This package was once the standard
    approach for GPU computing in R, but appears to have gone without an update since
    2017 and has since been removed from the CRAN repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, it appears that GPU work has transitioned to the TensorFlow mathematical
    library. The RStudio team provides information about using a local or cloud GPU
    on the following pages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/install/local_gpu](https://tensorflow.rstudio.com/install/local_gpu)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/install/cloud_server_gpu](https://tensorflow.rstudio.com/install/cloud_server_gpu)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the time of publication, a typical GPU used for deep learning is priced at
    several hundred US dollars for entry-level models and around $1,000-$3,000 for
    moderately priced units with greater performance. High-end units may cost many
    thousands of dollars.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than spending this much up front, many people rent server time by the
    hour on cloud providers like AWS and Microsoft Azure, where it costs approximately
    $1 per hour for a minimal GPU instance—just don’t forget to shut it down when
    your work completes, as it can get expensive quite quickly!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is certainly an exciting time to be studying machine learning. Ongoing work
    on the relatively uncharted frontiers of parallel and distributed computing offers
    great potential for tapping the knowledge found in the deluge of big data. And
    the burgeoning data science community is facilitated by the free and open-source
    R programming language, which provides a very low barrier to entry—you simply
    need to be willing to learn.
  prefs: []
  type: TYPE_NORMAL
- en: The topics you have learned, in both this chapter as well as previous chapters,
    provide the foundation for understanding more advanced machine learning methods.
    It is now your responsibility to keep learning and adding tools to your arsenal.
    Along the way, be sure to keep in mind the no free lunch theorem—no learning algorithm
    rules them all, and they all have varying strengths and weaknesses. For this reason,
    there will always be a human element to machine learning, adding subject-specific
    knowledge and the ability to match the appropriate algorithm to the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: In the coming years, it will be interesting to see how the human side changes
    as the line between machine learning and human learning blurs. Services such as
    Amazon’s Mechanical Turk provide crowd-sourced intelligence, offering a cluster
    of human minds ready to perform simple tasks at a moment’s notice. Perhaps one
    day, just as we have used computers to perform tasks that human beings cannot
    do easily, computers will employ human beings to do the reverse. What interesting
    food for thought!
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 4000 people at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/r](https://packt.link/r)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/r.jpg)'
  prefs: []
  type: TYPE_IMG
