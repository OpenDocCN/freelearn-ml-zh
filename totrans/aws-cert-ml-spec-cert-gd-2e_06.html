<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer091">
			<h1 class="chapter-number"><a id="_idTextAnchor707"/>6</h1>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor708"/>Applying Machine Learning Algorithms</h1>
			<p><a id="_idTextAnchor709"/>In the previous chapter, you learned about understanding data and visualization. It is now time to move on to the modeling phase and study machine learning algorithms! In the earlier chapters, you learned that building machine learning models requires a lot of knowledge about AWS services, data engineering, data exploration, data architecture, and much more. This time, you will delve deeper into the algorithms that have been introduced <span class="No-Break">and more.</span></p>
			<p>Having a good sense of the different types of algorithms and machine learning approaches will put you in a very good position to make decisions during your projects. Of course, this type of knowledge is also crucial to the AWS Certified Machine Learning <span class="No-Break">Specialty exam.</span></p>
			<p>Bear in mind that there are thousands of algorithms out there. You can even propose your own algorithm for a particular problem. In this chapter, you will learn about the most relevant ones and, hopefully, the ones that you will probably face in <span class="No-Break">the exam.</span></p>
			<p>The main topics of this chapter are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Storing the <span class="No-Break">training data</span></li>
				<li>A word about <span class="No-Break">ensemble models</span></li>
				<li><span class="No-Break">Supervised learning:</span></li>
				<li><span class="No-Break">Regression models</span></li>
				<li><span class="No-Break">Classification models</span></li>
				<li><span class="No-Break">Forecasting models</span></li>
				<li><span class="No-Break">Object2Vec</span></li>
				<li><span class="No-Break">Unsupervised learning:</span></li>
				<li><span class="No-Break">Clustering</span></li>
				<li><span class="No-Break">Anomaly detection</span></li>
				<li><span class="No-Break">Dimensionality reduction</span></li>
				<li><span class="No-Break">IP Insights</span></li>
				<li>Textual analysis (natural <span class="No-Break">language processing)</span></li>
				<li><span class="No-Break">Image processing</span></li>
				<li><span class="No-Break">Reinforcement learning</span></li>
			</ul>
			<p>Alright, grab a coffee and <span class="No-Break">rock it!</span></p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor710"/><a id="_idTextAnchor711"/>Introducing this chapter</h1>
			<p>During this chapter, you will read about several algorithms, modeling concepts, and learning strategies. All these topics are beneficial for you to know for the exam and throughout your career as a <span class="No-Break">data scientist.</span></p>
			<p>This chapter has been structured in such a way that it not only covers the necessary topics of the exam but also gives you a good sense of the most important learning strategies out there. For example, the exam will check your knowledge regarding the basic concepts of K-Means. However, this chapter will cover it on a much deeper level, since this is an important topic for your career as a <span class="No-Break">data scientist.</span></p>
			<p>The chapter will follow this approach of looking deeper into the algorithms’ logic for some types of models that every data scientist should master. Furthermore, keep this in mind: sometimes you may go deeper than what is expected of you in the exam, but that will be extremely important for you in <span class="No-Break">your career.</span></p>
			<p>Many times during this chapter, you will see the term <strong class="bold">built-in algorithms</strong>. This term will be used to refer to the list of algorithms implemented by AWS on their <span class="No-Break">SageMaker SDK.</span></p>
			<p>Here is a concrete example: you can use scikit-learn’s <strong class="bold">K-nearest neighbors</strong> algorithm, or KNN for short (if you don’t remember what scikit-learn is, refresh your memory by going back to <a href="B21197_01.xhtml#_idTextAnchor018"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><em class="italic">, Machine Learning Fundamentals</em>) to create a classification model and deploy it to SageMaker. However, AWS also offers its own implementation of the KNN algorithm on its SDK, which is optimized to run in the AWS environment. Here, KNN is an example of a <span class="No-Break">built-in algorithm.</span></p>
			<p>The possibilities on AWS are endless because you can either take advantage of built-in algorithms or bring in your own algorithm to create models on SageMaker. Finally, just to make this very clear, here is an example of how to import a built-in algorithm from the <span class="No-Break">AWS SDK:</span></p>
			<pre class="console"><strong class="source-inline">import sagemaker</strong></pre>
			<pre class="console"><strong class="source-inline">knn = sagemaker.estimator.Estimator(get_image_uri(boto3.Session().region_name, "knn"),</strong></pre>
			<pre class="console"><strong class="source-inline">        get_execution_role(),</strong></pre>
			<pre class="console"><strong class="source-inline">        train_instance_count=1,</strong></pre>
			<pre class="console"><strong class="source-inline">        train_instance_type='ml.m5.2xlarge',</strong></pre>
			<pre class="console"><strong class="source-inline">        output_path=output_path,</strong></pre>
			<pre class="console"><strong class="source-inline">        sagemaker_session=sagemaker.Session())</strong></pre>
			<pre class="console"><strong class="source-inline">knn.set_hyperparameters(**hyperparams)</strong></pre>
			<p>You will learn how to create models on SageMaker in <a href="B21197_09.xhtml#_idTextAnchor1224"><span class="No-Break"><em class="italic">Chapter 9</em></span></a><em class="italic">, Amazon SageMaker Modeling</em>. For now, just understand that AWS has its own set of libraries where those built-in algorithms <span class="No-Break">are implemented.</span></p>
			<p>To train and evaluate a model, you need training and testing data. After instantiating your estimator, you should then feed it with those datasets. Not to spoil <a href="B21197_09.xhtml#_idTextAnchor1224"><span class="No-Break"><em class="italic">Chapter 9</em></span></a><em class="italic">, Amazon SageMaker Modeling</em>, but you should know about the concept of <strong class="bold">data channels</strong> <span class="No-Break">in advance.</span></p>
			<p>Data channels are<a id="_idTextAnchor712"/> configurations related to input data that you can pass to SageMaker when you are creating a training job. You should set these configurations just to inform SageMaker of how your input data <span class="No-Break">is formatted.</span></p>
			<p>In <a href="B21197_09.xhtml#_idTextAnchor1224"><span class="No-Break"><em class="italic">Chapter 9</em></span></a><em class="italic">, Amazon SageMaker Modeling</em>, you will learn how to create training jobs and how to set data channels. As of now, you should know that while configuring data channels, you can set a <strong class="bold">content type</strong> (<strong class="source-inline">ContentType</strong>) and an <strong class="bold">input mode</strong> (<strong class="source-inline">TrainingInputMode</strong>). You will now take a closer look at how and where the training data should be stored so that it can be integrated properly with AWS’s <span class="No-Break">built-in algorithms.</span></p>
			<h1 id="_idParaDest-131"><a id="_idTextAnchor713"/><a id="_idTextAnchor714"/>Storing the training data</h1>
			<p><a id="_idTextAnchor715"/>First <a id="_idTextAnchor716"/>of all, you can use multiple AWS services to prepare data for machine learning, such as <strong class="bold">Elastic MapReduce (EMR),</strong> Redshift, Glue, and so on. After preprocessing the training data, you should store it in S3, in a format expected by the algorithm you are using. <em class="italic">Table 6.1</em> shows the list of acceptable data formats <span class="No-Break">per algorithm.</span></p>
			<table id="table001-5" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Data<a id="_idTextAnchor717"/> format</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Algorithm</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Application/x-image</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Object detection algorithm, <span class="No-Break">semantic segmentation</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Application/x-recordio</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Object <span class="No-Break">detection algorithm</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Application/x-recordio-protobuf</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Factorization machines, K-Means, KNN, latent Dirichlet allocation, linear learner, NTM, PCA, <span class="No-Break">RCF, sequence-to-sequence</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Application/jsonlines</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">BlazingText, DeepAR</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Image/.jpeg</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Object detection algorithm, <span class="No-Break">semantic segmentation</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Image/.png</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Object detection algorithm, <span class="No-Break">semantic segmentation</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Text/.csv</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>IP Insights, K-Means, KNN, latent Dirichlet allocation, linear learner, NTM, PCA, <span class="No-Break">RCF, XGBoost</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">Text/.libsvm</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">XGBoost</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.1 – Data formats that are acceptable per AWS algorithm</p>
			<p>As you can see, many algorithms accept <strong class="source-inline">Text/.csv</strong> format. You should follow these rules if you want to use <span class="No-Break">that format:</span></p>
			<ul>
				<li>Your CSV file <em class="italic">cannot</em> have a <span class="No-Break">header record.</span></li>
				<li>For supervised learning, the target variable must be in the <span class="No-Break">first column.</span></li>
				<li>While configuring the training pipeline, set the input data channel as <strong class="source-inline">content_type</strong> equal <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">text/csv</strong></span><span class="No-Break">.</span></li>
				<li>For unsupervised learning, set <strong class="source-inline">label_size</strong> within <strong class="source-inline">content_type</strong>, as <span class="No-Break">follows: </span><span class="No-Break"><strong class="source-inline">'content_type=text/csv;label_size=0'</strong></span><span class="No-Break">.</span></li>
			</ul>
			<p>Although<a id="_idTextAnchor718"/> <strong class="source-inline">text/.csv</strong> format is fine for many use cases, most of the time, AWS’s built-in algorithms work better <a id="_idTextAnchor719"/>with <strong class="source-inline">recordIO-protobuf</strong>. This is an optimized data format that is used to train AWS’s built-in algorithms, where SageMaker converts each observation in the dataset into a binary representation that is a set of <span class="No-Break">4-byte floats.</span></p>
			<p>RecordIO-protobuf accepts two types of input modes: pipe mode and file mode. In pipe mode, the data will be streamed directly from S3, which helps optimize storage. In file mode, the data is copied from S3 to the training instance’s <span class="No-Break">store volume.</span></p>
			<p>You are almost ready! Now you can take a quick look at some modeling definitions that will help you understand some more <span class="No-Break">advanced algorithms.</span></p>
			<h1 id="_idParaDest-132"><a id="_idTextAnchor720"/><a id="_idTextAnchor721"/>A word about ensemble models</h1>
			<p>Before you start <a id="_idTextAnchor722"/>diving into the algorithms, there is an important modeling concept that you should be <a id="_idTextAnchor723"/>aware of – <strong class="bold">ensemble</strong>. The term ensemble is used to describe methods that use multiple algorithms to create <span class="No-Break">a model.</span></p>
			<p>A regular algorithm that <em class="italic">does not</em> implement ensemble methods will rely on a single model to train and predict the target variable. That is what happens when you create a decision tree or regression model. On the other hand, algorithms that <em class="italic">do</em> implement ensemble methods will rely on multiple models to predict the target variable. In that case, since each of these models might come up with a different prediction for the target variable, ensemble algorithms implement either a voting (for classification models) or averaging (for regression models) system to output the <a id="_idTextAnchor724"/>final results. <em class="italic">Table 6.2</em> illustrates a very simple voting system for an ensemble algorithm composed of <span class="No-Break">three models.</span><a id="_idTextAnchor725"/></p>
			<table id="table002-3" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Transaction</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Model A</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Model B</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Model C</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Prediction</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>3</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>4</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Fraud</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Not Fraud</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.2 – An example of a voting system on ensemble methods</p>
			<p>As described before, the same approach works for <a id="_idTextAnchor726"/>regression problems, where instead of voting, it could average the results of each model and use that as <span class="No-Break">the outcome.</span></p>
			<p>Voting and averaging are just two examples of ensemble approaches. Other powerful techniques <a id="_idTextAnchor727"/>include blending and stacking, where you can create multiple models and use the outcome of each <a id="_idTextAnchor728"/>model as a feature for a main model. Looking back at <em class="italic">Table 6.2</em>, columns <em class="italic">Model A</em>, <em class="italic">Model B</em>, and <em class="italic">Model C</em> could be used as features to predict the <a id="_idTextAnchor729"/><span class="No-Break">final outcome.</span></p>
			<p>It turns out that many machine learning algorithms use ensemble methods while training, in an embedded way. These algorithms can be classified into two <span class="No-Break">main categories:</span></p>
			<ul>
				<li><strong class="bold">Bootstrapping aggregation</strong> or <strong class="bold">bagging</strong>: With this approach, several models are trained on top<a id="_idTextAnchor730"/> of different samples of da<a id="_idTextAnchor731"/>ta. Predictions <a id="_idTextAnchor732"/>are then made through the voting or averaging system. The<a id="_idTextAnchor733"/> most popular algorithm from this category is known as <span class="No-Break"><strong class="bold">Random Forest</strong></span><span class="No-Break">.</span></li>
				<li><strong class="bold">Boosting</strong>: With this approach, several <a id="_idTextAnchor734"/>models are trained on top of different samples of the data. One model then tries to correct the error of the next model by penalizing incorrect predictions. The<a id="_idTextAnchor735"/> most popular algorithms from this category are <a id="_idTextAnchor736"/><strong class="bold">stochastic gradient boosting</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">AdaBoost</strong></span><span class="No-Break">.</span></li>
			</ul>
			<p>Now that you know what ensemble models are, you can look at some machine learning algorithms that are likely to be present in your exam. Not all of them use <span class="No-Break">ensemble approaches.</span></p>
			<p>The next few sections are split based on AWS algorithm categories, <span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break">Supervised learning</span></li>
				<li><span class="No-Break">Unsupervised learning</span></li>
				<li><span class="No-Break">Textual analysis</span></li>
				<li><span class="No-Break">Image processing</span></li>
			</ul>
			<p>Finally, you will have an overview of reinforcement learning <span class="No-Break">on AWS.</span></p>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor737"/><a id="_idTextAnchor738"/>Supervised learning</h1>
			<p>AWS provides <a id="_idTextAnchor739"/>supervised learning algorithms for general purposes (regression and classification tasks) and more specific purposes (forecasting and vectorization). The list of built-in algorithms that can be found in these sub-categories is <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Linear <span class="No-Break">learner algorithm</span></li>
				<li>Factorization <span class="No-Break">machines algorithm</span></li>
				<li><span class="No-Break">XGBoost algorithm</span></li>
				<li><span class="No-Break">KNN algorithm</span></li>
				<li><span class="No-Break">Object2Vec algorithm</span></li>
				<li>DeepAR <span class="No-Break">forecasting algorithm</span></li>
			</ul>
			<p>You will start by learning about regression models and the linear <span class="No-Break">learner algorithm.</span></p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor740"/><a id="_idTextAnchor741"/>Working with regression models</h2>
			<p>L<a id="_idTextAnchor742"/>ooking at <strong class="bold">linear regression</strong> models is a<a id="_idTextAnchor743"/> nice way to understand what is going on inside <strong class="bold">regression models</strong> in general (linear and non-linear regression models). This is mandatory knowledge for every data scientist and can help you solve real challenges as well. You will now take a closer look at this in the <span class="No-Break">following subsections.</span></p>
			<h3 id="_idParaDest-135"><a id="_idTextAnchor744"/>Introducing regression algorithms</h3>
			<p>Linear regression <a id="_idTextAnchor745"/>models aim to predict a numeric value (<em class="italic">y</em>) according to one or more variables (<em class="italic">x</em>). Mathematically, such a relationship can be defined as <em class="italic">y = f(x)</em>, where <em class="italic">y</em> is known <a id="_idTextAnchor746"/>as the <strong class="bold">dependent variable</strong> and <em class="italic">x</em> is known as <a id="_idTextAnchor747"/>the <span class="No-Break"><strong class="bold">independent variable</strong></span><span class="No-Break">.</span></p>
			<p>With regression models, the component that you want to predict (<em class="italic">y</em>) is always a continuous number – for example, the price of houses or the number of transactions. You saw this in <a href="B21197_01.xhtml#_idTextAnchor018"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><em class="italic">, Machine</em> <em class="italic">Learning Fundamentals</em>, in <span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.2</em>, when you were learning about the right type of supervised learning algorithm, given the target variable. Please feel free to go back and <span class="No-Break">review it.</span></p>
			<p>When you use <em class="italic">just one variable to predict y</em>, this<a id="_idTextAnchor748"/> problem is referred to as <strong class="bold">simple linear regression</strong>. On the other hand, when you use <em class="italic">more than one variable to predict y</em>, <a id="_idTextAnchor749"/>you have a <strong class="bold">multiple linear </strong><span class="No-Break"><strong class="bold">regression</strong></span><span class="No-Break"> problem.</span></p>
			<p>There is also another class of regression models, known as <strong class="bold">non-linear regression</strong>. However, let us put that aside for a moment and <a id="_idTextAnchor750"/>understand what simple linear <span class="No-Break">regression means.</span></p>
			<p>Regression models belong to the supervised side of machine learning (the other side is non-supervised) because algorithms try to predict values according to existing correlations between independent and <span class="No-Break">dependent variables.</span></p>
			<p>But what does <em class="italic">f</em> mean in <em class="italic">y=f(x)</em>? Here, <em class="italic">f</em> is the regression function responsible for predicting <em class="italic">y</em> based on <em class="italic">x</em>. In other words, this is the function that you want to find. When talking about simple linear regression, pay attention to the next three questions <span class="No-Break">and answers:</span></p>
			<ul>
				<li>What is the shape of <em class="italic">f</em> in <span class="No-Break">linear regression?</span><p class="list-inset">Linear, <span class="No-Break">of course!</span></p></li>
				<li>How can you represent a <span class="No-Break">linear relationship?</span><p class="list-inset">Using a <em class="italic">straight</em> line (you will understand why in a <span class="No-Break">few minutes).</span></p></li>
				<li>So what is the function that defines <span class="No-Break">a line?</span><p class="list-inset"><em class="italic">ax + b</em> (just check any <span class="No-Break"><em class="italic">mathematics</em></span><span class="No-Break"> book).</span></p></li>
			</ul>
			<p>That is it! Linear regression models are given by <em class="italic">y = ax + b</em>. When you are trying to predict <em class="italic">y</em> given <em class="italic">x</em>, you just need to find out the values of <em class="italic">a</em> and <em class="italic">b</em>. You can adopt the same logic to figure out what is going on inside other kinds <span class="No-Break">of regression.</span></p>
			<p>Finding out the values of <em class="italic">a</em> and <em class="italic">b</em> is the only thing you are going to do. It is nice to know that <em class="italic">a</em> is also known as <a id="_idTextAnchor751"/>the <strong class="bold">alpha coefficient</strong>, or <strong class="bold">slope</strong>, and<a id="_idTextAnchor752"/> represents the line’s inclination, while <em class="italic">b</em> is also known as <a id="_idTextAnchor753"/>the <strong class="bold">beta coefficient</strong>, or <strong class="bold">y intercept</strong>, and represents the place where the line crosses the <a id="_idTextAnchor754"/><em class="italic">y</em> axis (into a two-dimensional plane consisting of <em class="italic">x</em> and <em class="italic">y</em>). You will learn about these two terms in a <span class="No-Break">later subsection.</span></p>
			<p>It is also nice to know that<a id="_idTextAnchor755"/> there is a bias (<em class="italic">e</em>) associated with every predictor that you do not have control over. <a id="_idTextAnchor756"/>That being said, the formal definition of simple linear regression is given by <em class="italic">y = ax + b + </em><span class="No-Break"><em class="italic">e</em></span><span class="No-Break">.</span></p>
			<p>In the next subsection, you will learn how to find alpha and beta to solve a simple linear <span class="No-Break">regression problem.</span></p>
			<h3 id="_idParaDest-136"><a id="_idTextAnchor757"/>Least squares method</h3>
			<p>There are <a id="_idTextAnchor758"/>different ways to find the slope and <em class="italic">y</em> intercept of a line, but the most used method is known as the <strong class="bold">least squares method</strong>. The principle behind this method is simple: you have to find the <em class="italic">best line that reduces the sum of </em><span class="No-Break"><em class="italic">squared error</em></span><span class="No-Break">.</span></p>
			<p>In <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.1</em>, you can see a Cartesian plane with multiple points and lines in it. <em class="italic">Line a</em> represents the best fit for this data – in other words, that would be the best linear regression function for those points. But how can you know that? It is simple: if you compute the error associated with each point, you will realize that <em class="italic">Line a</em> contains the least sum of <span class="No-Break">squared errors.</span></p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B21197_06_01.jpg" alt="Figure 6.1 – Visualizing the principle of the least squares method" width="1286" height="517"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor759"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – Visualizing the principle of the least squares method</p>
			<p>It is worth u<a id="_idTextAnchor760"/>nderstanding linear regression from scratch not only for the certification exam but also for your career as a data scientist. To provide you with a complete example, a spreadsheet containing all the calculations that you are going to see h<a id="_idTextAnchor761"/>as been developed! You are encouraged to jump on this support material and perform some simulations. In any case, you will see these calculations in action in the <span class="No-Break">next subsection.</span></p>
			<h3 id="_idParaDest-137"><a id="_idTextAnchor762"/>Creating a linear regression model from scratch</h3>
			<p>You are going to use a very s<a id="_idTextAnchor763"/>imple dataset, with only <span class="No-Break">two variables:</span></p>
			<ul>
				<li><em class="italic">x</em>: Represents the person’s number of years of <span class="No-Break">work experience</span></li>
				<li><em class="italic">y</em>: Represents the person’s <span class="No-Break">average salary</span></li>
			</ul>
			<p>You want to understand the relationship between <em class="italic">x</em> and <em class="italic">y</em> and, if possible, predict the salary (<em class="italic">y</em>) based on years of experience (<em class="italic">x</em>). Real problems very often have far more independent variables and are not necessarily linear. However, this example will give you the baseline knowledge to master more <span class="No-Break">complex algorithms.</span></p>
			<p>To find out what the alpha and beta coefficients are (or slope and <em class="italic">y</em> intercept if you prefer), you need to find some statistics related to the dataset. In <em class="italic">Table 6.3</em>, you have the data and these <span class="No-Break">auxiliary statistics.</span></p>
			<p class="IMG---Figure"><a id="_idTextAnchor764"/></p>
			<table id="table003-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">X (</strong><span class="No-Break"><strong class="bold">INDEPENDENT)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Y (</strong><span class="No-Break"><strong class="bold">DEPENDENT)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">X MEAN</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Y MEAN</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">COVARIANCE  (</strong><span class="No-Break"><strong class="bold">X,Y)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">X VARIANCE</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Y VARIANCE</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">1</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">1.000</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">21.015</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">20</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">21.808.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">2</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">1.500</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">14.595</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">12</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">17.388.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">3</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">3.700</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">4.925</span></p>
						</td>
						<td class="No-Table-Style">
							<p>6</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3.880.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">4</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">5.000</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">1.005</span></p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">448.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">5</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">4.000</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">835</span></p>
						</td>
						<td class="No-Table-Style">
							<p>0</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2.788.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">6</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">6.500</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">415</span></p>
						</td>
						<td class="No-Table-Style">
							<p>0</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">688.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">7</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">7.000</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">1.995</span></p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1.768.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">8</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">9.000</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">8.325</span></p>
						</td>
						<td class="No-Table-Style">
							<p>6</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">11.088.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><em class="italic">9</em></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">9.000</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">11.655</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">12</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">11.088.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">10</em></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><em class="italic">10.000</em></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">19.485</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">20</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">18.748.900</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">COUNT</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">10</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">5,50</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">5.670,00</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">8.425,00</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">8,25</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">8.970.100,00</strong></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.3 – Dataset to predict average salary based on the amount of work experience</p>
			<p>As you can see, there <a id="_idTextAnchor765"/>is an almost perfect linear relationship between <em class="italic">x</em> and <em class="italic">y</em>. As the amount of work experience increases, so does the salary. In addition to <em class="italic">x</em> and <em class="italic">y</em>, you need to compute the following statistics: the number of records, the mean of <em class="italic">x</em>, the mean of <em class="italic">y</em>, the covariance of <em class="italic">x</em> and <em class="italic">y</em>, the variance of <em class="italic">x</em>, and the variance of <em class="italic">y</em>. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.2 </em> depicts formulas that provide a mathematical representation of variance and covariance (respectively), where <em class="italic">x bar</em>, <em class="italic">y bar</em>, and <em class="italic">n</em> represent the mean of <em class="italic">x</em>, the mean of <em class="italic">y</em>, and the number of <span class="No-Break">records, respectively:</span></p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B21197_06_02.jpg" alt="Figure 6.2 – Mathematical representation of variance and covariance respectively" width="1650" height="358"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor766"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor767"/>Figure 6.2 – Mathematical representation of variance and covariance respectively</p>
			<p>If you want to check the calculation details of the formulas for each of those auxiliary statistics in <em class="italic">Table 6.2</em>, please refer to the support material provided along with this book. There, you will find these formulas already implemented <span class="No-Break">for you.</span></p>
			<p>These statistics are important because they will be used to compute the alpha and beta coefficients. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.3</em> explains how you can compute both coefficients, along with the c<a id="_idTextAnchor768"/>orrelation co<a id="_idTextAnchor769"/>efficients R and R squared. These last two metrics will give you an id<a id="_idTextAnchor770"/>ea about the quality of the model, where the closer they are to 1, the better the <span class="No-Break">model is.</span></p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B21197_06_03.jpg" alt="Figure 6.3 – Equations to calculate coefficients for simple linear regression" width="1080" height="845"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Equations to calculate coefficients for simple linear regression</p>
			<p>After applying these formulas, you will come up with the results shown in <em class="italic">Table 6.4</em>. It already contains all the information that you need to make predictions, on top of the new data. If you replace the coefficients in the original equation, <em class="italic">y = ax + b + e</em>, you will find the regression formula to be as follows: <em class="italic">y = 1021.212 * x + </em><span class="No-Break"><em class="italic">53.3</em></span><span class="No-Break">.</span></p>
			<table id="table004-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Coefficient</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Description</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Value</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Alpha</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Line inclination</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,021,212,121</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Beta</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Interceptor</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">53</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>R</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Correlation</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0,979,364,354</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">R^2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Determination</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0,959,154,538</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.4 – Finding regression coefficients</p>
			<p>From this point on, to make predictions, all you have to do is replace <em class="italic">x</em> with the number of years of experience. As a result, you will find <em class="italic">y</em>, which is the projected salary. You can see the model fit in <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.4</em> and some model predictions in <span class="No-Break"><em class="italic">Table 6.5</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B21197_06_04.jpg" alt="Figure 6.4 – Fitting data in the regression equation" width="1400" height="524"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor771"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4 – Fitting data in the regression equation</p>
			<table id="table005-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">INPUT</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">PREDICTION</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">ERROR</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1.075</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">75</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2.096</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">596</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>3</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3.117</span></p>
						</td>
						<td class="No-Table-Style">
							<p>- <span class="No-Break">583</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>4</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">4.138</span></p>
						</td>
						<td class="No-Table-Style">
							<p>- <span class="No-Break">862</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">5.159</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1.159</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>6</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">6.181</span></p>
						</td>
						<td class="No-Table-Style">
							<p>- <span class="No-Break">319</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>7</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">7.202</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">202</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>8</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">8.223</span></p>
						</td>
						<td class="No-Table-Style">
							<p>- <span class="No-Break">777</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>9</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">9.244</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">244</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">10</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">10.265</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">265</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">11</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">11.287</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">12</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">12.308</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">13</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">13.329</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">14</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">14.350</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">15</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">15.372</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">16</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">16.393</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">17</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">17.414</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">18</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">18.435</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">19</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">19.456</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">20</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">20.478</span></p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.5 – Model predictions</p>
			<p>While you are analyzing regression models, you should be able to know whether your model is of good quality or not. You read about many modeling issues (such as overfitting) in <a href="B21197_01.xhtml#_idTextAnchor018"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><em class="italic">, Machine Learning Fundamentals</em>, and you already know that you always have to check <span class="No-Break">model performance.</span></p>
			<p>A good approach to <a id="_idTextAnchor772"/>regression models is performing what is called residual analysis. This is where you plot the errors of the model in a scatter plot and check whether they are randomly distributed (as expected) or not. If the errors are <em class="italic">not</em> randomly distributed, this means that your model was unable to generalize the data. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.5</em> shows a residual analysis based on the data from <span class="No-Break"><em class="italic">Table 6.5</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B21197_06_05.jpg" alt="Figure 6.5 – Residual analysis" width="1209" height="522"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor773"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.5 – Residual analysis</p>
			<p>The takeaway here is that the errors are randomly distributed. Such evidence, along with a high R squared rating, can be used as arguments to support the use of <span class="No-Break">this model.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In <a href="B21197_07.xhtml#_idTextAnchor970"><span class="No-Break"><em class="italic">Chapter 7</em></span></a><em class="italic">, Evaluating and Optimizing Models</em>, you will learn about evaluation metrics. For instance, you will learn that each type of model may have its own set of evaluation metrics. Regression models a<a id="_idTextAnchor774"/>re commonly evaluated with <strong class="bold">Mean Squared Error (MSE)</strong> and <strong class="bold">Root Mean Squared Error (RMSE)</strong>. In other words, apart from R, R squared, and <a id="_idTextAnchor775"/>residual analysis, ideally, you will execute your model on test sets to extract other performance metrics. You can even use a cross-validation system to check model performance, as you learned in <a href="B21197_01.xhtml#_idTextAnchor018"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><em class="italic">, Machine </em><span class="No-Break"><em class="italic">Learning Fundamentals</em></span><span class="No-Break">.</span></p>
			<p>Very often, when the model residuals <em class="italic">do</em> present a pattern and are <em class="italic">not</em> randomly distributed, it is because the existing relationship in the data is not linear, but non-linear, so another modeling technique must be applied. In the next subsection, you will learn how you can interpret <span class="No-Break">regression models.</span></p>
			<h3 id="_idParaDest-138"><a id="_idTextAnchor776"/>Interpreting regression models</h3>
			<p>It is also good to know how <a id="_idTextAnchor777"/>to interpret a linear regression model. Sometimes, you use linear regression not necessarily to create a predictive model but to do a regression analysis. You can then use regression analysis to understand the relationship between the independent and <span class="No-Break">dependent variables.</span></p>
			<p>Looking back at the regression equation (<em class="italic">y = 1021.212 * x + 53.30</em>), you can see the two terms: alpha or slope (<em class="italic">1021.20</em>) and beta or <em class="italic">y</em> intercept (<em class="italic">53.3</em>). You can interpret this model as follows: <em class="italic">for each additional year of working experience, you will increase your salary by $1,021.20</em>. Also, note that when “years of experience” is equal to 0, the expected salary is going to be $53.30 (this is the point where the straight line crosses the <span class="No-Break"><em class="italic">y</em></span><span class="No-Break"> axis).</span></p>
			<p>From a broad perspective, your regression analysis should answer the following question: for each extra unit that is added to the independent variable (slope), what is the average change in the <span class="No-Break">dependent variable?</span></p>
			<h3 id="_idParaDest-139"><a id="_idTextAnchor778"/>Checking adjusted R squared</h3>
			<p>At this point, y<a id="_idTextAnchor779"/>ou have a much better idea of regression models! There is just one other very important topic that you should be aware of, regardless of whether it will come up in the exam or not, which is the parsimony aspect of <span class="No-Break">your model.</span></p>
			<p>You have already heard about parsimony in <a href="B21197_01.xhtml#_idTextAnchor018"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><em class="italic">, Machine Learning Fundamentals</em>. This is the ability to prioritize simple models over complex ones. Looking into regression models, you might have to use more than one feature to predict your outcome. This is also known as a multiple <span class="No-Break">regression model.</span></p>
			<p>When that is the case, the R and R squared coefficients tend to reward more complex models with more features. In other words, if you keep adding new features to a multiple regression model, you will come up with higher R and R squared coefficients. That is why you <em class="italic">cannot</em> anchor your decisions <em class="italic">only</em> based on those <span class="No-Break">two metrics.</span></p>
			<p>Another a<a id="_idTextAnchor780"/>dditional metric that you could use (apart from R, R squared, MSE, and RMSE) is known as <strong class="bold">adjusted R squared</strong>. This metric is penalized when you add extra features to the model that do not bring any real value. In <em class="italic">Table 6.6</em>, you can see when a model is starting to <span class="No-Break">lose parsimony.</span></p>
			<p class="IMG---Figure"><a id="_idTextAnchor781"/></p>
			<table id="table006-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Number </strong><span class="No-Break"><strong class="bold">of features</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">R squared</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Adjusted </strong><span class="No-Break"><strong class="bold">R squared</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">81</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">79</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">83</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">82</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>3</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">88</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">87</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>4</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">90</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">86</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">92</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">85</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.6 – Comparing R squared and adjusted R squared</p>
			<p>Here, you can conclude that maintaining three variables in the model is better than maintaining four or five. Adding four or five variables to the model will increase the R squared (as expected), but decrease the adjusted <span class="No-Break">R squared.</span></p>
			<p>At this point, you should have a very good understanding of regression models. Now, let us check what AWS offers in terms of built-in algorithms for this class <span class="No-Break">of models.</span></p>
			<h3 id="_idParaDest-140"><a id="_idTextAnchor782"/>Regression modeling on AWS</h3>
			<p>AWS has <a id="_idTextAnchor783"/>a built-in<a id="_idTextAnchor784"/> algorithm known as <strong class="bold">linear learner</strong>, where <a id="_idTextAnchor785"/>you can implement linear regression models. The built-in linear learner<a id="_idTextAnchor786"/> uses <strong class="bold">Stochastic Gradient Descent (SGD)</strong> to train <span class="No-Break">the model.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">You will learn more about SGD when neural networks are discussed. For now, you can look at SGD as an alternative to the popular least squares error method that was <span class="No-Break">just discussed.</span></p>
			<p>The linear<a id="_idTextAnchor787"/> learner built-in<a id="_idTextAnchor788"/> algorithm provides a hyperparameter that can apply normalization to the data, prior to the training process. The name of this hyperparameter is <strong class="source-inline">normalize_data</strong>. This is very helpful since linear models are sensitive to the scale of the data and usually take advantage of <span class="No-Break">data normalization.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Data normalization was discussed in <a href="B21197_04.xhtml#_idTextAnchor451"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><em class="italic">, Data Preparation and Transformation</em>. Please review that chapter if you <span class="No-Break">need to.</span></p>
			<p>Some other important hyperparameters of the linear learner algorithm are <strong class="bold">L1</strong> and <strong class="bold">wd</strong>, which <a id="_idTextAnchor789"/>play the<a id="_idTextAnchor790"/> roles of <strong class="bold">L1 regularization</strong> and <strong class="bold">L2 </strong><span class="No-Break"><strong class="bold">regularization</strong></span><span class="No-Break">, respectively.</span></p>
			<p>L1 and L2 regularization help the linear learner (or any other regression algorithm implementation) to avoid overfitting. Conventionally, regression models that implement L1 regularization are called <strong class="bold">lasso regression</strong> models, while <a id="_idTextAnchor791"/>regression models with L2 regularization are <a id="_idTextAnchor792"/>called <strong class="bold">ridge </strong><span class="No-Break"><strong class="bold">regression</strong></span><span class="No-Break"> models.</span></p>
			<p>Although it might sound complex, it is not! The regression model equation is still the same: <em class="italic">y = ax + b + e</em>. The change is in the loss function, which is used to find the coefficients that best minimize the error. If you look back at <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.1</em>, you will see that the error function is defined as <em class="italic">e = (ŷ - y)^2</em>, where <em class="italic">ŷ</em> is the regression function value and <em class="italic">y</em> is the <span class="No-Break">real value.</span></p>
			<p>L1 and L2 regularization add a penalty term to the loss function, as shown in the formulas in <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.6</em> (note that you are replacing <em class="italic">ŷ</em> with <em class="italic">ax + </em><span class="No-Break"><em class="italic">b</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B21197_06_06.jpg" alt="Figure 6.6 – L1 and L2 regularization" width="1650" height="190"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor793"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.6 – L1 and L2 regularization</p>
			<p>The λ (lambda) parameter must be greater than 0 and manually tuned. A very high lambda value may result in an underfitting issue, while a very low lambda may not result in expressive changes in the end results (if your model is overfitted, it will <span class="No-Break">stay overfitted).</span></p>
			<p>In practical t<a id="_idTextAnchor794"/>erms, the main difference between L1 and L2 regularization is that L1 will shrink <a id="_idTextAnchor795"/>the less important coefficients to 0, which will force the feature to be dropped (acting as a feature selector). In other words, if your model is overfitting because of the high number of features, L1 regularization should help you solve <span class="No-Break">this problem.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">During your exam, remember the basis of L1 and L2 regularization, especially the key difference between them, where L1 works well as a <span class="No-Break">feature selector.</span></p>
			<p>Finally, many built-in algorithms can serve multiple modeling purposes. The linear learner algorithm can be used for regression, binary classification, and multi-classification. Make sure you remember this during your exam (it is <em class="italic">not just</em> about <span class="No-Break">regression models).</span></p>
			<p>AWS <a id="_idTextAnchor796"/>has other built-in algorithms that work for regression and classification problems –that is<strong class="bold">, factorization machines, KNN,</strong> and the <strong class="bold">XGBoost</strong> algorithm. Since these algorithms can also be used for <a id="_idTextAnchor797"/>classification purposes, these will be covered in the <a id="_idTextAnchor798"/>section about <span class="No-Break">classification algorithms.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">You’ve just been given a very important tip to remember during the exam: linear learner, factorization machines, KNN, and XGBoost are suitable for both regression and classification problems. These algorithms are often known as algorithms for <span class="No-Break">general purposes.</span></p>
			<p>With that, you have reached the end of this section about regression models. Remember to check out the supporting material before you take the exam. You can also use the reference material when you are working on your daily activities! Now, let us move on to another classical example of a machine learning problem: <span class="No-Break">classification models.</span></p>
			<h2 id="_idParaDest-141">W<a id="_idTextAnchor799"/><a id="_idTextAnchor800"/>orking with classification models</h2>
			<p>You have been learning what <a id="_idTextAnchor801"/>classification models are throughout this book. However, now, you are going to look at some algorithms that are suitable for classification problems. Keep <a id="_idTextAnchor802"/>in mind that there are hundreds of classification algorithms out there, but since you are preparing for the AWS Certified Machine Learning Specialty exam, the ones that have been pre-built by AWS will <span class="No-Break">be covered.</span></p>
			<p>You will start with <strong class="bold">factorization machines</strong>. Factorization machines is considered an extension of the linear learner algorithm, optimized to find the relationship between features within high-dimensional <span class="No-Break">sparse datasets.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">A very traditional use case for <a id="_idTextAnchor803"/>factorization machines is <em class="italic">recommendation systems</em>, where you usually have a high level of sparsity in the data. During the exam, if you are faced with a general-purpose problem (either a regression or binary classification task) where the underlying datasets are sparse, then factorization machines is probably the best answer from an <span class="No-Break">algorithm perspective.</span></p>
			<p>When you use factorization machines in a regression model, the RMSE will be used to evaluate t<a id="_idTextAnchor804"/>he model. On the other hand, in the binary classification mode, the algorithm will use log loss, accuracy, and F1 score to evaluate results. A deeper discussion about evaluation metrics will be provided in <a href="B21197_07.xhtml#_idTextAnchor970"><span class="No-Break"><em class="italic">Chapter 7</em></span></a><em class="italic">, Evaluating and </em><span class="No-Break"><em class="italic">Optimizing Models</em></span><span class="No-Break">.</span></p>
			<p>You should be a<a id="_idTextAnchor805"/>ware that factorization machines only accepts input data in the <strong class="bold">recordIO-protobuf</strong> format. This is b<a id="_idTextAnchor806"/>ecause of the data sparsity characteristic, in which recordIO-protobuf is supposed to do a better job on data processing compared to <span class="No-Break"><strong class="source-inline">text/.csv</strong></span><span class="No-Break"> format.</span></p>
			<p>The next built-in algorithm suitable for classification problems is known as K-nearest neighbors, or KNN for short. As the name suggests, this algorithm will try to find the <em class="italic">K</em> closest points to the input data and return either of the <span class="No-Break">following predictions:</span></p>
			<ul>
				<li>The most repeated class of the <em class="italic">K</em> closest points, if it is a <span class="No-Break">classification task</span></li>
				<li>The average value of the label of the <em class="italic">K</em> closest points, if it is a <span class="No-Break">regression task</span></li>
			</ul>
			<p>KNN is an <strong class="bold">index-based algorithm</strong> because it computes distances between points, assigns indexes <a id="_idTextAnchor807"/>for these points, and then stores the sorted distances and their indexes. With that type of data structure, KNN can easily select the top <em class="italic">K</em> closest points to make the final prediction. Note that <em class="italic">K</em> is a hyperparameter of KNN and should be optimized during the <span class="No-Break">modeling process.</span></p>
			<p>The other AWS built-in algorithm available for general purposes, including classification, is known as <strong class="bold">eXtreme Gradient Boosting</strong>, or <strong class="bold">XGBoost</strong> for short. This is an ensemble, decision <a id="_idTextAnchor808"/><span class="No-Break">tree-based model.</span></p>
			<p>XGBoost uses a set of <strong class="bold">weaker</strong> models (decision trees) to predict the target variable, which can be a regression task, binary class, or multi-class. This is a very popular algorithm and has been used in machine learning competitions by the <span class="No-Break">top performers.</span></p>
			<p>XGBoost uses a boosting learning strategy, in which one model tries to correct the error of the prior model. It carries the name “gradient” because it uses the gradient descent algorithm to minimize the loss when adding <span class="No-Break">new trees.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The term <em class="italic">weaker</em> is used in this context to describe very simple <span class="No-Break">decision trees.</span></p>
			<p>Although XGBoost i<a id="_idTextAnchor809"/>s much more robust than a single decision tree, it is important to go into the exam with a clear understanding of what decision trees are and their main configurations. By the way, they are the base model of many ensemble algorithms, such as AdaBoost, Random Forest, gradient boost, <span class="No-Break">and XGBoost.</span></p>
			<p>Decision trees are rule-based algorithms that organize decisions in the form of a tree, as shown in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B21197_06_07.jpg" alt="Figure 6.7 – Example of what a decision tree model looks like" width="938" height="368"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor810"/>Figure 6.7 – Example of what a decision tree model looks like</p>
			<p>They are formed by a root node (at the very top of the tree), intermediary or decision nodes (in the middle of the tree), and leaf nodes (bottom nodes with no splits). The depth of the tree is given by the difference between the root node and the very last leaf node. For example, in <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.7</em>, the depth of the tree <span class="No-Break">is 3.</span></p>
			<p>The depth of the tree is one of the most important hyperparameters of this type of model and it is often known as<a id="_idTextAnchor811"/> the <strong class="bold">max depth</strong>. In other words, the max depth controls the maximum depth that a decision tree <span class="No-Break">can reach.</span></p>
			<p>Another very important hyperparameter of decision tree models is the minimum number of samples/observations in the leaf nodes. It is also used to control the growth of <span class="No-Break">the tree.</span></p>
			<p>Decision trees have many other ty<a id="_idTextAnchor812"/>pes of hyperparameters, but these two are especially important for controlling how the model overfits. Decision trees with a high depth or a very small number of observations in the leaf nodes are likely to face issues <span class="No-Break">during extrapolation/prediction.</span></p>
			<p>The reason for this is simple: decision trees use data from the leaf nodes to make predictions, based on the proportion (for classification tasks) or average value (for regression tasks) of each observation/target variable that belongs to that node. Thus, the node should have enough data to make good predictions outside the <span class="No-Break">training set.</span></p>
			<p>If you encounter the term <strong class="bold">CART</strong> during the exam, you should know that it stands for <strong class="bold">Classification and Regression Trees</strong>, since de<a id="_idTextAnchor813"/>cision trees can be used for classification and <span class="No-Break">regression tasks.</span></p>
			<p>To select the best variables to split the data in the tree, the model will choose the ones that maximize the separation of the target variables across the nodes. This task can be performed by different me<a id="_idTextAnchor814"/>thods, such as<a id="_idTextAnchor815"/> <strong class="bold">Gini</strong> and <span class="No-Break"><strong class="bold">information gain</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-142">Fo<a id="_idTextAnchor816"/><a id="_idTextAnchor817"/>recasting models</h2>
			<p>Time series refers <a id="_idTextAnchor818"/>to data points that are c<a id="_idTextAnchor819"/>ollected on a <a id="_idTextAnchor820"/>regular basis with a sequence dependency. Time series have a measure, a fact, and a time unit, as shown in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B21197_06_08.jpg" alt="Figure 6.8 – Time series statement" width="1158" height="142"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">F<a id="_idTextAnchor821"/>igure 6.8 – Time series statement</p>
			<p>Additionally, time series can be classified as <strong class="bold">univariate</strong> or <strong class="bold">multivariate</strong>. A univariate time series con<a id="_idTextAnchor822"/>tains just one variable connected across a period of time, while a multivariate time series co<a id="_idTextAnchor823"/>ntains two or more variables connected across a period. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.9</em> shows the univariate <span class="No-Break">time series.</span></p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B21197_06_09.jpg" alt="Figure 6.9 – Time series example" width="1242" height="703"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.9 – Time series example</p>
			<p>Time series can be dec<a id="_idTextAnchor824"/>omposed <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Observed</strong> or <strong class="bold">level</strong>: The ave<a id="_idTextAnchor825"/>rage values of <span class="No-Break">the series</span></li>
				<li><strong class="bold">Trend</strong>: Increasing, decreasing pattern (sometimes, there is <span class="No-Break">no trend)</span></li>
				<li><strong class="bold">Seasonality</strong>: Regular peaks at specific periods of time (sometimes, there is <span class="No-Break">no seasonality)</span></li>
				<li><strong class="bold">Noise</strong>: Something that cannot <span class="No-Break">be explained</span></li>
			</ul>
			<p>Sometimes, you can also find isolated peaks in the series that cannot be captured in a forecasting model. In such cases, you might want to consider those peaks as outliers. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.10</em> is a decomposition of the time series shown in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.9</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B21197_06_10.jpg" alt="Figure 6.10 – Time series decomposition" width="1071" height="590"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.10 – Time series decomposition</p>
			<p>It is also worth high<a id="_idTextAnchor826"/>lighting that you can use <strong class="bold">additive</strong> or <strong class="bold">multiplicative</strong> approaches to decompose time series. Additive models suggest that your time series <em class="italic">adds</em> each component to explain the target variable – that is, <em class="italic">y(t) = level + trend + seasonality + </em><span class="No-Break"><em class="italic">noise</em></span><span class="No-Break">.</span></p>
			<p>Multiplicative models, on the other hand, suggest that your time series <em class="italic">multiplies</em> each component to explain the target variable – that is, <em class="italic">y(t) = level * trend * seasonality * </em><span class="No-Break"><em class="italic">noise</em></span><span class="No-Break">.</span></p>
			<p>In the next section, you will take a closer look at time <span class="No-Break">series components.</span></p>
			<h3 id="_idParaDest-143"><a id="_idTextAnchor827"/>Checking the stationarity of time series</h3>
			<p>Decomposing time series and <a id="_idTextAnchor828"/>understanding how their components inter<a id="_idTextAnchor829"/>act with additive and multiplicative models is a great achievement! However, the more you learn, the more you want to go deeper into the problem. Maybe you have realized that time series without trend and seasonality are easier to predict than the ones with all <span class="No-Break">those components!</span></p>
			<p>That is naturally right. If you do not have to understand trend and seasonality, and if you do not have control over the noise, all you have to do is explore the observed values and find their <span class="No-Break">regression relationship.</span></p>
			<p>A time series with constant mean<a id="_idTextAnchor830"/> and variance across a time period is known as <strong class="bold">stationary</strong>. In general, time series <em class="italic">with</em> trend and seasonality are <em class="italic">not</em> stationary. It is possible to apply data transformations to the series to transform it into a stationary time series so that the modeling task tends to be easier. This type of transformation is known <span class="No-Break">as </span><span class="No-Break"><strong class="bold">di<a id="_idTextAnchor831"/>fferentiation</strong></span><span class="No-Break">.</span></p>
			<p>While you are exploring a time series, you can check stationarity by applying hypothesis tests, such as <strong class="bold">Di<a id="_idTextAnchor832"/>ckey-Fuller</strong>, <strong class="bold">KPSS</strong>, and <strong class="bold">Phillips-Perron</strong>, just to mention a few. If you find it non-stationary, then you <a id="_idTextAnchor833"/>can apply differentiation to make it a stationary time <a id="_idTextAnchor834"/>series. Some algorithms already have that <span class="No-Break">capability embedded.</span></p>
			<h3 id="_idParaDest-144"><a id="_idTextAnchor835"/>Exploring, exploring, and exploring</h3>
			<p>At this point, it is important to remember that exploration tasks happen all the time in data science. Nothing is different here. While you are building time series models, you might want to take a look at the data and check whether it is suitable for this type <span class="No-Break">of modeling.</span></p>
			<p><strong class="bold">Autocorrelation plots</strong> are one o<a id="_idTextAnchor836"/>f the tools that you can use for time series analysis. Autocorrelation plots allow you to check the correlations between lags in the time series. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.11</em> shows an example of this type <span class="No-Break">of visualization.</span></p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B21197_06_11.jpg" alt="Figure 6.11 – Autocorrelation plot" width="1077" height="582"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figu<a id="_idTextAnchor837"/>re 6.11 – Autocorrelation plot</p>
			<p>Remember, if you are playing with univariate time series, your time series just contains one variable. Therefore, finding autocorrelation across the lags of your unique variable is crucial to understanding whether you can build a good model <span class="No-Break">or not.</span></p>
			<p>And yes, it turns out that, sometimes, it might happen that you do not have a time series in front of you. Furthermore, no matter your efforts, you will not be able to model this data as a time series. This type of data is often known as <span class="No-Break"><strong class="bold">whi<a id="_idTextAnchor838"/>te</strong></span><span class="No-Break"> </span><span class="No-Break"><strong class="bold">noise</strong></span><span class="No-Break">.</span></p>
			<p>Another type of series that you cannot predict is known<a id="_idTextAnchor839"/> as a <strong class="bold">random</strong> <strong class="bold">walk</strong>. Random walks are random by nature, but they have a dependency on the previous time step. For example, the next point of a random walk could be a random number between 0 and 1, and also the last point of <span class="No-Break">the series.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Be careful if you come across those terms in the exam and remember to relate them to randomness in <span class="No-Break">time series.</span></p>
			<p>With that, you have covered the main theory behind time series modeling. You should also be aware that the most popular algorithms out there for working with time series are known as <strong class="bold">Au<a id="_idTextAnchor840"/>to-Regressive Integrated Moving Average (ARIMA)</strong> and <strong class="bold">Exponential Smoothing (ETS)</strong>. This book will not go into the details of these two models. Instead, you will see what AWS can offer in terms of time <span class="No-Break">series modeling.</span></p>
			<h3 id="_idParaDest-145"><a id="_idTextAnchor841"/>Understanding DeepAR</h3>
			<p>The <strong class="bold">DeepAR</strong> forecasting algor<a id="_idTextAnchor842"/>ithm is a built-in SageMaker algorithm that is used to forecast a one-dimensional time <a id="_idTextAnchor843"/>series using a <strong class="bold">Recurrent Neural </strong><span class="No-Break"><strong class="bold">Network (RNN)</strong></span><span class="No-Break">.</span></p>
			<p>Traditional time series algorithms, such as ARIMA and ETS, are designed to fit one model per time series. For example, if you want to forecast sales per region, you might have to create one model per region, since each region may have its own sales behaviors. DeepAR, on the other hand, allows you to operate more than one time series in a single model, which seems to be a huge advantage for more complex <span class="No-Break">use cases.</span></p>
			<p>The input data for DeepAR<a id="_idTextAnchor844"/>, as expected, is <em class="italic">one or more</em> time series. Each of these time series can be associated with <span class="No-Break">the following:</span></p>
			<ul>
				<li>A vector of static (time-independent) categorical features, controlled by the <span class="No-Break"><strong class="source-inline">cat</strong></span><span class="No-Break"> field</span></li>
				<li>A vector of dynamic (time-dependent) time series, controlled <span class="No-Break">by </span><span class="No-Break"><strong class="source-inline">dynamic_feat</strong></span></li>
			</ul>
			<p class="callout-heading">Important note</p>
			<p class="callout">Note that the ability to train and make predictions on top of multiple time series is strictly related to the vector of static categorical features. While defining the time series that DeepAR will train on, you can set categorical variables to specify which group each time series <span class="No-Break">belongs to.</span></p>
			<p>Two of the main hyperparameters of DeepAR are <strong class="source-inline">context_length</strong>, which is used to control how far in the past the model can see during the training process, and <strong class="source-inline">prediction_length</strong>, which is used to control how far in the future the model will <span class="No-Break">output predictions.</span></p>
			<p>DeepAR can also handle missing values, which, in this case, refers to existing gaps in the time series. A very interesting functionality of DeepAR is its ability to create derived features from time series. These derived features, which are created from basic time frequencies, help the algorithm learn time-dependent patterns. <em class="italic">Table 6.7</em> shows all the derived features created by DeepAR, according to each type of time series that it is <span class="No-Break">trained on.</span></p>
			<table id="table007-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Frequency of the </strong><span class="No-Break"><strong class="bold">time series</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Derived feature</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Minute</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Minute of hour, hour of day, day of week, day of month, day <span class="No-Break">of year</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Hour</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Hour of day, day of week, day of month, day <span class="No-Break">of year</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Day</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Day of week, day of month, day <span class="No-Break">of year</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Week</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Day of month, week <span class="No-Break">of year</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Month</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Month <span class="No-Break">of year</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.7 – DeepAR derived features per frequency of time series</p>
			<p>You have now completed this section about forecasting models. Next, you will take a look at the last algorithm regarding supervised learning – that is, the <span class="No-Break"><strong class="bold">Object2Vec</strong></span><span class="No-Break"> algorithm.</span></p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor845"/><a id="_idTextAnchor846"/>Object2Vec</h2>
			<p>Object2Vec<a id="_idTextAnchor847"/> is a built-in <a id="_idTextAnchor848"/>SageMaker algorithm that generalizes the well-known <strong class="bold">Word2Vec</strong> algorithm. Object2Vec is used to create <strong class="bold">embedding spaces</strong> for high dimensional objects. These embedding spaces are, per definition, compressed representations of the original object and can be used for multiple purposes, such as feature engineering or <span class="No-Break">object comparison.</span></p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B21197_06_12.jpg" alt="Figure 6.12 – A visual example of an embedding space" width="929" height="280"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor849"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.12 – A visual example of an embedding space</p>
			<p><span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.12</em> illustrates what is meant by an embedding space. The first and last layers of the neural network model just map the input data with itself (represented by the same <span class="No-Break">vector size).</span></p>
			<p>As you move on to the internal layers of the model, the data is compressed more and more until it hits the layer in the middle of this architecture, known as the embedding layer. On that particular layer, you have a smaller vector, which aims to be an accurate and compressed representation of the high-dimensional original vector from the <span class="No-Break">first layer.</span></p>
			<p>With this, you just completed the first section about machine learning algorithms in AWS. Coming up next, you will take a look at some <span class="No-Break">unsupervised algorithms.</span></p>
			<h1 id="_idParaDest-147">U<a id="_idTextAnchor850"/><a id="_idTextAnchor851"/>nsupervised learning</h1>
			<p>AWS provides several unsupervised learning <a id="_idTextAnchor852"/>algorithms for the <span class="No-Break">following tasks:</span></p>
			<ul>
				<li>Clustering: <span class="No-Break">K-Means algorithm</span></li>
				<li>Dimension reduction: <strong class="bold">Principal Component </strong><span class="No-Break"><strong class="bold">Analysis (PCA)</strong></span></li>
				<li>Pattern recognition: <span class="No-Break">IP Insights</span></li>
				<li>Anomaly detection: The <strong class="bold">Random Cut Forest (</strong><span class="No-Break"><strong class="bold">RCF)</strong></span><span class="No-Break"> algorithm</span></li>
			</ul>
			<p>Let us start by talking about clustering and how the most popular clustering algorithm <span class="No-Break">works: K-Means.</span></p>
			<h2 id="_idParaDest-148">C<a id="_idTextAnchor853"/><a id="_idTextAnchor854"/>lustering</h2>
			<p>Clustering a<a id="_idTextAnchor855"/>lgorithms are <a id="_idTextAnchor856"/>very popular in data science. Basically, they aim to identify similar groups in a given dataset, also known as <em class="italic">clusters</em>. Clustering algorithms belong to the field of non-supervised learning, which means that they do not need a label or response variable to <span class="No-Break">be trained.</span></p>
			<p>This is just fantastic since labeled data is very scarce! However, it comes with some limitations. The main one is that clustering algorithms provide clusters for you, but not the meaning of each cluster. Thus, someone, as a subject matter expert, has to analyze the properties of each cluster to define <span class="No-Break">their meanings.</span></p>
			<p>There are many t<a id="_idTextAnchor857"/>ypes of clustering approaches, such as hierarchical clustering and partitional clustering. Inside <a id="_idTextAnchor858"/>each approach, you will find several algorithms. However, K-Means is probably the most popular clustering algorithm, and you are likely to <a id="_idTextAnchor859"/>come across it in <span class="No-Break">your exam.</span></p>
			<p>When you are playing with K-Means, somehow, you have to specify the number of clusters that you want to create. Then, you have to allocate the data points across each cluster, so that each data point will belong to a single cluster. This is exactly what you should expect as a result at the end of the <span class="No-Break">clustering process!</span></p>
			<p>You need to specify the number of clusters that you want to create and pass this number to the K-Means algorithm. Then, the algorithm will randomly initiate the central point of each cluster (this is known a<a id="_idTextAnchor860"/>s <span class="No-Break"><strong class="bold">centroid initialization</strong></span><span class="No-Break">).</span></p>
			<p>Once you have the centroids of each cluster, all you need to do is assign a cluster to each data point. To do that, you have to use a proximity or distance metric! This book will use the term <span class="No-Break"><em class="italic">distance metric</em></span><span class="No-Break">.</span></p>
			<p>The <strong class="bold">distance metric</strong> is <a id="_idTextAnchor861"/>responsible for calculating the distance between data points and centroids. The data point will belong to the closer cluster centroid, according to the <span class="No-Break">distance metric.</span></p>
			<p>The most popular distance metric is <a id="_idTextAnchor862"/>called <strong class="bold">Euclidean distance</strong> and the math behind it is simple; imagine that the points of your dataset are composed of two dimensions, <em class="italic">x</em> and <em class="italic">y</em>. So, you could consider points <em class="italic">a</em> and <em class="italic">b</em> <span class="No-Break">as follows:</span></p>
			<ul>
				<li><em class="italic">a (</em><span class="No-Break"><em class="italic">x=1, y=1)</em></span></li>
				<li><em class="italic">b (</em><span class="No-Break"><em class="italic">x=2, y=5)</em></span></li>
			</ul>
			<p>The Euclidean distance between points <em class="italic">a</em> and <em class="italic">b</em> is given by the following formula, where <em class="italic">x</em><span class="subscript">1</span> and <em class="italic">y</em><span class="subscript">1</span> refer to the values of point <em class="italic">a</em>, and <em class="italic">x</em><span class="subscript">2</span> and <em class="italic">y</em><span class="subscript">2</span> refer to the values of point <em class="italic">b</em>: <img src="image/B21197_06_12a.png" alt="" role="presentation" width="229" height="72"/>. The same function can be generalized by the following equation: <img src="image/B21197_06_12b.png" alt="" role="presentation" width="124" height="66"/>. Once you have completed this process and assigned a cluster for each data point, you <img src="image/B21197_06_12c.png" alt="" role="presentation" width="106" height="30"/> m<a id="_idTextAnchor863"/>e<a id="_idTextAnchor864"/>thods, such as <strong class="bold">single link, average link</strong>, and <span class="No-Break"><strong class="bold">complete link</strong></span><span class="No-Break">.</span></p>
			<p>Due to this centroid refreshment, you will have to keep checking the closest cluster for each data point and keep refreshing the centroids, iteratively, until the cluster centroids converge and no cluster reassignment is needed, or the maximum number of allowed iterations <span class="No-Break">is reached.</span></p>
			<p>Alright, the following is a summarization of the components and steps that compose the <span class="No-Break">K-Means method:</span></p>
			<ul>
				<li>Centroid initialization, cluster assignment, centroid refreshment, and then redo the last two steps until <span class="No-Break">it converges</span></li>
				<li>A distance metric to assign data points to each cluster (in this case, <span class="No-Break">Euclidian distance)</span></li>
				<li>A linkage method to recalculate the cluster centroids (for the sake of our demonstration, you will learn about the <span class="No-Break">average linkage)</span></li>
			</ul>
			<p>With these definitions, you are now ready to walk through the following real example, step by step (some support material is also available for <span class="No-Break">your reference).</span></p>
			<h3 id="_idParaDest-149"><a id="_idTextAnchor865"/>Computing K-Means step by step</h3>
			<p>In this example, you will simulate K-<a id="_idTextAnchor866"/>Means in a very small dataset, with only two columns (<em class="italic">x</em> and <em class="italic">y</em>) and six data points (<em class="italic">A</em>, <em class="italic">B</em>, <em class="italic">C</em>, <em class="italic">D</em>, <em class="italic">E</em>, and <em class="italic">F</em>), as defined in <span class="No-Break"><em class="italic">Table 6.8</em></span><span class="No-Break">.</span></p>
			<table id="table008-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Point</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">x</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">y</strong></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>A</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>B</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>C</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>D</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>6</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>E</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>F</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>6</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Cluster 1</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">1</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">1</strong></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Cluster 2</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">2</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">2</strong></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Cluster 3</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">5</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">5</strong></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.8 – Iteration input data for K-Means</p>
			<p><em class="italic">Table 6.8</em> contains three clusters with the following centroids: <em class="italic">(1,1), (2,2), (5,5).</em> The number of clusters (3) was defined <em class="italic">a priori</em> and the centroid for each cluster was randomly defined. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.13</em> shows the stage of the algorithm that you are at <span class="No-Break">right now.</span></p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B21197_06_13.jpg" alt="Figure 6.13 – Plotting the K-Means results before completing the first iteration" width="1017" height="587"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor867"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.13 – Plotting the K-Means results before completing the first iteration</p>
			<p>Here, you can’t <a id="_idTextAnchor868"/>see points <em class="italic">A</em>, <em class="italic">B</em>, and <em class="italic">C</em> since they overlap with cluster centroids, but don’t worry – they will appear soon. Next, you have to compute the distance of each data point to each cluster centroid, and then, you need to choose the cluster that is the closest to <span class="No-Break">each point.</span></p>
			<table id="table009-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">xc1</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">yc1</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">xc2</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">yc2</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">xc3</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">yc3</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">distance-c1</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">distance-c2</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">distance-c3</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Cluster</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,4</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">5,7</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Cluster 1</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,4</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">4,2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Cluster 2</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">5,7</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">4,2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Cluster 3</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">6,4</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">5,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Cluster 3</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">4,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3,2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">4,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Cluster 2</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">5,1</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">4,0</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3,2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Cluster 3</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style" colspan="10">
							<p><span class="No-Break">Legend</span></p>
							<p>xc1 = x value of <span class="No-Break">cluster 1</span></p>
							<p>yc1 = y value of <span class="No-Break">cluster 1</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.9 – Processing iteration 1</p>
			<p><em class="italic">Table 6.9</em> contains the <span class="No-Break">following elements:</span></p>
			<ul>
				<li>Each row represents a <span class="No-Break">data point.</span></li>
				<li>The first six columns represent the centroid axis (<em class="italic">x</em> and <em class="italic">y</em>) of <span class="No-Break">each cluster.</span></li>
				<li>The next three columns represent the distance of each data point to each <span class="No-Break">cluster centroid.</span></li>
				<li>The last column represents the clusters that are the closest to each <span class="No-Break">data point.</span></li>
			</ul>
			<p>Looking at data point <em class="italic">A</em> (first row), you can see that it was assigned to cluster 1 because the distance from data point <em class="italic">A</em> to cluster 1 is 0 (do you remember that they were overlapping?). The same calculation happens to all other data points to define a cluster for each <span class="No-Break">data point.</span></p>
			<p>Before you move <a id="_idTextAnchor869"/>on, you might want to see how those Euclidian distances between the clusters and the data points were computed. For demonstration purposes, the following simulation will consider the distance from data point <em class="italic">A</em> to cluster 3 (the first row in <em class="italic">Table 6.9</em>, column <strong class="source-inline">distance-c3</strong>, <span class="No-Break">value </span><span class="No-Break"><em class="italic">5,7</em></span><span class="No-Break">).</span></p>
			<p>First of all, the following formula was used to calculate the Euclidian <span class="No-Break">distance: <img src="image/B21197_06_13a.png" alt="" role="presentation" width="350" height="110"/></span><a id="_idTextAnchor870"/></p>
			<p>Here, you have <span class="No-Break">the following:</span></p>
			<ul>
				<li><em class="italic">x</em><span class="subscript">1</span> = <em class="italic">x</em> of data point <em class="italic">A</em> = 1</li>
				<li><em class="italic">y</em><span class="subscript">1</span> = <em class="italic">y</em> of data point <em class="italic">A</em> = 1</li>
				<li><em class="italic">x</em><span class="subscript">2</span> = <em class="italic">x</em> of cluster 3 = 5</li>
				<li><em class="italic">y</em><span class="subscript">2</span> = <em class="italic">y</em> of cluster 3 = 5</li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.14</em> applies the formula, step <span class="No-Break">by step.</span></p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B21197_06_14.jpg" alt="Figure 6.14 – Computing the Euclidian distance step by step" width="1164" height="417"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.14 – Computing the Euclidian distance step by step</p>
			<p>That is just fantastic, isn’t it? You have almost completed the first iteration of K-Means. In the very last step of iteration 1, you have to refresh the cluster centroids. Remember: initially, they were randomly defined, but now, you have just assigned some data points to each cluster, which means you should be able to identify where the central point of the <span class="No-Break">cluster is.</span></p>
			<p>In this example, the <strong class="bold">linkage</strong> method will be used to re<a id="_idTextAnchor871"/>fresh the cluster centroids. This is a very simple step, and the results are presented in <span class="No-Break"><em class="italic">Table 6.10</em></span><span class="No-Break">.</span></p>
			<table id="table010-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Point</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">x</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">y</strong></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>A</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>B</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>C</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>D</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>6</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>E</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>F</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>6</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Cluster 1</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">1</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">1</strong></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Cluster 2</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1,5</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">3,5</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Cluster 3</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">4</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">5,7</strong></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.10 – K-Means results after iteration 1</p>
			<p><em class="italic">Table 6.10</em> shows the same data points (<em class="italic">A</em> to <em class="italic">F</em>) that you are dealing with (by the way, they will never change), and the centroids of clusters 1, 2, and 3. Those centroids are quite different from what they were initially, as shown in <em class="italic">Table 6.8</em>. This is because they were refreshed using average linkage! The method got the average value of all the <em class="italic">x</em> and <em class="italic">y</em> values of the data points of each cluster. In the next simulation, have a look at how <em class="italic">(1.5, 3.5)</em> were obtained as centroids of <span class="No-Break">cluster 2.</span></p>
			<p>If you look at <em class="italic">Table 6.9</em>, you will see that cluster 2 only has two data points assigned to it: <em class="italic">B</em> and <em class="italic">E</em>. These are the second and fifth rows in that figure. If you take the average values of the <em class="italic">x</em> axis of each point, then you will have <em class="italic">(2 + 1) / 2 = 1.5</em> and <em class="italic">(2 + 5) / 2 = </em><span class="No-Break"><em class="italic">3.5</em></span><span class="No-Break">.</span></p>
			<p>With that, you are done with iteration 1 of K-Means and you can view the results in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.15</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B21197_06_15.jpg" alt="Figure 6.15 – Plotting the K-Means results after the first iteration" width="865" height="499"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor872"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.15 – Plotting the K-Means results after the first iteration</p>
			<p>Now, you can see <a id="_idTextAnchor873"/>almost all the data points, except for data point A because it is still overlapping with the centroid of cluster 1. Moving on, you have to redo the <span class="No-Break">following steps:</span></p>
			<ul>
				<li>Recalculate the distance between each data point and each cluster centroid and reassign clusters, <span class="No-Break">if needed.</span></li>
				<li>Recalculate the <span class="No-Break">cluster centroids.</span></li>
			</ul>
			<p>You do those two tasks many times until the cluster centroids converge and they don’t change anymore, <em class="italic">or</em> you reach the maximum number of allowed iterations, which can be set as a hyperparameter of K-Means. For demonstration purposes, after four iterations, your clusters will look like <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.16</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B21197_06_16.jpg" alt="Figure 6.16 – Plotting the K-Means results after the fourth iteration" width="892" height="526"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor874"/>Figure 6.16 – Plotting the K-Means results after the fourth iteration</p>
			<p>On the fourth iteration, all the cluster centroids look pretty consistent, and you can clearly see that all data points could be grouped according to <span class="No-Break">their proximity.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In this example, you have only set two dimensions for each data point (dimensions <em class="italic">x</em> and <em class="italic">y</em>). In real use cases, you can see far more dimensions, and that is why clustering algorithms play a very important role in identifying groups in the data in a more <span class="No-Break">automated fashion.</span></p>
			<p>Hopefully, you have en<a id="_idTextAnchor875"/>joyed how to compute K-Means from scratch! This knowledge will be beneficial for the exam and for your career as a data scientist. By the way, as advised many times, data scientists must be skeptical and curious, so you might be wondering why three clusters were defined in this example and not two or four. You may also be wondering how you measure the quality of <span class="No-Break">the clusters.</span></p>
			<p>You didn’t think this explanation wouldn’t be provided, <span class="No-Break">did you?</span></p>
			<h3 id="_idParaDest-150"><a id="_idTextAnchor876"/>Defining the number of clusters and measuring cluster quality</h3>
			<p>Although K-Means is a great algorithm for finding patterns in your data, it will not provide the meaning of each cluster, nor the number of clusters you have to create to maximize <span class="No-Break">cluster quality.</span></p>
			<p>In clustering, cluster quality m<a id="_idTextAnchor877"/>eans that you want to create groups with a high homogeneity among the elements of the same cluster, and a high heterogeneity among the elements of different clusters. In other words, the elements of the same clusters should be close/similar, whereas the elements of different clusters should be <span class="No-Break">well separated.</span></p>
			<p>One way to compute the cluster’s homogeneity is<a id="_idTextAnchor878"/> by using a metric known as the <strong class="bold">sum of square errors</strong>, or <strong class="bold">SSE</strong> for short. This metric will compute the sum of squared differences between each data point and its cluster centroid. For example, when all the data points are located at the same point where the cluster centroid is, then the SSE will be 0. In other words, you want to minimize the SSE. The following equation formally defines the <span class="No-Break">SSE: <img src="image/B21197_06_16a.png" alt="" role="presentation" width="212" height="84"/></span><a id="_idTextAnchor879"/></p>
			<p>Now that you know how to check the cluster quality, it is easier to understand how to define the number of appropriate clusters for a given dataset. All you have to do is find the optimal number of clusters to minimize the SSE. A very popular method that works aro<a id="_idTextAnchor880"/>und that logic is known as the <span class="No-Break"><strong class="bold">elbow method</strong></span><span class="No-Break">.</span></p>
			<p>The elbow method proposes executing the clustering algorithm many times. In each execution, you will test a different number of clusters, <em class="italic">k</em>. After each execution, you compute the SSE related to that <em class="italic">k</em> number of clusters. Finally, you can plot these results and select the number of <em class="italic">k</em> where the SSE stops to <span class="No-Break">drastically decrease.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Adding more clusters will naturally decrease the SSE. In the elbow method, you want to find the point where that change becomes smoother, which means that the addition of new clusters will not bring too <span class="No-Break">much value.</span></p>
			<p>In the previous example, three clusters were created. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.17</em> shows the elbow analysis that supports <span class="No-Break">this decision.</span></p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B21197_06_17.jpg" alt="Figure 6.17 – The elbow method" width="1012" height="590"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Fi<a id="_idTextAnchor881"/>gure 6.17 – The elbow method</p>
			<p>You can conclude that adding more than three or four clusters will add unnecessary complexity to the <span class="No-Break">clustering process.</span></p>
			<p>Of course, you sho<a id="_idTextAnchor882"/>uld always consider the business background while defining the number of clusters. For example, if you are creating a customer segmentation model and your company has prepared the commercial team and business processes to support four segments of customers, there is no harm in setting up four clusters instead <span class="No-Break">of three.</span></p>
			<p>Finally, you should know that AWS has implemented K-Means as part of its list of built-in algorithms. In other words, you don’t have to use external libraries or bring your own algorithm to play with K-Means <span class="No-Break">on AWS.</span></p>
			<h3 id="_idParaDest-151"><a id="_idTextAnchor883"/>Conclusion</h3>
			<p>That was a really good accomplishment: you just mastered the basics of clustering algorithms and you should now be able to drive your own projects and research about this topic! For the exam, remember that clustering belongs to the unsupervised field of machine learning, so there is no need to have <span class="No-Break">labeled data.</span></p>
			<p>Also, make sure that you know how the most popular algorithm of this field works – that is, K-Means. Although clustering algorithms do not provide the meaning of each group, they are very powerful for finding patterns in the data, either to model a particular problem or just to explore <span class="No-Break">the data.</span></p>
			<p>Coming up next, you will keep studying unsupervised algorithms and see how AWS has built one of the most powerful algorithms out there for anomaly detection, k<a id="_idTextAnchor884"/>nown <span class="No-Break">as </span><span class="No-Break"><strong class="bold">RCF</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-152">Anom<a id="_idTextAnchor885"/><a id="_idTextAnchor886"/>aly detection</h2>
			<p>Finding anom<a id="_idTextAnchor887"/>alies in data is a very com<a id="_idTextAnchor888"/>mon task in modeling and data exploratory analysis. Sometimes, you might want to find anomalies in the data just to remove them before fitting a regression model, while other times, you might want to create a model that identifies anomalies as an end goal – for example, in fraud <span class="No-Break">detection systems.</span></p>
			<p>Again, you can use many different methods to find anomalies in the data. With some creativity, the possibilities are endless. However, there is a particular algorithm that works around this problem that you should definitely be aware of for your <span class="No-Break">exam: RCF.</span></p>
			<p>RCF is an unsu<a id="_idTextAnchor889"/>pervised decision tree-based algorithm that creates multiple decision trees (forests) using random subsamples of the training data. Technically, it randomizes the data and then creates samples according to the number of trees. Finally, these samples are distributed across <span class="No-Break">each tree.</span></p>
			<p>These sets of trees are used to assign an anomaly score to the data points. To calculate the anomaly score for a particular data point, it is passed down each tree in the forest. As the data point moves through the tree, the path length from the root node to the leaf node is recorded for that specific tree. The anomaly score for that data point is then determined by considering the distribution of path lengths across all the trees in <span class="No-Break">the forest.</span></p>
			<p>If a data point follows a short path in most trees (i.e., it is close to the root node), it is considered a common point and will have a lower <span class="No-Break">anomaly score.</span></p>
			<p>On the other hand, if a data point follows a long path in many trees (i.e., it is far from the root node), it is considered an uncommon point and will have a higher <span class="No-Break">anomaly score.</span></p>
			<p>The most important hyperparameters of RCF are <strong class="source-inline">num_trees</strong> and <strong class="source-inline">num_samples_per_tree</strong>, which are the number of trees in the forest and the number of samples per <span class="No-Break">tree, respectively.</span></p>
			<h2 id="_idParaDest-153">Dime<a id="_idTextAnchor890"/><a id="_idTextAnchor891"/>nsionality reduction</h2>
			<p>Another unsu<a id="_idTextAnchor892"/>pervised algo<a id="_idTextAnchor893"/>rithm that was implemented by AWS in its list of built-in algorithms is known as p<a id="_idTextAnchor894"/>rincipal component analysis, or PCA for short. PCA is a technique that’s used to reduce the number of variables/dimensions in <span class="No-Break">a dataset.</span></p>
			<p>The main idea behind PCA <a id="_idTextAnchor895"/>is plotting the data points to another set of coordinates, known as <strong class="bold">Principal Components (PCs)</strong>, which aims to explain the most variance in the data. By definition, the first component will capture more variance than the second component, then the second component will capture more variance than the third one, and <span class="No-Break">so on.</span></p>
			<p>You can set up as many PCs <a id="_idTextAnchor896"/>as you need, as long as it does<a id="_idTextAnchor897"/> not surpass the number of variables in your dataset. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.18</em> shows how these PCs <span class="No-Break">are drawn:</span></p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B21197_06_18.jpg" alt="Figure 6.18 – Finding PCs in PCA" width="1282" height="651"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.18 – Finding PCs in PCA</p>
			<p>As mentioned previously, the first PC will be drawn in such a way that it will capture most of the variance in the data. That is why it passes near the majority of the data points in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.18</em></span><span class="No-Break">.</span></p>
			<p>Then, the second PC will be perpendicular to the first one, so that it will be the second component that explains the variance in the data. If you want to create more components (consequentially, capturing more variance), you just have to follow the same rule of adding perpendicular comp<a id="_idTextAnchor898"/>onents. <strong class="bold">Eigenvectors</strong> and <strong class="bold">eigenvalues</strong> are the linea<a id="_idTextAnchor899"/>r algebra concepts associated with PCA that compute <span class="No-Break">the PCs.</span></p>
			<p>So, what is the story with dimension reduction here? In case it is not clear yet, these PCs can be used to replace your original variables. For example, consider you have 10 variables in your dataset, and you want to reduce this dataset to three variables that best represent the others. A potential solution for that would<a id="_idTextAnchor900"/> be applying PCA and extracting the first <span class="No-Break">three PCs!</span></p>
			<p>Do these three<a id="_idTextAnchor901"/> components explain 100% of your dataset? Probably not, but ideally, they will explain most of the variance. Adding more PCs will explain more variance but at the cost of adding <span class="No-Break">extra dimensions.</span></p>
			<h3 id="_idParaDest-154"><a id="_idTextAnchor902"/>Using AWS’s built-in algorithm for PCA</h3>
			<p>In AWS, PCA works in two <span class="No-Break">different modes:</span></p>
			<ul>
				<li><strong class="bold">Regular</strong>: For datasets with<a id="_idTextAnchor903"/> a moderate number of observations <span class="No-Break">and features</span></li>
				<li><strong class="bold">Randomized</strong>: For datasets with a large number of observations <span class="No-Break">and features</span></li>
			</ul>
			<p>The difference is that, in randomized mode, it is used as an <span class="No-Break">approximation algorithm.</span></p>
			<p>Of course, the main hyperparameter of PCA is the number of components that you want to extract, known <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">num_components</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-155">IP In<a id="_idTextAnchor904"/><a id="_idTextAnchor905"/>sights</h2>
			<p>IP Insights is an unsup<a id="_idTextAnchor906"/>ervised algorithm that is used for pattern recognition. Essentially, it learns the usage<a id="_idTextAnchor907"/> pattern of <span class="No-Break">IPv4 addresses.</span></p>
			<p>The <em class="italic">modus operandi</em> of this algorithm is very intuitive: it is trained on top of pairs of events in the format of entity and IPv4 address so that it can understand the pattern of each entity that it was <span class="No-Break">trained on.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">For instance, you can understand “entity” as user IDs or <span class="No-Break">account numbers.</span></p>
			<p>Then, to make predictions, it receives a pair of events with the same data structure (entity, IPv4 address) and returns an anomaly score for that particular IP address, according to the <span class="No-Break">input entity.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">This anomaly score that is returned by IP Insights infers how anomalous the pattern of the <span class="No-Break">event is.</span></p>
			<p>You might come <a id="_idTextAnchor908"/>across many applications with IP Insights. For example, you can create an IP Insights model that was trained on top of your application login events (this is your entity). You should be able to expose this model through an API endpoint to make predictions in <span class="No-Break">real time.</span></p>
			<p>Then, during the authe<a id="_idTextAnchor909"/>ntication process of your application, you could call your endpoint and pass the IP address that is trying to log in. If you got a high score (meaning this pattern of logging in looks anomalous), you can request extra information before authorizing access (even if the password <span class="No-Break">was right).</span></p>
			<p>This is just one of the many applications of IP Insights you could think about. Next, you will learn about <span class="No-Break">textual analysis.</span></p>
			<h1 id="_idParaDest-156">Textu<a id="_idTextAnchor910"/><a id="_idTextAnchor911"/>al analysis</h1>
			<p>Modern appli<a id="_idTextAnchor912"/>cations use <a id="_idTextAnchor913"/><strong class="bold">Natural Language Processing (NLP)</strong> for seve<a id="_idTextAnchor914"/>ral purpo<a id="_idTextAnchor915"/>ses, such as text translation, document classifications, web search, <strong class="bold">Named Entity Recognition (NER)</strong>, and <span class="No-Break">many<a id="_idTextAnchor916"/> other<a id="_idTextAnchor917"/>s.</span></p>
			<p>AWS offers a suite of algorithms for most NLP use cases. In the next few subsections, you will have a look at these built-in algorithms for <span class="No-Break">textual analysis.</span></p>
			<h2 id="_idParaDest-157">Blazi<a id="_idTextAnchor918"/><a id="_idTextAnchor919"/>ngText algorithm</h2>
			<p>BlazingText <a id="_idTextAnchor920"/>does two d<a id="_idTextAnchor921"/>ifferent types of tasks: text classification, which is a supervised learning approach that exten<a id="_idTextAnchor922"/>ds the <strong class="bold">fastText</strong> text classifier, and Word2Vec, which is an unsu<a id="_idTextAnchor923"/>pervised <span class="No-Break">learning algorithm.</span></p>
			<p>BlazingText’s implementations of these two algorithms are optimized to run on large datasets. For example, you can train a model on top of billions of words in a <span class="No-Break">few minutes.</span></p>
			<p>This scalability aspect of BlazingText is possible due to <span class="No-Break">the following:</span></p>
			<ul>
				<li>Its ability to use multi-core CPUs and a single GPU to accelerate <span class="No-Break">text classification</span></li>
				<li>Its ability to use multi-core CPUs or GPUs, with custom CUDA kernels for GPU acceleration, when playing with the <span class="No-Break">Word2Vec algorithm</span></li>
			</ul>
			<p>The Word2Vec option suppo<a id="_idTextAnchor924"/>rts <strong class="bold">batch_skipgram</strong> mode, which allows BlazingText to do distributed training across <span class="No-Break">multiple CPUs.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The distributed training that’s performed by BlazingText uses a mini-batching approach to conve<a id="_idTextAnchor925"/>rt <strong class="bold">level-1 BLAS (Basic Linear Algebra Subprograms)</strong> operations into <strong class="bold">level-3 BLAS</strong> operations. If you see thes<a id="_idTextAnchor926"/>e terms during your exam, you should know that they are related to BlazingText (<span class="No-Break">Word2Vec mode).</span></p>
			<p>Still in Word2Vec mode<a id="_idTextAnchor927"/>, BlazingText supports both<a id="_idTextAnchor928"/> the <strong class="bold">skip-gram</strong> and <strong class="bold">Continuous Bag of Words (</strong><span class="No-Break"><strong class="bold">CBOW)</strong></span><span class="No-Break"> architectures.</span></p>
			<p>Finally, note the following configurations of BlazingText, since they are likely to be present in <span class="No-Break">your exam:</span></p>
			<ul>
				<li>In Word2Vec mode, only the train channel <span class="No-Break">is available.</span></li>
				<li>BlazingText expects a single text file with space-separated tokens. Each line of the file must contain a single sentence. This means you usually have to preprocess your corpus of data before <span class="No-Break">using BlazingText.</span></li>
			</ul>
			<h2 id="_idParaDest-158">Seque<a id="_idTextAnchor929"/><a id="_idTextAnchor930"/>nce-to-sequence algorithm</h2>
			<p>This is a supervised algorithm that<a id="_idTextAnchor931"/> transforms an input sequence into<a id="_idTextAnchor932"/> an output sequence. This sequence can be a text sentence or even an <span class="No-Break">audio recording.</span></p>
			<p>The most common use cases for sequence-to-sequence are machine translation, text summarization, and speech-to-text. Anything that you think is a sequence-to-sequence problem can be approached by <span class="No-Break">this algorithm.</span></p>
			<p>Technically, AWS SageMaker’s Seq2Seq uses <a id="_idTextAnchor933"/>two types of neural networks to create models: an <strong class="bold">RNN</strong> and a <strong class="bold">Convolutional Neural Network (CNN)</strong> with an <span class="No-Break">at<a id="_idTextAnchor934"/>tention mechanism.</span></p>
			<p><strong class="bold">Latent Dirichlet allocation</strong>, or <strong class="bold">LDA</strong> for short, is used for topic modeling. Topic modeling is a textual analysis tech<a id="_idTextAnchor935"/>nique where you can extract a set of topics from a corpus of text data. LDA learns these topics based on the probability distribution of the words in the corpus <span class="No-Break">of text.</span></p>
			<p>Since this is an unsupervised algorithm, there is no need to set a target variable. Also, the number of topics must be specified up-front, and you will have to analyze each topic to find its <span class="No-Break">domain meaning.</span></p>
			<h2 id="_idParaDest-159">Neura<a id="_idTextAnchor936"/><a id="_idTextAnchor937"/>l Topic Model algorithm</h2>
			<p>Just like the LDA <a id="_idTextAnchor938"/>algorithm, the <strong class="bold">Neural Topic Model (NTM)</strong> also aims to extr<a id="_idTextAnchor939"/>act topics from a corpus of data. However, the difference between LDA and NTM is their learning logic. While LDA learns from probability distributions of the words in the documents, NTM is built on top of <span class="No-Break">neural networks.</span></p>
			<p>The NTM network architecture has a bottleneck layer, which creates an embedding representation of the documents. This bottleneck layer contains all the necessary information to predict document composition, and its coefficients can be <span class="No-Break">considered topics.</span></p>
			<p>With that, you have completed this section on textual analysis. In the next section, you will learn about image <span class="No-Break">processing algorithms.</span></p>
			<h1 id="_idParaDest-160">Image<a id="_idTextAnchor940"/><a id="_idTextAnchor941"/> processing</h1>
			<p>Image processing is a<a id="_idTextAnchor942"/> very popular topic in machine learning. The idea is pretty self-explanatory: creating models that can analyze images and make inferences on top of them. By inference, you can understand this as detecting objects in an image, classifying images, and <span class="No-Break">so on.</span></p>
			<p>AWS offers a set of built-in algorithms you can use to train image processing models. In the next few sections, you will have a look at <span class="No-Break">those algorithms.</span></p>
			<h2 id="_idParaDest-161">Image<a id="_idTextAnchor943"/><a id="_idTextAnchor944"/> classification algorithm</h2>
			<p>As the name suggests, the image classification algorithm is u<a id="_idTextAnchor945"/>sed to classify images using supervised learning. In other words, it needs a label within each image. It supports <span class="No-Break">multi-label classification.</span></p>
			<p>The way it operates is simple: during training, it receives an image and its associated labels. During inference, it receives an image and returns all the predicted labels. The image classification algorithm uses a CNN (<strong class="bold">Res<a id="_idTextAnchor946"/>Net</strong>) for training. It can either train the model from scratch or take advantage of transfer learning to pre-load the first few layers of the <span class="No-Break">neural network.</span></p>
			<p>According to AWS’s documentation, the <strong class="source-inline">.jpg</strong> and <strong class="source-inline">.png</strong> file formats are supported, but the recommended form<a id="_idTextAnchor947"/>at is <span class="No-Break"><strong class="bold">MXNet’s RecordIO</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-162">Seman<a id="_idTextAnchor948"/><a id="_idTextAnchor949"/>tic segmentation algorithm</h2>
			<p>The semantic segmentation algorithm prov<a id="_idTextAnchor950"/>ides a pixel-level capability for creating computer vision applications. It tags each pixel of the image with a class, which is an important feature for complex applications such as self-driving and medical <span class="No-Break">image diagnostics.</span></p>
			<p>In terms of its implementation, the semantic segmentation algo<a id="_idTextAnchor951"/>rithm uses the <strong class="bold">MXNet Gluon framework</strong> and the <strong class="bold">Gluon CV toolkit</strong>. You can <a id="_idTextAnchor952"/>choose any of the following algorithms to train <span class="No-Break">a model:</span></p>
			<ul>
				<li><strong class="bold">Fully Convolutional </strong><span class="No-Break"><strong class="bold">Network (FCN)</strong></span></li>
				<li><strong class="bold">Pyramid Scene </strong><span class="No-Break"><strong class="bold">Parsing (PSP)</strong></span></li>
				<li><span class="No-Break">DeepLabV3</span></li>
			</ul>
			<p>All these options work as an <strong class="bold">en<a id="_idTextAnchor953"/>coder-decoder</strong> neural network architecture. The outpu<a id="_idTextAnchor954"/>t of the network is known as a <span class="No-Break"><strong class="bold">segmentation mask</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-163">Objec<a id="_idTextAnchor955"/><a id="_idTextAnchor956"/>t detection algorithm</h2>
			<p>Just like<a id="_idTextAnchor957"/> the image classification algorithm, the main goal of the object detection algorithm is also self-explanatory: it detects and classifies objects in images. It uses a supervised approach to train a deep <span class="No-Break">neural network.</span></p>
			<p>During the inference process, this algorithm returns the identified objects and a score of confidence regarding the prediction. The object detection algorithm uses <strong class="bold">Single Shot MultiBox Detector (SSD)</strong> and supp<a id="_idTextAnchor958"/>orts two t<a id="_idTextAnchor959"/>ypes of network archi<a id="_idTextAnchor960"/>tecture: <strong class="bold">Visual Geometry Group (VGG)</strong> and <strong class="bold">Residual </strong><span class="No-Break"><strong class="bold">Network (ResNet).</strong></span></p>
			<h1 id="_idParaDest-164">Summa<a id="_idTextAnchor961"/><a id="_idTextAnchor962"/>ry</h1>
			<p>That was such a journey! Take a moment to recap what you have just learned. This chapter had four main topics: supervised learning, unsupervised learning, textual analysis, and image processing. Everything that you have learned fits into those subfields of <span class="No-Break">machine learning.</span></p>
			<p>The list of supervised learning algorithms that you have studied includes <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break">Linear learner</span></li>
				<li><span class="No-Break">Factorization machines</span></li>
				<li><span class="No-Break">XGBoost</span></li>
				<li><span class="No-Break">KNN</span></li>
				<li><span class="No-Break">Object2Vec</span></li>
				<li><span class="No-Break">DeepAR forecasting</span></li>
			</ul>
			<p>Remember that you can use linear learner, factorization machines, XGBoost, and KNN for multiple purposes, including solving regression and classification problems. Linear learner is probably the simplest algorithm out of these four; factorization machines extends linear earner and is good for sparse datasets, XGBoost uses an ensemble method based on decision trees, and KNN is an <span class="No-Break">index-based algorithm.</span></p>
			<p>The other two algorithms, Object2Vec and DeepAR, are used for specific purposes. Object2Vec is used to create vector representations of the data, while DeepAR is used to create <span class="No-Break">forecast models.</span></p>
			<p>The list of unsupervised learning algorithms that you have studied includes <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break">K-Means</span></li>
				<li><span class="No-Break">PCA</span></li>
				<li><span class="No-Break">IP Insights</span></li>
				<li><span class="No-Break">RCF</span></li>
			</ul>
			<p>K-Means is a very popular algorithm that is used for clustering. PCA is used for dimensionality reduction, IP Insights is used for pattern recognition, and RCF is used for <span class="No-Break">anomaly detection.</span></p>
			<p>You then looked at regression models and K-Means in more detail. You did this because, as a data scientist, you should at least master these two very popular algorithms so that you can go deeper into other algorithms <span class="No-Break">by yourself.</span></p>
			<p>Then, you moved on to the second half of this chapter, where you learned about textual analysis and the <span class="No-Break">following algorithms:</span></p>
			<ul>
				<li><span class="No-Break">BlazingText</span></li>
				<li><span class="No-Break">Sequence-to-sequence</span></li>
				<li><span class="No-Break">LDA</span></li>
				<li><span class="No-Break">NTM</span></li>
			</ul>
			<p>Finally, you learned about image processing and looked at <span class="No-Break">the following:</span></p>
			<ul>
				<li>Image <span class="No-Break">classification algorithm</span></li>
				<li>Semantic <span class="No-Break">segmentation algorithm</span></li>
				<li>Object <span class="No-Break">detection algorithm</span></li>
			</ul>
			<p>Since the topics covered in this chapter are very important with regard to the AWS Certified Machine Learning Specialty exam, you are highly encouraged to jump into the AWS website and search for machine learning algorithms. There, you will find the most recent information about the algorithms that you have just learned about. Please make sure you do it before taking <span class="No-Break">the exam.</span></p>
			<p>That brings you to the end of this quick refresher and the end of this chapter. In the next chapter, you will learn about the existing mechanisms provided by AWS that you can use to optimize and evaluate <span class="No-Break">these algorithms.</span></p>
			<h1 id="_idParaDest-165"><a id="_idTextAnchor963"/>Exam Readiness Drill – Chapter Review Questions</h1>
			<p>Apart from a solid understanding of key concepts, being able to think quickly under time pressure is a skill that will help you ace your certification exam. That is why working on these skills early on in your learning journey <span class="No-Break">is key.</span></p>
			<p>Chapter review questions are designed to improve your test-taking skills progressively with each chapter you learn and review your understanding of key concepts in the chapter at the same time. You’ll find these at the end of <span class="No-Break">each chapter.</span></p>
			<p class="callout-heading">How To Access These Resources</p>
			<p class="callout">To learn how to access these resources, head over to the chapter titled <a href="B21197_11.xhtml#_idTextAnchor1477"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Accessing the Online </em><span class="No-Break"><em class="italic">Practice Resources</em></span><span class="No-Break">.</span></p>
			<p>To open the Chapter Review Questions for this chapter, perform the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Click the link – <a href="https://packt.link/MLSC01E2_CH06"><span class="No-Break">https://packt.link/MLSC01E2_CH06</span></a><span class="No-Break">.</span><p class="list-inset">Alternatively, you can scan the following <strong class="bold">QR code</strong> (<span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.19</em></span><span class="No-Break">):</span></p></li>
			</ol>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B21197_06_19.jpg" alt="Figure 6.19 – QR code that opens Chapter Review Questions for logged-in users" width="550" height="150"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.19 – QR code that opens Chapter Review Questions for logged-in users</p>
			<ol>
				<li value="2">Once you log in, you’ll see a page similar to the one shown in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.20</em></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B21197_06_20.jpg" alt="Figure 6.20 – Chapter Review Questions for Chapter 6" width="1376" height="1350"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.20 – Chapter Review Questions for Chapter 6</p>
			<ol>
				<li value="3">Once ready, start the following practice drills, re-attempting the quiz <span class="No-Break">multiple times.</span></li>
			</ol>
			<h2 id="_idParaDest-166"><a id="_idTextAnchor964"/>Exam Readiness Drill</h2>
			<p>For the first three attempts, don’t worry about the <span class="No-Break">time limit.</span></p>
			<h3 id="_idParaDest-167"><a id="_idTextAnchor965"/>ATTEMPT 1</h3>
			<p>The first time, aim for at least <strong class="bold">40%</strong>. Look at the answers you got wrong and read the relevant sections in the chapter again to fix your <span class="No-Break">learning gaps.</span></p>
			<h3 id="_idParaDest-168"><a id="_idTextAnchor966"/>ATTEMPT 2</h3>
			<p>The second time, aim for at least <strong class="bold">60%</strong>. Look at the answers you got wrong and read the relevant sections in the chapter again to fix any remaining <span class="No-Break">learning gaps.</span></p>
			<h3 id="_idParaDest-169"><a id="_idTextAnchor967"/>ATTEMPT 3</h3>
			<p>The third time, aim for at least <strong class="bold">75%</strong>. Once you score 75% or more, you start working on <span class="No-Break">your timing.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">You may take more than <strong class="bold">three</strong> attempts to reach 75%. That’s okay. Just review the relevant sections in the chapter till you <span class="No-Break">get there.</span></p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor968"/>Working On Timing</h1>
			<p>Target: Your aim is to keep the score the same while trying to answer these questions as quickly as possible. Here’s an example of how your next attempts should <span class="No-Break">look like:</span></p>
			<table id="table011-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Attempt</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Score</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Time Taken</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Attempt 5</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">77%</span></p>
						</td>
						<td class="No-Table-Style">
							<p>21 mins <span class="No-Break">30 seconds</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Attempt 6</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">78%</span></p>
						</td>
						<td class="No-Table-Style">
							<p>18 mins <span class="No-Break">34 seconds</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Attempt 7</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">76%</span></p>
						</td>
						<td class="No-Table-Style">
							<p>14 mins <span class="No-Break">44 seconds</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.11 – Sample timing practice drills on the online platform</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The time limits shown in the above table are just examples. Set your own time limits with each attempt based on the time limit of the quiz on <span class="No-Break">the website.</span></p>
			<p>With each new attempt, your score should stay above <strong class="bold">75%</strong> while your “time taken” to complete should “decrease”. Repeat as many attempts as you want till you feel confident dealing with the <span class="No-Break">time pressure.</span></p>
		</div>
	</div>
</div>
</body></html>