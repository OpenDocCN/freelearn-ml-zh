<html><head></head><body>
		<div id="_idContainer249">
			<h1 id="_idParaDest-89"><em class="italic"><a id="_idTextAnchor100"/>Chapter 7</em>: Doing Automated Machine Learning with Amazon SageMaker Autopilot</h1>
			<p class="author-quote">"One of the holy grails of machine learning is to automate more and more of the feature engineering process." </p>
			<p class="author-quote">– Pedro Domingos </p>
			<p class="author-quote">"Automated machine learning, the best thing since sliced bread!"</p>
			<p class="author-quote">– Anonymous</p>
			<p><strong class="bold">Automated Machine Learning </strong>(<strong class="bold">AutoML</strong>) via hyperscalers – that is, via cloud providers – has the potential to bring AI democratization to the masses. In the previous chapter, you created a <strong class="bold">Machine Learning </strong>(<strong class="bold">ML</strong>) workflow in SageMaker, and also learned about the internals of SageMaker Autopilot. </p>
			<p>In this chapter, we will look at a couple of examples explaining how Amazon SageMaker Autopilot can be used in a visual, as well as in notebook, format. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Creating an Amazon SageMaker Autopilot limited experiment</li>
				<li>Creating an AutoML experiment</li>
				<li>Running the SageMaker Autopilot experiment and deploying the model</li>
				<li>Invoking and testing the SageMaker Autopilot model</li>
				<li>Building and running SageMaker Autopilot experiments from the notebook</li>
			</ul>
			<p>Let's get started!</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor101"/>Technical requirements</h1>
			<p>You will need access to an Amazon SageMaker Studio instance on your machine. </p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor102"/>Creating an Amazon SageMaker Autopilot limited experiment</h1>
			<p>Let's gets a hands-on introduction to applying AutoML using SageMaker <a id="_idIndexMarker340"/>Autopilot. We will download and apply AutoML to an open source dataset. Let's get started!</p>
			<ol>
				<li>From Amazon SageMaker Studio, start a data science notebook by clicking on the <strong class="bold">Python 3</strong> button, as shown in the following screenshot:<div id="_idContainer204" class="IMG---Figure"><img src="image/Figure_7.1_B16890.jpg" alt="Figure 7.1 – Amazon SageMaker Launcher main screen&#13;&#10;"/></div><p class="figure-caption">Figure 7.1 – Amazon SageMaker Launcher main screen</p><p>Download <a id="_idIndexMarker341"/>the Bank Marketing dataset from UCI by calling the following URL retrieve commands and save it in your notebook: </p><div id="_idContainer205" class="IMG---Figure"><img src="image/Figure_7.2_B16890.jpg" alt="Figure 7.2 – Amazon SageMaker Studio Jupyter Notebook – downloading the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 7.2 – Amazon SageMaker Studio Jupyter Notebook – downloading the dataset</p><p>This Bank Marketing dataset is from a Portuguese banking institution and has the classification goal of predicting the client's subscription to deposit (binary feature, y). The dataset is from Moro, Cortez, and Rita's paper on "<em class="italic">A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems</em>", published by Elsevier. The dataset can be downloaded from <a id="_idIndexMarker342"/>the UCI website (<a href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing">https://archive.ics.uci.edu/ml/datasets/Bank+Marketing</a>), as shown in the following screenshot:</p><div id="_idContainer206" class="IMG---Figure"><img src="image/Figure_7.3_B16890.jpg" alt="Figure 7.3 – Bank Marketing dataset; &quot;A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems&quot;, Elsevier&#13;&#10;"/></div><p class="figure-caption">Figure 7.3 – Bank Marketing dataset; "A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems", Elsevier</p><p>The attribute information for the Bank Marketing dataset can be seen in the following screenshot:</p><div id="_idContainer207" class="IMG---Figure"><img src="image/Figure_7.4_B16890.jpg" alt="Figure 7.4 – Attributes for the Bank Marketing dataset &quot;A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems&quot;, Elsevier&#13;&#10;"/></div><p class="figure-caption">Figure 7.4 – Attributes for the Bank Marketing dataset "A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems", Elsevier</p><p>Now that <a id="_idIndexMarker343"/>you have downloaded the dataset, you can unzip the file using the commands shown in the following screenshot:</p><div id="_idContainer208" class="IMG---Figure"><img src="image/Figure_7.5_B16890.jpg" alt="Figure 7.5 – Amazon SageMaker Studio Jupyter Notebook – decompressing the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 7.5 – Amazon SageMaker Studio Jupyter Notebook – decompressing the dataset</p><p>The <a id="_idIndexMarker344"/>extracted archive has the following three files inside it:</p><ul><li><strong class="source-inline">bank-additional-full.csv</strong>, along with all examples (complete data), ordered by date (from May 2008 to November 2010)</li><li><strong class="source-inline">bank-additional.csv</strong>, with 10% of the examples (4,119) randomly selected from <strong class="source-inline">bank-additional-full.csv</strong></li><li><strong class="source-inline">bank-additional-names.txt</strong>, which contains the field information described in the preceding screenshot<p>As shown in the following screenshot, you can view the contents of the files using pandas once you've loaded the CSV file into the pandas DataFrame:</p></li></ul></li>
			</ol>
			<div>
				<div id="_idContainer209" class="IMG---Figure">
					<img src="image/Figure_7.6_B16890.jpg" alt="Figure 7.6 – Amazon SageMaker Studio Jupyter Notebook – loading the dataset in a pandas DataFrame and visualizing it &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.6 – Amazon SageMaker Studio Jupyter Notebook – loading the dataset in a pandas DataFrame and visualizing it </p>
			<p>Using NumPy, split the dataset into training and testing segments. In this case, we will <a id="_idIndexMarker345"/>use 95% of the data for training and 5% of the data for testing, as shown in the following screenshot. You will store this data in two files: one for training and another for testing.</p>
			<div>
				<div id="_idContainer210" class="IMG---Figure">
					<img src="image/Figure_7.7_B16890.jpg" alt="Figure 7.7 - Amazon SageMaker Studio Jupyter Notebook – splitting the dataset into training/test and saving the files in S3&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.7 - Amazon SageMaker Studio Jupyter Notebook – splitting the dataset into training/test and saving the files in S3</p>
			<p>Using the SageMaker API, create a session and upload the training data we created in the previous step to S3:</p>
			<div>
				<div id="_idContainer211" class="IMG---Figure">
					<img src="image/Figure_Preface_1_B16890.jpg" alt="Figure 7.8 – Amazon SageMaker Studio Jupyter Notebook – uploading the dataset to S3&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.8 – Amazon SageMaker Studio Jupyter Notebook – uploading the dataset to S3</p>
			<p>In the previous chapter, we learned how to create an AutoML experiment using the notebook. Now, let's create an experiment via the <a id="_idIndexMarker346"/>SageMaker UI. Click on the experiment icon in the left pane and create an experiment by providing the experiment's name and S3 bucket address, as shown in the following screenshot: </p>
			<div>
				<div id="_idContainer212" class="IMG---Figure">
					<img src="image/Figure_7.9_B16890.jpg" alt="Figure 7.9 – Amazon SageMaker Studio UI – creating an experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.9 – Amazon SageMaker Studio UI – creating an experiment</p>
			<ol>
				<li value="2">Set the target attribute to <strong class="source-inline">y</strong>. The target attribute is described in the dataset as Output variable (desired target): <strong class="source-inline">y</strong> – has the client subscribed a term deposit? <strong class="source-inline">(binary: "yes","no")</strong>:<div id="_idContainer213" class="IMG---Figure"><img src="image/Figure_7.10_B16890.jpg" alt="Figure 7.10 – Amazon SageMaker Studio UI – creating an experiment&#13;&#10;"/></div><p class="figure-caption">Figure 7.10 – Amazon SageMaker Studio UI – creating an experiment</p><p>As shown in the preceding screenshot, you can define the ML problem by yourself – it's binary classification in this case – or let the SageMaker AutoML engine decide this on its own. In this case, we will leave it as <strong class="bold">Auto</strong>, and you will see that the SageMaker will recognize this as a binary classification problem. </p></li>
				<li>You can either run the full experiment – that is, data analysis, feature engineering, and modeling tuning – or create a notebook to view the candidate definitions. We will do both with this dataset to demonstrate the benefits of each approach:<div id="_idContainer214" class="IMG---Figure"><img src="image/Figure_7.11_B16890.jpg" alt="Figure 7.11 – Amazon SageMaker Studio UI – complete experiment versus pilot &#13;&#10;for candidate definitions&#13;&#10;"/></div><p class="figure-caption">Figure 7.11 – Amazon SageMaker Studio UI – complete experiment versus pilot for candidate definitions</p><p>Lastly, you can set some advanced optional parameters, such as a custom SageMaker role, encryption key (if your S3 data is encrypted), and VPC information, if you are working with a virtual private cloud:</p><div id="_idContainer215" class="IMG---Figure"><img src="image/Figure_7.12_B16890.jpg" alt="Figure 7.12 – Amazon SageMaker Studio UI – Advanced Settings&#13;&#10;"/></div><p class="figure-caption">Figure 7.12 – Amazon SageMaker Studio UI – Advanced Settings</p><p>With that, we have entered all the required information and can run the experiment. Upon <a id="_idIndexMarker347"/>submitting the job, you will see the following screen, which contains two steps (analyzing data and candidate definitions generation). This is because we have chosen not to run the entire experiment; we have only chosen to generate candidate definitions:</p><div id="_idContainer216" class="IMG---Figure"><img src="image/Figure_7.13_B16890.jpg" alt="Figure 7.13 – Amazon SageMaker Studio experiment creation UI – Analyzing Data screen&#13;&#10;"/></div><p class="figure-caption">Figure 7.13 – Amazon SageMaker Studio experiment creation UI – Analyzing Data screen</p></li>
				<li>Once this partial experiment is completed, you will see the following screen, which <a id="_idIndexMarker348"/>shows the completed job information, trials, and job profile. Since we only generated the candidates in this case, the experiment didn't take too long. The <strong class="bold">Open candidate generation notebook</strong> and <strong class="bold">Open data exploration notebook</strong> buttons can be found at the top-right of the page. Both these buttons will open the respective notebooks:</li>
			</ol>
			<div>
				<div id="_idContainer217" class="IMG---Figure">
					<img src="image/Figure_7.14_B16890.jpg" alt="Figure 7.14 – Amazon SageMaker AutoML experiment completion view&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.14 – Amazon SageMaker AutoML experiment completion view</p>
			<p>The SageMaker Autopilot candidate definition notebook helps the data scientist take a deeper look at the dataset, its features, its classification problem, and the quality <a id="_idIndexMarker349"/>metric of the trained model. This is essentially an in-depth view of what happens behind the scenes in the SageMaker Autopilot pipeline and gives the data scientist a chance to run this manually and fine-tune or make changes as they deem necessary:</p>
			<div>
				<div id="_idContainer218" class="IMG---Figure">
					<img src="image/Figure_7.15_B16890.jpg" alt="Figure 7.15 – Amazon SageMaker Autopilot candidate definition notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.15 – Amazon SageMaker Autopilot candidate definition notebook</p>
			<p>The candidate definition notebook is a fairly large file and contains a table of contents, as shown <a id="_idIndexMarker350"/>in the preceding screenshot. Similarly, the data exploration notebook provides you with insights into the dataset: </p>
			<div>
				<div id="_idContainer219" class="IMG---Figure">
					<img src="image/Figure_7.16_B16890.jpg" alt="Figure 7.16 – Amazon SageMaker Autopilot data exploration notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.16 – Amazon SageMaker Autopilot data exploration notebook</p>
			<p>These insights include what you would typically expect from a data scientist – a data scientist <a id="_idIndexMarker351"/>looks for features and their data types, range, mean, median, descriptive statistics, missing data, and more. Even if you are skeptical about the AutoML capabilities that are available in general, this is an excellent place for a data scientist to just explore the dataset and its respective candidates:</p>
			<div>
				<div id="_idContainer220" class="IMG---Figure">
					<img src="image/Figure_7.17_B16890.jpg" alt="Figure 7.17 – Amazon SageMaker Autopilot data exploration notebook – descriptive statistics&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.17 – Amazon SageMaker Autopilot data exploration notebook – descriptive statistics</p>
			<p>The Amazon SageMaker Autopilot data exploration and candidate definition notebooks provide a <a id="_idIndexMarker352"/>transparent view for users to analyze data and conduct experiments. As notebooks go, these are executable pieces of code where you can see the preprocessors, hyperparameters, algorithms, ranges of hyperparameters, and all the prescribed preprocessing steps that are used to identify the best candidates. </p>
			<p>In the next section, we will build and run a full Autopilot experiment. </p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor103"/>Creating an AutoML experiment</h1>
			<p>Since the Autopilot data exploration and candidate definition notebooks provide an in-depth <a id="_idIndexMarker353"/>overview of the dataset, the complete experiment actually runs these steps and give you a final, tuned model based on the steps described in these notebooks. Now, let's create a full experiment using the same UI as looked at earlier: </p>
			<ol>
				<li value="1">From Amazon SageMaker Studio, start a data science experiment. Click on the experiment icon in the left-hand pane and create an experiment by providing the <a id="_idIndexMarker354"/>experiment name and S3 bucket address, as shown in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer221" class="IMG---Figure">
					<img src="image/Figure_7.18_B16890.jpg" alt="Figure 7.18 – Amazon SageMaker Autopilot – creating the experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.18 – Amazon SageMaker Autopilot – creating the experiment</p>
			<p>In the previous <em class="italic">Creating an Amazon SageMaker Autopilot limited experiment section</em>,  we did the limited run. In this section, we will use the complete experiment feature:  </p>
			<div>
				<div id="_idContainer222" class="IMG---Figure">
					<img src="image/Figure_7.19_B16890.jpg" alt="Figure 7.19 – Amazon SageMaker Autopilot – creating the complete experiment &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.19 – Amazon SageMaker Autopilot – creating the complete experiment </p>
			<p>When you <a id="_idIndexMarker355"/>start the experiment, it will behave very similar to our earlier candidate experiment, aside from the fact that this complete experiment will take longer and will build and execute the entire pipeline. You will see the following screen in the meantime while you wait for the results: </p>
			<div>
				<div id="_idContainer223" class="IMG---Figure">
					<img src="image/Figure_7.20_B16890.jpg" alt=""/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.20 – Amazon SageMaker Autopilot – running the full experiment</p>
			<p>While the <a id="_idIndexMarker356"/>experiment is running, you can track its progress by looking at the individual experiments and getting valuable insights from the <strong class="bold">Trials</strong> tab. You may also notice that the problem type here is correctly classified as binary classification:</p>
			<div>
				<div id="_idContainer224" class="IMG---Figure">
					<img src="image/Figure_7.21_B16890.jpg" alt="Figure 7.21 – Amazon SageMaker Autopilot – running the full experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.21 – Amazon SageMaker Autopilot – running the full experiment</p>
			<p>The detailed summary of the experiment shown in the following screenshot shows the inference <a id="_idIndexMarker357"/>containers that were used, the model data URI, and the environments that were utilized, along with their respective <strong class="bold">Amazon Resource Names</strong> (<strong class="bold">ARNs</strong>), which uniquely identify AWS resources:</p>
			<div>
				<div id="_idContainer225" class="IMG---Figure">
					<img src="image/Figure_7.22_B16890.jpg" alt="Figure 7.22 – Amazon SageMaker Autopilot inference container information&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.22 – Amazon SageMaker Autopilot inference container information</p>
			<p>The <strong class="bold">Trials</strong> tab shows the different trials and tuning jobs that run, as well as the objective function (F1 score), which demonstrates how it improves over time: </p>
			<div>
				<div id="_idContainer226" class="IMG---Figure">
					<img src="image/Figure_7.23_B16890.jpg" alt="Figure 7.23 – Amazon SageMaker Autopilot experiment run trials – best model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.23 – Amazon SageMaker Autopilot experiment run trials – best model</p>
			<p>You have <a id="_idIndexMarker358"/>seen this exact iteration in previous chapters; it is déjà vu all over again. We have seen this process unfolding in the OSS tools, but it's just different here, in that it's done in a more organized end-to-end manner. You have the entire pipeline built into one; that is, the strategy, data analysis, feature engineering, model tuning, and hyperparameter optimization processes. You can see the tuning job's details in the following screenshot:</p>
			<div>
				<div id="_idContainer227" class="IMG---Figure">
					<img src="image/Figure_7.24_B16890.jpg" alt="Figure 7.24 – Amazon SageMaker Autopilot tuning job details showing Bayesian strategy &#13;&#10;and resource information&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.24 – Amazon SageMaker Autopilot tuning job details showing Bayesian strategy and resource information</p>
			<p>Now that <a id="_idIndexMarker359"/>we've run the entire experiment and the process is completed, let's deploy the best model. </p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor104"/>Running the SageMaker Autopilot experiment and deploying the model</h1>
			<p>Amazon SageMaker Studio makes it easy for us to build, train, and deploy machine learning <a id="_idIndexMarker360"/>models; that is, it enables the data <a id="_idIndexMarker361"/>science life cycle. To deploy the model we built in the preceding section, we will need to set certain parameters. For this, you must provide the endpoint name, instance type, how many instances (count), and if you'd like to capture the request and response information. Let's get started:</p>
			<ol>
				<li value="1">If you select the <strong class="bold">Data capture</strong> option, you will need an S3 bucket for storage, as shown in the following screenshot: <div id="_idContainer228" class="IMG---Figure"><img src="image/Figure_7.25_B16890.jpg" alt="Figure 7.25 – Amazon SageMaker endpoint deployment&#13;&#10;"/></div><p class="figure-caption">Figure 7.25 – Amazon SageMaker endpoint deployment</p></li>
				<li>Once <a id="_idIndexMarker362"/>you've clicked on <strong class="bold">Deploy</strong>, you <a id="_idIndexMarker363"/>will see the following screen, which shows the progress of the new endpoint being created:<div id="_idContainer229" class="IMG---Figure"><img src="image/Figure_7.26_B16890.jpg" alt="Figure 7.26 – Amazon SageMaker endpoint deployment in progress&#13;&#10;"/></div><p class="figure-caption">Figure 7.26 – Amazon SageMaker endpoint deployment in progress</p><p>Once <a id="_idIndexMarker364"/>the deployment <a id="_idIndexMarker365"/>is completed, you will see the following status of InService:</p><div id="_idContainer230" class="IMG---Figure"><img src="image/Figure_7.27_B16890.jpg" alt="Figure 7.27 – Amazon SageMaker endpoint deployment completed &#13;&#10;"/></div><p class="figure-caption">Figure 7.27 – Amazon SageMaker endpoint deployment completed </p></li>
				<li>The model endpoint is an important resource for ensuring the quality of the model. By enabling the model monitor, you can detect data drift and monitor the quality of any models in production. This proactive detection of the model's quality helps ensure that your machine learning service does not end up providing the wrong results in production. You can click on the <strong class="screen-inline">Enable monitoring</strong> button to engage the Amazon SageMaker Model Monitor:</li>
			</ol>
			<div>
				<div id="_idContainer231" class="IMG---Figure">
					<img src="image/Figure_7.28_B16890.jpg" alt="Figure 7.28 – Amazon SageMaker Autopilot Model Monitor startup screen&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.28 – Amazon SageMaker Autopilot Model Monitor startup screen</p>
			<p>Model monitoring is an important area of the machine learning life cycle. As shown in <a id="_idIndexMarker366"/>the following <a id="_idIndexMarker367"/>screenshot, the Amazon SageMaker Model Monitor addresses this by capturing data, creating a baseline, scheduling monitoring jobs, and then allowing SMEs to interpret the results in the case of outliers and violations:</p>
			<div>
				<div id="_idContainer232" class="IMG---Figure">
					<img src="image/Figure_7.29_B16890.jpg" alt="Figure 7.29 – Amazon SageMaker Autopilot Model Monitor enablement notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.29 – Amazon SageMaker Autopilot Model Monitor enablement notebook</p>
			<p>Now that we have created and the deployed the model, it is time to test it out by invoking it. This operation of invoking a machine learning model that's been exposed via a web service is typically called inferencing or evaluation. </p>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor105"/>Invoking the model</h2>
			<p>With the model built and deployed using Amazon SageMaker Autopilot, we can test it out. Remember <a id="_idIndexMarker368"/>the test data we saved earlier? Now, it's time to use it. Here, you can see that we are iterating through the <strong class="source-inline">automl-test.csv</strong> file and invoking the endpoint by passing the line of data as a request:</p>
			<div>
				<div id="_idContainer233" class="IMG---Figure">
					<img src="image/Figure_7.30_B16890.jpg" alt="Figure 7.30 – Amazon SageMaker Autopilot – model invocation from the notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.30 – Amazon SageMaker Autopilot – model invocation from the notebook</p>
			<p>The request contains information about the person applying for the loan. We have removed the outcome (label) from the request, and then compared it as we wish to print the value out. You can see the request, the label, and the corresponding response from the web service in the preceding screenshot. You can use this information to calculate the accuracy of the service results; they are fairly accurate:</p>
			<div>
				<div id="_idContainer234" class="IMG---Figure">
					<img src="image/Figure_7.31_B16890.jpg" alt="Figure 7.31 – Amazon SageMaker Autopilot – model invocation responses&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.31 – Amazon SageMaker Autopilot – model invocation responses</p>
			<p>Now that <a id="_idIndexMarker369"/>you have learned how to set up an AutoML experiment from the Amazon SageMaker Autopilot UI, in the next section, we will use notebooks to do the same. </p>
			<h1 id="_idParaDest-95"><a id="_idTextAnchor106"/>Building and running SageMaker Autopilot experiments from the notebook </h1>
			<p>Customer churn is a real problem for businesses and in this example, we will use our knowledge <a id="_idIndexMarker370"/>of completing AutoML in Amazon SageMaker Autopilot to build a customer churn prediction experiment using the notebook. In this experiment, we will use a publicly available dataset of US mobile customers provided by Daniel T. Larose in his book <em class="italic">Discovering Knowledge in Data</em>. To demonstrate running the full gamut, the sample notebook executes the Autopilot experiment by performing feature engineering, building a model pipeline (along with any optimal hyperparameters), and deploying the model. </p>
			<p>The evolution of the UI/API/CLI paradigm has helped us utilize the same interface in multiple formats; in this case, we will be utilizing the capabilities of Amazon SageMaker Autopilot directly from the notebook. Let's get started:</p>
			<ol>
				<li value="1">Open the <strong class="source-inline">autopilot_customer_churn</strong> notebook from the <strong class="source-inline">amazon-sagemaker-examples/autopilot</strong> folder, as shown in the following screenshot: <div id="_idContainer235" class="IMG---Figure"><img src="image/Figure_7.32_B16890.jpg" alt="Figure 7.32 – Amazon SageMaker Autopilot – customer churn prediction Autopilot notebook&#13;&#10;"/></div><p class="figure-caption">Figure 7.32 – Amazon SageMaker Autopilot – customer churn prediction Autopilot notebook</p></li>
				<li>Run the <a id="_idIndexMarker371"/>setup by specifying <a id="_idIndexMarker372"/>the S3 bucket <a id="_idIndexMarker373"/>and the <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) role, as we did in the previous <em class="italic">Creating an AutoML experiment </em>section. Download the dataset, as shown in the following screenshot:<div id="_idContainer236" class="IMG---Figure"><img src="image/Figure_7.33_B16890.jpg" alt="Figure 7.33 – Amazon SageMaker Autopilot – running the notebook to set up a default bucket and creating the session&#13;&#10;"/></div><p class="figure-caption">Figure 7.33 – Amazon SageMaker Autopilot – running the notebook to set up a default bucket and creating the session</p></li>
				<li>At this <a id="_idIndexMarker374"/>point, you will need to <a id="_idIndexMarker375"/>install the prerequisites, and download the dataset, as shown in the following screenshot: <div id="_idContainer237" class="IMG---Figure"><img src="image/Figure_7.34_B16890.jpg" alt="Figure 7.34 – Amazon SageMaker Autopilot – downloading the dataset and unzipping the file&#13;&#10;"/></div><p class="figure-caption">Figure 7.34 – Amazon SageMaker Autopilot – downloading the dataset and unzipping the file</p></li>
				<li>Once <a id="_idIndexMarker376"/>the dataset has been <a id="_idIndexMarker377"/>downloaded and uncompressed, you can add it to a pandas DataFrame and view it. It shows information about the customer, such as their calling attributes, as shown in the following screenshot:<div id="_idContainer238" class="IMG---Figure"><img src="image/Figure_7.35_B16890.jpg" alt="Figure 7.35 – Amazon SageMaker notebook showing the dataset's information&#13;&#10;"/></div><p class="figure-caption">Figure 7.35 – Amazon SageMaker notebook showing the dataset's information</p></li>
				<li>We can <a id="_idIndexMarker378"/>now sample the <a id="_idIndexMarker379"/>dataset as test and training buckets, and then upload these files to S3 for future use. Once they've been uploaded, you will get the S3 buckets' names, as shown in the following screenshot:<div id="_idContainer239" class="IMG---Figure"><img src="image/Figure_7.36_B16890.jpg" alt="Figure 7.36 – Amazon SageMaker Autopilot – sample dataset for test and training, and uploading the files to the S3 &#13;&#10;"/></div><p class="figure-caption">Figure 7.36 – Amazon SageMaker Autopilot – sample dataset for test and training, and uploading the files to the S3 </p><p>So far, everything <a id="_idIndexMarker380"/>we have <a id="_idIndexMarker381"/>done is traditional notebook work. Now, we will set up the Autopilot job.</p></li>
				<li>Let's define the configuration, as shown in the following screenshot: <div id="_idContainer240" class="IMG---Figure"><img src="image/Figure_7.37_B16890.jpg" alt="Figure 7.37 – Amazon SageMaker Autopilot – configuring the Autopilot job config &#13;&#10;"/></div><p class="figure-caption">Figure 7.37 – Amazon SageMaker Autopilot – configuring the Autopilot job config </p></li>
				<li>Now, let's launch the SageMaker Autopilot job by invoking the <strong class="source-inline">create_auto_ml_job</strong> API call, like so:<div id="_idContainer241" class="IMG---Figure"><img src="image/Figure_7.38_B16890.jpg" alt="Figure 7.38 – Amazon SageMaker Autopilot – configuring the Autopilot job&#13;&#10;"/></div><p class="figure-caption">Figure 7.38 – Amazon SageMaker Autopilot – configuring the Autopilot job</p><p>The job <a id="_idIndexMarker382"/>runs with multiple <a id="_idIndexMarker383"/>trials, including the components of each experiment, as shown in the following screenshot:</p><div id="_idContainer242" class="IMG---Figure"><img src="image/Figure_7.39_B16890.jpg" alt="Figure 7.39 – Amazon SageMaker Autopilot – trial components in the Autopilot job notebook&#13;&#10;"/></div><p class="figure-caption">Figure 7.39 – Amazon SageMaker Autopilot – trial components in the Autopilot job notebook</p><p>While tracking <a id="_idIndexMarker384"/>the Amazon SageMaker <a id="_idIndexMarker385"/>Autopilot job's progress, you can print its status, along with any delays, as shown in the following screenshot. However, to view the details of individual trial runs in a meaningful manner visually, you can use the user interface:</p><div id="_idContainer243" class="IMG---Figure"><img src="image/Figure_7.40_B16890.jpg" alt="Figure 7.40 – Amazon SageMaker Autopilot – trial components in the Autopilot job notebook&#13;&#10;"/></div><p class="figure-caption">Figure 7.40 – Amazon SageMaker Autopilot – trial components in the Autopilot job notebook</p></li>
				<li>Once the <a id="_idIndexMarker386"/>feature engineering <a id="_idIndexMarker387"/>and model tuning jobs in the trials are complete, you can run <strong class="source-inline">describe_auto_ml_job</strong> to get the best candidate information. Then, you can traverse the <strong class="source-inline">best_candidate</strong> object to get information about the underlying score and metric, as shown in the following screenshot: </li>
			</ol>
			<div>
				<div id="_idContainer244" class="IMG---Figure">
					<img src="image/Figure_7.41_B16890.jpg" alt="Figure 7.41 – Amazon SageMaker Autopilot – trial components in the Autopilot job notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.41 – Amazon SageMaker Autopilot – trial components in the Autopilot job notebook</p>
			<p>Once the <a id="_idIndexMarker388"/>job is completed, you will <a id="_idIndexMarker389"/>see the candidate model, the final metric (the F1 score in this case), and any associated values:</p>
			<div>
				<div id="_idContainer245" class="IMG---Figure">
					<img src="image/Figure_7.42_B16890.jpg" alt="Figure 7.42 – Amazon SageMaker Autopilot job results&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.42 – Amazon SageMaker Autopilot job results</p>
			<p>We will deploy and invoke the best candidate model, which has a 93% F1 score, in the next section. </p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor107"/>Hosting and invoking the model</h2>
			<p>Similar to how we invoked the model we built using the Experiment UI earlier, we will now host <a id="_idIndexMarker390"/>and invoke the model we built <a id="_idIndexMarker391"/>in the notebook. The difference is that in the first instance, we were low-code, while here we are building it using code:</p>
			<ol>
				<li value="1">To host the service, you will need to create a model object, endpoint configuration, and eventually an endpoint. Previously, this was done using the UI, but here, we will use the Amazon SageMaker Python instance to accomplish the same. This can be seen in the following screenshot:<div id="_idContainer246" class="IMG---Figure"><img src="image/Figure_7.43_B16890.jpg" alt="Figure 7.43 – Amazon SageMaker notebook – hosting the model&#13;&#10;"/></div><p class="figure-caption">Figure 7.43 – Amazon SageMaker notebook – hosting the model</p><p>The <strong class="source-inline">get_waiter</strong> method is part of Boto3, which is the Python SDK for AWS. Like other waiters, it polls until a successful state is reached. An error is typically returned after 60 failed checks. You can read about the methods by looking at the API documentation for it, which can be found here: <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint</a>.</p><p>Now that the endpoint has been created and the model has been hosted, we can invoke the service. To evaluate the model, you will need to create a predictor instance and pass it the endpoint's information, along with the parameters for prediction. Instead of calling the endpoint line by line, we can perform bulk predictions by passing in the entire test data CSV file and comparing the results against the ground truth. You can see the accuracy numbers in the following screenshot: </p><div id="_idContainer247" class="IMG---Figure"><img src="image/Figure_7.44_B16890.jpg" alt="Figure 7.44 – Amazon SageMaker model evaluation for accuracy&#13;&#10;"/></div><p class="figure-caption">Figure 7.44 – Amazon SageMaker model evaluation for accuracy</p></li>
				<li>Once you <a id="_idIndexMarker392"/>have finished testing the <a id="_idIndexMarker393"/>endpoint, we must clean up. In cloud environments, you must clean up after yourself, so make this a priority checklist item. If you don't do this, you won't like the billing statement from leaving a server running. Virtual or not, it all adds up.<p>When you're cleaning up a UI, turn off and delete the compute instances and the endpoints. Since we are doing a manual cleanup, you must delete the endpoint, endpoint config, and the model:</p></li>
			</ol>
			<div>
				<div id="_idContainer248" class="IMG---Figure">
					<img src="image/Figure_7.45_B16890.jpg" alt="Figure 7.45 – Amazon SageMaker Autopilot cleanup with resulting response codes&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.45 – Amazon SageMaker Autopilot cleanup with resulting response codes</p>
			<p>Even though these examples have shown you how AWS AutoML <a id="_idIndexMarker394"/>enables you to perform <a id="_idIndexMarker395"/>feature engineering, model tuning, and hyperparameter optimization, you don't have to limit yourself to the algorithms provided by AWS. You can bring your own data processing code to SageMaker Autopilot, as shown at <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/custom-feature-selection/Feature_selection_autopilot.ipynb">https://github.com/aws/amazon-sagemaker-examples/blob/master/autopilot/custom-feature-selection/Feature_selection_autopilot.ipynb</a>.</p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor108"/>Summary</h1>
			<p>Building AutoML systems to democratize AI from scratch is a considerable effort. Therefore, cloud hyperscalers act as enablers and accelerators to jumpstart this journey. In this chapter, you learned how to use Amazon SageMaker Autopilot, both via notebooks and via the experimentation user interface. You were also exposed to the larger AWS machine learning ecosystem and SageMaker's capabilities. </p>
			<p>In the next chapter, we will study another major cloud computing platform, Google Cloud Platform, and the AutoML offerings provided it. Happy coding! </p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor109"/>Further reading</h1>
			<p>For more information on the topics that were covered in this chapter, please refer to the following links and resources:</p>
			<ul>
				<li><em class="italic">Mastering Machine Learning on AWS: Advanced machine learning in Python using SageMaker, Apache Spark, and TensorFlow</em>, by Dr. Saket S.R. Mengle , Maximo Gurmendez, Packt Publishing: <a href="https://www.amazon.com/Mastering-Machine-Learning-AWS-TensorFlow/dp/1789349796">https://www.amazon.com/Mastering-Machine-Learning-AWS-TensorFlow/dp/1789349796</a></li>
				<li><em class="italic">Learn Amazon SageMaker: A guide to building, training, and deploying machine learning models for developers and data scientists</em>, by Julien Simon and Francesco Pochetti, Packt Publishing: <a href="https://www.amazon.com/Learn-Amazon-SageMaker-developers-scientists/dp/180020891X">https://www.amazon.com/Learn-Amazon-SageMaker-developers-scientists/dp/180020891X</a></li>
			</ul>
		</div>
	</body></html>