<html><head></head><body>
<div class="book" title="Chapter&#xA0;11.&#xA0;Ensembling Time Series Models" id="28FAO1-2006c10fab20488594398dc4871637ee"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch11" class="calibre1"/>Chapter 11. Ensembling Time Series Models</h1></div></div></div><p class="calibre7">All of the models developed in this book so far have dealt with situations that arise when observations are independent of each other. The example of overseas visitors explains a time series in which the observations are dependent on the previously observed data. In a brief discussion of this example, it was established that it is necessary to develop time series models. Since the time series is sequential in nature, the time stamp may be displayed in nanoseconds, seconds, minutes, hours, days, or months.</p><p class="calibre7">This chapter will open with a quick review of the important concepts of time series in autocorrelation and partial autocorrelation functions, as well as fitted model assessment measures. Much like the classification and regression models, a host of methods are available for analyzing time series data. An important class of time series models in seasonal decomposition includes LOESS (STL), exponential smoothing state space models (ets), Box-Jenkins (ARIMA) models, and autoregressive neural network models. These will be discussed and illustrated in the following section. The ensembling of time series models will be illustrated in the final section of the chapter.</p><p class="calibre7">The main areas that will be covered in this chapter include the following:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Time series datasets</li><li class="listitem">Time series visualization</li><li class="listitem">Core concepts</li><li class="listitem">Time series models</li><li class="listitem">Bagging time series</li><li class="listitem">Ensembling time series models</li></ul></div></div>

<div class="book" title="Chapter&#xA0;11.&#xA0;Ensembling Time Series Models" id="28FAO1-2006c10fab20488594398dc4871637ee">
<div class="book" title="Technical requirements"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch11lvl1sec80" class="calibre1"/>Technical requirements</h1></div></div></div><p class="calibre7">In this chapter, we will be using the following R libraries:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="literal">forecast</code></li><li class="listitem"><code class="literal">forecastHybrid</code></li></ul></div></div></div>

<div class="book" title="Time series datasets"><div class="book" id="29DRA2-2006c10fab20488594398dc4871637ee"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch11lvl1sec81" class="calibre1"/>Time series datasets</h1></div></div></div><p class="calibre7">Time series data is structurally<a id="id490" class="calibre1"/> different from the data discussed up until now. A glimpse of time series data was seen in <span class="strong"><em class="calibre9">Overseas Visitor</em></span> in <span class="strong"><em class="calibre9">section 1</em></span> of <a class="calibre1" title="Chapter 1. Introduction to Ensemble Techniques" href="part0012_split_000.html#BE6O2-2006c10fab20488594398dc4871637ee">Chapter 1</a>, <span class="strong"><em class="calibre9">Introduction to Ensemble Techniques</em></span>, and the bootstrapping of the time series models was briefly touched on in <a class="calibre1" title="Chapter 2. Bootstrapping" href="part0018_split_000.html#H5A41-2006c10fab20488594398dc4871637ee">Chapter 2</a>, <span class="strong"><em class="calibre9">Bootstrapping</em></span>. The complexity that arises in the analysis of time series data is that the observations are not independent and, consequently, we need to specify the dependence. Box et al. (2015) is the benchmark book for the statistical analysis of time series, and its first edition was published in 1970. The class of models invented and popularized in Box and Jenkins is the popular autoregressive integrated moving average, famously abbreviated as ARIMA. This is also often known as the Box-Jenkins model.</p><p class="calibre7">
<span class="strong"><em class="calibre9">Table 1</em></span> summarizes twenty-one time series datasets. The Length column gives the number of observations/data points of the series, while the <span class="strong"><strong class="calibre8">Frequency</strong></span> column gives the periodicity of the time series, and the remaining six columns are simply the summaries obtained by applying the summary function to a numeric object. The first column, of course, gives the names of the datasets as they are available in R, and hence we have not changed the cases, upper or lower. The numbers of observations in the datasets range from 19 to 7980.</p><p class="calibre7">But what does frequency or periodicity mean? In a dataset which includes periodicity, the associated time index gets repeated. For instance, we might have yearly, quarterly, monthly, or weekly data, and thus, in the middle two cases, the frequency will be <span class="strong"><strong class="calibre8">4</strong></span> and <span class="strong"><strong class="calibre8">12</strong></span> respectively. The frequency need not be an integer and can also be a fractional value. For example, carcinogenesis tests will have values in nanoseconds. The summary of the time series data is simply the result of applying the summary function to a numeric dataset. Consequently, we implicitly assume that time series data is numeric. The variation as seen in the summaries also shows that different datasets will require different handling. A quick introduction to a time series application can be found in Chapter 10 of Tattar et al. (2017).</p><p class="calibre7">A description of the datasets used in<a id="id491" class="calibre1"/> this chapter can be found in the following table:</p><div class="informalexample"><table border="1" class="calibre16"><colgroup class="calibre17"><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/></colgroup><thead class="calibre19"><tr class="calibre20"><th valign="bottom" class="calibre21">
<p class="calibre22">Dataset</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Length</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Frequency</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Minimum</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Q1</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Median</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Mean</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Q3</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Maximum</p>
</th></tr></thead><tbody class="calibre24"><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">AirPassengers</code>
</p>
</td><td class="calibre25">
<p class="calibre22">144</p>
</td><td class="calibre25">
<p class="calibre22">12</p>
</td><td class="calibre25">
<p class="calibre22">104.00</p>
</td><td class="calibre25">
<p class="calibre22">180.00</p>
</td><td class="calibre25">
<p class="calibre22">265.50</p>
</td><td class="calibre25">
<p class="calibre22">280.30</p>
</td><td class="calibre25">
<p class="calibre22">360.50</p>
</td><td class="calibre25">
<p class="calibre22">622.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">BJsales</code>
</p>
</td><td class="calibre25">
<p class="calibre22">150</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">198.60</p>
</td><td class="calibre25">
<p class="calibre22">212.58</p>
</td><td class="calibre25">
<p class="calibre22">220.65</p>
</td><td class="calibre25">
<p class="calibre22">229.98</p>
</td><td class="calibre25">
<p class="calibre22">254.68</p>
</td><td class="calibre25">
<p class="calibre22">263.30</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">JohnsonJohnson</code>
</p>
</td><td class="calibre25">
<p class="calibre22">84</p>
</td><td class="calibre25">
<p class="calibre22">4</p>
</td><td class="calibre25">
<p class="calibre22">0.44</p>
</td><td class="calibre25">
<p class="calibre22">1.25</p>
</td><td class="calibre25">
<p class="calibre22">3.51</p>
</td><td class="calibre25">
<p class="calibre22">4.80</p>
</td><td class="calibre25">
<p class="calibre22">7.13</p>
</td><td class="calibre25">
<p class="calibre22">16.20</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">LakeHuron</code>
</p>
</td><td class="calibre25">
<p class="calibre22">98</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">575.96</p>
</td><td class="calibre25">
<p class="calibre22">578.14</p>
</td><td class="calibre25">
<p class="calibre22">579.12</p>
</td><td class="calibre25">
<p class="calibre22">579.00</p>
</td><td class="calibre25">
<p class="calibre22">579.88</p>
</td><td class="calibre25">
<p class="calibre22">581.86</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">Nile</code>
</p>
</td><td class="calibre25">
<p class="calibre22">100</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">456.00</p>
</td><td class="calibre25">
<p class="calibre22">798.50</p>
</td><td class="calibre25">
<p class="calibre22">893.50</p>
</td><td class="calibre25">
<p class="calibre22">919.35</p>
</td><td class="calibre25">
<p class="calibre22">1032.50</p>
</td><td class="calibre25">
<p class="calibre22">1370.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">UKgas</code>
</p>
</td><td class="calibre25">
<p class="calibre22">108</p>
</td><td class="calibre25">
<p class="calibre22">4</p>
</td><td class="calibre25">
<p class="calibre22">84.80</p>
</td><td class="calibre25">
<p class="calibre22">153.30</p>
</td><td class="calibre25">
<p class="calibre22">220.90</p>
</td><td class="calibre25">
<p class="calibre22">337.63</p>
</td><td class="calibre25">
<p class="calibre22">469.90</p>
</td><td class="calibre25">
<p class="calibre22">1163.90</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">UKDriverDeaths</code>
</p>
</td><td class="calibre25">
<p class="calibre22">192</p>
</td><td class="calibre25">
<p class="calibre22">12</p>
</td><td class="calibre25">
<p class="calibre22">1057.00</p>
</td><td class="calibre25">
<p class="calibre22">1461.75</p>
</td><td class="calibre25">
<p class="calibre22">1631.00</p>
</td><td class="calibre25">
<p class="calibre22">1670.31</p>
</td><td class="calibre25">
<p class="calibre22">1850.75</p>
</td><td class="calibre25">
<p class="calibre22">2654.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">USAccDeaths</code>
</p>
</td><td class="calibre25">
<p class="calibre22">72</p>
</td><td class="calibre25">
<p class="calibre22">12</p>
</td><td class="calibre25">
<p class="calibre22">6892.00</p>
</td><td class="calibre25">
<p class="calibre22">8089.00</p>
</td><td class="calibre25">
<p class="calibre22">8728.50</p>
</td><td class="calibre25">
<p class="calibre22">8788.79</p>
</td><td class="calibre25">
<p class="calibre22">9323.25</p>
</td><td class="calibre25">
<p class="calibre22">11317.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">WWWusage</code>
</p>
</td><td class="calibre25">
<p class="calibre22">100</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">83.00</p>
</td><td class="calibre25">
<p class="calibre22">99.00</p>
</td><td class="calibre25">
<p class="calibre22">138.50</p>
</td><td class="calibre25">
<p class="calibre22">137.08</p>
</td><td class="calibre25">
<p class="calibre22">167.50</p>
</td><td class="calibre25">
<p class="calibre22">228.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">airmiles</code>
</p>
</td><td class="calibre25">
<p class="calibre22">24</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">412.00</p>
</td><td class="calibre25">
<p class="calibre22">1580.00</p>
</td><td class="calibre25">
<p class="calibre22">6431.00</p>
</td><td class="calibre25">
<p class="calibre22">10527.83</p>
</td><td class="calibre25">
<p class="calibre22">17531.50</p>
</td><td class="calibre25">
<p class="calibre22">30514.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">austres</code>
</p>
</td><td class="calibre25">
<p class="calibre22">89</p>
</td><td class="calibre25">
<p class="calibre22">4</p>
</td><td class="calibre25">
<p class="calibre22">13067.30</p>
</td><td class="calibre25">
<p class="calibre22">14110.10</p>
</td><td class="calibre25">
<p class="calibre22">15184.20</p>
</td><td class="calibre25">
<p class="calibre22">15273.45</p>
</td><td class="calibre25">
<p class="calibre22">16398.90</p>
</td><td class="calibre25">
<p class="calibre22">17661.50</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">co2</code>
</p>
</td><td class="calibre25">
<p class="calibre22">468</p>
</td><td class="calibre25">
<p class="calibre22">12</p>
</td><td class="calibre25">
<p class="calibre22">313.18</p>
</td><td class="calibre25">
<p class="calibre22">323.53</p>
</td><td class="calibre25">
<p class="calibre22">335.17</p>
</td><td class="calibre25">
<p class="calibre22">337.05</p>
</td><td class="calibre25">
<p class="calibre22">350.26</p>
</td><td class="calibre25">
<p class="calibre22">366.84</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">discoveries</code>
</p>
</td><td class="calibre25">
<p class="calibre22">100</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">0.00</p>
</td><td class="calibre25">
<p class="calibre22">2.00</p>
</td><td class="calibre25">
<p class="calibre22">3.00</p>
</td><td class="calibre25">
<p class="calibre22">3.10</p>
</td><td class="calibre25">
<p class="calibre22">4.00</p>
</td><td class="calibre25">
<p class="calibre22">12.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">lynx</code>
</p>
</td><td class="calibre25">
<p class="calibre22">114</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">39.00</p>
</td><td class="calibre25">
<p class="calibre22">348.25</p>
</td><td class="calibre25">
<p class="calibre22">771.00</p>
</td><td class="calibre25">
<p class="calibre22">1538.02</p>
</td><td class="calibre25">
<p class="calibre22">2566.75</p>
</td><td class="calibre25">
<p class="calibre22">6991.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">nhtemp</code>
</p>
</td><td class="calibre25">
<p class="calibre22">60</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">47.90</p>
</td><td class="calibre25">
<p class="calibre22">50.58</p>
</td><td class="calibre25">
<p class="calibre22">51.20</p>
</td><td class="calibre25">
<p class="calibre22">51.16</p>
</td><td class="calibre25">
<p class="calibre22">51.90</p>
</td><td class="calibre25">
<p class="calibre22">54.60</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">nottem</code>
</p>
</td><td class="calibre25">
<p class="calibre22">240</p>
</td><td class="calibre25">
<p class="calibre22">12</p>
</td><td class="calibre25">
<p class="calibre22">31.30</p>
</td><td class="calibre25">
<p class="calibre22">41.55</p>
</td><td class="calibre25">
<p class="calibre22">47.35</p>
</td><td class="calibre25">
<p class="calibre22">49.04</p>
</td><td class="calibre25">
<p class="calibre22">57.00</p>
</td><td class="calibre25">
<p class="calibre22">66.50</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">presidents</code>
</p>
</td><td class="calibre25">
<p class="calibre22">120</p>
</td><td class="calibre25">
<p class="calibre22">4</p>
</td><td class="calibre25">
<p class="calibre22">23.00</p>
</td><td class="calibre25">
<p class="calibre22">46.00</p>
</td><td class="calibre25">
<p class="calibre22">59.00</p>
</td><td class="calibre25">
<p class="calibre22">56.31</p>
</td><td class="calibre25">
<p class="calibre22">69.00</p>
</td><td class="calibre25">
<p class="calibre22">87.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">treering</code>
</p>
</td><td class="calibre25">
<p class="calibre22">7980</p>
</td><td class="calibre25">
<p class="calibre22">1</p>
</td><td class="calibre25">
<p class="calibre22">0.00</p>
</td><td class="calibre25">
<p class="calibre22">0.84</p>
</td><td class="calibre25">
<p class="calibre22">1.03</p>
</td><td class="calibre25">
<p class="calibre22">1.00</p>
</td><td class="calibre25">
<p class="calibre22">1.20</p>
</td><td class="calibre25">
<p class="calibre22">1.91</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">gas</code>
</p>
</td><td class="calibre25">
<p class="calibre22">476</p>
</td><td class="calibre25">
<p class="calibre22">12</p>
</td><td class="calibre25">
<p class="calibre22">1646.00</p>
</td><td class="calibre25">
<p class="calibre22">2674.75</p>
</td><td class="calibre25">
<p class="calibre22">16787.50</p>
</td><td class="calibre25">
<p class="calibre22">21415.27</p>
</td><td class="calibre25">
<p class="calibre22">38628.50</p>
</td><td class="calibre25">
<p class="calibre22">66600.00</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">uspop</code>
</p>
</td><td class="calibre25">
<p class="calibre22">19</p>
</td><td class="calibre25">
<p class="calibre22">0.1</p>
</td><td class="calibre25">
<p class="calibre22">3.93</p>
</td><td class="calibre25">
<p class="calibre22">15.00</p>
</td><td class="calibre25">
<p class="calibre22">50.20</p>
</td><td class="calibre25">
<p class="calibre22">69.77</p>
</td><td class="calibre25">
<p class="calibre22">114.25</p>
</td><td class="calibre25">
<p class="calibre22">203.20</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">sunspots</code>
</p>
</td><td class="calibre25">
<p class="calibre22">2820</p>
</td><td class="calibre25">
<p class="calibre22">12</p>
</td><td class="calibre25">
<p class="calibre22">0.00</p>
</td><td class="calibre25">
<p class="calibre22">15.70</p>
</td><td class="calibre25">
<p class="calibre22">42.00</p>
</td><td class="calibre25">
<p class="calibre22">51.27</p>
</td><td class="calibre25">
<p class="calibre22">74.93</p>
</td><td class="calibre25">
<p class="calibre22">253.80</p>
</td></tr></tbody></table></div><div class="blockquote"><blockquote class="blockquote1"><p class="calibre27">Table 1: Time Series Datasets in R</p></blockquote></div></div>

<div class="book" title="Time series datasets">
<div class="book"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch11lvl1sec82" class="calibre1"/></h2></div></div></div><div class="book" title="AirPassengers"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec53" class="calibre1"/>AirPassengers</h3></div></div></div><p class="calibre7">The <code class="literal">AirPassengers</code> dataset contains the<a id="id492" class="calibre1"/> monthly totals of international airline passengers from 1949 to 1960. The monthly count numbers are in thousands. Over twelve years, the monthly data accumulated 144 observations. Since we have multiple observations across the years for the months, the seasonality aspect of the travelers count can be captured from the data. This was popularized in Box et al. (2015).</p></div><div class="book" title="co2"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec54" class="calibre1"/>co2</h3></div></div></div><p class="calibre7">The <code class="literal">co2</code> time series data is related to <a id="id493" class="calibre1"/>atmospheric concentrations of carbon dioxide. The concentration is expressed in parts per million (ppm), and this dataset is reported in the preliminary 1997 SIO manometric mole fraction scale. This time series was captured on a monthly basis for the period of 1959–97. On the help page of <code class="literal">co2</code>, it is noted that the missing values for the months of February, March, and April, 1964 are obtained by linearly interpolating between the values for January and May of 1964.</p></div><div class="book" title="uspop"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec55" class="calibre1"/>uspop</h3></div></div></div><p class="calibre7">The US census<a id="id494" class="calibre1"/> population (in millions), <code class="literal">uspop</code>, was recorded by the decennial census between 1790 and 1970. This was made available in a small time series dataset and, accordingly, it only consists of 19 data points. Seasonality is not captured in this dataset.</p></div><div class="book" title="gas"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec56" class="calibre1"/>gas</h3></div></div></div><p class="calibre7">The <code class="literal">gas</code> time series data contains <a id="id495" class="calibre1"/>Australian monthly gas production. The data available here is for the period of 1956–95. Consequently, we have 476 observations here. This dataset is drawn from the <code class="literal">forecast</code> package.</p></div><div class="book" title="Car Sales"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec57" class="calibre1"/>Car Sales</h3></div></div></div><p class="calibre7">The <code class="literal">car sales</code> data is adapted from <a id="id496" class="calibre1"/>Abraham and Ledolter (1983). For more information, refer to Table 2.7, page 68 of the book. The sales and advertising data is available for a period of 36 months. Here, we have additional information on the amount spent on advertisements each week. This is the first instance of additional variables availability, and it calls for specialized treatment, which we will explore further later in the chapter. The data is available in the <code class="literal">Car_Sales.csv</code> file and this is available in the code bundle.</p></div><div class="book" title="austres"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec58" class="calibre1"/>austres</h3></div></div></div><p class="calibre7">The <code class="literal">austres</code> time series dataset consists<a id="id497" class="calibre1"/> of a quarterly number of Australian residents for the period March 1971 to March 1994.</p></div><div class="book" title="WWWusage"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec59" class="calibre1"/>WWWusage</h3></div></div></div><p class="calibre7">The <code class="literal">WWWusage</code> time series dataset <a id="id498" class="calibre1"/>consists of the number of users connected to the internet through a server. The data is collected at a time interval of one minute. The time series values are collected for 100 observations.</p><p class="calibre7">Visualization gives invaluable insights and we will plot some of the time series next.</p></div></div></div>

<div class="book" title="Time series datasets">
<div class="book" title="Time series visualization"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch11lvl1sec83" class="calibre1"/>Time series visualization</h2></div></div></div><p class="calibre7">The main characteristic of time<a id="id499" class="calibre1"/> series data is that the observations are taken at regular intervals. A plot of the time series values (the <span class="strong"><em class="calibre9">y</em></span> axis) against the time itself (<span class="strong"><em class="calibre9">x</em></span> axis) is of great importance and gives away many structural insights. A time series plot is not merely a scatterplot with time as the <span class="strong"><em class="calibre9">x</em></span> axis. The time is non-decreasing and hence it has more importance and meaning in a time series plot than the mere <span class="strong"><em class="calibre9">x</em></span> axis in a scatterplot. For instance, lines can connect the points of a time series plot that will indicate the path of the time series, and such a connection would be meaningless in the scatterplot, which would be all over the place. The path will generally indicate the trend and as such, shows in which direction the series will go next. Changes in time series are easily depicted in the plot. We will now visualize the different time series.</p><p class="calibre7">The <code class="literal">plot.ts</code> function is central to the scheme of visualization here. An external graphical device of appropriate size is first invoked with the <code class="literal">windows</code> function. The <code class="literal">X11</code> function can be used in Ubuntu/Linux. Next, we run the <code class="literal">plot.ts</code> function on the <code class="literal">AirPassengers</code> dataset:</p><div class="informalexample"><pre class="programlisting">&gt; windows(height=100,width=150)
&gt; plot.ts(AirPassengers)</pre></div><p class="calibre7">The following plot shows an increase in the number of monthly passengers across the years, on average:</p><div class="mediaobject"><img src="../images/00467.jpeg" alt="Time series visualization" class="calibre10"/><div class="caption"><p class="calibre14">Figure 1: Monthly airline passenger count</p></div></div><p class="calibre11"> </p><p class="calibre7">We can see here that a pattern seems to be repeating itself after a cycle of 12 months, which indicates a seasonal trend across the months. It would be nice to obtain a plot where we select the first year and look at the plot across the months, then move to the next year and impose the next year's monthly data and visualize it, and so on until the entire data is displayed. A <code class="literal">plotts</code> function is created which achieves a plot of this description, and its structure is given in <span class="strong"><em class="calibre9">Figure 3</em></span>:</p><div class="mediaobject"><img src="../images/00468.jpeg" alt="Time series visualization" class="calibre10"/><div class="caption"><p class="calibre14">Figure 2: The time series frequency plot function</p></div></div><p class="calibre11"> </p><p class="calibre7">The <code class="literal">plotts</code> function is now applied on the <code class="literal">AirPassengers</code> data. The function is available in the <code class="literal">Utilities.R</code> file of the <a id="id500" class="calibre1"/>companion chapter code bundle, and it is invoked in the beginning of the <code class="literal">C11.R</code> file using the <code class="literal">source</code> command. The data has 12 years of data, and thus we will have 12 curves on the resulting time series plots. The <code class="literal">legend</code> of the plot will require more than the usual area, and hence we plot it on the right-hand side of the graph. The required manipulations are accomplished with the <code class="literal">par</code>, <code class="literal">mar</code>, and <code class="literal">legend</code> functions as follows:</p><div class="informalexample"><pre class="programlisting">&gt; par(mar=c(5.1, 4.1, 4.1, 8.1), xpd=TRUE)
&gt; plotts(AirPassengers)
&gt; legend("topright", inset=c(-0.2,0), "-",
+        legend=c(start(AirPassengers)[1]:end(AirPassengers)[1]),
+        col=start(AirPassengers)[1]:end(AirPassengers)[1],lty=2)</pre></div><p class="calibre7">We can now clearly see the seasonal impact in the following figure:</p><div class="mediaobject"><img src="../images/00469.jpeg" alt="Time series visualization" class="calibre10"/><div class="caption"><p class="calibre14">Figure 3: Seasonal plot for the AirPassengers dataset</p></div></div><p class="calibre11"> </p><p class="calibre7">The monthly passenger count <a id="id501" class="calibre1"/>visit hits a low in the months of February and November. The monthly passenger count increases steadily from February to July, remains at a similar level for August, and then decreases steeply until November. A slight increase can be seen for the months of December and January. Consequently, the seasonal plots give more insights, and they should be used complementarily with the <code class="literal">plot.ts</code> function. Hyndman's forecast package contains a function named <code class="literal">seasonalplot</code> which accomplishes the same result as the <code class="literal">plotts</code> function defined here.</p><p class="calibre7">The Australian residents dataset <code class="literal">austres</code> is covered next. The <code class="literal">plotts</code> function and legend will be used to enhance the display:</p><div class="informalexample"><pre class="programlisting">&gt;plot.ts(austres)
&gt;windows(height=100,width=150)
&gt;par(mar=c(5.1, 4.1, 4.1, 8.1), xpd=TRUE)
&gt;plotts(austres)
&gt;legend("topright", inset=c(-0.2,0), "-",
+        legend=c(start(austres)[1]:end(austres)[1]),
+        col=start(austres)[1]:end(austres)[1],lty=2)</pre></div><p class="calibre7">The following plot is a quarterly time series of the number of Australian residents:</p><div class="mediaobject"><img src="../images/00470.jpeg" alt="Time series visualization" class="calibre10"/><div class="caption"><p class="calibre14">Figure 4: Quarterly time series of the number of Australian residents</p></div></div><p class="calibre11"> </p><p class="calibre7">What is the difference between the seasonal plots of <span class="strong"><em class="calibre9">Figure 4</em></span> and <span class="strong"><em class="calibre9">Figure 5</em></span>? Of course, we are looking for differences other than the trivial monthly and quarterly periodicity. In <span class="strong"><em class="calibre9">Figure 5</em></span>, we can see that, although there is an increase in the quarterly number of monthly residents, it is hardly a seasonal factor; it appears to be more of a trend factor than a seasonal one. Thus, the seasonal<a id="id502" class="calibre1"/> contribution appears less in comparison with the <code class="literal">AirPassengers</code> dataset.</p><p class="calibre7">The time series plot for the carbon dioxide concentrations is visualized next. We use the <code class="literal">plot.ts</code> function on the <code class="literal">co2</code> dataset:</p><div class="informalexample"><pre class="programlisting">&gt;plot.ts(co2)</pre></div><p class="calibre7">The result of running the <code class="literal">plot.ts</code> function is the next output:</p><div class="mediaobject"><img src="../images/00471.jpeg" alt="Time series visualization" class="calibre10"/><div class="caption"><p class="calibre14">Figure 5: Visualization of the Mauna Loa atmospheric CO2 concentration</p></div></div><p class="calibre11"> </p><p class="calibre7">A seasonal impact is easily<a id="id503" class="calibre1"/> seen in the time series plot of the carbon dioxide concentrations. A seasonal plot might provide more insight, and we will use the <code class="literal">plotts</code> function next:</p><div class="informalexample"><pre class="programlisting">&gt;windows(height=100,width=150)
&gt;par(mar=c(5.1, 4.1, 4.1, 8.1), xpd=TRUE)
&gt;plotts(co2)
&gt;legend("topright",inset=c(-0.2,0),
+        "-",
+        legend=c(c(start(co2)[1]:(start(co2)[1]+3)),". . . ",
+                 c((end(co2)[1]-3):end(co2)[1])),
+        col=c(c(start(co2)[1]:(start(co2)[1]+3)),NULL,
+              c((end(co2)[1]-3):end(co2)[1])),lty=2)</pre></div><p class="calibre7">The <code class="literal">plotts</code> and <code class="literal">legend</code> functions have been used in the same way as previously. The result of the program is shown in <span class="strong"><em class="calibre9">Figure 7</em></span>, and we can clearly see the seasonal impact in the time series display:</p><div class="mediaobject"><img src="../images/00472.jpeg" alt="Time series visualization" class="calibre10"/><div class="caption"><p class="calibre14">Figure 6: Seasonal plot of the Mauna Loa Atmospheric CO2 concentration</p></div></div><p class="calibre11"> </p><p class="calibre7">
<span class="strong"><strong class="calibre8">Exercise</strong></span>: Use the <code class="literal">seasonalplot</code> function<a id="id504" class="calibre1"/> from the <code class="literal">forecast</code> package and replicate the seasonal plots. What is the difference here, if any?</p><p class="calibre7">The seasonality is an important aspect of the time series. It is important to identify it early so that an appropriate model is chosen for analysis of the time series. We will visualize three more time series datasets, <code class="literal">UKDriverDeaths</code>, <code class="literal">gas</code>, and <code class="literal">uspop</code>:</p><div class="informalexample"><pre class="programlisting">&gt;windows(height=100,width=300)
&gt;par(mfrow=c(1,3))
&gt;plot.ts(UKDriverDeaths,main="UK Driver Deaths")
&gt;plot.ts(gas,main="Australian monthly gas production")
&gt;plot.ts(uspop,main="Populations Recorded by the US Census")</pre></div><p class="calibre7">The three displays in <span class="strong"><em class="calibre9">Figure 7</em></span> are unlike any seen thus far. It seems unlikely that the models that fit well earlier will perform similarly here. We see a lot of variability for the <code class="literal">UKDriverDeaths</code> and <code class="literal">gas</code> datasets. For <code class="literal">UKDriverDeaths</code>, it appears that there was a decline in fatalities after the year <code class="literal">1983</code>. For the gas dataset, we can see that there was a regular seasonal impact until the year <code class="literal">1970</code>, and following that year, the <code class="literal">gas</code> productivity shot up drastically. It might <a id="id505" class="calibre1"/>be an indication of some technological breakthrough or some other phenomenological changes. The variability also increases, and barely appears constant across the time horizon. The <code class="literal">uspop</code> shows an exponential growth.</p><p class="calibre7">
<span class="strong"><strong class="calibre8">Exercise</strong></span>: Visually inspect if there is a seasonal impact for the <code class="literal">UKDriverDeaths</code> and <code class="literal">gas</code> datasets:</p><div class="mediaobject"><img src="../images/00473.jpeg" alt="Time series visualization" class="calibre10"/><div class="caption"><p class="calibre14">Figure 7: Three time series plots: UKDriverDeaths, gas, and uspop</p></div></div><p class="calibre11"> </p></div></div>

<div class="book" title="Time series datasets">
<div class="book" title="Core concepts and metrics"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch11lvl1sec84" class="calibre1"/>Core concepts and metrics</h2></div></div></div><p class="calibre7">The visualization of the time series data has conveyed a similar story in all the examples, from <span class="strong"><em class="calibre9">Figure 1</em></span> to <span class="strong"><em class="calibre9">Figure 7</em></span>. The trend and<a id="id506" class="calibre1"/> seasonality of the observations imply that the future values of the time series are dependent on the current values, and thus we can't assume that the observations are independent of each other. But what does this mean? To reiterate the point, consider the simpler <code class="literal">uspop</code> (US population) dataset, the third-right panel display of <span class="strong"><em class="calibre9">Figure 7</em></span>. Here, we don't have a seasonal influence. Now, consider the census year 1900. The population at the next census is certainly not less than in the year 1890, and it is not well beyond the same number of the same year. A similar narrative holds for most time series; for example, if we are recording the maximum temperature of the day. Here, if today's maximum temperature is 42°C, the next day's maximum temperature is highly influenced by this number and it is almost completely ruled out that the next day's maximum temperature will be either 55°C or 25°C. Although it is easily seen that the observations are dependent on each other, the formal specification is also a challenge in itself. Let us formally introduce a time series.</p><p class="calibre7">We will denote a time series by <span class="strong"><img src="../images/00474.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>that is observed at times <span class="strong"><img src="../images/00475.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>. An alternative notation for a time series observed up to time T is <span class="strong"><img src="../images/00476.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>. A time series may be conceptualized as a stochastic process Y observed at times t =1, 2, 3, …. Associated with the time series process <span class="strong"><img src="../images/00474.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> is the error process <span class="strong"><img src="../images/00477.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>. The error process is generally assumed to be a white noise process with zero mean and some constant variance. The error process is often referred to as the innovation process. Note that the time series <span class="strong"><img src="../images/00478.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> might depend on the past values of the process in <span class="strong"><img src="../images/00479.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>, as well as the values of error <span class="strong"><img src="../images/00480.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> and the past values of the error process <span class="strong"><img src="../images/00481.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>. The value <span class="strong"><img src="../images/00482.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> is also referred to as the first lag value of <span class="strong"><img src="../images/00478.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>, <span class="strong"><img src="../images/00483.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> the second lag value of <span class="strong"><img src="../images/00478.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>, and so on. Now, if the observations are dependent on each other, the specification of the relationship between them is the biggest challenge. Of course, we can't go into detail here. However, if we believe that the first-order lagged terms are dependent, there must be a relationship here, and we can obtain a scatterplot with the observations <span class="strong"><img src="../images/00478.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> on the y-axis and the first-order lagged terms on the x-axis. The first-order lagged scatterplot for the <code class="literal">AirPassengers</code> dataset is obtained as follows:</p><div class="informalexample"><pre class="programlisting">&gt;plot(AirPassengers[1:143],AirPassengers[2:144],
+      xlab="Previous Observation",
+      ylab="Current Observation")</pre></div><p class="calibre7">The use of indexing changes the class of time series objects to a numeric object:</p><div class="mediaobject"><img src="../images/00484.jpeg" alt="Core concepts and metrics" class="calibre10"/><div class="caption"><p class="calibre14">Figure 8: Lag plot of the AirPassengers dataset</p></div></div><p class="calibre11"> </p><p class="calibre7">In the preceding graphical display, we can clearly see that there is (almost) a linear relationship between the lagged observations, and thus a model might be of the form <span class="strong"><img src="../images/00485.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>. Can the scatterplot<a id="id507" class="calibre1"/> help in determining the order of the dependency? Hardly! We will obtain a plot of the <code class="literal">WWWusage</code> dataset next and look at the lagged plots:</p><div class="informalexample"><pre class="programlisting">&gt;windows(height=200,width=200)
&gt;par(mfrow=c(2,2))
&gt;plot.ts(WWWusage)
&gt;plot(WWWusage[1:99],WWWusage[2:100],
+      xlab="Previous Observation",
+      ylab="Current Observation",main="Lag-1 Plot"
+      )
&gt;plot(WWWusage[1:98],WWWusage[3:100],
+      xlab="Previous Observation",
+      ylab="Current Observation",main="Lag-2 Plot"
+      )
&gt;plot(WWWusage[1:97],WWWusage[4:100],
+      xlab="Previous Observation",
+      ylab="Current Observation",main="Lag-3 Plot"
+      )</pre></div><p class="calibre7">Following are the lagged plots for <code class="literal">WWWUsage</code>:</p><div class="mediaobject"><img src="../images/00486.jpeg" alt="Core concepts and metrics" class="calibre10"/><div class="caption"><p class="calibre14">Figure 9: Lagged plots for WWWUsage</p></div></div><p class="calibre11"> </p><p class="calibre7">The first lagged plot might give the impression that the observations are correlated. However, the higher-order lagged plots barely make any sense, and going back to the first-order lagged plot creates more confusion. As a consequence, we need a more formal method of obtaining insights on the order of lags.</p><p class="calibre7">The two measures that are <a id="id508" class="calibre1"/>useful for understanding the nature of dependency in time series data are <span class="strong"><strong class="calibre8">auto-correlation function</strong></span> (<span class="strong"><strong class="calibre8">ACF</strong></span>) and <span class="strong"><strong class="calibre8">partial auto-correlation function</strong></span> (<span class="strong"><strong class="calibre8">PACF</strong></span>). As the name suggests, ACF is the correlation of a time series with its <a id="id509" class="calibre1"/>own lagged values. The PACF's partial nomenclature accounts for removing the impact of intermediate variables from the lagged one. In simple terms, the PACF for lag 3 will include only the first <span class="strong"><img src="../images/00478.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>; third lagged variables <span class="strong"><img src="../images/00487.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> and the <span class="strong"><img src="../images/00488.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> variables are not allowed to influence the PACF. The lag-k ACF is defined as the correlation between the random variable <span class="strong"><em class="calibre9">Y</em></span>
<span class="strong"><em class="calibre9">t</em></span> and the k-th lagged variable <span class="strong"><em class="calibre9">Y</em></span>
<span class="strong"><em class="calibre9">t-k</em></span>:</p><div class="mediaobject"><img src="../images/00489.jpeg" alt="Core concepts and metrics" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">Where <span class="strong"><img src="../images/00490.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> is the variance of the time series. The partial autocorrelation function PACF between <span class="strong"><em class="calibre9">Yt</em></span> and its k-th lag <span class="strong"><em class="calibre9">Yt-k</em></span> is the partial correlation of the time series when controlling the values at shorter lags <span class="strong"><em class="calibre9">Y</em></span>
<span class="strong"><em class="calibre9">t-1</em></span>, <span class="strong"><em class="calibre9">Y</em></span>
<span class="strong"><em class="calibre9">t-2</em></span>, <span class="strong"><em class="calibre9">…,</em></span> <span class="strong"><em class="calibre9">Y</em></span>
<span class="strong"><em class="calibre9">t-k+1</em></span>. It is not possible to go into the mathematical details of the PACF concept; the reader may refer to Box et al. (2015) for more information. The sample ACF formula, based on <span class="strong"><em class="calibre9">n</em></span> observations, is given using the following:</p><div class="mediaobject"><img src="../images/00491.jpeg" alt="Core concepts and metrics" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">For an explicit formula of the PACF, we<a id="id510" class="calibre1"/> refer the reader to the document available on the web at <a class="calibre1" href="http://mondi.web.elte.hu/spssdoku/algoritmusok/acf_pacf.pdf">http://mondi.web.elte.hu/spssdoku/algoritmusok/acf_pacf.pdf</a>.</p><p class="calibre7">In spite of the intimidating formula, we have an easy getaway by simply using the <code class="literal">acf</code> and <code class="literal">pacf</code> functions on two datasets, <code class="literal">austres</code> and <code class="literal">uspop</code>:</p><div class="informalexample"><pre class="programlisting">&gt;jpeg("ACF_PACF_Plots.jpeg")
&gt;par(mfrow=c(2,2))
&gt;acf(austres,main="ACF of Austres Data")
&gt;pacf(austres,main="PACF of Austres Data")
&gt;acf(uspop,main="ACF of US Population")
&gt;pacf(uspop,main="PACF of US Population")
&gt;dev.off()
RStudioGD 
        2 </pre></div><p class="calibre7">We will keep the interpretation of ACF and PACF plots simpler. The important guideline in ACF and PACF plots are the horizontal blue lines. Any lagged ACF and PACF plots beyond the two lines are significant, and those within the limits are insignificant:</p><div class="mediaobject"><img src="../images/00492.jpeg" alt="Core concepts and metrics" class="calibre10"/><div class="caption"><p class="calibre14">Figure 10: ACF and PACF plots for austres and uspop datasets</p></div></div><p class="calibre11"> </p><p class="calibre7">We can see from <span class="strong"><em class="calibre9">Figure 10</em></span> for the <code class="literal">austres</code> time series that we need to extend the ACF plot to include more lags. This is because all plotted lags are beyond the horizontal blue lines. For the <code class="literal">uspop</code> time series, the first time series, the first four lags are significant and the rest are within the horizontal blue lines. The PACF plots can be interpreted in a similar way.</p><p class="calibre7">The ACF and PACF plots play an<a id="id511" class="calibre1"/> important role in the identification of the ARMA models. Even if the plots reveal information about the lag for the case of AR, it can be used to specify the number of previous values of the time series as part of the input vector for a neural network adapted for the time series data.</p><p class="calibre7">In many practical problems, we have additional variables, and we might refer to these as covariate time series or exogenous variables. Let us denote the covariate time series by <span class="strong"><img src="../images/00493.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>, where <span class="strong"><img src="../images/00494.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> might be a scalar or vector time series. We adopt the convention that only the current and past values of <span class="strong"><img src="../images/00495.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>, will influence <span class="strong"><img src="../images/00478.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> and that the future values of <span class="strong"><img src="../images/00496.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> will not impact <span class="strong"><img src="../images/00478.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> in any manner. That is, only the lagged values of the covariates will have influence, as opposed to their lead values. In the <code class="literal">Car Sales</code> dataset, the sales are the time series of interest, and it is the advertising aspect that we believe impacts the sales; sales can't possibly explain the advertisement amount! The <code class="literal">ccf</code> function is used to obtain the cross-correlation coefficients as follows:</p><div class="informalexample"><pre class="programlisting">&gt;CarSales &lt;- read.csv("../Data/Car_Sales.csv")
&gt;summary(CarSales)
     Sales       Advertising  
 Min.   :12.0   Min.   : 1.0  
 1st Qu.:20.3   1st Qu.:15.8  
 Median :24.2   Median :23.0  
 Mean   :24.3   Mean   :28.5  
 3rd Qu.:28.6   3rd Qu.:41.0  
 Max.   :36.5   Max.   :65.0  
&gt;jpeg("CCF_Car_Sales_Advertising.jpeg")
&gt;ccf(x=CarSales$Advertising,y=CarSales$Sales,
+     main="Cross Correlation Between Sales and Advertising")
&gt;dev.off()
RStudioGD 
        2 </pre></div><p class="calibre7">The following figure shows the cross correlation between sales and advertising:</p><div class="mediaobject"><img src="../images/00497.jpeg" alt="Core concepts and metrics" class="calibre10"/><div class="caption"><p class="calibre14">Figure 11: Cross-correlation coefficients for advertising spend and car sales</p></div></div><p class="calibre11"> </p><p class="calibre7">Should we look at the positive lag values or the negative lag values? Note that the <code class="literal">ccf</code> plot is not symmetrical, and hence we can't be absolved for ignoring the signs of the lag values. On running <code class="literal">?ccf</code> at the R terminal, we get <code class="literal">The lag k value returned by ccf(x, y) from the help file, which estimates the correlation between x[t+k] and y[t]</code>. Consequently, the positive lags are the lead-ins, while the negative lags are of interest to us. In this example, only the previous lags of <span class="strong"><img src="../images/00494.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>, (that is, <span class="strong"><img src="../images/00494.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> and <span class="strong"><img src="../images/00498.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>) are significant.</p><p class="calibre7">We close this section with a brief discussion of the accuracy measurements. As with earlier learning problems, we will have a slew of models available for us. This is the main topic of discussion in the next section, and we need to define certain assessment metrics accordingly. Let <span class="strong"><img src="../images/00474.jpeg" alt="Core concepts and metrics" class="calibre15"/></span> denote the time series and, as a consequence of using a certain model, the fitted values will be <span class="strong"><img src="../images/00499.jpeg" alt="Core concepts and metrics" class="calibre15"/></span>. We can access the accuracy of the models through various methods; some of the accuracy measurements include the following:</p><div class="mediaobject"><img src="../images/00500.jpeg" alt="Core concepts and metrics" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">For the moment, we will not concern <a id="id512" class="calibre1"/>ourselves with the model. Instead, we will use it as a main tool to extract fitted values and help in obtaining the defined metrics. Using the <code class="literal">subset</code> function, we will define the training dataset and fit a model using the <code class="literal">auto.arima</code> function from the <code class="literal">forecast</code> package. Using the <code class="literal">accuracy</code> and <code class="literal">forecast</code> functions, we will then obtain the different accuracies:</p><div class="informalexample"><pre class="programlisting">&gt;co2_sub &lt;- subset(co2,start=1,end=443)
&gt;co2_arima &lt;- auto.arima(co2_sub)
&gt;accuracy(forecast(co2_arima,h=25),x=co2[444:468])
                  ME  RMSE   MAE      MPE   MAPE  MASE   ACF1
Training set  0.0185 0.283 0.225  0.00541 0.0672 0.211 0.0119
Test set     -0.0332 0.349 0.270 -0.00912 0.0742 0.252     NA</pre></div><p class="calibre7">The <code class="literal">forecast</code> function is a very important one. Given a fitted time series, it will provide predictions for the future periods as requested, and the accuracy function computes the required accuracy for the seven different criteria. The mean error criteria is often useless, and for near unbiased models, its numerical value will be in the vicinity of 0. The metrics RMSE, MAE, MPE, and MAPE are often useful, and the lower their values, the better the model fit is. Furthermore, the training <a id="id513" class="calibre1"/>set error and test set error must be comparable. If they are very different from one other, then the model is not useful for forecasts. In the following section, we will review a class of useful time series models.</p></div></div>

<div class="book" title="Time series datasets">
<div class="book" title="Essential time series models"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch11lvl1sec85" class="calibre1"/>Essential time series models</h2></div></div></div><p class="calibre7">We have encountered a <a id="id514" class="calibre1"/>set of models for the different regression models thus far. Time series data brings additional complexity, and hence we have even more models to choose from (or rather, ensemble from). A quick review of the important models is provided here. Most of the models discussed here deal with univariate time series <span class="strong"><img src="../images/00474.jpeg" alt="Essential time series models" class="calibre15"/></span>, and we need even more specialized models and methods to incorporate <span class="strong"><img src="../images/00493.jpeg" alt="Essential time series models" class="calibre15"/></span>. We will begin with the simplest possible time series model and then move up to the neural network implementations.</p><div class="book" title="Naïve forecasting"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec60" class="calibre1"/>Naïve forecasting</h3></div></div></div><p class="calibre7">Suppose that we have the data <span class="strong"><img src="../images/00501.jpeg" alt="Naïve forecasting" class="calibre15"/></span>, and we <a id="id515" class="calibre1"/>need forecasts for the next <span class="strong"><em class="calibre9">h</em></span> time points <span class="strong"><img src="../images/00502.jpeg" alt="Naïve forecasting" class="calibre15"/></span>. The naïve forecast model does not require any modeling exercises or computations, it simply returns the current value as future predictions, and thus <span class="strong"><img src="../images/00503.jpeg" alt="Naïve forecasting" class="calibre15"/></span>. It's that simple. Even for this simple task, we will use the naïve function from the forecast package and ask it to provide the forecast for the next <code class="literal">25</code> observations with <code class="literal">h=25</code>:</p><div class="informalexample"><pre class="programlisting">&gt;co2_naive &lt;- naive(co2_sub,h=25,level=c(90,95))
&gt;summary(co2_naive)

Forecast method: Naive method

Model Information:
Call: naive(y = co2_sub, h = 25, level = c(90, 95)) 

Residual sd: 1.1998 

Error measures:
              ME RMSE  MAE   MPE  MAPE  MASE  ACF1
Training set 0.1  1.2 1.07 0.029 0.319 0.852 0.705

Forecasts:
         Point Forecast Lo 90 Hi 90 Lo 95 Hi 95
Dec 1995            360   358   362   357   362
Jan 1996            360   357   362   356   363
Feb 1996            360   356   363   356   364

Oct 1997            360   350   369   348   371
Nov 1997            360   350   369   348   371
Dec 1997            360   350   370   348   371</pre></div><p class="calibre7">As anticipated, the forecast values remain the same throughout the period. They can be visualized easily, and the accuracies can also be easily computed as follows:</p><div class="informalexample"><pre class="programlisting">&gt;plot(co2_naive) # Output suppressed
&gt;accuracy(forecast(co2_naive,h=25),x=co2[444:468])
               ME RMSE  MAE   MPE  MAPE MASE  ACF1
Training set 0.10 1.20 1.07 0.029 0.319 1.00 0.705
Test set     3.54 4.09 3.55 0.972 0.974 3.32    NA</pre></div><p class="calibre7">The natural question that arises is <a id="id516" class="calibre1"/>whether the naïve forecasts are any good. An answer to this can be provided in other ways. Complex and sophisticated models will always claim to have advantages and merits. The models might indeed have advantages, but the reference and benchmarking should be clear. The naïve forecasts provide this important benchmark. Note that, for the training period, the accuracy values are different for the naïve forecasts, and it is important that the proposed models are at least better than the metrics of the naïve forecasts. This is the main purpose of the naïve forecasts.</p></div><div class="book" title="Seasonal, trend, and loess fitting"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec61" class="calibre1"/>Seasonal, trend, and loess fitting</h3></div></div></div><p class="calibre7">Season, trend, and loess are<a id="id517" class="calibre1"/> the three technical words that are combined to form the stl model. Earlier, we saw in the visual displays of the time series that some of<a id="id518" class="calibre1"/> them depict seasonal effects, some show a trend, some show a combination of both seasonal and trend, and some are simply irregular time series. The <a id="id519" class="calibre1"/>displays thus indicate the presence or absence of the specific nature of the underlying phenomenon. In this section, we will look at how to make use of the seasonal and trend part of the time series. The third component of the stl model in loess is not explained at all. Loess is a nonparametric regression technique, and stands for local polynomial regression, which generalizes the weighted least squares criteria to a p-th order polynomial. The loess method also <a id="id520" class="calibre1"/>consists of a vital component known as kernel. Kernel is a smoothing method, but we will not go into too much detail about this.</p><p class="calibre7">Cleveland et al. (1990) proposed a<a id="id521" class="calibre1"/> seasonal-trend decomposition based on the loess, and the full <a id="id522" class="calibre1"/>details of the procedure can be obtained from the following source: <a class="calibre1" href="http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/stl-a-seasonal-trend-decomposition-procedure-based-on-loess.pdf">http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/stl-a-seasonal-trend-decomposition-procedure-based-on-loess.pdf</a>. This paper is readable, intuitive, and insightful, and the reader should truly follow it. The stl model is a filtering method that decomposes a seasonal time series in three parts: trend, seasonal, and remainder. Let <span class="strong"><img src="../images/00501.jpeg" alt="Seasonal, trend, and loess fitting" class="calibre15"/></span> be the time series, and we denote trend, seasonal, and remainder parts by <span class="strong"><img src="../images/00504.jpeg" alt="Seasonal, trend, and loess fitting" class="calibre15"/></span>, <span class="strong"><img src="../images/00505.jpeg" alt="Seasonal, trend, and loess fitting" class="calibre15"/></span>, and <span class="strong"><img src="../images/00506.jpeg" alt="Seasonal, trend, and loess fitting" class="calibre15"/></span>; then we will have the following:</p><div class="mediaobject"><img src="../images/00507.jpeg" alt="Seasonal, trend, and loess fitting" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">Refer to Cleveland et al.'s paper for complete details.</p><p class="calibre7">Using the <code class="literal">stl</code> function from the <code class="literal">stats</code> package, we decompose the <code class="literal">AirPassengers</code> data as follows:</p><div class="informalexample"><pre class="programlisting">&gt;AP_stl &lt;- stl(AirPassengers,s.window=frequency(AirPassengers))
&gt;summary(AP_stl)
 Call:
 stl(x = AirPassengers, s.window = frequency(AirPassengers))

 Time.series components:
    seasonal         trend       remainder    
 Min.   :-73.3   Min.   :123   Min.   :-36.2  
 1st Qu.:-25.1   1st Qu.:183   1st Qu.: -6.4  
 Median : -5.5   Median :260   Median :  0.3  
 Mean   :  0.1   Mean   :280   Mean   : -0.2  
 3rd Qu.: 20.4   3rd Qu.:375   3rd Qu.:  5.9  
 Max.   : 94.8   Max.   :497   Max.   : 48.6  
 IQR:
     STL.seasonal STL.trend STL.remainder data 
      46          192        12           180  
   %  25.2        106.4       6.8         100.0

 Weights: all == 1

 Other components: List of 5
 $ win  : Named num [1:3] 12 21 13
 $ deg  : Named int [1:3] 0 1 1
 $ jump : Named num [1:3] 2 3 2
 $ inner: int 2
 $ outer: int 0
&gt;jpeg("STL_Decompose_AirPassengers.jpeg")
&gt;plot(AP_stl)
&gt;dev.off()
windows 
      2 
&gt;accuracy(forecast(AP_stl))
                  ME RMSE  MAE    MPE MAPE  MASE     ACF1
Training set 0.00498 11.2 8.29 -0.129 3.29 0.259 0.000898</pre></div><p class="calibre7">By executing the preceding code, the following graph plot is obtained:</p><div class="mediaobject"><img src="../images/00508.jpeg" alt="Seasonal, trend, and loess fitting" class="calibre10"/><div class="caption"><p class="calibre14">Figure 12: STL decompose of AirPassengers</p></div></div><p class="calibre11"> </p><p class="calibre7">It is important to <a id="id523" class="calibre1"/>specify the seasonality through the <code class="literal">s.window</code> option in the <code class="literal">stl</code> function. From <a id="id524" class="calibre1"/>the seasonal plot, we can see that each component increases with time. However, we get a clear picture of the different components of the<a id="id525" class="calibre1"/> passenger count over time. Though the seasonal part increases in magnitude, the pattern remains the same throughout the period. The trend shows a linear increase, which indicates the direction in which the series is headed. It is clear that seasonality plays an important role in this context.</p><p class="calibre7"><span class="strong"><strong class="calibre8">Exercise</strong></span>: It has been previously remarked that seasonality does not appear to be a useful factor in the analysis of the <code class="literal">austres</code> dataset. Use the <code class="literal">stl</code> decomposition and check whether the observation holds true.</p><p class="calibre7">A more parametric model will be considered next, in the form of an exponential smoothing model.</p></div><div class="book" title="Exponential smoothing state space model"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec62" class="calibre1"/>Exponential smoothing state space model</h3></div></div></div><p class="calibre7">The basic exponential smoothing<a id="id526" class="calibre1"/> model can be clearly defined. Denote the smoothing factor by <span class="strong"><img src="../images/00509.jpeg" alt="Exponential smoothing state space model" class="calibre15"/></span>, and initialize <span class="strong"><img src="../images/00510.jpeg" alt="Exponential smoothing state space model" class="calibre15"/></span>. The basic exponential smoothing model is defined as follows:</p><div class="mediaobject"><img src="../images/00511.jpeg" alt="Exponential smoothing state space model" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">The details of the exponential models<a id="id527" class="calibre1"/> can be found at <a class="calibre1" href="https://labs.omniti.com/people/jesus/papers/holtwinters.pdf">https://labs.omniti.com/people/jesus/papers/holtwinters.pdf</a>. A more general model form is the <span class="strong"><strong class="calibre8">exponential smoothing state space model</strong></span>. Here, a model is specified on three fronts, as in the<a id="id528" class="calibre1"/> stl model: the error component, the trend component, and the third is the seasonal component. In the <code class="literal">ets</code> function of the forecast package, the component can have <span class="strong"><strong class="calibre8">additive</strong></span> effect denoted by <span class="strong"><strong class="calibre8">A</strong></span>, it can have a <span class="strong"><strong class="calibre8">multiplicative</strong></span> effect, denoted by M, or it might be asked to be automatically selected (Z), and this specification is<a id="id529" class="calibre1"/> possible for each of the components. The effect can be specified to be neither additive nor multiplicative with the letter N. A model in the <code class="literal">ets</code> function is thus specified with the first letter for error component, the second letter for the trend component, and the third letter for the seasonal component. Consequently, the notation <code class="literal">model="ZZZ"</code> means that each of the three components is selected automatically. <code class="literal">model="AMZ"</code> means that the error component is additive, the trend is multiplicative, the seasonal component is automatically chosen, and so on. Hyndman et al. (2008) provides a comprehensive account of the details of exponential smoothing methods. Next, we will use the <code class="literal">ets</code> function from the <code class="literal">forecast</code> package to fit the exponential smoothing model:</p><div class="informalexample"><pre class="programlisting">&gt;uspop_sub &lt;- subset(uspop,start=1,end=15)
&gt;USpop_ets &lt;- ets(uspop_sub)
&gt;summary(USpop_ets)
ETS(A,A,N) 

Call:
 ets(y = uspop_sub) 

  Smoothing parameters:
    alpha = 0.8922 
    beta  = 0.8922 

  Initial states:
    l = 2.3837 
    b = 1.7232 

  sigma:  1.68

 AIC AICc  BIC 
66.2 72.8 69.7 

Training set error measures:
               ME RMSE MAE  MPE MAPE   MASE  ACF1
Training set 1.11 1.68 1.4 3.26  4.6 0.0318 -0.28</pre></div><p class="calibre7">The <code class="literal">ets</code> function has fit an additive error for the error and trend component, while choosing not to add<a id="id530" class="calibre1"/> any of it for the seasonal factor. This makes sense because there is no seasonal component for the <code class="literal">uspop</code> dataset. Using this fitted model, we will <code class="literal">forecast</code> the US population for the period of 1940–70, calculate the accuracies for the training and test dataset with the <code class="literal">accuracy</code> function, and also compare with the <code class="literal">naive</code> forecasts:</p><div class="informalexample"><pre class="programlisting">&gt;forecast(USpop_ets,h=4)
     Point Forecast Lo 80 Hi 80 Lo 95 Hi 95
1940            139   137   141   136   142
1950            156   151   160   149   162
1960            172   165   180   161   183
1970            189   178   200   173   205
&gt;plot(forecast(USpop_ets,h=4))
&gt;accuracy(forecast(USpop_ets,h=4),x=uspop[16:19])
               ME RMSE  MAE   MPE MAPE  MASE  ACF1
Training set 1.11 1.68 1.40 3.259 4.60 0.165 -0.28
Test set     2.33 9.02 8.26 0.578 4.86 0.973    NA
&gt;accuracy(forecast(naive(uspop_sub),h=4),x=uspop[16:19])
                ME  RMSE   MAE  MPE MAPE MASE  ACF1
Training set  8.49  9.97  8.49 21.7 21.7 1.00 0.778
Test set     43.58 51.35 43.58 24.2 24.2 5.13    NA</pre></div><p class="calibre7">Following is a plot depicting exponential smoothing for US population data:</p><div class="mediaobject"><img src="../images/00512.jpeg" alt="Exponential smoothing state space model" class="calibre10"/><div class="caption"><p class="calibre14">Figure 13: Exponential smoothing for US population data</p></div></div><p class="calibre11"> </p><p class="calibre7">The accuracy <a id="id531" class="calibre1"/>comparison is performed with the naïve forecasts, and we find that there is a significant improvement with the <code class="literal">ets</code> forecasts. Consequently, the <code class="literal">ets</code> forecasts are useful, and we can use them for future predictions.</p><p class="calibre7">Next, we will move on to the popular Box-Jenkins/ARIMA models.</p></div><div class="book" title="Auto-regressive Integrated Moving Average (ARIMA) models"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec63" class="calibre1"/>Auto-regressive Integrated Moving Average (ARIMA) models</h3></div></div></div><p class="calibre7">Box and Jenkins' approach<a id="id532" class="calibre1"/> to time series with the ARIMA models changed the way analysis and forecasts of time series data is<a id="id533" class="calibre1"/> performed. The ARIMA model is a special case of the more general linear process model, and for the time series <span class="strong"><img src="../images/00474.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre15"/></span> with the innovation process <span class="strong"><img src="../images/00477.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre15"/></span>, it is given as follows:</p><div class="mediaobject"><img src="../images/00513.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">Here, <span class="strong"><img src="../images/00514.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre15"/></span> are the coefficients of the linear process. Note that there is no restriction on the lagged values of the innovation process and we indeed mean that there are infinite terms in this linear process model. In the popular autoregressive AR(p) model, p is the order of the AR model. This is given using the following:</p><div class="mediaobject"><img src="../images/00515.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">The AR model can be shown to be a particular case of the linear process model. When the time series is expressed in terms of the innovation process, another useful model is the moving average MA(q) model of order q:</p><div class="mediaobject"><img src="../images/00516.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">A time series might depend on past errors as well as past values, and such a structural dependency is captured in an autoregressive moving average <code class="literal">ARMA(p,q)</code> model of order <code class="literal">(p,q)</code>:</p><div class="mediaobject"><img src="../images/00517.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">The order of <span class="strong"><em class="calibre9">p</em></span> and <span class="strong"><em class="calibre9">q</em></span> can be decided by the rule of thumb related through ACF and PACF in <span class="strong"><em class="calibre9">Table 2</em></span>:</p><div class="mediaobject"><img src="../images/00518.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre10"/><div class="caption"><p class="calibre14">Table 2: ACF and PACF for ARMA models</p></div></div><p class="calibre11"> </p><p class="calibre7">The ARMA models work well with stationary time series data, and here stationary loosely means that the variability of the series is constant throughout. It is a restrictive assumption, and for many time<a id="id534" class="calibre1"/> series phenomena, it does not hold true. In many practical scenarios, it has been that stationary can be obtained by differencing the series <span class="strong"><img src="../images/00474.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre15"/></span>, that is, we can consider the difference <span class="strong"><img src="../images/00519.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre15"/></span>. The difference <span class="strong"><img src="../images/00520.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre15"/></span> is a first-order difference, and sometimes, one may require higher order difference. In most practical scenarios, differencing up to order 4 has been known to bring stationarity. The order of differencing is generally denoted by the letter d, and applying ARMA models on the difference is referred to as an autoregressive integrated moving average model, or ARIMA model. A succinct abbreviation is <code class="literal">ARIMA(p,d,q)</code>.</p><p class="calibre7">We have come across the seasonal <a id="id535" class="calibre1"/>component too often in this chapter, and it is accommodated in ARIMA through seasonal ARIMA models. The motivated reader can go through Chapter 10 of Tattar et al. (2017) for more details. We will simply add here that we have further notation in capital letters (P, D, Q) for the seasonal parameters, along with the frequency term. We are now in a position to understand the fitted model at the end of the previous section. The <code class="literal">co2_arima</code> accuracy had been accessed, and we will now look at the summary:</p><div class="informalexample"><pre class="programlisting">&gt;summary(co2_arima)
Series: co2_sub 
ARIMA(2,1,2)(1,1,2)[12] 

Coefficients:
        ar1    ar2     ma1     ma2    sar1   sma1    sma2
      0.033  0.250  -0.369  -0.246  -0.828  0.014  -0.750
s.e.  0.341  0.122   0.342   0.197   0.230  0.210   0.173

sigma^2 estimated as 0.0837:  log likelihood=-73.4
AIC=163   AICc=163   BIC=195

Training set error measures:
                 ME  RMSE   MAE     MPE   MAPE  MASE   ACF1
Training set 0.0185 0.283 0.225 0.00541 0.0672 0.179 0.0119</pre></div><p class="calibre7">The best fit ARIMA model order is <code class="literal">(2,1,2)(1,1,2)[12]</code>, which means that the seasonal frequency is at <code class="literal">12</code> (something we already knew), and that the seasonal order (P,D,Q) is <code class="literal">(1,1,2)</code> and the ARIMA order (p,d,q) is <code class="literal">(2,1,2)</code>. It is this differencing order that achieves stationarity. The forecasts are obtained and then visualized:</p><div class="informalexample"><pre class="programlisting">&gt;jpeg("CO2_Forecasts.jpeg")
&gt;plot(forecast(co2_arima,h=25))</pre></div><p class="calibre7">The following figure shows the output:</p><div class="mediaobject"><img src="../images/00521.jpeg" alt="Auto-regressive Integrated Moving Average (ARIMA) models" class="calibre10"/><div class="caption"><p class="calibre14">Figure 14: CO2 forecast</p></div></div><p class="calibre11"> </p><p class="calibre7">Consequently, we have fitted the ARIMA<a id="id536" class="calibre1"/> models for the carbon dioxide concentration levels.</p><p class="calibre7">Next, we will look at the nonlinear neural network time series models.</p></div><div class="book" title="Auto-regressive neural networks"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec64" class="calibre1"/>Auto-regressive neural networks</h3></div></div></div><p class="calibre7">Neural networks have <a id="id537" class="calibre1"/>previously been seen in action for classification as well as regression problems. Since the time series are dependent observations, we need to tweak the architecture of neural networks to incorporate the dependency. The tweaking is to allow the lagged values of the time series as the members of the input layer. The rest of the architecture follows the same structure as the usual neural network. The <code class="literal">nnetar</code> function in the <code class="literal">forecast</code> stands for neural network autoregressive, and the <code class="literal">p=</code> option allows the lagged values of the time series, which we apply to the <code class="literal">gas</code> problem:</p><div class="informalexample"><pre class="programlisting">&gt;gas_sub &lt;- subset(gas,start=1,end=450)
&gt;gas_nnetar &lt;- nnetar(gas_sub,p=25,P=12,size=10,repeats=10)
&gt;plot(forecast(gas_nnetar,h=26))
&gt;accuracy(forecast(gas_nnetar,h=26),x=gas[451:476])
               ME RMSE  MAE    MPE  MAPE  MASE    ACF1
Training set    2  318  237 -0.127  1.78 0.148 -0.0879
Test set     5033 6590 5234 10.566 10.94 3.276      NA</pre></div><div class="mediaobject"><img src="../images/00522.jpeg" alt="Auto-regressive neural networks" class="calibre10"/><div class="caption"><p class="calibre14">Figure 15: Gas forecast using auto-regressive neural network</p></div></div><p class="calibre11"> </p><p class="calibre7">We have now seen the autoregressive neural network in action.</p></div><div class="book" title="Messing it all up"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch11lvl2sec65" class="calibre1"/>Messing it all up</h3></div></div></div><p class="calibre7">We began the chapter with a brief introduction of seven datasets and a mention of 21 datasets in <span class="strong"><em class="calibre9">Table 1</em></span>. The data visualization provides moderate insight, and the accuracy metrics are useful in analyzing the usefulness of the models. A series of models have been introduced in this section up to now, and now we will mess it all up. A <code class="literal">get_Accuracy</code> function, which will fit six different time series models, is defined. The <span class="strong"><strong class="calibre8">LM</strong></span>, which stands for <span class="strong"><strong class="calibre8">linear model</strong></span>, has not been explained; neither has the TBATS model. The linear model is very simple, in that<a id="id538" class="calibre1"/> the time index is <a id="id539" class="calibre1"/>taken as a covariate. In general, if a time series has T observations, the covariate vector simply consists of the values 1, 2, 3, …, T. We expect the linear model to perform poorly. The TBATS model won't be explained in further detail here and so it is recommended to do some extra reading in order to get more information on this. The <code class="literal">get_Accuracy</code> model fits each of the six models to the 21 datasets, names the model, and enlists its performance over the entire dataset. The following<a id="id540" class="calibre1"/> program gets the desired results:</p><div class="informalexample"><pre class="programlisting">&gt;get_Accuracy&lt;- function(ts){
+   tsname &lt;- deparse(substitute(ts))
+   Acc_Mat &lt;- data.frame(TSName = rep(tsname,6),Models=c(
+               "ETS","STL","LM","ARIMA","NNETAR","TBATS"),
+                ME=numeric(6),RMSE=numeric(6),MAE=numeric(6),
+                MPE=numeric(6), MAPE=numeric(6),MASE=numeric(6))
+   for(i in 1:nrow(Acc_Mat)){
+     Acc_Mat[1,3:8] &lt;- accuracy(ets(ts)$fitted,ts)[1:6]
+     if(frequency(ts)&gt;1) Acc_Mat[2,3:8] &lt;- accuracy(ts-stl(ts,
+            frequency(ts))$time.series[,3],ts)[1:6] else
+       Acc_Mat[2,3:8] &lt;- NA
+     Acc_Mat[3,3:8] &lt;- accuracy(fitted(lm(ts~I(1:length(ts)))),ts)[1:6]
+     Acc_Mat[4,3:8] &lt;- accuracy(auto.arima(ts)$fitted,ts)[1:6]
+     Acc_Mat[5,3:8] &lt;- accuracy(fitted(nnetar(ts)),ts)[1:6]
+     Acc_Mat[6,3:8] &lt;- accuracy(fitted(tbats(ts)),ts)[1:6]
+   }
+   Acc_Mat
+ }
&gt; TSDF &lt;- data.frame(TSName=character(0),Models=character(0),
+ Accuracy=numeric(0))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(AirPassengers))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(BJsales))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(JohnsonJohnson))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(LakeHuron))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(Nile))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(UKgas))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(UKDriverDeaths))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(USAccDeaths))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(WWWusage))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(airmiles))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(austres))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(co2))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(discoveries))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(lynx))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(nhtemp))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(nottem))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(presidents))
In addition: Warning message:
In ets(ts) :
  Missing values encountered. Using longest contiguous portion of time series
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(treering))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(gas))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(uspop))
&gt; TSDF &lt;- rbind(TSDF,get_Accuracy(sunspots))
&gt; write.csv(TSDF,"../Output/TS_All_Dataset_Accuracies.csv",row.names=F)</pre></div><p class="calibre7">The output of the preceding code<a id="id541" class="calibre1"/> block is the following table: </p><div class="informalexample"><table border="1" class="calibre16"><colgroup class="calibre17"><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/><col class="calibre18"/></colgroup><thead class="calibre19"><tr class="calibre20"><th valign="bottom" class="calibre21">
<p class="calibre22">TSName</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">Model</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">ME</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">RMSE</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">MAE</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">MPE</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">MAPE</p>
</th><th valign="bottom" class="calibre21">
<p class="calibre22">MASE</p>
</th></tr></thead><tbody class="calibre24"><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">AirPassengers</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ETS</p>
</td><td class="calibre25">
<p class="calibre22">1.5807</p>
</td><td class="calibre25">
<p class="calibre22">10.6683</p>
</td><td class="calibre25">
<p class="calibre22">7.7281</p>
</td><td class="calibre25">
<p class="calibre22">0.4426</p>
</td><td class="calibre25">
<p class="calibre22">2.8502</p>
</td><td class="calibre25">
<p class="calibre22">0.0164</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">AirPassengers</code>
</p>
</td><td class="calibre25">
<p class="calibre22">STL</p>
</td><td class="calibre25">
<p class="calibre22">-0.1613</p>
</td><td class="calibre25">
<p class="calibre22">11.9379</p>
</td><td class="calibre25">
<p class="calibre22">8.5595</p>
</td><td class="calibre25">
<p class="calibre22">-0.0662</p>
</td><td class="calibre25">
<p class="calibre22">3.4242</p>
</td><td class="calibre25">
<p class="calibre22">0.5515</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">AirPassengers</code>
</p>
</td><td class="calibre25">
<p class="calibre22">LM</p>
</td><td class="calibre25">
<p class="calibre22">0.0000</p>
</td><td class="calibre25">
<p class="calibre22">45.7362</p>
</td><td class="calibre25">
<p class="calibre22">34.4055</p>
</td><td class="calibre25">
<p class="calibre22">-1.2910</p>
</td><td class="calibre25">
<p class="calibre22">12.3190</p>
</td><td class="calibre25">
<p class="calibre22">0.7282</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">AirPassengers</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ARIMA</p>
</td><td class="calibre25">
<p class="calibre22">1.3423</p>
</td><td class="calibre25">
<p class="calibre22">10.8462</p>
</td><td class="calibre25">
<p class="calibre22">7.8675</p>
</td><td class="calibre25">
<p class="calibre22">0.4207</p>
</td><td class="calibre25">
<p class="calibre22">2.8005</p>
</td><td class="calibre25">
<p class="calibre22">-0.0012</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">AirPassengers</code>
</p>
</td><td class="calibre25">
<p class="calibre22">NNETAR</p>
</td><td class="calibre25">
<p class="calibre22">-0.0118</p>
</td><td class="calibre25">
<p class="calibre22">14.3765</p>
</td><td class="calibre25">
<p class="calibre22">11.4899</p>
</td><td class="calibre25">
<p class="calibre22">-0.2964</p>
</td><td class="calibre25">
<p class="calibre22">4.2425</p>
</td><td class="calibre25">
<p class="calibre22">0.5567</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">AirPassengers</code>
</p>
</td><td class="calibre25">
<p class="calibre22">TBATS</p>
</td><td class="calibre25">
<p class="calibre22">0.4655</p>
</td><td class="calibre25">
<p class="calibre22">10.6614</p>
</td><td class="calibre25">
<p class="calibre22">7.7206</p>
</td><td class="calibre25">
<p class="calibre22">0.2468</p>
</td><td class="calibre25">
<p class="calibre22">2.8519</p>
</td><td class="calibre25">
<p class="calibre22">0.0215</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">BJsales</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ETS</p>
</td><td class="calibre25">
<p class="calibre22">0.1466</p>
</td><td class="calibre25">
<p class="calibre22">1.3272</p>
</td><td class="calibre25">
<p class="calibre22">1.0418</p>
</td><td class="calibre25">
<p class="calibre22">0.0657</p>
</td><td class="calibre25">
<p class="calibre22">0.4587</p>
</td><td class="calibre25">
<p class="calibre22">-0.0110</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">BJsales</code>
</p>
</td><td class="calibre25">
<p class="calibre22">STL</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">BJsales</code>
</p>
</td><td class="calibre25">
<p class="calibre22">LM</p>
</td><td class="calibre25">
<p class="calibre22">0.0000</p>
</td><td class="calibre25">
<p class="calibre22">9.1504</p>
</td><td class="calibre25">
<p class="calibre22">7.1133</p>
</td><td class="calibre25">
<p class="calibre22">-0.1563</p>
</td><td class="calibre25">
<p class="calibre22">3.1686</p>
</td><td class="calibre25">
<p class="calibre22">0.9872</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">BJsales</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ARIMA</p>
</td><td class="calibre25">
<p class="calibre22">0.1458</p>
</td><td class="calibre25">
<p class="calibre22">1.3281</p>
</td><td class="calibre25">
<p class="calibre22">1.0447</p>
</td><td class="calibre25">
<p class="calibre22">0.0651</p>
</td><td class="calibre25">
<p class="calibre22">0.4601</p>
</td><td class="calibre25">
<p class="calibre22">-0.0262</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">BJsales</code>
</p>
</td><td class="calibre25">
<p class="calibre22">NNETAR</p>
</td><td class="calibre25">
<p class="calibre22">-0.0001</p>
</td><td class="calibre25">
<p class="calibre22">1.4111</p>
</td><td class="calibre25">
<p class="calibre22">1.0849</p>
</td><td class="calibre25">
<p class="calibre22">-0.0040</p>
</td><td class="calibre25">
<p class="calibre22">0.4798</p>
</td><td class="calibre25">
<p class="calibre22">0.2888</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">BJsales</code>
</p>
</td><td class="calibre25">
<p class="calibre22">TBATS</p>
</td><td class="calibre25">
<p class="calibre22">0.1622</p>
</td><td class="calibre25">
<p class="calibre22">1.3566</p>
</td><td class="calibre25">
<p class="calibre22">1.0666</p>
</td><td class="calibre25">
<p class="calibre22">0.0732</p>
</td><td class="calibre25">
<p class="calibre22">0.4712</p>
</td><td class="calibre25">
<p class="calibre22">-0.0113</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">JohnsonJohnson</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ETS</p>
</td><td class="calibre25">
<p class="calibre22">0.0495</p>
</td><td class="calibre25">
<p class="calibre22">0.4274</p>
</td><td class="calibre25">
<p class="calibre22">0.2850</p>
</td><td class="calibre25">
<p class="calibre22">1.0917</p>
</td><td class="calibre25">
<p class="calibre22">7.0339</p>
</td><td class="calibre25">
<p class="calibre22">-0.2948</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">JohnsonJohnson</code>
</p>
</td><td class="calibre25">
<p class="calibre22">STL</p>
</td><td class="calibre25">
<p class="calibre22">-0.0088</p>
</td><td class="calibre25">
<p class="calibre22">0.1653</p>
</td><td class="calibre25">
<p class="calibre22">0.1080</p>
</td><td class="calibre25">
<p class="calibre22">-0.5953</p>
</td><td class="calibre25">
<p class="calibre22">2.8056</p>
</td><td class="calibre25">
<p class="calibre22">-0.4155</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">JohnsonJohnson</code>
</p>
</td><td class="calibre25">
<p class="calibre22">LM</p>
</td><td class="calibre25">
<p class="calibre22">0.0000</p>
</td><td class="calibre25">
<p class="calibre22">1.6508</p>
</td><td class="calibre25">
<p class="calibre22">1.3287</p>
</td><td class="calibre25">
<p class="calibre22">22.6663</p>
</td><td class="calibre25">
<p class="calibre22">66.3896</p>
</td><td class="calibre25">
<p class="calibre22">0.6207</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">JohnsonJohnson</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ARIMA</p>
</td><td class="calibre25">
<p class="calibre22">0.0677</p>
</td><td class="calibre25">
<p class="calibre22">0.4074</p>
</td><td class="calibre25">
<p class="calibre22">0.2676</p>
</td><td class="calibre25">
<p class="calibre22">2.0526</p>
</td><td class="calibre25">
<p class="calibre22">6.5007</p>
</td><td class="calibre25">
<p class="calibre22">0.0101</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">JohnsonJohnson</code>
</p>
</td><td class="calibre25">
<p class="calibre22">NNETAR</p>
</td><td class="calibre25">
<p class="calibre22">0.0003</p>
</td><td class="calibre25">
<p class="calibre22">0.3501</p>
</td><td class="calibre25">
<p class="calibre22">0.2293</p>
</td><td class="calibre25">
<p class="calibre22">-0.6856</p>
</td><td class="calibre25">
<p class="calibre22">5.8778</p>
</td><td class="calibre25">
<p class="calibre22">-0.0347</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">JohnsonJohnson</code>
</p>
</td><td class="calibre25">
<p class="calibre22">TBATS</p>
</td><td class="calibre25">
<p class="calibre22">0.0099</p>
</td><td class="calibre25">
<p class="calibre22">0.4996</p>
</td><td class="calibre25">
<p class="calibre22">0.3115</p>
</td><td class="calibre25">
<p class="calibre22">0.9550</p>
</td><td class="calibre25">
<p class="calibre22">7.5277</p>
</td><td class="calibre25">
<p class="calibre22">-0.1084</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">sunspots</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ETS</p>
</td><td class="calibre25">
<p class="calibre22">-0.0153</p>
</td><td class="calibre25">
<p class="calibre22">15.9356</p>
</td><td class="calibre25">
<p class="calibre22">11.2451</p>
</td><td class="calibre25">
<p class="calibre22">#NAME?</p>
</td><td class="calibre25">
<p class="calibre22">Inf</p>
</td><td class="calibre25">
<p class="calibre22">0.0615</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">sunspots</code>
</p>
</td><td class="calibre25">
<p class="calibre22">STL</p>
</td><td class="calibre25">
<p class="calibre22">0.0219</p>
</td><td class="calibre25">
<p class="calibre22">12.2612</p>
</td><td class="calibre25">
<p class="calibre22">8.7973</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">Inf</p>
</td><td class="calibre25">
<p class="calibre22">0.18</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">sunspots</code>
</p>
</td><td class="calibre25">
<p class="calibre22">LM</p>
</td><td class="calibre25">
<p class="calibre22">0</p>
</td><td class="calibre25">
<p class="calibre22">42.9054</p>
</td><td class="calibre25">
<p class="calibre22">34.1212</p>
</td><td class="calibre25">
<p class="calibre22">#NAME?</p>
</td><td class="calibre25">
<p class="calibre22">Inf</p>
</td><td class="calibre25">
<p class="calibre22">0.9196</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">sunspots</code>
</p>
</td><td class="calibre25">
<p class="calibre22">ARIMA</p>
</td><td class="calibre25">
<p class="calibre22">-0.0267</p>
</td><td class="calibre25">
<p class="calibre22">15.6006</p>
</td><td class="calibre25">
<p class="calibre22">11.0258</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">Inf</p>
</td><td class="calibre25">
<p class="calibre22">-0.0106</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">sunspots</code>
</p>
</td><td class="calibre25">
<p class="calibre22">NNETAR</p>
</td><td class="calibre25">
<p class="calibre22">-0.0672</p>
</td><td class="calibre25">
<p class="calibre22">10.3105</p>
</td><td class="calibre25">
<p class="calibre22">7.6878</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">Inf</p>
</td><td class="calibre25">
<p class="calibre22">0.0108</p>
</td></tr><tr class="calibre20"><td class="calibre25">
<p class="calibre22">
<code class="literal1">sunspots</code>
</p>
</td><td class="calibre25">
<p class="calibre22">TBATS</p>
</td><td class="calibre25">
<p class="calibre22">-0.0514</p>
</td><td class="calibre25">
<p class="calibre22">15.5788</p>
</td><td class="calibre25">
<p class="calibre22">11.0119</p>
</td><td class="calibre25">
<p class="calibre22">NA</p>
</td><td class="calibre25">
<p class="calibre22">Inf</p>
</td><td class="calibre25">
<p class="calibre22">-0.0013</p>
</td></tr></tbody></table></div><p class="calibre7">Table 3: Accuracy for six models across 21 datasets</p><p class="calibre7">The overall message is the same as what was <a id="id542" class="calibre1"/>obtained in the introductory chapter for the classification problem. Since it is not always possible for us to carry out the inspection of the results all the time, it is desirable to combine the results of multiple models to put across a unified story of greater accuracy. We begin this task with the simple idea of bagging the exponential time series models.</p></div></div></div>

<div class="book" title="Time series datasets">
<div class="book" title="Bagging and time series"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_5"><a id="ch11lvl1sec86" class="calibre1"/>Bagging and time series</h2></div></div></div><p class="calibre7">In this section, we will only illustrate the bagging technique for the ETS model. The main purpose of bagging is to stabilize the <a id="id543" class="calibre1"/>predictions or forecasts. Here, we will base the bagging on the Box-Cox and Loess-based decomposition. Using 500 such bootstrap samples, the bagging model for ETS will be obtained:</p><div class="informalexample"><pre class="programlisting">&gt;uspop_bagg_ets &lt;- baggedETS(uspop_sub,bootstrapped_series = 
+                               bld.mbb.bootstrap(uspop_sub, 500))
&gt;forecast(uspop_bagg_ets,h=4);subset(uspop,start=16,end=19)
     Point Forecast Lo 100 Hi 100
1940            141    136    145
1950            158    150    165
1960            175    164    184
1970            193    178    204
Time Series:
Start = 1940 
End = 1970 
Frequency = 0.1 
[1] 132 151 179 203
&gt;plot(forecast(uspop_bagg_ets,h=4))</pre></div><p class="calibre7">Is there an advantage to using the bagging method? We can quickly check this using the confidence intervals:</p><div class="informalexample"><pre class="programlisting">&gt;forecast(uspop_bagg_ets,h=4)
     Point Forecast Lo 100 Hi 100
1940            141    136    145
1950            158    150    165
1960            175    164    184
1970            193    178    204
&gt;forecast(USpop_ets,h=4,level=99.99)
     Point Forecast Lo 99.99 Hi 99.99
1940            139      133      146
1950            156      142      169
1960            172      150      194
1970            189      157      221</pre></div><p class="calibre7">The confidence intervals of the bagged ETS are clearly shorter, and hence reflect the decrease in the variance, which is the main purpose of bagging:</p><div class="mediaobject"><img src="../images/00523.jpeg" alt="Bagging and time series" class="calibre10"/><div class="caption"><p class="calibre14">Figure 16: Bagging forecasts for US population</p></div></div><p class="calibre11"> </p><p class="calibre7">The accuracy comparison is also easily<a id="id544" class="calibre1"/> performed here:</p><div class="informalexample"><pre class="programlisting">&gt;accuracy(forecast(USpop_ets,h=4),x=uspop[16:19])
               ME RMSE  MAE   MPE MAPE  MASE  ACF1
Training set 1.11 1.68 1.40 3.259 4.60 0.165 -0.28
Test set     2.33 9.02 8.26 0.578 4.86 0.973    NA
&gt;accuracy(forecast(uspop_bagg_ets,h=4),x=subset(uspop,start=16,end=19))
                 ME RMSE  MAE    MPE MAPE   MASE  ACF1 Theil's U
Training set  1.137 1.44 1.24  2.226 4.48 0.0283 0.563        NA
Test set     -0.359 7.87 7.48 -0.995 4.63 0.1700 0.296     0.299</pre></div><p class="calibre7">The advantage of ensembling homogeneous base learners is clearly seen here. Next, we move to the heterogeneous base learners and their ensemble.</p></div></div>

<div class="book" title="Time series datasets">
<div class="book" title="Ensemble time series models"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_6"><a id="ch11lvl1sec87" class="calibre1"/>Ensemble time series models</h2></div></div></div><p class="calibre7">The <code class="literal">forecastHybrid</code> R package<a id="id545" class="calibre1"/> gives a platform to ensemble heterogeneous time series models. The main function that enables this task is the <code class="literal">hybridModel</code> function. The core function provides the option referred to as <code class="literal">models</code>. It takes as input a string of up to six characters, and the characters are representatives of the models: <code class="literal">a</code> for the <code class="literal">auto.arima</code> model, <code class="literal">e</code> for <code class="literal">ets</code>, <code class="literal">f</code> for <code class="literal">thetam</code>, <code class="literal">n</code> denoting <code class="literal">nnetar</code>, <code class="literal">s</code> for <code class="literal">stlm</code>, and finally, <code class="literal">t</code> represents <code class="literal">tbats</code>. Consequently, if we give a character string of <code class="literal">ae</code> to models, it will combine results from the ARIMA and ets models. This is illustrated on the <code class="literal">co2</code> dataset for different combinations of the time series models:</p><div class="informalexample"><pre class="programlisting">&gt;accuracy(forecast(co2_arima,h=25),x=co2[444:468])
                  ME  RMSE   MAE      MPE   MAPE  MASE   ACF1
Training set  0.0185 0.283 0.225  0.00541 0.0672 0.211 0.0119
Test set     -0.0332 0.349 0.270 -0.00912 0.0742 0.252     NA
&gt;AP_Ensemble_02 &lt;- hybridModel(co2_sub,models="ae")
Fitting the auto.arima model
Fitting the ets model
&gt;accuracy(AP_Ensemble_02,h=25,x=co2[444:468])
             ME  RMSE   MAE     MPE   MAPE    ACF1 Theil's U
Test set 0.0258 0.271 0.219 0.00755 0.0653 0.00289     0.226
&gt;AP_Ensemble_03 &lt;- hybridModel(co2_sub,models="aen")
Fitting the auto.arima model
Fitting the ets model
Fitting the nnetar model
&gt;accuracy(AP_Ensemble_03,h=25,x=co2[444:468])
            ME  RMSE   MAE    MPE  MAPE  ACF1 Theil's U
Test set 0.017 0.304 0.245 0.0049 0.073 0.282      0.25
&gt;AP_Ensemble_04 &lt;- hybridModel(co2_sub,models="aens")
Fitting the auto.arima model
Fitting the ets model
Fitting the nnetar model
Fitting the stlm model
&gt;accuracy(AP_Ensemble_04,h=25,x=co2[444:468])
             ME  RMSE   MAE     MPE  MAPE  ACF1 Theil's U
Test set 0.0165 0.275 0.221 0.00478 0.066 0.209     0.226
&gt;AP_Ensemble_05 &lt;- hybridModel(co2_sub,models="aenst")
Fitting the auto.arima model
Fitting the ets model
Fitting the nnetar model
Fitting the stlm model
Fitting the tbats model
&gt;accuracy(AP_Ensemble_05,h=25,x=co2[444:468])
             ME  RMSE   MAE     MPE   MAPE  ACF1 Theil's U
Test set 0.0123 0.267 0.216 0.00348 0.0645 0.153      0.22</pre></div><p class="calibre7">Though the discussion of the ensemble is very brief here, time series literature has only recently begun to adapt to ensembling techniques.</p><p class="calibre7">
<span class="strong"><strong class="calibre8">Exercise</strong></span>: The options of <code class="literal">weights</code> and <code class="literal">errorMethod</code> are crucial to <a id="id546" class="calibre1"/>put different time series models together. Explore these options for the different datasets introduced and discussed in the chapter.</p></div></div>
<div class="book" title="Summary" id="2ACBS1-2006c10fab20488594398dc4871637ee"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch11lvl1sec88" class="calibre1"/>Summary</h1></div></div></div><p class="calibre7">Time series data poses new challenges and complexities. The chapter began with an introduction to important and popular datasets. We looked at different time series and their intricacies. Visualization of time series provides great insight, and the time series plots, along with the seasonal plot, are complementarily used for clear ideas and niche implementations. Accuracy metrics are different for the time series, and we looked at more than a handful of these. The concepts of ACF and PACF are vital in model identification, and seasonal components are also important to the modeling of time series. We also saw that different models express different datasets, and the degree of variation is something similar to the usual regression problems. The bagging of time series (ets only) reduces the variance of the forecasts. Combining heterogeneous base learners was discussed in the concluding section. The next chapter is the concluding chapter. We will summarize the main takeaways from the first eleven chapters and outline some shortcomings and further scope.</p></div></body></html>