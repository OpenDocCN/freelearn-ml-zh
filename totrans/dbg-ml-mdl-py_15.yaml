- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Correlation versus Causality
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters of this book, you learned how to train, evaluate, and build
    high-performance and low-bias machine learning models. However, the algorithms
    and example methods we used to practice the concepts that were introduced in this
    book do not necessarily provide you with a causal relationship between features
    and output variables in a supervised learning setting. In this chapter, we will
    discuss how causal inference and modeling could help you increase the reliability
    of your models in production.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Correlation as part of machine learning models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causal modeling to reduce risks and improve performance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessing causation in machine learning models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causal modeling using Python
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned about the benefits of causal
    modeling and inference compared to correlative modeling and practice with available
    Python functionalities to identify the causal relationship between features and
    output variables.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need the following for this chapter as they will help you better understand
    the concepts, use them in your projects, and practice with the provided code:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Python library requirements:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dowhy` == 0.5.1'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bnlearn` == 0.7.16'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` >= 1.2.2'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`d3blocks` == 1.3.0'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You will also require basic knowledge of machine learning model training, validation,
    and testing
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code files for this chapter are available on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter15](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter15).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Correlation as part of machine learning models
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The majority of machine learning modeling and data analysis projects result
    in correlative relationships between features and output variables in supervised
    learning settings and statistical modeling. Although these relationships are not
    causal, identifying causal relationships is of high value, even if it’s not a
    necessity in most problems we try to solve. For example, we can define medical
    diagnosis as “*The identification of the diseases that are most likely to be causing
    the patient’s symptoms, given their medical history.*” (Richens et al., 2020).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'Identifying causal relationships resolves issues in identifying misleading
    relationships between variables. Relying solely on correlations rather than causality
    could result in spurious and bizarre associations such as the following ([https://www.tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations);
    [https://www.buzzfeednews.com/article/kjh2110/the-10-most-bizarre-correlations](https://www.buzzfeednews.com/article/kjh2110/the-10-most-bizarre-correlations)):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: US spending on science, space, and technology correlates with suicides by hanging,
    strangulation, and suffocation
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total revenue generated by arcades correlates with computer science doctorates
    awarded in the US
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: US crude oil imports from Norway correlates with drivers killed in collisions
    with railway trains
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eating organic food correlates with autism
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obesity correlates with the debt bubble
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find more of these spurious correlations in the sources for these examples.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Relying on correlations versus causation could decrease the reliability of different
    aspects of technology development and improvement processes such as AB testing.
    For example, understanding “if we get more visitors to search, we’ll see an increase
    in purchases and revenue” ([https://conversionsciences.com/correlation-causation-impact-ab-testing/](https://conversionsciences.com/correlation-causation-impact-ab-testing/))
    helps in proper decision-making and investment in technology development.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Now that you understand the problems with relying solely on correlative relationships,
    let’s discuss what causal modeling means in a machine learning setting.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Causal modeling to reduce risks and improve performance
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Causal modeling helps in eliminating unreliable correlative relationships between
    variables. Eliminating such unreliable relationships reduces the risks of wrong
    decision-making across different domains of applications for machine learning,
    such as healthcare. Decisions in healthcare, such as diagnosing diseases and assigning
    effective treatment regimens to patients, have a direct effect on quality of life
    and survival. Hence, decisions need to be based on reliable models and relationships
    in which causal modeling and inference could help us (Richens et al., 2020; Prosperi
    et al., 2020; Sanchez et al., 2022).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Causal modeling techniques help in eliminating bias, such as confounding and
    collider bias, in our models (Prosperi et al., 2020) (*Figure 15**.1*). An example
    of such bias is smoking as a confounder of the relationship between yellow fingers
    and lung cancer (Prosperi et al., 2020). As shown in *Figure 15**.1*, the existence
    of collider variables results in correlative, but biased and unreal, associations
    between some of the input variables and outcome. Also, not having some of the
    variables that could be confounding in our modeling could result in us concluding
    other variables are associated with the outcome:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 15.1 – Schematic representation of confounding and collider bi\uFEFF\
    as](img/B16369_15_01.jpg)"
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: Figure 15.1 – Schematic representation of confounding and collider bias
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will mention some concepts and techniques in causal modeling such as
    causal inference and how to test causation in a machine learning model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Assessing causation in machine learning models
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Calculating the correlation between features and outcomes in machine learning
    modeling has been a common approach in many fields and industries. For example,
    we can simply calculate the Pearson correlation coefficient to identify correlative
    features with the target variable. There are also features in many of our machine
    learning models that contribute to the prediction of outcomes not as causal but
    rather as correlative predictors. There are several ways to differentiate between
    such correlative and causal features with the available functionalities in Python.
    Here are a few examples:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**Experimental design**: One way to establish causality is to conduct experiments
    where we measure the effect of changes in the causal feature on the target variable.
    However, such experimental studies may not always be feasible or ethical.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature importance**: We can use explainability techniques, as presented
    in [*Chapter 6*](B16369_06.xhtml#_idTextAnchor201), *Interpretability and Explainability
    in Machine Learning Modeling*, to identify feature importance and use such information
    to discriminate between correlation and causality.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Causal inference**: Causal inference methods aim to identify the causal relationship
    between variables. You can use causal inference to determine whether a change
    in one variable causes a change in another variable.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We discussed different explainability techniques such as SHAP, LIME, and counterfactual
    explanations in [*Chapter 6*](B16369_06.xhtml#_idTextAnchor201), *Interpretability
    and Explainability in Machine Learning Modeling*. You can use these techniques
    to identify features that are not causal in your models. For example, features
    with low SHAP values most probably are not causal in the model under investigation.
    If there is a feature with low importance in the local approximation, according
    to LIME, then it is likely to not be causal regarding the output of your model.
    Or if changing a feature has little or no effect on the output of your model,
    through counterfactual analysis, then it is likely not a causal feature.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: We can also use another technique, called **permutation feature importance**,
    which is also considered under the umbrella of explainability techniques to identify
    features with a low chance of being causal. In this approach, we change the values
    of a feature and measure the effect of change on the model’s performance. Then
    we can identify features with low effects that are likely to not be causal.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: We already practiced explainability techniques in [*Chapter 6*](B16369_06.xhtml#_idTextAnchor201),
    *Interpretability and Explainability in Machine Learning Modeling*. We will focus
    on causal inference for the remainder of this chapter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Causal inference
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In causal inference, we aim to identify and understand the causal relationship
    between variables in a dataset or model. In this process, we might rely on different
    statistical and machine learning techniques to analyze data and infer causal relationships
    between variables. *Figure 15**.2* shows five such methods: **experimental design**,
    **observational studies**, **propensity score matching**, **instrumental variables**,
    and **machine** **learning-based methods**:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.2 – Five causal inference techniques](img/B16369_15_02.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: Figure 15.2 – Five causal inference techniques
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'In **experimental design**, you design experiments to compare outcome variables
    for samples with differences in a treatment variable, or different conditions
    based on a specific feature or characteristics. Examples of treatment and outcome
    variables are provided in *Table 15.1* to help you understand the difference between
    these two terms:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '| **Treatment Variable** | **Outcome Variable** |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| Education level | Income level |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| Smoking | Lung cancer |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| Physical activity | Cardiovascular health |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| Family income | Academic performance |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: Table 15.1 – Examples of treatment and outcome variables in causal modeling
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: In **observational studies**, we use observational data, instead of controlled
    experiments, and try to identify causal relationships by controlling confounding
    variables. **Propensity score matching** matches treatment and control groups
    based on the probability of receiving the treatment given the observed variables.
    **Instrumental variables** is used to overcome a common problem in observational
    studies where the treatment and outcome variables are jointly determined by other
    variables, or confounders, that are not included in the model. This approach starts
    with identifying an instrument that is correlated with the treatment variable
    and uncorrelated with the outcome variable, except through its effect on the treatment
    variable. **Machine learning-based methods** are other categories of techniques
    where machine learning methods such as Bayesian networks and decision trees are
    used to identify causal relationships between variables and outcomes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian networks
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can benefit from Bayesian networks in causal modeling and identifying causal
    relationships between variables. Bayesian networks are graphical models that show
    the relationship between variables through **directed acyclic graphs** (**DAGs**),
    where each variable, including the input features and outputs, is a node and directions
    show the relationship between variables (*Figure 15**.3*):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.3 – Illustrating an example Bayesian network](img/B16369_15_03.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
- en: Figure 15.3 – Illustrating an example Bayesian network
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: What this network tells us is that higher values of **Feature A** and **Feature
    B** make it more likely for the outcome to occur. Note that the features could
    be numerical or categorical. Although the directions, such as from Feature A to
    the outcome (*Figure 15**.3*), don’t necessarily mean causality, Bayesian networks
    can be used for estimating the causal effects of variables on the outcome while
    controlling the confounding variables.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'From a probabilistic perspective, the network can be used to simplify the joint
    probability of all the variables, including the features and outcome, as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: p(F A, F B, F C, Outcome) = p(Outcome| F A, F B)p(F B| F C)p(F C| F A)p(F A)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Here, p(Outcome| F A, F B) is the **conditional probability distribution** (**CPD**)
    of the outcome given the values of Features A and B, p(F B| F C) is the CPD of
    Feature B given Feature C, p(F C| F A) is the CPD of Feature C given Feature A,
    and p(F A) is the probability of Feature A that is not conditional to other features
    as no edge is directed toward it in the graph. These CPDs can help us estimate
    the effect of change one feature value has on another. It tells us about the likelihood
    of the occurrence of one variable given the occurrence of one or more variables.
    You will learn how to make a Bayesian network in a data-driven way for a given
    dataset and how to identify the CPDs of the network using Python by the end of
    this chapter.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: There are several methods available in Python for causal inference. We’ll cover
    these next.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Causal modeling using Python
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Several Python libraries provide you with easy-to-use functionalities for using
    causal methods and conducting causal inference. Some of these are as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '`dowhy` ([https://pypi.org/project/dowhy/](https://pypi.org/project/dowhy/))'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pycausalimpact` ([https://pypi.org/project/pycausalimpact/](https://pypi.org/project/pycausalimpact/))'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`causalnex` ([https://pypi.org/project/causalnex/](https://pypi.org/project/causalnex/))'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`econml` ([https://pypi.org/project/econml/](https://pypi.org/project/econml/))'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bnlearn` ([https://pypi.org/project/bnlearn/](https://pypi.org/project/bnlearn/))'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next few subsections, we will review `dowhy` and `bnlearn`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Using dowhy for causal effect estimation
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we want to practice with a propensity score matching approach that is
    useful when you have a treatment variable in mind – for example, when you want
    to identify the effect of a drug on patients and have other variables in the model,
    such as their diet, age, sex, and so on. Here, we will use the breast cancer dataset
    of `scikit-learn`, where the target variable is a binary outcome telling us about
    the cells, from masses of breast cancer patients, as being from malignant or benign
    masses. Here, we will use the mean *radius* feature – the mean distance from the
    center to points on the perimeter – as the treatment variable.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must import the required libraries and modules in Python:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we must load the breast cancer dataset and convert it into a DataFrame:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we need to convert the numerical values of the treatment variable, the
    mean radius, into a binary as propensity scoring matching only accepts binary
    treatment variables:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We also need to make a list of common causes, which in this case we consider
    as being all the other attributes in the dataset:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can build a model using `CausalModel()` from `dowhy` by specifying
    the data, treatment, outcome variable, and common causes. The `CausalModel()`
    object helps us estimate the causal effect of the `treatment` variable (mean radius)
    on the outcome variable (`target`):'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we can estimate the causal effect of the specified treatment variable,
    the mean radius, on the target variable. Note that propensity score matching,
    which we’re using here, is applicable only for discrete treatment variables:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `estimate` value is -0.279, which means that the probability of the outcome
    is decreased by ~28% with the high mean radius as the treatment variable. This
    propensity score is the conditional probability of receiving the treatment (high
    mean radius) given a set of observed covariates. The backdoor adjustment controls
    the confounding variables, which are associated with both the treatment and outcome
    variables.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use `refute_estimate()` to assess the validity of our hypothesis
    regarding the causal variables and their data-driven estimated effects on the
    outcome. For example, we can use the `''placebo_treatment_refuter''` method, which
    replaces the specified treatment variable with an independent random variable.
    If our assumption of causality between the treatment and outcome is correct, then
    the new estimate goes close to zero. Here is the code to check the validity of
    our assumption using `''placebo_treatment_refuter''`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This results in the new effect of 0.0014, which is an assurance about the validity
    of our assumption. However, the *p*-value estimate, which is another output of
    this command, is 0.48, which shows the level of statistical confidence.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: A low *p*-value from `refute_estimate()` does not mean that the treatment variable
    is not causal. A low *p*-value shows the sensitivity of the estimated causal effect
    to the specific assumption being tested. The significance of the refutation result
    does not imply the absence of a causal relationship between the treatment variable
    and the outcome variable.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Using bnlearn for causal inference through Bayesian networks
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the libraries that exists in both the Python and R programming languages
    for Bayesian network learning and inference is `bnlearn`. We can learn a Bayesian
    network for a given dataset using this library and then use the learned graph
    to infer causal relationships.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'To practice with `bnlearn`, we must install and then import this library and
    load the Sprinkler dataset that exists as part of it:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we must fit a `structure_learning()` model to generate a Bayesian network
    or a DAG:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we must define the properties of the nodes and visualize the DAG, as
    follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This results in the network shown in *Figure 15**.4*. As shown in this DAG,
    `''Sprinkler''` could be a causal variable for both cloudy weather and wet grass.
    And wet grass could be potentially caused by rain and sprinklers. But there are
    functionalities to quantify these dependencies:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.4 – Learned DAG using bnlearn for the Sprinkler dataset](img/B16369_15_04.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: Figure 15.4 – Learned DAG using bnlearn for the Sprinkler dataset
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use `independence_test()` as follows to test the dependency of the
    variables:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*Table 15.2* includes a summary of the output of the previous command, clearly
    showing the significance of the dependency of the paired variables in the DAG:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '| **Source** | **Target** | **p-value (from** **chi_sqare test)** | **chi-square**
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '| Cloudy | Rain | 1.080606e-87 | 394.061629 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: '| Sprinkler | Wet_Grass | 1.196919e-23 | 100.478455 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: '| Sprinkler | Cloudy | 8.383708e-53 | 233.906474 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
- en: '| Rain | Wet_Grass | 3.886511e-64 | 285.901702 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: Table 15.2 – Summary of using bnlearn.independence_test() on the Sprinkler dataset
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use `bnlearn.parameter_learning.fit()` to learn about the CPDs,
    as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Figure 15**.5* shows the CPDs of the `Cloudy`, `Rain`, and `Sprinkler` variables.
    These CPDs, in combination with the identified DAG (*Figure 15**.4*), provide
    the required information to not only identify potentially causal relationships
    between the variables but also do a quantitative assessment of them:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.5 – Examples of CPDs identified by bnlearn for the Sprinkler dataset](img/B16369_15_05.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: Figure 15.5 – Examples of CPDs identified by bnlearn for the Sprinkler dataset
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you practiced using causal modeling, but there is much more
    to this topic. This is one of the most important topics in machine learning and
    you will benefit from learning more about this subject.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the difference between correlative and causal
    relationships, the importance of causal modeling, and techniques such as Bayesian
    networks for causal inference. Later, we went through Python practices to help
    you start working with causal modeling and inference in your projects so that
    you can identify more reliable relationships between variables in your datasets
    and design reliable models.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn techniques for preserving privacy and ensuring
    security while maximizing the benefits of using private and proprietary data in
    building reliable machine learning models.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Could you have a feature that is highly correlated with the output but not causal
    in a supervised learning model?
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between experimental design and observation studies for
    causal inference?
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the requirements for using instrumental variables for causal inference?
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Could relationships in a Bayesian network necessarily be considered causal?
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Schölkopf, Bernhard. *Causality for machine learning*. Probabilistic and Causal
    Inference: The Works of Judea Pearl. 2022\. 765-804.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schölkopf, Bernhard. *机器学习的因果性*. 概率与因果推理：朱迪亚·佩尔的工作. 2022. 765-804.
- en: 'Kaddour, Jean, et al. *Causal machine learning: A survey and open problems*.
    arXiv preprint arXiv:2206.15475 (2022).'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaddour, Jean, 等人. *因果机器学习：综述与开放问题*. arXiv预印本 arXiv:2206.15475 (2022).
- en: Pearl, Judea. *Bayesian* *networks*. (2011).
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pearl, Judea. *贝叶斯* *网络*. (2011).
- en: 'Richens, Jonathan G., Ciarán M. Lee, and Saurabh Johri. *Improving the accuracy
    of medical diagnosis with causal machine learning*. Nature communications 11.1
    (2020): 3923.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Richens, Jonathan G., Ciarán M. Lee, 和 Saurabh Johri. *利用因果机器学习提高医疗诊断的准确性*.
    Nature communications 11.1 (2020): 3923.'
- en: 'Prosperi, Mattia, et al. *Causal inference and counterfactual prediction in
    machine learning for actionable healthcare*. Nature Machine Intelligence 2.7 (2020):
    369-375.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Prosperi, Mattia, 等人. *在可操作的医疗保健中，机器学习的因果推理和反事实预测*. Nature Machine Intelligence
    2.7 (2020): 369-375.'
- en: 'Sanchez, Pedro, et al. *Causal machine learning for healthcare and precision
    medicine*. Royal Society Open Science 9.8 (2022): 220638.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sanchez, Pedro, 等人. *因果机器学习在医疗和精准医学中的应用*. Royal Society Open Science 9.8 (2022):
    220638.'
