["```py\n 3 10 \n    265 311 303 321 337 310 302 298 265 311 \n    255 315 305 337 346 316 305 309 255 315 \n    262 316 303 342 332 315 298 299 262 316\n\n```", "```py\n    PCA loadPCA(char* fileName, int& rows, int& cols,Mat& pcaset){ \n      FILE* in = fopen(fileName,\"r\"); \n      int a; \n      fscanf(in,\"%d%d\",&rows,&cols); \n\n      pcaset = Mat::eye(rows,cols,CV_64F); \n      int i,j; \n\n      for(i=0;i<rows;i++){ \n        for(j=0;j<cols;j++){ \n          fscanf(in,\"%d\",&a); \n          pcaset.at<double>(i,j) = a; \n        } \n      } \n\n      PCA pca(pcaset, // pass the data \n        Mat(), // we do not have a pre-computed mean vector, \n        // so let the PCA engine compute it \n        CV_PCA_DATA_AS_ROW, // indicate that the vectors \n        // are stored as matrix rows \n        // (use CV_PCA_DATA_AS_COL if the vectors are \n        // the matrix columns) \n        pcaset.cols// specify, how many principal components to retain \n      ); \n      return pca; \n    }\n\n```", "```py\n    Subdiv2D* subdiv; \n    CvRect rect = { 0, 0, 640, 480 }; \n\n    subdiv = new Subdiv2D(rect); \n\n    std::vector<CvPoint> points; \n\n    //initialize points somehow \n    ... \n\n    //iterate through points inserting them in the subdivision \n    for(int i=0;i<points.size();i++){     \n      float x = points.at(i).x; \n      float y = points.at(i).y; \n      Point2f fp(x, y); \n      subdiv->insert(fp); \n    }\n\n```", "```py\n    vector<Vec6f> triangleList; \n\n    subdiv->getTriangleList(triangleList); \n    vector<Point> pt(3); \n\n    for( size_t i = 0; i < triangleList.size(); i++ ) \n    { \n      Vec6f t = triangleList[i]; \n      pt[0] = Point(cvRound(t[0]), cvRound(t[1])); \n      pt[1] = Point(cvRound(t[2]), cvRound(t[3])); \n      pt[2] = Point(cvRound(t[4]), cvRound(t[5])); \n    }\n\n```", "```py\n    void warpTextureFromTriangle(Point2f srcTri[3], Mat originalImage, Point2f dstTri[3], Mat warp_final){ \n\n      Mat warp_mat(2, 3, CV_32FC1); \n      Mat warp_dst, warp_mask; \n      CvPoint trianglePoints[3]; \n      trianglePoints[0] = dstTri[0]; \n      trianglePoints[1] = dstTri[1]; \n      trianglePoints[2] = dstTri[2]; \n      warp_dst  = Mat::zeros(originalImage.rows, originalImage.cols, originalImage.type()); \n      warp_mask = Mat::zeros(originalImage.rows, originalImage.cols, originalImage.type()); \n\n      /// Get the Affine Transform \n      warp_mat = getAffineTransform(srcTri, dstTri); \n\n      /// Apply the Affine Transform to the src image \n      warpAffine(originalImage, warp_dst, warp_mat, warp_dst.size()); \n      cvFillConvexPoly(new IplImage(warp_mask), trianglePoints, 3, CV_RGB(255,255,255), CV_AA, 0);   \n      warp_dst.copyTo(warp_final, warp_mask); \n    }\n\n```", "```py\n    float cubeSize = 10.0; \n    std::vector<CvPoint3D32f> modelPoints; \n    modelPoints.push_back(cvPoint3D32f(0.0f, 0.0f, 0.0f)); \n    modelPoints.push_back(cvPoint3D32f(0.0f, 0.0f, cubeSize)); \n    modelPoints.push_back(cvPoint3D32f(cubeSize, 0.0f, 0.0f)); \n    modelPoints.push_back(cvPoint3D32f(0.0f, cubeSize, 0.0f)); \n    CvPOSITObject *positObject = cvCreatePOSITObject( &modelPoints[0],   \n      static_cast<int>(modelPoints.size()) );\n\n```", "```py\n    std::vector<CvPoint2D32f> srcImagePoints; \n    srcImagePoints.push_back( cvPoint2D32f( -48, -224 ) ); \n    srcImagePoints.push_back( cvPoint2D32f( -287, -174 ) ); \n    srcImagePoints.push_back( cvPoint2D32f( 132, -153 ) ); \n    srcImagePoints.push_back( cvPoint2D32f( -52, 149 ) );\n\n```", "```py\n    //Estimate the pose \n    float* rotation_matrix = new float[9]; \n    float* translation_vector = new float[3]; \n    CvTermCriteria criteria = cvTermCriteria(CV_TERMCRIT_EPS | \n      CV_TERMCRIT_ITER, 100, 1.0e-4f); \n    cvPOSIT( positObject, &srcImagePoints[0], FOCAL_LENGTH, criteria, \n      rotation_matrix, translation_vector );\n\n```", "```py\n    float Model3D[58][3]= {{-7.308957,0.913869,0.000000}, ...\n\n```", "```py\n    #include \"opencv2/opencv.hpp\" \n\n    using namespace cv; \n\n    int main(int, char**) \n    { \n      VideoCapture cap(0);// opens the default camera, could use a \n                        // video file path instead           \n\n      if(!cap.isOpened()) // check if we succeeded \n        return -1; \n\n      AAM aam = loadPreviouslyTrainedAAM(); \n      HeadModel headModel = load3DHeadModel(); \n      Mapping mapping = mapAAMLandmarksToHeadModel(); \n\n      Pose2D pose = detectFacePosition(); \n\n      while(1) \n      { \n        Mat frame; \n        cap >> frame; // get a new frame from camera \n\n        Pose2D new2DPose = performAAMSearch(pose, aam); \n        Pose3D new3DPose = applyPOSIT(new2DPose, headModel, mapping); \n\n        if(waitKey(30) >= 0) break; \n      } \n\n      // the camera will be deinitialized automatically in VideoCapture \n      // destructor \n      return 0; \n    }\n\n```"]