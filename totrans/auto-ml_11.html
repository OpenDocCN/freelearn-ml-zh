<html><head></head><body>
		<div id="_idContainer314">
			<h1 id="_idParaDest-107"><em class="italic"><a id="_idTextAnchor119"/>Chapter 9</em>: Automated Machine Learning with GCP</h1>
			<p class="author-quote">"<em class="italic">The first rule of any technology used in a business is that automation </em><em class="italic">applied to an efficient operation will magnify the efficiency. The second is that automation applied to an inefficient operation will magnify the inefficiency.</em>" </p>
			<p class="author-quote"><em class="italic">-Bill Gates</em></p>
			<p>This has been a long yet rewarding journey of learning about major hyperscalers and how they implement automated machine learning in their respective platforms. In the previous chapter, you learned how to get started with Google Cloud AI Platform, learned about AI Hub, and learned how to build a notebook instance in GCP. You also learned about the different flavors of automated machine learning offered by GCP, including AutoML Natural Language, AutoML Tables, AutoML Translation, AutoML Video, and AutoML Vision. </p>
			<p>Continuing with the breadth of GCP offerings, capabilities, and services, we will now do a deep dive into Cloud AutoML Tables. We will build models and explain how automated machine learning works with AutoML Tables; that is, how you can take unstructured data and perform automated machine learning tasks by analyzing the input features (feature engineering), selecting the model (neural architecture search), and performing hyperparameter tuning. We will deploy these models to GCP and test them via web services to demonstrate their operationalization. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Getting started with Google Cloud AutoML Tables</li>
				<li>Creating an AutoML Tables experiment</li>
				<li>Understanding AutoML Tables model deployment</li>
				<li>AutoML Tables with BigQuery public datasets</li>
				<li>Automated machine learning for price prediction</li>
			</ul>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor120"/>Getting started with Google Cloud AutoML Tables</h1>
			<p>AutoML Tables helps harness the insights in your structured data. In any large enterprise, there <a id="_idIndexMarker435"/>are multiple modalities of data, including structured, unstructured, and semi-structured data. For most organizations dealing with databases and transactions, there is indeed a lot of structured data out there. This data is quite suitable for advances analytics, and GCP's AutoML Tables is just the tool to help you automatically build and deploy machine learning models based on structured data.</p>
			<p>AutoML Tables enables machine learning engineers and data scientists to automatically build and deploy state-of-the-art machine learning models on structured data faster than anyone could manually do. It automates modeling on a wide range of data types, from numbers and classes to strings, timestamps, lists, and nested fields. Google Cloud AutoML tables make this happen with minimal code. In this chapter, we will learn how to take an exported CSV file, click a few buttons, wait a while, and get a very highly tuned model on the other end.</p>
			<p>Google's automated machine learning team has worked hard so that the tool works for a wide variety of data types. Google's AutoML Tables explores that vast space of possible models and hyperparameters so that it can try and optimize things on your behalf. As we explore the examples in this chapter, you will see that the first step is to import your training data via the <strong class="bold">Import</strong> tab, give it a name, and select the source – either a table from BigQuery, a file on your machine, or a file on Google Cloud Storage. This first step takes a bit of time as the system analyzes the columns of your dataset. Once it's done this, you'll get to edit the auto-generated schema and select the column for predicting on. Here, you can also update the column type, as well as whether it is nullable. </p>
			<p>You can also view datasets that may have a lot of columns to get a nice overview of their data. You can click on the different column names to see some statistics about your columns. After analyzing the data, we can start the training process. This is where AutoML really shines because all you have to do is click <strong class="bold">Train</strong>. </p>
			<p>There are some options that you can set, including a maximum budget of training hours. This enables you to experiment with your data if you want and limit that training time before committing to a full, longer training run. You'll notice that the training times shown are somewhat on the long side of things. This is because it's not only doing model tuning but also selecting what model to use in the first place. So, as a result, there's a lot of things happening during training. But we don't have to do anything here. </p>
			<p>Once the <a id="_idIndexMarker436"/>training is completed, we must evaluate and deploy the model. You will be able to see how the training did, as well as the metrics about the model's performance. Finally, we will deploy the model to get predictions. There's even an editor in the browser that will make requests to your endpoint, so you don't need to set up a local environment to make these calls to try and test it out. </p>
			<p>Now that you have learned how AutoML Tables works, let's explore it in practice. </p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor121"/>Creating an AutoML Tables experiment </h1>
			<p>AutoML Tables <a id="_idIndexMarker437"/>automatically builds and deploys state-of-the-art machine learning models on structured data. Let's start with our first experiment to put this knowledge into practice: </p>
			<ol>
				<li>Access the <a id="_idIndexMarker438"/>Google Cloud AI Platform home page by visiting this link: <a href="https://console.cloud.google.com/home/">https://console.cloud.google.com/home/</a>. Click on the <strong class="bold">Datasets</strong> link in the left pane; you will see the following screen:<div id="_idContainer268" class="IMG---Figure"><img src="image/Figure_9.1_B16890.jpg" alt="Figure 9.1 – Google Cloud AI Platform home page&#13;&#10;"/></div><p class="figure-caption">Figure 9.1 – Google Cloud AI Platform home page</p></li>
				<li>On <a id="_idIndexMarker439"/>the <strong class="bold">Google AutoML Tables</strong> main screen, start the process by creating a new dataset. Click on the <strong class="bold">NEW DATASET</strong> button to create a new dataset and name it <strong class="source-inline">IrisAutoML</strong>. Then, click on <strong class="bold">CREATE DATASET</strong>:<div id="_idContainer269" class="IMG---Figure"><img src="image/Figure_9.2_B16890.jpg" alt="Figure 9.2 – AutoML Tables – Create new dataset screen &#13;&#10;"/></div><p class="figure-caption">Figure 9.2 – AutoML Tables – Create new dataset screen </p></li>
				<li>For this <a id="_idIndexMarker440"/>experiment, we will start with the Iris dataset. You can download the CSV file from <a href="https://www.kaggle.com/uciml/iris">https://www.kaggle.com/uciml/iris</a> since we will be using it in the next step. The dataset is too small to be used for automated machine learning though, but you will see how this unfolds soon. </li>
				<li>Now, you need to import the data (CSV) file into <strong class="bold">Google AutoML Tables</strong>. The file needs to be uploaded to a storage bucket. Select the file from your machine and click on <strong class="bold">BROWSE</strong> to create a storage destination on GCP, as shown in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer270" class="IMG---Figure">
					<img src="image/Figure_9.3_B16890.jpg" alt="Figure 9.3 – AutoML Tables – import file from local computer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – AutoML Tables – import file from local computer</p>
			<p>To <a id="_idIndexMarker441"/>create a storage bucket, you need to follow these steps. </p>
			<ol>
				<li value="1">First, provide a name for your storage bucket:<div id="_idContainer271" class="IMG---Figure"><img src="image/Figure_9.4_B16890.jpg" alt="Figure 9.4 – AutoML Tables – creating a storage bucket on GCP&#13;&#10;"/></div><p class="figure-caption">Figure 9.4 – AutoML Tables – creating a storage bucket on GCP</p></li>
				<li>Then, choose <a id="_idIndexMarker442"/>where you would like to store the data. The options are region (single region), dual region with <strong class="bold">high availability</strong> (<strong class="bold">HA</strong>), or multi-region for highest availability across multiple locations. For this example, we will choose <strong class="bold">us-central1</strong> as a single region, but you can choose another region if it suits you better geographically:<div id="_idContainer272" class="IMG---Figure"><img src="image/Figure_9.5_B16890.jpg" alt="Figure 9.5 – AutoML Tables – choosing a location to create a storage bucket&#13;&#10;"/></div><p class="figure-caption">Figure 9.5 – AutoML Tables – choosing a location to create a storage bucket</p></li>
				<li>Next, choose <a id="_idIndexMarker443"/>the default storage class for the data. The storage classes you can choose from are <strong class="bold">Standard</strong>, <strong class="bold">Nearline (</strong>backup<strong class="bold">)</strong>, <strong class="bold">Coldline (</strong>disaster recovery<strong class="bold">)</strong>, and <strong class="bold">Archive (</strong>for archival use<strong class="bold">)</strong>. Choose the <strong class="bold">Standard</strong> class for the purpose of this implementation, as seen in the following screenshot:  <div id="_idContainer273" class="IMG---Figure"><img src="image/Figure_9.6_B16890.jpg" alt="Figure 9.6 – AutoML Tables – choosing a storage class for your data on GCP&#13;&#10;"/></div><p class="figure-caption">Figure 9.6 – AutoML Tables – choosing a storage class for your data on GCP</p></li>
				<li>Finally, the <a id="_idIndexMarker444"/>encryption settings need to be configured. Here, you can provide your own key or use the default setting of using Google's managed key. Click on <strong class="bold">CREATE</strong> to complete the process of making the bucket:</li>
			</ol>
			<div>
				<div id="_idContainer274" class="IMG---Figure">
					<img src="image/Figure_9.7_B16890.jpg" alt="Figure 9.7 – AutoML Tables – choosing encryption settings &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – AutoML Tables – choosing encryption settings </p>
			<p>This will trigger the bucket being created and the data being imported. You will see the following screen: </p>
			<div>
				<div id="_idContainer275" class="IMG---Figure">
					<img src="image/Figure_9.8_B16890.jpg" alt="Figure 9.8 – AutoML Tables – data being imported into the GCP bucket&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – AutoML Tables – data being imported into the GCP bucket</p>
			<p>This is <a id="_idIndexMarker445"/>where we will learn an important lesson: not all data is suitable for automated machine learning. Once the import process is complete, you will see the following error message:</p>
			<div>
				<div id="_idContainer276" class="IMG---Figure">
					<img src="image/Figure_9.9_B16890.jpg" alt="Figure 9.9 – AutoML Tables – too few rows error &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.9 – AutoML Tables – too few rows error </p>
			<p>Even though you can do this experiment with other tools, cloud automated machine learning platforms set a minimum bar to ensure the quality of their algorithms is not compromised. This example provides us with a critical lesson that not all problems are automated machine learning-worthy.  </p>
			<p>Let's repeat the same experiment with a larger dataset – the loan risk dataset – which contains 21 fields and 1,000 instances. You can download it from BigML (<a href="http://bml.io/W2SpyF">http://bml.io/W2SpyF</a>, BigML, Inc. Corvallis, Oregon, USA, 2011). This dataset was created by Dr. Hans Hofmann at Institut für Statistik und Ökonometrie, Universität Hamburg, and contains fields such as checking status, duration, credit history, purpose, credit amount, and savings status. These can be used to create a model that will predict the level <a id="_idIndexMarker446"/>of the risk of a loan application. </p>
			<p>Let's carry out the aforementioned steps for the loan risk dataset by creating a bucket:</p>
			<ol>
				<li value="1">Download the dataset from <a href="http://bml.io/W2SpyF">http://bml.io/W2SpyF</a>. Click on the <strong class="bold">CREATE DATASET</strong> button and import the loan risk dataset:<div id="_idContainer277" class="IMG---Figure"><img src="image/Figure_9.10_B16890.jpg" alt="Figure 9.10 – AutoML Tables – choosing a new dataset bucket&#13;&#10;"/></div><p class="figure-caption">Figure 9.10 – AutoML Tables – choosing a new dataset bucket</p></li>
				<li>As the import process starts, upload the csv file extracted from the dataset that we downloaded in step 5 file and point it to the destination cloud storage by clicking the <strong class="bold">SELECT FILES</strong> button:<div id="_idContainer278" class="IMG---Figure"><img src="image/Figure_9.11_B16890.jpg" alt="Figure 9.11 – AutoML Tables – choosing storage for data &#13;&#10;"/></div><p class="figure-caption">Figure 9.11 – AutoML Tables – choosing storage for data </p><p>Since the loan dataset meets the required size limitations, it is imported successfully, and you <a id="_idIndexMarker447"/>will see the following training screen. This is where you can edit the auto-generated schema and select the column for predicting on. You can also update the column type, as well as whether it is nullable. </p><p>This screen gives you a detailed overview of the dataset. You can click on the different column names to see some statistics about your columns:</p><div id="_idContainer279" class="IMG---Figure"><img src="image/Figure_9.12_B16890.jpg" alt=""/></div><p class="figure-caption">Figure 9.12 – AutoML Tables – training screen </p></li>
				<li>Now, select <a id="_idIndexMarker448"/>the target column; that is, the column to predict, which is the class. The class is a categorical field with two possible values: good credit or bad credit. This determines whether this specific individual qualifies for credit. Once you've selected the class, click on <strong class="bold">TRAIN MODEL</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer280" class="IMG---Figure">
					<img src="image/Figure_9.13_B16890.jpg" alt="Figure 9.13 – AutoML Tables – selecting the target column for training&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.13 – AutoML Tables – selecting the target column for training</p>
			<p>Upon clicking on the <strong class="bold">TRAIN MODEL</strong> button, you will see a fluid menu on the right. The menu can be seen in the following screenshot. This is where you can set experimental parameters <a id="_idIndexMarker449"/>and is where AutoML really shines because all you have to do is click <strong class="bold">Train</strong>. There are some options that you can set, including a maximum budget for training hours. This enables you to experiment with your data if you want and limit that training time before committing to a full, longer training run. You'll notice that the training times shown are somewhat on the long side of things. This is because it's not only doing model tuning but also selecting what model to use in the first place:</p>
			<div>
				<div id="_idContainer281" class="IMG---Figure">
					<img src="image/Figure_9.14_B16890.jpg" alt="Figure 9.14 – AutoML Tables – choosing a storage class for your data on GCP&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.14 – AutoML Tables – choosing a storage class for your data on GCP</p>
			<p>How long <a id="_idIndexMarker450"/>should you train your model for? The suggested training time from GCP is defined at <a href="https://cloud.google.com/automl-tables/docs/train">https://cloud.google.com/automl-tables/docs/train</a>, as shown in the following screenshot: </p>
			<div>
				<div id="_idContainer282" class="IMG---Figure">
					<img src="image/Figure_9.15_B16890.jpg" alt="Figure 9.15 – AutoML Tables – suggested training times &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.15 – AutoML Tables – suggested training times </p>
			<p>You can find the respective pricing guide at <a href="https://cloud.google.com/automl-tables/pricing">https://cloud.google.com/automl-tables/pricing</a>. </p>
			<p>You can also review the advanced options, which is where you can see the optimization objectives for the experiment. Since <a id="_idIndexMarker451"/>this is a classification experiment, the objectives listed include A<strong class="bold">UC ROC</strong>, <strong class="bold">Log loss</strong>, <strong class="bold">AUC PR</strong>, <strong class="bold">Precision</strong>, and <strong class="bold">Recall</strong>. The <strong class="bold">Early stopping</strong> toggle ensures that upon detecting that no more improvements can be made, it stops the process. Otherwise, AutoML Tables will continue training until the budget is met. </p>
			<p>Click on <strong class="bold">TRAIN MODEL</strong> to start this operation:</p>
			<div>
				<div id="_idContainer283" class="IMG---Figure">
					<img src="image/Figure_9.16_B16890.jpg" alt="Figure 9.16 – AutoML Tables – advanced options for training&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.16 – AutoML Tables – advanced options for training</p>
			<p>Upon starting the experiment, you will see the following screen. It's initiated when the infrastructure is set up, as well as when the model is eventually trained:</p>
			<div>
				<div id="_idContainer284" class="IMG---Figure">
					<img src="image/Figure_9.17_B16890.jpg" alt="Figure 9.17 – AutoML Tables – starting the AutoML Tables experiment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.17 – AutoML Tables – starting the AutoML Tables experiment</p>
			<p>Once the training is completed, we must evaluate and deploy the model. At this stage, you will <a id="_idIndexMarker452"/>be able to see how the training did, as well as any metrics about the model's performance. Finally, you can deploy the model to get predictions about credit worthiness:</p>
			<div>
				<div id="_idContainer285" class="IMG---Figure">
					<img src="image/Figure_9.18_B16890.jpg" alt="Figure 9.18 – AutoML Tables – choosing a storage class for your data on GCP&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.18 – AutoML Tables – choosing a storage class for your data on GCP</p>
			<p>The accuracy is measured as a percentage, while the area under the <strong class="bold">precision recall</strong> (<strong class="bold">PR</strong>) curve <a id="_idIndexMarker453"/>ranges from <strong class="source-inline">0</strong> to <strong class="source-inline">1</strong>. Training the model with different training costs (duration) will get you a higher value, which indicates a higher-quality model:</p>
			<div>
				<div id="_idContainer286" class="IMG---Figure">
					<img src="image/Figure_9.19_B16890.jpg" alt="Figure 9.19 – AutoML Tables – details of the trained model, including its F1 score, accuracy, and "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.19 – AutoML Tables – details of the trained model, including its F1 score, accuracy, and precision </p>
			<p>The following <a id="_idIndexMarker454"/>page also shows the confusion matrix, which shows the quality of the model on the data; that is, how many data-points were predicted correctly, compared to how many were incorrectly predicted:</p>
			<div>
				<div id="_idContainer287" class="IMG---Figure">
					<img src="image/Figure_9.20_B16890.jpg" alt="Figure 9.20 – AutoML Tables – confusion matrix &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.20 – AutoML Tables – confusion matrix </p>
			<p>Feature importance – that is, which feature has the biggest impact on the resulting model – is also shown. In this case, you can observe that the checking status, the duration <a id="_idIndexMarker455"/>of credit, and the purpose seem to have the most impact on the credit decision:</p>
			<div>
				<div id="_idContainer288" class="IMG---Figure">
					<img src="image/Figure_9.21_B16890.jpg" alt="Figure 9.21 – AutoML Tables – feature importance table &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.21 – AutoML Tables – feature importance table </p>
			<p>Now that we've trained the model, let's proceed with its deployment. </p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor122"/>Understanding AutoML Tables model deployment</h1>
			<p>In order <a id="_idIndexMarker456"/>to deploy the model that we trained in the previous section, perform the following steps:</p>
			<ol>
				<li value="1">We must click on the <strong class="bold">TEST &amp; USE</strong> tab to deploy the model. There are multiple ways of testing the trained model: you can either test it as a batch prediction (file-based), as an online prediction (API), or export it in a Docker container. The option at the top of the page lets you toggle between online predictions via the REST API and batch predictions. This allows you to upload a CSV file or point to a BigQuery table and get prediction results for that entire file or table. Considering the amount of time it takes to use, AutoML Tables enables you to achieve a much higher level of model performance than you could reach manually. We will be doing online API-based prediction in this section:<div id="_idContainer289" class="IMG---Figure"><img src="image/Figure_9.22_B16890.jpg" alt="Figure 9.22 – AutoML Tables – exporting the model &#13;&#10;"/></div><p class="figure-caption">Figure 9.22 – AutoML Tables – exporting the model </p></li>
				<li>Click on the <strong class="bold">ONLINE PREDICTION</strong> tab. You will see the following screen. Here, you can call the API right from the console:<div id="_idContainer290" class="IMG---Figure"><img src="image/Figure_9.23_B16890.jpg" alt="Figure 9.23 – AutoML Tables – online prediction on the trained model&#13;&#10;"/></div><p class="figure-caption">Figure 9.23 – AutoML Tables – online prediction on the trained model</p></li>
				<li>However, if <a id="_idIndexMarker457"/>you just click on <strong class="bold">PREDICT</strong>, it will give you the error shown in the following screenshot. Why? Because the model hasn't been deployed yet, which means there is no endpoint to call:<div id="_idContainer291" class="IMG---Figure"><img src="image/Figure_9.24_B16890.jpg" alt="Figure 9.24 – AutoML Tables – online prediction on the trained model's error &#13;&#10;"/></div><p class="figure-caption">Figure 9.24 – AutoML Tables – online prediction on the trained model's error </p></li>
				<li>Click <a id="_idIndexMarker458"/>on the <strong class="bold">Deploy model</strong> button. You will see the following popup, confirming the deployment details. Now, click on <strong class="bold">DEPLOY</strong>:<div id="_idContainer292" class="IMG---Figure"><img src="image/Figure_9.25_B16890.jpg" alt="Figure 9.25 – AutoML Tables – Deploying the trained model popup&#13;&#10;"/></div><p class="figure-caption">Figure 9.25 – AutoML Tables – Deploying the trained model popup</p><p>This starts the process of model deployment. Once completed, you will see the following screen, which states that the model has been successfully deployed and is available for requests, along with the size it takes up. You should remember that the model is now running on a server, so you will be spending compute and storage costs associated with running the model. This is what the prior warning was about. </p></li>
				<li>At <a id="_idIndexMarker459"/>this point, you can go ahead and click on the <strong class="bold">PREDICT</strong> button:<div id="_idContainer293" class="IMG---Figure"><img src="image/Figure_9.26_B16890.jpg" alt="Figure 9.26 – AutoML Tables – calling the prediction API&#13;&#10;"/></div><p class="figure-caption">Figure 9.26 – AutoML Tables – calling the prediction API</p><p>It will pass the JSON request to the API and invoke the prediction function. This function will return the response, along with the prediction confidence score, as shown in the following screenshot: </p><div id="_idContainer294" class="IMG---Figure"><img src="image/Figure_9.27_B16890.jpg" alt="Figure 9.27 – AutoML Tables – response from the online prediction API&#13;&#10;"/></div><p class="figure-caption">Figure 9.27 – AutoML Tables – response from the online prediction API</p><p>The preceding <a id="_idIndexMarker460"/>screenshot shows the results of the model. It has a good credit response since it has a <strong class="source-inline">0.661</strong> confidence score. At this point, you can switch to the feature column view and edit some of the parameters. We intuitively known that age and the duration of the credit have a significant impact on our credit results. Lowering the age from <strong class="source-inline">48</strong> to <strong class="source-inline">18</strong> and increasing the credit term to <strong class="source-inline">60</strong> in the editable form turns this good credit decision into a bad one. </p></li>
				<li>Let's change these values and invoke the API again. You will see that the results have changed to bad ones, as seen in the following screenshot: </li>
			</ol>
			<div>
				<div id="_idContainer295" class="IMG---Figure">
					<img src="image/Figure_9.28_B16890.jpg" alt="Figure 9.28 – AutoML Tables – invoking the model with a modified age and credit duration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.28 – AutoML Tables – invoking the model with a modified age and credit duration</p>
			<p>The preceding <a id="_idIndexMarker461"/>experiments have shown you how to train, deploy, and test a model. Now, let's explore how to use BigQuery-based public datasets with AutoML Tables. </p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor123"/>AutoML Tables with BigQuery public datasets</h1>
			<p>Data has been called the new oil of the digital economy. To extend this analogy, automated machine learning is the engine that uses data to provide advanced analytics without <a id="_idIndexMarker462"/>custom manual plumbing each time, but I digress. Real-world data for performing machine learning experiments comes from various organizations, though counterparts are needed to perform experiments and try out hypotheses. Such a data repository is the Google BigQuery cloud data warehouse – specifically, its large collection of public datasets. In this example, we will use BigQuery, one of the three methods specified in the data ingestion process for AutoML Tables, for our experiment. </p>
			<p>Like the loan dataset we used earlier, the adult income dataset is a public dataset derived from the 1994 United States Census Bureau and uses demographic information to predict the income of two classes: above or below $50,000 per year. The dataset contains 14 attributes, with the target fields being income and number of attributes. The data <a id="_idIndexMarker463"/>can be downloaded from <a href="https://www.kaggle.com/wenruliu/adult-income-dataset?select=adult.csv">https://www.kaggle.com/wenruliu/adult-income-dataset?select=adult.csv</a>. However, BigQuery contains a repository of popular public datasets, so we will use that instead. Let's get started: </p>
			<ol>
				<li value="1">As we did previously, click on <strong class="bold">Create new dataset</strong> in the <strong class="bold">Tables</strong> tab and click on the <strong class="bold">CREATE DATASET</strong> button:<div id="_idContainer296" class="IMG---Figure"><img src="image/Figure_9.29_B16890.jpg" alt="Figure 9.29 – AutoML Tables – Create new dataset prompt&#13;&#10;"/></div><p class="figure-caption">Figure 9.29 – AutoML Tables – Create new dataset prompt</p></li>
				<li>Now, to add to the dataset, select the third option – that is, <strong class="bold">Select a table or view from BigQuery</strong> – as shown in the following screenshot:<div id="_idContainer297" class="IMG---Figure"><img src="image/Figure_9.30_B16890.jpg" alt="Figure 9.30 – AutoML Tables – selecting the BigQuery data&#13;&#10;"/></div><p class="figure-caption">Figure 9.30 – AutoML Tables – selecting the BigQuery data</p></li>
				<li>BigQuery can be accessed at <a href="https://console.cloud.google.com/bigquery">https://console.cloud.google.com/bigquery</a>. This is where you can view the datasets it contains. You can do this by calling the following query:<p class="source-code">SELECT  * FROM  `bigquery-public-data.ml_datasets.census_adult_income`</p><p>You will see the following output. Our goal is to export this data to a bucket where it can be used for our experiment. Set the destination table for the query result as a dataset and click on <strong class="bold">Run</strong>:</p></li>
			</ol>
			<div>
				<div id="_idContainer298" class="IMG---Figure">
					<img src="image/Figure_9.31_B16890.jpg" alt="Figure 9.31 – AutoML Tables – BigQuery search results from the census adult income dataset&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.31 – AutoML Tables – BigQuery search results from the census adult income dataset</p>
			<p>The following <a id="_idIndexMarker464"/>is a brief list of BigQuery public datasets. This makes using these curated datasets quite accessible and easy to use across the entire GCP suite of products:</p>
			<div>
				<div id="_idContainer299" class="IMG---Figure">
					<img src="image/Figure_9.32_B16890.jpg" alt="Figure 9.32 – AutoML Tables – BigQuery public datasets&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.32 – AutoML Tables – BigQuery public datasets</p>
			<p>In the <a id="_idIndexMarker465"/>previous step, you ran the query, which is now completed, and created a dataset, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer300" class="IMG---Figure">
					<img src="image/Figure_9.33_B16890.jpg" alt="Figure 9.33 – AutoML Tables – BigQuery public dataset export&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.33 – AutoML Tables – BigQuery public dataset export</p>
			<p>Now that <a id="_idIndexMarker466"/>the data has been exported to a bucket, you can use it to experiment in AutoML Tables.</p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor124"/>Automated machine learning for price prediction</h1>
			<p>So far, you have seen how AutoML Tables can be used for classification problems; that is, finding <a id="_idIndexMarker467"/>classes in a dataset. Now, let's do some regression; that is, predicting values. To do this, we will use the house sales prediction dataset. The King County house sales dataset contains prices for King County, which includes Seattle. The dataset can be downloaded from Kaggle at <a href="https://www.kaggle.com/harlfoxem/housesalesprediction">https://www.kaggle.com/harlfoxem/housesalesprediction</a>.</p>
			<p>For this experiment, our goal is to predict a house's sale value (price) by using 21 features and 21,613 observations or data points:</p>
			<ol>
				<li value="1">Let's start in AI Platform by clicking on the <strong class="bold">CREATE DATASET</strong> button on the main page:<div id="_idContainer301" class="IMG---Figure"><img src="image/Figure_9.34_B16890.jpg" alt="Figure 9.34 – AutoML Tables – getting started with the AI Platform home page&#13;&#10;"/></div><p class="figure-caption">Figure 9.34 – AutoML Tables – getting started with the AI Platform home page</p><p>Here, you <a id="_idIndexMarker468"/>must choose a dataset name and region, as shown in the following screenshot. Set the dataset's type to tabular since it currently has classification and regression automated machine learning capabilities and click <strong class="bold">CREATE</strong>:</p><div id="_idContainer302" class="IMG---Figure"><img src="image/Figure_9.35_B16890.jpg" alt="Figure 9.35 – AutoML Tables – selecting the automated machine learning objective &#13;&#10;"/></div><p class="figure-caption">Figure 9.35 – AutoML Tables – selecting the automated machine learning objective </p></li>
				<li>Upon <a id="_idIndexMarker469"/>clicking <strong class="bold">CREATE</strong>, you will see the following screen. Select the<strong class="bold"> Upload CSV files</strong> <strong class="bold">from your computer</strong> option and upload it to cloud storage by pressing <strong class="bold">CONTINUE</strong>:<div id="_idContainer303" class="IMG---Figure"><img src="image/Figure_9.36_B16890.jpg" alt="Figure 9.36 – AutoML Tables – choosing storage parameters for your data&#13;&#10;"/></div><p class="figure-caption">Figure 9.36 – AutoML Tables – choosing storage parameters for your data</p></li>
				<li>Upon <a id="_idIndexMarker470"/>clicking <strong class="bold">CONTINUE</strong>, the dataset will be uploaded and you will see the following screen, which shows a description of the data. Click on <strong class="bold">TRAIN NEW MODEL</strong>:<div id="_idContainer304" class="IMG---Figure"><img src="image/Figure_9.37_B16890.jpg" alt="Figure 9.37 – AutoML Tables – data description details once uploading is completed&#13;&#10;"/></div><p class="figure-caption">Figure 9.37 – AutoML Tables – data description details once uploading is completed</p></li>
				<li>At this <a id="_idIndexMarker471"/>point, you are at the training the new model workflow. Here, set the objective to <strong class="source-inline">Regression</strong> and the method to <strong class="bold">AutoML</strong>. Then, press <strong class="bold">CONTINUE</strong>:<div id="_idContainer305" class="IMG---Figure"><img src="image/Figure_9.38_B16890.jpg" alt="Figure 9.38 – AutoML Tables – Train new model steps&#13;&#10;"/></div><p class="figure-caption">Figure 9.38 – AutoML Tables – Train new model steps</p></li>
				<li>Next, we must edit the model definition. Here, choose the target column (the price to be predicted) and the data split; that is, how you would like the test and training data to be split. The default option of random assignment is a good choice <a id="_idIndexMarker472"/>unless you have a specific need to do manual or chronological stratification. Click <strong class="bold">CONTINUE</strong> to proceed:<div id="_idContainer306" class="IMG---Figure"><img src="image/Figure_9.39_B16890.jpg" alt="Figure 9.39 – AutoML Tables – Train new model steps&#13;&#10;"/></div><p class="figure-caption">Figure 9.39 – AutoML Tables – Train new model steps</p><p>The following screenshot gives you the option to perform granular actions with data, such as removing or filtering columns, applying transformations, and more:</p><div id="_idContainer307" class="IMG---Figure"><img src="image/Figure_9.40_B16890.jpg" alt="Figure 9.40 – AutoML Tables – description of the dataset upon being uploaded&#13;&#10;"/></div><p class="figure-caption">Figure 9.40 – AutoML Tables – description of the dataset upon being uploaded</p></li>
				<li>You <a id="_idIndexMarker473"/>can also choose optimization <a id="_idIndexMarker474"/>objectives. The choices are <strong class="bold">root mean square error</strong> (<strong class="bold">RMSE</strong>), <strong class="bold">mean absolute error</strong> (<strong class="bold">MAE</strong>), or <strong class="bold">root mean square log error</strong> (<strong class="bold">RMSLE</strong>), which <a id="_idIndexMarker475"/>is robust <a id="_idIndexMarker476"/>against the outliers. Select <strong class="bold">RMSE (Default)</strong> and click on <strong class="bold">CONTINUE</strong> to proceed:<div id="_idContainer308" class="IMG---Figure"><img src="image/Figure_9.41_B16890.jpg" alt="Figure 9.41 – AutoML Tables – description of the optimization objectives&#13;&#10;"/></div><p class="figure-caption">Figure 9.41 – AutoML Tables – description of the optimization objectives</p></li>
				<li>The final thing we must look at before we start training is the training budget. This step <a id="_idIndexMarker477"/>should be familiar to you from our earlier experiments. Set a budget of 5 hours and click on <strong class="bold">START TRAINING</strong>. Do not forget to toggle on <strong class="bold">Enable early stopping</strong> – we don't want to exhaust the budget if the results are reached earlier:<div id="_idContainer309" class="IMG---Figure"><img src="image/Figure_9.42_B16890.jpg" alt="Figure 9.42 – AutoML Tables – training the new model's compute and price step&#13;&#10;"/></div><p class="figure-caption">Figure 9.42 – AutoML Tables – training the new model's compute and price step</p><p>The model will start training. You will be able to see its progress in the <strong class="bold">Training jobs and models</strong> side panel:</p><div id="_idContainer310" class="IMG---Figure"><img src="image/Figure_9.43_B16890.jpg" alt="Figure 9.43 – AutoML Tables – new model training started &#13;&#10;"/></div><p class="figure-caption">Figure 9.43 – AutoML Tables – new model training started </p><p>This specific model took 1 hour and 35 minutes to train. The following screen will appear once it's <a id="_idIndexMarker478"/>completed. This screen will show you the status attributes and training performance of the model:</p><div id="_idContainer311" class="IMG---Figure"><img src="image/Figure_9.44_B16890.jpg" alt="Figure 9.44 – AutoML Tables – training performance and results&#13;&#10;"/></div><p class="figure-caption">Figure 9.44 – AutoML Tables – training performance and results</p><p>Scroll down the <strong class="bold">Training performance and results</strong> page to view the feature importance <a id="_idIndexMarker479"/>chart for this model. This chart proves the age-old adage of real estate – location, location, location – to be correct. Also, the price of the property and the square feet of living space are closely related. This is not surprising either:</p><div id="_idContainer312" class="IMG---Figure"><img src="image/Figure_9.45_B16890.jpg" alt="Figure 9.45 – AutoML Tables – results and their feature importance&#13;&#10;"/></div><p class="figure-caption">Figure 9.45 – AutoML Tables – results and their feature importance</p></li>
				<li>At this point, you can deploy and test the model by clicking on <strong class="bold">DEPLOY &amp; TEST</strong>, as shown in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer313" class="IMG---Figure">
					<img src="image/Figure_9.46_B16890.jpg" alt="Figure 9.46 – AutoML Tables – deploying the model to an endpoint&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.46 – AutoML Tables – deploying the model to an endpoint</p>
			<p>In the several experiments we've conducted in this section, we have found that the size of the data <a id="_idIndexMarker480"/>was a substantial factor for improved accuracy. As the number of observations in a dataset increases, automated machine learning can perform a better neural architecture search and hyperparameter optimization to get the best results. </p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor125"/>Summary</h1>
			<p>In this chapter, you learned how to perform automated machine learning using AutoML Tables. We started by setting up a Cloud AutoML Tables-based experiment and then demonstrated how the AutoML Tables model is trained and deployed. Using multiple data sources, we explored AutoML Tables with BigQuery public datasets, as well as both classification and regression. We hope that this chapter has made you familiar with working with GCP AutoML so that you can apply it to your automated machine learning experiments. </p>
			<p>In the next chapter, we will explore an enterprise use case for automated machine learning. </p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor126"/>Further reading</h1>
			<p>For more information regarding what was covered in this chapter, please refer to the following links:</p>
			<ul>
				<li>AutoML Tables beginner's guide: <p><a href="https://cloud.google.com/automl-tables/docs/beginners-guide">https://cloud.google.com/automl-tables/docs/beginners-guide</a></p></li>
				<li>AutoML Tables notebooks:<p><a href="https://cloud.google.com/automl-tables/docs/notebooks">https://cloud.google.com/automl-tables/docs/notebooks</a></p></li>
			</ul>
		</div>
	</body></html>