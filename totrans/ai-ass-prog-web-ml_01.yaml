- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s a New World, One with AI Assistants, and You’re Invited
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In November 2022, ChatGPT arrived from seemingly nowhere. Over time, ChatGPT
    gained momentum, gradually evolving into a widely embraced tool. Eventually, millions
    actively incorporated ChatGPT into their workflows, leveraging its capabilities
    for generating insights, summarizing text, crafting code, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Its arrival changed many people’s workflow and improved it a lot in tasks like
    quickly understanding large bodies of text, writing emails, and more. Here you
    are, having bought this book, and hoping that you can learn how to use an AI tool
    like **ChatGPT** or **GitHub** **Copilot** to make you more efficient. That’s
    exactly the mission of this book: to teach you not only how to use these two AI
    tools but also to be able to apply them across various problem domains.'
  prefs: []
  type: TYPE_NORMAL
- en: Before we start solving problems using an AI assistant, let’s back up a bit;
    how did we get here? ChatGPT just didn’t arrive out of nowhere, right?
  prefs: []
  type: TYPE_NORMAL
- en: How ChatGPT came to be, from NLP to LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To tell the story of how we got here, to AI tools like ChatGPT, powered by **large
    language models** (**LLMs**), let’s first cover **natural language processing**
    (**NLP**).
  prefs: []
  type: TYPE_NORMAL
- en: 'NLP is a field of computer science, artificial intelligence, and computational
    linguistics. It’s concerned with the interactions between computers and human
    language, and how to program computers to process and analyze large amounts of
    natural language data. NLP is a hugely interesting area that has a range of useful
    applications in the real world. Here are some:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech recognition**: If you have a modern smartphone, you’ve likely interacted
    with voice assistants like Siri or Alexa, for example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Machine translation**: Google Translate is perhaps what comes to mind when
    thinking of machine translation, the ability to translate from one language to
    another automatically.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentiment analysis**: A very useful area is understanding the sentiment in
    areas like social media, for example. Companies want to know how brands are perceived;
    e-commerce wants to quickly understand product reviews to boost their business.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chatbots and virtual assistants**: You’ve likely seen chatbots being integrated
    on web pages even before the advent of ChatGPT. These chatbots can answer simpler
    questions, and companies have them to ensure you quickly get an answer to simpler
    questions and provide a more natural experience than an FAQ page, among other
    usage areas.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text summaries**: Search engines come to mind again when thinking about text
    summaries. You might have seen how, when you use search engines like Bing or Google,
    it’s able to summarize a page and show the summary together with the link to the
    page in a search result page. As a user, you get a better understanding of what
    link to click.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content recommendation**: This is another important area used by a variety
    of different domains. E-commerce uses this to present products you’re likely to
    be interested in, Xbox uses this to recommend what games to play and buy, and
    video streaming services display content you might want to watch next.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see already, with NLP, both companies and end users benefit greatly
    from adopting it.
  prefs: []
  type: TYPE_NORMAL
- en: The rise of LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How did we evolve from NLP to LLMs, then? Initially, NLP used rule-based systems
    and statistical methods underneath. This approach, although working well for some
    tasks, struggled with human language.
  prefs: []
  type: TYPE_NORMAL
- en: This changed for the better when deep learning, a subset of machine learning,
    was introduced to NLP, and we got models like RNN, recurrent neural networks,
    and transformer-based models, capable of learning patterns in data. The result
    was a considerable improvement in performance. With transformer-based models,
    we’re starting to lay the foundations of large language models.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are a type of transformer model. They can generate human-like text and,
    unlike NLP models, they’re good at a variety of tasks without needing specific
    training data. How is this possible, you ask? The answer is a combination of improved
    architecture, a vast increase in computational power, and gigantic datasets.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs rest on the idea that a large enough neural network can learn to do anything,
    given enough data and compute. This is a paradigm shift in how we program computers.
    Instead of writing code, we write prompts and let the model do the rest.
  prefs: []
  type: TYPE_NORMAL
- en: GPT models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many different types of LLMs out there, but let’s focus on GPT for
    a second, a type of LLM on which the book’s chosen tools are based (even if GitHub
    Copilot uses a specific subset known as Codex).
  prefs: []
  type: TYPE_NORMAL
- en: 'There have been several different versions developed in the last few years.
    Here are some models developed by the company OpenAI:'
  prefs: []
  type: TYPE_NORMAL
- en: 'GPT-1: The first one, with 117 million parameters using transformer architecture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GPT-2: This model has 1.5 billion parameters and is able to generate coherent
    and relevant text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GPT-3: This model has 175 billion parameters and is considerably better than
    its predecessor with features like answering questions, fiction generation, and
    even writing code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GPT-4: This model has been quoted to have 1.76 trillion parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of parameters allows the model to understand more nuanced and coherent
    text. It should also be said that the larger the model, the larger the computational
    resources that are needed to train it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ChatGPT recently switched to GPT-4 and the difference compared to GPT-3 is significant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How LLMs are better
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a better understanding of how LLMs came to be and where they
    came from, what makes LLMs great? What are some good examples of why we really
    should adopt AI assistants based on LLMs?
  prefs: []
  type: TYPE_NORMAL
- en: 'Because LLMs are bigger and more advanced, there are some areas in which they
    clearly outperform traditional NLP models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Context**: LLMs can understand not just the recent input but can produce
    responses based on a longer conversation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Few-shot learning**: To perform a task, LLMs usually just need a few examples
    to produce a correct response. This should be contrasted with NLP models, which
    usually use a large amount of task-specific training data to perform properly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance**: LLMs are better than traditional NLP models in areas like
    translations, questions, and summarization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s worth mentioning that LLMs aren’t perfect; they do generate incorrect responses
    and can sometimes make up responses, also known as hallucinations. It’s our hope
    though that by reading this book, you will see the advantages of using LLM-based
    AI assistants and you will feel the pros clearly outweigh the cons.
  prefs: []
  type: TYPE_NORMAL
- en: The new paradigm, programming with natural language
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probably the biggest game changer with using LLM-based AI assistants is that
    you’re able to interact with them using nothing but natural language. There’s
    no need to learn a programming language to get the response you need. This change
    constitutes a new paradigm in interacting with AI. We’re moving away from writing
    in specific languages for producing apps, data retrieval, or even how we produce
    images, presentations, and more to express at a high level what we want through
    a prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of things that are now possible to do using prompts, where
    it before needed considerably more effort:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Programming**: With a prompt, you express what app you want to build or what
    changes you want to make with the code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image generation**: Where you before needed a designer or artist, you can
    now generate via prompts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Videos**: There are tools out there that, once given a prompt, will generate
    videos where an avatar reads out your written text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text tasks**: LLM-based AI assistants can generate emails, summarize large
    bodies of text, author interview ads, and much more; anything you can imagine
    with text really.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these application areas mentioned above make it clear that LLM-based AI
    tools are useful not only to programmers and data scientists but numerous different
    professions.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Is everything working perfectly at this point? AI assistants aren’t able to
    replace “you” just yet, and should be considered more of a “thinking partner.”
    Microsoft has even, through conscious naming, called their AI assistants “Copilots”
    where you’re clearly the pilot that sets out the direction. These tools can generate
    text and other modalities in seconds, but you need to verify the correctness.
    Often, the first response you get from a tool is something you need to iterate
    over. The good news is that it just takes seconds to redo the instruction.
  prefs: []
  type: TYPE_NORMAL
- en: An important thing to realize about AI assistants is that the more skilled you
    are at a certain topic, the more intelligent questions you can ask of it, and
    you’ll be able to better assess the correctness of the response.
  prefs: []
  type: TYPE_NORMAL
- en: About this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The goals of this book are to:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduce you to the new paradigm of programming with natural language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide you with the tools to get started using AI assistants.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Empower you to use AI assistants effectively and responsibly by teaching you
    prompt engineering and specifically a set of prompting strategies (covered in
    *Chapter 2*) and some sound practices (covered in *Chapter 8*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We believe that with these tools, prompting strategies, and practices, you will
    be able to use AI assistants effectively and responsibly to augment your work
    and increase your productivity.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for professional developers within both the web and machine learning
    space. It is for those who want to learn how to use AI assistants like GitHub
    Copilot and ChatGPT to augment their work and increase their productivity.
  prefs: []
  type: TYPE_NORMAL
- en: Evolution of programming languages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Programming has gone through a series of changes and paradigm shifts throughout
    history:'
  prefs: []
  type: TYPE_NORMAL
- en: Ada Lovelace wrote the first algorithm for a machine, the Analytical Engine,
    in the 1840s. Lovelace is considered the first computer programmer and the first
    to recognize that the machine had applications beyond pure calculation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the 1940s, the first programmable computers were created. These computers
    were programmed using punch cards. One such computer was the Harvard Mark I, which
    was used to calculate the trajectory of artillery shells. Also, Bombe is worth
    mentioning, which was used to crack the Enigma code during World War II and was
    instrumental in the Allies winning the war.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the 1950s, the first high-level programming languages were created. This
    time period saw the birth of FORTRAN, LISP, COBOL, and ALGOL. Some of these languages
    are still in use today, especially in banking systems, scientific computing, and
    defense.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the 1970s, the first object-oriented programming languages were created.
    The 1970s meant we got Smalltalk, C++, and Objective-C. Except for Smalltalk,
    these languages are heavily in use today.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the 1990s, the first functional programming languages were created. The 1990s
    gave us Haskell, OCaml, and Scala. The benefit of these languages is that they
    encourage immutability and pure functions, which makes them easier to reason about
    and test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the 2000s, the first declarative programming languages were created. Declarative
    programming languages are used to describe what you want to do, rather than how
    you want to do it. The 2000s gave us SQL, HTML, and CSS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the 2010s, the first low-code and no-code platforms were created. These platforms
    opened programming to a wider audience, and allowed anyone, regardless of technical
    background, to build applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the 2020s, the first AI assistants were created that leveraged natural language.
    If you can write a sentence, you can write code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, programming has gone through a series of changes and paradigm shifts.
    Prompt-first programming is the latest paradigm shift and mastering it will be
    key to staying relevant in the immediate future.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If changes and paradigm shifts took years or decades in the past, they now take
    months or even weeks. We’re moving toward a new world at breakneck speed.
  prefs: []
  type: TYPE_NORMAL
- en: There’s reason to be excited, as we’re moving faster than before, but as always,
    we should exercise caution. We should be aware of the risks and the dangers of
    using these tools irresponsibly, but most of all we should be aware of the opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: As Alan Kay once said, “The best way to predict the future is to invent it.”
  prefs: []
  type: TYPE_NORMAL
- en: How to use this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We believe the best way to use this book is to follow the chapters in order.
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 2*, with the prompting strategies, is the most important chapter in
    the book. These patterns and strategies are referred to throughout the book and
    are the foundation for how to use AI assistants effectively and responsibly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The book is written in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introduction**: The first chapter aims to provide you with an overview of
    what this book is about, its goals, and who it is for.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prompt strategy**: The idea is to lay the foundation on how to break down
    problems within the domains of data science and web development. From this chapter,
    you will learn strategies you can adopt for your own problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tools of the trade**: The third chapter introduces you to our tools, GitHub
    Copilot and ChatGPT, what they are, how they work, and how to install them. However,
    the book is written in such a way that you can take any of the prompts we suggest
    and feed those into any AI assistant, and get a similar experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The remaining chapters of the book show how we use the prompt strategies from
    *Chapter 2* and apply them to various domains from web development to data science
    and machine learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Happy reading!
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/aicode](https://packt.link/aicode)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code510410532445718281.png)'
  prefs: []
  type: TYPE_IMG
