<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Implementing Unsupervised Algorithms</h1>
                </header>
            
            <article>
                
<p><span>In <a href="b2822c69-13f0-4943-9e66-f9ef04898b60.xhtml">Chapter 3</a>, <em>Supervised Machine Learning Models for Your Data</em>, we focused on</span><span> </span><em>supervised</em><span> </span><span>machine learning <span>algorithms</span>. </span>This chapter will build on the previous chapters in that we will continue the tour of the machine learning paradigm offered in IBM Cloud. The chapter will cover <strong>supervised</strong> versus <strong>unsupervised</strong> as well as <strong>semi-supervised</strong> learning.</p>
<p>Supervised learning problems are usually categorized into <strong>regression</strong> and <strong>classification</strong> problems, and we saw the ways that using IBM Watson Studio and its model builder feature can help solve for those sort of problems.</p>
<p>Unsupervised learning, on the other hand, allows us to approach problems when we might have little or no idea what the results should or would look like. Here, in these types of problems, we can attempt to derive structure from the data itself by<span> </span><strong>clustering</strong><span> </span>(the data) based upon relationships identified among the variables within the data, even if we don't necessarily know the effect of those variables.</p>
<p>This chapter will focus on the concept of unsupervised machine learning and its related topics.</p>
<p>Moreover, this chapter will discuss some common clustering algorithms. And finally, this chapter will conclude by discussing online versus batch learning concepts.</p>
<p>We will divide this chapter into the following areas:</p>
<ul>
<li>Unsupervised learning</li>
<li>Semi-supervised learning</li>
<li>Anomaly detection</li>
<li>Online and/or batch learning</li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unsupervised learning</h1>
                </header>
            
            <article>
                
<p>As we discussed in the last chapter, supervised learning is the machine learning process of leveraging a function that maps an input to an output based on example input-output pairs, inferring a function from labeled training data comprising a set of training samples.</p>
<p>Again, in the last chapter, we saw how, when using the model builder, we could set a <strong>label column</strong> for a predictive model to predict. Recall that, in one example, we chose the column <kbd>IS_TENT</kbd> from within the training data for the model to predict.</p>
<p>Now, in this section of this chapter, we want to examine scenarios where we have no label data defined in our data, or in other words, unsupervised learning problems. To reiterate, in these cases, we have no feedback (or label) based on the prior prediction results available; we expect to solve these cases without indicating or setting a desired label.</p>
<div class="packt_infobox">To further understand what unsupervised learning really is, you can head on to the following link:<span> </span><a href="https://www.datasciencecentral.com/profiles/blogs/what-is-unsupervised-learning">https://www.datasciencecentral.com/profiles/blogs/what-is-unsupervised-learning</a>.<br/>
<br/>
Why not always use supervised learning (and labeled data)? To understand why you might find yourself using an unsupervised learning model, consider the fact that it is usually easier to find unlabeled data (it's cheaper), and polishing unlabeled data and adding labels typically requires subject matter experts and can be a complex process in itself.</div>
<p>One way to accomplish the goal of unsupervised learning is through the use of a <strong>clustering</strong> algorithm. Clustering uses only data to determine patterns, anomalies (more on anomalies in a later section of this chapter), or similarities in the data.</p>
<p>Clustering organizes data by identifying data that is similar within different clusters as well as data that isn’t similar across clusters.</p>
<p>Clustering is popular within the field of statistical data analysis as different clusters expose different details about the objects within data, which is different from classification or regression, where you have some previous information on the results.</p>
<p>A popular type of clustering algorithm is the <strong>K-means clustering algorithm</strong>.  This algorithm is used to classify or to group objects based on attributes or features into <em>K number of groups</em> (indicating how the methodology got its name).</p>
<p>In this method, <em>K</em> will be a positive integer number and is simply the number of clusters or distinct groups the data is classified into, without the use of a labeled or target field. K-means tries to uncover patterns in the set of input fields within data rather than predicting an outcome.</p>
<p>In the next section of this chapter, we will look at a working example showing the use of the K-means algorithm to create clusters from data in Watson Studio in an effort to produce a prediction, without having knowledge of what the predictor(s) may be.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Watson Studio, machine learning flows, and KMeans</h1>
                </header>
            
            <article>
                
<p>The <strong>flow</strong> editor in Watson Studio presents a very cool graphical view of a model while you build it by combining various types of nodes representing objects or actions. The flow editor has three palettes that you can choose from: SPSS modeler nodes, Spark ML algorithm nodes, and neural network nodes. In this example, we’ll create an SPSS modeler flow.</p>
<p>Note: <span>SPSS is the abbreviation of </span>Statistical Package for Social Sciences<span> and it is used by researchers to perform statistical analysis. The technology was acquired by IBM in 2009. The current versions (2015) are named IBM SPSS Statistics.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started</h1>
                </header>
            
            <article>
                
<p>By now, we know that you need to create a Watson project and include or add data to it. Since we've gone through this before, we'll skip over that and get into how to use the Flow Editor offered by Watson Studio.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an SPSS modeler flow</h1>
                </header>
            
            <article>
                
<p>Let's create an SPSS modeler flow by performing the following steps:</p>
<ol>
<li>To create an SPSS modeler flow, first we must go to <span class="packt_screen">Add to project</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/693eab51-d2e8-45a8-9000-1c088f0408e9.png"/></div>
<ol start="2">
<li>We can then use the <span class="packt_screen">Assets</span> tab (as shown in the following screenshot) and click on the <span class="packt_screen">Modeler Flow</span> icon:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e43eb739-0249-4293-925a-207f05fc6e0b.png"/></div>
<ol start="3">
<li>Next, type a name and description for the flow and select the <span class="packt_screen">IBM SPSS Modeler</span> runtime (on the lower left) then click on the <span class="packt_screen">Create</span> button (on the lower right):</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/251d4418-da71-40cb-bb44-e6f3f1602735.png"/></div>
<ol start="4">
<li>Now we are ready to create our machine learning modeler flow using the following flow editor canvas:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/03dbf455-29bc-4921-8890-c727174accd5.png"/></div>
<div class="packt_infobox">The flow editor palette empowers you to use machine learning, <strong>artificial intelligence</strong> (<strong>AI</strong>), and statistics modeling methods to derive new information from your data without the need for programming.</div>
<ol start="5">
<li>Now we are ready to add our data, so we can drag a <span class="packt_screen">Data Asset</span> node (found under <span class="packt_screen">Import</span>) onto the canvas:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2f52b91f-0a80-4aba-95bb-2879ad96f64d.png" style=""/></div>
<ol start="6">
<li>Once you have a <span class="packt_screen">Data Asset</span> node, you can double-click it, select <span class="packt_screen">Change data asset</span>, select your preferred (training) file, and then click on <span class="packt_screen">OK</span>. If you now right-click on the node, you can select <span class="packt_screen">Preview</span> (shown in the following screenshot) to see your data (in read-only mode):</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/84e94674-ce77-45cc-8188-9754a007c86b.png" style=""/></div>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="7">
<li>To generate a profile of the data, you can add the <span class="packt_screen">Data Audit</span> node (found under <span class="packt_screen">Outputs</span>) by dragging it onto the canvas, connecting it to the <span class="packt_screen">Data Asset</span> node and then clicking the VCR-type run icon:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/517e21d5-f22c-4930-8fd9-8e21590fe566.png" style=""/></div>
<p style="padding-left: 60px">You can see that the <span class="packt_screen">Data Audit</span> node shows <span class="packt_screen">25 Fields</span> that it automatically found in the <span class="packt_screen">Data Asset</span> node. Again, if you double-click on the <span class="packt_screen">Data Audit</span> node, you'll be able to view and update various parameters, such as a name for the node (you can have multiple <span class="packt_screen">Data Audit</span> nodes in a flow), as well as what to include in the output summarizations (graphs, basic and/or advanced statistics, and so on):</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/290867bf-f4d4-4d6a-b05e-e88b9019356f.png" style=""/></div>
<p class="mce-root"/>
<p style="padding-left: 60px">The outputs from the <span class="packt_screen">Data Audit</span> node provides a detailed profile of your data. You can change parameters, rerun your flow, and recheck the results to become comfortable with the outputs:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8b6a151b-d87d-4bdb-a39c-9f585f9dbc59.png"/></div>
<p style="padding-left: 60px">The bottom page of the preceding screenshot is as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/03b2d648-f414-4b76-a458-fcea94ac4327.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Additional node work</h1>
                </header>
            
            <article>
                
<p>Before moving onto actually building a classification model, it should be noted that there are numerous nodes available on the pallet to help with or actually perform almost any operation or process that you need to perform without having to code anything!</p>
<p>If you take a moment to look over on the left-hand side panel (called the <span class="packt_screen">Nodes Palette</span>), you'll see different types of nodes available for you to use while working on your data. These nodes are organized into the following six basic categories:</p>
<ul>
<li><strong>Record operations</strong>: This can be used to perform operations such as selecting, appending, and sorting on the record (row) level.</li>
<li><strong>Field operations</strong>: These nodes are helpful in the data preparation phase. You can filter data, rename features, and choose the type of your attributes.</li>
<li><strong>Graphs</strong>: Nodes in this section will help you with basic data exploration and understanding distribution or relationship between features.</li>
<li><strong>Modeling</strong>: These nodes provide different modeling algorithms for different types of problems.</li>
<li><strong>Outputs</strong>: These nodes are helpful in understanding your data and model. You can display results in table format or get a report on evaluation parameters of your model.</li>
<li><strong>Export</strong>: After processing and modeling, this node will help you export data from the flow editor to your DSX project<strong>.</strong></li>
</ul>
<p>Let's try one out. They all are implemented in pretty much the same way: drag and drop the selected node on to the canvas and right-click to take further actions such as open, preview, or run.</p>
<p>For example, let's look at the <span class="packt_screen">Filter</span> node found under <span class="packt_screen">Field Operations</span>. The following screenshot shows the <span class="packt_screen">Filter</span> node added to the canvas and connected to our <span class="packt_screen">Data Asset</span> node:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/41ee05d2-fbe6-4732-bab0-0931827f6cb9.png" style=""/></div>
<p>You can use the <span class="packt_screen">Filter</span> node to rename columns, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d6e38972-e908-4acc-8830-f0927574ca14.png" style=""/></div>
<p>You can also filter out or retain only selected fields of data from your original <span class="packt_screen">Data Asset</span> node:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/767fd991-6319-4c5b-9ea8-77aaadcba84d.png" style=""/></div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Once you are happy with your data, you can set a variable to be the model's <span class="packt_screen">Target</span> variable using the <span class="packt_screen">Type</span> node. This will help the model to distinguish between input and target features. For example, you can do the following tasks:</p>
<ol>
<li>Drag and drop the <span class="packt_screen">Type</span> node on the canvas.</li>
<li>Connect the <span class="packt_screen">Type</span> node to the <span class="packt_screen">Filter</span> node.</li>
<li>Right-click on the <span class="packt_screen">Type</span> node and click on <span class="packt_screen">Open</span> to open the node.</li>
<li>Click on <span class="packt_screen">Read Values</span>, then select the column name <span class="packt_screen">class</span> and change the role of the variable to <span class="packt_screen">Target</span>, and finally click on <span class="packt_screen">Save</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e183188a-7fe1-4af8-a419-be28b7cc024f.png" style=""/></div>
<ol start="5">
<li>To see what the distribution of the <span class="packt_screen">Target</span> variable (ours is set to <span class="packt_screen">class</span>) is, you can use the <span class="packt_screen">Distribution</span> node (from the <span class="packt_screen">Graphs</span> section of the node palette). Again, just drag the node onto the canvas and open and provide information such as <span class="packt_screen">Plot</span> (select the <span class="packt_screen">class</span> field under <span class="packt_screen">Field (discrete)</span>) and under <span class="packt_screen">Color (discrete)</span> (use <span class="packt_screen">class</span>) and click on <span class="packt_screen">Save</span>. After you run the flow, the output looks like this:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1dabfba2-769f-4da0-82fb-c2749a6e9f44.png"/></div>
<p style="padding-left: 60px">In this data, we see that there are more <strong>cronic cases</strong> (<strong>ckd</strong>) than <strong>non-cronic cases</strong> (<strong>notckd</strong>). <span>This is our current flow displayed on the canvas:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/47f1ec63-39ef-4726-99c9-e650f255e43b.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training and testing</h1>
                </header>
            
            <article>
                
<p>Another useful function in the SPSS modeler flow is the ability to easily divide data into training and testing sets. This can be accomplished using the <span class="packt_screen">Partition</span> node. To train, test, and validate the stages of model building, the <span class="packt_screen">Partition</span> nodes are used to produce a partition field that splits the data into separate subsets or samples.</p>
<p>Using a sample to generate the model and a separate sample to test it will get you a good hint of how well the model will generalize to larger datasets that are corresponding to the current data:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/718bbbbb-f139-4cec-97ae-a25511cce565.png"/></div>
<p>If we add a <span class="packt_screen">Partition</span> node to our flow, open it and adjust the settings as shown in the preceding screenshot, we are instructing the modeler to add a new field (<kbd>PartionMyData</kbd>) to our data, which will designate the record split (based upon 75/25). To see the results of this node, we can add a <span class="packt_screen">Table</span> node to the flow and provide the following settings:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/568be8c2-b10a-4547-b80a-2b6f94d56002.png" style=""/></div>
<p class="mce-root"/>
<p>The preceding screenshot indicates that we want to query our data and generate a table based upon the values in our derived field that are equal to <kbd>1_Training</kbd>; in other words, all of the records that the <span class="packt_screen">Partition</span> node has designated as members of our training data. Our flow now looks as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/af998dba-cfb7-4451-9fc7-1b2f6889ede2.png" style=""/></div>
<p>Running the flow now generates the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c8a6fecf-a939-4dd3-a48f-2e1ed40d7279.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SPSS flow and K-means</h1>
                </header>
            
            <article>
                
<p>As we mentioned earlier in this chapter, a popular type of clustering algorithm is the <strong>K-means clustering</strong> algorithm<strong>.</strong> Again, without the use of a labeled or target field, rather than trying to predict an outcome, K-means tries to uncover patterns and find structure in the data, by grouping and/or clustering data points in the set of input fields within data.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Using the sample data that we have been working with in this chapter, let's say that we don't know whether a person has chronic kidney disease or not and would like to use the K-means algorithm to build an unsupervised model to see whether we can identify any pattern for chronic kidney disease.</p>
<p>We'll choose the <span class="packt_screen">K-Means</span> node in our flow to accomplish this task.</p>
<div class="packt_infobox">The <span class="packt_screen">K-Means</span> node offers a method of cluster analysis which you can refer to <em>Chapter 11</em> in the documentation of IBM SPSS Modeller 15 from the following link: <a href="http://public.dhe.ibm.com/software/analytics/spss/documentation/modeler/15.0/en/ModelingNodes.pdf">http://public.dhe.ibm.com/software/analytics/spss/documentation/modeler/15.0/en/ModelingNodes.pdf</a>.</div>
<p>Let's take a look at the following steps to learn how to learn about the K-means algorithm:</p>
<ol>
<li>From the left, under <span class="packt_screen">Modeling</span>, we can select the <span class="packt_screen">K-Means</span> node and drop it onto the canvas.</li>
<li>Next, connect the node to the <span class="packt_screen">Type</span> <span>node as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/14313503-6087-452e-87e0-c8b248bc9693.png"/></div>
<div class="packt_infobox">Note that I have disconnected the <span class="packt_screen">Partition</span> node that we used earlier.</div>
<ol start="3">
<li>Once we have added the K-Class node, right-click and open it to change its settings (on the right-hand side of the canvas). Specifically, under <span class="packt_screen">BUILD OPTIONS</span>, we'll set <span class="packt_screen">Number of clusters</span> to <kbd>2</kbd> based upon the idea that we would want to organize our data into two groups (or clusters): those with chronic kidney disease and those who do not have chronic kidney disease. All of the other settings can remain defaults. Finally, click on <span class="packt_screen">Save</span>.</li>
<li>Now, after you run the flow, a golden <span class="packt_screen">K-Means</span> node will appear (shown in the following screenshot) on which you can right-click and select <span class="packt_screen">View Model</span><span>:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c935f58c-959e-47c0-937b-a30726038fab.png" style=""/></div>
<ol start="5">
<li>SPSS visualizations offer interactive tables and charts to help evaluate a predictive model. These visualizations provide a single all-inclusive set of output so that you don't need to create multiple charts and tables to determine the model’s performance. Depending on the algorithm, you'll see a set of visualizations that are related to your specific data set and model. The following is the output from our K-means model:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9f3de051-6746-40b7-aa9f-d2c59f63f00b.png"/></div>
<p class="mce-root"/>
<p style="padding-left: 60px">The output includes information on <span class="packt_screen">Cluster Quality</span> (shown in the preceding screenshot) as well as <span class="packt_screen">Predictor Importance</span> (shown in the following screenshot):</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/66e65a16-fde7-43fd-aadc-1eb9a3a5ceff.png"/></div>
<div class="packt_infobox"><span><strong>Cluster Quality Evaluation</strong> is a complex subject and is beyond the scope of this chapter, however IBM Watson Studio provides the typical Cluster Quality details such as the Cluster Sizes Chart which is a horizontal bar chart displaying the relative sizes of the clustering in descending order. Hovering over a bar shows the precise percentage of the total number of instances in that cluster based on the K-Means model.  All of the clustering information should be reviewed and evaluated in respect to various project options and outcomes.  </span></div>
<p style="padding-left: 60px">And finally (although there are other informational visualizations generated), it shows the basic <span class="packt_screen">Model Information (as shown below)</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8eff363e-59fb-4cde-b052-d0290948b17f.png"/></div>
<div class="packt_infobox">An awesome feature of the SPSS modeler flow is that you can build multiple, different models within the same canvas!</div>
<p>It is literally so easily to make changes to the nodes, rerun (the flow), and then re-evaluate the results to determine the best algorithm and parameters, that you should just assume multiple iterations as part of the process.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exporting model results</h1>
                </header>
            
            <article>
                
<p>Once you are comfortable with your model, you can export the results using another handy node named the <span class="packt_screen">Data Asset Export</span> node. As with other nodes, you can drag and drop it onto the canvas, connect it to the golden <span class="packt_screen">K-Means</span> node and open it to edit its settings:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/4ba6ab73-1f13-4829-ab50-32b6eb96e28e.png" style=""/></div>
<p>For the node settings, all you really need to do is type a name to your file (I have typed <kbd>Lovely</kbd>) under the <span class="packt_screen">Target path</span> section in the <span class="packt_screen">Data Asset Export</span> settings as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0163c418-6f68-487b-9205-d29134184718.png" style=""/></div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>You might also select <span class="packt_screen">Replace the data set</span> as the option under the <span class="packt_screen">If the data set already exists*</span> section.</p>
<p>Now, when you run the flow, the data will be exported to your project storage, where you can see and access it from the <span class="packt_screen">Assets</span> tab in the project:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/504757ca-596c-4a51-a608-5e03c300114a.png"/></div>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Semi-supervised learning</h1>
                </header>
            
            <article>
                
<p><strong>Semi-supervised</strong> learning is another class of machine learning process and technique that also makes use of unlabeled data for training (as does unsupervised learning) but, typically, a small amount of labeled data with a large amount of unlabeled data is present and used by the model. This is usually referred to as <strong>partly labeled data</strong>.</p>
<p>Semi-supervised learning falls somewhere between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data).</p>
<p>Semi-supervised learning programs do attempt to use certain standard assumptions to help them make use of unlabeled data. These standard assumptions are continuity, cluster, and manifold.</p>
<p class="mce-root"/>
<p>Without going too deep into describing these assumptions, loose definitions are as follows:</p>
<ul>
<li><strong>Continuity</strong>: This assumption implies that close data points also tends to share a label.</li>
<li><strong>Cluster</strong>: This assumption says that the data that tends to form discrete clusters, and points in the same cluster end up sharing a label.</li>
<li><strong>Manifold</strong>: This assumption assumes that the data lies approximately on what is referred to as a manifold of much lower dimensionality than the original data, and with this assumption, there is an attempt to understand the manifold using both labeled and unlabeled data to reduce dimensionality.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Anomaly detection</h1>
                </header>
            
            <article>
                
<p><strong>Anomalies</strong> also referred to as outliers, novelties, noise, deviations, and exceptions are typically defined as the identification of rare items, events, or observations within a pool or set of data that raise suspicions by differing significantly from the majority of the data.</p>
<p>Why should so much importance be placed on anomalies and their detection?</p>
<p>Because anomalies in data will almost always translate to some kind of problem, such as fraud, a defect, medical problems, or errors in a text.</p>
<p>Anomaly detection is a technique used to recognize unusual patterns that do not conform to expected behavior, called <strong>outliers</strong>. In order to locate anomalies, you need to understand that can fall into several broad categories.</p>
<p>Typically, we consider anomalies to be either point, contextual, or collective in nature. Point anomalies are what you may guess: a single point of data that is very different from the rest. Contextual anomalies are when seemingly good data is only good within a certain context. Collective anomalies are where you consider data in a collective set an anomaly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Machine learning based approaches</h1>
                </header>
            
            <article>
                
<p>Of course, there are a number of generally accepted machine learning based approaches to the process of anomaly detection. These currently include the following:</p>
<ul>
<li><strong>Density-based anomaly detection</strong>:<strong> </strong>This approach is based on the KNN algorithm; the nearest set of data points are evaluated using a scoring method dependent on the type of the data (categorical or numerical).</li>
<li><strong>Clustering-based anomaly detection</strong>: One of the most desired concepts in the domain of unsupervised learning for anomaly detection is Clustering.</li>
<li><strong>Support vector machine based anomaly detection</strong>:<strong> </strong>This algorithm uses a training set to learn soft boundaries in order to cluster the normal data instances then, using the testing instance, it calibrates itself to locate the abnormalities that fall outside the learned region.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Online or batch learning</h1>
                </header>
            
            <article>
                
<p>Think of online and batch machine learning concepts as basically the difference between performing multiple iterations of updating predictor values from new chunks of data compared to churning through all of the available data first, and then setting the predictor values:</p>
<ul>
<li>Online machine learning: This is a technique of machine learning where data are made available in sequential order and is used to streamline the best predictor for future data at each step or iteration.</li>
<li>Batch learning: Batch machine learning is a method that will generate the best predictor by learning on the entire training dataset at once.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we started out by providing brief descriptions of unsupervised learning, semi-supervised learning, anomaly detection, and finally online and batch learning.</p>
<p>In the next chapter, we will use Python as the programming language on notebooks that we will learn to create. We will also learn how to create various machine learning projects with Watson Studio.</p>


            </article>

            
        </section>
    </body></html>