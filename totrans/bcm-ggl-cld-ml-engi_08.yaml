- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Discovering Google Cloud ML API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Application programming interfaces** (**APIs**) allow one computer program
    to make its data and functionality available for other programs to use. In other
    words, through the APIs of a program or a service, users can send a request to
    and get a response back from the program/service. ML APIs are cloud-based AI services
    that help you build ML intelligence into your applications, by leveraging APIs
    from the **Cloud Service Provider** (**CSP**). They are available as REST APIs,
    client library SDKs, and user interfaces.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Google Cloud ML APIs provide an interface to leverage Google’s ML services
    in the cloud. In this chapter, we will discuss the Google Cloud ML API spectrum,
    which includes the following cloud services:'
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud sight APIs, including the Cloud Vision API and Cloud Video API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud language APIs, including **Natural Language Processing** (**NLP**)
    and Translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud conversation APIs, including Speech-to-Text, Text-to-Speech, and
    Dialogflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with Google’s Cloud Sight API.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Sight API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Google Cloud Sight API** offer powerful Google pre-trained machine learning
    models for vision processing and video processing. We will examine the concepts
    for both the Cloud Vision API and the Cloud Video API.
  prefs: []
  type: TYPE_NORMAL
- en: The Cloud Vision API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Cloud Vision API** is a tool to decipher images through Google’s pre-trained
    advanced ML models. It can interpret images and classify them into lots of categories.
    It can extract and detect text, whether the text is within pictures or document
    photos.
  prefs: []
  type: TYPE_NORMAL
- en: 'Google Cloud Vision allows developers to easily integrate vision detection
    features within applications, including image labeling, landmark detection, logo
    detection, and content detection:'
  prefs: []
  type: TYPE_NORMAL
- en: Image label detection can detect, identify, and label objects, locations, activities,
    animal species, products, and many other things that exist within an image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Landmark detection can identify landmarks, such as popular landmarks and natural
    or man-made structures, within an image. It provides the name of the landmark,
    the bounding polygon vertices, and the location of the landmark (latitude and
    longitude).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logo detection detects popular product logos, such as popular company logos,
    product logos, and so on, within an image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content detection detects explicit content, such as adult content, violent content,
    racy content, and so on, within an image. It provides a likelihood that such content
    is present within the image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the use cases for the Google Cloud Vision API are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Text digitization**: The Cloud Vision API can detect text in images, especially
    in scanned images. The best part of it is that you can customize your own models
    and train them for a specific scenario on top of the core built-in feature. For
    example, you can put specific doctors’ prescriptions in a customized model and
    train it on top of the models that Google already provides, to make it more robust.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and surveillance**: Google Cloud Vision provides very precise facial
    recognition, facial comparison, and facial tracking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Brand research with the Logo API**: Google Cloud Vision offers a separate
    logo detection API where you can look up a logo in banner ads to tell the brand
    name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**In-store sentiment analysis**: Real-time marketing and customer support can
    leap forward if we detect the opinions and emotions of a customer who’s inside
    a store in real time. Google Cloud Vision catches customers’ sentiments through
    the facial expressions of a user in a store.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Robotics**: Enabling robots to understand their environment is a huge challenge
    and requires precise object detection by Google Vision APIs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the major areas in Cloud Vision is Google’s Cloud Vision **optical character
    recognition** (**OCR**), a method of converting handwritten texts or printed texts
    into machine-encoded text. With OCR, the Google Vision API can identify and extract
    text from images, with two annotations: **Text Detection** identifies and extracts
    text from images, and **Document Text Detection** extracts text from images with
    a format that is optimized for dense text and documents. The JSON extraction response
    from Text Detection contains the extracted text together with all the individual
    words that occurred in that text, and the JSON extraction response from Document
    Text Detection includes page information, blocks, paragraphs, and words, as well
    as page break information. Google Cloud Vision OCR has the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multi-language support**: Google Cloud Vision OCR supports many languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`librarysur`. and can be used very easily.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fast speed**: The Google Cloud Storage platform integrates with the OCR API
    service. Utilizing GCS, the OCR API can be very fast.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: It can scale, and Google’s OCR pricing strategy encourages
    users to scale up the usage of the API, as more usage leads to a cheaper average
    price.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With Google’s pre-trained models, the Cloud Vision API provides many ML features
    that enable developers to integrate them into various application developments.
    OCR has many business use cases: banks use OCR to compare statements, hospitals
    use OCR to convert handwritten forms to standard-text-filled forms, and governments
    use OCR for survey feedback collections, among others.'
  prefs: []
  type: TYPE_NORMAL
- en: The Cloud Video API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `.MOVIE`, `.MPEG4`, `.MP4`, and `.AVI`. The Google Cloud Video API provides
    the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Label detection**: It can detect the entities within a video, and provide
    a list of video segment annotations, a list of frame annotations, or a list of
    shot annotations upon request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shot change detection**: It can annotate a video by a shot or scene, and
    label objects that are relative to the video scene.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text detection**: It can provide the actual text as well as the location
    of the text within the video.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explicit content detection**: It can annotate explicit content and place
    a timestamp within the video.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object tracking**: It can track multiple objects within a video and provide
    the location of each object within the various frames.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speech transcription**: It can capture the spoken words/sentences within
    a video and transcribe them into text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Through the Google Cloud Video API, developers can annotate videos stored locally
    or in Cloud Storage, or live-streamed, with contextual information at the level
    of the entire video, per segment, per shot, and per frame, and develop related
    intelligent applications.
  prefs: []
  type: TYPE_NORMAL
- en: The Google Cloud Language API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google’s **Cloud Language API** includes language translation and NLP. The Cloud
    Translation API allows you to detect a language and translate it to another one,
    thus you only need to specify a target language since it detects the source language
    automatically. NLP allows you to uncover the structure and the meaning of the
    input text. It provides an interface for developers or computer programs to send
    requests and get responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Google’s NLP API has several methods to perform text analysis and annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`analyzeSentiment` method. The sentiment analysis response fields consist of
    the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-1.0` (negative) and `1.0` (positive), based on the overall emotional leaning
    of the text, and a magnitude of the sentiment, which indicates the overall strength
    of emotion (both positive and negative) within the given text, between `0.0` and
    `+inf`. The score of a document’s sentiment indicates the overall emotion of a
    document. The magnitude of a document’s sentiment indicates how much emotional
    content is present within the document.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Language** contains the language of the document, either passed in the initial
    request or automatically detected if absent.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentences** contain a list of the sentences extracted from the original document,
    and the sentence-level sentiment values attached to each sentence, which contain
    score and magnitude values as described previously.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis indicates the differences between positive and negative emotions
    in a document but it does not identify the specific positive and negative emotions.
    For example, when detecting something that is considered *angry*, or text that
    is considered *sad*, the analysis response only indicates that the sentiment is
    negative, not *sad* or *angry*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Entity analysis**: Inspects the given text for known entities, such as proper
    nouns that map to unique entities (specific people, places, and so on) or common
    nouns (also called **nominals**, such as restaurants, stadiums, and so on). Entity
    analysis returns a set of detected entities and parameters associated with those
    entities, such as the entity’s type, the relevance of the entity to the overall
    text, and locations in the text that refer to the same entity. Entities are returned
    in the order (highest to lowest) of their salience scores, which reflect their
    relevance to the overall text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Entity sentiment analysis**: Combines both entity analysis and sentiment
    analysis and attempts to determine the sentiment (positive or negative) expressed
    about entities within the text. Entity sentiment is represented by numerical score
    and magnitude values for each detected entity. Those scores are then aggregated
    into an overall sentiment score and magnitude for an entity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`analyzeSyntax` method. Syntactic analysis consists of the following operations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentence extraction breaks up the stream of text into a series of sentences.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Tokenization breaks the stream of text up into a series of tokens, with each
    token usually corresponding to a single word.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The Natural Language API then processes the tokens and, using their locations
    within sentences, adds syntactic information to the tokens.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`classifyText` method. For an input text, Google’s Natural Language API filters
    the categories returned by the `classifyText` method to include only the most
    relevant categories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, with sentiment analysis, entity analysis, entity sentiment analysis,
    content classification, and syntax analysis, Google’s pre-trained models of the
    Natural Language API can help developers to apply natural language understanding
    to their applications and solve many business use cases.
  prefs: []
  type: TYPE_NORMAL
- en: The Google Cloud Conversation API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Google Cloud Conversation API** provides a way to have interactive natural
    language AI conversations. It has three aspects: Cloud Dialogflow, Cloud Text-to-Speech,
    and Cloud Speech-to-Text:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dialogflow** provides a natural language understanding platform where you
    can design and integrate a conversational user interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text-to-Speech** converts text input into audio data of natural human speech.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speech-to-Text** converts audio or speech inputs to texts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Dialogflow allows you to build virtual agents and chatbots. Dialogflow
    analyzes text or audio inputs and responds using text or speech.
  prefs: []
  type: TYPE_NORMAL
- en: 'Intents are at the core of Dialogflow. An intent categorizes an end user’s
    intention. When a user adds an inputs, Dialogflow does intent classification by
    using training phrases – examples of what the end users may actually say – to
    train the model, and the training results are the mapping of the phrases to intents.
    Using user intents, a typical workflow for Dialogflow is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An end user will provide an input phrase, which will be sent to some type of
    agent. The agent performs intent classification and maps the input phrase into
    an intent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the intent, it will extract the relevant parameters and link actions to
    intents, such as retrieving a bank account balance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The parameters and actions will be sent to create a response.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The response is speech or text that is returned to the end user.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Google Cloud Speech-to-Text enables the integration of Google speech recognition
    technologies into application development using Google’s advanced AI technologies.
    There are three main methods in Speech-to-Text:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Synchronous recognition**: When the Speech-to-Text API receives speech audio
    data, it performs data recognition/processing and returns results after all audio
    data has been processed before it processes the next request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asynchronous recognition**: When the Speech-to-Text API receives audio data
    input, it initiates a long-running operation, which periodically polls for recognition
    results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Streaming recognition**: Real-time audio recognition, such as capturing live
    audio from a microphone. Streaming recognition provides interim results while
    audio is being captured, allowing results to appear while a user is still speaking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech-to-Text can use one of several machine learning models to transcribe
    your audio file. Google has trained these speech recognition models for specific
    audio types and sources. When you send an audio transcription request to Speech-to-Text,
    you can improve the results that you receive by specifying the source of the original
    audio. This allows the Speech-to-Text API to process your audio files using a
    machine learning model trained to recognize speech audio from that particular
    type of source.
  prefs: []
  type: TYPE_NORMAL
- en: The Google Cloud Text-to-Speech API allows you to convert text to human-like
    speech using WaveNet voices, which synthesize speech with more human-like emphasis
    and inflection on syllables, phonemes, and words. WaveNet produces speech audio
    that people prefer over other text-to-speech technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Text-to-Speech uses a synthetic voice to create audio from the text that is
    presented to it. It creates natural-sounding human speech as playable audio. In
    addition to normal text, the Cloud Text-to-Speech API can convert **Speech Synthesis
    Markup Language** (**SSML**) to audio. SSML allows you to control the way in which
    text is converted to speech.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have introduced the Google Cloud ML API services: the Cloud
    Sight API with Vision and Video APIs, the Cloud Language API with the Translation
    and NPL APIs, and the Cloud conversation API with Dialogflow, Speech-to-Text and
    Text-to-Speech. These Google pre-trained API services provide the best functions
    and interfaces for ML application development, and we have shown some sample business
    use cases leveraging Google ML APIs.'
  prefs: []
  type: TYPE_NORMAL
- en: To master the Google ML API services, labs are an important part of the learning
    process, and we have provided some ML API hands-on demonstrations in [*Appendix
    5*](B18333_15.xhtml#_idTextAnchor233), *Practicing with the Google Cloud ML API*.
    Please review and understand all the practice steps.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss the best practices in implementing ML in
    Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For further insights into the learnings of this chapter, you can refer to the
    following links:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Vision AI | Derive Image Insights via ML | Cloud Vision API*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vision/](https://cloud.google.com/vision/)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Video AI - Video Content Analysis | Cloud Video Intelligence API*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/video-intelligence/](https://cloud.google.com/video-intelligence/)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Speech-to-Text: Automatic Speech Recognition*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/speech-to-text](https://cloud.google.com/speech-to-text)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Text-to-Speech: Lifelike Speech Synthesis*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/text-to-speech](https://cloud.google.com/text-to-speech)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Dialogflow*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/dialogflow/](https://cloud.google.com/dialogflow/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Appendix 5*](B18333_15.xhtml#_idTextAnchor233), *Practicing with the Google
    Cloud ML API*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
