- en: Deploying Computer Vision Applications on Jetson TX1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter described the installation of OpenCV and CUDA on a Jetson
    TX1 development board. This chapter will describe how to use these features on
    the board. The properties of the Jetson TX1 GPU that make it useful for parallel
    processing will be described in detail. The chapter will also describe how we
    can execute the CUDA and C++ codes, seen earlier in this book, on Jetson TX1\.
    It will also demonstrate the performance of the Jetson TX1 GPU in executing CUDA
    code. The primary motive of this chapter will be to demonstrate the use of Jetson
    TX1 in deploying image- and video-processing applications. Basic image-processing
    applications such as image reading, displaying, addition, thresholding, and filtering
    are taken as examples to demonstrate the use of Jetson TX1 for computer vision
    applications. Moreover, camera interfacing is important for the deployment of
    the board in real-life scenarios. This chapter will describe the procedure to
    use the onboard camera or USB camera for video-capturing and processing applications.
    How to deploy some advanced applications, like face detection and background subtraction,
    will be explained in the last part of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Device properties of a Jetson TX1 board
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running CUDA programs on a Jetson TX1 board
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image processing on a Jetson TX1 board
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interfacing cameras with a Jetson TX1 development board
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced applications such as face detection, eye detection, and background
    subtraction on a Jetson TX1 development board
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires a good understanding of the OpenCV, CUDA, and any programming
    language. It also requires any Nvidia GPU development board, like Jetson TK1,
    TX1, or TX2\. The code files used in this chapter can be downloaded from the following
    GitHub link: [https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2xDtHhm](http://bit.ly/2xDtHhm)'
  prefs: []
  type: TYPE_NORMAL
- en: Device properties of Jetson TX1 GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CUDA provides a simple interface to determine the capabilities of a GPU device,
    which is Tegra X1 present on a Jetson TX1 board. It is important to find out the
    properties of the device that will help in writing optimal programs for it. The
    program to find the properties of the device is available in the CUDA sample programs
    installed with JetPack in the home folder. You can also run the program we developed
    in the second chapter to find out the device properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the program on an Nvidia Tegra X1 GPU is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3691873c-0729-4c74-a7db-d8605b91b509.png)'
  prefs: []
  type: TYPE_IMG
- en: The JetPack 3.3 installs the CUDA 9.0 runtime version. The global memory for
    the GPU device is around 4 GB, with a GPU clock speed of around 1 GHz. This clock
    speed is slower than the GeForce 940 GPU mentioned earlier in this book. The memory
    clock speed is only 13 MHz compared to 2.505 GHz on GeForce 940, which makes Jetson
    TX1 slower. The L2 cache is 256 KB compared to 1 MB on GeForce 940\. Most of the
    other properties are similar to GeForce 940.
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of threads that can be launched per block in *X*, *Y*, and
    *Z* directions are 1,024, 1,024, and 64 respectively. These numbers should be
    used while determining the number of parallel threads to be launched from a program.
    The same care should be taken while launching the number of parallel blocks per
    grid.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we have seen the device properties of the Tegra X1 GPU available
    on a Jetson TX1 development board. It is an embedded board so memory is available
    and the clock rate is comparatively slower than for GPU devices like GeForce 940
    that comes with a laptop. Still, it is way faster than embedded platforms like
    Arduino and Raspberry Pi. It can be easily used in deploying computer vision applications
    that require high computational power. Now that we have seen the device properties,
    we will start by developing the first program using CUDA on Jetson TX1\.
  prefs: []
  type: TYPE_NORMAL
- en: Basic CUDA program on Jetson TX1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, the example of adding two large arrays is taken to demonstrate
    the use of a Jetson TX1 development board in executing CUDA programs. The performance
    of the program is also measured using CUDA events.
  prefs: []
  type: TYPE_NORMAL
- en: 'The kernel function for adding two large arrays with 50,000 elements is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The kernel function takes two device pointers, which point to input arrays
    as input, and one device pointer, which points to output arrays in the device
    memory as arguments. The thread ID of the current kernel execution is calculated
    and array elements indexed by the thread index are added by the kernel. If the
    number of kernels launched is less than the number of array elements, then the
    same kernel will add `Array` elements offset by the block dimension as shown in
    the `while` loop. The `main` function for adding two arrays is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Two host arrays are defined and memory is allocated to them using the `cudaMalloc`
    function. They are initialized to some random values and uploaded to the device
    memory. Two CUDA events are created to measure the performance of the CUDA program.
    The kernel is launched with 1,024 blocks in parallel, with each block having 1,024
    threads. These numbers are taken from the device properties, as explained in the
    last section. The result from the kernel function is transferred to the host memory.
    The time taken by the kernel function is recorded by the `e_start` and `e_stop`
    events, before and after the kernel launch. The time taken by the function is
    displayed on the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is added to verify the correctness of the result, computed
    by the GPU, and to clean up the memory used by the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The same array addition operation is performed on the CPU and compared with
    the result obtained from the GPU to verify whether the GPU has computed the result
    correctly or not. This is also displayed on the console. All the memory used by
    the program is freed up by using the `cudaFree` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two commands need to be run from the Terminal to execute the
    program. The program should be in the current working directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `nvcc` command is used to compile CUDA code with an Nvidia CUDA compiler.
    The file name is passed as an argument to the command. The name of the object
    file, which will be created by the compiler, is specified with the `-o` option.
    This filename will be used to execute the program. This is done by the second
    command. The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/adb67283-4e75-494c-978d-b230fc682b6c.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen from the result, Jetson TX1 takes `3.4ms` to compute the sum
    of two arrays with 50,000 elements, which is slower than GeForce 940 used in the
    third chapter of this book, but still it is faster than sequential execution on
    a CPU.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, this section demonstrated the use of a Jetson TX1 development
    board in the execution of CUDA programs. The syntax is the same as we have seen
    earlier in this book. So all CUDA programs developed earlier in the book can be
    executed on Jetson TX1 without much modification. The procedure to execute the
    program is also described. The next section will describe the use of Jetson TX1
    for image-processing applications.
  prefs: []
  type: TYPE_NORMAL
- en: Image processing on Jetson TX1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will demonstrate the use of Jetson TX1 in the deployment of image-processing
    applications. We will again use OpenCV and CUDA for accelerating computer vision
    applications on Jetson TX1\. In the last chapter, we saw the installation procedure
    for JetPack 3.3, which contains OpenCV and CUDA. But in the latest JetPack, OpenCV
    is not compiled with CUDA support nor has it GStreamer support, which is needed
    for accessing the camera from the code. So, it is a good idea to remove the OpenCV
    installation that comes with JetPack and to compile the new version of OpenCV
    with CUDA and GStreamer support. The next section will demonstrate the procedure
    to do that.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling OpenCV with CUDA support (if necessary)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Though OpenCV which comes with JetPack, can work with a new OpenCV installation,
    it is a good idea to remove the old installation first and then start a new one.
    This will avoid unnecessary confusion. To accomplish that, the following steps
    have to be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command from the Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure that all the packages installed are the latest versions. If that
    is not the case, then you can update them by running the following two commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The latest versions of cmake and gcc compiler are needed to compile OpenCV
    from the source so they can be installed by running the following two commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'There are some dependencies that need to be installed to compile OpenCV with
    GStreamer support. This can be done by the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Download the source for the latest version of OpenCV and extract it in a folder
    by executing the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now go inside the `opencv` folder and create the `build` directory. Then go
    inside this newly created `build` directory. These can be done by executing the
    following commands from Command Prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cmake` command is used to compile `opencv` with CUDA support. Make sure
    the `WITH_CUDA` flag is set to `ON` in this command. Note `CUDA_ARCH_BIN` should
    be set to `5.3` for a Jetson TX1 development board and `6.2` for Jetson TX2\.
    The examples are not built to save time and space. The entire `cmake` command
    is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It will start the configuration and creation of `makefile`. The `cmake` command
    will create `makefile` in the `build` directory after successful configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To compile OpenCV using `makefile` execute the `make -j4` command from the command
    window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After successful compilation, to install OpenCV you have to execute the command
    `sudo make install` from the command line.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If these steps are executed successfully then OpenCV 3.4.0 will be installed
    with CUDA and GStreamer support on Jetson TX1, and any computer vision application
    made using OpenCV can be deployed on it. The next section will demonstrate simple
    image-processing operations on the board.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and displaying images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first basic operation needed for any computer vision application is that
    of reading and displaying images that are stored on the disk. This section will
    demonstrate a simple code to do this operation on Jetson TX1\. The OpenCV syntax
    will not change much as we move from the GPU on the computer to the Jetson TX1
    development board. A few minor changes will be there. The code for reading and
    displaying images on Jetson TX1 is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The necessary OpenCV libraries are included in the code. The image is read using
    the `imread` function inside the `Main` function. The image is read as a grayscale
    image because the second argument to the `imread` command is specified as `0`.
    To read an image as a color image, it can be specified as `1`. The `if` statement
    checks whether the image is read or not, and if it is not then the code is terminated
    after displaying an error on the console. When the name of the image is incorrect
    or the image is not stored in the specified path, then an error in reading an
    image can happen. This error is handled by the `if` statement. The image is displayed
    using the `imshow` command. The `waitKey` function is used to display the image
    until any key is pressed on the keyboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code shown can be saved as the `image_read.cpp` file and executed
    using the following command from the Terminal. Make sure that the program file
    is stored in the current working directory of the Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e845b1c3-7dcf-4e95-98ba-48b43c16ec77.png)'
  prefs: []
  type: TYPE_IMG
- en: This section demonstrated the procedure to read and display an image on Jetson
    TX1\. In the next section, we will see some more image-processing operations and
    also try to measure the performance of them on Jetson TX1.
  prefs: []
  type: TYPE_NORMAL
- en: Image addition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section will demonstrate the use of Jetson TX1 for simple image-processing
    applications like image addition. The intensities of pixels at the same location
    are added to construct the new image after addition. Suppose in two images, the
    pixel at (0,0) has intensity values 50 and 150 respectively, then the intensity
    value in the resultant image will be 200, which is the addition of the two intensity
    values. OpenCV addition is a saturated operation, which means that if an answer
    of addition goes above 255 then it will be saturated at 255\. The code to perform
    addition on Jetson TX1 is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: One thing to be kept in mind while doing image addition is that both the images
    should be of the same size. If it is not the case, then they should be resized
    before addition. In the preceding code, two images of the same size are read from
    the disk and uploaded to the device memory for addition on a GPU. The `add` function
    from the `cv::cuda` module is used to perform image addition on the device. The
    resultant image is downloaded to the host and displayed on the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/060e8009-68ad-4fe0-a469-d40c3aff8e01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The performance of image addition is also measured using the `cv::getTickCount()`
    and `cv::getTickFrequency()` functions. The time taken by the addition operation
    is displayed on the console as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e92015f-18e5-499d-998d-3a42d70b0232.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen from the preceding screenshot, it takes around `0.26ms` to add
    two images of the size 256 x 256 on Jetson TX1\. This is a very good performance
    for an embedded platform. It should be noted that performance should be measured
    before the `imshow` function to measure the accurate time for the addition operation.
    The `imshow` function takes more time to display an image, so the time measured
    will not be an accurate estimation of time taken to do an add operation.
  prefs: []
  type: TYPE_NORMAL
- en: Image thresholding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will demonstrate the use of Jetson TX1 for more computationally
    intensive computer vision applications, like image thresholding. Image thresholding
    is a very simple image segmentation technique used to extract important regions
    from a grayscale image, based on certain intensity values. In this technique,
    if the pixel value is greater than a certain threshold value then it is assigned
    one value, or else it is assigned another value.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenCV provides different types of thresholding techniques, and it is decided
    by the last argument of the function. These thresholding types are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cv:.THRES H_BINARY`: If the intensity of the pixel is greater than the threshold,
    then set the pixel intensity equal to the `maxVal` constant, or else set the pixel
    intensity to zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv::THRESH_BINARY_INV`: If the intensity of the pixel is greater than the
    threshold, then set the pixel intensity equal to zero, or else set the pixel intensity
    to the `maxVal` constant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv::THRESH_TRUNC`: This is basically a truncation operation. If the intensity
    of the pixel is greater than the threshold, then set the pixel intensity equal
    to the threshold, or else keep the intensity value as it is.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv::THRESH_TOZERO`: If the intensity of the pixel is greater than the threshold,
    then keep the pixel intensity as it is, or else set the pixel intensity to zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv::THRESH_TOZERO_INV`: If the intensity of the pixel is greater than the
    threshold, then set that pixel intensity equal to zero, or else keep the pixel
    intensity as it is.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The program to implement all these thresholding techniques using OpenCV and
    CUDA on Jetson TX1 is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The function used for image thresholding in OpenCV and CUDA on a GPU is `cv::cuda::threshold`.
    This function has many arguments. The first argument is the source image, which
    should be a grayscale image. The second argument is the destination at which the
    result is to be stored. The third argument is the threshold value, which is used
    to segment the pixel values. The fourth argument is the `maxVal` constant, which
    represents the value to be given if the pixel value is more than the threshold
    value. The final argument is the thresholding methods discussed earlier. The output
    of the program that shows the original image and the output of five thresholding
    techniques is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97d3d2e4-1bbe-4207-a477-4016201eaa19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The performance of image thresholding is also measured using the `cv::getTickCount()`
    and `cv::getTickFrequency()` functions. The time taken by five thresholding operations
    is displayed on the console, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95e2352a-1d63-44ca-bcb5-702a117b41ad.png)'
  prefs: []
  type: TYPE_IMG
- en: It takes `0.32ms` to do five thresholding operations on Jetson TX1, which is
    again a very good performance for an image segmentation task on embedded platforms.
    The next section will describe the filtering operations on Jetson TX1.
  prefs: []
  type: TYPE_NORMAL
- en: Image filtering on Jetson TX1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image filtering is a very important step in image preprocessing and feature
    extractions. Low pass filters, like averaging, Gaussian, and median filters, are
    used to remove different types of noise in an image, while high pass filters,
    like Sobel, Scharr, and Laplacian, are used to detect edges in an image. Edges
    are important features that can be used for computer vision tasks like object
    detection and classification. Image filtering is explained in detail earlier in
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section describes the procedure to apply low pass and high pass filters
    on an image on Jetson TX1\. The code for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Laplacian is a second-order derivative used to extract both vertical and horizontal
    images from an image. It is highly sensitive to noise so sometimes it is necessary
    to remove noise using a low pass filter, like the Gaussian blur, and then apply
    a Laplacian filter. So in the code, the Gaussian filter of size 3 x 3 is applied
    to an input image with a standard deviation equal to `1`. The filter is created
    using the `cv::cuda::createGaussianFilter` function of OpenCV. The Laplacian filter
    is then applied to the Gaussian blurred image. The Laplacian filter is created
    using the `cv::cuda::createLaplacianFilter` function of OpenCV. The output of
    the Gaussian blurring and Laplacian filter is downloaded back to the host memory
    for display on the console. The performance of the filtering operations is also
    measured in the code. The output of the program is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb538e16-9cee-4b60-ab1b-808e7831baae.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen from the output, the Laplacian filter on a blurred image will
    remove false edges from an image. It will also remove Gaussian noise present in
    an input image. If an input image is distorted by salt and pepper noise then the
    median filter should be used as a preprocessing step to a Laplacian filter for
    edge detection.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we have seen different image-processing functions such as image
    addition, image thresholding and image filtering on Jetson TX1\. We have also
    seen that the performance of these operations on Jetson TX1 is much better than
    the performance of the same code on a CPU. The next section will describe the
    interfacing of the camera with a Jetson TX1 so that it can be used in real-life
    situations.
  prefs: []
  type: TYPE_NORMAL
- en: Interfacing cameras with Jetson TX1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Jetson TX1 can be interfaced with USB cameras or CSI cameras. The development
    board comes with one camera of 5 MP already interfaced with Jetson TX1\. This
    camera can be used to capture video just like a webcam on a laptop. Camera interfacing
    is an important feature that makes the Jetson TX1 development board useful in
    real-time situations. It supports up to six-lane cameras. The detailed list of
    cameras supported by Jetson TX1 can be found at the following link: [https://elinux.org/Jetson_TX1
    .](https://elinux.org/Jetson_TX1)'
  prefs: []
  type: TYPE_NORMAL
- en: This section will demonstrate the procedure to capture videos using a camera
    interfaced with Jetson TX1 and how these videos can be used to develop computer
    vision applications, like face detection and background subtraction.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and displaying video from onboard camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will describe the method used to capture video from a USB camera
    or onboard camera interfaced with Jetson TX1\. For this, OpenCV should be compiled
    with GStreamer support; otherwise, the format of the captured video will not be
    supported by OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can be used to capture video from a camera and display it
    on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The code is more or less similar to a code used for capturing video from a
    webcam on a desktop. Instead of using a device ID as an argument to capture an
    object, the string that specifies GStreamer pipeline is used. This is shown as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The width and height of the captured video are specified as 1,280 and 720 pixels.
    The frame rate is also specified. These values will change according to formats
    supported by interfaced cameras. Use `nvvidconv` to convert video to BGR format
    that is supported by OpenCV. It is also used for image scaling and flipping. To
    flip the captured video, the flip method can be specified as an integer value
    other than zero.
  prefs: []
  type: TYPE_NORMAL
- en: The `cap.isOpened` property is used to check whether capturing from the camera
    has started or not. Then the frames are read one by one using the read method
    and displayed on the screen until `q` is pressed by the user. The rate of frame
    capturing is also measured in the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the live video is captured by the camera for two different frames,
    and the frame rate is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2993e7b3-e147-4021-a841-5ed772f34066.png)'
  prefs: []
  type: TYPE_IMG
- en: To summarize, in this section we have seen the procedure to capture video from
    a camera interfaced with a Jetson TX1 development board. This captured video can
    be used to develop useful real-time computer vision applications as described
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced applications on Jetson TX1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will describe the use of a Jetson TX1 embedded platform in the
    deployment of advanced computer vision applications, like face detection, eye
    detection, and background subtraction.
  prefs: []
  type: TYPE_NORMAL
- en: Face detection using Haar cascades
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Haar cascade uses rectangular features to detect an object. It uses rectangles
    of different sizes to calculate different line and edge features. The idea behind
    the Haar-like feature detection algorithm is to compute the difference between
    the sum of white pixels and the sum of black pixels inside the rectangle.
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of this method is the fast sum computation using the integral
    image approach. This makes the Haar cascade ideal for real-time object detection.
    It requires less time for processing an image than other algorithms used for object
    detection. The Haar cascade is ideal for deployment on embedded systems like Jetson
    TX1 because of its low computational complexity and low memory footprint. So in
    this section, this algorithm is used to deploy face detection applications on
    Jetson TX1.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for face detection from a video captured by a camera interfaced with
    Jetson TX1 is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The Haar cascade is an algorithm which needs to be trained to do a particular
    task. It is difficult to train a Haar cascade from scratch for a particular application,
    so OpenCV provides some trained XML files which can be used to detect objects.
    These XML files are provided in the `\usr\local\opencv\data\haarcascades_cuda`
    directory of the OpenCV and CUDA installations.
  prefs: []
  type: TYPE_NORMAL
- en: The webcam is initialized, and frames from the webcam are captured one by one.
    The frame is uploaded to the device memory for processing on the GPU. OpenCV and
    CUDA provide the `CascadeClassifier` class that can be used for implementing the
    Haar cascade. The create method is used to create an object of that class. It
    requires the filename of the trained XML file to be loaded.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the `while` loop,the `detectMultiscale` method is applied to every frame
    so that faces of different sizes can be detected in each frame. The detected location
    is converted to a rectangle vector, using the convert method. Then, this vector
    is iterated using the `for` loop so that a bounding box can be drawn using a rectangle
    function on all the detected faces. This procedure is repeated for every frame
    captured from the webcam. The performance of the algorithm is also measured in
    terms of frames per second.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/203b7c76-1671-45d1-97b5-5b4cd0fc34bd.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen from the output, the face is correctly localized in two different
    frames of the webcam at different positions. The second frame is a little bit
    blurred, but it is not affecting the algorithm. The performance of the algorithm
    on Jetson TX1 is also shown in the right image. The algorithm works at around
    five frames per second.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, this section demonstrates the use of Jetson TX1 in detecting faces
    from a live video captured from a webcam. This application can be used for person
    identification, face locking, attendance monitoring, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Eye detection using Haar cascades
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section will describe the use of Haar cascades in detecting the eyes of
    humans. The XML file for a trained Haar cascade for eye detection is provided
    in the OpenCV installation directory. This file is used to detect eyes. The code
    for it is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The code is similar to the code for face detection. This is the advantage of
    using Haar cascades. If an XML file for a trained Haar cascade on a given object
    is available then the same code will work in all applications. Just the name of
    the XML file needs to change while creating an object of the `CascadeClassifier`
    class. In the preceding code, `haarcascade_eye.xml` , which is the trained XML
    file for eye detection, is used. The other code is self-explanatory. The scale
    factor is set at `1.02` so that image size will be reduced by `1.02` at every
    scale. The output of the eye detection program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a440675f-7e4d-4361-9348-7813b5d8500e.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have detected objects from video and images using a Haar cascade,
    the captured video can also be used to detect and track objects using the background
    subtraction method as described in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Background subtraction using Mixture of Gaussian (MoG)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Background subtraction is an important preprocessing step for object detection
    and tracking applications. It can also be used for unusual activity detection
    from CCTV footage. This section demonstrates the use of Jetson TX1 in a background
    subtraction application. The camera interfaced with Jetson TX1 is mounted in a
    room for activity detection inside the room. The background of the room is initialized
    in the first frame.
  prefs: []
  type: TYPE_NORMAL
- en: The MoG, which is a widely used background subtraction method used for separating
    the foreground from the background based on Gaussian mixtures, is used for activity
    detection. The background is continuously updated from the sequence of frames.
    A mixture of K Gaussian distribution is used to categorize pixels as foreground
    or background. The time sequence of the frame is also weighted to improve background
    modeling. The intensities that are continuously changing are categorized as foreground,
    and intensities that are static are categorized as background.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for activity monitoring using MoG is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The camera interfaced with Jetson TX1 is initialized with the GStreamer pipeline.
    The `createBackgroundSubtractorMOG` class is used to create an object for MoG
    implementation. The `apply` method of the created object is used to create a foreground
    mask from the first frame. It requires an input image, an `image` array to store
    foreground mask, and learning rate as the input. The image of the room without
    any activity is initialized as a background for the MoG. So, any activity that
    will happen will be categorized as foreground by the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: This foreground mask and the background image are continuously updated after
    every frame inside the `while` loop. The `getBackgroundImage` function is used
    to fetch the current background model.
  prefs: []
  type: TYPE_NORMAL
- en: The foreground mask is used to create a foreground image, which indicates which
    objects are currently moving. It is basically logical and operates between the
    original frame and foreground mask. The foreground mask, foreground image, and
    the modeled background are downloaded to the host memory after every frame, for
    displaying on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of two different frames from the video is shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf472126-4abb-4203-a695-d60f675917bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first row indicates the background of the room without any activity. When
    someone moves a hand in front of the camera, it will be detected as foreground,
    as shown in the second frame result. In the same way, if someone puts a cell phone
    in front of the camera, that will also be categorized as foreground, as shown
    in the third frame. The performance of the code in terms of frames per second
    is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c0f9dae-08fd-438f-96ab-fa6067dd7a20.png)'
  prefs: []
  type: TYPE_IMG
- en: The technique works at around 60-70 frames per second, which can easily be used
    to take a real-time decision. Though the demonstration in this section is very
    trivial, this application can be used in many real-life situations. The activity
    inside a room can be used to control the appliances present in the room. This
    will help in saving electricity when no person is present. This application can
    also be used at an ATM for monitoring activity inside it. It can also be used
    for other video surveillance applications in public places. Python can also be
    used as the programming language on Jetson TX1, which will be explained in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision using Python and OpenCV on Jetson TX1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up till now, we have developed all computer vision applications using C/C++,
    OpenCV, and CUDA. Jetson TX1 also supports the Python programming language for
    computer vision applications. When OpenCV is compiled on Jetson TX1, it also installs
    Python binaries for OpenCV. So programmers who are comfortable in Python programming
    language can use a Python interface for OpenCV in developing computer vision applications
    and deploying them on Jetson TX1\. Python also comes preinstalled with Jetson
    TX1 as is the case for all Linux operating systems. Windows users can install
    Python separately. The installation procedure and advantages of Python are explained
    in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'One disadvantage of using Python is that OpenCV Python interface is still not
    greatly benefited by CUDA acceleration. Still, the ease of learning Python and
    the wide range of applications in which it can be used have encouraged many software
    developers to use Python for computer vision applications. The sample code for
    reading and displaying images using Python and OpenCV is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In Python,the `import` command is used to include a library in a file. So the
    `cv2` library is included by using the `import cv2` command. Images are stored
    as `numpy` arrays so `numpy` is also imported in a file. The `imread` function
    is used to read an image in the same way as C++. All OpenCV functions have to
    be prefixed with `cv2.` in Python. The `imshow` function is used to display an
    image. All OpenCV functions have a similar signature and functionality in Python
    as C++.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command can be used to execute the code from the Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the program is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79d8b542-c442-41a4-927e-6f40e2831558.png)'
  prefs: []
  type: TYPE_IMG
- en: This section is just included to make you aware that Python can also be used
    as a programming language for developing computer vision applications using OpenCV
    and deploying it on Jetson TX1.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter described the use of Jetson TX1 in the deployment of CUDA and OpenCV
    code. The properties of the GPU device present on a TX1 board that make it ideal
    for deploying computationally complex applications are explained in detail. The
    performance of Jetson TX1 for CUDA applications such as adding two large arrays
    is measured and compared with GPUs present on laptops. The procedure to work with
    images on Jetson TX1 is explained in detail in this chapter. The image-processing
    applications like image addition, image thresholding, and image filtering are
    deployed on Jetson TX1 and performance is measured for them.
  prefs: []
  type: TYPE_NORMAL
- en: The best part of Jetson TX1 is that multiple cameras can be interfaced with
    it in an embedded environment, and videos from that camera can be processed to
    design complex computer vision applications. The procedure to capture video from
    an onboard or USB camera interfaced with Jetson TX1 is explained in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter also described the deployment of advanced computer vision applications
    like face detection, eye detection, and background subtraction on Jetson TX1\.
    The Python language can also be used to deploy computer vision applications on
    Jetson TX1\. This concept is explained in the last part of the chapter. So far,
    we have seen how the C/C++ language can leverage the advantages of CUDA and GPU
    acceleration.
  prefs: []
  type: TYPE_NORMAL
- en: The next couple of chapters will demonstrate the use of CUDA and GPU acceleration
    for the Python language using the PyCUDA module.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Compare the performance of a GPU device on Jetson TX1 with a GeForce 940 GPU
    seen earlier in the book.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'State True or False: All CUDA programs seen earlier in the book can be executed
    on Jetson TX1 without modification.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the need for recompiling OpenCV on Jetson TX1?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'State True or False: OpenCV can''t capture video from a camera connected to
    the USB port.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'State True or False: It is better to use a CSI camera for computationally intensive
    applications than a USB camera.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are developing computationally intensive computer vision applications
    using OpenCV, which language would you prefer for faster performance?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is there a need to install separate OpenCV Python binding or Python interpreter
    on Jetson TX1?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
