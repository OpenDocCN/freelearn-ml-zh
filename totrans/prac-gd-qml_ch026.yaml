- en: Appendix C
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computational Complexity
  prefs: []
  type: TYPE_NORMAL
- en: '*An algorithm is a finite answer to an infinite number of questions*'
  prefs: []
  type: TYPE_NORMAL
- en: — Stephen Kleene
  prefs: []
  type: TYPE_NORMAL
- en: Computational complexity theory is the branch of theoretical computer science
    that is concerned with quantifying the resources needed to solve problems with
    algorithms. It asks questions such as “How much time is needed to multiply two
    integer numbers of ![n](img/file244.png "n") bits each?”, “Do you need more memory
    space to solve a problem than to check its solution?”, or “Is randomness useful
    in computational tasks?”.
  prefs: []
  type: TYPE_NORMAL
- en: In this brief introduction to computational complexity, we will focus mainly
    on the concepts involved in estimating how much time is required to solve certain
    problems. For a thorough treatment of this and other topics (including space or
    memory complexity, the role of randomness in computation, approximation algorithms,
    and other advanced matters), you can check standard computational complexity books
    such as the ones by Sipser [[90](ch030.xhtml#Xsipser2012introduction)], Papadimitriou
    [[74](ch030.xhtml#Xpapadimitriou1993computational)], or Arora and Barak [[8](ch030.xhtml#Xarora2009computational)].
  prefs: []
  type: TYPE_NORMAL
- en: To study the kind of questions posed in computational complexity theory, we
    need first to introduce a computational model that allows us to measure computation
    time, memory, and other resources. The usual choice is that of **Turing machines**.
    It is beyond the scope of this book to mathematically define what Turing machines
    are (for the details, check the books cited in the previous paragraph), but let
    us at least give an informal description so you can understand how we can use
    them to model computational tasks and to measure the resources involved in solving
    problems with them. Please notice that different textbooks use slightly different
    definitions of Turing machines, but it is straightforward to show that they are
    all equivalent in power.
  prefs: []
  type: TYPE_NORMAL
- en: C.1 A few words on Turing machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Turing machine is a (theoretical) device that has a (potentially infinite)
    **tape** divided into **cells**. Each of these cells can store a symbol from a
    finite and fixed number of possibilities (usually, ![0](img/file12.png "0"), ![1](img/file13.png
    "1"), and a “blank” symbol to denote an empty cell). The machine also has a **head**
    that, at any given moment, is scanning one of the tape cells. Additionally, the
    machine is in a **state** (also from a finite number of fixed options) at any
    step in the computation.
  prefs: []
  type: TYPE_NORMAL
- en: The machine has a list of instructions that, depending on the machine’s state
    and the content of the cell that the head is scanning, tell the machine what it
    should do next. This can involve changing the machine state, writing a different
    symbol on the cell that is being scanned, and moving the head one cell to the
    left or to the right. For instance, one such instruction could be “If the state
    is ![q_{2}](img/file1610.png "q_{2}") and the symbol being read is ![1](img/file13.png
    "1"), change the state to ![q_{5}](img/file1611.png "q_{5}"), change the symbol
    to ![0](img/file12.png "0"), and stay in the same cell,” while another could be
    “If the state is ![q_{0}](img/file1612.png "q_{0}") and the symbol is ![0](img/file12.png
    "0"), change the state to ![q_{1}](img/file1613.png "q_{1}"), leave the symbol
    unchanged, and move the head one cell to the right.”
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A Turing machine is a (theoretical) device that has an unbounded tape divided
    into cells and a head that scans one of those cells. At any given moment, the
    machine is in an internal state from a finite number of possibilities. The instructions
    of the machine specify, depending on the machine state and the content of the
    cell that the head is scanning, what the next state is, the new content of the
    cell, and the action of the machine (move left, move right, or stay, for instance).
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to perform a computation, the input is given as a finite string of
    symbols on the tape (the rest are left blank). Then, the Turing machine operates
    in the following way: it starts in a predefined initial state and with its head
    scanning the first symbol of the input; then, it changes its state, tape content,
    and head position following its instructions in discrete steps. Eventually, the
    machine can stop because it reaches a predefined, halting state. If the machine
    stops, the output of the computation is the string of symbols written on the tape.'
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: 'It is not guaranteed that a Turing machine will stop for all its inputs. In
    fact, it can be proved that determining whether a Turing machine will eventually
    stop with a given input (what is usually called the **halting problem**) is unsolvable
    in a very precise way: there is no algorithm that can give the correct answer
    for every possible Turing machine and every possible input. Check the book by
    Sipser [[90](ch030.xhtml#Xsipser2012introduction)] for a proof of this amazing
    fact.'
  prefs: []
  type: TYPE_NORMAL
- en: Turing machines may seem like too simple a model, but it can be proved that
    any computation that can be carried out with any other reasonable computational
    model can also be carried out with a Turing machine (maybe with some slowdown).
    For instance, it is rather straightforward to prove that if we extend Turing machines
    by giving them multiple tapes (**multi-tape Turing** **machines**) or the possibility
    of non-deterministically choosing among several instructions for the same state-symbol
    situation (**non-deterministic** **Turing machines**), the new devices aren’t
    more powerful than our original single-tape, deterministic Turing machines (again,
    see the book by Sipser [[90](ch030.xhtml#Xsipser2012introduction)] for all the
    details). The same happens if we consider models that are much closer to the actual
    architecture of modern computers, such as the **Random-Access Machines** model
    (see Section 3.4 in the book by Savage [[84](ch030.xhtml#Xsavage1998models)]),
    or even models, such as that of **while-Programs** (see the book by Kfoury, Moll,
    and Arbib [[58](ch030.xhtml#Xkfoury2012programming)]) that are based on common
    programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: This has led to the firm belief that Turing machines indeed formally capture
    the informal notion of what an algorithm is. This fact is usually known as the
    **Church-Turing thesis**.
  prefs: []
  type: TYPE_NORMAL
- en: C.2 Measuring computational time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can say that the Church-Turing thesis is simply stating that, if you are
    only interested in identifying which tasks can be solved algorithmically and which
    cannot, you can just use any of a wide number of equivalent models: single-tape
    Turing machines, multi-tape Turing machines, non-deterministic Turing machines,
    Random-Access Machines, while-Programs, and many, many others. Each of them will
    give you exactly the same power.'
  prefs: []
  type: TYPE_NORMAL
- en: But be cautious! If you care about the resources needed to carry out the computations
    (and that is what computational complexity is all about), then the choice of the
    model can be important. So let’s fix, for now, the single-tape Turing machines
    (the ones that we have described informally in the previous section) as our computational
    model. In this way, we can easily measure the time needed to carry out a certain
    computation with one of these Turing machines as the number of steps that it must
    take to complete it.
  prefs: []
  type: TYPE_NORMAL
- en: That works well for a fixed Turing machine with a particular input, but we are
    usually more interested in analyzing how the running time grows with the size
    of the input than we are in finding concrete running-time values for concrete
    problem instances. For example, we could be interested in knowing whether the
    time needed for a certain task grows so rapidly that it quickly becomes unfeasible
    to solve the problem when the input size becomes moderately big.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this reason, we will define the running time of a Turing machine as a function
    of the input length, not as a function of the particular input. Namely, the running
    time of a Turing machine ![M](img/file704.png "M") is a function ![T](img/file74.png
    "T") that takes as input a non-negative integer ![n](img/file244.png "n") and
    returns the maximum number of steps that ![M](img/file704.png "M") performs with
    an input ![x](img/file269.png "x") of ![n](img/file244.png "n") bits before it
    stops. Notice that this is a worst-case definition of running-time: it is defined
    in terms of the string that needs the most time in order to be processed. Note
    also that, if a machine does not stop for some inputs, its running time for inputs
    of those lengths will be infinite. This is not a problem for our purposes, because
    we will only consider machines that always stop.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The running time of a Turing machine ![M](img/file704.png "M") is a function
    ![T](img/file74.png "T") such that ![T(n)](img/file1614.png "T(n)") is the maximum
    number of steps that ![M](img/file704.png "M") performs when given an input of
    length ![n](img/file244.png "n").
  prefs: []
  type: TYPE_NORMAL
- en: For other computational models, running times can be defined in analogous ways.
    For instance, for multi-tape Turing machines, the running time is again measured
    as the maximum number of steps performed on inputs of size ![n](img/file244.png
    "n"). For computational models that use idealized programming languages (the while-Programs
    model, for instance) or abstract architectures (the Random-Access Machines model),
    running time can be defined as the maximum number of basic instructions (setting
    a variable to zero, incrementing a variable, comparing the value of two variables...)
    executed with inputs of size ![n](img/file244.png "n").
  prefs: []
  type: TYPE_NORMAL
- en: C.3 Asymptotic complexity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to compare different running times associated with different Turing
    machines, it is convenient to perform some simplifications. We usually do not
    care about whether the running time of a Turing machine is exactly ![T_{1}(n)
    = 4321n^{2} + 784n + 142](img/file1615.png "T_{1}(n) = 4321n^{2} + 784n + 142")
    or, rather, ![T_{2}(n) = n^{3} + 3n^{2} + 5n + 3](img/file1616.png "T_{2}(n) =
    n^{3} + 3n^{2} + 5n + 3"). In fact, we are more interested in whether ![T(n)](img/file1614.png
    "T(n)") grows roughly like ![n^{3}](img/file1617.png "n^{3}") or like ![n^{2}](img/file1618.png
    "n^{2}"), because this implies a qualitative difference: for values of ![n](img/file244.png
    "n") that are big enough, any polynomial of degree ![3](img/file472.png "3") grows
    more rapidly than any polynomial of ![2](img/file302.png "2"). In the context
    of computational complexity theory, we would always prefer a ![T(n)](img/file1614.png
    "T(n)") that grows as ![n^{2}](img/file1618.png "n^{2}") over one that grows as
    ![n^{3}](img/file1617.png "n^{3}"), because its behavior for big inputs (its asymptotic
    growth, in other words) is better.'
  prefs: []
  type: TYPE_NORMAL
- en: This intuitive idea is captured by the famous **Big O notation**. Given two
    time functions ![T_{1}(n)](img/file1619.png "T_{1}(n)") and ![T_{2}(n)](img/file1620.png
    "T_{2}(n)"), we say that ![T_{1}(n)](img/file1619.png "T_{1}(n)") is ![O(T_{2}(n))](img/file1621.png
    "O(T_{2}(n))") (and we read it is as “![T_{1}(n)](img/file1619.png "T_{1}(n)")
    is Big O of ![T_{2}(n)](img/file1620.png "T_{2}(n)")”) if there exist an integer
    constant ![n_{0}](img/file1622.png "n_{0}") and a real constant ![C > 0](img/file1262.png
    "C > 0") such that for all ![n \geq n_{0}](img/file1623.png "n \geq n_{0}") it
    holds that
  prefs: []
  type: TYPE_NORMAL
- en: '![T_{1}(n) \leq CT_{2}(n).](img/file1624.png "T_{1}(n) \leq CT_{2}(n).")'
  prefs: []
  type: TYPE_IMG
- en: For instance, you can check that ![4321n^{2} + 784n + 142](img/file1625.png
    "4321n^{2} + 784n + 142") is ![O(n^{3} + 3n^{2} + 5n + 3)](img/file1626.png "O(n^{3}
    + 3n^{2} + 5n + 3)").
  prefs: []
  type: TYPE_NORMAL
- en: The main idea behind this definition is that if ![T_{1}(n)](img/file1619.png
    "T_{1}(n)") is ![O(T_{2}(n))](img/file1621.png "O(T_{2}(n))"), then the growth
    of ![T_{1}](img/file1627.png "T_{1}") is not worse than that of ![T_{2}(n)](img/file1620.png
    "T_{2}(n)"). For example, it is easy to prove that ![n^{a}](img/file1628.png "n^{a}")
    is ![O(n^{b})](img/file1629.png "O(n^{b})") whenever ![a \leq b](img/file1630.png
    "a \leq b") and that ![n^{a}](img/file1628.png "n^{a}") is ![O(2^{n})](img/file1631.png
    "O(2^{n})") for any ![a](img/file16.png "a"). But, on the other hand, ![n^{b}](img/file1632.png
    "n^{b}") is not ![O(n^{a})](img/file1633.png "O(n^{a})") and ![2^{n}](img/file256.png
    "2^{n}") is not ![O(n^{a})](img/file1633.png "O(n^{a})"). See *Figure* * [*C.1*](#FigureC.1)
    for an example with linear, quadratic, cubic, and exponential functions. Notice
    how the exponential function eventually dominates all the others despite having
    ![10^{- 4}](img/file1634.png "10^{- 4}") as its coefficient.*
  prefs: []
  type: TYPE_NORMAL
- en: '*![Figure C.1: Growth of linear, quadratic, cubic, and exponential functions](img/file1635.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure C.1**: Growth of linear, quadratic, cubic, and exponential functions'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Given two non-negative functions ![T_{1}(n)](img/file1619.png "T_{1}(n)") and
    ![T_{2}(n)](img/file1620.png "T_{2}(n)"), we say that ![T_{1}(n)](img/file1619.png
    "T_{1}(n)") is ![O(T_{2}(n))](img/file1621.png "O(T_{2}(n))") if there exist ![n_{0}](img/file1622.png
    "n_{0}") and ![C > 0](img/file1262.png "C > 0") such that
  prefs: []
  type: TYPE_NORMAL
- en: '![T_{1}(n) \leq CT_{2}(n)](img/file1636.png "T_{1}(n) \leq CT_{2}(n)")'
  prefs: []
  type: TYPE_IMG
- en: for every ![n \geq n_{0}](img/file1623.png "n \geq n_{0}").
  prefs: []
  type: TYPE_NORMAL
- en: Big O notation is extremely useful to estimate the behavior of running times
    without having to focus on small, cumbersome details. If the running time of a
    Turing machine is ![4321n^{2} + 784n + 142](img/file1625.png "4321n^{2} + 784n
    + 142"), we can just say that it is ![O(n^{2})](img/file1637.png "O(n^{2})") and
    forget about the particular coefficients in the time function. This is also the
    reason why we can abstractly think about the number of steps and not, for example,
    milliseconds. The particular amount of time that each step takes is a constant
    that will be “absorbed” by the Big O notation.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this comes at a price. A running time such as ![10^{100}n^{2}](img/file1638.png
    "10^{100}n^{2}") is certainly ![O(n^{2})](img/file1637.png "O(n^{2})"). But it
    is not preferable to ![n^{3}](img/file1617.png "n^{3}") unless ![n > 10^{100}](img/file1639.png
    "n > 10^{100}"), something that will never happen in practical situations, because
    ![10^{100}](img/file1640.png "10^{100}") is much, much bigger than the number
    of atoms in the visible universe. So use this notation wisely: with Big O comes
    Big Responsibility.'
  prefs: []
  type: TYPE_NORMAL
- en: C.4 P and NP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned at the beginning of this appendix, computational complexity
    theory studies the amount of resources needed to solve problems with algorithms.
    So far, we have focused on how to mathematically define the notion of algorithm
    with the help of Turing machines and on how to measure the time needed to perform
    computations with them. Now, we turn our attention to defining computational problems
    and classifying them according to the time they take to be solved. That is, we
    will think in terms of their inherent complexity and not in terms of specific
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In computational complexity theory, a **problem** consists of an infinite number
    of instances or inputs for which an output value needs to be returned. For example,
    we may be given two natural numbers and asked to compute their product. Or we
    may be given a graph and asked to check if it has a Hamiltonian path or not. In
    both cases, the number of possible inputs is infinite and there is a well-defined
    output or answer associated with each such input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem instances are usually encoded as binary strings in some way. For example,
    we can represent a natural number by its binary expansion or a graph by (the concatenation
    of the rows of) its adjacency matrix. In the same way, outputs can also be represented
    by binary strings. Consequently, a problem can be identified with a function that
    takes a binary string as its input and returns a binary string as its output.
    But a Turing machine does exactly that: it receives binary strings as inputs and
    returns binary strings as outputs. This allows us to study which problems can
    be solved with Turing machines and how much time is needed to solve them.'
  prefs: []
  type: TYPE_NORMAL
- en: In computational complexity, the simplest category of problem that we can consider
    is that of **decision problems**, in which the output is a single bit (we usually
    identify ![1](img/file13.png "1") with “true” and ![0](img/file12.png "0") with
    “false”). Examples of decision problems include determining whether a natural
    number ![m](img/file259.png "m") is prime, determining whether a graph has a Hamiltonian
    path, and determining whether a Turing machine stops for all its inputs.
  prefs: []
  type: TYPE_NORMAL
- en: We say that a Turing machine is a **decider** for a decision problem if, given
    as input a binary string representing an instance of the problem, it eventually
    stops and returns the correct output (![0](img/file12.png "0") or ![1](img/file13.png
    "1")) for that instance. In that case, we also say that the Turing machine **solves**
    or **decides** the problem. There exist deciders for the problems of determining
    whether a number is prime and of determining whether a graph has a Hamiltonian
    path, but not for the problem of determining whether a Turing machine stops for
    all of its inputs (this is a consequence of the unsolvability of the halting problem
    that we mentioned earlier).
  prefs: []
  type: TYPE_NORMAL
- en: Once we know that a problem has a decider, we can try to further refine its
    classification by taking into account the resources used by the decider. This
    leads, for instance, to the definition of the famous ![P](img/file1.png "P") (short
    for “polynomial time”) class. We say that a decision problem ![A](img/file183.png
    "A") is in ![P](img/file1.png "P") if there exists a decider for ![A](img/file183.png
    "A") that runs in polynomial time. That is, there exists a Turing machine ![D](img/file1101.png
    "D") that decides ![A](img/file183.png "A") and whose running time ![T(n)](img/file1614.png
    "T(n)") is ![O(n^{a})](img/file1633.png "O(n^{a})") for some non-negative integer
    ![a](img/file16.png "a"). Notice that, for a problem to be in ![P](img/file1.png
    "P"), it is enough to find one polynomial-time decider for it. However, in order
    to show that a decision problem ![A](img/file183.png "A") is not in ![P](img/file1.png
    "P"), we need to prove that no Turing machine running in polynomial time is able
    to decide ![A](img/file183.png "A"). This is usually much, much harder to do.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, a celebrated result by Agrawal, Kayal, and Saxen [[5](ch030.xhtml#Xagrawal2004primes)]
    shows that the problem of determining whether a natural number is a prime is indeed
    in ![P](img/file1.png "P"). Other, simpler examples of problems in ![P](img/file1.png
    "P") include checking whether a number is a perfect square or checking whether
    a binary string is a palindrome (that is, it reads the same from left to right
    and from right to left). However, for the problem of determining whether a graph
    has a Hamiltonian path, we do not know whether it is in ![P](img/file1.png "P")
    or not. We very strongly believe that it is not in ![P](img/file1.png "P"), but
    despite the best efforts of thousands of mathematicians over several decades,
    we still can’t prove it.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We define ![P](img/file1.png "P") as the class of decision problems that can
    be solved with Turing machines in polynomial time.
  prefs: []
  type: TYPE_NORMAL
- en: Actually, ![P](img/file1.png "P") is interesting for several reasons. First,
    it is quite robust. We have defined it in terms of the computation time required
    by deciders that are single-tape Turing machines. However, if we had chosen another
    computational model such as, for instance, multi-tape Turing machines, then we
    would have arrived at exactly the same set of problems. This is so because it
    is possible to simulate a multi-tape Turing machine with a single-tape Turing
    machine with just a polynomial overhead in running time. The same is true for
    any other reasonable (classical) computational model, so although the particular
    running time might differ from one model to another (say ![O(n^{4}](img/file1641.png
    "O(n^{4}")) with single-tape Turing machines and ![O(n^{2})](img/file1637.png
    "O(n^{2})") with ![2](img/file302.png "2")-tape Turing machines), one will be
    polynomial if and only if the other is.
  prefs: []
  type: TYPE_NORMAL
- en: What is more, ![P](img/file1.png "P") seems to capture quite well the notion
    of a problem being efficiently solvable. It is true that in ![P](img/file1.png
    "P") we allow running times such as ![n^{1000}](img/file1642.png "n^{1000}"),
    which can hardly be deemed as efficient. However, the running time of naturally-occurring
    problems that we can prove to be in ![P](img/file1.png "P") is typically much
    more tame, such as ![O(n^{2})](img/file1637.png "O(n^{2})") or ![O(n^{3})](img/file1643.png
    "O(n^{3})"). Moreover, if a decision problem is not in ![P](img/file1.png "P"),
    then the running time of any of its deciders will grow faster than any polynomial
    (at least, for an infinite number of its inputs). And that is something that we
    can unequivocally classify as not efficient at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another central class of problems in computational complexity is ![NP](img/file2.png
    "NP"). It is, again, a class of decision problems. But, in this case, the defining
    property is not that we can solve them efficiently (as in the case of ![P](img/file1.png
    "P")) but that we can check their solutions with an efficient algorithm. To make
    this idea formal, we say that a problem ![A](img/file183.png "A") has a **polynomial-time
    verifier** if there exists a Turing machine ![V](img/file379.png "V") that runs
    in polynomial time and a polynomial ![q](img/file292.png "q") with the two following
    properties:'
  prefs: []
  type: TYPE_NORMAL
- en: If ![x](img/file269.png "x") is an instance of problem ![A](img/file183.png
    "A") of size ![n](img/file244.png "n") for which the answer is “true,” then there
    exists a binary string ![y](img/file270.png "y") of length at most ![q(n)](img/file1644.png
    "q(n)") such that ![V](img/file379.png "V") on input ![(x,y)](img/file1645.png
    "(x,y)") returns ![1](img/file13.png "1"). The string ![y](img/file270.png "y")
    is usually called a **witness**, a **certificate**, or a **proof** for ![x](img/file269.png
    "x").
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If ![x](img/file269.png "x") is an instance of problem ![A](img/file183.png
    "A") of size ![n](img/file244.png "n") for which the answer is “false,” then for
    every binary string ![y](img/file270.png "y") of length at most ![q(n)](img/file1644.png
    "q(n)"), ![V](img/file379.png "V") on input ![(x,y)](img/file1645.png "(x,y)")
    returns ![0](img/file12.png "0").
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This definition is a little bit convoluted, so let’s analyze it in detail. The
    idea here is that for an instance ![x](img/file269.png "x") of ![A](img/file183.png
    "A") whose answer is positive, we can find a certificate ![y](img/file270.png
    "y") that is not long (its length is polynomial in the size ![x](img/file269.png
    "x")) and that we can check when we are given ![y](img/file270.png "y") together
    with ![x](img/file269.png "x"), with an efficient algorithm. However, for instances
    whose answer is negative, there is no such certificate. Note also that the total
    running time of ![V](img/file379.png "V") on ![(x,y)](img/file1645.png "(x,y)")
    is polynomial in the length of ![x](img/file269.png "x"), because ![V](img/file379.png
    "V") runs in polynomial time in its whole input and ![y](img/file270.png "y")
    has a length that is polynomial in ![x](img/file269.png "x"). Hence, this definition
    really captures the notion of checking that the answer to ![x](img/file269.png
    "x") is positive (through certificate ![y](img/file270.png "y")) with an efficient
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: With this notion at our disposal, we can now define ![NP](img/file2.png "NP")
    as the class of decision problems for which there exists a polynomial-time verifier.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: An alternative, but equivalent, definition of ![NP](img/file2.png "NP") can
    be given in terms of non-deterministic Turing machines. In fact, ![NP](img/file2.png
    "NP") is short for ”non-deterministic polynomial time.” You can find all the details
    in Sipser’s book [[90](ch030.xhtml#Xsipser2012introduction)].
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss an example to illustrate this definition. The problem of determining
    whether a graph has a Hamiltonian path is in ![NP](img/file2.png "NP"). The certificate
    ![y](img/file270.png "y") can, in this case, be just a Hamiltonian path in the
    graph. Indeed, it is easy to write a program (in Python, for example) that, given
    a graph represented by ![x](img/file269.png "x") and a sequence of vertices represented
    by ![y](img/file270.png "y"), checks whether ![y](img/file270.png "y") is a path
    in ![x](img/file269.png "x") that visits all the vertices in the graph. Moreover,
    we can easily do this computation in polynomial time and the certificate is always
    of size linear in the number of graph vertices. As required, for graphs that have
    a Hamiltonian path, there exists at least a certificate. However, for graphs without
    Hamiltonian paths, no ![y](img/file270.png "y") will make the verifier output
    ![1](img/file13.png "1"). If needed, we could translate our algorithm into Turing
    machine instructions; it is a tedious process, but it has no real difficulty.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '![NP](img/file2.png "NP") is the class of decision problems whose solution
    can be verified with Turing machines in polynomial time.'
  prefs: []
  type: TYPE_NORMAL
- en: Similar arguments can be given to prove that many important problems are in
    ![NP](img/file2.png "NP"), including determining whether a Boolean formula is
    satisfiable, determining whether a graph is ![3](img/file472.png "3")-colorable,
    or determining whether a graph has a cut of size bigger than a given integer ![k](img/file317.png
    "k"). The certificates for them can, of course, be a satisfying assignment, a
    ![3](img/file472.png "3")-coloring of the graph, and a cut of size bigger than
    ![k](img/file317.png "k"). All of them are of a size comparable to the problem
    instances they certify and can be checked efficiently with obvious procedures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, any problem in ![P](img/file1.png "P") is also in ![NP](img/file2.png
    "NP"). This is easily proved. By definition, a problem ![A](img/file183.png "A")
    in ![P](img/file1.png "P") has a decider. But we can directly use this decider
    to obtain a verifier for ![A](img/file183.png "A"): we only need to ignore the
    candidate certificate ![y](img/file270.png "y") and compute the answer with the
    decider itself. If the machine knows how to solve the problem in polynomial time
    on its own, it does not need any external help!'
  prefs: []
  type: TYPE_NORMAL
- en: So, we know that ![P](img/file1.png "P") is contained in ![NP](img/file2.png
    "NP"). And it seems like we should be able to prove that they are different, because
    there must be problems whose solutions we can check efficiently, but for which
    it is impossible to find those same solutions in a reasonable amount of time,
    right? Well, it turns out that this is by no means an easy task. In fact, it is
    literally the million-dollar question!
  prefs: []
  type: TYPE_NORMAL
- en: Determining whether ![P = NP](img/file337.png "P = NP") is one of the seven
    Millennium Problems selected by the Clay Mathematics Institute in 2000 as the
    most important open questions in all of mathematics (for an accessible account
    of the Millennium Problems, check the book by Keith Devlin [[30](ch030.xhtml#Xdevlin2002millennium)]).
    Whoever is able to give proof showing that ![P \neq NP](img/file1646.png "P \neq
    NP") or to show that every problem in ![NP](img/file2.png "NP") is also in ![P](img/file1.png
    "P"), will receive a one-million-dollar prize and will become world-famous.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Every problem in ![P](img/file1.png "P") is also in ![NP](img/file2.png "NP").
    The question of whether there are problems in ![NP](img/file2.png "NP") that cannot
    be solved in polynomial time is one of the most important open questions in all
    of mathematics.
  prefs: []
  type: TYPE_NORMAL
- en: Almost every expert in computational complexity believes that, in fact, ![P
    \neq NP](img/file1646.png "P \neq NP"). All the evidence points in that direction.
    And it certainly seems logical that *checking* a solution should be easier in
    general than *finding* a solution. However, no one has yet succeeded in proving
    that there are problems in ![NP](img/file2.png "NP") that are not in ![P](img/file1.png
    "P"), and the most natural proof techniques have been shown to be insufficient
    (see *Section 6.5* in the epic book by Moore and Mertens [[68](ch030.xhtml#Xmoore2011nature)]).
  prefs: []
  type: TYPE_NORMAL
- en: C.5 Hardness, completeness, and reductions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although our current mathematical tools are not powerful enough to give satisfactory
    lower bounds on the resources needed by computational problems, we do know a good
    deal more about comparing the relative hardness of problems. The main concept
    used for that kind of comparison is what we call a **reduction**.
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, a reduction is a procedure to solve a problem from the solution
    to a different problem. We could say that we reduce solving problem ![A](img/file183.png
    "A") to solving problem ![B](img/file184.png "B"). So if we know how to solve
    ![B](img/file184.png "B") with an algorithm, we can use that algorithm and some
    additional computation to also solve ![A](img/file183.png "A").
  prefs: []
  type: TYPE_NORMAL
- en: 'To put it more formally, consider two problems ![A](img/file183.png "A") and
    ![B](img/file184.png "B"), and imagine that we have an algorithm ![M_{B}](img/file1647.png
    "M_{B}") that solves ![B](img/file184.png "B"). ![M_{B}](img/file1647.png "M_{B}")
    is usually called an **oracle** for ![B](img/file184.png "B"). We say that ![A](img/file183.png
    "A") is **reducible** to ![B](img/file184.png "B") if we can solve ![A](img/file183.png
    "A") given an oracle for ![B](img/file184.png "B"). For instance, multiplying
    two numbers is reducible to adding two numbers: if we are given an oracle that
    adds numbers, we can use it to multiply by repeated addition.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, when studying computational classes such as ![P](img/file1.png "P")
    and ![NP](img/file2.png "NP"), we are interested in reductions that take a polynomial
    amount of time. But how can we capture that idea formally? Well, we can simply
    count each call to the oracle as just another step in the computation. Then, we
    say that a problem ![A](img/file183.png "A") is **polynomial-time** **reducible**
    to a problem ![B](img/file184.png "B") if, given an oracle ![M_{B}](img/file1647.png
    "M_{B}") for ![B](img/file184.png "B"), we can solve any instance ![x](img/file269.png
    "x") of ![A](img/file183.png "A") with a total number of computational steps plus
    calls to ![M_{B}](img/file1647.png "M_{B}") that is polynomial in the size of
    ![x](img/file269.png "x"). Another way of seeing this is imagining that we extend
    our Turing machines with the capability of computing ![M_{B}](img/file1647.png
    "M_{B}") in a single step (these new devices are unsurprisingly called **oracle
    Turing machines**). Then, showing that ![A](img/file183.png "A") is polynomial-time
    reducible to ![B](img/file184.png "B") is the same as finding an oracle Turing
    machine (with an oracle for ![B](img/file184.png "B")) that solves ![A](img/file183.png
    "A") in polynomial time.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that ![A](img/file183.png "A") being polynomial-time reducible to ![B](img/file184.png
    "B") has important consequences. The first one is that if ![B](img/file184.png
    "B") is in ![P](img/file1.png "P"), then ![A](img/file183.png "A") is also in
    ![P](img/file1.png "P"). This is so because, if ![B](img/file184.png "B") is in
    ![P](img/file1.png "P"), we can replace every call to ![M_{B}](img/file1647.png
    "M_{B}") with an actual Turing machine that solves ![B](img/file184.png "B") and
    runs in polynomial time, making the total time involved in solving ![A](img/file183.png
    "A") also polynomial. This also implies that if ![A](img/file183.png "A") is not
    in ![P](img/file1.png "P"), then ![B](img/file184.png "B") cannot be in ![P](img/file1.png
    "P") either, because it would lead us to a contradiction.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we say that a problem ![B](img/file184.png "B") is ![NP](img/file2.png
    "NP")**-hard** if every problem ![A](img/file183.png "A") in ![NP](img/file2.png
    "NP") is polynomial-time reducible to ![B](img/file184.png "B"). This means that
    ![B](img/file184.png "B") is at least as hard as any problem ![A](img/file183.png
    "A") in ![NP](img/file2.png "NP"), because if we knew how to solve ![B](img/file184.png
    "B") efficiently, then we would also know how to solve ![A](img/file183.png "A")
    efficiently. And if at least one problem in ![A](img/file183.png "A") cannot be
    solved in polynomial time, that implies that ![B](img/file184.png "B") cannot
    be solved in polynomial time either.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A problem is ![NP](img/file2.png "NP")-hard if every problem in ![NP](img/file2.png
    "NP") is polynomial-time reducible to it.
  prefs: []
  type: TYPE_NORMAL
- en: Being ![NP](img/file2.png "NP")-hard seems like a very strong property. Is it
    really possible for *every* problem ![A](img/file183.png "A") in ![NP](img/file2.png
    "NP") to be reduced to a single problem ![B](img/file184.png "B")? As surprising
    as this may seem, we know of hundreds (if not thousands) of problems that occur
    naturally in practice and that are indeed ![NP](img/file2.png "NP")-hard. A notable
    example is the problem of determining whether a Boolean formula is satisfiable
    or not, also called SAT. That SAT is ![NP](img/file2.png "NP")-hard is the content
    of the famous Cook-Levin theorem (see the book by Sipser for a proof [[90](ch030.xhtml#Xsipser2012introduction)]).
    In *Chapter* * [*3*](ch011.xhtml#x1-590003), *Working with Quadratic* *Unconstrained
    Binary Optimization Problems*, we work with many ![NP](img/file2.png "NP")-hard
    problems. For many other examples and much more on the concept of ![NP](img/file2.png
    "NP")-hardness, you can check the classical book by Garey and Johnson [[44](ch030.xhtml#Xgarey1979computers)].*
  prefs: []
  type: TYPE_NORMAL
- en: '*In fact, it turns out that we can prove that SAT and other decision problems
    in ![NP](img/file2.png "NP") have a property that is a bit stronger than ![NP](img/file2.png
    "NP")-hardness known as ![NP](img/file2.png "NP")**-completeness**. In order to
    discuss it, we first need to talk about a special type of reduction that is very
    useful when studying decision problems. We say that a decision problem ![A](img/file183.png
    "A") is **many-one reducible** to a decision problem ![B](img/file184.png "B")
    if there exists an algorithm ![F](img/file1320.png "F") that transforms an instance
    ![x](img/file269.png "x") of ![A](img/file183.png "A") into an instance ![F(x)](img/file1648.png
    "F(x)") of ![B](img/file184.png "B") with the property that the answer to ![x](img/file269.png
    "x") in ![A](img/file183.png "A") is positive if and only if the answer to ![x](img/file269.png
    "x") in ![B](img/file184.png "B") is positive.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that, in this case, we indeed have a reduction in the more general sense
    that we were discussing earlier. If we are given an oracle ![M_{B}](img/file1647.png
    "M_{B}") for ![B](img/file184.png "B"), we can solve any instance ![x](img/file269.png
    "x") of ![A](img/file183.png "A") by computing ![F(x)](img/file1648.png "F(x)")
    and applying ![M_{B}](img/file1647.png "M_{B}") to ![F(x)](img/file1648.png "F(x)").
    Here, we are using only one call to ![M_{B}](img/file1647.png "M_{B}"), but in
    a general reduction, we can use ![M_{B}](img/file1647.png "M_{B}") as many times
    as we see fit. Thus, a many-one reduction is a special case of a reduction. Additionally,
    in the case in which the transformation ![F](img/file1320.png "F") can be computed
    in polynomial time, we say that we have a **polynomial-time** **many-one reduction**.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A polynomial-time many-one reduction of a decision problem ![A](img/file183.png
    "A") to a decision problem ![B](img/file184.png "B") is a polynomial-time algorithm
    ![F](img/file1320.png "F") that takes instances ![x](img/file269.png "x") of ![A](img/file183.png
    "A") to instances ![F(x)](img/file1648.png "F(x)") of ![B](img/file184.png "B")
    with the property that the answer to ![x](img/file269.png "x") in ![A](img/file183.png
    "A") is “true” if and only if the answer to ![F(x)](img/file1648.png "F(x)") in
    ![B](img/file184.png "B") is “true.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can actually define that subclass of ![NP](img/file2.png "NP")-hard
    problems that we talked about before: the class of ![NP](img/file2.png "NP")**-complete**
    problems. We say that a problem is ![NP](img/file2.png "NP")-complete if it is
    both in ![NP](img/file2.png "NP") and every problem in ![NP](img/file2.png "NP")
    is polynomial-time many-one reducible to it. As we mentioned before, SAT, for
    example, is ![NP](img/file2.png "NP")-complete. Other ![NP](img/file2.png "NP")-complete
    problems include determining whether a graph is ![3](img/file472.png "3")-colorable,
    determining whether the constraints of a binary linear program can be satisfied,
    determining whether a graph has a cut of size bigger than a given integer ![k](img/file317.png
    "k"), and many other natural decision problems.'
  prefs: []
  type: TYPE_NORMAL
- en: '![NP](img/file2.png "NP")-complete problems are central to the study of the
    ![P\overset{?}{=}NP](img/file1649.png "P\overset{?}{=}NP") question because ![P
    = NP](img/file337.png "P = NP") if and only if at least one ![NP](img/file2.png
    "NP")-complete problem is in ![P](img/file1.png "P"). So, you can focus on, say,
    just studying SAT. If you find a polynomial-time algorithm for it, then ![P =
    NP](img/file337.png "P = NP"). If, on the contrary, you show that it is impossible
    to solve SAT in polynomial time, you have found a problem in ![NP](img/file2.png
    "NP") that is not in ![P](img/file1.png "P") and then, immediately, you can conclude
    that ![P \neq NP](img/file1646.png "P \neq NP").'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A problem ![B](img/file184.png "B") is ![NP](img/file2.png "NP")-complete if
    it is in ![NP](img/file2.png "NP") and every other problem ![A](img/file183.png
    "A") in ![NP](img/file2.png "NP") is polynomial-time many-one reducible to ![B](img/file184.png
    "B").
  prefs: []
  type: TYPE_NORMAL
- en: There are, of course, ![NP](img/file2.png "NP")-hard problems that are not ![NP](img/file2.png
    "NP")-complete. This is the case, for instance, if you have an ![NP](img/file2.png
    "NP")-hard problem that is not a decision problem (and, hence, cannot be in ![NP](img/file2.png
    "NP")). Many problems that we study in *Chapter* * [*3*](ch011.xhtml#x1-590003),
    *Working with Quadratic* *Unconstrained Binary Optimization Problems*, fall under
    that category. For instance, finding a minimal coloring for a graph is clearly
    ![NP](img/file2.png "NP")-hard. If you knew how to solve this problem efficiently,
    then you could also determine whether a graph is ![3](img/file472.png "3")-colorable
    (you just need to compute the minimal coloring and check whether its number of
    colors is at most ![3](img/file472.png "3")). But checking whether a graph is
    ![3](img/file472.png "3")-colorable is ![NP](img/file2.png "NP")-hard and, thus,
    finding a minimal coloring is also ![NP](img/file2.png "NP")-hard.*
  prefs: []
  type: TYPE_NORMAL
- en: '*Many other examples of problems that are optimization versions of ![NP](img/file2.png
    "NP")-complete problems are also ![NP](img/file2.png "NP")-hard, including determining
    the maximum number of clauses that can be simultaneously satisfied in a Boolean
    formula in conjunctive normal form (the MAX-SAT problem), finding a maximum cut
    in a graph (the Max-Cut problem), finding a minimum-cost solution of a binary
    linear program, or solving the Traveling Salesperson problem. However, none of
    them is ![NP](img/file2.png "NP")-complete because they are not in ![NP](img/file2.png
    "NP"): they are not decision problems to start with and, moreover, it is far from
    clear that you could check efficiently that a candidate solution is, indeed, an
    optimal solution!'
  prefs: []
  type: TYPE_NORMAL
- en: C.6 A very brief introduction to quantum computational complexity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have focused only on measuring time complexity with classical models.
    However, this is a book on quantum computing, so it is natural to ask what will
    change if we consider quantum computational models instead. This is studied in
    **quantum computational complexity theory**, a fascinating topic that is totally
    beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Let us, however, say a few words on the kind of concepts that arise when quantum
    models are considered instead of classical Turing machines. This is not at all
    needed to understand any other part of the book, so feel completely free to skip
    it. We will need to be brief, but you can refer to the survey by Watrous [[96](ch030.xhtml#Xwatrous2008quantum)]
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: It turns out that it is possible to define a class of problems that can be seen
    as a quantum analogous to ![P](img/file1.png "P"). This class is known as ![BQP](img/file1650.png
    "BQP"), and it contains those decision problems that can be solved with bounded
    error in polynomial time with a quantum algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: There are a couple of things that we need to clarify here. The first one is
    that quantum algorithms being probabilistic, we cannot expect the correct answer
    to a decision problem to always be obtained. Instead, we impose that this correct
    answer is returned, for each input, with high probability. Formally, the requirement
    is that for every positive instance ![x](img/file269.png "x"), the probability
    of obtaining ![1](img/file13.png "1") when the input to the algorithm is ![x](img/file269.png
    "x") should be at least ![\left. 2\slash 3 \right.](img/file1651.png "\left. 2\slash
    3 \right."); similarly, for every negative instance ![x](img/file269.png "x"),
    the probability of obtaining ![0](img/file12.png "0") when the algorithm runs
    on ![x](img/file269.png "x") should be at least ![\left. 2\slash 3 \right.](img/file1651.png
    "\left. 2\slash 3 \right."). In this way, we can repeat the procedure with the
    same input several times and take the majority result. If the number of repetitions
    is big enough (but fixed), we can make the probability of error arbitrarily small
    while still having a total running time that is polynomial.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: '![BQP](img/file1650.png "BQP") is not exactly analogous to ![P](img/file1.png
    "P") but to another (classical) computational class called ![BPP](img/file1652.png
    "BPP"). The class ![BPP](img/file1652.png "BPP") contains those decision problems
    that can be solved with bounded error in polynomial time with a probabilistic
    Turing machine (that is, a Turing machine with multiple instructions for certain
    state-symbol situations and that can decide which instruction to execute based
    on a sequence of random bits). ![BPP](img/file1652.png "BPP") stands for **bounded-error
    probabilistic polynomial time** while ![BQP](img/file1650.png "BQP") stands for
    **bounded-error quantum polynomial time**.'
  prefs: []
  type: TYPE_NORMAL
- en: The other thing that needs to be clarified about our definition of ![BQP](img/file1650.png
    "BQP") is what we exactly understand by a quantum algorithm. In the classical
    case, we have identified this notion with a (single-tape) Turing machine. It is
    possible to define a quantum version of Turing machines (see, for instance, the
    paper by Bernstein and Vazirani [[16](ch030.xhtml#Xbernstein1997quantum)]) and
    use it in our definition. But since our primary model for quantum computations
    throughout this book is the quantum circuit model, a natural question is whether
    we can also use it to formalize the notion of quantum algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, we can give a definition of what is a quantum algorithm in terms of
    quantum circuits, and this definition is equivalent in computational power to
    the one in terms of quantum Turing machines (and polynomially equivalent with
    respect to running time). However, there exist several subtleties that need to
    be confronted.
  prefs: []
  type: TYPE_NORMAL
- en: The first one is related to being able to consistently measure the execution
    time of a quantum circuit. To do that, we need to fix a finite set of gates and
    express every circuit using only those gates. Then, we can assign a cost of one
    unit to each of those gates and measure the running time of a circuit as its total
    number of gates. Otherwise, if we allow arbitrary gates, then we could argue that
    any circuit is just a single unitary gate (plus some measurements), something
    that is clearly meaningless in terms of analyzing its complexity. Notice that
    fixing a finite set of permitted gates also allows us to describe every circuit
    as a finite binary string, for instance, giving a list of the gates that we use
    and the qubits on which we apply them.
  prefs: []
  type: TYPE_NORMAL
- en: The finite set of gates needs to be chosen in a way that we can approximate
    any given quantum circuit to arbitrary precision. A possible way of doing this
    is explained in the survey by Watrous [[96](ch030.xhtml#Xwatrous2008quantum)].
  prefs: []
  type: TYPE_NORMAL
- en: 'A second technical problem that we need to tackle is that, while a Turing machine
    can process inputs of any size, every quantum circuit has a fixed number of qubits
    and, hence, only admits inputs of a fixed size. As a consequence, we cannot represent
    a full algorithm (that needs to be able to solve every possible instance of a
    problem) with just one quantum circuit: we need to consider an infinite family
    of circuits, one for each input size. So, a quantum algorithm is not a single
    quantum circuit, but a collection ![\{ C_{n}\}](img/file1653.png "\{ C_{n}\}")
    of circuits, one for each natural number ![n](img/file244.png "n"), so that ![C_{n}](img/file1654.png
    "C_{n}") admits ![n](img/file244.png "n") qubits as its input.'
  prefs: []
  type: TYPE_NORMAL
- en: The final issue that we need to address is related to the way in which we select
    that infinite family of circuits. If we allow any collection of circuits to represent
    a quantum algorithm, then we can end up in pathological situations such as being
    able to solve (a problem equivalent to) the Halting problem, which we know to
    be uncomputable! This is because we could just select a different, totally unrelated
    quantum circuit for each size in a way that the quantum circuit already “knows”
    the answer to the Halting problem for its input size. This is not something particular
    to just quantum circuits. The same happens with classical Boolean circuits (as
    we mentioned, this is a subtle point; see Section 2.2 in the book by Kitaev et
    al. [[60](ch030.xhtml#Xkitaev2002classical)] or Chapter 6 in the book by Arora
    and Barak [[8](ch030.xhtml#Xarora2009computational)], especially what is said
    there about the ![\left. P\slash poly \right.](img/file1655.png "\left. P\slash
    poly \right.") class of problems).
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this issue is to specify all the quantum circuits in the family
    in a **uniform** way. For instance, we can impose that there exists a (classical)
    Turing machine that, given a natural number ![n](img/file244.png "n"), generates
    the circuit for input size ![n](img/file244.png "n") in polynomial time (in ![n](img/file244.png
    "n")). In this way, we can’t hide any additional complexity in the selection of
    the quantum circuits. Remember that we can represent our quantum circuits as finite
    binary strings (because we have fixed a finite number of allowable quantum gates),
    so it makes sense to obtain them as the output of a Turing machine. Moreover,
    every circuit will have a polynomial size (a polynomial-time Turing machine can
    only output a polynomial number of bits, after all) and hence a polynomial running
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '![BQP](img/file1650.png "BQP") is the class of decision problems that can be
    solved with bounded error by polynomial-time uniform families of quantum circuits.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have defined ![BQP](img/file1650.png "BQP"), it is natural to ask
    about its relationship with ![P](img/file1.png "P") and ![NP](img/file2.png "NP")
    in order to be able to assess the power of quantum computers when compared to
    that of classical ones.
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to show that ![P \subseteq BQP](img/file1656.png "P \subseteq BQP"),
    that is, that every problem in ![P](img/file1.png "P") is also in ![BQP](img/file1650.png
    "BQP"). This follows directly from the fact that we can simulate any classical
    Boolean circuit with a quantum circuit (as we show in *Section* * [*1.5.2*](ch008.xhtml#x1-370001.5.2))
    and from the fact that polynomial-time uniform families of classical circuits
    are equivalent to polynomial-time Turing machines (see Section 6.2 in the book
    by Arora and Barak [[8](ch030.xhtml#Xarora2009computational)]). But this is not
    surprising at all, because we expect quantum computers to be at least as powerful
    as classical computers.*
  prefs: []
  type: TYPE_NORMAL
- en: '*So the question that we should really ask is whether there are problems in
    ![BQP](img/file1650.png "BQP") that are not in ![P](img/file1.png "P"). The short
    answer is that…we don’t know. Proving it would imply a major breakthrough not
    only in quantum computational complexity but also in classical computational complexity
    theory. It can be proved that ![BQP](img/file1650.png "BQP") is contained in ![PSPACE](img/file1657.png
    "PSPACE"), the class of decision problems solvable in polynomial space. Showing
    that ![P](img/file1.png "P") is different from ![BQP](img/file1650.png "BQP")
    would also imply that ![P](img/file1.png "P") is different from ![PSPACE](img/file1657.png
    "PSPACE"), which is a major open question in computational complexity (although
    it should be easier to solve than the ![P](img/file1.png "P") versus ![NP](img/file2.png
    "NP") problem, because ![NP](img/file2.png "NP") is also contained in ![PSPACE](img/file1657.png
    "PSPACE")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'That being said, we have good reasons to believe that there are problems in
    ![BQP](img/file1650.png "BQP") that are not in ![P](img/file1.png "P"). In fact,
    we have a very good candidate: the factoring problem (given natural numbers ![m](img/file259.png
    "m") and ![k](img/file317.png "k"), check whether ![m](img/file259.png "m") has
    a factor ![l \neq 1](img/file1658.png "l \neq 1") that is less than ![k](img/file317.png
    "k")) is in ![BQP](img/file1650.png "BQP") thanks to Shor’s algorithm [[87](ch030.xhtml#Xshor99polynomial)],
    but it would be really, really surprising if it were in ![P](img/file1.png "P").
    In fact, many cryptographic protocols currently in use rely on the assumption
    that factoring is not in ![P](img/file1.png "P"). So, every time that you buy
    something online and you send your credit card number over the internet, you are
    implicitly trusting that ![P](img/file1.png "P") and ![BQP](img/file1650.png "BQP")
    are not equal (and that nobody owns a powerful enough quantum computer!).'
  prefs: []
  type: TYPE_NORMAL
- en: And what about ![BQP](img/file1650.png "BQP") and ![NP](img/file2.png "NP")?
    The situation there is a little bit more complicated. The evidence that we have
    seems to imply that there are problems in ![BQP](img/file1650.png "BQP") that
    are not in ![NP](img/file2.png "NP") (one of the strongest results in this direction
    can be found in a recent paper by Raz and Tal [[79](ch030.xhtml#Xraz2022oracle)]).
    But we also have some evidence that seems to suggest that there are problems in
    ![NP](img/file2.png "NP") that are not in ![BQP](img/file1650.png "BQP"), due
    to results by Bennett, Bernstein, Brassard, and Vazirani [[15](ch030.xhtml#Xbennett1997strengths)]
    that show that Grover’s algorithm is, in a certain sense, optimal among quantum
    algorithms for search tasks.
  prefs: []
  type: TYPE_NORMAL
- en: If all this is true, it would imply that there are problems that we can solve
    efficiently with quantum algorithms that we couldn’t solve efficiently even with
    non-deterministic machines. But, contrary to what can be read sometimes in the
    media, it also would imply that not every problem in ![NP](img/file2.png "NP")
    could be solved efficiently with a quantum computer, even if it were fault-tolerant.
    In particular, it would imply that no ![NP](img/file2.png "NP")-complete problem
    could be solved efficiently with quantum algorithms (we have represented all these
    relationships in *Figure* * [*C.2*](#FigureC.2)).*
  prefs: []
  type: TYPE_NORMAL
- en: '*![Figure C.2: Possible relationships between P, NP, BQP, and NP-complete problems
    according to the available evidence and the most accepted conjectures. Be warned:
    some of these classes might end up being completely equal! ](img/file1659.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure C.2**: Possible relationships between ![P](img/file1.png "P"), ![NP](img/file2.png
    "NP"), ![BQP](img/file1650.png "BQP"), and ![NP](img/file2.png "NP")-complete
    problems according to the available evidence and the most accepted conjectures.
    Be warned: some of these classes might end up being completely equal!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Does this mean that quantum computers are not useful at all for optimization
    problems? Not necessarily. The methods that we describe in *Part* *[*II*](ch010.xhtml#x1-58000II)
    of this book may not be able to give the optimal solution to every optimization
    problem out there. But they provide approximation algorithms that might beat whatever
    is possible with just classical algorithms. For instance, the QAOA algorithm that
    we study in *Chapter* *[*5*](ch013.xhtml#x1-940005), *QAOA: Quantum Approximate
    Optimization* *Algorithm*, is considered a possible candidate for that kind of
    advantage (for some recent results in this direction, see the papers by Basso
    et al. [[12](ch030.xhtml#Xbasso2021quantum)] and by Farhi et al. [[38](ch030.xhtml#Xfarhi2022quantum)],
    but also check the response by Hastings [[51](ch030.xhtml#Xhastings2021classical)]).
    And even if that were not the case, methods such as quantum annealing (described
    in *Chapter* *[*4*](ch012.xhtml#x1-750004), *Adiabatic Quantum Computing and Quantum*
    *Annealing*) or QAOA may provide good heuristics that are useful in practice,
    in the same way that genetic algorithms, simulated annealing, or particle-swarm
    optimization are used to solve practical problems in many different fields.********'
  prefs: []
  type: TYPE_NORMAL
