- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Hyperparameter Optimization
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数优化
- en: How a Kaggle solution performs is not simply determined by the type of learning
    algorithm you choose. Aside from the data and the features that you use, it is
    also strongly determined by the algorithm’s **hyperparameters**, the parameters
    of the algorithm that have to be fixed *prior to* training, and cannot be learned
    during the training process. Choosing the right variables/data/features is most
    effective in tabular data competitions; however, hyperparameter optimization is
    effective in *all* competitions, of any kind. In fact, given fixed data and an
    algorithm, hyperparameter optimization is the only sure way to enhance the predictive
    performance of the algorithm and climb the leaderboard. It also helps in ensembling,
    because an ensemble of tuned models always performs better than an ensemble of
    untuned ones.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle解决方案的表现并不仅仅取决于你选择的机器学习算法类型。除了数据和使用的特征之外，它还强烈取决于算法的**超参数**，这些参数必须在训练之前固定，并且在训练过程中无法学习。在表格数据竞赛中选择正确的变量/数据/特征是最有效的；然而，超参数优化在**所有**类型的竞赛中都是有效的。实际上，给定固定的数据和算法，超参数优化是唯一确保提高算法预测性能并攀登排行榜的方法。它还有助于集成，因为经过调优的模型集成总是比未经调优的模型集成表现更好。
- en: You may hear that tuning hyperparameters manually is possible if you know and
    understand the effects of your choices on the algorithm. Many Kaggle Grandmasters
    and Masters have declared that they often rely on directly tuning their models
    in competitions. They operate selectively on the most important hyperparameters
    in a bisection operation style, exploring smaller and smaller intervals of a parameter’s
    values until they find the value that produces the best result. Then, they move
    on to another parameter. This works perfectly well if there is a single minimum
    for each parameter and if the parameters are independent from each other. In this
    case, the search is mostly driven by experience and knowledge of learning algorithms.
    In our experience, however, that is not the case with most tasks you will encounter
    on Kaggle. The sophistication of the problems and the algorithms used requires
    a systematic approach that only a search algorithm can provide. Hence, we decided
    to write this chapter.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会听说，如果你了解并理解你的选择对算法的影响，手动调整超参数是可能的。许多Kaggle大师和专家都宣称，他们在比赛中经常直接调整他们的模型。他们以二分法操作风格有选择性地操作最重要的超参数，探索参数值的越来越小的区间，直到他们找到产生最佳结果的价值。然后，他们转向另一个参数。如果每个参数只有一个最小值，并且参数之间相互独立，这种方法将完美无缺。在这种情况下，搜索主要是由经验和学习算法的知识驱动的。然而，根据我们的经验，在Kaggle上遇到的大多数任务并非如此。问题的复杂性和使用的算法需要一种只有搜索算法才能提供的系统方法。因此，我们决定编写这一章节。
- en: In this chapter, we will explore how to extend your cross-validation approach
    to find the best hyperparameters that can generalize to your test set. The idea
    is to deal with the pressure and scarcity of time and resources that you experience
    in competitions. For this reason, we will concentrate on **Bayesian optimization
    methods**, which are a proven way to optimize for complex models and data problems
    based on the resources you have available. We won’t limit ourselves to searching
    for the best values for pre-defined hyperparameters; we will also delve into the
    problem of neural network architecture.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何扩展你的交叉验证方法来找到最佳的超参数，这些参数可以推广到你的测试集。这个想法是处理你在比赛中经历的压力和资源稀缺。因此，我们将专注于**贝叶斯优化方法**，这是一种基于你可用资源的复杂模型和数据问题优化的有效方法。我们不会限制自己只搜索预定义超参数的最佳值；我们还将深入研究神经网络架构的问题。
- en: 'We will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Basic optimization techniques
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本优化技术
- en: Key parameters and how to use them
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键参数及其使用方法
- en: Bayesian optimization
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯优化
- en: Let’s start!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Basic optimization techniques
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本优化技术
- en: The core algorithms for hyperparameter optimization, found in the Scikit-learn
    package, are **grid search** and **random search**. Recently, the Scikit-learn
    contributors have also added the **halving algorithm** to improve the performances
    of both grid search and random search strategies.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn包中用于超参数优化的核心算法是**网格搜索**和**随机搜索**。最近，Scikit-learn的贡献者还添加了**减半算法**来提高网格搜索和随机搜索策略的性能。
- en: In this section, we will discuss all these basic techniques. By mastering them,
    not only will you have effective optimization tools for some specific problems
    (for instance, SVMs are usually optimized by grid search) but you will also be
    familiar with the basics of how hyperparameter optimization works.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论所有这些基本技术。通过掌握它们，你不仅将拥有针对某些特定问题的有效优化工具（例如，SVMs通常通过网格搜索进行优化），而且你还将熟悉超参数优化的工作原理的基础。
- en: 'To start with, it is crucial to figure out what the necessary ingredients are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，弄清楚必要的成分至关重要：
- en: A model whose hyperparameters have to be optimized
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要优化超参数的模型
- en: A search space containing the boundaries of the values to search between for
    each hyperparameter
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含每个超参数搜索之间值边界的搜索空间
- en: A cross-validation scheme
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证方案
- en: An evaluation metric and its score function
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个评估指标及其评分函数
- en: All these elements come together in the search method to determine the solution
    you are looking for. Let’s see how it works.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些元素都在搜索方法中汇集起来，以确定你正在寻找的解决方案。让我们看看它是如何工作的。
- en: Grid search
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网格搜索
- en: '**Grid search** is a method that searches through the hyperparameters exhaustively,
    and is not feasible in high-dimensional space. For every parameter, you pick a
    set of values you want to test. You then test all the possible combinations in
    this set. That is why it is exhaustive: you try everything. It is a very simple
    algorithm and it suffers from the curse of dimensionality, but, on the positive
    side, it’s *embarrassingly parallel* (see [https://www.cs.iusb.edu/~danav/teach/b424/b424_23_embpar.html](https://www.cs.iusb.edu/~danav/teach/b424/b424_23_embpar.html)
    for a definition of this computer science term). This means you can obtain an
    optimal tuning very quickly, if you have enough processors to run the search on.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**网格搜索**是一种遍历超参数的方法，在高维空间中不可行。对于每个参数，你选择一组你想要测试的值。然后，你测试这个集合中所有可能的组合。这就是为什么它是穷举的：你尝试了所有可能的情况。这是一个非常简单的算法，它受到维度灾难的影响，但，从积极的一面来看，它是**令人尴尬地并行**的（参见[https://www.cs.iusb.edu/~danav/teach/b424/b424_23_embpar.html](https://www.cs.iusb.edu/~danav/teach/b424/b424_23_embpar.html)以了解这个计算机科学术语的定义）。这意味着如果你有足够的处理器来运行搜索，你可以非常快速地获得最优调整。'
- en: 'As an example, let’s take a classification problem and **support-vector machine
    classification** (**SVC**). **Support-vector machines** (**SVMs**) for both classification
    and regression problems are probably the machine learning algorithm that you will
    use grid search for the most. Using the `make_classification` function from Scikit-learn,
    we can generate a classification dataset quickly:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个分类问题为例，让我们看看**支持向量机分类**（**SVC**）。对于分类和回归问题，支持向量机（**SVMs**）可能是你将最频繁使用网格搜索的机器学习算法。使用Scikit-learn的`make_classification`函数，我们可以快速生成一个分类数据集：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For our next step, we define a basic SVC algorithm and set the search space.
    Since the **kernel** **function** of the SVC (the internal function that transforms
    the input data in an SVM) determines the different hyperparameters to set, we
    provide a list containing two dictionaries of distinct search spaces for parameters
    to be used depending on the type of kernel chosen. We also set the evaluation
    metric (we use accuracy in this case, since the target is perfectly balanced):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '对于我们的下一步，我们定义了一个基本的SVC算法并设置了搜索空间。由于SVC的**核函数**（SVM中转换输入数据的内部函数）决定了要设置的不同的超参数，我们提供了一个包含两个不同搜索空间字典的列表，用于根据选择的核类型使用参数。我们还设置了评估指标（在这种情况下，我们使用准确率，因为目标是完美平衡的）： '
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In our example, a linear kernel doesn’t require the tuning of the `gamma` parameter,
    though it is very important for a radial basis function kernel. Therefore, we
    provide two dictionaries: the first containing the parameters for the linear kernel,
    the second containing parameters for a radial basis function kernel. Each dictionary
    only contains a reference to the kernel it is relevant to and only the range of
    parameters that are relevant for that kernel.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，线性核不需要调整`gamma`参数，尽管它对于径向基函数核非常重要。因此，我们提供了两个字典：第一个包含线性核的参数，第二个包含径向基函数核的参数。每个字典只包含与该核相关的引用以及对该核相关的参数范围。
- en: It is important to note that the evaluation metric can be different from the
    cost function optimized by the algorithm. In fact, as discussed in *Chapter 5*,
    *Competition Tasks and Metrics*, you may encounter scenarios in which the evaluation
    metric for the competition is different, but you cannot modify the cost function
    of your algorithm. Under these circumstances, tuning the hyperparameters according
    to your evaluation metric can still help in obtaining a well-performing model.
    Though built around the algorithm’s cost function, the optimal set of hyperparameters
    found will be the one returning the best evaluation metric under such constraints.
    It probably won’t be the theoretically best result that you could obtain for the
    problem, but it may often not be far from it.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，评估指标可能与算法优化的成本函数不同。事实上，如第5章“竞赛任务和指标”中所述，你可能会遇到竞赛的评估指标不同，但你无法修改算法的成本函数。在这种情况下，根据你的评估指标调整超参数仍然有助于获得性能良好的模型。虽然这个最优的超参数集是基于算法的成本函数构建的，但找到的将是在这种约束下返回最佳评估指标的参数集。这或许不是理论上你能为该问题获得的最佳结果，但它可能通常不会离最佳结果太远。
- en: 'All the ingredients (model, search space, evaluation metric, cross-validation
    scheme) are combined into the `GridSearchCV` instance, and then the model is fit
    to the data:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所有成分（模型、搜索空间、评估指标、交叉验证方案）都组合到`GridSearchCV`实例中，然后模型被拟合到数据上：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After a while, depending on the machine you are running the optimization on,
    you will obtain the best combination based on cross-validated results.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 过了一段时间，根据你在其上运行优化的机器，你将根据交叉验证的结果获得最佳组合。
- en: In conclusion, grid search is a very simple optimization algorithm that can
    leverage the availability of multi-core computers. It can work fine with machine
    learning algorithms that do not require many tunings (such as SVM and the ridge
    and lasso regressions) but, in all other cases, its applicability is quite narrow.
    First, it is limited to optimizing hyperparameters by discrete choice (you need
    a limited set of values to cycle through). In addition, you cannot expect it to
    work effectively on algorithms requiring *multiple* hyperparameters to be tuned.
    This is because of the exploding complexity of the search space, and because most
    of the computational inefficiency is due to the fact that the search is trying
    parameter values blindly, most of which do not work for the problem.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，网格搜索是一种非常简单的优化算法，可以利用多核计算机的可用性。它可以很好地与不需要很多调整的机器学习算法（如SVM和岭回归和Lasso回归）一起工作，但在所有其他情况下，其适用性相当有限。首先，它限于通过离散选择来优化超参数（你需要一个有限的值集来循环）。此外，你不能期望它在需要调整*多个*超参数的算法上有效工作。这是由于搜索空间的爆炸性复杂性，以及由于大多数计算效率低下是由于搜索在盲目地尝试参数值，其中大多数对问题不起作用。
- en: Random search
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机搜索
- en: '**Random search**, which simply samples the search space randomly, is feasible
    in high-dimensional spaces and is widely used in practice. The downside of random
    search, however, is that it doesn’t use information from prior experiments to
    select the next setting (a problem shared by grid search, we should note). In
    addition, to find the best solution as fast as possible, you cannot do anything
    except hope to be lucky you catch the right hyperparameters.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机搜索**，简单地随机采样搜索空间，在高维空间中是可行的，并且在实践中被广泛使用。然而，随机搜索的缺点是它没有使用先前实验的信息来选择下一个设置（我们应注意的是，这是与网格搜索共享的问题）。此外，为了尽可能快地找到最佳解决方案，你除了希望幸运地找到正确的超参数外，别无他法。'
- en: 'Random search works incredibly well and it is simple to understand. Despite
    the fact it relies on randomness, it isn’t just based on blind luck, though it
    may initially appear to be. In fact, it works like random sampling in statistics:
    the main point of the technique is that if you do enough random tests, you have
    a good possibility of finding the right parameters without wasting energy on testing
    slightly different combinations of similarly performing combinations.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索工作得非常好，而且很容易理解。尽管它依赖于随机性，但它并不仅仅基于盲目的运气，尽管一开始看起来可能如此。实际上，它就像统计学中的随机抽样：这种技术的主要观点是，如果你进行足够的随机测试，你就有很好的机会找到正确的参数，而无需在测试稍微不同的相似性能组合上浪费能量。
- en: 'Many AutoML systems rely on random search when there are too many parameters
    to set (see Golovin, D. et al. *Google Vizier: A Service for Black-Box Optimization*,
    2017). As a rule of thumb, consider looking at random search when the dimensionality
    of your hyperparameter optimization problem is sufficiently high (for example,
    over 16).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '当参数设置过多时，许多AutoML系统依赖于随机搜索（参见Golovin, D. 等人 *Google Vizier: A Service for Black-Box
    Optimization*，2017）。作为一个经验法则，当你的超参数优化问题的维度足够高时（例如，超过16），可以考虑使用随机搜索。'
- en: 'Below, we run the previous example using random search:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我们使用随机搜索来运行之前的示例：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that, now, we don’t care about running the search on separate spaces
    for the different kernels. Contrary to grid search, where each parameter, even
    the ineffective ones, is systematically tested, which requires computational time,
    here the efficiency of the search is not affected by the set of hyperparameters
    tested. The search doesn’t depend on irrelevant parameters, but is guided by chance;
    any trial is useful, even if you are testing only one valid parameter among many
    for the chosen kernel.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在我们不再关心在单独的空间中运行搜索以针对不同的核。与网格搜索不同，在网格搜索中，每个参数（即使是无效的参数）都会系统地测试，这需要计算时间，而在这里，搜索的效率不受测试的超参数集的影响。搜索不依赖于无关参数，而是由机会引导；任何试验都是有用的，即使你只测试了所选核中许多有效参数中的一个。
- en: Halving search
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减半搜索
- en: 'As we mentioned, both grid search and random search work in an uninformed way:
    if some tests find out that certain hyperparameters do not impact the result or
    that certain value intervals are ineffective, the information is not propagated
    to the following searches.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，网格搜索和随机搜索都以无信息的方式工作：如果某些测试发现某些超参数不会影响结果或某些值区间无效，则该信息不会传播到后续的搜索中。
- en: For this reason, Scikit-learn has recently introduced the `HalvingGridSearchCV`
    and `HalvingRandomSearchCV` estimators, which can be used to search a parameter
    space using **successive halving** applied to the grid search and random search
    tuning strategies.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Scikit-learn最近引入了`HalvingGridSearchCV`和`HalvingRandomSearchCV`估计器，可以使用这些估计器通过应用于网格搜索和随机搜索调整策略的**连续减半**来搜索参数空间。
- en: In halving, a large number of hyperparameter combinations are evaluated in an
    initial round of tests but using a small amount of computational resources. This
    is achieved by running the tests on a subsample of a few cases from your training
    data. A smaller training set needs fewer computations to be tested, so fewer resources
    (namely time) are used at the cost of more imprecise performance estimations.
    This initial round allows the selection of a subset of candidate hyperparameter
    values, which have performed better on the problem, to be used for the second
    round, when the training set size is increased.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在减半法中，在初始测试轮次中，会评估大量超参数组合，但使用的计算资源却很少。这是通过在训练数据的一小部分案例上运行测试来实现的。较小的训练集需要更少的计算来测试，因此，在牺牲更精确的性能估计的代价下，使用的资源（即时间）更少。这个初始轮次允许选择一组候选超参数值，这些值在问题上的表现更好，用于第二轮，当训练集大小增加时。
- en: The following rounds proceed in a similar way, allocating larger and larger
    subsets of the training set to be searched as the range of tested values is restricted
    (testing now requires more time to execute, but returns a more precise performance
    estimation), while the number of candidates continues to be halved.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 随后的轮次以类似的方式进行，随着测试值的范围受到限制（现在测试需要更多的时间来执行，但返回更精确的性能估计），将更大的训练集子集分配给搜索，而候选者的数量继续减半。
- en: 'Here is an example applied to the previous problem:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个应用于之前问题的示例：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this way, halving provides information to the successive optimization steps
    via the selection of the candidates. In the next sections, we will discuss even
    smarter ways to achieve a more precise and efficient search through the space
    of hyperparameters.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，减半通过选择候选者向后续优化步骤提供信息。在下一节中，我们将讨论通过超参数空间实现更精确和高效搜索的更智能的方法。
- en: '![](img/Kazuki_Onodera.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![Kazuki_Onodera](img/Kazuki_Onodera.png)'
- en: Kazuki Onodera
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Kazuki Onodera
- en: '[https://www.kaggle.com/onodera](https://www.kaggle.com/onodera)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/onodera](https://www.kaggle.com/onodera)'
- en: Let’s pause for an interview with another Kaggler. Kazuki Onodera is a Competitions
    Grandmaster and Discussions Master who has around 7 years of competition experience.
    He’s also a Senior Deep Learning Data Scientist at NVIDIA and a member of the
    NVIDIA KGMON (Kaggle Grandmasters of NVIDIA) team.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂停一下，进行另一位Kaggler的采访。小野田和树是一位拥有约7年比赛经验的竞赛大师和讨论大师。他也是NVIDIA的高级深度学习数据科学家，并是NVIDIA
    KGMON（Kaggle NVIDIA大师）团队的一员。
- en: What’s your favorite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你最喜欢的比赛类型是什么？为什么？在技术和解决方法方面，你在Kaggle上的专长是什么？
- en: Instacart Market Basket Analysis. *This competition proved quite challenging
    for the Kaggle community because of its use of anonymized data related to customer
    orders over time in order to predict which previously purchased products will
    be in a user’s next order. The reason why I like it is that I love feature engineering
    and I could come up with a bunch of good and interesting features everyone else
    couldn’t, which allowed me to get second place in the competition.*
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Instacart购物篮分析。*这项比赛对Kaggle社区来说相当具有挑战性，因为它使用了与客户订单相关的匿名数据，以预测用户下一次订单中将会购买哪些之前购买的产品。我喜欢它的原因是我热爱特征工程，我能想出一堆其他人无法想到的好奇特征，这让我在比赛中获得了第二名。*
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你是如何应对Kaggle比赛的？这种方法与你在日常工作中所做的方法有何不同？
- en: '*I try to imagine how a model works, and delve into false negatives and false
    positives. Same as in my daily work.*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*我试图想象一个模型是如何工作的，并深入研究假阴性和假阳性。这和我的日常工作一样。*'
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请告诉我们您参加过的特别具有挑战性的比赛，以及您使用了哪些见解来应对这项任务。
- en: Human Protein Atlas - Single Cell Classification. *This competition was a kind
    of instance segmentation competition, but no masks were provided. So, it turned
    into being a weakly supervised multi-label classification problem. I created a
    two-stage pipeline for removing label noise.*
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 人类蛋白质图谱 - 单细胞分类。*这项比赛是一种实例分割比赛，但没有提供掩码。因此，它变成了一个弱监督的多标签分类问题。我创建了一个两阶段管道来去除标签噪声。*
- en: Has Kaggle helped you in your career? If so, how?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle是否帮助了你的职业生涯？如果是的话，是如何帮助的？
- en: '*Yes. I’m now working in the NVIDIA KGMON (Kaggle Grandmasters of NVIDIA) team.
    Kaggle launches many different machine learning competitions, different with regards
    to data type, tabular, image, natural language, and signal, as well as with regards
    to sector and domain: industry, finance, astronomy, pathology, sports, retail,
    and so on. I bet nobody can access and have experience with all these kinds of
    data except Kagglers.*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*是的。我现在在NVIDIA KGMON（Kaggle NVIDIA大师）团队工作。Kaggle推出了许多不同的机器学习比赛，这些比赛在数据类型、表格、图像、自然语言和信号等方面各不相同，以及在与行业和领域相关方面：工业、金融、天文学、病理学、体育、零售等等。我相信除了Kagglers之外，没有人能够访问并拥有所有这些类型的数据经验。*'
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的经验中，不经验的Kaggler通常忽略了什么？你现在知道的事情，你希望在你最初开始时就知道？
- en: '*Target analysis. Also, seed averaging is quite overlooked: always simple but
    powerful.*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标分析。此外，种子平均法常常被忽视：总是简单但强大。*'
- en: What mistakes have you made in competitions in the past?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的比赛中，你犯过哪些错误？
- en: '*Target analysis. Top teams always analyze the target better than others, so
    if I couldn’t get a better place in a competition, I go and read about the top
    solutions, because they always describe to me the knowledge about the data that
    I missed during the competition.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标分析。顶尖团队总是比其他人更好地分析目标，所以如果我在比赛中没有获得更好的名次，我会去阅读关于顶尖解决方案的内容，因为他们总是向我描述我在比赛中遗漏的数据知识。*'
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis or machine learning?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否推荐使用特定的工具或库来进行数据分析或机器学习？
- en: '*Just Python and Jupyter* *Notebooks.*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*仅Python和Jupyter笔记本。*'
- en: What’s the most important thing someone should keep in mind or do when they’re
    entering a competition?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们参加比赛时，他们应该记住或做些什么最重要？
- en: '*If you can learn from a defeat, you haven’t really lost.*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你能从失败中学习，那么你实际上并没有真正失败。*'
- en: Do you use other competition platforms? How do they compare to Kaggle?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否使用其他竞赛平台？它们与Kaggle相比如何？
- en: '*KDD Cup and RecSys. Both meet the minimum requirements for being interesting
    and challenging.*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*KDD Cup和RecSys。两者都满足有趣和具有挑战性的最低要求*。'
- en: Key parameters and how to use them
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键参数及其使用方法
- en: The next problem is using the right set of hyperparameters for each kind of
    model you use. In particular, in order to be efficient in your optimization, you
    need to know the values of each hyperparameter that it actually makes sense to
    test for each distinct algorithm.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个问题是为你使用的每种模型选择正确的超参数集。特别是，为了在优化中提高效率，你需要知道每个算法中实际有意义的每个超参数的值。
- en: In this section, we will examine the most common models used in Kaggle competitions,
    especially the tabular ones, and discuss the hyperparameters you need to tune
    in order to obtain the best results. We will distinguish between classical machine
    learning models and gradient boosting models (which are much more demanding in
    terms of their space of parameters) for generic tabular data problems.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检查Kaggle竞赛中最常用的模型，特别是表格模型，并讨论你需要调整的超参数以获得最佳结果。我们将区分用于通用表格数据问题的经典机器学习模型和梯度提升模型（在参数空间方面要求更高）。
- en: As for neural networks, we can give you an idea about specific parameters to
    tune when we present the standard models (for instance, the TabNet neural model
    has some specific parameters to set so that it works properly). However, most
    of the optimization on deep neural networks in Kaggle competitions is not performed
    on standard models, but on *custom* ones. Consequently, apart from basic learning
    parameters such as the learning rate and the batch size, optimization in neural
    networks is based on the specific characteristics of the neural architecture of
    your model. You have to deal with the problem in an ad hoc way. Near the end of
    the chapter, we will discuss an example of **neural architecture search** (**NAS**)
    using KerasTuner ([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 至于神经网络，当我们介绍标准模型时（例如，TabNet神经网络模型有一些特定的参数需要设置，以便它能够正常工作），我们可以给你一些关于调整特定参数的想法。然而，Kaggle竞赛中大多数深度神经网络的优化并不是在标准模型上进行的，而是在*自定义*模型上进行的。因此，除了基本的学习参数（如学习率和批量大小）之外，神经网络的优化基于你模型神经架构的特定特征。你必须以专门的方式处理这个问题。在章节的末尾，我们将讨论使用KerasTuner（[https://keras.io/keras_tuner/](https://keras.io/keras_tuner/))进行**神经架构搜索**（**NAS**）的示例。
- en: Linear models
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性模型
- en: 'The linear models that need to be tuned are usually linear regressions or logistic
    regressions with regularization:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 需要调整的线性模型通常是带有正则化的线性回归或逻辑回归：
- en: '`C`: The range you should search is `np.logspace(-4, 4, 10)`; smaller values
    specify stronger regularization.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`C`：你应该搜索的范围是`np.logspace(-4, 4, 10)`；较小的值指定更强的正则化。'
- en: '`alpha`: You should search the range `np.logspace(-2, 2, 10)`; smaller values
    specify stronger regularization, larger values specify stronger regularization.
    Also take note that higher values take more time to process when using lasso.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`：你应该在范围`np.logspace(-2, 2, 10)`中搜索；较小的值指定更强的正则化，较大的值指定更强的正则化。此外，请注意，当使用lasso时，较高的值需要更多的时间来处理。'
- en: '`l1_ratio`: You should pick from the list `[.1, .5, .7, .9, .95, .99, 1]`;
    it applies only to elastic net.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`l1_ratio`：你应该从列表`[.1, .5, .7, .9, .95, .99, 1]`中选择；它仅适用于弹性网络。'
- en: In Scikit-learn, depending on the algorithm, you find either the hyperparameter
    `C` (logistic regression) or `alpha` (lasso, ridge, elastic net).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scikit-learn中，根据算法，你可以找到超参数`C`（逻辑回归）或`alpha`（lasso、ridge、弹性网络）。
- en: Support-vector machines
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持向量机
- en: '**SVMs** are a family of powerful and advanced supervised learning techniques
    for classification and regression that can automatically fit linear and non-linear
    models. Scikit-learn offers an implementation based on `LIBSVM`, a complete library
    of SVM classification and regression implementations, and `LIBLINEAR`, a scalable
    library for linear classification ideal for large datasets, especially sparse
    text-based ones. In their optimization, SVMs strive to separate target classes
    in classification problems using a decision boundary characterized by the largest
    possible margin between classes.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**SVMs**是一系列用于分类和回归的强大且先进的监督学习技术，可以自动拟合线性和非线性模型。Scikit-learn提供了一个基于`LIBSVM`的实现，这是一个完整的SVM分类和回归实现库，以及`LIBLINEAR`，一个适用于大型数据集（尤其是稀疏文本数据集）的线性分类可扩展库。在它们的优化中，SVMs通过使用具有最大可能类间边界的决策边界来尝试在分类问题中分离目标类别。'
- en: 'Though SVMs work fine with default parameters, they are often not optimal,
    and you need to test various value combinations using cross-validation to find
    the best ones. Listed according to their importance, you have to set the following
    parameters:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管SVM使用默认参数可以正常工作，但它们通常不是最优的，你需要通过交叉验证测试各种值组合来找到最佳组合。按照其重要性列出，你必须设置以下参数：
- en: '`C`: The penalty value. Decreasing it makes the margin between classes larger,
    thus ignoring more noise but also making the model more generalizable. A best
    value can normally be found in the range `np.logspace(-3, 3, 7)`.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`C`：惩罚值。减小它会使类之间的间隔更大，从而忽略更多的噪声，但也使模型更具泛化能力。最佳值通常可以在范围 `np.logspace(-3, 3,
    7)` 中找到。'
- en: '`kernel`: This parameter will determine how non-linearity will be implemented
    in an SVM and it can be set to `''linear''`, `''poly''`, `''``rbf''`, `''sigmoid''`,
    or a custom kernel. The most commonly used value is certainly `rbf`.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel`：此参数将确定在SVM中如何实现非线性。它可以设置为 `''linear''`、`''poly''`、`''rbf''`、`''sigmoid''`
    或自定义核。最常用的值无疑是 `rbf`。'
- en: '`degree`: Works with `kernel=''poly''`, signaling the dimensionality of the
    polynomial expansion. It is ignored by other kernels. Usually, setting its values
    to between `2` and `5` works the best.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`degree`：与 `kernel=''poly''` 一起使用，表示多项式展开的维度。其他核函数会忽略它。通常，将其值设置为 `2` 到 `5`
    之间效果最佳。'
- en: '`gamma`: A coefficient for `''rbf''`, `''``poly''`, and `''sigmoid''`. High
    values tend to fit data in a better way, but can lead to some overfitting. Intuitively,
    we can imagine `gamma` as the influence that a single example exercises over the
    model. Low values make the influence of each example reach further. Since many
    points have to be considered, the SVM curve will tend to take a shape less influenced
    by local points and the result will be a smoother decision contour curve. High
    values of `gamma`, instead, mean the curve takes into account how points are arranged
    locally more and, as a result, you get a more irregular and wiggly decision curve.
    The suggested grid search range for this hyperparameter is `np.logspace(-3, 3,
    7)`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gamma`：是 `''rbf''`、`''poly''` 和 `''sigmoid''` 的系数。高值往往能更好地拟合数据，但可能导致一些过拟合。直观上，我们可以将
    `gamma` 视为单个示例对模型的影响。低值使每个示例的影响范围更广。由于必须考虑许多点，SVM曲线将倾向于形成一个受局部点影响较小的形状，结果将得到一个更平滑的决定边界曲线。相反，高值的
    `gamma` 意味着曲线更多地考虑局部点的排列方式，因此你得到一个更不规则和波动的决定曲线。此超参数的建议网格搜索范围是 `np.logspace(-3,
    3, 7)`。'
- en: '`nu`: For regression and classification with nuSVR and nuSVC, this parameter
    sets a tolerance for the training points that are near to the margin and are not
    classified correctly. It helps in ignoring misclassified points just near or on
    the margin, hence it can render the classification decision curve smoother. It
    should be in the range `[0,1]` since it is a proportion relative to your training
    set. Ultimately, it acts like `C`, with high proportions enlarging the margin.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nu`：对于使用 nuSVR 和 nuSVC 的回归和分类，此参数设置接近边界的训练点的容差，这些点没有被正确分类。它有助于忽略刚好在边界附近或被错误分类的点，因此可以使分类决策曲线更平滑。它应该在
    `[0,1]` 范围内，因为它与你的训练集的比例相关。最终，它类似于 `C`，高比例会扩大间隔。'
- en: '`epsilon`: This parameter specifies how much error SVR will accept, by defining
    an `epsilon` large range where no penalty is associated with an incorrect prediction
    of the example during the training of the algorithm. The suggested search range
    is `np.logspace(-4, 2, 7)`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epsilon`：此参数指定SVR将接受多少误差，通过定义一个大的 `epsilon` 范围，在该范围内，算法训练期间对示例的错误预测不会关联任何惩罚。建议的搜索范围是
    `np.logspace(-4, 2, 7)`。'
- en: '`penalty`, `loss`, and `dual`: For LinearSVC, these parameters accept the `(''l1'',
    ''squared_hinge'', False)`, `(''l2'', ''hinge'', True)`, `(''l2'', ''squared_hinge'',
    True)`, and `(''l2'', ''squared_hinge'', False)` combinations. The `(''l2'', ''hinge'',
    True)` combination is analogous to the `SVC(kernel=''linear'')` learner.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`penalty`、`loss` 和 `dual`：对于 LinearSVC，这些参数接受 `(''l1'', ''squared_hinge'',
    False)`、`(''l2'', ''hinge'', True)`、`(''l2'', ''squared_hinge'', True)` 和 `(''l2'',
    ''squared_hinge'', False)` 组合。`(''l2'', ''hinge'', True)` 组合类似于 `SVC(kernel=''linear'')`
    学习器。'
- en: It may appear that an SVM has many hyperparameters to set, but many settings
    are specific only to implementations or to kernels, so you only have to select
    the relevant parameters.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 可能看起来支持向量机（SVM）有很多超参数需要设置，但实际上许多设置仅针对特定实现或核函数，因此你只需要选择相关的参数。
- en: Random forests and extremely randomized trees
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机森林和极端随机树
- en: '*Leo Breiman* and *Adele Cutler* originally devised the idea at the core of
    the random forest algorithm, and the name of the algorithm remains a trademark
    of theirs today (though the algorithm is open source). Random forests are implemented
    in Scikit-learn as `RandomForestClassifier` or `RandomForestRegressor`.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*Leo Breiman* 和 *Adele Cutler*最初设计了随机森林算法核心的想法，并且算法的名字至今仍然是他们的商标（尽管算法是开源的）。随机森林在Scikit-learn中实现为`RandomForestClassifier`或`RandomForestRegressor`。'
- en: A random forest works in a similar way to bagging, also devised by Leo Breiman,
    but operates only using binary split decision trees, which are left to grow to
    their extremes. Moreover, it samples the cases to be used in each of its models
    using **bootstrapping**. As the tree is grown, at each split of a branch, the
    set of variables considered for the split is drawn randomly, too.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林的工作方式与袋装法类似，也是由Leo Breiman提出的，但它仅使用二分分割决策树，这些树被允许生长到极端。此外，它使用**重抽样**来为每个模型中的案例进行采样。当树生长时，在每次分支的分割中，考虑用于分割的变量集合也是随机抽取的。
- en: 'This is the secret at the heart of the algorithm: it ensembles trees that,
    due to different samples and variables considered at the splits, are very different
    from each other. As they are different, they are also uncorrelated. This is beneficial
    because when the results are ensembled, much variance is ruled out, as the extreme
    values on both sides of a distribution tend to balance out. In other words, bagging
    algorithms guarantee a certain level of diversity in the predictions, allowing
    them to develop rules that a single learner (such as a decision tree) might not
    come across. All this diversity is useful because it helps in building a distribution
    whose average is a better predictor than any of the individual trees in the ensemble.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是算法核心的秘密：它组合了由于在不同分割点考虑了不同的样本和变量，彼此之间非常不同的树。由于它们不同，它们也是不相关的。这很有益处，因为当结果被组合时，可以排除很多方差，因为分布两端的极端值往往相互平衡。换句话说，袋装算法保证了预测的一定多样性，使得它们可以发展出单个学习器（如决策树）可能不会遇到的规则。所有这种多样性都是有用的，因为它有助于构建一个平均值为更好的预测器，比集成中的任何单个树都要好。
- en: '**Extra Trees** (also known as **extremely randomized trees**), represented
    in Scikit-learn by the `ExtraTreesClassifier`/`ExtraTreesRegressor` classes, are
    a more randomized kind of random forest that produces a lower variance in the
    estimates at the cost of greater bias of the estimators. However, when it comes
    to CPU efficiency, Extra Trees can deliver a considerable speed-up compared to
    random forests, so they can be ideal when you are working with large datasets
    in terms of both examples and features. The reason for the resulting higher bias
    but better speed is the way splits are built in an Extra Tree. Random forests,
    after drawing a random set of features to be considered for splitting a branch
    of a tree, carefully search among them for the best values to assign to each branch.
    By contrast, in Extra Trees, both the set of candidate features for the split
    and the actual split value are decided completely randomly. So, there’s no need
    for much computation, though the randomly chosen split may not be the most effective
    one (hence the bias).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**Extra Trees**（也称为**极端随机树**），在Scikit-learn中由`ExtraTreesClassifier`/`ExtraTreesRegressor`类表示，是一种更随机的随机森林，它以更大的偏差为代价，在估计中产生更低的方差。然而，当涉及到CPU效率时，Extra
    Trees与随机森林相比可以提供相当的速度提升，因此在处理大型数据集（包括示例和特征）时，它们可能是理想的。导致更高偏差但速度更好的原因是Extra Tree中构建分割的方式。随机森林在为树的分支分割抽取一个随机特征集后，会仔细搜索这些特征以找到分配给每个分支的最佳值。相比之下，在Extra
    Trees中，分割的候选特征集和实际的分割值都是完全随机决定的。因此，不需要太多的计算，尽管随机选择的分割可能不是最有效的（因此有偏差）。'
- en: 'For both algorithms, the key hyperparameters that should be set are as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两种算法，应该设置的关键超参数如下：
- en: '`max_features`: This is the number of sampled features that are present at
    every split, which can determine the performance of the algorithm. The lower the
    number, the speedier, but with higher bias.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_features`: 这是每个分割中存在的采样特征的数量，这可以确定算法的性能。数字越低，速度越快，但偏差越高。'
- en: '`min_samples_leaf`: This allows you to determine the depth of the trees. Large
    numbers diminish the variance and increase the bias.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_leaf`: 这允许你确定树的深度。大数值会减少方差并增加偏差。'
- en: '`bootstrap`: This is a Boolean that allows bootstrapping.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap`: 这是一个布尔值，允许进行重抽样。'
- en: '`n_estimators`: This is the number of trees. Remember that the more trees the
    better, though there is a threshold beyond which we get diminishing returns depending
    on the data problem. Also, this comes at a computational cost that you have to
    take into account based on the resources you have available.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extra Trees are a good alternative to random forests, especially when the data
    you have is particularly noisy. Since they trade some variance reduction for more
    bias given their random choice of splits, they tend to overfit less on important
    yet noisy features that would otherwise dominate the splits in a random forest.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Gradient tree boosting
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gradient tree boosting or **gradient boosting decision trees** (**GBDT**) is
    an improved version of boosting (boosting works by fitting a sequence of weak
    learners on reweighted versions of the data). Like AdaBoost, GBDT is based on
    a gradient descent function. The algorithm has proven to be one of the most proficient
    ones from the family of models that are based on ensembles, though it is characterized
    by an increased variance of estimates, more sensitivity to noise in data (both
    problems can be mitigated by using subsampling), and significant computational
    costs due to non-parallel operations.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Apart from deep learning, gradient boosting is the most developed machine learning
    algorithm. Since AdaBoost and the initial gradient boosting implementation, as
    developed by *Jerome Friedman*, various other implementations of the algorithms
    appeared, the most recent ones being XGBoost, LightGBM, and CatBoost.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: LightGBM
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The high-performance LightGBM algorithm ([https://github.com/Microsoft/LightGBM](https://github.com/Microsoft/LightGBM))
    is capable of being distributed on multiple computers and handling large amounts
    of data quickly. It was developed by a team at Microsoft as an open-source project
    on GitHub (there is also an academic paper: [https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html](https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html)).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: LightGBM is based on decision trees, like XGBoost, but it follows a different
    strategy. While XGBoost uses decision trees to split on a variable and explore
    different tree splits at that variable (the **level-wise** tree growth strategy),
    LightGBM concentrates on one split and goes on splitting from there in order to
    achieve a better fit (the **leaf-wise** tree growth strategy). This allows LightGBM
    to quickly reach a good fit of the data, and to generate alternative solutions
    compared to XGBoost (which is good, if you expect to blend the two solutions together
    in order to reduce the variance of the estimates). Algorithmically speaking, if
    we think of the structure of splits operated by a decision tree as a graph, XGBoost
    pursues a *breadth-first* search (BFS) and LightGBM a *depth-first* search (DFS).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'Tuning LightGBM may appear daunting; it has more than a hundred parameters
    to tune that you can explore at this page: [https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst)
    (also here: [https://lightgbm.readthedocs.io/en/latest/Parameters.html](https://lightgbm.readthedocs.io/en/latest/Parameters.html)).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'As a rule of thumb, you should focus on the following hyperparameters, which
    usually have the most impact on the results:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '`n_estimators`: An integer between 10 and 10,000 that sets the number of iterations.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate`: A real number between 0.01 and 1.0, usually sampled from a
    log-uniform distribution. It represents the step size of the gradient descent
    procedure that computes the weights for the summed ensemble of all the iterations
    of the algorithm up to this point.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_depth`: An integer between 1 and 16, representing the maximum number of
    splits on features. Setting it to a number below 0 allows the maximum possible
    number of splits, usually risking overfitting to data.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_leaves`: An integer between 2 and 2^`max_depth`, representing the number
    of final leaves each tree will have at most.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_data_in_leaf`: An integer between 0 and 300 that determines the minimum
    number of data points in one leaf.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_gain_to_split`: A float between 0 and 15; it sets the minimum gain of
    the algorithm for tree partitioning. By setting this parameter, you can avoid
    unnecessary tree splits and thus reduce overfitting (it corresponds to the `gamma`
    parameter in XGBoost).'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_bin`: An integer between 32 and 512 that sets the maximum number of bins
    that feature values will be bucketed into. Having this parameter larger than the
    default value of 255 implies more risk of producing overfitting results.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subsample`: A real number between 0.01, and 1.0, representing the portion
    of the sample to be used in training.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subsample_freq`: An integer between 0 and 10 specifying the frequency, in
    terms of iterations, at which the algorithm will subsample the examples.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that, if set to zero, the algorithm will ignore any value given to the
    `subsample` parameter. In addition, it is set to zero by default, therefore just
    setting the `subsample` parameter won’t work.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '`feature_fraction`: A real number between 0.1 and 1.0 allowing you to specify
    the portion of features to be subsampled. Subsampling the features is another
    way to allow more randomization to play a role in the training, fighting noise
    and multicollinearity present in the features.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subsample_for_bin`: An integer between 30 and the number of examples. This
    sets the number of examples that are sampled for the construction of histogram
    bins.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reg_lambda`: A real number between 0 and 100.0 that sets the L2 regularization.
    Since it is more sensitive to the scale than to the exact number of the parameter,
    it is usually sampled from a log-uniform distribution.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reg_alpha`: A real number between 0 and 100.0, usually sampled from a log-uniform
    distribution, which sets the L1 regularization.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale_pos_weight`: A real number between 1e-6 and 500, better sampled from
    the log-uniform distribution. The parameter weights the positive cases (thus effectively
    upsampling or downsampling) against the negative cases, which are kept to the
    value of 1.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Although the number of hyperparameters to tune when using LightGBM may appear
    daunting, in reality only a few of them matter a lot. Given a fixed number of
    iterations and learning rate, just a few are the most impactful (`feature_fraction`,
    `num_leaves`, `subsample`, `reg_lambda`, `reg_alpha`, `min_data_in_leaf`), as
    explained in this blog article by *Kohei Ozaki*, a Kaggle Grandmaster: [https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258).
    Kohei Ozaki leverages this fact in order to create a fast-tuning procedure for
    Optuna (you’ll find more on the Optuna optimizer at the end of this chapter).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: XGBoost ([https://github.com/dmlc/XGBoost](https://github.com/dmlc/XGBoost))
    stands for **eXtreme Gradient Boosting**. It is an open-source project that is
    not part of Scikit-learn, though it has recently been expanded by a Scikit-learn
    wrapper interface that makes it easier to incorporate XGBoost into a Scikit-learn-style
    data pipeline.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: The XGBoost algorithm gained momentum and popularity in 2015 data science competitions,
    such as those on Kaggle and the KDD Cup 2015\. As the creators (*Tianqui Chen*,
    *Tong He*, and *Carlos Guestrin*) report in papers they wrote on the algorithm,
    out of 29 challenges held on Kaggle during 2015, 17 winning solutions used XGBoost
    as a standalone solution or as part of an ensemble of multiple different models.
    Since then, the algorithm has always retained a strong appeal among the community
    of data scientists, though it struggled to keep pace with the innovation brought
    about by other GBM implementations such as LightGBM and CatBoost.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Aside from good performance both in terms of accuracy and computational efficiency,
    XGBoost is also a *scalable* solution, using at best multi-core processors as
    well as distributed machines.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'XGBoost represents a new generation of GBM algorithms thanks to important tweaks
    to the initial tree boost GBM algorithm:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Sparsity-awareness; it can leverage sparse matrices, saving both memory (no
    need for dense matrices) and computation time (zero values are handled in a special
    way).
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approximate tree learning (weighted quantile sketch), which produces similar
    results but in much less time compared to the classical complete explorations
    of possible branch cuts.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel computing on a single machine (using multi-threading during the search
    for the best split) and, similarly, distributed computations on multiple machines.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Out-of-core computations on a single machine, leveraging a data storage solution
    called **column block**. This arranges data on a disk by columns, thus saving
    time by pulling data from the disk in the way the optimization algorithm (which
    works on column vectors) expects it.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XGBoost can also deal with missing data in an effective way. Other tree ensembles
    based on standard decision trees require missing data first to be imputed using
    an off-scale value, such as a negative number, in order to develop an appropriate
    branching of the tree to deal with missing values.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'As for XGBoost’s parameters ([https://xgboost.readthedocs.io/en/latest/parameter.html](https://xgboost.readthedocs.io/en/latest/parameter.html)),
    we have decided to highlight a few key ones you will find across competitions
    and projects:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '`n_estimators`: Usually an integer ranging from 10 to 5,000.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate`: A real number ranging from 0.01 to 1.0, better sampled from
    the log-uniform distribution.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_child_weight`: Usually an integer between 1 and 10.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_depth`: Usually an integer between 1 and 50.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_delta_step`: Usually an integer sampled between 0 and 20, representing
    the maximum delta step we allow for each leaf output.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subsample`: A real number from 0.1 to 1.0 indicating the proportion of examples
    to be subsampled.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`colsample_bytree`: A real number from 0.1 to 1.0 indicating the subsample
    ratio of columns by tree.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`colsample_bylevel`: A real number from 0.1 to 1.0 indicating the subsample
    ratio by level in trees.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reg_lambda`: A real number between 1e-9 and 100.0, preferably sampled from
    the log-uniform distribution. This parameter controls the L2 regularization.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reg_alpha`: A real number between 1e-9 and 100.0, preferably sampled from
    the log-uniform distribution. This parameter controls the L1 regularization.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gamma`: Specifying the minimum loss reduction for tree partitioning, this
    parameter requires a real number between 1e-9 and 0.5, preferably sampled from
    the log-uniform distribution.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale_pos_weight`: A real number between 1e-6 and 500.0, preferably sampled
    from the log-uniform distribution, which represents a weight for the positive
    class.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like LightGBM, XGBoost also has many similar hyperparameters to tune, hence
    all of the considerations previously made for LightGBM are also valid for XGBoost.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: CatBoost
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In July 2017, Yandex, the Russian search engine, made another interesting GBM
    algorithm public, CatBoost ([https://catboost.ai/](https://catboost.ai/)), whose
    name comes from putting together the two words “Category” and “Boosting.” In fact,
    its strong point is its ability to handle categorical variables, which make up
    most of the information in most relational databases, by adopting a mixed strategy
    of one-hot encoding and target encoding. Target encoding is a way to express categorical
    levels by assigning them an appropriate numeric value for the problem at hand;
    more on this can be found in *Chapter 7*, *Modeling for Tabular Competitions*.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: The idea used by CatBoost to encode categorical variables is not new, but it
    is a kind of feature engineering that has been used before, mostly in data science
    competitions. Target encoding, also known as likelihood encoding, impact coding,
    or mean encoding, is simply a way to transform your labels into a number based
    on their association with the target variable. If you have a regression, you could
    transform labels based on the mean target value typical of that level; if it is
    a classification, it is simply the probability of classification of your target
    given that label (the probability of your target conditional on each category
    value). It may appear a simple and smart feature engineering trick but it has
    side effects, mostly in terms of overfitting, because you are taking information
    from the target into your predictors.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'CatBoost has quite a few parameters (see [https://catboost.ai/en/docs/references/training-parameters/](https://catboost.ai/en/docs/references/training-parameters/)).
    We have limited our discussion to the eight most important ones:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '`iterations`: Usually an integer between 10 and 1,000, but it can increase
    based on the problem.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`depth`: An integer between 1 and 8; usually higher values require longer fitting
    times and do not produce better results.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate`: A real value between 0.01 and 1.0, better sampled from the
    log-uniform distribution.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_strength`: A real number log-linearly sampled from the range 1e-9 to
    10.0, which specifies the randomness level for scoring splits.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bagging_temperature`: A real value between 0.0 and 1.0 that sets the Bayesian
    bootstrap.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`border_count`: An integer between 1 and 255 indicating the splits for numerical
    features.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`l2_leaf_reg`: An integer between 2 and 30; the value for L2 regularization.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale_pos_weight`: A real number between 0.01 and 10.0 representing the weight
    for the positive class.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even if CatBoost may appear to be just another GBM implementation, it has quite
    a few differences (highlighted also by the different parameters being used) that
    may provide great help in a competition, both as a single-model solution and as
    a model integrated into a larger ensemble.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: HistGradientBoosting
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recently, Scikit-learn has introduced a new version of gradient boosting inspired
    by LightGBM’s binned data and histograms (see this presentation at EuroPython
    by *Olivier Grisel*: [https://www.youtube.com/watch?v=urVUlKbQfQ4](https://www.youtube.com/watch?v=urVUlKbQfQ4)).
    Either as a classifier (`HistGradientBoostingClassifier`) or a regressor (`HistGradientBoostingRegressor`),
    it can be used for enriching ensembles with different models and it presents a
    much shorter and essential range of hyperparameters to be tuned:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '`learning_rate`: A real number between 0.01 and 1.0, usually sampled from a
    log-uniform distribution.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_iter`: An integer that can range from 10 to 10,000.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_leaf_nodes`: An integer from 2 to 500\. It interacts with `max_depth`;
    it is advisable to set only one of the two and leave the other set to `None`.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_depth`: An integer between 2 and 12.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_samples_leaf`: An integer between 2 and 300.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`l2_regularization`: A float between 0.0 and 100.0.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_bins`: An integer between 32 and 512.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even if Scikit-learn’s `HistGradientBoosting` is nothing too different from
    LightGBM or XGBoost, it does provide a different way to implement GBMs in a competition,
    and models built by `HistGradientBoosting` may provide a contribution when ensembling
    multiple predictions, such as in blending and stacking.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Having reached the end of this section, you should be more familiar with the
    most common machine learning algorithms (only deep learning solutions have not
    been discussed) and their most important hyperparameters to tune, which will help
    you in building an outstanding solution in a Kaggle competition. Knowing the basic
    optimization strategies, usable algorithms, and their key hyperparameters is just
    a starting point. In the next section, we will begin an in-depth discussion about
    how to tune them more optimally using Bayesian optimization.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Alberto_Danese.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
- en: Alberto Danese
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/albedan](https://www.kaggle.com/albedan)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Our second interview of the chapter is with Alberto Danese, Head of Data Science
    at Nexi, an Italian credit card and digital payments company. A Competitions Grandmaster
    who joined the platform in 2015, he obtained most of his gold medals as a solo
    competitor.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: What’s your favorite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '*I’ve always worked in the Financial Services industry, dealing mostly with
    structured data, and I do prefer competitions that belong to this category. I
    enjoy being able to have a practical grasp of what the data is all about and doing
    some smart feature engineering in order to squeeze every bit of information out
    of the data.*'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '*Technically speaking, I’ve got good experience with classical ML libraries
    and especially with Gradient Boosting Decision Trees: the most common libraries
    (XGBoost, LightGBM, CatBoost) are always my first choice.*'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '*I always spend a lot of time just exploring the data and trying to figure
    out what the problem that the sponsor is actually trying to solve with machine
    learning is. Different from what newbies usually think about Kaggle, I don’t spend
    so much time on all the “tweaking” of the specific ML algorithm – and apparently
    this approach has paid off!*'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '*In my daily job, understanding the data is also extremely important, but there
    are some additional phases that are completely missing in a Kaggle competition.
    I’ve got to:*'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '*Define a business problem to be solved with ML (together with colleagues in
    the business departments)*'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Find the data, sometimes also from external data providers*'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*And when the ML part is done, understand how to put it in production and manage
    the evolutions*'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '*I enjoyed the*TalkingData AdTracking Fraud Detection Challenge*, with which
    I became a Grandmaster. Besides being on an extremely interesting topic (fighting
    fraud from click-farms), it really pushed me to do efficient feature engineering,
    as the volumes were huge (more than 100M labeled rows) and cutting on computation
    times was key in order to test different approaches. It also forced me to understand
    how to exploit lag/lead features (and other window functions) in the best way,
    in order to create a sort of time series in an otherwise classical ML problem.*'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career? If so, how?
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '*Definitely! Being able to achieve great objective and verifiable results is
    no doubt something that makes a resume stand out. When I was hired by Cerved (a
    marketing intelligence service company) in 2016, the hiring manager was perfectly
    aware of what Kaggle was – and having some real-world projects to talk about during
    an interview is something extremely valuable. For sure Kaggle had an important
    role in the evolution of my career.*'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '*I think that everyone just starts coding, maybe forking a public kernel and
    just changing a few lines or parameters. This is perfectly fine at the beginning!
    But you do have to spend a decent amount of time not coding, but studying the
    data and understanding the problem.*'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: What mistakes have you made in competitions in the past?
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '*Not sure if it counts as a mistake, but I have often preferred to compete
    solo: on one hand it’s great as it forces you to handle every single aspect of
    a competition, and you’re able to manage your time as you wish. But I’ve really
    enjoyed collaborating with teammates on a couple of competitions as well: I probably
    should consider teaming up more often, as you can learn a lot from collaborating.*'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis or machine learning?
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '*Besides the* *usual ones, I’ve always been a great fan of* `data.table` *(starting
    from the R version): I think it’s not getting the credit it deserves! It’s really
    a great package when you want to deal with huge data on a local machine.*'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: What’s the most important thing someone should keep in mind or do when they’re
    entering a competition?
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '*Understand the problem and the data first: don’t start coding right away!*'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Leaving behind grid search (feasible only when the space of experiments is limited),
    the usual choice for the practitioner is to apply random search optimization or
    try a **Bayesian optimization** (**BO**) technique, which requires a more complex
    setup.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Originally introduced in the paper *Practical Bayesian optimization of machine
    learning algorithms* by Snoek, J., Larochelle, H., and Adams, R. P. ([http://export.arxiv.org/pdf/1206.2944](http://export.arxiv.org/pdf/1206.2944)),
    the key idea behind Bayesian optimization is that we optimize a **proxy function**
    (also called a **surrogate function**) rather than the true objective function
    (which grid search and random search both do). We do this if there are no gradients,
    if testing the true objective function is costly (if it is not, then we simply
    go for random search), and if the search space is noisy and complex enough.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian search balances *exploration* with *exploitation*. At the start, it
    explores randomly, thus training the surrogate function as it goes. Based on that
    surrogate function, the search exploits its initial approximate knowledge of how
    the predictor works in order to sample more useful examples and minimize the cost
    function. As the *Bayesian* part of the name suggests, we are using priors in
    order to make smarter decisions about sampling during optimization. This way,
    we reach a minimization more quickly by limiting the number of evaluations we
    need to make.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization uses an **acquisition function** to tell us how promising
    an observation will be. In fact, to manage the tradeoff between exploration and
    exploitation, the algorithm defines an acquisition function that provides a single
    measure of how useful it would be to try any given point.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Usually, Bayesian optimization is powered by Gaussian processes. Gaussian processes
    perform better when the search space has a smooth and predictable response. An
    alternative when the search space is more complex is using tree algorithms (for
    instance, random forests), or a completely different approach called **Tree Parzen
    Estimators** or **Tree-structured Parzen Estimators** (**TPEs**).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Instead of directly building a model that estimates the success of a set of
    parameters, thus acting like an oracle, TPEs estimate the parameters of a multivariate
    distribution that define the best-performing values of the parameters, based on
    successive approximations provided by the experimentations. In this way, TPEs
    derive the best set of parameters by sampling them from a probabilistic distribution,
    and not directly from a machine learning model like Gaussian processes does.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'We will discuss each of these approaches, first by examining Scikit-optimize
    and KerasTuner, both based on Gaussian processes (Scikit-optimize can also use
    random forests and KerasTuner can use multi-armed bandits), and then Optuna, which
    is principally based on TPE (though it also offers different strategies: [https://optuna.readthedocs.io/en/stable/reference/samplers.html](https://optuna.readthedocs.io/en/stable/reference/samplers.html)).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Though Bayesian optimization is considered the state of the art for hyperparameter
    tuning, always keep in mind that for more complex parameter spaces, using Bayesian
    optimization provides no advantage in terms of time and computation spent over
    a solution simply found by random search. For instance, in Google Cloud Machine
    Learning Engine services, the usage of Bayesian optimization is limited to problems
    involving at most sixteen parameters. For larger numbers of parameters, it resorts
    to random sampling.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Using Scikit-optimize
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Scikit-optimize (`skopt`) has been developed using the same API as Scikit-learn,
    as well as making extensive use of NumPy and SciPy functions. In addition, it
    was created by some of the contributors to the Scikit-learn project, such as *Gilles
    Louppe*.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Based on Gaussian process algorithms, the package is well maintained, though
    sometimes it has to catch up because of improvements on the Scikit-learn, NumPy,
    or SciPy sides. For instance, at the time of writing, in order to run it properly
    on Kaggle Notebooks you have to roll back to older versions of these packages,
    as explained in a GitHub issue ([https://github.com/scikit-optimize/scikit-optimize/issues/981](https://github.com/scikit-optimize/scikit-optimize/issues/981)).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: The package has an intuitive API and it is quite easy to hack it and use its
    functions in custom optimization strategies. Scikit-optimize is also renowned
    for its useful graphical representations. In fact, by visualizing the results
    of an optimization process (using Scikit-optimize’s `plot_objective` function),
    you can figure out whether you can re-define the search space for the problem
    and formulate an explanation of how optimization works for a problem.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'In our worked example, we will refer to the work that can be found in the following
    Kaggle Notebooks:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/lucamassaron/tutorial-bayesian-optimization-with-lightgbm](https://www.kaggle.com/lucamassaron/tutorial-bayesian-optimization-with-lightgbm)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/lucamassaron/scikit-optimize-for-lightgbm](https://www.kaggle.com/lucamassaron/scikit-optimize-for-lightgbm)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our purpose here is to show you how to quickly handle an optimization problem
    for a competition such as *30 Days of ML*, a recent competition that involved
    many Kagglers in learning new skills and applying them in a competition lasting
    30 days. The goal of this competition is to predict the value of an insurance
    claim, so it is a regression problem. You can find out more about this initiative
    and download the data necessary for the example we are going to present (materials
    are always available to the public), by visiting [https://www.kaggle.com/thirty-days-of-ml](https://www.kaggle.com/thirty-days-of-ml).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'If you cannot access the data because you have not taken part in the competition
    previously, you can use this Kaggle Dataset: [https://www.kaggle.com/lucamassaron/30-days-of-ml](https://www.kaggle.com/lucamassaron/30-days-of-ml).'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: The following code will present how to load the data for this problem and then
    set up a Bayesian optimization process that will improve the performance of a
    LightGBM model.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by loading the packages:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As a next step, we load the data. The data doesn’t need much processing, aside
    from turning some categorical features with alphabetical letters as levels into
    ordered numeric ones:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After making the data available, we define a reporting function that can be
    used by Scikit-optimize for various optimization tasks. The function takes the
    data and the optimizer as inputs. It can also handle **callback functions**, which
    are functions that perform actions such as reporting, early stopping based on
    having reached a certain threshold of time spent searching or performance not
    improving (for instance, not seeing improvements for a certain number of iterations),
    or saving the state of the processing after each optimization iteration:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We now have to prepare the scoring function (upon which the evaluation is based),
    the validation strategy (based on cross-validation), the model, and the search
    space. For the scoring function, which should be a root mean squared error metric,
    we refer to the practices in Scikit-learn where you always minimize a function
    (if you have to maximize, you minimize its negative).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'The `make_scorer` wrapper can easily replicate such practices:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Setting the search space requires the use of different functions from Scikit-optimize,
    such as `Real`, `Integer`, or `Choice`, each one sampling from a different kind
    of distribution that you define as a parameter (usually the uniform distribution,
    but the log-uniform is also used when you are more interested in the scale effect
    of a parameter than its exact value):'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once you have defined:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Your cross-validation strategy
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your evaluation metric
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your base model
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your hyperparameter search space
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All that is left is just to feed them into your optimization function, `BayesSearchCV`.
    Based on the CV scheme provided, this function will look for the minimum of your
    scoring function based on values within the search space. You can set a maximum
    number of iterations performed, the kind of surrogate function (Gaussian processes
    (`GP`) works on most occasions), and the random seed for reproducibility:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: At this point, you can start the search using the reporting function we defined
    previously. After a while, the function will return the best parameters for the
    problem.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the example, we set a limit on operations by specifying a maximum time allowed
    (6 hours) before stopping and reporting the best results. Since the Bayesian optimization
    approach blends together exploration and exploitation of different combinations
    of hyperparameters, stopping at any time will always return the best solution
    found so far (but not necessarily the best one possible). This is because the
    acquisition function will always give priority of exploration to the most promising
    parts of the search space, based on the estimated performances returned by the
    surrogate function and their uncertainty intervals.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Customizing a Bayesian optimization search
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `BayesSearchCV` function offered by Scikit-optimize is certainly convenient,
    because it wraps and arranges all the elements of a hyperparameter search by itself,
    but it also has limitations. For instance, you may find it useful in a competition
    to:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Have more control over each search iteration, for instance mixing random search
    and Bayesian search
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be able to apply early stopping on algorithms
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customize your validation strategy more
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stop experiments that do not work early (for instance, immediately evaluating
    the performance of the single cross-validation folds when it is available, instead
    of waiting to have all folds averaged at the end)
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create clusters of hyperparameter sets that perform in a similar way (for instance,
    in order to create multiple models differing only in the hyperparameters used,
    to be used for a blending ensemble)
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of these tasks would not be too complex if you could modify the `BayesSearchCV`
    internal procedure. Luckily, Scikit-optimize lets you do just this. In fact, behind
    `BayesSearchCV`, as well as behind other wrappers from the package, there are
    specific minimizing functions that you can use as standalone parts of your own
    search function:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '`gp_minimize`: Bayesian optimization using Gaussian processes'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`forest_minimize`: Bayesian optimization using random forests or extremely
    randomized trees'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gbrt_minimize`: Bayesian optimization using gradient boosting'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dummy_minimize`: Just random search'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following example, we are going to modify the previous search using our
    own custom search function. The new custom function will accept early stopping
    during training and it will prune experiments if one of the fold validation results
    is not a top-performing one.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: You can find the next example working in a Kaggle Notebook at [https://www.kaggle.com/lucamassaron/hacking-bayesian-optimization](https://www.kaggle.com/lucamassaron/hacking-bayesian-optimization).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: As in the previous example, we start by importing the necessary packages.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the same way as before, we upload the data from the *30 Days of ML* competition:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now we set all the necessary elements for a hyperparameter search, that is,
    the scoring function, the validation strategy, the search space, and the machine
    learning model to be optimized. The scoring function and the validation strategy
    will later become the core elements constituting the objective function, the function
    the Bayesian optimization will strive to minimize.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Notice this time that we have not included the number of estimators (the `n_estimators`
    parameter) in the search space. Instead, we set it when instantiating the model
    and we enter a high value, since we expect to stop the model early based on a
    validation set.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: As a next step, you now need to create the objective function. The objective
    function should just accept as input the parameters to be optimized and return
    the resulting score. However, the objective function also needs to accept the
    elements necessary for the search you have just prepared. Naturally, you could
    refer to them from inside the function. However, it is a good practice to take
    them into the function itself, in its internal memory space. This has its advantages;
    for instance, you will make the elements immutable and they will be carried along
    with the objective function (by pickling or if you distribute the search task
    on a multi-processor level). You can obtain this second result by creating a `make`
    function that takes in the elements, with the modified objective function being
    returned by the `make` function. With this simple structure, your objective function
    will incorporate all the elements such as the data and the model, and you will
    only need to pass in the parameters to be tested.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start coding the function. We will stop along the way to discuss some
    relevant aspects:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this first part of the function, you simply create an objective function,
    doing cross-validation and fitting the data using early stopping. We have used
    an aggressive early stopping strategy to save time, but you could raise the number
    of patient rounds if you believe that it might work better for your problem. Notice
    that the validation examples are sequentially taken out from the examples in the
    training folds (see how `train_index` and `val_index` are defined in the code),
    leaving the out-of-fold examples (`test_index` derived from the `kf` cross-validation
    splitting) untouched for the final validation. This is important if you do not
    want to incur adaptive overfitting on the data you use for early stopping.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next part, before moving on to the cross-validation loop and proceeding
    to the remaining cross-validation folds to be trained and tested, you analyze
    the result obtained by the fold on the out-of-fold set:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Notice that we are keeping a global dictionary, `history`, containing the results
    obtained from each fold up to now. We can compare the results across multiple
    experiments and cross-validations; the cross-validation is reproducible due to
    the random seed, so the results of the same fold are perfectly comparable. If
    the result of the present fold is sub-par compared to the previously obtained
    folds in other iterations (using the bottom quartile as a reference), the idea
    is to stop and return the average of the folds tested so far. The rationale for
    this is that if one fold doesn’t present acceptable results, then the whole cross-validation
    probably won’t either. You can therefore just quit and move on to another set
    of more promising parameters. It is a kind of early stopping on cross-validation
    that should speed up your search and allow you to cover more experiments in less
    time.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, using our `make_objective` function, we put together all the elements
    (model, data, search space, validation strategy, and scoring function) into a
    single function, the objective function. As a result, we now have a function that
    only takes in the parameters to be optimized and returns a score, based on which
    the minimization engine of the optimization will decide the next experiments:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Since we want to control each step of the optimization and save it for later
    use, we also prepare a callback function that will save a list of the experiments
    executed and their results, at every iteration of the minimization process. Simply
    by using these two pieces of information, the minimization engine can be halted
    at any time, and it can thereafter resume the optimization from the checkpoint:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'At this point, we are ready to start. Bayesian optimization needs some starting
    points to work properly. We create a number of experiments with random search
    (using the `dummy_minimize` function) and save their results:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can then retrieve the saved experiments and print the sequence of sets of
    hyperparameters that the Bayesian optimization has tested, along with their results.
    In fact, we can find the set of parameters and their results contained in the
    `x0` and `y0` lists:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'At this point, we can even resume the Bayesian optimization with some changes
    in the search space, the acquisition function, the number of calls, or the callbacks:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once we are satisfied that we don’t need to continue calling the optimization
    function, we can print both the best score obtained (based on our inputs and validation
    scheme) and the set of best hyperparameters:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Based on the best result, we can re-train our model for use in the competition.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Now we have the set of parameters and their results (the `x0` and `y0` lists),
    we could also explore the different results and cluster together the ones that
    are similar in output but different in the set of parameters used. This will help
    us to train a more diverse set of models with similar performances but different
    optimization strategies. This is the ideal situation for **blending**, which is
    the averaging of multiple models in order to lower the variance of the estimates
    and obtain a better public and private leaderboard score.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Refer to *Chapter 9*, *Ensembling with Blending and Stacking Solutions*, for
    a discussion on blending.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Extending Bayesian optimization to neural architecture search
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Moving on to deep learning, neural networks also seem to have quite a few hyperparameters
    to fix:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Batch size
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning rate
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The kind of optimizer and its internal parameters
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these parameters influence how the network learns and they can make a big
    impact; just a slight difference in batch size or learning rate can determine
    whether a network can reduce its error beyond a certain threshold or not.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: That being said, these learning parameters are not the only ones that you can
    optimize when working with **deep neural networks** (**DNNs**). How the network
    is organized in layers and the details of its architecture can make even more
    of a difference.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: In fact, technically speaking, an **architecture** implies the representational
    capacity of the deep neural network, which means that, depending on the layers
    you use, the network will either be able to read and process all the information
    available in the data, or it will not. While you had a large but limited set of
    choices with other machine learning algorithms, with DNNs your choices seem unlimited,
    because the only apparent limit is your knowledge and experience in handling parts
    of neural networks and putting them together.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'Common best practices for great deep learning practitioners when assembling
    well-performing DNNs depend mainly on:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Relying on pre-trained models (so you have to be very knowledgeable about the
    solutions available, such as those found on Hugging Face ([https://huggingface.co/models](https://huggingface.co/models))
    or on GitHub)
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading cutting-edge papers
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copying top Kaggle Notebooks from the same competition or previous ones
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trial and error
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ingenuity and luck
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a famous lesson given by *Professor Geoffrey Hinton*, he states that you
    can achieve similar and often better results using automated methods such as Bayesian
    optimization. Bayesian optimization will also avoid you getting stuck because
    you cannot figure out the best combinations of hyperparameters among the many
    possible ones.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: For a recording of Prof. Geoffrey Hinton’s lesson, see [https://www.youtube.com/watch?v=i0cKa0di_lo](https://www.youtube.com/watch?v=i0cKa0di_lo).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: For the slides, see [https://www.cs.toronto.edu/~hinton/coursera/lecture16/lec16.pdf](https://www.cs.toronto.edu/~hinton/coursera/lecture16/lec16.pdf).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned before, even in most sophisticated AutoML systems, when you
    have too many hyperparameters, relying on random optimization may produce better
    results or the same results in the same amount of time as Bayesian optimization.
    In addition, in this case, you also have to fight against an optimization landscape
    with sharp turns and surfaces; in DNN optimization, many of your parameters won’t
    be continuous but Boolean instead, and just one change could unexpectedly transform
    the performance of your network for the better or for the worse.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'Our experience tells us that random optimization may not be suitable for a
    Kaggle competition because:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: You have limited time and resources
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can leverage your previous optimization results in order to find better
    solutions
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bayesian optimization in this scenario is ideal: you can set it to work based
    on the time and computational resources that you have and do it by stages, refining
    your settings through multiple sessions. Moreover, it is unlikely that you will
    easily be able to leverage parallelism for tuning DNNs, since they use GPUs, unless
    you have multiple very powerful machines at hand. By working sequentially, Bayesian
    optimization just needs one good machine to perform the task. Finally, even if
    it is hard to find optimal architectures by a search, due to the optimization
    landscape you leverage information from previous experiments, especially at the
    beginning, totally avoiding combinations of parameters that won’t work. With random
    optimization, unless you change the search space along the way, all combinations
    are always liable to be tested.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: There are also drawbacks, however. Bayesian optimization models the hyperparameter
    space using a surrogate function built from previous trials, which is not an error-free
    process. It is not a remote possibility that the process ends up concentrating
    only on a part of the search space while ignoring other parts (which may instead
    contain the minimum you are looking for). The solution to this is to run a large
    number of experiments to be safe, or to alternate between random search and Bayesian
    optimization, challenging the Bayesian model with random trials that can force
    it to reshape its search model in a more optimal way.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: For our example, we use again the data from the *30 Days of ML* initiative by
    Kaggle, a regression task. Our example is based on TensorFlow, but with small
    modifications it can run on other deep learning frameworks such as PyTorch or
    MXNet.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, you can find the example on Kaggle here: [https://www.kaggle.com/lucamassaron/hacking-bayesian-optimization-for-dnns](https://www.kaggle.com/lucamassaron/hacking-bayesian-optimization-for-dnns).'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'After importing the TensorFlow package, we leverage its `Dataset` function
    to create an iterable capable of feeding our neural network with batches of data:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We have also made leaky ReLU activation a custom object for our model; it can
    be called by a string, and there is no need to directly use the function.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: 'We proceed to code a function that creates our deep neural network model based
    on a set of hyperparameters:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Internally, the code in the `create_model` function customizes the neural network
    architecture based on the inputs provided. For instance, as parameters for the
    function you can provide the dimensions of the embeddings for each categorical
    variable, or define the structure and number of dense layers present in the network.
    All these parameters are related to the parameter space you want to be explored
    by Bayesian optimization, hence every input parameter of the function creating
    the model should be related to a **sampling function** defined in the search space.
    All you have to do is to place the sampling functions in a list, in the same order
    as expected by the `create_model` function:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As previously illustrated, you now combine all the elements related to the
    search into an objective function to be created by a function incorporating your
    basic search elements, such as the data and the cross-validation strategy:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The next step is to provide a sequence of random search runs (as a way to start
    building some feedback from the search space) and gather the results as a starting
    point. Then, we can feed them into a Bayesian optimization and proceed by using
    `forest_minimize` as a surrogate function:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Notice that after the first ten rounds of random search, we proceed with our
    search using a random forest algorithm as a surrogate function. That will ensure
    better and faster results than using a Gaussian process.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: As before, in this process we have to strive to make the optimization feasible
    within the time and resources we have (for instance, by setting a low number of
    `n_calls`). Hence, we can proceed with batches of search iterations by saving
    the state of the optimization, checking the results obtained, and deciding thereafter
    to proceed or conclude the optimization process and not invest more time and energy
    into looking for a better solution.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Creating lighter and faster models with KerasTuner
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the previous section has puzzled you because of its complexity, KerasTuner
    can offer you a fast solution for setting up an optimization without much hassle.
    Though it uses Bayesian optimization and Gaussian processes by default, the new
    idea behind KerasTuner is **hyperband optimization**. Hyperband optimization uses
    the bandit approach to figure out the best parameters (see [http://web.eecs.umich.edu/~mosharaf/Readings/HyperBand.pdf](http://web.eecs.umich.edu/~mosharaf/Readings/HyperBand.pdf)).
    This works quite well with neural networks, whose optimization landscape is quite
    irregular and discontinuous, and thus not always suitable for Gaussian processes.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that you cannot avoid building the function that builds a custom
    network using input hyperparameters; KerasTuner just makes it much easier to handle.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start from the beginning. KerasTuner ([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/))
    was announced as a “flexible and efficient hyperparameter tuning for Keras models”
    by *François Chollet*, the creator of Keras.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'The recipe proposed by Chollet for running KerasTuner is made up of simple
    steps, starting from your existing Keras model:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Wrap your model in a function with `hp` as the first parameter.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define hyperparameters at the beginning of the function.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace DNN static values with hyperparameters.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the code that models a complex neural network from the given hyperparameters.
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If necessary, dynamically define hyperparameters as you build the network.
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’ll now explore how all these steps can work for you in a Kaggle competition
    by using an example. At the moment, KerasTuner is part of the stack offered by
    any Kaggle Notebook, hence you don’t need to install it. In addition, the TensorFlow
    add-ons are part of the Notebook’s pre-installed packages.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are not using a Kaggle Notebook and you need to try KerasTuner, you
    can easily install both using the following commands:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can find this example already set up on a Kaggle Notebook here: [https://www.kaggle.com/lucamassaron/kerastuner-for-imdb/](https://www.kaggle.com/lucamassaron/kerastuner-for-imdb/).'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first step is to import the necessary packages (creating shortcuts for
    some commands, such as for `pad_sequences`) and to upload the data we will be
    using directly from Keras:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This time, we are using the IMDb dataset, which is available in the Keras package
    ([https://keras.io/api/datasets/imdb/](https://keras.io/api/datasets/imdb/)).
    The dataset has some interesting characteristics:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: It is a dataset of 25,000 movie reviews from IMDb
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reviews are labeled by sentiment (positive/negative)
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The target classes are balanced (hence accuracy works as a scoring measure)
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each review is encoded as a list of word indexes (integers)
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For convenience, words are indexed by overall frequency
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, it has been successfully used in a popular Kaggle competition on
    word embeddings ([https://www.kaggle.com/c/word2vec-nlp-tutorial/overview](https://www.kaggle.com/c/word2vec-nlp-tutorial/overview)).
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: 'This example involves natural language processing. This type of problem is
    often solved by using **recurrent neural networks** (**RNNs**) based on LSTM or
    GRU layers. BERT, RoBERTa, and the other transformer-based models often achieve
    better results – being pre-trained models relying on large language corpora –
    but this is not necessarily true in all problems, and RNNs can prove a strong
    baseline to beat or a good addition to an ensemble of neural models. In our example,
    all words are already numerically indexed. We just add to the existing indices
    the numeric codes that denote padding (so we can easily normalize all the text
    to the phrase length), the start of the sentence, an unknown word, and an unused
    word:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The next step involves creating a custom layer for **attention**. Attention
    is the foundation of transformer models and it is one of the most innovative ideas
    in neural NLP of recent times.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'For all the details of how these kinds of layers work, see the seminal paper
    on attention: Vaswani, A. et al. *Attention is all you need.* Advances in neural
    information processing systems. 2017 ([https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)).'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of attention can be easily conveyed. LSTM and GRU layers output processed
    sequences, but not all the elements in these output sequences are necessarily
    important for your predictions. Instead of averaging all the output sequences
    using a pool layer across the stratified sequences, you can actually take a *weighted
    average* of them (and during the training phase learn the correct weights to be
    used). This weighting process (**attention**) definitely improves the results
    you are going to pass on further. Of course, you can make this approach even more
    sophisticated using multiple attention layers (we call this **multi-head attention**),
    but in our example a single layer will suffice because we want to demonstrate
    that using attention is more effective in this problem than simply averaging or
    just concatenating all the results together:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As a further variation in our experiments on the architecture of the DNNs for
    this problem, we also want to test the effectiveness of using different kinds
    of optimizers such as **Rectified Adam** (an adaptive learning Adam optimizer;
    read this post to learn more: [https://lessw.medium.com/new-state-of-the-art-ai-optimizer-rectified-adam-radam-5d854730807b](https://lessw.medium.com/new-state-of-the-art-ai-optimizer-rectified-adam-radam-5d854730807b))
    or **Stochastic Weighted Averaging** (**SWA**). SWA is a way to average the weights
    traversed during the optimization based on a modified learning rate schedule:
    if your model tends to overfit or overshoot, SWA helps in getting near to an optimal
    solution and it is proven to work especially in NLP problems.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Having defined two key functions, we now face the most important function to
    code: the one that will provide different neural architectures given the parameters.
    We don’t encode all the various parameters we want to connect to the different
    architectural choices; we only provide the `hp` parameter, which should contain
    all the possible parameters we want to use, and that will be run by KerasTuner.
    Aside from `hp` in the function input, we fix the size of the vocabulary and the
    length to be padded (adding dummy values if the effective length is shorter or
    cutting the phrase if the length is longer):'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the first part of the function, we simply recover all the settings from the
    `hp` parameter. We also make explicit the range of the search space for each of
    them. Contrary to the solutions we’ve seen so far, this part of the work is done
    *inside* the model function, not outside.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: The function continues by defining the different layers using the parameters
    extracted from `hp`. In some cases, a parameter will switch on or off a part of
    the network performing certain data processing. For instance, in the code we inserted
    a branch of the graph (`conv_filters` and `conv_kernel`) that processes the sequence
    of words using convolutional layers, which, in their 1D form, can also prove useful
    for NLP problems, since they can catch local sequences of words and meanings that
    LSTMs may find harder to grasp.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can define the actual model:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We start by defining the input layer and transform it with a subsequent embedding
    layer that will encode the sequence values into dense layers. Some dropout regularization
    is applied to the process using `SpatialDropout1D`, a function that will randomly
    drop entire columns of the output matrix (standard dropout drops random single
    elements in the matrix instead). After these initial phases, we split the network
    into one pipeline based on convolutions (`Conv1D`) and another based on recurrent
    layers (GRU or LSTM). It is after the recurrent layers that we apply the attention
    layer. Finally, the outputs of these two pipelines are concatenated and, after
    a few more dense layers, they arrive at the final output node, a sigmoid since
    we have to represent a probability bounded in the range 0 to 1.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: 'After the model definition, we set the learning parameters and compile the
    model before returning it:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Note that we have built the model using the functional API of Keras, not the
    sequential one. We would advise you to avoid the sequential one, in fact; it is
    easier to set up, but severely restricts your potential architectures.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: At this point, most of the work is already done. As a suggestion, having worked
    out many optimizations using KerasTuner ourselves, we prefer to first build a
    *non-parametric* model, using all the possible architectural features that we
    want to test, with the mutually exclusive parts of the network set to the most
    complex solutions. After we have set up the generative function and our model
    seems to be working properly, we can, for instance, represent its graph and have
    it successfully fit some examples as a test. After that, we start inserting the
    parametric variables into the architecture and setting up the `hp` parameter definitions.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: In our experience, starting with a parametric function immediately will take
    more time and debugging effort. The idea behind KerasTuner is to let you think
    of your DNNs as a set of modular circuits and to help you optimize how the data
    flows inside them.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we import KerasTuner. First, we set the tuner itself, and then we start
    the search:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As a tuner, we opt for the Bayesian optimization one, but you can also try the
    Hyperband tuner ([https://keras.io/api/keras_tuner/tuners/hyperband/](https://keras.io/api/keras_tuner/tuners/hyperband/))
    and check if it works better for your problem. We provide our model function to
    the `hypermodel` parameter. Then, we set the objective using a string or a function,
    the maximum number of trials (KerasTuner will stop earlier if there is nothing
    more to be done), and the initial number of random trials – the more the better
    – in order to inform the Bayesian process. Early stopping is a standard and well-performing
    practice in modeling DNNs that you absolutely cannot ignore. Finally, but importantly,
    we set the directory where we want to save our search and a seed number for reproducibility
    of the optimization steps.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: 'The search phase is run like a standard fit of a Keras model and – this is
    quite important – it accepts callbacks. Therefore, you can easily add early stopping
    to your model. In this case, the given epoch number should therefore be considered
    the maximum number of epochs. You may also want to optimize the batch size, which
    we haven’t done in our example. This still requires some extra work, but you can
    get an idea of how to achieve it by reading this GitHub closed issue: [https://github.com/keras-team/keras-tuner/issues/122](https://github.com/keras-team/keras-tuner/issues/122).'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: 'After the optimization is complete, you can extract the best parameters and
    save the best model without any need to retrain it:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In this example, KerasTuner finds a solution that uses:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: A larger embedding layer
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just plain GRU and LSTM layers (no bi-directional layers)
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stacking of multiple one-dimensional convolution layers (Conv1D)
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More and larger dense layers
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interestingly, the solution is not only more effective, but also lighter and
    faster than our previous attempts based on intuition and experience with the problem.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: Chollet himself suggests using KerasTuner not just to make your DNNs perform
    better but also to shrink them to a more manageable size, something that may make
    the difference in Code competitions. This allows you to put together more models
    that work together within the limited inference time provided by the sponsors
    of the competition.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: 'If you would like to examine more examples of using KerasTuner, François Chollet
    also created a series of Notebooks for Kaggle competitions in order to showcase
    the workings and functionalities of his optimizer:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/fchollet/keras-kerastuner-best-practices](https://www.kaggle.com/fchollet/keras-kerastuner-best-practices)
    for the *Digit Recognizer* datasets'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/fchollet/titanic-keras-kerastuner-best-practices](https://www.kaggle.com/fchollet/titanic-keras-kerastuner-best-practices)
    for the *Titanic* dataset'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/fchollet/moa-keras-kerastuner-best-practices](https://www.kaggle.com/fchollet/moa-keras-kerastuner-best-practices)
    for the *Mechanisms of Action (MoA) Prediction* competition'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TPE approach in Optuna
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We complete our overview of Bayesian optimization with another interesting tool
    and approach to it. As we have discussed, Scikit-optimize uses Gaussian processes
    (as well as tree algorithms) and it directly models the surrogate function and
    the acquisition function.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: As a reminder of these topics, the **surrogate function** helps the optimization
    process to model the potential performance result when you try a set of hyperparameters.
    The surrogate function is built using the previous experiments and their results;
    it is just a predictive model applied in order to forecast the behavior of a specific
    machine learning algorithm on a specific problem. For each parameter input provided
    to the surrogate function, you get an expected performance output. That’s intuitive
    and also quite hackable, as we have seen.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: The **acquisition function** instead points out what set of hyperparameters
    could be tested in order to improve the ability of the surrogate function to predict
    the performances of the machine learning algorithm. It is also useful for really
    testing if we can reach a top-performing result based on the surrogate function’s
    forecasts. These two objectives represent the *explore* part (where you run experiments)
    and the *exploit* part (where you test the performance) of a Bayesian optimization
    process.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: Instead, optimizers based on **TPE** tackle the problem by estimating the likelihood
    of success of the values of parameters. In other words, they model the success
    distribution of the parameters themselves using successive refinements, assigning
    a higher probability to more successful value combinations.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: In this approach, the set of hyperparameters is divided into good and bad ones
    by these distributions, which take the role of the surrogate and acquisition functions
    in Bayesian optimization, since the distributions tell you where to sample to
    get better performances or explore where there is uncertainty.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: To explore the technical details of TPE, we suggest reading Bergstra, J. et
    al. *Algorithms for hyper-parameter optimization*. Advances in neural information
    processing systems 24, 2011 ([https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf](https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf)).
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, TPE can model the search space and simultaneously suggest what the
    algorithm can try next, by sampling from the adjusted probability distribution
    of parameters.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: For a long time, **Hyperopt** was the option for those preferring to use TPE
    instead of Bayesian optimization based on Gaussian processes. In October 2018,
    however, Optuna appeared in the open source and it has become the preferred choice
    for Kagglers due to its versatility (it also works out of the box for neural networks
    and even for ensembling), speed, and efficiency in finding better solutions compared
    to previous optimizers.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will demonstrate just how easy is to set up a search, which
    is called a *study* under Optuna terminology. All you need to do is to write an
    objective function that takes as input the parameters to be tested by Optuna and
    then returns an evaluation. Validation and other algorithmic aspects can be handled
    in a straightforward manner inside the objective function, also using references
    to variables external to the function itself (both global variables or local ones).
    Optuna also allows **pruning**, that is, signaling that a particular experiment
    is not going well and that Optuna can stop and forget about it. Optuna provides
    a list of functions that activate this callback (see [https://optuna.readthedocs.io/en/stable/reference/integration.html](https://optuna.readthedocs.io/en/stable/reference/integration.html));
    the algorithm will run everything efficiently for you after that, which will significantly
    reduce the time needed for optimization.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: All of this is in our next example. We return to optimizing for the *30 Days
    of ML* competition. This time, we are trying to figure out what parameters make
    XGBoost work for this competition.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: You can find the Notebook for this example at [https://www.kaggle.com/lucamassaron/optuna-bayesian-optimization](https://www.kaggle.com/lucamassaron/optuna-bayesian-optimization).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, we upload the libraries and the data, as before:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: When using Optuna, you just have to define an objective function containing
    the model, the cross-validation logic, the evaluation measure, and the search
    space.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: 'Naturally, for data you can refer to objects outside the function itself, rendering
    the construction of the function much easier. As in KerasTuner, here you need
    a special input parameter based on a class from Optuna:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In this example, for performance reasons, we won’t cross-validate but use one
    fixed dataset for training, one for validation (early stopping), and one for testing
    purposes. We are using GPU in this example, and we are also subsetting the available
    data in order to fit the execution of 60 trials into a reasonable length of time.
    If you don’t want to use GPU, just remove the `tree_method` and `predictor` parameters
    from the `XGBRegressor` instantiation. Also notice how we set a callback in the
    `fit` method in order to provide Optuna feedback on how the model is performing,
    so the optimizer can stop an underperforming experiment early to give space to
    other attempts.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Another notable aspect is that you can decide to optimize either for minimization
    or maximization, depending on your problem (Scikit-optimize works only on minimization
    problems).
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: To complete the run, you just have to print or export the best test performance
    and the best parameters found by the optimization.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Ruchi_Bhatia.png)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
- en: Ruchi Bhatia
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/ruchi798](https://www.kaggle.com/ruchi798)'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: As a conclusion to this dense chapter, let’s look at one last interview. This
    time, we’re speaking to Ruchi Bhatia, a Grandmaster in Datasets and Notebooks.
    Ruchi is currently a graduate student at Carnegie Mellon University, a Data Scientist
    at OpenMined, and a Data Science Global Ambassador at Z by HP.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: What’s your favorite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '*My favorite kinds of competitions are NLP and Analytics competitions. Being
    multilingual has played a significant role in my main focus and interest: Natural
    Language Processing.*'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: '*As for Analytics competitions, I enjoy making sense out of complex data and
    backing my answers to questions with the support of data! Every competition on
    Kaggle is novel and requires different techniques. I mainly follow a data-driven
    approach to algorithm selection and have no set favorites.*'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '*When a new competition is announced, my priority is to understand the problem
    statement in depth. Sometimes problem statements can be out of our comfort zone
    or domain, so it’s* *crucial to ensure we grasp them well before moving on to
    exploratory data analysis. While performing EDA, my goal is to understand data
    distribution and focus on getting to know the data at hand. During this, we are
    likely to come across patterns, and we should make an effort to understand those
    and form a hypothesis for outliers and exceptional cases.*'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '*After this, I spend time understanding the competition metrics. The creation
    of a leak-free cross-validation strategy is my next step. After this, I choose
    a baseline model and make my first submission. If the correlation between the
    local validation and the competition leaderboard is not satisfying, I iterate
    for as long as needed to understand possible discrepancies and account for them.*'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: '*Then I move on to improve my modeling approach with time. Apart from this,
    tweaking parameters and trying new experiments help to gain an understanding of
    what works best with the data at hand (ensuring that I’m preventing overfitting
    during the whole process). Finally, in the last few weeks of the competition,
    I perform model ensembling and check the robustness of my solution.*'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '*As for my projects outside of Kaggle, most of my time is spent in data gathering,
    cleaning, and getting relevant value out of the data.*'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career? If so, how?
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '*Kaggle has tremendously helped me accelerate my career. Not only did it help
    me find my passion for data science, but it also motivated me to contribute effectively
    and stay consistent. It’s the perfect place to try hands-on experiments with an
    enormous amount of data at our fingertips and showcase our work on a global scale.
    In addition, our work is easily accessible, so we can reach a broader audience
    as well.*'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '*I have used a majority of my Kaggle work on my portfolio to indicate the diversity
    of work I have done in my journey thus far. Kaggle competitions aim to solve novel
    and real-world problems, and I feel employers look for our ability and aptitude
    to solve such problems. I’ve also curated a broad range of datasets that helped
    me highlight my acumen in working with raw data. These projects helped me secure
    multiple job opportunities.*'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '*In my* *experience, I’ve noticed that many Kagglers get disheartened when
    their ranking in competitions isn’t what they expected it to be. After weeks and
    months of hard work, I can see why they might give up early, but winning Kaggle
    competitions is no easy feat. There are several people of different educational
    backgrounds and work experience competing, and having the courage to try is all
    that’s important. We should focus on our individualistic growth and see how far
    we’ve come in our journey.*'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis or machine learning?
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '*Comprehensive exploratory data analysis combined with relevant visualizations
    help us spot data trends and context that can improve our methodology. Since I
    believe in the power of visualizations, my favorite data science libraries would
    be Seaborn and TensorBoard. Seaborn for EDA and TensorBoard for visualizations
    needed during the machine learning workflow. I occasionally use Tableau too.*'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: What’s the most important thing someone should keep in mind or do when they’re
    entering a competition?
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: '*When people enter a competition, I believe they should prepare themselves
    for deep diving into the problem statement and researching. Competitions on Kaggle
    are particularly challenging and help solve real-life problems in many cases.
    People should have a positive mindset and not get disheartened. Kaggle competitions
    provide the perfect opportunity to learn and grow!*'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-423
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed hyperparameter optimization at length as a way
    to increase your model’s performance and score higher on the leaderboard. We started
    by explaining the code functionalities of Scikit-learn, such as grid search and
    random search, as well as the newer halving algorithms.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: Then, we progressed to Bayesian optimization and explored Scikit-optimize, KerasTuner,
    and finally Optuna. We spent more time discussing the direct modeling of the surrogate
    function by Gaussian processes and how to hack it, because it can allow you greater
    intuition and a more ad hoc solution. We recognize that, at the moment, Optuna
    has become a gold standard among Kagglers, for tabular competitions as well as
    for deep neural network ones, because of its speedier convergence to optimal parameters
    in the time allowed in a Kaggle Notebook.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: However, if you want to stand out among the competition, you should strive to
    test solutions from other optimizers as well.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will move on to discuss another way to improve your
    performance in Kaggle competitions: ensembling models. By discovering the workings
    of averaging, blending, and stacking, we will illustrate how you can boost your
    results beyond what you can obtain by tuning hyperparameters alone.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code40480600921811704671.png)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
