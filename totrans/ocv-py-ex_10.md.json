["```py\nimport cv2\nimport numpy as np\n\nclass DenseDetector(object):\n    def __init__(self, step_size=20, feature_scale=40, img_bound=20):\n        # Create a dense feature detector\n        self.detector = cv2.FeatureDetector_create(\"Dense\")\n\n        # Initialize it with all the required parameters\n        self.detector.setInt(\"initXyStep\", step_size)\n        self.detector.setInt(\"initFeatureScale\", feature_scale)\n        self.detector.setInt(\"initImgBound\", img_bound)\n\n    def detect(self, img):\n        # Run feature detector on the input image\n        return self.detector.detect(img)\n\nif __name__=='__main__':\n    input_image = cv2.imread(sys.argv[1])\n    input_image_sift = np.copy(input_image)\n\n    # Convert to grayscale\n    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n\n    keypoints = DenseDetector(20,20,5).detect(input_image)\n\n    # Draw keypoints on top of the input image\n    input_image = cv2.drawKeypoints(input_image, keypoints,\n            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n    # Display the output image\n    cv2.imshow('Dense feature detector', input_image)\n\n    # Initialize SIFT object\n    sift = cv2.SIFT()\n\n    # Detect keypoints using SIFT\n    keypoints = sift.detect(gray_image, None)\n\n    # Draw SIFT keypoints on the input image\n    input_image_sift = cv2.drawKeypoints(input_image_sift,\n            keypoints, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n    # Display the output image\n    cv2.imshow('SIFT detector', input_image_sift)\n\n    # Wait until user presses a key\n    cv2.waitKey()\n```", "```py\nimport os\nimport sys\nimport argparse\nimport cPickle as pickle\nimport json\n\nimport cv2\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\ndef build_arg_parser():\n    parser = argparse.ArgumentParser(description='Creates features for given images')\n    parser.add_argument(\"--samples\", dest=\"cls\", nargs=\"+\", action=\"append\",\n            required=True, help=\"Folders containing the training images. \\\n            The first element needs to be the class label.\")\n    parser.add_argument(\"--codebook-file\", dest='codebook_file', required=True,\n            help=\"Base file name to store the codebook\")\n    parser.add_argument(\"--feature-map-file\", dest='feature_map_file', required=True,\n            help=\"Base file name to store the feature map\")\n\n    return parser\n\n# Loading the images from the input folder\ndef load_input_map(label, input_folder):\n    combined_data = []\n\n    if not os.path.isdir(input_folder):\n        raise IOError(\"The folder \" + input_folder + \" doesn't exist\")\n\n    # Parse the input folder and assign the  labels\n    for root, dirs, files in os.walk(input_folder):\n        for filename in (x for x in files if x.endswith('.jpg')):\n            combined_data.append({'label': label, 'image': os.path.join(root, filename)})\n\n    return combined_data\n\nclass FeatureExtractor(object):\n    def extract_image_features(self, img):\n        # Dense feature detector\n        kps = DenseDetector().detect(img)\n\n        # SIFT feature extractor\n        kps, fvs = SIFTExtractor().compute(img, kps)\n\n        return fvs\n\n    # Extract the centroids from the feature points\n    def get_centroids(self, input_map, num_samples_to_fit=10):\n        kps_all = []\n\n        count = 0\n        cur_label = ''\n        for item in input_map:\n            if count >= num_samples_to_fit:\n                if cur_label != item['label']:\n                    count = 0\n                else:\n                    continue\n\n            count += 1\n\n            if count == num_samples_to_fit:\n                print \"Built centroids for\", item['label']\n\n            cur_label = item['label']\n            img = cv2.imread(item['image'])\n            img = resize_to_size(img, 150)\n\n            num_dims = 128\n            fvs = self.extract_image_features(img)\n            kps_all.extend(fvs)\n\n        kmeans, centroids = Quantizer().quantize(kps_all)\n        return kmeans, centroids\n\n    def get_feature_vector(self, img, kmeans, centroids):\n        return Quantizer().get_feature_vector(img, kmeans, centroids)\n\ndef extract_feature_map(input_map, kmeans, centroids):\n    feature_map = []\n\n    for item in input_map:\n        temp_dict = {}\n        temp_dict['label'] = item['label']\n\n        print \"Extracting features for\", item['image']\n        img = cv2.imread(item['image'])\n        img = resize_to_size(img, 150)\n\n        temp_dict['feature_vector'] = FeatureExtractor().get_feature_vector(\n                    img, kmeans, centroids)\n\n        if temp_dict['feature_vector'] is not None:\n            feature_map.append(temp_dict)\n\n    return feature_map\n\n# Vector quantization\nclass Quantizer(object):\n    def __init__(self, num_clusters=32):\n        self.num_dims = 128\n        self.extractor = SIFTExtractor()\n        self.num_clusters = num_clusters\n        self.num_retries = 10\n\n    def quantize(self, datapoints):\n        # Create KMeans object\n        kmeans = KMeans(self.num_clusters,\n                        n_init=max(self.num_retries, 1),\n                        max_iter=10, tol=1.0)\n\n        # Run KMeans on the datapoints\n        res = kmeans.fit(datapoints)\n\n        # Extract the centroids of those clusters\n        centroids = res.cluster_centers_\n\n        return kmeans, centroids\n\n    def normalize(self, input_data):\n        sum_input = np.sum(input_data)\n        if sum_input > 0:\n            return input_data / sum_input\n        else:\n            return input_data\n\n    # Extract feature vector from the image\n    def get_feature_vector(self, img, kmeans, centroids):\n        kps = DenseDetector().detect(img)\n        kps, fvs = self.extractor.compute(img, kps)\n        labels = kmeans.predict(fvs)\n        fv = np.zeros(self.num_clusters)\n\n        for i, item in enumerate(fvs):\n            fv[labels[i]] += 1\n\n        fv_image = np.reshape(fv, ((1, fv.shape[0])))\n        return self.normalize(fv_image)\n\nclass DenseDetector(object):\n    def __init__(self, step_size=20, feature_scale=40, img_bound=20):\n        self.detector = cv2.FeatureDetector_create(\"Dense\")\n        self.detector.setInt(\"initXyStep\", step_size)\n        self.detector.setInt(\"initFeatureScale\", feature_scale)\n        self.detector.setInt(\"initImgBound\", img_bound)\n\n    def detect(self, img):\n        return self.detector.detect(img)\n\nclass SIFTExtractor(object):\n    def compute(self, image, kps):\n        if image is None:\n            print \"Not a valid image\"\n            raise TypeError\n\n        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        kps, des = cv2.SIFT().compute(gray_image, kps)\n        return kps, des\n\n# Resize the shorter dimension to 'new_size'\n# while maintaining the aspect ratio\ndef resize_to_size(input_image, new_size=150):\n    h, w = input_image.shape[0], input_image.shape[1]\n    ds_factor = new_size / float(h)\n\n    if w < h:\n        ds_factor = new_size / float(w)\n\n    new_size = (int(w * ds_factor), int(h * ds_factor))\n    return cv2.resize(input_image, new_size)\n\nif __name__=='__main__':\n    args = build_arg_parser().parse_args()\n\n    input_map = []\n    for cls in args.cls:\n\n        assert len(cls) >= 2, \"Format for classes is `<label> file`\"\n        label = cls[0]\n        input_map += load_input_map(label, cls[1])\n\n    # Building the codebook\n    print \"===== Building codebook =====\"\n    kmeans, centroids = FeatureExtractor().get_centroids(input_map)\n    if args.codebook_file:\n        with open(args.codebook_file, 'w') as f:\n            pickle.dump((kmeans, centroids), f)\n\n    # Input data and labels\n    print \"===== Building feature map =====\"\n    feature_map = extract_feature_map(input_map, kmeans, centroids)\n    if args.feature_map_file:\n        with open(args.feature_map_file, 'w') as f:\n            pickle.dump(feature_map, f)\n```", "```py\nimport os\nimport sys\nimport argparse\n\nimport cPickle as pickle\nimport numpy as np\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn import preprocessing\n\ndef build_arg_parser():\n    parser = argparse.ArgumentParser(description='Trains the classifier models')\n    parser.add_argument(\"--feature-map-file\", dest=\"feature_map_file\", required=True,\n            help=\"Input pickle file containing the feature map\")\n    parser.add_argument(\"--svm-file\", dest=\"svm_file\", required=False,\n            help=\"Output file where the pickled SVM model will be stored\")\n    return parser\n\n# To train the classifier\nclass ClassifierTrainer(object):\n    def __init__(self, X, label_words):\n        # Encoding the labels (words to numbers)\n        self.le = preprocessing.LabelEncoder()\n\n        # Initialize One vs One Classifier using a linear kernel\n        self.clf = OneVsOneClassifier(LinearSVC(random_state=0))\n\n        y = self._encodeLabels(label_words)\n        X = np.asarray(X)\n        self.clf.fit(X, y)\n\n    # Predict the output class for the input datapoint\n    def _fit(self, X):\n        X = np.asarray(X)\n        return self.clf.predict(X)\n\n    # Encode the labels (convert words to numbers)\n    def _encodeLabels(self, labels_words):\n        self.le.fit(labels_words)\n        return np.array(self.le.transform(labels_words), dtype=np.float32)\n\n    # Classify the input datapoint\n    def classify(self, X):\n        labels_nums = self._fit(X)\n        labels_words = self.le.inverse_transform([int(x) for x in labels_nums])\n        return labels_words\n\nif __name__=='__main__':\n    args = build_arg_parser().parse_args()\n    feature_map_file = args.feature_map_file\n    svm_file = args.svm_file\n\n    # Load the feature map\n    with open(feature_map_file, 'r') as f:\n        feature_map = pickle.load(f)\n\n    # Extract feature vectors and the labels\n    labels_words = [x['label'] for x in feature_map]\n\n    # Here, 0 refers to the first element in the\n    # feature_map, and 1 refers to the second\n    # element in the shape vector of that element\n    # (which gives us the size)\n    dim_size = feature_map[0]['feature_vector'].shape[1]\n\n    X = [np.reshape(x['feature_vector'], (dim_size,)) for x in feature_map]\n\n    # Train the SVM\n    svm = ClassifierTrainer(X, labels_words)\n    if args.svm_file:\n        with open(args.svm_file, 'w') as f:\n            pickle.dump(svm, f)\n```", "```py\n$ pip install scikit-learn\n\n```", "```py\n$ python create_features.py --samples bag images/bag/ --samples dress images/dress/ --samples footwear images/footwear/ --codebook-file models/codebook.pkl --feature-map-file models/feature_map.pkl\n$ python training.py --feature-map-file models/feature_map.pkl --svm-file models/svm.pkl\n\n```", "```py\nimport os\nimport sys\nimport argparse\nimport cPickle as pickle\n\nimport cv2\nimport numpy as np\n\nimport create_features as cf\nfrom training import ClassifierTrainer\n\ndef build_arg_parser():\n    parser = argparse.ArgumentParser(description='Extracts features \\\n            from each line and classifies the data')\n    parser.add_argument(\"--input-image\", dest=\"input_image\", required=True,\n            help=\"Input image to be classified\")\n    parser.add_argument(\"--svm-file\", dest=\"svm_file\", required=True,\n            help=\"File containing the trained SVM model\")\n    parser.add_argument(\"--codebook-file\", dest=\"codebook_file\",\n            required=True, help=\"File containing the codebook\")\n    return parser\n\n# Classifying an image\nclass ImageClassifier(object):\n    def __init__(self, svm_file, codebook_file):\n        # Load the SVM classifier\n        with open(svm_file, 'r') as f:\n            self.svm = pickle.load(f)\n\n        # Load the codebook\n        with open(codebook_file, 'r') as f:\n            self.kmeans, self.centroids = pickle.load(f)\n\n    # Method to get the output image tag\n    def getImageTag(self, img):\n        # Resize the input image\n        img = cf.resize_to_size(img)\n\n        # Extract the feature vector\n        feature_vector = cf.FeatureExtractor().get_feature_vector(img, self.kmeans, self.centroids)\n\n        # Classify the feature vector and get the output tag\n        image_tag = self.svm.classify(feature_vector)\n\n        return image_tag\n\nif __name__=='__main__':\n    args = build_arg_parser().parse_args()\n    svm_file = args.svm_file\n    codebook_file = args.codebook_file\n    input_image = cv2.imread(args.input_image)\n\n    print \"Output class:\", ImageClassifier(svm_file, codebook_file).getImageTag(input_image)\n```", "```py\n$ python classify_data.py --input-image new_image.jpg --svm-file models/svm.pkl --codebook-file models/codebook.pkl\n\n```"]