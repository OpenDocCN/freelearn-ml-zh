- en: Chapter 2. Stock Market Price Prediction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章. 股票市场价格预测
- en: In this chapter, we will cover an amazing application that belongs to predictive
    analysis. I hope the name of the chapter has already given you a rough idea of
    what this chapter is going to be all about. We will try to predict the price of
    the stock index. We will apply some modern machine learning techniques as well
    as deep learning techniques.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一个属于预测分析的精彩应用。我希望章节的名称已经给了你一个大致的印象，本章将要讲述什么。我们将尝试预测股票指数的价格。我们将应用一些现代机器学习技术以及深度学习技术。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Introducing the problem statement
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍问题陈述
- en: Collecting the dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集数据集
- en: Understanding the dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据集
- en: Data preprocessing and data analysis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据预处理和数据分析
- en: Feature engineering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程
- en: Selecting the Machine Learning (ML) algorithm
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择机器学习（ML）算法
- en: Training the baseline model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练基线模型
- en: Understanding the testing matrix
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解测试矩阵
- en: Testing the baseline model
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试基线模型
- en: Exploring problems with the existing approach
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索现有方法的问题
- en: Understanding the revised approach
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解修订方法
- en: Understanding concepts and approaches
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解概念和方法
- en: Implementing the revised approach
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施修订方法
- en: Testing the revised approach
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试修订方法
- en: Understanding problems with the revised approach
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用修订方法理解问题
- en: The best approach
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳方法
- en: Summary
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摘要
- en: So, let's get started!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始吧！
- en: Introducing the problem statement
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍问题陈述
- en: The stock market is a place where you can buy and sell units of ownership in
    the company, which we call **stocks**. If the company performs well and increases
    its profit, then you will earn some profit as well because you have the stocks
    of the company, but if the company's profit goes down, then you will lose the
    money you have with the company. So if you invest your money in the right company
    at the right time, it could lead to you earning quite a lot of money. The question
    is which company's stock should you buy? Is there any way we can predict the future
    prices of the stock of any company given the historical prices of the company's
    stock so that we can have higher chances of getting good returns? The answer is
    yes. This is what we will explore in this chapter.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 股票市场是一个你可以买卖公司所有权单位的地方，我们称之为**股票**。如果公司表现良好并增加其利润，那么你也会获得一些利润，因为你拥有公司的股票，但如果公司的利润下降，那么你将失去你在公司中的钱。所以如果你在正确的时间和正确的公司投资，可能会让你赚很多钱。问题是你应该购买哪只公司的股票？有没有一种方法，我们可以根据公司股票的历史价格预测任何公司股票的未来价格，这样我们就有更高的机会获得良好的回报？答案是肯定的。这就是我们在本章要探讨的内容。
- en: If you invest in the stock market, then you may have heard that stock prices
    are completely random and unpredictable. This is called the *efficient market
    hypothesis,* but a majority of the big financial firms, such as JP Morgan, Citigroup,
    and Goldman Sachs, have mathematical and quantitative analysts who are trying
    to develop predictive models to help these big firms decide when to invest and
    in which stock.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你投资股市，你可能听说过股票价格是完全随机且不可预测的。这被称为**有效市场假说**，但大多数大型金融公司，如摩根大通、花旗集团和高盛，都有数学和定量分析师，他们试图开发预测模型，帮助这些大公司决定何时投资以及投资哪只股票。
- en: Before investing in any stock, we do some basic research regarding the company's
    profile. We try to understand its business model. We also check the balance sheets
    of the company to get to know what the profit and loss of the company is. What
    are the products that the company will launch in the next couple of months? What
    kind of news is coming in about the company? What are the current industry trends?
    After researching all these parameters, we will invest our money in a particular
    company's stock if we feel we will gain some profit; otherwise, we won't invest
    in that company.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在投资任何股票之前，我们会对公司的概况进行一些基本研究。我们试图了解其商业模式。我们还检查公司的资产负债表，以了解公司的盈亏情况。公司将在接下来的几个月内推出哪些产品？关于公司的哪些新闻正在传来？当前的行业趋势是什么？在研究了所有这些参数之后，如果我们觉得我们将会获得一些利润，我们就会投资特定公司的股票；否则，我们不会投资那个公司。
- en: 'We depend on various sources of information to get an idea about whether we
    need to buy stocks or sell stocks. Don''t you think all this analysis takes a
    lot of our time? I want to put two questions in front of you. First, can we use
    some of the data points discussed here and build a system that will help us find
    out future stock prices? And can we use historical stock prices to predict future
    stock prices? The answer to both of these questions is yes, definitely: we can
    build a system that will use historical stock prices and some of the other data
    points so that we can predict the future prices of stock. As per the efficient
    market hypothesis, by using historical prices of stock and various other data
    points, we can obtain the future prices of the stock, which will be better than
    a random guess. In this chapter, we will build a predictive model, which will
    predict the close price of the stock. In the next section, we will look at how
    to collect the dataset in order to build the model. So, let''s get started!'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们依赖各种信息来源来了解我们是否需要购买股票或出售股票。您不觉得所有这些分析都花费了我们很多时间吗？我想向您提出两个问题。首先，我们能否使用这里讨论的一些数据点构建一个系统，帮助我们找出未来的股票价格？还有，我们能否使用历史股票价格来预测未来的股票价格？这两个问题的答案都是肯定的：我们可以构建一个系统，使用历史股票价格和一些其他数据点，以便我们能够预测股票的未来价格。根据有效市场假说，通过使用股票的历史价格和多种其他数据点，我们可以获得股票的未来价格，这将比随机猜测更好。在本章中，我们将构建一个预测模型，该模型将预测股票的收盘价。在下一节中，我们将探讨如何收集数据集以构建模型。那么，让我们开始吧！
- en: Collecting the dataset
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集数据集
- en: 'In order to build the model, first we need to collect the data. We will use
    the following two data points:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建模型，我们首先需要收集数据。我们将使用以下两个数据点：
- en: '**Dow Jones Industrial Average** (**DJIA**) index prices'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**道琼斯工业平均指数**（**DJIA**）指数价格'
- en: News articles
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新闻文章
- en: DJIA index prices give us an overall idea about the stock market's movements
    on a particular day, whereas news articles help us find out how news affects the
    stock prices. We will build our model using these two data points. Now let's collect
    the data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 道琼斯工业平均指数价格给我们一个特定日子股市走势的整体概念，而新闻文章帮助我们了解新闻如何影响股票价格。我们将使用这两个数据点来构建我们的模型。现在，让我们收集数据。
- en: Collecting DJIA index prices
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集道琼斯工业平均指数价格
- en: 'In order to collect the DJIA index prices, we will use Yahoo Finance. You can
    visit this link: [https://finance.yahoo.com/quote/%5EDJI/history?period1=1196706600&period2=1512325800&interval=1d&filter=history&frequency=1d](https://finance.yahoo.com/quote/%5EDJI/history?period1=1196706600&period2=1512325800&interval=1d&filter=history&frequency=1d).
    Once you click on this link, you can see that the price data shows up. You can
    change the time period and click on the **Download Data** link and that''s it;
    you can have all the data in `.csv` file format. Refer to the following screenshot
    of the Yahoo finance DJIA index price page:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了收集道琼斯工业平均指数价格，我们将使用雅虎财经。您可以访问此链接：[https://finance.yahoo.com/quote/%5EDJI/history?period1=1196706600&period2=1512325800&interval=1d&filter=history&frequency=1d](https://finance.yahoo.com/quote/%5EDJI/history?period1=1196706600&period2=1512325800&interval=1d&filter=history&frequency=1d)。一旦您点击此链接，您就可以看到价格数据出现。您可以更改时间范围并点击**下载数据**链接，就这样；您就可以拥有所有以`.csv`文件格式存储的数据。请参考以下雅虎财经道琼斯工业平均指数价格页面截图：
- en: '![Collecting DJIA index prices](img/B08394_02_01.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![收集道琼斯工业平均指数价格](img/B08394_02_01.jpg)'
- en: 'Figure 2.1: Yahoo Finance page for DJIA index price'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：道琼斯工业平均指数价格雅虎财经页面
- en: 'Here, we have downloaded the dataset for the years 2007-2016, which means we
    have 10 years of data for DJIA index prices. You can see this in *Figure 2.1*,
    as well. You can find this dataset using this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/DJIA_data.csv](https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/DJIA_data.csv).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已下载了2007-2016年的数据集，这意味着我们拥有10年的道琼斯工业平均指数价格数据。您也可以在*图2.1*中看到这一点。您可以使用以下GitHub链接找到这个数据集：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/DJIA_data.csv](https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/DJIA_data.csv)。
- en: Just bear with me for a while; we will understand the meaning of each of the
    data attributes in the *Understand the dataset* section in this chapter. Now,
    let's look at how we can collect the news articles.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 请稍等片刻；我们将理解本章“理解数据集”部分中每个数据属性的意义。现在，让我们看看我们如何收集新闻文章。
- en: Collecting news articles
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集新闻文章
- en: We want to collect news articles so that we can establish the correlation between
    how news affects the DJIA index value. We are going to perform a sentiment analysis
    on the news articles. You may wonder why we need to perform sentiment analysis.
    If any news has a negative effect on the financial market, then it is likely that
    the prices of stocks will go down, and if news about the financial market is positive,
    then it is likely that prices of the stocks will go up. For this dataset, we will
    use news articles from the New York Times (NYTimes). In order to collect the dataset
    of news articles, we will use the New York Times' developer API. So, let's start
    coding!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要收集新闻文章，以便我们可以建立新闻如何影响道琼斯工业平均指数（DJIA）值之间的相关性。我们将对新闻文章进行情感分析。您可能会想知道为什么我们需要进行情感分析。如果任何新闻对金融市场有负面影响，那么股票价格很可能会下降；如果有关金融市场的新闻是积极的，那么股票价格很可能会上涨。对于这个数据集，我们将使用《纽约时报》（NYTimes）的新闻文章。为了收集新闻文章数据集，我们将使用《纽约时报》的开发者API。那么，让我们开始编码吧！
- en: 'First of all, register yourself on the NYTimes developer website and generate
    your API key. The link is [https://developer.nytimes.com/signup](https://developer.nytimes.com/signup).
    I have generated the API key for the Archive API. Here, we are using *newsapi,
    JSON, requests*, and *sys* dependencies. You can also refer to the NYTimes developer
    documentation using this link: [https://developer.nytimes.com/archive_api.json#/Documentation/GET/%7Byear%7D/%7Bmonth%7D.json](https://developer.nytimes.com/archive_api.json#/Documentation/GET/%7Byear%7D/%7Bmonth%7D.json).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要在《纽约时报》开发者网站上注册并生成您的API密钥。链接是[https://developer.nytimes.com/signup](https://developer.nytimes.com/signup)。我已经为存档API生成了API密钥。在这里，我们使用*newsapi,
    JSON, requests*和*sys*依赖项。您也可以通过以下链接参考《纽约时报》开发者文档：[https://developer.nytimes.com/archive_api.json#/Documentation/GET/%7Byear%7D/%7Bmonth%7D.json](https://developer.nytimes.com/archive_api.json#/Documentation/GET/%7Byear%7D/%7Bmonth%7D.json)。
- en: 'You can find the code at this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/getdata_NYtimes.py](https://github.com/jalajthanaki/stock_price_prediction/blob/master/getdata_NYtimes.py).
    You can see the code snippet in the following screenshot:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下GitHub链接找到代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/getdata_NYtimes.py](https://github.com/jalajthanaki/stock_price_prediction/blob/master/getdata_NYtimes.py)。您可以在下面的屏幕截图中看到代码片段：
- en: '![Collecting news articles](img/B08394_02_02.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![收集新闻文章](img/B08394_02_02.jpg)'
- en: 'Figure 2.2: Code snippet for getting the news article data from the New York
    Times'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2：从《纽约时报》获取新闻文章数据的代码片段
- en: 'As you can see in the code, there are three methods. The first two methods
    are for exceptions and the third method checks for the validation and requests
    the URL that can generate the news article data for us. This NYTimes API URL takes
    three parameters, which are given as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在代码中所见，有三个方法。前两个方法是用于异常处理，第三个方法用于验证并请求为我们生成新闻文章数据的URL。这个《纽约时报》API URL需要三个参数，如下所示：
- en: Year
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年份
- en: Month
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月份
- en: API key
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API密钥
- en: 'After this step, we will call the third function and pass the year value from
    2007 to 2016\. We will save the data in the *JSON* format. You can refer to the
    code snippet in the following screenshot:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步之后，我们将调用第三个函数，并传递从2007年到2016年的年份值。我们将以*JSON*格式保存数据。您可以在下面的屏幕截图中的代码片段中参考：
- en: '![Collecting news articles](img/B08394_02_03.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![收集新闻文章](img/B08394_02_03.jpg)'
- en: 'Figure 2.3: Code snippet for getting news article data from the New York Times'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3：从《纽约时报》获取新闻文章数据的代码片段
- en: 'You can find the raw JSON dataset using this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/2016-01.json](https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/2016-01.json).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下GitHub链接找到原始JSON数据集：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/2016-01.json](https://github.com/jalajthanaki/stock_price_prediction/blob/master/data/2016-01.json)。
- en: Now let's move on to the next section, in which we will understand the dataset
    and the attributes that we have collected so far.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入下一节，我们将了解我们迄今为止收集的数据集和属性。
- en: Understanding the dataset
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据集
- en: 'In this section, we will understand the meaning of data attributes, which will
    help us understand what kind of dataset we are going to deal with and what kind
    of preprocessing is needed for the dataset. We understand our dataset in two sections,
    and those sections are given as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解数据属性的含义，这将帮助我们了解我们将要处理的数据集类型以及数据集需要进行的预处理类型。我们将在两个部分中理解我们的数据集，如下所示：
- en: Understanding the DJIA dataset
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解道琼斯工业平均指数（DJIA）数据集
- en: Understanding the NYTimes news article dataset
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解《纽约时报》新闻文章数据集
- en: Understanding the DJIA dataset
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解道琼斯工业平均指数数据集
- en: 'In the DJIA dataset, we have seven data attributes. They are quite easy to
    understand, so let''s look at each of them one by one:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在道琼斯工业平均指数数据集中，我们有七个数据属性。它们很容易理解，所以让我们逐一查看它们：
- en: '`Date`: The first column indicates the date in the YYYY-MM-DD format when you
    see data in the .csv file.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Date`: 第一列表示在.YYMMDD格式的.csv文件中看到的数据的日期。'
- en: '`Open`: This indicates the price at which the market opens, so it is the opening
    value for the DJIA index for that particular trading day.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Open`: 这表示市场开盘时的价格，因此它是特定交易日的道琼斯工业平均指数的开盘值。'
- en: '`High`: This is the highest price for the DJIA index for a particular trading
    day.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`High`: 这是特定交易日的道琼斯工业平均指数的最高价格。'
- en: '`Low`: This is the lowest price for DJIA index for a particular trading day.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Low`: 这是特定交易日的道琼斯工业平均指数的最低价格。'
- en: '`Close`: The price of DJIA index at the close of the trading day.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Close`: 交易日的道琼斯工业平均指数收盘价。'
- en: '`Adj close`: The adjusted closing price (adj close price) uses the closing
    price as a starting point and takes into account components such as dividends,
    stock splits, and new stock offerings. The adj close price represents the true
    reflection of the DJIA index. Let me give you an example so that you can understand
    the adj close price better: if a company offers a dividend of $5 per share, and
    if the closing price of that company share is $100, then the adj close price will
    become $95\. So, the adj close price considers various factors and, based on them,
    generates the true value of the company''s stock. Here, we are looking at the
    DJIA index value so, most of the time, the closing price and the adj close price
    are the same.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Adj close`: 调整后的收盘价（adj close price）以收盘价为基础，并考虑诸如股息、股票分割和新股票发行等因素。调整后的收盘价代表了道琼斯工业平均指数的真实反映。让我给你举一个例子，以便你能更好地理解调整后的收盘价：如果一家公司提供每股5美元的股息，并且该公司的股票收盘价为100美元，那么调整后的收盘价将变为95美元。因此，调整后的收盘价考虑了各种因素，并根据这些因素生成公司股票的真实价值。在这里，我们关注的是道琼斯工业平均指数的价值，所以，大多数情况下，收盘价和调整后的收盘价是相同的。'
- en: '`Volume`: These values indicate the number of index traded on exchange for
    a particular trading day.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Volume`: 这些值表示特定交易日在交易所交易的数量。'
- en: These are the basic details of the DJIA index dataset. We use historical data
    and try to predict future movement in the DJIA index.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是道琼斯工业平均指数数据集的基本细节。我们使用历史数据并尝试预测道琼斯工业平均指数的未来走势。
- en: In the next section, we will look at the NYTimes news article dataset.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将查看《纽约时报》新闻文章数据集。
- en: Understanding the NYTimes news article dataset
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解《纽约时报》新闻文章数据集
- en: 'We have used the NYTimes developer API and collected the news articles in a
    JSON form, so, here, we will look at the JSON response so we can identify the
    data attributes that are the most important and that we can focus on. In the next
    figure, you can see the JSON response that we get from the NYTimes:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用了《纽约时报》开发者API，并以JSON形式收集了新闻文章，因此，在这里，我们将查看JSON响应，以便我们可以识别出最重要的数据属性，并集中关注。在下一张图中，你可以看到我们从《纽约时报》得到的JSON响应：
- en: '![Understanding the NYTimes news article dataset](img/B08394_02_04.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![理解《纽约时报》新闻文章数据集](img/B08394_02_04.jpg)'
- en: 'Figure 2.4: JSON response for news articles using the NYTimes developer tool'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4：使用《纽约时报》开发者工具的新闻文章的JSON响应
- en: 'In this figure, we can see the JSON response for a single news article. As
    you can see, there is a main data attribute response that carries all other data
    attributes. We will focus on the data attributes that are given inside the docs
    array. Don''t worry; we will not use all the data attributes. Here, we will focus
    on the following data attributes:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图表中，我们可以看到单篇新闻文章的JSON响应。正如你所见，有一个主要数据属性响应，它携带了所有其他数据属性。我们将关注docs数组内部给出的数据属性。不用担心；我们不会使用所有数据属性。在这里，我们将关注以下数据属性：
- en: '`type_of_material`: This attribute indicates that a particular news article
    is derived from a particular kind of source, whether it''s a blog, a news article,
    analysis, and so on.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_of_material`: 此属性表示特定的新闻文章是从某种特定的来源中提取的，无论是博客、新闻文章、分析等等。'
- en: '`headlines`: The headline data attribute has the two sub-data attributes. The
    main data attribute contains the actual headline of the news and the kicker data
    attribute is convey the highlight of the article.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`headlines`: 标题数据属性有两个子数据属性。主要数据属性包含新闻的实际标题，而kicker数据属性则传达文章的亮点。'
- en: '`pub_date`: This data attribute indicates the publication of the news article.
    You can find this attribute in the second-last section of the doc array.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pub_date`: 这个数据属性表示新闻文章的发布日期。你可以在文档数组的倒数第二部分找到这个属性。'
- en: '`section_name`: This data attribute appeared in the preceding image in the
    last section. It provides the category of the news article.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`section_name`: 这个数据属性出现在前面图像的最后一部分。它提供了新闻文章的类别。'
- en: '`news_desk`: This data attribute also indicates the news category. When `section_name`
    is absent in a response, we will refer to this attribute.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`news_desk`: 这个数据属性也指示新闻类别。当响应中缺少`section_name`时，我们将参考这个属性。'
- en: As we understand data attributes properly, we should move on to the next section,
    which is the data preprocessing and data analysis part.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 正确理解数据属性后，我们应该继续到下一部分，即数据预处理和数据分析部分。
- en: Data preprocessing and data analysis
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理和数据分析
- en: In this section, we will mainly cover data preprocessing and data analysis.
    As a part of data preprocessing, we are preparing our training dataset. You may
    be wondering what kind of data preparation I'm talking about, considering we already
    have the data. Allow me to tell you that we have two different datasets and both
    datasets are independent. So, we need to merge the DJIA dataset and NYTimes news
    article dataset in order to get meaningful insights from these datasets. Once
    we prepare our training dataset, we can train the data using different machine
    learning (ML) algorithms.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将主要介绍数据预处理和数据分析。作为数据预处理的一部分，我们正在准备我们的训练数据集。你可能想知道我所说的数据准备是什么，考虑到我们已经有数据了。让我告诉你，我们有两个不同的数据集，并且这两个数据集都是独立的。因此，我们需要合并道琼斯工业平均指数数据集和纽约时报新闻文章数据集，以便从这些数据集中获得有意义的见解。一旦我们准备好了训练数据集，我们就可以使用不同的机器学习（ML）算法来训练数据。
- en: Now let's start the coding to prepare the training dataset. We will be using
    `numpy`, `csv`, `JSON`, and `pandas` as our dependency libraries. Here, our code
    is divided into two parts. First, we will prepare the dataset for the DJIA index
    dataset and then we will move to the next part, which is preparing the NYTimes
    news article dataset. During the preparation of the training dataset, we will
    code the basic data analysis steps as well.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们开始编写代码来准备训练数据集。我们将使用`numpy`、`csv`、`JSON`和`pandas`作为我们的依赖库。在这里，我们的代码分为两部分。首先，我们将为道琼斯指数数据集准备数据集，然后我们将转到下一部分，即准备纽约时报新闻文章数据集。在准备训练数据集的过程中，我们将编写基本的数据分析步骤。
- en: Preparing the DJIA training dataset
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备道琼斯工业平均指数训练数据集
- en: 'You can see the code snippet in the following screenshot. You can find the
    code at this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在下面的屏幕截图中看到代码片段。你可以在以下GitHub链接中找到代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb)。
- en: '![Preparing the DJIA training dataset](img/B08394_02_05.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![准备道琼斯工业平均指数训练数据集](img/B08394_02_05.jpg)'
- en: 'Figure 2.5: Code snippet for preparing the DJIA dataset'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：准备道琼斯工业平均指数数据集的代码片段
- en: 'As you can see in the preceding code snippet, we are reading the csv file that
    we downloaded from the Yahoo Finance page earlier. After that, we convert the
    data into a list format. We also separated the header and actual data from the
    list. Once we have the data in list format, we convert the data into a numpy array.
    We have selected only three columns from the DIJA dataset, as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在前面的代码片段中看到的，我们正在读取我们从雅虎财经页面下载的csv文件。之后，我们将数据转换为列表格式。我们还从列表中分离了标题和实际数据。一旦我们有了列表格式的数据，我们将数据转换为numpy数组。我们从DIJA数据集中选择了仅三个列，如下所示：
- en: Date
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期
- en: Close price
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收盘价
- en: Adj close price
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整后收盘价
- en: 'You may have one question in mind: why have we considered only close price
    and Adj close price from the DJIA csv file? Let me clarify: as we know that open
    price is mostly a nearby value of the last day''s close price, we haven''t considered
    the open price. We haven''t considered the high price and low price because we
    don''t know in which particular timestamp these high and low prices occurred.
    For the first iteration, it is quite complicated to predict when the stock index
    reach a high or low value, so, in the meantime, we ignore these two columns. We
    are mainly interested in the overall trend for the DJIA index. If we figure out
    the trend precisely, we can predict the high and low price values later on. Here,
    we restrict our goal to predicting the closing prices for the DJIA index for future
    trading days.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能有一个疑问：为什么我们只考虑了DJIA csv文件中的收盘价和调整后的收盘价？让我澄清一下：正如我们所知，开盘价通常是前一天收盘价的一个附近值，所以我们没有考虑开盘价。我们没有考虑最高价和最低价，因为我们不知道这些最高价和最低价发生在哪个特定的时间戳。对于第一次迭代来说，预测股票指数何时达到高或低值相当复杂，所以，在此期间，我们忽略这两个列。我们主要对DJIA指数的整体趋势感兴趣。如果我们能精确地找出趋势，我们就可以在以后预测高和低的价格值。在这里，我们限制我们的目标为预测未来交易日的DJIA指数的收盘价。
- en: 'Now back to the coding part: we built the pandas dataframe in such a way that
    the date column acts as the index column, and close price and adj close price
    are the two other columns of the dataset. You can see the output of the dataframe
    defined in the form of the `df` variable in the code snippet given in *Figure
    2.5*. You can see the output of dataframe df in the following figure:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到编码部分：我们以这种方式构建了pandas数据框，使得日期列作为索引列，而收盘价和调整后的收盘价是数据集的两个其他列。您可以在代码片段中看到以`df`变量形式定义的数据框的输出，该代码片段见*图2.5*。您可以在以下图中看到数据框df的输出：
- en: '![Preparing the DJIA training dataset](img/B08394_02_06.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![准备DJIA训练数据集](img/B08394_02_06.jpg)'
- en: 'Figure 2.6: Output of pandas dataframe, which is defined as the *df* variable
    in the code snippet in Figure 2.5'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：pandas数据框的输出，该数据框在图2.5的代码片段中定义为*df*变量
- en: Hopefully now you have a clear understanding of the kind of steps we have followed
    so far. We have created the basic dataframe, so now we will move on to the basic
    data analysis part for a DJIA dataset.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 希望现在您已经清楚地理解了我们迄今为止所遵循的步骤。我们已经创建了基本的数据框，所以现在我们将继续进行DJIA数据集的基本数据分析部分。
- en: Basic data analysis for a DJIA dataset
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DJIA数据集的基本数据分析
- en: 'In this section, we will perform basic data analysis on a DJIA dataset. This
    dataset has the date value, but if you look at the values of the date carefully,
    then you will see that there are some missing dates. Suppose data is missing for
    30-12-2006, 31-12-2006, 1-1-2007, and many other dates. In such cases, we will
    add the date values that are missing. You can refer to the code snippet given
    in *Figure 2.7*, as well as find the code for this on this GitHub: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将对DJIA数据集进行基本数据分析。这个数据集有日期值，但如果您仔细查看日期值，您会发现有一些缺失的日期。假设数据缺失于2006年12月30日、31日、2007年1月1日以及许多其他日期。在这种情况下，我们将添加缺失的日期值。您可以参考图2.7中的代码片段，以及在此GitHub上找到此代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb)。
- en: '![Basic data analysis for a DJIA dataset](img/B08394_02_07.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![DJIA数据集的基本数据分析](img/B08394_02_07.jpg)'
- en: 'Figure 2.7: Code snippet for adding all the missing date values in the DJIA
    dataset'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7：在DJIA数据集中添加所有缺失日期值的代码片段
- en: As you can see in the preceding figure, we come across another challenge after
    adding these missing date values. We have added the date value, but there is no
    close price or adj close price available corresponding to each of them, so we
    need to replace the NaN values logically, not randomly.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，我们在添加这些缺失的日期值之后遇到了另一个挑战。我们已经添加了日期值，但是没有对应每个日期的收盘价或调整后的收盘价，因此我们需要逻辑地替换NaN值，而不是随机替换。
- en: 'In order to replace the NaN values of close price and adj close price, we will
    use the pandas interpolation functionality. We use linear interpolation to generate
    the missing values for NaN. There are many types of interpolation available, but
    here we are using linear interpolation, and the mathematical equation for linear
    interpolation is as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了替换收盘价和调整后收盘价的NaN值，我们将使用pandas插值功能。我们使用线性插值生成NaN的缺失值。有几种插值类型可用，但在这里我们使用线性插值，线性插值的数学方程如下：
- en: '![Basic data analysis for a DJIA dataset](img/B08394_02_39.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![DJIA数据集的基本数据分析](img/B08394_02_39.jpg)'
- en: 'Equation 2.1: Linear interpolation math formula'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 公式2.1：线性插值数学公式
- en: If the two known points are given by the coordinates (x1,y_1) and (x_3,y_3),
    the linear interpolant is the straight line between these points.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个已知点由坐标(x1,y_1)和(x_3,y_3)给出，线性插值是这两个点之间的直线。
- en: 'You can refer to the code snippet in the following screenshot:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考以下截图中的代码片段：
- en: '![Basic data analysis for a DJIA dataset](img/B08394_02_08.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![DJIA数据集的基本数据分析](img/B08394_02_08.jpg)'
- en: 'Figure 2.8: Code snippet for basic data analysis and interpolation implementation'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8：基本数据分析与插值实现的代码片段
- en: The code for this is available on GitHub at [https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码可在GitHub上找到：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb)。
- en: As you can see in the code snippet, we haven't defined which type of interpolation
    should be performed on our dataset; in this case, linear interpolation has been
    performed by default. So after applying the linear interpolation, we can replace
    the NaN values with the actual logical values. We have also removed three records
    from the year 2006\. So now, we have a total of 3653 records.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码片段所示，我们尚未定义应在我们的数据集上执行哪种类型的插值；在这种情况下，默认执行了线性插值。因此，在应用线性插值后，我们可以用实际的逻辑值替换NaN值。我们还删除了2006年的三条记录。因此，现在我们总共有3653条记录。
- en: This is the kind of basic data preprocessing and data analysis we did for the
    DJIA index dataset. Now let's move on to the NYTimes news article dataset. We
    need to prepare the training dataset first, so let's begin with it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们为道琼斯工业平均指数（DJIA）数据集所做的基本数据预处理和数据分析。现在让我们继续到纽约时报新闻文章数据集。首先，我们需要准备训练数据集，所以让我们从这里开始。
- en: Preparing the NYTimes news dataset
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备纽约时报新闻数据集
- en: 'In this section, we will see how we can prepare the NYTimes news dataset. We
    have downloaded the whole news article dataset but we have not put in a filtering
    mechanism for choosing news article categories. Perform the following steps when
    preparing the NYTimes dataset:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解如何准备纽约时报新闻数据集。我们已经下载了整个新闻文章数据集，但我们还没有添加选择新闻文章类别的过滤机制。在准备纽约时报数据集时，请执行以下步骤：
- en: Converting publication date into the YYYY-MM-DD format.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将发布日期转换为YYYY-MM-DD格式。
- en: Filtering news articles by their category.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过类别过滤新闻文章。
- en: Implementing the filter functionality and merge the dataset.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现过滤功能并合并数据集。
- en: Saving the merged dataset in the pickle file format.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将合并后的数据集保存为pickle文件格式。
- en: So, let's start coding for each of these steps.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们开始为每个步骤编写代码。
- en: Converting publication date into the YYYY-MM-DD format
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将发布日期转换为YYYY-MM-DD格式
- en: 'First, we will convert the publication date of the news articles into the YYYY-MM-DD
    format so that we can merge DJIA and NYTimes news article datasets later on. In
    order to achieve this, you can refer to the following code snippet:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将新闻文章的发布日期转换为YYYY-MM-DD格式，以便我们可以在以后合并道琼斯工业平均指数（DJIA）和纽约时报新闻文章数据集。为了实现这一点，你可以参考以下代码片段：
- en: '![Converting publication date into the YYYY-MM-DD format](img/B08394_02_09.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![将发布日期转换为YYYY-MM-DD格式](img/B08394_02_09.jpg)'
- en: 'Figure 2.9: Code snippet for converting the date format of the publication
    date of the news article'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9：转换新闻文章发布日期格式的代码片段
- en: Here, we have written a function that can parse and convert the publication
    date format into the necessary YYYY-MM-DD format. We will call this function later
    on when we read the JSON files in which we have stored the JSON response.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们编写了一个可以将发布日期格式解析并转换为必要的YYYY-MM-DD格式的函数。稍后当我们读取存储JSON响应的JSON文件时，我们将调用此函数。
- en: Filtering news articles by category
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过类别过滤新闻文章
- en: 'The other thing that we are going to do here is filter our news article dataset
    by news category. We have downloaded all types of news articles, but for the stock
    market price prediction application, we need news articles that belong to specific
    news categories. So, we need to implement filters that will help us extract the
    necessary subset of news articles. You can refer to the following code snippet:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里要做的另一件事是按新闻类别过滤我们的新闻文章数据集。我们下载了所有类型的新闻文章，但为了股票市场价格预测应用程序，我们需要属于特定新闻类别的新闻文章。因此，我们需要实现过滤器，帮助我们提取必要的新闻文章子集。您可以在以下代码片段中参考：
- en: '![Filtering news articles by category](img/B08394_02_10.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![按类别过滤新闻文章](img/B08394_02_10.jpg)'
- en: 'Figure 2.10: Code snippet for filtering news articles by their categories'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10：按类别过滤新闻文章的代码片段
- en: 'You can refer to the code provided at this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下GitHub链接提供的代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).
- en: 'As shown in the preceding figure, we are extracting news articles that belong
    to the following news categories:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，我们正在提取属于以下新闻类别的新闻文章：
- en: Business
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业
- en: National
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 国内
- en: World
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 世界
- en: U.S.A.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 美国
- en: Politics
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 政治
- en: Opinion
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评论
- en: Tech
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科技
- en: Science
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科学
- en: Health
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康
- en: Foreign
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外国
- en: Implementing the filter functionality and merging the dataset
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现过滤器功能并合并数据集
- en: 'Now, we need to iterate each of the JSON files and extract the news articles
    that have one of the news categories defined in the previous section. You can
    refer to the code snippet for the implementation of the filter functionality.
    In the upcoming code snippet, you can also find the implementation for merging
    the DJIA dataset and the NYTimes news articles dataset. To merge the two datasets,
    we are adding each of the news article headlines to the pandas dataframe,and from
    this we will generate our final training dataset. This functionality is shown
    in the following screenshot:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要迭代每个JSON文件，并提取上一节中定义的新闻类别之一的新闻文章。您可以参考实现过滤器功能的代码片段。在即将到来的代码片段中，您还可以找到合并道琼斯工业平均指数（DJIA）数据集和纽约时报新闻文章数据集的实现。为了合并这两个数据集，我们将每个新闻文章的标题添加到pandas数据框中，然后我们将从这个数据框生成我们的最终训练数据集。此功能在以下屏幕截图中显示：
- en: '![Implementing the filter functionality and merging the dataset](img/B08394_02_11.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![实现过滤器功能并合并数据集](img/B08394_02_11.jpg)'
- en: 'Figure 2.11: Code snippet for the filtering and merging functionalities'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11：过滤和合并功能的代码片段
- en: 'We have also coded a bit of the exceptional handling functionality. This is
    done so that if any JSON response does not have the value for the data attributes
    section_name, news_desk, or type_of_material, then this code will throw an exception.
    You can refer to the code snippet in the following screenshot:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还编写了一部分异常处理功能。这样做是为了如果任何JSON响应没有data属性中的section_name、news_desk或type_of_material的值，则此代码将抛出异常。您可以在以下屏幕截图中查看代码片段：
- en: '![Implementing the filter functionality and merging the dataset](img/B08394_02_12.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![实现过滤器功能并合并数据集](img/B08394_02_12.jpg)'
- en: 'Figure 2.12: Implementation of exception handling'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12：异常处理的实现
- en: 'We will consider news articles that have no `section_name` and `news_desk`
    as well. We will add all the news article headlines to our dataset and put them
    into the pandas dataframe. You can see the code snippet in the following screenshot:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将考虑没有`section_name`和`news_desk`的新闻文章。我们将把所有新闻文章的标题添加到我们的数据集中，并将它们放入pandas数据框中。您可以在以下屏幕截图中看到代码片段：
- en: '![Implementing the filter functionality and merging the dataset](img/B08394_02_13.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![实现过滤器功能并合并数据集](img/B08394_02_13.jpg)'
- en: 'Figure 2.13: Handling news articles that have no section_name and news_desk'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13：处理没有section_name和news_desk的新闻文章
- en: 'You can see the final merged dataset in the form of the pandas dataframe, as
    shown in the following screenshot:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在下面的屏幕截图中以pandas数据框的形式看到最终的合并数据集：
- en: '![Implementing the filter functionality and merging the dataset](img/B08394_02_14.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![实现过滤器功能并合并数据集](img/B08394_02_14.jpg)'
- en: 'Figure 2.14: Final merged training dataset'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14：最终合并的训练数据集
- en: Here, for each date, we correspond all the news headlines that belong to the
    business, national, world, U.S.A., politics, opinion, technology, science, and
    heath categories. We have downloaded 1,248,084 news articles, and from these articles,
    we have considered 461,738 news articles for our model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，对于每个日期，我们对应所有属于商业、国家、世界、美国、政治、观点、科技、科学和健康类别的新闻标题。我们已下载了1,248,084篇新闻文章，并从中考虑了461,738篇新闻文章用于我们的模型。
- en: 'You can access the code using this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过此GitHub链接访问代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).
- en: Saving the merged dataset in the pickle file format
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将合并后的数据集保存为pickle文件格式
- en: Once we merge the data, we need to save the data objects, so we will use the
    pickle module of Python. Pickle helps us serialize and de-serialize the data.
    The pickle dependency library is fast because the bulk of it is written in C,
    like the Python interpreter itself. Here, we save our training dataset as a `.pkl`
    file format. You can refer to the following code snippet*:*
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们合并了数据，我们需要保存数据对象，因此我们将使用Python的pickle模块。Pickle帮助我们序列化和反序列化数据。Pickle依赖库运行速度快，因为大部分是用C语言编写的，就像Python解释器本身一样。在这里，我们将我们的训练数据集保存为`.pkl`文件格式。您可以参考以下代码片段*：
- en: '![Saving the merged dataset in the pickle file format](img/B08394_02_15.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![将合并后的数据集保存为pickle文件格式](img/B08394_02_15.jpg)'
- en: 'Figure 2.15: Code snippet for saving data in the pickle format'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15：将数据保存为pickle格式的代码片段
- en: We have saved the dataset as the `pickled_ten_year_filtered_lead_para.pkl` file.
    You can find the code on GitHub at [https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将数据集保存为`pickled_ten_year_filtered_lead_para.pkl`文件。您可以在GitHub上找到代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/datapreparation.ipynb).
- en: In the next section, we will mainly focus on the feature engineering part. We
    will also perform some minor data cleaning steps. So let's jump to the next section.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将主要关注特征工程部分。我们还将进行一些小的数据清洗步骤。所以，让我们跳到下一节。
- en: Feature engineering
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'As discussed earlier, we want to predict the close price for the DJIA index
    for a particular trading day. In this section, we will do feature selection based
    on our intuition for our basic prediction model for stock prices. We have already
    generated the training dataset. So, now we will load the saved .pkl format dataset
    and perform feature selection as well as minor data processing. We will also generate
    the sentiment score for each of the filtered NYTimes news articles and will use
    this sentiment score to train our baseline model. We will use the following Python
    dependencies:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们想要预测特定交易日的道琼斯工业平均指数的收盘价。在本节中，我们将根据我们的直觉进行特征选择，以构建我们的基本股价预测模型。我们已经生成了训练数据集。因此，现在我们将加载保存的.pkl格式数据集，并执行特征选择以及一些小的数据处理。我们还将为每个过滤后的《纽约时报》新闻文章生成情感分数，并使用这个情感分数来训练我们的基线模型。我们将使用以下Python依赖项：
- en: numpy
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: numpy
- en: pandas
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas
- en: nltk
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: nltk
- en: 'This section has the following steps:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包含以下步骤：
- en: Loading the dataset
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集
- en: Minor preprocessing
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小型预处理
- en: Feature selection
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征选择
- en: Sentiment analysis
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 情感分析
- en: So, let's begin coding!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始编码！
- en: Loading the dataset
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据集
- en: We have saved the data in the pickle format, and now we need to load data from
    it. You can refer to the following code snippet*:*
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将数据保存为pickle格式，现在我们需要从其中加载数据。您可以参考以下代码片段*：
- en: '![Loading the dataset](img/B08394_02_16.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![加载数据集](img/B08394_02_16.jpg)'
- en: 'Figure 2.16: Code snippet for loading the dataset from the pickle file'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16：从pickle文件加载数据的代码片段
- en: 'You can refer to the code by clicking on this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过点击此GitHub链接来查看代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).
- en: As you can see, in the dataframe output, there is a dot (.) before every article
    headline in the entire dataset, so we need to remove these dots. We will execute
    this change in the next section.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，在数据框输出中，整个数据集中的每篇文章标题前都有一个点（.），因此我们需要移除这些点。我们将在下一节中执行此更改。
- en: Minor preprocessing
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微小预处理
- en: 'As a part of minor preprocessing, we will be performing the following two changes:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 作为预处理的一部分，我们将执行以下两个更改：
- en: Converting the adj close prices into the integer format
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将调整后的收盘价转换为整数格式
- en: Removing the leftmost dot (.) from news headlines
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从新闻标题中移除最左侧点（.）
- en: Converting adj close price into the integer format
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将调整后的收盘价转换为整数格式
- en: 'We know that the adj close price is in the form of a float format. So, here
    we will convert float values into the integer format as well as store the converted
    values as *price* attributes in our pandas dataframe. Now, you may wonder why
    we consider only the adj close prices. Bear with me for a while, and I will give
    you the reason for that. You can find the convergence code snippet in the following
    screenshot:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道调整后的收盘价是浮点格式。因此，在这里我们将浮点值转换为整数格式，并将转换后的值作为*prix*属性存储在我们的pandas数据框中。现在，您可能想知道为什么我们只考虑调整后的收盘价。请稍等片刻，我将给出原因。您可以在下面的屏幕截图中的代码片段中找到收敛代码：
- en: '![Converting adj close price into the integer format](img/B08394_02_17.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![将调整后的收盘价转换为整数格式](img/B08394_02_17.jpg)'
- en: 'Figure 2.17: Code snippet for converting the adj close price into the integer
    format'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.17：将调整后的收盘价转换为整数格式的代码片段
- en: Tip
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'You can refer to the code at this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下GitHub链接中的代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).
- en: Now, let's move on to the second change.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续进行第二个更改。
- en: Removing the leftmost dot from news headlines
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从新闻标题中移除最左侧点
- en: 'In this section, we will see the implementation for removing the leftmost dot.
    We will be using the `lstrip()` function to remove the dot. You can refer to the
    code snippet in the following screenshot:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到移除最左侧点的实现。我们将使用`lstrip()`函数来移除点。您可以在下面的屏幕截图中的代码片段中参考：
- en: '![Removing the leftmost dot from news headlines](img/B08394_02_18.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![从新闻标题中移除最左侧点](img/B08394_02_18.jpg)'
- en: 'Figure 2.18: Code snippet for removing *dot* from the news article headlines'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18：从新闻文章标题中移除*点*的代码片段
- en: Tip
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'You can refer to the code at this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下GitHub链接中的代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).
- en: Now, let's move on to our next section, which is feature engineering.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续下一节，这一节是特征工程。
- en: Feature engineering
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'Feature selection is one of the most important aspects of feature engineering
    and any **Machine Learning** (**ML**) application. So, here we will focus on feature
    selection. In the previous section, I raised the question of why we select only
    the *adj close price* and not the *close price.* The answer to this question lies
    in the feature selection. We select the *adj close prices* because these prices
    give us a better idea about what the last price of the DJIA index is, including
    the stock, mutual funds, dividends, and so on. In our dataset, *close prices*
    are mostly the same as the *adj close price* and in future, if we consider the
    *close price* for unseen data records, we can''t derive the *adj close price*
    because it may be equal to the *close price* or higher than the *close price,*
    The *adj close price* for DJIA index may higher than the c*lose price* because
    it will include stocks, mutual funds, dividend and so on. but we don''t know how
    much higher it will be for unseen dataset where we have just considered *close
    price*. So if we consider the *adj close price,* then we will know that the *close
    price* may be less than or equal to the *adj close price*, but not more than the
    *adj close price*. The *adj close price* is kind of maximum possible value for
    closing price. So, we have considered the *adj close price* for the development.
    For the baseline model, we will be considering the *adj close price*. We have
    renamed the column to *price*. You can refer to the following code snippet:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择是特征工程和任何**机器学习**（**ML**）应用最重要的方面之一。因此，我们将重点关注特征选择。在前一节中，我提出了为什么我们只选择*调整后的收盘价*而不是*收盘价*的问题。这个问题的答案在于特征选择。我们选择*调整后的收盘价*，因为这些价格能让我们更好地了解道琼斯工业平均指数的最后一个价格，包括股票、共同基金、股息等。在我们的数据集中，*收盘价*大多与*调整后的收盘价*相同，在未来，如果我们考虑未见过的新数据记录的*收盘价*，我们无法推导出*调整后的收盘价*，因为它可能等于*收盘价*或高于*收盘价*，道琼斯工业平均指数的*调整后的收盘价*可能高于*收盘价*，因为它将包括股票、共同基金、股息等。但我们不知道在只考虑*收盘价*的未见过数据集中，它将高出多少。所以如果我们考虑*调整后的收盘价*，那么我们将知道*收盘价*可能小于或等于*调整后的收盘价*，但不会超过*调整后的收盘价*。*调整后的收盘价*是收盘价可能的最大值。因此，我们考虑了*调整后的收盘价*进行开发。对于基线模型，我们将考虑*调整后的收盘价*。我们将列名重命名为*price*。您可以参考以下代码片段：
- en: '![Feature engineering](img/B08394_02_19.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![特征工程](img/B08394_02_19.jpg)'
- en: 'Figure 2.19: Code snippet for considering the adj close price as a part of
    feature selection'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.19：将调整后的收盘价作为特征选择一部分的代码片段
- en: As a next step, we will now perform sentiment analysis on the news article dataset.
    We can use the sentiment score when we train our model. So, let's move on to the
    sentiment analysis part.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 作为下一步，我们现在将对新闻文章数据集进行情感分析。我们可以在训练模型时使用情感得分。所以，让我们继续进行情感分析部分。
- en: Sentiment analysis of NYTimes news articles
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对《纽约时报》新闻文章进行情感分析
- en: In order to implement sentiment analysis, we are using the nltk inbuilt sentiment
    analysis module. We will obtain negative, positive, and compound sentiment scores.
    We have used a lexicon-based approach. In the lexicon-based approach, words of
    each sentence are analyzed, and based on the `sentiwordnet` score, each word is
    given a specific sentiment score; then, the aggregate sentence level score is
    decided.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现情感分析，我们使用了nltk内置的情感分析模块。我们将获得负面、正面和复合情感得分。我们使用了基于词典的方法。在基于词典的方法中，分析每个句子的单词，并根据`sentiwordnet`得分，每个单词被赋予一个特定的情感得分；然后，决定句子级别的聚合得分。
- en: Note
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Sentiwordnet is the dictionary which contain sentiment score for words.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Sentiwordnet 是包含单词情感得分的词典。
- en: 'We will cover details related to sentiment analysis in [Chapter 5](ch05.xhtml
    "Chapter 5. Sentiment Analysis"), *Sentiment Analysis*. You can refer to the following
    sentiment analysis code snippet:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第5章](ch05.xhtml "第5章. 情感分析")中详细介绍与情感分析相关的细节，*情感分析*。您可以参考以下情感分析代码片段：
- en: '![Sentiment analysis of NYTimes news articles](img/B08394_02_20.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![《纽约时报》新闻文章的情感分析](img/B08394_02_20.jpg)'
- en: 'Figure 2.20: Sentiment analysis code snippet'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.20：情感分析代码片段
- en: All scores generated by the preceding code are stored in the dataframe, so you
    can see the aggregate score of news article headlines in the following screenshot*:*
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的得分都由前面的代码生成并存储在数据框中，因此您可以在以下屏幕截图中看到新闻文章标题的聚合得分：*
- en: '![Sentiment analysis of NYTimes news articles](img/B08394_02_21.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![《纽约时报》新闻文章的情感分析](img/B08394_02_21.jpg)'
- en: 'Figure 2.21: Aggregate sentiment analysis score stored in the dateframe'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.21：存储在数据框中的聚合情感分析得分
- en: By the end of this section, we will obtain the sentiment score for the NYTimes
    news articles dataset and combine these sentiment scores as part of the training
    dataset. So far, we have done minor preprocessing, selected the data attribute
    as per our intuition, and generated the sentiment score. Now, we will select the
    machine learning algorithm and try to build the baseline model. So, let's move
    on to the next section.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 到本节结束时，我们将获得NYTimes新闻文章数据集的情感分数，并将这些情感分数作为训练数据集的一部分。到目前为止，我们已经进行了轻微的预处理，根据我们的直觉选择了数据属性，并生成了情感分数。现在，我们将选择机器学习算法，并尝试构建基线模型。因此，让我们进入下一节。
- en: Selecting the Machine Learning algorithm
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择机器学习算法
- en: In this section, we will choose the Machine Learning (ML) algorithm based on
    our intuition and then perform training using our training dataset. This is the
    first model for this particular chapter, so the trained model is our baseline
    model, which we will improve later on. So, let's decide which kind of ML algorithm
    suits this stock price prediction application.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将根据我们的直觉选择机器学习（ML）算法，然后使用我们的训练数据集进行训练。这是本章的第一个模型，因此训练的模型是我们的基线模型，我们将在以后对其进行改进。因此，让我们决定哪种ML算法适合这个股价预测应用。
- en: The stock price prediction application is a time-series analysis problem, where
    we need to predict the next point in the time series. This prediction activity
    is similar to linear regression, so we can say that this application is a kind
    of regression problem and any algorithm from the regression family should work.
    Let's select the ensemble algorithm, which is *RandomForestRegressor*, in order
    to develop our baseline model. So let's train our baseline model, and, based on
    the result of that model, we will modify our approach.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 股价预测应用是一个时间序列分析问题，我们需要预测时间序列中的下一个点。这种预测活动类似于线性回归，因此我们可以说这个应用是一种回归问题，回归家族中的任何算法都应该适用。让我们选择集成算法，即*RandomForestRegressor*，来开发我们的基线模型。因此，让我们训练我们的基线模型，并根据该模型的结果，我们将修改我们的方法。
- en: Training the baseline model
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练基线模型
- en: 'As you know, we have selected the **RandomForestRegressor** algorithm. We will
    be using the scikit-learn library to train the model. These are the steps we need
    to follow:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，我们已经选择了**RandomForestRegressor**算法。我们将使用scikit-learn库来训练模型。以下是我们需要遵循的步骤：
- en: Splitting the training and testing dataset
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分割训练和测试数据集
- en: Splitting prediction labels for the training and testing dataset
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练和测试数据集的预测标签分开
- en: Converting sentiment scores into the numpy array
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将情感分数转换为numpy数组
- en: Training the ML model
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练机器学习模型
- en: So, let's implement each of these steps one by one.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们逐一实现这些步骤。
- en: Splitting the training and testing dataset
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分割训练和测试数据集
- en: 'We have 10 years of data values. So for training purposes, we will be using
    8 years of the data, which means the dataset from 2007 to 2014\. For testing purposes,
    we will be using 2 years of the data, which means data from 2015 and 2016\. You
    can refer to the code snippet in the following screenshot to implement this:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有10年的数据值。因此，为了训练目的，我们将使用8年的数据，这意味着从2007年到2014年的数据集。为了测试目的，我们将使用2年的数据，这意味着2015年和2016年的数据。你可以参考以下截图中的代码片段以了解其实施：
- en: '![Splitting the training and testing dataset](img/B08394_02_22.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![分割训练和测试数据集](img/B08394_02_22.jpg)'
- en: 'Figure 2.22: Splitting the training and testing dataset'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.22：分割训练和测试数据集
- en: As you can see from the preceding screenshot, our training dataset has been
    stored in the train dataframe and our testing dataset has been stored in the test
    dataframe.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述截图所示，我们的训练数据集已存储在train数据框中，而我们的测试数据集已存储在test数据框中。
- en: Splitting prediction labels for the training and testing datasets
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将训练和测试数据集的预测标签分开
- en: 'As we split the training and testing dataset, we also need to store the adj
    close price separately because we need to predict these *adj close prices* (indicated
    in the code as `prices`); these price values are labels for our training data,
    and this training becomes supervised training as we will provide the actual price
    in the form of labels. You can refer to the following code for the implementation:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们分割训练和测试数据集的同时，我们还需要单独存储调整后的收盘价，因为我们需要预测这些*调整后的收盘价*（在代码中标记为`prices`）；这些价格值是我们训练数据的标签，这种训练成为监督训练，因为我们将以标签的形式提供实际的价格。你可以参考以下代码以了解其实施：
- en: '![Splitting prediction labels for the training and testing datasets](img/B08394_02_23.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![分割预测标签以用于训练和测试数据集](img/B08394_02_23.jpg)'
- en: 'Figure 2.23: Splitting the prediction labels for training and testing datasets'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.23：分割训练和测试数据集的预测标签
- en: Here, all attributes except the price are given in a feature vector format and
    the price is in the form of labels. The ML algorithm takes this feature vector,
    labels the pair, learns the necessary pattern, and predicts the price for the
    unseen data.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，除了价格以外的所有属性都是以特征向量格式给出的，而价格是以标签的形式。ML算法接受这个特征向量，标记这对数据，学习必要的模式，并预测未见数据的价格。
- en: Converting sentiment scores into the numpy array
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将情感分数转换为numpy数组
- en: 'Before we start the training, there is one last, necessary point that we need
    to keep in mind: we are converting the sentiment analysis scores into the numpy
    array format. This is because once we set the price attribute as a prediction
    label, our features vector will contain only the sentiment scores and date. So
    in order to generate a proper feature vector, we have converted the sentiment
    score into a numpy array. The code snippet to implement this is provided in the
    following screenshot:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始训练之前，还有一个最后、必要的问题需要我们记住：我们将情感分析分数转换为numpy数组格式。这是因为一旦我们将价格属性设置为预测标签，我们的特征向量将只包含情感分数和日期。因此，为了生成一个合适的特征向量，我们将情感分数转换为numpy数组。实现此功能的代码片段在以下截图提供：
- en: '![Converting sentiment scores into the numpy array](img/B08394_02_24.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![将情感分数转换为numpy数组](img/B08394_02_24.jpg)'
- en: 'Figure 2.24: Code snippet for converting sentiment analysis score into the
    numpy array'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.24：将情感分析分数转换为numpy数组的代码片段
- en: As you can see from the code snippet, we have performed the same conversion
    operation for both training the dataset and testing the dataset.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从代码片段中可以看到，我们对训练数据集和测试数据集都执行了相同的转换操作。
- en: Note
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that if you get a value error, check the dataset because there may be a
    chance that a column in the dataset has a blank or null value.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果您得到一个值错误，请检查数据集，因为可能存在数据集中某一列有空白或空值的情况。
- en: Now, let's train our model!
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们训练我们的模型！
- en: Training of the ML model
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML模型的训练
- en: 'In the first iteration, we use the RandomForestRegressor algorithm, which is
    provided as part of the scikit-learn dependency. You can find the code for this
    in the following screenshot:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次迭代中，我们使用的是作为scikit-learn依赖部分提供的RandomForestRegressor算法。您可以在以下截图找到此代码：
- en: '![Training of the ML model](img/B08394_02_25.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![ML模型的训练](img/B08394_02_25.jpg)'
- en: 'Figure 2.25: Code snippet for training using RandomForestRegressor'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.25：使用RandomForestRegressor进行训练的代码片段
- en: As you can see from the preceding screenshot, we have used all the default values
    for our hyperparameters. For a more detailed description regarding hyperparameters,
    you can refer to [http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从前面的截图中所见，我们已经为我们的超参数使用了所有默认值。有关超参数的更详细描述，您可以参考[http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)。
- en: Now that our model has been trained, we need to test it using our testing dataset.
    Before we test, let's discuss the approach we will take to test our model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了模型，我们需要使用我们的测试数据集来测试它。在我们测试之前，让我们讨论我们将采取的测试模型的方法。
- en: Understanding the testing matrix
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解测试矩阵
- en: 'In this section, we will understand the testing matrix and visualization approaches
    to evaluate the performance of the trained ML model. So let''s understand both
    approaches, which are as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解测试矩阵和可视化方法来评估训练好的ML模型的表现。所以让我们了解这两种方法，它们如下：
- en: The default testing matrix
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认测试矩阵
- en: The visualization approach
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化方法
- en: The default testing matrix
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 默认测试矩阵
- en: 'We are using the default score API of scikit-learn to check how well the ML
    is performing. In this application, the score function is the coefficient of the
    sum of the squared error. It is also called the coefficient of R2, which is defined
    by the following equation:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用scikit-learn的默认分数API来检查ML的表现如何。在这个应用程序中，分数函数是平方误差和的系数。它也被称为R2系数，其定义如下方程：
- en: '![The default testing matrix](img/B08394_02_40.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![默认测试矩阵](img/B08394_02_40.jpg)'
- en: 'Here, *u* indicates the residual sum of squares. The equation for *u* is as
    follows:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*u* 表示残差平方和。*u* 的方程如下：
- en: '![The default testing matrix](img/B08394_02_41.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![默认测试矩阵](img/B08394_02_41.jpg)'
- en: 'The variable *v* indicates the total sum of squares. The equation for *v* is
    as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 *v* 表示平方和的总和。*v* 的方程如下：
- en: '![The default testing matrix](img/B08394_02_42.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![默认测试矩阵](img/B08394_02_42.jpg)'
- en: The best possible score is 1.0, and it can be a negative score as well. A negative
    score indicates that the trained model can be arbitrarily worse. A constant model
    that always predicts the expected value for label *y*, disregarding the input
    features, will produce an R2 score of 0.0.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳可能分数是 1.0，它也可以是负分数。负分数表示训练模型可以任意糟糕。一个始终预测标签 *y* 的预期值，而忽略输入特征的恒定模型将产生 R2 分数为
    0.0。
- en: In order to obtain the score, we just need to call the score function. The code
    for testing will be the same as that in the *Test baseline model* section. Now
    let's take a look at another testing approach that is quite helpful in understanding
    the output with respect to true testing labels. So, let's check that out!
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得分数，我们只需调用分数函数。测试的代码将与“测试基线模型”部分中的代码相同。现在让我们看看另一种有助于理解输出与真实测试标签的测试方法。那么，让我们来看看吧！
- en: The visualization approach
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化方法
- en: In this section, we will be exploring an effective and intuitive approach, which
    is the **visualization** of the predicted output versus real output. This approach
    gives you a lot of insight as the graphs are easy to understand and you can decide
    the next steps to improve the model.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一种有效且直观的方法，即预测输出与实际输出的**可视化**。这种方法提供了很多洞察力，因为图表易于理解，你可以决定下一步如何改进模型。
- en: In this application, we will be using the actual prices from the testing dataset
    and the predicted prices for the testing dataset, which will indicate how good
    or bad the predictions are. You will find the code and graph for this process
    in the next section, named *Testing the baseline model*.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个应用中，我们将使用测试数据集中的实际价格和预测价格，这将表明预测的好坏。你将在下一节中找到这个过程的相关代码和图表，该节名为“测试基线模型”。
- en: Testing the baseline model
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试基线模型
- en: 'In this section, we will be implementing our testing approach so that we can
    evaluate our model''s accuracy. We will first generate the output prediction and
    then we''ll start testing it. We will be implementing the following steps here:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现测试方法，以便评估我们模型的准确性。我们首先生成输出预测，然后开始测试。以下是我们将在这里实施的步骤：
- en: Generating and interpreting the output
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成和解释输出
- en: Generating the score
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成分数
- en: Visualizing the output
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化输出
- en: Generating and interpreting the output
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成和解释输出
- en: 'To generate the prediction, we are using the `treeinterpreter` library. We
    are predicting the price value for each of our testing dataset records using the
    following code:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成预测，我们正在使用 `treeinterpreter` 库。我们使用以下代码为测试数据集中的每条记录预测价格值：
- en: '![Generating and interpreting the output](img/B08394_02_26.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![生成和解释输出](img/B08394_02_26.jpg)'
- en: 'Figure 2.26: Code snippet for generating the prediction'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.26：生成预测的代码片段
- en: Here, *prediction* is the array in which we have elements that are the corresponding
    predicted *adj close price* for all records of the testing dataset. Now, we will
    compare this predicted output with the actual *adj close price* of the testing
    dataset. By doing this, we will get to know how accurately our first model is
    predicting the *adj close price*. In order to evaluate further, we will generate
    the accuracy score.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*prediction* 是一个数组，其中包含与测试数据集中所有记录对应的预测 *adj close price* 元素。现在，我们将比较这个预测输出与测试数据集的实际
    *adj close price*。通过这样做，我们将了解我们的第一个模型在预测 *adj close price* 方面的准确性。为了进一步评估，我们将生成准确度分数。
- en: Generating the accuracy score
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成准确度分数
- en: 'In this section, we will generate the accuracy score as per the equations provided
    in the *default testing matrix* section. The code for this is as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将根据“默认测试矩阵”部分提供的方程生成准确度分数。相应的代码如下：
- en: '![Generating the accuracy score](img/B08394_02_27.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![生成准确度分数](img/B08394_02_27.jpg)'
- en: 'Figure 2.27: Code snippet for generating the score for the test dataset'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.27：为测试数据集生成分数的代码片段
- en: As you can see from the preceding code snippet, our model is not doing too well.
    At this point, we don't know what mistakes we've made or what went wrong. This
    kind of situation is common when you are trying to solve or build an ML model.
    We can grasp the problem better using visualization techniques.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码片段所示，我们的模型表现并不太好。在这个阶段，我们还不知道我们犯了什么错误或者出了什么问题。当你试图解决或构建一个机器学习模型时，这种情况很常见。我们可以使用可视化技术更好地把握问题。
- en: Visualizing the output
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化输出
- en: 'We will be using the visualization graph in this section. Using the graph,
    we will identify the kind of error we have committed so that we can fix that error
    in the next iteration. We will plot a graph where the *y-axis* represents the
    *adj close prices* and the *x-axis* represent the *dates*. We plot the *actual
    prices* and *predicted prices* on the graph so that we will get a brief idea about
    how our algorithm is performing. We will use the following code snippet to generate
    the graph:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用可视化图表。使用图表，我们将识别我们犯的错误类型，以便我们可以在下一次迭代中修复这个错误。我们将绘制一个图表，其中*Y轴*代表*调整后的收盘价*，而*X轴*代表*日期*。我们在图表上绘制*实际价格*和*预测价格*，以便我们大致了解我们的算法表现如何。我们将使用以下代码片段生成图表：
- en: '![Visualizing the output](img/B08394_02_28.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![可视化输出](img/B08394_02_28.jpg)'
- en: 'Figure 2.28: Code snippet for generating graph for predicted prices vs actual
    prices.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.28：生成预测价格与实际价格对比图的代码片段。
- en: As you can see from the preceding graph, the top single line (orange color)
    represents the actual price and the messy spikes (blue color) below the line represent
    the predicted prices. From this plot, we can summarize that our model can't predict
    the proper prices. Here, you can see that the actual prices and predicted prices
    are not aligned with each other. We need to fix this issue. There are some techniques
    that we can try, such as alignment, smoothing, and trying a different algorithm.
    So, let's cover the problems of this approach in the next section.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述图表所示，最上面的单行（橙色）代表实际价格，而线下的杂乱尖峰（蓝色）代表预测价格。从这个图中，我们可以总结出我们的模型无法正确预测价格。在这里，你可以看到实际价格和预测价格并没有对齐。我们需要解决这个问题。有一些技术我们可以尝试，比如对齐、平滑和尝试不同的算法。所以，让我们在下一节中讨论这个方法的问题。
- en: Note
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: You can access the entire code on this topic from the GitHub link at [https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从GitHub链接[https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb)中获取这个主题的完整代码。
- en: Exploring problems with the existing approach
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索现有方法的问题
- en: 'In this section, we will be discussing the problems of the existing approach.
    There are mainly three errors we could have possibly committed, which are listed
    as follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论现有方法的问题。我们可能犯的主要有三个错误，如下列所示：
- en: Alignment
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对齐
- en: Smoothing
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平滑
- en: Trying a different ML algorithm
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的机器学习算法
- en: Let's discuss each of the points one by one.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一点讨论每个问题。
- en: Alignment
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对齐
- en: As we have seen in the graph, our actual price and predicted prices are not
    aligned with each other. This becomes a problem. We need to perform alignment
    on the price of the stocks. We need to consider the average value of our dataset,
    and based on that, we will generate the alignment. You can understand more about
    alignment in upcoming section called *Alignment-based approach*.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在图中看到的，我们的实际价格和预测价格并没有对齐。这成为一个问题。我们需要对股票的价格进行对齐。我们需要考虑我们数据集的平均值，并根据这个平均值生成对齐。你可以在接下来的名为*基于对齐的方法*的部分中了解更多关于对齐的信息。
- en: Smoothing
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平滑
- en: The second problem I feel we have with our first model is that we haven't applied
    any smoothing techniques. So for our model, we need to apply smoothing techniques
    as well. We will be using the **Exponentially Weighted Moving Average** (**EWMA**)
    technique for smoothing*.* This technique is used to adjust the variance of the
    dataset.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我感觉我们第一个模型存在的问题是，我们没有应用任何平滑技术。所以，对于我们的模型，我们也需要应用平滑技术。我们将使用**指数加权移动平均**（**EWMA**）技术进行平滑。这种技术用于调整数据集的方差。
- en: Trying a different ML algorithm
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试不同的机器学习算法
- en: For our model, we have used the `RandomForestRegressor` algorithm. But what
    if we try the same thing with our model using a different algorithm, say *Logistic
    Regression*? In the next section, you will learn how to implement this algorithm—after
    applying the necessary alignment and smoothing, of course.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的模型，我们使用了 `RandomForestRegressor` 算法。但如果我们尝试使用不同的算法，比如 *逻辑回归* 来做同样的事情，会怎样呢？在下节中，你将学习如何实现这个算法——当然是在应用必要的对齐和平滑之后。
- en: We have seen the possible problems with our first baseline approach. Now, we
    will try to understand the approach for implementing the alignment, smoothing,
    and `Logistic Regression` algorithms.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了我们第一个基线方法可能存在的问题。现在，我们将尝试理解实现对齐、平滑和 `Logistic Regression` 算法的途径。
- en: Understanding the revised approach
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解修订的方法
- en: In this section, we will be looking at the key concepts and approaches for alignment
    and smoothing. It is not that difficult to implement the *Logistic Regression*
    algorithm; we will be using the scikit-learn API. So, we will start with understanding
    the concepts and approaches for implementation.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨对齐和平滑的关键概念和方法。实现 *逻辑回归* 算法并不困难；我们将使用 scikit-learn API。因此，我们将从理解实现的概念和方法开始。
- en: Understanding concepts and approaches
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解概念和方法
- en: Here, we will discuss how alignment and smoothing will work. Once we understand
    the technicality behind alignment and smoothing, we will focus on the Logistic
    Regression-based approach.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将讨论对齐和平滑将如何工作。一旦我们理解了对齐和平滑的技术细节，我们将专注于基于逻辑回归的方法。
- en: Alignment-based approach
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于对齐的方法
- en: Using this approach, we will be increasing the prices using a constant value
    so that our predicted price and actual price in testing the dataset will be aligned.
    Suppose we take 10 days into consideration. We will generate the average of the
    value of the prices. After that, we generate the average value for the prices
    that have been predicted by the first ML model. Once we generate both average
    values, we need to subtract the values, and the answer is the alignment value
    for those `10` days.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们将使用一个常数来增加价格，以便我们的预测价格和测试数据集中的实际价格对齐。假设我们考虑 10 天。我们将生成价格的平均值。之后，我们生成第一个机器学习模型预测的价格的平均值。一旦我们生成了这两个平均值，我们需要减去这些值，得到的答案就是这
    10 天的对齐值。
- en: Let's take an intuitive working example that will help clear your vision. Consider
    10 days from January 2, 2015, to January 11, 2015\. For each record, you will
    take the average value for the actual price. Suppose the number will come to 17,676
    and the average of predicted price value will be 13,175\. In this case, you will
    get a difference of 4,501, which is the value for the alignment. We will add this
    value to our testing dataset so that testing price values and predicted price
    values will be aligned. You will find the code implementation in the *Implement
    revised approach* section.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个直观的工作示例来帮助你澄清思路。考虑从 2015 年 1 月 2 日到 1 月 11 日的 10 天。对于每条记录，你将取实际价格的平均值。假设这个数字将是
    17,676，预测价格的平均值将是 13,175。在这种情况下，你将得到 4,501 的差异，这就是对齐的值。我们将把这个值添加到我们的测试数据集中，以便测试价格值和预测价格值对齐。你将在
    *实现修订方法* 部分找到代码实现。
- en: Smoothing-based approach
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于平滑的方法
- en: 'In this approach, we will be using EWMA. **EWMA** stands for **Exponentially
    Weighted Moving Average**. The smoothing approach is based on the weighted average
    concept. In general, a weighted moving average is calculated by the following
    equation:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，我们将使用 EWMA。**EWMA** 代表 **指数加权移动平均**。平滑方法基于加权平均的概念。一般来说，加权移动平均是通过以下方程计算的：
- en: '![Smoothing-based approach](img/B08394_02_43.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![基于平滑的方法](img/B08394_02_43.jpg)'
- en: 'Here, *x[t]* is the input and *y[t]* is the output. Weights are calculated
    using the following equations:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*x[t]* 是输入，*y[t]* 是输出。权重使用以下方程计算：
- en: '![Smoothing-based approach](img/B08394_02_29.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![基于平滑的方法](img/B08394_02_29.jpg)'
- en: 'Figure 2.29: Equation for calculating the weight for EWMA'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.29：计算 EWMA 权重的方程
- en: 'Image source: [http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows](http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows](http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows)
- en: Here, α is the smoothing constant. If the value of the smoothing constant is
    high, then it will be close to the actual value, and if the smoothing constant
    is low, then it will be smoother but not close to the actual value. Typically,
    in statistics the smoothing constant ranges between 0.1 and 0.3\. Therefore, we
    can generate the smoothed value using the smoothing constant.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，α 是平滑常数。如果平滑常数的值较高，则它将接近实际值；如果平滑常数较低，则它将更平滑，但不会接近实际值。通常，在统计学中，平滑常数的范围在 0.1
    到 0.3 之间。因此，我们可以使用平滑常数生成平滑值。
- en: Let's take a working example. Take a smoothing constant = 0.3; if the actual
    value is 100 and the predicted value is 110, then the smoothed value can be obtain
    using this equation, which is (smoothing constant * actual value ) + (1- smoothing
    constant) * predicted value. The value that we will obtain is *(0.3* 100) + (1-0.3)*110
    = 107*. For more information, you can refer to [http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows](http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个工作示例来演示。取平滑常数 = 0.3；如果实际值是 100，预测值是 110，那么平滑值可以通过以下公式获得，即（平滑常数 * 实际值）+（1-平滑常数）*
    预测值。我们将获得的价值是 *(0.3* 100) + (1-0.3)*110 = 107*。更多信息，您可以参考[http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows](http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows)。
- en: We will see the actual code-level implementation in the Implement revised approach
    section. pandas already has an API, so we can easily implement EWMA.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在“实现改进方法”部分看到实际的代码级实现。pandas 已经有了 API，因此我们可以轻松实现 EWMA。
- en: Logistic Regression-based approach
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于逻辑回归的方法
- en: Implementing the Logistic Regression algorithm is a simple task because we just
    need to use the scikit-learn API. For the testing dataset, we will apply alignment
    and smoothing. After evaluating accuracy, we will decide whether we need to change
    the ML algorithm or not. We started with our intuition and slowly we improved
    our approaches. I don't really need to explain the Logistic Regression algorithm
    itself, but during the implementation, we will discuss the important points.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 实现逻辑回归算法是一个简单的任务，因为我们只需要使用 scikit-learn API。对于测试数据集，我们将应用对齐和平滑。在评估准确度后，我们将决定是否需要更改机器学习算法。我们从直觉出发，逐渐改进我们的方法。我并不需要真正解释逻辑回归算法本身，但在实现过程中，我们将讨论重要点。
- en: Now, it is time to move on to the implementation part of our revised approach.
    So, let's take a look at the next section.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候继续我们改进方法的具体实现部分了。让我们看看下一节。
- en: Implementing the revised approach
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现改进的方法
- en: 'In this section, we will discuss the three parts of implementation, which are
    as follows:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论实现的三个部分，如下所述：
- en: Implementation
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现
- en: Testing the revised approach
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试改进的方法
- en: Understanding the problem with the revised approach
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解改进方法中的问题
- en: Implementation
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: 'Here, we are implementing the following:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在实现以下内容：
- en: Alignment
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对齐
- en: Smoothing
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平滑
- en: Logistic Regression
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: 'We have already discussed the approach and key concepts, so now we just focus
    on the code part here. You can find all the code at this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了方法和关键概念，所以现在我们只需关注这里的代码部分。您可以在以下 GitHub 链接中找到所有代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb)。
- en: Implementing alignment
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现对齐
- en: 'The alignment is performed on the testing dataset. You can refer to the following
    code snippet:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐是在测试数据集上进行的。您可以参考以下代码片段：
- en: '![Implementing alignment](img/B08394_02_30.jpg)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![实现对齐](img/B08394_02_30.jpg)'
- en: 'Figure 2.30: Code snippet for alignment on the test dataset'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.30：测试数据集上的对齐代码片段
- en: 'As you can see in the preceding code snippet, we obtain a difference of 10
    days *adj close price* using the average price of the last 5 days and the average
    price of the predicted upcoming 5 days in order to align the test data. Here,
    we also convert the date from the string into the date format. As you can see,
    5096.99 is the difference in the test prediction price, which we will add to our
    predicted *adj close price* value. We have generated the graph again so we can
    easily understand that the alignment approach is implemented nicely. You can refer
    to the following code snippet:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在前面的代码片段中看到的，我们使用过去5天的平均价格和预测的下一个5天的平均价格来获得10天的*adj close price*差异，以便对齐测试数据。在这里，我们还把日期从字符串转换为日期格式。如您所见，5096.99是测试预测价格中的差异，我们将将其添加到我们的预测*adj
    close price*值中。我们再次生成了图表，以便我们能够轻松理解对齐方法得到了很好的实现。您可以参考以下代码片段：
- en: '![Implementing alignment](img/B08394_02_31.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![实现对齐](img/B08394_02_31.jpg)'
- en: 'Figure 2.31: Code snippet of the graph for the alignment approach'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.31：对齐方法的代码片段
- en: As you can see in the preceding code snippet, the alignment graph shows that
    our testing dataset price and predicted prices are aligned. The benefit of the
    aligned graph is that now we can define in a precise manner that `RandomForestRegressor`
    didn't do its job with high accuracy as its performance was not great for all
    data records. The alignment graph gave us a crystal clear picture of our previous
    iteration. So when we train the logistic regression now, we will evaluate the
    predicted prices using alignment.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在前面的代码片段中看到的，对齐图表显示我们的测试数据集价格和预测价格是对齐的。对齐图表的好处是，现在我们可以精确地定义`RandomForestRegressor`没有以高精度完成其工作，因为它的性能对于所有数据记录来说都不太理想。对齐图表为我们之前的迭代提供了一个清晰的画面。因此，当我们现在训练逻辑回归时，我们将使用对齐来评估预测价格。
- en: Implementing smoothing
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现平滑处理
- en: 'We are using the pandas EWMA API using 60 days'' time span and frequency time
    *D.* This "D" indicates that we are dealing with the datetime format in our dataset.
    You can see the code implementation in the following code snippet:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用pandas EWMA API，时间跨度为60天，频率时间为*D.* 这个"D"表示我们在数据集中处理的是日期时间格式。您可以在以下代码片段中看到代码实现：
- en: '![Implementing smoothing](img/B08394_02_32.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![实现平滑处理](img/B08394_02_32.jpg)'
- en: 'Figure 2.32: Code snippet for EWMA smoothing'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.32：EWMA平滑的代码片段
- en: 'We are also generating the graph in which we put the *predicted price, average
    predicted price, actual price*, and *average actual price*. You can refer to the
    following code and graph:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在生成一个图表，其中包含*预测价格、平均预测价格、实际价格*和*平均实际价格*。您可以参考以下代码和图表：
- en: '![Implementing smoothing](img/B08394_02_33.jpg)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![实现平滑处理](img/B08394_02_33.jpg)'
- en: 'Figure 2.33: Code snippet for generating the graph after smoothing'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.33：平滑后生成图表的代码片段
- en: In this graph, you can see that after smoothing the *average predicted price,*
    the curve follows the *actual price* trend. Although the accuracy is not great,
    we will move toward a positive direction. The smoothing technique will be useful
    for us if we want to tune our algorithm. You can refer to the following graph
    for the *average predicted price versus actual price:*
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图表中，您可以看到在平滑*平均预测价格*之后，曲线遵循*实际价格*的趋势。尽管准确性不是很高，但我们将会朝着积极的方向发展。如果我们想调整我们的算法，平滑技术将对我们很有用。您可以参考以下图表查看*平均预测价格与实际价格*：
- en: '![Implementing smoothing](img/B08394_02_34.jpg)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![实现平滑处理](img/B08394_02_34.jpg)'
- en: 'Figure 2.34: Code snippet for the graph, indicating average_predicted_price
    versus actual_price'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.34：表示平均预测价格与实际价格的代码片段
- en: By referring to the preceding graph, we can indicate that we apply alignment
    and smoothing because it helps tune our ML model for the next iteration.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 通过参考前面的图表，我们可以指出我们应用了对齐和平滑，因为这有助于调整我们的机器学习模型以进行下一次迭代。
- en: Implementing logistic regression
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现逻辑回归
- en: 'In this section, we will be implementing logistic regression. Take a look at
    the following screenshot:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现逻辑回归。请看以下截图：
- en: '![Implementing logistic regression](img/B08394_02_35.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![实现逻辑回归](img/B08394_02_35.jpg)'
- en: 'Figure 2.35: Code snippet for logistic regression'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.35：逻辑回归的代码片段
- en: Here, we have trained the model again using the logistic regression ML algorithm.
    We have also implemented alignment and smoothing for the test dataset. Now, let's
    evaluate the logistic regression model.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们再次使用逻辑回归机器学习算法训练了模型。我们还为测试数据集实现了对齐和平滑。现在，让我们评估逻辑回归模型。
- en: Testing the revised approach
  id: totrans-349
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试改进方法
- en: 'We have tested the logistic regression model. You can refer to the visualization
    in the form of graphs that show that this revised approach is certainly better
    than *RandomForesRegressor (without alignment and smoothing),* but it is not up
    to the mark:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经测试了逻辑回归模型。您可以参考以下图表形式的可视化，显示这种改进方法确实比*RandomForesRegressor（没有对齐和光滑）*要好，但还没有达到标准：
- en: '![Testing the revised approach](img/B08394_02_36.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![测试改进方法](img/B08394_02_36.jpg)'
- en: 'Figure 2.36: Year-wise prediction graph'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.36：年度预测图表
- en: As you can see in the preceding screenshot, we have generated a year-wise graph
    for *logistic Regression*; we can see a slight improvement using this model. We
    have also used alignment and smoothing, but they are not too effective.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个屏幕截图所示，我们为*逻辑回归*生成了年度图表；我们可以看到使用此模型有轻微的改进。我们还使用了对齐和光滑，但效果并不太明显。
- en: Now, let's discuss what the problems with this revised approach are, and then
    we can implement the best approach.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下这个改进方法存在的问题，然后我们可以实施最佳方法。
- en: Understanding the problem with the revised approach
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解改进方法中的问题
- en: In this section, we will discuss why our revised approach doesn't give us good
    results. ML models don't work because datasets are not normalized. The second
    reason is that even after alignment and smoothing, the *RandomForestRegression*
    ML model faces an overfitting issue. For the best approach, we need to handle
    normalization and overfitting. We can solve this issue using a neural network-based
    ML algorithm. So in our last iteration, we will develop the neural network that
    can give us the best accuracy.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论为什么我们的改进方法没有给我们带来良好的结果。ML模型不起作用是因为数据集没有归一化。第二个原因是，即使在归一化和光滑之后，*RandomForestRegression*
    ML模型仍然面临过拟合问题。对于最佳方法，我们需要处理归一化和过拟合。我们可以使用基于神经网络的ML算法来解决这个问题。因此，在我们的最后一次迭代中，我们将开发一个可以给我们最佳精度的神经网络。
- en: The best approach
  id: totrans-357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最佳方法
- en: 'Here, we are going to implement the neural network-based algorithm **multilayer
    perceptron** (**MLP**). You can refer to the following code snippet:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将实现基于神经网络的算法**多层感知器**（**MLP**）。您可以参考以下代码片段：
- en: '![The best approach](img/B08394_02_37.jpg)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![最佳方法](img/B08394_02_37.jpg)'
- en: 'Figure 2.37: Code snippet for multilayer perceptron'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.37：多层感知器的代码片段
- en: 'Here, you can see that we are using the Relu activation function, and the gradient
    descent solver function is ADAM. We are using a learning rate of 0.0001\. You
    can evaluate the result by referring to the following graph:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到我们正在使用ReLU激活函数，梯度下降求解器函数是ADAM。我们使用的学习率是0.0001。您可以通过参考以下图表来评估结果：
- en: '![The best approach](img/B08394_02_38.jpg)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![最佳方法](img/B08394_02_38.jpg)'
- en: 'Figure 2.38: Code snippet for generating the graph for the actual and predicted
    prices'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.38：生成实际和预测价格图表的代码片段
- en: 'This graph shows that all the data records'' predicted prices follow the actual
    price pattern. You can say that our MLP model works well to predict the stock
    market prices. You can find the code at this GitHub link: [https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb).'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 此图表显示，所有数据记录的预测价格都遵循实际价格模式。您可以说我们的MLP模型在预测股票市场价格方面表现良好。您可以在以下GitHub链接中找到代码：[https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb](https://github.com/jalajthanaki/stock_price_prediction/blob/master/Stock_Price_Prediction.ipynb)。
- en: Summary
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to predict stock prices. We covered the different
    machine learning algorithms that can help us in this. We tried Random Forest Regressor,
    Logistic Regression, and multilayer perceptron. We found out that the multilayer
    perceptron works really well. I really want to discuss something beyond what we
    have done so far. If you are under the impression that using the sentiment analysis
    of news and predictive methods, we can now correctly predict the stock market
    price with a hundred percent accuracy, then you would be wrong. We can't predict
    stock prices with a hundred percent accuracy. Many communities, financial organizations,
    and academic researchers are working in this direction in order to make a stock
    market price predictive model that is highly accurate. This is an active research
    area.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何预测股票价格。我们介绍了可以帮助我们在这一领域的一些不同的机器学习算法。我们尝试了随机森林回归器、逻辑回归和多层感知器。我们发现多层感知器效果非常好。我真的很想讨论一些超出我们目前所做内容的事情。如果你认为通过使用新闻的情感分析和预测方法，我们现在可以以百分之百的准确性正确预测股票市场价格，那么你就错了。我们无法以百分之百的准确性预测股票价格。许多社区、金融机构和学术研究人员正在这个方向上努力，以创建一个高度准确的股票市场价格预测模型。这是一个活跃的研究领域。
- en: So if you are interested in research and freelancing, then you can join some
    pretty cool communities. There are two communities that are quite popular. One
    of these is quantopian ([https://www.quantopian.com/](https://www.quantopian.com/)).
    In this community, you can submit your stock price prediction algorithm, and if
    it outperforms other competitors' algorithms, then you will win a cash price,
    and if you get the license for your algorithm, then you get some profit from transactions
    that will be done through your licensed algorithm. The second community is numer.ai
    ([https://numer.ai/](https://numer.ai/)). This community is similar to quantopian.
    So, the possibilities of this application are limitless. Both communities offer
    some great tutorials. So try something different, and hopefully you will come
    up with a great algorithm.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果你对研究和自由职业感兴趣，那么你可以加入一些相当酷的社区。其中有两个社区非常受欢迎。其中一个就是Quantopian（[https://www.quantopian.com/](https://www.quantopian.com/)）。在这个社区中，你可以提交你的股票价格预测算法，如果它优于其他竞争对手的算法，那么你将赢得现金奖励，如果你获得了你算法的许可，那么你将从通过你许可的算法完成的交易中获得一些利润。第二个社区是numer.ai（[https://numer.ai/](https://numer.ai/)）。这个社区与Quantopian类似。因此，这个应用的潜力是无限的。这两个社区都提供了一些优秀的教程。所以尝试一些不同的事物，希望你能想出一个出色的算法。
- en: In the next chapter, we will tap the retail or e-commerce domain and try to
    figure out some interesting facts about the user behavior dataset and users' social
    footprint. This will help us understand how the company should change their website
    or some functionality on the website. What are the chances of the email campaign
    going well and which type of users will respond to this campaign? Keep reading
    this book! We will discuss all these things in the next chapter.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探索零售或电子商务领域，并试图找出一些关于用户行为数据集和用户社交足迹的有趣事实。这将帮助我们了解公司应该如何改变他们的网站或网站上的某些功能。电子邮件营销活动成功的可能性有多大？哪些类型的用户会对这项活动做出回应？继续阅读这本书！我们将在下一章讨论所有这些内容。
