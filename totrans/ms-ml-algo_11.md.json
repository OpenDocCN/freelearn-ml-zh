["```py\nimport numpy as np\n\nfrom keras.datasets import fashion_mnist\n\n(X_train, _), (_, _) = fashion_mnist.load_data()\n\nnb_samples = 1000\nnb_epochs = 400\nbatch_size = 200\ncode_length = 256\n\nX_train = X_train.astype(np.float32)[0:nb_samples] / 255.0\n\nwidth = X_train.shape[1]\nheight = X_train.shape[2]\n```", "```py\nimport tensorflow as tf\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n    input_images = tf.placeholder(tf.float32, shape=(None, width, height, 1))\n\n    r_input_images = tf.image.resize_images(input_images, (32, 32))\n\n    # Encoder\n    conv_0 = tf.layers.conv2d(inputs=r_input_images,\n                              filters=32,\n                              kernel_size=(3, 3),\n                              strides=(2, 2),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    conv_1 = tf.layers.conv2d(inputs=conv_0,\n                              filters=64,\n                              kernel_size=(3, 3),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    conv_2 = tf.layers.conv2d(inputs=conv_1,\n                              filters=128,\n                              kernel_size=(3, 3),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    # Code layer\n    code_input = tf.layers.flatten(inputs=conv_2)\n\n    code_layer = tf.layers.dense(inputs=code_input,\n                                 units=code_length,\n                                 activation=tf.nn.sigmoid)\n\n    # Decoder\n    decoder_input = tf.reshape(code_layer, (-1, 16, 16, 1))\n\n    convt_0 = tf.layers.conv2d_transpose(inputs=decoder_input,\n                                         filters=128,\n                                         kernel_size=(3, 3),\n                                         strides=(2, 2),\n                                         activation=tf.nn.relu,\n                                         padding='same')\n\n    convt_1 = tf.layers.conv2d_transpose(inputs=convt_0,\n                                         filters=64,\n                                         kernel_size=(3, 3),\n                                         activation=tf.nn.relu,\n                                         padding='same')\n\n    convt_2 = tf.layers.conv2d_transpose(inputs=convt_1,\n                                         filters=32,\n                                         kernel_size=(3, 3),\n                                         activation=tf.nn.relu,\n                                         padding='same')\n\n    convt_3 = tf.layers.conv2d_transpose(inputs=convt_2,\n                                         filters=1,\n                                         kernel_size=(3, 3),\n                                         activation=tf.sigmoid,\n                                         padding='same')\n\n    # Loss\n    loss = tf.nn.l2_loss(convt_3 - r_input_images)\n\n    # Training step\n    training_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n```", "```py\nimport numpy as np\nimport tensorflow as tf\n\nsession = tf.InteractiveSession(graph=graph)\ntf.global_variables_initializer().run()\n\nfor e in range(nb_epochs):\n    np.random.shuffle(X_train)\n\n    total_loss = 0.0\n\n    for i in range(0, nb_samples - batch_size, batch_size):\n        X = np.zeros((batch_size, width, height, 1), dtype=np.float32)\n        X[:, :, :, 0] = X_train[i:i + batch_size, :, :]\n\n        _, n_loss = session.run([training_step, loss], \n                                feed_dict={\n                                    input_images: X\n                                })\n        total_loss += n_loss\n\n    print('Epoch {}) Total loss: {}'.format(e + 1, total_loss))\n```", "```py\nimport numpy as np\n\ncodes = session.run([code_layer], \n                    feed_dict={\n                        input_images: np.expand_dims(X_train, axis=3),\n                    })[0]\n\nprint(np.mean(codes))\n0.5545144\n```", "```py\nimport numpy as np\n\nXs = np.reshape(X_train[0:10], (10, width, height, 1))\n\nYs = session.run([convt_3], \n                 feed_dict={\n                     input_images: Xs\n                })\n\nYs = np.squeeze(Ys[0] * 255.0)\n```", "```py\nimport tensorflow as tf\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n    input_noisy_images = tf.placeholder(tf.float32, shape=(None, width, height, 1))\n    input_images = tf.placeholder(tf.float32, shape=(None, width, height, 1))\n\n    # Encoder\n    conv_0 = tf.layers.conv2d(inputs=input_noisy_images,\n                              filters=32,\n                              kernel_size=(3, 3),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    conv_1 = tf.layers.conv2d(inputs=conv_0,\n                              filters=64,\n                              kernel_size=(3, 3),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    conv_2 = tf.layers.conv2d(inputs=conv_1,\n                              filters=128,\n                              kernel_size=(3, 3),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    # Code layer\n    code_input = tf.layers.flatten(inputs=conv_2)\n\n    code_layer = tf.layers.dense(inputs=code_input,\n                                 units=width * height,\n                                 activation=tf.nn.sigmoid)\n\n    # Decoder\n    decoder_input = tf.reshape(code_layer, (-1, width, height, 1))\n\n    convt_0 = tf.layers.conv2d_transpose(inputs=decoder_input,\n                                         filters=128,\n                                         kernel_size=(3, 3),\n                                         activation=tf.nn.relu,\n                                         padding='same')\n\n    convt_1 = tf.layers.conv2d_transpose(inputs=convt_0,\n                                         filters=64,\n                                         kernel_size=(3, 3),\n                                         activation=tf.nn.relu,\n                                         padding='same')\n\n    convt_2 = tf.layers.conv2d_transpose(inputs=convt_1,\n                                         filters=32,\n                                         kernel_size=(3, 3),\n                                         activation=tf.nn.relu,\n                                         padding='same')\n\n    convt_3 = tf.layers.conv2d_transpose(inputs=convt_2,\n                                         filters=1,\n                                         kernel_size=(3, 3),\n                                         activation=tf.sigmoid,\n                                         padding='same')\n\n    # Loss\n    loss = tf.nn.l2_loss(convt_3 - input_images)\n\n    # Training step\n    training_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n```", "```py\nimport numpy as np\nimport tensorflow as tf\n\nsession = tf.InteractiveSession(graph=graph)\ntf.global_variables_initializer().run()\n\nfor e in range(nb_epochs):\n    total_loss = 0.0\n\n    for i in range(0, nb_samples - batch_size, batch_size):\n        X = np.zeros((batch_size, width, height, 1), dtype=np.float32)\n        X[:, :, :, 0] = X_train[i:i + batch_size, :, :]\n        Xn = np.clip(X + np.random.normal(0.0, 0.2, size=(batch_size, width, height, 1)), 0.0, 1.0)\n\n        _, n_loss = session.run([training_step, loss], \n                                feed_dict={\n                                    input_images: X,\n                                    input_noisy_images: Xn\n                                })\n        total_loss += n_loss\n\n    print('Epoch {}) Total loss: {}'.format(e + 1, total_loss))\n```", "```py\nimport tensorflow as tf\n\n...\n\n# Loss\nsparsity_constraint = tf.reduce_sum(0.001 * tf.norm(code_layer, ord=1, axis=1))\nloss = tf.nn.l2_loss(convt_3 - r_input_images) + sparsity_constraint\n\n...\n```", "```py\nimport numpy as np\n\ncodes = session.run([code_layer], \n                    feed_dict={\n                        input_images: np.expand_dims(X_train, axis=3),\n                    })[0]\n\nprint(np.mean(codes))\n0.45797634\n```", "```py\nimport tensorflow as tf\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n    input_images = tf.placeholder(tf.float32, shape=(batch_size, width, height, 1))\n\n    # Encoder\n    conv_0 = tf.layers.conv2d(inputs=input_images,\n                              filters=32,\n                              kernel_size=(3, 3),\n                              strides=(2, 2),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    conv_1 = tf.layers.conv2d(inputs=conv_0,\n                              filters=64,\n                              kernel_size=(3, 3),\n                              strides=(2, 2),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    conv_2 = tf.layers.conv2d(inputs=conv_1,\n                              filters=128,\n                              kernel_size=(3, 3),\n                              activation=tf.nn.relu,\n                              padding='same')\n\n    # Code layer\n    code_input = tf.layers.flatten(inputs=conv_2)\n\n    code_mean = tf.layers.dense(inputs=code_input,\n                                units=width * height)\n\n    code_log_variance = tf.layers.dense(inputs=code_input,\n                                        units=width * height)\n\n    code_std = tf.sqrt(tf.exp(code_log_variance))\n\n    # Normal samples\n    normal_samples = tf.random_normal(mean=0.0, stddev=1.0, shape=(batch_size, width * height))\n\n    # Sampled code\n    sampled_code = (normal_samples * code_std) + code_mean\n\n    # Decoder\n    decoder_input = tf.reshape(sampled_code, (-1, 7, 7, 16))\n\n    convt_0 = tf.layers.conv2d_transpose(inputs=decoder_input,\n                                         filters=64,\n                                         kernel_size=(3, 3),\n                                         strides=(2, 2),\n                                         activation=tf.nn.relu,\n                                         padding='same')\n\n    convt_1 = tf.layers.conv2d_transpose(inputs=convt_0,\n                                        filters=32,\n                                        kernel_size=(3, 3),\n                                        strides=(2, 2),\n                                        activation=tf.nn.relu,\n                                        padding='same')\n\n    convt_2 = tf.layers.conv2d_transpose(inputs=convt_1,\n                                        filters=1,\n                                        kernel_size=(3, 3),\n                                        padding='same')\n\n    convt_output = tf.nn.sigmoid(convt_2)\n\n    # Loss\n    reconstruction = tf.nn.sigmoid_cross_entropy_with_logits(logits=convt_2, labels=input_images)\n    kl_divergence = 0.5 * tf.reduce_sum(tf.square(code_mean) + tf.square(code_std) - tf.log(1e-8 + tf.square(code_std)) - 1, axis=1) \n\n    loss = tf.reduce_sum(reconstruction) + kl_divergence\n\n    # Training step\n    training_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n```"]