["```py\nimport matplotlib.pyplot as plt\nlabel = ['model A', 'model B']\ncounts = [3, 5]\nedu_label = ['BS', 'MS', 'PhD']\nedu_counts = [10, 5, 2]\nfig, ax = plt.subplots(1, 2, figsize=(12, 5))\nax[0].bar(label, counts)\nax[0].set_title('Counts of Machine Models')\nax[0].set_ylabel('Count')\nax[0].set_xlabel('Machine Model')\nax[1].bar(edu_label, edu_counts)\nax[1].set_title('Counts of Education Level')\nax[1].set_ylabel('Count')\nax[1].set_xlabel('Education Level')\nfig.show()\n```", "```py\nfrom scipy.stats import skewnorm\nimport matplotlib.pyplot as plt\na = 4\nx = skewnorm.rvs(a, size=3000) + 0.5\nx = x[x > 0]\ndfw_highs = [\n    85, 87, 75, 88, 80, 86, 90, 94, 93, 92, 90, 92, 94,\n    93, 97, 90, 95, 96, 96, 95, 92, 70, 79, 73, 88, 92,\n    94, 93, 95, 76, 78, 86, 81, 95, 77, 71, 69, 88, 86,\n    89, 84, 82, 77, 84, 81, 79, 75, 75, 91, 86, 86, 84,\n    82, 68, 75, 78, 82, 83, 85]\nfig, ax = plt.subplots(1,2, figsize=(12, 5))\nax[0].hist(x, bins=30)\nax[0].set_xlabel('Wait Time (hr)')\nax[0].set_ylabel('Frequency')\nax[0].set_title('Wait Times');\nax[1].hist(dfw_highs, bins=7)\nax[1].set_title('High Temperatures for DFW (4/2022-5/2022)')\nax[1].set_ylabel('Frequency')\nax[1].set_xlabel('Temperature (F)')\nfig.show()\n```", "```py\nfrom scipy.stats import mode\nm = mode([1,2,3,4,4,4,5,5])\nprint(\n    f\"The mode is {m.mode[0]} with a count of\"\n    f\" {m.count[0]} instances\"\n)\n# The mode is 4 with a count of 3 instances\n```", "```py\nimport numpy as np\nvalues = [85, 99, 70, 71, 86, 88, 94, 105]\nmedian = np.median(values)\nprint(f\"The median value is {median:.2f}\")\n# The median value is 87.00\n```", "```py\nimport numpy as np\nvalues = [85, 99, 70, 71, 86, 88, 94]\nmean = np.mean(values)\nprint(f\"The mean value is {mean:.1f}\")\n# The mean value is 84.7\n```", "```py\nimport numpy as np\nvalues = [85, 99, 70, 71, 86, 88, 94, 105]\nmax_value = np.max(values)\nmin_value = np.min(values)\nrange_ = max_value - min_value\nprint(f\"The data have a range of {range_}\"\n      f\" with max of {max_value}\"\n      f\" and min of {min_value}\")\n# The data have a range of 35 with max of 105 and min of 70\n```", "```py\nimport numpy as np\nfrom scipy import stats\nvalues = [85, 99, 70, 71, 86, 88, 94]\nquartiles = np.quantile(values, [0.25, 0.5, 0.75],\n    method=\"closest_observation\")\nprint(f\"The quartiles are Q1: {quartiles[0]},\n    Q2: {quartiles[1]}, Q3: {quartiles[2]}\")\niqr = stats.iqr(values,interpolation='closest_observation')\nprint(f\"The interquartile range is {iqr}\")\n# The quartiles are Q1: 71, Q2: 85, Q3: 88\n# The interquartile range is 17\n```", "```py\nimport numpy as np\nfrom scipy import stats\nvalues = stats.norm.rvs(10, size=3000)\nq1, q3 = np.quantile(values, [.25, .75],\n    method='closest_observation')\niqr = stats.iqr(values,interpolation='closest_observation')\nlower_fence = q1 - iqr * 1.5\nupper_fence = q3 + iqr * 1.5\n# may vary due to randomness in data generation\nprint(f\"The lower fence is {lower_fence:.2f} and the upper\n    fence is {upper_fence:.2f}\")\n# The lower fence is 7.36 and the upper fence is 12.67\n```", "```py\nimport numpy as np\nvalues = [85, 99, 70, 71, 86, 88, 94]\nvariance = np.var(values)\nstandard_dev = np.std(values)\nprint(f\"The variance is {variance:.2f} and the standard\n    deviation is {standard_dev:.2f}\")\n# The variance is 101.06 and the standard deviation is 10.05\n```", "```py\nfrom scipy.stats import skewnorm, norm\nfrom scipy.stats import skew as skew_calc\n# generate data\nskew_left = -skewnorm.rvs(10, size=3000) + 4\nskew_right = skewnorm.rvs(10, size=3000) + 3\nsymmetric = norm.rvs(10, size=3000)\n# calculate skewness\nskew_left_value = skew_calc(skew_left)\nskew_right_value = skew_calc(skew_right)\nsymmetric_value = skew_calc(symmetric)\n# Output may vary some due to randomness of generated data\nprint(f\"The skewness value of this left skewed\n    distribution is {skew_left_value:.3f}\")\nprint(f\"The skewness value of this right skewed\n    distribution is {skew_right_value:.3f}\")\nprint(f\"The skewness value of this symmetric distribution\n    is {symmetric_value:.3f}\")\n```", "```py\nfrom scipy.stats import norm\nfrom scipy.stats import gennorm\nfrom scipy.stats import kurtosis\n# generate data\nlight_tailed = gennorm.rvs(5, size=3000)\nsymmetric = norm.rvs(10, size=3000)\nheavy_tailed = gennorm.rvs(1, size=3000)\n# calculate skewness\nlight_tailed_value = kurtosis(light_tailed)\nheavy_tailed_value = kurtosis(heavy_tailed)\nsymmetric_value = kurtosis(symmetric)\n# Output may vary some due to randomness of generated data\nprint(f\"The kurtosis value of this light-tailed\n    distribution is {light_tailed_value:.3f}\")\nprint(f\"The kurtosis value of this heavy_tailed\n    distribution is {heavy_tailed_value:.3f}\")\nprint(f\"The kurtosis value of this normal\n    distribution is {symmetric_value:.3f}\")\n```", "```py\nimport matplotlib.pyplot as plt, statsmodels.api as sm, pandas as pd, numpy as np, scipy.stats\ndf_duncan = sm.datasets.get_rdataset(\"Duncan\",\n    \"carData\").data\ndf_duncan.loc[df_duncan['type'] == 'prof',\n    'type'] = 'professional'\ndf_duncan.loc[df_duncan['type'] == 'wc',\n    'type'] = 'white-collar'\ndf_duncan.loc[df_duncan['type'] == 'bc',\n    'type'] = 'blue-collar'\ndf_professional = df_duncan.loc[(\n    df_duncan['type'] == 'professional')]\ndf_blue_collar = df_duncan.loc[(\n    df_duncan['type'] == 'blue-collar')]\n```", "```py\ndef plot_distributions(n_replicas, professional_sample, blue_collar_sample, professional_label, blue_collar_label, p=5):\n    fig, ax = plt.subplots(2, 1, figsize=(10,8))\n    ax[0].hist(professional_sample, alpha=.3, bins=20)\n    ax[0].axvline(professional_sample.mean(),\n        color='black', linewidth=5)\n# sampling distribution mean\n    ax[0].axvline(np.percentile(professional_sample, p/2.),\n        color='red', linewidth=3, alpha=0.99)\n# 95% CI Lower limit (if bootstrapping)\n    ax[0].axvline(np.percentile(professional_sample,\n        100-p/2.), color='red', linewidth=3, alpha=0.99)\n# 95% CI Upper Limit  (if bootstrapping)\n    ax[0].title.set_text(str(professional_label) +\n        \"\\nn = {} Resamples\".format(n_replicas))\n    ax[1].hist(blue_collar_sample, alpha=.3, bins=20)\n    ax[1].axvline(blue_collar_sample.mean(), color='black',\n        linewidth=5) # sampling distribution mean\n    ax[1].axvline(np.percentile(blue_collar_sample, p/2.),\n        color='red', linewidth=3, alpha=0.99)\n# 95% CI Lower limit (if bootstrapping)\n    ax[1].axvline(np.percentile(blue_collar_sample,\n        100-p/2.), color='red', linewidth=3, alpha=0.99)\n# 95% CI Upper Limit (if bootstrapping)\n    ax[1].title.set_text(str(blue_collar_label) +\n        \"\\nn = {} Resamples\".format(n_replicas))\n    if n_replicas > 1:\n        print(\"Lower confidence interval limit: \",\n            np.percentile(round(professional_sample,4),\n            p/2.))\n        print(\"Upper confidence interval limit: \",\n            np.percentile(round(professional_sample,4),\n            100-p/2.))\n        print(\"Mean: \", round(professional_sample,\n            4).mean())\n        print(\"Standard Error: \",\n            round(professional_sample.std() /\n            np.sqrt(n_replicas), 4) )\n        print(\"Lower confidence interval limit: \",\n            np.percentile(round(blue_collar_sample,4),\n            p/2.))\n        print(\"Upper confidence interval limit: \",\n            np.percentile(round(blue_collar_sample,4),\n            100-p/2.))\n        print(\"Mean: \", round(blue_collar_sample,4).mean())\n        print(\"Standard Error: \",\n            round(blue_collar_sample.std() /\n            np.sqrt(n_replicas), 4) )\n    else:\n        print(\"At least two samples required to create the following statistics:\\nConfidence Intervals\\nMean\\nStandard Error\")\n```", "```py\nn_replicas=0\nplot_distributions(n_replicas=n_replicas,\nprofessional_sample=df_professional['income'],\n    blue_collar_sample=df_blue_collar['income'],\n    professional_label=\"Professional\",\n    blue_collar_label=\"Blue Collar\")\n```", "```py\nn_replicas = 1000\nprofessional_bootstrap_means = pd.Series(\n    [df_professional.sample(frac=0.5, replace=True)\n    ['income'].mean() for i in range(n_replicas)])\nblue_collar_bootstrap_means = pd.Series(\n    [df_blue_collar.sample(frac=0.5, replace=True)\n    ['income'].mean() for i in range(n_replicas)])\n```", "```py\nscipy.stats.sem(professional_bootstrap_means)\nscipy.stats.sem(blue_collar_bootstrap_means)\n```", "```py\ndf_prof_corr = df_professional.sample(n=10)\ndf_blue_corr = df_blue_collar.sample(n=10)\ncorr, _ = scipy.stats.pearsonr(df_prof_corr['income'],\n    df_blue_corr['income'])\n```", "```py\nn_replicas = n_replicas\nprofessional_bootstrap_means = pd.Series([df_prof_corr.sample(frac=0.5,replace=False).income.mean()for i in range(n_replicas)])\nblue_collar_bootstrap_means = pd.Series([df_blue_corr.sample(frac=0.5, replace=False).income.mean() for i in range(n_replicas)])\ncorr, _ = scipy.stats.pearsonr(\n    professional_bootstrap_means,\n    blue_collar_bootstrap_means)\nprint(corr)\n```", "```py\nfrom itertools import permutations\n# list of 10 people in the party\npeople = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10']\n# all the ways that the 3 prizes are distributed\nperm = permutations(people, 3)\nlist_perm = list(perm)\nprint(f\"There are {len(list_perm)} ways to distribute the prizes!\")\n```", "```py\nprint(f\"The 10 first ways to distribute the prizes: \\n\n    {list_perm[:10]} \")\n```", "```py\n#list of 10 people in the party\npeople = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10']\n# all the ways that the 10 different gifts are distributed\nperm = permutations(people)\nlist_perm = list(perm)\nprint(f\"There are {len(list_perm)}\n    ways to distributed the gifts!\")\n```", "```py\n from itertools import combinations\n# list of 10 people in the party\npeople = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10']\n# all the ways that the 3 prizes are distributed\ncomb = combinations(people, 3)\nlist_comb = list(comb)\nprint(f\"There are {len(list_comb)} ways to distribute the prizes!\")\n```", "```py\nimport numpy as np\n# create permutation testing function\ndef permutation_testing(A,B,n_iter=1000):\n#A, B are 2 lists of samples to test the hypothesis,\n#n_iter is number of iterations with the default is 1000\n    differences = []\n    P = np.array(A+B)\n    original_mean = np.array(A).mean()- np.array(B).mean()\n    for i in range(n_iter):\n      np.random.shuffle(P)#create a random permutation of P\n      A_new = P[:len(A)] # having the same size of A\n      B_new = P[-len(B):] # having the same size of B\n      differences.append(A_new.mean()-B_new.mean())\n    #Calculate p_value\n    p_value = round(1-(float(len(np.where(\n        differences<=original_mean)[0]))/float(n_iter)),2)\n    return p_value\n```", "```py\nA = [3,5,4]\nB = [43,41,56,78,54]\npermutation_testing(A,B,n_iter=10000)\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(42) # for reproducible purpose\n# create a random data\ndf = np.random.beta(a=1, b=10, size = 10000)\ndf_log = np.log(df) #log transformation\ndf_sqrt = np.sqrt(df) # Square Root transformation\ndf_cbrt = np.cbrt(df) # Cube Root transformation\nplt.figure(figsize = (10,10))\nplt.subplot(2,2,1)\nplt.hist(df)\nplt.title(\"Original Data\")\nplt.subplot(2,2,2)\nplt.hist(df_log)\nplt.title(\"Log Transformation\")\nplt.subplot(2,2,3)\nplt.hist(df_sqrt)\nplt.title(\"Square Root Transformation\")\nplt.subplot(2,2,4)\nplt.hist(df_cbrt)\nplt.title(\"Cube Root Transformation\")\nplt.show()\n```"]