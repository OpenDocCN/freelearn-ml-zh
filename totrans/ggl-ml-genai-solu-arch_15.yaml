- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: ML Governance and the Google Cloud Architecture Framework
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习治理与谷歌云架构框架
- en: As technologists, we often, of course, find the technological aspects of **machine
    learning** (**ML**) to be the most fun and exciting parts, while legal and regulatory
    concepts don’t always inspire us quite as much. However, these concepts are required
    to build robust solutions at scale in production. They are what help us make the
    transition from hobbyist activities to designing reliable systems that can be
    vital to a company’s success or even affect millions of people’s lives.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 作为技术人员，我们当然经常发现**机器学习**（**ML**）的技术方面是最有趣和最令人兴奋的部分，而法律和监管概念并不总是那么吸引我们。然而，这些概念对于在生产的规模上构建稳健的解决方案是必需的。它们帮助我们从业余爱好活动过渡到设计可靠系统，这对公司的成功至关重要，甚至可能影响数百万人的生活。
- en: 'With that in mind, this chapter will cover the following subjects:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，本章将涵盖以下主题：
- en: ML governance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习治理
- en: An overview of the Google Cloud Architecture Framework
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谷歌云架构框架概述
- en: Architecture Framework concepts about AI/ML workloads on Google Cloud
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于谷歌云架构框架中AI/ML工作负载的概念
- en: Let’s go ahead and dive right into our first topic.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接深入我们的第一个主题。
- en: ML governance
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习治理
- en: ML governance refers to everything that’s required to manage ML models within
    an organization, throughout the entire model development life cycle. As models
    can play a significant role in critical decision-making processes, it’s important
    to ensure that they are transparent, reliable, fair, and secure, and we need to
    implement structured frameworks to achieve these goals. These frameworks include
    policies and best practices that ensure responsible and ethical use of data and
    ML technologies.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习治理指的是在组织内部管理机器学习模型所需的一切，贯穿整个模型开发生命周期。由于模型在关键决策过程中可以发挥重要作用，因此确保它们是透明的、可靠的、公平的和安全的至关重要，我们需要实施结构化的框架来实现这些目标。这些框架包括政策和最佳实践，确保数据和使用机器学习技术的负责任和道德使用。
- en: When discussing ML governance in this chapter, I will also include data governance
    in the scope of the discussion, because the use of data is so inherent in the
    ML life cycle. Let’s start there.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章讨论机器学习治理时，我还会将数据治理纳入讨论范围，因为数据的使用在机器学习生命周期中是如此内在。让我们从这里开始。
- en: Data governance
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据治理
- en: When it comes to managing data in the ML life cycle, there are a number of aspects
    that we need to consider, such as data quality, lineage, privacy, security, and
    retention. Let’s take a look at each of these in more detail.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到管理机器学习生命周期中的数据时，我们需要考虑许多方面，例如数据质量、血缘、隐私、安全和保留。让我们更详细地看看这些方面。
- en: Data security, privacy, and access control
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据安全、隐私和访问控制
- en: Of all the aspects of a data governance strategy, data security is arguably
    the most important. Data security incidents tend to make headline news, and those
    are not the kinds of news headlines you want to be responsible for!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有数据治理策略的方面中，数据安全可以说是最重要的。数据安全事件往往会成为头条新闻，而这些并不是你希望负责的新闻头条！
- en: Fundamental to data security is the concept of data access control, which, as
    the name suggests, focuses on who can access the data and how they can access
    the data. The worst-case scenario is that somebody from outside the company gains
    access to sensitive data and leaks it publicly or uses it for nefarious purposes
    such as ransom or sabotage.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据安全的基本概念是数据访问控制，正如其名称所暗示的，它关注的是谁可以访问数据以及他们如何访问数据。最坏的情况是，公司外部的人获得了敏感数据的访问权限，并将其公开泄露或用于勒索或破坏等恶意目的。
- en: When it comes to data security, my favorite term is **defense-in-depth** (**DiD**),
    which alludes to the fact that a thorough data security strategy consists of using
    many different tools to protect the data and other resources. In the following
    sub-sections, I will outline steps we can take to secure our data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到数据安全时，我最喜欢的术语是**深度防御**（**DiD**），它暗示了一个全面的数据安全策略包括使用许多不同的工具来保护数据和其它资源。在接下来的子章节中，我将概述我们可以采取的步骤来确保我们的数据安全。
- en: Data categorization
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据分类
- en: 'Before defining security policies for your data, it’s important to establish
    a categorization system in order to understand which elements of data need more
    focus in terms of protection. For instance, data that is published openly on your
    website, such as product descriptions and prices, is generally not considered
    to be top secret, whereas your customers’ credit card details are highly sensitive.
    You can categorize your data in terms of tiers, such as the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义数据的安全策略之前，建立一个分类系统以了解哪些数据元素在保护方面需要更多关注是很重要的。例如，公开发布在你网站上的数据，如产品描述和价格，通常不被认为是绝密信息，而你的客户的信用卡详情则是高度敏感的。你可以根据以下层级对数据进行分类：
- en: '**Tier 0**: Highly-sensitive, such as customer passwords and credit card details'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零层**：高度敏感，例如客户密码和信用卡详情'
- en: '**Tier 1**: Sensitive, such as customer purchase or transaction history'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一层**：敏感，例如客户购买或交易历史'
- en: '**Tier 2**: Somewhat sensitive, such as customer addresses and phone numbers'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二层**：有些敏感，例如客户地址和电话号码'
- en: '**Tier 3**: Non-sensitive, such as publicly viewable information'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三层**：非敏感，例如公开可查看的信息'
- en: These are just examples; you would need to work with your organization’s information
    security experts to determine what categories would make the most sense for your
    organization.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是示例；你需要与你的组织信息安全专家合作，以确定哪些类别对你的组织最有意义。
- en: After categorizing our data, let’s discuss how we can secure it.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在对数据进行分类之后，让我们讨论如何保护它们。
- en: Network security
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 网络安全
- en: We can look at the DiD approach as layers in an onion. At the outermost layer,
    we begin with network security. If unintended users of the data do not have a
    network path to the data, then that’s a really solid foundation in your security
    strategy. Network security practices include setting up devices such as firewalls
    to control what kinds of traffic are allowed to enter a protected network. Google
    Cloud provides such devices, as well as other network security constructs, such
    as **Virtual Private Cloud** (**VPC**), which allows you to set up your own private
    networks and control how to access them, and **VPC Service Controls** (**VPC-SC**),
    which enables you to create a security perimeter around your resources to prevent
    data exfiltration.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将DiD方法看作是洋葱的层。在最外层，我们从网络安全开始。如果数据的不当用户没有访问数据的网络路径，那么这将是你的安全策略中的一个非常坚实的基础。网络安全实践包括设置诸如防火墙之类的设备来控制允许进入受保护网络的流量类型。Google
    Cloud提供了这样的设备，以及其他网络安全结构，例如**虚拟专用云**（**VPC**），它允许你设置自己的私有网络并控制如何访问它们，以及**VPC服务控制**（**VPC-SC**），它使你能够围绕你的资源创建安全边界以防止数据泄露。
- en: Authentication and authorization
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 身份验证和授权
- en: The next layer in the onion is authentication and authorization to grant or
    deny permissions to access resources. Even if somebody gets access to a protected
    network, the next step is to determine which resources they are allowed to access
    and what actions they are allowed to perform on those resources. You need to ensure
    that the data can be accessed only by people and systems that are authorized to
    do so, and authorization should be based on business criticality. In other words,
    a person or system should only be able to access a piece of data if they need
    such access to perform a required business function. At all times, you should
    be able to easily determine who (or what) has access to which data, and why.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 洋葱的下一层是身份验证和授权，以授予或拒绝访问资源的权限。即使有人获得了访问受保护网络的权限，下一步就是确定他们允许访问哪些资源以及他们可以在这些资源上执行哪些操作。你需要确保只有被授权的人员和系统才能访问数据，并且授权应基于业务关键性。换句话说，一个人或系统只有在他们需要这样的访问来执行所需的业务功能时才能访问某份数据。在任何时候，你都应能够轻松地确定谁（或什么）可以访问哪些数据，以及为什么。
- en: Google Cloud **Identity and Access Management** (**IAM**) can be used to configure
    and enforce such permissions, or, for software components, additional mechanisms
    such as **Transport Layer Security** (**TLS**) authentication can also be used.
    A little later in this section, we will also cover data cataloging with Google
    Cloud Dataplex. Dataplex and Google Cloud BigLake can be used to make it easier
    for companies to manage and enforce permissions for accessing their data resources.
    Google Cloud BigQuery offers additional data security mechanisms such as row-level
    and column-level access control, meaning that not only can you grant or restrict
    access to tables within BigQuery, but you can more granularly grant or restrict
    access to specific rows and/or columns within those tables. This provides additional
    flexibility to protect resources from unintended access. For example, with column-level
    security, you could configure that only people in the finance department can view
    columns that contain customers’ credit card details, while other employees and
    systems cannot. With row-level security, you could configure that sales representatives
    can only view details for customers in their region and not in other regions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud **身份和访问管理**（**IAM**）可用于配置和强制执行此类权限，或者对于软件组件，还可以使用如**传输层安全性**（**TLS**）认证等额外机制。在本节稍后，我们还将介绍使用Google
    Cloud Dataplex进行数据编目。Dataplex和Google Cloud BigLake可用于使公司更容易管理和强制执行对其数据资源的访问权限。Google
    Cloud BigQuery提供额外的数据安全机制，如行级和列级访问控制，这意味着您不仅可以授予或限制对BigQuery中表的访问权限，还可以更细致地授予或限制对那些表中的特定行和/或列的访问权限。这为保护资源免受意外访问提供了额外的灵活性。例如，使用列级安全，您可以配置只有财务部门的人员可以查看包含客户信用卡详情的列，而其他员工和系统则不能。使用行级安全，您可以配置销售代表只能查看其区域客户的详细信息，而不能查看其他区域的客户。
- en: Data encryption
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据加密
- en: At the innermost layer are the data resources themselves. Best practices suggest
    that data should be encrypted as a further security measure. In that case, even
    if a malicious or unintended user gets access to the data, they would need the
    encryption keys to unencrypt the data. It goes without saying that encryption
    keys should be stored in a highly secure manner in a separate system, with all
    of the layers of security implemented to protect them. Again, Google Cloud provides
    tools to implement all of those layers of security mechanisms, including encryption
    and key management using Google Cloud Key Management.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在最内层是数据资源本身。最佳实践建议数据应加密作为进一步的安全措施。在这种情况下，即使恶意或非故意用户获得了对数据的访问权限，他们也需要解密密钥来解密数据。不言而喻，加密密钥应以高度安全的方式存储在独立的系统中，并实施所有安全层来保护它们。再次强调，Google
    Cloud提供了实施所有这些安全机制的工具，包括使用Google Cloud密钥管理进行加密和密钥管理。
- en: Logging and auditing
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 记录和审计
- en: 'In addition to all of those mechanisms, a strong data security strategy should
    incorporate auditing and logging implementations to monitor data access and modifications
    and support audits and forensic investigations to detect or investigate policy
    violations and data breaches. Google Cloud Logging and Audit Logs can be used
    for those purposes. *Figure 13**.1* shows what kinds of logs can be tracked by
    Google Cloud Audit Logs:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了所有这些机制之外，强大的数据安全策略应结合审计和日志实施来监控数据访问和修改，并支持审计和取证调查以检测或调查策略违规和数据泄露。Google Cloud日志和审计日志可用于这些目的。*图13.1*显示了Google
    Cloud审计日志可以跟踪哪些类型的日志：
- en: '![Figure 13.1: Audit log types in Google Cloud Audit Logs](img/B18143_13_1.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1：Google Cloud审计日志中的审计日志类型](img/B18143_13_1.jpg)'
- en: 'Figure 13.1: Audit log types in Google Cloud Audit Logs'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1：Google Cloud审计日志中的审计日志类型
- en: As we can see in *Figure 13**.1*, there are three types of logs that we can
    capture using Google Cloud Audit Logs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图13.1*所示，我们可以使用Google Cloud审计日志捕获三种类型的日志。
- en: Data privacy
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据隐私
- en: While intrinsically related to data security, data privacy more specifically
    focuses on the lawful, ethical, and safe handling of **personal information**
    (**PI**). It is one of the most important aspects of data security because privacy
    violations can severely damage a company’s reputation and customer trust.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然与数据安全内在相关，但数据隐私更具体地关注于**个人信息**（**PI**）的合法、道德和安全处理。这是数据安全最重要的方面之一，因为隐私侵犯可能会严重损害公司的声誉和客户信任。
- en: Not only that, but they can incur serious legal ramifications. There are numerous
    international standards and regulations that govern data privacy and protection,
    such as the **General Data Protection Regulation** (**GDPR**) in the **European
    Union** (**EU**), the **California Consumer Privacy Act** (**CCPA**) in the US,
    and many others globally. These regulations outline rules about data handling,
    such as collection, storage, processing, and sharing. Navigating these regulations
    and ensuring compliance in how your systems handle data can be quite challenging.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，他们还可能招致严重的法律后果。有许多国际标准和法规管理数据隐私和保护，例如欧盟的**通用数据保护条例**（**GDPR**），美国的**加州消费者隐私法案**（**CCPA**），以及全球许多其他法规。这些法规概述了数据处理规则，如收集、存储、处理和共享。遵守这些法规并确保系统处理数据的合规性可能相当具有挑战性。
- en: It can also be a challenge to keep track of sensitive data that may be dispersed
    throughout your datasets. Imagine a company that has petabytes of data that comes
    from many different sources, such as credit card readers in stores or customer-facing
    online forms. It’s easy to identify that data being transmitted from a credit
    card machine needs to be protected, but this may not be as obvious for other data
    interfaces. For example, perhaps customers are accidentally entering their credit
    card details into online form fields that are not intended for that purpose (for
    example, if a customer accidentally pastes their credit card details into a field
    that was not intended for entering credit card details). Such fields may not be
    considered sensitive and therefore do not get any special attention from a security
    perspective. The Google Cloud Sensitive Data Protection service, which now incorporates
    the Google Cloud **Data Loss Prevention** (**DLP**) tool, can help to identify
    and protect sensitive information in your datasets. If sensitive data is found,
    you can use the Sensitive Data Protection service to implement protection mechanisms
    such as de-identification, masking, tokenization, and redaction.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪散布在数据集各个部分中的敏感数据也可能是一项挑战。想象一家拥有来自许多不同来源的PB级数据的公司，例如商店中的信用卡读取器或面向客户的在线表单。很容易识别从信用卡机传输的数据需要受到保护，但对于其他数据接口来说，这可能并不那么明显。例如，也许客户不小心将信用卡详细信息输入到非此目的的在线表单字段中（例如，如果客户不小心将信用卡详细信息粘贴到未打算输入信用卡详细信息的字段中）。这些字段可能不被视为敏感，因此从安全角度没有得到任何特殊关注。现在集成了谷歌云**数据丢失预防**（**DLP**）工具的谷歌云**敏感数据保护**服务可以帮助识别和保护数据集中的敏感信息。如果发现敏感数据，可以使用敏感数据保护服务实施保护机制，如去标识化、掩码、令牌化和编辑。
- en: 'In the context of data security, privacy, and access control, it’s important
    to highlight the concept of shared responsibilities and shared fate on Google
    Cloud. Rather than risking misstating legal terminology here, I instead recommend
    reading Google Cloud’s official policy on this topic, which can be found at the
    following URL:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据安全、隐私和访问控制方面，强调在谷歌云平台上的共同责任和共同命运的概念非常重要。为了避免在这里错误地表述法律术语，我建议阅读谷歌云关于此主题的官方政策，该政策可以在以下网址找到：
- en: '[https://cloud.google.com/architecture/framework/security/shared-responsibility-shared-fate](https://cloud.google.com/architecture/framework/security/shared-responsibility-shared-fate)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/architecture/framework/security/shared-responsibility-shared-fate](https://cloud.google.com/architecture/framework/security/shared-responsibility-shared-fate)'
- en: Before we move on to discuss ML model governance, we will round out this section
    with a discussion of data quality, cataloging, and lineage.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讨论机器学习模型治理之前，我们将通过讨论数据质量、编目和血缘关系来结束本节。
- en: Data quality, cataloging, and lineage
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据质量、编目和血缘关系
- en: Considering that data can be such a valuable resource for a company, it’s important
    to establish practices that ensure the accuracy, consistency, discoverability,
    and (depending on the use case) timeliness of data. For example, considering that
    data is often used to make important business decisions, inaccurate or out-of-date
    data could have negative impacts on a company’s business. This also applies to
    business decisions that are automated by ML models. If we feed inaccurate data
    into an ML model, we will get inaccurate predictions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到数据对公司来说可能是一项宝贵的资源，因此建立确保数据准确性、一致性、可发现性以及（根据用例）及时性的实践至关重要。例如，考虑到数据通常用于做出重要的商业决策，不准确或过时的数据可能会对公司业务产生负面影响。这也适用于由机器学习模型自动化的商业决策。如果我们向机器学习模型输入不准确的数据，我们将得到不准确的预测。
- en: An effective data governance strategy starts with clear policies, responsibilities,
    and standards for data quality. We then need to establish frameworks to measure
    and monitor data quality factors. Best practices in this regard include regular
    data cleaning processes for correcting data errors, de-duplication, and filling
    in missing values, as well as automation mechanisms such as regular, automated
    data quality checks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有效的数据治理策略始于明确的数据政策、责任和标准，以确保数据质量。然后我们需要建立框架来衡量和监控数据质量因素。在此方面，最佳实践包括定期的数据清理过程，用于纠正数据错误、去重和填充缺失值，以及自动化机制，如定期的自动数据质量检查。
- en: Data discoverability is also an important factor. After all, even if you have
    created pristinely curated datasets, they are not very useful if nobody knows
    they exist. When companies have well-established data management practices, it’s
    easier for data producers and consumers to know exactly where their data is and
    the current status of that data, at any given time. In such companies, a robust
    data catalog forms the heart of the company’s data infrastructure. I’ve worked
    with many clients over the years in various consulting roles, and you’d be surprised
    how many companies operate without well-defined data management strategies. Given
    that data can be the life-blood of an organization, it’s surprising to learn that
    many companies are not fully aware of exactly what data they own. Various systems
    throughout the company are producing and gathering data all day every day, but
    if that data is not being cataloged in some way, it may simply sit in silos in
    remote, disparate parts of the company, unavailable and unknown to most of the
    rest of the organization. Bear in mind that data can be used for all kinds of
    interesting business use cases. If you don’t know what data you have access to,
    you may be missing out on significant business opportunities.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的可发现性也是一个重要因素。毕竟，即使你创建了精心策划的数据集，如果没有人知道它们的存在，它们也并不很有用。当公司建立了良好的数据管理实践时，数据生产者和消费者更容易确切地知道他们的数据在哪里以及数据的当前状态，在任何给定时间。在这样的公司中，一个强大的数据目录构成了公司数据基础设施的核心。多年来，我在各种咨询角色中与许多客户合作过，你会惊讶地发现有多少公司没有明确的数据管理策略。鉴于数据可能是组织的生命线，了解到许多公司并不完全清楚他们拥有哪些数据，这令人惊讶。公司内各种系统全天候都在产生和收集数据，但如果这些数据没有以某种方式编目，它们可能只是简单地坐在公司偏远、分散的部分的孤岛中，对大多数组织来说既不可用也不为人知。请记住，数据可以用于各种有趣的企业用例。如果你不知道你有什么数据可以访问，你可能会错失重大的商业机会。
- en: It’s also important to implement data lineage tracking to understand where data
    comes from and how it gets transformed as it moves through various processing
    systems within a company. If I find a piece of data somewhere in my company, I
    want to know how it got there and every step it took along the way. Which systems
    did it pass through? What did those systems do to the data? Are there intermediate
    datasets that were created by those other systems in various parts of the company?
    This is not only important from a business operations perspective but can be required
    for compliance purposes. For example, if you need to comply with data sovereignty
    regulations, you better know where your data is at all times. If a customer decides
    to exercise their right to be forgotten in markets that are subject to GDPR –
    or other relevant regulations – you will have a really hard time complying if
    you do not have a good handle on your data. Similarly, if a data breach occurs,
    data lineage can help identify what data was compromised and understand the potential
    impacts and recovery steps needed.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 实施数据血缘追踪同样重要，以便了解数据来源以及它在公司内部各种处理系统中如何被转换。如果我在我公司某个地方找到一些数据，我想知道它是如何到达那里的，以及它走过的每一步。它通过了哪些系统？这些系统对数据做了什么？在其他公司各个部分，那些其他系统是否创建了中间数据集？这不仅从业务运营的角度来看很重要，而且在合规性方面可能也是必需的。例如，如果您需要遵守数据主权法规，您最好始终知道您的数据在哪里。如果客户决定在受
    GDPR 或其他相关法规约束的市场行使被遗忘的权利，如果您没有很好地掌握您的数据，您将很难遵守。同样，如果发生数据泄露，数据血缘可以帮助确定哪些数据被泄露，并了解潜在的
    影响 和所需的恢复步骤。
- en: Fortunately, Google Cloud provides numerous tools to help with each of the aforementioned
    activities, such as Dataproc and Dataflow for cleaning and processing data, and
    Dataplex for cataloging, data quality, and data lineage tracking.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Google Cloud 提供了众多工具来帮助完成上述各项活动，例如 Dataproc 和 Dataflow 用于数据清洗和处理，以及 Dataplex
    用于目录管理、数据质量和数据血缘追踪。
- en: Next, we will discuss ML model governance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论机器学习模型治理。
- en: ML model governance
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习模型治理
- en: In this section, we discuss the aspects required to ensure that the models we
    build and deploy are reliable, scalable, and secure and that they continue to
    meet those requirements on an ongoing basis. There are a number of factors that
    we need to incorporate in order to achieve this goal, which we discuss in the
    following sub-sections.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论确保我们构建和部署的模型可靠、可扩展和安全的各个方面，以及它们持续满足这些要求的基础。为了实现这一目标，我们需要考虑许多因素，这些因素将在以下子节中进行讨论。
- en: Model documentation
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型文档
- en: 'Starting with every developer’s favorite topic: documentation! While documentation
    is not always the most fun part of a developer’s job, it is essential to building
    and maintaining production-grade systems. I’ve worked with clients and teams in
    various companies that have not always done a great job of developing accurate,
    high-quality documentation, and one thing that you can almost guarantee in the
    lack of such documentation is that it will make your job a lot more difficult
    when you need to maintain and improve your systems over time. Imagine that you
    join a new team and you are tasked with improving the performance of a particular
    application that uses ML to perform medical diagnoses, and you find that the original
    application and underlying model were developed years ago by people who have left
    the company and did not document how they implemented the system. This is not
    a good place to be in, and you would be surprised how commonly these kinds of
    scenarios exist in the industry. Perhaps most importantly in the context of this
    chapter, model documentation can be essential—and sometimes even legally required—for
    compliance purposes.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从每个开发者最喜欢的主题：文档！虽然文档并不是开发者工作中最有乐趣的部分，但它对于构建和维护生产级系统至关重要。我曾与各种公司中的客户和团队合作，他们并不总是能很好地开发准确、高质量文档，而且你可以几乎肯定的是，缺乏这种文档将使你在需要随着时间的推移维护和改进系统时的工作变得更加困难。想象一下，你加入了一个新的团队，并被分配去提高一个特定应用程序的性能，该应用程序使用机器学习进行医学诊断，而你发现原始应用程序和底层模型是几年前由已经离开公司的人开发的，他们没有记录他们是如何实现该系统的。这并不是一个好的地方，而且你会惊讶地发现，这些类型的场景在行业中是多么普遍。也许在本章的背景下，最重要的是，模型文档对于合规性——有时甚至是法律要求——可能是至关重要的。
- en: So, what does high-quality model documentation look like? Generally, our documentation
    should keep detailed records of factors such as model design, data inputs, transformations,
    algorithms, and hyperparameters. Let’s take a look at each of these in more detail.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，高质量的模型文档是什么样的呢？通常，我们的文档应该详细记录模型设计、数据输入、转换、算法和超参数等因素。让我们更详细地看看这些内容。
- en: Model design
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型设计
- en: Documentation regarding model design should clearly define the purpose of the
    model, such as the objectives the model intends to achieve and the context within
    which it needs to operate. This includes potential use cases and intended users
    or systems that will interact with the model. We also need to provide a detailed
    description of the model’s architecture, such as its layers, structures, and interdependencies
    among different components of the model. Additionally, we should include details
    regarding the model’s design rationale, such as the reasoning behind choosing
    this particular model architecture or design, including comparisons with other
    potential designs that were considered and an explanation of why they were not
    chosen.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型设计的文档应明确定义模型的目的，例如模型打算实现的目标和模型需要运行的上下文。这包括潜在的使用案例和将与此模型交互的预期用户或系统。我们还需要提供模型架构的详细描述，例如其层、结构和模型不同组件之间的相互依赖关系。此外，我们还应包括有关模型设计理由的详细信息，例如选择这种特定的模型架构或设计的理由，包括与其他考虑的潜在设计进行比较，以及解释为什么它们没有被选择。
- en: Data inputs
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据输入
- en: Our model documentation should describe the data collection process we used,
    including sources, methods of collection, and the timeframe during which data
    was collected. We should list all the features used by the model, including their
    definitions, types (for example, categorical, and numerical), any assumptions
    made about the data, and explanations as to why each feature is relevant to the
    model’s predictions. Additionally, we need to document any known issues in terms
    of data quality, including missing values, outliers, or inconsistencies, and how
    these issues were handled or mitigated.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型文档应描述我们使用的数据收集过程，包括来源、收集方法以及数据收集的时间范围。我们应该列出模型使用的所有特征，包括它们的定义、类型（例如，分类和数值），对数据所做的任何假设，以及解释为什么每个特征与模型的预测相关。此外，我们还需要记录任何已知的数据质量问题，包括缺失值、异常值或不一致性，以及如何处理或缓解这些问题。
- en: Transformations
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 转换
- en: 'Another best practice is to detail the steps taken to clean and preprocess
    the data, such as handling missing data, normalization, encoding techniques, and
    feature engineering, including explanations of any methods used for feature selection
    or reduction (such as **principal component analysis** (**PCA**), as depicted
    in *Figure 13**.2*), and the rationale for their use:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项最佳实践是详细说明用于清理和预处理数据的步骤，例如处理缺失数据、归一化、编码技术和特征工程，包括对任何用于特征选择或减少的方法的解释（例如，如图*图13.2*所示的**主成分分析**（**PCA**）），以及使用这些方法的理由：
- en: '![Figure 13.2: PCA](img/B18143_13_2.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图13.2：PCA](img/B18143_13_2.jpg)'
- en: 'Figure 13.2: PCA'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2：PCA
- en: Algorithms
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 算法
- en: In our documentation, we should discuss why a particular ML algorithm was chosen,
    including a comparison with other algorithms that were considered and a rationale
    explaining the algorithm’s suitability for the problem at hand, citing relevant
    literature or empirical evidence, as appropriate. It’s also important to detail
    the configuration of the algorithm, including any customizations specific to the
    project.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的文档中，我们应该讨论为什么选择特定的机器学习算法，包括与其他考虑的算法的比较，以及解释该算法为何适合当前问题的理由，根据适当的相关文献或经验证据进行引用。同样重要的是详细说明算法的配置，包括针对项目的任何特定定制。
- en: Hyperparameters
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 超参数
- en: We should include details on all hyperparameters that the model uses, providing
    a definition and range for each, as well as the process used for hyperparameter
    tuning, such as grid search, random search, or Bayesian optimization. Additionally,
    we should include the final values chosen for each hyperparameter and provide
    a rationale for why these particular values were chosen, supported by the tuning
    process’s outcomes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该包括模型使用的所有超参数的详细信息，为每个提供定义和范围，以及用于超参数调整的过程，例如网格搜索、随机搜索或贝叶斯优化。此外，我们还应包括每个超参数选择的最终值，并解释为什么选择这些特定的值，并支持调整过程的结果。
- en: Additional factors
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 额外因素
- en: Our documentation should also explain how the model’s performance was evaluated,
    including the metrics used (**mean squared error** (**MSE**), **area under the
    ROC curve** (**ROC-AUC**)) and the results of these evaluations. We should document
    any known limitations of the model, document potential biases in the model’s predictions,
    and describe how these biases could impact different demographic groups or individuals.
    We also need to detail any regulatory standards or ethical guidelines relevant
    to the model and discuss how compliance has been ensured. Finally, we need to
    outline the plan for ongoing monitoring of the model’s performance and behavior
    in a production environment, including strategies for handling model drift, anomalies,
    or performance degradation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的文档还应解释如何评估模型的表现，包括使用的指标（**均方误差**（**MSE**），**ROC曲线下面积**（**ROC-AUC**））以及这些评估的结果。我们应该记录模型已知的任何局限性，记录模型预测中的潜在偏差，并描述这些偏差如何影响不同的群体或个人。我们还需要详细说明与模型相关的任何监管标准或伦理指南，并讨论如何确保合规性。最后，我们需要概述在生产环境中持续监控模型表现和行为的计划，包括处理模型漂移、异常或性能下降的策略。
- en: Model versioning
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型版本控制
- en: 'Just as with code versioning in traditional software development, model versioning
    in ML projects is essential for ensuring that teams can trace back through the
    evolution of models, replicate results, roll back to previous versions when necessary,
    and maintain a record of all changes made throughout a model’s life cycle. This
    becomes especially important in large or collaborative environments where multiple
    iterations of models may be developed over time by many different people and teams.
    It’s also important for debugging, continuous improvement, and audit and compliance
    purposes. *Figure 13**.3* shows an example of model version metadata in the Vertex
    AI Model Registry:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在传统软件开发中的代码版本控制一样，在机器学习项目中进行模型版本控制对于确保团队能够追踪模型的演变过程、复制结果、在必要时回滚到先前版本，以及维护整个模型生命周期中所有变更的记录至关重要。这在大型或协作环境中尤为重要，因为在这样的环境中，随着时间的推移，可能由许多不同的人或团队开发出多个模型的多个迭代。对于调试、持续改进、审计和合规性目的来说，这也同样重要。*图13.3*展示了Vertex
    AI模型注册表中模型版本元数据的一个示例：
- en: '![Figure 13.3: Model version metadata in Vertex AI Model Registry](img/B18143_13_3.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图13.3：Vertex AI模型注册表中的模型版本元数据](img/B18143_13_3.jpg)'
- en: 'Figure 13.3: Model version metadata in Vertex AI Model Registry'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3：Vertex AI模型注册表中的模型版本元数据
- en: When I speak of model versioning, I’m referring to more than just the model
    artifacts, such as the actual model files, weights, and architecture. We should
    implement version tracking for every relevant item that is used in the model development
    process. This includes any code associated with the model, be it for preprocessing,
    training, evaluation, or deployment, as well as datasets, whether they consist
    of raw data, preprocessed data, or feature-engineered data. Even hyperparameter
    values and performance evaluation metrics should be versioned so that we can easily
    understand which versions of these elements pertain to which versions of our models.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当我提到模型版本控制时，我指的是不仅仅是模型工件，例如实际模型文件、权重和架构。我们应该为模型开发过程中使用的每个相关项目实施版本跟踪。这包括与模型相关的任何代码，无论是预处理、训练、评估还是部署，以及数据集，无论它们是原始数据、预处理数据还是特征工程数据。甚至超参数值和性能评估指标也应进行版本控制，这样我们就可以轻松理解哪些版本的这些元素与我们的模型版本相对应。
- en: A well-implemented model versioning tool, such as Vertex AI Model Registry,
    will also enable us to add custom metadata to more comprehensively track our various
    model versions.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实施良好的模型版本控制工具，如Vertex AI模型注册表，也将使我们能够添加自定义元数据，以更全面地跟踪我们的各种模型版本。
- en: Model monitoring
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型监控
- en: As we discussed in previous chapters, we need to continuously monitor models
    after we have deployed them to production. The intention is to identify any drift,
    anomalies, or degradation in model performance, including important markers such
    as fairness and explainability metrics. Again, this is not only important for
    **business continuity** (**BC**) purposes but also for compliance reasons. We
    may have certified that our model is compliant with specific regulations before
    and during deployment, but it could drift and lapse out of compliance if not regularly
    monitored on an ongoing basis. If we have set up MLOps pipelines to automate the
    process of continuously improving our models over time, then this monitoring should
    extend to all aspects of our pipeline, such as ensuring that we perform data quality
    monitoring during the data preprocessing steps, in addition to new model validation
    and other important steps in the process.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在前几章所讨论的，在我们将模型部署到生产环境中之后，我们需要持续监控这些模型。目的是识别模型性能中的任何漂移、异常或退化，包括公平性和可解释性等重要指标。再次强调，这不仅对**业务连续性**（**BC**）至关重要，而且出于合规性的考虑。我们可能在部署前和部署期间已经证明我们的模型符合特定的法规，但如果不能定期持续监控，模型可能会偏离并失去合规性。如果我们已经设置了MLOps管道来自动化随时间持续改进模型的过程，那么这种监控应该扩展到我们管道的所有方面，例如确保我们在数据预处理步骤中进行数据质量监控，以及在新模型验证和其他过程中的其他重要步骤。
- en: As with everything else regarding our model development and management implementations,
    we want our monitoring processes to be automated as much as possible. We should
    set thresholds beyond which some kind of corrective action is either automatically
    initiated or a human is notified if there is a problem. For example, if we see
    that performance or fairness metric values have changed by more than a specified
    amount, then corrective action is initiated, either by automatically training
    and evaluating a new model version on updated data or by paging on-call support
    engineers to intervene.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们对于模型开发和管理的所有其他实施一样，我们希望我们的监控过程尽可能地自动化。我们应该设定阈值，超过这个阈值时，如果存在问题，则应自动启动某种纠正措施，或者通知值班支持工程师介入。例如，如果我们看到性能或公平性指标值的变化超过了指定的数量，那么就会启动纠正措施，这可能包括在更新后的数据上自动训练和评估新的模型版本，或者呼叫值班支持工程师进行干预。
- en: As we also discussed in previous chapters, Vertex AI provides built-in tools
    for monitoring model performance both after deployment and throughout each relevant
    step in the model development process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前几章所讨论的，Vertex AI提供了内置工具，用于监控模型性能，无论是在部署后还是在模型开发过程中的每个相关步骤。
- en: Auditing and compliance
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 审计和合规
- en: Many industries have strict regulations (for example, GDPR, HIPAA, and various
    financial regulations) that require certain standards for factors such as data
    privacy, bias, transparency, and many more. Non-compliance with these regulations
    can lead to legal penalties and loss of customer trust. If we have workloads that
    are subject to regulatory standards, then we will need to establish auditing processes
    to help ensure our workloads remain compliant on an ongoing basis.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 许多行业都有严格的法规（例如，GDPR、HIPAA以及各种金融法规），这些法规要求对数据隐私、偏差、透明度等因素设定一定的标准。不遵守这些法规可能导致法律处罚和客户信任的丧失。如果我们有受监管标准约束的工作负载，那么我们需要建立审计流程，以确保我们的工作负载持续符合法规。
- en: How we implement such processes will mainly depend on the types of regulations
    with which we need to comply. Such processes could consist of a regular human-review
    process, or, as always, it would be best if we could automate auditing processes
    as much as possible and notify a human only when an issue that appears not to
    be automatically resolvable occurs. In the case of human-review processes, this
    is where documentation is inherently important because good-quality documentation
    can greatly simplify the review process and can make it easier to determine corrective
    actions when issues are identified. Ideally, we would want to identify potential
    risks in model performance, security, or reliability before they escalate into
    larger issues, and establishing regular review processes can help to ensure this
    happens.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何实施这些流程将主要取决于我们需要遵守的法规类型。这些流程可能包括常规的人工审查流程，或者，正如我们一直所做的那样，尽可能自动化审计流程，只有在出现似乎无法自动解决的问题时才通知人类。在人工审查流程的情况下，这是文档固有的重要性的地方，因为高质量的文档可以极大地简化审查过程，并在发现问题时更容易确定纠正措施。理想情况下，我们希望在模型性能、安全性或可靠性问题升级为更大问题之前就识别出潜在风险，并建立定期的审查流程可以帮助确保这一点发生。
- en: For some types of regulations, well-established audit checklists and **standard
    operating procedures** (**SOPs**) can be used, making the auditing task a bit
    easier. However, bear in mind that the regulatory landscape for ML is still evolving,
    and organizations must stay abreast of changes to remain compliant.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些类型的法规，可以使用建立良好的审计清单和**标准操作程序**（SOPs），这使得审计任务变得稍微容易一些。然而，请记住，机器学习的法规环境仍在不断发展，组织必须跟上变化以保持合规。
- en: In the previous chapter, we discussed the concept of explainability. Explainability
    is particularly important in the context of regulatory compliance. If you can’t
    easily or adequately explain how a given model or system works, then you will
    have a difficult time ensuring regulatory compliance.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了可解释性的概念。在合规监管的背景下，可解释性尤为重要。如果你不能轻松或充分地解释一个特定的模型或系统是如何工作的，那么你将很难确保合规性。
- en: Now that we’ve covered many of the important factors of ML governance in quite
    a bit of detail, let’s zoom back out and focus on the bigger picture again. In
    the coming sections, we will discuss how to operationalize ML governance, what
    ML governance looks like in different industries, and how to stay abreast of the
    evolving ML governance landscape.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经相当详细地覆盖了许多机器学习治理的重要因素，让我们再次放大视角，关注更大的图景。在接下来的章节中，我们将讨论如何实施机器学习治理，不同行业中机器学习治理的样子，以及如何跟上不断发展的机器学习治理格局。
- en: Operationalization of ML governance
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习治理的 operationalization
- en: As I’ve alluded to in each of the previous sections, we usually would want to
    automate as much of our ML governance practices and processes as possible, and
    there are tools and platforms that can assist in achieving this goal, such as
    data catalogs, model management tools, and auditing tools, which I describe in
    the following sub-sections.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在前几节中暗示的那样，我们通常希望尽可能自动化我们的机器学习治理实践和流程，并且有一些工具和平台可以帮助实现这一目标，例如数据目录、模型管理工具和审计工具，我将在以下子节中描述。
- en: Data catalogs
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据目录
- en: 'We briefly talked about data cataloging earlier in this chapter. Data catalogs
    are a kind of metadata management tool that helps companies find and manage large
    amounts of data spread across their organization, whether on-premises or in the
    cloud. You can think of a data catalog as a massive inventory of a company’s data
    assets, designed to let users discover, organize, and understand their data sources.
    We’ve already introduced Google Cloud Dataplex, which Google describes as an “*intelligent
    data fabric that enables organizations to centrally discover, manage, monitor,
    and govern their data across data lakes, data warehouses, and data marts, with
    consistent controls*.” *Figure 13**.4* shows an example of a catalog created by
    Google Cloud Dataplex:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章前面简要地讨论了数据编目。数据目录是一种元数据管理工具，帮助公司找到和管理其组织内部大量分布的数据，无论是在本地还是在云端。你可以将数据目录视为公司数据资产的庞大库存，旨在让用户发现、组织和理解他们的数据源。我们已经介绍了Google
    Cloud Dataplex，谷歌将其描述为“*一种智能数据布料，使组织能够集中发现、管理、监控和治理其数据湖、数据仓库和数据集市，具有一致的控制*。”*图13.4*展示了由Google
    Cloud Dataplex创建的目录示例：
- en: '![Figure 13.4: Dataplex catalog](img/B18143_13_4.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图13.4：Dataplex目录](img/B18143_13_4.jpg)'
- en: 'Figure 13.4: Dataplex catalog'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4：Dataplex 目录
- en: This concept of consistent controls is particularly relevant in the context
    of governance. With Dataplex, you can use metadata to describe all of your company’s
    data assets, and you can manage permissions in a uniform way across different
    Google Cloud data storage and processing tools. This is, of course, important
    from a governance perspective, and Dataplex also provides data quality and data
    lineage functionality, which are also important in the context of governance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种一致控制的观念在治理的背景下尤其相关。使用 Dataplex，你可以使用元数据来描述你公司所有的数据资产，并且你可以以统一的方式管理不同 Google
    Cloud 数据存储和处理工具的权限。这当然从治理的角度来看非常重要，而且 Dataplex 还提供了数据质量和数据血缘功能，这些在治理的背景下也同样重要。
- en: Model management platforms
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型管理平台
- en: These platforms assist in the model’s entire life cycle, including development,
    deployment, monitoring, and maintenance. They are essential for activities such
    as model versioning, experiment tracking, and model performance monitoring. By
    providing a structured environment for managing ML models, these platforms help
    ensure that models are reliable and reproducible and that they meet performance
    expectations. They also facilitate compliance by providing detailed model development
    and deployment process records. Of course, Vertex AI is Google Cloud’s native
    model management ecosystem, providing all of the aforementioned features.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些平台协助模型整个生命周期的各个方面，包括开发、部署、监控和维护。它们对于模型版本控制、实验跟踪和模型性能监控等活动至关重要。通过为管理机器学习模型提供一个结构化环境，这些平台有助于确保模型是可靠和可重复的，并且满足性能预期。它们还通过提供详细的模型开发和部署过程记录来促进合规性。当然，Vertex
    AI 是 Google Cloud 的原生模型管理生态系统，提供了上述所有功能。
- en: So far, we’ve focused on aspects of ML governance that are common to many industries.
    In the next section, let’s take a look at how ML governance applies to specific
    industries.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直关注的是许多行业共有的机器学习治理方面。在下一节中，让我们来看看机器学习治理是如何应用于特定行业的。
- en: ML governance in different industries and locations
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同行业和地区的机器学习治理
- en: What can make regulatory compliance even more complex is that different countries,
    states, and industries can all have varying regulations. ML governance therefore
    varies significantly across different industries and geographic locations. In
    this section, we’ll discuss governance factors for specific regions and sectors,
    such as healthcare and finance, as well as regional considerations.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 什么可以使合规性监管变得更加复杂的是，不同的国家、州和行业都可以有不同的法规。因此，机器学习治理在不同行业和地理区域之间差异很大。在本节中，我们将讨论特定地区和部门（如医疗保健和金融）的治理因素，以及区域考虑因素。
- en: Healthcare
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 医疗保健
- en: I currently live in the US, and when I hear the terms “regulatory compliance”
    and “healthcare” in the same sentence, the first thing that pops into my mind
    is the **Health Insurance Portability and Accountability Act** (**HIPAA**), which
    grants patients certain rights over their health information, including secure
    handling and confidentiality, and outlines significant penalties for breaches
    and non-compliance. If you work in healthcare in the US, you will almost certainly
    need to be aware of, and work within, the requirements of HIPAA. When designing
    and implementing ML systems in this industry, you must ensure that the data handling
    practices throughout the entire model development life cycle comply with those
    requirements. Other countries have their own regulatory requirements that you
    must learn and understand if you operate in those areas.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我目前居住在美国，当我听到“合规性监管”和“医疗保健”这两个词在同一句话中时，我脑海中首先想到的是**健康保险可携带性和问责法案**（**HIPAA**），该法案赋予患者对其健康信息的某些权利，包括安全处理和保密性，并规定了违规和不合规的重大处罚。如果你在美国从事医疗保健工作，你几乎肯定需要了解并遵守
    HIPAA 的要求。在设计实施该行业的机器学习系统时，你必须确保整个模型开发生命周期中的数据处理实践符合这些要求。其他国家和地区也有自己的监管要求，如果你在这些地区运营，你必须学习和理解这些要求。
- en: Finance
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 金融
- en: In the finance industry, fraud is perhaps one of the biggest concerns or threats,
    and the finance industry is heavily regulated to avoid the potential of fraud
    occurring. If your company operates in the US, for example, then the financial
    operations of your company will need to abide by regulations such as the **Sarbanes-Oxley
    Act** (**SOX**), which is mainly intended to prevent corporate fraud and improve
    the reliability and accuracy of corporate disclosures to protect investors. If
    your systems handle credit card data in any way, then you will likely need to
    comply with **Payment Card Industry Data Security Standard** (**PCI DSS**) regulations,
    which are a set of security standards relating to the secure handling of credit
    card information.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融行业，欺诈可能是最大的担忧或威胁之一，金融行业受到严格的监管以避免欺诈发生的可能性。例如，如果你的公司在美运营，那么你的公司的财务操作将需要遵守诸如**萨班斯-奥克斯利法案**（**SOX**）等法规，该法案主要旨在防止企业欺诈并提高企业披露的可靠性和准确性，以保护投资者。如果你的系统以任何方式处理信用卡数据，那么你很可能需要遵守**支付卡行业数据安全标准**（**PCI
    DSS**）的法规，这是一套与安全处理信用卡信息相关的安全标准。
- en: Region-specific governance considerations
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 地区特定的治理考虑因素
- en: Different regions have different regulatory requirements. For example, if you
    operate in the EU and the **European Economic Area** (**EEA**), then you will
    be subject to GDPR requirements, which protect the PI of individuals in those
    regions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 不同地区有不同的监管要求。例如，如果你在欧盟和**欧洲经济区**（**EEA**）运营，那么你将受到GDPR要求的影响，该要求保护这些地区个人的个人信息。
- en: The state of California has the CCPA, which regulates how businesses worldwide
    are allowed to handle the PI of California residents.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚州有CCPA，该法案规定了全球企业如何处理加州居民的个人信息。
- en: There are also regulations that govern how data related to children must be
    handled, such as the **Children’s Online Privacy Protection Act** (**COPPA**),
    which is intended to protect the privacy of children under 13 years of age.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 还有规定如何处理与儿童相关的数据，例如**儿童在线隐私保护法案**（**COPPA**），该法案旨在保护13岁以下儿童的隐私。
- en: In addition to region-specific and industry-specific regulations, we must also
    ensure that we remain compliant with obligations regarding fairness, transparency,
    explainability, accountability, and ethics. And, not only do we need to manage
    the complexity of regulations in different regions and industries, but that complexity
    is further extended by the fact that regulations may change over time. Let’s discuss
    this topic in more detail next.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 除了地区和行业特定的法规外，我们还必须确保我们遵守关于公平、透明度、可解释性、责任和伦理的义务。而且，我们不仅需要管理不同地区和行业的法规复杂性，而且这种复杂性还因法规可能随时间变化而进一步扩展。让我们在下一节中更详细地讨论这个话题。
- en: Keeping up with the evolving landscape of ML governance
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟进机器学习治理的演变趋势
- en: I can confidently say that the ML industry is one of the most quickly evolving
    industries at the moment. Companies, governments, and research institutions all
    over the world continue to invest heavily in this industry. As a result, compliance
    regulations related to this industry continue to evolve rapidly. In order to consistently
    remain successful and, quite frankly, ensure that you don’t get into trouble,
    your company needs to stay current in this ever-evolving landscape. In this section,
    I outline important concepts and best practices in this space.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以自信地说，机器学习行业是目前发展最快的行业之一。全球的公司、政府和研究机构都在这个行业中大量投资。因此，与这个行业相关的合规法规也在迅速演变。为了持续成功，坦白说，确保你不陷入麻烦，你的公司需要在这个不断变化的环境中保持最新。在本节中，我概述了该领域的重要概念和最佳实践。
- en: Ongoing education and training
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续教育和培训
- en: Your company’s employees need ongoing education to stay current with advances
    in regulatory requirements. In addition to technical capabilities, your employees
    must understand ethical considerations and risk management strategies related
    to ML deployment. Well-informed and well-trained individuals are less likely to
    make costly errors such as violating data privacy standards. Also, since this
    is not a static field, new types of bias and ethical dilemmas emerge almost daily.
    I highly recommend implementing regular training sessions, workshops, and educational
    resources for employees to learn about the latest trends, tools, ethical considerations,
    and best practices regarding ML governance.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您公司的员工需要持续教育，以跟上监管要求的进步。除了技术能力外，您的员工还必须了解与机器学习部署相关的伦理考虑和风险管理策略。信息充分且受过良好训练的个人不太可能犯下诸如违反数据隐私标准等代价高昂的错误。此外，由于这是一个不断发展的领域，新的类型偏见和伦理困境几乎每天都在出现。我强烈建议实施定期的培训课程、研讨会和教育资源，让员工了解最新的趋势、工具、伦理考虑和关于机器学习治理的最佳实践。
- en: Regularly updating governance policies and practices
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定期更新治理政策和实践
- en: Along with the technologies and ethical considerations, the legal landscape
    for data protection and privacy also continually evolves. Organizations must regularly
    update their governance policies to comply with new and changing laws and standards
    (GDPR, CCPA, or industry-specific regulations), and as new technologies and methodologies
    develop, governance policies must adapt to accommodate and manage them appropriately.
    What worked for a simple linear regression model might not be sufficient for a
    complex **deep learning** (**DL**) system. Unfortunately, the threat landscape
    also continues to develop as new technologies emerge, and what was secure yesterday
    might not be quite as secure tomorrow. As a result, we need to regularly review
    and update security policies and practices to protect sensitive data and ML systems
    against new vulnerabilities and attack strategies.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 除了技术和伦理考虑之外，数据保护和隐私的法律环境也在不断演变。组织必须定期更新其治理政策，以符合新的和不断变化的法律和标准（GDPR、CCPA或行业特定法规），并且随着新技术和方法的发展，治理政策必须适应以适当容纳和管理它们。对于简单的线性回归模型有效的方法可能不足以应对复杂的**深度学习**（**DL**）系统。不幸的是，随着新技术的出现，威胁环境也在不断发展，昨天还安全的事物明天可能就不再那么安全了。因此，我们需要定期审查和更新安全政策和实践，以保护敏感数据和机器学习系统免受新的漏洞和攻击策略的侵害。
- en: Additionally, in consideration of Google’s **Site Reliability Engineering**
    (**SRE**) practices, while we should do everything we can to avoid a negative
    event occurring, if such an event does occur, we need to learn from that scenario.
    As such, we should conduct thorough post-mortems on any issues and use these insights
    to improve policies and prevent future occurrences.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑到谷歌的**站点可靠性工程**（**SRE**）实践，尽管我们应该尽一切努力避免负面事件的发生，但如果此类事件确实发生，我们需要从该场景中学习。因此，我们应该对任何问题进行彻底的复盘，并利用这些见解来改进政策并防止未来发生。
- en: Another set of concepts that are quite closely linked to SRE are encapsulated
    in the Google Cloud Architecture Framework, which I will discuss in the next section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 另一套与SRE紧密相关的概念包含在谷歌云架构框架中，我将在下一节中讨论。
- en: An overview of the Google Cloud Architecture Framework
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌云架构框架概述
- en: In Google’s own words, “*the Google Cloud Architecture Framework provides recommendations
    and describes best practices to help architects, developers, administrators, and
    other cloud practitioners design and operate a cloud topology that’s secure, efficient,
    resilient, high-performing, and cost-effective*.” In this section, we discuss
    some of the key concepts from the framework and how they can be applied to AI/ML
    workloads on Google Cloud, especially within the context of ML governance.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 用谷歌自己的话说，“*谷歌云架构框架提供了建议并描述了最佳实践，以帮助架构师、开发人员、管理员和其他云实践者设计和运营一个安全、高效、弹性、高性能且成本效益的云拓扑结构*。”在本节中，我们将讨论框架的一些关键概念以及它们如何应用于谷歌云上的AI/ML工作负载，特别是在机器学习治理的背景下。
- en: 'For reference, the framework documentation can be found at the following URL:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下URL可以找到框架文档：
- en: '[https://cloud.google.com/architecture/framework](https://cloud.google.com/architecture/framework)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/architecture/framework](https://cloud.google.com/architecture/framework)'
- en: Let’s begin with an overview of the fundamental concepts of the framework, which
    are referred to as **pillars**. One way to think of it is that, by ensuring all
    of these pillars are implemented, we can build a solid and enduring structure
    (system).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从框架的基本概念概述开始，这些概念被称为 **基柱**。一种思考方式是，通过确保所有这些基柱都得到实施，我们可以构建一个坚固且持久的结构（系统）。
- en: 'The categories of the framework are the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 框架的分类如下：
- en: System design
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统设计
- en: Operational excellence
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运营卓越
- en: Security, privacy, and compliance
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性、隐私和合规性
- en: Reliability
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可靠性
- en: Cost optimization
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本优化
- en: Performance optimization
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能优化
- en: In the following sub-sections, I’ll describe what each category represents,
    starting with system design.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的子章节中，我将描述每个类别代表的内容，从系统设计开始。
- en: Pillar 1 – System design
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基柱 1 – 系统设计
- en: 'Interestingly, the *System design* category in the Google Cloud Architecture
    Framework is more akin to the foundation of the overall framework than a pillar,
    because a well-designed system appropriately incorporates all of the pillars.
    The *System design* category encapsulates four core principles:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，Google Cloud 架构框架中的 *系统设计* 类别更类似于整体框架的基础，而不是一个基柱，因为一个设计良好的系统适当地融合了所有的基柱。*系统设计*
    类别封装了四个核心原则：
- en: Document everything
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录一切
- en: Simplify your design and use fully managed services
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简化你的设计并使用完全托管的服务
- en: Decouple your architecture
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解耦你的架构
- en: Use a stateless architecture
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用无状态架构
- en: Let’s take a look at each of these in more detail.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些内容。
- en: Principle 1 – Document everything
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原则 1 – 记录一切
- en: 'We touched on this principle quite a bit in this chapter’s *ML model governance*
    section. In a broader system design context, we’re not just referring to documentation
    related to our model, but rather related to every aspect of how our systems are
    implemented, including aspects such as architecture diagrams and maintenance runbooks.
    The question I always ask in this context is: if a new member joined our team
    and were required to quickly learn everything they need to know to improve and
    maintain a system we’ve built, what are all of the details they would need to
    review? If any of those details are not adequately documented, then that’s a gap
    that we need to address by developing the required documentation. This also helps
    other teams that we need to collaborate with or that need to interact with our
    system in some way, and it makes everybody’s job easier if regulatory compliance
    officers need to audit our systems.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的 *ML 模型治理* 部分对此原则进行了相当多的讨论。在更广泛的系统设计背景下，我们不仅指的是与我们的模型相关的文档，而是与我们的系统实施的各个方面相关的文档，包括架构图和维护手册等方面。在这种情况下，我总是问这样一个问题：如果一位新成员加入我们的团队，并且需要快速学习他们需要了解的所有内容以改进和维护我们构建的系统，他们需要审查的所有细节是什么？如果其中任何细节没有得到充分的记录，那么这就是我们需要通过开发必要的文档来解决的问题。这也帮助了我们需要与之协作的其他团队，或者需要以某种方式与我们的系统交互的团队，如果监管合规官员需要审计我们的系统，这也会使每个人的工作变得更简单。
- en: Principle 2 – Simplify your design and use fully managed services
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原则 2 – 简化你的设计并使用完全托管的服务
- en: 'Ever since I heard of the concept of Occam’s razor, I have been a big fan of
    it. There are a number of different ways in which it can be summarized, but a
    fairly common one is: “If there are two possible explanations for a particular
    phenomenon, use the simpler one.”This can be extended to say: don’t make things
    more complicated than needed. The opposite of this is the concept of a Rube Goldberg
    machine, which applies an extremely complex set of mechanisms to achieve a simple
    goal. While Rube Goldberg machines can be fun to watch, they are generally quite
    impractical, and they are not what you want to implement in the design of your
    large-scale, low-latency, highly sensitive production system.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 自从我听说奥卡姆剃刀的概念以来，我就成了它的忠实粉丝。它有几种不同的总结方式，但其中一种相当常见的是：“如果对某个现象有两种可能的解释，使用更简单的那一个。”这可以进一步扩展为：不要使事情比必要的更复杂。与此相反的是鲁布·戈尔伯格机器的概念，它通过极其复杂的机制来实现一个简单的目标。虽然鲁布·戈尔伯格机器观看起来很有趣，但它们通常非常不实用，而且它们不是你希望在大型、低延迟、高度敏感的生产系统设计中实现的东西。
- en: Keeping your system design as simple as possible has many benefits, such as
    making it easier to troubleshoot, maintain, and secure your systems. Highly complex
    systems with many different components are difficult to troubleshoot when something
    goes wrong. Similarly, in terms of security, highly complex systems often have
    a larger **attack surface**. We will cover that concept in more detail later in
    this chapter.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能简化你的系统设计有许多好处，例如，使故障排除、维护和保障系统变得更加容易。当出现问题时，具有许多不同组件的高度复杂系统很难进行故障排除。同样，在安全方面，高度复杂的系统通常具有更大的
    **攻击面**。我们将在本章后面更详细地介绍这个概念。
- en: Another way in which we can make our jobs easier is by offloading responsibilities
    to a **cloud service provider** (**CSP**). One of the primary benefits of cloud
    computing is that CSPs offer platforms and systems that have been designed to
    address common needs in the industry. When a company runs all of its workloads
    in its own data centers, it either needs to build solutions and platforms completely
    by itself or install and manage software created by other companies. Both of those
    options incur a lot of staff overhead and require specific training to manage.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将责任外包给 **云服务提供商** (**CSP**) 来使我们的工作变得更简单。云计算的主要好处之一是 CSP 提供了旨在解决行业常见需求的平台和系统。当一家公司在自己的数据中心运行所有工作负载时，它要么需要完全自行构建解决方案和平台，要么安装和管理其他公司创建的软件。这两种选择都会产生大量的员工开销，并需要特定的培训来管理。
- en: Let’s take the example of building and maintaining a platform to enable data
    scientists to develop and deploy ML models. In previous chapters, we outlined
    the various steps that are required in the model development life cycle. If we
    are running all of our workloads “on-premises” (that is, not in the cloud), then
    we need to either design, build, and maintain a platform that supports all of
    those steps or, as many companies do, we could try to hack something together,
    using a hodge-podge of random third-party software solutions that all require
    specific training and don’t necessarily work very well together. In the cloud,
    however, we can simply use the platform provided by the cloud provider and let
    them do all of the hard work for us so that our teams can focus on their core
    competencies and primary objectives rather than building and maintaining infrastructure.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以构建和维护一个平台为例，这个平台能够使数据科学家开发和部署机器学习模型。在前几章中，我们概述了模型开发生命周期中所需的各个步骤。如果我们所有的“本地”工作负载（即不在云中）运行，那么我们需要设计、构建和维护一个支持所有这些步骤的平台，或者像许多公司所做的那样，我们可以尝试拼凑一些东西，使用各种随机的第三方软件解决方案，这些解决方案都需要特定的培训，并且不一定能很好地协同工作。然而，在云中，我们只需使用云提供商提供的平台，让他们为我们做所有艰苦的工作，这样我们的团队能够专注于他们的核心能力和主要目标，而不是构建和维护基础设施。
- en: Similar concepts exist across other types of workloads. For example, on-premises,
    we may build and maintain our own Kubernetes environments for our company’s containerized
    workloads. We would spend a lot of time maintaining those systems, but in the
    cloud, we could use managed services such as **Google Kubernetes Engine** (**GKE**)
    or Cloud Run. In this context, we talk about services that offload more of the
    infrastructure management tasks to the cloud provider as “going further up the
    stack.” In the case of GKE and Cloud Run, Cloud Run would be seen as “further
    up the stack” because it provides more of a fully managed experience than the
    basic form of GKE, although the more recent launch of GKE Autopilot also provides
    a very hands-off approach, in which more of the platform management tasks are
    implemented by Google Cloud.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 类似的概念存在于其他类型的工作负载中。例如，在本地，我们可能为公司容器化工作负载构建和维护自己的 Kubernetes 环境。我们可能会花费大量时间维护这些系统，但在云中，我们可以使用如
    **Google Kubernetes Engine** (**GKE**) 或 Cloud Run 这样的托管服务。在这种情况下，我们所说的将更多基础设施管理任务外包给云提供商的服务称为“向更高层栈发展”。在
    GKE 和 Cloud Run 的情况下，Cloud Run 可以被视为“向更高层栈发展”，因为它比 GKE 的基本形式提供了更多的完全托管体验，尽管 GKE
    Autopilot 的最新推出也提供了一种非常少干预的方法，在这种方法中，更多的平台管理任务由 Google Cloud 实现。
- en: Principle 3 – Decouple your architecture
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原则 3 – 解耦你的架构
- en: This ties in with *principle 2* to an extent. It refers to breaking your overall
    system design into smaller components. A classic example of this is to break a
    monolithic application into microservices. The reason is that each microservice
    is easier to manage than a very large and complex monolithic system architecture.
    Smaller components can be developed and scaled independently, which can improve
    the speed of development of new features in your systems.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这在一定程度上与*原则2*相关。它指的是将你的整体系统设计分解成更小的组件。一个典型的例子是将单体应用分解成微服务。原因是每个微服务比一个非常庞大且复杂的单体系统架构更容易管理。较小的组件可以独立开发和扩展，这可以提高你系统中新功能开发的速度。
- en: Principle 4 – Use a stateless architecture
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原则4 – 使用无状态架构
- en: In a stateless architecture, each transaction is independent. When processing
    a request, the server does not remember any prior requests or transactions, and
    the client must send any necessary data for a transaction in each request. In
    a stateful architecture, on the other hand, the server maintains the state of
    the client’s session. The context of previous transactions is remembered, and
    future transactions can be affected by what happened in the past.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在无状态架构中，每个事务都是独立的。在处理请求时，服务器不会记住任何先前的请求或事务，客户端必须在每个请求中发送任何必要的数据以进行事务。相反，在有状态架构中，服务器维护客户端会话的状态。先前事务的上下文会被记住，未来的事务可能会受到过去发生的事情的影响。
- en: I would add the words “whenever possible” to the title of this principle because
    sometimes your system will need to maintain state, but what you would want to
    do, as much as possible, is minimize the amount of state that needs to be maintained
    and offload the state management from your application to a separate mechanism
    such as a caching layer.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我会在这个原则的标题中添加“尽可能”这个词，因为有时你的系统将需要维护状态，但尽可能，你想要做的是最小化需要维护的状态量，并将状态管理从你的应用程序卸载到单独的机制，如缓存层。
- en: Stateless architectures are generally easier to scale because they don’t require
    maintaining client states, allowing requests to be processed by any available
    server. Stateful architectures require more complex infrastructure to ensure that
    the client interacts with the same server or that the state is shared, which can
    be challenging in large-scale environments. Stateful systems also use more resources
    to manage and store session data, which can further affect scalability and system
    complexity.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 无状态架构通常更容易扩展，因为它们不需要维护客户端状态，允许请求由任何可用的服务器处理。有状态架构需要更复杂的基础设施来确保客户端与同一服务器交互或状态共享，这在大型环境中可能具有挑战性。有状态系统还使用更多资源来管理和存储会话数据，这可能会进一步影响可扩展性和系统复杂性。
- en: Pillar 2 – Operational excellence
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 柱石2 – 运营卓越
- en: The *Operational excellence* pillar is concerned with efficiently running, managing,
    and monitoring systems on Google Cloud. It includes concepts such as automation,
    observability, and scalability.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*运营卓越*支柱关注于在Google Cloud上高效地运行、管理和监控系统。它包括自动化、可观测性和可扩展性等概念。'
- en: This pillar talks about automating system deployments using **continuous integration
    and continuous deployment** (**CI/CD**), and managing your infrastructure using
    **infrastructure as code** (**IaC**). This is a very important concept because
    it provides all of the benefits of traditional software development, such as version
    tracking and incremental updates. If you manage your infrastructure updates using
    version tracking mechanisms, then you can maintain strong records for auditing
    purposes, and if issues are introduced by any updates, then you can more easily
    roll back to a previous version that was known to work well. This is often referred
    to as **GitOps**, and the opposite of this is referred to as **ClickOps**. In
    the case of ClickOps, infrastructure updates are made by people clicking around
    in a UI. If you have hundreds of people in your technology organization, and every
    day they are all making updates to your infrastructure by clicking around in a
    UI, then it can become difficult to coordinate and track these updates over time.
    Terraform is a popular tool for implementing IaC on Google Cloud.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这个支柱讨论了使用**持续集成和持续部署**（**CI/CD**）来自动化系统部署，以及使用**基础设施即代码**（**IaC**）来管理你的基础设施。这是一个非常重要的概念，因为它提供了传统软件开发的所有好处，例如版本跟踪和增量更新。如果你使用版本跟踪机制来管理基础设施更新，那么你可以为审计目的保持强大的记录，并且如果任何更新引入了问题，那么你可以更容易地回滚到已知工作良好的先前版本。这通常被称为**GitOps**，而与之相反的是**ClickOps**。在ClickOps的情况下，基础设施更新是通过人们在用户界面中点击来完成的。如果你在你的技术组织中有一百多人，并且他们每天都在通过在用户界面中点击来更新你的基础设施，那么随着时间的推移，协调和跟踪这些更新可能会变得困难。Terraform是实现在Google
    Cloud上实施IaC的流行工具。
- en: The *Operational excellence* pillar also outlines best practices for incorporating
    testing throughout the software delivery life cycle. This includes unit tests,
    integration tests, system tests, and other types of tests such as performance
    and security testing. Rather than testing everything at the end, we should aim
    to include each type of test as relevant throughout each step in the development
    life cycle. For example, unit tests could be automated as part of our build process.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**运营卓越**支柱还概述了在整个软件交付生命周期中融入测试的最佳实践。这包括单元测试、集成测试、系统测试以及其他类型的测试，如性能和安全测试。我们不应该在最后测试一切，而应该旨在在每个开发生命周期的每个步骤中都包含每种类型的测试。例如，单元测试可以作为我们的构建过程的一部分自动化。'
- en: When deploying software, the *Operational excellence* pillar recommends using
    approaches such as immutable infrastructure updates via blue/green deployments
    and A/B or canary tests. Google Cloud provides CI/CD tooling that can be used
    to implement these strategies. The recommendation is to use small but frequent
    updates to your systems, which are easier to manage and roll back than large,
    infrequent changes.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署软件时，**运营卓越**支柱建议使用诸如通过蓝/绿部署和A/B或金丝雀测试进行不可变基础设施更新等方法。Google Cloud提供了可用于实施这些策略的CI/CD工具。建议使用小而频繁的系统更新，这些更新比大而罕见的更改更容易管理和回滚。
- en: In terms of observability, this pillar provides recommendations on effectively
    setting up monitoring, alerting, and logging, including common metrics to keep
    an eye on, and defining thresholds beyond which some kind of alert or corrective
    action should be invoked. It also talks about the importance of setting up audit
    trails to keep track of changes to your systems. For cases in which something
    does go wrong, it provides guidelines on establishing support and escalation procedures,
    as well as review processes such as post-mortem assessments to learn from any
    failures.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在可观察性方面，这个支柱提供了关于有效地设置监控、警报和日志的建议，包括需要关注的常见指标，以及定义阈值，超过这些阈值应触发某种警报或纠正措施。它还讨论了设置审计跟踪以跟踪系统更改的重要性。对于出现问题的案例，它提供了建立支持和升级程序以及审查过程（如事后评估）的指南，以从任何失败中学习。
- en: Of course, it’s also important to ensure that your infrastructure is adequately
    scaled to handle your expected traffic volumes and that you implement plans to
    proactively scale accordingly for known peak events.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，确保你的基础设施能够适当地扩展以处理预期的流量量，并且实施计划以主动应对已知的峰值事件，这也是非常重要的。
- en: Finally, this pillar covers the importance of automating as many of your system
    management tasks as possible to minimize how much you need to rely on potentially
    error-prone manual processes to keep your systems running effectively.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这一支柱涵盖了尽可能自动化您的大部分系统管理任务的重要性，以最大限度地减少您需要依赖可能存在错误的手动过程来有效运行系统。
- en: Pillar 3 – Security, privacy, and compliance
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三支柱 – 安全、隐私和合规性
- en: This is perhaps the most relevant of the pillars in the context of ML governance,
    and we’ve already touched on these topics earlier in this chapter, but here, we
    will take a look at how these concepts are more formally structured within the
    Google Cloud Architecture Framework.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML治理的背景下，这可能是最相关的支柱之一，我们已经在本章前面讨论了这些主题，但在这里，我们将探讨这些概念如何在谷歌云架构框架中得到更正式的结构化。
- en: In addition to the concept of DiD that we discussed earlier, Google recommends
    strategies to implement **security by default**. This consists of best practices
    for ensuring that security is built in as the default configuration in your system
    architecture, including concepts such as the **principle of least privilege**
    (**PoLP**), in which users are given the minimum permissions required to perform
    their job functions, and nothing more. It also refers to locking down access at
    the network level. For example, if you know that, in normal operating circumstances,
    your system should only ever be accessed from one or two other systems, then you
    could set up network rules that block access from any sources other than those
    specific systems. Google Cloud also provides an offering called **Confidential
    Computing** for processing sensitive data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们之前讨论的DiD概念之外，谷歌推荐了实施**默认安全**的策略。这包括确保安全作为默认配置嵌入到您的系统架构中的最佳实践，包括诸如**最小权限原则**（**PoLP**）等概念，其中用户仅被授予执行其工作职能所需的最小权限，不再更多。这还涉及到在网络级别锁定访问。例如，如果您知道在正常操作情况下，您的系统应该只从一到两个其他系统访问，那么您可以设置网络规则，阻止来自除这些特定系统之外的任何来源的访问。谷歌云还提供了一种名为**保密计算**的服务，用于处理敏感数据。
- en: 'I want to take this opportunity to highlight that the pillars of the Google
    Cloud Architecture Framework are often interrelated. For example, we talked about
    the concept of GitOps in the context of the *Operational excellence* pillar. This
    concept of using IaC to manage how you deploy to your systems is a highly recommended
    way to establish security-by-default practices. For example, you can create Terraform
    modules that undergo stringent security assessment processes for setting up your
    infrastructure in a way that aligns with your corporate security policies and
    industry-wide best practices. Once those “secure-by-default” modules have been
    approved, anybody in your company could safely use them to set up the required
    infrastructure securely. This makes it much easier for your employees to abide
    by your security policies in terms of provisioning infrastructure. To make it
    easy for you to provision infrastructure resources that align with security best
    practices, Google Cloud provides the **security foundations blueprint**, which
    you can reference at the following URL:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我想借此机会强调，谷歌云架构框架的支柱通常是相互关联的。例如，我们在**运营卓越**支柱的背景下讨论了GitOps的概念。这种使用IaC来管理您如何部署到系统的概念是建立默认安全实践的高度推荐方式。例如，您可以创建经过严格安全评估流程的Terraform模块，以符合您的企业安全政策和行业最佳实践来设置基础设施。一旦这些“默认安全”模块获得批准，公司中的任何人都可以安全地使用它们来设置所需的基础设施。这使得您的员工在提供基础设施方面遵守安全政策变得更加容易。为了使您能够轻松提供符合安全最佳实践的基础设施资源，谷歌云提供了**安全基础蓝图**，您可以在以下URL中参考：
- en: '[https://cloud.google.com/architecture/security-foundations](https://cloud.google.com/architecture/security-foundations)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/architecture/security-foundations](https://cloud.google.com/architecture/security-foundations)'
- en: As an association between this pillar and the pillar of *Operational excellence*,
    the CI/CD pipelines that are used to deploy your resources should have security
    mechanisms built in. For example, you could use automation to check for security
    vulnerabilities when artifacts are created. Google Cloud also provides a mechanism
    called Binary Authorization to validate the contents of Docker containers that
    are built and deployed by your CI/CD pipelines to ensure that those images contain
    exactly what you expect them to contain and nothing more. It can also validate
    that a specific build system or pipeline created a specific container image. If
    a security check highlights any potential problems at any point in your CI/CD
    pipeline, the pipeline can automatically be halted to ensure that potential security
    threats are not introduced into your deployments. Similarly, you can use Google
    Cloud’s Artifact Analysis feature to scan automatically for potential vulnerabilities
    in containers stored in Artifact Registry and Container Registry. Even after deployment,
    you can continuously scan your web applications by using Google Cloud’s Web Security
    Scanner to identify vulnerabilities in applications deployed to Compute Engine,
    App Engine, and GKE.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与*运营卓越*支柱之间的关联，用于部署资源的CI/CD管道应内置安全机制。例如，您可以使用自动化在创建工件时检查安全漏洞。谷歌云还提供了一种称为二进制授权的机制，以验证由CI/CD管道构建和部署的Docker容器的内容，以确保这些镜像正好包含您期望的内容，没有更多。它还可以验证特定的构建系统或管道创建了一个特定的容器镜像。如果在CI/CD管道的任何点上安全检查突出了任何潜在问题，则管道可以自动停止，以确保不会将潜在的安全威胁引入到您的部署中。同样，您可以使用谷歌云的工件分析功能自动扫描存储在工件注册表和容器注册表中的容器中的潜在漏洞。即使在部署之后，您也可以通过使用谷歌云的Web安全扫描器来持续扫描您的Web应用程序，以识别部署到计算引擎、App
    Engine和GKE的应用程序中的漏洞。
- en: This pillar also provides recommendations on proactively identifying and cataloging
    risks to your company and how to mitigate common risks. Google Cloud has also
    recently launched the Risk Protection Program, which includes tools such as Risk
    Manager, to help you manage risks.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 此支柱还提供了主动识别和编制公司风险以及减轻常见风险的建议。谷歌云最近还推出了风险保护计划，其中包括风险管理器等工具，以帮助您管理风险。
- en: Of course, **IAM** is an important component of this pillar. Google Cloud provides
    many tools that help manage this aspect, such as IAM and Cloud Audit Logs, which
    we discussed are essential for access management and auditing.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，**IAM**是这个支柱的一个重要组成部分。谷歌云提供了许多帮助管理这一方面的工具，例如IAM和云审计日志，我们讨论过这些对于访问管理和审计是必不可少的。
- en: This pillar also calls out the importance of using cloud asset management tools
    such as Cloud Asset Inventory to track all of your company’s technology assets
    and monitor for deviations from your compliance policies.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这个支柱还强调了使用云资产管理工具，如云资产清单，来跟踪贵公司所有技术资产并监控是否符合合规政策的重要性。
- en: In addition to all of the topics we’ve covered in this section, the security
    pillar also covers topics such as network security, data security, privacy, and
    regulatory compliance, which we covered earlier in this chapter. It also provides
    details on how to use Google Cloud Assured Workloads to help you meet your compliance
    obligations, how to monitor for compliance, and how to address data sovereignty,
    data residency, software sovereignty, and operational sovereignty.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 除了本节中我们讨论的所有主题外，安全支柱还涵盖了网络安全、数据安全、隐私和法规遵从性等主题，这些内容我们在本章前面已经讨论过。它还提供了如何使用谷歌云保证工作负载来帮助您满足合规义务、如何监控合规性以及如何处理数据主权、数据驻留、软件主权和运营主权等细节。
- en: Pillar 4 – Reliability
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四支柱 – 可靠性
- en: The *Reliability* pillar focuses on concepts such as **high availability** (**HA**),
    scalability, automated change management, and **disaster recovery** (**DR**).
    It covers topics that some of you may know from Google’s SRE practices, such as
    defining **service-level indicators** (**SLIs**), **service-level objectives**
    (**SLOs**), **service-level agreements** (**SLAs**), and error budgets. As was
    the case with the *Operational excellence* pillar, the *Reliability* pillar includes
    observability as a major component. It also reiterates some other concepts from
    the *Operational excellence* pillar, such as automating deployments and incremental
    updates using CI/CD pipelines, and the importance of setting up appropriate observability
    and alerting mechanisms, **incident management** (**IM**), and post-mortem practices.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**可靠性**支柱关注诸如**高可用性**（**HA**）、可伸缩性、自动化变更管理和**灾难恢复**（**DR**）等概念。它涵盖了你们中的一些人可能从谷歌的SRE实践中了解到的主题，例如定义**服务级别指标**（**SLIs**）、**服务级别目标**（**SLOs**）、**服务级别协议**（**SLAs**）和错误预算。与**运营卓越**支柱的情况一样，**可靠性**支柱将可观察性作为一个主要组成部分。它还重申了**运营卓越**支柱中的一些其他概念，例如使用CI/CD管道自动化部署和增量更新，以及设置适当的可观察性和警报机制、**事件管理**（**IM**）和事后分析实践。'
- en: This pillar talks about ways of creating redundancy for higher availability
    in your system architectures, including using multiple Google Cloud zones and
    regions to mitigate any potential issues that may occur in a particular location.
    In addition to these kinds of proactive mitigation techniques, it also outlines
    practices for establishing DR strategies, such as synchronizing data to other
    regions and establishing playbooks for failing over to those regions if needed.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个支柱讨论了在系统架构中创建冗余以提高可用性的方法，包括使用多个谷歌云区域和地区来减轻特定地点可能发生的任何潜在问题。除了这些类型的主动缓解技术之外，它还概述了建立DR策略的实践，例如将数据同步到其他地区，并在需要时建立故障转移至这些地区的操作手册。
- en: Finally, it goes into much detail regarding best practices for specific Google
    Cloud products. This pillar contains a wealth of knowledge and much more detail
    on many specific Google Cloud products than would be appropriate to include here.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它详细介绍了特定谷歌云产品的最佳实践。这个支柱包含了大量的知识，并且比这里适当包含的更多关于许多特定谷歌云产品的详细信息。
- en: Pillar 5 – Cost optimization
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第五支柱 – 成本优化
- en: You can be guaranteed this is very important to almost every customer. In fact,
    cost optimization is often one of the main factors that entice companies to move
    to the cloud in the first place. When companies run their workloads in their own
    data centers, they often have to purchase and install enough infrastructure (and
    more) to cater for their highest peak events that may only happen once or twice
    per year. For the rest of the year, that infrastructure is highly under-utilized,
    which amounts to a lot of wasted money. In the cloud, however, companies can scale
    their infrastructure up and down based on what they actually need and therefore
    do not need to waste money on over-provisioned infrastructure. Also, as discussed
    earlier in this chapter, offloading infrastructure management to a cloud provider
    enables companies to invest their time in innovation and developing features that
    support their core business.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你们可以保证这对几乎每一位客户都非常重要。事实上，成本优化通常是吸引公司首先迁移到云的主要因素之一。当公司在自己的数据中心运行工作负载时，他们通常需要购买和安装足够的（甚至更多）基础设施来满足他们可能一年或两年才发生一次的最高峰值事件。而在一年中的其余时间，这些基础设施高度未被充分利用，这导致了大量的浪费。然而，在云中，公司可以根据他们的实际需求调整其基础设施的规模，因此不需要在过度配置的基础设施上浪费金钱。此外，正如本章前面讨论的那样，将基础设施管理外包给云服务提供商使公司能够将时间投资于创新和开发支持其核心业务的功能。
- en: 'The first major focus of this pillar is on the concept of financial operations
    or **FinOps**, which is a cultural paradigm that includes a set of technical processes
    and business best practices to help organizations optimize and manage their cloud
    investments more effectively. In this context, it’s important to provide each
    technology team in the organization with visibility into their cloud spend and
    for each team to take accountability for that spend. To learn more about FinOps,
    I recommend reading the Google Cloud FinOps whitepaper, which can be found at
    the following URL:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 该支柱的第一个主要重点是财务操作或**FinOps**的概念，这是一个文化范式，包括一系列技术流程和业务最佳实践，以帮助组织更有效地优化和管理他们的云投资。在这种情况下，向组织中的每个技术团队提供对他们的云支出的可见性，并要求每个团队对其支出负责，这是非常重要的。要了解更多关于FinOps的信息，我建议阅读Google
    Cloud FinOps白皮书，该白皮书可以在以下URL找到：
- en: '[https://cloud.google.com/resources/cloud-finops-whitepaper](https://cloud.google.com/resources/cloud-finops-whitepaper)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/resources/cloud-finops-whitepaper](https://cloud.google.com/resources/cloud-finops-whitepaper)'
- en: Remember that we generally cannot optimize or improve something without monitoring
    it. As such, the *Cost optimization* pillar provides recommendations regarding
    monitoring costs, analyzing trends, and forecasting future costs. If you forecast
    that you will spend a certain amount of money in the next year or the next 3 years,
    you can purchase **committed use discounts** (**CUDs**) to save money on those
    workloads. You can also use labels to categorize your expenses in billing reports,
    such as attributing resource expenses to specific workloads and environments.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们通常无法在没有监控的情况下优化或改进某事物。因此，“成本优化”支柱提供了关于监控成本、分析趋势和预测未来成本的推荐。如果你预测你将在下一年或未来三年内花费一定金额，你可以购买**承诺使用折扣**（**CUDs**）来节省那些工作负载的费用。你还可以使用标签对账单报告中的费用进行分类，例如将资源费用分配给特定的作业和环境。
- en: The *Cost optimization* pillar also provides best practices on **optimizing**
    resource usage to reduce costs, such as ensuring that you provision your infrastructure
    based on your current and projected needs (including some buffer where appropriate),
    and do not over-provision. This is referred to as **right-sizing**, and Google
    Cloud even provides a right-sizing recommender that can highlight opportunities
    for improving your sizing by identifying resources that appear to be under-utilized
    (and therefore over-provisioned). You should also use auto-scaling, which, in
    addition to ensuring that you have enough resources to serve your required traffic
    volumes, can scale resources down when they’re not needed, thus saving money.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: “成本优化”支柱还提供了关于**优化**资源使用以降低成本的最佳实践，例如确保你根据当前和预期的需求（包括适当的情况下的一些缓冲）来配置你的基础设施，并且不要过度配置。这被称为**正确规模**，Google
    Cloud甚至提供了一个正确规模推荐器，可以突出显示通过识别看似未充分利用（因此过度配置）的资源来改进规模的机会。你还应该使用自动扩展，这不仅确保你有足够的资源来服务所需的流量量，而且在不需要时可以缩减资源，从而节省资金。
- en: When implementing cost optimization mechanisms, it’s important to set up budgets,
    alerts, and quotas to control your spending. For example, you can specify a certain
    spending budget and get alerted when you are close to reaching that budget. You
    can also use quotas to set hard limits on resource usage and can set API caps
    to limit API usage after a certain threshold is reached.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施成本优化机制时，设置预算、警报和配额以控制支出是很重要的。例如，你可以指定一个特定的支出预算，并在接近达到该预算时收到警报。你还可以使用配额来设置资源使用的硬性限制，并可以设置API上限，以在达到一定阈值后限制API的使用。
- en: As with the *Reliability* pillar, the *Cost optimization* pillar provides detailed
    best practices for many specific Google Cloud products, such as optimizing storage
    tiers in **Google Cloud Storage** (**GCS**) or optimizing partitions in BigQuery.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 与**可靠性**支柱一样，“成本优化”支柱为许多具体的Google Cloud产品提供了详细的最佳实践，例如优化**Google Cloud Storage**（**GCS**）中的存储层或优化BigQuery中的分区。
- en: Pillar 6 – Performance optimization
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第六支柱 – 性能优化
- en: Performance optimization can be linked to cost optimization, so there is some
    overlap in terms of these concepts. For example, if your systems are performing
    optimally, then they may be less costly to run. A well-implemented auto-scaling
    strategy is a prime example of this. The *Performance optimization* pillar provides
    recommendations on how to define performance requirements, how to monitor and
    analyze performance, and, of course, how to optimize performance.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 性能优化可以与成本优化相关联，因此在这些概念方面存在一些重叠。例如，如果你的系统运行得最优，那么它们可能运行成本更低。实施良好的自动扩展策略是这一点的典型例子。**性能优化**支柱提供了如何定义性能要求、如何监控和分析性能以及当然如何优化性能的建议。
- en: In terms of monitoring and analyzing performance, this refers back to the concept
    of observability, in which we need to implement and monitor performance metrics
    such as latency and resource utilization.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控和分析性能方面，这指的是可观察性的概念，我们需要实施和监控性能指标，如延迟和资源利用率。
- en: As with the *Reliability* and *Cost optimization* pillars, the *Performance
    optimization* pillar also provides many in-depth recommendations for specific
    Google Cloud products, which is a level of detail beyond what would be appropriate
    to include here.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 就像**可靠性**和**成本优化**支柱一样，**性能优化**支柱也为特定的Google Cloud产品提供了许多深入的建议，这是超出这里适当包含的详细程度。
- en: Now that you understand what the Google Cloud Architecture Framework is and
    what it consists of, let’s look at how we can apply its concepts in the context
    of AI/ML on Google Cloud.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经了解了Google Cloud架构框架是什么以及它由什么组成，让我们看看我们如何在Google Cloud的AI/ML环境中应用其概念。
- en: Note
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Across all of the categories in the Google Cloud Architecture Framework, the
    theme that is reiterated the most is automation. The idea is to automate everything
    as much as possible. Vetted, repeatable processes that can run automatically tend
    to make our jobs easier across all pillars.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Cloud架构框架的所有类别中，最经常重复的主题是自动化。想法是尽可能自动化一切。经过验证、可重复且可自动运行的过程往往会使我们在所有支柱上的工作变得更简单。
- en: Architecture Framework concepts about AI/ML workloads on Google Cloud
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于Google Cloud上AI/ML工作负载的架构框架概念
- en: 'In this section, we will assess how the Google Cloud Architecture Framework
    can be used with regard to AI/ML workloads on Google Cloud. We will use the steps
    in the model development life cycle to frame our discussion. As a reminder, the
    steps in the model development life cycle are summarized at a high level in *Figure
    13**.5*:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将评估如何使用Google Cloud架构框架来处理Google Cloud上的AI/ML工作负载。我们将使用模型开发生命周期中的步骤来构建我们的讨论框架。作为提醒，模型开发生命周期的步骤在*图13.5*中进行了高层次的总结：
- en: '![Figure 13.5: The ML model development life cycle](img/B18143_13_5.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图13.5：ML模型开发生命周期](img/B18143_13_5.jpg)'
- en: 'Figure 13.5: The ML model development life cycle'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5：ML模型开发生命周期
- en: Let’s begin with the data collection and preparation activities in the model
    development life cycle, which include gathering, ingesting, storing, and processing
    data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从模型开发生命周期中的数据收集和准备活动开始，这些活动包括收集、摄取、存储和处理数据。
- en: Spoiler alert!
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 揭秘！
- en: You will notice that we have already been using many of these practices throughout
    this book. Here, we are calling them out explicitly so that you can understand
    how they apply to workloads in general.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，我们已经在整本书中使用了许多这些实践。在这里，我们明确指出这些实践，以便你了解它们如何应用于一般的工作负载。
- en: Data collection and preparation
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集和准备
- en: Data management is perhaps the most important of all the topics related to ML
    governance. As we know by now, the quality of your data directly impacts the quality
    of your models. Also, in terms of security, when malicious actors try to access
    your systems, they are usually after your data, because data is such a valuable
    resource, and data breaches can have catastrophic effects for your company. Let’s
    look at how we can apply recommendations in the Google Cloud Architecture Framework
    regarding data handling. In this case, we will not discuss system design as a
    separate pillar, because an effective system design encapsulates all of the other
    pillars.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管理可能是与ML治理相关的所有主题中最重要的。正如我们所知，你的数据质量直接影响你模型的质量。此外，从安全的角度来看，当恶意行为者试图访问你的系统时，他们通常是为了你的数据，因为数据是一种如此有价值的资源，数据泄露可能对你的公司产生灾难性的影响。让我们看看我们如何应用Google
    Cloud架构框架中关于数据处理的建议。在这种情况下，我们不会将系统设计作为一个单独的支柱来讨论，因为有效的系统设计封装了所有其他支柱。
- en: Operational excellence in data collection and preparation
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集和准备中的运营卓越
- en: Remember that operational excellence focuses on concepts such as automation,
    observability, and availability. The following sub-sections explore these concepts
    in the context of data collection and preparation.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，运营卓越关注自动化、可观察性和可用性等概念。以下子章节将探讨这些概念在数据收集和准备中的具体应用。
- en: Process automation and integration
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 流程自动化和集成
- en: In earlier chapters of this book, I talked about the importance of building
    data pipelines to automate our data processing steps. Essentially, we want to
    establish repeatable processes and then put in place mechanisms to run those processes
    automatically, either based on a schedule (such as daily, weekly, or monthly)
    or in reaction to some event, such as new data becoming available. Hence, the
    concept of implementing data processing pipelines is an application of the automation
    recommendations outlined in the *Operational excellence* pillar of the Google
    Cloud Architecture Framework. Google Cloud provides many services that we can
    integrate together to set up data processing pipelines, such as Dataproc, Dataflow,
    GCS, Pub/Sub, and BigQuery.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前几章中，我谈到了构建数据管道以自动化我们的数据处理步骤的重要性。本质上，我们希望建立可重复的过程，然后实施机制来自动运行这些过程，无论是基于时间表（如每日、每周或每月）还是对某些事件（如新数据的可用性）的反应。因此，实施数据处理管道的概念是谷歌云架构框架中“运营卓越”支柱中概述的自动化建议的应用。谷歌云提供了许多我们可以集成在一起以设置数据处理管道的服务，例如Dataproc、Dataflow、GCS、Pub/Sub和BigQuery。
- en: Consistency and standardization
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一致性和标准化
- en: In the MLOps chapter, I shared experiences I’ve had with various organizations
    at different levels of maturity in terms of how they implemented their ML workload
    operations. When companies do not have well-established processes in place, their
    teams tend to use lots of random different tools that each have their own learning
    curves, and they maintain their artifacts in silos. These practices are not conducive
    to company-wide collaboration, and they hinder the scalability and efficiency
    of a company’s ML operations. I then talked about the importance of standardizing
    tools and processes throughout the company in order to overcome those limitations.
    This all relates to the operational excellence pillar of the Google Cloud Architecture
    Framework. Consistency in tools, libraries, and processes across teams and projects
    reduces complexity and learning curves, making it easier to manage and scale operations.
    Perhaps the most relevant example of this, in relation to ML operations, is to
    use Vertex AI for all of our model development and deployment needs, since it
    provides a standard set of tools for every step in the model development and management
    life cycle.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在MLOps章节中，我分享了与不同成熟度级别的各种组织合作的经验，这些组织在实施他们的机器学习工作负载操作方面有所不同。当公司没有建立良好的流程时，他们的团队往往会使用大量随机不同的工具，每个工具都有自己的学习曲线，并且他们在孤岛中维护他们的工件。这些做法不利于公司范围内的协作，并阻碍了公司机器学习操作的扩展性和效率。然后我谈到了在整个公司标准化工具和流程的重要性，以克服这些限制。这一切都与谷歌云架构框架的运营卓越支柱有关。在团队和项目之间保持工具、库和流程的一致性，可以减少复杂性和学习曲线，使管理和扩展操作变得更加容易。也许与机器学习操作最相关的例子是，为了满足我们所有模型开发和部署需求，使用Vertex
    AI，因为它为模型开发和管理的生命周期中的每个步骤提供了一套标准工具。
- en: Observability
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可观察性
- en: All of the regular system monitoring and logging requirements also apply to
    AI/ML workloads, and AI/ML workloads also have additional requirements regarding
    monitoring the quality of model prediction outputs on an ongoing basis to ensure
    that they do not drift over time. In earlier chapters, we discussed ML-specific
    metrics to monitor, such as MSE for linear regression use cases or AUC-ROC scores
    for classification use cases, as well as fairness metrics. Google Cloud Logging
    and Google Cloud Monitoring can be used for observability purposes at all points
    in the ML model development life cycle on Google Cloud, from evaluating training
    validation metrics to tracking the latency of responses from a model deployed
    on a Vertex AI prediction endpoint, and Vertex AI Model Monitoring can be used
    to watch for drift.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 所有常规的系统监控和日志记录要求也适用于 AI/ML 工作负载，并且 AI/ML 工作负载还有关于持续监控模型预测输出质量方面的额外要求，以确保它们不会随时间漂移。在早期章节中，我们讨论了用于监控的特定于
    ML 的指标，例如线性回归用例的 MSE 或分类用例的 AUC-ROC 分数，以及公平性指标。谷歌云日志和谷歌云监控可用于在谷歌云上 ML 模型开发生命周期的所有点上实现可观察性，从评估训练验证指标到跟踪在
    Vertex AI 预测端点部署的模型响应的延迟，以及 Vertex AI 模型监控可用于监视漂移。
- en: Security, privacy, and compliance in data collection and preparation
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集和准备中的安全、隐私和合规性
- en: By now, we should thoroughly understand that data security and privacy are paramount
    in almost every company. One sure way to quickly lose customers and damage your
    company’s reputation is to become a victim of a data breach. My opinion is that
    managing sensitive data securely is the most important thing you can possibly
    do; it takes priority over all other considerations in this chapter, this book,
    and your company’s business.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我们应该已经充分理解，在几乎每家公司中，数据安全和隐私都是至关重要的。一种快速失去客户并损害公司声誉的方式就是成为数据泄露的受害者。我的观点是，安全地管理敏感数据是你可能能做的事情中最重要的；它比本章、这本书以及你公司的业务中的所有其他考虑都更重要。
- en: In our overview of this pillar earlier in this chapter, we talked about how
    data and systems should be protected through multiple layers of defenses (DiD),
    incorporating factors such as access management, encryption, and network security.
    The following sub-sections explore these concepts in the context of data collection
    and preparation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面关于这一支柱的概述中，我们讨论了如何通过多层防御（DiD）来保护数据和系统，包括访问管理、加密和网络安全等因素。以下小节将探讨这些概念在数据收集和准备背景下的应用。
- en: Data access control
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据访问控制
- en: When collecting and preparing data in Google Cloud, we can use IAM to ensure
    that only authorized individuals and services can access the data, and we can
    control who can view, modify, or interact with the data based on roles and responsibilities.
    For example, a data scientist might have permission to read and analyze data but
    not delete it, or finance data may only be accessible to the finance department.
    This is made easier if we use Google Cloud Dataplex to build a data catalog because
    Dataplex allows us to centrally manage permissions for our data assets across
    multiple different GCS and processing services.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在谷歌云中收集和准备数据时，我们可以使用 IAM 来确保只有授权的个人和服务可以访问数据，并且我们可以根据角色和职责控制谁可以查看、修改或与数据交互。例如，数据科学家可能只有读取和分析数据的权限，但没有删除数据的权限，或者财务数据可能仅供财务部门访问。如果我们使用谷歌云
    Dataplex 来构建数据目录，这会变得更加容易，因为 Dataplex 允许我们集中管理跨多个不同的 GCS 和处理服务的我们的数据资产权限。
- en: Data protection and encryption
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据保护和加密
- en: Sensitive data should always be encrypted, both when it’s stored (at rest) and
    when it’s being transferred between services or locations (in transit). Google
    Cloud provides automatic encryption for data stored in its services, and we can
    use TLS to protect data in transit. For highly sensitive data, we can even encrypt
    it during processing by using Google Cloud Confidential Computing. Also, during
    the data preparation phase, sensitive data elements can be masked or tokenized
    to hide their actual values, therefore enhancing privacy while still allowing
    the data to be used for analysis.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据应始终加密，无论是在存储（静止状态）时还是在服务或位置之间传输时（传输中）。谷歌云为其服务中存储的数据提供自动加密，我们可以使用 TLS 来保护传输中的数据。对于高度敏感的数据，我们甚至可以使用谷歌云
    Confidential Computing 在处理过程中对其进行加密。此外，在数据准备阶段，敏感数据元素可以被屏蔽或标记化，以隐藏其实际值，从而在增强隐私的同时，仍然允许数据用于分析。
- en: Data classification and discovery
  id: totrans-210
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据分类和发现
- en: We can use the Google Cloud Sensitive Data Protection service to discover, classify,
    and mask sensitive elements in datasets. When collecting data, this service can
    help automatically identify information such as **personally identifiable information**
    (**PII**) or financial data so that we can treat it with higher levels of protection.
    This is another area in which Google Cloud Dataplex can help because tracking
    all of our data assets in a data catalog makes classification and discovery easy.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Google Cloud敏感数据保护服务来发现、分类和屏蔽数据集中的敏感元素。在收集数据时，此服务可以帮助自动识别诸如**个人身份信息**（**PII**）或财务数据等信息，以便我们能够对其进行更高水平的保护。这是Google
    Cloud Dataplex可以提供帮助的另一个领域，因为在一个数据目录中跟踪所有我们的数据资产使得分类和发现变得容易。
- en: Auditing and monitoring
  id: totrans-212
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 审计和监控
- en: We introduced Cloud Audit Logs earlier. We can use Cloud Audit Logs to keep
    a detailed log of who accesses the data and what operations they perform, which
    is important for accountability and traceability. This is especially relevant
    in ML workloads, where understanding who introduced what data and when can be
    required for explainability and troubleshooting. And, guess what?! Google Cloud
    Dataplex integrates with Cloud Audit Logs to generate audit logs for actions that
    are performed in the data catalog.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前介绍了云审计日志。我们可以使用云审计日志来详细记录谁访问了数据以及他们执行了哪些操作，这对于问责和可追溯性非常重要。这在机器学习工作负载中尤其相关，因为了解谁引入了什么数据以及何时引入可能对于可解释性和故障排除是必需的。而且，你知道吗？！Google
    Cloud Dataplex与云审计日志集成，以生成数据目录中执行的操作的审计日志。
- en: Data retention and deletion
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据保留和删除
- en: When using Google Cloud, we can establish policies about how long data should
    be retained based on its nature and relevance. When using GCS, for example, a
    retention policy can be specified to prevent an object from being deleted within
    the timeframe specified by the retention policy. This can be important for regulatory
    purposes or to comply with legal holds. Conversely, Object Lifecycle Management
    can be used to automatically delete data after a certain period (as long as it
    does not conflict with a data retention policy). For sensitive data that you want
    to delete permanently, Google Cloud provides mechanisms to ensure that the deletion
    is performed securely and is irrecoverable.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Google Cloud时，我们可以根据数据性质和相关性建立数据保留政策。例如，在使用GCS时，可以指定保留策略以防止对象在保留策略指定的时间框架内被删除。这对于符合监管目的或遵守法律保留可能很重要。相反，可以使用对象生命周期管理在一段时间后自动删除数据（只要它不与数据保留策略冲突）。对于您希望永久删除的敏感数据，Google
    Cloud提供机制以确保删除操作安全且不可恢复。
- en: Compliance frameworks and certifications
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 合规框架和认证
- en: Google Cloud provides tools and documentation to help businesses comply with
    standards such as GDPR and HIPAA (as well as many more), and it undergoes independent
    third-party audits to ensure its services comply with common regulatory standards.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud提供工具和文档，帮助业务符合GDPR和HIPAA等标准（以及许多其他标准），并且它接受独立第三方审计，以确保其服务符合常见的监管标准。
- en: Resilience against threats
  id: totrans-218
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 防御威胁
- en: Services such as Cloud Security Command Center and Event Threat Detection allow
    for continuous data and environment monitoring for potential threats, offering
    insights and actionable recommendations. Regularly scanning and assessing the
    systems involved in data collection and preparation for vulnerabilities can help
    ensure that data isn’t exposed to potential breaches. You can also use VPC network
    security and VPC-SC to control access to your data storage and processing systems
    and to prevent data exfiltration.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 云安全命令中心和事件威胁检测等服务允许对潜在威胁进行持续的数据和环境监控，提供洞察和可操作的推荐。定期扫描和评估数据收集和准备过程中涉及的系统，可以帮助确保数据不会暴露于潜在的违规风险。您还可以使用VPC网络安全和VPC-SC来控制对您的数据存储和处理系统的访问，以防止数据泄露。
- en: All of the items we discussed in this section are important to ensure that data
    is handled securely and that user privacy is protected. Ethical considerations
    also come into play to ensure that data is collected and used in ways that are
    fair, transparent, and don’t propagate biases, especially when it’ll be used to
    train ML models that might impact individuals’ lives.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中讨论的所有项目对于确保数据安全处理和保护用户隐私都至关重要。道德考量也至关重要，以确保数据以公平、透明的方式收集和使用，不会传播偏见，尤其是在它将被用于训练可能影响个人生活的机器学习模型时。
- en: Reliability in data collection and preparation
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集和准备中的可靠性
- en: Remember that the *Reliability* pillar in the Google Cloud Architecture Framework
    focuses on ensuring that services and applications perform consistently and meet
    the expected SLOs, even in the case of unexpected disturbances or increased demands.
    The following sub-sections discuss how we can apply concepts from the *Reliability*
    pillar in the data collection and preparation phases of the ML model development
    life cycle.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，谷歌云架构框架中的**可靠性**支柱侧重于确保服务和应用程序在意外干扰或需求增加的情况下也能持续一致地运行，并满足预期的SLOs。以下子部分讨论了如何在机器学习模型开发生命周期的数据收集和准备阶段应用**可靠性**支柱的概念。
- en: Automated data ingestion and processing
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自动化数据摄取和处理
- en: Relying on manual processes for data collection can be prone to errors, while
    automated data ingestion helps to ensure that data can be collected consistently.
    We can also automate data validation steps to ensure that incoming data adheres
    to the expected formats and value ranges, which can prevent corrupted or malformed
    data from propagating through our data processing and ML pipelines. For data transformation
    scripts and configurations, we should use version control to ensure that if changes
    introduce errors, we can easily revert to a previous, stable version.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于手动过程进行数据收集可能会出错，而自动数据摄取有助于确保数据可以一致地收集。我们还可以自动化数据验证步骤，以确保传入的数据符合预期的格式和值范围，这可以防止损坏或格式不正确的数据在我们的数据处理和机器学习管道中传播。对于数据转换脚本和配置，我们应该使用版本控制来确保如果更改引入了错误，我们可以轻松地回滚到先前的稳定版本。
- en: Infrastructure resilience
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基础设施弹性
- en: Many of Google Cloud’s data storage and processing services are either designed
    for HA by default or provide mechanisms to help you build resilience into your
    architecture, such as by using multiple machines across multiple zones and regions.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌云的大多数数据存储和处理服务要么默认设计为高可用性，要么提供机制来帮助您将弹性构建到架构中，例如通过在多个区域和地区使用多台机器。
- en: If we are designing systems ourselves, we should ensure that data storage and
    processing infrastructure have redundant components. In the event of a failure,
    backup systems can take over, ensuring uninterrupted data collection and preparation.
    We should also implement backup and restore mechanisms to regularly back up raw
    and processed data. We could store data across multiple zones or regions to safeguard
    against potential issues in any particular location. This not only protects against
    data loss but also allows for restoring to a previous state if data becomes corrupted
    or if there’s a need to revisit earlier data versions. We could also implement
    load balancing for data ingestion services for high-velocity data streams to help
    ensure an even distribution of data loads and prevent system overloads. We should
    also design our infrastructure to scale (up or out) based on demand to ensure
    reliable performance under varying loads, and we could implement queueing mechanisms
    to manage data spikes.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们自行设计系统，我们应该确保数据存储和处理基础设施具有冗余组件。在发生故障的情况下，备份系统可以接管，确保数据收集和准备不间断。我们还应该实施备份和恢复机制，定期备份原始和经过处理的数据。我们可以将数据存储在多个区域或地区，以防止任何特定位置的潜在问题。这不仅保护了数据丢失，还允许在数据损坏或需要回顾早期数据版本时恢复到之前的状态。我们还可以为高速数据流的数据摄取服务实施负载均衡，以确保数据负载的均匀分布并防止系统过载。我们还应该设计我们的基础设施根据需求进行扩展（向上或向外），以确保在变化负载下的可靠性能，并可以实施排队机制来管理数据峰值。
- en: Continuous monitoring and alerts
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 持续监控和警报
- en: As is the case with the *Operational excellence* pillar, observability is a
    key component of this pillar. We should regularly check the health of systems
    involved in data collection and preparation and implement alerting mechanisms
    that notify relevant teams when anomalies or failures are detected.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 与**运营卓越**支柱一样，可观察性是这个支柱的关键组成部分。我们应该定期检查参与数据收集和准备的系统健康状况，并实施当检测到异常或故障时通知相关团队的警报机制。
- en: Cost optimization in data collection and preparation
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集和准备中的成本优化
- en: Managing costs is important during data collection and preparation due to potentially
    vast volumes of data, complex preprocessing tasks, and varying infrastructure
    needs. The following sub-sections discuss how we can apply concepts from the *Cost
    optimization* pillar in the data collection and preparation phases of the ML model
    development life cycle.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据收集和准备阶段，由于可能涉及大量数据、复杂的预处理任务以及不断变化的基础设施需求，管理成本至关重要。以下子节将讨论我们如何在机器学习模型开发生命周期的数据收集和准备阶段应用来自*成本优化*支柱的概念。
- en: Efficient data storage
  id: totrans-232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 高效的数据存储
- en: Storage systems such as GCS and BigQuery provide various classes of storage
    that are priced differently. From a cost optimization perspective, it’s important
    that we use the appropriate storage class for our data. For example, frequently
    accessed data can be stored in Standard storage, while infrequently accessed data
    could be moved to Nearline or Coldline storage. To make this easier for us to
    manage, we can implement policies to automatically transition data to cheaper
    storage classes or delete it once it’s no longer needed. We could also reduce
    the amount of data stored (and, therefore, reduce our costs) by removing duplicates
    and compressing our data. In terms of feature storage, we should evaluate the
    necessity of every feature during the data preparation stage. Removing redundant
    or low-importance features can significantly reduce storage and computation costs.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如GCS和BigQuery之类的存储系统提供了不同类别的存储，价格各不相同。从成本优化的角度来看，使用适合我们数据的适当存储类别非常重要。例如，频繁访问的数据可以存储在标准存储中，而很少访问的数据可以转移到近线或冷线存储。为了使我们更容易管理，我们可以实施策略以自动将数据过渡到更便宜的存储类别或在其不再需要时删除它。我们还可以通过删除重复数据并压缩数据来减少存储的数据量（因此减少我们的成本）。在特征存储方面，我们应该在数据准备阶段评估每个特征的需求。删除冗余或低重要性的特征可以显著降低存储和计算成本。
- en: Optimized data processing
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优化的数据处理
- en: I’m a huge fan of using serverless solutions wherever possible. Not only do
    we offload the headaches of managing infrastructure to the cloud provider, but
    with serverless solutions such as BigQuery and Dataflow, we generally only pay
    for what we use, and we don’t have to worry about over-provisioning (and therefore
    overpaying for) infrastructure. We can also opt for scalable services such as
    GKE or Cloud Dataflow that can handle spikes in data processing loads but scale
    down in low-demand periods, and for non-critical, fault-tolerant data processing
    tasks, we can use preemptible **virtual machines** (**VMs**), which are generally
    cheaper than regular instances.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我非常推崇尽可能使用无服务器解决方案。这不仅将管理基础设施的烦恼转移给了云服务提供商，而且使用BigQuery和Dataflow等无服务器解决方案，我们通常只需为使用的部分付费，无需担心过度配置（因此过度支付）基础设施。我们还可以选择可扩展的服务，如GKE或Cloud
    Dataflow，这些服务可以处理数据处理负载的峰值，但在低需求时期可以缩减规模，对于非关键、容错的数据处理任务，我们可以使用预付费的**虚拟机**（**VMs**），这通常比常规实例便宜。
- en: It’s also important to consider the location of our data, and we should generally
    aim to process data as near as possible to where it resides for a number of reasons,
    including cost and latency. For example, storing our data in the `us-central1`
    region while our processing infrastructure is located in the `us-east4` region
    would be sub-optimal from a latency perspective and would incur additional network
    egress costs as the data is transmitted across regions. This also applies in the
    cases of hybrid cloud infrastructures, in which some of your resources are in
    the cloud while others are located on your own premises. In such cases, consider
    the location at which your on-premises resources are connected to the cloud, as
    well as the data storage location and data processing location. We discussed the
    various methods of connecting your on-premises resources to Google Cloud (such
    as VPNs and “interconnects”) in [*Chapter 3*](B18143_03.xhtml#_idTextAnchor059),
    and you can further bolster the security of such hybrid configurations by using
    VPC-SC to establish a trusted perimeter within which your data is transmitted
    and processed.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们的数据位置也很重要，我们通常应尽可能在数据所在位置附近处理数据，出于多种原因，包括成本和延迟。例如，如果我们把数据存储在`us-central1`区域，而我们的处理基础设施位于`us-east4`区域，从延迟的角度来看将是不理想的，并且会因数据跨区域传输而产生额外的网络出口成本。这同样适用于混合云基础设施的情况，其中一些资源位于云中，而其他资源位于您的自有设施上。在这种情况下，考虑您的本地资源连接到云的位置，以及数据存储位置和数据处理位置。我们已在[*第三章*](B18143_03.xhtml#_idTextAnchor059)中讨论了将您的本地资源连接到Google
    Cloud的各种方法（例如VPN和“互连”），您还可以通过使用VPC-SC在数据传输和处理过程中建立可信边界来进一步增强此类混合配置的安全性。
- en: Also, if we are using VMs and those VMs need to work together to process our
    data, we can use **Google Compute Engine** (**GCE**) placement policies (specifically,
    the “compact placement policy”) to specify that our VMs should be located close
    to each other, which can be particularly important for **high-performance computing**
    (**HPC**) workloads.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果我们正在使用虚拟机（VMs），并且这些虚拟机需要协同工作来处理我们的数据，我们可以使用**Google Compute Engine**（**GCE**）的放置策略（特别是“紧凑放置策略”）来指定我们的虚拟机应彼此靠近，这对于**高性能计算**（**HPC**）工作负载尤为重要。
- en: Finally, where real-time processing isn’t necessary, we can accumulate data
    and process it in batches, which is often more cost-effective than streaming.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果不需要实时处理，我们可以累积数据并批量处理，这通常比流式传输更经济。
- en: Cost monitoring and analytics
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 成本监控和分析
- en: We can use tools such as Cost Explorer or custom dashboards in Cloud Monitoring
    to get insights into our spending patterns and set up billing alerts to notify
    us of unexpected spikes in costs so that we can intervene accordingly in a timely
    manner. Additionally, we should regularly analyze our billing reports to identify
    areas where costs can be trimmed, such as by looking for under-utilized resources
    or services.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用诸如成本探索器或云监控中的自定义仪表板等工具来了解我们的支出模式，并设置账单警报以通知我们意外成本激增的情况，这样我们就可以及时采取相应措施。此外，我们还应定期分析我们的账单报告，以确定可以削减成本的区域，例如通过寻找未充分利用的资源或服务。
- en: Cost governance
  id: totrans-241
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 成本治理
- en: A good practice is to set budgets for projects or departments and implement
    quotas for specific services to prevent unintentional overspending. It’s also
    important to establish a resource organization and cost attribution strategy.
    We can use Google Cloud projects, folders, and labels to organize and attribute
    costs, which makes it easier to track and optimize expenses for specific tasks
    or teams, and we should promote a culture in which teams are aware of the costs
    associated with their data handling and processing activities, and encourage cost-saving
    practices.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的做法是为项目或部门设置预算，并为特定服务实施配额，以防止意外超支。建立资源组织和成本归属策略也很重要。我们可以使用Google Cloud项目、文件夹和标签来组织和分配成本，这使得跟踪和优化特定任务或团队的支出变得更容易，我们还应该推广一种文化，让团队意识到他们数据处理和活动相关的成本，并鼓励节约成本的做法。
- en: Regular reviews
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 定期审查
- en: We should regularly review the architecture of our data collection and preparation
    systems because newer and more cost-effective solutions might emerge over time.
    Similarly, we should periodically evaluate the relevance of the data we’re collecting
    because some data might become irrelevant over time, and the costs associated
    with its collection, storage, and processing could be eliminated.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该定期审查我们的数据收集和准备系统架构，因为随着时间的推移，可能会出现更新、更经济的解决方案。同样，我们也应该定期评估我们收集的数据的相关性，因为一些数据可能会随着时间的推移而变得不相关，与其收集、存储和处理相关的成本可以消除。
- en: Performance optimization in data collection and preparation
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集和准备中的性能优化
- en: As we discussed in the overview sections earlier in this chapter, there are
    some links between performance optimization and cost optimization because a system
    that performs optimally will often use resources more efficiently. The following
    sub-sections discuss how we can apply concepts from the *Performance optimization*
    pillar in the data collection and preparation phases of the ML model development
    life cycle.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在本章前面的概述部分所讨论的，性能优化和成本优化之间存在一些联系，因为表现最优的系统通常会更有效地使用资源。以下子部分将讨论我们如何将来自*性能优化*支柱的概念应用于机器学习模型开发生命周期的数据收集和准备阶段。
- en: High-performance data collection
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 高性能数据收集
- en: To optimize our data ingestion processes for real-time data ingestion, we can
    use services such as Cloud Pub/Sub or Cloud Dataflow, which can help to achieve
    minimal latency and efficient data streaming. We can also use parallel processing
    in our data collection strategies by using distributed systems to fetch data from
    multiple sources concurrently, thus making our data collection more efficient.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化我们的实时数据摄取过程，我们可以使用如Cloud Pub/Sub或Cloud Dataflow等服务，这些服务可以帮助实现最小延迟和高效的数据流。我们还可以通过使用分布式系统从多个来源并发获取数据，在我们的数据收集策略中使用并行处理，从而使我们的数据收集更加高效。
- en: Efficient data storage
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 高效数据存储
- en: It’s important to use appropriate data structures such as columnar formats (for
    example, Parquet) for analytics workloads, which can lead to faster querying.
    In the case of high-performance storage use cases, we can use storage solutions
    such as Cloud Bigtable for low-latency, high-throughput workloads, which can help
    to ensure quick data access during the preparation phase. How we index our datasets
    can also improve the speed of retrieval and querying, which is especially important
    for large datasets during the data exploration phase.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 使用适当的数据结构，如列式格式（例如，Parquet）进行分析工作负载非常重要，这可以导致更快的查询。在高性能存储用例中，我们可以使用如Cloud Bigtable等存储解决方案，以低延迟、高吞吐量工作负载，这有助于确保在准备阶段快速访问数据。我们如何索引我们的数据集也可以提高检索和查询的速度，这在数据探索阶段对大型数据集尤为重要。
- en: Accelerated data processing
  id: totrans-251
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 加速数据处理
- en: We can use platforms such as Cloud Dataflow and Cloud Dataproc, which provide
    managed Beam, Spark, and Hadoop clusters, to distribute data processing tasks
    across multiple nodes. For workloads such as feature engineering or data augmentation
    tasks in ML, using hardware accelerators such as GPU/TPU acceleration can drastically
    improve performance. Also, in platforms such as BigQuery, we can write optimized
    SQL queries to minimize computational overhead and improve processing speed.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用如Cloud Dataflow和Cloud Dataproc等平台，这些平台提供托管Beam、Spark和Hadoop集群，以在多个节点间分配数据处理任务。对于机器学习中的特征工程或数据增强任务等工作负载，使用如GPU/TPU加速器等硬件加速器可以显著提高性能。此外，在如BigQuery等平台上，我们可以编写优化的SQL查询以最小化计算开销并提高处理速度。
- en: Network optimization
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 网络优化
- en: If we’re transferring large amounts of data from on-premises systems to Google
    Cloud, dedicated interconnects provide a high-speed, low-latency connection. For
    collecting data from global sources, **content delivery networks** (**CDNs**)
    ensure optimal data transfer speeds, and we can also use tools such as Traffic
    Director to manage and optimize network traffic, ensuring efficient data flow
    between services.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从本地系统向Google Cloud传输大量数据，专用互连提供高速、低延迟的连接。对于从全球来源收集数据，**内容分发网络**（**CDNs**）确保最佳数据传输速度，我们还可以使用如Traffic
    Director等工具来管理和优化网络流量，确保服务之间高效的数据流。
- en: Resource allocation and auto-scaling
  id: totrans-255
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 资源分配和自动扩展
- en: As we discussed earlier, it’s important to ensure that services automatically
    scale resources based on demand. For example, Cloud Dataflow can auto-scale worker
    instances based on the data processing load. We should also tailor VM types and
    configurations (in terms of memory and CPU resources) to the specific needs of
    the data collection and preparation tasks.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，确保服务根据需求自动扩展资源非常重要。例如，Cloud Dataflow 可以根据数据处理负载自动扩展工作实例。我们还应该根据数据收集和准备任务的具体需求调整虚拟机类型和配置（在内存和
    CPU 资源方面）。
- en: Next, let’s discuss how the Google Cloud Architecture Framework applies to the
    model building and training steps in our model development life cycle.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论如何将 Google Cloud 架构框架应用于我们模型开发生命周期中的模型构建和训练步骤。
- en: Model building and training
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型构建和训练
- en: As we did in the previous section regarding data collection and preparation,
    we will discuss the concepts of each pillar in the context of this phase in the
    model development life cycle.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在上一节关于数据收集和准备中做的那样，我们将在这个模型开发生命周期阶段的背景下讨论每个支柱的概念。
- en: Operational excellence in model building and training
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型构建和训练中的运营卓越
- en: Let’s begin with operational excellence, and how it applies to model building
    and training.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从运营卓越开始，并探讨它如何应用于模型构建和训练。
- en: Standardized and automated workflows
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 标准化和自动化工作流程
- en: The key components here are MLOps pipelines, version control, and CI/CD tooling.
    We can use Vertex AI Pipelines to create standardized, end-to-end ML pipelines
    that automate our model training and evaluation steps, including hyperparameter
    optimization. We can use Google Cloud’s source control tooling to manage our pipeline
    definition code, and Google Cloud’s CI/CD tooling, such as Cloud Build and Cloud
    Deploy, to build and deploy our pipeline definitions to Vertex AI Pipelines.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这里关键组件是 MLOps 管道、版本控制和 CI/CD 工具。我们可以使用 Vertex AI Pipelines 创建标准化的、端到端的 ML 管道，自动化我们的模型训练和评估步骤，包括超参数优化。我们可以使用
    Google Cloud 的源代码管理工具来管理我们的管道定义代码，以及 Google Cloud 的 CI/CD 工具，如 Cloud Build 和 Cloud
    Deploy，将我们的管道定义构建和部署到 Vertex AI Pipelines。
- en: Observability
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可观察性
- en: There are two main types of monitoring and logging that we need to implement
    during the model training and building phase. First, we need to track model performance
    metrics during model training, such as loss, accuracy, and validation scores.
    We can do this by using Vertex AI and tools such as TensorBoard. The second is
    related to system resource monitoring, for which we can use Google Cloud Monitoring
    to keep an eye on the resource consumption of VMs, TPUs, or GPUs during model
    training, which can help to achieve optimal resource utilization and timely detection
    of any potential bottlenecks that might occur.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练和构建阶段，我们需要实施两种主要的监控和日志记录类型。首先，我们需要在模型训练期间跟踪模型性能指标，如损失、准确性和验证分数。我们可以通过使用
    Vertex AI 和 TensorBoard 等工具来实现这一点。第二是与系统资源监控相关，我们可以使用 Google Cloud Monitoring
    来监控模型训练期间虚拟机、TPU 或 GPU 的资源消耗，这有助于实现最佳资源利用并及时检测可能出现的任何潜在瓶颈。
- en: Managed infrastructure
  id: totrans-266
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 管理基础设施
- en: We should use managed infrastructure for our model training and building steps.
    By using managed infrastructure such as Vertex AI, we automatically use the recommendations
    outlined by the *Operational excellence* pillar in the Google Cloud Architecture
    Framework.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该为我们模型训练和构建步骤使用管理基础设施。通过使用 Vertex AI 等管理基础设施，我们自动使用了 Google Cloud 架构框架中 *运营卓越*
    桩柱概述的建议。
- en: Security, privacy, and compliance in model building and training
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型构建和训练中的安全、隐私和合规性
- en: Data security will still be a major focus in this section, considering that
    the training process involves data handling. The following sub-sections discuss
    how we can apply concepts from the *Security, privacy, and compliance* pillar
    in the model building and training phases of the ML model development life cycle.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到训练过程涉及数据处理，数据安全仍将是本节的一个主要关注点。以下子节将讨论我们如何在机器学习模型开发生命周期的模型构建和训练阶段应用来自 *安全、隐私和合规性*
    桩柱的概念。
- en: Data security
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据安全
- en: The mechanisms here are the same as we discussed in the *Data collection and
    preparation* section. We should ensure that data used for model building and training
    is encrypted both in transit and at rest. When using sensitive data for training,
    we can use data masking and tokenization to mask or tokenize specific fields to
    prevent exposure of PII or other sensitive data points. Additionally, we can use
    services such as VPC-SC to restrict the services and resources that can access
    our data, thus creating a secure perimeter around the data used for training.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的机制与我们之前在*数据收集和准备*部分讨论的是相同的。我们应该确保用于模型构建和训练的数据在传输和静止状态下都进行了加密。当使用敏感数据进行训练时，我们可以使用数据掩码和标记化来掩码或标记特定字段，以防止暴露PII或其他敏感数据点。此外，我们可以使用VPC-SC等服务来限制可以访问我们数据的服务和资源，从而在用于训练的数据周围创建一个安全边界。
- en: Environment security
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 环境安全
- en: We can set up secure training environments to ensure that VMs and containers
    are securely configured, patched, and hardened, or use managed environments such
    as Vertex AI, which take care of a lot of these activities for us, and we can
    use VPC and firewall rules to secure the network traffic related to model training.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以设置安全训练环境，以确保虚拟机和容器被安全配置、打补丁和加固，或者使用Vertex AI等托管环境，这些环境为我们处理许多这些活动，并且我们可以使用VPC和防火墙规则来保护与模型训练相关的网络流量。
- en: Compliance monitoring
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 合规性监控
- en: We can use tools such as Cloud Security Command Center to continuously monitor
    and ensure that the training environment adheres to compliance standards, and
    we should also regularly audit data sources for training to ensure compliance
    with data usage policies, especially if sourcing data from third parties.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用诸如云安全命令中心之类的工具来持续监控并确保训练环境符合合规标准，我们还应该定期审计训练数据源以确保遵守数据使用政策，尤其是如果从第三方获取数据时。
- en: Privacy
  id: totrans-276
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 隐私
- en: If working with sensitive datasets, we can use techniques such as differential
    privacy to introduce noise into the data, ensuring individual data points are
    not identifiable. We can also use data de-identification to remove PI so that
    it cannot be associated with specific individuals.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如果处理敏感数据集，我们可以使用差分隐私等技术向数据中引入噪声，确保单个数据点不可识别。我们还可以使用数据去标识化来删除PI，使其无法与特定个人关联。
- en: In addition to all of the aforementioned, we can use IAM to control access to
    the training environment and artifacts.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述所有内容之外，我们还可以使用IAM来控制对训练环境和工件访问的权限。
- en: Reliability in model building and training
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型构建和训练的可靠性
- en: The following sub-sections discuss how we can apply concepts from the *Reliability*
    pillar in the model-building and training phases of the ML model development life
    cycle.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 以下子部分讨论了如何在机器学习模型开发生命周期的模型构建和训练阶段应用*可靠性*支柱中的概念。
- en: Data reliability
  id: totrans-281
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据可靠性
- en: As we’ve done in earlier chapters of this book, we can implement validation
    checks for incoming data to ensure consistency, quality, and completeness. We
    should also regularly back up training data to prevent data loss and use data
    versioning for reproducibility.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本书的早期章节中所做的那样，我们可以实施对传入数据的验证检查，以确保一致性、质量和完整性。我们还应该定期备份训练数据以防止数据丢失，并使用数据版本化以确保可重复性。
- en: Training infrastructure reliability
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 训练基础设施可靠性
- en: We can provision redundant resources in regional or multi-regional deployments
    to ensure training can continue even if one data center faces issues. In terms
    of infrastructure scalability, Vertex AI can automatically scale resources based
    on the training workload. Of course, it’s important to use monitoring tools to
    keep an eye on resource utilization and health.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在区域或跨区域部署中配置冗余资源，以确保即使一个数据中心出现问题，训练也能继续进行。在基础设施可伸缩性方面，Vertex AI可以根据训练工作负载自动扩展资源。当然，使用监控工具来关注资源利用率和健康状况是非常重要的。
- en: Model training resilience
  id: totrans-285
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型训练弹性
- en: We can use checkpointing to save model states at regular intervals during training.
    In case of interruptions, training could resume from the latest checkpoint rather
    than starting from scratch. For transient failures in any stage of the model building
    process, we should implement retry policies to automatically attempt the task
    again before raising an error.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在训练过程中定期使用检查点来保存模型状态。在发生中断的情况下，训练可以从最新的检查点恢复，而不是从头开始。对于模型构建过程中的任何阶段的暂时性故障，我们应该实施重试策略，在引发错误之前自动尝试任务。
- en: Dependency management
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 依赖关系管理
- en: Vertex AI lets us use containerization to ensure consistent software and library
    versions across training runs, preventing “it works on my machine” issues. This
    also brings with it all of the other established benefits of containerization,
    such as standardization and scalability. Think about how we used containers during
    the practical exercises in our MLOps chapter. We packaged our custom data processing
    and training code into containers, and then we could use them seamlessly in later
    stages of the model development process, simply by pointing to the container locations
    during various steps being implemented on systems such as Vertex AI and Dataproc.
    This kind of packaging, which facilitates repeatable execution results, is essential
    for automating steps in an MLOps pipeline, as well as automatically scaling our
    training and inference workloads based on their varying resource requirements.
    Such automation is a core benefit of MLOps practices. Furthermore, by using discrete
    packages of code for each step in the MLOps life cycle in this way, we can scale
    each step independently, providing flexibility in accordance with the best practices
    outlined in the *Operational excellence* and *Reliability* pillars of the Google
    Cloud Architecture Framework.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 允许我们使用容器化来确保在训练运行中软件和库版本的一致性，防止“在我的机器上可行”的问题。这也带来了容器化所固有的所有其他好处，例如标准化和可扩展性。想想我们在
    MLOps 章节中的实践练习中是如何使用容器的。我们将自定义数据处理和训练代码打包到容器中，然后我们可以在模型开发过程的后续阶段无缝使用它们，只需在实施于
    Vertex AI 和 Dataproc 等系统上的各个步骤中指向容器位置即可。这种打包方式，有助于实现可重复执行的结果，对于自动化 MLOps 管道中的步骤以及根据其不同的资源需求自动扩展我们的训练和推理工作负载至关重要。这种自动化是
    MLOps 实践的核心好处。此外，通过以这种方式为 MLOps 生命周期中的每个步骤使用独立的代码包，我们可以独立扩展每个步骤，根据 Google Cloud
    架构框架中“运营卓越”和“可靠性”支柱中概述的最佳实践提供灵活性。
- en: To further mitigate potential dependency issues, if we have dependencies on
    external systems such as data providers, we should ensure they have uptime guarantees
    and fallback mechanisms.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步减轻潜在的依赖性问题，如果我们依赖于外部系统，如数据提供者，我们应该确保它们有正常运行时间和回退机制。
- en: DR
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: DR
- en: 'It’s important to regularly back up model architectures, configurations, trained
    weights, and other essential components to allow for quick recovery in case of
    data corruption or loss. We should establish clear protocols for restoring from
    backups, ensuring minimal downtime and a quick return to operational status in
    case of disruptions. The following point cannot be emphasized enough: we must
    periodically test our recovery procedures. Companies often focus only on backup
    mechanisms and not on testing the recovery processes. We want to ensure that our
    recovery processes are effective (that is, they actually work) and efficient (that
    is, they work as quickly as possible).'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 定期备份模型架构、配置、训练权重和其他关键组件对于在数据损坏或丢失的情况下快速恢复至关重要。我们应该建立明确的恢复备份协议，确保在发生中断时最小化停机时间并快速恢复到操作状态。以下这一点不容忽视：我们必须定期测试我们的恢复程序。公司往往只关注备份机制，而不测试恢复过程。我们希望确保我们的恢复程序是有效的（即，它们实际上可行）和高效的（即，它们尽可能快地工作）。
- en: Cost optimization in model building and training
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型构建和训练中的成本优化
- en: The following sub-sections discuss how we can apply concepts from the *Cost
    optimization* pillar in the model building and training phases of the ML model
    development life cycle.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 以下子部分讨论了如何在机器学习模型开发生命周期的模型构建和训练阶段应用“成本优化”支柱中的概念。
- en: Resource efficiency
  id: totrans-294
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 资源效率
- en: To optimize costs during model building and training, we should ensure that
    VMs, GPUs, or TPUs used for training are appropriately sized for the workload.
    Initially, this may take some experimentation to find the best configuration of
    resources, but by the time we have standardized our training process into an MLOps
    pipeline, we should have a good idea of the required resources. Using Vertex AI
    and serverless services can help us optimize costs because those services can
    scale our resources based on demand. We can also utilize CUDs to save on computing
    costs.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在模型构建和训练期间优化成本，我们应该确保用于训练的 VM、GPU 或 TPU 的大小适合工作负载。最初，这可能需要一些实验来找到最佳资源配置，但当我们把我们的训练过程标准化为
    MLOps 管道时，我们应该对所需资源有一个很好的了解。使用 Vertex AI 和无服务器服务可以帮助我们优化成本，因为这些服务可以根据需求扩展我们的资源。我们还可以利用
    CUDs 来节省计算成本。
- en: For training jobs that can handle interruptions, we can use preemptible VMs,
    which can offer substantial savings.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可以处理中断的训练作业，我们可以使用可抢占的虚拟机，这可以提供实质性的节省。
- en: It should also be noted that simpler model architectures can be easier, quicker,
    and cheaper to train than complex model architectures. It’s also important to
    shut down all resources when not in use so that we don’t pay when they are idle.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 还应注意的是，简单的模型架构可能比复杂的模型架构更容易、更快、更便宜地进行训练。在不使用时关闭所有资源也很重要，这样我们就不需要在它们空闲时支付费用。
- en: Review and optimize regularly
  id: totrans-298
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 定期审查和优化
- en: We can use tools such as Google Cloud Cost Management to regularly review and
    analyze infrastructure costs, and identify opportunities for optimization. As
    always, we can use budgets, quotas, and billing alerts to help keep our costs
    under control, and we should periodically review our ML infrastructure, data storage,
    and associated processes to identify and eliminate inefficiencies.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用如Google Cloud Cost Management之类的工具定期审查和分析基础设施成本，并确定优化机会。一如既往，我们可以使用预算、配额和账单警报来帮助控制成本，我们还应该定期审查我们的机器学习基础设施、数据存储和相关流程，以识别和消除低效之处。
- en: Performance optimization in model building and training
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型构建和训练中的性能优化
- en: The following sub-sections discuss how we can apply concepts from the *Performance
    optimization* pillar in the model building and training phases of the ML model
    development life cycle.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的子章节讨论了如何在机器学习模型开发生命周期中的模型构建和训练阶段应用来自**性能优化**支柱的概念。
- en: Compute optimization
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算优化
- en: To optimize performance, we can use hardware acceleration and specialized hardware
    such as GPUs and TPUs, which can significantly accelerate the training process.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化性能，我们可以使用硬件加速和专门的硬件，如GPU和TPU，这可以显著加速训练过程。
- en: Distributed training
  id: totrans-304
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分布式训练
- en: We can distribute the training process across multiple nodes to run in parallel
    and reduce training time. Also, for hyperparameter tuning, we can use services
    such as Vertex AI Vizier to perform concurrent trials, significantly reducing
    the time required to find optimal model parameters.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将训练过程分布在多个节点上并行运行，以减少训练时间。此外，对于超参数调整，我们可以使用如Vertex AI Vizier之类的服务进行并发试验，显著减少寻找最佳模型参数所需的时间。
- en: Data I/O optimization
  id: totrans-306
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据I/O优化
- en: We should use high-throughput data sources and systems for performant workloads
    so that the data coming into the training process isn’t a bottleneck.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该使用高吞吐量的数据源和系统来处理高性能工作负载，以确保进入训练过程的数据不会成为瓶颈。
- en: As mentioned in other sections of this chapter, it’s important to continuously
    track performance metrics such as processing speed, memory usage, and I/O throughput
    using tools such as Google Cloud Monitoring, and then adjusting resources or configurations
    as needed. We can also use profiling to analyze ML training code, identify performance
    bottlenecks, and then optimize the most time-consuming segments.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章其他部分所述，使用工具如Google Cloud Monitoring持续跟踪性能指标，如处理速度、内存使用和I/O吞吐量，并根据需要调整资源或配置，这一点非常重要。我们还可以使用分析来分析机器学习训练代码，识别性能瓶颈，然后优化耗时最长的部分。
- en: Next, let’s discuss how the Google Cloud Architecture Framework applies the
    model evaluation and deployment steps in our model development life cycle.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论Google Cloud架构框架如何将模型评估和部署步骤应用于我们的模型开发生命周期。
- en: Model evaluation and deployment
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估和部署
- en: In this section, we will discuss the concepts of each pillar in the context
    of model evaluation and deployment in the model development life cycle. Note that,
    in some phases, the same concepts that we’ve already discussed in previous phases
    of the model development life cycle still apply. In the remaining sections of
    this chapter, I will briefly call out when the same concepts apply again.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论模型开发生命周期中模型评估和部署阶段每个支柱的概念。请注意，在某些阶段，我们在模型开发生命周期的先前阶段已经讨论过的相同概念仍然适用。在本章剩余的部分，我将简要指出当相同的概念再次适用时。
- en: Operational excellence in model evaluation and deployment
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估和部署的运营卓越
- en: Let’s begin with operational excellence, and how it applies to model evaluation
    and deployment.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从运营卓越开始，以及它是如何应用于模型评估和部署的。
- en: Automation, observability, and scalability
  id: totrans-314
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自动化、可观测性和可扩展性
- en: In this phase of the ML model development life cycle, the same concepts from
    the *Operational excellence* pillar, such as automated workflows, observability,
    and scalability, which we’ve already discussed in the context of the model building
    and training phase, apply again here. Basically, we can set up MLOps pipelines
    that automate our model evaluation and deployment steps using Vertex AI Pipelines,
    and we can use Google Cloud Monitoring and logging tools to track metrics related
    to our model evaluations and deployed model performance. We can also use load
    balancers and Vertex AI auto-scaling infrastructure to ensure that our models
    can handle varying levels of demand.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习模型开发生命周期的这个阶段，与 *运营卓越* 柱相关的相同概念，例如自动化工作流程、可观察性和可伸缩性，我们在模型构建和训练阶段已经讨论过，现在再次适用。基本上，我们可以设置
    MLOps 管道，使用 Vertex AI Pipelines 自动化我们的模型评估和部署步骤，并可以使用 Google Cloud Monitoring
    和日志工具跟踪与我们的模型评估和部署模型性能相关的指标。我们还可以使用负载均衡器和 Vertex AI 自动扩展基础设施，以确保我们的模型能够处理不同级别的需求。
- en: A/B testing and canary deployments
  id: totrans-316
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A/B 测试和金丝雀部署
- en: When deploying new model versions, we can use A/B testing to gradually shift
    traffic and compare performance against previous versions. Of course, we want
    to ensure that the newer versions being deployed perform better than the previous
    versions and that they don’t negatively impact user experience. Using canary deployments,
    we can deploy new model versions to a small subset of users first, closely monitor
    performance, and then gradually expand to a broader user base. We should also
    use model versioning to allow for quick rollbacks if newer versions result in
    unexpected behaviors or errors.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 当部署新的模型版本时，我们可以使用 A/B 测试来逐步转移流量，并与之前的版本比较性能。当然，我们希望确保正在部署的新版本性能优于之前的版本，并且不会对用户体验产生负面影响。使用金丝雀部署，我们可以首先将新的模型版本部署给一小部分用户，密切监控性能，然后逐步扩展到更广泛的用户群体。我们还应该使用模型版本控制，以便在较新版本导致意外行为或错误时能够快速回滚。
- en: Security, privacy, and compliance in model evaluation and deployment
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估和部署中的安全、隐私和合规性
- en: Again, the same concepts regarding data security and privacy apply here also,
    as well as access control, compliance regulations, and auditing. In addition to
    all of that, we can use network security controls and VPC-SC to protect the endpoints
    on which our models are hosted.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，关于数据安全和隐私的相同概念也适用，以及访问控制、合规法规和审计。除此之外，我们还可以使用网络安全控制措施和 VPC-SC 来保护我们模型托管端点。
- en: Reliability in model evaluation and deployment
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估和部署中的可靠性
- en: In this case, the same concepts of infrastructure resilience, such as deploying
    resources in multiple zones or regions, also apply here, as well as health checks,
    load balancing, auto-scaling, DR, monitoring, alerting, and dependency management.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，基础设施弹性的相同概念，例如在多个区域或地区部署资源，同样适用，以及健康检查、负载均衡、自动扩展、灾难恢复（DR）、监控、警报和依赖关系管理。
- en: Cost optimization in model evaluation and deployment
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估和部署中的成本优化
- en: When discussing cost optimization in the context of model evaluation and deployment,
    some concepts from our previous phases apply again, such as right-sizing resources,
    shutting down idle resources, using CUDs, and setting budgets and alerts. It’s
    also important to note that smaller, simpler models require fewer resources and
    are therefore cheaper to run than larger, more complex models.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论模型评估和部署中的成本优化时，我们之前阶段的一些概念再次适用，例如合理配置资源、关闭闲置资源、使用 CUDs、设置预算和警报。还应注意，较小的、简单的模型需要较少的资源，因此比较大的、更复杂的模型运行成本更低。
- en: Performance optimization in model evaluation and deployment
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估和部署中的性能优化
- en: You won’t be surprised to hear the terms *auto-scaling* and *load balancing*
    being used in the context of performance optimization for model evaluation and
    deployment, as well as optimizing compute and storage resources, and hardware
    acceleration.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型评估和部署的性能优化以及优化计算和存储资源、硬件加速的背景下，听到 *自动扩展* 和 *负载均衡* 这些术语并不令人惊讶。
- en: We can also use caching mechanisms to improve response times. For example, we
    can cache frequent prediction results so that repeated requests can be served
    without invoking the model again, and we can store frequently accessed data or
    intermediate model evaluation results in memory for quicker access.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用缓存机制来提高响应时间。例如，我们可以缓存频繁的预测结果，以便在不需要再次调用模型的情况下服务重复请求，并且我们可以将频繁访问的数据或中间模型评估结果存储在内存中，以便快速访问。
- en: By now, you have become an expert in the Google Cloud Architecture Framework
    and how it specifically applies to the ML model development life cycle. Let’s
    take a moment to summarize everything we covered in this chapter.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你已经成为了谷歌云架构框架以及它如何具体应用于机器学习模型开发生命周期的专家。让我们花一点时间来总结本章中我们涵盖的所有内容。
- en: Summary
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter discussed various aspects of ML model governance, including documentation,
    versioning, monitoring, auditing, compliance, operationalization, and continuous
    improvement. We then explored some industry-specific and region-specific regulations,
    such as HIPAA for healthcare, SOX for finance, GDPR (EU), and CCPA (California).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了机器学习模型治理的各个方面，包括文档、版本控制、监控、审计、合规性、运营化和持续改进。然后我们探讨了行业特定和地区特定的法规，例如医疗保健行业的HIPAA、金融行业的SOX、欧盟的GDPR和加州的CCPA。
- en: Next, we focused on the Google Cloud Architecture Framework and how to apply
    its pillars—*Operational excellence*, *Security, privacy and compliance*, *Reliability*,
    *Cost optimization*, and *Performance efficiency*—to the various stages of the
    ML life cycle. We dived deep into each pillar, detailing its relevance across
    different phases, from data collection and preparation to model evaluation and
    deployment. This included important concepts, such as cost-efficient model deployment,
    enhancing security throughout the model life cycle, and maintaining high reliability
    and performance standards. Overall, this chapter covered many factors related
    to deploying and managing ML workloads on Google Cloud, with best practices and
    optimizations in mind.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们专注于谷歌云架构框架及其支柱——*运营卓越*、*安全、隐私和合规性*、*可靠性*、*成本优化*和*性能效率*——如何应用于机器学习生命周期的各个阶段。我们深入探讨了每个支柱，详细说明了其在不同阶段的相关性，从数据收集和准备到模型评估和部署。这包括诸如成本效益模型部署、在整个模型生命周期中增强安全性以及保持高可靠性和性能标准等重要概念。总体而言，本章涵盖了与在谷歌云上部署和管理机器学习工作负载相关的许多因素，同时考虑了最佳实践和优化。
- en: In the next chapter, we’ll take a look at using some other popular tools and
    frameworks in the industry—such as Spark MLlib and PyTorch—on Google Cloud.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨在谷歌云上使用一些其他流行的工具和框架——例如Spark MLlib和PyTorch。
