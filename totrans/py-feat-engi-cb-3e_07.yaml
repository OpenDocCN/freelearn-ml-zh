- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Performing Feature Scaling
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行特征缩放
- en: Many machine learning algorithms are sensitive to the variable scale. For example,
    the coefficients of linear models depend on the scale of the feature – that is,
    changing the feature scale will change the coefficient’s value. In linear models,
    as well as in algorithms that depend on distance calculations such as clustering
    and principal component analysis, features with larger value ranges tend to dominate
    over features with smaller ranges. Therefore, having features on a similar scale
    allows us to compare feature importance and may help algorithms converge faster,
    improving performance and training times.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法对变量尺度很敏感。例如，线性模型的系数取决于特征的尺度——也就是说，改变特征尺度将改变系数的值。在线性模型以及依赖于距离计算的算法（如聚类和主成分分析）中，值范围较大的特征往往会支配值范围较小的特征。因此，将特征放在相似的尺度上允许我们比较特征的重要性，并可能帮助算法更快收敛，从而提高性能和训练时间。
- en: Scaling techniques, in general, divide the variables by some constant; therefore,
    it is important to highlight that the shape of the variable distribution does
    not change when we rescale the variables. If you want to change the distribution
    shape, check out [*Chapter 3*](B22396_03.xhtml#_idTextAnchor351), *Transforming*
    *Numerical Variables*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，缩放技术将变量除以某个常数；因此，重要的是要强调，当我们重新缩放变量时，变量分布的形状不会改变。如果你想改变分布形状，请查看[*第3章*](B22396_03.xhtml#_idTextAnchor351)，*转换*
    *数值变量*。
- en: In this chapter, we will describe different methods to set features on a similar
    scale.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将描述不同的方法来设置特征在相似的尺度上。
- en: 'This chapter will cover the following recipes:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Standardizing the features
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化特征
- en: Scaling to the maximum and minimum values
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放到最大值和最小值
- en: Scaling with the median and quantiles
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用中位数和分位数进行缩放
- en: Performing mean normalization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行均值归一化
- en: Implementing maximum absolute scaling
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现最大绝对缩放
- en: Scaling to vector unit length
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放到向量单位长度
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The main libraries that we use in this chapter are scikit-learn (`sklearn`)
    for scaling, `pandas` to handle the data, and `matplotlib` for plotting.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们使用的库主要有用于缩放的scikit-learn（`sklearn`），用于处理数据的`pandas`，以及用于绘图的`matplotlib`。
- en: Standardizing the features
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准化特征
- en: 'Standardization is the process of centering the variable at `0` and standardizing
    the variance to `1`. To standardize features, we subtract the mean from each observation
    and then divide the result by the standard deviation:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化是将变量中心在`0`并标准化方差为`1`的过程。为了标准化特征，我们从每个观测值中减去均值，然后将结果除以标准差：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>x</mi><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mrow><mi>s</mi><mi>t</mi><mi>d</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac></mrow></mrow></math>](img/25.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>x</mi><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mrow><mi>s</mi><mi>t</mi><mi>d</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac></mrow></mrow></math>](img/25.png)'
- en: The result of the preceding transformation is called the **z-score** and represents
    how many standard deviations a given observation *deviates* from the mean.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个转换的结果被称为**z分数**，表示给定观测值与平均值相差多少个标准差。
- en: Standardization is generally useful when models require the variables to be
    centered at zero and data is not sparse (centering sparse data will destroy its
    sparse nature). On the downside, standardization is sensitive to outliers and
    the z-score does not keep the symmetric properties if the variables are highly
    skewed, as we discuss in the following section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型需要变量以零为中心且数据不是稀疏的（稀疏数据的中心化会破坏其稀疏性）时，标准化通常很有用。然而，标准化对异常值敏感，并且如果变量高度偏斜，z分数不会保持对称属性，正如我们在下一节中讨论的。
- en: Getting ready
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'With standardization, the variable distribution does not change; what changes
    is the magnitude of their values, as we see in the following figure:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标准化，变量分布不会改变；改变的是它们值的幅度，正如我们在以下图中看到的：
- en: '![Figure 7.1 – Distribution of a normal and skewed variable before and after
    standardization.](img/B22396_07_1.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1 – 标准化前后正态和偏斜变量的分布](img/B22396_07_1.jpg)'
- en: Figure 7.1 – Distribution of a normal and skewed variable before and after standardization.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: The z-score (*x* axis in the bottom panels) indicates how many standard deviations
    an observation deviates from the mean. When the z-score is `1`, the observation
    lies 1 standard deviation to the right of the mean, whereas when the z-score is
    `-1`, the sample is 1 standard deviation to the left of the mean.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: In normally distributed variables, we can estimate the probability of a value
    being greater or smaller than a given z-score, and this probability distribution
    is symmetric. The probability of an observation being smaller than a z-score of
    `-1` is equivalent to the probability of a value being greater than `1` (horizontal
    line in the bottom-left panel). This symmetry is fundamental to many statistical
    tests. In skewed distributions, this symmetry does not hold. As illustrated in
    the bottom-right panel of *Figure 7**.1* (horizontal lines), the probability of
    a value being smaller than `-1` is different from that of being greater than `1`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The mean and the standard deviation are sensitive to outliers; therefore, the
    features may scale differently from each other in the presence of outliers when
    using standardization.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: In practice, we often apply standardization ignoring the shape of the distribution.
    However, keep in mind that if the models or tests you are using make assumptions
    about the data’s distribution, you might benefit from transforming the variables
    before standardization, or trying a different scaling method.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we’ll apply standardization to the variables of the California
    housing dataset:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by importing the required Python packages, classes, and functions:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s load the California housing dataset from scikit-learn into a DataFrame
    and drop the `Latitude` and `Longitude` variables:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let’s divide the data into train and test sets:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we’ll set up the `StandardScaler()` function from scikit-learn and fit
    it to the train set so that it learns each variable’s mean and standard deviation:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-learn scalers, like any scikit-learn transformer, return NumPy arrays
    by default. To return `pandas` or `polars` DataFrames, we need to specify the
    output container with the `set_output()` method, as we did in *Step 4*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s standardize the train and test sets with the trained scaler:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`StandardScaler()` stores the mean and standard deviation learned from the
    training set during `fit()`. Let’s visualize the learned parameters.'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'First, we’ll print the mean values that were learned by `scaler`:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We see the mean values of each variable in the following output:'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: scaler.scale_
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: array([1.89109236e+00, 1.25962585e+01, 2.28754018e+00,                          4.52736275e-01,
    1.14954037e+03, 6.86792905e+00])
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s print the descriptive statistics from the original variables in the test
    set:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the following output, we see that the variables’ mean values are different
    from zero and the variance varies:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Descriptive statistical parameters of the variables before scaling](img/B22396_07_2.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – 缩放前的变量的描述性统计参数](img/B22396_07_2.jpg)'
- en: Figure 7.2 – Descriptive statistical parameters of the variables before scaling
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 缩放前的变量的描述性统计参数
- en: 'Let’s now print the descriptive statistical values from the transformed variables:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来打印转换变量的描述性统计值：
- en: '[PRE9]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the following output, we see that the variables’ mean is now centered at
    `0` and the variance is approximately `1`:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下输出中，我们可以看到变量的均值现在集中在 `0`，方差约为 `1`：
- en: '![Figure 7.3 – Descriptive statistical parameters of the scaled variables showing
    a mean of 0 and variance of approximately 1](img/B22396_07_3.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – 缩放变量的描述性统计参数，显示均值为 0 和方差约为 1](img/B22396_07_3.jpg)'
- en: Figure 7.3 – Descriptive statistical parameters of the scaled variables showing
    a mean of 0 and variance of approximately 1
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – 缩放变量的描述性统计参数，显示均值为 0 和方差约为 1
- en: Note
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `AveRooms`, `AveBedrms`, and `AveOccup` variables are highly skewed, which
    can lead to observed values in the test set that are much greater or much smaller
    than those in the training set, and hence we see that the variance deviates from
    `1`. This is to be expected because standardization is sensitive to outliers and
    very skewed distributions.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`AveRooms`、`AveBedrms` 和 `AveOccup` 变量高度偏斜，这可能导致测试集中的观察值远大于或远小于训练集中的值，因此我们看到方差偏离
    `1`。这是可以预料的，因为标准化对异常值和非常偏斜的分布很敏感。'
- en: We mentioned, in the *Getting ready* section, that the shape of the distribution
    does not change with standardization. Go ahead and corroborate that by executing
    `X_test.hist()` and then `X_test_scaled.hist()` to compare the variables’ distribution
    before and after the transformation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *准备就绪* 部分中，我们提到分布的形状不会随着标准化而改变。通过执行 `X_test.hist()` 然后执行 `X_test_scaled.hist()`
    来验证这一点，并比较转换前后的变量分布。
- en: How it works...
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we standardized the variables of the California housing dataset
    by utilizing scikit-learn. We split the data into train and test sets because
    the parameters for the standardization should be learned from the train set. This
    is to avoid leaking data from the test to the train set during the preprocessing
    steps and to ensure the test set remains naïve to all feature transformation processes.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们通过使用 scikit-learn 对加利福尼亚住房数据集的变量进行了标准化。我们将数据分为训练集和测试集，因为标准化的参数应该从训练集中学习。这是为了避免在预处理步骤中将测试集的数据泄露到训练集中，并确保测试集对所有特征转换过程保持无知的。
- en: To standardize these features, we used scikit-learn’s `StandardScaler()` function,
    which is able to learn and store the parameters utilized in the transformation.
    Using `fit()`, the scaler learned each variable’s mean and standard deviation
    and stored them in its `mean_` and `scale_` attributes. Using `transform()`, the
    scaler standardized the variables in the train and test sets. The default output
    of `StandardScaler()` is a NumPy array, but through the `set_output()` parameter,
    we can change the output container to a `pandas` DataFrame, as we did in *Step
    4*, or to `polars`, by setting `transform="polars"`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了标准化这些特征，我们使用了 scikit-learn 的 `StandardScaler()` 函数，该函数能够学习并存储在转换中使用的参数。使用
    `fit()`，缩放器学习每个变量的均值和标准差，并将它们存储在其 `mean_` 和 `scale_` 属性中。使用 `transform()`，缩放器对训练集和测试集中的变量进行了标准化。`StandardScaler()`
    的默认输出是 NumPy 数组，但通过 `set_output()` 参数，我们可以将输出容器更改为 `pandas` DataFrame，就像我们在 *步骤
    4* 中所做的那样，或者通过设置 `transform="polars"` 来更改为 `polars`。
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`StandardScaler()` will subtract the mean and divide it by the standard deviation
    by default. If we want to just center the distributions without standardizing
    the variance, we can do so by setting `with_std=False` when initializing the transformer.
    If we want to set the variance to `1`, without cantering the distribution, we
    can do so by setting `with_mean=False` in *Step 4*.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`StandardScaler()` 默认会减去均值并除以标准差。如果我们只想对分布进行中心化而不进行标准化，我们可以在初始化转换器时设置 `with_std=False`。如果我们想在
    *步骤 4* 中将方差设置为 `1`，而不对分布进行中心化，我们可以通过设置 `with_mean=False` 来实现。'
- en: Scaling to the maximum and minimum values
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩放到最大值和最小值
- en: 'Scaling to the minimum and maximum values squeezes the values of the variables
    between `0` and `1`. To implement this scaling method, we subtract the minimum
    value from all the observations and divide the result by the value range – that
    is, the difference between the maximum and minimum values:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>x</mi><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi
    mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mrow><mi>max</mi><mfenced
    open="(" close=")"><mi>x</mi></mfenced><mo>−</mo><mi mathvariant="normal">m</mi><mi
    mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac></mrow></mrow></math>](img/26.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: Scaling to the minimum and maximum is suitable for variables with very small
    standard deviations, when the models do not require data to be centered at zero,
    and when we want to preserve zero entries in sparse data, such as in one-hot encoded
    variables. On the downside, it is sensitive to outliers.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Scaling to the minimum and maximum value does not change the distribution of
    the variables, as illustrated in the following figure:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Distribution of a normal and skewed variable before and after
    scaling to the minimum and maximum value](img/B22396_07_4.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Distribution of a normal and skewed variable before and after scaling
    to the minimum and maximum value
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: This scaling method standardizes the maximum value of the variables to a unit
    size. Scaling to the minimum and maximum value tends to be the preferred alternative
    to standardization, and it is suitable for variables with very small standard
    deviations and when we want to preserve zero entries in sparse data, such as in
    one-hot encoded variables, or variables derived from counts, such as bag of words.
    However, this procedure does not center the variables at zero, so if the algorithm
    has that requirement, this method might not be the best choice.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Scaling to the minimum and maximum values is sensitive to outliers. If outliers
    are present in the training set, the scaling will squeeze the values toward one
    of the tails. If, on the contrary, outliers are in the test set, the variable
    will show values greater than `1` or smaller than `0` after scaling, depending
    on whether the outlier is on the left or right tail.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we’ll scale the variables of the California housing dataset
    to values between `0` and `1`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by importing `pandas` and the required classes and functions:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s load the California housing dataset from scikit-learn into a `pandas`
    DataFrame, dropping the `Latitude` and `Longitude` variables:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s divide the data into training and test sets:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let’s set up the scaler and then fit it to the train set so that it learns
    each variable’s minimum and maximum values and the value range:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, let’s scale the variables in the train and test sets with the trained
    scaler:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '`MinMaxScaler()` stores the maximum and minimum values and the value ranges
    in its `data_max_`, `min_`, and `data_range_` attributes, respectively.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'We can corroborate the minimum values of the transformed variables by executing
    `X_test_scaled.min()`, which will return the following output:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: MedInc           1.000000
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: HouseAge        1.000000
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: AveRooms        1.071197
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: AveBedrms      0.750090
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Population     0.456907
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: AveOccup        2.074553
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'dtype: float64'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: import pandas as pd
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.datasets import fetch_california_housing
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.model_selection import train_test_split
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.preprocessing import RobustScaler
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: X, y = fetch_california_housing(
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return_X_y=True, as_frame=True)
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X.drop(labels=[     "Latitude", "Longitude"], axis=1,
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: inplace=True)
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: X_train, X_test, y_train, y_test = train_test_split(
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X, y, test_size=0.3, random_state=0)
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: scaler = RobustScaler().set_output(
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: transform="pandas")
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: scaler.fit(X_train)
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: X_train_scaled = scaler.transform(X_train)
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_test_scaled = scaler.transform(X_test)
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: scaler.center_
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'RobustScaler():'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This scaling procedure does not change the variable distributions. Go ahead
    and compare the distribution of the variables before and after the transformation
    by using histograms.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: import pandas as pd
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.datasets import fetch_california_housing
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.model_selection import train_test_split
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: X, y = fetch_california_housing(
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return_X_y=True, as_frame=True)
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X.drop(labels=[
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"Latitude", "Longitude"], axis=1, inplace=True)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: X_train, X_test, y_train, y_test = train_test_split(
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X, y, test_size=0.3, random_state=0)
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: means = X_train.mean(axis=0)
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: MedInc           3.866667
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: HouseAge        28.618702
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: AveRooms         5.423404
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: AveBedrms        1.094775
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Population    1425.157323
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: AveOccup         3.040518
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'dtype: float64'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: ranges = X_train.max(axis=0)-X_train.min(axis=0)
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: MedInc           14.500200
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: HouseAge         51.000000
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: AveRooms        131.687179
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: AveBedrms        33.733333
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Population    35679.000000
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: AveOccup        598.964286
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'dtype: float64'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: X_train_scaled = (X_train - means) / ranges
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_test_scaled = (X_test - means) / ranges
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: from sklearn.preprocessing import (
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: StandardScaler, RobustScaler
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: scaler_mean = StandardScaler(
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: with_mean=True, with_std=False,
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ).set_output(transform="pandas")
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: scaler_minmax = RobustScaler(
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: with_centering=False,
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: with_scaling=True,
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: quantile_range=(0, 100)
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ).set_output(transform="pandas")
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: scaler_mean.fit(X_train)
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: scaler_minmax.fit(X_train)
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: X_train_scaled = scaler_minmax.transform(
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: scaler_mean.transform(X_train)
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_test_scaled = scaler_minmax.transform(
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: scaler_mean.transform(X_test)
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: import matplotlib.pyplot as plt
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: import pandas as pd
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.preprocessing import MaxAbsScaler
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: data = pd.read_csv("bag_of_words.csv")
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: scaler = MaxAbsScaler().set_output(
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: transform="pandas")
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: scaler.fit(data)
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: data_scaled = scaler.transform(data)
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: scaler.max_abs_
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: array([ 7.,  6.,  2.,  2., 11.,  4.,  3.,  6., 52.,  2.])
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: data.hist(bins=20, figsize=(20, 20))
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: plt.show()
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: data_scaled.hist(bins=20, figsize=(20, 20))
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: plt.show()
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: import pandas as pd
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.datasets import fetch_california_housing
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.model_selection import train_test_split
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.preprocessing import (
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: MaxAbsScaler, StandardScaler)
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.pipeline import Pipeline
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: X, y = fetch_california_housing(
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return_X_y=True, as_frame=True)
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X.drop( labels=[ "Latitude",
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"Longitude"], axis=1, inplace=True)'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_train, X_test, y_train, y_test = train_test_split(
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X, y, test_size=0.3, random_state=0)
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: scaler_mean = StandardScaler(
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: with_mean=True, with_std=False)
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: scaler_maxabs = MaxAbsScaler()
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: scaler = Pipeline([
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ("scaler_mean", scaler_mean),
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ("scaler_max", scaler_maxabs),
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ']).set_output(transform="pandas")'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: scaler.fit(X_train)
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: X_train_scaled = scaler.transform(X_train)
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_test_scaled = scaler.transform(X_test)
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: import numpy as np
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: import pandas as pd
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.datasets import fetch_california_housing
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.model_selection import train_test_split
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from sklearn.preprocessing import Normalizer
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: X, y = fetch_california_housing(
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return_X_y=True, as_frame=True)
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X.drop(labels=[
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"Latitude", "Longitude"], axis=1, inplace=True)'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: X_train, X_test, y_train, y_test = train_test_split(
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X, y, test_size=0.3, random_state=0)
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: scaler = Normalizer(norm='l1')
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: X_train_scaled = scaler.fit_transform(X_train)
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_test_scaled = scaler.transform(X_test)
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: np.round(np.linalg.norm(X_train, ord=1, axis=1), 1)
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: array([ 255.3,  889.1, 1421.7, ...,  744.6, 1099.5,
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 1048.9])
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: np.round(np.linalg.norm(
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_train_scaled, ord=1, axis=1), 1)
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: array([1., 1., 1., ..., 1., 1., 1.])
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
