["```py\n    import matplotlib.pyplot as plt\n    import pandas as pd\n    ```", "```py\n    X = pd.read_csv(\n        \"occupancy.csv\", parse_dates=[\"date\"])\n    X.head()\n    ```", "```py\n    def plot_timeseries(n_id):\n        fig, axes = plt.subplots(nrows=2, ncols=3,\n        figsize=(20, 10))\n        X[X[«id»] == n_id][\"temperature\"].plot(\n            ax=axes[0, 0], title=\"temperature\")\n        X[X[«id»] == n_id][\"humidity\"].plot(\n            ax=axes[0, 1], title=\"humidity\")\n        X[X[«id»] == n_id][\"light\"].plot(\n            ax=axes[0, 2], title=\"light\")\n        X[X[«id»] == n_id][\"co2\"].plot(\n        ax=axes[1, 0], title=\"co2\")\n        X[X[«id»] == n_id][\"humidity_ratio\"].plot(\n            ax=axes[1,1], title=\"humidity_ratio\")\n        plt.show()\n    ```", "```py\n    plot_timeseries(2)\n    ```", "```py\n    plot_timeseries(15)\n    ```", "```py\n    import pandas as pd\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import classification_report\n    from sklearn.model_selection import train_test_split\n    from tsfresh import extract_features\n    from tsfresh.utilities.dataframe_functions import (\n        impute\n    )\n    ```", "```py\n    X = pd.read_csv(\"occupancy.csv\", parse_dates=[\"date\"])\n    ```", "```py\n    y = pd.read_csv(\"occupancy_target.csv\",\n        index_col=\"id\")[\"occupancy\"]\n    ```", "```py\n    features = extract_features(\n        X[[«id», «light»]], column_id=\"id\")\n    ```", "```py\n    feats = features.columns[10:15]\n    ```", "```py\n    Index(['light__mean', 'light__length', \n        'light__standard_deviation', \n        'light__variation_coefficient', \n        'light__variance'], dtype='object')\n    ```", "```py\n    features[feats].head()\n    ```", "```py\n    impute(features)\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n        features,\n        y,\n        test_size=0.1,\n        random_state=42,\n    )\n    ```", "```py\n    cls = LogisticRegression(random_state=10, C=0.01)\n    cls.fit(X_train, y_train)\n    print(classification_report(\n         y_test, cls.predict(X_test)))\n    ```", "```py\n                      precision     recall  f1-score   support\n                   0         1.00        1.00        1.00           11\n                   1         1.00        1.00        1.00            3\n         accuracy                                       1.00           14\n       macro avg         1.00        1.00        1.00           14\n    weighted avg         1.00        1.00        1.00           14\n    ```", "```py\n    features = extract_features(\n        X,\n        column_id=\"id\",\n        impute_function=impute,\n        column_sort=\"date\",\n    )\n    ```", "```py\n    import pandas as pd\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import classification_report\n    from sklearn.model_selection import train_test_split\n    from tsfresh import (\n        extract_features,\n        extract_relevant_features,\n        select_features,\n    )\n    from tsfresh.utilities.dataframe_functions import impute\n    ```", "```py\n    X = pd.read_csv(\"occupancy.csv\", parse_dates=[\"date\"])\n    y = pd.read_csv(\"occupancy_target.csv\",\n        index_col=\"id\")[\"occupancy\"]\n    ```", "```py\n    features = extract_features(\n        X[[«id», «light»]],\n        column_id=\"id\",\n        impute_function=impute,\n    )\n    ```", "```py\n    features = select_features(features, y)\n    ```", "```py\n    feats = features.columns[0:5]\n    features[feats].head()\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n        features,\n        y,\n        test_size=0.1,\n        random_state=42,\n    )\n    ```", "```py\n    cls = LogisticRegression(\n        random_state=10, C=0.1, max_iter=1000)\n    cls.fit(X_train, y_train)\n    print(classification_report(\n        y_test, cls.predict(X_test)))\n    ```", "```py\n                      precision     recall  f1-score   support\n                   0         1.00        0.91        0.95           11\n                   1         0.75        1.00        0.86            3\n    accuracy                                       0.93           14\n       macro avg         0.88        0.95        0.90           14\n    extract_relevant_features, and, like this, combine *steps 3* and *4*. We’ll do that to create and select features automatically for the five time series in our dataset:\n\n    ```", "```py\n\n    ```", "```py\n    import pandas as pd\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import classification_report\n    from sklearn.model_selection import train_test_split\n    from tsfresh.feature_extraction import (\n        extract_features\n    )\n    from tsfresh.feature_extraction import settings\n    ```", "```py\n    X = pd.read_csv(\"occupancy.csv\", parse_dates=[\"date\"])\n    y = pd.read_csv(\"occupancy_target.csv\",\n        index_col=\"id\")[\"occupancy\"]\n    ```", "```py\n    minimal_feat = settings.MinimalFCParameters()\n    minimal_feat.items()\n    ```", "```py\n    ItemsView({'sum_values': None, 'median': None, 'mean': None, 'length': None, 'standard_deviation': None, 'variance': None, 'root_mean_square': None, 'maximum': None, 'absolute_maximum': None, 'minimum': None})\n    ```", "```py\n    features = extract_features(\n        X[[«id», «light»]],\n        column_id=\"id\",\n        default_fc_parameters=minimal_feat,\n    )\n    features.shape\n    ```", "```py\n    features.head()\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n        features,\n        y,\n        test_size=0.1,\n        random_state=42,\n    )\n    ```", "```py\n    cls = LogisticRegression(random_state=10, C=0.01)\n    cls.fit(X_train, y_train)\n    print(classification_report(\n        y_test, cls.predict(X_test)))\n    ```", "```py\n                        precision     recall  f1-score   support\n    0         1.00        0.91        0.95           11\n                   1         0.75        1.00        0.86            3\n         accuracy                                       0.93           14\n       macro avg         0.88        0.95        0.90           14\n    weighted avg         0.95        0.93        0.93           14\n    ```", "```py\n    light_feat = {\n        «sum_values\": None,\n        \"median\": None,\n        «standard_deviation\": None,\n        \"quantile\": [{\"q\": 0.2}, {\"q\": 0.7}],\n    }\n    ```", "```py\n    co2_feat = {\n        «root_mean_square\": None,\n        «number_peaks\": [{\"n\": 1}, {\"n\": 2}],\n    }\n    ```", "```py\n    kind_to_fc_parameters = {\n        «light»: light_feat,\n        \"co2\": co2_feat,\n    }\n    ```", "```py\n    features = extract_features(\n        X[[«id», «light», «co2»]],\n        column_id=\"id\",\n        kind_to_fc_parameters=kind_to_fc_parameters,\n    )\n    ```", "```py\n    Index(['light__sum_values', 'light__median',\n        'light__standard_deviation',\n        'light__quantile__q_0.2',\n        'light__quantile__q_0.7',\n        'co2__root_mean_square',\n        'co2__number_peaks__n_1',\n        'co2__number_peaks__n_2'],\n        dtype='object')\n    ```", "```py\n    import pandas as pd\n    from sklearn.feature_selection import SelectFromModel\n    from sklearn.linear_model import LogisticRegression\n    from tsfresh import (\n        extract_features,\n        extract_relevant_features,\n    )\n    from tsfresh.feature_extraction import settings\n    ```", "```py\n    X = pd.read_csv(\"occupancy.csv\", parse_dates=[\"date\"])\n    y = pd.read_csv(\n        \"occupancy_target.csv\",\n        index_col=\"id\")[\"occupancy\"]\n    ```", "```py\n    features = extract_relevant_features(\n        X,\n        y,\n        column_id=\"id\",\n        column_sort=\"date\",\n    )\n    features.shape\n    ```", "```py\n    cls = LogisticRegression(\n        penalty=\"l1\",\n        solver=»liblinear\",\n        random_state=10,\n        C=0.05,\n        max_iter=1000,\n    )\n    ```", "```py\n    selector = SelectFromModel(cls)\n    ```", "```py\n    selector.fit(features, y)\n    ```", "```py\n    features = selector.get_feature_names_out()\n    ```", "```py\n    array([\n    'light__sum_of_reoccurring_data_points',\n    'co2__fft_coefficient__attr_\"abs\"__coeff_0',\n    'co2__spkt_welch_density__coeff_2', 'co2__variance',\n    'temperature__c3__lag_1', 'temperature__abs_energy',\n    'temperature__c3__lag_2', 'temperature__c3__lag_3',\n    'co2__sum_of_reoccurring_data_points',\n    'light__spkt_welch_density__coeff_8',\n    'light__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"',\n             'light__agg_linear_trend__attr_\"slope\"__chunk_len_50__f_agg_\"var\"',  'light__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"var\"'],\n    dtype=object)\n    ```", "```py\n    kind_to_fc_parameters = settings.from_columns(\n        selector.get_feature_names_out(),\n    )\n    ```", "```py\n    {'light':\n        {‹sum_of_reoccurring_data_points': None,\n        ‹spkt_welch_density': [{'coeff': 8}],\n        'variance': None,\n        ‹agg_linear_trend': [\n            {‹attr': 'slope','chunk_len': 50,\n                'f_agg': 'var'},\n            {‹attr': 'intercept',\n                'chunk_len': 10,'f_agg':'var'}\n            ]\n        },\n    'co2':\n        {‹spkt_welch_density': [{'coeff': 2}],\n        'variance': None,\n        ‹sum_of_reoccurring_data_points': None\n        },\n        'temperature': {\n            'c3': [{'lag': 1}, {'lag': 2}, {'lag':3}],\n            'abs_energy': None}\n    }\n    ```", "```py\n    features = extract_features(\n        X,\n        column_id=\"id\",\n        column_sort=\"date\",\n        kind_to_fc_parameters=kind_to_fc_parameters,\n    )\n    ```", "```py\n    import pandas as pd\n    from sklearn.pipeline import Pipeline\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import classification_report\n    from tsfresh.transformers import (\n        RelevantFeatureAugmenter)\n    ```", "```py\n    X = pd.read_csv(\"occupancy.csv\", parse_dates=[\"date\"])\n    y = pd.read_csv(\n        \"occupancy_target.csv\",\n        index_col=\"id\")[\"occupancy\"]\n    ```", "```py\n    tmp = pd.DataFrame(index=y.index)\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n        tmp, y, random_state=0)\n    ```", "```py\n    kind_to_fc_parameters = {\n        \"light\": {\n            \"c3\": [{\"lag\": 3}, {\"lag\": 2}, {\"lag\": 1}],\n            «abs_energy\": None,\n            «sum_values\": None,\n            «fft_coefficient\": [\n                {«attr\": \"real\", \"coeff\": 0},\n                {«attr\": \"abs\", \"coeff\": 0}],\n            «spkt_welch_density\": [\n                {«coeff\": 2}, {\"coeff\":5}, {\"coeff\": 8}\n            ],\n            «agg_linear_trend\": [\n                {«attr\": \"intercept\",\n                „chunk_len\": 50, „f_agg\": „var\"},\n                {\"attr\": \"slope\",\n                «chunk_len\": 50, \"f_agg\":\"var\"},\n            ],\n            «change_quantiles\": [\n                {«f_agg\": \"var\", \"isabs\": False,\n                «qh\": 1.0,\"ql\": 0.8},\n                {«f_agg\": \"var\", \"isabs\": True,\n                «qh\": 1.0,\"ql\": 0.8},\n            ],\n        },\n    \"co2\": {\n        «fft_coefficient\": [\n            {«attr\": \"real\", \"coeff\": 0},\n            {«attr\": \"abs\", \"coeff\": 0}],\n        \"c3\": [{\"lag\": 3}, {\"lag\": 2}, {\"lag\": 1}],\n        «sum_values\": None,\n        «abs_energy\": None,\n        «sum_of_reoccurring_data_points\": None,\n        «sum_of_reoccurring_values\": None,\n        },\n    \"temperature\": {\"c3\": [{\"lag\": 1},\n        {«lag»: 2},{«lag»: 3}], «abs_energy\": None},\n    }\n    ```", "```py\n    augmenter = RelevantFeatureAugmenter(\n        column_id=\"id\",\n        column_sort=\"date\",\n        kind_to_fc_parameters=kind_to_fc_parameters,\n    )\n    ```", "```py\n    pipe = Pipeline(\n        [\n            (\"augmenter\", augmenter),\n            («classifier», LogisticRegression(\n        random_state=10, C=0.01)),\n        ]\n    )\n    ```", "```py\n    pipe.set_params(augmenter__timeseries_container=X)\n    ```", "```py\n    pipe.fit(X_train, y_train)\n    ```", "```py\n    print(classification_report(\n        y_test, pipe.predict(X_test)))\n    ```", "```py\n                      precision     recall  f1-score   support\n                   0         1.00        0.96        0.98           28\n                   1         0.86        1.00        0.92            6\n         accuracy                                       0.97           34\n    macro avg         0.93        0.98        0.95           34\n    weighted avg         0.97        0.97        0.97           34\n    ```"]