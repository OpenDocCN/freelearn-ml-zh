- en: Chapter 2. Turn Your Browser into Photoshop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is likely that you have used Photoshop or at least heard about it. With a
    few clicks, you can easily modify an image, enhance it, or do some sort of preprocessing.
    Actually, it is not that hard to do using JavaScript. For most of the functions,
    you need only a couple lines of code. This chapter is mostly about filters and
    image segmentation. Here, we will discuss many popular techniques and their applications.
    Moreover, we will introduce a new JavaScript library—tracking.js ([http://trackingjs.com](http://trackingjs.com)).
    It is mostly used for object tracking applications, but there are many utilties,
    which are relevant to the topic. It is interesting to know how to use both JSFeat,
    which we introduced in the first chapter, and tracking.js libraries together.
    We will see how to do this. Besides, we will compare their advantages in terms
    of image filtering. We will start from the installation of the new library and
    then follow the filter examples from the easiest to the most exciting ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the tracking.js library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is filtering and how to use it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic edge detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced image processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing the tracking.js library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let me give you a quick review of the tracking.js library. It is a great library
    that helps you with object detection, tracking, and image filtering. You can download
    it from [http://trackingjs.com](http://trackingjs.com). In this section, we will
    focus on the the installation of the library and how both JSFeat and tracking.js
    libraries can be used together.
  prefs: []
  type: TYPE_NORMAL
- en: Installation and image loading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Actually, the installation of a JavaScript library is straightforward. You
    just need to add a script file to your `<head>` tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The image loading is done using the context, just like we did in the previous
    chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In contrast to the JSFeat library, tracking.js works with arrays and it does
    not create a new object for images (as you remember, it is the `matrix_t` function
    for JSFeat). In that case, how do we apply a simple operation? Here is an example
    of how to convert a colored image to grayscale:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The last parameter indicates whether you need to return the array in the RGBA
    format (`true`) or just in one channel grayscale (`false`). In that case, we receive
    a `Uint8ClampedArray`, which we can easily convert to the `ImageData` constructor
    and put it to the canvas context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Simple, isn't it? The only thing we should mention is that for most operations,
    tracking.js returns `Float32Array`. Generally, you can cast it to the unsigned
    byte array without losing any information.
  prefs: []
  type: TYPE_NORMAL
- en: Conversion between JSFeat and tracking.js image formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In some cases JSFeat and tracking.js libraries complement each other. To benefit
    from using them together, you will probably need to convert a JSFeat matrix to
    an array and vice versa. The critical difference is that, even for a grayscale
    data, tracking.js sometimes uses four array elements: R, G, B, A.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To use a matrix as an array, we just need to get `mat.data` from a matrix.
    In the following code, we load matrix from the `ImageData` constructor and pass
    `mat.data` to the tracking.js grayscale function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Since the `mat` variable consists of four channels, we do not need to convert
    it to a different format. But what if we want to use the gray variable as a matrix?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In that case, we skip G, B, A elements and add only R elements to the buffer.
    With that buffer, we then populate the one channel matrix.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the conversion process is simple, just keep in mind that tracking.js
    usually uses 4-channel data.
  prefs: []
  type: TYPE_NORMAL
- en: What is filtering and how to use it?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image filtering is always a powerful tool to use in your Computer Vision applications.
    It allows you to apply many exciting effects on your photos, such as image correction,
    noise reduction, embossing, and many more. Image filtering is actually a huge
    subpart of an image processing area. In this section, we will discuss the concepts
    of image filtering and talk about a basic operation—convolution, which is widely
    used in all Computer Vision applications. Furthermore, we will see how different
    effects, such as blurring, are achieved.
  prefs: []
  type: TYPE_NORMAL
- en: Image convolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The core of most filtering operations is image convolution. With its understanding
    you will have the power to make your own image filters.
  prefs: []
  type: TYPE_NORMAL
- en: The image convolution idea is that you want to apply to each pixel of the original
    image a transformation which is based on neighboring pixels. For this, you have
    a kernel—a simple 2D matrix, this is our transformation matrix. For each pixel
    of the original image, we take the sum of products, each product is just a new
    value of a resulting image. To compute it, each element of the kernel should be
    multiplied with the corresponding image pixel, where the center of the kernel
    must be multiplied with the current pixel of an image. The whole process is called
    convolution.
  prefs: []
  type: TYPE_NORMAL
- en: To see a practical example of convolution, we should move to one of the most
    popular filters, it uses the **Gaussian kernel**. The filter itself is called
    a Gaussian filter (or Gaussian blur), and it is used for image smoothing, noise
    removing, and for edge detection. Most of the edge detection algorithms are sensitive
    to noise, using the Gaussian filter before the edge detection helps to remove
    unnecessary noise.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, we present an example of convolution using the Gaussian
    kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image convolution](img/image00101.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'From left to right: the Gaussian kernel, original matrix, and result matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute a value in the `(2, 2)` position of the result matrix, we do the
    convolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '*(1*0 + 2*1 + 1*3 + 2*2 + 4*1 + 2*2 + 1*4 + 2*3 + 1*5) / 16 = 2*'
  prefs: []
  type: TYPE_NORMAL
- en: See how the neighbors of the original matrix affect the result? Simply, a kernel
    matrix represents weights for the transformation process.
  prefs: []
  type: TYPE_NORMAL
- en: The 2D convolution requires four loops to compute so, in that case, it is better
    not to use big kernels; otherwise, our filtering process will be too slow. Usually,
    in image processing, the kernels from *3x3* to *7x7* are used and, as we already
    mentioned, the kernel should have a center and the dimensions should be odd. There
    are methods to improve the performance of the convolution operation, and we will
    analyze one of them in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The Gaussian filter and separate convolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Normally, we do not want to use heavy processing methods, such as applying
    a 2D kernel on an image. To speed up the computation, we can use a different approach.
    For most of the Computer Vision applications, we need only some sort of blurring
    and edge detection methods. In that case, the 2D kernels which are used there
    may be presented as two separate 1D kernels. This type of operation states that
    you can get the same result by applying two separate filters for rows and columns.
    The process is called separate convolution. Here is an example of the Gaussian
    kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The 2D matrix is separable if it can be presented as the outer product of two
    vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Enough of the theory! We did not even see the Gaussian filter in work. Moreover,
    it is a good point to combine both JSFeat and tracking.js libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a Gaussian kernel, we will use JSFeat:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You can get different sizes of a Gaussian kernel. The larger the size, the
    more blurry the image will be. Previously, we saw kernels only for the size of
    3 elements. Next, sigma specifies how wide your blur will be. If you set it to
    0, then the function calculates the optimal value for the given kernel size itself.
    The result is written to the `kernelArray` variable and, of course, the data type
    is float, since we are working with floating point operations. After executing
    the function, `kernelArray` will contain the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To get a full 2D kernel, we can use the `multiply` function, which we saw in
    the previous chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You can print `C` to see that it represents the Gaussian kernel.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use 1D kernels, we need to apply filters one by one to the original image.
    Unfortunately, JSFeat library does not provide you with such functionality. But
    tracking.js does! We will do this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that you need to set the last parameter to `true` if you want to return
    an RGBA array. Using the preceding code, we receive a blurred image, but what
    if we apply each filter separately? To see a clearer result, we need to choose
    a larger kernel size:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Gaussian filter and separate convolution](img/image00102.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From left to right, we see a gray image and then we see a horizontal filter
    applied to it followed by a vertical filter for the the same gray image. Finally,
    if we apply both filters to the original image, as we did in the code, we will
    receive a blurred image like the last one. Eventually, the separate convolution
    works! It is really great to use that when you can present a 2D kernel as two
    1D kernels.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worth mentioning that you can apply a Gaussian filter without using separate
    filters. For JSFeat library, see the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'For the tracking.js, see the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: For the last one, the result returns `Float32Array`. So if you want to display
    it properly, you need to convert it to the `Uint8ClampedArray` type. In addition,
    this is the first function you see which returns RGBA values, you cannot return
    only one channel array here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the examples with different kernel sizes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Gaussian filter and separate convolution](img/image00103.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the bigger the kernel size we take, the less the information
    we receive from an image and the blurrier it becomes.
  prefs: []
  type: TYPE_NORMAL
- en: The Gaussian filter is very useful when you need to reduce the image noise and
    reduce its details. Besides, it is commonly used to reduce the size of an image
    to get a better image approximation for a small size.
  prefs: []
  type: TYPE_NORMAL
- en: The box blur
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is a different blur method that needs to be discussed. Sometimes, you
    just need a rough approximation for the Gaussian Blur operation, a filter which
    is faster than Gaussian. Furthermore, you can sacrifice some blur quality. In
    that case, you can use the box blur filter.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is just a regular mean operation. It has a simple kernel for a diameter
    of 3 elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'So, for a diameter = *d* it will be like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Where, *n = d * d* is the number of elements in a kernel.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is simpler than Gaussian blur, but produces worse results. It is usually
    used as an approximation of a Gaussian blur. With the JSFeat library, it can be
    applied as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we use a `kernelRadius` parameter instead of a diameter (matrix size).
    The same result can be achieved if you use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Separate filter vector with tracking.js library. Actually, a close result to
    the Gaussian filter can be achieved if you apply box blur three times with a three
    times smaller kernel. For example, if the Gaussian kernel size is equal to 33
    values, then the kernel size for the box blur should be 11 (or with radius = 5):'
  prefs: []
  type: TYPE_NORMAL
- en: '![The box blur](img/image00104.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The first image has the Gaussian filter applied, the next has the box blur,
    which was applied thrice, and the last has the box blur with the same kernel size
    as the Gaussian kernel. Can you tell the difference between the first two images?
    It is really impossible to point it out. In addition, we see that the box blur
    for the last image removed more details and it produced an even worse result.
    Use the box blur filter only when you need to speed up the computation. But why
    is it so fast? There is magic in computing an integral image.
  prefs: []
  type: TYPE_NORMAL
- en: The integral image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Integrals are really useful when you need to compute image parameters quickly.
    For example, you can compute a filtered image for the box blur filter using the
    same amount of processing time for any kernel size. Isn't this amazing? Furthermore,
    it is also used for object detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Computing the integral image is just a simple algorithm that generates sums
    of values in rectangular subsets of a matrix. For the JSFeat library, it can be
    computed like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The first matrix will contain the integral image or regular sums of image subsets,
    the next matrix will contain squares of those sums, and the last will contain
    the tilted integral image. The dimensions of all input matrices should be 1 pixel
    larger than the original. To display the result, we need to normalize it, for
    example, the bottom-right element will contain the sum of all pixel values in
    a matrix. We cannot display the result matrix because the largest possible pixel
    value of an image is 255\. We need to divide each pixel by the maximum value in
    a matrix and multiply it by 255\. Here is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The integral image](img/image00105.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We got what we expected—the maximum value is situated in the bottom-right corner
    for the first two matrices and the tilted result is presented in the last.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can apply a box blur using integrals by yourself! Here is a simple explanation
    of how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The integral image](img/image00106.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We need to compute the sum in the ABCD rectangle. From the integral image,
    we know which sums are stored in *A*, *B*, *C*, and *D* positions. The sum of
    the rectangle can be computed using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*S = value in C – value in B – value in D + value in A*'
  prefs: []
  type: TYPE_NORMAL
- en: This can be applied to any size of the box blur filter, and this is why it is
    that fast. First, we need to compute an integral image, which is done in one loop
    over all pixel values and then we just calculate *S* for each pixel.
  prefs: []
  type: TYPE_NORMAL
- en: Basic edge detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For most Computer Vision applications, you process an image but you do not actually
    need to get all the information from it. For example, sometimes you just need
    to get the shape information to find an appropriate object. There is a huge topic
    in the field of image processing called **edge detection**. Methods related to
    that topic, search for points where pixel brightness changes dramatically. The
    extracted information aims to capture changes in the properties of an image. To
    understand the concept better and to see how the basic edge information can be
    extracted from an image, we will discuss different edge filters (or operators)
    starting with the Sobel filter.
  prefs: []
  type: TYPE_NORMAL
- en: The Sobel filter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Sobel operator or Sobel filter is common and widely used. It helps to detect
    edges and transitions in images. The Sobel operator uses two kernels during the
    processing—one for horizontal changes in brightness and another for vertical changes.
    Its kernel values are focused not on the current pixel, but on it neighboring
    pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typical Sobel kernels look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As you see, the kernels can be decomposed of two separate filters, which is
    good in terms of processing time. You can run this filter in different ways in
    the libraries. Since tracking.js provides more functionality with separable filters,
    let''s see some of its examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This is another way of applying separable filters in tracking.js library. We
    use the `separableConvolve` function, whereas for the fourth and fifth parameters,
    it uses Sobel vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are usually called derivatives, since they measure the change in
    values. We can compute these derivatives in JSFeat as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Where `imgGxGy` returns a 2-channel matrix, the first channel represents horizontal
    derivatives and the second represents vertical derivatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the result of a Sobel filter, we need to combine those two results;
    this is done using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, the value variable is the value of each pixel and it is computed using
    pixel values from horizontal and vertical derivatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the Sobel operator on an image directly you may prefer to use the following
    tracking.js function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: You need to remember that it returns an RGBA array and you need to normalize
    it, since it contains values larger than 255.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final result will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Sobel filter](img/image00107.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From left to right, we see the horizontal derivative, followed by the vertical
    derivative, and finally, the result after applying the Sobel filter. As you can
    see, the edges of the image have a good visualization. To get edges, not just
    changes in image pixels, we need to go a bit deeper. But let's discuss several
    other useful operators that you may want to use in edge detection.
  prefs: []
  type: TYPE_NORMAL
- en: Other operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You need to keep in mind that in Computer Vision, there is usually no perfect
    way for doing things. There are several operators that need to be mentioned; in
    some cases, they can produce better results than the Sobel filter. For example,
    the Prewitt operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes, it is a good point to start from, but it averages the result value
    too much, remember the box blur filter? Compare it with the Gaussian Blur, where
    the center of a kernel has more weight. If we want to do that, the Sobel filter
    is preferred. However, sometimes you need to save just a bit more information
    for the center. And if you need that, you can use the Scharr filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: See, the centre has more weight now. Actually, it is difficult to see the difference
    between Prewitt, Sobel and Sharr operators, which is why we don't have visual
    examples here. It is better to perform some experiments and check which filter
    you need exactly.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced image processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We talked about filters a lot, but they usually require only some sort of a
    matrix kernel and that is it. If you think that there should be more cool stuff
    in image filtering, you are totally right! First, we will see how to apply edge
    detection and how it works. In the final part, we will review the histogram equalization
    algorithm, which you probably use a lot if you have Photoshop.
  prefs: []
  type: TYPE_NORMAL
- en: The Canny edge detector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s be curious; what if we threshold an image after the Sobel filter? Thresholding
    is done by iterating over all pixels of a grayscale image and checking whether
    the value exceeds the threshold value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This is what the threshold looks like. Just set the value to `255` if it is
    higher than the threshold and to `0` when it is not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are several examples of different thresholds, each image having a higher
    threshold value than the previous:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Canny edge detector](img/image00108.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: See? The higher the threshold we set, the fewer the edges we get. This is the
    first step of the Canny edge detection algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: When you need to process only the most important information from images (it
    is usually shape information), and you need to remove unnecessary data without
    losing the important structural properties of an image, it is really smart to
    use an edge detector. Nowadays, the Canny edge detector is used most commonly.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can run the whole algorithm using the JSFeat library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Before the start of a Canny algorithm we usually apply the Gaussian Blur to
    reduce the noise. The larger you choose the kernel size, the fewer edges and less
    noise you get. Lower and higher thresholds are usually chosen empirically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the lower threshold, all pixels (weak pixels) are removed (or suppressed)
    by the algorithm, as we did while playing with the Sobel filter thresholding.
    Pixels with a value larger than the higher threshold are marked as strong pixels.
    At the last stage, in addition to weak pixels, the algorithm suppress all pixels
    that are not connected to those strong pixels. As a rule of thumb, the smaller
    your lower threshold is, the more noise you get; the larger your higher threshold
    is, the fewer the object edges you receive. This is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Canny edge detector](img/image00109.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The algorithm detects object boundaries or edges. For the first image, we picked
    50 and 300 as the lower and higher thresholds, respectively, and we did not use
    the Gaussian Blur. For the second image, we applied the Gaussian filter. As a
    result, many noise edges were removed. If we increase the lower threshold to 100,
    then we will get the result from the third image. In that case, much of the noise
    data from the ground is removed. After increasing the higher threshold, we get
    fewer object edges, which can be seen in the fourth image. You can play with parameters;
    just remember that when you increase any of the thresholds, you receive less information.
  prefs: []
  type: TYPE_NORMAL
- en: The Canny filter returns only 0 for background and 255 for edges. The thickness
    of the edges is 1 pixel, which is really important when you need to find an object.
    The Canny edge detector is included in many Computer Vision frameworks and its
    application is very wide. It is adaptive to various environment conditions and
    it is very robust.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram equalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes, you may want to improve the contrast of an image. It helps to see
    the details better when the important data is represented by close contrast values.
    The help comes from methods that operate with image histograms. An image histogram
    presents the number of pixels for each tonal value. Suppose you have an array,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You may want to redistribute values in case they have a better spreading of
    their intensity values. Let''s use the histogram equalization method which is
    provided by JSFeat:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Histogram equalization is just a usual function. The first parameter indicates
    the input matrix, the second indicates the output equalized matrix. With our array,
    we receive as a result of equalization `equalized.data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The histogram for the original (left) and equalized (right) arrays will look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The equalize histogram function maps old values to the new ones, performing
    a better spread over the whole range of values, 0-255\. In the preceding example,
    most of the values were situated in the first part of the range, after the redistribution,
    the difference between values was increased. Visually, it helps to distinguish
    separate image objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how it looks with an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Histogram equalization](img/image00110.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Left – the original grayscale image, and right – the image after equalization.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the contrast is much better now and the image itself looks
    more impressive. The grass and plants got much darker and the constructions are
    brighter. The histograms for the input and output images are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Histogram equalization](img/image00111.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As a consequence of better spreading, histogram equalization makes the histogram
    a bit more flat, so the histogram values do not have such a clear center.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram equalization can be used not only for a better image view, but also
    for extracting better image information. It is usually useful when an image background
    and foreground do not have high contrast. The biggest drawback that you should
    know is that this function may increase image noise. Anyway, histogram equalization
    is really useful, for example, in medical imaging and photo correction.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you first learned how to install tracking.js and how to use
    it with JSFeat. Now you know how to create your own image filters using the image
    convolution operation. Moreover, with separable convolutions, you can create much
    faster implementations of regular filters. When you need to reduce the noise,
    you will commonly use the Gaussian filter or the box blur filter when you need
    a faster algorithm. Edge detection? No problem, you can implement it and use it
    in your applications for both cases, when you need only the edges or the whole
    information about a change in image brightness. Last but not least, you now know
    how to improve the image contrast using histogram equalization. Look at how much
    we have covered in such a small chapter! There are many more topics on image processing
    and filtering, we just discussed a small portion of it. Eventually, we will be
    ready to use this knowledge in object detection.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to detect various objects using different
    tracking techniques, such as color detection and feature estimation. In addition,
    we will be able to create our own tracker. See you there!
  prefs: []
  type: TYPE_NORMAL
