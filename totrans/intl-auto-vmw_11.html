<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">DevOps with vRealize Code Stream</h1>
                </header>
            
            <article>
                
<p>The DevOps operating model and its supporting CI/CD toolsets implementation approach to managing IT is changing the roles and responsibilities of IT resources, as well as the traditional design, delivery, and operation processes. This chapter will enable you to make the process changes that are required for the adoption of DevOps. We will look into the highest priority processes to transform and apply techniques to compare and contrast the key differences between legacy operating models, processes, and team structures with the strategic operating model that's required for DevOps. We will also go through <strong>VMware vRealize Code Stream</strong> (<strong>vRCS</strong>) and its orchestration for DevOps release processes and continuous application delivery.</p>
<p><span>You will learn about the DevOps Cloud operational model for the private cloud. which enables developers to seamlessly deploy, configure, and manage production-ready applications by leveraging VMware Cloud Automation services, along with configuration management tools such as Puppet to accelerate DevOps operations. You will also learn about CI/CD with <strong>VMware Kubernetes Engine</strong> (<strong>VKE</strong>).</span></p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li class="h1">Application development life cycles</li>
<li class="h1">Automation with vRealize</li>
<li class="h1">vRCS</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>You can download VMware vRealize Code Stream from <a href="https://my.vmware.com/web/vmware/info/slug/infrastructure_operations_management/vmware_vrealize_code_stream/2_x">https://my.vmware.com/web/vmware/info/slug/infrastructure_operations_management/vmware_vrealize_code_stream/2_x</a> and VMware Wavefront from <a href="https://www.vmware.com/download/eula/wavefront-terms-of-service.html">https://www.vmware.com/download/eula/wavefront-terms-of-service.html</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Application development life cycles</h1>
                </header>
            
            <article>
                
<p>It is important to understand the change that has taken place in terms of application development life cycles in order to understand application transformation. When the pace of change was slow, application development always had a pre-determined plan with a finite end goal. The design of the application was thought through and agreed up-front, including capturing all of the user's requirements. Then, a series of steps followed that involved developing the plan, testing the functionality of the application, testing whether the application would run efficiently and to the right scale (non-functional testing), user acceptance testing to agree that the application had been built the way it was supposed to be, before finally going live in its final format.</p>
<p>The pace of change in some modern applications, coupled with the fact that they can be very experimental in nature, means that the waterfall approach (where the final application design is fully understood upfront) just doesn't work. Instead, application development, application design, user, and even customer testing occurs in rapid iterations, meaning that the application develops with a continuous feedback loop. Development teams are also typically assigned to individual components, so there is no concept of a controlled state that everyone has to comply with. Development occurs in simultaneous streams with frequent code check-ins to confirm overall functionality.</p>
<p>We can apply these results in terms such as CD, DevOps, and Agile. While these principles can be applied to traditional application architectures, they tend to be best suited to cloud-based application tools, platforms, and architectures. It should be noted that this area has several models and is still maturing, despite being widely practiced.</p>
<p>One very important thing to realize is that Agile and DevOps is not a replacement for waterfall. Customers will use both disciplines, which are dependent on the application development requirements. Applying Agile principles of development to a mission-critical traditional application could have terrible consequences, and conversely you could use as many cloud technologies as you want, but using a waterfall approach for application development that is exploratory in nature would fundamentally cripple the ability to deliver effectively.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CD pipeline</h1>
                </header>
            
            <article>
                
<p>DevOps helps with the CD pipeline process by going through the following procedure:</p>
<ul>
<li><strong>Plan</strong>: We have to first plan and define software release cycles; user-defined use cases; Agile planned actions; and a proper plan for backlogs and problems with a follow-up plan.</li>
<li><strong>Code</strong>: This is defined with a set of processes with related tools that allows us to write scripts, along with its assessment and testing. It also helps with following defined security and compliance metrics.</li>
<li><strong>Commit</strong>: This can help us define procedures and its related tools for code assessment, consolidation, and executing it with the main source code repository. This stack also assists in maintaining source control with daily testing, executing on-demand, and the proactive scanning of code. </li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CI pipeline</h1>
                </header>
            
            <article>
                
<p>The CI pipeline provides processes, practices, and tooling to help with the automated building and testing of every code commit in the source code repository. This includes automated security and compliance testing and logging.</p>
<p>Test processes, practices, and tooling for automated unit, functional, security, and compliance testing, logging results, and gaining approval to promote artifacts to the next stage in the flow.</p>
<p><span>The artifact repository consists of services and activities that are necessary to achieve the desired end state in terms of maintaining version, promotion, governance, and policy controls that are related deliverable artifacts. Generally stated, such artifacts are those that are converted from sources into binary packages, though other transformations may exist.</span></p>
<p>We develop and update software continuously so that the software can be released to production on-demand via CD.</p>
<p><span>The configuration consists of services and activities that are necessary to achieve the desired end state in terms of automating idempotent and expedient deployment of applications to static and on-demand hybrid cloud infrastructures. The design and implementation will be consistent with predefined SDLC process, including proper source artifact management (for example, Puppet modules, Chef cookbooks, deployment blueprints, and so on).</span></p>
<p><span>The control stack consists of services that are necessary to achieve the desired end state in terms of managing the tool chains that are recommended to operate the applications that are deployed by this infrastructure. This will also incorporate the SDLC processes, tools, integrations, and actions that are needed to maintain defined service-level agreements for a specific customer.</span></p>
<p><span>The feedback stack allows you to get automated feedback such as alerts, audit reports, test reports, and deployment process reports delivered when required.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Planning</h1>
                </header>
            
            <article>
                
<p><span>To achieve consistently successful business outcomes, VMware collaborates with customers in assessing, recommending, and documenting changes that are necessary to achieve optimal delivery processes. This collaborative effort is based on industry best practices in the following service foundation areas:</span><br/></p>
<ul>
<li><strong>Software Development Life Cycle</strong> (<strong>SDLC</strong>)</li>
<li><strong>Source code management</strong> (<strong>SCM</strong>)</li>
<li><strong>Continuous integration</strong> (<strong>CI</strong>)</li>
<li><strong>Artifact repository</strong> (<strong>AR</strong>)</li>
<li><strong>Continuous delivery</strong> (<strong>CD</strong>)</li>
<li><strong>Hybrid cloud provisioning</strong> (<strong>HCP</strong>)</li>
<li><strong>Configuration management</strong> (<strong>CM</strong>)</li>
<li><strong>Continuous operational management</strong> (<strong>COM</strong>)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SDLC</h1>
                </header>
            
            <article>
                
<p>The SDLC foundation consists of services and activities that are necessary to achieve optimally aligned personnel roles, tool chains, and processes to achieve the desired end state of the software delivery life cycle management by the customer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SCM</h1>
                </header>
            
            <article>
                
<p>The SCM foundation consists of services and activities that are necessary to achieve the desired end state in terms of managing and version-controlling software source artifacts. Source artifacts include, among other sources, application source code, documentation, configuration information, and process control flow configurations. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CI</h1>
                </header>
            
            <article>
                
<p>The CI consists of services and activities that are necessary to achieve the desired end state in terms of automated build, test, and deliverable (that is, binary) artifact creation. The CI process assists in application builds and its verification tests with rapid feedback while developers build software by using tools such as Jenkins, Gerrit Triggers, and vRA.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">AR</h1>
                </header>
            
            <article>
                
<p>VMware and customers collaborate to define and refine processes and activities that transform sources into customer deliverable artifacts. This includes assessing and realigning activities and related key accountability roles, responsibilities, and required skillsets, key interactions, and hand-offs related to supporting the service definition process with agreed upon use cases and business outcomes.</p>
<p>The AR foundation consists of services and activities that are necessary to achieve the desired end state in terms of maintaining version, promotion, governance, and policy controls related to deliverable artifacts. Generally stated, such artifacts are those that are converted from sources into binary packages, though other transformations may exist.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Release pipeline automation (CD)</h1>
                </header>
            
            <article>
                
<p>The CD consists of services and activities that are necessary to achieve the desired end state in terms of automating governance and release policies regarding deliverable artifacts. This involves providing the tools and integrations that are necessary to orchestrate manually-gated organizational decision processing and automated delivery processes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CM</h1>
                </header>
            
            <article>
                
<p>The CM foundation consists of services and activities that are necessary to achieve the desired end state in terms of automated, idempotent, and expedient deployment of applications to a static and on-demand hybrid cloud infrastructure. The design and implementation will be consistent with the agreed upon SDLC process, including proper source artifact management (for example, Puppet modules, Chef cookbooks, deployment blueprints, and so on).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">HC</h1>
                </header>
            
            <article>
                
<p>The HC foundation consists of services and activities that are necessary to achieve the desired end state in terms of automating resource provisioning to achieve application deployments to the hybrid cloud. In this context, the hybrid cloud may include the following:</p>
<ul>
<li>VMware vCloud Air, Linux containers, AWS, and other heterogeneous cloud platforms</li>
<li>On-premise virtualized/cloud and physical infrastructures</li>
</ul>
<p>This foundation service involves providing the tools and integrations that are necessary to automate the provisioning of infrastructure services (that is, compute, network, and storage) for all deliverable artifact deployments. The design and implementation will be consistent with the agreed upon SDLC process, including proper source artifact management (for example, provisioning blueprints, workflow scripts, and so on).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">COM</h1>
                </header>
            
            <article>
                
<p>The COM foundation consists of services and activities that are necessary to achieve the desired end state in terms of managing the tool chains that operate the service foundations, as well as the applications that are deployed by that infrastructure. This consists of incorporating processes, tools, integrations, and activities that are necessary to maintain any <strong>service-level agreements</strong> (<strong>SLA</strong>) that the customer is either bound to or reasonably desires. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feedback</h1>
                </header>
            
            <article>
                
<p>Feedback into the planning stack is necessary as errors occur. This consists of bug reporting and deficiencies in software features, including any change that's required by the operating software and its underlying infrastructure, all of which should be tracked for handling by the coding stack. Then, the cycle continues. This feedback then goes into the planning stack and we start the iteration again. We always want to be ensuring that all of our stacks are working well together and providing us with the desired outcomes. Our various processes can be continually updated an improved to keep pace with changes and updates in the tool chain, in the types of code that the stacks are dealing with, and the infrastructure that the resulting applications are hosted on.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Request fulfillment </h1>
                </header>
            
            <article>
                
<p>vRealize Automation assists users in requesting and managing different kinds of IT services <span>through a unified IT service catalog</span> that spans across the hybrid cloud.</p>
<p>The following is a screenshot of the catalog for software provisioning:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/54cea82e-e0eb-462b-8f06-8a2bb59c4732.png"/></p>
<p>It can provide programmatic access to support the on-demand delivery of software based on the DevOps model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Change management </h1>
                </header>
            
            <article>
                
<p class="VMNormal">vRO has an internal versioning system that automatically keeps track of changes. It has API interfaces to integrate with third-party tools such as Jenkins and also has an audit log that help users to review changes and access. vRA can provide automation for approval processes by integrating with Active Directory and can also be configuring for alternate approvers to ensure that change management and business requirements are met.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Release management </h1>
                </header>
            
            <article>
                
<p>There have been fundamental changes in the application's release process which demands new tooling that can keep up with it. The first change is in the rise of containers and microservices. They enable faster code pushes, but this is at the expense of increased complexity. Instead of the 100 metrics you had for your virtualization environments, now you need to track thousands and at high speed. The old-style tooling cannot keep up with these scale and changes, and they fail over. CD and DevOps are being adopted in larger enterprises, so engineering teams are now pushing code to production many times per day, thus driving the need for continuous monitoring. DevOps is mainstream, even though the tools that the operations teams use are still fragmented and consequentially slowing down troubleshooting services.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compliance management </h1>
                </header>
            
            <article>
                
<p>Customers expect data centers to be compliant because it is an extension of their IT. Heavily regulated verticals such as the public sector, finance, and healthcare cannot use this infrastructure without compliance certifications. Customers running a hybrid or public cloud infrastructure rely on compliance certifications instead of independent audits to ensure that proper security controls are in place. A number of high profile security breaches, court cases, and global legislative changes have raised awareness of the complexity and risks of running in the cloud. Open a browser and go to <a href="https://marketplace.vmware.com.">https://marketplace.vmware.com</a>.</p>
<p><strong>VMware Cloud</strong> (<strong>VMC</strong>) on AWS is working on implementing the compliance certifications and frameworks by targeting <strong>Cloud Security Alliance</strong> (<strong>CSA</strong>) and <strong>General Data Protection Regulation</strong> (<strong>GDPR</strong>) first, followed by <span><strong>International Organization for Standardization</strong></span> (<span><strong>ISO</strong></span>), <strong>Security Operations Center</strong> (<strong>SOC</strong>), <strong>Health Insurance Portability and Accountability Act</strong> (<strong>HIPPA</strong>), <strong>Payment Card Industry</strong> (<strong>PCI</strong>), the <strong>Federal Risk Authorization and Management Program</strong> (<strong>FedRAMP</strong>), and <strong>Criminal Justice </strong><strong>Information Services</strong> (<strong>CJIS</strong>). Security certifications that exist today are applicable to cloud computing and should be strongly considered. Cloud services will apply the mandated principles of policy, security, strategy, and compliance, which must be followed even by the lightest requirement use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Incident management</h1>
                </header>
            
            <article>
                
<p>An incident is essentially any issue that, if left unattended, could result in customer escalation. We can avoid many escalations by implementing a customer incident management process. We do not define customer escalation processes in any geographies. Our customer relationship management approach must evolve to emphasize the importance of escalation prevention. In response, we can plan to identify incidents, track them, and resolve them to avoid escalations. Management oversight and guidance during this process should help managers resolve these kinds of situations before they become escalations. Communication is the major focus. Communications protocols must define who, what, and when. The response to the customer must provide a balance between the cost of gained customer satisfaction and the cost of investment. We can do a better job at managing customer expectations and issues before they result in an escalation. The purpose of this process is to highlight issues that could escalate early on so that management and executive oversights can be applied in a timely manner to either prevent escalations from occurring or reduce the severity of an escalation if one does occur. The DevOps team now acts as level 2 support while before they came into action as level 3 support.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Event management </h1>
                </header>
            
            <article>
                
<p>The DevOps team have to monitor and manage all of the applications, as per the customer's requirements, for compute, storage, network, VMs, containers, and so on, by using vRealize tools and get critical alerts for the events related to applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Capacity management </h1>
                </header>
            
            <article>
                
<p>Custom profiles allow you to expand the capabilities of capacity planning by automating capacity calculations based on specifications that you create. Choosing a committed project will alter our capacity numbers as it assumes the resource is committed. If we don't want these numbers to change, then we can go back and select a plan from the <span class="packt_screen">Capacity and Utilization</span> dashboard. Maintenance mode allows us to prevent planned downtime from affecting capacity planning.</p>
<p class="mce-root"/>
<p>The solution must provide the ability to proactively determine capacity issues and risks for the virtual environment. It must provide capacity trending, demand forecasting, and a what-if impact analysis of future projects: </p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/de0fb929-c7a3-4377-b4af-e8f0a8357108.png" style="width:38.25em;height:14.58em;"/></p>
<p>A custom dashboard will be created for use by the test and development team. The intention is to give a specific view of test and dev VMs in the vSphere infrastructure, focusing on workload, capacity remaining, and reclaimable capacity. The following components will make up the test and dev dashboard:</p>
<ul>
<li>Dev VMs overview, displaying health, risk, and efficiency for the server and workstation VMs</li>
<li>VM workload heat map, color-coded to display the selected type VMs</li>
<li>VMs with the lowest disk space <span class="packt_screen">Capacity Remaining</span> (%) over the past week:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ea5c4395-2301-4813-87be-3fd45792936f.png" style="width:23.17em;height:21.33em;"/></p>
<ul>
<li>Idle VMs and VMs with the lowest utilization, flagged as idle if the utilization index becomes 1</li>
<li>Reclaimable capacity displays the percentage of resources that can be reclaimed</li>
<li>Powered off VMs and VMs are flagged as powered on</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Wavefront dashboard</h1>
                </header>
            
            <article>
                
<p>Wavefront is a metric-driven monitoring and analytics platform. DevOps and developers teams at enterprises that run cloud-native apps such as Box, Lyft, Intuit, and Workday use Wavefront to monitor the performance of cloud applications that reach amazing scale. The Wavefront platform collects and analyzes metrics from distributed applications running on VMware Cloud on AWS, AWS containers, microservices, cloud infrastructure, and even business data. Once metric data is in a Wavefront time-series database, Wavefront customers can apply powerful and flexible analytics in the form of the Wavefront Query Language. Developer teams use this to monitor the performance of their cloud services and distributed applications at unprecedented scale. They can troubleshoot faster and proactively alert and detect the leading indicators of anomalies with instant access, and unified visibility drives accelerate code releases by enabling the same visibility across all cloud services, infrastructures, and tools. Developer teams get instant visibility across all cloud services. Wavefront spreads across hundreds of engineers, enabling a self-service approach and empowering teams to innovate because Wavefront provides visibility in digital environments (digital service is the business). Business decisions are aligned with application code delivery, which helps everyone move faster with unified visibility.</p>
<p>Wavefront offers many ways to ingest data. We can retrieve data from AWS (APIs, CloudWatch, and CloudTrail) directly and can create metrics from logs.</p>
<p>Wavefront's key differentiators from DevOps and developer teams are as follows:</p>
<ul>
<li>Wavefront allows you to apply advanced metrics and query-driven analytics. There are over 100 mathematical transformations available for you to work with metrics data. We can troubleshoot issues faster using analytics. Wavefront, as a SaaS analytics platform, offers massive scale and high availability.</li>
<li>It offers customizable dashboards that help DevOps teams take ownership of code in production. Dashboards can be shared and exported with one click.</li>
<li>Intelligent alerting and proactive monitoring help detect leading indicators (quickly) or quickly zero-in on an anomaly where we can isolate problems by their desired shape or time, or by any condition we define.</li>
</ul>
<p>Once Wavefront enters an organization, its adoption spreads across hundreds of developers, enabling a self-service approach and empowering them to innovate in a collaborative fashion. Synchronized business decisions aligned with code releases helps SaaS businesses move faster. Because Wavefront is typically adopted at leading SaaS enterprises, and since their cloud service is their lifeline, it helps business leaders make analytics-driven business decisions. These decisions are synchronized with cloud services code delivery, helping everyone move faster.</p>
<p>Wavefront integrations allow you to collect, analyze, and harness data from any data source, and tier important things to remember. Wavefront integrations help to accelerate this process with full RESTful APIs and user interfaces. Data from individual tools can be correlated with other tiers. Wavefront is unique at a very high scale with these features. Powerful correlations across tiers help us win across point tools and metrics platforms. The Wavefront platform offers RESTful APIs for extensibility. The Wavefront API integrates with any tool of choice for developers or DevOps tooling, and makes integration easy. For example, Lyft wanted to keep their Grafana dashboards and use Wavefront as the most scalable backend time-series database.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting insights by monitoring how people work</h1>
                </header>
            
            <article>
                
<p>We have to monitor how people are working and get better insights in to whether the business and operations are going well or not. It is always hard to collect metrics and monitor people, and we can't compel people to generate metrics on their own. So, with the collaborative solutions such as slack and SaaS metrics monitoring solutions such as Wavefront, it becomes easier to track and monitor people's interests and activities, and gain insights from this. Wavefront allows you to apply advanced metrics and query-driven analytics. There are over 100 mathematical transformations available to work with metrics data. We can troubleshoot issues faster with Wavefront, which is a SaaS analytics platform with massive scale and high availability. It offers customizable dashboards, which help DevOps teams to take ownership for code in production. Their dashboards have one-click intelligent alerting and proactive monitoring where we can isolate a problem by its desired shape or time, or any condition that's been defined.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Automation with vRealize</h1>
                </header>
            
            <article>
                
<p>vRA can be designed in a distributed and highly available architecture to provide multi-role services. This highly available architecture with load balancing can be configured from the vRA installation wizard by integrating it with VMware Identity Manager with high availability mode for <strong>Single Sign-On</strong> (<strong>SSO</strong>). It will be clustered with embedded vRA appliance PostgreSQL internal databases as the external PostgreSQL option is no longer available. It also has clustered embedded vRO services and high availability for workflows and extensibility. It accesses Microsoft Active Directory servers to perform the authentication of users and Active Directory group membership enumeration. This provides a prescribed reference architecture design that allows for an SDDC content life cycle solution. The solution addresses the following three main objectives:</p>
<ul>
<li>Automation of the transfer of vRO and vRA content between different environments</li>
<li>vRO/vRA content storage and version control, including rollbacks</li>
<li>Reduction of the time and effort required to test the compliance of the vRO/vRA content using automation</li>
</ul>
<p>This has been designed to allow authenticated users to achieve the synchronization of content between vRA environments. The services that are defined in the project are as follows:</p>
<ul>
<li>Creation of content packages</li>
<li>Testing packages on a test/validation environment</li>
<li>Deployment of packages to the deployment's target environment</li>
<li>Management of endpoints (adding/deleting)</li>
</ul>
<p>The following diagram shows the <strong>SDDC Content</strong> <strong>Life cycle</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1560 image-border" src="assets/2f3d75f7-1ad5-47bd-91bb-98373b51b4b3.png" style="width:42.08em;height:22.83em;"/></p>
<p>Following are the components:</p>
<ul>
<li>The <strong>Production Tenant</strong> is the production vRA tenant endpoint. vRA and vRO content is deployed to this endpoint so that it can be consumed by end users.</li>
<li><strong>vRO</strong> provides orchestration capabilities using workflows for capture, test, and release content.</li>
<li><strong>Workflows</strong> are organized into a vRCS pipeline that represents the content life cycle, allowing content to flow through development, test, and into production.</li>
<li><strong>Xenon</strong> provides the content storage capability. The SDDC content is stored in the repository after it is captured and version controlled throughout its life cycle.</li>
<li><strong>Configuration</strong> <span>of the VMs that are used to host the services of the solution is based on the recommendation to deploy an infrastructure that supports up to 100 pipelines and up to 30 simultaneous pipeline executions.</span><br/></li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying Infrastructure as Code</h1>
                </header>
            
            <article>
                
<p>We need to configure vRA and NSX, which will allow for an isolated network of VMs to be used from the dev environment.</p>
<p>The network layout of the desired solution is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/14548237-9354-4a06-ad88-681c6a02b5fe.png" style="width:34.17em;height:3.75em;"/></p>
<p>NSX Edge will provide <strong>Source Network Address Translation</strong> (<strong>SNAT</strong>) routing so that isolated VMs can have access to external dev network resources in this layout. It will also provide <strong><span>destination NAT</span></strong> (<strong>DNAT</strong>) port forwarding so that dev machines are able to access specific services on a target isolated VM by addressing the NSX Edge in this layout. This design will also make use of the vSphere linked clones technology to minimize storage requirements. vRA provisioning will be implemented with the following blueprint structure:</p>
<ul>
<li><strong>Base Windows image</strong>: This will provision a blank Windows image that will become accessible through vRA.</li>
<li><strong>Base Linux image</strong>: This will provision a blank Linux image that will be become accessible through vRA.</li>
<li><strong>Windows linked clone component</strong>: This will be the linked clone blueprint on top of the VM that was instantiated from the base Windows image and a specific snapshot. This represents the actual isolated VM to be provisioned.</li>
<li><strong>Linux linked clone component</strong>: This will be the linked cone blueprint on top of the VM that was instantiated from the base Linux image and a specific snapshot. This represents the actual isolated VM to be provisioned.</li>
<li><strong>Multi-machine blueprint</strong>: This will be a collection of the component blueprints that will be provisioned at once:</li>
</ul>
<p>To provision the machine properly, the following components should be included:</p>
<ul>
<li><strong>External network profile</strong>: This is a definition of the subnet from the external dev network, along with details for routing and DNS resolution:</li>
<li><strong>Cluster reservation</strong>: A dedicated reservation is needed to limit resource usage to only a single datastore (so that the linked clone works), as well as to map the network port group to the <span class="packt_screen">External</span> network profile.</li>
</ul>
<ul>
<li><strong>NAT network profile</strong>: This is a definition of the subnet that isolated VMs will use behind NSX Edge. This is only a template that will later be copied into the multi-machine blueprint components assignment:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3359a955-98d0-4fb5-9e05-76826c1bb0e6.png" style="width:31.00em;height:25.42em;"/></p>
<ul>
<li><strong>Reservation policy</strong>: This will be a dedicated reservation policy that ensures that all blueprints will only address the designated cluster reservation that's created.</li>
<li><strong>Machine prefix</strong>: This is only used to distinguish the machines that have been provisioned by the multi-machine blueprint.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">vRealize Code Stream</h1>
                </header>
            
            <article>
                
<p>vRealize Application Services is about modeling an application and automating its provisioning. vRCS is about modeling an application release process. The two are complementary: Code Stream relies on integrations with <strong>virtual reality as a service</strong> (<strong>vRAAS</strong>), scripts, Puppet, and so on to deploy code. Code Stream allows us to codify or model the entire release process and promotion of builds across stages and/or environments (functional testing, load testing, systems integration testing, staging, and finally production). This includes not just triggering application deployment (via scripts or other tools) but triggering tests and looking at test results before deciding to promote a build to the next stage.</p>
<p>It also supports creating manual tasks in a stage for operations that are not automated today. It's really a process orchestration tool rather than an app deployment or provisioning solution. Code Stream allows us to trigger the deployment of individual artifacts (<kbd>.jar</kbd>, <kbd>.war</kbd>, config files, and so on) as opposed to vRAAS, which forces us to redeploy the entire stack, including the underlying machine. One Code Stream appliance can handle about 100 concurrent pipeline executions. Puppet, Chef, and other configuration management tools are not direct competitors to Code Stream. These tools are often used to configure and deploy software, but Code Stream is all about modeling a release process. The core value of Code Stream is really to tie configuration management and infrastructure provisioning, as well as continuous integration and testing and approval systems together to automate the entire release process.</p>
<p>There are a number of technical advantages of this:</p>
<ul>
<li>Code Stream can automate and accelerate the life cycle of any type of software. This includes applications (traditional and cloud-native), as well as infrastructure and IT content (blueprints, workflows, scripts, templates, and so on).</li>
<li>Code Stream does not prescribe a certain type of release model or toolset. It can model the release process for companies who are just starting out and put a majority of manual tasks to a 100% automated release model. Therefore, it adapts to an organization's maturity level and allows them to gradually move toward a more automated model.</li>
<li>Code Stream allows teams to provision and deploy code to private as well as public clouds. Code Stream can take advantage of vRA's converged blueprint or work with other provisioning solutions such as Cloud Foundry. </li>
<li>VMware offers the best full-stack and completely integrated solution from the foundational SDDC to the management/provisioning layer with vRA, and finally release automation capabilities with Code Stream. So, while all products can be used independently (no vendor lock-in), when used together, customers have an unmatched platform to help them become more agile.</li>
</ul>
<p>We can install Code Stream without vRA as there is definitely value in deploying both products to get benefits from a fully integrated solution for provisioning automation and release automation. Code Stream supports two deployment models:</p>
<ul>
<li>Standalone, where only the Code Stream functionality is enabled on the virtual appliance. Admins can then optionally configure Code Stream to provision machines via an external vRA appliance.</li>
<li>Unified, where both the Code Stream and vRA functionality is enabled on the same appliance. vRA also requires a separate Windows server for IaaS functionality. This configuration is not a supported configuration for production.</li>
</ul>
<p>Jenkins is a build automation tool that promotes CI, a development practice that requires developers to integrate code into a shared source code repository such as Git several times a day. Each check-in is then verified by an automated build, allowing teams to detect problems early. At the heart of any CI tool is the job that automates a build and build-related activities such as a test that is run pre or post-build.</p>
<p>Release Automation tools such as Code Stream focus on modeling and automating the broader release process, all the way to production, which typically integrates CI and additional categories of tools such as provisioning, change management, and monitoring, and often, people do this for some manual tasks and/or approvals. Companies often use release automation tools to work toward CD, a practice where every good build is potentially pushed to production. CD is a superset of CI, involving more tools and more teams—not just development but operations and release teams as well. At the heart of a release automation or CD tool is the pipeline that models a process, including business constructs such as approvals.</p>
<p>Jenkins is an extensible tool and can be customized to go beyond doing basic builds and testing to orchestrate other activities toward the release process. We can customize vRO workflows to do some of what vRA does, but at some point we end up writing so much logic that the workflow-based solution becomes hard to maintain over time. The same can happen with custom solutions on top of Jenkins: they may work initially but get harder to manage over time, especially as you try to manage more applications. That's the typical drawback of a build versus buy approach. Jenkins Enterprise has a pipeline component to achieve release automation. It's still lacking key capabilities such as manual tasks and approvals and easy passing of variables from one step to the next in the pipeline, which are typically offered by top release automation vendors.</p>
<p>Code Stream is only available as a standalone product because of the following reasons:</p>
<ul>
<li>It does not comply with all the requirements and expected capabilities of suites such as vCloud or vRealize. For instance, it does not support localization, HA, or unattended installation.</li>
<li>It needs to evolve rapidly and follow a more frequent release cadence than existing suites.</li>
<li>It shares some common services with vRA, but it can be deployed without vRA so that release engineers or DevOps teams who don't use vRA can still have a lightweight continuous delivery solution.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pipeline automation model – the release process for any kind of software</h1>
                </header>
            
            <article>
                
<p>vRealize Code Stream is used by customers who want to automate their release or CD process. vRealize Code Stream allows developers and operations teams to release software more frequently by reducing operational risk. It is designed based on the principle to integrate and extend rather than rip and replace so that that we can use existing tools alongside the SDLC. This will help developers to use their existing investment in tools and skills. At the time of writing this book, vRealize Code Stream has three main capabilities:</p>
<ul>
<li>Pipeline automation</li>
<li>Artifact management</li>
<li>Release dashboard</li>
</ul>
<p>It will provide RESTful APIs and capabilities based on a comprehensive integration framework. Some examples of manual tasks are as follows:</p>
<ul>
<li><strong>Approvals</strong>:<strong> </strong>Code Stream has its own native approval workflow capability, which is shared with other vRealize products. Approvals can be used to add manual oversight at any stage in the pipeline's execution. In addition, Code Stream can also leverage vRO plugins to call work order ticketing systems to coordinate the approval workflows. </li>
<li> <strong>Modeling manual tasks</strong>: Tasks that require manual execution usually require some type of notification to the task owner via a work order ticketing system. Code Stream leverages vRO workflows and plugins to integrate with existing systems such as BMC Remedy <strong>IT Service Management</strong> (<strong>ITSM</strong>), HP Service Manager, ServiceNow, and so on. </li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"> vRCS deployment architecture</h1>
                </header>
            
            <article>
                
<p>This chapter describes the recommended deployment topologies for vRCS. vRCS can leverage vRA for VM provisioning. There are a couple of possible deployments:</p>
<ul>
<li>vRCS and vRA on the same single appliance (recommended for small POCs where vRCS and vRA are both lab/evaluation systems)</li>
<li>vRCS and vRA on two separate appliances (recommended for large POCs or production)</li>
</ul>
<ul>
<li>vRCS and vRA on two separate appliances where vRA is HA enabled (recommended for large POCs or production)</li>
<li>Artifactory deployed as an external entity</li>
</ul>
<p>vRCS does not support connecting to an external vRO and does not support its own HA setup, but it can integrate with an external HA setup of vRA for VM provisioning:</p>
<ul>
<li>vRCS and vRA (vRA) on the same single appliance</li>
<li>vRCS and vRA on two separate appliances</li>
<li>vRCS and vRA on two separate appliances where vRA is HA enabled</li>
<li>Artifactory deployed as an external entity</li>
</ul>
<p>Please be aware of the following when configuring the deployment:</p>
<ul>
<li>If the deployment of vRCS and vRA is in same appliance, it can lock up the whole appliance. Since the HA setup of vRA has its own SSO server, and there is no identity federation support, vRCS must use a shared user account to access vRA.</li>
<li>Please configure the vRA endpoint as a shared account and not per user session. vRCS integrates with <span><strong>Advanced Service Designer</strong> (<strong>ASD</strong>) </span>forms, and there is a new plugin named <span>ASD </span>that is shipped with vRCS 1.2. This plugin only works with an internal vRA.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"> System architecture</h1>
                </header>
            
            <article>
                
<p>The vRCS architecture describes the various components that are involved with the system architecture. Both vRCS and vRA can be on the same appliance with the appropriate license. vRCS requires the endpoint to be configured so that it can be integrated with any external product or service deployment. It requires an endpoint from vRA, even though vRA and vRCS are in same appliance for vRCS to communicate with vRA for VM provisioning.</p>
<p>vRCS can interact with vRA in two ways:</p>
<ul>
<li>Shared account (using single common user)</li>
<li>Per user session (SSO):</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1559 image-border" src="assets/3eb3c018-862e-43c5-956d-781dc3a09565.png" style="width:57.08em;height:43.92em;"/></p>
<p>Users have access to the following ports:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Server role</strong></p>
</td>
<td style="width: 70.2943%">
<p class="CDPAlignCenter CDPAlign"><strong>Port</strong></p>
</td>
</tr>
<tr>
<td style="width: 26.7057%">
<p>vRCS/vRA appliance</p>
</td>
<td style="width: 70.2943%">
<p class="CDPAlignCenter CDPAlign"><kbd>443</kbd></p>
</td>
</tr>
<tr>
<td style="width: 26.7057%">
<p>vRA identity appliance</p>
</td>
<td style="width: 70.2943%">
<p class="CDPAlignCenter CDPAlign"><kbd>7444</kbd></p>
</td>
</tr>
</tbody>
</table>
<p>The following diagram represents the vRCS communication workflow:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/55d6b76a-0aa4-40bc-800e-7bd54e544f84.png" style="width:40.58em;height:31.50em;"/><br/></p>
<p>Administrators need access to the following ports, other than the ports that are required by users:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td style="width: 29.7791%">
<p class="CDPAlignCenter CDPAlign"><strong>Server role</strong></p>
</td>
<td colspan="2" style="width: 21.5178%">
<p class="CDPAlignCenter CDPAlign"><strong>Port</strong></p>
 </td>
</tr>
<tr>
<td style="width: 29.7791%">
<p>vRA identity appliance</p>
</td>
<td colspan="2" style="width: 21.5178%">
<p class="CDPAlignCenter CDPAlign"><kbd>5480</kbd></p>
</td>
</tr>
<tr>
<td style="width: 29.7791%">
<p>vRCS/vRA appliance</p>
</td>
<td colspan="2" style="width: 21.5178%">
<p class="CDPAlignCenter CDPAlign"><kbd>5480</kbd></p>
</td>
</tr>
<tr>
<td style="width: 29.7791%">
<p class="CDPAlignCenter CDPAlign"><strong>Server role</strong></p>
</td>
<td style="width: 21.5178%">
<p class="CDPAlignCenter CDPAlign"><strong>Inbound ports</strong></p>
</td>
<td style="width: 47.8386%">
<p class="CDPAlignCenter CDPAlign"><strong> Service/system outbound ports</strong></p>
</td>
</tr>
<tr>
<td style="width: 29.7791%">
<p>vRCS/vRA appliance</p>
</td>
<td style="width: 21.5178%">
<p><kbd>443</kbd></p>
<p>SSH: <kbd>22</kbd></p>
<p>VAMI: <kbd>5480</kbd></p>
</td>
<td style="width: 47.8386%">
<p>Identity VA: <kbd>7444</kbd></p>
</td>
</tr>
<tr>
<td style="width: 29.7791%">
<p>vRA identity appliance</p>
</td>
<td style="width: 21.5178%">
<p><kbd>7444</kbd></p>
<p>SSH: <kbd>22</kbd></p>
<p>VAMI: <kbd>5480</kbd></p>
</td>
<td style="width: 47.8386%">
<p>LDAP: <kbd>389</kbd></p>
<p>LDAPS: <kbd>636</kbd></p>
<p> </p>
</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Integrating vRCS with an external, standalone vRA</h1>
                </header>
            
            <article>
                
<p>vRCS can integrate with an existing vRA for VM provisioning. Therefore, an endpoint needs to be created where external vRA endpoint-related details can be specified. This endpoint will be listed under the provisioning category while adding a task in a stage. This endpoint can support both shared account and per user session options. If an external vRA and vRCS links to the same SSO server, both options per user session and shared account are supported. However, if an external vRA has its own SSO server, only the shared account option is supported. This is because the identity federation between two SSO servers is not supported.</p>
<p>The user needs access to the following ports:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Server role</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Port</strong></p>
</td>
</tr>
<tr>
<td>
<p>vRCS</p>
</td>
<td>
<p><kbd>443</kbd></p>
</td>
</tr>
<tr>
<td>
<p>vRA appliance</p>
</td>
<td>
<p><kbd>443</kbd></p>
</td>
</tr>
<tr>
<td>
<p>vRA identity appliance (Code Stream)</p>
</td>
<td>
<p><kbd>7444</kbd></p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Administrators need access to the following ports, in addition to the ports that are required by users:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Server role</strong></p>
</td>
<td colspan="2">
<p class="CDPAlignCenter CDPAlign"><strong>Port</strong></p>
</td>
</tr>
<tr>
<td>
<p>vRCS</p>
</td>
<td colspan="2">
<p class="CDPAlignCenter CDPAlign"><kbd>5480</kbd></p>
</td>
</tr>
<tr>
<td>
<p>vRA appliance</p>
</td>
<td colspan="2">
<p class="CDPAlignCenter CDPAlign"><kbd>5480</kbd></p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Server role</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Inbound ports</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Service/system outbound ports</strong></p>
</td>
</tr>
<tr>
<td>
<p>vRCS</p>
</td>
<td>
<p><kbd>443</kbd></p>
<p>SSH: <kbd>22</kbd></p>
<p>VAMI: <kbd>5480</kbd></p>
</td>
<td>
<p>Identity CS VA: <kbd>7444</kbd></p>
<p>vRA VA: <kbd>443</kbd></p>
</td>
</tr>
<tr>
<td>
<p>vRA appliance</p>
</td>
<td>
<p><kbd>443</kbd></p>
<p>SSH: <kbd>22</kbd></p>
<p>VAMI: <kbd>5480</kbd></p>
</td>
<td>
<p>Identity vRA VA: <kbd>7444</kbd></p>
</td>
</tr>
<tr>
<td>
<p>vRA identity appliance (Code Stream)</p>
</td>
<td>
<p><kbd>7444</kbd></p>
<p>SSH: <kbd>22</kbd></p>
<p>VAMI: <kbd>5480</kbd></p>
</td>
<td>
<p>LDAP: <kbd>389</kbd></p>
<p>LDAPS: <kbd>636</kbd></p>
</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Code Stream provides the ability to model and visualize the release process of any type of software (applications, blueprints, workflows, configuration files, Puppet manifests, Chef recipes, and so on). All stakeholders (devs, operations teams, release engineers, and so on) can go to a central place to track the state of application and software releases. Users can view not just the history but exactly where builds and releases have failed. Code Stream and vRA use the same delivery platform (the same virtual appliance) and share many common services, including capturing release processes that IT is struggling with or spending a lot of time on, and automating those via vRCS and vRA.</p>
<p>As opposed to acquiring, integrating, and managing different solutions for provisioning and release automation, customers can benefit from a single solution. By integrating with artifact repositories such as JFrog Artifactory, Code Stream can manage and track the multiple artifact versions that are generated with new releases, and track their deployment across various environments. As companies release new app versions more often, the risk of deploying the wrong artifact version and breaking production increases significantly. To help customers have visibility into and tie all of their different repositories (Yum, NuGet, Nexus, and so on) into one place for troubleshooting and security auditing, it is important to track which artifacts have been deployed where. Code Stream can work for both Java/Linux and .NET/Windows shops and their respective toolsets. Certain release management tools (for example, Octopus, Microsoft Release Manager, and Chef Delivery) support only one technology or are optimized for one technology or certain toolsets. Code Stream does not prescribe any particular toolset, meaning it can support different teams using different technologies across the enterprise. In fact, it can be even be used for the life cycle of software that is not an application: scripts, workflows, blueprints, and so on.</p>
<p>In the next chapter, <a href="5cce66c5-1e67-470e-a3f8-1ba791438615.xhtml" target="_blank">Chapter 10</a>, <em>Transforming VMware IT Operations Using ML</em> we will learn about how to manage different cloud models from a single console and about the phase-wise transformation of data center operations methodologies. We will also learn how to design scalable infrastructure to host both legacy and new cloud native apps on unified platforms using ML-based solutions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li><em>DevOps and Agile development—VMware</em>, at<span> </span><a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/solutionoverview/vmware-devops-agile-development-white-paper.pdf">https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/solutionoverview/vmware-devops-agile-development-white-paper.pdf</a></li>
<li><em>vRealize Code Stream Management Pack for IT DevOps—VMware</em>, at<span> </span><a href="https://www.vmware.com/files/pdf/products/vrealize/vmware-vrealize-code-stream-management-solution-brief.pdf">https://www.vmware.com/files/pdf/products/vrealize/vmware-vrealize-code-stream-management-solution-brief.pdf</a></li>
<li><em>DevOps-Ready IT: Continuous Delivery of vRealize Automation Blueprints</em>, at <a href="https://blogs.vmware.com/management/2016/05/devops-ready-it-continuous-delivery-of-vrealize-automation-blueprints.html">https://blogs.vmware.com/management/2016/05/devops-ready-it-continuous-delivery-of-vrealize-automation-blueprints.html</a></li>
<li><em>vRealize Code Stream | Application Release Automation</em>, at<span> </span><a href="https://www.vmware.com/in/products/vrealize-code-stream.html" target="_blank">https://www.vmware.com/in/products/vrealize-code-stream.html</a></li>
<li><em>vRealize Code Stream Documentation—VMware Docs</em>, at <a href="https://docs.vmware.com/en/vRealize-Code-Stream/index.html">https://docs.vmware.com/en/vRealize-Code-Stream/index.html</a></li>
<li><em>From Zero to DevOps Hero using Cloud Automation</em>, at <a href="https://blogs.vmware.com/management/2018/10/devops-hero-with-cloud-automation.html">https://blogs.vmware.com/management/2018/10/devops-hero-with-cloud-automation.html</a></li>
<li><em>vRealize Code Stream—VMware</em>, at <a href="https://code.vmware.com/web/sdk/2.2.0/vrealize-code-stream">https://code.vmware.com/web/sdk/2.2.0/vrealize-code-stream</a></li>
<li><em>Overview of vSphere Integrated Containers For DevOps Administrators—VMware vSphere</em>, at<span> </span><a href="https://vmware.github.io/vic-product/assets/files/html/1.1/vic_dev_ops/overview_of_vic_devops.html">https://vmware.github.io/vic-product/assets/files/html/1.1/vic_dev_ops/overview_of_vic_devops.html</a></li>
</ul>


            </article>

            
        </section>
    </body></html>