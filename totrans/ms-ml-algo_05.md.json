["```py\ndef theta(theta_prev, z1=50.0, x3=10.0):\n    num = (8.0 * z1 * theta_prev) + (4.0 * x3 * (12.0 - theta_prev))\n    den = (z1 + x3) * (12.0 - theta_prev)\n    return num / den\n\ntheta_v = 0.01\n\nfor i in range(1000):\n    theta_v = theta(theta_v)\n\nprint(theta_v)\n1.999999999999999\n\np = [theta_v/6.0, (1-(theta_v/4.0)), theta_v/12.0]\n\nprint(p)\n[0.33333333333333315, 0.5000000000000002, 0.16666666666666657]\n```", "```py\nfrom sklearn.datasets import make_blobs\n\nnb_samples = 1000\nX, Y = make_blobs(n_samples=nb_samples, n_features=2, centers=3, cluster_std=1.5, random_state=1000)\n```", "```py\nfrom sklearn.mixture import GaussianMixture\n\ngm = GaussianMixture(n_components=3)\ngm.fit(X)\n```", "```py\nprint(gm.weights_)\n\n[ 0.32904743  0.33027731  0.34067526]\n\nprint(gm.means_)\n\n[[ 3.03902183 -7.69186648]\n [ 9.04414279 -0.37455175]\n [ 7.37103878 -5.77496152]]\n\nprint(gm.covariances_)\n\n[[[ 2.34943036  0.08492009]\n  [ 0.08492009  2.36467211]]\n\n [[ 2.10999633  0.02602279]\n  [ 0.02602279  2.21533635]]\n\n [[ 2.71755196 -0.0100434 ]\n  [-0.0100434   2.39941067]]]\n```", "```py\nimport numpy as np\n\nfrom sklearn.datasets import fetch_mldata\n\ndigits = fetch_mldata('MNIST original')\nX = zero_center(digits['data'].astype(np.float64))\nnp.random.shuffle(X)\n\nOmega = np.random.uniform(0.0, 0.75, size=X.shape[1])\nXh = X + np.random.normal(0.0, Omega, size=X.shape)\n```", "```py\nfrom sklearn.decomposition import FactorAnalysis\n\nfa = FactorAnalysis(n_components=64, random_state=1000)\nfah = FactorAnalysis(n_components=64, random_state=1000)\n\nXfa = fa.fit_transform(X)\nXfah = fah.fit_transform(Xh)\n\nprint(fa.score(X))\n-2162.70193446\n\nprint(fah.score(Xh))\n-3046.19385694\n```", "```py\nfrom sklearn.covariance import LedoitWolf\n\nldw = LedoitWolf()\nldwh = LedoitWolf()\n\nldw.fit(X)\nldwh.fit(Xh)\n\nprint(ldw.score(X))\n-2977.12971009\n\nprint(ldwh.score(Xh))\n-2989.27874799\n```", "```py\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=64, svd_solver='full', random_state=1000)\nXpca = pca.fit_transform(Xh)\n\nprint(pca.score(Xh))\n-3772.7483580391995\n```", "```py\nprint(np.sum(pca.explained_variance_ratio_))\n0.862522337381\n```", "```py\nfrom sklearn.decomposition import FastICA\n\nfastica = FastICA(n_components=64, max_iter=5000, random_state=1000)\nfastica.fit(X)\n```", "```py\nfastica = FastICA(n_components=640, max_iter=5000, random_state=1000)\nfastica.fit(Xs)\n```", "```py\nM = fastica.mixing_\nM0 = M[0] / np.max(M[0])\n\nprint(len(M0[np.abs(M0) < (np.mean(np.abs(M0)) / 2.0)]))\n233\n```"]