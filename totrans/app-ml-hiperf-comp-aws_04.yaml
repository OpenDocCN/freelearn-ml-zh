- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data Storage
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data storage in the cloud has become very common, not just for personal usage
    but also for business, computational, and application purposes as well. On the
    personal side, cloud storage is provided by well-known companies, ranging from
    a free usage tier of a few **Gigabytes** (**GBs**), to pay monthly or yearly plans
    for **Terabytes** (**TBs**) of data. These services are well integrated with applications
    on mobile devices, enabling users to store thousands of pictures, videos, songs,
    and other types of files.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: For applications requiring high-performance computations, cloud data storage
    plays an even bigger role. For example, training **Machine Learning** (**ML**)
    models over large datasets generally requires algorithms to run in a distributed
    fashion. If data is stored on the cloud, then it makes it much easier and more
    efficient for the ML platform to partition the data stored in the cloud and make
    these separate partitions available to the distributed components of the model
    training job. Similarly, for several other applications requiring large data amounts
    and high throughput, it makes much more sense to use cloud data storage to avoid
    throttling local storage. In addition, cloud data storage almost always has built-in
    redundancy to avoid hardware failures, accidental deletes, and hence loss of data.
    There are also several security and governance tools and features that are always
    provided with cloud data storage services. Furthermore, the true cost of ownership
    of data storage in the cloud is significantly reduced due to scale and infrastructure
    maintenance being managed by the storage service provider.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: AWS provides several options for cloud data storage. In this chapter, we will
    learn about the various AWS data storage services, along with the security, access
    management, and governance aspects of these services. In addition, we will also
    learn about the tiered storage options to save cloud data storage costs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: AWS services for storing data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data security and governance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tiered storage for cost optimization
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the right storage option for **High-Performance Computing** (**HPC**)
    workloads
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main technical requirements for being able to work with the various AWS
    storage options in this chapter are to have an AWS account and the appropriate
    permissions to use these storage services.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: AWS services for storing data
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AWS offers three different types of data storage services: object, file, and
    block. Depending on the need for the application, one or more of these types of
    services can be used. We will go through the AWS services spanning these storage
    categories in this section. The various AWS data storage services are shown in
    *Figure 4**.1*.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – AWS data storage services](img/B18493_04_001.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – AWS data storage services
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss the various storage options provided by
    AWS.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Simple Storage Service (S3)
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Simple Storage Service (S3)
- en: '**Amazon S3** is one of the most commonly used cloud data storage services
    for web applications, and high-performance compute use cases. It is Amazon’s object
    storage service providing virtually unlimited data storage. Some of the advantages
    of using Amazon S3 include very high scalability, durability, data availability,
    security, and performance. Amazon S3 can be used for a variety of cloud-native
    applications, ranging from simple data storage to very large data lakes to web
    hosting and high-performance applications, such as training very advanced and
    compute-intensive ML models. Amazon S3 offers several classes of storage options
    with differences in terms of data access, resiliency, archival needs, and cost.
    We can choose the storage class that best suits our use case and business needs.
    There is also an option for cost saving when the access pattern is unknown or
    changes over time (S3 Intelligent-Tiering). We will discuss these different S3
    storage classes in detail in the *Tiered storage for cost optimization* section
    of this chapter.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon S3** 是最常用的云数据存储服务之一，适用于网络应用和高性能计算用例。它是亚马逊的对象存储服务，提供几乎无限的数据存储。使用 Amazon
    S3 的一些优点包括非常高的可扩展性、持久性、数据可用性、安全性和性能。Amazon S3 可用于各种云原生应用，从简单的数据存储到非常大的数据湖，再到网站托管和高性能应用，例如训练非常高级和计算密集型的机器学习模型。Amazon
    S3 提供了几种存储选项，这些选项在数据访问、弹性、归档需求和成本方面有所不同。我们可以选择最适合我们的用例和业务需求的存储类别。当访问模式未知或随时间变化时，还有节省成本的选项（S3
    智能分层）。我们将在本章的“分层存储以优化成本”部分详细讨论这些不同的 S3 存储类别。'
- en: Key capabilities and features of Amazon S3
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon S3 的关键功能和特性
- en: In Amazon S3, data is stored as objects in *buckets*. An object is a file and
    any metadata that describes the file, and buckets are the resources (containers)
    for the objects. Some of the key capabilities of Amazon S3 are discussed next.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Amazon S3 中，数据以对象的形式存储在 *存储桶* 中。对象是一个文件及其描述文件的任何元数据，而存储桶是对象的资源（容器）。接下来将讨论
    Amazon S3 的一些关键功能。
- en: Data durability
  id: totrans-21
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据持久性
- en: Amazon S3 is designed to provide very high levels of durability to the data,
    up to 99.999999999%. This means that the chances of data objects stored in Amazon
    S3 getting lost are extremely low (average expected loss of approximately 0.000000001%
    of objects, or 1 out of 10,000 objects every 10 million years). For HPC applications,
    data durability is of the utmost importance. For example, for training an ML model,
    data scientists need to carry out various experiments on the same dataset in order
    to fine-tune the model parameters to get the best performance. If the data storage
    from which training and validation data is read is not durable for these experiments,
    then the results of the trained model will not be consistent and hence can lead
    to incorrect insights, as well as bad inference results. For this reason, Amazon
    S3 is used in many ML and other data-dependent HPC applications for storing very
    large amounts of data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3 设计用于提供非常高的数据持久性，高达 99.999999999%。这意味着存储在 Amazon S3 中的数据对象丢失的可能性极低（平均预期损失约为
    0.000000001% 的对象，或者说每 1000 万个对象中大约有 1 个在 1000 万年中丢失）。对于高性能计算应用，数据持久性至关重要。例如，为了训练机器学习模型，数据科学家需要对同一数据集进行各种实验，以微调模型参数以获得最佳性能。如果用于读取训练和验证数据的存储不适用于这些实验，则训练模型的输出将不会一致，从而导致错误的见解以及不良的推理结果。因此，Amazon
    S3 被用于许多机器学习和其他数据依赖型高性能计算应用，用于存储大量数据。
- en: Object size
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对象大小
- en: In Amazon S3, we can store objects up to 5 TB in size. This is especially useful
    for applications that require processing large files, such as videos (for example,
    high-definition movies or security footage), large logs, or other similar files.
    Many high-performance compute applications, such as training ML models for a video
    classification example, require processing thousands of such large files to come
    up with a model that makes inferences on unseen data well. A deep learning model
    can read these large files from Amazon S3 one (or more) at a time, store them
    temporarily on the model training virtual machine, compute and optimize model
    parameters, and then move on to the next object (file). This way, even machines
    with smaller disk space and memory can be used to train these computationally
    intensive models over large data files. Similarly, at the time of model inference,
    if there is a need to store the data, it can be stored in Amazon S3 for up to
    5 TB of object size.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Amazon S3 中，我们可以存储高达 5 TB 大小的对象。这对于需要处理大型文件的应用程序特别有用，例如视频（例如，高清电影或安全录像）、大型日志或其他类似文件。许多高性能计算应用程序，如用于视频分类的机器学习模型训练，需要处理数千个此类大型文件，以生成对未见数据做出良好推断的模型。深度学习模型可以一次（或多次）从
    Amazon S3 读取这些大型文件，将它们临时存储在模型训练虚拟机上，计算和优化模型参数，然后继续处理下一个对象（文件）。这样，即使是磁盘空间和内存较小的机器也可以用于在大型数据文件上训练这些计算密集型模型。同样，在模型推理时，如果需要存储数据，可以将其存储在
    Amazon S3 中，对象大小可达 5 TB。
- en: Storage classes
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 存储类别
- en: 'Amazon S3 has various storage classes. We can store data in any of these classes
    and can also move the data across the classes. The right storage class to pick
    for storing data depends on our data storage, cost, and retention needs. The different
    S3 storage classes are as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3 有各种存储类别。我们可以在这些类别中的任何一个中存储数据，也可以在类别之间移动数据。选择用于存储数据的正确存储类别取决于我们的数据存储、成本和保留需求。不同的
    S3 存储类别如下：
- en: S3 Standard
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 标准版
- en: S3 Standard-Infrequent Access
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 标准版-不经常访问
- en: S3 One Zone-Infrequent Access
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 单区-不经常访问
- en: S3 Intelligent-Tiering
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 智能分层
- en: S3 Glacier Instant Retrieval
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 冰川即时检索
- en: S3 Glacier Flexible Retrieval
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 冰川灵活检索
- en: S3 Glacier Deep Archive
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 冰川深存档
- en: S3 Outposts
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 Outposts
- en: We will learn about these storage classes in the *Tiered storage for cost optimization*
    section of this chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的“分层存储以优化成本”部分了解这些存储类别。
- en: Storage management
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 存储管理
- en: Amazon S3 also has various advanced storage management options, such as data
    replication, prevention of accidental deletion of data, and data version control.
    Data in Amazon S3 can be replicated into destination buckets in the same or different
    AWS Regions. This can be done to add redundancy and hence reliability and also
    improve performance and latency. This is quite important for HPC applications
    as well since real-time HPC applications that need access to data stored in Amazon
    S3 will benefit from accessing data from a geographically closer AWS Region. Performance
    is generally accelerated by up to 60% when datasets are replicated across multiple
    AWS Regions. Amazon S3 also supports batch operations for data access, enabling
    various S3 operations to be carried out on billions of objects with a single API
    call. In addition, lifecycle policies can be configured for objects stored in
    Amazon S3\. Using these policies, S3 objects can be moved automatically to different
    storage classes depending on access need, resulting in cost optimization.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3 还提供了各种高级存储管理选项，例如数据复制、防止数据意外删除和数据版本控制。Amazon S3 中的数据可以被复制到同一或不同 AWS
    区域的目标存储桶中。这样做可以增加冗余，从而提高可靠性和性能，并降低延迟。这对于高性能计算（HPC）应用也非常重要，因为需要访问存储在 Amazon S3
    中的数据的实时 HPC 应用将从访问地理位置更近的 AWS 区域的数据中受益。当数据集在多个 AWS 区域之间复制时，性能通常可以加速高达 60%。Amazon
    S3 还支持数据访问的批量操作，允许通过单个 API 调用执行各种 S3 操作。此外，可以为存储在 Amazon S3 中的对象配置生命周期策略。使用这些策略，S3
    对象可以根据访问需求自动移动到不同的存储类别，从而实现成本优化。
- en: Storage monitoring
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 存储监控
- en: 'Amazon S3 also has several monitoring capabilities. For example, tags can be
    assigned to S3 buckets, and AWS cost allocation reports can be used to view aggregated
    usage and cost using these tags. Amazon CloudWatch can also be used to view the
    health of S3 buckets. In addition, bucket- and object-level activities can also
    be tracked using AWS CloudTrail. *Figure 4**.2* shows an example of various storage
    monitoring tools working with an Amazon S3 bucket:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊S3还具有一些监控功能。例如，可以将标签分配给S3存储桶，并使用AWS成本分配报告来查看使用这些标签的汇总使用情况和成本。Amazon CloudWatch还可以用于查看S3存储桶的健康状况。此外，还可以使用AWS
    CloudTrail跟踪存储桶和对象级别的活动。*图4**.2*展示了各种存储监控工具与Amazon S3存储桶协同工作的示例：
- en: '![Figure 4.2 – S3 storage monitoring and management](img/B18493_04_002.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2 – S3存储监控和管理](img/B18493_04_002.jpg)'
- en: Figure 4.2 – S3 storage monitoring and management
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 – S3存储监控和管理
- en: The preceding figure shows that we can also configure Amazon **Simple Notification
    Service** (**SNS**) to trigger AWS Lambda to carry out various tasks in the case
    of certain events, such as new file uploads and so on.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图示显示，我们还可以配置亚马逊**简单通知服务**（**SNS**）以在发生某些事件的情况下触发AWS Lambda执行各种任务，例如新文件上传等。
- en: Data transfer
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据传输
- en: For any application built upon large amounts of data and using S3, the data
    first needs to be transferred to S3\. There are various services provided by AWS
    that work with S3 for different data transfer needs, including hybrid (premises/cloud)
    storage and online and offline data transfer. For example, if we want to extend
    our on-premise storage with cloud AWS storage, we can use **AWS Storage Gateway**
    (*Figure 4**.3*). Some of the commonly implemented use cases for AWS Storage Gateway
    are the replacement of tape libraries, cloud storage backend file shares, and
    low-latency caching of data for on-premise applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于建立在大量数据之上并使用S3的任何应用程序，数据首先需要传输到S3。AWS提供了各种服务，这些服务与S3协同工作，以满足不同的数据传输需求，包括混合（本地/云）存储以及在线和离线数据传输。例如，如果我们想将我们的本地存储扩展到云AWS存储，我们可以使用**AWS存储网关**（*图4**.3*）。AWS存储网关的一些常见用例包括替换磁带库、云存储后端文件共享以及为本地应用程序提供低延迟数据缓存。
- en: '![Figure 4.3 – Data transfer example using AWS Storage Gateway](img/B18493_04_003.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – 使用AWS存储网关的数据传输示例](img/B18493_04_003.jpg)'
- en: Figure 4.3 – Data transfer example using AWS Storage Gateway
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 使用AWS存储网关的数据传输示例
- en: For use cases requiring online data transfer, AWS DataSync can be used to efficiently
    transfer hundreds of terabytes into Amazon S3\. In addition, AWS Transfer Family
    can also be used to transfer data to S3 using SFTP, FTPS, and FTP. For offline
    data transfer use cases, AWS Snow Family has a few options available, including
    AWS Snowcone, AWS Snowball, and AWS Snowmobile. For more details about the AWS
    Snow Family, refer to the *Further* *reading* section.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要在线数据传输的用例，可以使用AWS DataSync高效地将数百TB数据传输到Amazon S3。此外，AWS Transfer Family也可以用于使用SFTP、FTPS和FTP将数据传输到S3。对于离线数据传输用例，AWS
    Snow Family提供了一些选项，包括AWS Snowcone、AWS Snowball和AWS Snowmobile。有关AWS Snow Family的更多详细信息，请参阅*进一步阅读*部分。
- en: Performance
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能
- en: One big advantage of S3 for HPC applications is that it supports parallel requests.
    Each S3 prefix supports 3,500 requests per second to add data and 5,500 requests
    per second to retrieve data. Prefixes are used to organize data in S3 buckets.
    These are a sequence of characters at the beginning of an object’s key name. We
    can have as many prefixes as we need in parallel, and each prefix will support
    this throughput. This way, we can achieve the desired throughput for our application
    by adding prefixes. In addition, if there is a long geographic separation between
    the client and the S3 bucket, we can use Amazon S3 Transfer Acceleration to transfer
    data. Amazon CloudFront is a globally distributed network of edge locations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: S3对于HPC应用程序的一个重大优势是它支持并行请求。每个S3前缀每秒支持3500次添加数据请求和5500次检索数据请求。前缀用于在S3存储桶中组织数据。这些是对象键名开头的一系列字符。我们可以根据需要并行拥有多个前缀，每个前缀都将支持这种吞吐量。这样，我们可以通过添加前缀来实现应用程序所需的吞吐量。此外，如果客户端和S3存储桶之间存在较长的地理距离，我们可以使用Amazon
    S3传输加速来传输数据。Amazon CloudFront是一个全球分布的边缘位置网络。
- en: Using S3 Transfer Allocation, data is first transferred to an edge location
    in Amazon CloudFront. From the edge location, an optimized high-bandwidth and
    low-latency network path is then used to transfer the data to the S3 bucket. Furthermore,
    data can also be cached in CloudFront edge locations for frequently accessed requests,
    further optimizing performance. These performance-related features help in improving
    throughput and reducing latency for data access, especially suited to various
    HPC applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用S3传输分配，数据首先传输到Amazon CloudFront的边缘位置。从边缘位置，然后使用优化后的高带宽和低延迟网络路径将数据传输到S3存储桶。此外，数据还可以在CloudFront边缘位置缓存，以优化频繁访问请求的性能。这些与性能相关的功能有助于提高数据访问的吞吐量和降低延迟，特别适合各种高性能计算（HPC）应用。
- en: Consistency
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一致性
- en: Data storage requests to Amazon S3 have strong read-after-write consistency.
    This means that any data written (new or an overwrite) to S3 is available immediately.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 向Amazon S3的数据存储请求具有强大的读后写一致性。这意味着任何写入（新或覆盖）到S3的数据都可以立即访问。
- en: Analytics
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分析
- en: Amazon S3 also has analytics capabilities, including S3 Storage Lens and S3
    Storage Class Analysis. S3 Storage Lens can be used to improve storage cost efficiency,
    as well as to provide best practices for data protection. In addition, it can
    be used to look into object storage usage and activity trends. It can provide
    a single view across thousands of accounts in an organization and can generate
    insights on various levels, such as account, bucket, and prefix. Using S3 Storage
    Class, we can optimize cost by deciding on when to move data to the right storage
    class. This information can be used to configure the lifecycle policy to make
    the data transfer for the S3 bucket. Amazon S3 Inventory is another S3 feature
    that generates daily or weekly reports, including bucket names, key names, last
    modification dates, object size, class, replication, encryption status, and a
    few additional properties.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3还具备分析功能，包括S3存储透镜和S3存储类分析。S3存储透镜可用于提高存储成本效率，以及提供数据保护的最佳实践。此外，它还可以用于查看对象存储的使用和活动趋势。它可以在组织中的数千个账户中提供单一视图，并在多个级别上生成见解，如账户、存储桶和前缀。使用S3存储类，我们可以通过决定何时将数据移动到正确的存储类来优化成本。这些信息可用于配置生命周期策略，以实现S3存储桶的数据传输。Amazon
    S3库存是另一个S3功能，它生成每日或每周报告，包括存储桶名称、键名称、最后修改日期、对象大小、类别、复制、加密状态以及一些额外的属性。
- en: Data security
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据安全
- en: Amazon S3 has various security measures and features. These features include
    blocking unauthorized users from accessing data, locking objects to prevent deletions,
    modifying object ownership for access control, identity and access management,
    discovery and protection of sensitive data, server-side and client-side encryption,
    the inspection of an AWS environment, and connection to S3 from on-premise or
    in the cloud using private IP addresses. We will learn about these data security
    and access management features in detail in the *Data security and* *governance*
    section.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3具有各种安全措施和功能。这些功能包括阻止未经授权的用户访问数据、锁定对象以防止删除、修改对象所有权以进行访问控制、身份和访问管理、发现和保护敏感数据、服务器端和客户端加密、检查AWS环境，以及使用私有IP地址从本地或云连接到S3。我们将在*数据安全与*
    *治理* 部分详细了解这些数据安全和访问管理功能。
- en: Amazon S3 example
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon S3示例
- en: 'To be able to store data in an S3 bucket, we first need to create the bucket.
    Once the bucket is created, we can upload objects to the bucket. After uploading
    the object, we can download, move, open, or delete it. In order to create an S3
    bucket, there are certain prerequisites listed as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要能在S3存储桶中存储数据，我们首先需要创建该存储桶。一旦存储桶创建成功，我们就可以向其中上传对象。上传对象后，我们可以下载、移动、打开或删除它。为了创建S3存储桶，有一些先决条件，如下所述：
- en: Signing up for an AWS account
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册AWS账户
- en: Creating an **Identity and Access Management** (**IAM**) user or a federated
    user assuming an IAM role
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个**身份和访问管理**（**IAM**）用户或假定IAM角色的联合用户
- en: Signing in as an IAM user
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以IAM用户身份登录
- en: Details of how to carry out these prerequisite steps can be found on Amazon
    S3’s documentation web page (see the *Further* *reading* section).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如何执行这些先决步骤的详细信息可以在Amazon S3的文档网页上找到（参见*进一步* *阅读* 部分）。
- en: S3 bucket creation
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3存储桶创建
- en: 'We can create an S3 bucket by logging into the AWS management console and selecting
    S3 in the services. Once in the S3 console, we will see a screen like that shown
    in *Figure 4**.4*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以通过登录 AWS 管理控制台并在服务中选择 S3 来创建一个 S3 存储桶。一旦进入 S3 控制台，我们将看到一个类似于 *图 4**.4*
    所示的屏幕。4*:'
- en: '![Figure 4.4 – Amazon S3 console](img/B18493_04_004.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – Amazon S3 控制台](img/B18493_04_004.jpg)'
- en: Figure 4.4 – Amazon S3 console
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – Amazon S3 控制台
- en: 'As *Figure 4**.4* shows, we do not have any S3 buckets so far in our account.
    To create an S3 bucket, perform the following steps:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 4**.4* 所示，我们目前在账户中还没有任何 S3 存储桶。要创建一个 S3 存储桶，请执行以下步骤：
- en: Click on one of the **Create bucket** buttons shown on this page. *Figure 4**.5*
    shows the **Create bucket** page on the S3 console.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击此页面上显示的 **创建存储桶** 按钮之一。*图 4**.5* 显示了 S3 控制台上的 **创建存储桶** 页面。
- en: 'Next, we need to specify **Bucket name** and **AWS Region**. Note that the
    S3 bucket name needs to be globally unique:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要指定 **存储桶名称** 和 **AWS 区域**。请注意，S3 存储桶名称需要是全球唯一的：
- en: '![Figure 4.5 – Amazon S3 bucket creation](img/B18493_04_005.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – Amazon S3 存储桶创建](img/B18493_04_005.jpg)'
- en: Figure 4.5 – Amazon S3 bucket creation
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – Amazon S3 存储桶创建
- en: 'We can also select certain bucket settings from one of our existing S3 buckets.
    On the S3 **Create bucket** page, we can also define whether the objects in the
    bucket are owned by the account creating the bucket or not, as other AWS accounts
    can also own the objects in the bucket. In addition, we can also select whether
    we want to block all public access to the bucket (as shown in *Figure 4**.6*).
    There are also other options that we can select on the S3 bucket creation page,
    such as versioning, tags, encryption, and object locking:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以从我们的现有 S3 存储桶中选择某些存储桶设置。在 S3 **创建存储桶** 页面上，我们还可以定义存储桶中的对象是否由创建存储桶的账户拥有，因为其他
    AWS 账户也可以拥有存储桶中的对象。此外，我们还可以选择是否要阻止对存储桶的所有公共访问（如图 *图 4**.6* 所示）。在 S3 存储桶创建页面上还有其他我们可以选择的功能，例如版本控制、标签、加密和对象锁定：
- en: '![Figure 4.6 – Public access options for the S3 bucket](img/B18493_04_006.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – S3 存储桶的公共访问选项](img/B18493_04_006.jpg)'
- en: Figure 4.6 – Public access options for the S3 bucket
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – S3 存储桶的公共访问选项
- en: 'Once the bucket has been created, it will show up in the S3 console as shown
    in *Figure 4**.7*, where we have created a bucket named `myhpcbucket`. We can
    add objects to it using the console, AWS **Command Line Interface** (**CLI**),
    AWS SDK, or Amazon S3 Rest API:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储桶创建完成后，它将显示在 S3 控制台中，如图 *图 4**.7* 所示，其中我们创建了一个名为 `myhpcbucket` 的存储桶。我们可以使用控制台、AWS
    **命令行界面** （**CLI**）、AWS SDK 或 Amazon S3 Rest API 向其中添加对象：
- en: '![Figure 4.7 – Amazon S3 console showing myhpcbucket](img/B18493_04_007.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 显示 myhpcbucket 的 Amazon S3 控制台](img/B18493_04_007.jpg)'
- en: Figure 4.7 – Amazon S3 console showing myhpcbucket
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 显示 myhpcbucket 的 Amazon S3 控制台
- en: We can click on the bucket name and view objects stored in it along with bucket
    properties, permissions, metrics, management options, and access points.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以点击存储桶名称，查看其中存储的对象以及存储桶属性、权限、指标、管理选项和访问点。
- en: In this section, we have learned about the Amazon S3 storage class, its key
    features and capabilities, and how to create an Amazon S3 bucket. In the next
    section, we are going to discuss Amazon Elastic File System, which is the file
    system for Amazon Elastic Compute Cloud instances.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了关于 Amazon S3 存储类、其关键特性和功能，以及如何创建一个 Amazon S3 存储桶。在下一节中，我们将讨论 Amazon
    Elastic File System，它是 Amazon Elastic Compute Cloud 实例的文件系统。
- en: Amazon Elastic File System (EFS)
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Elastic File System (EFS)
- en: '**Amazon Elastic File System** (**EFS**) is a fully managed serverless elastic
    NFS file system specifically designed for Linux workloads. It can quickly scale
    up to petabytes of data automatically and is well suited to work with on-premise
    resources as well as with various AWS services. Amazon EFS is designed such that
    thousands of **Amazon Elastic Compute Cloud** (**EC2**) instances can be provided
    with parallel shared access. In addition to EC2, EFS file systems can also be
    accessed by **Amazon Elastic Container Service** (**ECS**), **Amazon Elastic Kubernetes
    Service** (**EKS**), **AWS Fargate**, and **AWS Lambda** functions through a file
    system interface. The following are some of the common EFS use cases:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**亚马逊弹性文件系统**（**EFS**）是一个完全管理的无服务器弹性NFS文件系统，专门为Linux工作负载设计。它可以自动扩展到PB级数据，非常适合与本地资源以及各种AWS服务一起使用。亚马逊EFS的设计使得数千个**亚马逊弹性计算云**（**EC2**）实例可以提供并行共享访问。除了EC2之外，EFS文件系统还可以通过文件系统接口由**亚马逊弹性容器服务**（**ECS**）、**亚马逊弹性Kubernetes服务**（**EKS**）、**AWS
    Fargate**和**AWS Lambda**函数访问。以下是一些常见的EFS用例：'
- en: '**High-performance compute**: Since Amazon EFS is a shared file system, it
    is ideal for applications that require distributed workload across many instances.
    Applications and use cases requiring high-performance computes, such as image
    and video processing, content management, and ML applications, such as feature
    engineering, data processing, model training, numerical optimization, big data
    analytics, and similar applications, can benefit from Amazon EFS.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高性能计算**：由于亚马逊EFS是一个共享文件系统，因此非常适合需要跨多个实例分布式工作负载的应用程序。需要高性能计算的应用程序和用例，如图像和视频处理、内容管理以及特征工程、数据处理、模型训练、数值优化、大数据分析等类似的应用程序，可以从亚马逊EFS中受益。'
- en: '**Containerized applications**: Amazon EFS is a very good fit for containerized
    applications because of its durability, which is a very important requirement
    of these applications. EFS integrates with Amazon container-based services such
    as Amazon ECS, Amazon EKS, and AWS Fargate.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器化应用程序**：由于亚马逊EFS具有耐久性，这对于这些应用程序来说是非常重要的，因此非常适合容器化应用程序。EFS与亚马逊基于容器的服务集成，例如亚马逊ECS、亚马逊EKS和AWS
    Fargate。'
- en: '**DevOps**: Amazon EFS can be used for DevOps because of its capability to
    share code. This helps with code modification and the application of bug fixes
    and enhancements in a fast, agile, and secure manner, resulting in quick turnaround
    time based on customer feedback.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DevOps**：由于亚马逊EFS具有共享代码的能力，因此可以用于DevOps。这有助于快速、敏捷、安全地修改代码以及应用错误修复和增强，从而根据客户反馈实现快速周转时间。'
- en: '**Database backup**: Amazon EFS is also often used as a database backup. This
    is because of the very high durability and reliability of EFS, and its low cost,
    along with being a POSIX-compliant file storage system – all of these often being
    requirements for a database backup from which the main database can be restored
    quickly in case of a loss or emergency.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库备份**：亚马逊EFS也常被用作数据库备份。这是因为EFS具有非常高的耐久性和可靠性，低成本，以及作为符合POSIX规范的文件存储系统——所有这些通常都是数据库备份的要求，在数据丢失或紧急情况下，可以从该备份快速恢复主数据库。'
- en: In the next section, we will discuss the key capabilities of Amazon EFS.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论亚马逊EFS的关键功能。
- en: Key capabilities and features of Amazon EFS
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊EFS的关键功能和特性
- en: In this section, we will discuss some of the key capabilities and features of
    Amazon EFS. Some of the key capabilities of Amazon S3 also apply to Amazon EFS.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论亚马逊EFS的一些关键功能和特性。亚马逊S3的一些关键功能也适用于亚马逊EFS。
- en: Durability
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 耐久性
- en: Like Amazon S3, Amazon EFS is also very highly durable and reliable, offering
    99.999999999% durability. EFS achieves this high level of durability and redundancy
    by storing everything across multiple **Availability Zones** (**AZs**) within
    the same AWS Region (unless we select EFS One Zone storage class for the EFS storage).
    Because data is available across multiple AZs, EFS has the ability to recover
    and repair very quickly from concurrent device failures.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 与亚马逊S3一样，亚马逊EFS也非常具有高度耐久性和可靠性，提供99.999999999%的耐久性。EFS通过在同一个AWS区域内的多个**可用区**（**AZs**）存储所有内容来实现这一高水平的耐久性和冗余（除非我们为EFS存储选择EFS单区存储类）。由于数据可以在多个AZs中访问，EFS具有从并发设备故障中快速恢复和修复的能力。
- en: Storage classes
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 存储类
- en: 'Amazon EFS also offers multiple options for storage via storage classes. These
    storage classes are as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊EFS还提供了通过存储类进行存储的多种选项。这些存储类如下：
- en: Amazon EFS Standard
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊EFS标准
- en: Amazon EFS One Zone
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon EFS单区
- en: Amazon EFS Standard-Infrequent Access
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon EFS标准-不常用访问
- en: Amazon EFS One Zone-Infrequent Access
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon EFS单区-不常用访问
- en: We will discuss these classes in the *Tiered storage for cost optimization*
    section. We can easily move files between storage classes for cost and performance
    optimization using policies.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*分层存储以优化成本*部分讨论这些类别。我们可以通过策略轻松地在存储类别之间移动文件以实现成本和性能优化。
- en: Performance and throughput
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能和吞吐量
- en: Amazon EFS has two modes each for performance and throughput. For performance
    modes, it has **General Purpose** and **Max I/O**. General Purpose mode provides
    low latency for random as well as sequential input-output file system operations.
    Max I/O, on the other hand, is designed for very high throughput and operations
    per second. It is, therefore, very well suited for high-performance and highly
    parallelized compute applications.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon EFS有两种性能和吞吐量模式。对于性能模式，它有**通用型**和**最大I/O**。通用型模式为随机以及顺序输入输出文件系统操作提供低延迟。另一方面，最大I/O模式是为非常高的吞吐量和每秒操作而设计的。因此，它非常适合高性能和高并行化计算应用。
- en: For throughput, EFS has Bursting (default) and Provisioned modes. In Bursting
    mode, the throughput scales with the size of the file system and can burst dynamically
    depending on the nature of the workload. In Provisioned mode, throughput can be
    provisioned depending on the dedicated throughput needed by the application. It
    does not depend on the size of the file system.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于吞吐量，EFS有突发（默认）和配置模式。在突发模式下，吞吐量随着文件系统的大小而扩展，并且可以根据工作负载的性质动态地突发。在配置模式下，吞吐量可以根据应用程序所需的专用吞吐量进行配置。它不依赖于文件系统的大小。
- en: Scalability
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可伸缩性
- en: Amazon EFS is highly elastic and scalable. It grows up and down in size as more
    data is added or removed and is designed for high throughput, **Input/Output Operations
    Per Second** (**IOPS**), and low latency for a wide variety of workloads and use
    cases. It also has the capability to provide very high burst throughput for unpredictable
    and spiky workloads, supporting up to 10 GB/second and 500,000 IOPS at the time
    of writing.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon EFS具有高度弹性和可伸缩性。随着数据的增加或减少，其大小会上下增长，并且是为高吞吐量、**每秒输入/输出操作**（**IOPS**）和低延迟而设计的，适用于广泛的负载和用例。它还具有为不可预测和波动的负载提供非常高的突发吞吐量的能力，在撰写本文时，支持高达10
    GB/秒和500,000 IOPS。
- en: AWS Backup
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AWS备份
- en: Amazon EFS works with AWS Backup, which is a fully managed backup service. It
    automates and enables us to centrally manage the EFS file systems, removing costly
    and tedious manual processes.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon EFS与AWS Backup一起工作，AWS Backup是一个完全托管的备份服务。它自动化并使我们能够集中管理EFS文件系统，消除了昂贵且繁琐的手动流程。
- en: Data transfer
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据传输
- en: Like Amazon S3, Amazon EFS also works with various AWS data transfer services,
    such as AWS DataSync and AWS Transfer Family, for transferring data in and out
    of EFS for one-time migration, as well as for periodic synchronization, replication,
    and data recovery.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与Amazon S3一样，Amazon EFS也与各种AWS数据传输服务一起工作，例如AWS DataSync和AWS Transfer Family，用于在EFS中传输数据，用于一次性迁移，以及用于定期同步、复制和数据恢复。
- en: An Amazon EFS example
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon EFS示例
- en: 'We can create an Amazon EFS file system either using the AWS Management Console
    or the AWS CLI. In this section, we will see an example of creating an EFS file
    system using the AWS Management Console:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用AWS管理控制台或AWS CLI创建Amazon EFS文件系统。在本节中，我们将通过AWS管理控制台创建EFS文件系统的示例：
- en: 'When we log into AWS Management Console and browse to Amazon EFS service, we
    will see the main page like the one shown in *Figure 4**.8*. It also lists all
    the EFS file systems that we have created in the AWS Region that we are looking
    at:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们登录AWS管理控制台并浏览到Amazon EFS服务时，我们会看到类似于*图4.8*的主页面。它还列出了我们在查看的AWS区域中创建的所有EFS文件系统：
- en: '![Figure 4.8 – Amazon EFS landing page](img/B18493_04_008.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图4.8 – Amazon EFS登录页面](img/B18493_04_008.jpg)'
- en: Figure 4.8 – Amazon EFS landing page
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 – Amazon EFS登录页面
- en: To create an Amazon EFS file system, we click on the **Create file system**
    button. When we click this button, we are shown a screen as shown in *Figure 4**.9*.
    Here, we can pick any name for our file system.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建Amazon EFS文件系统，我们点击**创建文件系统**按钮。当我们点击此按钮时，我们会看到一个类似于*图4.9*的屏幕。在这里，我们可以为我们的文件系统选择任何名称。
- en: '![Figure 4.9 – Creating an Amazon EFS file system](img/B18493_04_009.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9 – 创建Amazon EFS文件系统](img/B18493_04_009.jpg)'
- en: Figure 4.9 – Creating an Amazon EFS file system
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9 – 创建Amazon EFS文件系统
- en: For the file system, select a **Virtual Private Cloud** (**VPC**), and also
    select whether we want it across all AZs in our region or just one AZ.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can also click on the **Customize** button to configure other options, such
    as **Lifecycle management** (*Figure 4**.10*), **Performance mode** and **Throughput
    mode** (*Figure 4**.11*), **Encryption**, **Tags**, network options, and the **File**
    **system** policy.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.10 – Selecting options for an Amazon EFS file system](img/B18493_04_010.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 – Selecting options for an Amazon EFS file system
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Selecting additional options for Amazon EFS](img/B18493_04_011.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 – Selecting additional options for Amazon EFS
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Clicking on **Next** and then **Create** will create the Amazon EFS file system.
    The EFS file system we have created is shown in *Figure 4**.12*.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Created EFS file system](img/B18493_04_012.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Figure 4.12 – Created EFS file system
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: We can click on the file system to view its various properties as well as to
    get the command to mount it to a Linux instance as shown in *Figure 4**.13*. Once
    the EFS file system is mounted, we can use it just like a regular file system.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.13 – Mounting options and commands for the EFS file system](img/B18493_04_013.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: Figure 4.13 – Mounting options and commands for the EFS file system
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss Amazon **Elastic Block Store** (**EBS**) and its key features
    and capabilities in the next section.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EBS
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Amazon EBS** is a scalable, high-performance block storage service that can
    be used to create storage volumes that attach to EC2 instances. These volumes
    can be used for various purposes, such as a regular block storage volume, creating
    file systems on top of these, or even running databases. The following are some
    of the common use cases where Amazon EBS is used:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: EBS can be used for big data analytics, where frequent resizing of clusters
    is needed, especially for Hadoop and Spark.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several types of databases can be deployed using Amazon EBS. Some examples include
    MySQL, Oracle, Microsoft SQL Server, Cassandra, and MongoDB.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we are running a computation job on an EC2 instance and need storage volume
    attached to it to read the data and write results without the need to scale across
    multiple instances, then EBS serves as a good option.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let’s look at some of the key features and capabilities of Amazon EBS.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Key features and capabilities of Amazon EBS
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we discuss the key features and capabilities of Amazon EBS,
    such as volume types, snapshots, elastic volumes, EBS-optimized instances, and
    durability.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Volume types
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'EBS volumes are divided into two main categories: **SSD-backed storage** and
    **HDD-backed storage**. We discuss these categories here:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '**SSD-backed storage**: In SSD-backed storage, performance depends mostly on
    IOPS and is best suited for transactional workloads, for example, databases and
    boot volumes. There are two main types of SSD-backed storage volumes:'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provisioned IOPS SSD volumes**: They are very high throughput volumes and
    are designed to provide single-digit millisecond latencies while delivering the
    provisioned performance 99.9% of the time. They are especially suited for critical
    applications that require very high uptime.'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**General purpose SSD volumes**: These storage volumes also offer single-digit
    millisecond latency while delivering the provisioned performance 99% of the time.
    They are especially suited for transactional workloads, virtual desktops, boot
    volumes, and similar applications.'
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDD-backed storage**: In HDD-backed storage, performance depends mostly on
    MB/s and is best suited for throughput-intensive workloads, for example, MapReduce
    and log processing. There are also two main types of HDD-backed storage volumes:'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throughput optimized HDD volumes**: These volumes deliver performance measured
    in MB/s and are best suited for applications such as MapReduce, Kafka, log processing,
    and ETL workloads.'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cold HDD volumes**: They provide the lowest cost of all EBS volumes and are
    backed by hard disk drives. These volumes are best suited for infrequently accessed
    workloads, such as cold datasets.'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The option of picking the appropriate category for EBS volume provides user
    flexibility depending on the use case.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Snapshots
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Amazon EBS has the ability to store the volume snapshots to Amazon S3\. This
    is done incrementally, adding only the blocks of data that have been changed since
    the last snapshot. The data life cycle for EBS snapshots can be used to schedule
    the automated creation and deletion of EBS. These snapshots can be used not just
    for data recovery but also for initiating new volumes, expanding volume sizes,
    and moving EBS volumes across AZs in an AWS Region.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Elastic volumes
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Using Amazon EBS Elastic Volumes, we can increase the capacity of the volume
    dynamically at a later point and can also change the type of volume without any
    downtime.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: EBS-optimized instances
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To fully utilize the IOPS configured for an EBS volume and provide maximum performance,
    some EC2 instances can be launched as EBS-optimized instances. This ensures dedicated
    throughput between Amazon EC2 instance and Amazon EBS volume.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Durability
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like Amazon S3 and Amazon EFS, Amazon EBS is also highly durable and reliable.
    Data in Amazon EBS is replicated on multiple servers in an AZ to provide redundancy
    and recovery in case any single component in the volume storage fails.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: EBS volume creation
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When creating an EC2 instance, we can add additional EBS volumes to it, as shown
    in *Figure 4**.14* in the **Add Storage** step. In addition, we can also add new
    volumes from the EC2 management console after the instance has been launched.
    In the EC2 management console, we can review our existing volumes and snapshots
    along with lifecycle management policies.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.14 – Adding an EBS volume during the EC2 instance creation process](img/B18493_04_014.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: Figure 4.14 – Adding an EBS volume during the EC2 instance creation process
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 4**.15* shows an example where we have two EBS volumes, along with
    their various configuration parameters:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Volumes page in EC2 management console showing two EBS volumes
    that were created](img/B18493_04_015.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
- en: Figure 4.15 – Volumes page in EC2 management console showing two EBS volumes
    that were created
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: So far, in this chapter, we have learned about Amazon S3, Amazon EFS, and Amazon
    EBS. In the next section, we discuss the Amazon FSx family of file systems.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Amazon FSx
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Amazon FSx is a feature-rich, scalable, high-performance, and cost-effective
    family of file systems. It consists of the following commonly used four file systems:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Amazon FSx for NetApp ONTAP
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon FSx for Windows File Server
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon FSx for Lustre
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon FSx for OpenZFS
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the common examples where the FSx family of file systems is used are
    the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: FSx can deliver very low latency (sub-millisecond) and millions of IOPS and
    is highly scalable, making it ideal for high-performance compute applications,
    such as ML, numerical optimization, big data analytics, and similar applications
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data can be migrated without breaking or modifying existing code and workflows
    to FSx by matching the FSx file system to that of the on-premise one
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Media and entertainment is another example where FSx is very commonly used because
    of it being a high-performance file system
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key features of Amazon FSx
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will discuss the key features of Amazon FSx, such as management,
    durability, and cost.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Fully managed
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Amazon FSx is fully managed, making it very easy to migrate applications built
    on commonly used file systems in the industry to AWS. Linux, Windows, and macOS
    applications requiring very low latency and high performance work very well with
    Amazon FSx because of its sub-millisecond latencies.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Durability
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The data in Amazon FSx is replicated across or within AZs, in addition to having
    the option to replicate data across AWS Regions. It also integrates with AWS Backup
    for backup management and protection. These features make Amazon FSx a highly
    available and durable family of file systems.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cost and performance of Amazon FSx can be optimized depending on the need.
    It can be used for small as well as very compute-intensive workloads, such as
    ML and big data analytics. Like Amazon EBS, it also offers SSD and HDD storage
    options that can be configured for performance and storage capacity separately.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Creating an FSx file system
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can create an FSx file system by logging into the AWS management console.
    In the console, upon pressing the **Create file system** button, we get the option
    of selecting the type of FSx file system (*Figure 4**.16*).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.16 – FSx file system types](img/B18493_04_016.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: Figure 4.16 – FSx file system types
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Upon selecting the type that we want to create, we are also prompted with additional
    options, some of which are specific to that particular FSx system being created.
    Some of these options, such as deployment and storage types, network and security,
    and Windows authentication, are shown in *Figures 4.17*–*4.19* for FSx for Windows
    File Server. These options will vary depending on the type of file system that
    we are creating. After creating the file system, we can mount it to our EC2 instance.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.17 – Creating FSx for Windows File Server](img/B18493_04_017.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
- en: Figure 4.17 – Creating FSx for Windows File Server
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.18 – Network and security options for FSx for Windows File Server](img/B18493_04_018.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: Figure 4.18 – Network and security options for FSx for Windows File Server
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.19 – Authentication and encryption options for FSx for Windows File
    Server](img/B18493_04_019.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
- en: Figure 4.19 – Authentication and encryption options for FSx for Windows File
    Server
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our discussion on the various data storage options provided by
    AWS. We have learned about Amazon S3, Amazon EFS, Amazon EBS, and the Amazon FSx
    family, along with their key capabilities and features. In the next section, we
    will learn about the data security and governance aspects of cloud data storage
    on AWS.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Data security and governance
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data security and governance are very important aspects of cloud storage solutions
    and applications, whether they are web pages, file storage, ML applications, or
    any other application utilizing cloud data storage. It is of absolute importance
    that the data is protected while being at rest in storage or in transit. In addition,
    access controls should be applied to different users based on the privileges needed
    for data access. All the AWS data storage services mentioned previously have various
    security, protection, access management, and governance features. We will discuss
    these features in the following sections.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: IAM
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to be able to access AWS resources, we need an AWS account and to authenticate
    every time we log in. Once we have logged into AWS, we need permission to access
    the AWS resources. AWS IAM is used to attach permission policies to users, groups,
    and roles. These permission policies govern and control the access to AWS resources.
    We can specify who can access which resource and what actions they can take for
    that resource (for example, creating an S3 bucket, adding objects, listing objects,
    deleting objects, and so on). All AWS data storage services described in the previous
    section are integrated with AWS IAM, and access to these services and associated
    resources can be governed and controlled using IAM.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Data protection
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All AWS data storage and file system services have various data protection features.
    We should always protect AWS account credentials and create individual user accounts
    using AWS IAM, giving each user the least privileges to access AWS resources that
    are needed for their job duties. A few additional security recommendations that
    help with data protection in AWS are the use of **Multi-Factor Authentication**
    (**MFA**), **Secure Socket Layer** (**SSL**), **Transport Layer Security** (**TLS**),
    activity logging via **AWS CloudTrail**, AWS encryption solutions, and **Amazon
    Macie** for Amazon S3 for securing personal and sensitive data.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: The various tiers of Amazon S3 (except One Zone-IA) store all data objects across
    at least three AZs in an AWS Region. The One Zone-IA storage class provides redundancy
    and protection by storing data on multiple devices within the same AZ. In addition,
    with the help of versioning, different versions of data objects can be preserved
    and recovered as needed.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Data encryption
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AWS provides data encryption at rest as well as in transit. Encryption in transit
    can be carried out by enabling SSL/TLS. Also, all data across AWS Regions flowing
    over the AWS global network is automatically encrypted. In Amazon S3, data can
    also be encrypted using client-side encryption. Data at rest on Amazon S3 can
    be encrypted using either server-side encryption or client-side encryption. For
    server-side encryption, we can either use **AWS Key Management Service** (**KMS**)
    or Amazon S3-managed encryption. For client-side encryption, we need to take care
    of the encryption process and upload objects to S3 after encrypting them. We can
    also create encrypted Amazon EFS file systems, Amazon EBS volumes, and the Amazon
    FSx family of file systems.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Logging and monitoring
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logging and monitoring are two very essential components of any storage solution
    since we need to keep track of who is accessing the data and what they are doing
    with it. Often this logging is also necessary to satisfy audits and build analytics
    and reports for usage and threat analysis. AWS data storage services have several
    logging and monitoring tools available. Amazon CloudWatch alarms can be used to
    monitor metrics, triggering alarms to Amazon SNS to send notifications. We can
    also use Amazon CloudTrail to view actions taken by a user, IAM roles, and AWS
    services in our data storage and file systems. In addition, there are other logging
    and monitoring features, such as Amazon CloudWatch Logs to access log files and
    Amazon CloudWatch Events to capture state information and take corrective actions.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Resilience
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AWS infrastructure consists of AWS Regions, which in turn consist of multiple
    physically separated AZs. These AZs have high throughput and low latency connectivity.
    By default, S3, EFS, EBS, and FSx resources are backed up and replicated either
    across multiple AZs across an AWS Region or within the same AZ, depending on the
    configuration picked by the user. In addition, there are also several other resilience
    features specific to these data storage and file systems, such as lifecycle configuration,
    versioning, S3 object lock, EBS snapshots, and so on. All these features make
    the data stored on AWS highly resilient to failures and loss.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the aforementioned mentioned security and governance features
    of data storage services on AWS, there are several other options available as
    well, such as the configuration of VPCs, network isolation, and a few additional
    options. With the combination of these tools and resources, AWS data storage services
    are among the most secure cloud storage services available.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: AWS provides the option of using tiered storage for Amazon S3 and Amazon EFS.
    This helps with optimizing the data storage cost for the user.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Tiered storage for cost optimization
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS provides options for configuring its data storage services with various
    different tiers of storage types. This significantly helps with optimizing cost
    and performance depending on the use case requirements. In this section, we will
    discuss the tiered storage options for Amazon S3 and Amazon EFS.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 storage classes
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned in the *Amazon Simple Storage Service (S3)* section, there are
    various storage classes depending on the use case, access pattern, and cost requirements.
    We can configure S3 storage classes at the object level. We will discuss these
    storage classes in the following sections.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 Standard
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon S3 Standard is the general-purpose S3 object storage commonly used for
    frequently accessed data. It provides high throughput and low latency. Some of
    the common applications of S3 Standard are online gaming, big data analytics,
    ML model training and data storage, an offline feature store for ML applications,
    content storage, and distribution, and websites with dynamic content.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 Intelligent-Tiering
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazon S3 Intelligent-Tiering** is the storage class for unknown, unpredictable,
    and changing access patterns. There are three access tiers in S3 Intelligent-Tiering
    – frequent, infrequent, and archive tiers. S3 Intelligent-Tiering monitors access
    patterns and moves data to the appropriate tiers accordingly in order to save
    costs without impacting performance, retrieval fees, or creating operational overhead.
    In addition, we can also set up S3 Intelligent-Tiering to move data to the Deep
    Archive Access tier for data that is accessed very rarely (180 days or more).
    This can result in further additional cost savings.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 Standard-Infrequent Access
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazon S3 Standard-Infrequent Access** is for use cases where data is generally
    accessed less frequently, but rapid access may be required. It offers a low per
    GB storage price and retrieval charge but the same performance and durability
    as S3 Standard. Some of the common use cases for this tier are backups, a data
    store for disaster recovery, and long-term storage. For high-performance compute
    applications, such as ML, this storage tier can be used to store historical data
    on which models have already been trained or analytics have already been carried
    out and is not needed for model retraining for a while.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 One Zone-Infrequent Access
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazon S3 One Zone-Infrequent Access** is very similar to Amazon S3 Standard-Infrequent
    Access, but the data is stored in only one AZ (multiple devices) instead of the
    default three AZs within the same AWS Region as for other S3 storage classes.
    This is even more cost-effective than the S3 Standard-Infrequent Access storage
    class and is commonly used for storing secondary backups or easily re-creatable
    data, for example, engineered features no longer used for active ML model training.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 Glacier
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazon S3 Glacier** storage classes are highly flexible, low-cost, and high-performance
    data archival storage classes. In Amazon S3 Glacier, there are three storage classes.
    Amazon S3 Glacier Instant Retrieval is generally used where data is accessed very
    rarely, but the retrieval is required with latency in milliseconds, for example,
    news media assets and genomics data. Amazon S3 Flexible Retrieval is for use cases
    where large datasets such as backup recovery data need to be retrieved at no additional
    cost, but instant retrieval is not a requirement. The usual retrieval times for
    such use cases are a few minutes to a few hours. Amazon S3 Glacier Deep Archive
    is for use cases that require very infrequent retrieval, such as preserved digital
    media and compliance archives, for example. It is the lowest-cost storage of all
    the options discussed previously, and the typical retrieval time is 12 hours to
    2 days.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: S3 on Outposts
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For on-premise AWS Outposts environments, object storage can be configured using
    **Amazon S3 on Outposts**. It stores data reliably and redundantly across multiple
    devices and servers on AWS Outposts, especially suited for use cases with local
    data residency requirements.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will discuss the different storage classes for
    Amazon EFS.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EFS storage classes
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon EFS provides the option of different storage classes for access based
    on how frequently the data needs to be accessed, as discussed here.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EFS Standard and EFS Standard-Infrequent Access classes
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon EFS Standard and EFS Standard-Infrequent Access classes are highly available,
    durable, and elastic file system storage classes. They are both replicated across
    multiple geographically separated AZs within an AWS Region. EFS Standard is for
    use cases where our data needs frequent access, whereas the EFS Standard-Infrequent
    Access class is for use cases where frequent data access is not required. Using
    EFS Standard-Infrequent Access, we can reduce the storage cost significantly.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EFS One Zone and EFS One Zone-Infrequent Access classes
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon EFS One Zone and EFS One Zone-Infrequent Access classes store data within
    a single AZ across multiple devices, reducing the storage cost compared to Amazon
    EFS Standard and EFS Standard-Infrequent Access classes, respectively. For frequently
    accessed files, EFS One Zone is recommended, whereas for infrequently accessed
    files, EFS One Zone-Infrequent Access class is recommended.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: With multiple options available for Amazon S3 and Amazon EFS, the right approach
    is to first determine performance, access, and retrieval needs for a use case
    and then pick the storage class that satisfies these requirements while minimizing
    the total cost. Significant amounts of savings can be achieved if we pick the
    right storage class, especially for very big datasets and use cases where data
    scales significantly over time.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have discussed various AWS storage options for HPC along with their
    capabilities and cost optimization options. In the next section, we will learn
    about how to pick the right storage option for our HPC use cases.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right storage option for HPC workloads
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With so many choices available for cloud data storage, it becomes challenging
    to decide which storage option to pick for HPC workloads. The choice of data storage
    depends heavily on the use case and performance, throughput, latency, scaling,
    archival, and retrieval requirements.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: For use cases where we need to archive our object data for a very long time,
    Amazon S3 should be considered. In addition, Amazon S3 can be very well suited
    to several HPC applications since it can be accessed by other AWS services. For
    example, in Amazon SageMaker, we can carry out feature engineering using data
    stored in Amazon S3 and then ingest those features in the SageMaker offline feature
    store, which is, again, stored in Amazon S3\. Amazon SageMaker uses Amazon S3
    for ML model training. It reads data from Amazon S3 and carries out model fitting,
    hyperparameter optimization, and validation using this data. The model artifacts
    created as a result are then stored in Amazon S3 as well, which can be used for
    real-time or batch inference. In addition to ML, Amazon S3 is also a good choice
    of storage for carrying out data analytics, for storing data on which we want
    to run complex queries, data archiving, and backups.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EFS is a shared file system for Amazon EC2 instances. Thousands of EC2
    instances can share the same EFS file system. This makes it ideal for applications
    where high-performance scaling is needed. High-performance compute applications
    such as content management systems, distributed applications running on various
    instances needing access to the same data in the file system, and very large-scale
    data analysis are a few examples where EFS should be used.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EBS is a block storage service for single EC2 instances (except EBS Multi-Attach),
    so the main use case for EBS is when we need high-performance storage for an EC2
    instance. For high-performance compute applications such as ML and numerical optimization,
    often we need to access data for training and tuning our algorithms. The size
    of the data is often very large to be stored in memory during the process (for
    example, several thousand videos). In such cases, we may store data temporarily
    on EBS drives attached to the EC2 instances on which we are running our algorithms,
    making it much faster to swap and read between data files to carry out the compute
    operations.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Amazon FSx should be used when we have a similar file system running on-premise
    and we want to migrate our applications to the cloud while also designing new
    applications on a similar file system without worrying about underlying infrastructure
    and tools and process changes.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: These are some of the examples we have discussed here where high-performance
    compute applications can benefit from various AWS data storage options. At the
    time of designing the architecture, it is very important that we pick the right
    selection of storage options to make our application give the best performance
    while also making sure that we do not incur unneeded costs.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed the different data storage options available
    on AWS, along with their main features and capabilities. We have introduced Amazon
    S3 – a highly scalable and reliable object storage service, Amazon EFS – a shared
    file system for EC2 instances, Amazon EBS – block storage for EC2 instances, and
    the Amazon FSx family of file systems. We have also talked about the data protection
    and governance capabilities of these services and how they integrate with various
    other data protection, access management, encryption, logging, and monitoring
    services. We have also explored the various tiers of storage available for Amazon
    S3 and Amazon EFS and how we can use these tiers to optimize cost for our use
    cases. Finally, we have discussed a few examples of when to use which data storage
    service for high-performance compute applications.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good understanding of various AWS data storage services,
    we are ready to move on to the next part of the book, [*Chapter 5*](B18493_05.xhtml#_idTextAnchor095)*,
    Data Analysis*, which begins with how to carry out data analysis using AWS services.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For further reading on the material we learned in this chapter, please refer
    to the following articles:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '*Amazon S3* *Features*: [https://aws.amazon.com/s3/features/](https://aws.amazon.com/s3/features/)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Amazon Regions and Availability* *Zones*: [https://aws.amazon.com/about-aws/global-infrastructure/regions_az/](https://aws.amazon.com/about-aws/global-infrastructure/regions_az/)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*AWS Snow* *Family*: [https://aws.amazon.com/snow/](https://aws.amazon.com/snow/)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting started with Amazon* *S3*: [https://docs.aws.amazon.com/AmazonS3/latest/userguide/GetStartedWithS3.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/GetStartedWithS3.html)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Prerequisite: Setting up Amazon* *S3*: [https://docs.aws.amazon.com/AmazonS3/latest/userguide/setting-up-s3.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/setting-up-s3.html)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*AWS EFS Deep Dive: What is it and when to use* *it*: [https://www.learnaws.org/2021/01/23/aws-efs-deep-dive/](https://www.learnaws.org/2021/01/23/aws-efs-deep-dive/)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Achieve highly available and durable database backup workflows with Amazon*
    *EFS*: [https://aws.amazon.com/blogs/storage/using-amazon-efs-to-cost-optimize-highly-available-durable-database-backup-workflows/](https://aws.amazon.com/blogs/storage/using-amazon-efs-to-cost-optimize-highly-available-durable-database-backup-workflows/)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Amazon EFS* *features*: [https://aws.amazon.com/efs/features/](https://aws.amazon.com/efs/features/)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*AWS* *Backup*: [https://aws.amazon.com/backup/](https://aws.amazon.com/backup/)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Amazon EBS* *features*: [https://aws.amazon.com/ebs/features/](https://aws.amazon.com/ebs/features/)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Amazon FSx* *Documentation*: [https://docs.aws.amazon.com/fsx/index.html](https://docs.aws.amazon.com/fsx/index.html)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Amazon S3 Glacier storage* *classes*: [https://aws.amazon.com/s3/storage-classes/glacier/](https://aws.amazon.com/s3/storage-classes/glacier/)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 2: Applied Modeling'
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Part 2* focuses on the application of **high-performance computing** (**HPC**)
    for machine learning. It includes a hands-on implementation of an end-to-end solution
    starting with analyzing large amounts of data and then covering distributed training
    and deploying models at scale, including performance optimization and machine
    learning at the edge.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'This part comprises the following chapters:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18493_05.xhtml#_idTextAnchor095), *Data Analysis*'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18493_06.xhtml#_idTextAnchor116), *Distributed Training of Machine
    Learning Models*'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18493_07.xhtml#_idTextAnchor128), *Deploying Machine Learning
    Models at Scale*'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18493_08.xhtml#_idTextAnchor161), *Optimizing and Managing Machine
    Learning Models for Edge Deployment*'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18493_09.xhtml#_idTextAnchor175), *Performance Optimization
    for Real-Time Inference*'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B18493_10.xhtml#_idTextAnchor186), *Data Visualization*'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
