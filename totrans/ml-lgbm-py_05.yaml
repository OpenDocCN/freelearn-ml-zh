- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LightGBM Parameter Optimization with Optuna
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previous chapters have discussed the LightGBM hyperparameters and their effect
    on building models. A fundamental problem when building a new model is finding
    the optimal hyperparameters to achieve the best performance.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter focuses on the parameter optimization process using a framework
    called Optuna. Different optimization algorithms are discussed alongside the pruning
    of the hyperparameter space. A practical example shows how to apply Optuna to
    find optimal parameters for LightGBM. Advanced use cases for Optuna are also shown.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter’s main topics are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Optuna and optimization algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing LightGBM with Optuna
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chapter includes examples and code excerpts illustrating how to perform
    parameter optimization studies for LightGBM using Optuna. Complete examples and
    instructions for setting up a suitable environment for this chapter are available
    at [https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-5](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-5).
  prefs: []
  type: TYPE_NORMAL
- en: Optuna and optimization algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Examples from previous chapters have shown that choosing the best hyperparameters
    for a problem is critical in solving a machine learning problem. The hyperparameters
    significantly impact the algorithm’s performance and generalization capability.
    The optimal parameters are also specific to the model used and the learning problem
    being solved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other issues complicating hyperparameter optimization are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cost**: For each unique set of hyperparameters (of which there can be many),
    an entire training run, often with cross-validation, must be performed. This is
    highly time-consuming and computationally expensive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High-dimensional search spaces**: Each parameter can have a vast range of
    potential values, making testing each value impossible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parameter interaction**: Optimizing each parameter in isolation is often
    impossible, as some parameters’ values interact with others’ values. A good example
    is the learning rate and the number of estimators in LightGBM: fewer estimators
    necessitate a larger learning rate, and vice versa. This phenomenon is shown in
    *Figure 5**.1*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.1 – A parallel coordinate plot showing a parameter interaction between
    the learning rate and the number of estimators: having more estimators requires
    a lower learning rate, and vice versa](img/B16690_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1 – A parallel coordinate plot showing a parameter interaction between
    the learning rate and the number of estimators: having more estimators requires
    a lower learning rate, and vice versa'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5**.1* visualizes parameter interactions using a technique called a
    **parallel coordinate plot**. Parallel coordinate plots are a visualization tool
    designed to represent high-dimensional data, making them especially useful for
    visualizing the results of hyperparameter optimization. Each dimension (in this
    context, a hyperparameter) is portrayed as a vertical axis arranged in parallel.
    The range of each axis mirrors the range of values that the hyperparameter can
    assume. Every individual configuration of hyperparameters is depicted as a line
    crossing all these axes, with the intersection point on each axis indicating the
    value of that hyperparameter for the given configuration. Lines can also be color-coded
    based on performance metrics, such as validation accuracy, to discern which hyperparameter
    combinations yield superior outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: The beauty of parallel coordinate plots lies in their ability to illustrate
    relationships between multiple hyperparameters and their cumulative impact on
    performance, such as the parameter interaction shown in *Figure 5**.1*. Observing
    the lines’ clustering or similarities in their color allows us to glean trends
    and intricate interdependencies between hyperparameters. This ability to visualize
    multidimensional patterns helps data scientists pinpoint which hyperparameter
    values or combinations are most conducive to optimal model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Given the challenges and complications of hyperparameter optimization, a naive
    approach to finding the optimal parameters is manual optimization. With manual
    optimization, a human practitioner selects parameters based on intuitive understanding
    and experience. A model is trained with these parameters, and the process is repeated
    until satisfactory parameters are found. Manual optimization is simple to implement
    but is very time-consuming due to the human-in-the-loop nature of the process.
    Human intuition is also fallible, and good parameter combinations can easily be
    missed.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The process of finding optimal parameters is often called a parameter **study**.
    Each configuration (combination of parameters) tested in the study is referred
    to as a **trial**.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapters’ examples, the approach we used thus far was **grid
    search**. With grid search, we set up a parameter grid consisting of each parameter
    and a range of potential values and exhaustively tested each possible combination
    to find the optimal values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Grid search solves the parameter interaction problem well: since each possible
    combination is tested, each interaction is accounted for.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the downside of using grid search is the cost. Since we exhaustively
    test each parameter combination, the number of trials quickly becomes prohibitive,
    especially if more parameters are added. For example, consider the following grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: An optimization study for this grid would require 36 trials. Adding just one
    additional parameter with two possible values doubles the cost of the study.
  prefs: []
  type: TYPE_NORMAL
- en: What’s needed is an algorithm and framework that can intelligently optimize
    the parameters within a limited number of trials that we control. Several frameworks
    exist for this purpose, including SHERPA, a Python library for tuning machine
    learning models; Hyperopt, another Python library for parameter optimization over
    complex search spaces; and Talos, a tool specifically tailored for Keras. However,
    in the next section, and for the rest of the chapter, we look at **Optuna**, a
    framework designed to automate tuning machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Optuna
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Optuna is an open source **hyperparameter optimization** (**HPO**) framework
    designed to automate finding the best hyperparameters for machine learning models
    ([https://optuna.org/](https://optuna.org/)). It is written in Python and can
    be easily integrated with various machine learning libraries, including LightGBM.
  prefs: []
  type: TYPE_NORMAL
- en: Optuna provides efficient optimization algorithms to search hyperparameter spaces
    more effectively. In addition to the optimization algorithms, Optuna also provides
    pruning strategies to save computational resources and time by pruning poorly
    performing trials.
  prefs: []
  type: TYPE_NORMAL
- en: Besides optimization and pruning algorithms, Optuna also provides an easy-to-use
    API for defining parameter types (integer, float, or categorical), creating and
    automating resumable optimization studies, and visualizing the results of optimization
    runs. Later in the chapter, we see how to use the API practically.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Optuna provides several efficient optimization algorithms. In this section,
    we focus on two of the available algorithms: a **Tree-Structured Parzen Estimator**
    (**TPE**) and a **Covariance Matrix Adaptation Evolution Strategy** (**CMA-ES**)
    algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: TPE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To understand TPE, we must first know what a Parzen estimator is.
  prefs: []
  type: TYPE_NORMAL
- en: A Parzen estimator, or **Kernel Density Estimator** (**KDE**), is a technique
    used to estimate the probability distribution of a set of data points. It’s a
    non-parametric method, meaning it doesn’t assume any specific underlying distribution
    for the data. Instead, it tries to “learn” the distribution based on the observed
    data points.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have data points and want to know how the data is distributed. One
    way to do this is by placing small “hills” (kernel functions) over each data point.
    These “hills” can have different shapes, such as Gaussian (bell-shaped) or uniform
    (box-shaped). The height of the “hill” at any point represents the likelihood
    that a new data point would fall at that location. The Parzen estimator works
    by adding up all these “hills” to create a smooth landscape representing the estimated
    probability distribution of the data.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of TPE, the data points we care about are the parameter combinations,
    and the probability distribution is the likelihood of a set of parameters being
    `good` or `bad` [1], [2].
  prefs: []
  type: TYPE_NORMAL
- en: 'TPE starts by sampling a few random combinations of hyperparameters and evaluating
    the model’s performance for each. Based on these initial results, TPE divides
    the hyperparameter combinations into two groups: `good` (those that lead to better
    performance) and `bad` (those that lead to worse performance):'
  prefs: []
  type: TYPE_NORMAL
- en: 'l(x): The probability density function of `good` configurations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'g(x) : The probability density function of `bad` configurations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TPE then estimates the probability distributions of hyperparameter combinations
    for both `good` and `bad` groups using the Parzen estimator technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'With estimations of the probability distributions available, TPE calculates
    the **Expected Improvement** (**EI**) of hyperparameter configurations. EI can
    be calculated as the ratio between the two densities:  l(x) _ g(x) .     With each trail, the algorithm samples new hyperparameter configurations that
    maximize the EI.'
  prefs: []
  type: TYPE_NORMAL
- en: The tree structure in TPE comes from the algorithm’s ability to handle parameter
    interaction within the hyperparameter search space, where specific hyperparameters’
    relevance depends on others’ values. To handle this, TPE builds a hierarchical
    structure that captures the relationships between different hyperparameters and
    adapts the sampling process accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, TPE estimates the distributions of `good` and `bad` parameters and
    uses them to find optimal parameters by maximizing new trials’ expected improvement.
    TPE is cost-effective since it approximates the distributions and can search for
    better parameters optimally (in a non-exhaustive way). TPE also handles parameter
    interactions.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative algorithm provided by Optuna is the CMA-ES algorithm, which we
    discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: CMA-ES
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CMA-ES is another optimization algorithm that can be used to find optimal hyperparameters
    [3]. Compared to TPE, CMA-ES is well suited to cases that involve continuous variables
    and when the search space is non-linear and non-convex.
  prefs: []
  type: TYPE_NORMAL
- en: CMA-ES is an example of an **evolutionary algorithm** (**EA**). An EA is a type
    of optimization algorithm inspired by the process of natural evolution. It aims
    to find the best solution to a problem by mimicking how nature evolves species
    through selection, reproduction, mutation, and inheritance. Evolutionary algorithms
    start with a population of candidate solutions and modify the candidates with
    each subsequent *generation* to adapt more closely to the best solution. This
    generational process is illustrated in *Figure 5**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – A two-dimensional illustration of candidate solutions (red x
    marks) evolving with each subsequent generation to approximate the global optimum
    (located at the top and center of each landscape). In the context of CMA-ES, each
    candidate solution represents a combination of hyperparameter values, and the
    algorithm’s performance determines the optimum](img/B16690_05_02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – A two-dimensional illustration of candidate solutions (red x marks)
    evolving with each subsequent generation to approximate the global optimum (located
    at the top and center of each landscape). In the context of CMA-ES, each candidate
    solution represents a combination of hyperparameter values, and the algorithm’s
    performance determines the optimum
  prefs: []
  type: TYPE_NORMAL
- en: Central to the evolutionary process of CMA-ES is the covariance matrix. A covariance
    matrix is a square, symmetric matrix representing the covariance between pairs
    of variables (in the case of CMA-ES, the hyperparameters), providing insight into
    their relationships. The diagonal elements of the matrix represent the variances
    of individual variables, while the off-diagonal elements represent the covariances
    between pairs of variables. When there’s a positive covariance, it signals that
    the variables usually move in the same direction, either increasing or decreasing.
    Conversely, a negative covariance points to a relationship where, as one variable
    rises, the other tends to fall, and vice versa. A covariance of zero suggests
    no linear relationship between the variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'CMA-ES applies the evolutionary principles as follows when optimizing hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Within the hyperparameter search space, initialize the mean and the covariance
    matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Repeat the evolutionary process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a population of candidates from the search space using the mean and
    the covariance matrix. Each candidate represents a combination of hyperparameter
    values.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the fitness of the candidates. **Fitness** refers to the quality of
    a candidate or how well it solves the optimization problem. With CMA-ES, this
    means training the model on the dataset using the candidate hyperparameters and
    evaluating the performance on the validation set.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the best candidates from the population.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the mean and the covariance matrix from the best candidates.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat for a maximum number of trials or until no improvement is seen in the
    population’s fitness.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CMA-ES performs well in complex search spaces and intelligently samples the
    search space, guided by the covariance matrix. It is beneficial when the hyperparameter
    search space is complex and non-linear or when the evaluation of the validation
    data is noisy (for instance, when a metric is an inconsistent performance indicator).
  prefs: []
  type: TYPE_NORMAL
- en: 'Both TPE and CMA-ES address the issues associated with hyperparameter optimization:
    both algorithms effectively search a high-dimensional search space. Both algorithms
    capture parameter interaction. Both algorithms give us control of the cost: we
    can decide our optimization budget and limit our search to that.'
  prefs: []
  type: TYPE_NORMAL
- en: The main differences between TPE and CMA-ES lie in their overall approach. TPE
    is a probabilistic model with a sequential search strategy, compared to CMA-ES,
    which is population-based and evaluates solutions in parallel. This often means
    TPE is more exploitative in its search, while CMA-ES balances exploration and
    exploitation using population control mechanisms. However, TPE is typically more
    efficient than CMA-ES, especially for a small number of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Optuna provides further optimization to the search process in pruning ineffective
    trials. We’ll discuss some pruning strategies next.
  prefs: []
  type: TYPE_NORMAL
- en: Pruning strategies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Pruning strategies refer to methods that avoid spending optimization time on
    unpromising trials by pruning these trials from the study. Pruning occurs synchronously
    with the model training process: the validation error is checked during training,
    and the training is stopped if the algorithm is underperforming. In this way,
    pruning is similar to *early stopping*.'
  prefs: []
  type: TYPE_NORMAL
- en: Median pruning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Optuna provides several pruning strategies, one of the simplest being **median
    pruning**. With median pruning, each trial reports an intermediate result after
    *n* steps. The median of the intermediate results is then taken, and any trials
    below the median of previous trials at the same step are stopped.
  prefs: []
  type: TYPE_NORMAL
- en: Successive halving and Hyperband
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A more sophisticated strategy is called **successive halving** [4]. This takes
    a more global approach and assigns a small, equal budget of training steps to
    all trials. Successive halving then proceeds iteratively: at each iteration, the
    performance of each trial is evaluated, and the top half of the candidates are
    selected for the next round, with the bottom half pruned away. The training budget
    is doubled for the next iteration, and the process is repeated. This way, the
    optimization budget is spent on the most promising candidates. As a result, a
    small optimization budget is spent on eliminating the underperforming candidates,
    and more resources are spent on finding the best parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hyperband** is another pruning technique that extends successive halving
    by incorporating random search and a multi-bracket resource allocation strategy
    [5]. While successive halving efficiently narrows down a set of candidate configurations
    by iteratively pruning underperforming ones and allocating more resources to the
    remaining promising ones, it relies on a fixed initial set of configurations and
    a single resource allocation scheme.'
  prefs: []
  type: TYPE_NORMAL
- en: Hyperband instead uses a multi-bracket resource allocation strategy, which divides
    the total computational budget into several brackets, each representing a different
    level of resource allocation. Within each bracket, successive halving is applied
    to iteratively eliminate underperforming configurations and allocate more resources
    to the remaining promising ones. At the beginning of each bracket, a new set of
    hyperparameter configurations is sampled using random search, which allows Hyperband
    to explore the hyperparameter space more broadly and reduce the risk of missing
    good configurations. This concurrent process enables Hyperband to adaptively balance
    exploration and exploitation in the search process, ultimately leading to more
    efficient and effective hyperparameter tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Optuna has performed empirical studies of optimization algor[ithms and corresponding
    pruning strategies (https://github.com](https://github.com/optuna/optuna/wiki/Benchmarks-with-Kurobako)/optuna/optuna/wiki/Benchmarks-with-Kurobako).
    *Empirically, they found that Hyperband is the best TPE or CMA-ES* *optimization
    strategy*.
  prefs: []
  type: TYPE_NORMAL
- en: This section gave an overview of the theory and algorithms powering Optuna,
    focusing on TPE, CMA-ES, and advanced pruning strategies. In the next section,
    we’ll practically apply Optuna to a machine learning problem with LightGBM.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing LightGBM with Optuna
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ll walk through applying Optuna using a classification example. The problem
    we’ll be modeling is to predict customer churn (*Yes*/*No*) for a telecommunications
    provider. The dataset is available from [https://github.com/IBM/telco-customer-churn-on-icp4d/tree/master/data](https://github.com/IBM/telco-customer-churn-on-icp4d/tree/master/data).     The data describes each customer using data available to the provider – for example,
    gender, whether the customer is paying for internet service, has paperless billing,
    pays for tech support, and their monthly charges. The data consists of both numeric
    and categorical features. The data has already been cleaned and is balanced, allowing
    us to focus on the parameter optimization study.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by defining the objective of our parameter study. The `objective`
    function is called once for each trial. In this case, we want to train a LightGBM
    model on the data and calculate the F1 score. Optuna passes a `trial` object to
    the `objective` function, which we can use to set up the parameters for the specific
    trial. The following is an example code snippet that shows how to define an `objective`
    function with parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see how we use the methods provided by `trial` to set up the hyperparameters.
    For each parameter, a value is suggested by the optimization algorithm within
    the range specified. We can suggest categorical variables using `trial.suggest_categorical`
    (as can be seen for the `boosting` type), and `int` and `float` parameters using
    `suggest_int` and `suggest_float`, respectively. When suggesting floats or integers,
    a range and, optionally, a step size are specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Setting a step size means the optimization algorithm does not suggest any arbitrary
    value in the range but limits suggestions to the steps between the lower and upper
    bound (40, 60, 80, 100, …, 400).
  prefs: []
  type: TYPE_NORMAL
- en: We also have the option to log scale the range of possible values by passing
    `log=True` for numeric parameters. Log scaling the parameter range has the effect
    that more values are tested close to the range’s lower bound and (logarithmically)
    fewer values towards the upper bound. Log scaling is particularly well suited
    to the learning rate where we want to focus on smaller values and exponentially
    increase tested values until the upper bound.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply pruning when training LightGBM models, Optuna provides a purpose-built
    callback that integrates with the optimization process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We must specify an error metric when creating the callback, and, in our case,
    we specify `"binary"` for the binary error.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the hyperparameters set up, we can fit as we usually do, passing the parameters
    and the callback as we would normally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We train the model using five-fold cross-validation with the F1 macro score
    for scoring. Finally, the `objective` function returns the mean of the F1 scores
    as the trial evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are ready to start an optimization study with the defined `objective` function.
    We create a sampler, pruner, and the study itself and then call `optimize` with
    our `objective` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We use the TPE optimization algorithm as a sampler alongside Hyperband pruning.
    The minimum and maximum resources specified for the Hyperband pruner control the
    minimum and the maximum number of iterations (or estimators) trained per trial.
    When applying pruning, the reduction factor controls how many trials are promoted
    in each halving round.
  prefs: []
  type: TYPE_NORMAL
- en: The study is created by specifying the optimization direction (`maximize` or
    `minimize`). Here, we are optimizing the F1 score, so we want to maximize the
    value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then call `study.optimize` and set our optimization budget: `n_trials=100`.
    We also perform a memory optimization setting, `gc_after_trial=True`. Performing
    `n_jobs=-1` runs as many trials as there are CPU cores in parallel.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the optimization, we can get the best trial and parameters by
    calling the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding example shows how to apply Optuna to find LightGBM hyperparameters
    effectively. Next, we look at some advanced features of the Optuna framework.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Optuna features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When optimizing hyperparameters for large machine learning problems, the optimization
    process may run for days or weeks. In these cases, saving an optimization study
    and resuming it later is helpful to guard against data loss or migrating the study
    between different machines.
  prefs: []
  type: TYPE_NORMAL
- en: Saving and resuming an optimization study
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Optuna supports saving and resuming an optimization study in two ways: **in
    memory** and using a **remote** **database** (**RDB**).'
  prefs: []
  type: TYPE_NORMAL
- en: 'When a study is run in memory, the standard Python methods for serializing
    an object can be applied. For example, either `joblib` or `pickle` may be used.
    We use `joblib` to save a study:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To restore and resume the study, we deserialize the `study` object and continue
    with optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The alternative to running the study in memory is to use an RDB. When using
    an RDB, the study’s intermediate (trial) and final results are persisted in a
    SQL database backend. The RDB can be hosted on a separate machine. Any of the
    SQL databases supported by SQL Alchemy may be used (https://docs.sqlalchemy.org/en/20/core/engines.xhtml#database-urls).
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we use a SQLite database as an RDB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Optuna manages the connection to the RDB and the persistence of the results.
    After setting up the connection, optimization can proceed as usual.
  prefs: []
  type: TYPE_NORMAL
- en: 'Restoring the study from an RDB backend is straightforward; we specify the
    same `storage` and set `load_if_exists` to `True`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Understanding parameter effects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In many cases, it’s also valuable to better understand the effects of hyperparameters
    when solving a specific problem. For example, the `n_estimators` parameter directly
    affects the computational complexity of a model. If we know the parameter to be
    less important, we can choose smaller values to improve our model’s runtime performance.
    Optuna provides several visualizations to dive deeper into the results of a study
    and gain insight into hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'A straightforward visualization plots the *importance of each parameter*: how
    much each affected the training outcome. We can create an importance plot as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The importance plot for our study is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – A parameter importance plot showing the importance of each hyperparameter
    to the object values (F1 score)](img/B16690_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – A parameter importance plot showing the importance of each hyperparameter
    to the object values (F1 score)
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 5**.3*, we can see that the learning rate is by far the most critical
    parameter affecting the success of a trial. The number of leaves and estimators
    follows this. Using this information, we may decide to focus more heavily on finding
    an optimal learning rate in future studies.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a parallel coordinate plot as follows, specifying the parameters
    it should contain. The plot helps us visualize the interaction between hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the resulting plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – A parallel coordinate plot for our study. Each horizontal line
    is the configuration for a single trial. Darker lines indicate more successful
    trials (higher F1 scores)](img/B16690_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – A parallel coordinate plot for our study. Each horizontal line
    is the configuration for a single trial. Darker lines indicate more successful
    trials (higher F1 scores)
  prefs: []
  type: TYPE_NORMAL
- en: 'The parallel coordinate plot shows that the best trials all used DART as the
    boosting type and have a learning rate of just below 0.1 and more than 200 estimators.
    We can also visually see some parameter interactions: GBDT models correlate with
    slightly higher learning rates. Far fewer leaf nodes are required when there is
    a large number of estimators because having many estimators and large numbers
    of leaf nodes leads to overfitting.'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-objective optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the optimization studies shown previously, we focused on a single optimization
    objective: maximizing our F1 score. However, in some instances, we would like
    to optimize two potentially competing objectives. For example, say we want to
    create the smallest GBDTs possible (fewest leaves) while obtaining a good F1 score.
    Reducing the number of leaves can potentially negatively impact our performance,
    so a trade-off exists.'
  prefs: []
  type: TYPE_NORMAL
- en: Optuna supports solving this type of problem by using `objective` function and
    specify the optimization directions.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, consider the trade-off between the learning rate and performance.
    We want to train our model as fast as possible, which requires a high learning
    rate. However, we know the best performance is achieved using a small learning
    rate and many iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use Optuna to optimize this trade-off. We define a new `objective` function,
    fixing all other parameters to the optimal values found earlier. We return two
    evaluations: the learning and the cross-validated F1-score. We want to maximize
    both values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'When calling `optimize`, we then set the direction for the optimization of
    both evaluations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'When performing MOO, there isn’t always a single best result: a trade-off often
    exists between the objectives. Therefore, we want to visualize the study results
    to explore the trade-off and select parameter values that perform well with both
    objectives. This type of visualization is called a **Pareto front** and can be
    created as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – A scatter plot showing the Pareto front for a MOO study](img/B16690_05_05.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – A scatter plot showing the Pareto front for a MOO study
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in *Figure 5**.5*, the F1 score is poor if the learning rate is too
    low and picks up quickly as the learning rate gets to 0.01\. The F1 score peaks
    at 0.12 and slowly trails off as the learning rate increases. We now have the
    necessary information to decide on our trade-off: we can choose a higher learning
    rate for faster training, sacrificing the minimum amount of classification performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduced Optuna as a framework for HPO. We discussed the problems
    of finding optimal hyperparameters and how HPO algorithms may be used to find
    suitable parameters efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'We discussed two optimization algorithms available in Optuna: TPE and CMA-ES.
    Both algorithms allow a user to set a specific budget for optimization (the number
    of trials to perform) and proceed to find suitable parameters within the constraints.
    Further, we discussed the pruning of unpromising optimization trials to save additional
    resources and time. Median pruning and the more complex but effective pruning
    techniques of successive halving and Hyperband were discussed.'
  prefs: []
  type: TYPE_NORMAL
- en: We then proceeded to show how to perform HPO studies for LightGBM in a practical
    example. We also showed advanced features of Optuna that can be used to save and
    resume studies, understand the effects of parameters, and perform MOO.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter focuses on two case studies using LightGBM, where the data
    science process is discussed and applied in detail.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| *[**1]* | *J. Bergstra, R. Bardenet, Y. Bengio, and B. Kégl, “Algorithms
    for Hyper-Parameter Optimization,” in Advances in Neural Information Processing*
    *Systems, 2011.* |'
  prefs: []
  type: TYPE_TB
- en: '| *[**2]* | *J. Bergstra, D. Yamins, and D. Cox, “Making a Science of Model
    Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures,”
    in Proceedings of the 30th International Conference on Machine Learning,* *Atlanta,
    2013.* |'
  prefs: []
  type: TYPE_TB
- en: '| *[**3]* | *N. Hansen and A. Ostermeier, “Adapting arbitrary normal mutation
    distributions in evolution strategies: the covariance matrix adaptation,” in Proceedings
    of IEEE International Conference on Evolutionary* *Computation, 1996.* |'
  prefs: []
  type: TYPE_TB
- en: '| *[**4]* | *K. Jamieson and A. Talwalkar, Non-stochastic Best Arm Identification
    and Hyperparameter* *Optimization, 2015.* |'
  prefs: []
  type: TYPE_TB
- en: '| *[**5]* | *L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar,
    Hyperband: A Novel Bandit-Based Approach to Hyperparameter* *Optimization, 2018.*
    |'
  prefs: []
  type: TYPE_TB
