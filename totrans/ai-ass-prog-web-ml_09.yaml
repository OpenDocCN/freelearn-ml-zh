- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Augment Web Apps with AI Services
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过人工智能服务增强Web应用
- en: Introduction
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: 'There are several ways that a web app can be augmented with AI services: you
    could leverage an existing Web API exposing a model, or build it yourself and
    have it call a model.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 网络应用可以通过多种方式增强人工智能服务：你可以利用现有的暴露模型的Web API，或者自己构建并使其调用模型。
- en: The reason you would want to add AI to your app in the first place is to make
    it smarter. Not smarter for its own sake, but to make it more useful to the user.
    For example, if you have a web app that allows users to search for products, you
    could add a feature that suggests products based on the user’s previous purchases.
    In fact, why limit yourself to previous purchases? Why not suggest products based
    on the user’s previous searches? Or, what if the user could take a picture of
    a product and the app would suggest similar products?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你最初想要将人工智能添加到你的应用中的原因是为了让它变得更智能。不是为了它自己的目的而变得聪明，而是为了让它对用户更有用。例如，如果你有一个允许用户搜索产品的网络应用，你可以添加一个基于用户先前购买的产品推荐功能。实际上，为什么只限于先前购买的产品呢？为什么不能根据用户的先前搜索推荐产品？或者，如果用户可以拍照产品，应用会推荐类似的产品呢？
- en: As you can see, there are a lot of possibilities for augmenting your web app
    with AI that would improve the user experience.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，有很多可能性可以增强你的网络应用，使其通过人工智能提升用户体验。
- en: 'In this chapter, we will:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将：
- en: Discuss different model formats like Pickle and ONNX
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论不同的模型格式，如Pickle和ONNX
- en: Learn how to use both Pickle and ONNX to persist your model as a file using
    Python
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何使用Python中的Pickle和ONNX将你的模型持久化为文件
- en: Consume a model stored in ONNX format and expose it via a REST API using JavaScript
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费存储在ONNX格式的模型并通过JavaScript REST API公开
- en: Business domain, e-commerce
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业领域，电子商务
- en: 'We keep working on our e-commerce domain, but our business focus is on ratings.
    A good or bad rating can influence how many units are sold of a specific product.
    The logical domain consists of the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在努力工作在我们的电子商务领域，但我们的业务重点是评分。好的或坏的评分可以影响特定产品的销量。逻辑领域包括以下内容：
- en: '**Products**: the products to be rated'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品**：要评分的产品'
- en: '**Ratings**: the actual ratings and meta information like comments, dates and
    more'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评分**：实际的评分和元信息，如评论、日期等'
- en: Problem and data domain
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题和数据领域
- en: The problem to figure out is how we use this rating data and learn from it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 需要解决的问题是如何使用这些评分数据并从中学习。
- en: '**Insights**: We could, for example, get the insights that we should start/stop
    selling a certain product. There might be other insights as certain products sell
    well in certain parts of the world.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**洞察**：例如，我们可以得到这样的洞察，我们应该开始/停止销售某种产品。可能还有其他洞察，因为某些产品在世界某些地区销售得很好。'
- en: '**Technical** **problem**: The technical aspect of this is figuring out how
    to ingest the data, train a model from it, and then figure out how a web application
    can leverage said model.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术** **问题**：这一方面的技术问题是弄清楚如何摄取数据，从数据中训练模型，然后弄清楚如何让网络应用利用该模型。'
- en: Feature breakdown
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征分解
- en: Looking at this from a feature standpoint, we need to see this as consisting
    of three major parts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从功能的角度来看，我们需要将其视为由三个主要部分组成。
- en: '**Data ingestion and training**: this needs a separate interface, maybe it’s
    done without a user interface and it’s just static data being fed into code capable
    of training a model from it. With that understanding, we can outline the steps
    like so:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取和训练**：这需要一个单独的界面，可能是在没有用户界面的情况下完成的，只是静态数据被输入到能够从数据中训练模型的代码中。有了这个理解，我们可以概述以下步骤：'
- en: Load data
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据
- en: Clean data
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洗数据
- en: Create features
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建功能
- en: Train model
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型
- en: Evaluate model
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型
- en: Run predictions
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行预测
- en: '**Consuming the model**: Once the model is trained, it needs to be exposed,
    preferably through a web endpoint. To get there, we think we need these set of
    steps:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费模型**：一旦模型训练完成，它需要被公开，最好是通过Web端点。为了达到这一点，我们认为我们需要以下步骤：'
- en: Convert the model to suitable format if needed
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如有必要，将模型转换为合适的格式
- en: Build a Web API
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建Web API
- en: Expose model through Web API
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Web API公开模型
- en: Deploy model, there’s a step here where we need to bring the API online
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署模型，这里有一个步骤需要将API上线
- en: '**Prediction**: For the prediction part, this is a functionality that’s meant
    for “back office” and not customer facing.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**：对于预测部分，这是一个面向“后台”而非面向客户的功能。'
- en: Build user interface to run predictions
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建用户界面以运行预测
- en: Build underlying code that talks to the Web API to make predictions possible
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建与Web API通信的底层代码以实现预测
- en: Prompt strategy
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You could go with either prompt approach here, either get suggestions from a
    prompt comment or use the chat interface.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: For prompt pattern, we’ll use the “Exploratory pattern” as described in *Chapter
    2*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Creating a model
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine we are dealing with the following data in the `sales_rating.csv` file
    that is the result of merging two datasets, one containing sales data and the
    other containing rating data. The data looks like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding data shows a dataset with `product_id`, `avg_rating`, and `sold`
    columns. Our theory is that the average rating of a product is correlated with
    the number of sales. It seems like a fair assumption that a product with a high
    rating will sell more than a product with a low rating. By creating a model, we
    can come closer to determining whether it’s likely that our assumption is true
    or not.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Coming up with a plan
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can ask Copilot about the steps we need to take to create a model. We type
    these prompts as comments:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to ask Copilot to come up with text answers about something else
    other than code, you can type the text as a comment in a code file or inside of
    a Markdown file. It also helps to place yourself on the next row after the comment
    and start the row with “a:” for answer. You can also ask questions using Copilot
    Chat:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Tell me the answer of life, the universe and everything.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**[End of response]**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: The above reference is from the book *Hitchhikers guide to the Galaxy* by Douglas
    Adams.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s ask Copilot to help us with the steps to create a model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: What are the steps to create a model in Python given a CSV file?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Output:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: import pandas and scikit-learn
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: read the CSV file
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: create a test and training dataset
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: create a model
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how good is the model?
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: predict
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: save the model to pkl
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OK, we have a plan, so let’s execute it and use Copilot to help us with the
    code.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s start by creating a new notebook in VS Code. Let’s call it `sales.ipynb`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '`.ipynb` is the file format for Jupyter Notebook that you as a data science
    practitioner are most likely familiar with. The idea is that you work on a file
    with cells, where some cells are text cells and others are code cells you can
    run.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: To use certain libraries, we need to install them. We can use Copilot to help
    us with that. We can leverage the fact that we are data science practitioners
    and therefore have an understanding of what libraries we need. Therefore, we will
    suggest the pandas and scikit-learn libraries below to help us with our task.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Install pandas and scikit-learn in a notebook.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**[End of response]**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s import the libraries we need.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Import pandas and scikit-learn in a notebook.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**[End of response]**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Reading the CSV file
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have the libraries we need, let’s read the CSV file.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Read a CSV file in a notebook.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中读取CSV文件。
- en: '**[End of prompt]**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: '**[Prompt response]**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**[End of response]**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: The CSV file is now loaded into a pandas DataFrame, a structure holding columns
    and rows. Let’s take a look at the first few rows.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件现在已加载到pandas DataFrame中，这是一个包含列和行的结构。让我们看看前几行。
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This will produce the following output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Great, we have the data loaded into a DataFrame. Next, we need to split the
    data into test and training datasets.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，我们已经将数据加载到DataFrame中。接下来，我们需要将数据分为测试集和训练集。
- en: Creating test and training datasets
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建测试集和训练集
- en: In machine learning, we typically split the data into test and training datasets.
    The training dataset is used to train the model and the test dataset is used to
    test the model. We can use Copilot to help us with this.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，我们通常将数据分为测试集和训练集。训练集用于训练模型，测试集用于测试模型。我们可以使用Copilot来帮助我们完成这项工作。
- en: '**[Prompt]**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示]**'
- en: Create test and training dataset in a notebook, suggested test size of 0.2.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中创建测试集和训练集，建议测试集大小为0.2。
- en: '**[End of prompt]**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: '**[Prompt response]**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**[End of response]**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: 0.2 is a good test size. It means that 20% of the data will be used for testing
    and 80% will be used for training.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 0.2是一个好的测试集大小。这意味着20%的数据将用于测试，80%的数据将用于训练。
- en: You may need to start typing “test_size” and “training” on the respective rows,
    then press *TAB* to accept the suggestion.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要在相应的行中开始键入“test_size”和“training”，然后按*TAB*键接受建议。
- en: Now we have things set up, let’s create a model next.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置好了，接下来让我们创建一个模型。
- en: Creating a model
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建模型
- en: 'Creating a model involves selecting the algorithm we want to use and then training
    the model. Let’s suggest a prompt:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 创建模型涉及选择我们想要使用的算法，然后训练模型。让我们提出一个提示：
- en: '**[Prompt]**'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示]**'
- en: Create a model in a notebook using the `LinearRegression` algorithm.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中使用`LinearRegression`算法创建一个模型。
- en: '**[End of prompt]**'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: '**[Prompt response]**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: '[PRE8]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**[End of response]**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: In the preceding code, we created a model using the `LinearRegression` algorithm
    and then trained the model using the training dataset with the `fit` method. Also,
    note how we are using the `avg_rating` column as the input and the `sold` column
    as the output. This is because we want to predict the number of sales based on
    the average rating.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用`LinearRegression`算法创建了一个模型，然后使用`fit`方法使用训练集训练了模型。同时，请注意我们是如何使用`avg_rating`列作为输入，`sold`列作为输出的。这是因为我们想要根据平均评分预测销售数量。
- en: How good is the model?
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型有多好？
- en: At this point, we want to find out how good the model is. To find this out,
    let’s ask Copilot to help us.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们想知道模型有多好。为了找出这一点，让我们请Copilot来帮助我们。
- en: You can either use a comment style and get suggestions inline, or use Copilot
    Chat. In both cases, Copilot will understand from the context.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用注释风格并获取内联建议，或者使用Copilot Chat。在两种情况下，Copilot都会根据上下文理解。
- en: '**[Prompt]**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示]**'
- en: How good is the model in a notebook? Show the code.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中，模型表现如何？显示代码。
- en: '**[End of prompt]**'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: '**[Prompt response]**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**[End of response]**'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: 'It seems that calling `score` on the model and passing in the `test` dataset
    is how we find out how good a model is. We can even ask Copilot about this:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型上的`score`并传入`test`数据集似乎是我们了解模型有多好的方法。我们甚至可以询问Copilot关于这一点：
- en: '**[Prompt]**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示]**'
- en: What does score do?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 分数是什么意思？
- en: '**[End of prompt]**'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: '**[Prompt response]**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**[End of response]**'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: 'If you want, you keep querying and have things explained in more detail, like
    with the below prompt:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您愿意，您可以继续查询并更详细地解释，如下面的提示：
- en: '**[Prompt]**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示]**'
- en: What does that mean in simpler terms?
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这在简单术语中意味着什么？
- en: '**[End of prompt]**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: '**[Prompt response]**'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: '[PRE11]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**[End of response]**'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: Predict
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: 'We won’t know how good the model is until we try to predict something, even
    if we could refer to the score value. Let’s craft a prompt for this task:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试预测某些东西之前，我们不会知道模型有多好，即使我们可以参考分数值。让我们为这个任务编写一个提示：
- en: '**[Prompt]**'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示]**'
- en: Predict in a notebook. Show the code.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中预测。显示代码。
- en: '**[End of prompt]**'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: '**[Prompt response]**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**[End of response]**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: OK, we got a variable called `predictions` that contains the predictions, but
    it is hard to understand if the predictions are reasonable. Let’s try asking Copilot
    and see what it suggests.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: How do you suggest we show the predictions in a notebook?
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**[End of response]**'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Any other ways you suggest we show the predictions in a notebook except for
    printing?
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**[End of response]**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve gotten more information on our various options, let’s use that
    knowledge in a prompt:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Show me how to print and plot predictions vs the actual data in a notebook.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**[End of response]**'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this code in a notebook will produce the following plot:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![plot](img/B21232_09_01.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: Plot showing predictions vs actual data'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'In the plot, it looks like the line is a good fit for the data. We can also
    print predictions to see the actual values:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Saving the model to a .pkl file
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have one step left: we need to save the model to a file. We have a few different
    choices for how to save the model. We can save it as a pickle file or an ONNX
    file, for example. Let’s start with saving it as a pickle file.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, let’s craft a prompt for this task:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Save the model to a pkl in the notebook.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**[End of response]**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: For the completion of the above, you may need to start typing “import” to get
    the suggestion. Additionally, it’s a good bet it’s going to use the pickle library,
    so on the next line you can start typing “pickle” and press *TAB* to accept the
    suggestion.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Creating a REST API in Python
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, we have a `model.pkl` file that contains our model. We can expose
    the model using this file via a REST API. Let’s ask Copilot to help us with this.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Create a REST API in Python that exposes the model in a pkl file.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**[End of response]**'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Note how we use several prompts above. First, we set the context by adding the
    prompt “Create a REST API in Python that exposes the model in a pkl file” at the
    top of the file. Then we use various helper prompts like “load the model”, “app”,
    and “routes” to help us with the code. We end up with an API that exposes the
    model via a REST API.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Converting the model to ONNX
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you’ve seen how we can use Pickle to save a model and then load it in
    Python. However, Pickle has drawbacks, including being Python-specific. ONNX,
    on the other hand, is a format that is not Python-specific and can be used in
    other languages. Let’s see how we can use the ONNX format to work with our model.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to solve our task in two steps:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Convert the model to ONNX format.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load the model and create a REST API in JavaScript.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a model in ONNX format
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because we’re using a notebook, we need to install the dependencies, import
    the libraries we need, and then convert the model to ONNX format.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: What dependencies do I need for ONNX? Show me the Python code for installing
    those dependencies.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**[End of response]**'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Show me how to import the libraries I need for ONNX and show me how to convert
    the model to ONNX format.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**[End of response]**'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Now I should have a `model.onnx` file that contains the model in ONNX format.
    Let’s see if we can load it in JavaScript next.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Loading the ONNX model in JavaScript
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we need to load the ONNX model in JavaScript and specifically Node.js,
    as we’re doing this on the backend. We can use the `onnxruntime` library to do
    this. Let’s ask Copilot to help us with this.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Show me a step-by-step guide to load the ONNX model in JavaScript.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: install onnxruntime in JavaScript
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: load the ONNX model in JavaScript
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: predict using ONNX model in JavaScript
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[End of response]**'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a plan, let’s execute it.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Installing onnxruntime in JavaScript
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because we’re building a Node.js project, let’s first, in a new folder, create
    an `app.js` file and run the `npm init -y` terminal command to create a new Node.js
    project.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: The first step in our plan is to install `onnxruntime` in JavaScript. We can
    use npm to perform this task.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Install onnxruntime in JavaScript.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**[End of response]**'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Great, this installs the `onnxruntime` library in our project. Next, we need
    to load the ONNX model.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Loading the ONNX model in JavaScript
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have `onnxruntime` installed, we can load the ONNX model.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Load the ONNX model in JavaScript.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '**[End of response]**'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding code, we load the model from the ONNX file and then we make
    predictions using the model with the input `4.5` to represent the average rating
    to see what sales we can expect.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Assignment: Build a REST API in JavaScript that consumes the model'
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Take the model we created in the previous section and add the code to the notebook
    to turn it into an ONNX file.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new folder in the repo called and create a new file called `app.js`
    in that folder.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the POST /predict route to the `server.js` file and ensure it returns a
    prediction given the input.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s some starter prompts you can try to help you with this assignment:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: Create a REST API in JavaScript using Express'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prompt**: Create a POST /predict route in a REST API in JavaScript using
    Express'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prompt**: Load the model from ONNX in a REST API in JavaScript using Express'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prompt**: Predict using the ONNX model in a REST API in JavaScript using
    Express'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solution
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: See repo [[https://github.com/PacktPublishing/AI-Assisted-Software-Development-with-GitHub-Copilot-and-ChatGPT/tree/main/09](https://github.com/PacktPublishing/AI-Assisted-Software-Development-with-GitHub-Copilot-and-ChatGPT/tree/main/09)]
    and the *09* folder for the solution.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅代码库 [[https://github.com/PacktPublishing/AI-Assisted-Software-Development-with-GitHub-Copilot-and-ChatGPT/tree/main/09](https://github.com/PacktPublishing/AI-Assisted-Software-Development-with-GitHub-Copilot-and-ChatGPT/tree/main/09)]
    和 *09* 文件夹以获取解决方案。
- en: Quiz
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验
- en: What’s the difference between Pickle and ONNX?
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Pickle 和 ONNX 之间的区别是什么？
- en: Pickle is Python-specific and ONNX is not.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pickle 是 Python 特定的，而 ONNX 则不是。
- en: Pickle can be used in JavaScript and ONNX can’t.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pickle 可以在 JavaScript 中使用，而 ONNX 则不能。
- en: ONNX is less efficient than Pickle.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ONNX 的效率不如 Pickle。
- en: Summary
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered various model formats like Pickle and ONNX and how
    to persist your model as a file using Python. Storing a model as a file is useful
    because it allows you to integrate it with other applications.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了各种模型格式，如 Pickle 和 ONNX，以及如何使用 Python 将模型持久化为文件。将模型存储为文件很有用，因为它允许您将其与其他应用程序集成。
- en: Then we discussed the pros and cons of different formats for storing models
    like Pickle and ONNX. We came to the conclusion that ONNX is probably the better
    choice because it’s not Python-specific and can be used in other languages.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们讨论了存储模型的不同格式的优缺点，如 Pickle 和 ONNX。我们得出结论，ONNX 可能是更好的选择，因为它不是 Python 特定的，并且可以在其他语言中使用。
- en: Then we covered how to load a model stored in ONNX format using JavaScript and
    create a REST API to make the model available to other applications.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们介绍了如何使用 JavaScript 加载存储为 ONNX 格式的模型，并创建 REST API 使模型可供其他应用程序使用。
- en: In the next chapter, we’ll go into more detail of how we can use GitHub Copilot
    and get the most out of it. We’ll cover both tips and tricks and features that
    help make you faster and more productive.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更详细地介绍如何使用 GitHub Copilot 并充分利用它。我们将涵盖技巧和窍门以及有助于让您更快、更高效的功能。
- en: Join our community on Discord
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/aicode](https://packt.link/aicode)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/aicode](https://packt.link/aicode)'
- en: '![](img/QR_Code510410532445718281.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code510410532445718281.png)'
