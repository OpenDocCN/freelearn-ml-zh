<html><head></head><body>
		<div class="Content" id="_idContainer009">
			<p class="hidden">1</p>
		</div>
		<div class="Content" id="_idContainer010">
			<h1 id="_idParaDest-10"><a id="_idTextAnchor010"/>Introduction to Amazon Web Services</h1>
		</div>
		<div class="Content" id="_idContainer011">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will able to:</p>
			<ul>
				<li class="bullets">Describe the basics of working on AWS using Amazon S3</li>
				<li class="bullets">Import data from and export data to Amazon S3 using the AWS Management Console and Command-Line Interface (CLI)</li>
				<li class="bullets">Use the AWS Management Console</li>
				<li class="bullets">Identify Machine Learning services</li>
			</ul>
			<p>This chapter describes the working of S3 using AWS management console and recognize machine learning services.</p>
		</div>
		<div class="Content" id="_idContainer045">
			<h2 id="_idParaDest-11"><a id="_idTextAnchor011"/>Introduction</h2>
			<p>This chapter will introduce you to the <strong class="keyword">Amazon Web Service (AWS)</strong> interface, and will teach you how to store and retrieve data with <strong class="keyword">Amazon Simple Storage (S3)</strong>. </p>
			<p>Next, you will apply your S3 knowledge by importing and exporting text data via the management console and the <strong class="bold">Command-Line Interface (CLI)</strong>.</p>
			<p>Lastly, you will learn how to locate and test <strong class="bold">Artificial Intelligence (AI)</strong> and <br/><strong class="bold">Machine Learning (ML)</strong> services. </p>
			<h2 id="_idParaDest-12"><a id="_idTextAnchor012"/>What is AWS?</h2>
			<p>AWS is a secure cloud platform that delivers on-demand computing power, databaseÂ storage, applications, and other IT resources, through a cloud services platform via the internet with a pay-as-you-go pricing model. As of 2018, AWS dominates the cloud infrastructure services worldwide market with ~30% of the market share, compared to the trailing Microsoft (~15%) and Google (~5%), as per Canalys (<a href="">https://www.canalys.com/static/press_release/2018/270418-cloud-infrastructure-market-grows-47-q1-2018-despite-underuse.pdf</a>).</p>
			<h3 id="_idParaDest-13"><a id="_idTextAnchor013"/>What is Machine Learning?</h3>
			<p>Machine Learning<strong class="bold"> </strong>is a subset of Artificial Intelligence in the field of computer science that often uses statistical techniques to provide computers with the ability to learn with data without being programmed. Machine Learning explores the building and construction of algorithms that can learn from and make predictions about, data. The algorithms transcend static instructions and make data-driven predictions and decisions with a model from sample inputs. </p>
			<p>Machine Learning is essential to learn in today's world, since it is an integral part of all industries' competitive and operational data strategies. More specifically, ML allows insights from <strong class="bold">Natural Language Processing (NLP)</strong> to power chatbots; fraud detection ML insights are used in the financial industry, and ML applications allow for efficient online recommendation engines, such as friend suggestions on Facebook, Netflix displaying movies, you probably like, and more items to consider on Amazon. </p>
			<h3 id="_idParaDest-14"><a id="_idTextAnchor014"/>What is Artificial Intelligence?</h3>
			<p>Artificial Intelligence is intelligence that's demonstrated by machines; more specifically, any device that perceives its environment and takes actions that increases its chance of successfully achieving its goals. Contemporary examples are understanding human speech, competing at the highest levels of strategic games (such as Chess and Go), and autonomous cars. </p>
			<p>Artificial Intelligence is important because it adds intelligence to existing products. Products that are currently used will be further improved with AI capabilities, for example, Siri was added to the new generation of Apple products. Conversational chatbots can be combined with large amounts of data to improve technologies at home and in the office.</p>
			<p>Overall, this chapter will provide you with the foundational knowledge of AWS to build sophisticated AI and ML applications in your projects. This will help you with the tools to identify free-tier AWS services. Thus, you will be able to use them exclusively, or integrate them to analyze data, build a conversational chatbot, store and process an incredible amount of data, and bring your ideas to fruition.</p>
			<p>This chapter will introduce you to the AWS interface and help you learn how to store and retrieve data with <strong class="bold">Amazon Simple Storage Service (S3)</strong>. You will apply your S3 knowledge by importing and exporting text data via the AWS Management Console and the CLI. You will also learn how to locate and test AI and ML services.</p>
			<h2 id="_idParaDest-15"><a id="_idTextAnchor015"/>What is Amazon S3?</h2>
			<p><strong class="bold">S3</strong> is an online cloud object storage and retrieval service. Amazon S3 is a cloud object storage. Instead of data being associated with a server, S3 storage is server independent and can be accessed over the internet Data stored in S3 is managed as objects using an <strong class="bold">Application Programming Interface</strong> (<strong class="bold">API</strong>) that is accessible via the internet (HTTPS). </p>
			<p>The benefits of using S3 are as follows: </p>
			<ul>
				<li>Amazon S3 runs on the largest global cloud infrastructure, to deliver 99.99% durability.</li>
				<li>It provides the widest range of options to transfer data.</li>
				<li>It allows you to run Big Data analytics without moving data into a separate analytics system.</li>
				<li>It supports security standards and compliance certificates.</li>
				<li>It offers a flexible set of storage management and administration capabilities.<h4>Note</h4><p class="callout">For more information refer<em class="italics">: </em><a href="">https://aws.amazon.com/s3/</a>.</p></li>
			</ul>
			<h3 id="_idParaDest-16"><a id="_idTextAnchor016"/>Why use S3?</h3>
			<p>The<strong class="bold"> S3</strong> is a place to store and retrieve your files. It is recommended for storing static content such as text files, images, audio files, video files, and so on. For example, S3 can be used as a static web server if the website consists exclusively of HTML and images. The website can be connected to an FTP client to serve the static files. In addition, S3 can also be used to store user generated image and text files.</p>
			<p>However, the two most important applications of it are as follows:</p>
			<ul>
				<li>To store static data from web pages or mobile apps</li>
				<li>To implement Big Data analytics</li>
			</ul>
			<p>It can easily be used in conjunction with additional AWS Machine Learning and infrastructure services. For example, text documents imported to Amazon S3 can be summarized by code running in an AWS Lambda function that is analyzed using AWS Comprehend. We will cover both in <em class="italics">Chapter</em> <em class="italics">2,</em> <em class="italics">Summarizing Text Document using NLP</em> and <em class="italics">Chapter</em> <em class="italics">3,</em> <em class="italics">Perform Topic Modeling and Theme Extraction</em>.</p>
			<h3 id="_idParaDest-17"><a id="_idTextAnchor017"/>The Basics of Working on AWS with S3</h3>
			<p>The first step to accessing S3 is to create an AWS Free-tier account, which provides access to the AWS Management Console. The AWS Management Console is a web application that provides one method to access all of AWS's powerful storage and ML/AI services.</p>
			<p>The second step is to understand the access level. AWS defines <strong class="bold">Identity and Access Management (IAM)</strong>. The same email/password is used for accessing the IAM</p>
			<h3 id="_idParaDest-18"><a id="_idTextAnchor018"/>AWS Free-Tier Account</h3>
			<p>AWS provides a free-tier (<em class="italics">within their individual free usage stipulations</em>) account, and one of the included storage services is <em class="italics">Amazon Simple Storage</em> (<em class="italics">S3</em>). Thus, you can maximize cost savings and reduce errors before making a large investment by testing services to optimize your<strong class="bold"> </strong>ML and AI workflows. </p>
			<h3 id="_idParaDest-19"><a id="_idTextAnchor019"/>Importing and Exporting Data into S3</h3>
			<p>AWS Import and Export is a service that you can use to transfer large amounts of data from physical storage devices into AWS. You mail your portable storage devices to AWS, and AWS Import/Export transfers data directly from your storage devices using Amazon's high-speed internal network. Your data load typically begins the next business day after your storage device arrives at AWS. After the data export or import completes, services return your storage device. For large datasets, AWS data transfer can be significantly faster than internet transfer and more cost-effective than upgrading your connectivity.</p>
			<h3 id="_idParaDest-20"><a id="_idTextAnchor020"/>How S3 Differs from a Filesystem</h3>
			<p>S3 is used to store almost any type of file, thus, it can get confused with similarities to a traditional filesystem. However, S3 differs in a few ways from a traditional filesystem. Overall, the folders in a traditional file system are <strong class="bold">Buckets</strong> in S3; a file in a traditional filesystem is an <strong class="bold">object</strong> in S3. S3 uses objects, since you can store any data type (that is, more than files) in Buckets.</p>
			<p>Another difference is how objects can be accessed. Objects stored in Buckets can be accessed from a web service endpoint (such as a web browser, for example, Chrome, Firefox, and so on), so each object requires a globally unique name. The name restrictions for objects are similar to the restrictions in selecting a URL when creating a new website. Obviously, you need to select a unique URL, according to the same logic that your house has a unique address.</p>
			<p>For example, if you created a Bucket (with public permission settings) named <strong class="inline">myBucket</strong> and then uploaded a text file named <strong class="inline">pos_sentiment__leaves_of_grass.txt</strong> to the Bucket, the object would be accessible from a web browser via the corresponding subdomain.</p>
			<h2 id="_idParaDest-21"><a id="_idTextAnchor021"/>Core S3 Concepts</h2>
			<p>The S3 hierarchy includes the following concepts: </p>
			<p><strong class="keyword">Type of data storable</strong>: S3 is recommended for storing static content, such as text files, images, audio, video, and so on.</p>
			<p><strong class="keyword">Objects</strong>: Objects are the most basic entities that are stored in S3. Every object contains data, metadata, and a key. Metadata is data about the data and provides basic information about the data stored in an object. Metadata is stored in a set of name-value pairs, used to describe the information associated with the object.</p>
			<p><strong class="keyword">Keys</strong>: A key is the name assigned to an object that uniquely identifies an object inside a Bucket. All objects in a bucket have one key associated with them.</p>
			<p><strong class="keyword">Bucket</strong>: Just like a folder, a Bucket is the container where you store objects. Buckets are created at root level, and do not have a filesystem hierarchy. More specifically, you can have multiple Buckets, but you cannot have sub-Buckets within a Bucket. Buckets are the containers for objects, and you can control (create, delete, and list objects in the Bucket) access to it, view access logs for it, and select the geographical region where Amazon S3 will store the Bucket.</p>
			<p><strong class="keyword">Region</strong>: Region refers to the geographical region where Amazon S3 stores a Bucket, based on the user's preference. The region can be selected when creating a Bucket. The location should be based on where the data will be accessed the most. Overall, specific region selection has the biggest impact if S3 is used to store files for a website that's exclusively accessed in a specific geographic region. The object storage in a Bucket with different forms is as follows: </p>
			<div>
				<div class="IMG---Figure" id="_idContainer012">
					<img alt="Figure 1.1: Object storage" src="image/image001.jpg"/>
				</div>
			</div>
			<h6>Figure 1.1: Object storage</h6>
			<div>
				<div class="IMG---Figure" id="_idContainer013">
					<img alt="Figure 1.2: Object storage: using a unique key and myBucket&#13;&#10;" src="image/image003.jpg"/>
				</div>
			</div>
			<h6>Figure 1.2: Object storage using a unique key and myBucket</h6>
			<div>
				<div class="IMG---Figure" id="_idContainer014">
					<img alt="Figure 1.3: Object stored in myBucket&#13;&#10;" src="image/image005.jpg"/>
				</div>
			</div>
			<h6>Figure 1.3: Object stored in myBucket</h6>
			<h3 id="_idParaDest-22"><a id="_idTextAnchor022"/>S3 Operations</h3>
			<p>The S3 Application Program Interface (API) is quite simple, and it includes the following operations for the respective entity:</p>
			<ul>
				<li><strong class="keyword">Bucket</strong>: Create, Delete, and List keys in a Bucket</li>
				<li><strong class="keyword">Object</strong>: Write, Read, and Delete </li>
			</ul>
			<h2 id="_idParaDest-23"><a id="_idTextAnchor023"/>Data Replication</h2>
			<p>Amazon replicates data across the region in multiple servers located in Amazon's data centers. Data replication benefits include high availability and durability. More specifically, when you create a new object in S3, the data is saved in S3; however, the change needs to be replicated across the Amazon S3 regions. Overall, replication may take some time, and you might notice delays resulting from various replication mechanisms. Please consider the following when performing the indicated operations.</p>
			<p>After deleting an object, replication can cause a lag time that allows the deleted data to display until the deletion is fully replicated. Creating an object and immediately trying to display it in the object list might be delayed as a result of a replication delay.</p>
			<h3 id="_idParaDest-24"><a id="_idTextAnchor024"/>REST Interface </h3>
			<p>S3's native interface is a <strong class="bold">Representational State Transfer</strong> <strong class="bold">(REST)</strong> API. It is recommended to always use HTTPS requests to perform any S3 operations. The two higher-level interfaces that we will use to interact with S3 are the AWS Management Console and the AWS <strong class="bold">Command-Line Interface</strong> (<strong class="bold">CLI</strong>). Accessing objects with the API is quite simple, and includes the following operations for the respective entity:</p>
			<ul>
				<li><strong class="keyword">Bucket</strong>: Create, Delete, or List<strong class="inline"> </strong>keys in a Bucket</li>
				<li><strong class="keyword">Object</strong>: Write, Read, or Delete </li>
			</ul>
			<h3 id="_idParaDest-25"><a id="_idTextAnchor025"/>Exercise 1: Using the AWS Management Console to Create an S3 Bucket </h3>
			<p>In this exercise, we will import a text file into our S3 Bucket. To import a file, you need to have access to the Amazon S3 console: </p>
			<ol>
				<li>Press the <em class="italics">Ctrl</em> key while clicking <a href="">https://console.aws.amazon.com/console/home</a> to open the AWS Management Console in a new browser tab.</li>
				<li>Click inside the search bar located under AWS services:<div class="IMG---Figure" id="_idContainer015"><img alt="Figure 1.4: Searching AWS services&#13;&#10;" src="image/image007.jpg"/></div><h6> </h6><h6>Figure 1.4: Searching AWS services</h6></li>
				<li>Type <strong class="inline">S3</strong> into the search bar, and an auto-populated list will display. Then, click on the <strong class="bold">S3 Scalable Storage in the Cloud</strong> drop-down option:<div class="IMG---Figure" id="_idContainer016"><img alt="Figure 1.5: Selecting the S3 service&#13;&#10;" src="image/image009.jpg"/></div><h6> </h6><h6>Figure 1.5: Selecting the S3 service</h6></li>
				<li>Now, we need to create an S3 Bucket. In the S3 dashboard, click the <br/><strong class="bold">Create Bucket</strong> button. </li>
				<li>If this is the first time that you are that you are creating a bucket, your screen will look as follows:<div class="IMG---Figure" id="_idContainer017"><img alt="Figure 1.6: Creating the Bucket" src="image/image011.jpg"/></div><h6>Figure 1.6: Creating the Bucket</h6><h4>Note</h4><p class="callout">If you have already created S3 Buckets, your dashboard will list all of the Buckets you have created.</p></li>
				<li><strong class="bold">Enter a unique Bucket name</strong>: Bucket names must be unique across all existing Bucket names in Amazon S3. That If you encounter a naming issue, please refer to <a href="">https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html</a>. </li>
				<li><strong class="bold">Region</strong>: If a default region is auto-populated, then keep the default location. If it is not auto-populated, select a region near your current location. </li>
				<li>Click the <strong class="bold">Next</strong> button to continue for the creation of bucke<strong class="bold">t</strong>:<div class="IMG---Figure" id="_idContainer018"><img alt="Figure 1.7: Creation of Bucket&#13;&#10;" src="image/image013.jpg"/></div><h6>Figure 1.7: The Create Bucket window</h6></li>
				<li>An S3 Bucket provides the property options Versioning, Server Access Logging, Tags, Object-Level Logging, and Default Encryption. However, we will not enable them.</li>
				<li>Your Bucket will be displayed in the bucket list, like so:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer019">
					<img alt="Figure 1.8: The Bucket has been created &#13;&#10;" src="image/image015.jpg"/>
				</div>
			</div>
			<h6>Figure 1.8: The Bucket has been created </h6>
			<h3 id="_idParaDest-26"><a id="_idTextAnchor026"/>Exercise 2: Importing and Exporting the File with your S3 Bucket </h3>
			<p>In this exercise, we will import and export the file with the S3 Bucket. The following are the steps for completion:</p>
			<p><strong class="bold">Importing a File:</strong></p>
			<ol>
				<li value="1">You will import a file to your Amazon S3 Bucket.</li>
				<li>Click the Bucket's name to navigate to the Bucket:<div class="IMG---Figure" id="_idContainer020"><img alt="Figure 1.9: Navigate to Bucket&#13;&#10;" src="image/image017.jpg"/></div><h6>Figure 1.9: Navigate to Bucket</h6></li>
				<li>You are in the Bucket's home page. select <strong class="bold">Upload</strong>: <div class="IMG---Figure" id="_idContainer021"><img alt="Figure 1.10: Uploading the file into Bucket&#13;&#10;" src="image/image019.jpg"/></div><h6>Figure 1.10: Uploading the file into the Bucket</h6></li>
				<li>To select a file to upload, click <strong class="bold">Add files</strong>. Navigate to the <strong class="inline">pos_sentiment__leaves_of_grass.txt</strong> location and select the sample file that you want to store:<div class="IMG---Figure" id="_idContainer022"><img alt="" src="image/image021.jpg"/></div><h6>Figure 1.11: Adding a new file to the Bucket</h6></li>
				<li>After selecting a file to upload, select <strong class="bold">Next</strong>:<div class="IMG---Figure" id="_idContainer023"><img alt="Figure 1.12: Select the file to upload in Bucket" src="image/image023.jpg"/></div><h6>Figure 1.12: Select the file to upload to the Bucket</h6></li>
				<li>Click on the <strong class="bold">Next</strong> button and leave the default options selected:<div class="IMG---Figure" id="_idContainer024"><img alt="" src="image/image025.jpg"/></div><h6>Figure 1.13: Default Options page while uploading the file</h6></li>
				<li>You have the ability to set property settings for your object, such as <strong class="inline">storage class</strong>, <strong class="inline">encryption</strong>, and <strong class="inline">metadata</strong>. However, leave the default values as-is, and then click on the <strong class="bold">Next</strong> button:<div class="IMG---Figure" id="_idContainer025"><img alt="Figure 1.14: Setting Properties" src="image/image027.jpg"/></div><h6>Figure 1.14: Setting properties</h6></li>
				<li>Click on the <strong class="bold">Upload</strong> button to upload the files:<div class="IMG---Figure" id="_idContainer026"><img alt="Figure 1.15: Upload option to upload the files&#13;&#10;" src="image/image029.jpg"/></div><h6>Figure 1.15: Uploading the files</h6></li>
				<li>You will be directed to your object in your bucket's home screen:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer027">
					<img alt="Figure 1.16: Files uploaded in the Bucket&#13;&#10;" src="image/image031.jpg"/>
				</div>
			</div>
			<h6>Figure 1.16: Files uploaded to the Bucket</h6>
			<p><strong class="bold">Export File</strong>: </p>
			<ol>
				<li value="1">Select the checkbox next to the file to export (<em class="italics">Red Marker #1 â see the following screenshot</em>). This populates the file's information display screen. ClickÂ on  <strong class="bold">Download</strong> (<em class="italics">Red Marker #2 â see the following screenshot</em>) to retrieve the textÂ file:<div class="IMG---Figure" id="_idContainer028"><img alt="Figure 1.17: Exporting the file" src="image/image033.jpg"/></div><h6>Figure 1.17: Exporting the file</h6></li>
				<li>The file will download, as shown in the lower left-hand corner of the screen:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer029">
					<img alt="Figure 1.18: Dowmloading the file to export" src="image/image035.jpg"/>
				</div>
			</div>
			<h6>Figure 1.18: Downloading the file to export</h6>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor027"/>AWS Command-Line Interface (CLI)</h2>
			<p>The CLI is an open source tool built on the AWS SDK for Python (Boto) to perform setups, determine if calls work as intended, verify status information, and so on. The CLI provides another access tool for all AWS services, including S3. Unlike the Management Console, the CLI can be automated via scripts. </p>
			<p>To authenticate your AWS account to the CLI, you must create a configuration file to obtain your public key and secret key. Next, you will install, and then configure, the AWS CLI.</p>
			<h3 id="_idParaDest-28"><a id="_idTextAnchor028"/>Exercise 3: Configuring the Command-Line Interface</h3>
			<p>In this exercise, we will configure the CLI with our respective AWS Access Key ID and AWS Secret Access Key. The following are the steps for completion: </p>
			<ol>
				<li value="1">Go to.: <a href="">https://console.aws.amazon.com/console/home</a> and then, click on <strong class="bold">Users</strong>:<div class="IMG---Figure" id="_idContainer030"><img alt="Figure 1.19: The Amazon Console home page with the Users option highlighted" src="image/image037.jpg"/></div><h6>Figure 1.19: The Amazon Console home page with the Users option highlighted</h6></li>
				<li>In the upper-right corner of the signed-in AWS Management Console, click on <strong class="bold">My Security Credentials</strong>: <div class="IMG---Figure" id="_idContainer031"><img alt="" src="image/image039.jpg"/></div><h6>Figure 1.20: Selecting My Security Credentials</h6></li>
				<li>Next, click on <strong class="bold">Continue to Security Credentials</strong>:<div class="IMG---Figure" id="_idContainer032"><img alt="Figure 1.21: Security Credentials " src="image/image041.jpg"/></div><h6>Figure 1.21: Security Credentials </h6></li>
				<li>Click on the <strong class="bold">Access keys</strong> (<strong class="bold">access key ID and secret access key</strong>) option:<div class="IMG---Figure" id="_idContainer033"><img alt="Figure 1.22: Access key generation&#13;&#10;" src="image/image043.jpg"/></div><h6>Figure 1.22: Access key generation</h6></li>
				<li>Then, click on <strong class="bold">Create New Access Key:</strong><div class="IMG---Figure" id="_idContainer034"><img alt="Figure 1.23: Creating a new access key" src="image/image045.jpg"/></div><h6>Figure 1.23: Creating a new access key</h6></li>
				<li>Click on <strong class="bold">Download Key File</strong> to download the key file:<div class="IMG---Figure" id="_idContainer035"><img alt="Figure 1.24: Downloading the key file " src="image/image047.jpg"/></div><h6>Figure 1.24: Downloading the key file </h6></li>
				<li>The <strong class="inline">rootkey.csv</strong> that contains the keys will be downloaded. Click it to view the the details:<div class="IMG---Figure" id="_idContainer036"><img alt="Figure 1.25: Downloaded key file" src="image/image049.jpg"/></div><h6>Figure 1.25: The downloaded key file</h6></li>
				<li>Store the keys in a safe location. Protect your AWS account, and never share, email, or store keys in a non-secure location. An AWS representative will never request your keys, so be vigilant when it comes to potential phishing scams.</li>
				<li>Open the Command Prompt and type <strong class="inline">aws configure</strong>: </li>
				<li>You will be prompted for four input variables, one by one type your respective information, then press <em class="italics">Enter</em> after each input: <p><strong class="inline">AWS Access Key ID</strong></p><p><strong class="inline">AWS Secret Access Key </strong></p><p><strong class="inline">Default region</strong> </p><p><strong class="inline">Default output format</strong> <strong class="inline">(json</strong>)</p></li>
				<li>The name is obtained in your console (<strong class="bold">N. Virginia</strong> is displayed here, but yours is determined by your unique location):<div class="IMG---Figure" id="_idContainer037"><img alt="Figure 1.26: Location search" src="image/image051.jpg"/></div><h6>Figure 1.26: Location search</h6></li>
				<li>The code is obtained from the following <strong class="bold">Available Regions</strong> list:<div class="IMG---Figure" id="_idContainer038"><img alt="Figure 1.27: List of available regions" src="image/image053.jpg"/></div><h6>Figure 1.27: List of available regions</h6></li>
				<li>The Command Prompt 's final input variable will look as follows. Then, pressÂ <em class="italics">Enter</em>:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer039">
					<img alt="Figure 1.28: The last step in AWS CLI configuration in the Command Prompt " src="image/image055.jpg"/>
				</div>
			</div>
			<h6>Figure 1.28: The last step in AWS CLI configuration in the Command Prompt </h6>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor029"/>Command Line-Interface (CLI) Usage </h2>
			<p>When using a command, specify at least one path argument. The two path arguments are LocalPath and S3Uri:</p>
			<p><strong class="bold">LocalPath</strong>: This represents the path of a local file or directory, which can be written as an absolute or relative path.</p>
			<p><strong class="bold">S3Uri</strong>: This represents the location of an S3 object, prefix, or Bucket. The command form is <strong class="inline">s3://myBucketName/myKey</strong>. The path argument must begin with <strong class="inline">s3://</strong>, to indicate that the path argument refers to an S3 object.</p>
			<p>The overall command structure is <strong class="inline">aws s3 &lt;Command&gt; [&lt;Arg&gt; â¦]</strong>. The following table shows the different commands , with a description and an example:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer040">
					<img alt="Figure 1.29: Commands list " src="image/image057.jpg"/>
				</div>
			</div>
			<h6>Figure 1.29: Command list </h6>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor030"/>Recursion and Parameters </h2>
			<p>Importing files one at a time is time-consuming, especially if you have many files in a folder that need to be imported. A simple solution is to use a recursive procedure. A recursive procedure is one that has the ability to call itself and saves you, as the user, from entering the same import command for each file.</p>
			<p>Performing a recursive CLI command requires passing a parameter to the API. This sounds complicated, but it is incredibly easy. First, a parameter is simply a name or option that is passed to a program to affect the operation of the receiving program. In our case, the parameter is <strong class="bold">recursive</strong>, and the entire command to perform the recursive command is as follows:</p>
			<p class="snippet">aws s3 cp s3://myBucket . --recursive</p>
			<p>With the command, is all of the s3 objects in a respective Bucket are copied to a specified directory:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer041">
					<img alt="Figure 1.30: Parameter List&#13;&#10;" src="image/image059.jpg"/>
				</div>
			</div>
			<p class="Normal" lang="en-US" xml:lang="en-US"> </p>
			<h6>Figure 1.30: Parameter List</h6>
			<h3 id="_idParaDest-31"><a id="_idTextAnchor031"/>Activity 1: Importing and Exporting the Data into S3 with the CLI</h3>
			<p>In this activity, we will be using the CLI to create a Bucket in S3 and import a second text file. Suppose that you are an entrepreneur and you are creating a chatbot. You have identified text documents that contain content that will allow your chatbot to interact with customers more effectively. Before the text documents can be parsed, they need to be uploaded to an S3 Bucket. Once they are in S3, further analysis will be possible. To ensure that this has happened correctly, you will need to have installed Python, have an environment set up, and have a user authenticated with the CLI:</p>
			<ol>
				<li value="1">Configure the Command-Line Interface and verify that it is able to successfully connect to your AWS environment.</li>
				<li>Create a new S3 Bucket.</li>
				<li>Import a text file into the Bucket.</li>
				<li>Export the file from the Bucket and verify the exported objects.<h4>Note</h4><p class="callout">To refer to the detailed steps, go to the <em class="italics">Appendix A</em> at the end of this book on PageÂ no. 192 </p></li>
			</ol>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor032"/>Using the AWS Console to Identify Machine Learning Services</h2>
			<p>The AWS Console provides a web-based interface to navigate, discover, and utilize AWS services for AI and ML. In this topic, we will explore two ways to use the Console to search Machine Learning services. In addition, we will test an ML API with text data retrieved from a website.</p>
			<h3 id="_idParaDest-33"><a id="_idTextAnchor033"/>Exercise 4: Navigating the AWS Management Console</h3>
			<p>In this exercise, we will navigate the AWS Management Console to locate Machine Learning services. Starting from the console <a href="">https://console.aws.amazon.com/console/</a> and only using console search features, navigate to the Amazon Lex <a href="">https://console.aws.amazon.com/lex/</a> service information page: </p>
			<ol>
				<li value="1">Click on <a href="">https://console.aws.amazon.com/console/</a> to navigate to the AWS Console. Then, click on <strong class="bold">Services</strong>: <div class="IMG---Figure" id="_idContainer042"><img alt="Figure 1.31: AWS Console&#13;&#10;" src="image/image061.jpg"/></div><h6>Figure 1.31: AWS Console</h6></li>
				<li>Scroll down the page to view all of the Machine Learning services. Then, click on <strong class="bold">Amazon Lex</strong>:<div class="IMG---Figure" id="_idContainer043"><img alt="Figure 1.32: Options for Machine Learning &#13; &#10;" src="image/image063.jpg"/></div><h6>Figure 1.32: Options for Machine Learning</h6></li>
				<li>You will be redirected to the Amazon Lex home screen:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer044">
					<img alt="Figure 1.33: Amazon Lex home screen&#13;&#10;" src="image/image065.jpg"/>
				</div>
			</div>
			<h6>Figure 1.33: Amazon Lex home screen</h6>
			<p>Locating new AWS Services is an essential skill for discovering more tools to provide solutions for your data projects. Now, let's review another way to locate Machine Learning resources via the <strong class="bold">Search bar</strong>.</p>
			<h3 id="_idParaDest-34"><a id="_idTextAnchor034"/>Activity 2: Testing the Amazon Comprehend's API Features</h3>
			<p>In this activity, we will display text analysis o<a id="_idTextAnchor035"/>utput by using a partial text file input in the API explorer. Exploring an API is a skill that saves development time by making sure that the output is in a desired format for your project. Thus, we will test Comprehend's text analysis features. </p>
			<p>Suppose that you are an entrepreneur creating a chatbot. You have identified a business topic and the corresponding text documents, with content that will allow the chatbot to make your business successful. Your next step is to identify/verify an AWS service to parse the text document for sentiment, language, key phrases, and entities. Before investing time in writing a complete program, you want to test the AWS service's features via the AWS Management Console's interface. To ensure that this happens correctly, you will need to search the web for an article (written in English or Spanish) that contains the subject matter (sports, movies, current events, and so on) that you're interested in. The AWS Management Console is also accessible via the root user's account.</p>
			<p>You are aware that exploring APIs is a skill that can save development time by ensuring that the output is in a desired format for your project. The following are the steps of completion:</p>
			<ol>
				<li value="1">Identify an AWS service, via the AWS Management Console, to accomplish your objectives.</li>
				<li>Navigate to your web page of choice, which contains articles in English and Spanish.</li>
				<li>Copy the text from the article written in English or Spanish, in order to identify the following features: sentiment, language, key phrases, and entities.</li>
				<li>Obtain a score representing the articles: sentiment, language, key phrases, and entities.<h4>Note</h4><p class="callout">To refer to the detailed steps, go to the <em class="italics">Appendix A</em> at the end of this book on PageÂ no. 194</p></li>
			</ol>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor036"/>Summary</h2>
			<p>At the beginning of this chapter, we explained what Amazon Web Services is, what Machine Learning is, and what Artificial Intelligence is. Following this, you learned what Amazon S3 is, and why Amazon S3 is used. You also explored the basic requirements for working with AWS using S3. With this, you used IAM (Identity and Access Management).</p>
			<p>Next, you learned how to import and export data into S3. Following that, you explored the components of S3. At the same time, you learned about the REST Interface. In the last part of this chapter, we looked at the AWS command line and its usages. Finally, we explored the concepts of recursion and parameters, and how to use the AWS Console to identify Machine Learning services.</p>
			<p>In the next chapter, you will learn how to summarize text documents by using Natural Language Processing (NLP). Researching new AWS services is essential for discovering additional solutions to solve any machine learning problems that you are working on.</p>
		</div>
	</body></html>