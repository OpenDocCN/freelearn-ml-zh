- en: 'Chapter 4: Adding Feature Store to ML Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：将特征存储添加到机器学习模型
- en: In the last chapter, we discussed **Feast** installation in your local system,
    common terminology in Feast, what the project structure looks like, API usage
    with an example, and a brief overview of the Feast architecture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了在本地系统中安装 **Feast**，Feast 中的常见术语，项目结构的样子，以及使用示例的 API 使用方法，并对 Feast
    架构进行了简要概述。
- en: So far in the book, we have been talking about issues with feature management
    and how a feature store can benefit data scientists and data engineers. It is
    time for us to get our hands dirty with an ML model and add Feast to the ML pipeline.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本书一直在讨论特征管理的问题以及特征存储如何使数据科学家和数据工程师受益。现在是时候让我们亲自动手，将 Feast 添加到机器学习管道中。
- en: In this chapter, we will revisit the **Customer Lifetime Value** (**LTV/CLTV**)
    ML model built in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014), *An Overview
    of the Machine Learning Life Cycle*. We will use AWS cloud services instead of
    the local system to run the examples in this chapter. As mentioned in [*Chapter
    3*](B18024_03_ePub.xhtml#_idTextAnchor050), *Feature Store Fundamentals, Terminology,
    and Usage*, installation for AWS is different from that of a local system, so
    we will have to create a few resources. I will be using some Free Tier services
    and some that are featured services (free for the first 2 months of use with limits).
    Also, the terms and API usage examples we looked at in [*Chapter 3*](B18024_03_ePub.xhtml#_idTextAnchor050),
    *Feature Store Fundamentals, Terminology, and Usage*, will be very useful as we
    try to include Feast in the ML pipeline.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾在 [*第一章*](B18024_01_ePub.xhtml#_idTextAnchor014)，《机器学习生命周期概述》中构建的
    **客户终身价值**（**LTV/CLTV**）机器学习模型。我们将使用 AWS 云服务而不是本地系统来运行本章的示例。正如在 [*第三章*](B18024_03_ePub.xhtml#_idTextAnchor050)，《特征存储基础、术语和用法》中提到的，AWS
    的安装与本地系统不同，因此我们需要创建一些资源。我将使用一些免费层服务和一些特色服务（前两个月使用免费，但有限制）。此外，我们在 [*第三章*](B18024_03_ePub.xhtml#_idTextAnchor050)，《特征存储基础、术语和用法》中查看的术语和
    API 使用示例，在我们尝试将 Feast 包含到机器学习管道中时将非常有用。
- en: The goal of this chapter is to learn what it takes to include a feature store
    in a project and how it differs from the traditional ML model building that we
    did in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014), *An Overview of the
    Machine Learning Life Cycle*. We will learn about Feast installation, how to build
    a feature engineering pipeline for the LTV model, how to define feature definitions,
    and we will also look at feature ingestion in Feast.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是了解将特征存储添加到项目中的所需条件以及它与我们在 [*第一章*](B18024_01_ePub.xhtml#_idTextAnchor014)，《机器学习生命周期概述》中进行的传统机器学习模型构建有何不同。我们将学习
    Feast 的安装，如何为 LTV 模型构建特征工程管道，如何定义特征定义，我们还将查看 Feast 中的特征摄取。
- en: 'We will discuss the following topics in order:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按以下顺序讨论以下主题：
- en: Creating Feast resources in AWS
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AWS 中创建 Feast 资源
- en: Feast initialization for AWS
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feast 初始化针对 AWS
- en: Exploring the ML life cycle with Feast
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Feast 探索机器学习生命周期
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To follow the code examples in the chapter, all you need is familiarity with
    Python and any notebook environment, which could be a local setup such as Jupyter
    or an online notebook environment such as Google Collab, Kaggle, or SageMaker.
    You will also need an AWS account with full access to resources such as Redshift,
    S3, Glue, DynamoDB, the IAM console, and more. You can create a new account and
    use all the services for free during the trial period. You can find the code examples
    for the book at the following GitHub link:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本章中的代码示例，您只需要熟悉 Python 和任何笔记本环境，这可以是本地设置，如 Jupyter，或者在线笔记本环境，如 Google Collab、Kaggle
    或 SageMaker。您还需要一个 AWS 账户，并有权访问 Redshift、S3、Glue、DynamoDB、IAM 控制台等资源。您可以在试用期间创建新账户并免费使用所有服务。您可以在以下
    GitHub 链接找到本书的代码示例：
- en: https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter04
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter04
- en: 'The following GitHub link points to the feature repository:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 GitHub 链接指向特征存储库：
- en: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/customer_segmentation](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/customer_segmentation)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/customer_segmentation](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/customer_segmentation)'
- en: Creating Feast resources in AWS
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AWS 中创建 Feast 资源
- en: As discussed in the previous chapter, Feast aims to provide a quick setup for
    beginners to try it out; however, for team collaboration and to run a model in
    production, it requires a better setup. In this section, we will set up a Feast
    environment in the AWS cloud and use it in model development. In the previous
    chapter, we also discussed that Feast provides multiple choices when picking an
    online and offline store. For this exercise, Amazon S3 with Redshift will be used
    as an offline/historical store and DynamoDB will be used as an online store. So,
    we need a few resources on AWS before we can start using the feature store in
    our project. Let's create the resources one after another.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，Feast 致力于为初学者提供快速设置，以便他们尝试使用它；然而，为了团队协作和在生产中运行模型，它需要一个更好的设置。在本节中，我们将在
    AWS 云中设置一个 Feast 环境，并在模型开发中使用它。在前一章中，我们还讨论了 Feast 在选择在线和离线存储时提供了多种选择。对于这个练习，我们将使用
    Amazon S3 和 Redshift 作为离线/历史存储，并使用 DynamoDB 作为在线存储。因此，在我们开始使用项目中的特征存储功能之前，我们需要在
    AWS 上准备一些资源。让我们依次创建这些资源。
- en: Amazon S3 for storing data
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon S3 用于存储数据
- en: As mentioned in the AWS documentation, **Amazon Simple Storage Service** (**Amazon
    S3**) *is an object storage service offering industry-leading scalability, data
    availability, security, and performance*. Feast provides the capability to use
    S3 to store and retrieve all data and metadata. You could also use version control
    systems such as GitHub or GitLab to collaborate on the metadata and sync to S3
    during deployment. To create an S3 bucket in AWS, log in to your AWS account,
    navigate to the S3 service using the search box, or visit [https://s3.console.aws.amazon.com/s3/home?region=us-east-1](https://s3.console.aws.amazon.com/s3/home?region=us-east-1).
    A web page will be displayed, as shown in *Figure 4.1*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如 AWS 文档中所述，**Amazon Simple Storage Service** (**Amazon S3**) 是一种提供行业领先的可扩展性、数据可用性、安全性和性能的对象存储服务。Feast
    提供了使用 S3 存储和检索所有数据和元数据的功能。您还可以使用版本控制系统，如 GitHub 或 GitLab，在部署期间协作编辑元数据并将其同步到 S3。要在
    AWS 中创建 S3 存储桶，请登录您的 AWS 账户，使用搜索框导航到 S3 服务，或访问 [https://s3.console.aws.amazon.com/s3/home?region=us-east-1](https://s3.console.aws.amazon.com/s3/home?region=us-east-1)。将显示一个网页，如图
    *图 4.1* 所示。
- en: '![Figure 4.1 – AWS S3 home page'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1 – AWS S3 主页'
- en: '](img/B18024_04_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18024_04_01.jpg]'
- en: Figure 4.1 – AWS S3 home page
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – AWS S3 主页
- en: If you already have the buckets, you will see them on the page. I am using a
    new account, hence I don't see any buckets yet. To create a new bucket, click
    on `feast-demo-mar-2022`. One thing to keep in mind is that S3 bucket names are
    unique across accounts. If bucket creation fails with an error, **Bucket with
    the same name already exists**, try adding a few random characters to the end.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经有了存储桶，您将在页面上看到它们。我正在使用一个新账户，因此我还没有看到任何存储桶。要创建一个新的存储桶，请点击 `feast-demo-mar-2022`。需要注意的是，S3
    存储桶名称在账户间是唯一的。如果存储桶创建失败并出现错误，**存在同名存储桶**，请尝试在末尾添加一些随机字符。
- en: '![Figure 4.2 – S3 Create bucket'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.2 – 创建 S3 存储桶'
- en: '](img/B18024_04_02.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18024_04_02.jpg]'
- en: Figure 4.2 – S3 Create bucket
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 创建 S3 存储桶
- en: After successful bucket creation, you will see a screen similar to *Figure 4.3*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 存储桶创建成功后，您将看到一个类似于 *图 4.3* 的屏幕。
- en: '![Figure 4.3 – After S3 bucket creation'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.3 – 创建 S3 存储桶之后'
- en: '](img/B18024_04_03.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18024_04_03.jpg]'
- en: Figure 4.3 – After S3 bucket creation
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 创建 S3 存储桶之后
- en: AWS Redshift for an offline store
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS Redshift 用于离线存储
- en: As mentioned in the AWS documentation, *Amazon Redshift uses SQL to analyze
    structured and semi-structured data across data warehouses, operational databases,
    and data lakes, using AWS-designed hardware and machine learning to deliver the
    best price performance at any scale*. As mentioned earlier, we will use a Redshift
    cluster for querying historical data. We need to create a cluster since we don't
    have one already. Before we create a cluster, let's create an **Identity and Access
    Management** (**IAM**) role. This is a role that Redshift will assume on our behalf
    to query the historical data in S3.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如 AWS 文档中所述，*Amazon Redshift 使用 SQL 分析数据仓库、操作数据库和数据湖中的结构化和半结构化数据，利用 AWS 设计的硬件和机器学习，在任何规模下提供最佳的价格性能*。如前所述，我们将使用
    Redshift 集群来查询历史数据。由于我们还没有集群，我们需要创建一个。在创建集群之前，让我们创建一个 **身份和访问管理** (**IAM**) 角色。这是一个
    Redshift 将代表我们查询 S3 中历史数据的角色。
- en: 'Let''s start by creating an IAM role:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个 IAM 角色开始：
- en: To create an IAM role, navigate to the AWS IAM console using the search or visit
    the URL https://us-east-1.console.aws.amazon.com/iamv2/home?region=us-east-1#/roles.
    A web page similar to the one in *Figure 4.4* will be displayed.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建 IAM 角色，请使用搜索导航到 AWS IAM 控制台或访问 URL https://us-east-1.console.aws.amazon.com/iamv2/home?region=us-east-1#/roles。将显示一个类似于
    *图 4.4* 的网页。
- en: '![Figure 4.4 – IAM home page'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.4 – IAM 主页'
- en: '](img/B18024_04_04.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B18024_04_04.jpg]'
- en: Figure 4.4 – IAM home page
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – IAM 主页
- en: To create a new role, click on the **Create role** button in the top-right corner.
    The following page will be displayed.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建新角色，请点击右上角的 **创建角色** 按钮。将显示以下页面。
- en: '![Figure 4.5 – IAM Create role'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.5 – IAM 创建角色'
- en: '](img/B18024_04_05.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B18024_04_05.jpg]'
- en: Figure 4.5 – IAM Create role
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – IAM 创建角色
- en: 'From the options available on the page, select **Custom trust policy**, copy
    the following code block, and replace the policy in the JSON in the textbox:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在页面上的可用选项中，选择 **自定义信任策略**，复制以下代码块，并用文本框中的 JSON 中的策略替换它：
- en: '[PRE0]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Scroll all the way to the bottom and click on **Next**. On the next page, you
    will see a list of IAM policies that can be attached to the role, as shown in
    *Figure 4.6*.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将页面滚动到最底部并点击 **下一步**。在下一页，您将看到一个可以附加到角色的 IAM 策略列表，如图 *图 4.6* 所示。
- en: '![Figure 4.6 – IAM permissions for the role'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6 – 角色的 IAM 权限'
- en: '](img/B18024_04_06.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B18024_04_06.jpg]'
- en: Figure 4.6 – IAM permissions for the role
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 角色的 IAM 权限
- en: We need **S3** access, since the data will be stored in S3 as Parquet files,
    and **AWS Glue** access. The data stored in S3 will be loaded as an external schema
    into Redshift using AWS Glue Data Catalog/Lake Formation. Follow along here and
    you will understand what it means to load data as an external schema. For S3 access,
    search for **AmazonS3FullAccess** and select the corresponding checkbox, then
    search for **AWSGlueConsoleFullAccess** and select the corresponding checkbox.
    Scroll all the way down and click on **Next**.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要 **S3** 访问权限，因为数据将以 Parquet 文件的形式存储在 S3 中，以及 **AWS Glue** 访问权限。存储在 S3 中的数据将通过
    AWS Glue 数据目录/Lake Formation 作为外部模式加载到 Redshift 中。请跟随这里，您将了解将数据作为外部模式加载的含义。对于
    S3 访问，搜索 **AmazonS3FullAccess** 并选择相应的复选框，然后搜索 **AWSGlueConsoleFullAccess** 并选择相应的复选框。将页面滚动到最底部并点击
    **下一步**。
- en: Important Note
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: We are providing full access to S3 and Glue on all the resources here, but it
    is recommended to restrict access to specific resources. I will leave that as
    an exercise since it is out of scope for this chapter.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在这里为所有资源提供对 S3 和 Glue 的完全访问权限，但建议限制对特定资源的访问。我将将其留作练习，因为这不属于本章的范围。
- en: The following page will be displayed after you click on **Next**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在点击 **下一步** 后，将显示以下页面。
- en: '![Figure 4.7 – IAM review'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.7 – IAM 审查'
- en: '](img/B18024_04_07.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B18024_04_07.jpg]'
- en: Figure 4.7 – IAM review
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – IAM 审查
- en: On this page, provide a name for the role. I have named the role `feast-demo-mar-2022-spectrum-role`.
    Review the details of the role and click on **Create role**. On successful creation,
    you will find the role on the IAM console page.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此页面上，为角色提供一个名称。我已将角色命名为 `feast-demo-mar-2022-spectrum-role`。审查角色的详细信息并点击 **创建角色**。在成功创建后，您将在
    IAM 控制台页面上找到该角色。
- en: Now that we have the IAM role ready, the next step is to create a **Redshift**
    cluster and assign the created IAM role to it. To create the Redshift cluster,
    navigate to the Redshift home page using the search bar or visit the link https://us-east-1.console.aws.amazon.com/redshiftv2/home?region=us-east-1#clusters.
    The following page will be displayed.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了 IAM 角色，下一步是创建一个 **Redshift** 集群并将创建的 IAM 角色分配给它。要创建 Redshift 集群，请使用搜索栏导航到
    Redshift 主页或访问链接 https://us-east-1.console.aws.amazon.com/redshiftv2/home?region=us-east-1#clusters。将显示以下页面。
- en: '![Figure 4.8 – Redshift home page'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.8 – Redshift 主页'
- en: '](img/B18024_04_08.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B18024_04_08.jpg]'
- en: Figure 4.8 – Redshift home page
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – Redshift 主页
- en: On the page in *Figure 4.8*, click on **Create cluster**. The following page
    will be displayed.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *图 4.8* 中的页面上，点击 **创建集群**。将显示以下页面。
- en: '![Figure 4.9 – Create a Redshift cluster'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.9 – 创建 Redshift 集群'
- en: '](img/B18024_04_09.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B18024_04_09.jpg]'
- en: Figure 4.9 – Create a Redshift cluster
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – 创建 Redshift 集群
- en: From the web page displayed in *Figure 4.9*, I am picking **Free trial** for
    the demo, but this can be configured based on the dataset size and load. After
    picking **Free trial**, scroll all the way down and pick a password. The following
    figure shows the lower half of the window when you scroll down.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从显示在 *图 4.9* 中的网页，我选择了用于演示的 **免费试用**，但可以根据数据集大小和负载进行配置。选择 **免费试用** 后，滚动到页面底部并选择一个密码。以下图显示了向下滚动后的窗口下半部分。
- en: '![Figure 4.10 – Create cluster lower half'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.10 – 创建集群下半部分'
- en: '](img/B18024_04_10.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_10.jpg)'
- en: Figure 4.10 – Create cluster lower half
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 创建集群下半部分
- en: Once you've picked a password, click on **Create cluster** at the bottom. Cluster
    creation takes a few minutes. Once the cluster creation is complete, you should
    see the newly created cluster in the AWS Redshift console. One last thing that
    is pending is associating the IAM role that we created earlier with the Redshift
    cluster. Let's do that now. Navigate to the newly created cluster. You will see
    a web page similar to the one in *Figure 4.11*.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择密码后，点击底部的 **创建集群**。集群创建需要几分钟。一旦集群创建完成，你应该在 AWS Redshift 控制台中看到新创建的集群。最后一件待办事项是将我们之前创建的
    IAM 角色与 Redshift 集群关联起来。现在让我们来做这件事。导航到新创建的集群。你会看到一个类似于 *图 4.11* 中的网页。
- en: '![Figure 4.11 – Redshift cluster page'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.11 – Redshift 集群页面'
- en: '](img/B18024_04_11.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_11.jpg)'
- en: Figure 4.11 – Redshift cluster page
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – Redshift 集群页面
- en: On the cluster home page, select the **Properties** tab and scroll down to **Associated
    IAM roles**. You will see the options displayed in *Figure 4.12*.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在集群主页上，选择 **属性** 选项卡并滚动到 **关联 IAM 角色**。你将看到 *图 4.12* 中显示的选项。
- en: '![Figure 4.12 – Redshift Properties tab'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.12 – Redshift 属性选项卡'
- en: '](img/B18024_04_12.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_12.jpg)'
- en: Figure 4.12 – Redshift Properties tab
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – Redshift 属性选项卡
- en: From the web page, click on the `feast-demo-mar-2022-spectrum-role`, hence I
    am associating that role. Once you click on the button, the cluster will be updated
    with the new role. It may take a few minutes again. Once the cluster is ready,
    we are done with the required infrastructure for now. We will add the external
    data catalog when the features are ready to be ingested.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从网页上，点击 `feast-demo-mar-2022-spectrum-role`，因此我将关联该角色。点击按钮后，集群将更新为新角色。这又可能需要几分钟。一旦集群准备就绪，我们现在就完成了所需的必要基础设施。当功能准备就绪以进行摄取时，我们将添加外部数据目录。
- en: '![Figure 4.13 – Redshift Associate IAM roles'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.13 – Redshift 关联 IAM 角色'
- en: '](img/B18024_04_13.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_13.jpg)'
- en: Figure 4.13 – Redshift Associate IAM roles
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – Redshift 关联 IAM 角色
- en: We need an IAM user to access these resources and perform operations on them.
    Let's create that next.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个 IAM 用户来访问这些资源并对它们进行操作。让我们接下来创建它。
- en: Creating an IAM user to access the resources
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 IAM 用户以访问资源
- en: 'There are different ways to provide access to the users for the resources.
    If you are part of the organization, then the IAM roles can be integrated with
    Auth0 and active directories. Since that is out of scope here, I will be creating
    an IAM user and will give the required permissions for the user to access the
    resources created earlier:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的方式为用户提供对资源的访问权限。如果你是组织的一部分，那么 IAM 角色可以与 Auth0 和活动目录集成。由于这超出了本节范围，我将创建一个
    IAM 用户，并将为用户分配必要的权限以访问之前创建的资源：
- en: Let's create the IAM user from the AWS console. The IAM console can be accessed
    using the search or visiting https://console.aws.amazon.com/iamv2/home#/users.
    The IAM console looks as shown in *Figure 4.14*.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从 AWS 控制台创建 IAM 用户。可以通过搜索或访问 https://console.aws.amazon.com/iamv2/home#/users
    访问 IAM 控制台。IAM 控制台的外观如 *图 4.14* 所示。
- en: '![Figure 4.14 – IAM user page'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.14 – IAM 用户页面'
- en: '](img/B18024_04_14.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_14.jpg)'
- en: Figure 4.14 – IAM user page
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14 – IAM 用户页面
- en: On the IAM user page, click on the **Add users** button in the top right. The
    following web page will be displayed.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 IAM 用户页面上，点击右上角的 **添加用户** 按钮。将显示以下网页。
- en: '![Figure 4.15 – IAM Add user'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.15 – IAM 添加用户'
- en: '](img/B18024_04_15.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_15.jpg)'
- en: Figure 4.15 – IAM Add user
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 – IAM 添加用户
- en: 'On the web page, provide a user name and select **Access key - Programmatic
    access**, then click on **Next: Permissions** at the bottom. The following web
    page will be displayed.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页上，提供一个用户名并选择 **访问密钥 - 程序化访问**，然后点击底部的 **下一步：权限**。将显示以下网页。
- en: '![Figure 4.16 – IAM permissions'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.16 – IAM 权限'
- en: '](img/B18024_04_16.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_16.jpg)'
- en: Figure 4.16 – IAM permissions
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.16 – IAM 权限
- en: 'On the displayed web page, click on **Attach existing policies directly** and
    from the list of available policies, search for and attach the following policies:
    **AmazonRedshiftFullAccess**, **AmazonS3FullAccess**, and **AmazonDynamoDBFullAccess**.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在显示的网页上，点击**直接附加现有策略**，然后从可用策略列表中搜索并附加以下策略：**AmazonRedshiftFullAccess**、**AmazonS3FullAccess**和**AmazonDynamoDBFullAccess**。
- en: Important Note
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: We are attaching full access here without restricting the user to specific resources.
    It is always a good practice to restrict access based on the resources and only
    provide required permissions.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在这里提供了完整的访问权限，而不限制用户访问特定的资源。根据资源限制访问并仅提供所需的权限总是一个好的做法。
- en: 'Click **Next: Tags** and feel free to add tags and again click on **Next: Review**.
    The review page looks like the following:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步：标签**，您可以自由添加标签，然后再次点击**下一步：审查**。审查页面看起来如下：
- en: '![Figure 4.17 – IAM user review'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.17 – IAM 用户审查'
- en: '](img/B18024_04_17.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_17.jpg)'
- en: Figure 4.17 – IAM user review
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.17 – IAM 用户审查
- en: From the review page, click on the **Create user** button. The web page in *Figure
    4.18* will be displayed.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从审查页面，点击**创建用户**按钮。*图 4.18*中的网页将会显示。
- en: '![Figure 4.18 – IAM user credentials'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.18 – IAM 用户凭据'
- en: '](img/B18024_04_18.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_18.jpg)'
- en: Figure 4.18 – IAM user credentials
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.18 – IAM 用户凭据
- en: On the web page, click on the **Download.csv** button and save the file in a
    secure location. It contains the **Access key ID** and **Secret access key** for
    the user we just created. The secret will be lost if you don't download and save
    it from this page. However, you can go into the user from the IAM user page and
    manage the secret (delete the existing credentials and create new credentials).
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页上点击**Download.csv**按钮，并将文件保存在安全的位置。它包含我们刚刚创建的用户**访问密钥 ID**和**秘密访问密钥**。如果您不从这个页面下载并保存它，秘密将会丢失。然而，您可以从
    IAM 用户页面进入用户并管理秘密（删除现有的凭据并创建新的凭据）。
- en: Now that the infrastructure is ready, let's initialize the Feast project.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在基础设施已经就绪，让我们初始化 Feast 项目。
- en: Feast initialization for AWS
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Feast AWS 初始化
- en: 'We have the infrastructure required for running Feast now. However, we need
    to initialize a Feast project before we can start using it. To initialize a Feast
    project, we need to install the Feast library as we did in [*Chapter 3*](B18024_03_ePub.xhtml#_idTextAnchor050),
    *Feature Store Fundamentals, Terminology, and Usage*. However, this time, we also
    need to install the AWS dependencies. Here is the link to the notebook: [https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_Feast_aws_initialization.ipynb.](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_Feast_aws_initialization.ipynb
    )'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有运行 Feast 所需的基础设施。然而，在我们开始使用它之前，我们需要初始化一个 Feast 项目。要初始化 Feast 项目，我们需要像在[*第
    3 章*](B18024_03_ePub.xhtml#_idTextAnchor050)中那样安装 Feast 库，即*特征存储基础、术语和用法*。但是，这次，我们还需要安装
    AWS 依赖项。以下是笔记本的链接：[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_Feast_aws_initialization.ipynb.](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_Feast_aws_initialization.ipynb
    )
- en: 'The following command installs Feast with the required AWS dependencies:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令安装 Feast 并带有所需的 AWS 依赖项：
- en: '[PRE1]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the dependencies are installed, we need to initialize the Feast project.
    Unlike the initialization we did in the last chapter, here, Feast initialization
    needs additional inputs such as Redshift ARN, database name, S3 path, and so on.
    Let''s look at how the initialization differs here. Before we initialize the project,
    we need the following details:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖项安装完成后，我们需要初始化 Feast 项目。与上一章中我们进行的初始化不同，这里的 Feast 初始化需要额外的输入，例如 Redshift ARN、数据库名称、S3
    路径等。让我们看看初始化在这里是如何不同的。在我们初始化项目之前，我们需要以下详细信息：
- en: '**AWS Region**: The Region where your infrastructure is running. I have created
    all the resources in **us-east-1**. If you have created them in a different Region,
    use that.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS 区域**：您的基础设施运行的区域。我已在**us-east-1**创建了所有资源。如果您在另一个区域创建了它们，请使用该区域。'
- en: '**Redshift Cluster ID**: The cluster identifier of the Redshift cluster that
    was created earlier. It can be found on the home page.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Redshift 集群 ID**：之前创建的 Redshift 集群的标识符。它可以在主页上找到。'
- en: '`dev`.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dev`。'
- en: '`awsuser`. If you gave a different user name during cluster creation, use that
    here.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`awsuser`。如果您在集群创建时提供了不同的用户名，请在这里使用。'
- en: '`s3://feast-demo-mar-2022/staging`. Also create the staging folder in the bucket.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s3://feast-demo-mar-2022/staging`。同时也在存储桶中创建 staging 文件夹。'
- en: '`arn:aws:iam::<account_number>:role/feast-demo-mar-2022-spectrum-role`.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`arn:aws:iam::<account_number>:role/feast-demo-mar-2022-spectrum-role`。'
- en: 'Once you have the values for the mentioned parameters, the new project can
    be initialized in two ways. One is using the following command:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了提到的参数值，新的项目可以通过以下两种方式之一初始化。一种是使用以下命令：
- en: '[PRE2]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The preceding command initializes the Feast project. During initialization,
    the command will ask you for the mentioned arguments.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令初始化 Feast 项目。在初始化过程中，命令将要求你提供提到的参数。
- en: 'The second way is to edit the `feature_store.yaml` file:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是编辑 `feature_store.yaml` 文件：
- en: '[PRE3]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Whichever method you choose for initializing the project, make sure that you
    provide the appropriate values for the parameters. I have highlighted the parameter
    that may need to be replaced for the Feast functionalities to work without issues.
    If you are using the first method, the `init` command will give the option to
    choose whether to load example data or not. Choose `no` to upload the example
    data.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你选择哪种方法来初始化项目，确保你提供了适当的参数值。我已经突出显示了可能需要替换的参数，以便 Feast 功能能够无问题地工作。如果你使用第一种方法，`init`
    命令将提供选择是否加载示例数据的选项。选择 `no` 以不上传示例数据。
- en: 'Now that we have our feature repository initialized for the project, let''s
    apply our initial feature set, which is basically empty. The following code block
    removes the unwanted files that get created if you use `feast init` for the initialization
    of the project:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为项目初始化了特征存储库，让我们应用我们的初始特征集，它基本上是空的。以下代码块移除了如果你使用 `feast init` 初始化项目时创建的不需要的文件：
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If you don't run the preceding commands, it will create the feature definitions
    for the entity and feature views in the `driver_repo.py` file.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有运行前面的命令，它将在 `driver_repo.py` 文件中创建实体和特征视图的特征定义。
- en: 'The following code block creates feature and entity definitions defined in
    the project. In this project, there are none so far:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块创建了项目中定义的特征和实体定义。在这个项目中，目前还没有：
- en: '[PRE18]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: When the preceding command is run, it displays the message **No changes to registry**,
    which is correct since we don't have any feature definitions yet.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行前面的命令时，它将显示消息 **No changes to registry**，这是正确的，因为我们还没有任何特征定义。
- en: The folder structure of `customer_segmentation` should look like *Figure 4.19*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`customer_segmentation` 文件夹的结构应该看起来像 *图4.19*。'
- en: '![Figure 4.19 – Project folder structure'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.19 – 项目文件夹结构'
- en: '](img/B18024_04_19.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_19.jpg)'
- en: Figure 4.19 – Project folder structure
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19 – 项目文件夹结构
- en: The feature repository is ready for use now. This can be checked into *GitHub*
    or *GitLab* for versioning and collaboration.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 特征存储库现在已准备好使用。这可以提交到 *GitHub* 或 *GitLab* 以进行版本控制和协作。
- en: Important Note
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Also note that all the preceding steps can be automated using infrastructure
    as code frameworks such as Terraform, the AWS CDK, Cloud Formation, or others.
    Depending on the team structure followed in the organization, it will be the responsibility
    of the data engineer or platform/infrastructure team to create the required resources
    and share the repository details that can be used by data scientists or engineers.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，所有前面的步骤都可以使用基础设施即代码框架（如 Terraform、AWS CDK、Cloud Formation 等）自动化。根据组织遵循的团队结构，数据工程师或平台/基础设施团队将负责创建所需资源并共享数据科学家或工程师可以使用的存储库详细信息。
- en: In the next section, let's look at how the ML life cycle changes with the feature
    store.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们看看机器学习生命周期如何随着特征存储而变化。
- en: Exploring the ML life cycle with Feast
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Feast 探索机器学习生命周期
- en: In this section, let's discuss what ML model development looks like when you
    are using a feature store. We went through the ML life cycle in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014),
    *An Overview of the Machine Learning Life Cycle*. This makes it easy to understand
    how it changes with a feature store and enables us to skip through a few steps
    that will be redundant.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们讨论一下当你使用特征存储时，机器学习模型开发看起来是什么样子。我们在 [*第1章*](B18024_01_ePub.xhtml#_idTextAnchor014)
    中回顾了机器学习生命周期，*机器学习生命周期概述*。这使得理解它如何随着特征存储而变化变得容易，并使我们能够跳过一些将变得冗余的步骤。
- en: '![Figure 4.20 – ML life cycle'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.20 – 机器学习生命周期'
- en: '](img/B18024_04_20.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_20.jpg)'
- en: Figure 4.20 – ML life cycle
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.20 – 机器学习生命周期
- en: Problem statement (plan and create)
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述（计划和创建）
- en: The problem statement remains the same as it was in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014),
    *An Overview of the Machine Learning Life Cycle*. Let's assume that you own a
    retail business and would like to improve the customer experience. First and foremost,
    you want to find your customer segments and customer lifetime value.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 问题陈述与[*第一章*](B18024_01_ePub.xhtml#_idTextAnchor014)，*机器学习生命周期概述*中的一致。假设你拥有一家零售业务，并希望提高客户体验。首先，你想要找到你的客户细分和客户终身价值。
- en: Data (preparation and cleaning)
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据（准备和清理）
- en: 'Unlike in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014), *An Overview
    of the Machine Learning Life Cycle*, before exploring the data and figuring out
    the access and more, here the starting point for model building is the feature
    store. Here is the link to the notebook:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 与[*第一章*](B18024_01_ePub.xhtml#_idTextAnchor014)，*机器学习生命周期概述*不同，在探索数据并确定访问权限等之前，这里的模型构建起点是特征存储。以下是笔记本的链接：
- en: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_browse_feast_for_features.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_browse_feast_for_features.ipynb
    )'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_browse_feast_for_features.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_browse_feast_for_features.ipynb)'
- en: '[Let''s start with the Feature Store:](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_browse_feast_for_features.ipynb
    )'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[让我们从特征存储开始：](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_browse_feast_for_features.ipynb)'
- en: 'So, let''s open up a notebook and install Feast with AWS dependencies:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，让我们打开一个笔记本并使用AWS依赖项安装Feast：
- en: '[PRE19]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'If the feature repository created in the last section was pushed into source
    control such as GitHub or GitLab, let''s clone the repository. The following code
    clones the repository:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在上一节中创建的特征仓库已推送到源代码控制，如GitHub或GitLab，请克隆该仓库。以下代码克隆了仓库：
- en: '[PRE20]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now that we have the feature repository, let''s connect to Feast/the feature
    store and check what''s available:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了特征仓库，让我们连接到Feast/特征存储并检查可用性：
- en: '[PRE21]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The preceding code block connects to the Feast feature repository. The `repo_path="."`
    parameter indicates that `feature_store.yaml` is in the current working directory.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块连接到Feast特征仓库。`repo_path="."`参数表示`feature_store.yaml`位于当前工作目录。
- en: 'Let''s check whether the feature store contains any **entities** or **feature
    views** that can be used in the model instead of exploring the data and regenerating
    the features that already exist:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查特征存储是否包含任何可用于模型的**实体**或**特征视图**，而不是探索数据并重新生成已存在的特征：
- en: '[PRE22]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code block lists the **entities** and **feature views** that
    exist in the current feature repository we are connected to. The code block outputs
    two empty lists as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块列出了我们连接到的当前特征仓库中存在的**实体**和**特征视图**。代码块输出如下两个空列表：
- en: '[PRE23]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Important Note
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You may be wondering *What about the features created by other teams? How can
    I get access to them and check what's available?* There are ways to manage that.
    We will get to that a little later.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，*其他团队创建的特征怎么办？我如何获取访问权限并检查可用性？* 有方法可以管理这些。我们稍后会提到。
- en: Since the entities and feature views are empty, there is nothing that can be
    used. The next step is to perform data exploration and feature engineering.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 由于实体和特征视图为空，没有可用的内容。下一步是进行数据探索和特征工程。
- en: We will be skipping over the data exploration stage as we have already done
    it in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014), *An Overview of the
    Machine Learning Life Cycle*. Also, the steps for generating the features would
    be the same. Hence I will not be expanding on feature engineering. Instead, I
    will use the same code and briefly mention what the code does. Refer to [*Chapter
    1*](B18024_01_ePub.xhtml#_idTextAnchor014), *An Overview of the Machine Learning
    Life Cycle*, for a detailed description of how features are generated.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将跳过数据探索阶段，因为我们已经在[*第一章*](B18024_01_ePub.xhtml#_idTextAnchor014)，*机器学习生命周期概述*中完成了它。因此，生成特征的步骤也将相同。因此，我将不会详细说明特征工程。相反，我将使用相同的代码，并简要说明代码的功能。有关特征生成详细描述，请参阅[*第一章*](B18024_01_ePub.xhtml#_idTextAnchor014)，*机器学习生命周期概述*。
- en: Model (feature engineering)
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型（特征工程）
- en: 'In this section, we will generate the features required for the model. Just
    the way we did in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014), *An Overview
    of the Machine Learning Life Cycle*, we will use 3 months of data to generate
    RFM features and 6 months of data to generate the labels for the dataset. We will
    go through the steps in the same order as we did in [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014),
    *An Overview of the Machine Learning Life Cycle*. Here is the link to the feature
    engineering notebook:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将生成模型所需的特征。就像我们在[*第1章*](B18024_01_ePub.xhtml#_idTextAnchor014)，“机器学习生命周期概述”中所做的那样，我们将使用3个月的数据来生成RFM特征，并使用6个月的数据来生成数据集的标签。我们将按照与[*第1章*](B18024_01_ePub.xhtml#_idTextAnchor014)，“机器学习生命周期概述”中相同的顺序进行操作。以下是特征工程笔记本的链接：
- en: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb).'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb)。'
- en: 'Let''s start with feature engineering:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从特征工程开始：
- en: 'The following code block reads the dataset and filters out the data that doesn''t
    belong to `United Kingdom`:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码块读取数据集并过滤掉不属于`United Kingdom`的数据：
- en: '[PRE24]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Once we have the filtered data, the next step is to create two DataFrames, one
    for 3 months and one for 6 months.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们有了过滤后的数据，下一步是创建两个DataFrame，一个用于3个月，一个用于6个月。
- en: 'The following code block creates two different DataFrames, one for the data
    between `2011-03-01 00:00:00.054000` and `2011-06-01 00:00:00.054000`, the second
    one for the data between `2011-06-01 00:00:00.054000` and `2011-12-01 00:00:00.054000`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块创建了两个不同的DataFrame，一个用于`2011-03-01 00:00:00.054000`和`2011-06-01 00:00:00.054000`之间的数据，第二个用于`2011-06-01
    00:00:00.054000`和`2011-12-01 00:00:00.054000`之间的数据：
- en: '[PRE25]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The next step is to generate RFM features from the 3 months DataFrame. The
    following code block generates RFM values for all customers:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是从3个月DataFrame中生成RFM特征。以下代码块为所有客户生成RFM值：
- en: '[PRE26]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Now that we have generated RFM values for all the customers, the next step is
    to generate an R group, an F group, and an M group for each of the customers ranging
    from 0 to 3\. Once we have the RFM groups for the customers, they will be used
    to calculate the RFM score by summing the individual group values for the customer.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为所有客户生成了RFM值，下一步是为每个客户生成一个R组、一个F组和三个M组，范围从0到3。一旦我们有了客户的RFM组，它们将被用来通过累加客户各个组的单个值来计算RFM分数。
- en: 'The following code block generates RFM groups for the customers and calculates
    the RFM score:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码块为客户生成RFM组并计算RFM分数：
- en: '[PRE27]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: With the RFM score calculated, it is time to group customers into low-, mid-,
    and high-value customers.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RFM分数计算完成后，是时候将客户分为低价值、中价值和高价值客户了。
- en: 'The following code block groups customers into these groups:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块将这些客户分组到这些组中：
- en: '[PRE28]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now we have the RFM features ready. Let's keep those aside and calculate the
    revenue using the 6-month DataFrame that was created in an earlier step.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了RFM特征，让我们先把这些放一边，并使用之前步骤中创建的6个月DataFrame来计算收入。
- en: 'The following code block calculates the revenue from every customer in the
    6-months dataset:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块计算6个月数据集中每个客户的收入：
- en: '[PRE29]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The next step is to merge the 6-months dataset with revenue into the RFM features
    DataFrame. The following code block merges both the DataFrames in the `CustomerId`
    column:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是将6个月数据集与收入合并到RFM特征DataFrame中。以下代码块在`CustomerId`列中合并了两个DataFrame：
- en: '[PRE30]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Since we are treating the problem as a classification problem, let's generate
    the customer LTV labels to use the **k-means** clustering algorithm. Here, we
    will be using the 6-months revenue to generate the labels. Customers will be grouped
    into three groups, namely **LowLTV**, **MidLTV**, and **HighLTV**.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们将问题视为一个分类问题，让我们生成客户LTV标签以使用**k-means**聚类算法。在这里，我们将使用6个月的收入来生成标签。客户将被分为三个组，即**LowLTV**、**MidLTV**和**HighLTV**。
- en: 'The following code block generates the LTV groups for the customers:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块为客户生成LTV组：
- en: '[PRE31]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now we have the final dataset, let''s look at what the feature set that we
    have generated looks like. The following code block converts categorical values
    into integer values:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了最终的数据库，让我们看看我们生成的特征集是什么样的。以下代码块将分类值转换为整数值：
- en: '[PRE32]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding code block produces the following feature set:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块生成了以下特征集：
- en: '![](img/B18024_04_21.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18024_04_21.jpg)'
- en: Figure 4.21 – Final feature set for the model
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.21 – 模型的最终特征集
- en: In [*Chapter 1*](B18024_01_ePub.xhtml#_idTextAnchor014), *An Overview of the
    Machine Learning Life Cycle*, the next step that was performed was model training
    and scoring. This is where we'll diverge from that. I am assuming this will be
    our final feature set. However, during the model development, the feature set
    evolves over time. We will discuss how to handle these changes in later chapters.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第1章*](B18024_01_ePub.xhtml#_idTextAnchor014)，*机器学习生命周期概述*中，接下来执行的操作是模型训练和评分。这就是我们将与之分道扬镳的地方。我假设这将是我们最终的特征集。然而，在模型开发过程中，特征集会随着时间的推移而演变。我们将在后面的章节中讨论如何处理这些变化。
- en: Now that we have a feature set, the next thing is to create entities and feature
    views in Feast.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了特征集，下一步就是在Feast中创建实体和功能视图。
- en: Creating entities and feature views
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建实体和功能视图
- en: 'In the previous chapter, [*Chapter 3*](B18024_03_ePub.xhtml#_idTextAnchor050),
    *Feature Store Fundamentals, Terminology, and Usage*, we defined **entities**
    and **feature views**. An entity is defined as a collection of semantically related
    features. Entities are domain objects to which features can be mapped. A feature
    view is defined as feature view is like a database table. It represents the structure
    of the feature data at its source. A feature view consists of entities, one or
    more features, and a data source. A feature view is generally modeled around a
    domain object similar to database objects. Since creating and applying a feature
    definition is a one-time activity, it is better to keep it in a separate notebook
    or Python file. Here is a link to the notebook:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章[*第3章*](B18024_03_ePub.xhtml#_idTextAnchor050)，*特征存储基础、术语和用法*中，我们定义了**实体**和**功能视图**。实体被定义为语义相关的特征集合。实体是特征可以映射到的域对象。功能视图被定义为类似于数据库表的视图。它表示特征数据在其源处的结构。功能视图由实体、一个或多个特征和一个数据源组成。功能视图通常围绕类似于数据库对象的域对象进行建模。由于创建和应用特征定义是一项一次性活动，因此最好将其保存在单独的笔记本或Python文件中。以下是笔记本的链接：
- en: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb
    )'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb)'
- en: 'Let''s open a notebook, install the libraries, and clone the feature repository
    as mentioned before:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开一个笔记本，安装库，并像之前提到的那样克隆功能仓库：
- en: '[PRE33]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now that we have cloned the feature repository, let''s create the entity and
    feature views. Going by the definition of entity and feature views, the job is
    to identify the entities, features, and feature views in the feature set in *Figure
    4.21*. Let''s start with the entities. The only domain object that can be found
    in *Figure 4.21* is `customerid`:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经克隆了功能仓库，让我们创建实体和功能视图。根据实体和功能视图的定义，任务是识别*图4.21*中的功能集中的实体、特征和功能视图。让我们从实体开始。在*图4.21*中可以找到的唯一域对象是`customerid`：
- en: 'Let''s start by defining the customer entity. The following code block defines
    the customer entity for Feast:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们先定义客户实体。以下代码块定义了Feast中的客户实体：
- en: '[PRE35]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The preceding entity definition has a few required attributes, such as `name`,
    `value_type`, and `join_key`, and others are optional. There are additional attributes
    that can be added if the users want to provide more information. The most important
    attribute is `join_key`. The value of this attribute should match the column name
    in the feature DataFrame.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 上述实体定义有几个必需的属性，例如`name`、`value_type`和`join_key`，其他属性是可选的。如果用户想提供更多信息，还可以添加其他属性。最重要的属性是`join_key`。此属性的值应与特征DataFrame中的列名匹配。
- en: We have figured out the entity in the feature set. The next job is to define
    the feature views. Before we define feature views, a thing to keep in mind is
    to define the feature views as if you are a consumer who didn't generate the feature
    set. What I mean by that is do not name the feature views `customer_segmentation_features`
    or `LTV_features` and push all of them to a single table. Always try to break
    them into logical groups that are meaningful when other data scientists browse
    through them.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定了特征集中的实体。接下来的任务是定义特征视图。在我们定义特征视图之前，需要注意的一点是，要像没有生成特征集的消费者一样定义特征视图。我的意思是不要将特征视图命名为
    `customer_segmentation_features` 或 `LTV_features` 并将它们全部推送到一个表中。始终尝试将它们分成其他数据科学家浏览时有意义的逻辑组。
- en: With that in mind, let's look at the feature set and decide how many logical
    groups can be formed here and what features go into what groups. From *Figure
    4.21*, it can be grouped into either one or two groups. The two groups I see are
    RFM features for the customers and revenue features. Since RFM also has revenue
    details, I would rather group them into one group instead of two as there are
    no clear subgroups here. I will call it `customer_rfm_features`.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们查看特征集并决定可以形成多少个逻辑组以及哪些特征属于哪个组。从 *图 4.21* 可以看到，它可以分为一组或两组。我看到的两组是客户的
    RFM 特征和收入特征。由于 RFM 也包含收入细节，我更愿意将它们分为一组而不是两组，因为没有明显的子组。我将称之为 `customer_rfm_features`。
- en: 'The following code block defines the feature view:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块定义了特征视图：
- en: '[PRE36]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The preceding code block has two definitions. The first one is the batch source
    definition. Depending on the offline store that is being used, the definition
    of the batch source differs. In the previous chapter, we used `FileSource` in
    the example. Since we are using Redshift to query the offline store, `RedshiftSource`
    has been defined. The input to the object is query, which is a simple `SELECT`
    statement. The source can be configured to have complex SQL queries with joins,
    aggregation, and more. However, the output should match the column names defined
    in `FeatureView`. The other input to the source is `created_timestamp_column`
    and `event_timestamp_column`. These columns are missing in *Figure 4.21*. The
    columns represent what their headings state, the time when the event occurred,
    and when the event was created. These columns need to be added to the data before
    we ingest it.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块有两个定义。第一个是批源定义。根据所使用的离线存储，批源的定义不同。在上一章的例子中，我们使用了 `FileSource`。由于我们使用 Redshift
    查询离线存储，因此定义了 `RedshiftSource`。对象输入是查询，这是一个简单的 `SELECT` 语句。源可以配置为具有复杂的 SQL 查询，包括连接、聚合等。然而，输出应与
    `FeatureView` 中定义的列名匹配。源的其他输入是 `created_timestamp_column` 和 `event_timestamp_column`。这些列在
    *图 4.21* 中缺失。这些列代表它们的标题所表示的内容，即事件发生的时间和事件创建的时间。在我们摄取数据之前，需要将这些列添加到数据中。
- en: '`FeatureView` represents the table structure of the data at the source. As
    we looked at it in the last chapter, it has `entities`, `features`, and the `batch_source`.
    In *Figure 4.21*, the entity is `customer`, that was defined earlier. The rest
    of the columns are the features and the batch source, which is the `RedshiftSource`
    object. The feature name should match the column name and `dtype` should match
    the value type of the columns.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`FeatureView` 表示源数据的数据表结构。正如我们在上一章所看到的，它包含 `entities`、`features` 和 `batch_source`。在
    *图 4.21* 中，实体是 `customer`，这是之前定义的。其余的列是特征和批源，即 `RedshiftSource` 对象。特征名称应与列名匹配，`dtype`
    应与列的值类型匹配。'
- en: Now that we have the feature definition for our feature set, we must register
    the new definitions to be able to use them. To register the definitions, let's
    copy the entity and feature definitions into a Python file and add this file to
    our feature repository folder. I will be naming the file `rfm_features.py`. After
    adding the file to the repository, the folder structure looks like the following
    figure.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经有了特征集的特征定义，我们必须注册新的定义才能使用它们。为了注册定义，让我们将实体和特征定义复制到一个 Python 文件中，并将此文件添加到我们的特征仓库文件夹中。我将把这个文件命名为
    `rfm_features.py`。将文件添加到仓库后，文件夹结构如下所示。
- en: '![Figure 4.22 – Project with feature definitions file'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.22 – 包含特征定义文件的工程]'
- en: '](img/B18024_04_22.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18024_04_22.jpg](img/B18024_04_22.jpg)'
- en: Figure 4.22 – Project with feature definitions file
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.22 – 包含特征定义文件的工程
- en: Before registering the definition using the `apply` command, let's map the external
    schema on Redshift.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 `apply` 命令注册定义之前，让我们将外部模式映射到 Redshift 上。
- en: Creating an external catalog
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建外部目录
- en: If you recall correctly, during the Redshift resource creation, I mentioned
    that the data in Amazon S3 will be added as an external mapping using Glue/Lake
    Formation. What that means is data will not be ingested into Redshift directly;
    instead, the dataset will be in S3\. The structure of the dataset will be defined
    in the Lake Formation catalog, which you will see in a moment. Then, the database
    will be mapped as an external schema on Redshift. Hence, the ingestion will push
    data into S3 directly and the query will be executed using the Redshift cluster.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您记得正确，在创建 Redshift 资源期间，我提到将使用 Glue/Lake Formation 将 Amazon S3 中的数据添加为外部映射。这意味着数据不会直接被摄入
    Redshift；相反，数据集将位于 S3 中。数据集的结构将在 Lake Formation 目录中定义，您稍后将看到。然后，数据库将作为外部模式映射到
    Redshift 上。因此，摄入将直接将数据推入 S3，查询将使用 Redshift 集群执行。
- en: 'Now that we understand the workings of ingestion and querying, let''s create
    the database and catalog for our feature set in Lake Formation:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了摄入和查询的工作原理，让我们在 Lake Formation 中创建我们的功能集的数据库和目录：
- en: 'To create a database, visit the AWS Lake Formation page via a search or using
    this URL: https://console.aws.amazon.com/lakeformation/home?region=us-east-1#databases.'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建数据库，请通过搜索或使用此网址访问 AWS Lake Formation 页面：https://console.aws.amazon.com/lakeformation/home?region=us-east-1#databases。
- en: '![Figure 4.23 – Databases in AWS Lake Formation'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.23 – AWS Lake Formation 中的数据库'
- en: '](img/B18024_04_23.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_23.jpg)'
- en: Figure 4.23 – Databases in AWS Lake Formation
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.23 – AWS Lake Formation 中的数据库
- en: '*Figure 4.23* displays the list of databases in AWS Lake Formation.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.23* 显示了 AWS Lake Formation 中的数据库列表。'
- en: On the web page, click on **Create database**. The following web page will appear.
    If you see any popups in the transition, asking you to get started with Lake Formation,
    it can either be canceled or accepted.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页上，点击 **创建数据库**。将出现以下网页。如果在过渡过程中看到任何弹出窗口，要求您开始使用 Lake Formation，可以取消或接受。
- en: '![Figure 4.24 – Lake formation Create database'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.24 – 湖区形成创建数据库'
- en: '](img/B18024_04_24.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_24.jpg)'
- en: Figure 4.24 – Lake formation Create database
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.24 – 湖区形成创建数据库
- en: From the web page displayed above, give the database a name. I am calling it
    `dev`. Leave everything else as the default and click on **Create database**.
    The database will be created, and it will redirect to the database details page.
    As databases are groupings of tables together, you can think of this database
    as a grouping for all the feature views in the project. Once you have the database,
    the next step is to create the table. As you might have already realized, the
    table we create here corresponds to the feature view. In the current exercise,
    there is just one feature view. Hence, a corresponding table needs to be created.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上面显示的网页中，给数据库起一个名字。我将其命名为 `dev`。保留所有其他默认设置并点击 **创建数据库**。数据库将被创建，并将重定向到数据库详情页面。由于数据库是表的集合，您可以将此数据库视为项目中所有功能视图的集合。一旦您有了数据库，下一步就是创建表。如您所意识到的那样，我们在这里创建的表对应于功能视图。在当前练习中只有一个功能视图。因此，需要创建相应的表。
- en: Note
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: As and when you add a new feature view, a corresponding table needs to be added
    to the database in Lake Formation.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每当您添加一个新的功能视图时，都需要在 Lake Formation 的数据库中添加相应的表。
- en: 'To create a table in the database, click on **Tables** from the page in *Figure
    4.23* or visit this URL: [https://console.aws.amazon.com/lakeformation/home?region=us-east-1#tables.](https://console.aws.amazon.com/lakeformation/home?region=us-east-1#tables
    )'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在数据库中创建表，请从 *图 4.23* 页面点击 **表** 或访问此网址：[https://console.aws.amazon.com/lakeformation/home?region=us-east-1#tables.](https://console.aws.amazon.com/lakeformation/home?region=us-east-1#tables
    )
- en: '![Figure 4.25 – Lake Formation tables'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.25 – 湖区形成表'
- en: '](img/B18024_04_25.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_25.jpg)'
- en: Figure 4.25 – Lake Formation tables
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.25 – 湖区形成表
- en: 'From the web page in *Figure 4.25*, click on the **Create table** button at
    the top right. The following web page will be displayed:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 *图 4.25* 的网页中，点击右上角的 **创建表** 按钮。将显示以下网页：
- en: '![Figure 4.26 – Lake Formation Create table 1'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.26 – 湖区形成创建表 1'
- en: '](img/B18024_04_26.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_26.jpg)'
- en: Figure 4.26 – Lake Formation Create table 1
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.26 – 湖区形成创建表 1
- en: For the `customer_rfm_features` and I have selected the database that was created
    earlier (`dev`). A description is optional. Once these details are filled in,
    scroll down. The following options will be seen in the next part of the **Create
    table** page.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 `customer_rfm_features`，我已经选择了之前创建的数据库（`dev`）。描述是可选的。一旦填写了这些详细信息，向下滚动。在 **创建表**
    页面的下一部分将看到以下选项。
- en: '![Figure 4.27 – Lake Formation Create table 2'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.27 – 湖的形成 创建表 2'
- en: '](img/B18024_04_27.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_27.jpg)'
- en: Figure 4.27 – Lake Formation Create table 2
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.27 – 湖的形成 创建表 2
- en: The data store is one of the important properties here. It stands for the location
    of data in S3\. So far, we haven't pushed any data to S3 yet. We will be doing
    that soon. Let's define where data for this table will be pushed to. I am going
    to use the S3 bucket we created earlier, hence the location will be `s3://feast-demo-mar-2022/customer-rfm-features/`.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据存储是这里的一个重要属性。它代表 S3 中数据的位置。到目前为止，我们还没有将任何数据推送到 S3。我们很快就会这么做。让我们定义这个表的数据将推送到哪里。我将使用我们之前创建的
    S3 存储桶，因此位置将是 `s3://feast-demo-mar-2022/customer-rfm-features/`。
- en: Important Note
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: Create the `customer-rfm-features` folder in the S3 path.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 S3 路径中创建 `customer-rfm-features` 文件夹。
- en: After selecting the S3 path, scroll down to the last part of the page – the
    following options will be displayed.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 S3 路径后，向下滚动到页面最后部分 – 将显示以下选项。
- en: '![Figure 4.28 – Lake Formation Create table 3'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.28 – 湖的形成 创建表 3'
- en: '](img/B18024_04_28.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_28.jpg)'
- en: Figure 4.28 – Lake Formation Create table 3
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.28 – 湖的形成 创建表 3
- en: '*Figure 4.28* shows the last part of the table creation. The **Data format**
    section is asking for the file format of the data. We will be selecting **PARQUET**
    for this exercise. Feel free to experiment with others. Whatever format is selected
    here, all the ingested data files should be of the same format, else it might
    not work as expected.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.28* 展示了创建表的最后部分。**数据格式** 部分要求输入数据的文件格式。在这个练习中，我们将选择 **PARQUET**。您可以自由尝试其他格式。无论选择哪种格式，所有导入的数据文件都应该具有相同的格式，否则可能无法按预期工作。'
- en: 'The last section is the **Schema** definition of the dataset. You can either
    click on the **Add column** button and add the columns individually or can click
    on the **Upload Schema** button to upload a JSON defining all the columns at once.
    Let''s use the **Add column** button and add all the columns in order. Once all
    the columns are added along with the data types, the columns should look like
    the following:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个部分是数据集的 **模式** 定义。您可以选择点击 **添加列** 按钮并逐个添加列，或者点击 **上传模式** 按钮一次性上传一个定义所有列的
    JSON 文件。让我们使用 **添加列** 按钮并按顺序添加所有列。一旦添加了所有列以及数据类型，列应该看起来像以下这样：
- en: '![Figure 4.29 – Column list in Create table'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.29 – 创建表中的列列表'
- en: '](img/B18024_04_29.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_29.jpg)'
- en: Figure 4.29 – Column list in Create table
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.29 – 创建表中的列列表
- en: 'As can be seen from *Figure 4.29*, all the columns have been added, along with
    the entity `customerid` and the two timestamp columns: `event_timestamp` and `created_timestamp`.
    Once the columns are added, click on the **Submit** button at the bottom.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 4.29* 所示，所有列都已添加，包括实体 `customerid` 和两个时间戳列：`event_timestamp` 和 `created_timestamp`。一旦添加了列，点击底部的
    **提交** 按钮。
- en: Now, the only thing that is pending is to map this table in the Redshift cluster
    that has been created. Let's do that next. To create the mapping of the external
    schema, visit the Redshift cluster page and select the cluster that was created
    earlier. A web page similar to the one in *Figure 4.30* will be displayed.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，唯一待办的事情是将此表映射到已创建的 Redshift 集群。让我们接下来这么做。要创建外部模式的映射，请访问 Redshift 集群页面并选择之前创建的集群。将显示一个类似于
    *图 4.30* 的网页。
- en: '![Figure 4.30 – Redshift cluster details page'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.30 – Redshift 集群详情页'
- en: '](img/B18024_04_30.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_30.jpg)'
- en: Figure 4.30 – Redshift cluster details page
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.30 – Redshift 集群详情页
- en: 'From the web page displayed in *Figure 4.30*, click on **Query data** in the
    top right of the page. Among the options in the dropdown, pick **Query in query
    editor v2**. It will open up a query editor as shown in the following figure:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *图 4.30* 显示的网页上，点击页面右上角的 **查询数据**。在下拉菜单中的选项中，选择 **查询编辑器 v2**。它将打开一个查询编辑器，如图下所示：
- en: '![Figure 4.31 – Redshift query editor v2'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.31 – Redshift 查询编辑器 v2'
- en: '](img/B18024_04_31.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_31.jpg)'
- en: Figure 4.31 – Redshift query editor v2
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.31 – Redshift 查询编辑器 v2
- en: 'Select the cluster from the left panel and also the database if not selected
    by default. In the query editor shown in *Figure 4.31*, run the following query
    to map the external database into a schema called `spectrum`:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板选择集群，如果默认未选择，也选择数据库。在*图4.31*中显示的查询编辑器中运行以下查询，将外部数据库映射到名为`spectrum`的模式：
- en: '[PRE37]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In the preceding code block, replace `<redshift_role_arn>` with the **ARN**
    of the role that was created and associated with Redshift. The ARN can be found
    in the IAM console on the role details page, similar to the one in *Figure 4.32*.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的代码块中，将`<redshift_role_arn>`替换为与Redshift创建并关联的角色**ARN**。该ARN可以在IAM控制台的“角色详情”页面找到，类似于*图4.32*中的那个。
- en: '![Figure 4.32 – IAM role details page'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.32 – IAM角色详情页面]'
- en: '](img/B18024_04_32.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18024_04_32.jpg]'
- en: Figure 4.32 – IAM role details page
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.32 – IAM角色详情页面
- en: On successful execution of the query, you should be able to see the output `spectrum`
    schema under the database after refreshing the page as shown in *Figure 4.33*.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 查询成功执行后，你应该能够在刷新页面后看到*图4.33*中显示的数据库下的`spectrum`模式输出。
- en: '![Figure 4.33 – Redshift spectrum schema'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.33 – Redshift spectrum模式]'
- en: '](img/B18024_04_33.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18024_04_33.jpg]'
- en: Figure 4.33 – Redshift spectrum schema
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.33 – Redshift spectrum模式
- en: 'You can also verify the mapping by executing the following SQL `SELECT` query:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你也可以通过执行以下SQL `SELECT`查询来验证映射：
- en: '[PRE38]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The preceding SQL query will return an empty table in the result as the data
    is not ingested yet.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的SQL查询将返回一个空表作为结果，因为数据尚未摄取。
- en: We have completed the mapping of the external table now. All we are left with
    is to apply the feature set and ingest the data. Let's do that next.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完成了外部表的映射。我们现在剩下的是应用特征集并摄取数据。让我们接下来做这件事。
- en: Important Note
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It might seem like a lot of work to add a feature store in an ML pipeline, however,
    that is not true. Since we are doing it for the first time, it just seems like
    that. Also, all the steps from resource creation to mapping the external table
    can be automated using infrastructure as code. Here is a link to an example that
    automates infrastructure creation ([https://github.com/feast-dev/feast-aws-credit-scoring-tutorial](https://github.com/feast-dev/feast-aws-credit-scoring-tutorial)).
    Apart from that, if you use managed feature stores such as Tecton, SageMaker,
    or Databricks, the infrastructure is managed and all you will have to do is to
    create features, ingest them, and use them without worrying about the infrastructure.
    We will do a comparison of Feast with other feature stores in [*Chapter 7*](B18024_07_ePub.xhtml#_idTextAnchor113),
    *Feast Alternatives and ML Best Practices*.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习管道中添加特征存储可能看起来工作量很大，然而，这并不正确。由于我们这是第一次做，所以感觉是这样。此外，从资源创建到映射外部表的所有步骤都可以使用基础设施即代码来自动化。这里有一个自动化基础设施创建的示例链接（[https://github.com/feast-dev/feast-aws-credit-scoring-tutorial](https://github.com/feast-dev/feast-aws-credit-scoring-tutorial)）。除此之外，如果你使用像Tecton、SageMaker或Databricks这样的托管特征存储，基础设施将由它们管理，你所要做的就是创建特征、摄取它们并使用它们，无需担心基础设施。我们将在[*第7章*](B18024_07_ePub.xhtml#_idTextAnchor113)，“费曼替代方案和机器学习最佳实践”中比较Feast与其他特征存储。
- en: Applying definitions and ingesting data
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用定义和摄取数据
- en: So far, we have performed data cleaning, feature engineering, defined the entities
    and feature definitions, and also created and mapped the external table to Redshift.
    Now, let's apply the feature definitions and ingest the data. Continue in the
    same notebook that we created in the *Creating entities and feature views* section
    ([https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb)).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经执行了数据清洗、特征工程、定义实体和特征定义，并且还创建了映射到Redshift的外部表。现在，让我们应用特征定义并摄取数据。继续在*创建实体和特征视图*部分中我们创建的同一个笔记本中（[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb)）。
- en: 'To apply a feature set, we need the IAM user credentials that was created earlier.
    Recall that, during the creation of the IAM user, the credential files were available
    for download. The file contains `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.
    Once you have it handy, replace `<aws_key_id>` and `<aws_secret>` in the following
    code block:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用特征集，我们需要之前创建的 IAM 用户凭据。回想一下，在创建 IAM 用户期间，凭据文件可供下载。该文件包含 `AWS_ACCESS_KEY_ID`
    和 `AWS_SECRET_ACCESS_KEY`。一旦您手头有了这些信息，请将以下代码块中的 `<aws_key_id>` 和 `<aws_secret>`
    替换为：
- en: '[PRE39]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Important Note
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It is never a good idea to set the credentials in the notebook as a raw string.
    Depending on the tools that are available to the user, it is a good practice to
    use a secret manager to store secrets.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中直接设置凭据不是一个好主意。根据用户可用的工具，使用密钥管理器存储密钥是一个好的实践。
- en: 'After setting the environment variable, all you have to do is to run the following
    code block to apply the defined feature set:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 设置环境变量后，您只需运行以下代码块来应用定义的特征集：
- en: '[PRE43]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The preceding code block registers the new feature definitions and also creates
    the AWS DynamoDB tables for all the feature views in the definition. The output
    of the preceding code block is displayed in *Figure 4.34*.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块注册了新的特征定义，并为定义中的所有特征视图创建了 AWS DynamoDB 表。前面代码块的输出显示在 *图 4.34* 中。
- en: '![Figure 4.34 – Feast apply output'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.34 – Feast 应用输出'
- en: '](img/B18024_04_34.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_34.jpg)'
- en: Figure 4.34 – Feast apply output
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.34 – Feast 应用输出
- en: To verify that DynamoDB tables are created for the feature views, navigate to
    the DynamoDB console, using the search or visit https://console.aws.amazon.com/dynamodbv2/home?region=us-east-1#tables.
    You should see the `customer_rfm_features` table as shown in *Figure 4.35*.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证是否为特征视图创建了 DynamoDB 表，请导航到 DynamoDB 控制台，使用搜索或访问 https://console.aws.amazon.com/dynamodbv2/home?region=us-east-1#tables。您应该看到如
    *图 4.35* 所示的 `customer_rfm_features` 表。
- en: '![Figure 4.35 – DynamoDB tables'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.35 – DynamoDB 表'
- en: '](img/B18024_04_35.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_35.jpg)'
- en: Figure 4.35 – DynamoDB tables
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.35 – DynamoDB 表
- en: Now that feature definitions have been applied, to ingest the feature data,
    let's pick up the feature engineering notebook created in the *Model (feature
    engineering)* section ([https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb))
    and continue in that (the last command of feature engineering produced *Figure
    4.21*). To ingest the data, the only thing we have to do is write the features
    DataFrame to the S3 location that is mapped in *Figure 4.28*. I mapped the data
    store location as `s3://feast-demo-mar-2022/customer-rfm-features/`. Let's write
    the DataFrame to the location as Parquet.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经应用了特征定义，为了导入特征数据，让我们选取在 *模型（特征工程）* 部分创建的特征工程笔记本（[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_feature_engineering.ipynb)）并继续在该笔记本中（特征工程的最后一个命令生成了
    *图 4.21*）。为了导入数据，我们唯一要做的就是将特征 DataFrame 写入到 *图 4.28* 中映射的 S3 位置。我已经将数据存储位置映射为
    `s3://feast-demo-mar-2022/customer-rfm-features/`。让我们将 DataFrame 写入到该位置，格式为 Parquet。
- en: 'The following code block ingests the data in the S3 location:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块从 S3 位置导入数据：
- en: '[PRE45]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The preceding code block sets the AWS credentials of the IAM user, adds the
    missing columns, `event_timestamp` and `created_timestamp`, and finally writes
    the Parquet file to the S3 location. To verify that the file is written successfully,
    navigate to the S3 location and verify that the file exists. To make sure that
    the file is in the correct format, let''s navigate to the Redshift query editor
    in *Figure 4.32* and run the following query:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块设置了 IAM 用户的 AWS 凭据，添加了缺失的列 `event_timestamp` 和 `created_timestamp`，并将
    Parquet 文件写入到 S3 位置。为了验证文件已成功写入，请导航到 S3 位置并验证文件是否存在。为了确保文件格式正确，让我们导航到 *图 4.32*
    中的 Redshift 查询编辑器并运行以下查询：
- en: '[PRE55]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The preceding command should result in success, with the output as shown in
    *Figure 4.36*.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令应该成功执行，输出结果如 *图 4.36* 所示。
- en: '![Figure 4.36 – Redshift query after ingesting the data'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.36 – 数据导入后的红移查询'
- en: '](img/B18024_04_36.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_36.jpg)'
- en: Figure 4.36 – Redshift query after ingesting the data
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.36 – 数据导入后的红移查询
- en: Before we move on to the next stage of ML, let's just run a couple of APIs,
    look at what our feature repository looks like, and verify that the query to the
    historical store works okay. For the following code, let's use the notebook we
    used to create and apply feature definitions ([https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb)).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入 ML 的下一阶段之前，让我们运行几个 API，看看我们的特征存储库是什么样子，并验证对历史存储的查询是否正常。对于以下代码，让我们使用我们创建和应用特征定义的笔记本（[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/blob/main/Chapter04/ch4_create_apply_feature_definitions.ipynb))。
- en: 'The following code connects to the feature store and lists the available entities
    and feature views:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码连接到特征存储并列出可用的实体和特征视图：
- en: '[PRE56]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The preceding code block prints the `customer` entity and `customer_rfm_features`
    feature view. Let's query the offline store for a few entities and see if it works
    as expected.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码块打印了 `customer` 实体和 `customer_rfm_features` 特征视图。让我们查询离线存储中的几个实体，看看它是否按预期工作。
- en: 'To query offline data, we need entity IDs and timestamp columns. The entity
    ID column is a list of customer IDs and the timestamp column is used for performing
    point-in-time join queries on the dataset. The following code creates an entity
    DataFrame for the query:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 要查询离线数据，我们需要实体 ID 和时间戳列。实体 ID 列是客户 ID 的列表，时间戳列用于在数据集上执行点时间连接查询。以下代码为查询创建了一个实体
    DataFrame：
- en: '[PRE66]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: The preceding code block produces an entity DataFrame like the one in *Figure
    4.37*.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码块生成了一个类似于 *图 4.37* 中的实体 DataFrame。
- en: '![Figure 4.37 – Entity DataFrame'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.37 – 实体 DataFrame'
- en: '](img/B18024_04_37.jpg)'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_37.jpg)'
- en: Figure 4.37 – Entity DataFrame
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.37 – 实体 DataFrame
- en: 'With the sample entity DataFrame, let''s query the historical data. The following
    code fetches a subset of features from the historical store:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 使用示例实体 DataFrame，让我们查询历史数据。以下代码从历史存储中获取特征子集：
- en: '[PRE75]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The following code block may take a couple of minutes to run but finally outputs
    the following results:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块可能需要几分钟才能运行，但最终输出以下结果：
- en: '![Figure 4.38 – Historical retrieval job output'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.38 – 历史检索作业输出'
- en: '](img/B18024_04_38.jpg)'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_04_38.jpg)'
- en: Figure 4.38 – Historical retrieval job output
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.38 – 历史检索作业输出
- en: Now we can say that our feature engineering pipeline is ready. The next steps
    that are required are to train the model, perform validation, and, if happy with
    the performance of the model, deploy the pipeline into production. We will look
    at training, validation, deployment, and model scoring in the next chapter. Let's
    briefly summarize what we have learned next.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以说我们的特征工程流程已经准备好了。接下来需要进行的步骤是训练模型、执行验证，如果对模型的性能满意，则将流程部署到生产环境中。我们将在下一章中探讨训练、验证、部署和模型评分。接下来，让我们简要总结一下我们学到了什么。
- en: Summary
  id: totrans-376
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we started with the goal of adding the Feast feature store
    to our ML model development. We accomplished that by creating the required resources
    on AWS, adding an IAM user to access those resources. After creating the resources,
    we went through the steps of the ML life cycle again from the problem statement
    to feature engineering and feature ingestion. We also verified that created feature
    definitions and ingested data could be queried through the API.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们以将 Feast 特征存储添加到我们的 ML 模型开发为目标。我们通过在 AWS 上创建所需资源、添加 IAM 用户以访问这些资源来实现这一点。在创建资源后，我们再次从问题陈述到特征工程和特征摄取的
    ML 生命周期步骤进行了操作。我们还验证了创建的特征定义和摄取的数据可以通过 API 进行查询。
- en: Now that we have set the stage for the next steps of the ML life cycle – model
    training, validation, deployment, and scoring, in the next chapter, we will learn
    how the addition of the feature store right from the beginning makes the model
    production-ready when the development is complete.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经为 ML 生命周期的下一步——模型训练、验证、部署和评分——做好了准备，在下一章中，我们将学习从一开始就添加特征存储是如何使模型在开发完成后立即准备好生产的。
- en: References
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Feast documentation: [https://docs.feast.dev/](https://docs.feast.dev/)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feast 文档：[https://docs.feast.dev/](https://docs.feast.dev/)
- en: 'Credit scoring with Feast on AWS: [https://github.com/feast-dev/feast-aws-credit-scoring-tutorial](https://github.com/feast-dev/feast-aws-credit-scoring-tutorial)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AWS 上使用 Feast 进行信用评分：[https://github.com/feast-dev/feast-aws-credit-scoring-tutorial](https://github.com/feast-dev/feast-aws-credit-scoring-tutorial)
