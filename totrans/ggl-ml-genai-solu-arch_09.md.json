["```py\n    from sklearn.datasets import load_wine\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.decomposition import PCA\n    import matplotlib.pyplot as plt\n    import pandas as pd\n    # Load dataset\n    data = load_wine()\n    df = pd.DataFrame(data.data, columns=data.feature_names)\n    # Standardize the features\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    # Apply PCA\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n    principalDf = pd.DataFrame(data = principalComponents, \n        columns = ['principal component 1', \n            'principal component 2'])\n    # Visualize 2D Projection\n    plt.figure(figsize=(8,6))\n    plt.scatter(principalDf['principal component 1'], principalDf['principal component 2'], c=data.target)\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.show()\n    ```", "```py\ncomponents_df = pd.DataFrame(pca.components_, \n    columns=data.feature_names, index=['Component 1', 'Component 2'])\nprint(components_df)\n```", "```py\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n# Apply LDA\nlda = LDA(n_components=2)\nlda_components = lda.fit_transform(df, data.target)\nlda_df = pd.DataFrame(data = lda_components, \n    columns = ['LDA 1', 'LDA 2'])\n# Visualize 2D Projection\nplt.figure(figsize=(8,6))\nplt.scatter(lda_df['LDA 1'], lda_df['LDA 2'], c=data.target)\nplt.xlabel('LDA 1')\nplt.ylabel('LDA 2')\nplt.show()\n```", "```py\n# Create and print a DataFrame with the LDA coefficients and feature names\ncoef_df = pd.DataFrame(lda.coef_, columns=data.feature_names, \n    index=['Class 1 vs Rest', 'Class 2 vs Rest', 'Class 3 vs Rest'])\nprint(coef_df)\n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n# Load the data\ntitanic_raw = pd.read_csv('./data/titanic_train.csv')\ntitanic_raw.head()\n```", "```py\n# We first define a function to extract titles from passenger names\ndef get_title(name):\n    if '.' in name:\n        return name.split(',')[1].split('.')[0].strip()\n    else:\n        return 'Unknown'\n# Create a new \"Title\" feature\ntitanic['Title'] = titanic['Name'].apply(get_title)\n# Simplify the titles, merge less common titles into the same category\ntitanic['Title'] = titanic['Title'].replace(['Lady', 'Countess', \n    'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', \n    'Dona'], 'Distinguished')\ntitanic['Title'] = titanic['Title'].replace('Mlle', 'Miss')\ntitanic['Title'] = titanic['Title'].replace('Ms', 'Miss')\ntitanic['Title'] = titanic['Title'].replace('Mme', 'Mrs')\n```", "```py\n# Create \"CabinClass\" feature\ntitanic['CabinClass'] = titanic['Cabin'].apply(lambda x: x[0])\n```", "```py\ntitanic['FamilySize'] = titanic['SibSp'] + titanic['Parch'] + 1\n# Create \"FarePerPerson\" feature\ntitanic['FarePerPerson'] = titanic['Fare'] / titanic['FamilySize']\n```", "```py\n# Create new feature \"IsAlone\" from \"FamilySize\"\ntitanic['IsAlone'] = 0\ntitanic.loc[titanic['FamilySize'] == 1, 'IsAlone'] = 1\n```", "```py\n# Create \"AgeGroup\" feature\nbins = [0, 10, 20, 30, 40, 50, 60, 70, np.inf]\nlabels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', \n    '70+']\ntitanic['AgeGroup'] = pd.cut(titanic['Age'], bins=bins, labels=labels)\n```", "```py\n# Convert \"Title\" into numerical values using one-hot encoding\none_hot = OneHotEncoder()\ntitle_encoded = one_hot.fit_transform(titanic[['Title']]).toarray()\ntitle_encoded_df = pd.DataFrame(title_encoded, \n    columns=one_hot.get_feature_names_out(['Title']))\ntitanic = pd.concat([titanic, title_encoded_df], axis=1)\n```", "```py\ntitanic = titanic.drop(['name', 'ticket', 'Title', 'cabin', 'sex', \n    'embarked', 'AgeGroup', 'CabinClass', 'home.dest'], axis=1)\n```", "```py\ntitanic.head()\n```"]