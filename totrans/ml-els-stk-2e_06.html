<html><head></head><body>
		<div id="_idContainer093">
			<h1 id="_idParaDest-79"><em class="italic"><a id="_idTextAnchor081"/>Chapter 4</em>: Forecasting</h1>
			<p><strong class="bold">Forecasting</strong> is a natural extension of the time series modeling of Elastic ML. Since very expressive models are built behind the scenes and describe how data has behaved historically, it is therefore possible to project that information forward in time and predict how something should behave at a future time.</p>
			<p>We will spend time learning the concepts behind forecasting, as well as stepping through some practical examples.</p>
			<p>Specifically, this chapter will cover the following topics:</p>
			<ul>
				<li>Contrasting forecasting with prophesying</li>
				<li>Forecasting use cases</li>
				<li>Forecasting theory of operation</li>
				<li>Single time series forecasting</li>
				<li>Looking at forecasting results</li>
				<li>Multiple time series forecasting</li>
			</ul>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor082"/>Technical requirements</h1>
			<p>The information and examples demonstrated in this chapter are relevant as of v7.11 of the Elastic Stack. </p>
			<h1 id="_idParaDest-81"><a id="_idTextAnchor083"/>Contrasting forecasting with prophesying</h1>
			<p><em class="italic">Past performance is not indicative of future results.</em> This disclaimer is used by financial <a id="_idIndexMarker263"/>companies when they reference the <a id="_idIndexMarker264"/>performance of products such as mutual funds. But this disclaimer is a bit of an odd contradiction, because the past is all that we have to work with. If the companies that comprise the mutual fund have had consistently positive quarterly results for the last eight quarters straight, does that guarantee that they will also have a positive set of results for the next eight quarters and that their public valuation will continue to rise? Probability could be on the side of that being the case, but that might not be the whole story. And, before we get too wishful in thinking that Elastic ML’s ability to forecast is our key to making a fortune in the stock market, we should be realistic about one key caveat—there are always uncontrollable factors.</p>
			<p>The reason financial companies use the preceding disclaimer is that there are often unknown, uncontrollable factors that emerge and that can be very influential on the trajectory of something. For example, the government could change regulations or trade policies that greatly help or hinder a company’s ability to operate and be profitable, or there could be an internal fraudulent accounting scandal in which the executives conspired to falsify corporate performance, which becomes untenable to maintain and ultimately bankrupts the company.</p>
			<p>These factors are<a id="_idIndexMarker265"/> deemed unknown and external <a id="_idIndexMarker266"/>because of the following reasons:</p>
			<ul>
				<li>They are outside of the control of the entity itself (as in the example of the government dictating policies independently of a company’s activities).</li>
				<li>They are hidden from the available information about a system (an outside investor, in real time, only has access to publicly available performance reports, and not to knowledge of fraudulent activities that may be fabricating those performance reports).</li>
			</ul>
			<p>As such, predictions are only as good as the information you have and your ability to eliminate or mitigate external unknown factors that will affect your prediction. The same is true in the world of <strong class="bold">Information Technology</strong> (<strong class="bold">IT</strong>) data. It’s not always possible to predict a trend<a id="_idIndexMarker267"/> or a failure if an unknown, external factor is at play (someone incorrectly making a configuration change, a failing piece of hardware, and so on). However, we can use probabilistic analysis to give us our best guess at the future, aside from those possible external factors. Understanding this caveat allows us to satisfy some good forecasting use cases without getting hung up on the expectation of prophecy. Let’s now turn our focus to how we can use forecasting in a practical way.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor084"/>Forecasting use cases</h1>
			<p>In the context of Elastic <a id="_idIndexMarker268"/>ML, there are really just two—somewhat similar—use cases in which someone would use forecasting. These are outlined here:</p>
			<ul>
				<li><strong class="bold">Value-focused</strong>: This<a id="_idIndexMarker269"/> is where you extrapolate a time series into the future to understand a probable future value. This would be akin to answering questions such as: <em class="italic">“How many widgets will I sell per day 2 months from now?”</em></li>
				<li><strong class="bold">Time-focused</strong>: This<a id="_idIndexMarker270"/> is where you understand the likely time at which an expected value is to be reached. This would answer questions similar to: <em class="italic">“Do I expect to reach 80% utilization in the next week?”</em></li>
			</ul>
			<p>The differences between these two use cases might not just be how a question is asked (how the data is searched), but also how you interpret the output. However, before we delve into a few examples of how to use the forecasting feature, let’s take a little time to discuss how it works logistically.</p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor085"/>Forecasting theory of operation</h1>
			<p>The first thing<a id="_idIndexMarker271"/> to<a id="_idIndexMarker272"/> realize is that the act of invoking a forecast on data is that it is an extension of an existing Anomaly Detection job. In other words, you need to have an Anomaly Detection job configured, and that job needs to have analyzed historical data before you can forecast on that data. This is because the forecasting process uses the models that are created by the Anomaly Detection job. To forecast the data, you need to follow the same steps that were used to create an Anomaly Detection job as described in other chapters. If anomalies were generated by the execution of that job, you can disregard them if your only purpose is to execute forecasting. Once the job has learned on some historical data, the model or models (if the job is configured to analyze data from more than one time series) associated with that job are current and up to date, as represented in the following diagram:</p>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B17040_04_1.jpg" alt="Figure 4.1 – A symbolic representation of models gleaned from historical learning&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – A symbolic representation of models gleaned from historical learning</p>
			<p>We’ll consider <a id="_idIndexMarker273"/>the<a id="_idIndexMarker274"/> time before <strong class="bold">now</strong> as <strong class="bold">historical learning</strong>—the<a id="_idIndexMarker275"/> time over which the models have learned on actual data. When the user wishes to invoke a forecast at a particular time, a copy of the model(s) is created, and a separate process is used to take those models and extrapolate them into the “future.” This process is run in parallel to not interfere with the original models and their evolution. This is represented in the following diagram:</p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B17040_04_2.jpg" alt="Figure 4.2 – A symbolic representation of models copied for forecasting into the future&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – A symbolic representation of models copied for forecasting into the future</p>
			<p>The<a id="_idIndexMarker276"/> forecast <a id="_idIndexMarker277"/>values are written to the same results index as Anomaly Detection but as a special type of result (more detail on this later), and will<a id="_idIndexMarker278"/> be available for viewing in the <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>) or <a id="_idIndexMarker279"/>accessible via the <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>).</p>
			<p>It’s important to note that the <a id="_idIndexMarker280"/>normal path of the <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) job analyzing the actual real data will continue (if it is running in real time), and therefore after an amount of time there could be a difference between the predicted value for a future time (made at the time of the forecast) and the actual value when that time arrives, as shown in the following diagram: </p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B17040_04_3.jpg" alt="Figure 4.3 – A symbolic representation of a forecasting error&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – A symbolic representation of a forecasting error</p>
			<p>This forecasting <a id="_idIndexMarker281"/>error is to be expected, but hopefully it will be <a id="_idIndexMarker282"/>minimal. The differential between the two is not currently used by Elastic ML, but perhaps in the future it could inform the models about more accurate subsequent forecasts. Surely it is also possible that an unknown external factor (as described earlier) could lead to a certain number of forecasting errors. </p>
			<p>Another (perhaps simpler) way to think about uncertainty in predictions is to think about predicting the outcome of a coin toss. You could observe a sequence of prior coin flips, but if you are not taking into account the physics of the coin flip (speed, height, rotations, and so on) and are only relying on the outcome of past observations, then you’ll never get better than a 50/50 prediction on the outcome. Additionally, it is likely Elastic ML didn’t see behaviorally perfectly consistent data during the learning period. As such, with a certain amount of noise in the data, we should also expect a certain amount of variation or uncertainty in the forecast.</p>
			<p>There can also be multiple forecasts made by the user at other times. These will be stored separately, as represented in the following diagram:</p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B17040_04_4.jpg" alt="Figure 4.4 – A symbolic representation of invoking multiple forecasts at different times&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – A symbolic representation of invoking multiple forecasts at different times</p>
			<p>The distinction<a id="_idIndexMarker283"/> between <strong class="bold">forecast #1</strong> and <strong class="bold">forecast #2</strong> will be keyed <a id="_idIndexMarker284"/>off with an internal unique ID for each forecast instance. This will become apparent later when we look at how the forecast results are stored in the index.</p>
			<p>Now that we have a base understanding of the logistical operation of the forecasting process, let’s walk through an example of how to use Elastic ML for forecasting on a single time series.</p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor086"/>Single time series forecasting</h1>
			<p>To illustrate the<a id="_idIndexMarker285"/> procedure of forecasting, we will start with a dataset that is a single time series. While this dataset is generic, you could imagine that it could represent a system performance metric, the number of transactions processed by a system, or even sales revenue data. The important aspect of this dataset is that it contains several distinct time-based trends—a daily trend, a weekly trend, and an overall increasing trend. Elastic ML will discover all three trends and will effectively predict those into the future. It is good to note that the dataset also contains some anomalies, but (of course) future anomalies cannot be predicted as they are surprise events by definition. Since our discussion here is purely focused on forecasting, we will ignore the existence of any anomalies found in our dataset while building the models for forecasting.</p>
			<p>With that said, let’s jump into an example by using the <strong class="source-inline">forecast_example</strong> dataset from the GitHub repository. Once downloaded, the data can be easily imported into your Kibana via Elastic ML’s Data Visualizer. Let’s proceed, as follows:</p>
			<ol>
				<li>To upload the sample data, from the Kibana home screen, click on the <strong class="bold">Upload a file</strong> button, as<a id="_idIndexMarker286"/> shown in the following screenshot: <div id="_idContainer069" class="IMG---Figure"><img src="image/B17040_04_5.jpg" alt="Figure 4.5 – The option to upload a file in Kibana&#13;&#10;"/></div><p class="figure-caption">Figure 4.5 – The option to upload a file in Kibana</p></li>
				<li>Choose the <strong class="source-inline">forecast_example.json</strong> file from your local machine. Data Visualizer will then display the first 1,000 lines of the file to give you a preview of what the file contains, as well as a breakdown of the different fields. This is represented in the following screenshot:<div id="_idContainer070" class="IMG---Figure"><img src="image/B17040_04_6.jpg" alt="Figure 4.6 – Previewing the contents of the file to upload&#13;&#10;"/></div><p class="figure-caption">Figure 4.6 – Previewing the contents of the file to upload</p></li>
				<li>Click on<a id="_idIndexMarker287"/> the <strong class="bold">Import</strong> button, then name the destination index for the data to be uploaded to, as illustrated in the following screenshot:<div id="_idContainer071" class="IMG---Figure"><img src="image/B17040_04_7.jpg" alt="Figure 4.7 – Naming the destination index to upload to&#13;&#10;"/></div><p class="figure-caption">Figure 4.7 – Naming the destination index to upload to</p></li>
				<li>Provide a name <a id="_idIndexMarker288"/>for your destination index, make sure the <strong class="bold">Create index pattern</strong> option is checked if this is your first time uploading, and click on the <strong class="bold">Import</strong> button again to complete the upload. You should see the successful completion of the upload, as shown in the next screenshot:<div id="_idContainer072" class="IMG---Figure"><img src="image/B17040_04_8.jpg" alt="Figure 4.8 – Upload completed&#13;&#10;"/></div><p class="figure-caption">Figure 4.8 – Upload completed</p></li>
				<li>Once the data has <a id="_idIndexMarker289"/>been uploaded, navigate to <strong class="bold">Machine Learning</strong> and create an Anomaly Detection job, selecting the index pattern of the index name you created in the previous step. This is represented in the following screenshot:<div id="_idContainer073" class="IMG---Figure"><img src="image/B17040_04_9.jpg" alt="Figure 4.9 – Creating an Anomaly Detection job first&#13;&#10;"/></div><p class="figure-caption">Figure 4.9 – Creating an Anomaly Detection job first</p></li>
				<li>This particular <a id="_idIndexMarker290"/>dataset is only a single, time-series metric (a field called <strong class="source-inline">amount</strong>), so we will simply use the <strong class="bold">Single metric</strong> job wizard to build the job, as illustrated in the following screenshot:<div id="_idContainer074" class="IMG---Figure"><img src="image/B17040_04_10.jpg" alt="Figure 4.10 – Selecting the Single metric job wizard for this data&#13;&#10;"/></div><p class="figure-caption">Figure 4.10 – Selecting the Single metric job wizard for this data</p></li>
				<li>On the next screen and for this example, we will want to only analyze up to March 1, 2017 @ 00:00:00.000 in order to leave us some data to compare our forecast against later. You can accomplish this by first clicking the <strong class="bold">Use full forecast_example data</strong> button but then manually changing the ending date to match what is <a id="_idIndexMarker291"/>shown in the following screenshot: <div id="_idContainer075" class="IMG---Figure"><img src="image/B17040_04_11.jpg" alt="Figure 4.11 – Selecting to use only data up to a certain date&#13;&#10;"/></div><p class="figure-caption">Figure 4.11 – Selecting to use only data up to a certain date</p><p class="callout-heading">Note</p><p class="callout">This example dataset<a id="_idIndexMarker292"/> logs data from January 31, 2017 to March 1, 2017. Despite being from the past, we can contrive a scenario in which we are pretending to be in that time frame, and we will declare that today’s date is March 1, 2017. We therefore want to have an ML job analyze the data between January 31 and “today”, and then use ML to forecast that data 10 days into the future. We will later see how accurate our forecast is against the remainder of the data. If your Kibana time zone is set to your local time, the dates in this chapter may look slightly different, as the screenshots were taken with a version of Kibana that’s been set to the Eastern time zone of the <strong class="bold">United States</strong> (<strong class="bold">US</strong>).</p><p>Now, click the <strong class="bold">Next</strong> button to advance to the next step in the configuration wizard.</p></li>
				<li>After clicking the <strong class="bold">Next</strong> button, we will need to select what we desire to analyze from the <strong class="bold">Pick fields</strong> drop-down box. We will select <strong class="bold">Sum(amount)</strong> because the <strong class="source-inline">amount</strong> field is simply a numerical value over time. This is represented in the following <a id="_idIndexMarker293"/>screenshot:<div id="_idContainer076" class="IMG---Figure"><img src="image/B17040_04_12.jpg" alt="Figure 4.12 – Selecting to sum the amount field over time as our detection&#13;&#10;"/></div><p class="figure-caption">Figure 4.12 – Selecting to sum the amount field over time as our detection</p><p>Click the <strong class="bold">Next</strong> button to proceed, leaving the other options as their defaults for now.</p></li>
				<li>Now, we need to name our Anomaly Detection job—in the <strong class="bold">Job ID</strong> box, type in a logical name. In the following screenshot, the name <strong class="source-inline">forecast_example</strong> was <a id="_idIndexMarker294"/>used: <div id="_idContainer077" class="IMG---Figure"><img src="image/B17040_04_13.jpg" alt="Figure 4.13 – Naming the Anomaly Detection job&#13;&#10;"/></div><p class="figure-caption">Figure 4.13 – Naming the Anomaly Detection job</p><p>Again, leave the other options as their defaults and click the <strong class="bold">Next</strong> button.</p></li>
				<li>A validation step takes place to ensure that everything is properly set up for the analysis to work, as illustrated in the following screenshot:<div id="_idContainer078" class="IMG---Figure"><img src="image/B17040_04_14.jpg" alt="Figure 4.14 – Job validation step&#13;&#10;"/></div><p class="figure-caption">Figure 4.14 – Job validation step</p><p>Click the <strong class="bold">Next</strong> button <a id="_idIndexMarker295"/>to proceed.</p></li>
				<li>At this point, the job is ready to be created, as shown in the following screenshot:<div id="_idContainer079" class="IMG---Figure"><img src="image/B17040_04_15.jpg" alt="Figure 4.15 – Anomaly Detection job ready to be created&#13;&#10;"/></div><p class="figure-caption">Figure 4.15 – Anomaly Detection job ready to be created</p></li>
				<li>After <a id="_idIndexMarker296"/>the <strong class="bold">Create job</strong> button is clicked, you will see an animated preview of the results superimposed on top of the data, as illustrated in the following screenshot:<div id="_idContainer080" class="IMG---Figure"><img src="image/B17040_04_16.jpg" alt="Figure 4.16 – Results preview of job execution displayed&#13;&#10;"/></div><p class="figure-caption">Figure 4.16 – Results preview of job execution displayed</p><p>To access the<a id="_idIndexMarker297"/> ability to forecast, we need to click the <strong class="bold">View Results</strong> button, which will take us to <strong class="bold">Single Metric Viewer</strong>. In <strong class="bold">Single Metric Viewer</strong>, we can see the overall dataset and can appreciate the shape and complexity of the way this data behaves; there are both daily and weekly periodic components, as well as a gradual positive slope/trend that causes the data to drift up over time. This is depicted in the following screenshot:</p><p class="figure-caption"> </p><div id="_idContainer081" class="IMG---Figure"><img src="image/B17040_04_17.jpg" alt="Figure 4.17 – Results with annotations displayed&#13;&#10;"/></div><p class="figure-caption">Figure 4.17 – Results with annotations displayed</p><p>If we expose<a id="_idIndexMarker298"/> and explore the annotations, we actually see exactly where Elastic ML has detected different trends in the data. Also, remember that despite the fact we may only be interested in forecasting on this data, the job will still point out anomalies throughout the data’s history. We can simply ignore them in this case if we so choose.</p></li>
				<li>To invoke a forecast on this data, click the <strong class="bold">Forecast</strong> button, and in the dialog box enter a duration<a id="_idIndexMarker299"/> of 10 days (<strong class="source-inline">10d</strong>), as illustrated in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B17040_04_18.jpg" alt="Figure 4.18 – Initiating a new 10-day forecast&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.18 – Initiating a new 10-day forecast</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You should not attempt to ask for a forecasting duration that is longer than the duration of the data that the ML job has analyzed. In other words, don’t ask for a 2-week forecast if the ML job has only ever seen 1 week of data. At least have a one-to-one ratio of historical data to the amount that you want to forecast (and, ideally, you would have a higher ratio of historical data). Lastly, supply enough consistent data to learn about the principal patterns. For example, a minimum of three cycles of a periodic pattern is used to achieve the best possible predictions.</p>
			<p>After clicking the <strong class="bold">Run</strong> button shown in <em class="italic">Figure 4.18</em>, the forecast will be invoked and run in the background. We can see the results of our forecast almost immediately, as illustrated in the <a id="_idIndexMarker300"/>following screenshot:</p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B17040_04_19.jpg" alt="Figure 4.19 – Forecast results&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.19 – Forecast results</p>
			<p>The shaded area around the forecast/predicted zone is the 95th percentile confidence interval. In other words, Elastic ML has estimated that there is a 95% chance that the future values will be within this range (and, likewise, only a 2.5% chance that the future values will be either above or below the confidence interval). The 95th percentile range is currently a fixed value and is not yet settable by the user.</p>
			<p>Now that we have the ability to create simple forecasts from the UI, let’s explore the results of the forecast <a id="_idIndexMarker301"/>in more depth before moving on to a more complicated example.</p>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor087"/>Looking at forecast results</h1>
			<p>Now that we <a id="_idIndexMarker302"/>have run a forecast, we can look in more depth at the results that are generated by the forecasting process. We can view the results of a previously created forecast at any time in the UI via one of two methods. The first way is to click the <strong class="bold">Forecast</strong> button in <strong class="bold">Single Metric Viewer</strong> to reveal a list of previous forecasts, like so:</p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B17040_04_20.jpg" alt="Figure 4.20 – Viewing previously created forecasts from Single Metric Viewer &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.20 – Viewing previously created forecasts from Single Metric Viewer </p>
			<p>Alternatively, you can view them in the <strong class="bold">Job Management</strong> page under the <strong class="bold">Forecasts</strong> tab for that job, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B17040_04_21.jpg" alt="Figure 4.21 – Viewing previously created forecasts from the Job Management page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.21 – Viewing previously created forecasts from the Job Management page</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Forecast results<a id="_idIndexMarker303"/> built in Kibana have a default lifespan of 14 days. After that, the forecast results are deleted permanently. If a different expiration duration is desired, then the forecast will have to be invoked via the <strong class="source-inline">_forecast</strong> API endpoint, which will be discussed later but is documented at <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-forecast.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-forecast.html</a>.</p>
			<p>When viewing the forecast results in <strong class="bold">Single Metric Viewer</strong>, notice that when you hover your mouse over the forecast data points, a pop-up display will list three key pieces of information about the data point—the prediction value, the upper-bound value, and the lower-bound value, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B17040_04_22.jpg" alt="Figure 4.22 – Information revealed in the forecast’s pop-up display&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.22 – Information revealed in the forecast’s pop-up display</p>
			<p>Recall that the upper <a id="_idIndexMarker304"/>and lower bounds define a range of 95th percentile confidence. The prediction value is the value with the highest likelihood (probability). These three key values are stored in the <strong class="source-inline">.ml-anomalies-*</strong> results indices with the following names:</p>
			<ul>
				<li><strong class="source-inline">forecast_prediction</strong></li>
				<li><strong class="source-inline">forecast_upper</strong></li>
				<li><strong class="source-inline">forecast_lower</strong></li>
			</ul>
			<p>In <a href="B17040_05_Epub_AM.xhtml#_idTextAnchor090"><em class="italic">Chapter 5</em></a>, <em class="italic">Interpreting Results</em>, we will learn how we can query the <strong class="source-inline">.ml-anomalies-*</strong> indices to locate information for forecasts and how we can leverage that information for other purposes, such as for dashboards or alerts.</p>
			<p>If we want to see how well Elastic ML’s forecasting did compared to the actual next 10 days of the dataset (remember—the ML job’s models haven’t yet actually seen those days), we can return to the <strong class="bold">Job Management</strong> page and start the data feed of the job to continue on and analyze the remainder of the data. To do so, click on the <strong class="bold">Start datafeed</strong> link from the menu on the right-hand side, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B17040_04_23.jpg" alt="Figure 4.23 – Starting the data feed from the Job Management page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.23 – Starting the data feed from the Job Management page</p>
			<p>Once the dialog <a id="_idIndexMarker305"/>comes up, set the <strong class="bold">Search start time</strong> field to <strong class="bold">Continue from 2017-03-01 00:00:00</strong> (or whatever it says it is for your local time zone), and specify the <strong class="bold">Search end time</strong> field to be March 11, 2017 at 12:00 AM, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B17040_04_24.jpg" alt="Figure 4.24 – Continuing the data feed from where it previously left off&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.24 – Continuing the data feed from where it previously left off</p>
			<p>Once you have done this, return to <strong class="bold">Single Metric Viewer</strong> for the job, ensure that you are viewing the correct range of time with the Kibana time picker, and click on the <strong class="bold">Forecast</strong> button to view the previously created forecast, as described earlier in this chapter. You will now<a id="_idIndexMarker306"/> be able to see the forecast values superimposed over the actual values from the data, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B17040_04_25.jpg" alt="Figure 4.25 – Comparing the forecast to the actual data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.25 – Comparing the forecast to the actual data</p>
			<p>As described earlier in this chapter, there will be a slight discrepancy between the Elastic ML prediction of the data and the actual value that arrives in the future. This is because the predictions are probabilistic, and with probability comes a certain level of uncertainty. However, this does not diminish the usefulness of the forecasts. Combined with proactive alerting (as described in <a href="B17040_06_Epub_AM.xhtml#_idTextAnchor117"><em class="italic">Chapter 6</em></a>, <em class="italic">Alerting on ML Analysis</em>), we could have been alerted to the possibility of a breach. This proactive notification is especially useful when users cannot track hundreds or thousands of entities individually. In the next section, we’ll see <a id="_idIndexMarker307"/>how multi-metric forecasting allows us to track those entities automatically.</p>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor088"/>Multiple time series forecasting</h1>
			<p>To invoke<a id="_idIndexMarker308"/> forecasting on multiple time series, you simply just need an ML job that is modeling multiple time series. Let’s assume that we have an ML job that has analyzed web requests per country. In fact, using the built-in sample web logs (<strong class="source-inline">kibana_sample_data_logs</strong>) we used in <a href="B17040_03_Epub_AM.xhtml#_idTextAnchor049"><em class="italic">Chapter 3</em></a>, <em class="italic">Anomaly Detection</em>, we could easily create a multi-metric job that counts events, split on the source country code of the request (the field is called <strong class="source-inline">geo.src</strong>), as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B17040_04_26.jpg" alt="Figure 4.26 – Creating a multi-metric job for forecasting&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.26 – Creating a multi-metric job for forecasting</p>
			<p>There are 183 unique <a id="_idIndexMarker309"/>source countries in this dataset. After creating and running this Anomaly Detection job in order to build baseline models for all 183 countries, we are now in a position to invoke a forecast. If we approach the invocation of a forecast in the same way as we did before (via <strong class="bold">Single Metric Viewer</strong>), we might erroneously think that a forecast will only be executed for the series displayed, as<a id="_idIndexMarker310"/> illustrated in the following screenshot: </p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B17040_04_27.jpg" alt="Figure 4.27 – Invoking a multi-metric forecast from Single Metric Viewer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.27 – Invoking a multi-metric forecast from Single Metric Viewer</p>
			<p>In the preceding screenshot (although it might be a little difficult to see in the faded background behind the popup), we can see that the country code selected for the <strong class="source-inline">geo.src</strong> field is <strong class="source-inline">CN</strong> (China). But, as pointed out in the warning message of the <strong class="bold">Forecasting</strong> popup, clicking on the <strong class="bold">Run</strong> button will invoke the forecast and will run for all partitions present in the job (here, it knows that there are more than 100 partitions). </p>
			<p>Alternatively, we can use the <strong class="source-inline">_forecast</strong> API endpoint to invoke the forecast. To do so, in the <strong class="bold">Dev Tools</strong> console, we could issue this request:</p>
			<p class="source-code">  POST _ml/anomaly_detectors/web_traffic_per_country/_forecast</p>
			<p class="source-code">   {</p>
			<p class="source-code">    “duration”: “1d”</p>
			<p class="source-code">   }</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The Anomaly Detection job must be in an “open” state before you can invoke a forecast via the API.</p>
			<p>The immediate <a id="_idIndexMarker311"/>response from the API call is as follows:</p>
			<p class="source-code">   {</p>
			<p class="source-code">    “acknowledged” : true,</p>
			<p class="source-code">    “forecast_id” : “ sm7AF3cBpc7Wt6MbTWYg”</p>
			<p class="source-code">}</p>
			<p>The results of our forecast request will be available for viewing either in <strong class="bold">Single Metric Viewer</strong> or programmatically by querying the results indices, to be described in <a href="B17040_05_Epub_AM.xhtml#_idTextAnchor090"><em class="italic">Chapter 5</em></a>, <em class="italic">Interpreting Results</em>. With <strong class="bold">Single Metric Viewer</strong>, we can see the forecast for any country by clicking on the <strong class="bold">Forecast</strong> button, selecting our previously run forecast, then selecting the country code of our choice, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B17040_04_28.jpg" alt="Figure 4.28 – Viewing a single partition’s forecast from a multi-metric forecast&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.28 – Viewing a single partition’s forecast from a multi-metric forecast</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Viewing the results of a<a id="_idIndexMarker312"/> multi-metric forecast in <strong class="bold">Single Metric Viewer</strong> isn’t exactly ideal as of v7.10. This is because the view only shows partitions that have anomalies recorded for them. This feature will be added in v7.11.</p>
			<p>Forecasting across multiple time series could be extremely useful for capacity planning use cases, where hundreds or possibly thousands of entities need to be analyzed, and forecasting to see if any pending breaches in the near future are possible.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor089"/>Summary</h1>
			<p>Elastic ML has an additional feature over and above anomaly detection: the ability to take and extrapolate time series models into the future for forecasting purposes. With use cases that include advanced breach detection and capacity planning, this feature alleviates the human burden of manually charting, tracking, and predicting where things are going in the future, based upon how they have behaved in the past.</p>
			<p>In the next chapter, we’ll go deeper into the results that anomaly detection and forecasting give us, and we will set up a better understanding of how to leverage those results for dashboards and proactive alerts.</p>
		</div>
	</body></html>