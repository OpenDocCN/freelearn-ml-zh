- en: '3'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: Perform Topic Modeling and Theme Extraction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Extract and analyze common themes through topic modeling with Amazon Comprehend
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe the basics of topic modeling analysis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform topic modeling on a set of documents and analyze the results
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter describes Topic Modeling on common themes using Amazon Comprehend
    analyzing the result for document set.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first part of this chapter, you will learn how to analyze Topic modeling
    output from Amazon Comprehend. Specifically, you will learn the fundamentals of
    the algorithm used for Topic modeling, Latent Dirichlet Allocation (LDA). Learning
    LDA will allow you to apply Topic modeling to a multitude of unique business use
    cases.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: You will then perform Topic modeling on two documents with a known Topic structure.
    The first is the story **Romeo and Juliet** and the second is **War of the Worlds**.
    Lastly, you will analyze topics from 1,000 text documents containing negative
    movie reviews with Amazon Comprehend.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Extracting and Analyzing Common Themes
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can also utilize Amazon Comprehend to analyze a corpus of archives to locate
    the normal topics contained inside the corpus. Amazon Comprehend inspects reports
    in the corpus and, afterward, restores the most noticeable themes and the reports
    that are related to every subject. Subject displaying is an offbeat procedure:
    you present an arrangement of records for preparation and later get the outcomes
    when handling is finished. Amazon Comprehend performs point displaying on huge
    report sets. For the best results, you ought to incorporate around 1,000 records
    when you present a subject demonstrating work.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Topic Modeling with Latent Dirichlet Allocation (LDA)
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The subjects or **common themes** of a set of documents can be determined with
    Amazon Comprehend. For example, you have a movie review website with two message
    boards, and you want to determine which message board is discussing two newly
    released movies (one about sport and the other about a political Topic). You can
    provide the message board text data to Amazon Comprehend to discover the most
    prominent topics discussed on each message board.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: The machine learning algorithm that Amazon Comprehend uses to perform Topic
    Modeling is called latent Dirichlet allocation (LDA). LDA is a learning-based
    model that's used to determine the most important topics in a collection of documents.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: The way that LDA works is it considers every document to be a combination of
    topics, and each word in the document is associated to one of these topics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: For example, if the first paragraph of a document consists of words like **eat**,
    **chicken**, **restaurant**, and **cook** then you conclude that the Topic can
    be generalized to **Food**. And if the second paragraph of a document contains
    words like **ticket**, **train**, **kilometer**, and **vacation** then you can
    conclude that the Topic is **Travel**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Basic LDA example
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Topic modeling can seem complex, and understanding the fundamental steps of
    how LDA determines Topics is essential to performing Topic modeling on more complex
    business use cases. Thus, let's deconstruct LDA with the following simple example.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 主题建模可能看起来很复杂，理解LDA如何确定主题的基本步骤对于在更复杂的企业用例中进行主题建模至关重要。因此，让我们通过以下简单的例子来分解LDA。
- en: 'You have one document with five sentences. Your goal is to determine the two
    most common topics present in the document:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一篇包含五句话的文档。你的目标是确定文档中出现的两个最常见主题：
- en: I like to eat bread and bananas.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我喜欢吃面包和香蕉。
- en: I ate a bread and banana smoothie for breakfast.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我早餐吃了一杯面包和香蕉的冰沙。
- en: Puppies and kittens are cute.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小狗和小猫很可爱。
- en: My brother adopted a puppy yesterday.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 昨天我哥哥收养了一只小狗。
- en: Look at this cute opossum munching a piece of broccoli.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看看这只可爱的小负鼠正在吃一块西兰花。
- en: 'LDA discovers the topics that these sentences contain. For example, given the
    above sentences and asked for two topics, LDA might produce the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: LDA发现这些句子包含的主题。例如，给定上述句子并要求两个主题，LDA可能会产生以下结果：
- en: 'Sentences 1 and 2: 100% Topic A'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第1和第2句：100% 主题A
- en: 'Sentences 3 and 4: 100% Topic B'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 第3和第4句：100% 主题B
- en: 'Sentence 5: 60% Topic A, 40% Topic B'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 第5句：60% 主题A，40% 主题B
- en: '**Topic A**: 30% bread, 15% banana, 10% breakfast, 10% munching, (Thus, you
    can assume Topic A is about food)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**主题A**：30% 面包，15% 香蕉，10% 早餐，10% 咀嚼（因此，你可以假设主题A是关于食物的）'
- en: '**Topic B**: 20% Puppies, 20% kittens, 20% cute, 15% opossum, (This, you can
    assume Topic B is about cute animals).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**主题B**：20% 小狗，20% 小猫，20% 可爱，15% 小负鼠（你可以假设主题B是关于可爱动物的）'
- en: Why Use LDA?
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么使用LDA？
- en: LDA is useful when you have an arrangement of records that you need to find
    designs inside, without thinking about the reports themselves. LDA can be utilized
    to create subjects to comprehend an archives, general Topic. This is, usually
    utilized in suggestion frameworks, report arrangement, and record synopsis. In
    conclusion, LDA is helpful in preparing prescient models with subjects and events.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要找到记录中的设计，而不考虑报告本身时，LDA很有用。LDA可以用来创建主题，以理解档案，一般主题。这通常用于推荐系统、报告排序和文件摘要。总之，LDA在准备带有主题和事件预测模型时很有帮助。
- en: LDA has many use cases. For example, you have 30,000 user emails and want to
    determine the most common topics to provide group-specific recommended content
    based on the most prevalent topics. Manually reading, or even outsourcing the
    manual reading of, 30,000 emails, would take an excessive investment in terms
    of time and money, and the accuracy would be difficult to confirm. However, Amazon
    Comprehend can seamlessly provide the most common topics present in 30,000 emails
    in a few steps with incredible accuracy. First, convert the emails to text files,
    upload them to an S3 bucket, then imitate a Topic modeling job with Amazon Comprehend.
    The output is two `CSV` with the corresponding Topics and terms.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LDA有许多用例。例如，你有30,000封用户电子邮件，并希望确定最常见的主题，以便根据最普遍的主题提供针对特定群体的推荐内容。手动阅读，甚至外包30,000封电子邮件的阅读，将需要大量的时间和金钱投入，而且准确性难以确认。然而，Amazon
    Comprehend可以在几个步骤内无缝提供30,000封电子邮件中最常见的主题，并且准确性令人难以置信。首先，将电子邮件转换为文本文件，上传到S3存储桶，然后使用Amazon
    Comprehend进行主题建模作业。输出是两个包含相应主题和术语的`CSV`文件。
- en: Amazon Comprehend–Topic Modeling Guidelines
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Comprehend–主题建模指南
- en: 'The most accurate results are given if you provide Comprehend with the largest
    possible corpus. More specifically:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你向Comprehend提供尽可能大的语料库，将给出最准确的结果。更具体地说：
- en: You should use no less than 1,000 records in every subject demonstrating work
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该在每个主题中至少使用1,000条记录来展示工作
- en: Each report ought to be something like three sentences in length
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每篇报告的长度应大约为三句话
- en: If a record comprises of for the most part numeric information, you should expel
    it from the corpus
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一条记录主要由数字信息组成，你应该将其从语料库中排除
- en: 'Currently, Topic Modeling is limited to two document languages: **English**
    and **Spanish**.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，主题建模仅限于两种文档语言：**英语**和**西班牙语**。
- en: A Topic modeling job allows two format types for input data (see the following
    table 1). This allows users to process both collections of large documents (for
    example, newspaper articles or scientific journals), and short documents (for
    example, tweets or social media posts).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 主题建模作业允许两种输入数据格式类型（见下表1）。这使用户能够处理大量文档集合（例如，报纸文章或科学期刊），以及短文档（例如，推文或社交媒体帖子）。
- en: '**Input Format Options:**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入格式选项**：'
- en: '![Figure3.1:  AWS Comprehend - Topic modeling input format options.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_001.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure3.1: AWS Comprehend– Topic modeling input format options'
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Output Format Options:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2: AWS Comprehend - topic modeling output files description.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_002.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.2: AWS Comprehend– Topic modeling output files description'
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'After Amazon Comprehend processes your document collection, the modeling outputs
    two CSV files: Topic-terms.csv (see Figure 1) and `doc-topics.csv`.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'The `topic-terms.csv` file provides a list of topics in the document collection
    with the terms, respective Topic and weight. For example, if you gave Amazon Comprehend
    two hypothetical documents, **learning to garden** and **investment strategies**,
    it might return the following to describe the two topics in the collection:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3: Sample topic modeling output (topic-terms.csv) for two documents
    input.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_003.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.3: Sample Topic modeling output (`topic-terms.csv`) for two document''s
    input'
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The `doc-topics.csv` file provides a list of the documents provided for the
    Topic modeling job with the document names, and the respective topics and their
    proportions in each document. Given two hypothetical documents, `learning_to_garden.txt`
    and `investment_strategies.txt,` you can expect the following output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4: Sample topic modeling output (doc-topics.csv) for two documents
    input'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_004.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.4: Sample Topic modeling output (`doc-topics.csv`) for two document''s
    input'
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 13: Topic Modeling of a Known Topic Structure'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use Amazon Comprehend to perform Topic modeling on
    two documents with known topics (**Romeo and Juliet** and **War of the Worlds**).
    We are using two known topics to better understand LDA. Before proceeding to the
    exercise, just look at an overview of the data pipeline architecture:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5: Data pipeline architecture overview'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_005.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.5: Data pipeline architecture overview'
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The following are the steps to complete the Topic modelling of a known Topic
    structure:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: We need an input and output S3 bucket. Let's create both. Navigate to [https://s3.console.aws.amazon.com/s3/](https://s3.console.aws.amazon.com/s3/).
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, click on the **Create** **bucket** button to create a bucket:![Figure
    3.6: Create bucket'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_006.jpg)'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.6: Creating a bucket'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For Bucket name, enter a unique name that describes the function. Here, the
    name `aws-ml-input-for-topic-modeling` is used. Click on the **Create** button:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Clicking Create versus Next uses all default settings for: properties and permissions.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.7: Create bucket name input'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_007.jpg)'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.7: Creating bucket name input'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, click on the **Create** button to create a folder:![Figure 3.8: Create
    a folder in S3 for topic modeling input'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_008.jpg)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.8: Creating a folder in S3 for Topic modeling input'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Now, type in `known_structure`, as the folder name, and then click on the `'known_structure`'
    folder name
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After clicking on the `known_structure` folder:![Figure 3.9: Input bucket screen'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_010.jpg)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.9: Input bucket screen'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, click on the **Upload** button:![Figure 3.10: Upload screen'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_011.jpg)'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.10: Upload screen'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Now, you will prompted by the following for adding files. Click on **Add files**
    or drag the files onto the screen:![Figure 3.11 Add files screen
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_012.jpg)'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 3.11 Add files screen
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Navigate to download and upload the following two text files from the machine:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: You can download the Romeo and Juliet text file from /lesson3/topic_a/romeo_and_juliet.txt
    [https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/romeo_and_juliet.txt](https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/romeo_and_juliet.txt)
    /lesson3/topic_a/the_war_of_the_worlds.txt [https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/the_war_of_the_worlds.txt](https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/the_war_of_the_worlds.txt)
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the files have been uploaded, click on the `known_structure` text files
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Navigate to the Amazon S3 homescreen:![Figure 3.13: Click Amazon S3.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_014.jpg)'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.13: Amazon S3'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, create an output S3 bucket. Use the same S3 bucket creation process.
    Click on the **Create** **bucket** button:![Figure 3.14: Click Create Bucket.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_015.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.14: Creating a bucket'
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, name the bucket, and then click on the **Create** button:![Figure 3.15:
    Create bucket output for topic modeling'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_016.jpg)'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.15: Create bucket output for Topic modeling'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Navigate to Amazon Comprehend: [https://console.aws.amazon.com/comprehend/](https://console.aws.amazon.com/comprehend/).
    If you are presented with the following screen, click **Try Amazon Comprehend**:![Figure
    3.16: Amazon Comprehend home screen.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_017.jpg)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.16: Amazon Comprehend home screen'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, Click on the **Organization** in the left-hand side toolbar:![Figure 3.17:
    Amazon Comprehend Organization screen'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_018.jpg)'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.17: Amazon Comprehend Organization screen'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, click on the `known_structure_topic_modeling_job` in the **Name** field:![Figure
    3.18: Name of the topic modeling job input'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_019.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.18: Name of the Topic modeling job'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, scroll down to **Choose input data** and then click on **Search**:![Figure
    3.19: Click Search to locate the topic modeling input data source'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_020.jpg)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.19: Clicking Search to locate the Topic modeling input data source'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Navigate to the `known_structure` folder and then click on **Select**:![Figure
    3.20: Click Select for the S3 folder.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_021.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.20: Clicking on Select for the S3 folder'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, from the drop-down menu, select **One document per file**:![Figure 3.21:
    Select One document per file'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_022.jpg)'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.21: Selecting One document per file'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, enter **two** for the **Number of Topics** you need to have:![Figure 3.22:
    Enter 2 for the number of topics to perform topic modeling'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_023.jpg)'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.22: Entering 2 for the number of topics to perform Topic modeling'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, click on **Search** to search the bucket that was created previously:![Figure
    3.23: Click search for the topic modeling S3 output location'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_024.jpg)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.23: Clicking on search for the Topic modeling S3 output location'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once you find the bucket you created, click on the bucket you created to output
    Topic modeling:![Figure 3.24: Select the output S3 bucket'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_025.jpg)'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.24: Selecting the output S3 bucket'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, select the appropriate bucket and then click on **Select**:![Figure 3.25:
    Confirm by clicking Select'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_026.jpg)'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.25: Confirming by clicking Select'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Scroll down to choose an **IAM** role, and click the circle next to create
    an **IAM** role:![Figure 3.26: Select ‘Create an IAM role’'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_027.jpg)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.26: Selecting Create an IAM role'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, select the **Input** and **Output S3 buckets** from the **Permissions
    to access**:![Figure 3.27: Provide permission to Input and Output S3 buckets'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_028.jpg)'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.27: Providing permission to Input and Output S3 buckets'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Enter `myTopicModelingRole` in the Name suffix field and then click on the
    **Create job** button:![Figure 3.28: Click the Create job button'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_029.jpg)'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.28: Clicking the Create job button'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Creating the job may take a few minutes, but when completed, you will be redirected
    to the Comprehend home screen:![Figure 3.29: Comprehend home screen'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_030.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.29: Comprehend home screen'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'While the job is being processed, the status displayed will be **In Progress**:![Figure
    3.30: ‘In progress’ status displayed'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_031.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.30: In progress status displayed'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When the status updates to **Completed**, click on the Topic Modeling job name:![Figure3.31:
    Completed status displayed.'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_032.jpg)'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure3.31: Completed status displayed'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, scroll down to the **Output** section:![Figure 3.32: Topic modeling output
    display home screen'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_033.jpg)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.32: Topic modeling output display home screen'
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click on the hyperlink under **Data location**:![Figure 3.33: Topic modeling
    data output hyperlinked location'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_034.jpg)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.33: Topic modeling data output hyperlinked location'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click on the link of the output folder:![Figure 34: Topic modeling output folder'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_035.jpg)'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 34: Topic modeling output folder'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click on the output folder. Then, click on `output.tar.gz` and download the
    file:![Figure 3.35: Clicking on Download'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_036.jpg)'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.35: Clicking on Download'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click on `output.tar.gz` and select **Show in folder**. Click on **OK** to
    extract the files on your desktop:![Figure 3.36: Click OK'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_037.jpg)'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.36: Clicking on OK'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Navigate to your desktop. Two files will be extracted: `doc-topics.csv` and
    `topics-terms.csv`. There will be two files to examine: `topic-terms.xlsx` and
    `doc-topics.xlsx`:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure3.37: Topic modeling output CSV files'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_038.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure3.37: Topic modeling output CSV files'
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Your Topic-terms.csv and doc-topics.csv results should be the same as the following
    results. If your results are NOT the same, use the output files for the remainder
    of the chapter, which are located at Lesson3\topic_a\doc-topics.csv [https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/doc-topics.csv](https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/doc-topics.csv)
    and lesson3\topic_a\topic-terms.csv [https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/topic-terms.csv](https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/topic-terms.csv).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the output generated:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.38: topic-terms.csv result'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_039.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.38: `topic-terms.csv` result'
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 3.39: doc-topics.csv results'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image_Lesson3_040.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.39: doc-topics.csv results'
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 14: Performing Known Structure Analysis'
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will programmatically upload the CSV (`doc-topics.csv`
    and `Topic-terms.csv`) to S3, merge the CSV on the Topic column, and print the
    output to the console. The following are the steps for performing Known Structure
    Analysis:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-179
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For this step, you may either follow along with the exercise and type in the
    code or obtain it from the source code folder, `local_csv_to_s3_for_analysis.py`,
    and paste it into the editor. The source code is available on GitHub in the following
    repository: [https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/local_csv_to_s3_for_analysis.py](https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/topic_a/local_csv_to_s3_for_analysis.py).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will import `boto3` using the following command:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we will import `pandas` using the following command:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we will create the S3 client object using the following command:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we will create a variable with a unique bucket name. Here, the selected
    bucket name is `known-tm-analysis`, but you will need to create a unique name:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, create a new bucket:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create a list of the CSV filenames to import:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, iterate on each file to upload to S3 using the following line of code:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, check if the filename is `doc-topics.csv` :'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, get the `doc-topics.csv` file object and assign it to the `obj` variable
    using the following command:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令获取`doc-topics.csv`文件对象并将其分配给`obj`变量：
- en: '[PRE8]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, read the `csv` obj and assign it to the `doc_topics` variable:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，读取`csv`对象并将其分配给`doc_topics`变量：
- en: '[PRE9]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, merge the files on the Topic column to obtain the most common terms per
    document using the following command:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令合并主题列上的文件，以获取每个文档中最常见的术语：
- en: '[PRE10]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, navigate to the location of the `CSV` files in the Command Prompt, and
    execute the code with the following command:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，导航到命令提示符中`CSV`文件的位置，并使用以下命令执行代码：
- en: '[PRE11]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The console output is a merged `dataframe` that provides the `docnames` with
    their respective terms and the term''s weights (see the following):![Figure 3.40:
    known_strucutre topic modeling merged results'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制台输出是一个合并的`dataframe`，它提供了具有相应术语及其权重的`docnames`（见以下内容）：![图3.40：已知结构主题建模合并结果
- en: '](img/Image_Lesson3_041.jpg)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/Image_Lesson3_041.jpg](img/Image_Lesson3_041.jpg)'
- en: 'Figure 3.40: known_strucutre Topic modeling merged results'
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.40：已知结构主题建模合并结果
- en: 'To verify the CSV''s, navigate to S3, (reload the page if the new bucket does
    not appear), and the new bucket has been created in S3\. Click on the bucket to
    verify a successful import:![Figure 3.41: known-tm-analysis S3 bucket'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要验证CSV文件，导航到S3（如果新存储桶没有出现，请重新加载页面），并在S3中创建了新的存储桶。单击存储桶以验证成功导入：![图3.41：已知-tm-analysis
    S3存储桶
- en: '](img/Image_Lesson3_042.jpg)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/Image_Lesson3_042.jpg](img/Image_Lesson3_042.jpg)'
- en: 'Figure 3.41: known-tm-analysis S3 bucket'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.41：已知-tm-analysis S3存储桶
- en: 'There will be two CSV files in the bucket: `doc-topics.csv` and `topic-terms.csv`:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储桶中将有两个CSV文件：`doc-topics.csv`和`topic-terms.csv`：
- en: '![Figure 3.42: Topic modeling results uploaded to S3'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.42：主题建模结果上传到S3'
- en: '](img/Image_Lesson3_043.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Image_Lesson3_043.jpg](img/Image_Lesson3_043.jpg)'
- en: 'Figure 3.42: Topic modeling results uploaded to S3'
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.42：上传到S3的主题建模结果
- en: 'Activity 4: Perform Topic Modeling on a Set of Documents with Unknown Topics'
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动4：对一组未知主题的文档执行主题建模
- en: In this activity, we will perform Topic modeling on a set of documents with
    unknown topics. Topic modeling, we will consider an example. Suppose your employer
    wants you to build a data pipeline to analyze negative movie reviews that are
    in individual text files with a unique ID filename. Thus, you need to perform
    Topic modeling to determine which files represent the respective topics. Overall,
    negative reviews provide more monetary benefit or loss to the company, thus, they
    are prioritizing negative reviews versus positive reviews. The company's end goal
    is to incorporate the data into a feedback chatbot application. To ensure that
    this happens correctly, you need have a file that contains negative comments.
    The expected outcome for this activity will be the Topic modeling results from
    the negative movie review files.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将对一组未知主题的文档执行主题建模。我们将考虑一个例子。假设您的雇主希望您构建一个数据管道来分析存储在具有唯一ID文件名的单独文本文件中的负面电影评论。因此，您需要执行主题建模以确定哪些文件代表相应的主题。总的来说，负面评论为公司带来更多的货币收益或损失，因此，他们优先考虑负面评论而不是正面评论。公司的最终目标是将这些数据集成到反馈聊天机器人应用程序中。为了确保这一点正确发生，您需要有一个包含负面评论的文件。此活动的预期结果将是负面电影评论文件的主题建模结果。
- en: '**Performing Topic Modeling**'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行主题建模**'
- en: 'Navigate to the following link to obtain the text data file that contains negative
    review comments: [https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/localfoldernegative_movie_review_files/cv000_29416.txt](https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/localfoldernegative_movie_review_files/cv000_29416.txt).'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到以下链接以获取包含负面评论的文本数据文件：[https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/localfoldernegative_movie_review_files/cv000_29416.txt](https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/localfoldernegative_movie_review_files/cv000_29416.txt)。
- en: Create a bucket for the Topic modelling with a unique name.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用唯一名称创建一个用于主题建模的存储桶。
- en: Create a folder for the Topic modelling.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为主题建模创建一个文件夹。
- en: Import the OS and Boto3\. Mention your unique bucket name.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入操作系统和Boto3。提及您的唯一存储桶名称。
- en: Gather all of the working directories of the local path and make them into text files.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集所有本地路径的工作目录并将它们转换为文本文件。
- en: Create a list for all of the text files.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含所有文本文件的列表。
- en: Iterate the files and upload them to S3.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历文件并将它们上传到S3。
- en: Create a job on Organization using Amazon Comprehend.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在组织中创建一个使用Amazon Comprehend的作业。
- en: As per the requirements, choose the input data. It may be **My document** or
    **Example document**.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据要求选择输入数据。它可能是 **我的文档** 或 **示例文档**。
- en: Choose the file from the data source.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据源中选择文件。
- en: Apply the input format.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用输入格式。
- en: Provide the number of topics to perform the modeling.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供要建模的主题数量。
- en: Choose an IAM role and create a job.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 IAM 角色，并创建一个作业。
- en: Download the output file and extract the file.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载输出文件并提取文件。
- en: The generated output will include the two `.CSV` files.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成的输出将包括两个 `.CSV` 文件。
- en: '**Analysis of Unknown Topics**'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**未知主题分析**'
- en: Import `Boto3` and `pandas`.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `Boto3` 和 `pandas`。
- en: Create the S3 client.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 S3 客户端。
- en: Create a new bucket with a unique name.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用唯一名称创建一个新的存储桶。
- en: Create a list of CSV filenames to import.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建要导入的 CSV 文件名列表。
- en: Check the filename and assign it to the **obj** variable.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查文件名并将其分配给 **obj** 变量。
- en: Read the **obj** variable.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取 **obj** 变量。
- en: Merge the files on the Topic column.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主题列上合并文件。
- en: Print the merged files to the console.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将合并的文件打印到控制台。
- en: Note
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To refer to the detailed steps, go to the *Appendix A* at the end of this book
    on Page no.203
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要了解详细步骤，请参阅本书末尾的附录 A，第 203 页的 *附录 A*。
- en: Summary
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about analyzing Topic modeling results from AWS
    Comprehend. You are now able to incorporate S3 to store data and can use it to
    perform analysis. In addition, we learned how to analyze documents that we know
    the topics of before performing Topic modeling, and those documents where the
    Topic is known. The latter requires additional analysis to determine the relevant
    topics.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何从 AWS Comprehend 分析主题建模结果。你现在能够将 S3 用于存储数据，并使用它进行数据分析。此外，我们还学习了在执行主题建模之前如何分析已知主题的文档，以及那些已知主题的文档。后者需要额外的分析来确定相关主题。
- en: In the next chapter, we will dive into the concept of chatbots and their understanding
    by using Natural Processing Language.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨聊天机器人的概念以及它们通过自然语言处理的理解。
