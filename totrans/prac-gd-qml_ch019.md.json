["```py\n\nimport pennylane as qml \n\nimport numpy as np \n\nimport tensorflow as tf \n\nseed = 4321 \n\nnp.random.seed(seed) \n\ntf.random.set_seed(seed)\n\n```", "```py\n\ntf.keras.backend.set_floatx(’float64’)\n\n```", "```py\n\nfrom sklearn.datasets import load_breast_cancer \n\nx,y = load_breast_cancer(return_X_y = True)\n\n```", "```py\n\nfrom sklearn.model_selection import train_test_split \n\nx_tr, x_test, y_tr, y_test = train_test_split( \n\n    x, y, train_size = 0.8) \n\nx_val, x_test, y_val, y_test = train_test_split( \n\n    x_test, y_test, train_size = 0.5)\n\n```", "```py\n\nfrom sklearn.preprocessing import MaxAbsScaler \n\nscaler = MaxAbsScaler() \n\nx_tr = scaler.fit_transform(x_tr)\n\n```", "```py\n\nx_test = scaler.transform(x_test) \n\nx_val = scaler.transform(x_val) \n\n# Restrict all the values to be between 0 and 1\\. \n\nx_test = np.clip(x_test, 0, 1) \n\nx_val = np.clip(x_val, 0, 1)\n\n```", "```py\n\nfrom sklearn.decomposition import PCA \n\npca = PCA(n_components = 4) \n\nxs_tr = pca.fit_transform(x_tr) \n\nxs_test = pca.transform(x_test) \n\nxs_val = pca.transform(x_val)\n\n```", "```py\n\nfrom itertools import combinations \n\ndef ZZFeatureMap(nqubits, data): \n\n    # Number of variables that we will load: \n\n    # could be smaller than the number of qubits. \n\n    nload = min(len(data), nqubits) \n\n    for i in range(nload): \n\n        qml.Hadamard(i) \n\n        qml.RZ(2.0 * data[i], wires = i) \n\n    for pair in list(combinations(range(nload), 2)): \n\n        q0 = pair[0] \n\n        q1 = pair[1] \n\n        qml.CZ(wires = [q0, q1]) \n\n        qml.RZ(2.0 * (np.pi - data[q0]) * \n\n            (np.pi - data[q1]), wires = q1) \n\n        qml.CZ(wires = [q0, q1]) \n\ndef TwoLocal(nqubits, theta, reps = 1): \n\n    for r in range(reps): \n\n        for i in range(nqubits): \n\n            qml.RY(theta[r * nqubits + i], wires = i) \n\n        for i in range(nqubits - 1): \n\n            qml.CNOT(wires = [i, i + 1]) \n\n    for i in range(nqubits): \n\n        qml.RY(theta[reps * nqubits + i], wires = i)\n\n```", "```py\n\nstate_0 = [[1], [0]] \n\nM = state_0 * np.conj(state_0).T\n\n```", "```py\n\nnqubits = 4 \n\ndev = qml.device(\"default.qubit\", wires=nqubits) \n\ndef qnn_circuit(inputs, theta): \n\n    ZZFeatureMap(nqubits, inputs) \n\n    TwoLocal(nqubits = nqubits, theta = theta, reps = 1) \n\n    return qml.expval(qml.Hermitian(M, wires = [0])) \n\nqnn = qml.QNode(qnn_circuit, dev, interface=\"tf\")\n\n```", "```py\n\nweights = {\"theta\": 8} \n\nqlayer = qml.qnn.KerasLayer(qnn, weights, output_dim=1)\n\n```", "```py\n\nmodel = tf.keras.models.Sequential([qlayer])\n\n```", "```py\n\nopt = tf.keras.optimizers.Adam(learning_rate = 0.005) \n\nmodel.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())\n\n```", "```py\n\nearlystop = tf.keras.callbacks.EarlyStopping( \n\n    monitor = \"val_loss\", patience = 2, verbose = 1, \n\n    restore_best_weights = True)\n\n```", "```py\n\nhistory = model.fit(xs_tr, y_tr, epochs = 50, shuffle = True, \n\n    validation_data = (xs_val, y_val), \n\n    batch_size = 20, \n\n    callbacks = [earlystop])\n\n```", "```py\n\nEpoch 1/50 \n23/23 [====] - 22s 944ms/step - loss: 0.8069 - val_loss: 0.7639 \nEpoch 2/50 \n23/23 [====] - 21s 932ms/step - loss: 0.7485 - val_loss: 0.7174 \nEpoch 3/50 \n23/23 [====] - 21s 930ms/step - loss: 0.7022 - val_loss: 0.6819 \nEpoch 4/50 \n23/23 [====] - 22s 957ms/step - loss: 0.6685 - val_loss: 0.6554 \nEpoch 5/50 \n23/23 [====] - 21s 925ms/step - loss: 0.6433 - val_loss: 0.6362 \nEpoch 6/50 \n23/23 [====] - 21s 915ms/step - loss: 0.6249 - val_loss: 0.6232 \nEpoch 7/50 \n23/23 [====] - 21s 916ms/step - loss: 0.6122 - val_loss: 0.6141 \nEpoch 8/50 \n23/23 [====] - 21s 931ms/step - loss: 0.6029 - val_loss: 0.6081 \nEpoch 9/50 \n23/23 [====] - 21s 931ms/step - loss: 0.5961 - val_loss: 0.6052 \nEpoch 10/50 \n23/23 [====] - 22s 951ms/step - loss: 0.5918 - val_loss: 0.6027 \nEpoch 11/50 \n23/23 [====] - 22s 948ms/step - loss: 0.5889 - val_loss: 0.6007 \nEpoch 12/50 \n23/23 [====] - 22s 964ms/step - loss: 0.5865 - val_loss: 0.5997 \nEpoch 13/50 \n23/23 [====] - 21s 926ms/step - loss: 0.5855 - val_loss: 0.5998 \nEpoch 14/50 \n23/23 [====] - 22s 956ms/step - loss: 0.5841 - val_loss: 0.5993 \nEpoch 15/50 \n23/23 [====] - 22s 958ms/step - loss: 0.5835 - val_loss: 0.5994 \nEpoch 16/50 \n23/23 [====] - 22s 946ms/step - loss: 0.5831 - val_loss: 0.5997 \nEpoch 16: early stopping \nRestoring model weights from the end of the best epoch: 14.\n\n```", "```py\n\nimport matplotlib.pyplot as plt \n\ndef plot_losses(history): \n\n    tr_loss = history.history[\"loss\"] \n\n    val_loss = history.history[\"val_loss\"] \n\n    epochs = np.array(range(len(tr_loss))) + 1 \n\n    plt.plot(epochs, tr_loss, label = \"Training loss\") \n\n    plt.plot(epochs, val_loss, label = \"Validation loss\") \n\n    plt.xlabel(\"Epoch\") \n\n    plt.legend() \n\n    plt.show() \n\nplot_losses(history)\n\n```", "```py\n\nfrom sklearn.metrics import accuracy_score \n\ntr_acc = accuracy_score(model.predict(xs_tr) >= 0.5, y_tr) \n\nval_acc = accuracy_score(model.predict(xs_val) >= 0.5, y_val) \n\ntest_acc = accuracy_score(model.predict(xs_test) >= 0.5, y_test) \n\nprint(\"Train accuracy:\", tr_acc) \n\nprint(\"Validation accuracy:\", val_acc) \n\nprint(\"Test accuracy:\", test_acc)\n\n```", "```py\n\nnqubits = 4 \n\ndev = qml.device(\"default.qubit\", wires=nqubits) \n\nnreps = 2 \n\nweights_dim = qml.StronglyEntanglingLayers.shape( \n\n    n_layers = nreps, n_wires = nqubits) \n\nnweights = 3 * nreps * nqubits \n\ndef qnn_circuit_strong(inputs, theta): \n\n    ZZFeatureMap(nqubits, inputs) \n\n    theta1 = tf.reshape(theta, weights_dim) \n\n    qml.StronglyEntanglingLayers(weights = theta1, \n\n                                 wires = range(nqubits)) \n\n    return qml.expval(qml.Hermitian(M, wires = [0])) \n\nqnn_strong = qml.QNode(qnn_circuit_strong, dev) \n\nweights_strong = {\"theta\": nweights}\n\n```", "```py\n\n@qml.qnode(device, interface = \"tf\", diff_method = \"method\") \n\ndef qnn(): \n\n    # Circuit goes here.\n\n```", "```py\n\nqnn = qml.QNode(circuit, device, interface = \"tf\", \n\n                diff_method = \"method\")\n\n```", "```py\n\nqml.QNode.best_method_str(dev, inter)\n\n```", "```py\n\nqnn = qml.QNode(qnn_circuit, dev, \n\n    interface=\"tf\", diff_method=\"adjoint\")\n\n```", "```py\n\nmethod = \"adjoint\" # Set it to whatever you want! \n\ntf.random.set_seed(seed) \n\nqnn = qml.QNode(qnn_circuit, dev, interface=\"tf\", \n\n                diff_method = method) \n\nqlayer = qml.qnn.KerasLayer(qnn, weights, output_dim=1) \n\nmodel = tf.keras.models.Sequential([qlayer]) \n\nopt = tf.keras.optimizers.Adam(learning_rate = 0.005) \n\nmodel.compile(opt, loss=tf.keras.losses.BinaryCrossentropy()) \n\nhistory = model.fit(xs_tr, y_tr, epochs = 50, shuffle = True, \n\n    validation_data = (xs_val, y_val), \n\n    batch_size = 20, \n\n    callbacks = [earlystop])\n\n```", "```py\n\nfrom qiskit.circuit.library import ZZFeatureMap, TwoLocal \n\nnqubits = 3 # We’ll do it for three qubits. \n\nzzfm = ZZFeatureMap(nqubits, reps = 1) \n\ntwol = TwoLocal(nqubits, ’ry’, ’cx’, ’linear’, reps = 1) \n\n# Change rep(etition)s above to suit your needs.\n\n```", "```py\n\nfrom qiskit_machine_learning.neural_networks import TwoLayerQNN \n\nfrom qiskit.providers.aer import AerSimulator \n\nqnn = TwoLayerQNN(nqubits, feature_map = zzfm, ansatz = twol, \n\n                  quantum_instance = AerSimulator(method=\"statevector\"))\n\n```", "```py\n\nqnn.forward(np.random.rand(qnn.num_inputs), \n\n            np.random.rand(qnn.num_weights))\n\n```", "```py\n\nfrom qiskit_machine_learning.algorithms.classifiers import \\ \n\n    NeuralNetworkClassifier \n\nclassifier = NeuralNetworkClassifier(qnn)\n\n```", "```py\n\nclassifier.fit(data_train, labels_train)\n\n```", "```py\n\noutcomes = classifier.predict(data_test)\n\n```", "```py\n\nacc = classifier.score(data_test, labels_test)\n\n```"]