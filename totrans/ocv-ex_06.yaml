- en: Chapter 6. Learning Object Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we introduced you to the basic concepts of object segmentation
    and detection. This means isolating the objects that appear in an image for future
    processing and analysis.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: This chapter covers how to classify each of these isolated objects. In order
    to allow us to classify each object, we need to train our system to be capable
    of learning the required parameters to decide which specific label should be assigned
    to the detected object (depending on the different categories taken into account
    during the training phase).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is going to introduce you to the basic concepts of machine learning
    to classify images with different labels.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: We will create a basic application based on the segmentation algorithm, as discussed
    in [Chapter 5](ch05.html "Chapter 5. Automated Optical Inspection, Object Segmentation,
    and Detection"), *Automated Optical Inspection, Object Segmentation, and Detection*.
    This segmentation algorithm extracts parts of an image, which contains objects.
    For each object, we will extract the different features and analyze them using
    a machine learning algorithm. Using a machine learning algorithm, we are able
    to show, using our user interface, the labels of each object detected in the input
    image to the end user.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the different topics and algorithms, which are
    as follows:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to machine learning concepts
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common machine learning algorithms and processes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature extraction
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support vector machines
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and prediction
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing machine learning concepts
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning is an old concept that was defined in 1959 by Arthur Samuel
    as a *field of study that gives computers the ability to learn without being explicitly
    programmed*. Tom. M. Mitchel provided a more formal definition. In this definition,
    Tom links the concept of samples or experiences, labels, and performance measurements.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The machine learning definition by Arthur Samuel is referenced from *Some Studies
    in Machine Learning Using the Game of Checkers* in the *IBM Journal of Research
    and Development* (Volume: 3, Issue: 3), p. 210 and a phrase in *The New Yorker*
    and *Office Management* the same year.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: The more formal definition by Tom. M. Mitchel is referenced from *Machine Learning
    Book*, McGray Hill 1997 ([http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html](http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning involves pattern recognition and the learning theory in artificial
    intelligence and is related to computational statistics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning is used in hundreds of applications such as **OCR** (**Optical
    Character Recognition**), spam filtering, search engines, and thousands of Computer
    Vision applications that we will develop in the current chapter, where a machine
    learning algorithm tries to classify the objects that appear in the input image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on how machine ML algorithms learn from the data or samples, we can
    divide them into three categories, which are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised learning**: The computer learns from a set of labeled data. The
    goal is to learn the parameters of the model and rules that allow computers to
    map the relation between data and output label results.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unsupervised learning**: No labels are given, and the computer tries to discover
    the input structure of the input data.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reinforcement learning**: The computer interacts with a dynamic environment
    that performs its goal and learns from its mistakes.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Depending on the desired results that we obtain from our machine learning algorithm,
    we can categorize them into the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification**: In classification, the space of the inputs can be divided
    into *N* classes, and the prediction results of a given sample are one of these
    training classes. This is one of the most used categories. A typical example is
    an e-mail spam filtering where there are only two classes: spam and non spam or
    OCR, where only *N* characters are available, and each character is one class.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression**: The output is a continuous value instead of a discrete value
    such as a classification result. One example of regression can be the prediction
    of the house price by providing the house size, number of years, and location.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering**: The inputs are divided into *N* groups using unsupervised training.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Density estimation**: This finds the (probability) distribution of inputs.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our example, we will use a supervised learning classification algorithm,
    where a training dataset (with labels) is used to train the model, and the result
    of our model is a prediction of one label.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning is a modern approach to artificial intelligence and statistics
    and involves both the techniques.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, there are several approaches and methods, and some of them
    used are **SVM** (**support vector machines**), **ANNs** (**artificial neural
    networks**), clustering such as **K-Nearest Neighbors**, **decision trees,** or
    deep learning, which is a big **neural network** approach used in some cases that
    are convolutional, and so on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: All these methods and approaches are supported, implemented, and well-documented
    in OpenCV. We are going to explain one of them, SVM, in the next section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenCV implements eight of these machine learning algorithms. They all inherit
    from the `StatModel` class:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Artificial neural networks
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boost
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random trees
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expectation maximization
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-Nearest Neighbours
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Normal Bayes Classifier
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support vector machines
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To get more details of each algorithm, read the OpenCV document page of machine
    learning at [http://docs.opencv.org/trunk/dc/dd6/ml_intro.html](http://docs.opencv.org/trunk/dc/dd6/ml_intro.html).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following image, you can see the machine learning class hierarchy:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![Introducing machine learning concepts](img/B04283_06_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: The `StatModel` class provides all the `read` and `write` functions that are
    very important to save our machine learning parameters and training data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, the most time-consuming part is the `training` method.
    Training can take from seconds to weeks or months for large datasets and complex
    machine learning structures; for example, in deep learning and a big neural network
    structure with more than 100,000 images. In deep learning algorithms, it is common
    to use parallel hardware processing; for example, GPUs or graphic cards with the
    CUDA technology used to decrease the computing time during training.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: This means that we cannot train our algorithm each time we run our application,
    and it's recommended that we save our model after it is trained because all training/prediction
    parameters of machine learning are saved. Next, when we want to run it in the
    future, we only need to load/read from our saved model without training anymore
    if we need to update our model with more data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: The `StatModel` is an interface that is implemented by each of its implementations.
    The two key functions are `train` and `predict`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The `train` method is responsible for learning the parameters of the model
    from a training dataset. The `train` function has the following four calls that
    can be called in four different ways:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'It has the following parameters:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '`trainData`: This is the training data that can be loaded or created from the
    `TrainData` class. This class is new in OpenCV 3 and helps developers to create
    training data because different algorithms require different types of structure
    of arrays for training and prediction, such as the ANN algorithm.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`samples`: This is the array of training array samples such as training data
    in the format required by the machine learning algorithm.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`layout`: There are two types of layouts: `ROW_SAMPLE` (training samples are
    the matrix rows) and `COL_SAMPLE` (training samples are the matrix columns).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`responses`: This is the vector of responses that is associated with the sample
    data.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`p`: This is the `StatModel` parameter.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flags`: These are optional flags defined by each method.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `predict` method is simpler and has only one call:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'It has the following parameters:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '`samples`: These are the input samples to be predicted. There can be only one
    or multiple data to be predicted.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`results`: This is the result of each input row samples (computed by the algorithm
    from the previously trained model).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flags`: These are optional flags that are model-dependent. Some models, such
    as Boost and SVM recognize the `StatModel::RAW_OUTPUT` flag, which makes the method
    return the raw results (the sum) and not the class label.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `StatModel` class provides other very useful methods, which are as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '`isTrained()`: This returns `true` if the model is trained'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`isClassifier()`: This returns `true` if the model is a classifier or `false`
    in the case of regression'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getVarCount()`: This returns the number of variables in training samples'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save(const string& filename)`: This saves the model in the filename'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Ptr<_Tp> load(const string& filename)`: This loads the model from the filename,
    for example: `Ptr<SVM> svm = StatModel::load<SVM>("my_svm_model.xml");`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`calcError(const Ptr<TrainData>& data, bool test, OutputArray resp)`: This
    calculates the error from a test data, where the data is the training data. If
    the test is `true`, the method calculates the error from the test subset of all
    the training data, otherwise it''s computed over the training subset of the data.
    Finally `resp` is the optional output results.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we will learn how to construct a basic application that uses machine learning
    in Computer Vision apps.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Computer Vision and the machine learning workflow
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Computer Vision applications with machine learning have a common basic
    structure. This structure is divided into different steps that are repeated in
    almost all Computer Vision applications, and some others are omitted. In the following
    diagram, we show you the different steps involved:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '![Computer Vision and the machine learning workflow](img/B04283_06_02.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
- en: Almost any Computer Vision application starts with a preprocessing stage that
    is applied to the input image. Preprocessing involves light removal conditions
    and noise, thresholding, blur, and so on.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: After we apply all the preprocessing steps required to the input image, the
    second step is segmentation. In the segmentation step, we need to extract the
    regions of interest of an image and isolate each one as a unique object of interest.
    For example, in a face detection system, we need to separate the faces from the
    rest of the parts in the scene.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: After getting the objects inside the image, we continue with the next step.
    We need to extract all the features of each one detected object; a feature is
    a vector of characteristics of objects. A characteristic describes our objects
    and can be the area of the object, contour, texture pattern, and so on.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we have the descriptor of our object; a descriptor is a feature that describes
    an object, and we use these descriptors to train our model or predict one of them.
    To do this, we need to create a big dataset of features, where hundreds, thousands,
    and millions of images are preprocessed, and extracted features use all these
    features in a train model function that we choose:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![Computer Vision and the machine learning workflow](img/B04283_06_03.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: 'When we train a dataset, the model learns all the parameters required to predict
    when a new vector of features with an unknown label is given:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![Computer Vision and the machine learning workflow](img/B04283_06_04.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: After we get the prediction, sometimes, a post-processing of output data is
    required; for example, merging multiple classifications to decrease the prediction
    error or merging multiple labels. A sample case is **OCR** (**Optical Character
    Recognition**), where the classification result is per character, and by combining
    the results of character recognitions, we construct a word. This means that we
    can create a post-processing method to correct errors in detected words.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: With this small introduction to machine learning for Computer Vision, we will
    learn how to implement our own application that uses machine learning to classify
    objects in a slide tape. We will use support vector machines as our classification
    methods, and see how to use them. The other machine learning algorithms have very
    similar uses. The OpenCV documentation has a detailed information about all machine
    learning algorithms.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Automatic object inspection classification example
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuing with the example of the previous chapter, the automatic object inspection
    segmentation, where a carrier tape contains three different types of objects (nuts,
    screws, and rings), and with Computer Vision, we will be able to recognize each
    one of them to send notifications to a robot or similar to put each one in different
    boxes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '![Automatic object inspection classification example](img/B04283_06_05.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
- en: In [Chapter 5](ch05.html "Chapter 5. Automated Optical Inspection, Object Segmentation,
    and Detection"), *Automated Optical Inspection, Object Segmentation, and Detection,*
    we preprocessed the input images and extracted the regions of interest of images
    and isolated each object using different techniques. Now, we will apply all these
    concepts, as explained in previous sections, in this example to extract features
    and classify each object and allow to possible robot to put each one in different
    boxes. In our application, we are only going to show the labels of each image
    in an image, but we can send the positions in the image and the labels to other
    devices as a robot.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, our goal is from an input image with few objects to show the objects''
    names over each one, as per the following image. However, to learn all the steps
    of the complete process, we will train our system to show each image that is trained,
    create a plot to show each object the features that we are going to use with different
    colors, the preprocessed input image, and finally, the output classification result
    with the following result:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![Automatic object inspection classification example](img/B04283_06_06.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: 'We will perform the following steps for our example application:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'For training each image:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preprocess an image
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Segment an image
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each object in an image:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the features
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Add the object to the training feature vector with its label
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an SVM model.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train our SVM model with the training feature vector.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preprocess an input image to be classified.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Segment an input image.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each object detected:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the features
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Predict with an SVM model
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Paint the result in an output image
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For the preprocessing and segmentation stage, we will use the code discussed
    in [Chapter 5](ch05.html "Chapter 5. Automated Optical Inspection, Object Segmentation,
    and Detection"), *Automated Optical Inspection, Object Segmentation, and Detection*,
    and we will explain how to extract the features and create the vectors required
    to train and predict our model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's extract the features of each object. To understand the feature concept
    of a feature vector, we will extract very simple features, but it is enough to
    get good results. In other solutions, we can get more complex features, such as
    texture descriptors, contour descriptors, and so on.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we only have these three types of objects, *nuts*, *rings*,
    and *screws*, in different possible positions. All these possible objects and
    positions are shown in the following figure:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![Feature extraction](img/B04283_06_07.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: 'We will explore the good characteristics that will help the computer to identify
    each object. The characteristics are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: The area of an object
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The aspect ratio, which is the width divided by the height of the bounding rectangle
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of holes
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of contour sides
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These characteristics can describe our objects very well, and if we use all
    of them, the classification error can be very small. However, in our implemented
    example, we will use only the first two characteristics, the area and aspect ratio,
    for learning purposes because we can plot these characteristics in 2D graphics,
    and we can show that these values describe our objects correctly. We can differentiate
    one kind of object from the others visually in the graphic plot.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'To extract these features, we will use the black/white input ROI image as the
    input, where only one object appears in a white color with a black background.
    This input is the result of segmentation, as discussed in [Chapter 5](ch05.html
    "Chapter 5. Automated Optical Inspection, Object Segmentation, and Detection"),
    *Automated Optical Inspection, Object Segmentation, and Detection*. We will use
    the `findCountours` algorithm for segmentation objects and create the `ExtractFeatures`
    function for this purpose:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let's understand the code in detail.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: We will create a function that has one image as the input and returns two vectors
    of left and top position for each object detected in the image as parameters;
    this will be used to draw its label over each object. The output of the function
    is a vector of vectors of floats; in other words, a matrix where each row contains
    the features of each object that is detected.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a function that draws a label over each other:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we need to create the output vector variable and contours variable
    that are to be used in our `FindContours` algorithm segmentation, and we need
    to create a copy of our input image because the `findContours` OpenCV functions
    modify the input image:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can use the `findContours` function to retrieve each object in an image.
    If we don''t detect any contour, we return an empty output matrix:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For each object `contour` we are going to draw in a black image each object
    using `1` as the color value. This is our mask image to compute all features:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'It''s important to use the value `1` to draw inside the shape because we can
    calculate the area by summing all values inside the contour:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This area is our first feature. Now, we will use this area value as a filter
    to remove the small objects that we need to avoid. All objects with an area less
    than a minimum area are discarded. After we pass the filter, we create the second
    feature, that is, the aspect ratio of an object. This means that the maximum width
    or height is divided by the minimum width or height. This feature can differentiate
    the screw from other objects easily:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we have the features, and we only need to add these features to the output
    vector. To do this, we create a row vector of floats and add these values, and
    later on, add this row to the output vector:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If the left and top `params` are passed, then add the top-left values to the
    `params` output:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we will show the detected objects in a window for the user feedback,
    and when we finish processing all the objects in the image, we will return the
    output feature vector:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now, we can extract the features of each input image, and we need to continue
    with the next step, which is to train our model.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Training an SVM model
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use a supervised learning model, and then, we will require images of
    each object and their corresponding labels. There are no minimum number of images
    in the dataset. If we provide more images for the training process, we will get
    a better classification model (in most of the cases), but simple classifiers can
    be enough to train simple models. To do this, we create three folders (`screw`,
    `nut`, and `ring`), where all the images of each type are placed together.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: For each image in the folder, we need to extract the features and add them to
    the train feature matrix, and at same time, we need to create a new vector with
    the labels for each row, corresponding to each training matrix.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate our system, we split each folder into a number of images for testing
    and training purposes. We leave around 20 images for testing and the others for
    training. Then, we need to create two vectors of labels and two matrices for train
    and test.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, let''s understand the code. First, we need to create our model. We need
    to declare the model in order to be able access it as a global variable. OpenCV
    uses the `Ptr` template class for pointers:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After we declare the pointer to the new SVM model, we need to create it and
    train it. We create the `trainAndTest` function for this purpose:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let's understand the code in detail.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create the required variables to store the training and test
    data:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As mentioned earlier, we need to read all the images from each folder, extract
    the features, and save them in our training and test data. To do this, we will
    use the `readFolderAndExtractFeatures` function:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `readFolderAndExtractFeatures` function uses the `VideoCapture` OpenCV
    function to read all the images of a folder like a video or camera. For each image
    read, we extract the features and then add them to the corresponding output vector:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'After filling all the vectors with features and labels, we need to convert
    them to the OpenCV `mat` format in order to send them to the `training` function:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We are now ready to create and train our machine learning model, as mentioned
    earlier, and we are going to use a support vector machine. First, we need to set
    up the basic model parameters:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We need to define the SVM type and kernel to be used and the criteria to stop
    the learning process; in our case, we will use a maximum number of iterations,
    stopping at 100 iterations. For more information on each parameter and what it
    does, check out the OpenCV documentation. After we create the parameters of the
    setup, we need to create the model by calling the `train` method and using the
    `trainingDataMat` and response matrices:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We use the test vector (by setting the `num_for_test` variable greater than
    `0`) to obtain an approximation error of our model. To get the error estimation,
    we need to predict all the test vector features to obtain the SVM prediction results
    and then compare these results to the original labels:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We use the `predict` function using the `testDataMat` features and a new `mat`
    to predict results. The `predict` function allows you to do multiple predictions
    at the same time, giving a matrix instead of only one row.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: After the prediction is done, we only need to get the difference of `testPredict`
    using our `testResponses` (the original labels). If there are differences, we
    only need to count the number of differences and divide them by the total number
    of tests to get the error.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can use the new `TrainData` class to generate the feature vectors and samples
    and split out train data in test and train vectors.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we need to show the training data in a 2D plot, where the *y* axis
    is the aspect ratio feature and the *x* axis is the area of objects. Each point
    has a different color and shape (cross, square, and circle) that shows a different
    kind of object, and we can clearly see the groups of objects in the following
    figure:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![Training an SVM model](img/B04283_06_08.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: Now, we are very close to finishing our application sample. We have a trained
    SVM model that we can use as a classification model to detect the type of a new
    incoming and unknown feature vector. Then, the next step is to predict an input
    image with unknown objects.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Input image prediction
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we are ready to explain the main function, which loads the input image
    and predicts the objects that appear inside. We are going to use something like
    this, as shown in the following figure, as the input image where multiple and
    different objects appear:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![Input image prediction](img/B04283_06_09.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: 'For all training images, we need to load and preprocess the input image:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: First, we load and convert the images to gray color values.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then apply the preprocessing tasks, as discussed in [Chapter 5](ch05.html
    "Chapter 5. Automated Optical Inspection, Object Segmentation, and Detection"),
    *Automated Optical Inspection, Object Segmentation, and Detection,* using the
    `preprocessImage` function:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we extract the features of vectors of all the objects that appear in the
    image and the top-left positions of each one using the `ExtractFeatures` that
    we mentioned earlier:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'For each object that we detect, we store it as a feature row, and then, we
    convert each row as a `Mat` of one row and two features:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we predict the single object using the `predict` function of our `StatModel`
    SVM:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The float result of the prediction is the label of the object that is detected.
    Then, to complete the application, we only need to draw the label over each image
    in an output image.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will use a `stringstream` to store the text and a `Scalar` to store the
    color of each different label:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Draw the label text over each object using its detected position in the `ExtractFeatures`
    function:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, we will draw our results in the output window:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The final result of our application shows a window that is tiled with four
    screens, where the top-left image is the input training image, the top-right image
    is the plot training image, the bottom-left image is the input image to analyze
    preprocessed, and the bottom-right image is the final result of the prediction:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '![Input image prediction](img/B04283_06_10.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
- en: Summary
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned the basics of the machine learning model and how
    to apply a small sample application to understand all the basic tips required
    to create our own ML application.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning is complex and involves different techniques for each use case
    (supervised learning, unsupervised, clustering, and so on), and we learned how
    to create the most typical ML application and the supervised learning with an
    SVM.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'The most important concepts in supervised machine learning are: first, we need
    to have an appropriate number of samples or datasets; and second, we need to correctly
    choose the features that describe our objects correctly. For more information
    on image features, refer to [Chapter 8](ch08.html "Chapter 8. Video Surveillance,
    Background Modeling, and Morphological Operations"), *Video Surveillance, Background
    Modeling, and Morphological Operations*. Third, choose the best model that gives
    us the best predictions.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: If we don't reach the correct predictions we have to check each one of these
    concepts to look for where the issue is.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce background subtraction methods, which
    are very useful for video surveillance applications where the backgrounds don't
    give us any interesting information and must be discarded to allow the segmentation
    of the interested objects in which to analyze.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍背景减法方法，这对于视频监控应用非常有用，在这些应用中，背景不提供任何有趣的信息，必须被丢弃，以便对感兴趣的对象进行分割和分析。
