<html><head></head><body>
  <div class="calibre1" id="_idContainer145">
    <h1 class="chapternumber">14</h1>
    <h1 class="chaptertitle" id="_idParaDest-299">Building an MLP Model for Fashion-MNIST with ChatGPT</h1>
    <h1 class="heading" id="_idParaDest-300">Introduction</h1>
    <p class="normal">Building upon our foundational understanding of predictive modeling, we now dive into the dynamic world of <strong class="screentext">Multilayer Perceptron</strong> (<strong class="screentext">MLP</strong>) models. In this chapter, we embark on a journey to construct an MLP model from scratch, leveraging the versatility and power of neural networks for predictive analytics.</p>
    <p class="normal1">Our exploration of MLPs represents a significant leap into the realm of complex modeling techniques. While linear regression provided valuable insights into modeling relationships within data, MLPs offer a rich framework for capturing intricate patterns and nonlinear dependencies, making them well suited for a wide range of predictive tasks.</p>
    <p class="normal1">Through hands-on experimentation and iterative refinement, we will unravel the intricacies of MLP architecture and optimization. From designing the initial network structure to fine-tuning hyperparameters and incorporating advanced techniques such as batch normalization and dropout, we aim to equip you with the knowledge and skills to harness the full potential of neural networks in predictive modeling.</p>
    <p class="normal1">As we navigate through the construction and optimization of our MLP model, we will delve into the underlying principles of neural network dynamics, exploring how different architectural choices and optimization strategies influence model performance and generalization capabilities.</p>
    <h1 class="heading" id="_idParaDest-301">Business problem</h1>
    <p class="normal">A fashion e-commerce<a id="_idIndexMarker563" class="calibre3"/> store seeks to optimize customer engagement and increase revenue by leveraging machine learning techniques to gain deeper insights into customer behavior and preferences. By analyzing image data representing various fashion items purchased by customers, the store aims to tailor its product recommendations, improve customer satisfaction, and enhance the overall shopping experience.</p>
    <h1 class="heading" id="_idParaDest-302">Problem and data domain</h1>
    <p class="normal">In this chapter, we will employ <a id="_idIndexMarker564" class="calibre3"/>MLP models to understand the relationship between customers’ preferences and their purchasing patterns using the Fashion-MNIST dataset. MLP models offer a powerful framework for image classification tasks, allowing us to predict the type of clothing or accessory a customer is likely to purchase based on their interactions with the online store. By uncovering patterns in customer preferences, the e-commerce store can personalize recommendations and optimize inventory management to meet the diverse needs of its customer base.</p>
    <h2 class="heading1" id="_idParaDest-303">Dataset overview</h2>
    <p class="normal">The fashion e-commerce store <a id="_idIndexMarker565" class="calibre3"/>collects image data representing various fashion items, categorized into different classes, from its customers. The Fashion-MNIST dataset<a id="_idIndexMarker566" class="calibre3"/> comprises 70,000 grayscale images of clothing and accessories, each associated with a specific label indicating its category and of size 28x28.</p>
    <p class="normal1">Features in the dataset include:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Image data</strong>: Grayscale images of fashion items, each represented as a matrix of pixel intensities. These images serve as the input data for training the MLP model.</li>
      <li class="bulletlist1"><strong class="screentext">Label</strong>: The category label assigned to each image, representing the type of clothing or accessory depicted. Labels range from 0 to 9, corresponding to classes such as T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot.</li>
    </ul>
    <p class="normal1">By analyzing this <a id="_idIndexMarker567" class="calibre3"/>image data and its corresponding labels, we aim to train an MLP model capable of accurately classifying fashion items based on their visual features. This predictive model will enable the e-commerce store to <a id="_idIndexMarker568" class="calibre3"/>make personalized product recommendations, enhance customer engagement, and ultimately increase revenue by providing a seamless shopping experience tailored to individual preferences.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_14_01.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.1: Fashion-MNIST dataset</p>
    <h1 class="heading" id="_idParaDest-304">Breaking the problem down into features</h1>
    <p class="normal">Given the nature of the <a id="_idIndexMarker569" class="calibre3"/>Fashion-MNIST dataset, which comprises grayscale images of fashion items categorized into different classes, we will start by building a baseline MLP model. This will involve the following high-level steps:</p>
    <ol class="calibre16">
      <li class="bulletlist1" value="1"><strong class="screentext">Building the baseline model</strong>: Users will understand the process of constructing a simple MLP model for image classification using ChatGPT. We will guide users through loading the Fashion-MNIST dataset, preprocessing the image data, splitting it into training and testing sets, defining the model architecture, training the model, making predictions, and evaluating its performance.</li>
      <li class="bulletlist1"><strong class="screentext">Adding layers to the model</strong>: Once the baseline model is established, users will learn how to experiment with adding additional layers to the MLP architecture. We will explore how increasing the depth or width of the model impacts its performance and capacity to capture complex patterns in the image data.</li>
      <li class="bulletlist1"><strong class="screentext">Experimenting with batch sizes</strong>: Users will experiment with different batch sizes during model training to observe their effects on training speed, convergence, and generalization performance. We will explore how varying batch sizes influence the trade-off between computation efficiency and model stability.</li>
      <li class="bulletlist1"><strong class="screentext">Adjusting the number of neurons</strong>: Users will explore the impact of adjusting the number of neurons in each layer of the MLP model. By increasing or decreasing the number of neurons, users can observe changes in model capacity and its ability to learn intricate features from the image data.</li>
      <li class="bulletlist1"><strong class="screentext">Trying different optimizers</strong>: Finally, users will experiment with different optimization algorithms, such as SGD, Adam, and RMSprop, to optimize the training process of the MLP model. We will observe how different optimizers<a id="_idIndexMarker570" class="calibre3"/> influence training dynamics, convergence speed, and final model performance.</li>
    </ol>
    <p class="normal1">By following these steps, users will gain a comprehensive understanding of building and optimizing MLP models for image classification tasks using the Fashion-MNIST dataset. They will learn how to iteratively refine the model architecture and training process to achieve optimal performance and accuracy in classifying fashion items.</p>
    <h1 class="heading" id="_idParaDest-305">Prompting strategy</h1>
    <p class="normal">To leverage ChatGPT for machine learning we need to have a clear understanding of how to implement the prompting strategies specifically for code generation for machine learning.</p>
    <p class="normal1">Let’s brainstorm what we would like to achieve in this task to get a better understanding of what needs to go into prompts.</p>
    <h2 class="heading1" id="_idParaDest-306">Strategy 1: Task-Actions-Guidelines (TAG) prompt strategy</h2>
    <p class="normal"><strong class="screentext">1.1 - Task</strong>: The<a id="_idIndexMarker571" class="calibre3"/> specific task or goal is to create a classification model for the Fashion-MNIST dataset.</p>
    <p class="normal1"><strong class="screentext">1.2 - Actions</strong>: The key steps involved in creating a classification model using an MLP for the Fashion-MNIST dataset are:</p>
    <ul class="calibre15">
      <li class="bulletlist">Data preprocessing: Normalize pixel values, flatten images into vectors, and encode categorical labels.</li>
      <li class="bulletlist1">Data splitting: Partition the dataset into training, validation, and testing sets.</li>
      <li class="bulletlist1">Model selection: Opt for an MLP as the classification model.</li>
      <li class="bulletlist1">Model training: Train the MLP on the training data.</li>
      <li class="bulletlist1">Model evaluation: Use metrics like accuracy, precision, recall, and confusion matrix to evaluate the model’s performance.</li>
    </ul>
    <p class="normal1"><strong class="screentext">1.3 - Guidelines</strong>: We will provide the following guidelines to ChatGPT in our prompt:</p>
    <ul class="calibre15">
      <li class="bulletlist">The code should be compatible with Jupyter notebook.</li>
      <li class="bulletlist1">Ensure that there are detailed comments for each line of code. </li>
      <li class="bulletlist1">You have to explain each line of code, which will be then copied into the text block of the notebook, in detail for each method used in the code before providing the code.</li>
    </ul>
    <h2 class="heading1" id="_idParaDest-307">Strategy 2: Persona-Instructions-Context (PIC) prompt strategy</h2>
    <p class="normal"><strong class="screentext">2.1 - Persona</strong>: We <a id="_idIndexMarker572" class="calibre3"/>will adopt the persona of a beginner who needs to learn different steps of model creation, hence the code should be generated step by step.</p>
    <p class="normal1"><strong class="screentext">2.2 - Instructions</strong>: We have specified that we want the code generated for an MLP model with a single layer <em class="italic">and have instructed ChatGPT to provide one step at a time and wait for the user’s feedback.</em></p>
    <p class="normal1"><strong class="screentext">2.3 - Context</strong>: In this case, ChatGPT <a id="_idIndexMarker573" class="calibre3"/>is already aware of the Fashion-MNIST dataset, as it is widely known, so we do not need to provide additional context.</p>
    <h2 class="heading1" id="_idParaDest-308">Strategy 3: Learn-Improvise-Feedback-Evaluate (LIFE) prompt strategy</h2>
    <p class="normal"><strong class="screentext">3.1 - Learn</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">We want to learn<a id="_idIndexMarker574" class="calibre3"/> about MLP models and how they work.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.2 - Improvise</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">We will use this knowledge later when adding more layers, changing the batch size or activation functions, and so on.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.3 - Feedback</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">Share code and model outputs for feedback to ensure effective learning and understanding.</li>
      <li class="bulletlist1">Incorporate suggestions and critiques to refine the model and the approach<strong class="screentext">.</strong></li>
      <li class="bulletlist1">Provide errors to troubleshoot and resolve the issues.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.4- Evaluate</strong>: </p>
    <p class="normal1">Execute the code provided by ChatGPT to ensure accuracy and validity. This is used throughout the chapter.</p>
    <h1 class="heading" id="_idParaDest-309">Building an MLP model to accurately classify the Fashion-MNIST images using the free version of ChatGPT</h1>
    <p class="normal">ChatGPT’s <a id="_idIndexMarker575" class="calibre3"/>premium version has a code interpreter, but it doesn’t support the deep learning libraries such as Keras and TensorFlow required to execute the code. Hence, for this chapter, we will stick to the free version of ChatGPT. </p>
    <h2 class="heading1" id="_idParaDest-310">Feature 1: Building the baseline model</h2>
    <p class="normal">Let’s <a id="_idIndexMarker576" class="calibre3"/>craft our initial prompt for baseline model.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">I want to create a simple classification model for the Fashion-MNIST dataset (TAG 1.1) consisting of a single-layer MLP model (PIC 2.2). It should consist of the following steps (TAG1.2), provide one step at a time, and wait for the user’s feedback (PIC 2.2).</p>
    <ul class="calibre15">
      <li class="bulletlist">Data Preprocessing: Normalize pixel values, flatten images into vectors, and encode categorical labels.</li>
      <li class="bulletlist1">Data Splitting: Partition the dataset into training, validation, and testing sets.</li>
      <li class="bulletlist1">Model Selection: Opt for a Multi-Layer Perceptron (MLP) as the classification model.</li>
      <li class="bulletlist1">Model Training: Train the MLP on the training data.</li>
      <li class="bulletlist1">Model Evaluation: Use metrics like accuracy, precision, recall, and confusion matrix to evaluate the model’s performance.</li>
    </ul>
    <p class="normal1">I am a beginner user (PIC 2.1), so please provide step-by-step code and strictly follow the below instructions (TAG 1.3): </p>
    <p class="normal1">The code should be compatible with the Jupyter Notebook.</p>
    <p class="normal1">Ensure that there are detailed comments for each line of code. </p>
    <p class="normal1">You have to explain each line of code, which will be then copied into the text block of notebook, in detail for each method used in the code before providing the code.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">You should receive a response similar to the following, where ChatGPT has provided us with the code for step 1, Data Preprocessing, along with detailed comments and explanations.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure, let’s start with the first step: Data Preprocessing.</p>
    <p class="normal1">Data Preprocessing:</p>
    <ul class="calibre15">
      <li class="bulletlist">Data preprocessing is a crucial step in machine learning, where we prepare our data for training by applying various transformations and normalization techniques. In this step, we’ll normalize the pixel values, flatten the images into vectors, and encode categorical labels.</li>
    </ul>
    <p class="normal1">Normalize Pixel Values:</p>
    <ul class="calibre15">
      <li class="bulletlist">Normalizing pixel values ensures that each pixel’s value is scaled to a range between 0 and 1. This is important for the neural network to converge faster during training and to prevent any particular feature from dominating the learning process.</li>
    </ul>
    <p class="normal1">Flatten Images into Vectors:</p>
    <ul class="calibre15">
      <li class="bulletlist">MLP <a id="_idIndexMarker577" class="calibre3"/>models cannot directly work with multi-dimensional data like images. Hence, we need to flatten the images into 1D vectors, where each pixel value becomes a feature.</li>
    </ul>
    <p class="normal1">Encode Categorical Labels:</p>
    <ul class="calibre15">
      <li class="bulletlist">Since our labels are categorical (e.g., different types of clothing items), we need to encode them into numerical values so that our model can understand and learn from them.</li>
    </ul>
    <p class="normal1">Now, let’s implement these steps in code:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> tensorflow.keras.datasets <span class="hljs-keyword">import</span> fashion_mnist
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler, LabelEncoder
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-comment"># Step 1: Load Fashion-MNIST dataset</span>
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
<span class="hljs-comment"># Step 2: Normalize pixel values</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">normalize_images</span>(<span>train_data, test_data</span>):
    <span class="hljs-comment"># Convert to float32 to ensure division results in float</span>
    train_data = train_data.astype(<span class="hljs-string">'float32'</span>)
    test_data = test_data.astype(<span class="hljs-string">'float32'</span>)
    <span class="hljs-comment"># Normalize pixel values to the range 0-1</span>
    train_data /= <span class="hljs-attr">255.0</span>
    test_data /= <span class="hljs-attr">255.0</span>
    <span class="hljs-keyword">return</span> train_data, test_data
<span class="hljs-comment"># Step 3: Flatten images into vectors</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">flatten_images</span>(<span>train_data, test_data</span>):
    <span class="hljs-comment"># Reshape images to vectors</span>
    train_data = train_data.reshape(train_data.shape[<span class="hljs-attr">0</span>], -<span class="hljs-attr">1</span>)
    test_data = test_data.reshape(test_data.shape[<span class="hljs-attr">0</span>], -<span class="hljs-attr">1</span>)
    <span class="hljs-keyword">return</span> train_data, test_data
<span class="hljs-comment"># Step 4: Encode categorical labels</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">encode_labels</span>(<span>train_labels, test_labels</span>):
    <span class="hljs-comment"># Initialize LabelEncoder</span>
    label_encoder = LabelEncoder()
    <span class="hljs-comment"># Fit LabelEncoder on training labels and transform both training and testing labels</span>
    train_labels = label_encoder.fit_transform(train_labels)
    test_labels = label_encoder.transform(test_labels)
    <span class="hljs-keyword">return</span> train_labels, test_labels
<span class="hljs-comment"># Apply data preprocessing steps</span>
x_train, x_test = normalize_images(x_train, x_test)
x_train, x_test = flatten_images(x_train, x_test)
y_train, y_test = encode_labels(y_train, y_test)
<span class="hljs-comment"># Print the shapes of preprocessed data</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"x_train shape:"</span>, x_train.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"y_train shape:"</span>, y_train.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"x_test shape:"</span>, x_test.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"y_test shape:"</span>, y_test.shape)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We<a id="_idIndexMarker578" class="calibre3"/> import necessary libraries such as NumPy for numerical operations, TensorFlow for loading the Fashion-MNIST dataset, and scikit-learn for data preprocessing.</li>
      <li class="bulletlist1">We load the Fashion-MNIST dataset using the <code class="inlinecode">fashion_mnist.load_data()</code> method and split it into training and testing sets.</li>
      <li class="bulletlist1">Three functions, <code class="inlinecode">normalize_images</code>, <code class="inlinecode">flatten_images</code>, and <code class="inlinecode">encode_labels</code>, are defined to perform each data preprocessing step.</li>
    </ul>
    <p class="normal1">Inside each function:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">normalize_images</code> divides pixel values by 255 to scale them between 0 and 1.</li>
      <li class="bulletlist1"><code class="inlinecode">flatten_images</code> reshapes the images into 1D vectors.</li>
      <li class="bulletlist1"><code class="inlinecode">encode_labels</code> converts categorical labels into numerical values using <code class="inlinecode">LabelEncoder</code>.</li>
    </ul>
    <p class="normal1">Finally, we apply these preprocessing steps to the training and testing data and print their shapes to ensure everything is processed correctly.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will now<a id="_idIndexMarker579" class="calibre3"/> apply the prompt evaluation strategy (LIFE 3.4) and validate the code by executing the code for every step in the Google Colab environment. The code loads the model from Keras and normalizes the images, flattens them into vectors, encodes labels using LabelEncoder, then applies the preprocessing and prints the shape. The code runs perfectly fine without applying any modifications or any errors.</p>
    <p class="normal1">Please refer to the <code class="inlinecode">Learning MLP using Fashion-MNIST dataset with ChatGPT.ipynb</code> notebook for the executable code snippets or copy the code from the prompt response.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_02.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.2: Code execution – data preprocessing</p>
    <p class="normal1">We will now<a id="_idIndexMarker580" class="calibre3"/> instruct ChatGPT to proceed to the next step.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should <a id="_idIndexMarker581" class="calibre3"/>receive a response like the following, where ChatGPT should provide the code for step 2 – Data Splitting.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! Let’s move on to the next step:</p>
    <p class="normal1">Data Splitting:</p>
    <ul class="calibre15">
      <li class="bulletlist">In this step, we’ll <a id="_idIndexMarker582" class="calibre3"/>partition the dataset into training, validation, and testing sets. The training set will be used to train the model, the validation set will be used to tune hyperparameters and prevent overfitting, and the testing set will be used to evaluate the model’s performance on unseen data.</li>
    </ul>
    <p class="normal1">Training Set:</p>
    <ul class="calibre15">
      <li class="bulletlist">The training set<a id="_idIndexMarker583" class="calibre3"/> is used to train the model’s parameters (weights and biases) using optimization algorithms like gradient descent.</li>
    </ul>
    <p class="normal1">Validation Set:</p>
    <ul class="calibre15">
      <li class="bulletlist">The validation set<a id="_idIndexMarker584" class="calibre3"/> is used to evaluate the model’s performance during training and adjust hyperparameters such as learning rate, batch size, and number of epochs to optimize the model’s performance.</li>
    </ul>
    <p class="normal1">Testing Set:</p>
    <ul class="calibre15">
      <li class="bulletlist">The testing set<a id="_idIndexMarker585" class="calibre3"/> is used to evaluate the final performance of the trained model on unseen data and assess its generalization capability.</li>
    </ul>
    <p class="normal1">Now, let’s split the dataset:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Step 5: Split dataset into training, validation, and testing sets</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">split_dataset</span>(<span>train_data, train_labels, test_data, test_labels, validation_size=</span><span class="hljs-attr">0.1</span><span>, test_size=</span><span class="hljs-attr">0.1</span><span>, random_state=</span><span class="hljs-attr">42</span>):
    <span class="hljs-comment"># Split training set into training and validation sets</span>
    x_train, x_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=validation_size, random_state=random_state)
    <span class="hljs-comment"># Split testing set into testing and validation sets</span>
    x_test, x_val, y_test, y_val = train_test_split(test_data, test_labels, test_size=test_size, random_state=random_state)
    <span class="hljs-keyword">return</span> x_train, y_train, x_val, y_val, x_test, y_test
<span class="hljs-comment"># Apply data splitting</span>
x_train, y_train, x_val, y_val, x_test, y_test = split_dataset(x_train, y_train, x_test, y_test)
<span class="hljs-comment"># Print the shapes of split datasets</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Training set:"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"x_train shape:"</span>, x_train.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"y_train shape:"</span>, y_train.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"\nValidation set:"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"</span><span class="hljs-string">x_val shape:"</span>, x_val.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"y_val shape:"</span>, y_val.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"\nTesting set:"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"x_test shape:"</span>, x_test.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"y_test shape:"</span>, y_test.shape)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We <a id="_idIndexMarker586" class="calibre3"/>define a <code class="inlinecode">split_dataset</code> function to split the dataset into training, validation, and testing sets using the <code class="inlinecode">train_test_split</code> function from scikit-learn.</li>
      <li class="bulletlist1">The function takes training data, training labels, testing data, testing labels, and optional parameters such as validation size, test size, and random state.</li>
      <li class="bulletlist1">We split the training set into training and validation sets using the specified validation size.</li>
      <li class="bulletlist1">Then, we split the testing set into testing and validation sets using the specified test size.</li>
      <li class="bulletlist1">Finally, we print the shapes of the split datasets to verify the split.</li>
    </ul>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We execute the code in the notebook and it runs successfully. The data is split into training, validation, and test sets with the specified sizes.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_03.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.3: Code execution – data splitting</p>
    <p class="normal1">We will <a id="_idIndexMarker587" class="calibre3"/>now instruct ChatGPT to proceed to the next step.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step and define a single-layer baseline MLP model.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT should provide the code for a single-layer MLP model with an input layer, one hidden layer, and an output layer.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure, let’s move on to the next step:</p>
    <p class="normal1">Model Selection:</p>
    <ul class="calibre15">
      <li class="bulletlist">In this step, we’ll choose a Multi-Layer Perceptron (MLP)<a id="_idIndexMarker588" class="calibre3"/> as the classification model. An MLP consists of one or more layers of neurons, each fully connected to the next layer. For simplicity, we’ll start with a single-layer MLP as a baseline model.</li>
    </ul>
    <p class="normal1">Single-Layer MLP:</p>
    <ul class="calibre15">
      <li class="bulletlist">A single-layer MLP<a id="_idIndexMarker589" class="calibre3"/> consists of an input layer, a hidden layer, and an output layer. However, since it has only one hidden layer, it’s often referred to as a single-layer perceptron. Each neuron in the hidden layer receives input from all neurons in the input layer and produces an output, which is then passed through an activation function to introduce non-linearity. Finally, the output layer produces the final prediction.</li>
    </ul>
    <p class="normal1">Now, let’s<a id="_idIndexMarker590" class="calibre3"/> define the baseline single-layer MLP model:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense
<span class="hljs-comment"># Step 6: Define a single-layer MLP model</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">create_single_layer_mlp</span>(<span>input_shape, num_classes</span>):
    model = Sequential()
    <span class="hljs-comment"># Add a single hidden layer with ReLU activation</span>
    model.add(Dense(<span class="hljs-attr">128</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=input_shape))
    <span class="hljs-comment"># Add output layer with softmax activation for multi-class classification</span>
    model.add(Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>))
    <span class="hljs-keyword">return</span> model
<span class="hljs-comment"># Define input shape and number of classes</span>
input_shape = x_train.shape[<span class="hljs-attr">1</span>:]
num_classes = <span class="hljs-built_in">len</span>(np.unique(y_train))
<span class="hljs-comment"># Create the single-layer MLP model</span>
model = create_single_layer_mlp(input_shape, num_classes)
<span class="hljs-comment"># Print model summary</span>
model.summary()
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We import the necessary modules from <code class="inlinecode">TensorFlow.keras</code> to define the MLP model.</li>
      <li class="bulletlist1">We define a function <code class="inlinecode">create_single_layer_mlp</code> to create a single-layer MLP model.</li>
      <li class="bulletlist1">Inside the function:<ul class="calibre17">
          <li class="bulletlist2">We initialize a sequential model.</li>
          <li class="bulletlist3">We add a single hidden layer with 128 neurons and ReLU activation function.</li>
          <li class="bulletlist3">We add an output layer with softmax activation function for multi-class classification.</li>
          <li class="bulletlist3">We specify the input shape based on the shape of the training data and the number of output classes.</li>
          <li class="bulletlist3">We create the single-layer MLP model using the defined function.</li>
        </ul>
      </li>
      <li class="bulletlist1">Finally, we <a id="_idIndexMarker591" class="calibre3"/>print the summary of the model architecture.</li>
    </ul>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We execute the code and it runs without any errors and prints the model summary with the layer type, output shape, and number of parameters. It also provides us with the total parameters, trainable and non-trainable parameters. In our case, all the parameters are trainable parameters.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_04.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.4: Code execution – baseline model architecture</p>
    <p class="normal1">We will now<a id="_idIndexMarker592" class="calibre3"/> instruct ChatGPT to proceed to the next step for model training.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should <a id="_idIndexMarker593" class="calibre3"/>receive a response like the following where ChatGPT should provide the code for model training along with explanations of the key concepts involved, such as loss functions and optimization algorithms along with comments.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure, let’s move on to the next step:</p>
    <p class="normal1">Model Training:</p>
    <ul class="calibre15">
      <li class="bulletlist">In this step, we’ll train the MLP model<a id="_idIndexMarker594" class="calibre3"/> on the training data. Training involves feeding the training data to the model, adjusting its parameters (weights and biases) using optimization algorithms like stochastic gradient descent, and minimizing a loss function to make predictions as close to the actual labels as possible.</li>
    </ul>
    <p class="normal1">Loss Function:</p>
    <ul class="calibre15">
      <li class="bulletlist">The loss function<a id="_idIndexMarker595" class="calibre3"/> measures the difference between the predicted labels and the actual labels. For multi-class classification problems like Fashion-MNIST, we typically use categorical cross-entropy as the loss function.</li>
    </ul>
    <p class="normal1">Optimization Algorithm:</p>
    <ul class="calibre15">
      <li class="bulletlist">The optimization algorithm<a id="_idIndexMarker596" class="calibre3"/> is responsible for updating the model’s parameters during training to minimize the loss function. We’ll use Adam optimizer, which is an extension to stochastic gradient descent and is widely used in deep learning.</li>
    </ul>
    <p class="normal1">Training Parameters:</p>
    <ul class="calibre15">
      <li class="bulletlist">We’ll specify training parameters<a id="_idIndexMarker597" class="calibre3"/> such as batch size and number of epochs. Batch size determines the number of samples processed before updating the model’s parameters, while the number of epochs specifies how many times the entire training dataset is passed forward and backward through the model.</li>
    </ul>
    <p class="normal1">Now, let’s train the model:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.utils <span class="hljs-keyword">import</span> to_categorical
<span class="hljs-comment"># Step 7: Model Training</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">train_model</span>(<span>model, x_train, y_train, x_val, y_val, batch_size=</span><span class="hljs-attr">32</span><span>, epochs=</span><span class="hljs-attr">10</span>):
    <span class="hljs-comment"># Convert class vectors to binary class matrices (one-hot encoding)</span>
    y_train = to_categorical(y_train)
    y_val = to_categorical(y_val)
    <span class="hljs-comment"># Compile the model with categorical cross-entropy loss and Adam optimizer</span>
    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=<span class="hljs-string">'adam'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-comment"># Train the model on the training data</span>
    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val))
    <span class="hljs-keyword">return</span> history
<span class="hljs-comment"># Train the model</span>
history = train_model(model, x_train, y_train, x_val, y_val, batch_size=<span class="hljs-attr">32</span>, epochs=<span class="hljs-attr">10</span>)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We <a id="_idIndexMarker598" class="calibre3"/>import the necessary modules from <code class="inlinecode">TensorFlow.keras</code> to compile and train the model.</li>
      <li class="bulletlist1">We define a <code class="inlinecode">train_model</code> function to train the model on the training data.</li>
      <li class="bulletlist1">Inside the function:<ul class="calibre17">
          <li class="bulletlist2">We convert the class labels to binary class matrices using one-hot encoding.</li>
          <li class="bulletlist3">We compile the model with the categorical cross-entropy loss function and the Adam optimizer.</li>
          <li class="bulletlist3">We train the model on the training data with the specified batch size and number of epochs.</li>
        </ul>
      </li>
      <li class="bulletlist1">Finally, we train the model using the defined function and store the training history for visualization and analysis.</li>
    </ul>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We execute the code and it runs without any errors. It applies a one-hot encoding to class labels, complies the model with the categorical cross-entropy loss function and Adam<a id="_idIndexMarker599" class="calibre3"/> optimizer, and trains the model with batch size 32 for 10 epochs. This achieves a validation accuracy of approximately 88%.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_05.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.5: Code execution – model training</p>
    <p class="normal1">We will now instruct ChatGPT to proceed to the next step for model evaluation.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT should provide the code for evaluating the model against the test set, along with explanations of concepts like accuracy, precision, recall, and the confusion matrix.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Model Evaluation:</p>
    <ul class="calibre15">
      <li class="bulletlist">In this<a id="_idIndexMarker600" class="calibre3"/> step, we’ll use various metrics to evaluate the performance of the trained MLP model on the testing data. Commonly used metrics for classification tasks include accuracy, precision, recall, and the confusion matrix.</li>
    </ul>
    <p class="normal1">Accuracy:</p>
    <ul class="calibre15">
      <li class="bulletlist">Accuracy<a id="_idIndexMarker601" class="calibre3"/> measures the proportion of correctly classified instances out of the total instances.</li>
    </ul>
    <p class="normal1">Precision:</p>
    <ul class="calibre15">
      <li class="bulletlist">Precision<a id="_idIndexMarker602" class="calibre3"/> measures the proportion of true positive predictions out of all positive predictions. It indicates the model’s ability to avoid false positives.</li>
    </ul>
    <p class="normal1">Recall:</p>
    <ul class="calibre15">
      <li class="bulletlist">Recall <a id="_idIndexMarker603" class="calibre3"/>measures the proportion of true positive predictions out of all actual positive instances. It indicates the model’s ability to identify all positive instances.</li>
    </ul>
    <p class="normal1">Confusion Matrix:</p>
    <ul class="calibre15">
      <li class="bulletlist">A confusion matrix<a id="_idIndexMarker604" class="calibre3"/> provides a summary of the model’s performance by showing the number of true positive, true negative, false positive, and false negative predictions.</li>
    </ul>
    <p class="normal1">Now, let’s evaluate the model:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, precision_score, recall_score, confusion_matrix
<span class="hljs-comment"># Step 8: Model Evaluation</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">evaluate_model</span>(<span>model, x_test, y_test</span>):
    <span class="hljs-comment"># Predict labels for testing data</span>
    y_pred = model.predict(x_test)
    <span class="hljs-comment"># Convert predicted labels to class labels</span>
    y_pred_classes = np.argmax(y_pred, axis=<span class="hljs-attr">1</span>)
    <span class="hljs-comment"># Convert true labels to class labels</span>
    y_true_classes = np.argmax(y_test, axis=<span class="hljs-attr">1</span>)
    <span class="hljs-comment"># Calculate accuracy</span>
    accuracy = accuracy_score(y_true_classes, y_pred_classes)
    <span class="hljs-comment"># Calculate precision</span>
    precision = precision_score(y_true_classes, y_pred_classes, average=<span class="hljs-string">'weighted'</span>)
    <span class="hljs-comment"># Calculate recall</span>
    recall = recall_score(y_true_classes, y_pred_classes, average=<span class="hljs-string">'weighted'</span>)
    <span class="hljs-comment"># Calculate confusion matrix</span>
    cm = confusion_matrix(y_true_classes, y_pred_classes)
    <span class="hljs-keyword">return</span> accuracy, precision, recall, cm
<span class="hljs-comment"># Evaluate the model</span>
accuracy, precision, recall, cm = evaluate_model(model, x_test, y_test)
<span class="hljs-comment"># Print evaluation metrics</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Accuracy:"</span>, accuracy)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Precision:"</span>, precision)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Recall:"</span>, recall)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Confusion Matrix:\n"</span>, cm)
<span class="hljs-comment"># Visualize confusion matrix</span>
plt.imshow(cm, cmap=plt.cm.Blues)
plt.title(<span class="hljs-string">'Confusion Matrix'</span>)
plt.colorbar()
plt.xlabel(<span class="hljs-string">'Predicted Labels'</span>)
plt.ylabel(<span class="hljs-string">'True Labels'</span>)
plt.show()
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We <a id="_idIndexMarker605" class="calibre3"/>import necessary modules from <code class="inlinecode">matplotlib.pyplot</code> and scikit-learn to visualize the confusion matrix and calculate evaluation metrics.</li>
      <li class="bulletlist1">We define an <code class="inlinecode">evaluate_model</code> function to evaluate the model’s performance on the testing data.</li>
      <li class="bulletlist1">Inside the function:<ul class="calibre17">
          <li class="bulletlist2">We make predictions on the testing data using the trained model.</li>
          <li class="bulletlist3">We convert the predicted labels and true labels to class labels.</li>
          <li class="bulletlist3">We calculate accuracy, precision, recall, and confusion matrix using scikit-learn metrics functions.</li>
        </ul>
      </li>
      <li class="bulletlist1">Finally, we evaluate the model using the defined function, print the evaluation metrics, and visualize the confusion matrix.</li>
    </ul>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We execute the <a id="_idIndexMarker606" class="calibre3"/>code and note that it experiences an error due to the test labels not being encoded, but this is not evident from the error itself. We can get help from ChatGPT to resolve the error by applying the prompting strategy of providing the error to ChatGPT.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer code  Description automatically generated" src="../Images/B21232_14_06.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.6: Code execution – error for model evaluation</p>
    <p class="normal1">We provided the error to ChatGPT to get assistance.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Looks like there is some issue with the test labels. We received the below error: </p>
    <pre class="programlisting"><code class="hljs-code">------282/282 [==============================] - 2s 5ms/step --------------------------------------------------------------------------- AxisError Traceback (most recent call last) &lt;ipython-input-5-02193580c831&gt; in &lt;cell line: 23&gt;() 21 22 # Evaluate the model ---&gt; 23 accuracy, precision, recall, cm = evaluate_model(model, x_test, y_test) 24 25 # Print evaluation metrics 2 frames /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds) 57 58 try: ---&gt; 59 return bound(*args, **kwds) 60 except TypeError: 61 # A TypeError occurs if the object does have such a method in its AxisError: axis 1 is out of bounds for array of dimension 1
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT should provide the suggestions to troubleshoot the problem.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">It seems like there’s an issue with the shape of the labels. The error indicates that the axis specified for the argmax function is out of bounds. This typically occurs when the labels are not in the expected format or shape.</p>
    <p class="normal1">Let’s double-check the shape of the labels and make sure they are in the correct format for evaluation:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">"Shape of y_test:"</span>, y_test.shape)
</code></pre>
    <p class="normal1">This will help <a id="_idIndexMarker607" class="calibre3"/>us understand the shape of the labels and identify any discrepancies. Once we identify the issue, we can correct it accordingly.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We print the shape of <code class="inlinecode">y_test</code>:</p>
    <figure class="mediaobject"><img alt="A white rectangular object with red text  Description automatically generated" src="../Images/B21232_14_07.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.7: Code execution - shape of test labels</p>
    <p class="normal1">We will now provide ChatGPT with the output of the code.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">Shape of y_test: (<span class="hljs-attr">9000</span>,)
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the problem and provides us with the corrected code.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Thank you for providing the shape of <code class="inlinecode">y_test</code>. It seems that the labels are in 1D format, which means they are not one-hot encoded. In the evaluation function, we assumed that the labels are one-hot encoded, which caused the error.</p>
    <p class="normal1">To resolve this<a id="_idIndexMarker608" class="calibre3"/> issue, we need to modify the evaluation function to handle 1D labels instead of one-hot encoded labels. We can achieve this by removing the conversion of labels to one-hot encoding and directly compare the predicted labels with the true labels.</p>
    <p class="normal1">Let’s update the evaluation function accordingly:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Step 8: Model Evaluation</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">evaluate_model</span>(<span>model, x_test, y_test</span>):
    <span class="hljs-comment"># Predict labels for testing data</span>
    y_pred = model.predict(x_test)
    <span class="hljs-comment"># Convert predicted labels to class labels</span>
    y_pred_classes = np.argmax(y_pred, axis=<span class="hljs-attr">1</span>)
    <span class="hljs-comment"># Calculate accuracy</span>
    accuracy = accuracy_score(y_test, y_pred_classes)
    <span class="hljs-comment"># Calculate precision</span>
    precision = precision_score(y_test, y_pred_classes, average=<span class="hljs-string">'weighted'</span>)
    <span class="hljs-comment"># Calculate recall</span>
    recall = recall_score(y_test, y_pred_classes, average=<span class="hljs-string">'weighted'</span>)
    <span class="hljs-comment"># Calculate confusion matrix</span>
    cm = confusion_matrix(y_test, y_pred_classes)
    <span class="hljs-keyword">return</span> accuracy, precision, recall, cm
<span class="hljs-comment"># Evaluate the model</span>
accuracy, precision, recall, cm = evaluate_model(model, x_test, y_test)
<span class="hljs-comment"># Print evaluation metrics</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Accuracy:"</span>, accuracy)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Precision:"</span>, precision)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Recall:"</span>, recall)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Confusion Matrix:\n"</span>, cm)
<span class="hljs-comment"># Visualize confusion matrix</span>
plt.imshow(cm, cmap=plt.cm.Blues)
plt.title(<span class="hljs-string">'Confusion Matrix'</span>)
plt.colorbar()
plt.xlabel(<span class="hljs-string">'Predicted Labels'</span>)
plt.ylabel(<span class="hljs-string">'True Labels'</span>)
plt.show()
</code></pre>
    <p class="normal1">Explanation:</p>
    <p class="normal1">We removed the conversion of labels to one-hot encoding and directly used the <code class="inlinecode">y_test</code> true labels in the evaluation function.</p>
    <p class="normal1">We updated the accuracy, precision, and recall calculation functions to use the 1D labels instead of one-hot encoded labels.</p>
    <p class="normal1">Now, the <a id="_idIndexMarker609" class="calibre3"/>evaluation function should work correctly with the provided 1D labels, and the evaluation metrics should be calculated accurately.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will execute the code and it works fine now because the code provided has been modified to work with 1D labels. It also prints the confusion matrix.</p>
    <figure class="mediaobject"><img alt="A screenshot of a graph  Description automatically generated" src="../Images/B21232_14_08.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.8: Code execution – confusion matrix</p>
    <p class="normal1">This<a id="_idIndexMarker610" class="calibre3"/> completes feature 1. We achieved an accuracy of 0.8796 (87.96%), a precision of 0.8817 (88.17%), and a recall of 0.8796 (87.96%) with our single-layer MLP model. Next, we will move to the second feature, adding more layers to the model. We will also learn how ChatGPT can assist us in that.</p>
    <h2 class="heading1" id="_idParaDest-311">Feature 2: Adding layers to the model</h2>
    <p class="normal">Now that we<a id="_idIndexMarker611" class="calibre3"/> have a baseline model architecture, let us try adding layers to it. We will apply a prompting strategy to improvise a model and ask ChatGPT to provide us with the code for it.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Now that we have a baseline model with a single layer, can you please provide me code with two layers and three layers and calculate and compare the model performance due to the addition of layers?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for two-layer and three-layer models along with comparison results.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Certainly! Let’s define and train multi-layer perceptron (MLP) models with two and three layers, and then compare their performance with the baseline single-layer model.</p>
    <p class="normal1">Define MLP Models with Two and Three Layers:</p>
    <ul class="calibre15">
      <li class="bulletlist">We’ll define MLP models with additional hidden layers to see how the performance changes with the increase in the number of layers.</li>
    </ul>
    <p class="normal1">Two-Layer MLP:</p>
    <ul class="calibre15">
      <li class="bulletlist">The two-layer MLP will consist of an input layer, two hidden layers, and an output layer.</li>
    </ul>
    <p class="normal1">Three-Layer MLP:</p>
    <ul class="calibre15">
      <li class="bulletlist">The <a id="_idIndexMarker612" class="calibre3"/>three-layer MLP will consist of an input layer, three hidden layers, and an output layer.</li>
    </ul>
    <p class="normal1">Now, let’s define and train these models:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Define a two-layer MLP model</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">create_two_layer_mlp</span>(<span>input_shape, num_classes</span>):
    model = Sequential()
    <span class="hljs-comment"># Add first hidden layer with ReLU activation</span>
    model.add(Dense(<span class="hljs-attr">128</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=input_shape))
    <span class="hljs-comment"># Add second hidden layer with ReLU activation</span>
    model.add(Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>))
    <span class="hljs-comment"># Add output layer with softmax activation for multi-class classification</span>
    model.add(Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>))
    <span class="hljs-keyword">return</span> model
<span class="hljs-comment"># Define a three-layer MLP model</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">create_three_layer_mlp</span>(<span>input_shape, num_classes</span>):
    model = Sequential()
    <span class="hljs-comment"># Add first hidden layer with ReLU activation</span>
    model.add(Dense(<span class="hljs-attr">128</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=input_shape))
    <span class="hljs-comment"># Add second hidden layer with ReLU activation</span>
    model.add(Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>))
    <span class="hljs-comment"># Add third hidden layer with ReLU activation</span>
    model.add(Dense(<span class="hljs-attr">32</span>, activation=<span class="hljs-string">'relu'</span>))
    <span class="hljs-comment"># Add output layer with softmax activation for multi-class classification</span>
    model.add(Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>))
    <span class="hljs-keyword">return</span> model
<span class="hljs-comment"># Create two-layer MLP model</span>
two_layer_model = create_two_layer_mlp(input_shape, num_classes)
<span class="hljs-comment"># Create three-layer MLP model</span>
three_layer_model = create_three_layer_mlp(input_shape, num_classes)
<span class="hljs-comment"># Train two-layer MLP model</span>
two_layer_history = train_model(two_layer_model, x_train, y_train, x_val, y_val)
<span class="hljs-comment"># Train three-layer MLP model</span>
three_layer_history = train_model(three_layer_model, x_train, y_train, x_val, y_val)
</code></pre>
    <p class="normal1">Model Comparison:</p>
    <p class="normal1">Once the<a id="_idIndexMarker613" class="calibre3"/> models are trained, we can compare their performance based on evaluation metrics such as accuracy, precision, recall, and confusion matrix.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Evaluate two-layer MLP model</span>
two_layer_accuracy, _, _, _ = evaluate_model(two_layer_model, x_test, y_test)
<span class="hljs-comment"># Evaluate three-layer MLP model</span>
three_layer_accuracy, _, _, _ = evaluate_model(three_layer_model, x_test, y_test)
<span class="hljs-comment"># Print model comparison</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy:"</span>, accuracy)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"</span><span class="hljs-string">Two-layer MLP Accuracy:"</span>, two_layer_accuracy)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Three-layer MLP Accuracy:"</span>, three_layer_accuracy)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We define two additional MLP models with two and three hidden layers using the previously defined functions.</li>
      <li class="bulletlist1">We train both models using the training data and validation data.</li>
      <li class="bulletlist1">After training, we evaluate the performance of each model using the testing data and compare their accuracies.</li>
    </ul>
    <p class="normal1">The comparison helps us understand how the addition of layers affects the model’s performance.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will execute the code that defines the two additional models with two and three hidden layers. It also trains the models, evaluates the performance of both models, and prints the results.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_09.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.9: Feature 2 – adding layers to the model</p>
    <p class="normal1">Based on<a id="_idIndexMarker614" class="calibre3"/> these results, we can observe that the two-layer MLP model achieved slightly higher accuracy compared to both the single-layer and three-layer MLP models. However, the differences in accuracy are relatively small, indicating that the addition of layers did not significantly improve the model’s performance in this case. Let’s move on to the next feature and experiment with batch sizes using the baseline model. </p>
    <h2 class="heading1" id="_idParaDest-312">Feature 3: Experimenting with batch sizes</h2>
    <p class="normal">We have<a id="_idIndexMarker615" class="calibre3"/> now learned how to add more layers, and in our case, due to the dataset being simple, there was not much impact. We will now experiment with different batch sizes. We will apply a prompting strategy to improvise a model and ask ChatGPT to provide us the code for it.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you please provide me code with three combinations of batch sizes and compare the baseline single-layer model performance for these combinations?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should <a id="_idIndexMarker616" class="calibre3"/>receive a response like the following where ChatGPT understands the request and provides us with the code for different batch sizes along with comparison results.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Define and Train Models with Different Batch Sizes:</p>
    <ul class="calibre15">
      <li class="bulletlist">We’ll define and train the baseline single-layer MLP model with three different combinations of batch sizes.</li>
      <li class="bulletlist1">Combination 1: <code class="inlinecode">Batch Size = 32</code></li>
      <li class="bulletlist1">Combination 2: <code class="inlinecode">Batch Size = 64</code></li>
      <li class="bulletlist1">Combination 3: <code class="inlinecode">Batch Size = 128</code></li>
    </ul>
    <p class="normal1">Now, let’s define and train these models:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Define and train model with batch size = 32</span>
model_batch_32 = create_single_layer_mlp(input_shape, num_classes)
history_batch_32 = train_model(model_batch_32, x_train, y_train, x_val, y_val, batch_size=<span class="hljs-attr">32</span>)
<span class="hljs-comment"># Define and train model with batch size = 64</span>
model_batch_64 = create_single_layer_mlp(input_shape, num_classes)
history_batch_64 = train_model(model_batch_64, x_train, y_train, x_val, y_val, batch_size=<span class="hljs-attr">64</span>)
<span class="hljs-comment"># Define and train model with batch size = 128</span>
model_batch_128 = create_single_layer_mlp(input_shape, num_classes)
history_batch_128 = train_model(model_batch_128, x_train, y_train, x_val, y_val, batch_size=<span class="hljs-attr">128</span>)
</code></pre>
    <p class="normal1">Model Comparison:</p>
    <p class="normal1">Once the models are trained, we can compare their performance based on evaluation metrics such as accuracy.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Evaluate models with different batch sizes</span>
accuracy_batch_32, _, _, _ = evaluate_model(model_batch_32, x_test, y_test)
accuracy_batch_64, _, _, _ = evaluate_model(model_batch_64, x_test, y_test)
accuracy_batch_128, _, _, _ = evaluate_model(model_batch_128, x_test, y_test)
<span class="hljs-comment"># Print model comparison</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (Batch Size = 32):"</span>, accuracy_batch_32)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"</span><span class="hljs-string">Single-layer MLP Accuracy (Batch Size = 64):"</span>, accuracy_batch_64)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (Batch Size = 128):"</span>, accuracy_batch_128)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We define and train three baseline single-layer MLP models with different combinations of batch sizes (32, 64, and 128).</li>
      <li class="bulletlist1">After training, we evaluate the performance of each model using the testing data and compare their accuracies.</li>
    </ul>
    <p class="normal1">The <a id="_idIndexMarker617" class="calibre3"/>comparison helps us understand how different batch sizes affect the model’s performance.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will execute the code that defines models with batch sizes 32, 64, and 128. It also trains the models, evaluates their performance, and prints the results of the comparison of this performance.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_10.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.10: Code execution – batch size comparison</p>
    <p class="normal1">We can <a id="_idIndexMarker618" class="calibre3"/>see that there is not much difference between the models’ accuracies, so we will apply the ‘Learn prompting strategy’ (LIFE 3.1) and ask ChatGPT for possible reasons as to why this might be.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">282/282 [==============================] - 1s 3ms/step 282/282 [==============================] - 1s 4ms/step 282/282 [==============================] - 1s 3ms/step 
Single-layer MLP Accuracy (Batch Size = 32): 0.88 
Single-layer MLP Accuracy (Batch Size = 64): 0.8723333333333333 
Single-layer MLP Accuracy (Batch Size = 128): 0.8797777777777778
</code></pre>
    <p class="normal1">Why there is not much difference in the accuracies?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT explains the possible reasons.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">The differences in accuracy between the models trained with different batch sizes are relatively small. There could be several reasons for this:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Dataset Size</strong>: The Fashion-MNIST dataset is relatively small compared to other datasets commonly used in deep learning. With a smaller dataset, the impact of batch size on model performance may be less pronounced.</li>
      <li class="bulletlist1"><strong class="screentext">Model Complexity</strong>: The baseline single-layer MLP model may not be complex enough to fully leverage the benefits of different batch sizes. In more complex models, such as deep neural networks with multiple layers, the impact of batch size on training dynamics may be more significant.</li>
      <li class="bulletlist1"><strong class="screentext">Optimization Algorithm</strong>: The Adam optimizer used in training the models adapts the learning rate for each parameter based on the first and second moments of the gradients. This adaptive learning rate can mitigate the impact of batch size to some extent.</li>
      <li class="bulletlist1"><strong class="screentext">Convergence</strong>: The models may have already converged to a similar level of performance regardless of the batch size used. Once a model converges, further training with different batch sizes may not lead to substantial improvements in accuracy.</li>
    </ul>
    <p class="normal1">Overall, while batch size can influence training dynamics and convergence speed, its impact on model performance may be less pronounced in certain scenarios, especially with relatively simple models and datasets. Experimenting with larger and more complex models, as well as different optimization algorithms, may reveal more significant <a id="_idIndexMarker619" class="calibre3"/>differences in performance based on batch size.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">Now that we have learned how to change the batch size and what the possible reasons could be for it not having much impact on our model, let’s move on to the next feature and experiment with the number of neurons in the hidden layer of the baseline model. </p>
    <h2 class="heading1" id="_idParaDest-313">Feature 4: Experimenting with the number of neurons</h2>
    <p class="normal">We will <a id="_idIndexMarker620" class="calibre3"/>apply a prompting strategy to improvise a model and ask ChatGPT to provide us the code for experimenting with different numbers of neurons in the hidden layer.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you please provide me code with three combinations of numbers of neurons and compare the baseline single-layer model performance for the various combinations?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for different numbers of neurons in the hidden layer, along with the comparison results.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Of course! Let’s define and train the baseline single-layer MLP model with three different combinations of the number of neurons in the hidden layer, and then compare their performance.</p>
    <p class="normal1">Define and Train Models with Different Number of Neurons:</p>
    <ul class="calibre15">
      <li class="bulletlist">We’ll define and train the baseline single-layer MLP model with three different combinations of the number of neurons in the hidden layer:<ul class="calibre17">
          <li class="bulletlist2">Combination 1: <code class="inlinecode">Number of Neurons = 64</code></li>
          <li class="bulletlist3">Combination 2: <code class="inlinecode">Number of Neurons = 128</code></li>
          <li class="bulletlist3">Combination 3: <code class="inlinecode">Number of Neurons = 256</code></li>
        </ul>
      </li>
    </ul>
    <p class="normal1">Now, let’s <a id="_idIndexMarker621" class="calibre3"/>define and train these models:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Define and train model with 64 neurons in the hidden layer</span>
model_neurons_64 = create_single_layer_mlp(input_shape, num_classes)
history_neurons_64 = train_model(model_neurons_64, x_train, y_train, x_val, y_val)
<span class="hljs-comment"># Define and train model with 128 neurons in the hidden layer</span>
model_neurons_128 = create_single_layer_mlp(input_shape, num_classes)
history_neurons_128 = train_model(model_neurons_128, x_train, y_train, x_val, y_val)
<span class="hljs-comment"># Define and train model with 256 neurons in the hidden layer</span>
model_neurons_256 = create_single_layer_mlp(input_shape, num_classes)
history_neurons_256 = train_model(model_neurons_256, x_train, y_train, x_val, y_val)
</code></pre>
    <p class="normal1">Model Comparison:</p>
    <p class="normal1">Once the models are trained, we can compare their performance based on evaluation metrics such as accuracy.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Evaluate models with different number of neurons</span>
accuracy_neurons_64, _, _, _ = evaluate_model(model_neurons_64, x_test, y_test)
accuracy_neurons_128, _, _, _ = evaluate_model(model_neurons_128, x_test, y_test)
accuracy_neurons_256, _, _, _ = evaluate_model(model_neurons_256, x_test, y_test)
<span class="hljs-comment"># Print model comparison</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (Neurons = 64):"</span>, accuracy_neurons_64)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (Neurons = 128):"</span>, accuracy_neurons_128)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (Neurons = 256):"</span>, accuracy_neurons_256)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We define and train three baseline single-layer MLP models with different combinations of the number of neurons in the hidden layer (64, 128, and 256).</li>
      <li class="bulletlist1">After training, we evaluate the performance of each model using the testing data and compare their accuracies.</li>
    </ul>
    <p class="normal1">The <a id="_idIndexMarker622" class="calibre3"/>comparison helps us understand how different numbers of neurons in the hidden layer affect the model’s performance.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will execute the code that defines the models with 64, 128, and 256 neurons. It also trains the model, evaluates the performance for all the model variations, and prints the results of the comparison of their performance.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_11.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.11: Code execution – neurons comparison</p>
    <p class="normal1">We can see<a id="_idIndexMarker623" class="calibre3"/> that there is not much difference, so let’s move to our final feature of experimenting with different optimizers.</p>
    <h2 class="heading1" id="_idParaDest-314">Feature 5: Trying different optimizers</h2>
    <p class="normal">We will apply a <a id="_idIndexMarker624" class="calibre3"/>prompting strategy to improvise a model and ask ChatGPT to provide us code for experimenting with different optimizers such as SGD, Adam, and RMSProp. Also, as part of our prompting strategy, we will be specific and explicitly mention that the optimizer should be passed at compile time and that labels should be one-hot encoded, as these steps are commonly ignored by ChatGPT.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you please provide me code with different optimizers of SGD, Adam, and RMSprop and compare the baseline single-layer model performance for various combinations? The optimizer should be passed in at compile time and you should ensure that labels are one-hot encoded.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for different optimizers along with comparison results.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Certainly! Let’s define and train a baseline single-layer MLP model with three different optimizers (SGD, Adam, and RMSprop), and then compare their performance.</p>
    <p class="normal1">Define and Train Models with Different Optimizers:</p>
    <p class="normal1">We’ll define and train the baseline single-layer MLP model with three different optimizers: SGD, Adam, and RMSprop.</p>
    <p class="normal1">Now, let’s define and train these models:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> SGD, Adam, RMSprop
<span class="hljs-comment"># Define and train model with SGD optimizer</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">train_model_sgd</span>(<span>model, x_train, y_train, x_val, y_val, batch_size=</span><span class="hljs-attr">32</span><span>, epochs=</span><span class="hljs-attr">10</span>):
    <span class="hljs-comment"># One-hot encode the class labels</span>
    y_train_encoded = to_categorical(y_train)
    y_val_encoded = to_categorical(y_val)
    <span class="hljs-comment"># Compile the model with SGD optimizer</span>
    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=SGD(), metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-comment"># Train the model on the training data</span>
    history = model.fit(x_train, y_train_encoded, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val_encoded))
    <span class="hljs-keyword">return</span> history
<span class="hljs-comment"># Define and train model with Adam optimizer</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">train_model_adam</span>(<span>model, x_train, y_train, x_val, y_val, batch_size=</span><span class="hljs-attr">32</span><span>, epochs=</span><span class="hljs-attr">10</span>):
    <span class="hljs-comment"># One-hot encode the class labels</span>
    y_train_encoded = to_categorical(y_train)
    y_val_encoded = to_categorical(y_val)
    <span class="hljs-comment"># Compile the model with Adam optimizer</span>
    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=Adam(), metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-comment"># Train the model on the training data</span>
    history = model.fit(x_train, y_train_encoded, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val_encoded))
    <span class="hljs-keyword">return</span> history
<span class="hljs-comment"># Define and train model with RMSprop optimizer</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">train_model_rmsprop</span>(<span>model, x_train, y_train, x_val, y_val, batch_size=</span><span class="hljs-attr">32</span><span>, epochs=</span><span class="hljs-attr">10</span>):
    <span class="hljs-comment"># One-hot encode the class labels</span>
    y_train_encoded = to_categorical(y_train)
    y_val_encoded = to_categorical(y_val)
    <span class="hljs-comment"># Compile the model with RMSprop optimizer</span>
    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=RMSprop(), metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-comment"># Train the model on the training data</span>
    history = model.fit(x_train, y_train_encoded, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val_encoded))
    <span class="hljs-keyword">return</span> history
<span class="hljs-comment"># Train model with SGD optimizer</span>
model_sgd = create_single_layer_mlp(input_shape, num_classes)
history_sgd = train_model_sgd(model_sgd, x_train, y_train, x_val, y_val)
<span class="hljs-comment"># Train model with Adam optimizer</span>
model_adam = create_single_layer_mlp(input_shape, num_classes)
history_adam = train_model_adam(model_adam, x_train, y_train, x_val, y_val)
<span class="hljs-comment"># Train model with RMSprop optimizer</span>
model_rmsprop = create_single_layer_mlp(input_shape, num_classes)
history_rmsprop = train_model_rmsprop(model_rmsprop, x_train, y_train, x_val, y_val)
</code></pre>
    <p class="normal1">Model Comparison:</p>
    <p class="normal1">Once the models are trained, we can compare their performance based on evaluation metrics such as accuracy.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Evaluate models with different optimizers</span>
accuracy_sgd, _, _, _ = evaluate_model(model_sgd, x_test, y_test)
accuracy_adam, _, _, _ = evaluate_model(model_adam, x_test, y_test)
accuracy_rmsprop, _, _, _ = evaluate_model(model_rmsprop, x_test, y_test)
<span class="hljs-comment"># Print model comparison</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (SGD):"</span>, accuracy_sgd)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (Adam):"</span>, accuracy_adam)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Single-layer MLP Accuracy (RMSprop):"</span>, accuracy_rmsprop)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We <a id="_idIndexMarker625" class="calibre3"/>define and train three baseline single-layer MLP models with different optimizers (SGD, Adam, and RMSprop).</li>
      <li class="bulletlist1">After training, we evaluate the performance of each model using the testing data and compare their accuracies.</li>
    </ul>
    <p class="normal1">The comparison helps us understand how different optimizers affect the model’s performance.</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We execute the code that defines the models with different optimizers. It also trains the model, evaluates the performance of all the model variations, and prints the results for a comparison of their performance.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_14_12.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 14.12: Code Execution – Different Optimizers</p>
    <p class="normal1">Based on<a id="_idIndexMarker626" class="calibre3"/> these results, we can observe that the Adam optimizer achieved the highest accuracy, followed by RMSprop and SGD. This indicates that Adam performed better in optimizing the model’s parameters and improving its performance on the testing data.</p>
    <h1 class="heading" id="_idParaDest-315">Assignment</h1>
    <p class="normal">Compare the model performance of a single layer versus two hidden layers, but with 20 and 50 epochs.</p>
    <h1 class="heading" id="_idParaDest-316">Challenge</h1>
    <p class="normal">With the help of ChatGPT, improvise a model by adding a dropout layer and analyze the impact on model performance. Feel free to add more hidden layers to the model.</p>
    <h1 class="heading" id="_idParaDest-317">Summary</h1>
    <p class="normal">The prompt strategies used in this chapter provided a structured approach to learning and building a classification model using an MLP where ChatGPT assisted in generating code. The user validated the code using a Colab notebook and provided feedback to ChatGPT. By actively engaging with the material, you experimented with different techniques and iteratively refined your understanding, ultimately leading to a more comprehensive grasp of classification model creation using MLPs.</p>
    <p class="normal1">In the next chapter, we will learn how to use ChatGPT to generate code for <strong class="screentext">Convolutional Neural Networks</strong> (<strong class="screentext">CNNs</strong>) with the help of the CIFAR-10 dataset.</p>
    <h1 class="heading" id="_idParaDest-318">Join our community on Discord </h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers: </p>
    <p class="normal1"><a href="https://packt.link/aicode" class="calibre3"><span class="calibre3">https://packt.link/aicode</span></a></p>
    <p class="normal1"><span class="calibre3"><img alt="" src="../Images/QR_Code510410532445718281.png" class="calibre4"/></span></p>
  </div>
</body></html>