- en: Intuitive Deep Learning in C# .NET
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our goal in this chapter is to expose you to some of the powerful functionality
    that is available with Kelp.Net.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: How to use Kelp.Net to perform your own testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to write tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do benchmarks of functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to extend Kelp.Net
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kelp.Net[4] is a deep learning library written in C# and .NET. With the ability
    to chain functions into a function stack, it provides an incredible amount of
    power in a very flexible and intuitive platform. It also takes heavy advantage
    of the OpenCL language platform to enable seamless operation on both CPU-and GPU-enabled
    devices. Deep learning is an incredibly powerful tool, and native support for
    Caffe and Chainer model loading makes this platform even more powerful. As you
    will see, you can create a 1 million hidden layer deep learning network in just
    a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Kelp.Net also makes it very easy to save and load models to and from disk storage.
    This is a very powerful feature, allowing you to perform your training, save the
    model, and then load and test as required. It also makes it much easier to productionize
    code and truly separate the training and the test phases.
  prefs: []
  type: TYPE_NORMAL
- en: Among other things, Kelp.Net is an incredibly powerful tool for you to be able
    to learn and understand better various types of functions, their interactions,
    and performance. For instance, you can run tests against the same network with
    different optimizers and see the results by changing a single line of code. Also,
    you can design your tests easily to see the difference in using various batch
    sizes, number of hidden layers, epochs, and more. There really is no deep learning
    workbench for .NET that offers the power and flexibility found in Kelp.Net.
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin by talking a little bit about deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: What is deep learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To discuss deep learning, we need to go back in time, not so long ago, to when
    big data arrived in front of all our faces. The term was, and still is, everywhere.
    It was a skill that everyone just had to have, a buzzword-compliant checklist
    item. But what exactly did that term really mean? Well, it just meant that rather
    than siloed SQL databases and files being FTP'ed to use, we had this explosion
    of digital data from social media, internet search engines, e-commerce sites,
    and much more. And of course, this data came in various forms and formats. More
    formally, we were suddenly dealing with unstructured data. Not only did we have
    this explosion of data due to applications such as Facebook, Twitter, Google,
    and more, but also the explosion continues. More and more people get and stay
    connected to each other, sharing vast amounts of information about themselves
    that they wouldn't dare provide to someone if asked via a telephone call, right?
    And we have little to no control over the format and quality of that data. This
    will become an important point as we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: Now, this vast amount of data is great, but humans can barely absorb what they
    are exposed to daily, let alone this explosion of data. So, along the way, people
    realized that machine learning and artificial intelligence could be adapted to
    just such a task. From a simple machine learning algorithm, all the way up to
    multilayered networks, artificial intelligence and deep learning were born (at
    least the corporate world likes to believe it happened that way!).
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning, which is a branch of machine learning and artificial intelligence,
    uses many levels of neural network layers (hierarchical, if you like) to perform
    its job. In many cases, these networks are built to mirror what we think we know
    about the human brain, with neurons connecting layers together like an intricately
    layered web. This allows data processing to occur in a nonlinear fashion. Each
    layer processes data from the previous layer (with an exception being the first
    layer, of course), passing its information on to the next layer. With any luck,
    each layer improves the model, and in the end, we achieve our goal and solve our
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kelp.Net makes heavy usage of the open computing language, or OpenCL. According
    to Wikipedia:'
  prefs: []
  type: TYPE_NORMAL
- en: '"OpenCL views a computing system as consisting of a number of compute devices,
    which might be central processing units (CPUs), or accelerators such as graphics
    processing units (GPUs), attached to a host processor (a CPU). Functions executed
    on an OpenCL device are called kernels. A single compute device typically consists
    of several compute units, which in turn comprise multiple processing elements
    (PS). A single kernel execution can run on all or many of the PEs in parallel."'
  prefs: []
  type: TYPE_NORMAL
- en: In OpenCL, tasks are scheduled on command queues. There is at least one command
    queue for each device. The OpenCL runtime breaks the scheduled data-parallel tasks
    into pieces and sends the tasks to the device processing element.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenCL defines a memory hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Global**: Shared by all processing elements, and has high latency'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Read-only**: Smaller, of lower latency, and writable by the host CPU but
    not compute devices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local**: Shared by a process element group'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Per-element**: Private memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenCL also provides an API designed more towards math. This can be seen in
    the exposure of fixed-length vector types such as float4 (four vector of single-precision
    floats), available in lengths of 2, 3, 4, 8 and 16\. As you gain more exposure
    to Kelp.Net and start to create your own functions, you will encounter OpenCL
    programming. For now, it's enough to know that it exists and is being used under
    the hood extensively.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCL hierarchy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Kelp.Net, the hierarchy for various OpenCL resources is as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/637115a5-7fd0-4e75-9e81-73caec8cee8c.png)![](img/c519fb66-bcbc-4634-b380-1b6c1fdf9bec.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's describe these in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Compute kernel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A kernel object encapsulates a specific kernel function declared in a program
    and the argument values to be used when executing this kernel function.
  prefs: []
  type: TYPE_NORMAL
- en: Compute program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An OpenCL program consisting of a set of kernels. Programs may also contain
    auxiliary functions called by the kernel functions and constant data.
  prefs: []
  type: TYPE_NORMAL
- en: Compute sampler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An object that describes how to sample an image when the image is read in the
    kernel. The image read functions take a sampler as an argument. The sampler specifies
    the image addressing mode (meaning how out-of-range coordinates are handled),
    the filtering mode, and whether the input image coordinate is a normalized or
    unnormalized value.
  prefs: []
  type: TYPE_NORMAL
- en: Compute device
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A compute device is a collection of compute units. A command queue is used to
    queue commands to a device. Examples of commands include executing kernels or
    reading/writing memory objects. OpenCL devices typically correspond to a GPU,
    a multi-core CPU, and other processors such as **Digital Signal Processor** (**DSP**)
    and the cell/B.E. processor.
  prefs: []
  type: TYPE_NORMAL
- en: Compute resource
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An OpenCL resource that can be created and deleted by the application.
  prefs: []
  type: TYPE_NORMAL
- en: Compute object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An object identified by its handle in the OpenCL environment.
  prefs: []
  type: TYPE_NORMAL
- en: Compute context
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A compute context is the actual environment within which the kernels execute
    and the domain in which synchronization and memory management are defined.
  prefs: []
  type: TYPE_NORMAL
- en: Compute command queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A command queue is an object that holds commands that will be executed on a
    specific device. The command queue is created on a specific device within a context.
    Commands to a queue are queued in order but may be executed either in order or
    out of order.
  prefs: []
  type: TYPE_NORMAL
- en: Compute buffer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A memory object that stores a linear collection of bytes. Buffer objects are
    accessible using a pointer in a kernel executing on a device.
  prefs: []
  type: TYPE_NORMAL
- en: Compute event
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An event encapsulates the status of an operation such as a command. It can be
    used to synchronize operations in a context.
  prefs: []
  type: TYPE_NORMAL
- en: Compute image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A memory object that stores a 2D or 3D structured array. Image data can only
    be accessed with read and write functions. Read functions use a sampler.
  prefs: []
  type: TYPE_NORMAL
- en: Compute platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The host plus a collection of devices managed by the OpenCL framework that allow
    an application to share resources and execute kernels on devices on the platform.
  prefs: []
  type: TYPE_NORMAL
- en: Compute user event
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This represents a user-created event.
  prefs: []
  type: TYPE_NORMAL
- en: The Kelp.Net Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Functions are the basic building blocks of a Kelp.Net neural network. Single
    functions are chained together within function stacks to create powerful and possibly
    complex network chains. There are four primary types of functions you need to
    know about, and their purposes, should be self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: Single-input functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dual-input functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-input functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-output functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions are also chained together when networks are loaded from disks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each function has a forward and backward method that you will be implementing
    when you create functions of your own:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Function stacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Function stacks are layers of functions that are executed simultaneously in
    one forward, backward, or update pass. Function stacks are created when you either
    create a test or load a model from disk. Here are some examples of function stacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'They can be small and simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'They can be a little bit bigger:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, they can be very large:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Function dictionaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A function dictionary is a serializable dictionary of functions (described previously).
    When a network model is loaded from disk, a function dictionary will be returned
    and can be operated on exactly as if you had just created the function stack itself
    in code. The function dictionary is used primarily with the Caffe data model loader.
  prefs: []
  type: TYPE_NORMAL
- en: Caffe1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kelp.Net was developed strongly around the Caffe style of development and supports
    many of its features.
  prefs: []
  type: TYPE_NORMAL
- en: Caffe provides multimedia scientists and practitioners with a clean and modifiable
    framework for state-of-the-art deep learning algorithms and a collection of reference
    models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings
    for training and deploying general-purpose convolutional neural networks and other
    deep models efficiently on commodity architectures. Caffe fits industry and internet-scale
    media needs by CUDA GPU computation, processing over 40 million images a day on
    a single K40 or Titan GPU (approximately 2 ms per image). By separating model
    representation and actual implementation, Caffe allows experimentation and seamless
    switching among platforms for ease of development and deployment, from prototyping
    machines to cloud environments.
  prefs: []
  type: TYPE_NORMAL
- en: Chainer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'According to the Chainer documentation[2]:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Chainer is a flexible framework for neural networks. One major goal is flexibility,
    so it must enable us to write complex architectures simply and intuitively."'
  prefs: []
  type: TYPE_NORMAL
- en: Chainer adopts a define-by-run scheme, that is, the network is defined dynamically
    via the actual forward computation. More precisely, Chainer stores the history
    of computation instead of programming logic. For example, Chainer does not need
    any magic to introduce conditionals and loops into the network definitions. The
    define-by-run scheme is the core concept of Chainer. This strategy also makes
    it easy to write multi-GPU parallelization, since logic comes closer to network
    manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: Kelp.Net can load a Chainer model directly from disk.
  prefs: []
  type: TYPE_NORMAL
- en: Loss
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kelp.Net is comprised of a single abstract `LossFunction` class, designed to
    be implemented for your specific instance in determining how you evaluate loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'In machine learning, a loss function or cost function is a function that maps
    an event or values of one or more variables onto a real number intuitively, representing
    some cost associated with the event. Kelp.Net offers two out-of-the-box loss functions:
    mean squared error and softmax cross entropy. You can easily extend these to meet
    your needs.'
  prefs: []
  type: TYPE_NORMAL
- en: Model saving and loading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kelp.Net makes it very easy to save and load models with a call to one simple
    class. The `ModelIO` class exposes both a `Save` and a `Load` method for easy
    saving and loading to disk. Here is a very simple example of saving a model after
    training, reloading, and then performing testing on that model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4618e810-510c-49f1-8847-ec05afaf293e.png)'
  prefs: []
  type: TYPE_IMG
- en: Optimizers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Optimization algorithms minimize or maximize an error function depending on
    the model's parameters. Examples of parameters would be weights and biases. They
    help compute the output value and update the model towards the position of optimal
    solution by minimizing loss. Extending Kelp.Net to add your own optimization algorithms
    is a simple process, although adding the OpenCL and resource side of things is
    a coordinated effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kelp.Net comes with many predefined optimizers, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: AdaDelta
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AdaGrad
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GradientClipping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MomentumSGD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RMSprop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SGD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are all based on the abstract optimizer class.
  prefs: []
  type: TYPE_NORMAL
- en: Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kelp.Net natively supports the following datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: CIFAR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MNIST
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CIFAR
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CIFAR datasets come in two flavors, CIFAR-10 and CIFAR 100, with the difference
    being the number of classes within each. Let's briefly discuss both.
  prefs: []
  type: TYPE_NORMAL
- en: CIFAR-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CIFAR-10 dataset consists of 60,000 32 x 32 color images in 10 classes,
    with 6,000 images per class. There are 50,000 training images and 10,000 test
    images. The dataset is divided into five training batches and one test batch,
    each with 10,000 images. The test batch contains exactly 1,000 randomly selected
    images from each class. The training batches contain the remaining images in random
    order, but some training batches may contain more images from one class than another.
    Between them, the training batches contain exactly 5,000 images from each class.
  prefs: []
  type: TYPE_NORMAL
- en: CIFAR-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The CIFAR-100 dataset is just like CIFAR-10, except that it has 100 classes
    containing 600 images each. There are 500 training images and 100 testing images
    per class. The 100 classes in CIFAR-100 are grouped into 20 superclasses. Each
    image comes with a fine label (the class to which it belongs) and a coarse label
    (the superclass to which it belongs). Here is the list of classes in CIFAR-100:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Superclass** | **Classes** |'
  prefs: []
  type: TYPE_TB
- en: '| Aquatic mammals | Beaver, dolphin, otter, seal, and whale |'
  prefs: []
  type: TYPE_TB
- en: '| Fish | Aquarium fish, flatfish, ray, shark, and trout |'
  prefs: []
  type: TYPE_TB
- en: '| Flowers | Orchids, poppies, roses, sunflowers, and tulips |'
  prefs: []
  type: TYPE_TB
- en: '| Food containers | Bottles, bowls, cans, cups, and plates |'
  prefs: []
  type: TYPE_TB
- en: '| Fruit and vegetables | Apples, mushrooms, oranges, pears, and sweet peppers
    |'
  prefs: []
  type: TYPE_TB
- en: '| Household electrical devices | Clock, computer keyboard, lamp, telephone,
    and television |'
  prefs: []
  type: TYPE_TB
- en: '| Household furniture | Bed, chair, couch, table, and wardrobe |'
  prefs: []
  type: TYPE_TB
- en: '| Insects | Bee, beetle, butterfly, caterpillar, and cockroach |'
  prefs: []
  type: TYPE_TB
- en: '| Large carnivores | Bear, leopard, lion, tiger, and wolf |'
  prefs: []
  type: TYPE_TB
- en: '| Large man-made outdoor things | Bridge, castle, house, road, and skyscraper
    |'
  prefs: []
  type: TYPE_TB
- en: '| Large natural outdoor scenes | Cloud, forest, mountain, plain, and sea |'
  prefs: []
  type: TYPE_TB
- en: '| Large omnivores and herbivores | Camel, cattle, chimpanzee, elephant, and
    kangaroo |'
  prefs: []
  type: TYPE_TB
- en: '| Medium-sized mammals | Fox, porcupine, possum, raccoon, and skunk |'
  prefs: []
  type: TYPE_TB
- en: '| Non-insect invertebrates | Crab, lobster, snail, spider, and worm |'
  prefs: []
  type: TYPE_TB
- en: '| People | Baby, boy, girl, man, and woman |'
  prefs: []
  type: TYPE_TB
- en: '| Reptiles | Crocodile, dinosaur, lizard, snake, and turtle |'
  prefs: []
  type: TYPE_TB
- en: '| Small mammals | Hamster, mouse, rabbit, shrew, and squirrel |'
  prefs: []
  type: TYPE_TB
- en: '| Trees | Maple, oak, palm, pine, and willow |'
  prefs: []
  type: TYPE_TB
- en: '| Vehicles 1 | Bicycle, bus, motorcycle, pickup truck, and train |'
  prefs: []
  type: TYPE_TB
- en: '| Vehicles 2 | Lawn-mower, rocket, streetcar, tank, and tractor |'
  prefs: []
  type: TYPE_TB
- en: MNIST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The MNIST database is a large database of handwritten digits that is commonly
    used for training various image processing systems. The database is also widely
    used for training and testing in the field of machine learning. It has a training
    set of 60,000 examples and a test set of 10,000 examples. The digits have been
    size-normalized and centered in a fixed-size image, making it the standard of
    choice for people wanting to try various learning techniques without requiring
    the effort of preprocessing and formatting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/19ca2c60-4ff0-483f-8711-a7b0c4500ff3.png)'
  prefs: []
  type: TYPE_IMG
- en: MNIST Example
  prefs: []
  type: TYPE_NORMAL
- en: Tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Tests are actual execution events, small programs if you will. Because of the
    usage of OpenCL, these programs are compiled at runtime. To create a test, you
    only need to provide a single static `Run` function that encapsulates your code.
    Kelp.Net comes with a preconfigured tester, which makes it very simple to add
    your own tests. We will explore this in detail in our section on writing tests,
    for now, here is an example of a simple XOR test program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Monitoring Kelp.Net
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ReflectInsight from ReflectSoftware is hands down the best real-time logging
    framework for both logging and rich visualization available today. Kelp.Net has
    native support for this framework, thereby making it very easy for you to see
    what is going on inside your tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the main screen of ReflectInsight looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cdbc8870-d14b-43c1-820e-324905bcf3bb.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of the main screen of Reflect Insight
  prefs: []
  type: TYPE_NORMAL
- en: Watches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Watches allow you to keep an eye on specific data elements throughout the execution
    of your tests. When it comes to machine learning, understanding and seeing exactly
    what is going on inside your algorithms is incredibly important, and the watch
    panel is exactly the place to accomplish that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c6900a8-53fa-44a2-b40c-de21a72a6e8c.png)'
  prefs: []
  type: TYPE_IMG
- en: Messages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The message panel is where each message is displayed during test execution.
    The information available is totally up to you. The image displayed to the immediate
    left of the message text is based upon the type of message that you send (Information,
    Debug, Warning, Error, etc.):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/429ba129-b82f-404e-9542-a409769840fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each message has predefined properties that can be viewed via the Properties
    panel. There are standard properties, such as that shown below, which are available
    for every message. Then there are customize message properties that can be applied:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/58da7859-9e0b-422a-860d-7dc692adda5b.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of per message properties
  prefs: []
  type: TYPE_NORMAL
- en: Weaver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The weaver is a critical component of Kelp.Net and is the first object call
    you will make when running a test. This object houses a variety of OpenCL objects
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: ComputeContext
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An array of ComputeDevices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ComputeCommandQueue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Boolean flag indicating if the GPU is enabled
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ComputePlatform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dictionary of KernelSources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The weaver is the place to tell your program whether you will be using a CPU
    or GPU, and which device (if your system is capable of multiple devices) you will
    be using. You only need to make a single call to the weaver, at the beginning
    of your program, similar to what you see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You also can avoid using the initialization call of the weaver and allow it
    to determine what needs to happen automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the basic contents of the weaver. Its purpose is to build (compile
    dynamically at runtime) the program that will be executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Writing tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Creating tests for Kelp.Net is incredibly simple. Each test that you author
    needs only a single `Run` function exposed. The rest is your logic as to how you
    want your network to operate. The general guidelines for your `Run` function would
    be:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load data (real or simulated):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Create your function stack:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Select your optimizer:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Train your data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Test your data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Benchmarking functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `SingleBenchmark` class within the `KelpNetTester` class allows for simple
    benchmarking of various activation, noise, and other functions. If a function
    has a GPU capability, that is benchmarked, and so are CPU capabilities. The timing
    is at the microsecond level, as ReLU forward will usually always be below 1 ms
    in granularity.
  prefs: []
  type: TYPE_NORMAL
- en: '**With CPU enabled**![](img/e2b3619a-941f-49cf-8c3f-116833511bf8.png)**With
    GPU enabled**![](img/03550d87-07a5-4a7e-86b1-e3a64b026410.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's talk about how we run a single benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: Running a Single Benchmark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you run the `SingleBenchmark` class, the functions you see in the upcoming
    images will be timed. Forward and backward CPU and GPU timing will be provided
    (GPU when applicable). Here is a collapsed view of the benchmark tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e9befcb-0529-4b8e-8f39-6a46752776e6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And here is an expanded view of the benchmarks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/78e325aa-8eda-4da2-b0aa-5471ce3d223e.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we welcomed you to the world of intuitive deep learning. We
    showed you how you could use Kelp.Net to be your research platform to test virtually
    any hypothesis. We also showed you the power and flexibility of Kelp.Net. In our
    next chapter, we will enter the world of quantum computing and show you a little
    bit of the future of computing. Hold on to your hats, this one is different!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Convolutional Architecture for fast feature embedding*, Y Jia, E Shelhamer,
    J Donahue, S Karayev, J Long, proceedings of the 22^(nd) ACM international conference,
    2014'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chainer at [https://docs.chainer.org/en/stable/index.html](https://docs.chainer.org/en/stable/index.html)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Learning* *Multiple Layers of Features from Tiny Images* at [https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf),
    Alex Krizhevsky, 2009'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Original Kelp.Net at [https://github.com/harujoh](https://github.com/harujoh)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Filice ''15) Simone Filice, Giuseppe Castellucci, Danilo Croce, Roberto Basili,
    *Kelp: a kernel-based Learning Platform for Natural Language Processing*, proceedings
    of ACL: system demonstrations, Beijing, China (July 2015)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
