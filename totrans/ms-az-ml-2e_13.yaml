- en: '*Chapter 10*: Training Deep Neural Networks on Azure'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第10章*：在Azure上训练深度神经网络'
- en: In the previous chapter, we learned how to train and score classical ML models
    using non-parametric tree-based ensemble methods. While these methods work well
    on many small- and medium-sized datasets that contain categorical variables, they
    don't generalize well on large datasets.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用非参数的基于树的集成方法来训练和评分经典机器学习模型。虽然这些方法在包含分类变量的许多小型和中型数据集上表现良好，但它们在大数据集上的泛化能力不佳。
- en: In this chapter, we will train complex parametric models using **deep learning**
    (**DL**) for even better generalization with very large datasets. This will help
    you understand **deep neural networks** (**DNNs**), how to train and use them,
    and when they perform better than traditional models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用深度学习（**DL**）来训练复杂的参数模型，以实现与非常大的数据集的更好泛化。这将帮助您了解**深度神经网络**（**DNNs**），如何训练和使用它们，以及它们何时比传统模型表现更好。
- en: First, we will provide a short and practical overview of why and when DL works
    well and focus on understanding the general principles and rationale rather than
    the theoretical approach. This will help you to assess which use cases and datasets
    need DL and how it works in general.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将简要概述为什么以及何时深度学习（DL）效果良好，并着重于理解一般原则和理由，而不是理论方法。这将帮助您评估哪些用例和数据集需要深度学习，以及它的一般工作原理。
- en: Then, we will look at one of the popular application domains for DL – computer
    vision. We will train a simple **convolutional neural network** (**CNN**) model
    for image classification using the Azure Machine Learning service and additional
    Azure infrastructure. We will compare the performance to a model that has been
    fine-tuned on a pre-trained **residual neural network** (**ResNet**) model. This
    will set you up to train your models from scratch, fine-tune existing models for
    your application domain, and overcome situations where not enough training data
    is available.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将探讨深度学习的一个流行应用领域——计算机视觉。我们将使用Azure机器学习服务和额外的Azure基础设施来训练一个简单的**卷积神经网络**（**CNN**）模型进行图像分类。我们将将其性能与在预训练的**残差神经网络**（**ResNet**）模型上微调过的模型进行比较。这将为您从头开始训练模型、针对您的应用领域微调现有模型以及克服训练数据不足的情况做好准备。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introduction to Deep Learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习简介
- en: Training a CNN for image classification
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练CNN进行图像分类
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will use the following Python libraries and versions to
    create decision tree-based ensemble classifiers:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下Python库和版本来创建基于决策树的集成分类器：
- en: '`azureml-core 1.34.0`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-core 1.34.0`'
- en: '`azureml-sdk 1.34.0`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-sdk 1.34.0`'
- en: '`numpy 1.19.5`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy 1.19.5`'
- en: '`pandas 1.3.2`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas 1.3.2`'
- en: '`scikit-learn 0.24.2`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scikit-learn 0.24.2`'
- en: Similar to the previous chapters, you can execute this code using either a local
    Python interpreter or a notebook environment hosted in Azure Machine Learning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几章类似，您可以使用本地Python解释器或Azure机器学习托管的工作簿环境执行此代码。
- en: 'All the code examples in this chapter can be found in this book''s GitHub repository:
    [https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter10](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter10).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中所有的代码示例都可以在这个书的GitHub仓库中找到：[https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter10](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter10)。
- en: Introduction to Deep Learning
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习简介
- en: Deep learning has revolutionized the ML domain recently and is constantly outperforming
    classical statistical approaches, and even humans, in various tasks such as image
    classification, object detection, segmentation, speech transcription, text translation,
    text understanding, sales forecasting, and much more. In contrast to classical
    models, DL models use many millions of parameters, parameter sharing, optimization
    techniques, and implicit feature extraction to outperform all previously hand-crafted
    feature detectors and ML models when trained with enough data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习最近彻底改变了机器学习领域，并在各种任务中（如图像分类、目标检测、分割、语音转录、文本翻译、文本理解、销售预测等）不断优于经典统计方法，甚至优于人类。与经典模型相比，深度学习模型使用数百万个参数、参数共享、优化技术和隐式特征提取，当训练足够的数据时，可以优于所有之前手工制作的特征检测器和机器学习模型。
- en: In this section, we will help you understand the basics of neural networks and
    the path to training deeper models with more parameters, better generalization,
    and hence better performance. This will help you understand how DL-based approaches
    work, as well as why and when they make sense for certain domains and datasets.
    If you are already an expert in DL, feel free to skip this section and go directly
    to the practical examples in the *Training a CNN for image classification* section.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将帮助你了解神经网络的基本知识以及使用更多参数、更好泛化和更好性能来训练更深模型的路径。这将帮助你理解基于深度学习的各种方法是如何工作的，以及为什么和何时它们对某些领域和数据集是有意义的。如果你已经是深度学习的专家，请随意跳过本节，直接进入*训练用于图像分类的CNN*部分的实际示例。
- en: Why Deep Learning?
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么是深度学习？
- en: Many traditional optimization, classification, and forecasting processes have
    worked well over the past decades using classical ML approaches, such as k-nearest
    neighbor, linear and logistic regression, naïve Bayes, **support vector machines**
    (**SVMs**), tree-based ensemble models, and others. They worked well on various
    types of data (transactional, time series, operational, and so on) and data types
    (binary, numerical, and categorical) for small- to mid-sized datasets.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 许多传统的优化、分类和预测过程在过去几十年中已经使用经典的机器学习方法（如k最近邻、线性回归和逻辑回归、朴素贝叶斯、**支持向量机（SVMs**）、基于树的集成模型等）工作得很好。它们在小到中等规模的数据集上对各种类型的数据（交易、时间序列、运营等）和数据类型（二进制、数值和分类）都表现良好。
- en: However, in some domains, data generation has exploded, and classical ML models
    couldn't achieve better performance even with an increasing amount of training
    data. This especially affected the domains of computer vision and NLP around late
    2010\. That's when researchers had a breakthrough with neural networks – also
    called **multilayer perceptrons** (**MLPs**) – a technique that was used in the
    late 80s to capture the vast number of features in a large image dataset by using
    multiple nested layers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些领域，数据生成已经爆炸式增长，即使训练数据量不断增加，经典机器学习模型也无法实现更好的性能。这尤其影响了2010年底左右的计算机视觉和自然语言处理（NLP）领域。那时，研究人员在神经网络——也称为**多层感知器（MLPs**）——这一技术上取得了突破，这是一种在20世纪80年代使用的技术，通过使用多层嵌套层来捕捉大型图像数据集中的大量特征。
- en: 'The following chart captures this idea very well. While traditional ML approaches
    work very well on small- and medium-sized datasets, their performance usually
    does not improve with more training data. However, DL models are massive parametric
    models that can capture a vast number of details from training data. Hence, we
    can see that their prediction performance increases as the amount of data increases:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表很好地捕捉了这个想法。虽然传统的机器学习（ML）方法在小型和中等规模的数据集上工作得非常好，但它们的性能通常不会随着更多训练数据的增加而提高。然而，深度学习（DL）模型是大规模参数模型，可以从训练数据中捕捉大量细节。因此，我们可以看到，随着数据量的增加，它们的预测性能也在提高：
- en: '![Figure 10.1 – The effectiveness of DL versus traditional ML ](img/B17928_10_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1 – 深度学习与传统机器学习的有效性](img/B17928_10_01.jpg)'
- en: Figure 10.1 – The effectiveness of DL versus traditional ML
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 深度学习与传统机器学习的有效性
- en: Traditional models often use pre-engineered features and are optimized for datasets
    of various data types and ranges. In the previous chapter, we saw that gradient-boosted
    trees perform extremely well on categorical data. However, in domains that contain
    highly structured data or data of variable lengths, many traditional models reach
    their limits. This is especially true for pixel information in two- and three-dimensional
    images and videos, as well as waveforms in audio data and characters and character
    sequences in free-text data. ML models used to process such data using complex
    manually tuned feature extractors, such as **histogram of oriented gradients**
    (**HoG**) filters, **scale-invariant feature transform** (**SIFT**) features,
    or **local binary patterns** (**LBPs**) – just to name a few filters in the computer
    vision domain.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 传统模型通常使用预构建的特征，并针对各种数据类型和范围的数据集进行优化。在上一章中，我们看到了梯度提升树在分类数据上的表现极为出色。然而，在包含高度结构化数据或可变长度数据的领域中，许多传统模型已经达到了它们的极限。这尤其适用于二维和三维图像以及视频中的像素信息，以及音频数据中的波形以及自由文本数据中的字符和字符序列。以前，机器学习模型使用复杂的、手动调整的特征提取器来处理此类数据，例如**方向梯度直方图（HoG**）过滤器、**尺度不变特征变换（SIFT**）特征或**局部二值模式（LBPs**）——仅举计算机视觉领域中的几个过滤器为例。
- en: What makes this data so complicated is that no obvious linear relationship between
    the input data (for example, a single pixel) and the output exists – in most cases,
    seeing a single pixel of an image won't help determine the brand of a car in that
    image. Therefore, there was an increasing need to train larger and more capable
    parametric models that used raw, unprocessed data as input to capture these relationships
    from the input pixel to make a final prediction.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使这些数据如此复杂的原因是，输入数据（例如，单个像素）和输出之间不存在明显的线性关系——在大多数情况下，看到一个图像中的单个像素并不能帮助确定该图像中的汽车品牌。因此，训练更大、更强大的参数模型的需求不断增加，这些模型使用原始、未处理的数据作为输入，以从输入像素捕获这些关系并做出最终预测。
- en: It's important to understand that the need for deeper models with many more
    parameters comes from the vastly increasing amount of highly structured training
    data in specific domains, such as vision, audio, and language. These new models
    often have millions of parameters to capture the massive amounts of raw and augmented
    training data, as well as developing an internal generalized conceptual representation
    of the training data. Keep this in mind when choosing an ML approach for your
    use case.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，对具有更多参数的深度模型的必要性源于特定领域（如视觉、音频和语言）中高度结构化训练数据的巨大增加。这些新模型通常具有数百万个参数来捕捉大量的原始和增强训练数据，以及开发训练数据的内部泛化概念表示。在选择适用于您的用例的机器学习方法时，请记住这一点。
- en: A quick look at your training data often helps to determine whether a DL-based
    model is suitable for the task – given that DL models have millions of parameters
    to train. If your data is stored in a SQL database or CSV or Excel files, then
    you should probably look into classical ML approaches, such as parametric statistical
    (linear regression, SVM, and so on) or non-parametric (decision tree-based ensembles)
    approaches. If your data is so big that it doesn't fit into memory or is stored
    in a **Hadoop Distributed File System** (**HDFS**), blob storage, or a file storage
    server, then you could use a DL-based approach.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看您的训练数据通常有助于确定基于深度学习的模型是否适合该任务——鉴于深度学习模型有数百万个参数需要训练。如果您的数据存储在SQL数据库、CSV或Excel文件中，那么您可能需要考虑经典机器学习（ML）方法，例如参数统计（线性回归、支持向量机等）或非参数方法（基于决策树的集成）。如果您的数据量如此之大以至于无法放入内存，或者存储在**Hadoop分布式文件系统（HDFS**）、blob存储或文件存储服务器中，那么您可以使用基于深度学习的方法。
- en: From neural networks to deep learning
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从神经网络到深度学习
- en: The foundation of neural networks and hence today's DL-based approaches – the
    **perceptron** – is a concept that is over half a century old and was developed
    in the 1950s. In this section, we will take a look at the basics, and work our
    way back to **MLPs** – also called **artificial neural networks** (**ANNs**) –
    and **CNNs** in the 1980s, and then to **DNNs** and DL in the last decade. This
    will help you understand the foundational concepts of neural networks and hence
    DL, as well as how model architectures and training techniques have evolved over
    the last century into the state-of-the-art techniques we are using today.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的基础以及今天基于深度学习（DL）的方法——**感知器**——是一个超过半个世纪的概念，它是在20世纪50年代发展起来的。在本节中，我们将探讨基础知识，并逐步回顾到20世纪80年代的**多层感知器（MLPs**）——也称为**人工神经网络（ANNs**）——以及**卷积神经网络（CNNs**），然后是最近十年的**深度神经网络（DNNs**）和深度学习（DL）。这将帮助您理解神经网络和深度学习的基础概念，以及模型架构和训练技术在过去一个世纪中是如何演变成我们今天使用的最先进技术的。
- en: The perceptron – a classifier from the 50s
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 感知器——20世纪50年代的分类器
- en: 'Perceptrons are the foundational building blocks of today''s neural networks
    and are modeled on cells in the human brain (so-called **neurons**). They are
    simple non-linear functions consisting of two components: a weighted sum of all
    the inputs and an activation function that fires if the output is larger than
    the specified threshold. While this analogy of a neuron is a great way to model
    how a brain works, it is a poor model to understand how the input signal is transformed
    into its output.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器是今天神经网络的基石，它们模仿人类大脑中的细胞（所谓的**神经元**）。它们由两个简单非线性函数组成：所有输入的加权和以及一个激活函数，如果输出大于指定的阈值，则激活。虽然这种神经元的类比是模拟大脑工作方式的一个很好的方法，但它并不是理解输入信号如何转换为输出的一个很好的模型。
- en: Rather than neurons in the brain, we prefer a much simpler, non-biological approach
    to explain the perceptron, MLPs, and CNNs – namely, a simple geometric approach.
    When simplified, this method requires you to only understand the two-dimensional
    line equation. Once you understand the basics in two dimensions, the concept can
    be extended to multiple dimensions, where the line becomes a plane or hyperplane
    in a higher-dimensional feature space.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们更倾向于使用一种简单得多、非生物的方法来解释感知器、MLPs 和 CNNs，即简单的几何方法。当简化后，这种方法只需要你理解二维直线方程。一旦你理解了两维的基本概念，这个概念可以扩展到多维度，其中直线在更高维的特征空间中变成一个平面或超平面。
- en: 'If we look at a single perceptron, it describes a **weighted sum** of its inputs
    plus constant bias with an **activation function**. Let''s break down the two
    components of the perceptron. Do you know what is also described as a weighted
    sum of its inputs plus bias? Right, the line equation:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看一个单独的感知器，它描述了其输入的**加权求和**加上一个常量偏置和一个**激活函数**。让我们分解感知器的两个组成部分。你知道什么也被描述为输入的加权求和加上偏置吗？对，就是直线方程：
- en: '![](img/Formula_10.1.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10.1.png)'
- en: 'In the preceding equation, *x* is the input, *k* is the weight, and *b* is
    the bias term. You have probably seen this equation at some point in your math
    curriculum. A property of this equation is that when you''re inserting a point''s
    *x* and *y* coordinates into the line equation, it yields 0 = 0 for all the points
    that lie on the line. We can use this information to derive the vector form of
    the line equation, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，*x* 是输入，*k* 是权重，*b* 是偏置项。你可能在你的一些数学课程中看到过这个方程。这个方程的一个特性是，当你将一个点的 *x*
    和 *y* 坐标插入到直线方程中时，对于所有位于直线上的点，它会产生 0 = 0。我们可以利用这个信息推导出直线方程的向量形式，如下所示：
- en: '![](img/Formula_10.2.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10.2.png)'
- en: Hence, ![](img/Formula_10.3.png) is *0* when the point lies on the line. What
    happens if we insert the coordinates of a point that does not lie on the line?
    A good guess is that the result will be either positive or negative but certainly
    not 0\. A property of the vector line equation is that the sign of this result
    describes which side of the line the point lies on. Hence, the point lies either
    on the left or the right-hand side of the line when ![](img/Formula_10.4.png)
    is positive or negative but not null.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当点位于直线上时，![](img/Formula_10.3.png) 为 *0*。如果我们插入一个不在直线上的点的坐标会发生什么？一个很好的猜测是结果将是正的或负的，但肯定不是
    0\. 向量直线方程的一个特性是，这个结果的正负号描述了点位于直线的哪一侧。因此，当 ![](img/Formula_10.4.png) 为正或负但不是零时，点位于直线的左侧或右侧。
- en: 'To determine the side of the line, we can apply the sign function to ![](img/Formula_10.5.png).
    The sign function is often also referred to as the step function, as its output
    is either *1* or *-1*, hence positive or negative. The sign or step function here
    is our activation function and hence the second component of the perceptron. The
    output of the perceptron, ![](img/Formula_10.6.png), can be written as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定直线的哪一侧，我们可以将符号函数应用于 ![](img/Formula_10.5.png)。符号函数通常也被称为阶跃函数，因为它的输出是 *1*
    或 *-1*，因此是正的或负的。这里的符号或阶跃函数是我们的激活函数，因此是感知器的第二个组成部分。感知器的输出 ![](img/Formula_10.6.png)
    可以写成以下形式：
- en: '![](img/Formula_10.7.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10.7.png)'
- en: 'In the following chart, we can see two points, a line, and their shortest distance
    to the line. Both points are not lying on the line, so the line separates both
    points from each other. If we insert both points'' coordinates into the vector
    line equation, then one point would result in a positive value ![](img/Formula_10.8.png),
    whereas the other point would result in a negative value ![](img/Formula_10.9.png):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图表中，我们可以看到两个点、一条直线以及它们到直线的最短距离。两个点都不在直线上，因此直线将它们彼此分开。如果我们把两个点的坐标插入到向量直线方程中，那么一个点会产生一个正值
    ![](img/Formula_10.8.png)，而另一个点会产生一个负值 ![](img/Formula_10.9.png)：
- en: '![Figure 10.2 – A simple binary classifier ](img/B17928_10_02.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 一个简单的二元分类器](img/B17928_10_02.jpg)'
- en: Figure 10.2 – A simple binary classifier
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 一个简单的二元分类器
- en: The result would tell us which side of the line the point lies on. This line
    is a geometric description of the perceptron, which is a very simple classifier.
    The trained perceptron is defined through the line equation (or a hyperplane in
    multiple dimensions), which separates a space into left and right. This line is
    the decision boundary for a classification, and a point is an observation. By
    inserting a point into the line equation and applying the step function, we return
    the resulting class of the observation, which is left or right, -1 or +1, or class
    A or B. This describes a binary classifier.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 结果会告诉我们点位于线的哪一侧。这条线是感知器的几何描述，它是一个非常简单的分类器。训练好的感知器通过线方程（或多个维度中的超平面）定义，将空间分为左右两部分。这条线是分类的决策边界，而一个点是一个观察。通过将一个点插入线方程并应用步函数，我们返回观察结果的类别，即左或右，-1或+1，或类别A或B。这描述了一个二元分类器。
- en: And how do we find the decision boundary? To find the optimal decision boundary,
    we can follow an iterative training process while using labeled training samples.
    First, we must initialize a random decision boundary, then compute the distance
    from each sample to the decision boundary and move the decision boundary into
    the direction that minimizes the total sum of distances. The optimal vector to
    move the decision boundary is if we move it along the negative gradient, such
    that the distance between the point and the line reaches a minimum. By using a
    learning rate factor, we iterate this process a few times and end up with a perfectly
    aligned decision boundary, if the training samples are linearly separable. This
    process is called **gradient descent**, where we iteratively modify the classifier
    weights (decision boundaries, in this example) to find the optimal boundary with
    minimal error.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何找到决策边界？为了找到最优的决策边界，我们可以在使用标记的训练样本的同时遵循一个迭代训练过程。首先，我们必须初始化一个随机的决策边界，然后计算每个样本到决策边界的距离，并将决策边界移动到最小化总距离和的方向。移动决策边界的最优向量是如果我们沿着负梯度移动它，使得点与线之间的距离达到最小。通过使用学习率因子，我们迭代这个过程几次，最终得到一个完美对齐的决策边界，如果训练样本是线性可分的。这个过程被称为**梯度下降**，其中我们迭代地修改分类器的权重（在这个例子中是决策边界）以找到具有最小误差的最优边界。
- en: The multilayer perceptron
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多层感知器
- en: 'A perceptron describes a simple classifier whose decision boundary is a line
    (or hyperplane) that''s been defined through the weighted inputs. However, instead
    of using a single classifier, we can simply increase the number of neurons, which
    will result in multiple decision boundaries, as shown in the following chart:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器描述了一个简单的分类器，其决策边界是通过加权输入定义的线（或超平面）。然而，我们不是使用单个分类器，而是简单地增加神经元的数量，这将导致多个决策边界，如下面的图表所示：
- en: '![Figure 10.3 – Combining multiple perceptrons ](img/B17928_10_03.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3 – 多个感知器的组合](img/B17928_10_03.jpg)'
- en: Figure 10.3 – Combining multiple perceptrons
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – 多个感知器的组合
- en: Each neuron describes a decision boundary and hence will have separate weights
    and a separate output – left or right of the decision boundary. By stacking multiple
    neurons in layers, we can create classifiers whose inputs are the output of the
    previous ones. This allows us to combine the results from multiple decision boundaries
    into a single output – for example, finding all the samples that are enclosed
    by the decision boundaries of three neurons, as shown in the preceding chart.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 每个神经元描述一个决策边界，因此将具有独立的权重和输出 – 决策边界的左侧或右侧。通过在层中堆叠多个神经元，我们可以创建输入是前一个输出的分类器。这允许我们将多个决策边界的输出组合成一个单一的输出
    – 例如，找到所有被三个神经元的决策边界包围的样本，如前述图表所示。
- en: While a single layer of perceptrons describes a linear combination of inputs
    and outputs, researchers began to stack these perceptrons into multiple sequential
    layers, where each layer was followed by an activation function. This is called
    MLP, or an ANN. Using the geometric model as an analogy, you could simply stack
    multiple decision boundaries on complex geometric objects to create more complex
    decision boundaries.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当单层感知器描述输入和输出的线性组合时，研究人员开始将这些感知器堆叠成多个连续层，每一层后面都跟着一个激活函数。这被称为MLP，或人工神经网络。使用几何模型作为类比，你可以在复杂的几何对象上简单地堆叠多个决策边界，以创建更复杂的决策边界。
- en: Important Note
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Another analogy is that the classifier's decision boundary is always a straight
    hyperplane, but the input samples are transformed to be linearly separated through
    the decision boundary.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个类比是，分类器的决策边界始终是一个直线超平面，但输入样本通过决策边界被转换成线性分离。
- en: The same geometric analogy helps us understand the layers in DL models. While
    the first layers of a network describe very low-level geometric features, such
    as straight edges and lines, the higher levels describe complicated nested combinations
    of these low-level features; for example, four lines build a square, five squares
    build a more complex shape, and a combination of those shapes looks like a human
    face. We just built a face detector using a three-layer neural network.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的几何类比帮助我们理解深度学习模型中的层。虽然网络的第一层描述了非常低级的几何特征，例如直线和线条，但更高层描述了这些低级特征的复杂嵌套组合；例如，四条线构成一个正方形，五个正方形构成一个更复杂的形状，而这些形状的组合看起来像人脸。我们就是用三层神经网络构建了一个人脸检测器。
- en: 'The Google DeepDream experiment is a fantastic example of this analogy. In
    the following figure, we can visualize how three layers of different depths in
    a pre-trained DNN represent features in an image of a cloudy sky. The layers are
    extracted from the beginning, middle, and end of a DNN and transform the input
    image to minimize the loss of each layer. Here, we can see how the earlier layer
    focuses mostly on lines and edges (left), whereas the middle layer sees abstract
    shapes (middle), and the last layer activates on very specific high-level features
    in the image (right):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Google DeepDream实验是这个类比的一个绝佳例子。在下面的图中，我们可以可视化一个预训练的深度神经网络（DNN）中不同深度的三层如何表示多云天空图像中的特征。这些层是从DNN的开始、中间和末端提取出来的，并将输入图像转换为最小化每层的损失。在这里，我们可以看到早期层主要关注线条和边缘（左），中间层看到抽象形状（中间），而最后一层在图像的非常具体的高级特征上激活（右）：
- en: '![Figure 10.4 – DeepDream – minimizing loss for the layers of a DNN ](img/B17928_10_04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图10.4 – DeepDream – 最小化DNN层的损失](img/B17928_10_04.jpg)'
- en: Figure 10.4 – DeepDream – minimizing loss for the layers of a DNN
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – DeepDream – 最小化DNN层的损失
- en: Next, let's look at CNNs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看CNNs。
- en: CNNs
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CNNs
- en: Using multiple high-dimensional hyperplane equations, where each output feeds
    into each input of the following layer, requires a very large number of parameters.
    While a high number of parameters is required to model a massive amount of complex
    training data, a so-called fully connected neural network is not the best way
    to describe these connections. So, what's the problem?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多个高维超平面方程，其中每个输出馈送到下一层的每个输入，需要非常多的参数。虽然需要大量的参数来模拟大量的复杂训练数据，但所谓的全连接神经网络并不是描述这些连接的最佳方式。那么，问题是什么？
- en: In a fully connected network, each output is fed to each neuron of the consecutive
    layer as input. In each neuron, we require a weight for each input, so we need
    as many weights as there are input dimensions. This number quickly explodes when
    we start stacking multiple layers of perceptrons. Another problem is that the
    network cannot generalize because it learns all the individual weights separately
    for each dimension.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在全连接网络中，每个输出都被作为输入馈送到下一层的每个神经元。在每个神经元中，我们都需要为每个输入设置一个权重，因此我们需要与输入维度一样多的权重。当我们开始堆叠多个感知器层时，这个数字会迅速增加。另一个问题是，网络无法泛化，因为它为每个维度分别学习所有单个权重。
- en: In the 1980s, CNNs were invented to solve these problems. Their purpose was
    to reduce the number of connections and parameters on a single layer to a fixed
    set of parameters, independent of the number of input dimensions. The parameters
    of a layer are now shared within all the inputs. The idea of this approach comes
    from signal processing, where filters are applied to a signal through a convolution
    operation. Convolution means applying a single set of weights, such as a window
    function, to multiple regions of the input and later summing up all the signal
    responses of the filter for each location.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪80年代，卷积神经网络（CNNs）被发明来解决这些问题。它们的目的是将单层上的连接和参数数量减少到一个固定的参数集，这个参数集与输入维度的数量无关。现在，一个层的参数在所有输入之间是共享的。这种方法的灵感来源于信号处理，其中滤波器通过卷积操作应用于信号。卷积意味着将单一权重集，如窗口函数，应用于输入的多个区域，然后对每个位置的滤波器信号响应进行求和。
- en: 'This was the same idea for the convolution layers of CNNs. By using a fixed-sized
    filter that is convolved with the input, we can greatly reduce the number of parameters
    for each layer and add more nested layers to the network. By using a so-called
    pooling layer, we can also reduce the image size and apply filters to a downscaled
    version of the input. Let''s take a look at the popular layers that are used for
    building CNNs:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是卷积神经网络中卷积层相同的概念。通过使用与输入卷积的固定大小滤波器，我们可以大大减少每一层的参数数量，并在网络中添加更多嵌套层。通过使用所谓的池化层，我们还可以减少图像大小，并将滤波器应用于输入的降尺度版本。让我们看看用于构建卷积神经网络的流行层：
- en: '**Fully connected (FC)**: The FC layer is a layer of fully connected neurons,
    as described in the previous section about perceptrons – it connects every output
    from the previous layer with a neuron. In DNN, FC layers are often used at the
    end of the network to combine all the spatially distributed activations of the
    previous convolution layers. The FC layers also have the largest number of parameters
    in a model (usually around 90%).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接（FC）**：FC层是一个全连接神经元层，如前一小节关于感知器的描述中所述——它将前一层的每个输出与一个神经元连接起来。在深度神经网络中，FC层通常用于网络的末端，以结合前一卷积层的所有空间分布的激活。FC层在模型中也有最多的参数（通常约为90%）。'
- en: '**Convolution**: A convolution layer consists of spatial (often two-dimensional)
    filters that are convolved along the spatial dimensions and summed up along the
    depth dimension of the input. Due to weight sharing, they are much more efficient
    than fully connected layers and have a lot fewer parameters.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积**：卷积层由沿空间维度（通常是二维）卷积的空间（滤波器）组成，并在输入的深度维度上求和。由于权重共享，它们比全连接层更高效，并且参数更少。'
- en: '**Pooling**: Convolution layers are often followed by a pooling layer to reduce
    the spatial dimension of the volume for the next filter – this is the equivalent
    of a subsampling operation. The pooling operation itself has no learnable parameters.
    Most of the time, **max pooling** layers are used in DL models due to their simple
    gradient computation. Another popular choice is **avg pooling**, which is mostly
    used as a classifier at the end of a network.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**池化**：卷积层通常后面跟着一个池化层来减少下一滤波器的体积的空间维度——这相当于一个子采样操作。池化操作本身没有可学习的参数。大多数情况下，由于它们简单的梯度计算，在深度学习模型中会使用**最大池化**层。另一个流行的选择是**平均池化**，它通常用作网络末端的分类器。'
- en: '**Normalization**: In modern DNNs, normalization layers are often used to stabilize
    gradients throughout the network. Due to the unbounded behavior of some activation
    functions, filter responses have to be normalized. A commonly used normalization
    technique is **batch normalization**.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化**：在现代深度神经网络中，归一化层通常用于在整个网络中稳定梯度。由于某些激活函数的无界行为，滤波器响应必须归一化。常用的归一化技术是**批归一化**。'
- en: Now that we understand the main components of CNNs, we can look into how these
    models were stacked even deeper to improve generalization and hence improve the
    prediction's performance.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了卷积神经网络的主要组成部分，我们可以看看这些模型是如何堆叠得更深，以提高泛化能力，从而提高预测性能。
- en: From CNNs to DL
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从卷积神经网络到深度学习
- en: The perceptron from the 50s, as well as ANNs and CNNs from the 80s, build the
    foundation for all the DL models that are used today. By stabilizing the gradients
    during the training process, researchers could overcome the exploding and vanishing
    gradients problem and build deeper models. This was achieved by using additional
    normalization layers, rectified linear activation, auxiliary losses, and residual
    connections.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 20世纪50年代的感知器，以及80年代的ANN和CNN，为今天使用的所有深度学习模型奠定了基础。通过在训练过程中稳定梯度，研究人员克服了梯度爆炸和消失的问题，构建了更深的模型。这是通过使用额外的归一化层、修正线性激活、辅助损失和残差连接来实现的。
- en: Deeper models have more learnable parameters – often well over 100 million parameters
    – so they can find higher-level patterns and learn more complex transformations.
    However, to train deeper models, you must also use more training data. Therefore,
    companies and researchers built massive labeled datasets (such as ImageNet) to
    feed these models with training data.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 深度模型有更多的可学习参数——通常超过一亿个参数——因此它们可以找到更高层次的模式，学习更复杂的变换。然而，为了训练更深的模型，你还必须使用更多的训练数据。因此，公司和研究人员建立了大量的标记数据集（如ImageNet），为这些模型提供训练数据。
- en: This development process was facilitated by the availability of cheap parallelizable
    compute in the form of GPUs and cloud computing. Training these deep models quickly
    went from months to days to hours within a couple of years. Today, we can train
    a typical DNN in under an hour with a highly parallelized compute infrastructure.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这种发展过程得益于廉价并行计算资源（如GPU和云计算）的可用性。训练这些深度模型的速度在短短几年内从数月缩短到数天再到数小时。如今，我们可以在高度并行的计算基础设施下，在一小时内训练一个典型的深度神经网络（DNN）。
- en: A lot of research also went into new techniques for stacking layers, from very
    deep networks with skip connections, as in ResNet152, to networks with parallel
    layer groups, as in GoogLeNet. A combination of both layer types led to extremely
    efficient network architectures such as SqueezeNet and Inception. New layer types
    such as LSTM, GRU, and attention enabled significantly better prediction performance,
    while the GAN and transform models created entirely new ways to train and optimize
    models.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究也投入到了新的层堆叠技术中，从具有跳转连接的非常深的网络（如ResNet152）到具有并行层组的网络（如GoogLeNet）。这两种层类型的组合导致了极其高效的网络架构，如SqueezeNet和Inception。新的层类型如LSTM、GRU和注意力机制显著提高了预测性能，而GAN和变换模型创造了全新的训练和优化模型的方法。
- en: All these advances helped make DL what it has become today – a ubiquitous ML
    technique that, given enough training data, can outperform traditional ML models
    and often even humans in most prediction tasks. Today, DL is applied to almost
    any domain where there is sufficient data at hand.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些进步都帮助深度学习成为今天无处不在的机器学习技术——在提供足够训练数据的情况下，它可以在大多数预测任务中超越传统的机器学习模型，甚至优于人类。如今，深度学习被应用于几乎任何有足够数据可用的领域。
- en: DL versus traditional ML
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习与传统机器学习
- en: Let's look at the main differences between classical ML- and DL-based approaches
    and find out what DL models can do with so many more parameters and how they benefit
    from them.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看经典机器学习方法和基于深度学习方法的区别，并了解深度学习模型如何利用更多的参数以及它们从中获得的好处。
- en: If we look at the image or audio processing domain before 2012, we will see
    that ML models were not usually trained on the raw data itself. Instead, the raw
    data went through a manually crafted feature extractor and converted into a lower-dimensional
    feature space. When dealing with images of 256 x 256 x 3 dimensions (RGB) – which
    corresponds to a 196,608-dimensional feature space – and converting these into,
    say, a 2,048-dimensional feature embedding as input for the ML models, we greatly
    reduce the computational requirements for these models. The feature extractors
    for image and audio features often use a convolution operator and a specific filter
    (such as an edge detector, blob detector, spike/dip detector, and so on). However,
    the filter is usually constructed manually.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾2012年之前的图像或音频处理领域，我们会发现机器学习模型通常不是在原始数据本身上训练的。相反，原始数据经过人工设计的特征提取器转换成低维特征空间。当处理256
    x 256 x 3维度的图像（RGB，对应196,608维特征空间）并将其转换为例如2,048维特征嵌入作为机器学习模型的输入时，我们大大降低了这些模型的计算需求。图像和音频特征的特征提取器通常使用卷积算子和特定的滤波器（如边缘检测器、块检测器、尖峰/谷检测器等）。然而，滤波器通常是手动构建的。
- en: The classical ML models that have been developed in the past 50+ years are still
    the ones we are successfully using today. Among those are tree-based ensemble
    techniques, linear and logistic regression, SVMs, and MLPs. The MLP model is also
    known as a fully connected neural network with hidden layers and still serves
    as a classification or regression head in some of the early DL architectures.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去50多年中开发的经典机器学习模型仍然是今天我们成功使用的模型。其中包括基于树的集成技术、线性回归和逻辑回归、支持向量机（SVMs）和多层感知器（MLPs）。MLP模型也被称为具有隐藏层的全连接神经网络，并且在一些早期的深度学习架构中仍作为分类或回归头使用。
- en: 'The following diagram shows the typical pipeline of a classical ML approach
    in the computer vision domain:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了计算机视觉领域中经典机器学习方法的典型流程：
- en: '![Figure 10.5 – Traditional ML classifier ](img/B17928_10_05.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图10.5 – 传统机器学习分类器](img/B17928_10_05.jpg)'
- en: Figure 10.5 – Traditional ML classifier
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – 传统机器学习分类器
- en: First, the raw data is converted into a lower-dimensional feature embedding
    using hand-crafted image filters (SIFT, SURF, HoG, LBPs, Haar filters, and so
    on). Then, feature embedding is used to train an ML model; for example, a multi-layer,
    fully connected neural network or decision-tree classifier, as shown in the preceding
    diagram.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用手工制作的图像滤波器（SIFT、SURF、HoG、LBPs、Haar滤波器等）将原始数据转换为低维特征嵌入。然后，使用特征嵌入来训练机器学习模型；例如，一个多层全连接神经网络或决策树分类器，如前图所示。
- en: When it is difficult for a human being to express a relationship between an
    input image and an output label in simple rules, then it is most likely also difficult
    for a classical computer vision and ML approach to find such rules. DL-based approaches
    perform a lot better in these cases. The reason for this is that DL models are
    trained on raw input data instead of manually extracted features. Since convolution
    layers are the same as randomized and trained image filters, these filters for
    feature extraction are implicitly learned by the network.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当人类难以用简单规则表达输入图像和输出标签之间的关系时，那么对于经典计算机视觉和机器学习方法来说，找到这样的规则也可能很困难。基于深度学习的方法在这些情况下表现更好。原因在于深度学习模型是在原始输入数据上而不是在手动提取的特征上训练的。由于卷积层与随机和训练的图像滤波器相同，这些用于特征提取的滤波器被网络隐式地学习。
- en: 'The following diagram shows a DL approach to image classification, which is
    similar to the previous diagram for the classical ML approach:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了图像分类的深度学习方法，这与经典机器学习方法的前图类似：
- en: '![Figure 10.6 – DL-based classifier ](img/B17928_10_06.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图10.6 – 基于深度学习的分类器](img/B17928_10_06.jpg)'
- en: Figure 10.6 – DL-based classifier
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – 基于深度学习的分类器
- en: As we can see, the raw input data of the image is fed directly to the network,
    which outputs the final image label. This is why we often refer to a DL model
    as an end-to-end model – because it creates an end-to-end transformation between
    the input data (literally, the raw pixel values) and the model's output.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，原始输入图像数据直接输入到网络中，输出最终的图像标签。这就是我们通常将深度学习模型称为端到端模型的原因——因为它在输入数据（字面上，原始像素值）和模型输出之间创建了一个端到端转换。
- en: As shown in the preceding diagram, the DL-based model is an end-to-end model
    that learns both the feature extractor and the classifier in a single model. However,
    we often refer to the last fully connected layer.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，基于深度学习的模型是一个端到端模型，它在一个模型中学习特征提取器和分类器。然而，我们通常指的是最后一个全连接层。
- en: Important Note
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Look at the type of data before choosing your ML model. If you are dealing with
    images, video, audio, time series, language, or text, you may wish to use a DL
    model or feature extractor for embedding, clustering, classification, or regression.
    If you are working with operational or business data, then a classic ML approach
    would be a better fit.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择机器学习模型之前，看看你的数据类型。如果你处理的是图像、视频、音频、时间序列、语言或文本，你可能希望使用深度学习模型或特征提取器进行嵌入、聚类、分类或回归。如果你处理的是运营或业务数据，那么经典机器学习方法可能更适合。
- en: Using traditional ML with DL-based feature extractors
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用基于深度学习的特征提取器进行传统机器学习
- en: In many cases, especially when you have small datasets, not enough compute resources,
    or knowledge to train end-to-end DL models, you can also reuse a pre-trained DL
    model as a feature extractor. This can be done by loading a pre-trained model
    and performing a forward pass until the classification/regression head. It returns
    a multi-dimensional embedding (a so-called latent space representation) that you
    can directly plug into a classical ML model.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，尤其是当你拥有小数据集、计算资源不足或缺乏训练端到端深度学习模型的知识时，你也可以重用预训练的深度学习模型作为特征提取器。这可以通过加载预训练模型并执行正向传播直到分类/回归头部来实现。它返回一个多维嵌入（所谓的潜在空间表示），你可以直接将其插入到经典机器学习模型中。
- en: 'Here is an example of such a hybrid approach. We are using the `IncpetionV3`
    model as a feature extractor, pre-trained on the `imagenet` data. The DL model
    is only used to transform the raw input image data into a lower-dimensional feature
    representation. Then, an SVM model is trained on top of the image features. Let''s
    look at the source code for this example:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个这种混合方法的例子。我们使用在`imagenet`数据上预训练的`IncpetionV3`模型作为特征提取器。深度学习模型仅用于将原始输入图像数据转换为低维特征表示。然后，在图像特征之上训练一个SVM模型。让我们看看这个例子的源代码：
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the preceding code, we used TensorFlow to load the `InceptionV3` model with
    the ImageNet-based weights but without any classification or regression head.
    This is achieved by setting the `include_top` property to `False`. Then, we squeezed
    the output of the prediction – the image's latent representation – into a single
    vector. Finally, we trained an SVM on the image features using scikit-learn and
    a default train/test split.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用TensorFlow加载了基于ImageNet权重的`InceptionV3`模型，但没有任何分类或回归头。这是通过将`include_top`属性设置为`False`来实现的。然后，我们将预测的输出——图像的潜在表示——压缩成一个单一的向量。最后，我们使用scikit-learn和默认的train/test拆分在图像特征上训练了一个支持向量机（SVM）。
- en: We started with the classical approach, where feature extraction and ML were
    separated into two steps. However, the filters in the classical approach were
    hand-crafted and applied directly to the raw input data. In a DL approach, we
    implicitly learn the feature extraction.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从经典方法开始，其中特征提取和ML被分为两个步骤。然而，在经典方法中，过滤器是手工制作的，并直接应用于原始输入数据。在深度学习方法中，我们隐式地学习特征提取。
- en: Training a CNN for image classification
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练用于图像分类的卷积神经网络（CNN）
- en: 'Now that we have a good understanding of why and when to use DL models, we
    can start to implement one and run it using Azure Machine Learning. We will start
    with a task that DL performed very well with over the past years – computer vision,
    or more precisely, image classification. If you feel that this is too easy for
    you, you can replace the actual training script with any other computer vision
    technique and follow along with the steps in this section:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经很好地理解了为什么以及何时使用深度学习模型，我们就可以开始实施一个模型并使用Azure Machine Learning来运行它。我们将从一个深度学习在过去几年中表现非常出色的任务开始——计算机视觉，或者更准确地说，是图像分类。如果你觉得这对你来说太简单了，你可以用任何其他计算机视觉技术替换实际的训练脚本，并按照本节中的步骤进行操作：
- en: First, we will power up an Azure Machine Learning compute instance, which will
    serve as our Jupyter Notebook authoring environment. First, we will write a training
    script and execute it in the authoring environment to verify that it works properly,
    checkpoints the model, and logs the training and validation metrics. We will train
    the model for a few epochs to validate the setup, the code, and the resulting
    model.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将启动一个Azure Machine Learning计算实例，它将作为我们的Jupyter Notebook创作环境。首先，我们将编写一个训练脚本并在创作环境中执行它，以验证其是否正常工作，检查点保存模型，并记录训练和验证指标。我们将训练模型几个周期以验证设置、代码和生成的模型。
- en: Next, we will try to improve the algorithm by adding data augmentation to the
    training script. While this seems like an easy task, I want to reiterate that
    this is necessary and strongly recommended for any DL-based ML approach. Image
    data can easily be augmented to improve generalization and therefore model scoring
    performance. However, through this technique, training the model will take even
    longer than before because more training data is being used for each epoch.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将尝试通过在训练脚本中添加数据增强来改进算法。虽然这似乎是一个简单的任务，但我想要重申，这对于任何基于深度学习的ML方法来说都是必要的，并且强烈推荐。图像数据可以很容易地增强以提高泛化能力，从而提高模型评分性能。然而，通过这种技术，模型的训练将比之前更长，因为每个周期使用了更多的训练数据。
- en: Now, we must move the training script from the authoring environment to a GPU
    cluster – a remote compute environment. We will do all this – upload the data,
    generate the training scripts, create the cluster, execute the training script
    on the cluster, and retrieve the trained model – from within the authoring environment
    in the Azure Machine Learning service. If you are already training ML models yourself
    on your server, then this section will show you how to move your training scripts
    to a remote execution environment and how to benefit from dynamically scalable
    compute (both vertically and horizontally, hence larger and more machines), auto-scaling,
    cheap data storage, and much more.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须将训练脚本从创作环境迁移到GPU集群——一个远程计算环境。我们将在这个环境中完成所有这些工作——上传数据、生成训练脚本、创建集群、在集群上执行训练脚本，以及检索训练好的模型。如果你已经在自己的服务器上自行训练ML模型，那么本节将展示如何将你的训练脚本迁移到远程执行环境，以及如何从动态可扩展的计算（垂直和水平扩展，因此是更大和更多的机器）、自动扩展、低成本数据存储等众多好处中受益。
- en: Once you have successfully trained a CNN from scratch, you will want to move
    on to the next level in terms of model performance and complexity. A good and
    recommended approach is to fine-tune pre-trained DL models rather than train them
    from scratch. Using this approach, we can often also use a pre-trained model from
    a specific task, drop the classification head (usually the last one or two layers)
    from the model, and reuse the feature extractor for another task by training our
    classification head on top of it. This is called transfer learning and is widely
    used for training state-of-the-art models for various domains.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你成功从头开始训练了一个CNN，你将想要在模型性能和复杂性方面进入下一个层次。一个良好且推荐的方法是微调预训练的深度学习（DL）模型，而不是从头开始训练。采用这种方法，我们通常还可以使用来自特定任务的预训练模型，从模型中移除分类头（通常是最后的一个或两个层），并通过在它之上训练我们的分类头来重用特征提取器进行另一个任务。这被称为迁移学习，并且被广泛用于训练各种领域的最先进模型。
- en: Now, let's open a Jupyter notebook and start training a CNN image classifier.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们打开一个Jupyter笔记本，开始训练一个CNN图像分类器。
- en: Training a CNN from scratch in your notebook
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在笔记本中从头开始训练CNN
- en: 'Let''s train a CNN on Jupyter on the Azure Machine Learning service. First,
    we want to simply train a model in the current authoring environment, which means
    we must use the compute (CPU and memory) from the compute instance. This is a
    standard Python/Jupyter environment, so it is no different from training an ML
    model on your local machine. So, let''s go ahead and create a new compute instance
    in our Azure Machine Learning service workspace, and then open the Jupyter environment:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在Azure Machine Learning服务上的Jupyter中训练一个CNN。首先，我们只想在当前创作环境中简单地训练一个模型，这意味着我们必须使用计算实例（CPU和内存）。这是一个标准的Python/Jupyter环境，所以它与在本地机器上训练ML模型没有区别。因此，让我们在我们的Azure
    Machine Learning服务工作区中创建一个新的计算实例，然后打开Jupyter环境：
- en: 'Before we begin creating our CNN model, we need some training data. As we train
    the ML model on the authoring computer, the data needs to be on the same machine.
    For this example, we will use the MNIST image dataset:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们开始创建我们的卷积神经网络（CNN）模型之前，我们需要一些训练数据。由于我们在创作计算机上训练机器学习（ML）模型，数据需要位于同一台机器上。在这个例子中，我们将使用MNIST图像数据集：
- en: '[PRE1]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the preceding code, we loaded the training and testing data and put it in
    the `data` directory of the current environment where the code executes. In the
    next section, we will learn how to make the data available on any compute instance
    in the ML workspace.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们加载了训练和测试数据，并将其放在当前环境中代码执行的`data`目录中。在下一节中，我们将学习如何使数据在ML工作区中的任何计算实例上可用。
- en: 'Next, we must load the data, parse it, and store it in multi-dimensional NumPy
    arrays. We will use a helper function, `load`, which is defined in the accompanying
    source code for this chapter. After that, we must preprocess the training data
    by normalizing the pixel values to a range between `0` and `1`:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须加载数据，解析它，并将其存储在多维NumPy数组中。我们将使用一个辅助函数`load`，该函数定义在本章的配套源代码中。之后，我们必须通过将像素值归一化到`0`到`1`之间来预处理训练数据：
- en: '[PRE2]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Using the `reshape` method, we checked that the training and testing labels
    are one-dimensional vectors with a single label per training and testing sample.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`reshape`方法，我们检查了训练和测试标签是一维向量，每个训练和测试样本都有一个标签。
- en: Once we have the training data, it is time to decide which Python framework
    to use to train the neural network models. While you are not limited to any specific
    framework in Azure Machine Learning, it is recommended you use either TensorFlow
    (with Keras) or PyTorch to train neural networks and DL models. TensorFlow and
    Keras are great choices when you're training and deploying standard production
    models.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了训练数据，就是时候决定使用哪个Python框架来训练神经网络模型了。虽然你在Azure Machine Learning中不受任何特定框架的限制，但我们建议你使用TensorFlow（带Keras）或PyTorch来训练神经网络和深度学习模型。当你训练和部署标准生产模型时，TensorFlow和Keras是不错的选择。
- en: Important Note
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: PyTorch is a great choice for tinkering with exotic models and custom layers
    and debugging customized models. In my opinion, PyTorch is a bit easier to get
    started with, whereas TensorFlow is more complex and mature and has a bigger ecosystem.
    In this chapter, we will use TensorFlow due to its large ecosystem, Keras integration,
    great documentation, and good support in the Azure Machine Learning service.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是探索异构模型和自定义层以及调试定制模型的一个很好的选择。在我看来，PyTorch更容易上手，而TensorFlow则更复杂、更成熟，并且拥有更大的生态系统。在本章中，我们将使用TensorFlow，因为它拥有庞大的生态系统、Keras集成、优秀的文档以及在Azure机器学习服务中的良好支持。
- en: 'Having chosen an ML framework, we can start to construct a simple CNN. Let''s
    use `keras` to construct a sequential model:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择了一个机器学习框架后，我们可以开始构建一个简单的CNN。让我们使用`keras`构建一个序列模型：
- en: '[PRE3]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding code, we took advantage of the `keras.Sequential` model API
    to construct a simple CNN model. We went with the default initialization of the
    weights and solely specified the model structure here. You can also see the typical
    combination of a feature extractor until the `Flatten` layer, and the MLP classification
    head outputting 10 probabilities using the `softmax` activation function at the
    end.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们利用了`keras.Sequential`模型API构建了一个简单的CNN模型。我们采用了默认的权重初始化，并在这里仅指定了模型结构。您还可以看到典型的特征提取器组合，直到`Flatten`层，以及使用`softmax`激活函数在末尾输出10个概率的MLP分类头。
- en: 'Let''s take a quick look at the model, which has, in total, `409034` parameters,
    as shown in the following diagram. Please note that we specifically constructed
    a simple CNN from a tiny image size of `28x28` grayscale images. The following
    diagram shows the compact structure of the model defined. Here, we can observe
    that the largest number of parameters is the fully connected layer after the feature
    extractor, which contains 98% of the parameters of the total model:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下模型，该模型总共有`409034`个参数，如下面的图所示。请注意，我们特别构建了一个简单的CNN，其输入图像尺寸为`28x28`的灰度图像。下面的图显示了模型定义的紧凑结构。在这里，我们可以观察到最大的参数数量是在特征提取器之后的全连接层，它包含了总模型参数的98%：
- en: '![Figure 10.7 – DL model architecture ](img/B17928_10_07.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7 – 深度学习模型架构](img/B17928_10_07.jpg)'
- en: Figure 10.7 – DL model architecture
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – 深度学习模型架构
- en: 'After defining the model structure, we need to define the `loss` metric that
    we are trying to optimize and specify an optimizer. The optimizer is responsible
    for computing the changes for all the weights per training iteration, given the
    total and backpropagated loss. With Keras and TensorFlow, we can easily choose
    a state-of-the-art optimizer and use a default metric for classification:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定义了模型结构之后，我们需要定义我们试图优化的`loss`指标，并指定一个优化器。优化器负责在每次训练迭代中计算所有权重的变化，给定总损失和反向传播的损失。使用Keras和TensorFlow，我们可以轻松选择一个最先进的优化器，并为分类使用默认的指标：
- en: '[PRE4]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the preceding code, we defined a `categorical_crossentropy` loss and the
    `adam` optimizer to train the CNN. We also tracked another metric besides the
    loss – `accuracy`. This makes it easier to estimate and measure the performance
    of the CNN during training.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们定义了一个`categorical_crossentropy`损失和`adam`优化器来训练CNN。我们还跟踪了除了损失之外的另一个指标——`accuracy`。这使得在训练过程中更容易估计和衡量CNN的性能。
- en: 'Before we start training, we must define a model checkpoint. This is important
    as it allows us to pause and resume training at any given time after an epoch.
    Using Keras, it is quite simple to implement this, as follows:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始训练之前，我们必须定义一个模型检查点。这很重要，因为它允许我们在每个epoch之后在任何给定时间暂停和恢复训练。使用Keras，实现这一点相当简单，如下所示：
- en: '[PRE5]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we can start the training locally by invoking the `fit` method on
    the Keras model. We must supply the training data as well as the batch size and
    the number of epochs (iterations) for training. We must also pass the previously
    created `callback` model checkpoint so that we can save the model after each epoch:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以通过在Keras模型上调用`fit`方法来在本地开始训练。我们必须提供训练数据以及训练的批大小和epoch（迭代）数。我们还必须传递之前创建的`callback`模型检查点，这样我们就可以在每个epoch后保存模型：
- en: '[PRE6]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, we can use the trained model of the last epoch to compute the final
    score on the test set:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以使用最后一个epoch训练好的模型在测试集上计算最终得分：
- en: '[PRE7]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the preceding code, we can see that training a CNN on a compute instance
    in Azure Machine Learning is straightforward and similar to training a model on
    the local machine. The only difference is that we have to be sure that all the
    required libraries (and required versions) have been installed and that the data
    is available.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以看到在 Azure Machine Learning 的计算实例上训练 CNN 是直接且与在本地机器上训练模型类似的。唯一的区别是我们必须确保所有必需的库（及其所需版本）都已安装，并且数据是可用的。
- en: Generating more input data using augmentation
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用增强生成更多输入数据
- en: DL models usually have many millions of parameters to represent the model with
    the training set distribution. Hence, when dealing with DL, be it in custom vision
    using Cognitive Services, Azure Machine Learning Studio, or custom models in ML
    service workspaces, you should always implement data augmentation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: DL 模型通常有数百万个参数来表示训练集分布的模型。因此，在处理 DL 时，无论是使用认知服务进行自定义视觉、Azure Machine Learning
    Studio 或 ML 服务工作区中的自定义模型，都应该始终实现数据增强。
- en: Data augmentation is a way of creating more training data by slightly modifying
    the available data and providing the modified data to the ML algorithm. Depending
    on the use case, this could include mirroring, translating, scaling, or skewing
    images, as well as changing the brightness, luminosity, or color information of
    images. These modifications strongly improve the generalization of the model,
    such as enabling better scale, translation, rotation, and transformation invariance.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是一种通过稍微修改现有数据并提供修改后的数据给 ML 算法来创建更多训练数据的方法。根据用例的不同，这可能包括镜像、平移、缩放或倾斜图像，以及改变图像的亮度、亮度和颜色信息。这些修改可以极大地提高模型的泛化能力，例如，使模型能够更好地实现尺度、平移、旋转和变换的不变性。
- en: 'The benefit of using TensorFlow and Keras is that data augmentation is a built-in
    capability. First, we can create an `ImageDataGenerator` object, which stores
    all our modifications and can generate iterators through the augmented dataset.
    The data augmentation techniques for this generator can be configured when the
    generator is being initialized. However, we want to use the generator to simply
    iterate through the training images without augmentation and add augmentation
    once we have connected all the pieces. Let''s take a look:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 和 Keras 的好处是数据增强是一个内置功能。首先，我们可以创建一个 `ImageDataGenerator` 对象，该对象存储了所有我们的修改，并且可以通过增强数据集生成迭代器。此生成器的数据增强技术可以在初始化生成器时进行配置。然而，我们希望使用生成器简单地遍历训练图像而不进行增强，并在连接好所有组件后再添加增强。让我们看一下：
- en: 'Let''s implement an image data generator in Keras using the `ImageDataGenerator`
    object:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在 Keras 中使用 `ImageDataGenerator` 对象实现一个图像数据生成器：
- en: '[PRE8]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we can return a data iterator from the image data generator by passing
    the original training image data and labels to the generator. Before we sample
    images from the generator, we need to compute the training set statistics that
    will be required for further augmentations. Similar to the scikit-learn `BaseTransformer`
    interface, we need to call the `fit` method on the generator:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以通过将原始训练图像数据和标签传递给生成器来从图像数据生成器返回一个数据迭代器。在我们从生成器中采样图像之前，我们需要计算训练集统计信息，这些统计信息将用于进一步的增强。类似于
    scikit-learn 的 `BaseTransformer` 接口，我们需要在生成器上调用 `fit` 方法：
- en: '[PRE9]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we must create an iterator by using the `flow` method:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须使用 `flow` 方法创建一个迭代器：
- en: '[PRE10]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If instead of loading the images into NumPy arrays beforehand, we wanted to
    read individual images from a folder, we could use a different generator function
    to do so, as shown in the following snippet:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们不想事先将图像加载到 NumPy 数组中，而是想从文件夹中读取单个图像，我们可以使用不同的生成器函数来完成，如下面的代码片段所示：
- en: '[PRE11]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: However, in our example, the training images have been combined into a single
    file, so we don't need to load the image data ourselves.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们的例子中，训练图像已经被合并到一个单独的文件中，因此我们不需要自己加载图像数据。
- en: 'The iterator can now be used to loop through the data generator and yield new
    training samples with each iteration. To do so, we need to replace the `fit` function
    with the `fit_generator` function, which expects an iterator instead of a training
    dataset:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用迭代器来遍历数据生成器，并在每次迭代中产生新的训练样本。为此，我们需要用 `fit_generator` 函数替换 `fit` 函数，该函数期望一个迭代器而不是训练数据集：
- en: '[PRE12]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we can see, we can pass the same arguments for `epoch` and `callback` to
    the `fit_generator` function as we did to the `fit` function. The only difference
    is that now, we need to fix several steps per epoch so that the iterator yields
    new images. Once we have added augmentation methods to the generator, we could
    theoretically generate unlimited modifications of each training image per epoch.
    Hence, with this argument, we can define how many batches of data we wish to train
    each epoch with, which should roughly correspond to the number of training samples
    divided by the batch size.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们可以将相同的`epoch`和`callback`参数传递给`fit_generator`函数，就像我们传递给`fit`函数一样。唯一的区别是现在，我们需要在每个epoch中固定几个步骤，以便迭代器产生新的图像。一旦我们将增强方法添加到生成器中，理论上我们可以在每个epoch中为每个训练图像生成无限多的修改。因此，使用此参数，我们可以定义我们希望每个epoch训练多少批数据，这应该大致对应于训练样本数除以批大小。
- en: 'Finally, we can configure the data augmentation techniques. The default image
    data generator supports a variety of augmentations through different arguments:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以配置数据增强技术。默认的图像数据生成器通过不同的参数支持各种增强：
- en: Translation or shifts
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 翻译或平移
- en: Horizontal or vertical flips
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水平或垂直翻转
- en: Rotations
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旋转
- en: Brightness
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亮度
- en: Zoom
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放
- en: 'Let''s go back to the image data generator and activate data augmentation techniques.
    Here is an example generator that is often used for data augmentation in image
    processing:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到图像数据生成器并激活数据增强技术。以下是一个常用于图像处理数据增强的示例生成器：
- en: '[PRE13]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: By using this data generator, we can train the model with augmented image data
    and further improve the performance of the CNN. As we saw previously, this is
    a crucial and strongly recommended step in any DL training pipeline.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用此数据生成器，我们可以使用增强图像数据来训练模型，并进一步提高CNN的性能。正如我们之前所看到的，这是任何深度学习（DL）训练流程中的关键步骤，并且强烈推荐。
- en: Let's move all the code that we have developed so far into a file called `scripts/train.py`.
    We will use this file in the next section to schedule and run it on a GPU cluster.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将迄今为止开发的全部代码移动到一个名为`scripts/train.py`的文件中。我们将在下一节中使用此文件在GPU集群上安排和运行它。
- en: Training on a GPU cluster using Azure Machine Learning
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Azure机器学习在GPU集群上进行训练
- en: Now that we have a training script ready, verified that the script works, and
    added data augmentation, we can move this training script to a more performant
    execution environment. In DL, many operations, such as convolutions, pooling,
    and general tensor operators, can benefit from parallel execution. Therefore,
    we will execute the training script on a GPU cluster and track its status in the
    authoring environment.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好训练脚本，验证了脚本的工作，并添加了数据增强，我们可以将此训练脚本移动到更高效的执行环境中。在深度学习中，许多操作，如卷积、池化和通用张量运算符，可以从并行执行中受益。因此，我们将训练脚本在GPU集群上执行，并在创作环境中跟踪其状态。
- en: 'One benefit of using Azure Machine Learning is that we can set up and run everything
    in Python from the authoring environment – that is, the Jupyter notebook running
    on the Azure Machine Learning compute instance:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Azure机器学习的优点之一是我们可以从创作环境中设置和运行所有内容——即运行在Azure机器学习计算实例上的Jupyter笔记本：
- en: 'First, we must configure our Azure Machine Learning workspace, which is a single
    statement without arguments on the compute instance:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须配置我们的Azure机器学习工作区，这是一个在计算实例上不带参数的单个语句：
- en: '[PRE14]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we must load or create a GPU cluster with autoscaling for the training
    process:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须为训练过程加载或创建一个具有自动扩展功能的GPU集群：
- en: '[PRE15]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As shown in the preceding code snippet, creating a GPU cluster with autoscaling
    only requires a couple of lines of code within Jupyter with Azure Machine Learning.
    But how did we choose the VM size and the number of nodes for the GPU cluster?
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码片段所示，使用Azure机器学习创建具有自动扩展功能的GPU集群只需要在Jupyter中编写几行代码。但我们是如何选择虚拟机大小和GPU集群节点数量的呢？
- en: In general, you can decide between the NC, ND, and NV types from the N-series
    VMs in Azure. A later version number (for example, v2 or v3) usually means updated
    hardware, hence a newer CPU and GPU, and better memory. You can think of the different
    N-series versions in terms of applications (*NC*, where *C* means compute; *ND*,
    where *D* means deep learning; and *NV*, where *V* means video). The following
    table will help you compare the different N-series VM types and their GPU configurations.
    Most machines can be scaled up to four GPUs per VM.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您可以从 Azure 的 N 系列虚拟机中的 NC、ND 和 NV 类型中进行选择。较晚的版本号（例如，v2 或 v3）通常意味着更新的硬件，因此有更新的
    CPU 和 GPU，以及更好的内存。您可以将不同的 N 系列版本视为应用类型（*NC*，其中 *C* 代表计算；*ND*，其中 *D* 代表深度学习；*NV*，其中
    *V* 代表视频）。以下表格将帮助您比较不同的 N 系列虚拟机类型及其 GPU 配置。大多数机器可以扩展到每个虚拟机四个 GPU。
- en: 'The following table shows an Azure VM N-series comparison:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了 Azure VM N 系列的比较：
- en: '![Figure 10.8 – Azure VM N-series costs ](img/B17928_10_08.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.8 – Azure VM N 系列成本](img/B17928_10_08.jpg)'
- en: Figure 10.8 – Azure VM N-series costs
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – Azure VM N 系列成本
- en: The prices in the preceding table represent pay-as-you-go prices for Linux VMs
    in the West US 2 region for December 2021\. Please note that these prices may
    have changed by the time you are reading this, but it should give you an indication
    of the different options and configurations to choose from.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 上表中的价格代表 2021 年 12 月美国西部 2 区域 Linux VM 的按量付费价格。请注意，这些价格在你阅读此内容时可能已经发生变化，但它应该能给你一个不同选项和配置的选择指示。
- en: 'To get a better understanding of the costs and performance, we can look at
    a typical workload for training a ResNet50 model on the ImageNet dataset. The
    following table, provided by Nvidia, shows that it makes sense to choose the latest
    GPU models as their performance increase is much better and the costs are more
    efficient than the older GPU models:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解成本和性能，我们可以查看在 ImageNet 数据集上训练 ResNet50 模型的典型工作负载。以下由 Nvidia 提供的表格显示，选择最新的
    GPU 模型是有意义的，因为它们的性能提升更好，成本也更有效率，比旧款 GPU 模型更优。
- en: '![Figure 10.9 – GPU costs ](img/B17928_10_09.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.9 – GPU 成本](img/B17928_10_09.jpg)'
- en: Figure 10.9 – GPU costs
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – GPU 成本
- en: As shown in the preceding table, the performance increase that's visible in
    the lower training duration for the same task pays off and results in a much lower
    cost for the overall task.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如前表所示，对于相同任务的较短的训练时间所显示的性能提升是有回报的，并且导致整体任务的成本大大降低。
- en: Hence, the `STANDARD_NC6` model is a great starting point, from a pricing perspective,
    for experimenting with GPUs, CNNs, and DNNs in Azure. The only thing that we have
    to make sure of is that our model can fit into the available GPU memory of the
    VM. A common way to calculate this is to compute the number of parameters for
    the model, times 2 for storing gradients (times 1 when performing only inferencing),
    times the batch size, and times 4 for the single-precision size in bytes (or times
    2 for half-precision).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从定价角度来看，`STANDARD_NC6` 模型是开始在 Azure 上进行 GPU、CNN 和 DNN 实验的一个很好的起点。我们唯一需要确保的是我们的模型可以适应
    VM 可用的 GPU 内存。计算这个的一个常见方法是计算模型的参数数量，乘以 2 以存储梯度（仅进行推理时乘以 1），乘以批处理大小，再乘以 4 以字节为单位表示的单精度大小（或乘以
    2 以表示半精度）。
- en: In our example, the CNN architecture requires 1.6 MB to store the trainable
    parameters (weights and biases). To also store backpropagated losses for a batch
    size of 16, we would require around 51.2 MB (1.6 MB x 16 x 2) of GPU memory to
    perform the whole end-to-end training on a single GPU. This also fits easily in
    our 12 GB of GPU memory in the smallest NC instance.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，CNN 架构需要 1.6 MB 来存储可训练参数（权重和偏差）。为了存储批处理大小为 16 的反向传播损失，我们需要大约 51.2 MB（1.6
    MB x 16 x 2）的 GPU 内存来在单个 GPU 上执行整个端到端训练。这也很容易适应我们最小的 NC 实例中的 12 GB GPU 内存。
- en: Important Note
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: While these numbers seem small for our test case, you will often deal with larger
    models (with up to 100 million parameters) and larger image sizes. To put that
    into perspective, ResNet152, when trained on image dimensions of 224 x 224 x 3,
    has approximately 60 million parameters and a size of 240 MB. On the `STANDARD_NC6`
    instance, we could train, at most, at a batch size of 24, according to our equation.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些数字对于我们的测试案例来说似乎很小，但你经常会处理更大的模型（参数数量高达 1 亿）和更大的图像尺寸。为了更直观地说明这一点，ResNet152
    在 224 x 224 x 3 的图像尺寸上训练时，大约有 6000 万个参数和 240 MB 的大小。根据我们的公式，在 `STANDARD_NC6` 实例上，我们最多可以在批处理大小为
    24 的情况下进行训练。
- en: By adding more GPUs or nodes to the cluster, we must introduce a different framework
    to take advantage of the distributed setup. We will discuss this in more detail
    in [*Chapter 12*](B17928_12_ePub.xhtml#_idTextAnchor189), *Distributed Machine
    Learning on Azure*. However, we can add more nodes with autoscaling to the cluster
    so that multiple people can submit multiple jobs simultaneously. The number of
    maximum nodes can be computed as *simultaneous models/node * number of peak models
    to be trained simultaneously*. In our test scenario, we will go with a cluster
    size of `3` so that we can schedule a few models at the same time.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向集群添加更多的GPU或节点，我们必须引入一个不同的框架来利用分布式设置。我们将在[*第12章*](B17928_12_ePub.xhtml#_idTextAnchor189)，“Azure上的分布式机器学习”中更详细地讨论这个问题。然而，我们可以通过自动扩展添加更多的节点到集群，这样多个人可以同时提交多个作业。最大节点数可以计算为*每个节点的并发模型数*乘以同时要训练的峰值模型数。在我们的测试场景中，我们将选择`3`个节点的集群大小，这样我们就可以同时安排几个模型。
- en: 'Now that we have decided on a VM size and GPU configuration, we can continue
    with the training process. Next, we need to make sure that the cluster can access
    the training data. To do so, we will use the default datastore on the Azure Machine
    Learning workspace:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 既然我们已经决定了虚拟机的大小和GPU配置，我们就可以继续进行训练过程。接下来，我们需要确保集群可以访问训练数据。为此，我们将使用Azure机器学习工作区上的默认数据存储库：
- en: '[PRE16]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In the preceding code, we copied the training data from the local machine to
    the default datastore – the blob storage account. As we discussed in [*Chapter
    4*](B17928_04_ePub.xhtml#_idTextAnchor071), *Ingesting Data and Managing Datasets*,
    there are also other ways to upload your data to blob storage or another storage
    system.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们将训练数据从本地机器复制到了默认的数据存储库——blob存储账户。正如我们在[*第4章*](B17928_04_ePub.xhtml#_idTextAnchor071)，“数据摄取与管理数据集”中讨论的那样，还有其他方法可以将您的数据上传到blob存储或其他存储系统。
- en: 'Mounting blob storage to a machine, or even a cluster, is usually not a straightforward
    task. Yes, you could have a NAS and mount it as a network drive on every node
    in the cluster, but this is tedious to set up and scale. Using the Azure Machine
    Learning datastore API, we can simply request a reference to the datastore, which
    can be used to mount the correct folder on every machine that needs to access
    the data:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 将blob存储挂载到机器上，甚至是一个集群，通常不是一个简单的过程。是的，您可以在集群的每个节点上挂载一个NAS作为网络驱动器，但这设置和扩展起来都很繁琐。使用Azure机器学习数据存储API，我们可以简单地请求一个数据存储库的引用，这个引用可以用来在每个需要访问数据的机器上挂载正确的文件夹：
- en: '[PRE17]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The preceding command returns a `Datastore Mount` object, which doesn't look
    particularly powerful. However, if we pass this reference as a parameter to the
    training script, it can automatically mount the datastore and read the content
    from the datastore on each training compute in Azure Machine Learning. If you
    have ever played with mount points or `fstab`, you will understand that this one-liner
    can speed up your daily workflow.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令返回一个`Datastore Mount`对象，看起来并不特别强大。然而，如果我们把这个引用作为参数传递给训练脚本，它可以在Azure机器学习中的每个训练计算上自动挂载数据存储库并读取内容。如果您曾经玩过挂载点或`fstab`，您会理解这一行代码可以加快您的日常工作流程。
- en: 'Now, we can create an Azure Machine Learning configuration. Let''s create `ScriptRunConfiguration`
    so that we can schedule the training script on the cluster:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以创建一个Azure机器学习配置。让我们创建`ScriptRunConfiguration`，这样我们就可以在集群上安排训练脚本：
- en: '[PRE18]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To read the data from the specified default datastore, we need to parse the
    argument in the `train.py` script. Let''s go back to the script and replace the
    file-loading code with the following code block:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从指定的默认数据存储库读取数据，我们需要解析`train.py`脚本中的参数。让我们回到脚本，用以下代码块替换文件加载代码：
- en: '[PRE19]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This leaves us with scheduling and running the script on the GPU cluster. However,
    before doing so, we want to make sure that all the runs are tracked in the Azure
    Machine Learning service. Therefore, we must also add `Run` to the `train.py`
    file and reuse the Keras callback for Azure Machine Learning from [*Chapter 3*](B17928_03_ePub.xhtml#_idTextAnchor054),
    *Preparing the Azure Machine Learning Workspace*. Here is what the training script
    will look like:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这就剩下在GPU集群上安排和运行脚本了。然而，在这样做之前，我们想要确保所有运行都在Azure机器学习服务中被跟踪。因此，我们还需要在`train.py`文件中添加`Run`，并重用来自[*第3章*](B17928_03_ePub.xhtml#_idTextAnchor054)，“准备Azure机器学习工作区”的Keras回调。以下是训练脚本的样子：
- en: '[PRE20]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As we can see, we added the `Run` configuration and the Keras callback to track
    all the metrics during the epochs. We also collected the final test set metric
    and reported it to the Azure Machine Learning service. You can find the complete
    runnable example in the code provided with this book.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们添加了`Run`配置和Keras回调来跟踪整个训练过程中的所有指标。我们还收集了最终的测试集指标，并将其报告给Azure机器学习服务。您可以在本书提供的代码中找到完整的可运行示例。
- en: Improving your performance through transfer learning
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过转移学习提高您的性能
- en: In many cases, you won't have a dataset containing hundreds of millions of labeled
    training samples, and that's completely understandable. So, how can you still
    benefit from all the previous work and benchmarks? Shouldn't a feature extractor
    trained on recognizing animals also perform well on recognizing faces? The classifier
    would certainly be different, but the visual features that are extracted from
    the images should be similar.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，您可能没有包含数亿个标记训练样本的数据集，这是完全可以理解的。那么，您如何还能从所有之前的工作和基准测试中受益呢？难道在识别动物的特征提取器训练后，在识别面部时表现不佳吗？分类器当然会不同，但从图像中提取的视觉特征应该是相似的。
- en: 'This is the idea behind `faces` dataset, the `CoCo` dataset, and so on) and
    attach a custom classifier to the end of the model. Transfer learning means that
    we can transfer the features from a model from one task to another task: for example,
    from classification to object detection. It may be a bit confusing at first regarding
    whether we would want to reuse features for a different task. However, if a model
    has been taught to identify patterns of geographical shapes in images, this same
    feature extractor could certainly be reused for any image-related task in the
    same domain.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是`faces`数据集、`CoCo`数据集等背后的想法，并在模型的末端附加一个自定义分类器。转移学习意味着我们可以将一个模型从一项任务的特征转移到另一项任务：例如，从分类到目标检测。一开始可能会有些困惑，是否希望为不同的任务重用特征。然而，如果一个模型已经被训练来识别图像中的地理形状模式，这个相同的特征提取器当然可以用于同一领域中的任何与图像相关的任务。
- en: One useful property of transfer learning is that the initial learning task doesn't
    necessarily need to be a supervised ML task, so it is not necessary to have annotated
    training data to train the feature extractor. A popular unsupervised ML technique
    is called auto-encoders, where an ML model tries to generate a similar-looking
    output, given input, using a feature extractor and an upsampling network. By minimizing
    the error between the generated output and the input, the feature extractor learns
    to efficiently represent the input data in latent space. Auto-encoders are popular
    for pre-training network architectures before the pre-trained weights for the
    actual ML task are used.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习的一个有用特性是，初始学习任务不一定需要是一个监督式机器学习任务，因此不需要有标注的训练数据来训练特征提取器。一种流行的无监督机器学习技术称为自编码器，其中机器学习模型试图使用特征提取器和上采样网络，根据输入生成类似的外观输出。通过最小化生成的输出与输入之间的误差，特征提取器学会在潜在空间中高效地表示输入数据。自编码器在预训练网络架构之前，使用实际机器学习任务的预训练权重之前很受欢迎。
- en: We need to make sure that the pre-trained model was trained on a dataset in
    the same domain. Images of biological cells look very different from faces, and
    clouds look very different from buildings. In general, the ImageNet dataset covers
    a broad spectrum of photograph-style images for many standard visual features,
    such as buildings, cars, animals, and more. Therefore, it is a good choice to
    use a pre-trained model for many computer vision tasks.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要确保预训练模型是在同一领域的数据集上训练的。生物细胞图像与面部看起来非常不同，云与建筑物看起来也非常不同。一般来说，ImageNet数据集涵盖了广泛的照片风格图像，用于许多标准视觉特征，如建筑物、汽车、动物等。因此，对于许多计算机视觉任务，使用预训练模型是一个很好的选择。
- en: Transfer learning is not only tied to image data and modeling data for computer
    vision. Transfer learning has proven valuable in any domain where datasets are
    sufficiently similar, such as for human voices or written text. Hence, whenever
    you are implementing a DL model, do your research on what datasets could be used
    for transfer learning and to ultimately improve the model's performance.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习不仅与计算机视觉中的图像数据和建模数据相关。转移学习在数据集足够相似的所有领域都已被证明是有价值的，例如人类声音或书面文本。因此，无论何时您在实现深度学习模型时，都要研究可用于转移学习的数据集，以及最终提高模型性能。
- en: 'Let''s bring the theory into practice and dive into some examples. We saw a
    similar example earlier in this chapter, where we piped the output of the feature
    extractor to an SVM. In this section, we want to achieve something similar, but
    the result will be a single end-to-end model. Therefore, in this example, we will
    build a network architecture for the new model consisting of a pre-trained feature
    extractor and a newly initialized classification head:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将理论应用于实践，并深入研究一些示例。我们在本章前面看到了一个类似的例子，其中我们将特征提取器的输出管道化到一个SVM。在本节中，我们想要实现类似的效果，但结果将是一个单一端到端模型。因此，在这个例子中，我们将构建一个由预训练的特征提取器和新的分类器头部组成的新模型网络架构：
- en: 'First, we must define the number of output classes and the input shape and
    load the base model from Keras:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须定义输出类的数量、输入形状，并从Keras加载基本模型：
- en: '[PRE21]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the preceding code, most of the magic for pre-training happens thanks to
    Keras. First, we specified the image dataset that will be used to train this model
    using the `weights` argument, which will automatically initialize the model weights
    with the pre-trained `imagenet` weights. With the third argument, `include_top=False`,
    we told Keras to only load the feature extractor part of the model. Using the
    `pooling` argument, we also specified how the last pooling operation should be
    performed. In this case, we chose average pooling.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，预训练的大部分魔法都归功于Keras。首先，我们使用`weights`参数指定了将用于训练此模型的图像数据集，这将自动使用预训练的`imagenet`权重初始化模型权重。通过第三个参数`include_top=False`，我们告诉Keras只加载模型的特征提取部分。使用`pooling`参数，我们还指定了最后一个池化操作应该如何执行。在这种情况下，我们选择了平均池化。
- en: 'Next, we must freeze the layers of the model by setting their `trainable` property
    to `False`. To do so, we can simply loop over all the layers in the model:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须通过将它们的`trainable`属性设置为`False`来冻结模型的层。为此，我们可以简单地遍历模型中的所有层：
- en: '[PRE22]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we can attach any network architecture to the model that we want.
    In this case, we will attach the same classifier head that we used in the CNN
    network from the previous section. Finally, we must construct the final model
    class by using the new architecture and output as the classifier output layer:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以将任何网络架构附加到我们想要的模型上。在这种情况下，我们将附加与上一节中CNN网络中使用的相同分类器头部。最后，我们必须使用新的架构和输出作为分类器输出层来构建最终的模型类：
- en: '[PRE23]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: That's it! You have successfully built a new end-to-end model that combines
    a pre-trained ResNet50 feature extractor on ImageNet with your custom classifier.
    You can now use this Keras model and plug it into your preferred optimizer and
    send it off to the GPU cluster. The output of the training process will be a single
    model that can be managed and deployed as any other custom model.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！你已经成功构建了一个新的端到端模型，该模型结合了在ImageNet上预训练的ResNet50特征提取器以及你的自定义分类器。现在你可以使用这个Keras模型，将其插入你偏好的优化器中，并发送到GPU集群。训练过程的输出将是一个可以像任何其他自定义模型一样管理和部署的单个模型。
- en: Important Note
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You are not limited to always freezing all the layers of the original network.
    A common approach is to also unfreeze later layers in the network, decrease the
    learning rate by at least a factor of 10, and continue training. By repeating
    this procedure, we could even retrain (or fine-tune) all the layers of the network
    in a step-by-step approach with a decreasing learning rate.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 你不必总是冻结原始网络的所有层。一个常见的方法是同时解冻网络中的后续层，将学习率至少降低10倍，并继续训练。通过重复此过程，我们甚至可以以逐步降低学习率的方式重新训练（或微调）网络的所有层。
- en: Independently of your choice and use case, you should add transfer learning
    to your standard repertoire for training DL models. Treat it like other popular
    preprocessing and training techniques, such as data augmentation, which should
    always be used when you're training DL models.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 不论你的选择和使用案例如何，你应该将迁移学习添加到你的标准训练深度学习模型的方法库中。将其视为其他流行的预处理和训练技术，例如数据增强，这些技术应该在训练深度学习模型时始终使用。
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned when and how to use DL to train an ML model on Azure.
    We used both a compute instance and a GPU cluster from within the Azure Machine
    Learning service to train a model using Keras and TensorFlow.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了何时以及如何使用深度学习（DL）在Azure上训练机器学习（ML）模型。我们使用了Azure机器学习服务中的计算实例和GPU集群来使用Keras和TensorFlow训练模型。
- en: First, we found out that DL works very well on highly structured data with non-obvious
    relationships from the raw input data to the resulting prediction. Good examples
    include image classification, speech-to-text, and translation. We also saw that
    DL models are parametric models with a large number of parameters, so we often
    need a large amount of labeled or augmented input data. In contrast to traditional
    ML approaches, the extra parameters are used to train a fully end-to-end model,
    also including feature extraction from the raw input data.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们发现深度学习在具有非明显关系的结构化数据上工作得非常好，这些关系是从原始输入数据到最终预测结果。好的例子包括图像分类、语音转文本和翻译。我们还看到，深度学习模型是具有大量参数的参数模型，因此我们通常需要大量的标记或增强的输入数据。与传统机器学习方法相比，额外的参数用于训练一个完全端到端的模型，这还包括从原始输入数据中提取特征。
- en: Training a CNN using the Azure Machine Learning service is not difficult. We
    saw many approaches, from prototyping in Jupyter to augmenting the training data,
    to running the training on a GPU cluster with autoscaling. The difficult part
    in DL is preparing and providing enough high-quality training data, finding a
    descriptive error metric, and optimizing between costs and performance. We provided
    an overview of how to decide on the best VM and GPU size and configuration for
    your job, something that I recommend you do before starting your first GPU cluster.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Azure机器学习服务训练CNN并不困难。我们看到了许多方法，从在Jupyter中进行原型设计到增强训练数据，再到在具有自动扩展功能的GPU集群上运行训练。在深度学习中，困难的部分在于准备和提供足够的高质量训练数据，找到一个描述性的错误度量标准，以及在成本和性能之间进行优化。我们概述了如何为您的任务选择最佳的虚拟机和GPU大小及配置，我建议您在开始您的第一个GPU集群之前先做这件事。
- en: In the next chapter, we will go one step further and look into hyperparameter
    tuning and automated ML, a feature in the Azure Machine Learning service that
    lets you train and optimize stacked models automatically.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将进一步探讨超参数调整和自动机器学习，这是Azure机器学习服务中的一个功能，允许您自动训练和优化堆叠模型。
