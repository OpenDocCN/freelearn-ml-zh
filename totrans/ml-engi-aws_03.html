<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer115">
<h1 class="chapter-number" id="_idParaDest-58"><a id="_idTextAnchor060"/><a id="_idTextAnchor061"/>3</h1>
<h1 id="_idParaDest-59"><a id="_idTextAnchor062"/>Deep Learning Containers</h1>
<p>In <a href="B18638_02.xhtml#_idTextAnchor041"><em class="italic">Chapter 2</em></a>, <em class="italic">Deep Learning AMIs</em>, we used <strong class="bold">AWS Deep Learning AMIs</strong> (<strong class="bold">DLAMIs</strong>) to set up an environment inside an EC2 instance where we could train and evaluate a deep learning model. In this chapter, we will take a closer look at <strong class="bold">AWS Deep Learning Containers</strong> (<strong class="bold">DLCs</strong>), which can run consistently across multiple environments and services. In addition to this, we will discuss the similarities and differences between DLAMIs and DLCs.</p>
<p>The hands-on solutions in this chapter focus on the different ways we can use DLCs to solve several pain points when working on <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) requirements in the cloud. For example, container technologies such as <strong class="bold">Docker</strong> allow us to make the most of our running EC2 instances since we’ll be able to run different types of applications inside containers, without having to worry about whether their dependencies would conflict or not. In addition to this, we would have more options and solutions available when trying to manage and reduce costs. For one thing, if we were to use the container image support of <strong class="bold">AWS Lambda</strong> (a serverless compute service that lets us run our custom backend code) to deploy our deep learning model inside a serverless function, we would be able to significantly reduce the infrastructure costs associated with having an inference endpoint running 24/7. At the same time, with a serverless function, all we need to worry about is the custom code inside the function since AWS will take care of the infrastructure where this function would run.</p>
<p>In the scenario discussed in the <em class="italic">Understanding how AWS pricing works for EC2 instances</em> section of the previous chapter, we were able to reduce the cost of running a 24/7 inference endpoint to about <em class="italic">$69.12 per month</em> using an <strong class="source-inline">m6i.large</strong> instance. It is important to note that this value would more or less remain constant, even if this inference endpoint is not receiving any traffic. In other words, we might be paying <em class="italic">$69.12 per month</em> for a resource that could be either underutilized or unused. If we were to set up a staging environment that is configured the same as the production environment, this cost would double and it’s pretty much guaranteed that the staging environment resources would be severely underutilized. At this point, you might be wondering, <em class="italic">Is it possible for us to reduce this cost further?</em> The good news is that this is possible, so long as we can design a more optimal architecture using the right set of tools, services, and frameworks.</p>
<p>We will start the hands-on section of this chapter by training a <strong class="bold">PyTorch</strong> model inside a DLC. This model will be uploaded to a custom container image that will then be used to create an <strong class="bold">AWS Lambda</strong> function. After that, we will create an <strong class="bold">API Gateway</strong> HTTP API that accepts an HTTP request and triggers the AWS Lambda function with an event containing the input request data. The AWS Lambda function will then load the model we trained to perform ML predictions. </p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Getting started with AWS Deep Learning Containers</li>
<li>Essential prerequisites</li>
<li>Using AWS Deep Learning Containers to train an ML model</li>
<li>Serverless ML deployment with Lambda’s container image support</li>
</ul>
<p>While working on the hands-on solutions of this chapter, we will cover several <em class="italic">serverless</em> services such as AWS Lambda and Amazon API Gateway, which allow us to run applications without having to manage the infrastructure ourselves. At the same time, the cost of using these resources scales automatically, depending on the usage of these resources. In a typical setup, we may have an EC2 instance running 24/7 where we will be paying for the running resource, regardless of whether it is being used. With AWS Lambda, we only need to pay when the function code runs. If it only runs for a few seconds per month, then we may pay close to zero for that month!</p>
<p>With these points in mind, let’s begin this chapter with a quick introduction to how AWS DLCs work.</p>
<h1 id="_idParaDest-60"><a id="_idTextAnchor063"/>Technical requirements</h1>
<p>Before we start, we must have the following ready:</p>
<ul>
<li>A web browser (preferably Chrome or Firefox)</li>
<li>Access to the AWS account that was used in the first two chapters of this book</li>
<li>Access to the Cloud9 environment that you prepared in the <em class="italic">Creating your Cloud9 environment</em> and <em class="italic">Increasing the Cloud9 storage</em> sections of <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em></li>
</ul>
<p>The Jupyter notebooks, source code, and other files used for each chapter are available in this book’s GitHub repository at https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">It is recommended that you use an IAM user with limited permissions instead of the root account when running the examples in this book. We will discuss this, along with other security best practices, in detail in <a href="B18638_09.xhtml#_idTextAnchor187"><em class="italic">Chapter 9</em></a>, <em class="italic">Security, Governance, and Compliance Strategies</em>. If you are just starting using AWS, you may proceed with using the root account in the meantime.</p>
<h1 id="_idParaDest-61"><a id="_idTextAnchor064"/>Getting started with AWS Deep Learning Containers</h1>
<p>Containers<a id="_idIndexMarker219"/> allow developers, engineers, and system administrators to run processes, scripts, and<a id="_idIndexMarker220"/> applications inside consistent isolated environments. This consistency is guaranteed since these containers are launched from <a id="_idIndexMarker221"/>container images, similar to how EC2 instances are launched from <strong class="bold">Amazon Machine Images</strong> (<strong class="bold">AMIs</strong>). </p>
<p>It is important to note that we can run different isolated containers at the same time inside an instance. This allows engineering teams to make the most of the computing power available to the existing instances and run different types of processes and workloads, similar to what we have in the following diagram:</p>
<div>
<div class="IMG---Figure" id="_idContainer079">
<img alt="Figure 3.1 – Running multiple containers inside a single EC2 instance " height="511" src="image/B18638_03_001.jpg" width="1336"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – Running multiple containers inside a single EC2 instance</p>
<p>One of the <a id="_idIndexMarker222"/>most popular container management solutions available is <strong class="bold">Docker</strong>. It is an<a id="_idIndexMarker223"/> open source containerization platform that allows developers and engineers to easily build, run, and manage containers. It involves the usage of a <strong class="bold">Dockerfile</strong>, which<a id="_idIndexMarker224"/> is a text document containing instructions on how to build container images. These container images are then managed and stored inside container registries so that they can be used at a later time.</p>
<p class="callout-heading">Note</p>
<p class="callout">Docker images<a id="_idIndexMarker225"/> are used to create containers. Docker images are like ZIP files that package everything needed to run an application. When a Docker container is run from a container image (using the <strong class="source-inline">docker run</strong> command), the container acts like a virtual machine, with its environment isolated and separate from the server where the container is running. </p>
<p>Now that we have a better idea of how containers and container images work, let’s proceed by discussing what DLCs are and how these are used to speed up the training and deployment of ML models. One of the key benefits when using AWS DLCs is that most of the relevant ML packages, frameworks, and libraries are installed in the container images already. This means that ML engineers and data scientists no longer need to worry about installing and configuring the ML frameworks, libraries, and packages. This allows them to proceed with preparing the custom scripts used for training and deploying their deep learning models. </p>
<p>Since<a id="_idIndexMarker226"/> DLC<a id="_idIndexMarker227"/> images are simply prebuilt container images, these<a id="_idIndexMarker228"/> can be used in any<a id="_idIndexMarker229"/> AWS service<a id="_idIndexMarker230"/> where containers <a id="_idIndexMarker231"/>and container images can be used. These AWS services include <strong class="bold">Amazon EC2</strong>, <strong class="bold">Amazon Elastic Container Service</strong> (<strong class="bold">ECS</strong>), <strong class="bold">Amazon Elastic Kubernetes Service (EKS)</strong>, <strong class="bold">Amazon SageMaker</strong>, <strong class="bold">AWS CodeBuild</strong>, <strong class="bold">AWS Lambda</strong>, and<a id="_idIndexMarker232"/> more.</p>
<p>With these in mind, let’s proceed with training and deploying a deep learning model using AWS Deep Learning Containers!</p>
<h1 id="_idParaDest-62"><a id="_idTextAnchor065"/>Essential prerequisites</h1>
<p>In this section, we will ensure that the following prerequisites are ready before proceeding with the training steps:</p>
<ol>
<li>We will prepare a Cloud9 environment and ensure it has been set up so that we can train the model and build the custom container image.</li>
<li>We will prepare a training dataset that will be used when training the deep learning model.</li>
</ol>
<h2 id="_idParaDest-63"><a id="_idTextAnchor066"/>Preparing the Cloud9 environment</h2>
<p>In the<a id="_idIndexMarker233"/> first part of this chapter, we will run our Deep Learning Container inside an EC2 instance, similar to what’s shown in the following diagram:</p>
<div>
<div class="IMG---Figure" id="_idContainer080">
<img alt="Figure 3.2 – Running a Deep Learning Container inside an EC2 instance " height="537" src="image/B18638_03_002.jpg" width="1450"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.2 – Running a Deep Learning Container inside an EC2 instance</p>
<p>This <a id="_idIndexMarker234"/>container will serve as the environment where the ML model is trained using a script that utilizes the <strong class="bold">PyTorch</strong> framework. Even if PyTorch is not installed in the EC2 instance, the training script will still run successfully since it will be executed inside the container environment where PyTorch is preinstalled.</p>
<p class="callout-heading">Note</p>
<p class="callout">If you are wondering what PyTorch is, it is<a id="_idIndexMarker235"/> one of the most popular open source ML frameworks available. You may check out <a href="https://pytorch.org/">https://pytorch.org/</a> for more information.</p>
<p>In the next set of steps, we will make sure that our Cloud9 environment is ready:</p>
<ol>
<li value="1">Type <strong class="source-inline">cloud9</strong> in the search bar. Select <strong class="bold">Cloud9</strong> from the list of results:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer081">
<img alt="Figure 3.3 – Navigating to the Cloud9 console " height="665" src="image/B18638_03_003.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.3 – Navigating to the Cloud9 console</p>
<p class="list-inset">Here, we can see that the region is currently set to <strong class="bold">Oregon</strong> (<strong class="source-inline">us-west-2</strong>). Make sure that you change this to where you created the Cloud9 instance in <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>.</p>
<ol>
<li value="2">Open the Cloud9 environment you created in the <em class="italic">Creating your Cloud9 environment</em> section of <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>, by clicking the <strong class="bold">Open IDE</strong> button. If there are no existing environments in the list of<a id="_idIndexMarker236"/> created environments, make sure that you are in the same region (that is, <strong class="source-inline">us-west-2</strong>) where the Cloud9 environment was created in <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">If you skipped the first chapter, make sure that you complete the <em class="italic">Creating your Cloud9 environment</em> and <em class="italic">Increasing the Cloud9 storage</em> sections of that chapter before proceeding.</p>
<ol>
<li value="3">In the Terminal of the Cloud9 environment, run the following <strong class="source-inline">bash</strong> commands to create the <strong class="source-inline">ch03</strong> directory:<pre class="source-code"><strong class="bold">mkdir -p ch03</strong></pre><pre class="source-code"><strong class="bold">cd ch03</strong></pre></li>
</ol>
<p class="list-inset">We <a id="_idIndexMarker237"/>will use this directory as our current working directory for this chapter.</p>
<p>Now that we have our Cloud9 environment ready, let’s proceed with downloading the training dataset so that we can train our deep learning model.</p>
<h2 id="_idParaDest-64"><a id="_idTextAnchor067"/>Downloading the sample dataset</h2>
<p>The training dataset we will use<a id="_idIndexMarker238"/> in this chapter is the same dataset we used in <a href="B18638_02.xhtml#_idTextAnchor041"><em class="italic">Chapter 2</em></a>, <em class="italic">Deep Learning AMIs</em>. It has two columns that correspond to the continuous <em class="italic">x</em> and <em class="italic">y</em> variables. Later in this chapter, we will also generate a regression model using this dataset. The regression model is expected to accept an input <em class="italic">x</em> value and return a predicted <em class="italic">y</em> value.</p>
<p>In the next set of steps, we will download the training dataset into our Cloud9 environment: </p>
<ol>
<li value="1">Run the following command to create the <strong class="source-inline">data</strong> directory:<pre class="source-code">mkdir -p <strong class="bold">data</strong></pre></li>
<li>Next, let’s download the training data CSV file by using the <strong class="source-inline">wget</strong> command:<pre class="source-code">wget https://bit.ly/3h1KBx2 -O<strong class="bold"> data/training_data.csv</strong></pre></li>
<li>Use the <strong class="source-inline">head</strong> command to inspect what our training data looks like:<pre class="source-code">head <strong class="bold">data/training_data.csv</strong></pre></li>
</ol>
<p class="list-inset">This should give us rows of <em class="italic">(x,y) pairs</em>, similar to what is shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer082">
<img alt="Figure 3.4 – The first few rows of the training_data.csv file " height="400" src="image/B18638_03_004.jpg" width="1287"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.4 – The first few rows of the training_data.csv file</p>
<p class="list-inset">Since we<a id="_idIndexMarker239"/> started this section inside the <strong class="source-inline">ch03</strong> directory, it is important to note that the <strong class="source-inline">training_data.csv</strong> file should be inside the <strong class="source-inline">ch03/data</strong> directory.</p>
<p>Now that we have the prerequisites ready, we can proceed with the training step.</p>
<h1 id="_idParaDest-65"><a id="_idTextAnchor068"/>Using AWS Deep Learning Containers to train an ML model</h1>
<p>At this<a id="_idIndexMarker240"/> point, you might be wondering<a id="_idIndexMarker241"/> what makes a deep learning model different from other ML models. Deep learning models are networks of interconnected nodes that communicate with each other, similar to how networks of neurons communicate in a human brain. These models make use of multiple layers in the network, similar to what we have in the following diagram. Having more layers and more neurons per layer gives deep learning models the ability to process and learn complex non-linear patterns and relationships:</p>
<div>
<div class="IMG---Figure" id="_idContainer083">
<img alt="Figure 3.5 – Deep learning model " height="465" src="image/B18638_03_005.jpg" width="1060"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.5 – Deep learning model</p>
<p>Deep <a id="_idIndexMarker242"/>learning has several<a id="_idIndexMarker243"/> practical<a id="_idIndexMarker244"/> applications in <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>), <strong class="bold">computer vision</strong>, and <strong class="bold">fraud detection</strong>. In addition to these, here are some of its other <a id="_idIndexMarker245"/>applications and <a id="_idIndexMarker246"/>examples as well:</p>
<ul>
<li><strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>): These can be used to generate realistic examples from the original <a id="_idIndexMarker247"/>dataset, similar to what we had in the <em class="italic">Generating a synthetic dataset using a deep learning model</em> section of <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>.</li>
<li><strong class="bold">Deep Reinforcement Learning</strong>: This <a id="_idIndexMarker248"/>utilizes deep neural networks and reinforcement learning techniques to solve complex problems in industries such as robotics and gaming.</li>
</ul>
<p>These past couple of years, the training and deployment of deep learning models have been greatly <a id="_idIndexMarker249"/>simplified with deep <a id="_idIndexMarker250"/>learning frameworks<a id="_idIndexMarker251"/> such as <strong class="bold">PyTorch</strong>, <strong class="bold">TensorFlow</strong>, and <strong class="bold">MXNet</strong>. AWS DLCs speed things up further by providing container images that already come preinstalled with everything you need to run these ML frameworks. </p>
<p class="callout-heading">Note</p>
<p class="callout">You can view the list of available DLC images<a id="_idIndexMarker252"/> here: <a href="https://github.com/aws/deep-learning-containers/blob/master/available_images.md">https://github.com/aws/deep-learning-containers/blob/master/available_images.md</a>. Note that these container images are categorized by (1) the installed ML framework (<strong class="bold">PyTorch</strong>, <strong class="bold">TensorFlow</strong>, or <strong class="bold">MXNet</strong>), (2) the job type (<em class="italic">training</em> or <em class="italic">inference</em>), and (3) the installed Python version.</p>
<p>In the next <a id="_idIndexMarker253"/>set of steps, we will <a id="_idIndexMarker254"/>use the DLC image that’s been optimized to train PyTorch models:</p>
<ol>
<li value="1">Let’s download the <strong class="source-inline">train.py</strong> file by running the following command:<pre class="source-code">wget https://bit.ly/3KcsG3v -O <strong class="bold">train.py</strong></pre></li>
</ol>
<p class="list-inset">Before we proceed, let’s check the contents of the <strong class="source-inline">train.py</strong> file by opening it from the <strong class="source-inline">File</strong> tree:</p>
<div>
<div class="IMG---Figure" id="_idContainer084">
<img alt="Figure 3.6 – Opening the train.py file from the File tree " height="339" src="image/B18638_03_006.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.6 – Opening the train.py file from the File tree</p>
<p class="list-inset">We should see a script that makes use of the training data stored in the <strong class="source-inline">data</strong> directory to train a deep learning model. This model gets saved in the <strong class="source-inline">model</strong> directory after the training step has been completed:</p>
<div>
<div class="IMG---Figure" id="_idContainer085">
<img alt="Figure 3.7 – The main() function of the train.py script file " height="545" src="image/B18638_03_007.jpg" width="743"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.7 – The main() function of the train.py script file</p>
<p class="list-inset">Here, we <a id="_idIndexMarker255"/>can see that <a id="_idIndexMarker256"/>the <strong class="source-inline">main()</strong> function of our <strong class="source-inline">train.py</strong> script performs the following operations: </p>
<ul>
<li>(1) defines the model using the <strong class="source-inline">prepare_model()</strong> function </li>
<li>(2) loads the training data using the <strong class="source-inline">load_data()</strong> function</li>
<li>(3) performs the training step using the <strong class="source-inline">fit()</strong> method</li>
<li>(4) saves the model artifacts using the <strong class="source-inline">torch.save()</strong> method</li>
</ul>
<p class="list-inset">The last block of code in the preceding screenshot simply runs the <strong class="source-inline">main()</strong> function if <strong class="source-inline">train.py</strong> is being executed directly as a script.</p>
<p class="callout-heading">Note</p>
<p class="callout">You can find the complete <strong class="source-inline">train.py</strong> script here: <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/train.py">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/train.py</a>.</p>
<ol>
<li value="2">Next, create the <strong class="source-inline">model</strong> directory using the <strong class="source-inline">mkdir</strong> command:<pre class="source-code">mkdir -p <strong class="bold">model</strong></pre></li>
</ol>
<p class="list-inset">Later, we will see that the model output gets saved inside this directory.</p>
<ol>
<li value="3">Install <a id="_idIndexMarker257"/>the <strong class="source-inline">tree</strong> utility by<a id="_idIndexMarker258"/> running the following command:<pre class="source-code">sudo apt install <strong class="bold">tree</strong></pre></li>
<li>Let’s use the <strong class="source-inline">tree</strong> utility we just installed:<pre class="source-code"><strong class="bold">tree</strong></pre></li>
</ol>
<p class="list-inset">This should yield a tree-like structure, similar to what we have in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer086">
<img alt="Figure 3.8 – Results after using the tree command " height="386" src="image/B18638_03_008.jpg" width="1593"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.8 – Results after using the tree command</p>
<p class="list-inset">It is important to note that the <strong class="source-inline">train.py</strong> script is in the <strong class="source-inline">ch03</strong> directory, which is where the <strong class="source-inline">data</strong> and <strong class="source-inline">model</strong> directories are located as well.</p>
<ol>
<li value="5">Download the <strong class="source-inline">train.sh</strong> file using the <strong class="source-inline">wget</strong> command:<pre class="source-code">wget https://bit.ly/3Iz7zaV -O <strong class="bold">train.sh</strong></pre></li>
</ol>
<p class="list-inset">If we check the contents of the <strong class="source-inline">train.sh</strong> file, we should see the following lines:</p>
<pre class="list-inset1 source-code">aws ecr get-login-password --region <strong class="bold">us-west-2</strong> | docker login --username AWS --password-stdin 763104351884.dkr.ecr.<strong class="bold">us-west-2</strong>.amazonaws.com
TRAINING_IMAGE=763104351884.dkr.ecr.<strong class="bold">us-west-2</strong>.amazonaws.com/pytorch-training:1.8.1-cpu-py36-ubuntu18.04
docker run -it -v `pwd`:/env -w /env $TRAINING_IMAGE python train.py</pre>
<p class="list-inset">The <strong class="source-inline">train.sh</strong> script <a id="_idIndexMarker259"/>first authenticates<a id="_idIndexMarker260"/> with <strong class="bold">Amazon Elastic Container Registry</strong> (a fully managed Docker <a id="_idIndexMarker261"/>container registry where we can store our container images) so that we can successfully download the training container image. This container image has <em class="italic">PyTorch 1.8.1</em> and <em class="italic">Python 3.6</em> preinstalled already.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">The code in the <strong class="source-inline">train.sh</strong> script assumes that we will run the training experiment inside an EC2 instance (where the Cloud9 environment is running) in the <em class="italic">Oregon</em> (<strong class="source-inline">us-west-2</strong>) region. Make sure that you replace <strong class="source-inline">us-west-2</strong> with the appropriate region code. For more information on this topic, feel free to check out https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.xhtml.</p>
<p class="list-inset">The <strong class="source-inline">docker run</strong> command first downloads the specified container image and creates a running container process using that image. After that, the contents of the current working directory are “copied” to the container after the current working directory (<strong class="source-inline">ch03</strong>) is mounted to the container using the <strong class="source-inline">-v</strong> flag when running the <strong class="source-inline">docker run</strong> command. We then set the working directory to where our files were mounted (<strong class="source-inline">/env</strong>) inside the container using the <strong class="source-inline">-w</strong> flag. Once all the steps are complete, the <strong class="source-inline">train.py</strong> script is executed inside the environment of the running container. </p>
<p class="callout-heading">Note</p>
<p class="callout">Check out <a href="https://docs.docker.com/engine/reference/run/">https://docs.docker.com/engine/reference/run/</a> for more information on how to use the <strong class="source-inline">docker run</strong> command.</p>
<ol>
<li value="6">Now that<a id="_idIndexMarker262"/> we have a better<a id="_idIndexMarker263"/> idea of what will happen when we execute the <strong class="source-inline">train.sh</strong> file, let’s run it using the following commands:<pre class="source-code"><strong class="bold">chmod +x train.sh</strong></pre><pre class="source-code"><strong class="bold">./train.sh</strong></pre></li>
</ol>
<p class="list-inset">This should yield a set of logs, similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer087">
<img alt="Figure 3.9 – Logs generated while running the train.sh script " height="278" src="image/B18638_03_009.jpg" width="1208"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.9 – Logs generated while running the train.sh script</p>
<p class="list-inset">Here, the <strong class="source-inline">train.sh</strong> script ran a container that invoked the <strong class="source-inline">train.py</strong> (Python) script to train the deep learning model. In the preceding screenshot, we can see the logs that were generated by the <strong class="source-inline">train.py</strong> script as it iteratively updates the weights of the neural network to improve the quality of the output model (that is, reducing the loss per iteration so that we can minimize the error). It is important to note that this <strong class="source-inline">train.py</strong> script makes use of <strong class="bold">PyTorch</strong> to prepare and train a sample deep learning model using the data provided.</p>
<p class="list-inset">This is the reason why we’re using a deep learning container image that has <em class="italic">PyTorch 1.8.1</em> and <em class="italic">Python 3.6</em> preinstalled already.</p>
<p class="callout-heading">Note</p>
<p class="callout">This step may take 5 to 10 minutes to complete. Feel free to get a cup of coffee or tea while waiting!</p>
<ol>
<li value="7">After the training script has finished running, let’s check whether the <strong class="source-inline">model</strong> directory contains a <strong class="source-inline">model.pth</strong> file using the <strong class="source-inline">tree</strong> command:<pre class="source-code"><strong class="bold">tree</strong></pre></li>
</ol>
<p class="list-inset">This should <a id="_idIndexMarker264"/>yield a tree-like<a id="_idIndexMarker265"/> structure, similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer088">
<img alt="Figure 3.10 – Verifying whether the model was saved successfully " height="399" src="image/B18638_03_010.jpg" width="1579"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.10 – Verifying whether the model was saved successfully</p>
<p class="list-inset">This <strong class="source-inline">model.pth</strong> file contains the serialized model we have trained using the <strong class="source-inline">train.py</strong> script. This file was created using the <strong class="source-inline">torch.save()</strong> method after the model training step was completed. Feel free to check out <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.xhtml">https://pytorch.org/tutorials/beginner/saving_loading_models.xhtml</a> for more information.</p>
<p class="callout-heading">Note</p>
<p class="callout">The generated <strong class="source-inline">model.pth</strong> file allows us to use the parameters of the model to make predictions (after the model has been loaded from the file). For example, if our model makes use of an equation such as <em class="italic">ax^2 + bxy + cy^2 = 0</em>, the <em class="italic">a</em>, <em class="italic">b</em>, and <em class="italic">c</em> values are the model parameters. With this, if we have <em class="italic">x</em> (which is the independent variable), we can easily compute the value of <em class="italic">y</em>. That said, we can say that determining <em class="italic">a</em>, <em class="italic">b</em>, and <em class="italic">c</em> is the task of the training phase, and that determining <em class="italic">y</em> given <em class="italic">x</em> (and given <em class="italic">a</em>, <em class="italic">b</em>, and <em class="italic">c</em>) is the task of the inference phase. By loading the <strong class="source-inline">model.pth</strong> file, we can proceed with the inference phase and compute for the predicted value of <em class="italic">y</em> given an input <em class="italic">x</em> value.</p>
<p>Wasn’t that easy? With the<a id="_idIndexMarker266"/> training step <a id="_idIndexMarker267"/>complete, we will proceed with the deployment step in the next section.</p>
<h1 id="_idParaDest-66"><a id="_idTextAnchor069"/>Serverless ML deployment with Lambda’s container image support</h1>
<p>Now<a id="_idIndexMarker268"/> that we have the <strong class="source-inline">model.pth</strong> file, what do we do with it? The answer is simple: we will deploy this model in a serverless API using an <strong class="bold">AWS Lambda</strong> function<a id="_idIndexMarker269"/> and an <strong class="bold">Amazon API Gateway</strong> HTTP API, as <a id="_idIndexMarker270"/>shown in the following diagram: </p>
<div>
<div class="IMG---Figure" id="_idContainer089">
<img alt="Figure 3.11 – Serverless ML deployment with an API Gateway and AWS Lambda " height="263" src="image/B18638_03_011.jpg" width="1233"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.11 – Serverless ML deployment with an API Gateway and AWS Lambda</p>
<p>As we can see, the HTTP API should be able to accept <em class="italic">GET</em> requests from “clients” such as mobile apps and other web servers that interface with end users. These requests then get passed to the AWS Lambda function as input event data. The Lambda function then loads the model from the <strong class="source-inline">model.pth</strong> file and uses it to compute the predicted <em class="italic">y</em> value using the <em class="italic">x</em> value from the input event data.</p>
<h2 id="_idParaDest-67"><a id="_idTextAnchor070"/>Building the custom container image</h2>
<p>Our<a id="_idIndexMarker271"/> AWS Lambda function code needs to utilize <strong class="bold">PyTorch</strong> functions and utilities to load the model. To get this setup working properly, we will build a custom container image from an existing DLC image optimized for <strong class="bold">PyTorch</strong> inference requirements. This custom container image will be used for the environment where our AWS Lambda function code will run through AWS Lambda’s container image support.</p>
<p class="callout-heading">Note</p>
<p class="callout">For more information on <a id="_idIndexMarker272"/>AWS Lambda’s container image support, check out https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/.</p>
<p>It is important to note that a variety of DLC images are available for us to choose from. These images are categorized based on their job type (<em class="italic">training versus inference</em>), installed framework (<em class="italic">PyTorch versus TensorFlow versus MXNet versus other options</em>), and installed Python version (<em class="italic">3.8 versus 3.7 versus 3.6 versus other options</em>). Since we are planning to use a container where a <strong class="bold">PyTorch</strong> model can be loaded and used to perform predictions, we will be choosing a <strong class="bold">PyTorch</strong> DLC <em class="italic">optimized for inference</em> as the base image when building the custom Docker image.</p>
<p>The following steps focus on building a custom container image from an existing DLC image:</p>
<ol>
<li value="1">Make sure you are inside the <strong class="source-inline">ch03</strong> directory by running the <strong class="source-inline">pwd</strong> command in the Terminal.</li>
<li>Next, run the following commands to download <strong class="source-inline">dlclambda.zip</strong> and extract its contents inside the <strong class="source-inline">ch03</strong> directory:<pre class="source-code">wget https://bit.ly/3pt5mGN -O<strong class="bold"> dlclambda.zip</strong></pre><pre class="source-code">unzip <strong class="bold">dlclambda.zip</strong></pre></li>
</ol>
<p class="list-inset">This ZIP file contains the files and scripts needed to build the custom container image.</p>
<ol>
<li value="3">Use the <strong class="source-inline">tree</strong> command to see what the <strong class="source-inline">ch03</strong> directory looks like:<pre class="source-code"><strong class="bold">tree</strong></pre></li>
</ol>
<p class="list-inset">This should yield a tree-like structure, similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer090">
<img alt="Figure 3.12 – Results after running the tree command " height="708" src="image/B18638_03_012.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.12 – Results after running the tree command</p>
<p class="list-inset">Here, several<a id="_idIndexMarker273"/> new files have been extracted from the <strong class="source-inline">dlclambda.zip</strong> file:</p>
<ul>
<li><strong class="source-inline">Dockerfile</strong></li>
<li><strong class="source-inline">app/app.py </strong></li>
<li><strong class="source-inline">build.sh</strong> </li>
<li><strong class="source-inline">download-rie.sh </strong></li>
<li><strong class="source-inline">invoke.sh </strong></li>
<li><strong class="source-inline">run.sh </strong></li>
</ul>
<p class="list-inset">We will discuss each of these files in detail as we go through the steps in this chapter.</p>
<ol>
<li value="4">In the File tree, locate and open the <strong class="source-inline">app.py</strong> file located inside the <strong class="source-inline">ch03/app</strong> directory:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer091">
<img alt="Figure 3.13 – app.py Lambda handler implementation " height="362" src="image/B18638_03_013.jpg" width="731"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.13 – app.py Lambda handler implementation</p>
<p class="list-inset">This file<a id="_idIndexMarker274"/> contains the AWS Lambda handler implementation code, which (1) loads the model, (2) extracts the input <em class="italic">x</em> value from the event data, (3) computes for the predicted <em class="italic">y</em> value using the model, and (4) returns the output <em class="italic">y</em> value as a string.</p>
<p class="list-inset">In the <em class="italic">Completing and testing the serverless API setup</em> section near the end of this chapter, we will set up an HTTP API that accepts a value for <strong class="source-inline">x</strong> via the URL query string (for example, <strong class="source-inline">https://&lt;URL&gt;/predict?x=42</strong>). Once the request comes in, Lambda will call a handler function that contains the code to handle the incoming request. It will load the deep learning model and use it to predict the value of <strong class="source-inline">y</strong> using the value of <em class="italic">x</em>.</p>
<p class="callout-heading">Note</p>
<p class="callout">You can find the complete <strong class="source-inline">app/app.py</strong> file here: <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/app/app.p">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/app/app.py</a>.</p>
<ol>
<li value="5">Copy the <strong class="source-inline">model.pth</strong> file from the <strong class="source-inline">model</strong> directory into the <strong class="source-inline">app/model</strong> directory using the <strong class="source-inline">cp</strong> command:<pre class="source-code"><strong class="bold">cp model/model.pth app/model/model.pth</strong></pre></li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">Make sure that you only load ML models from trusted sources. Inside <strong class="source-inline">app/app.py</strong>, we are loading the model using <strong class="source-inline">torch.load()</strong>, which can be exploited by attackers with a model containing a malicious payload. Attackers can easily prepare a model (with a malicious payload) that, when loaded, would give the attacker access to your server or resource running the ML scripts (for example, through a <strong class="bold">reverse shell</strong>). For more information on this topic, you may check the author’s talk on how to hack and secure ML environments and systems: <a href="https://speakerdeck.com/arvslat/pycon-apac-2022-hacking-and-securing-machine-learning-environments-and-systems?slide=8">https://speakerdeck.com/arvslat/pycon-apac-2022-hacking-and-securing-machine-learning-environments-and-systems?slide=8</a>.</p>
<ol>
<li value="6">Next, let’s <a id="_idIndexMarker275"/>make the <strong class="source-inline">build.sh</strong>, <strong class="source-inline">download-rie.sh</strong>, <strong class="source-inline">invoke.sh</strong>, and <strong class="source-inline">run.sh</strong> script files executable using the <strong class="source-inline">chmod</strong> command:<pre class="source-code"><strong class="bold">chmod +x *.sh</strong></pre></li>
<li>Before running the <strong class="source-inline">build.sh</strong> command, let’s check the script’s contents using the <strong class="source-inline">cat</strong> command:<pre class="source-code">cat <strong class="bold">build.sh</strong></pre></li>
</ol>
<p class="list-inset">This should yield a single line of code, similar to what we have in the following code block:</p>
<pre class="list-inset1 source-code"><strong class="bold">docker build</strong> -t dlclambda .</pre>
<p class="list-inset">The <strong class="source-inline">docker build</strong> command builds a Docker container image using the instructions specified in the Dockerfile in the current directory. <em class="italic">What does this mean?</em> This means that we are building a container image using the relevant files in the directory and we’re using the instructions in the Dockerfile to install the necessary packages as well. This process is similar to preparing the <em class="italic">DNA</em> of a container, which can be used to create new containers with an environment configured with the desired set of tools and packages.</p>
<p class="list-inset">Since we passed <strong class="source-inline">dlclambda</strong> as the argument to the <strong class="source-inline">-t</strong> flag, our custom container image will have the <strong class="source-inline">dlclambda:latest</strong> name and tag after the build process completes. Note that we can replace the latest tag with a specific version number (for example, <strong class="source-inline">dlclambda:3</strong>), but we will stick with using the <strong class="source-inline">latest</strong> tag for now.</p>
<p class="callout-heading">Note</p>
<p class="callout">For more information on <a id="_idIndexMarker276"/>the <strong class="source-inline">docker build</strong> command, feel free to check out https://docs.docker.com/engine/reference/commandline/build/.</p>
<ol>
<li value="8">We must<a id="_idIndexMarker277"/> check the contents of the Dockerfile as well. What happens when we build the container image using this Dockerfile?<ol><li>The following DLC image is used as the base image for the two stages of the build: <strong class="source-inline">https://763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:1.8.1-cpu-py36-ubuntu18.04</strong>. It is important to note that this Dockerfile makes use of <strong class="bold">multi-stage builds</strong> to <a id="_idIndexMarker278"/>ensure that the final container does not contain the unused artifacts and files from the previous build stages. </li>
<li>Next, the <strong class="bold">Lambda Runtime Interface Client</strong> is installed. This allows any custom container image to be compatible for use with AWS Lambda.</li>
<li>The <strong class="source-inline">/function</strong> directory is created. The contents of the <strong class="source-inline">app/</strong> directory (inside the <strong class="source-inline">ch03</strong> directory of the Cloud9 environment) are then copied to the <strong class="source-inline">/function</strong> directory inside the container.</li>
<li><strong class="source-inline">ENTRYPOINT</strong> is set to <strong class="source-inline">/opt/conda/bin/python -m awslambdaric</strong>. <strong class="source-inline">CMD</strong> is then set to <strong class="source-inline">app.handler</strong>. The <strong class="source-inline">ENTRYPOINT</strong> and <strong class="source-inline">CMD</strong> instructions<a id="_idIndexMarker279"/> define which command is executed when the container starts to run.</li>
</ol></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">A <strong class="bold">multi-stage build</strong> is<a id="_idIndexMarker280"/> a process that helps significantly reduce the size of the Docker container image by having multiple <strong class="source-inline">FROM</strong> instructions within a single Dockerfile. Each of these <strong class="source-inline">FROM</strong> instructions corresponds to a new build stage where artifacts and files from previous stages can be copied. With a multi-stage build, the last build stage produces the final image (which ideally does not include the unused files from the previous build stages).</p>
<p class="list-inset">The expected final output would be a container image that can be used to launch a container, similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer092">
<img alt="Figure 3.14 – Lambda Runtime Interface Client " height="529" src="image/B18638_03_014.jpg" width="1266"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.14 – Lambda Runtime Interface Client</p>
<p class="list-inset">If this <a id="_idIndexMarker281"/>container is launched without any additional parameters, the following command will execute: </p>
<pre class="list-inset1 source-code">/opt/conda/bin/python -m <strong class="bold">awslambdaric</strong> <strong class="bold">app.handler</strong></pre>
<p class="list-inset">This will run the <strong class="bold">Runtime Interface Client</strong> and use the <strong class="source-inline">handler()</strong> function of our <strong class="source-inline">app.py</strong> file to process AWS Lambda events. This <strong class="source-inline">handler()</strong> function will then use the deep learning model we trained in the <em class="italic">Using AWS Deep Learning Containers to train an ML model</em> section to make predictions.</p>
<p class="callout-heading">Note</p>
<p class="callout">You can find the Dockerfile here: <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/Dockerfile">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/Dockerfile</a>. </p>
<p class="list-inset">Before running the <strong class="source-inline">build.sh</strong> script, make sure that you replace all instances of <strong class="source-inline">us-west-2</strong> in the Dockerfile with the appropriate region code.</p>
<ol>
<li value="9">Now, let’s run the <strong class="source-inline">build.sh</strong> script:<pre class="source-code"><strong class="bold">./build.sh</strong></pre></li>
<li>Finally, we need to check whether the size of the custom container image exceeds 10 GB using the <strong class="source-inline">docker images</strong> command:<pre class="source-code"><strong class="bold">docker images | grep dlclambda</strong></pre></li>
</ol>
<p class="list-inset">We should see that the container image size of <strong class="source-inline">dlclambda</strong> is <strong class="source-inline">4.61GB</strong>. It is important<a id="_idIndexMarker282"/> to note that there is a 10 GB limit when using container images for Lambda functions. The image size of our custom container image needs to be below 10 GB if we want these to be used in AWS Lambda.</p>
<p>At this point, our custom container image is ready. The next step is to test the container image locally before using it to create an AWS Lambda function.</p>
<h2 id="_idParaDest-68"><a id="_idTextAnchor071"/>Testing the container image</h2>
<p>We can test the <a id="_idIndexMarker283"/>container image locally using the <strong class="bold">Lambda Runtime Interface Emulator</strong>. This <a id="_idIndexMarker284"/>will help us check whether our container image will run properly when it is deployed to AWS Lambda later.</p>
<p>In the next couple of steps, we will download and use the Lambda Runtime Interface Emulator to check our container image:</p>
<ol>
<li value="1">Use the <strong class="source-inline">cat</strong> command to check the contents of <strong class="source-inline">download-rie.sh</strong>:<pre class="source-code">cat <strong class="bold">download-rie.sh</strong></pre></li>
</ol>
<p class="list-inset">This should print the following block of code as output in the Terminal:</p>
<pre class="list-inset1 source-code">mkdir -p ~/.aws-lambda-rie &amp;&amp; curl -Lo ~/.aws-lambda-rie/aws-lambda-rie \
https://github.com/aws/aws-lambda-runtime-interface-emulator/releases/latest/download/aws-lambda-rie \
&amp;&amp; chmod +x ~/.aws-lambda-rie/aws-lambda-rie</pre>
<p class="list-inset">The <strong class="source-inline">download-rie.sh</strong> script simply downloads the Lambda Runtime Interface Emulator binary and makes it executable using the <strong class="source-inline">chmod</strong> command.</p>
<ol>
<li value="2">Next, run the <strong class="source-inline">download-rie.sh</strong> script:<pre class="source-code">sudo <strong class="bold">./download-rie.sh</strong></pre></li>
<li>Use the <strong class="source-inline">cat</strong> command <a id="_idIndexMarker285"/>to check the contents of <strong class="source-inline">run.sh</strong>:<pre class="source-code">cat <strong class="bold">run.sh</strong></pre></li>
</ol>
<p class="list-inset">We should see a <strong class="source-inline">docker run</strong> command with several parameter values, similar to what we have in the following code block:</p>
<pre class="list-inset1 source-code"><strong class="bold">docker run</strong> -v ~/.aws-lambda-rie:/aws-lambda -p 9000:8080 <strong class="bold">--entrypoint /aws-lambda/aws-lambda-rie</strong> dlclambda:latest /opt/conda/bin/python -m awslambdaric app.handler</pre>
<p class="list-inset">Let’s quickly check the parameter values that were passed to each of the flags:</p>
<ul>
<li><strong class="source-inline">-v</strong>: <strong class="source-inline">~/.aws-lambda-rie</strong> is a directory outside of the running Docker container to be mounted to <strong class="source-inline">/aws-lambda</strong> (which is inside the container).</li>
<li><strong class="source-inline">-p</strong>: This binds port <strong class="source-inline">8080</strong> of the container to port <strong class="source-inline">9000</strong> of the instance.</li>
<li><strong class="source-inline">--entrypoint</strong>: This will override the default <strong class="source-inline">ENTRYPOINT</strong> command that gets executed when the container starts.</li>
<li><strong class="source-inline">[IMAGE]</strong>: <strong class="source-inline">dlclambda:latest.</strong></li>
<li><strong class="source-inline">[COMMAND]</strong> <strong class="source-inline">[ARG…]</strong>: <strong class="source-inline">/opt/conda/bin/python -m awslambdaric app.handler.</strong></li>
</ul>
<p class="list-inset">This <strong class="source-inline">docker run</strong> command overrides the default <strong class="source-inline">ENTRYPOINT</strong> command and uses<a id="_idIndexMarker286"/> the <strong class="bold">Lambda Interface Emulator</strong> binary, <strong class="source-inline">aws-lambda-rie</strong>, instead of using the <strong class="source-inline">--entrypoint</strong> flag. This will then start a local endpoint at <strong class="source-inline">http://localhost:9000/2015-03-31/functions/function/invocations</strong>.</p>
<p class="callout-heading">Note</p>
<p class="callout">For more information on <a id="_idIndexMarker287"/>the <strong class="source-inline">docker run</strong> command, feel free to check out <a href="https://docs.docker.com/engine/reference/commandline/run/">https://docs.docker.com/engine/reference/commandline/run/</a>.</p>
<ol>
<li value="4">Now, let’s<a id="_idIndexMarker288"/> invoke the <strong class="source-inline">run.sh</strong> script:<pre class="source-code"><strong class="bold">./run.sh</strong></pre></li>
<li>Create a new Terminal tab by clicking the plus (<strong class="bold">+</strong>) button, as shown in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer093">
<img alt="Figure 3.15 – Creating a new Terminal tab " height="358" src="image/B18638_03_015.jpg" width="770"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.15 – Creating a new Terminal tab</p>
<p class="list-inset">Note that the <strong class="source-inline">run.sh</strong> script should be kept running while we are opening a <strong class="bold">New Terminal</strong> tab.</p>
<ol>
<li value="6">In the <strong class="bold">New Terminal</strong> tab, run the following commands before executing the <strong class="source-inline">invoke.sh</strong> script:<pre class="source-code"><strong class="bold">cd ch03</strong></pre><pre class="source-code"><strong class="bold">cat invoke.sh</strong></pre></li>
</ol>
<p class="list-inset">This should show us what is inside the <strong class="source-inline">invoke.sh</strong> script file. It should contain a one-liner script, similar to what we have in the following block of code:</p>
<pre class="list-inset1 source-code">curl -X<strong class="bold">POST</strong> "<strong class="bold">http://localhost:9000/2015-03-31/functions/function/invocations</strong>" -d '{"queryStringParameters":{"x":<strong class="bold">42</strong>}}'</pre>
<p class="list-inset">This script simply makes use of the <strong class="source-inline">curl</strong> command to send a sample <strong class="source-inline">POST</strong> request containing the <strong class="source-inline">x</strong> input value to the local endpoint that was started by the <strong class="source-inline">run.sh</strong> script earlier. </p>
<ol>
<li value="7">Now, let’s run the <strong class="source-inline">invoke.sh</strong> script:<pre class="source-code"><strong class="bold">./invoke.sh</strong></pre></li>
</ol>
<p class="list-inset">This should yield a value close to <strong class="source-inline">"42.4586"</strong>. Feel free to change the input <strong class="source-inline">x</strong> value in the <strong class="source-inline">invoke.sh</strong> script to see how the output value changes as well.</p>
<ol>
<li value="8">Navigate back<a id="_idIndexMarker289"/> to the first tab and press <em class="italic">Ctrl</em> + <em class="italic">C</em> to stop the running <strong class="source-inline">run.sh</strong> script.</li>
</ol>
<p>Given that we were able to successfully invoke the <strong class="source-inline">app.py</strong> Lambda function handler inside the custom container image using the <strong class="bold">Lambda Runtime Interface Emulator</strong>, we can now proceed with pushing our container image to Amazon ECR and using it to create an AWS Lambda function. </p>
<h2 id="_idParaDest-69"><a id="_idTextAnchor072"/>Pushing the container image to Amazon ECR</h2>
<p><strong class="bold">Amazon Elastic Container Registry</strong> (<strong class="bold">ECR</strong>) is a<a id="_idIndexMarker290"/> container registry service that allows us to store<a id="_idIndexMarker291"/> and manage Docker container images. In this section, we will create an ECR repository and then push our custom container image to this ECR repository.</p>
<p>Let’s start by creating an ECR repository:</p>
<ol>
<li value="1">In the <a id="_idIndexMarker292"/>top right-hand corner of the Cloud9 environment, locate and click the circle beside the <strong class="bold">Share</strong> button, as shown in the following screenshot. Select <strong class="bold">Go To Dashboard</strong> from the list of options:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer094">
<img alt="Figure 3.16 – Navigating to the Cloud9 console " height="463" src="image/B18638_03_016.jpg" width="1602"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.16 – Navigating to the Cloud9 console</p>
<p class="list-inset">This should open the Cloud9 console, where we can find all the created Cloud9 environments.</p>
<ol>
<li value="2">Type <strong class="source-inline">registry</strong> in the search bar. Select <strong class="bold">Elastic Container Registry</strong> from the list of results.</li>
<li>Locate and click the <strong class="bold">Create repository</strong> button in the top right-hand corner of the ECR console page.</li>
<li>On the <strong class="bold">Create repository</strong> form, specify the <strong class="bold">Repository name</strong> field value (for example, <strong class="source-inline">dlclambda</strong>): </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer095">
<img alt="Figure 3.17 – Creating an ECR repository " height="629" src="image/B18638_03_017.jpg" width="869"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.17 – Creating an ECR repository</p>
<p class="list-inset">Optionally, you <a id="_idIndexMarker293"/>can enable <strong class="bold">Tag immutability</strong>, similar to what is shown in the preceding screenshot. This will help ensure that we do not accidentally overwrite existing container image tags.</p>
<ol>
<li value="5">Scroll down to the bottom of the page and then click <strong class="bold">Create Repository</strong>.</li>
<li>We should see a success notification, along with the <strong class="bold">View push commands</strong> button, similar to what we have in the following screenshot: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer096">
<img alt="Figure 3.18 – View push commands " height="173" src="image/B18638_03_018.jpg" width="1079"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.18 – View push commands</p>
<p class="list-inset">Click the <strong class="bold">View push commands</strong> button to open the <strong class="bold">Push commands for &lt;ECR repository name&gt;</strong> popup window.</p>
<ol>
<li value="7">Locate the <strong class="source-inline">bash</strong> command inside the gray box under <em class="italic">Step 1</em>. Copy the command to the clipboard by clicking the box button highlighted in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer097">
<img alt="Figure 3.19 – Push commands " height="742" src="image/B18638_03_019.jpg" width="836"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.19 – Push commands</p>
<p class="list-inset">This <a id="_idIndexMarker294"/>command will be used to authenticate the Docker client in our Cloud9 environment to Amazon ECR. This will give us permission to push and pull container images to Amazon ECR.</p>
<ol>
<li value="8">Navigate<a id="_idIndexMarker295"/> back to the <strong class="bold">Browser</strong> tab with the Cloud9 environment. In the Terminal, paste and run the copied <strong class="source-inline">bash</strong> command:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer098">
<img alt="Figure 3.20 – Running the client authentication command " height="322" src="image/B18638_03_020.jpg" width="904"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.20 – Running the client authentication command</p>
<p class="list-inset">We should get a <strong class="bold">Login Succeeded</strong> message. Without this step, we wouldn’t be able to push and pull container images from Amazon ECR.</p>
<ol>
<li value="9">Navigate back to the browser tab with the ECR push commands and copy the command under <em class="italic">Step 3</em>, as highlighted in the following screenshot:<em class="italic"> </em></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer099">
<img alt="Figure 3.21 – Copying the docker tag command " height="745" src="image/B18638_03_021.jpg" width="1235"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.21 – Copying the docker tag command</p>
<p class="list-inset">This time, we<a id="_idIndexMarker296"/> will be copying the <strong class="source-inline">docker tag</strong> command from the <strong class="bold">Push commands</strong> window to the clipboard. The <strong class="source-inline">docker tag</strong> command is used to create and map named references to Docker images.</p>
<p class="callout-heading">Note</p>
<p class="callout">The <strong class="source-inline">docker tag</strong> command is used to specify and add metadata (such as the name and the version) to a container image. A container image repository stores different versions of a specific image, and the <strong class="source-inline">docker tag</strong> command helps the repository identify which version of the image will be updated (or uploaded) when the <strong class="source-inline">docker push</strong> command is used. For <a id="_idIndexMarker297"/>more information, feel free to check out https://docs.docker.com/engine/reference/commandline/tag/.</p>
<ol>
<li value="10">Back in the <a id="_idIndexMarker298"/>browser tab that contains the Cloud9 environment, paste the copied <strong class="source-inline">docker tag</strong> command in the Terminal window. Locate the <strong class="source-inline">latest</strong> tag value at the end of the command and replace it with <strong class="source-inline">1</strong> instead: <pre class="source-code">docker tag dlclambda:latest <strong class="bold">&lt;ACCOUNT ID&gt;</strong>.dkr.ecr.us-west-2.amazonaws.com/dlclambda:<strong class="bold">latest</strong></pre></li>
</ol>
<p class="list-inset">The command should be similar to what we have in the following code block after the <strong class="source-inline">latest</strong> tag has been replaced with <strong class="source-inline">1</strong>:</p>
<pre class="list-inset1 source-code">docker tag dlclambda:latest <strong class="bold">&lt;ACCOUNT ID&gt;</strong>.dkr.ecr.us-west-2.amazonaws.com/dlclambda:<strong class="bold">1</strong></pre>
<p class="list-inset">Make sure that the <strong class="source-inline">&lt;ACCOUNT ID&gt;</strong> value is correctly set to the account ID of the AWS account you are using. The <strong class="source-inline">docker tag</strong> command that you copied from the <strong class="bold">Push commands</strong> window should already have the <strong class="source-inline">&lt;ACCOUNT ID&gt;</strong> value set correctly.</p>
<ol>
<li value="11">Use the <strong class="source-inline">docker images</strong> command to quickly check the container images in our Cloud9 environment:<pre class="source-code"><strong class="bold">docker images</strong></pre></li>
</ol>
<p class="list-inset">This should return all the container images, including the <strong class="source-inline">dlclambda</strong> container images, as shown in the following screenshot: </p>
<div>
<div class="IMG---Figure" id="_idContainer100">
<img alt="Figure 3.22 – Running the docker images command " height="66" src="image/B18638_03_022.jpg" width="988"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.22 – Running the docker images command</p>
<p class="list-inset">It is important to note that both container image tags shown in the preceding screenshot have the same image ID. This means that they point to the same image, even if they have different names and tags.</p>
<ol>
<li value="12">Push the <a id="_idIndexMarker299"/>container image to the Amazon ECR repository using the <strong class="source-inline">docker push</strong> command:<pre class="source-code"><strong class="bold">docker push &lt;ACCOUNT ID&gt;.dkr.ecr.us-west-2.amazonaws.com/dlclambda:1</strong></pre></li>
</ol>
<p class="list-inset">Make sure that you replace the value of <strong class="source-inline">&lt;ACCOUNT ID&gt;</strong> with the account ID of the AWS account you are using. You can get the value for <strong class="source-inline">&lt;ACCOUNT ID&gt;</strong> by checking the numerical value before <strong class="source-inline">.dkr.ecr.us-west-2.amazonaws.com/dlclambda</strong> after running the <strong class="source-inline">docker images</strong> command in the previous step.</p>
<p class="callout-heading">Note</p>
<p class="callout">Note that the image tag value is a <strong class="source-inline">1</strong> (one) instead of the letter <em class="italic">l</em> after the container image name and the colon.</p>
<ol>
<li value="13">Navigate back to the browser tab that contains the ECR push commands and click the <strong class="bold">Close</strong> button.</li>
<li>Locate and click the name of the ECR repository we created (that is, <strong class="source-inline">dlclambda</strong>) under the list of <strong class="bold">Private repositories</strong>:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer101">
<img alt="Figure 3.23 – Private repositories " height="278" src="image/B18638_03_023.jpg" width="1074"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.23 – Private repositories</p>
<p class="list-inset">This should redirect us to the details page, where we can see the different image tags, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer102">
<img alt="Figure 3.24 – Repository details page " height="272" src="image/B18638_03_024.jpg" width="1124"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.24 – Repository details page</p>
<p class="list-inset">Once our <a id="_idIndexMarker300"/>container image with the specified image tag has been reflected in the corresponding Amazon ECR repository details page, we can use it to create AWS Lambda functions using Lambda’s container image support.</p>
<p>Now that our custom container image has been pushed to <strong class="bold">Amazon ECR</strong>, we can prepare and configure the serverless API setup!</p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor073"/>Running ML predictions on AWS Lambda</h2>
<p><strong class="bold">AWS Lambda</strong> is a<a id="_idIndexMarker301"/> serverless<a id="_idIndexMarker302"/> compute service that allows developers and engineers to run event-driven code without having to provision or manage infrastructure. Lambda functions can be invoked by resources from other AWS services such <a id="_idIndexMarker303"/>as <strong class="bold">API Gateway</strong> (a fully managed service for configuring and managing APIs), <strong class="bold">Amazon S3</strong> (an<a id="_idIndexMarker304"/> object storage service where we can upload and download files), <strong class="bold">Amazon SQS</strong> (a fully managed message queuing service), and more. These<a id="_idIndexMarker305"/> functions are executed inside isolated runtime environments that have a defined max execution time and max memory limits, similar to what we have in the following diagram:</p>
<div>
<div class="IMG---Figure" id="_idContainer103">
<img alt="Figure 3.25 – AWS Lambda isolated runtime environment " height="442" src="image/B18638_03_025.jpg" width="1053"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.25 – AWS Lambda isolated runtime environment</p>
<p>There are<a id="_idIndexMarker306"/> two ways to deploy Lambda function code and its dependencies: </p>
<ul>
<li>Using a container image as the deployment package.</li>
<li>Using a <strong class="source-inline">.zip</strong> file as the deployment package </li>
</ul>
<p>When using a container image as the deployment package, the custom Lambda function code can use what is installed and configured inside the container image. That said, if we were to use the custom container image that was built from AWS DLC, we would be able to use the installed ML framework (that is, <strong class="bold">PyTorch</strong>) in our function code and run ML predictions inside an AWS Lambda execution environment.</p>
<p>Now that we have a better understanding of how AWS Lambda’s container image support works, let’s proceed with creating our AWS Lambda function:</p>
<ol>
<li value="1">Type <strong class="source-inline">lambda</strong> in the search bar. Select <strong class="bold">Lambda</strong> from the list of results to navigate to the AWS Lambda console.</li>
<li>Locate and click the <strong class="bold">Create function</strong> button found at the top-right of the page.</li>
<li>On the <strong class="bold">Create function</strong> page, choose <strong class="bold">Container image</strong> from the list of options available, as shown in the following screenshot. Under <strong class="bold">Basic information</strong>, specify a <strong class="bold">Function name</strong> value (for example, <strong class="source-inline">dlclambda</strong>):</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer104">
<img alt="Figure 3.26 – Using the container image support of AWS Lambda " height="887" src="image/B18638_03_026.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.26 – Using the container image support of AWS Lambda</p>
<p class="list-inset">Selecting the <strong class="bold">Container image</strong> option means that we will use a custom container image as the deployment package. This deployment package is expected to contain the Lambda code, along with its dependencies.</p>
<ol>
<li value="4">Under <strong class="bold">Container image URI</strong>, click the <strong class="bold">Browse Images</strong> button. This will open a<a id="_idIndexMarker307"/> popup window, similar to the following: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer105">
<img alt="Figure 3.27 – Selecting the container image " height="440" src="image/B18638_03_027.jpg" width="950"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.27 – Selecting the container image</p>
<p class="list-inset">Under <strong class="bold">Amazon ECR image repository</strong>, select the container image we have pushed to Amazon ECR (<strong class="source-inline">dlclambda:1</strong>).</p>
<ol>
<li value="5">Click the <strong class="bold">Select image</strong> button so that the <strong class="source-inline">dlclambda</strong> container image will be used for the deployment package of our Lambda function.</li>
<li>After <a id="_idIndexMarker308"/>that, click <strong class="bold">Create function</strong>.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">This step may take 3 to 5 minutes to complete. Feel free to get a cup of coffee or tea while waiting!</p>
<ol>
<li value="7">Navigate to the <strong class="bold">Configuration &gt; General configuration</strong> tab and click <strong class="bold">Edit</strong>:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer106">
<img alt="Figure 3.28 – Editing the general configuration " height="514" src="image/B18638_03_028.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.28 – Editing the general configuration</p>
<p class="list-inset">Here, we can see that the AWS Lambda function is configured with a default max memory limit of 128 MB and a timeout of 3 seconds. An error is raised if the Lambda function exceeds one or more of the configured limits during execution.</p>
<ol>
<li value="8">Next, update the <strong class="bold">Memory</strong> field value to <strong class="source-inline">10240</strong> MB since we’re expecting our <strong class="bold">AWS Lambda</strong> function to use a significant amount of memory while performing the inference task. Update the <strong class="bold">Timeout</strong> value to <strong class="source-inline">1</strong> min and <strong class="source-inline">0</strong> seconds as well since the inference step may take longer than the default value of 3 seconds:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer107">
<img alt="Figure 3.29 – Modifying the memory and timeout settings " height="737" src="image/B18638_03_029.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.29 – Modifying the memory and timeout settings</p>
<p class="list-inset">Note that<a id="_idIndexMarker309"/> increasing the memory and timeout limits here will influence the compute power and total running time available for the Lambda function, as well as the overall cost of running predictions using the service. For now, let’s focus on getting the <strong class="bold">AWS Lambda</strong> function to work using these current configuration values for <strong class="bold">Memory</strong> and <strong class="bold">Timeout</strong>. Once we can get the initial setup running, we can play with different combinations of configuration values to manage the performance and cost of our setup. </p>
<p class="callout-heading">Note</p>
<p class="callout">We can use the <strong class="bold">AWS Compute Optimizer</strong> to help <a id="_idIndexMarker310"/>us optimize the overall performance and cost of AWS Lambda functions. For more information on this topic, check out <a href="https://aws.amazon.com/blogs/compute/optimizing-aws-lambda-cost-and-performance-using-aws-compute-optimizer/">https://aws.amazon.com/blogs/compute/optimizing-aws-lambda-cost-and-performance-using-aws-compute-optimizer/</a>.</p>
<ol>
<li value="9">Click the <strong class="bold">Save</strong> button afterward. We should see a notification similar to <strong class="bold">Updating the function &lt;function name&gt;</strong> while the changes are being applied.</li>
<li>Navigate to the <strong class="bold">Test</strong> tab.</li>
<li>Under <strong class="bold">Test event</strong>, specify the <strong class="bold">Name</strong> field value (for example, <strong class="source-inline">test</strong>):</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer108">
<img alt="Figure 3.30 – Configuring the test event " height="1001" src="image/B18638_03_030.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.30 – Configuring the test event</p>
<p class="list-inset">Make sure<a id="_idIndexMarker311"/> that you specify the following test event value inside the code editor, similar to what is shown in the preceding screenshot:</p>
<pre class="list-inset1 source-code">{
  "queryStringParameters": {
    "x": 42
  }
}</pre>
<p class="list-inset">This test event value gets passed to the <strong class="source-inline">event</strong> (first) parameter of the AWS Lambda <strong class="source-inline">handler()</strong> function when a test execution is performed.</p>
<ol>
<li value="12">Click <strong class="bold">Save</strong>.</li>
<li>Now, let’s test our setup by clicking the <strong class="bold">Test</strong> button:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer109">
<img alt="Figure 3.31 – Successful execution result " height="858" src="image/B18638_03_031.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.31 – Successful execution result</p>
<p class="list-inset">After a few seconds, we should see that the execution results succeeded, similar to what we have in the preceding screenshot.</p>
<ol>
<li value="14">In the <strong class="bold">Test event</strong> editor, change the value of <strong class="source-inline">x</strong> to <strong class="source-inline">41</strong> and then click the <strong class="bold">Test</strong> button <a id="_idIndexMarker312"/>again. This time, you will notice that it’s significantly faster and returns a value (that is, <strong class="source-inline">41.481697</strong>) almost right away.</li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">During an AWS Lambda function’s first invocation, it may take a few seconds for its function code to be downloaded and for its execution environment to be prepared. This phenomenon is commonly referred to as a <em class="italic">cold start</em>. When it is invoked a second time (within the same minute, for example), the <a id="_idIndexMarker313"/>Lambda function runs immediately without the delay associated with the cold start. For example, a Lambda function may take around 30 to 40 seconds for its first invocation to complete. After that, all succeeding requests would take a second or less. The Lambda function completes its execution significantly faster since the execution environment that was prepared during the first invocation is frozen and reused for succeeding invocations. If the AWS Lambda function is not invoked after some time (for example, around 10 to 30 minutes of inactivity), the execution environment is deleted and a new one needs to be prepared again the next time the function gets invoked. There are different ways to manage this and ensure that the AWS Lambda function performs consistently without experiencing the effects of a cold start. One of the strategies is to<a id="_idIndexMarker314"/> utilize <strong class="bold">Provisioned Concurrency</strong>, which helps ensure predictable function start times. Check out <a href="https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/">https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/</a> for more information on this topic.</p>
<p>With our AWS Lambda function ready to perform ML predictions, we can proceed with creating the serverless HTTP API that will trigger our Lambda function.</p>
<h2 id="_idParaDest-71"><a id="_idTextAnchor074"/>Completing and testing the serverless API setup</h2>
<p>The AWS <a id="_idIndexMarker315"/>Lambda function we created needs to be triggered by an <a id="_idIndexMarker316"/>event source. One of the possible event sources is an API Gateway HTTP API configured to receive an HTTP request. After receiving the request, the HTTP API will pass the request data to the AWS Lambda function as an event. Once the Lambda function receives the event, it will use the deep learning model to perform inference, and then return the predicted output value to the HTTP API. After that, the HTTP API will return the HTTP response to the requesting resource.</p>
<p>There are different ways to create an API Gateway HTTP API. In the next couple of steps, we will create this HTTP API directly from the AWS Lambda console:</p>
<ol>
<li value="1">Locate the <strong class="bold">Function overview</strong> pane and click <strong class="bold">Add trigger</strong>:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer110">
<img alt="Figure 3.32 – Add trigger " height="332" src="image/B18638_03_032.jpg" width="1045"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.32 – Add trigger</p>
<p class="list-inset">The <strong class="bold">Add trigger</strong> button should be on the left-hand side of the <strong class="bold">Function overview</strong> pane, as shown in the preceding screenshot. </p>
<ol>
<li value="2">Add a<a id="_idIndexMarker317"/> new AWS <a id="_idIndexMarker318"/>Lambda trigger using the following trigger configuration: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer111">
<img alt="Figure 3.33 – Trigger configuration " height="771" src="image/B18638_03_033.jpg" width="915"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.33 – Trigger configuration</p>
<p class="list-inset">Here’s the trigger configuration that we have:</p>
<ul>
<li><strong class="bold">Select a trigger</strong>: <strong class="bold">API Gateway</strong></li>
<li><strong class="bold">Create a new API or use an existing one</strong>: <strong class="bold">Create an API</strong></li>
<li><strong class="bold">API type</strong>: <strong class="bold">HTTP API</strong></li>
<li><strong class="bold">Security</strong>: <strong class="bold">Open</strong></li>
</ul>
<p class="list-inset">This will create and configure an HTTP API that accepts a request and sends the request data as an event to the AWS Lambda function.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">Note that this configuration needs to be secured once we have configured our setup for production use. For more information on this topic, check out <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/security.xhtml">https://docs.aws.amazon.com/apigateway/latest/developerguide/security.xhtml</a>.</p>
<ol>
<li value="3">Once<a id="_idIndexMarker319"/> you have finished configuring the new trigger, click <a id="_idIndexMarker320"/>the <strong class="bold">Add</strong> button.</li>
<li>Locate the API Gateway trigger we just created under the <strong class="bold">Triggers</strong> pane. Click the <strong class="bold">API Gateway </strong>link (for example, <strong class="bold">dlclambda-API</strong>) which should open a new tab. Under <strong class="bold">Develop</strong> (in the sidebar), click <strong class="bold">Integrations</strong>. Under Routes for <strong class="bold">dlclambda-API</strong>, click <strong class="bold">ANY</strong>. Click <strong class="bold">Manage Integration</strong> and then click <strong class="bold">Edit</strong> (located in the<strong class="bold"> Integration Details</strong> pane). In the <strong class="bold">Edit Integration</strong> page, update the value of <strong class="bold">Payload format version</strong> (under <strong class="bold">Advanced Settings</strong>) to <strong class="bold">2.0 </strong>similar to what we have in <em class="italic">Figure 3.34</em>. Click <strong class="bold">Save</strong> afterwards.</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer112">
<img alt="Figure 3.34 – Updating the Payload format version " height="858" src="image/B18638_03_034.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.34 – Updating the Payload format version</p>
<p class="list-inset">After updating the <strong class="bold">Payload format version</strong>, navigate back to our <strong class="bold">AWS Lambda browser</strong> tab and then click the API endpoint link (which should open a new tab). Since we did not specify an <strong class="source-inline">x</strong> value in the URL, the Lambda function will use <strong class="source-inline">0</strong> as the default <strong class="source-inline">x</strong> value when performing a test inference. </p>
<p class="callout-heading">Note</p>
<p class="callout">You may want to trigger an exception instead if there is no <strong class="source-inline">x</strong> value specified when a request is sent to the API Gateway endpoint. Feel free to change this behavior by modifying <em class="italic">line 44</em> of <strong class="source-inline">app.py</strong>: <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/app/app.py">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter03/app/app.py</a>.</p>
<ol>
<li value="5">Append <strong class="source-inline">?x=42</strong> to the end of the browser URL, similar to what we have in the following URL string:<pre class="source-code">https://&lt;API ID&gt;.execute-api.us-west-2.amazonaws.com/default/dlclambda<strong class="bold">?x=42</strong></pre></li>
</ol>
<p class="list-inset">Make sure that you press the <strong class="bold">Enter</strong> key to invoke a Lambda function execution with <strong class="source-inline">42</strong> as the input <strong class="source-inline">x</strong> value: </p>
<div>
<div class="IMG---Figure" id="_idContainer113">
<img alt="Figure 3.35 – Testing the API endpoint " height="79" src="image/B18638_03_035.jpg" width="667"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.35 – Testing the API endpoint</p>
<p class="list-inset">This should return a value close to <strong class="source-inline">42.4586</strong>, as shown in the preceding screenshot. Feel free to test different values for <strong class="source-inline">x</strong> to see how the predicted <em class="italic">y</em> value changes.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">Make sure that you delete the AWS Lambda and API Gateway resources once you are done configuring and testing the API setup.</p>
<p>At this point, we<a id="_idIndexMarker321"/> should be proud of ourselves as we were able to successfully <a id="_idIndexMarker322"/>deploy our deep learning model in a serverless API using <strong class="bold">AWS Lambda</strong> and <strong class="bold">Amazon API Gateway</strong>! Before the release of AWS Lambda’s container image support, it was tricky to set up and maintain serverless ML inference APIs using the same tech stack we used in this chapter. Now that we have this initial setup working, it should be easier to prepare and configure similar serverless ML-powered APIs. Note that we also have the option to create a Lambda function URL to generate a unique URL endpoint for the Lambda function. </p>
<div>
<div class="IMG---Figure" id="_idContainer114">
<img alt="Figure 3.36 – Cost of running the serverless API versus an API running inside an EC2 instance " height="480" src="image/B18638_03_036.jpg" width="1141"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.36 – Cost of running the serverless API versus an API running inside an EC2 instance</p>
<p>Before we<a id="_idIndexMarker323"/> end this chapter, let’s quickly check what the costs would<a id="_idIndexMarker324"/> look like if we were to use <strong class="bold">AWS Lambda</strong> and <strong class="bold">API Gateway</strong> for the ML inference endpoint. As shown in the preceding diagram, the expected cost of running this serverless API depends on the traffic passing through it. This means that the cost would be minimal if no traffic is passing through the API. Once more traffic passes through this HTTP API endpoint, the cost would gradually increase as well. Comparing this to the chart on the right, the expected cost will be the same, regardless of whether there’s traffic passing through the HTTP API that was deployed inside an EC2 instance. </p>
<p>Choosing the architecture and setup to use for your API depends on a variety of factors. We will not discuss this topic in detail, so feel free to check out the resources available here: <a href="https://aws.amazon.com/lambda/resources/">https://aws.amazon.com/lambda/resources/</a>.</p>
<h1 id="_idParaDest-72"><a id="_idTextAnchor075"/>Summary</h1>
<p>In this chapter, we were able to take a closer look at <strong class="bold">AWS Deep Learning Containers</strong> (<strong class="bold">DLCs</strong>). Similar to <strong class="bold">AWS Deep Learning AMIs</strong> (<strong class="bold">DLAMIs</strong>), AWS DLCs already have the relevant ML frameworks, libraries, and packages installed. This significantly speeds up the process of building and deploying deep learning models. At the same time, container environments are guaranteed to be consistent since these are run from pre-built container images.</p>
<p>One of the key differences between DLAMIs and DLCs is that multiple AWS DLCs can run inside a single EC2 instance.  These containers can also be used in other AWS services that support containers. These services include <strong class="bold">AWS Lambda</strong>, <strong class="bold">Amazon ECS</strong>, <strong class="bold">Amazon EKS</strong>, and <strong class="bold">Amazon EC2</strong>, to name a few.</p>
<p>In this chapter, we were able to train a deep learning model using a DLC. We then deployed this model to an AWS Lambda function through Lambda’s container image support. After that, we tested the Lambda function to see whether it’s able to successfully load the deep learning model to perform predictions. To trigger this Lambda function from an HTTP endpoint, we created an API Gateway HTTP API.</p>
<p>In the next chapter, we will focus on <strong class="bold">serverless data management</strong> and use a variety of services to set up and configure a data warehouse and a data lake. We will be working with the following AWS services, capabilities, and features: <strong class="bold">Redshift Serverless</strong>, <strong class="bold">AWS Lake Formation</strong>, <strong class="bold">AWS Glue</strong>, and <strong class="bold">Amazon Athena</strong>.</p>
<h1 id="_idParaDest-73"><a id="_idTextAnchor076"/>Further reading</h1>
<p>For more information on the topics covered in this chapter, feel free to check out the following resources:</p>
<ul>
<li><em class="italic">What are Deep Learning Containers?</em> (<a href="https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/what-is-dlc.xhtml">https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/what-is-dlc.xhtml</a>)</li>
<li><em class="italic">Security in Amazon API Gateway</em> (https://docs.aws.amazon.com/apigateway/latest/developerguide/security.xhtml)</li>
<li><em class="italic">New for AWS Lambda – Container Image Support</em> (https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/)</li>
<li><em class="italic">Issues to Avoid When Implementing Serverless Architecture with AWS Lambda</em> (<a href="https://aws.amazon.com/blogs/architecture/mistakes-to-avoid-when-implementing-serverless-architecture-with-lambda/">https://aws.amazon.com/blogs/architecture/mistakes-to-avoid-when-implementing-serverless-architecture-with-lambda/)</a></li>
</ul>
</div>
</div>


<div id="sbo-rt-content"><div>
<div class="Basic-Graphics-Frame" id="_idContainer116">
</div>
</div>
<div class="Content" id="_idContainer117">
<h1 id="_idParaDest-74"><a id="_idTextAnchor077"/>Part 2:Solving Data Engineering and Analysis Requirements</h1>
<p>In this section, readers will learn how to perform data engineering using a variety of solutions and services on AWS.</p>
<p>This section comprises the following chapters:</p>
<ul>
<li><a href="B18638_04.xhtml#_idTextAnchor079"><em class="italic">Chapter 4</em></a>, <em class="italic">Serverless Data Management on AWS</em></li>
<li><a href="B18638_05.xhtml#_idTextAnchor105"><em class="italic">Chapter 5</em></a>, <em class="italic">Pragmatic Data Processing and Analysis</em></li>
</ul>
</div>
<div>
<div id="_idContainer118">
</div>
</div>
</div>
</body></html>