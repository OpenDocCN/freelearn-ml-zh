["```py\nint main(int argc, char* argv[])\n{\n    // Variable declarations and initializations\n\n    // Iterate until the user presses the Esc key\n    while(true)\n    {\n        // Initialize the output image before each iteration\n        outputImage = Scalar(0,0,0);\n\n        // Capture the current frame\n        cap >> frame;\n\n        // Check if 'frame' is empty\n        if(frame.empty())\n            break;\n\n        // Resize the frame\n        resize(frame, frame, Size(), scalingFactor, scalingFactor, INTER_AREA);\n        // Convert to HSV colorspace\n        cvtColor(frame, hsvImage, COLOR_BGR2HSV);\n\n        // Define the range of \"blue\" color in HSV colorspace\n        Scalar lowerLimit = Scalar(60,100,100);\n        Scalar upperLimit = Scalar(180,255,255);\n\n        // Threshold the HSV image to get only blue color\n        inRange(hsvImage, lowerLimit, upperLimit, mask);\n\n        // Compute bitwise-AND of input image and mask\n        bitwise_and(frame, frame, outputImage, mask=mask);\n\n        // Run median filter on the output to smoothen it\n        medianBlur(outputImage, outputImage, 5);\n\n        // Display the input and output image\n        imshow(\"Input\", frame);\n        imshow(\"Output\", outputImage);\n\n        // Get the keyboard input and check if it's 'Esc'\n        // 30 -> wait for 30 ms\n        // 27 -> ASCII value of 'ESC' key\n        ch = waitKey(30);\n        if (ch == 27) {\n            break;\n        }\n    }\n\n    return 1;\n}\n```", "```py\nMat image;\nPoint originPoint;\nRect selectedRect;\nbool selectRegion = false;\nint trackingFlag = 0;\n\n// Function to track the mouse events\nvoid onMouse(int event, int x, int y, int, void*)\n{\n    if(selectRegion)\n    {\n        selectedRect.x = MIN(x, originPoint.x);\n        selectedRect.y = MIN(y, originPoint.y);\n        selectedRect.width = std::abs(x - originPoint.x);\n        selectedRect.height = std::abs(y - originPoint.y);\n\n        selectedRect &= Rect(0, 0, image.cols, image.rows);\n    }\n\n    switch(event)\n    {\n        case CV_EVENT_LBUTTONDOWN:\n            originPoint = Point(x,y);\n            selectedRect = Rect(x,y,0,0);\n            selectRegion = true;\n            break;\n\n        case CV_EVENT_LBUTTONUP:\n            selectRegion = false;\n            if( selectedRect.width > 0 && selectedRect.height > 0 )\n            {\n                trackingFlag = -1;\n            }\n            break;\n    }\n}\n```", "```py\nint main(int argc, char* argv[])\n{\n    // Variable declaration and initialization\n\n    // Iterate until the user presses the Esc key\n    while(true)\n    {\n// Capture the current frame\n        cap >> frame;\n\n        // Check if 'frame' is empty\n        if(frame.empty())\n            break;\n\n        // Resize the frame\n        resize(frame, frame, Size(), scalingFactor, scalingFactor, INTER_AREA);\n\n        // Clone the input frame\n        frame.copyTo(image);\n\n        // Convert to HSV colorspace\n        cvtColor(image, hsvImage, COLOR_BGR2HSV);\n```", "```py\n        if(trackingFlag)\n        {\n            // Check for all the values in 'hsvimage' that are within the specified range\n            // and put the result in 'mask'\n            inRange(hsvImage, Scalar(0, minSaturation, minValue), Scalar(180, 256, maxValue), mask);\n\n            // Mix the specified channels\n            int channels[] = {0, 0};\nhueImage.create(hsvImage.size(), hsvImage.depth());\n            mixChannels(&hsvImage, 1, &hueImage, 1, channels, 1);\n\n            if(trackingFlag < 0)\n            {\n            // Create images based on selected regions of interest\n                Mat roi(hueImage, selectedRect), maskroi(mask, selectedRect);\n\n                // Compute the histogram and normalize it\ncalcHist(&roi, 1, 0, maskroi, hist, 1, &histSize, &histRanges);\n                normalize(hist, hist, 0, 255, CV_MINMAX);\n\n                trackingRect = selectedRect;\n                trackingFlag = 1;\n            }\n```", "```py\n            // Compute the histogram backprojection\n            calcBackProject(&hueImage, 1, 0, hist, backproj, &histRanges);\n            backproj &= mask;\n            RotatedRect rotatedTrackingRect = CamShift(backproj, trackingRect, TermCriteria(CV_TERMCRIT_EPS | CV_TERMCRIT_ITER, 10, 1));\n\n            // Check if the area of trackingRect is too small\n            if(trackingRect.area() <= 1)\n            {\n                // Use an offset value to make sure the trackingRect has a minimum size\n                int cols = backproj.cols, rows = backproj.rows;\n                int offset = MIN(rows, cols) + 1;\n                trackingRect = Rect(trackingRect.x - offset, trackingRect.y - offset, trackingRect.x + offset, trackingRect.y + offset) & Rect(0, 0, cols, rows);\n            }\n```", "```py\n            // Draw the ellipse on top of the image\n            ellipse(image, rotatedTrackingRect, Scalar(0,255,0), 3, CV_AA);\n        }\n\n// Apply the 'negative' effect on the selected region of interest\n        if(selectRegion && selectedRect.width > 0 && selectedRect.height > 0)\n        {\n            Mat roi(image, selectedRect);\n            bitwise_not(roi, roi);\n        }\n\n        // Display the output image\n        imshow(windowName, image);\n\n        // Get the keyboard input and check if it's 'Esc'\n        // 27 -> ASCII value of 'Esc' key\n        ch = waitKey(30);\n        if (ch == 27) {\n            break;\n        }\n}\n\n    return 1;\n}\n```", "```py\nint main(int argc, char* argv[])\n{\n    // Variable declaration and initialization\n\n    // Iterate until the user presses the Esc key\n    while(true)\n    {\n        // Capture the current frame\n        cap >> frame;\n\n        // Resize the frame\n        resize(frame, frame, Size(), scalingFactor, scalingFactor, INTER_AREA);\n\n        dst = Mat::zeros(frame.size(), CV_32FC1);\n\n        // Convert to grayscale\n        cvtColor(frame, frameGray, COLOR_BGR2GRAY );\n\n        // Detecting corners\n        cornerHarris(frameGray, dst, blockSize, apertureSize, k, BORDER_DEFAULT);\n\n        // Normalizing\n        normalize(dst, dst_norm, 0, 255, NORM_MINMAX, CV_32FC1, Mat());\n        convertScaleAbs(dst_norm, dst_norm_scaled);\n```", "```py\n        // Drawing a circle around each corner\n        for(int j = 0; j < dst_norm.rows ; j++)\n        {\n            for(int i = 0; i < dst_norm.cols; i++)\n            {\n                if((int)dst_norm.at<float>(j,i) > thresh)\n                {\n                    circle(frame, Point(i, j), 8,  Scalar(0,255,0), 2, 8, 0);\n                }\n            }\n        }\n\n        // Showing the result\n        imshow(windowName, frame);\n\n        // Get the keyboard input and check if it's 'Esc'\n        // 27 -> ASCII value of 'Esc' key\n        ch = waitKey(10);\n        if (ch == 27) {\n            break;\n        }\n    }\n\n    // Release the video capture object\n    cap.release();\n\n    // Close all windows\n    destroyAllWindows();\n\n    return 1;\n}\n```", "```py\nint main(int argc, char* argv[])\n{\n    // Variable declaration and initialization\n\n    // Iterate until the user presses the Esc key\n    while(true)\n    {\n        // Capture the current frame\n        cap >> frame;\n\n        // Resize the frame\n        resize(frame, frame, Size(), scalingFactor, scalingFactor, INTER_AREA);\n\n        // Convert to grayscale\n        cvtColor(frame, frameGray, COLOR_BGR2GRAY );\n\n        // Initialize the parameters for Shi-Tomasi algorithm\n        vector<Point2f> corners;\n        double qualityThreshold = 0.02;\n        double minDist = 15;\n        int blockSize = 5;\n        bool useHarrisDetector = false;\n        double k = 0.07;\n\n        // Clone the input frame\n        Mat frameCopy;\n        frameCopy = frame.clone();\n\n        // Apply corner detection\n        goodFeaturesToTrack(frameGray, corners, numCorners, qualityThreshold, minDist, Mat(), blockSize, useHarrisDetector, k);\n```", "```py\n        // Parameters for the circles to display the corners\n        int radius = 8;      // radius of the cirles\n        int thickness = 2;   // thickness of the circles\n        int lineType = 8;\n\n        // Draw the detected corners using circles\n        for(size_t i = 0; i < corners.size(); i++)\n        {\n            Scalar color = Scalar(rng.uniform(0,255), rng.uniform(0,255), rng.uniform(0,255));\n            circle(frameCopy, corners[i], radius, color, thickness, lineType, 0);\n        }\n\n        /// Show what you got\n        imshow(windowName, frameCopy);\n\n        // Get the keyboard input and check if it's 'Esc'\n        // 27 -> ASCII value of 'Esc' key\n        ch = waitKey(30);\n        if (ch == 27) {\n            break;\n        }\n    }\n\n    // Release the video capture object\n    cap.release();\n\n    // Close all windows\n    destroyAllWindows();\n\n    return 1;\n}\n```", "```py\nint main(int argc, char* argv[])\n{\n    // Variable declaration and initialization\n\n    // Iterate until the user hits the Esc key\n    while(true)\n    {\n        // Capture the current frame\n        cap >> frame;\n\n        // Check if the frame is empty\n        if(frame.empty())\n            break;\n\n        // Resize the frame\n        resize(frame, frame, Size(), scalingFactor, scalingFactor, INTER_AREA);\n\n        // Copy the input frame\n        frame.copyTo(image);\n\n        // Convert the image to grayscale\n        cvtColor(image, curGrayImage, COLOR_BGR2GRAY);\n\n        // Check if there are points to track\n        if(!trackingPoints[0].empty())\n        {\n            // Status vector to indicate whether the flow for the corresponding features has been found\n            vector<uchar> statusVector;\n\n            // Error vector to indicate the error for the corresponding feature\n            vector<float> errorVector;\n\n            // Check if previous image is empty\n            if(prevGrayImage.empty())\n            {\n                curGrayImage.copyTo(prevGrayImage);\n            }\n\n            // Calculate the optical flow using Lucas-Kanade algorithm\n            calcOpticalFlowPyrLK(prevGrayImage, curGrayImage, trackingPoints[0], trackingPoints[1], statusVector, errorVector, windowSize, 3, terminationCriteria, 0, 0.001);\n```", "```py\n            int count = 0;\n\n            // Minimum distance between any two tracking points\n            int minDist = 7;\n\n            for(int i=0; i < trackingPoints[1].size(); i++)\n            {\n                if(pointTrackingFlag)\n                {\n                    /* If the new point is within 'minDist' distance from an existing point, it will not be tracked */\n                    if(norm(currentPoint - trackingPoints[1][i]) <= minDist)\n                    {\n                        pointTrackingFlag = false;\n                        continue;\n                    }\n                }\n\n                // Check if the status vector is good\n                if(!statusVector[i])\n                    continue;\n\n                trackingPoints[1][count++] = trackingPoints[1][i];\n\n      // Draw a filled circle for each of the tracking points\n                int radius = 8;\n                int thickness = 2;\n                int lineType = 8;\n                circle(image, trackingPoints[1][i], radius, Scalar(0,255,0), thickness, lineType);\n            }\n\n            trackingPoints[1].resize(count);\n        }\n```", "```py\n        // Refining the location of the feature points\n        if(pointTrackingFlag && trackingPoints[1].size() < maxNumPoints)\n        {\n            vector<Point2f> tempPoints;\n            tempPoints.push_back(currentPoint);\n\n            // Function to refine the location of the corners to subpixel accuracy.\n            // Here, 'pixel' refers to the image patch of size 'windowSize' and not the actual image pixel\n            cornerSubPix(curGrayImage, tempPoints, windowSize, cvSize(-1,-1), terminationCriteria);\n\n            trackingPoints[1].push_back(tempPoints[0]);\n            pointTrackingFlag = false;\n        }\n\n        // Display the image with the tracking points\n        imshow(windowName, image);\n\n        // Check if the user pressed the Esc key\n        char ch = waitKey(10);\n        if(ch == 27)\n            break;\n\n        // Swap the 'points' vectors to update 'previous' to 'current'\n        std::swap(trackingPoints[1], trackingPoints[0]);\n\n        // Swap the images to update previous image to current image\n        cv::swap(prevGrayImage, curGrayImage);\n    }\n\n    return 1;\n}\n```", "```py\nint main(int, char** argv)\n{\n    // Variable declaration and initialization\n\n    // Iterate until the user presses the Esc key\n    while(true)\n    {\n        // Capture the current frame\n        cap >> frame;\n\n        if(frame.empty())\n            break;\n\n        // Resize the frame\n        resize(frame, frame, Size(), scalingFactor, scalingFactor, INTER_AREA);\n\n        // Convert to grayscale\n        cvtColor(frame, curGray, COLOR_BGR2GRAY);\n\n        // Check if the image is valid\n        if(prevGray.data)\n        {\n            // Initialize parameters for the optical flow algorithm\n            float pyrScale = 0.5;\n            int numLevels = 3;\n            int windowSize = 15;\n            int numIterations = 3;\n            int neighborhoodSize = 5;\n            float stdDeviation = 1.2;\n\n            // Calculate optical flow map using Farneback algorithm\n            calcOpticalFlowFarneback(prevGray, curGray, flowImage, pyrScale, numLevels, windowSize, numIterations, neighborhoodSize, stdDeviation, OPTFLOW_USE_INITIAL_FLOW);\n```", "```py\n            // Convert to 3-channel RGB\n            cvtColor(prevGray, flowImageGray, COLOR_GRAY2BGR);\n\n            // Draw the optical flow map\n            drawOpticalFlow(flowImage, flowImageGray);\n\n            // Display the output image\n            imshow(windowName, flowImageGray);\n        }\n\n        // Break out of the loop if the user presses the Esc key\n        ch = waitKey(10);\n        if(ch == 27)\n            break;\n\n        // Swap previous image with the current image\n        std::swap(prevGray, curGray);\n    }\n\n    return 1;\n}\n```", "```py\n// Function to compute the optical flow map\nvoid drawOpticalFlow(const Mat& flowImage, Mat& flowImageGray)\n{\n    int stepSize = 16;\n    Scalar color = Scalar(0, 255, 0);\n\n    // Draw the uniform grid of points on the input image along with the motion vectors\n    for(int y = 0; y < flowImageGray.rows; y += stepSize)\n    {\n        for(int x = 0; x < flowImageGray.cols; x += stepSize)\n        {\n            // Circles to indicate the uniform grid of points\n            int radius = 2;\n            int thickness = -1;\n            circle(flowImageGray, Point(x,y), radius, color, thickness);\n\n            // Lines to indicate the motion vectors\n            Point2f pt = flowImage.at<Point2f>(y, x);\n            line(flowImageGray, Point(x,y), Point(cvRound(x+pt.x), cvRound(y+pt.y)), color);\n        }\n    }\n}\n```"]