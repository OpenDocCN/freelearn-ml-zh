- en: Speech Recognition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音识别
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Reading and plotting audio data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取和绘制音频数据
- en: Transforming audio signals into the frequency domain
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将音频信号转换到频域
- en: Generating audio signals with custom parameters
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自定义参数生成音频信号
- en: Synthesizing music
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成音乐
- en: Extracting frequency domain features
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取频域特征
- en: Building **hidden Markov models** (**HMMs)**
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建**隐马尔可夫模型**（**HMMs**）
- en: Building a speech recognizer
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建语音识别器
- en: Building a **text-to-speech** (**TTS**) system
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个**文本到语音**（**TTS**）系统
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To address the recipes in this chapter, you will need the following files (which
    are available on GitHub):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理本章中的食谱，你需要以下文件（可在GitHub上找到）：
- en: '`read_plot.py`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`read_plot.py`'
- en: '`input_read.wav`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_read.wav`'
- en: '`freq_transform.py`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`freq_transform.py`'
- en: '`input_freq.wav`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_freq.wav`'
- en: '`generate.py`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate.py`'
- en: '`synthesize_music.py`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`synthesize_music.py`'
- en: '`extract_freq_features.py`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`extract_freq_features.py`'
- en: '`input_freq.wav`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_freq.wav`'
- en: '`speech_recognizer.py`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_recognizer.py`'
- en: '`tts.py`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tts.py`'
- en: Introducing speech recognition
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍语音识别
- en: '**Speech recognition** refers to the process of recognizing and understanding
    spoken language. The input comes in the form of audio data, and the speech recognizers
    will process this data to extract meaningful information from it. This has a lot
    of practical uses, such as voice-controlled devices, the transcription of spoken
    language into words and security systems.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**语音识别**指的是识别和理解口语的过程。输入以音频数据的形式出现，语音识别器将处理这些数据以从中提取有意义的信息。这有很多实际应用，例如语音控制设备、将口语转录成文字以及安全系统。'
- en: Speech signals are very versatile in nature. There are many variations of speech
    in the same language. There are different elements to speech, such as language,
    emotion, tone, noise, and accent. It's difficult to rigidly define a set of rules
    of what can constitute speech. Even with all these variations, humans are very
    good at understanding all of this with relative ease. Hence, we need machines
    to understand speech in the same way.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 语音信号在本质上非常灵活。同一种语言中有许多不同的语音变体。语音有许多不同的元素，如语言、情感、音调、噪声和口音。严格定义一组可以构成语音的规则是困难的。即使有所有这些变化，人类也非常擅长相对轻松地理解所有这些。因此，我们需要机器以同样的方式理解语音。
- en: Over the last couple of decades, researchers have worked on various aspects
    of speech, such as identifying the speaker, understanding words, recognizing accents,
    and translating speech. Among all these tasks, automatic speech recognition has
    been the focal point for many researchers. In this chapter, we will learn how
    to build a **speech recognizer**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几十年里，研究人员一直在研究语音的各个方面，例如识别说话者、理解单词、识别口音和翻译语音。在这些任务中，自动语音识别一直是许多研究人员的焦点。在本章中，我们将学习如何构建一个**语音识别器**。
- en: Reading and plotting audio data
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取和绘制音频数据
- en: Let's take a look at how to read an audio file and visualize the signal. This
    will be a good starting point, and it will give us a good understanding of the
    basic structure of audio signals. Before we start, we need to understand that
    audio files are digitized versions of actual audio signals. Actual audio signals
    are complex, continuous-valued waves. In order to save a digital version, we sample
    the signal and convert it into numbers. For example, speech is commonly sampled
    at 44,100 Hz. This means that each second of the signal is broken down into 44,100
    parts, and the values at these timestamps are stored. In other words, you store
    a value every 1/44,100 seconds. As the sampling rate is high, we feel that the
    signal is continuous when we listen to it on our media players.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何读取音频文件并可视化信号。这将是一个好的起点，并将使我们更好地理解音频信号的基本结构。在我们开始之前，我们需要理解音频文件是实际音频信号的数字化版本。实际的音频信号是复杂的、连续值的波。为了保存数字版本，我们采样信号并将其转换为数字。例如，语音通常以44,100
    Hz的频率采样。这意味着信号的每一秒被分解成44,100个部分，并且在这些时间戳处的值被存储。换句话说，你每1/44,100秒存储一个值。由于采样率很高，当我们通过媒体播放器听信号时，我们会感觉到信号是连续的。
- en: Getting ready
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use the `wavfile` package to read the audio file from
    a `.wav` input file. So, we will draw the signal with a diagram.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用`wavfile`包从`.wav`输入文件中读取音频文件。因此，我们将用图表绘制信号。
- en: How to do it...
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We will use the following steps to read and plot audio using the `wavfile`
    package:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下步骤使用`wavfile`包读取和绘制音频：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `read_plot.py` file that''s already provided for you):'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在已提供的`read_plot.py`文件中）：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will use the `wavfile` package to read the audio file from the `input_read.wav`
    input file that''s already provided for you:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`wavfile`包从已提供的`input_read.wav`输入文件中读取音频文件：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s print out the parameters of this signal:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打印出这个信号的参数：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The audio signal is stored as 16-bit signed integer data; we need to normalize
    these values:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 音频信号以16位有符号整数数据存储；我们需要归一化这些值：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, let''s extract the first 30 values to plot, as follows:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们提取前30个值以进行绘图，如下所示：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The *x* axis is the **time axis**. Let''s build this axis, considering the
    fact that it should be scaled using the sampling frequency factor:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*x*轴是**时间轴**。让我们考虑它应该使用采样频率因子进行缩放的事实来构建这个轴：'
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Convert the units to seconds, as follows:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将单位转换为秒，如下所示：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s now plot this as follows:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们按照以下方式绘制：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The full code is in the `read_plot.py` file. If you run this code, you will
    see the following signal:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完整的代码在`read_plot.py`文件中。如果您运行此代码，您将看到以下信号：
- en: '![](img/45ca3d88-69b9-4028-b6b4-6a06819e1bb9.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45ca3d88-69b9-4028-b6b4-6a06819e1bb9.png)'
- en: 'You will also see the following output printed on your Terminal:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您还将在您的终端上看到以下输出打印：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Wave audio files are uncompressed files. The format was introduced with Windows
    3.1 as a standard format for the sound used in multimedia applications. Its technical
    specifications and description can be found in the *Multimedia Programming Interface
    and Data Specifications 1.0* document ([https://www.aelius.com/njh/wavemetatools/doc/riffmci.pdf](https://www.aelius.com/njh/wavemetatools/doc/riffmci.pdf)).
    It is based on the **Resource Interchange File Format** (**RIFF**) specifications
    that were introduced in 1991, constituting a metaformat for multimedia files running
    in the Windows environment. The RIFF structure organizes blocks of data in sections
    called chunks, each of which describes a characteristic of the WAV file (such
    as the sample rate, the bit rate, and the number of audio channels), or contains
    the values of the samples (in this case, we are referring to chunk data). The
    chunks are 32 bit (with some exceptions).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 波形音频文件是不压缩的文件。该格式在Windows 3.1中引入，作为多媒体应用中使用的声音的标准格式。其技术规范和描述可以在*多媒体编程接口和数据规范1.0*文档中找到（[https://www.aelius.com/njh/wavemetatools/doc/riffmci.pdf](https://www.aelius.com/njh/wavemetatools/doc/riffmci.pdf)）。它基于1991年引入的**资源交换文件格式**（**RIFF**）规范，构成了在Windows环境中运行的多媒体文件的元格式。RIFF结构将数据块组织在称为块段的区域中，每个块段描述WAV文件的一个特征（如采样率、比特率和音频通道数），或包含样本的值（在这种情况下，我们指的是块数据）。块是32位（有一些例外）。
- en: There's more...
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: To read the WAV file, the `scipy.io.wavfile.read()` function was used. This
    function returns data from a WAV file along with the sample rate. The returned
    sample rate is a Python integer, and the data is returned as a NumPy array with
    a datatype that corresponds to the file.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了读取WAV文件，使用了`scipy.io.wavfile.read()`函数。此函数从WAV文件返回数据以及采样率。返回的采样率是一个Python整数，数据以与文件对应的NumPy数组形式返回。
- en: See also
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the `scipy.io.wavfile.read()` function: [https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考`scipy.io.wavfile.read()`函数的官方文档：[https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html)
- en: 'Refer to *WAV* (from Wikipedia): [https://en.wikipedia.org/wiki/WAV](https://en.wikipedia.org/wiki/WAV)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考*WAV*（来自维基百科）：[https://en.wikipedia.org/wiki/WAV](https://en.wikipedia.org/wiki/WAV)
- en: Transforming audio signals into the frequency domain
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将音频信号转换为频域
- en: Audio signals consist of a complex mixture of sine waves of different frequencies,
    amplitudes, and phases. Sine waves are also referred to as **sinusoids**. There
    is a lot of information that is hidden in the frequency content of an audio signal.
    In fact, an audio signal is heavily characterized by its frequency content. The
    whole world of speech and music is based on this fact. Before you proceed further,
    you will need some knowledge of **Fourier transforms**.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 音频信号由不同频率、幅度和相位的正弦波复杂混合而成。正弦波也被称为**正弦波**。音频信号的频率内容中隐藏着大量信息。事实上，音频信号在很大程度上由其频率内容来表征。整个语音和音乐的世界都基于这一事实。在继续之前，你需要了解一些关于**傅里叶变换**的知识。
- en: Getting ready
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to transform an audio signal into the frequency
    domain. To do this, the `numpy.fft.fft()` function is used. This function computes
    the one-dimensional *n*-point **discrete Fourier transform** (**DFT**) with the
    efficient **fast Fourier transform** (**FFT**) algorithm.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将看到如何将音频信号转换到频域。为此，我们使用`numpy.fft.fft()`函数。此函数使用高效的**快速傅里叶变换**（**FFT**）算法计算一维**n**点**离散傅里叶变换**（**DFT**）。
- en: How to do it...
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to transform audio signals into the frequency domain:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何将音频信号转换到频域：
- en: 'Create a new Python file and import the following package (the full code is
    in the `freq_transform.py` file that''s already provided for you):'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并导入以下包（完整的代码在提供的`freq_transform.py`文件中）：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Read the `input_freq.wav` file that is already provided for you:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取提供的`input_freq.wav`文件：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Normalize the signal, as follows:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式归一化信号：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The audio signal is just a NumPy array. So, you can extract the length using
    the following code:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 音频信号只是一个NumPy数组。因此，你可以使用以下代码提取长度：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s apply the Fourier transform. The Fourier transform signal is mirrored
    along the center, so we just need to take the first half of the transformed signal.
    Our end goal is to extract the power signal, so we square the values in the signal
    in preparation for this:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们应用傅里叶变换。傅里叶变换后的信号沿中心对称，所以我们只需要取变换信号的半个部分。我们的最终目标是提取功率信号，因此我们需要在准备阶段对信号中的值进行平方：
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Extract the length of the signal, as follows:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式提取信号的长度：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We need to double the signal according to the length of the signal:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要根据信号的长度将信号加倍：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The power signal is extracted using the following formula:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下公式提取功率信号：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The *x* axis is the time axis; we need to scale this according to the sampling
    frequency and then convert this into seconds:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*x* 轴是时间轴；我们需要根据采样频率对其进行缩放，然后将其转换为秒：'
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Plot the signal, as follows:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式绘制信号：
- en: '[PRE18]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If you run this code, you will see the following output:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行这段代码，你将看到以下输出：
- en: '![](img/70c4c4b5-2abc-46bc-b29b-9d57fba262ad.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70c4c4b5-2abc-46bc-b29b-9d57fba262ad.png)'
- en: How it works...
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The sound spectrum is a graphical representation of the sound level, normally
    in **decibels** (**dB**), depending on the frequency in Hz. If the sound to be
    analyzed is a so-called pure sound (signal at a single frequency constant over
    time), for example, a perfect sine wave, the signal spectrum will have a single
    component at the sine wave frequency, with a certain level in dB. In reality,
    any real signal consists of a large number of sinusoidal components of amplitude
    that are continuously variable over time. For these signals, it is impossible
    to analyze pure tones because there are always fractions of the signal energy
    that are difficult to represent with sinusoids. In fact, the representation of
    a signal as the sum of sinusoidal harmonic components, according to the Fourier
    transform theorem, is only valid for stationary signals, which often do not correspond
    to real sounds.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 声音频谱是声音水平的图形表示，通常以**分贝**（**dB**）为单位，取决于频率（Hz）。如果要分析的声音是所谓的纯音（随时间恒定的单一频率信号），例如，一个完美的正弦波，信号频谱将在正弦波频率处有一个单一成分，并有一定水平的dB。在现实中，任何真实信号都由大量幅度随时间连续变化的正弦波成分组成。对于这些信号，由于信号能量中总有难以用正弦波表示的部分，因此无法分析纯音。事实上，根据傅里叶变换定理，将信号表示为正弦谐波成分之和，仅对平稳信号有效，而平稳信号通常并不对应于真实声音。
- en: There's more...
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: The frequency analysis of the sounds is based on the Fourier transform theorem.
    That is, any periodic signal can be generated by summing together so many sinusoidal
    signals (called harmonics) having multiple whole frequencies of the frequency
    of the periodic signal (called fundamental frequency).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 声音的频率分析基于傅里叶变换定理。也就是说，任何周期性信号都可以通过将具有多个整频的周期性信号的正弦波（称为谐波）相加来生成，这些整频是周期性信号频率的倍数（称为基频）。
- en: See also
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考内容
- en: 'Refer to the official documentation of the `numpy.fft.fft()` function: [https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.fft.fft.html](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.fft.fft.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的`numpy.fft.fft()`函数：[https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.fft.fft.html](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.fft.fft.html)
- en: 'Refer to *The Fourier Transform*: [http://www.thefouriertransform.com/](http://www.thefouriertransform.com/)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考四阶变换：[http://www.thefouriertransform.com/](http://www.thefouriertransform.com/)
- en: 'Refer to *Time-frequency representations* (from Aalto University): [https://mycourses.aalto.fi/pluginfile.php/145214/mod_resource/content/3/slides_05_time-frequency_representations.pdf](https://mycourses.aalto.fi/pluginfile.php/145214/mod_resource/content/3/slides_05_time-frequency_representations.pdf)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自阿尔托大学的**时频表示**（[https://mycourses.aalto.fi/pluginfile.php/145214/mod_resource/content/3/slides_05_time-frequency_representations.pdf](https://mycourses.aalto.fi/pluginfile.php/145214/mod_resource/content/3/slides_05_time-frequency_representations.pdf)）
- en: Generating audio signals with custom parameters
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自定义参数生成音频信号
- en: 'Sound is a particular type of wave in which a variation of pressure that is
    induced by a vibrating body (that is, a sound source) propagates in the surrounding
    medium (usually air). Some examples of sound sources include the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 声音是一种特殊的波，其中由振动体（即声源）引起的压力变化在周围介质（通常是空气）中传播。以下是一些声源的例子：
- en: Musical instruments in which the vibrating part can be a struck string (such
    as a guitar), or rubbed with a bow (such as the violin).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乐器中，振动部分可以是击打的弦（如吉他），或者用弓拉（如小提琴）。
- en: Our vocal cords that are made to vibrate from the air that comes out of the
    lungs and give rise to the voice.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的声音是由从肺部出来的空气振动我们的声带而产生的。
- en: Any phenomenon that causes a movement of air (such as the beating wings of a
    bird, an airplane that breaks down the supersonic barrier, a bomb that explodes,
    or a hammer beating on an anvil) having appropriate physical characteristics.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何导致空气移动的现象（如鸟的拍打翅膀、突破音障的飞机、爆炸的炸弹或锤子敲打砧子）都具有适当的物理特性。
- en: To reproduce sound through electronic equipment, it is necessary to transform
    it into an analogue sound that is an electric current that originates from the
    transformation by conversion of the mechanical energy of the sound wave into electrical
    energy. In order to be able to use the sound signals with the computer, it is
    necessary to transfigure the analogue in a digital signal originating from the
    transformation of the analog sound into an audio signal represented by a flow
    of 0 and 1 (bit).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了通过电子设备再现声音，必须将其转换成模拟声音，即由将声波的机械能转换为电能的转换产生的电流。为了能够使用计算机中的声音信号，必须将模拟信号转换成由将模拟声音转换为表示为0和1（比特）流的音频信号。
- en: Getting ready
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use NumPy to generate audio signals. As we discussed
    earlier, audio signals are complex mixtures of sinusoids. So, we will bear this
    in mind when we generate our own audio signal.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用NumPy生成音频信号。正如我们之前讨论的，音频信号是正弦波的复杂混合。因此，在生成我们自己的音频信号时，我们要牢记这一点。
- en: How to do it...
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to generate audio signals with custom parameters:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用自定义参数生成音频信号：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `generate.py` file that''s already provided for you):'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并导入以下包（完整的代码已包含在您提供的`generate.py`文件中）：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We need to define the output file where the generated audio will be stored:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要定义输出文件，生成的音频将存储在该文件中：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s now specify the audio generation parameters. We want to generate a 3-second
    long signal with a sampling frequency of 44,100, and a tonal frequency of 587
    Hz. The values on the time axis will go from *-2*pi* to *2*pi*:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们指定音频生成参数。我们想要生成一个3秒长的信号，采样频率为44,100Hz，音调频率为587Hz。时间轴上的值将从*-2*pi*到*2*pi*：
- en: '[PRE21]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s generate the time axis and the audio signal. The audio signal is a simple
    sinusoid with the previously mentioned parameters:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成时间轴和音频信号。音频信号是一个具有之前提到的参数的简单正弦波：
- en: '[PRE22]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, let''s add some noise to the signal:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们向信号添加一些噪声：
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We need to scale the values to 16-bit integers before we store them:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在存储之前，我们需要将值缩放到16位整数：
- en: '[PRE24]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Write this signal to the output file:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此信号写入输出文件：
- en: '[PRE25]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Plot the signal using the first 100 values:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前100个值绘制信号：
- en: '[PRE26]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Generate the time axis, as follows:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式生成时间轴：
- en: '[PRE27]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Convert the time axis into seconds:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将时间轴转换为秒：
- en: '[PRE28]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Plot the signal, as follows:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式绘制信号：
- en: '[PRE29]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If you run this code, you will get the following output:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您运行此代码，您将得到以下输出：
- en: '![](img/6ada8825-3c7c-4b24-b6eb-a6a4227b51e0.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ada8825-3c7c-4b24-b6eb-a6a4227b51e0.png)'
- en: How it works...
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used the NumPy library to generate audio signals. We have
    seen that a digital sound is a sequence of numbers, so generating a sound will
    be enough to build an array that represents a musical tone. First, we set the
    filename to where the output will be saved. Then, we specified the audio parameters.
    Thus, we generated audio using a sine wave. We then added some noise, so we resized
    to 16-bit integer values. In the end, we wrote the signal on the output file.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了NumPy库来生成音频信号。我们已经看到数字声音是一系列数字，因此生成声音只需要构建一个表示音乐音调的数组。首先，我们将文件名设置为输出保存的位置。然后，我们指定了音频参数。因此，我们使用正弦波生成了音频。然后我们添加了一些噪声，所以我们将它们缩放到16位整数值。最后，我们将信号写入输出文件。
- en: There's more...
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: In the coding of a signal, each value assigned to the single sample is represented
    in bits. Each bit corresponds to a dynamic range of 6 dB. The higher the number
    of bits used, the higher the range of dB that can be represented by the single
    sample.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在信号的编码中，分配给单个样本的每个值都用位表示。每个位对应于6 dB的动态范围。使用的位数越多，单个样本可以表示的dB范围就越高。
- en: 'Some of the typical values are as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一些典型值如下：
- en: 8 bits per sample that correspond to 256 levels.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个样本8位对应于256个级别。
- en: 16 bits per sample (the number used for CDs) that correspond to 65,636 levels.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个样本16位（CD使用的数量）对应于65,536个级别。
- en: See also
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the NumPy library: [http://www.numpy.org/](http://www.numpy.org/)
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考NumPy库的官方文档：[http://www.numpy.org/](http://www.numpy.org/)
- en: 'Refer to *Sine wave* (from Wikipedia): [https://en.wikipedia.org/wiki/Sine_wave](https://en.wikipedia.org/wiki/Sine_wave)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自维基百科的**正弦波**：[https://en.wikipedia.org/wiki/Sine_wave](https://en.wikipedia.org/wiki/Sine_wave)
- en: Synthesizing music
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 音乐合成
- en: In traditional musical instruments, sound is produced by the vibration of mechanical
    parts. In synthetic instruments, vibration is described by functions over time,
    called signals, which express the variation in the time of the acoustic pressure.
    Sound synthesis is a process that allows you to generate the sound artificially.
    The parameters by which the timbre of the sound is determined differ according
    to the type of synthesis that is used for the generation, and can be provided
    directly by the composer, or with actions on appropriate input devices, or derived
    from the analysis of pre-existing sounds.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统乐器中，声音是通过机械部件的振动产生的。在合成乐器中，振动是通过时间函数描述的，称为信号，它们表达了声压随时间的变化。声音合成是一个允许您人工生成声音的过程。确定声音音色的参数根据所使用的合成类型而有所不同，可以直接由作曲家提供，或者通过适当的输入设备上的操作，或者从现有声音的分析中得出。
- en: Getting ready
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to synthesize some music. To do this, we will
    use various notes, such as *A*, *G*, and *D*, along with their corresponding frequencies,
    to generate some simple music.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将看到如何合成一些音乐。为此，我们将使用各种音符，如**A**、**G**和**D**，以及它们相应的频率，来生成一些简单的音乐。
- en: How to do it...
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s take a look at how to synthesize some music:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何合成一些音乐：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `synthesize_music.py` file that''s already provided for you):'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码已包含在您提供的`synthesize_music.py`文件中）：
- en: '[PRE30]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Define a function to synthesize a tone, based on input parameters:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个基于输入参数（如幅度和频率）合成音调的函数：
- en: '[PRE31]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Build the time axis values:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建时间轴值：
- en: '[PRE32]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Construct the audio sample using the input arguments, such as amplitude and
    frequency:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用输入参数（如幅度和频率）构建音频样本：
- en: '[PRE33]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s define the main function. You''ve been provided with a JSON file, called
    `tone_freq_map.json`, which contains some notes along with their frequencies:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义主函数。您已经提供了一个名为`tone_freq_map.json`的JSON文件，其中包含一些音符及其频率：
- en: '[PRE34]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Load that file, as follows:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式加载该文件：
- en: '[PRE35]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, let''s assume that we want to generate a `G` note for a duration of two
    seconds:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，假设我们想要生成一个持续两秒的`G`音符：
- en: '[PRE36]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Call the function with the following parameters:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下参数调用该函数：
- en: '[PRE37]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Write the generated signal into the output file, as follows:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成的信号写入输出文件，如下所示：
- en: '[PRE38]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: A single tone `.wav` file is generated (`output_tone.wav`). Open this file in
    a media player and listen to it. That's the *G* note!
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 生成单个音调的`.wav`文件（`output_tone.wav`）。在媒体播放器中打开此文件并聆听。这就是*G*音符！
- en: 'Now, let''s do something more interesting. Let''s generate some notes in sequence
    to give it a musical feel. Define a note sequence along with their durations in
    seconds:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们做一些更有趣的事情。让我们按顺序生成一些音符，以赋予它音乐感。定义一个音符序列及其持续时间（以秒为单位）：
- en: '[PRE39]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Iterate through this list and call the synthesizer function for each of them:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历此列表并对每个元素调用合成器函数：
- en: '[PRE40]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Write the signal to the output file:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将信号写入输出文件：
- en: '[PRE41]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: You can now open the `output_tone_seq.wav` file in your media player and listen
    to it. You can feel the music!
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您现在可以在媒体播放器中打开`output_tone_seq.wav`文件并聆听。您可以感受到音乐的魅力！
- en: How it works...
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Music is a work of ingenuity and creativity that is difficult to explain in
    a nutshell. Musicians read a piece of music recognizing the notes as they are
    placed on the stave. By analogy, we can regard the synthesis of sound as a sequence
    of the characteristic frequencies of the known ones. In this recipe, we have used
    this procedure to synthesize a short sequence of notes.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐是一种难以简而言之的独创性和创造性的作品。音乐家阅读乐谱时，会识别出音符在乐谱上的位置。通过类比，我们可以将声音的合成视为已知音符特征频率的序列。在这个配方中，我们已经使用这个程序来合成一系列音符。
- en: There's more...
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'To generate music artificially, the synthesizer is used. All synthesizers have
    the following basic components that work together to create a sound:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要人工生成音乐，使用合成器。所有合成器都有以下基本组件，它们协同工作以产生声音：
- en: An oscillator that generates the waveform and changes the tone
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成波形并改变音调的振荡器
- en: A filter that cuts out some frequencies in the wave to change the timbre
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个滤波器用于在波形中去除某些频率以改变音色
- en: An amplifier that controls the volume of the signal
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个放大器用于控制信号的音量
- en: A modulator to create effects
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个调制器用于创建效果
- en: See also
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: Refer to the official documentation of the NumPy library: [http://www.numpy.org/](http://www.numpy.org/)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考NumPy库的官方文档：[http://www.numpy.org/](http://www.numpy.org/)
- en: Refer to the official documentation of the `scipy.io.wavfile.write()` function: [https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考`scipy.io.wavfile.write()`函数的官方文档：[https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.write.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html)
- en: 'Refer to *Frequencies of Musical Notes* (from Michigan Technological University):
    [http://pages.mtu.edu/~suits/notefreqs.html](http://pages.mtu.edu/~suits/notefreqs.html)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考*音乐音符频率*（来自密歇根理工大学）：[http://pages.mtu.edu/~suits/notefreqs.html](http://pages.mtu.edu/~suits/notefreqs.html)
- en: Refer to *Principles of Sound Synthesis* (from the University of Salford): [http://www.acoustics.salford.ac.uk/acoustics_info/sound_synthesis/](http://www.acoustics.salford.ac.uk/acoustics_info/sound_synthesis/)
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考*声音合成原理*（来自萨福克大学）：[http://www.acoustics.salford.ac.uk/acoustics_info/sound_synthesis/](http://www.acoustics.salford.ac.uk/acoustics_info/sound_synthesis/)
- en: Extracting frequency domain features
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取频域特征
- en: In the *Transforming audio signals into the frequency domain* recipe, we discussed
    how to convert a signal into the frequency domain. In most modern speech recognition
    systems, people use frequency domain features. After you convert a signal into
    the frequency domain, you need to convert it into a usable form. **Mel Frequency
    Cepstral Coefficients** (**MFCC**) is a good way to do this. MFCC takes the power
    spectrum of a signal and then uses a combination of filter banks and **discrete
    cosine transform** (**DCT**) to extract the features.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在*将音频信号转换为频域*的配方中，我们讨论了如何将信号转换为频域。在大多数现代语音识别系统中，人们使用频域特征。在将信号转换为频域后，你需要将其转换为可用的形式。**梅尔频率倒谱系数**（**MFCC**）是这样做的好方法。MFCC取信号的功率谱，然后使用滤波器组和**离散余弦变换**（**DCT**）的组合来提取特征。
- en: Getting ready
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: In this recipe, we will see how to use the `python_speech_features` package
    to extract frequency domain features. You can find the installation instructions
    at [http://python-speech-features.readthedocs.org/en/latest](http://python-speech-features.readthedocs.org/en/latest).
    So, let's take a look at how to extract MFCC features.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将看到如何使用`python_speech_features`包来提取频域特征。你可以在[http://python-speech-features.readthedocs.org/en/latest](http://python-speech-features.readthedocs.org/en/latest)找到安装说明。所以，让我们看看如何提取MFCC特征。
- en: How to do it...
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to extract frequency domain features:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何提取频域特征：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `extract_freq_features.py` file that''s already provided for you):'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并导入以下包（完整的代码在提供的`extract_freq_features.py`文件中，已经为你准备好了）：
- en: '[PRE42]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Read the `input_freq.wav` input file that is already provided for you:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取提供的`input_freq.wav`输入文件：
- en: '[PRE43]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Extract the MFCC and filter bank features, as follows:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式提取MFCC和滤波器组特征：
- en: '[PRE44]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Print the parameters to see how many windows were generated:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印参数以查看生成了多少个窗口：
- en: '[PRE45]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let''s now visualize the MFCC features. We need to transform the matrix so
    that the time domain is horizontal:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们可视化MFCC特征。我们需要转换矩阵，以便时域是水平的：
- en: '[PRE46]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now, let''s visualize the filter bank features. Again, we need to transform
    the matrix so that the time domain is horizontal:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们可视化滤波器组特征。同样，我们需要转换矩阵，以便时域是水平的：
- en: '[PRE47]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'If you run this code, you will get the following output for MFCC features:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在以下输出中看到MFCC特征：
- en: '![](img/9f6de9bc-6a8b-4f22-b167-265da6b87b8f.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9f6de9bc-6a8b-4f22-b167-265da6b87b8f.png)'
- en: 'The filter bank features will look like the following output:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器组特征将如下所示：
- en: '![](img/c447803e-13e9-42d9-85f3-00e03bbe3f3e.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c447803e-13e9-42d9-85f3-00e03bbe3f3e.png)'
- en: 'You will get the following output on your Terminal:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在你的终端上看到以下输出：
- en: '[PRE48]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: How it works...
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The **cepstrum** is the result of the Fourier transform applied to the dB spectrum
    of a signal. Its name is derived from the reversal of the first four letters of
    the word **spectrum**. It was defined in 1963 by Bogert et al. Thus, the cepstrum
    of a signal is the Fourier transform of the log value of the Fourier transform
    of the signal.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**倒谱**是对信号的dB频谱应用傅里叶变换的结果。其名称来源于单词**spectrum**的前四个字母的倒置。它由Bogert等人于1963年定义。因此，信号的倒谱是信号傅里叶变换的对数值的傅里叶变换。'
- en: The graph of the cepstrum is used to analyze the rates of change of the spectral
    content of a signal. Originally, it was invented to analyze earthquakes, explosions,
    and the responses to radar signals. It is currently a very effective tool for
    discriminating the human voice in music informatics. For these applications, the
    spectrum is first transformed through the frequency bands of the Mel scale. The
    result is the spectral coefficient Mel, or MFCCs. It is used for voice identification
    and pitch detection algorithms.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 脉冲谱图用于分析信号频谱内容的变化率。最初，它是为了分析地震、爆炸和对雷达信号的响应而发明的。目前，它是音乐信息学中区分人声的非常有效的工具。对于这些应用，频谱首先通过梅尔尺度上的频带来转换。结果是梅尔频谱系数，或MFCC。它用于语音识别和音高检测算法。
- en: There's more...
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The cepstrum is used to separate the part of the signal that contains the excitation
    information from the transfer function performed by the larynx. The lifter action
    (filtering in the frequency domain) has as its objective the separation of the
    excitation signal from the transfer function.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱分析用于将包含激励信息的信号部分与喉部执行的传递函数分离。提升作用（频域中的滤波）的目标是将激励信号从传递函数中分离出来。
- en: See also
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the `python_speech_features` package: [https://python-speech-features.readthedocs.io/en/latest/](https://python-speech-features.readthedocs.io/en/latest/)
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方的`python_speech_features`包文档：[https://python-speech-features.readthedocs.io/en/latest/](https://python-speech-features.readthedocs.io/en/latest/)
- en: 'Refer to the MFCC tutorial: [http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考MFCC教程：[http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)
- en: Building HMMs
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建HMM
- en: We are now ready to discuss speech recognition. We will use HMMs to perform
    speech recognition; HMMs are great at modeling time series data. As an audio signal
    is a time series signal, HMMs perfectly suit our needs. An HMM is a model that
    represents probability distributions over sequences of observations. We assume
    that the outputs are generated by hidden states. So, our goal is to find these
    hidden states so that we can model the signal.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好讨论语音识别了。我们将使用HMM进行语音识别；HMM在建模时间序列数据方面非常出色。由于音频信号是一种时间序列信号，HMM非常适合我们的需求。HMM是一个表示观察序列概率分布的模型。我们假设输出是由隐藏状态生成的。因此，我们的目标是找到这些隐藏状态，以便我们可以建模信号。
- en: Getting ready
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to build an HMM using the `hmmlearn` package. Before
    you proceed, you will need to install the `hmmlearn` package. Let's take a look
    at how to build HMMs.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将看到如何使用`hmmlearn`包构建一个HMM。在继续之前，您需要安装`hmmlearn`包。让我们看看如何构建HMM。
- en: How to do it...
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to build HMMs:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建HMM：
- en: 'Create a new Python file and define a class to model HMMs (the full code is
    in the `speech_recognizer.py` file that''s already provided for you):'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并定义一个类来建模HMM（完整的代码在您已经提供的`speech_recognizer.py`文件中）：
- en: '[PRE49]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let''s initialize the class; we will use Gaussian HMMs to model our data. The
    `n_components` parameter defines the number of hidden states. `cov_type` defines
    the type of covariance in our transition matrix, and `n_iter` indicates the number
    of iterations it will go through before it stops training:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们初始化类；我们将使用高斯HMM来建模我们的数据。`n_components`参数定义了隐藏状态的数量。`cov_type`定义了传递矩阵中的协方差类型，而`n_iter`表示在停止训练之前它将进行的迭代次数：
- en: '[PRE50]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The choice of the preceding parameters depends on the problem at hand. You need
    to have an understanding of your data in order to select these parameters in a
    smart way.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 前述参数的选择取决于具体问题。您需要了解您的数据，以便以明智的方式选择这些参数。
- en: 'Initialize the variables, as follows:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化变量，如下所示：
- en: '[PRE51]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Define the model with the following parameters:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下参数定义模型：
- en: '[PRE52]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The input data is a NumPy array, where each element is a feature vector consisting
    of *k *dimensions:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入数据是一个NumPy数组，其中每个元素都是一个由*k*个维度组成的特征向量：
- en: '[PRE53]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Define a method to extract the score, based on the model:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个基于模型提取分数的方法：
- en: '[PRE54]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: We built a class to handle HMM training and prediction, but we need some data
    to see it in action. We will use it in the next recipe to build a speech recognizer.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们构建了一个类来处理HMM训练和预测，但我们需要一些数据来看到它的实际应用。我们将在下一个菜谱中使用它来构建一个语音识别器。
- en: How it works...
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: HMM is a model where the system is assumed to be a Markov process with unobserved
    states. A stochastic process is called Markovian when, having chosen a certain
    instance of *t* for observation, the evolution of the process, starting with *t*,
    depends only on *t*, and does not depend in any way on the previous instances.
    Thus, a process is Markovian when, given the moment of observation, only a particular
    instance determines the future evolution of the process, and that evolution does
    not depend on the past.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An HMM is, therefore, a Markov chain in which states are not directly observable.
    More precisely, it can be understood as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: The chain has a number of states
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The states evolve according to a Markov chain
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each state generates an event with a certain probability distribution that depends
    only on the state
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The event is observable, but the state is not
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HMMs are particularly known for their applications in the recognition of the
    temporal pattern of spoken speeches, handwriting, texture recognition, and bioinformatics.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the official documentation of the `hmmlearn` package: [https://hmmlearn.readthedocs.io/en/latest/](https://hmmlearn.readthedocs.io/en/latest/)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to *A Tutorial on Hidden Markov Models (*by Lawrence R. Rabiner): [https://www.robots.ox.ac.uk/~vgg/rg/slides/hmm.pdf](https://www.robots.ox.ac.uk/~vgg/rg/slides/hmm.pdf)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a speech recognizer
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Speech recognition is the process by which human oral language is recognized,
    and subsequently processed through a computer, or, more specifically, through
    a special speech recognition system. Speech recognition systems are used for automated
    voice applications in the context of telephone applications (such as automatic
    call centers) for dictation systems, which allow the dictation of speeches to
    the computer, for control systems of the navigation system satellite, or for a
    phone in a car via voice commands.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need a database of speech files to build our speech recognizer. We will use
    the database available at [https://code.google.com/archive/p/hmm-speech-recognition/downloads](https://code.google.com/archive/p/hmm-speech-recognition/downloads).
    This contains 7 different words, where each word has 15 audio files associated
    with it. Download the ZIP file and extract the folder that contains the Python
    file (rename the folder that contains the data as `data`). This is a small dataset,
    but it is sufficient in understanding how to build a speech recognizer that can
    recognize 7 different words. We need to build an HMM model for each class. When
    we want to identify the word in a new input file, we need to run all the models
    on this file and pick the one with the best score. We will use the HMM class that
    we built in the previous recipe.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to build a speech recognizer:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    in the `speech_recognizer.py` file that''s already provided for you):'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Define a function to parse the input arguments in the command line:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Let''s use the `HMMTrainer` class defined in the previous *Building HMMs* recipe:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Define the main function, and parse the input arguments:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Initiate the variable that will hold all the HMM models:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Parse the input directory that contains all the database''s audio files:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Extract the name of the subfolder:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The name of the subfolder is the label of this class; extract it using the
    following code:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Initialize the variables for training:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Iterate through the list of audio files in each subfolder:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Read each audio file, as follows:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Extract the MFCC features, as follows:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Keep appending this to the `X` variable, as follows:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Append the corresponding label too, as follows:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Once you have extracted features from all the files in the current class, train
    and save the HMM model. As HMM is a generative model for unsupervised learning,
    we don''t need labels to build HMM models for each class. We explicitly assume
    that separate HMM models will be built for each class:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Get a list of test files that were not used for training:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Parse the input files, as follows:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Read in each audio file, as follows:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Extract the MFCC features, as follows:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Define the variables to store the maximum score and the output label:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Iterate through all the models and run the input file through each of them:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Extract the score and store the maximum score:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Print the true and predicted labels:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The full code is in the `speech_recognizer.py` file. Run this file using the
    following command:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The following results are returned on your Terminal:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: How it works...
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we created a speech recognition system using an HMM. To do this,
    we first created a function to analyze input arguments. Then, a class was used
    to handle all HMM-related processing. Thus, we have classified the input data
    and then predicted the label of the test data. Finally, we printed the results.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A voice recognition system is based on a comparison of the input audio, which
    is appropriately processed, with a database created during system training. In
    practice, the software application tries to identify the word spoken by the speaker,
    looking for a similar sound in the database, and checking which word corresponds.
    Naturally, it is a very complex operation. Moreover, it is not done on whole words,
    but on the phonemes that compose them.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the official documentation of the `hmmlearn` package: [https://hmmlearn.readthedocs.io/en/latest/](https://hmmlearn.readthedocs.io/en/latest/)
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the official documentation of the `python_speech_features` package: [https://python-speech-features.readthedocs.io/en/latest/](https://python-speech-features.readthedocs.io/en/latest/)
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to the *Argparse Tutorial*: [https://docs.python.org/3/howto/argparse.html](https://docs.python.org/3/howto/argparse.html)'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to *Fundamentals of Speech Recognition: A Short Course* (from Mississippi
    State University): [http://www.iitg.ac.in/samudravijaya/tutorials/fundamentalOfASR_picone96.pdf](http://www.iitg.ac.in/samudravijaya/tutorials/fundamentalOfASR_picone96.pdf)'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a TTS system
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Speech synthesis is the technique that is used for the artificial reproduction
    of the human voice. A system used for this purpose is called a speech synthesizer
    and can be implemented by software or hardware. Speech synthesis systems are also
    known as TTS systems due to their ability to convert text into speech. There are
    also systems that convert phonetic symbols into speech.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Speech synthesis can be achieved by concatenating recordings of vocals stored
    in a database. The various systems of speech synthesis differ according to the
    size of the stored voice samples. That is, a system that stores single phonemes
    or double phonemes allows you to obtain the maximum number of combinations at
    the expense of overall clarity, while other systems which are designed for a specific
    use repeat themselves, to record whole words or entire sentences in order to achieve
    a high-quality result.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: A synthesizer can create a completely synthetic voice using vocal traits and
    other human characteristics. The quality of a speech synthesizer is evaluated
    on the basis of both the resemblance to the human voice and its level of comprehensibility.
    A TTS conversion program with good performance can play an important role in accessibility;
    for example, by allowing people with impaired vision or dyslexia to listen to
    documents written on the computer. For this type of application (since the early
    1980s), many operating systems have included speech synthesis functions.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will introduce the Python library that allows us to create
    TTS systems. We will run the `pyttsx` cross-platform TTS wrapper library.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to build a TTS system:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must install `pyttsx` for the Python 3 library (offline TTS for Python
    3) and its relative dependencies:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'To avoid possible errors, it is also necessary to install the `pypiwin32` library:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Create a new Python file and import the `pyttsx3` package (the full code is
    in the `tts.py` file that''s already provided for you):'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We create an engine instance that will use the specified driver:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'To change the speech rate, use the following commands:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'To change the voice of the speaker, use the following commands:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Now, we will use the `say` method to queue a command to speak an utterance.
    The speech is output according to the properties set before this command in the
    queue:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Finally, we will invoke the `runAndWait()` method. This method blocks while
    processing all currently queued commands and invokes callbacks for engine notifications
    appropriately. It returns when all commands queued before this call are emptied
    from the queue:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: At this point, a different voice will read the text supplied by us.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A speech synthesis system or engine is composed of two parts: a frontend and
    a backend. The frontend part deals with the conversion of the text into phonetic
    symbols, while the backend part interprets the phonetic symbols and reads them,
    thus, transforming them into an artificial voice. The frontend has two key functions;
    first, it performs an analysis of the written text to convert all numbers, abbreviations,
    and abbreviations into words in full. This preprocessing step is referred to as
    tokenization. The second function consists of converting each word into its corresponding
    phonetic symbols and performing the linguistic analysis of the revised text, subdividing
    it into prosodic units, that is, into prepositions, sentences, and periods. The
    process of assigning phonetic transcription to words is called conversion from
    text to phoneme, or from grapheme to phoneme.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An evolution of the classic TTS system is called `WaveNet`, and it seems to
    know how to speak, articulate accents, and pronounce a whole sentence fluently.
    WaveNet is a deep neural network that generates raw audio. It was created by researchers
    at the London-based artificial intelligence firm, DeepMind. WaveNet uses a deep
    generative model for sound waves that can imitate any human voice. The sentences
    pronounced by WaveNet sound 50% more similar to a human voice than the more advanced
    TTS. To demonstrate this, samples were created in English and Mandarin, and using
    the **Mean Opinion Scores** (**MOS**) system, which is now a standard in audio
    evaluation, samples of artificial intelligence were compared to those generated
    by normal TTS, parametric-TTS, and also with respect to the samples of real voices.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the official documentation of the `pyttsx3` package: [https://pyttsx3.readthedocs.io/en/latest/index.html](https://pyttsx3.readthedocs.io/en/latest/index.html)'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to *Text to Speech: A Simple Tutorial* (by D. Sasirekha and E. Chandra):
    [https://pdfs.semanticscholar.org/e7ad/2a63458653ac965fe349fe375eb8e2b70b02.pdf](https://pdfs.semanticscholar.org/e7ad/2a63458653ac965fe349fe375eb8e2b70b02.pdf)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to *WaveNet: A Generative Model for Raw Audio* (from Google DeepMind):
    [https://deepmind.com/blog/wavenet-generative-model-raw-audio/](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
