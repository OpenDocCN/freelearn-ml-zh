["```py\nfrom sklearn.datasets import make_classification\n\n>>> nb_samples = 500\n>>> X, Y = make_classification(n_samples=nb_samples, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1)\n```", "```py\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\n\n>>> svc = SVC(kernel='linear')\n>>> cross_val_score(svc, X, Y, scoring='accuracy', cv=10).mean()\n0.93191356542617032\n```", "```py\nimport numpy as np \n\n>>> def custom_kernel(x1, x2): \n return np.square(np.dot(x1, x2) + 1)\n```", "```py\nfrom sklearn.datasets import make_circles \n\n>>> nb_samples = 500 \n>>> X, Y = make_circles(n_samples=nb_samples, noise=0.1)\n```", "```py\nfrom sklearn.linear_model import LogisticRegression \n\n>>> lr = LogisticRegression() \n>>> cross_val_score(lr, X, Y, scoring='accuracy', cv=10).mean() \n0.438\n```", "```py\nimport multiprocessing \nfrom sklearn.model_selection import GridSearchCV \n\n>>> param_grid = [ \n { \n 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], \n 'C': [ 0.1, 0.2, 0.4, 0.5, 1.0, 1.5, 1.8, 2.0, 2.5, 3.0 ] \n } \n] \n\n>>> gs = GridSearchCV(estimator=SVC(), param_grid=param_grid, \n scoring='accuracy', cv=10, n_jobs=multiprocessing.cpu_count()) \n\n>>> gs.fit(X, Y) \nGridSearchCV(cv=10, error_score='raise', \n estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, \n decision_function_shape=None, degree=3, gamma='auto', kernel='rbf', \n max_iter=-1, probability=False, random_state=None, shrinking=True, \n tol=0.001, verbose=False), \n fit_params={}, iid=True, n_jobs=8, \n param_grid=[{'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'C': [0.1, 0.2, 0.4, 0.5, 1.0, 1.5, 1.8, 2.0, 2.5, 3.0]}], \n pre_dispatch='2*n_jobs', refit=True, return_train_score=True, \n scoring='accuracy', verbose=0) \n\n>>> gs.best_estimator_ \nSVC(C=2.0, cache_size=200, class_weight=None, coef0=0.0, \n decision_function_shape=None, degree=3, gamma='auto', kernel='rbf', \n max_iter=-1, probability=False, random_state=None, shrinking=True, \n tol=0.001, verbose=False) \n\n>>> gs.best_score_ \n0.87\n```", "```py\nfrom sklearn.datasets import load_digits \n\n>>> digits = load_digits() \n\n>>> param_grid = [ \n { \n 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], \n 'C': [ 0.1, 0.2, 0.4, 0.5, 1.0, 1.5, 1.8, 2.0, 2.5, 3.0 ] \n } \n] \n\n>>> gs = GridSearchCV(estimator=SVC(), param_grid=param_grid, \n scoring='accuracy', cv=10, n_jobs=multiprocessing.cpu_count()) \n\n>>> gs.fit(digits.data, digits.target) \nGridSearchCV(cv=10, error_score='raise', \n estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, \n decision_function_shape=None, degree=3, gamma='auto', kernel='rbf', \n max_iter=-1, probability=False, random_state=None, shrinking=True, \n tol=0.001, verbose=False), \n fit_params={}, iid=True, n_jobs=8, \n param_grid=[{'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'C': [0.1, 0.2, 0.4, 0.5, 1.0, 1.5, 1.8, 2.0, 2.5, 3.0]}], \n pre_dispatch='2*n_jobs', refit=True, return_train_score=True, \n scoring='accuracy', verbose=0) \n\n>>> gs.best_estimator_ \nSVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0, \n decision_function_shape=None, degree=3, gamma='auto', kernel='poly', \n max_iter=-1, probability=False, random_state=None, shrinking=True, \n tol=0.001, verbose=False) \n\n>>> gs.best_score_ \n0.97885364496382865\n```", "```py\nfrom sklearn.datasets import fetch_olivetti_faces\n\n>>> faces = fetch_olivetti_faces(data_home='/ML/faces/')\n```", "```py\n>>> param_grid = [\n { \n 'kernel': ['rbf', 'poly'],\n 'C': [ 0.1, 0.5, 1.0, 1.5 ],\n 'degree': [2, 3, 4, 5],\n 'gamma': [0.001, 0.01, 0.1, 0.5]\n }\n]\n\n>>> gs = GridSearchCV(estimator=SVC(), param_grid=param_grid, scoring='accuracy', cv=8,  n_jobs=multiprocessing.cpu_count())\n>>> gs.fit(faces.data, faces.target)\nGridSearchCV(cv=8, error_score='raise',\n estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n max_iter=-1, probability=False, random_state=None, shrinking=True,\n tol=0.001, verbose=False),\n fit_params={}, iid=True, n_jobs=8,\n param_grid=[{'kernel': ['rbf', 'poly'], 'C': [0.1, 0.5, 1.0, 1.5], 'gamma': [0.001, 0.01, 0.1, 0.5], 'degree': [2, 3, 4, 5]}],\n pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n scoring='accuracy', verbose=0)\n\n>>> gs.best_estimator_\nSVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n decision_function_shape=None, degree=2, gamma=0.1, kernel='poly',\n max_iter=-1, probability=False, random_state=None, shrinking=True,\n tol=0.001, verbose=False)\n```", "```py\n>>> gs.best_score_\n0.96999999999999997\n```", "```py\n>>> svc = SVC(kernel='linear') \n>>> svc.fit(X, Y) \n>>> svc.support_vectors_.shape \n(242L, 2L)\n```", "```py\nfrom sklearn.svm import NuSVC \n\n>>> nusvc = NuSVC(kernel='linear', nu=0.5) \n>>> nusvc.fit(X, Y) \n>>> nusvc.support_vectors_.shape \n(251L, 2L) \n\n>>> cross_val_score(nusvc, X, Y, scoring='accuracy', cv=10).mean() \n0.80633213285314143\n```", "```py\n>>> nusvc = NuSVC(kernel='linear', nu=0.15) \n>>> nusvc.fit(X, Y) \n>>> nusvc.support_vectors_.shape \n(78L, 2L) \n\n>>> cross_val_score(nusvc, X, Y, scoring='accuracy', cv=10).mean() \n0.67584393757503003\n```", "```py\nimport numpy as np \n\n>>> param_grid = [ \n { \n 'nu': np.arange(0.05, 1.0, 0.05) \n } \n] \n\n>>> gs = GridSearchCV(estimator=NuSVC(kernel='linear'), param_grid=param_grid, \n scoring='accuracy', cv=10, n_jobs=multiprocessing.cpu_count()) \n>>> gs.fit(X, Y) \nGridSearchCV(cv=10, error_score='raise', \n estimator=NuSVC(cache_size=200, class_weight=None, coef0=0.0, \n decision_function_shape=None, degree=3, gamma='auto', kernel='linear', \n max_iter=-1, nu=0.5, probability=False, random_state=None, \n shrinking=True, tol=0.001, verbose=False), \n fit_params={}, iid=True, n_jobs=8, \n param_grid=[{'nu': array([ 0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35,  0.4 ,  0.45, \n 0.5 ,  0.55,  0.6 ,  0.65,  0.7 ,  0.75,  0.8 ,  0.85,  0.9 ,  0.95])}], \n pre_dispatch='2*n_jobs', refit=True, return_train_score=True, \n scoring='accuracy', verbose=0) \n\n>>> gs.best_estimator_ \nNuSVC(cache_size=200, class_weight=None, coef0=0.0, \n decision_function_shape=None, degree=3, gamma='auto', kernel='linear', \n max_iter=-1, nu=0.5, probability=False, random_state=None, \n shrinking=True, tol=0.001, verbose=False) \n\n>>> gs.best_score_ \n0.80600000000000005 \n\n>>> gs.best_estimator_.support_vectors_.shape \n(251L, 2L)\n```", "```py\n>>> nb_samples = 50 \n\n>>> X = np.arange(-nb_samples, nb_samples, 1) \n>>> Y = np.zeros(shape=(2 * nb_samples,)) \n\n>>> for x in X: \n Y[int(x)+nb_samples] = np.power(x*6, 2.0) / 1e4 + np.random.uniform(-2, 2)\n```", "```py\nfrom sklearn.svm import SVR \n\n>>> svr = SVR(kernel='poly', degree=2, C=1.5, epsilon=0.5) \n>>> cross_val_score(svr, X.reshape((nb_samples*2, 1)), Y, scoring='neg_mean_squared_error', cv=10).mean() \n-1.4641683636397234\n```"]