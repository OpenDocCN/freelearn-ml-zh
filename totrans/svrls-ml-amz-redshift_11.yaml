- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Bringing Your Own Models for Database Inference
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库推理的自定义模型
- en: In this book, we’ve covered the process of training models natively using **Redshift
    Machine Learning** (**Redshift ML**). However, there may be instances where you
    need to utilize models built outside of Redshift. To address this, Redshift ML
    offers the **Bring Your Own Model** (**BYOM**) feature, allowing users to integrate
    their Amazon SageMaker machine learning models with Amazon Redshift. This feature
    facilitates making predictions and performing other machine learning tasks on
    data stored in the warehouse, without requiring data movement.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们介绍了使用**Redshift机器学习**（**Redshift ML**）原生训练模型的过程。然而，可能存在需要利用Redshift外部构建的模型的情况。为了解决这个问题，Redshift
    ML提供了**Bring Your Own Model**（**BYOM**）功能，允许用户将他们的Amazon SageMaker机器学习模型与Amazon
    Redshift集成。此功能便于在仓库中存储的数据上执行预测和其他机器学习任务，而无需数据移动。
- en: 'BYOM offers two approaches: **local inference** and **remote inference**. In
    this chapter, we’ll delve into the workings of BYOM and explore the various options
    available for creating and integrating BYOM. You’ll be guided through the process
    of building a machine learning model in Amazon SageMaker, and subsequently, employing
    Redshift ML’s BYOM feature to bring that model to Redshift. Moreover, you’ll learn
    how to apply these models to the data stored in Redshift’s data warehouse to make
    predictions.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: BYOM提供了两种方法：**本地推理**和**远程推理**。在本章中，我们将深入探讨BYOM的工作原理，并探索创建和集成BYOM的各种选项。您将指导完成在Amazon
    SageMaker中构建机器学习模型的过程，随后使用Redshift ML的BYOM功能将模型引入Redshift。此外，您还将学习如何将这些模型应用于存储在Redshift数据仓库中的数据以进行预测。
- en: By the end of this chapter, you’ll be proficient in bringing Amazon SageMaker-created
    models and executing predictions within Amazon Redshift. Utilizing BYOM, you can
    deploy models such as **XGBoost** and a **multilayer perceptron** (**MLP**) to
    Redshift ML. Once a pre-trained model is deployed on Redshift ML, you can run
    inferences locally on Redshift without relying on a SageMaker endpoint or SageMaker
    Studio. This simplicity empowers data analysts to conduct inference on new data
    using models created externally to Redshift, eliminating concerns about accessing
    SageMaker’s services.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将熟练地将Amazon SageMaker创建的模型在Amazon Redshift中执行预测。利用BYOM，您可以将**XGBoost**和**多层感知器**（**MLP**）等模型部署到Redshift
    ML。一旦在Redshift ML上部署了预训练模型，您就可以在Redshift上本地运行推理，而不依赖于SageMaker端点或SageMaker Studio。这种简单性使数据分析师能够使用外部创建的模型对新的数据进行推理，消除了访问SageMaker服务的担忧。
- en: This method significantly speeds up the delivery of machine learning models
    created outside of Redshift to the data team. Furthermore, since Redshift ML interacts
    with native Redshift SQL, the user experience for the data team remains consistent
    with other data analysis work performed on the data warehouse.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法显著加快了将Redshift外部创建的机器学习模型交付给数据团队的速度。此外，由于Redshift ML与原生Redshift SQL交互，数据团队的用户体验与其他在数据仓库上执行的数据分析工作保持一致。
- en: 'In this chapter, we will go through the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要主题：
- en: Benefits of BYOM
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BYOM的好处
- en: Supported model types
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持的模型类型
- en: BYOM for local inference
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BYOM用于本地推理
- en: BYOM for remote inference
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BYOM用于远程推理
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires a web browser and access to the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要网络浏览器和以下访问权限：
- en: An AWS account
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个AWS账户
- en: An Amazon Redshift Serverless endpoint
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Amazon Redshift Serverless端点
- en: An Amazon SageMaker notebook
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Amazon SageMaker笔记本
- en: Amazon Redshift Query Editor v2
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Redshift查询编辑器v2
- en: Completing the *Getting started with Amazon Redshift Serverless* section in
    [*Chapter 1*](B19071_01.xhtml#_idTextAnchor015)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成[第1章](B19071_01.xhtml#_idTextAnchor015)中的“Amazon Redshift Serverless入门”部分
- en: 'You can find the code used in this chapter here:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到本章节使用的代码：
- en: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift)'
- en: 'The data files required for this chapter are located in a public S3 bucket:
    `s3://packt-serverless-ml-redshift/`.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节所需的数据文件位于一个公共的S3桶中：`s3://packt-serverless-ml-redshift/`。
- en: Let’s begin!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Benefits of BYOM
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BYOM的好处
- en: With Amazon Redshift ML, you can use an existing ML model built in Amazon SageMaker
    and use it in Redshift without having to retrain it. To use BYOM, you need to
    provide model artifacts or a SageMaker endpoint, which takes a batch of data and
    returns predictions. BYOM is useful in cases where a machine learning model is
    not yet available in Redshift ML, for example, at the time of writing this book,
    a Random Cut Forest model is not yet available in Redshift ML, so you can build
    this model in SageMaker and easily bring it to Redshift and then use it against
    the data stored in Redshift.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Amazon Redshift ML，您可以使用在 Amazon SageMaker 中构建的现有机器学习模型，并在 Redshift 中使用它，而无需重新训练。要使用
    BYOM，您需要提供模型工件或 SageMaker 端点，该端点接收一批数据并返回预测。BYOM 在机器学习模型尚未在 Redshift ML 中可用的情况下很有用，例如，在撰写本书时，随机切割森林模型尚未在
    Redshift ML 中可用，因此您可以在 SageMaker 中构建此模型，并轻松将其带到 Redshift，然后使用它来处理存储在 Redshift
    中的数据。
- en: 'Here are some specific benefits of using Redshift ML with your own ML model:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Redshift ML 与您自己的机器学习模型有一些具体的优势：
- en: '**Improved efficiency**: By using an existing ML model, you can save time and
    resources that would otherwise be spent on training a new model'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提高效率**：通过使用现有的机器学习模型，您可以节省在训练新模型上花费的时间和资源。'
- en: '**Easy integration**: Redshift ML makes it easy to integrate your ML model
    into your data pipeline, allowing you to use it for real-time predictions or batch
    predictions'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于集成**：Redshift ML 使将您的机器学习模型集成到您的数据管道变得容易，允许您用于实时预测或批量预测。'
- en: '**Scalability**: Redshift ML is built on top of the highly scalable and performant
    Amazon Redshift data warehouse, so you can use your ML model to make predictions
    on large datasets without worrying about performance issues'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：Redshift ML 是建立在高度可扩展且性能卓越的 Amazon Redshift 数据仓库之上的，因此你可以使用你的机器学习模型对大型数据集进行预测，而无需担心性能问题。'
- en: Supported model types
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持的模型类型
- en: 'Amazon Redshift ML supports a wide range of machine learning models through
    the BYOM feature. Some common types of models that can be used with BYOM include
    the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift ML 通过 BYOM 功能支持广泛的机器学习模型。可以使用 BYOM 的常见模型类型包括以下几种：
- en: '**Linear regression models**: These models are like number predictors. They
    take into account several factors or features and use them to guess a specific
    numerical outcome. For example, if you want to predict the price of a house, a
    linear regression model would consider factors such as the size of the house,
    the number of rooms, and the location to estimate the house’s price.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性回归模型**：这些模型类似于数字预测器。它们考虑几个因素或特征，并使用它们来猜测特定的数值结果。例如，如果你想预测一栋房子的价格，线性回归模型会考虑诸如房子的面积、房间数量和位置等因素，以估计房子的价格。'
- en: '**Logistic regression models**: These models are binary outcome predictors.
    Instead of guessing numbers, they answer *yes* or *no* questions or make *0*/*1*
    predictions. For instance, if you want to predict whether a student will pass
    or fail an exam, a logistic regression model would consider factors such as the
    student’s study hours, previous test scores, and attendance to determine the likelihood
    of passing the exam.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归模型**：这些模型是二元结果预测器。它们不是猜测数字，而是回答“是”或“否”的问题，或者做出*0*/*1*的预测。例如，如果你想预测一个学生是否会通过或失败考试，逻辑回归模型会考虑诸如学生的学习时间、之前的考试成绩和出勤率等因素，以确定通过考试的可能性。'
- en: '**Decision tree models**: These are used to make predictions based on a tree-like
    structure. Think of it like a decision-making tree for predictions. You start
    at the top and follow branches based on known features. At each branch, you make
    a decision based on a feature and keep going until you reach a final prediction
    at the leaves. It’s a step-by-step process to find the most likely outcome.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树模型**：这些模型用于根据树状结构进行预测。可以将其想象为预测的决策树。你从顶部开始，根据已知特征跟随分支。在每个分支上，你根据一个特征做出决定，并继续前进，直到在叶子节点达到最终的预测。这是一个逐步的过程，用于找到最可能的结局。'
- en: '**Random forest models**: These are ensembles of decision trees. Groups of
    decision trees work together. Each tree is trained on a different part of the
    data. To make a prediction, all the trees give their answers, and their predictions
    are averaged to get the final result. It’s like taking the opinions of multiple
    trees to make a more accurate guess.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林模型**：这些是决策树的集合。一组决策树协同工作。每棵树都在数据的不同部分上训练。为了做出预测，所有树都给出它们的答案，并将它们的预测平均以得到最终结果。这就像汇集了多棵树的看法，以做出更准确的猜测。'
- en: '**Gradient boosting models**: These are also ensembles of decision trees, These
    are groups of decision trees that work together, but here, unlike in a random
    forest model, the trees are trained one after the other, and each tree tries to
    fix the mistakes of the previous one. They learn from each other’s errors and
    become better as a team. It’s like a learning process where they keep improving
    until they make good predictions together.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度提升模型**：这些也是决策树的集成，这些是共同工作的决策树组。在这里，与随机森林模型不同，树是依次训练的，并且每一棵树都试图纠正前一棵树的错误。它们从彼此的错误中学习，并作为一个团队变得更好。这就像一个学习过程，它们不断改进，直到它们一起做出好的预测。'
- en: '**Neural network models**: These are complex, multi-layered models that are
    able to learn complex patterns in data. These models are capable of learning intricate
    patterns in data. They operate using a process of information analysis, discovering
    underlying correlations similar to the functioning of interconnected neurons in
    the human brain. Through extensive training and exposure to diverse datasets,
    the model refines its ability to decipher complex patterns, making it proficient
    in uncovering intricate relationships within new data.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经网络模型**：这些是复杂的多层模型，能够学习数据中的复杂模式。这些模型能够学习数据中的复杂模式。它们通过信息分析的过程运行，发现类似于人脑中相互连接的神经元的功能。通过广泛的训练和接触多样化的数据集，模型提高了其解析复杂模式的能力，使其擅长在新数据中揭示复杂的关系。'
- en: '**Support vector machines** (**SVMs**): SVMs are powerful classifiers, acting
    like incredibly intelligent dividers. Imagine a 3D space with points representing
    different things. SVMs determine the most optimal way to draw a line or plane,
    called a hyperplane, that perfectly separates two distinct groups of points. It’s
    as if they possess an extraordinary ability to find the perfect boundary, ensuring
    the two groups are kept as far apart as possible, such as drawing an invisible
    but flawless line that keeps everything perfectly organized on each side.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVMs**）：SVMs 是强大的分类器，就像极其聪明的分隔器。想象一个三维空间，其中有点代表不同的事物。SVMs 确定绘制线或平面（称为超平面）的最优方式，以完美地分隔两组不同的点。这就像它们拥有一种非凡的能力来找到完美的边界，确保两组点尽可能远地分开，例如绘制一条无形但完美无瑕的线，将每一边上的事物组织得井井有条。'
- en: These are just a few examples of the types of models that can be used with BYOM
    in Amazon Redshift. In general, any model that can be represented as a set of
    model artifacts and a prediction function can be used with BYOM in Redshift.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是 Amazon Redshift 中可以使用 BYOM 的模型类型的一些示例。一般来说，任何可以表示为模型工件集和预测函数的模型都可以在 Redshift
    中使用 BYOM。
- en: We have learned what Redshift ML BYOM is and its benefits. In the next section,
    you will create a BYOM local inference model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了 Redshift ML BYOM 及其优势。在下一节中，你将创建一个 BYOM 本地推理模型。
- en: Creating the BYOM local inference model
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 BYOM 本地推理模型
- en: With BYOM local inference, the machine learning model and its dependencies are
    packaged into a group of files and deployed to Amazon Redshift where the data
    is stored, allowing users to make predictions on the stored data. Model artifacts
    and their dependencies are created when a model is trained and created on the
    Amazon SageMaker platform. By deploying the model directly onto the Redshift service,
    you are not moving the data over the network to another service. Local inference
    can be useful for scenarios where the data is sensitive or requires low latency
    predictions.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 BYOM 本地推理，机器学习模型及其依赖项被打包成一组文件，并部署到存储数据的 Amazon Redshift，使用户能够对存储的数据进行预测。当在
    Amazon SageMaker 平台上训练和创建模型时，会创建模型工件及其依赖项。通过直接将模型部署到 Redshift 服务，你不需要将数据通过网络移动到另一个服务。本地推理对于数据敏感或需要低延迟预测的场景非常有用。
- en: Let’s start working on creating the BYOM local inference model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始创建 BYOM 本地推理模型的工作。
- en: Creating a local inference model
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建本地推理模型
- en: 'To create the BYOM local inference model, the first step involves training
    and validating an Amazon SageMaker model. For this purpose, we will train and
    validate an XGBoost linear regression machine learning model on Amazon SageMaker.
    Follow the instructions found here to create the Amazon SageMaker model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 BYOM 本地推理模型，第一步涉及在 Amazon SageMaker 上训练和验证一个 Amazon SageMaker 模型。为此，我们将在
    Amazon SageMaker 上训练和验证一个 XGBoost 线性回归机器学习模型。按照以下说明创建 Amazon SageMaker 模型：
- en: '[https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb)'
- en: After you have followed the instructions given at the preceding URL, validate
    the model by running prediction functions. Now, let’s move on to the next steps.
    After successfully generating the predictions, we will create the Redshift ML
    model. Using the same notebook, let’s run a few commands to set some parameters.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在遵循了前面URL提供的说明后，通过运行预测函数来验证模型。现在，让我们继续下一步。在成功生成预测后，我们将创建Redshift ML模型。使用相同的笔记本，让我们运行一些命令来设置一些参数。
- en: Creating the model and running predictions on Redshift
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Redshift上创建模型并运行预测
- en: Now, validate the model by running prediction functions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在通过运行预测函数来验证模型。
- en: With the model trained and validated in SageMaker, it’s time to import it into
    Redshift. In the next section, using the same SageMaker notebook, we will set
    up the required parameters to build the Redshift `CREATE MODEL` statement. You
    will use this statement in Query Editor v2 to create your model in Redshift ML,
    enabling you to perform local inference on the data stored in the Redshift cluster
    with the integrated SageMaker model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker中训练和验证了模型后，现在是时候将其导入到Redshift中。在下一节中，我们将使用相同的SageMaker笔记本设置构建Redshift
    `CREATE MODEL`语句所需的参数。你将使用此语句在Query Editor v2中创建你的Redshift ML模型，使你能够使用集成的SageMaker模型在Redshift集群中存储的数据上执行本地推理。
- en: Setting up the parameters
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置参数
- en: 'Before setting up the parameters, run the following command in Query Editor
    v2 to create the schema for this chapter:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置参数之前，请在Query Editor v2中运行以下命令以创建本章的架构：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The first step of this process is setting up the following parameter values:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程的第一个步骤是设置以下参数值：
- en: '`S3_BUCKET` is used to store Redshift ML artifacts.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`S3_BUCKET`用于存储Redshift ML工件。'
- en: '`MODEL_PATH` is the S3 location of the model artifact of the Amazon SageMaker
    model. Optionally, you can print `model_data` using the `print` function in Python
    and look at the artifact location.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MODEL_PATH`是Amazon SageMaker模型工件在S3的位置。可选地，你可以使用Python中的`print`函数打印`model_data`并查看工件位置。'
- en: '`REDSHIFT_IAM_ROLE` is the cluster role:'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`REDSHIFT_IAM_ROLE`是集群角色：'
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, we will generate the `CREATE MODEL` statement that you are going to run
    on Redshift.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将生成你将在Redshift上运行的`CREATE MODEL`语句。
- en: Generating the CREATE MODEL statement
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成CREATE MODEL语句
- en: 'Execute the code provided here in a Jupyter notebook to automatically generate
    the `CREATE` `MODEL` statement:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在Jupyter笔记本中执行此处提供的代码以自动生成`CREATE` `MODEL`语句：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The output of the preceding statement is the `CREATE MODEL` statement that you
    are going to run in Query Editor v2\. Please copy the statement and head over
    to Query Editor v2 to perform the remaining steps.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 前述语句的输出是你要在Query Editor v2中运行的`CREATE MODEL`语句。请复制该语句并前往Query Editor v2以执行剩余步骤。
- en: Running local inference on Redshift
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Redshift上运行本地推理
- en: 'The following is the `CREATE MODEL` statement. You should have a similar one
    generated, where `FROM`, `IAM_ROLE`, and `S3_BUCKET` have different values:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`CREATE MODEL`语句。你应该生成一个类似的语句，其中`FROM`、`IAM_ROLE`和`S3_BUCKET`有不同的值：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding command, the `FROM` clause takes `model_data` as input, which
    contains the SageMaker model artifacts. When this command is run, Amazon Redshift
    ML compiles the model, deploys it to Redshift, and creates a `predict_abalone_age`
    prediction function, which is used in an SQL command to generate predictions natively
    in Redshift.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的命令中，`FROM`子句以`model_data`作为输入，其中包含SageMaker模型工件。当运行此命令时，Amazon Redshift
    ML编译模型，将其部署到Redshift，并创建一个`predict_abalone_age`预测函数，该函数用于SQL命令以在Redshift中本地生成预测。
- en: 'Once the `CREATE MODEL` statement is completed, you can use the `show model`
    command to see the model’s status:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成`CREATE MODEL`语句，你可以使用`show model`命令来查看模型的状态：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here is the output:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是输出结果：
- en: '![Figure 11.1 – Local inference model metadata](img/B19071_11_01.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图11.1 – 本地推理模型元数据](img/B19071_11_01.jpg)'
- en: Figure 11.1 – Local inference model metadata
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 – 本地推理模型元数据
- en: Notice that **Model State** is **READY** and **S3 Model Path** is the one we
    gave when creating the model. **Inference Type** is **Local**, which means the
    model type is local inference.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意**模型状态**为**就绪**，**S3模型路径**是我们创建模型时给出的。**推理类型**为**本地**，这意味着模型类型是本地推理。
- en: We have successfully created the local inference model; now, let’s prepare a
    test dataset to test whether the local inference is working without any issues.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功创建本地推理模型；现在，让我们准备一个测试数据集以测试本地推理是否运行无任何问题。
- en: Data preparation
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: Load the test data from the S3 bucket to a Redshift table to test our local
    inference model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将测试数据从S3存储桶加载到Redshift表以测试我们的本地推理模型。
- en: Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please update `IAM_ROLE`. Do not change the S3 bucket location.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 请更新`IAM_ROLE`。不要更改S3存储桶位置。
- en: 'Run the following command to create the table and load the data:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令创建表并加载数据：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Sample the test table to make sure the data is loaded:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对测试表进行采样以确保数据已加载：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is the sample dataset:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是样本数据集：
- en: '![Figure 11.2 – Showing sample records from the test dataset](img/B19071_11_02.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图11.2 – 显示测试数据集的样本记录](img/B19071_11_02.jpg)'
- en: Figure 11.2 – Showing sample records from the test dataset
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 – 显示测试数据集的样本记录
- en: Now that we have loaded the test data, let’s run the `SELECT` command, which
    invokes the `predict_abalone_age` function.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已加载测试数据，让我们运行`SELECT`命令，该命令调用`predict_abalone_age`函数。
- en: Inference
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推理
- en: 'Now, call the prediction function that was created as part of the `CREATE`
    `MODEL` statement:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，调用作为`CREATE` `MODEL`语句一部分创建的预测函数：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here’s the output of the predictions generated using local inference:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用本地推理生成的预测结果的输出：
- en: '![Figure 11.3 – Showing actual versus predicted values](img/B19071_11_03.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图11.3 – 显示实际值与预测值](img/B19071_11_03.jpg)'
- en: Figure 11.3 – Showing actual versus predicted values
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 – 显示实际值与预测值
- en: We have successfully trained and validated a SageMaker model and then deployed
    it to Redshift ML. We also generated predictions using the local inference function.
    This demonstrates Redshift’s BYOM local inference feature.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功训练和验证了一个SageMaker模型，并将其部署到Redshift ML。我们还使用本地推理函数生成了预测。这展示了Redshift的BYOM本地推理功能。
- en: In the next section, you are going to learn about the BYOM remote inference
    feature.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将了解BYOM远程推理功能。
- en: BYOM using a SageMaker endpoint for remote inference
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SageMaker端点进行远程推理的BYOM
- en: In this section, we will explore how to create a BYOM remote inference for an
    Amazon SageMaker Random Cut Forest model. This means you are bringing your own
    machine learning model, which is trained on data outside of Redshift, and using
    it to make predictions on data stored in a Redshift cluster using an endpoint.
    In this method, to use BYOM for remote inference, a machine learning model is
    trained, an endpoint is created in Amazon SageMaker, and then the endpoint is
    accessed from within a Redshift query using SQL functions provided by the Amazon
    Redshift ML extension.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨如何为Amazon SageMaker Random Cut Forest模型创建一个BYOM远程推理。这意味着您正在引入自己的机器学习模型，该模型在Redshift之外的数据上训练，并使用它通过端点对存储在Redshift集群中的数据进行预测。在此方法中，要使用BYOM进行远程推理，需要训练一个机器学习模型，在Amazon
    SageMaker中创建一个端点，然后使用Amazon Redshift ML扩展提供的SQL函数从Redshift查询中访问该端点。
- en: 'This method is useful when Redshift ML does not natively support models, for
    example, a Random Cut Forest model. You can read more about Random Cut Forest
    here: [https://tinyurl.com/348v8nnw](https://tinyurl.com/348v8nnw).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当Redshift ML原生不支持模型时，此方法很有用，例如Random Cut Forest模型。您可以在此处了解更多关于Random Cut Forest的信息：[https://tinyurl.com/348v8nnw](https://tinyurl.com/348v8nnw)。
- en: To demonstrate this feature, you will first need to follow the instructions
    found in this notebook ([https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.ipynb](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.ipynb))
    to create a Random Cut Forest machine learning model using Amazon SageMaker to
    detect anomalies. Please complete the Amazon SageMaker model training and validate
    the model to make sure the endpoint is working and then proceed to the next section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示此功能，您首先需要遵循此笔记本中的说明（[https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.ipynb](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.ipynb)）使用
    Amazon SageMaker 创建一个用于检测异常的随机切割森林机器学习模型。请完成 Amazon SageMaker 模型训练并验证模型，以确保端点正在运行，然后继续下一部分。
- en: Creating BYOM remote inference
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 BYOM 远程推理
- en: Once you have validated that the SageMaker endpoint is deployed and working
    properly, let’s define a `CREATE MODEL` reference point inside Redshift by specifying
    the SageMaker endpoint. Using the same notebook, let’s build the `CREATE MODEL`
    statement in Jupyter and run it in Query Editor v2.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您验证了 SageMaker 端点已部署且运行正常，让我们在 Redshift 中通过指定 SageMaker 端点定义一个 `CREATE MODEL`
    参考点。使用相同的笔记本，让我们在 Jupyter 中构建 `CREATE MODEL` 语句并运行它。
- en: Setting up the parameters
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置参数
- en: 'Let’s start by setting up the parameters:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先设置参数：
- en: '`S3_Bucket` is used to store Redshift ML artifacts'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`S3_Bucket` 用于存储 Redshift ML 工件'
- en: '`SAGEMAKER_ENDPOINT` is the model endpoint on the SageMaker side to run inferences
    against'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SAGEMAKER_ENDPOINT` 是 SageMaker 侧的模型端点，用于运行推理'
- en: '`REDSHIFT_IAM_ROLE` is the cluster role:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`REDSHIFT_IAM_ROLE` 是集群角色：'
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please update `REDSHIFT_IAM_ROLE` with your Redshift cluster role.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请使用您的 Redshift 集群角色更新 `REDSHIFT_IAM_ROLE`。
- en: Generating the BYOM remote inference command
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成 BYOM 远程推理命令
- en: 'Let’s generate the `CREATE MODEL` statement by running the following code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过运行以下代码生成 `CREATE MODEL` 语句：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You have finished the work with the Jupyter notebook. Now you have a pre-trained
    model in Amazon SageMaker and the next step is to bring it into Redshift ML. To
    do so, access Query Editor v2, connect to the Serverless endpoint, and run the
    commands outlined next.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您已完成 Jupyter 笔记本的工作。现在您在 Amazon SageMaker 中有一个预训练模型，下一步是将它带入 Redshift ML。为此，访问查询编辑器
    v2，连接到无服务器端点，并运行以下命令。
- en: 'In Query Editor v2, run the following command:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器 v2 中，运行以下命令：
- en: '[PRE10]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Retrieve the model metadata by running the `show` `model` command:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行 `show` `model` 命令检索模型元数据：
- en: '[PRE11]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 11.4 – Remote inference model metadata](img/B19071_11_04.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – 远程推理模型元数据](img/B19071_11_04.jpg)'
- en: Figure 11.4 – Remote inference model metadata
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 远程推理模型元数据
- en: Notice that in the model metadata, the **Model State** parameter is set to **READY**,
    indicating that the model is deployed. The **Endpoint** name is **randomcutforest-2022-12-31-03-48-13-259**.
    **Inference Type** is set to **Remote** inference. When this model is run, Redshift
    ML sends data stored in Redshift in batches to SageMaker, where inferences are
    generated. Generated predicted values are then sent back to Redshift, which are
    eventually presented to the user.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在模型元数据中，**模型状态**参数设置为 **READY**，表示模型已部署。**端点**名称为 **randomcutforest-2022-12-31-03-48-13-259**。**推理类型**设置为
    **远程**推理。当运行此模型时，Redshift ML 将存储在 Redshift 中的数据批量发送到 SageMaker，在那里生成推理。生成的预测值随后被发送回
    Redshift，最终呈现给用户。
- en: We have successfully deployed the model. In the next section, let’s run predictions.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功部署模型。在下一节中，我们将运行预测。
- en: The data preparation script
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据预处理脚本
- en: 'The following code snippet shows the data preparation script that you will
    need to run on Redshift. We will create the table that will be used to run inference
    on:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了您需要在 Redshift 上运行的预处理脚本。我们将创建用于运行推理的表：
- en: '[PRE12]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please update the `IAM_ROLE` parameter with your Redshift cluster attached role.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 请使用您附加到 Redshift 集群的 IAM 角色更新 `IAM_ROLE` 参数。
- en: 'Sample the data to make sure data is loaded:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 样本数据以确保数据已加载：
- en: '[PRE13]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here’s the output:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '![Figure 11.5 – Showing sample records from the test dataset](img/B19071_11_05.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.5 – 显示测试数据集的样本记录](img/B19071_11_05.jpg)'
- en: Figure 11.5 – Showing sample records from the test dataset
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 – 显示测试数据集的样本记录
- en: Now that we have the remote inference endpoint and test dataset, let’s invoke
    the prediction function.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了远程推理端点和测试数据集，让我们调用预测函数。
- en: Computing anomaly scores
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算异常分数
- en: 'Now, let’s compute the anomaly scores from the entire taxi dataset:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从整个出租车数据集中计算异常分数：
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following is the output of the remote inference predictions:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的输出是远程推理预测的结果：
- en: '![Figure 11.6 – Showing remote function prediction values](img/B19071_11_06.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.6 – 显示远程函数预测值](img/B19071_11_06.jpg)'
- en: Figure 11.6 – Showing remote function prediction values
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 – 显示远程函数预测值
- en: The preceding output shows the anomalous score for different days and the number
    of passengers.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输出显示了不同日期的异常分数和乘客数量。
- en: 'In the following code snippet, we will print any data points with scores greater
    than 3 and standard deviations (approximately the 99.9th percentile) from the
    mean score:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码片段中，我们将打印出任何得分大于 3 且标准差（大约是平均得分的 99.9 百分位）的数据点：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 11.7 – Showing unacceptable anomaly scores](img/B19071_11_07.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.7 – 显示不可接受的异常分数](img/B19071_11_07.jpg)'
- en: Figure 11.7 – Showing unacceptable anomaly scores
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7 – 显示不可接受的异常分数
- en: In the preceding results, we see that some days’ ridership is way higher and
    our remote inference function is flagging them as anomalous. This concludes the
    section on bringing remote inference models into Redshift.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的结果中，我们看到某些天的乘客量远远高于我们的远程推理函数，并将它们标记为异常。这标志着将远程推理模型引入 Redshift 的部分结束。
- en: Summary
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the benefits and use cases of Amazon Redshift
    ML BYOM for local and remote inference. We created two SageMaker models and then
    imported them into Redshift ML as local inference and remote inference model types.
    We loaded test datasets in Redshift and then we ran the prediction functions and
    validated both types. This demonstrates how Redshift simplifies and empowers the
    business community to perform inference on new data using models created outside.
    This method speeds up the delivery of machine learning models created outside
    of Redshift to the data warehouse team.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了 Amazon Redshift ML BYOM 在本地和远程推理方面的优势和用例。我们创建了两个 SageMaker 模型，然后将它们导入
    Redshift ML 作为本地推理和远程推理模型类型。我们在 Redshift 中加载了测试数据集，然后运行了预测函数并验证了这两种类型。这展示了 Redshift
    如何简化并赋予商业社区使用外部创建的模型进行数据推理的能力。这种方法加快了在 Redshift 外部创建的机器学习模型交付给数据仓库团队的速度。
- en: In the next chapter, you are going to learn about Amazon Forecast, which enables
    you to perform forecasting using Redshift ML.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将了解 Amazon Forecast，它使你能够使用 Redshift ML 进行预测。
