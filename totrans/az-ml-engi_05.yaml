- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure Automated Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Automated Machine Learning**, also referred to as AutoML, is the automation
    of the iterative and time-consuming process of machine learning model development.
    AutoML enables data scientists and machine learning engineers to develop high-performing
    models in an efficient way allowing them to scale and build the best model quickly.
    Data scientists can rely on AutoML to perform tedious model development tasks
    such as feature engineering, algorithm selection, hyperparameter tuning, and model
    evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Azure AutoML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Featurization concepts in AML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AutoML using AMLS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AutoML using AML Python SDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parsing your AutoML results via AML and the AML SDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to see how to create an automated machine learning
    model from start to end with step-by-step procedures.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to access your workspace, recall the steps from the previous chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://ml.azure.com](https://ml.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your workspace name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the workspace **User** interface on the left-hand side, click **Compute**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the **compute** screen, select your compute instance and select **Start**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Start compute](img/B18003_05_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Start compute
  prefs: []
  type: TYPE_NORMAL
- en: Your compute instance will change from having a **Stopped** status to a **Starting**
    status.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B18003_02.xhtml#_idTextAnchor038), *Working with Data in AMLS*,
    we cloned the Git repository – if you have not already done so, continue to follow
    the steps provided here. If you have already cloned the repository, skip to *step
    7*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the Terminal on your compute instance. Note the path will include your
    user in the directory. Type the following into the Terminal to clone the sample
    notebooks into your working directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Clicking on the refresh icon shown in *Figure 5**.2* will update and refresh
    the notebooks displayed on your screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Refresh](img/B18003_05_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Refresh
  prefs: []
  type: TYPE_NORMAL
- en: 'Review the notebooks in your `Azure-Machine-Learning-Engineering` directory.
    This will display the files cloned into your working directory as shown in *Figure
    5**.3*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Azure-Machine-Learning-Engineering](img/B18003_05_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Azure-Machine-Learning-Engineering
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s learn about what **Azure Machine Learning** (**AML**) AutoML is,
    some of its benefits, and how to consume them.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Azure AutoML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AutoML is a powerful solution that enables not only data scientists but also
    citizen data scientists to build machine learning models supporting a variety
    of use cases. AutoML currently supports classification, regression, time-series
    forecasting, and computer vision in preview. Classification involves a response
    variable that identifies a category. The input training dataset will be leveraged
    to build a model to predict which category a new sample will fall into. Leveraging
    the Titanic dataset, we can leverage the classification model to predict whether
    a passenger will survive on the Titanic. In addition to supporting classification
    model creation, AutoML is also able to generate a regression model. A regression
    model will provide a continuous value as the output of the model. An example of
    a regression model would be to predict gas prices or taxi fares. AutoML can also
    predict values based on time with time-series forecasting. Not only this but AutoML
    also supports image classification, object detection, and instance segmentation
    using the **AML Studio** (**AMLS**) Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: While AMLS supports a variety of AutoML tasks, the AMLS Python SDK supports
    a variety of features for developers and data scientists to leverage that are
    not currently available via AMLS alone.
  prefs: []
  type: TYPE_NORMAL
- en: With the Python SDK, not only do we find support for computer vision tasks but
    also for viewing featurization information, enabling voting ensemble models, showing
    the best model based on non-primary metrics, as well as enabling and disabling
    **Open Neural Network Exchange** (**ONNX**) model compatibility.
  prefs: []
  type: TYPE_NORMAL
- en: Featurization concepts in AML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to provide the best model, regardless of whether AutoML is being leveraged,
    an important step in model creation is the engineering features. AutoML in AMLS
    will default to leverage featurization. This can be disabled in the UI as well
    as the SDK if the feature engineering step has already been accomplished. These
    featurization transformations on your dataset can not only be enabled or disabled
    but they can also be customized or excluded from specific columns. There are several
    featurization steps applied to your dataset based on the type of column, and the
    column’s data type.
  prefs: []
  type: TYPE_NORMAL
- en: During training, AutoML leverages scaling or normalization to ensure model performance.
    AutoML leverages a variety of techniques, including scaling to unit variance,
    scaling by quantile range, scaling by the maximum absolute value, scaling by a
    column’s minimum and maximum, by applying **Principle Component Analysis** (**PCA**)
    for dimensionality reduction, **Singular Value Decomposition** (**SVD**) for dimensionality
    reduction, as well as rescaling each sample to a norm of 1.
  prefs: []
  type: TYPE_NORMAL
- en: Provided that featurization is enabled, certain columns will be dropped during
    the training process. Columns that have no variance – meaning all rows have the
    same value – or rows with high cardinality – meaning they have a very high variance,
    such as a column with GUID values – will be dropped. If a column has a numeric
    value but a low variance, AutoML will transform that value into a categorical
    feature and apply one-hot encoding. If a categorical column has high variance,
    one-hot hash encoding will be leveraged.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML will also generate a k-means clustering model for each numeric column.
    Each sample will have its distance from the centroid of the cluster added to the
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Often, datasets will include missing values. AutoML will replace missing values
    with averages if the column is numeric or impute values using the most common
    value for a given column if it is categorical. This can actually be customized
    by leveraging a `FeaturizationConfig` in AutoML. The imputer for missing values
    can replace values with the mean, median, or mode of a value.
  prefs: []
  type: TYPE_NORMAL
- en: For features that are date-time values, additional features will be generated
    including year, month, day, day of the year, day of the week, quarter, hour, minute,
    and second.
  prefs: []
  type: TYPE_NORMAL
- en: Specific to the forecasting task, the `TimeIndexFeaturization` class is leveraged
    to generate many different features. Examples include an integer value specifying
    whether it is before or after a certain date (July 1st, for example), the year,
    calendar quarter, calendar month, day, hour, minute, second, an a.m. or p.m. indicator,
    the day of the week, the day of the quarter (1 through 92), the day of the year
    (1 through 366), as well as an ISO week and year defined by the ISO 8601 standard.
  prefs: []
  type: TYPE_NORMAL
- en: For features that are text, term frequency will be added based on trigrams,
    bigrams, and unigrams. Text features are converted into document feature vectors.
    AutoML can be configured to leverage **Bidirectional Encoder Representations from
    Transformers** (**BERT**) during the featurization process by enabling deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML not only can handle a variety of featurization steps to prepare models
    for training but can also handle classification, regression, and time-series forecasting
    directly in AMLS and accomplish these same modeling tasks, as well as compute
    vision tasks through the AML Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore how to leverage AMLS to accomplish classification
    for the well-known Titanic dataset. The dataset link will be available in the
    book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML using AMLS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier in the chapter, there are two ways to use AutoML in AML.
    For citizen data scientists or data scientists who prefer a no-code approach,
    AMLS can be used; for data scientists with coding experience, the AML Python SDK
    can be used. In this section, we will show you how to use AMLS to train a classification
    model on your Titanic dataset with AutoML to predict whether a passenger would
    survive the Titanic disaster or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please sign in to AMLS at [https://ml.azure.com](https://ml.azure.com) and
    follow these instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: Select your subscription and the workspace you have been using throughout the
    book.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the left-hand side of the studio, click on **Automated ML** as shown in
    *Figure 5**.4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Importing AutoMLConfig](img/B18003_05_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Importing AutoMLConfig
  prefs: []
  type: TYPE_NORMAL
- en: 'Select `titanic.csv` from your local computer to Azure as shown in *Figure
    5**.5*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Creating a new dataset by uploading titanic.csv from your local
    computer](img/B18003_05_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Creating a new dataset by uploading titanic.csv from your local
    computer
  prefs: []
  type: TYPE_NORMAL
- en: 'Provide basic information for the dataset as shown in *Figure 5**.6*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Providing basic information for the dataset](img/B18003_05_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – Providing basic information for the dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next screen, click on `titanic.csv` as shown in *Figure 5**.7*. The
    dataset is available in the GitHub repo for this book:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Providing the location of stored data files](img/B18003_05_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – Providing the location of stored data files
  prefs: []
  type: TYPE_NORMAL
- en: 'Once uploaded, the next screen will show you the settings and preview based
    on the upload file. The only setting you need to change is under **Column headers**,
    which you should set to **Only first file has headers** as shown in *Figure 5**.8*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Dataset preview](img/B18003_05_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Dataset preview
  prefs: []
  type: TYPE_NORMAL
- en: 'The next screen will show the dataset’s schema, which has been autodetected
    from the file as shown in *Figure 5**.9*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Dataset settings](img/B18003_05_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Dataset settings
  prefs: []
  type: TYPE_NORMAL
- en: 'The last step is to review and confirm the details and click on **Create**
    as shown in *Figure 5**.10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.10 – Reviewing and confirming the creation of the dataset](img/B18003_05_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Reviewing and confirming the creation of the dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be taken back to the list of the datasets. You should see your Titanic
    dataset, which we named **training**, at the top of the list. Go ahead, select
    it, and click on **Next** as shown in *Figure 5**.11*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Select the training dataset and clicking on Next](img/B18003_05_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Select the training dataset and clicking on Next
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, you need to create an experiment for your AutoML run and then
    select the target column, sometimes called the *dependent variable*, and lastly,
    select a compute cluster for the model training as shown in *Figure 5**.12*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Creating a new AutoML experiment and selecting the target column
    and compute cluster](img/B18003_05_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Creating a new AutoML experiment and selecting the target column
    and compute cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next screen, you can select the machine learning task. AutoML has auto-detected
    the task based on the target column. In this case, it should be **Classification**
    as shown in *Figure 5**.13*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Selecting the machine learning task (for example, in this case,
    Classification)](img/B18003_05_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Selecting the machine learning task (for example, in this case,
    Classification)
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click on `0.5` hours). Click **Save** to exit as shown in *Figure 5**.14*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Configuring settings for the training job](img/B18003_05_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – Configuring settings for the training job
  prefs: []
  type: TYPE_NORMAL
- en: 'Click `3`. For the `10`, and finally, click on **Finish** as shown in *Figure
    5**.15*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Setting the validation type and test dataset](img/B18003_05_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – Setting the validation type and test dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the model training is done, you will be presented with a screen summarizing
    the training statistics, such as the duration of the training, a link to the **training**
    dataset, and a summary of the best-performing model, with the name of its algorithm
    and its performance metric (for example, **AUC weighted**) as shown in *Figure
    5**.16*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Model and run summary after training is completed](img/B18003_05_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.16 – Model and run summary after training is completed
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have seen how to leverage AutoML through AMLS, take a moment to
    review the output not only in the **Details** section as shown in *Figure 5**.16*
    but also review each tab and explore the wealth of information provided during
    an AutoML experiment run.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will explore leveraging AutoML through the AML Python SDK. The AML
    Python SDK provides fine-grained control over your experiment, as we will see
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML using the AML Python SDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have seen how to leverage AutoML inside AMLS, we will explore creating
    a model leveraging the AML Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in the chapter, in *Introduction to AutoML*, we cloned our sample notebooks
    to leverage this material. For this chapter, note that there is a single notebook
    titled `Chapter5_Titanic_AutoML`. The initial code should look familiar, as the
    preparation of the dataset has not changed. However, when we run the experiment,
    we will now be leveraging an AutoML experiment.
  prefs: []
  type: TYPE_NORMAL
- en: In order to run an AutoML experiment, we will need to import `AutoMLConfig`
    as shown in *line 8* of the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s `AutoMLConfig` being imported with the Python SDK:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Importing AutoMLConfig](img/B18003_05_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.17 – Importing AutoMLConfig
  prefs: []
  type: TYPE_NORMAL
- en: As part of an AutoML experiment, we are required to specify a training dataset,
    but we are not required to specify a validation or testing dataset. However, we
    can specify the training and validation datasets, and the test datasets in preview.
    In our sample, we will separate the dataset into a training, test, and validation
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging the `train_test_split` method from `sklearn`, we will break the dataset
    into three datasets used for training, validation, and testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now look into how we can split the data for training the model and also
    test the model to analyze the accuracy of the model built:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is going to split the dataset between model training and
    model evaluation. We are also specifying which column is used for prediction –
    in the following case, it’s `Survived`. Then, we will print the output to validate
    whether the split worked or not. Here’s the dataset being split for model training,
    testing, and validation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Dataset splitting](img/B18003_05_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.18 – Dataset splitting
  prefs: []
  type: TYPE_NORMAL
- en: Once the dataset has been split, we can upload the datasets from our local directory
    where they have been saved in the `automl_train` folder, and when placed into
    blob storage, they will be placed into a directory called `titanic-auto-ml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, the directory is uploaded into the default data
    store:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Uploading datasets to the data store](img/B18003_05_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.19 – Uploading datasets to the data store
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that the data is now in blob storage, we can leverage the files to create
    tabular datasets with the AML Python SDK, noting their location in blob storage
    as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Creating AML tabular datasets](img/B18003_05_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.20 – Creating AML tabular datasets
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the AML Python SDK, we can create an experiment as shown in the following
    code block in *line 4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.21 – Creating an Azure ML experiment](img/B18003_05_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.21 – Creating an Azure ML experiment
  prefs: []
  type: TYPE_NORMAL
- en: An AutoML experiment can be run on a compute instance but given the duration
    of an experiment will be longer than we have seen up to this point, we will run
    it on a compute cluster. The following code shows how to create a compute cluster
    as we saw in [*Chapter 1*](B18003_01.xhtml#_idTextAnchor020)*, Introducing the
    Azure Machine* *Learning Service*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will create a compute cluster for us to write out code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.22 – Compute cluster creation for running the AML experiment run](img/B18003_05_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.22 – Compute cluster creation for running the AML experiment run
  prefs: []
  type: TYPE_NORMAL
- en: For an AutoML experiment, we are able to provide fine-grained control over the
    experiment that is being run with the Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: 'An AutoML experiment run through the SDK can specify its behavior during the
    experiment run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.23 – AutoML experiment settings](img/B18003_05_023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.23 – AutoML experiment settings
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 5**.23*, we are able to specify `experiment_time_hours`.
    If no value is provided, the experiment run will time out after 6 days. `enable_early_stopping`,
    which defaults to `True`, will stop the experiment early if the model is not improving
    after `n_interations`. This behavior ensures that at a minimum, 20 iterations
    are run before an experiment run is stopped early.
  prefs: []
  type: TYPE_NORMAL
- en: '`iteration_timeout_minutes` is the number of minutes each iteration can run
    before it is terminated. If it is not specified, a default value of 1 month is
    used. Another setting that can be configured is `max_concurrent_iterations`. An
    AML compute cluster can handle a single iteration per node. Specifying this value
    will expand the number of active nodes in a given cluster. If `max_concurrent_iterations`
    is greater than the node count in a given cluster, then the experiment runs will
    be queued and will execute once a node is available within a cluster. Setting
    `max_cores_per_iteration` to a value of `–1` indicates that all the cores available
    from the compute running the iteration should be leveraged. This value defaults
    to `1`. It is acceptable to provide values of `–1`, `1`, or a number that is less
    than or equal to the number of cores that are on the compute running the training
    experiment.'
  prefs: []
  type: TYPE_NORMAL
- en: We can specify `n_cross_validations`, and that will ensure the validation dataset
    will be extracted from the training data. However, in our experiment, we are explicitly
    passing a validation dataset, so this is commented out in *line 7* of *Figure
    5**.23*. If neither `n_cross_validations` is set nor is a validation dataset provided,
    AutoML will use its own validation techniques. If neither is provided and an AutoML
    experiment run is working with a dataset greater than 20,000 rows, 10% of the
    data will be used as a validation dataset. If a dataset is smaller than 20,000
    rows, then cross-validation is leveraged. If the dataset is less than 1,000 rows,
    10 folds are used for cross-validation, and if the dataset is between 1,000 and
    20,000 rows, then 3 folds are used for cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: '`primary_metric` is the metric used to evaluate the model. Each task type has
    a list of valid metrics. The code here provides a list of the metrics available
    to use for a classification model evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24 – Primary metrics for classification](img/B18003_05_024.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.24 – Primary metrics for classification
  prefs: []
  type: TYPE_NORMAL
- en: Another property of an AutoML experiment run that can be set is featurization.
    The value here can either be set to `auto`, `off`, or `FeaturizationConfig`. If
    the value of `FeaturizationConfig` is specified, you can provide custom featurization,
    which will allow you to specify column transformer properties that support an
    imputer using the mean, median, or mode, as well as a one-hot hash encoding. For
    our example, we will leave the featurization as `auto`.
  prefs: []
  type: TYPE_NORMAL
- en: By setting the value of verbosity in *Figure 5**.23*, we specify how granular
    the information logged in a given experiment will be. Keeping the logging at the
    `INFO` level will provide fine-grained logs inside the run of an AutoML experiment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing that needs to be done is creating the `AutoMLConfig` object
    for running the experiment. There are many properties to support an AutoML experiment
    run. The first property we will review is the property *task*. The supported task
    types include classification, regression, and forecasting. Currently, in public
    preview, multi-class and multi-label image classification, object detection, and
    instance segmentation are available. For our task type, we will select `''classification''`
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25 – AutoMLConfig object](img/B18003_05_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.25 – AutoMLConfig object
  prefs: []
  type: TYPE_NORMAL
- en: The `debug_log` property specifies the log file to which the debug information
    is written. If not specified, the value of `'automl.log'` is used as the log file
    name.
  prefs: []
  type: TYPE_NORMAL
- en: '`compute_target` is specified, which can be either a compute instance or a
    compute cluster. Leveraging a compute cluster enables concurrent runs for an AutoML
    experiment run, which cannot be leveraged by a compute instance.'
  prefs: []
  type: TYPE_NORMAL
- en: '`blocked_models` is a list of models to exclude from a given AutoML experiment
    run. For a classification model, the following is a list of models that can be
    excluded from a given experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Classification Model** | **AutoMLConfig Value** |'
  prefs: []
  type: TYPE_TB
- en: '| Averaged Perceptron Classifier | `AveragedPerceptronClassifier` |'
  prefs: []
  type: TYPE_TB
- en: '| Bernoulli Naïve Bayes | `BernoulliNaiveBayes` |'
  prefs: []
  type: TYPE_TB
- en: '| Decision Tree | `DecisionTree` |'
  prefs: []
  type: TYPE_TB
- en: '| Extreme Random Trees | `ExtremeRandomTrees` |'
  prefs: []
  type: TYPE_TB
- en: '| Gradient Boosting | `GradientBoosting` |'
  prefs: []
  type: TYPE_TB
- en: '| K-Nearest Neighbors Classifier | `KNN` |'
  prefs: []
  type: TYPE_TB
- en: '| Light GBM Classified | `LightGBM` |'
  prefs: []
  type: TYPE_TB
- en: '| Linear Support Vector Machine | `LinearSVM` |'
  prefs: []
  type: TYPE_TB
- en: '| Logistic Regression | `LogisticRegression` |'
  prefs: []
  type: TYPE_TB
- en: '| Multinomial Naïve Bayes | `MultinomialNaiveBayes` |'
  prefs: []
  type: TYPE_TB
- en: '| Random Forest | `RandomForest` |'
  prefs: []
  type: TYPE_TB
- en: '| SGD Classifier | `SGD` |'
  prefs: []
  type: TYPE_TB
- en: '| Support Vector Machine | `SVM` |'
  prefs: []
  type: TYPE_TB
- en: '| TabNet Classifier | `TabNetClassifier` |'
  prefs: []
  type: TYPE_TB
- en: '| TensorFlow DNN Classifier | `TensorFlowDNN` |'
  prefs: []
  type: TYPE_TB
- en: '| TensorFlow Linear Classifier | `TensorFlowLinearClassifier` |'
  prefs: []
  type: TYPE_TB
- en: '| XGBoost Classifier | `XGBoostClassifier` |'
  prefs: []
  type: TYPE_TB
- en: Figure 5.26 – List of models available to block
  prefs: []
  type: TYPE_NORMAL
- en: '`enable_onnx_compatible_models` defaults to a value of `False`. If this value
    is set to `True`, then you can export models in the ONNX format to leverage them
    for high-performance gains during inference.'
  prefs: []
  type: TYPE_NORMAL
- en: '`training_data` can be a pandas DataFrame, an AML dataset, or a tabular dataset.
    *Figure 5**.20* showcases how to create the tabular training dataset, which is
    passed to the `AutoMLConfig` object in *Figure 5**.25* on *line 19*. Note that
    the training dataset does include the response variable, `Survived`, which is
    specified as the response variable in the `label_column_name` property on *line
    20*.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the validation dataset is provided in `AutoMLConfig` in the property
    named `validation_data`, which means that `n_cross_validations` cannot be provided
    in `automl_settings`. As mentioned earlier, it is not valid to supply both.
  prefs: []
  type: TYPE_NORMAL
- en: As part of the AML Python SDK, you can specify `test_data`. This feature is
    currently in preview. Metrics are calculated by using this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '`experiment_exit_score` is the value to hit for the primary metric. If the
    primary metric hits that value, then the experiment will terminate early.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to run the experiment, the `automl_config` object is submitted to
    the experiment as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27 – Submitting the AutoML experiment run](img/B18003_05_027.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.27 – Submitting the AutoML experiment run
  prefs: []
  type: TYPE_NORMAL
- en: 'In the notebook, while not required, we can specify to hold off on the execution
    of future cells until the run is complete by executing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28 – Waiting for completion](img/B18003_05_028.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.28 – Waiting for completion
  prefs: []
  type: TYPE_NORMAL
- en: Wait for the experiment to complete and then move on to see the output of the
    model training. We can also view the metric to understand how the model performed.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing your AutoML results via AMLS and the AML SDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the experiment run is completed, we are able to extract valuable information
    from the AutoML experiment run by leveraging the AML Python SDK:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For an AutoML experiment run, each run is executed as a child run of the AutoML
    experiment run. This means that we can get the best run for the experiment run
    by looking at the child runs for a given run as shown in *Figure 5**.29*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.29 – Retrieving the best child run for an AutoML experiment run](img/B18003_05_029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.29 – Retrieving the best child run for an AutoML experiment run
  prefs: []
  type: TYPE_NORMAL
- en: As we can view the information programmatically, we are also able to retrieve
    the best model through AMLS. In the studio, by clicking on the `automl-classification-titanic`
    experiment, we can see the run created for the experiment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Clicking on the run hyperlink brings us to the details of the experiment run.
    If we move over to the **Models** tab, we can see the models by their values for
    the primary metric, and an explanation provided for the best model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.30 – Retrieving the best child run for an AutoML experiment run
    in AMLS](img/B18003_05_030.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.30 – Retrieving the best child run for an AutoML experiment run in
    AMLS
  prefs: []
  type: TYPE_NORMAL
- en: From *Figure 5**.30*, if we click on the **View explanation** hyperlink, we
    can explore information about the best model that AutoML was able to create.
  prefs: []
  type: TYPE_NORMAL
- en: 'By clicking on the **Aggregate feature importance** tab, we can see the features
    that had the highest impact on the model. We can see that **Sex**, **Pclass**,
    **Age**, and **Fare** were the top four features by importance for the model that
    was created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.31 – Aggregate feature importance](img/B18003_05_031.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.31 – Aggregate feature importance
  prefs: []
  type: TYPE_NORMAL
- en: 'From the `best_run` object, we can pull back the featurization that occurred
    on the dataset programmatically by downloading the `featurization summary json`
    file from the `outputs` directory. This gives us insight into the automated featurization
    that occurred on the dataset to provide the best model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.32 – Retrieving the featurization results](img/B18003_05_032.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.32 – Retrieving the featurization results
  prefs: []
  type: TYPE_NORMAL
- en: 'The featurization results can not only be reviewed programmatically but the
    explanation of the best model within AMLS can also be reviewed as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.33 – The data transformation process implemented by AutoML](img/B18003_05_033.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.33 – The data transformation process implemented by AutoML
  prefs: []
  type: TYPE_NORMAL
- en: 'The run details can be viewed directly in the notebook by leveraging the `RunDetails`
    widget as shown in the code in *Figure 5**.34*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.34 – The RunDetails widget](img/B18003_05_034.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.34 – The RunDetails widget
  prefs: []
  type: TYPE_NORMAL
- en: 'With the widget, you can visualize the value of the metric at each iteration
    of the training run for the primary metric (and other metrics as well), as seen
    in the following figure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.35 – Training iteration for the AutoML experiment run](img/B18003_05_035.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.35 – Training iteration for the AutoML experiment run
  prefs: []
  type: TYPE_NORMAL
- en: 'For the training run, we are able to pull out the best run and the fitted model
    programmatically through the SDK as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.36 – Retrieving the best model](img/B18003_05_036.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.36 – Retrieving the best model
  prefs: []
  type: TYPE_NORMAL
- en: 'We are also able to retrieve the estimator leveraged by AutoML as shown here.
    `estimator` is a class that helps organize the execution and configuration used
    for a particular run. It also allows us to configure the scale and compute used
    for the modeling. There are multiple steps inside `estimator` to be the code,
    and `[-1]` goes back to the previous steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.37 – Retrieving the estimator](img/B18003_05_037.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.37 – Retrieving the estimator
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the model has been retrieved, we are able to leverage it for predictions
    directly as shown in *Figure 5**.38*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.38 – Leveraging the AutoML model directly](img/B18003_05_038.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.38 – Leveraging the AutoML model directly
  prefs: []
  type: TYPE_NORMAL
- en: 'We can leverage the test dataset to obtain metrics for the experiment, but
    we can also view a child run for the run that the best model was created for and
    retrieve the primary metrics for the test dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.39 – Best model child run](img/B18003_05_039.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.39 – Best model child run
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the run for the model test displays the metrics that were computed
    for the test dataset provided. This is on the unseen data that was not leveraged
    for model creation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.40 – Best model child run metrics](img/B18003_05_040.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.40 – Best model child run metrics
  prefs: []
  type: TYPE_NORMAL
- en: 'As an output of the model, a `scoring` file is generated that can be leveraged
    for model deployment. This `score.py` file can be downloaded from the best run
    as shown in *Figure 5**.41*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.41 – Downloading the scoring file](img/B18003_05_041.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.41 – Downloading the scoring file
  prefs: []
  type: TYPE_NORMAL
- en: 'Leveraging the AML Python SDK, the model can be registered to the AML workspace
    to enable the model deployment as shown in *Figure 5**.42*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.42 – Registering the AutoML model](img/B18003_05_042.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.42 – Registering the AutoML model
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that the model is registered and the scoring script is defined, we can
    deploy the model as an ACI service as shown in *Figure 5**.43*. Once the model
    has been deployed, which usually takes a few minutes, we can then use Postman
    or another REST- or HTTP-based client to call the inferencing API to test or consume
    other applications:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.43 – Model deployment](img/B18003_05_043.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.43 – Model deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'We are then able to call the test endpoint for real-time inferencing as shown
    in *Figure 5**.44*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.44 – AutoML best model deployment](img/B18003_05_044.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.44 – AutoML best model deployment
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s summarize the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we gave you an overview of Azure AutoML. We talked about how
    featurization, which can be an extremely time-consuming task, is handled by AutoML.
    We then explored how to use AutoML via AMLS for a no-code experience. Finally,
    we walked you through writing code using AutoML via the AML Python SDK and how
    to view and parse the output.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will show you how to deploy your ML models for real-time
    inference – for example, calling a REST API exposing the trained model – and for
    batch scoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2: Deploying and Explaining Models in AMLS'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Part 2*, readers will learn how to deploy models in AMLS in batches and
    in real time. Additionally, they will learn how to explain ML models and mitigate
    bias using AMLS.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18003_06.xhtml#_idTextAnchor086), *Deploying ML Models for Real-Time
    Inferencing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18003_07.xhtml#_idTextAnchor102), *Deploying ML Models for Batch
    Scoring*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18003_08.xhtml#_idTextAnchor108), *Responsible AI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18003_09.xhtml#_idTextAnchor119), *Productionizing Your Workload
    with MLOps*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
