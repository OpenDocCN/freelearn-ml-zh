- en: Azure Machine Learning Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Azure Machine Learning Studio** is an ML-as-a-Service platform for creating
    custom **machine learning** (**ML**) models. Azure ML Studio is a great tool for
    beginners who perhaps have some experience of consuming machine learning models
    and who would like to gain a deeper understanding of the training process. It
    offers more flexibility than the Cognitive Services APIs and an easy-to-learn
    development environment. The GUI does not require any programming and allows the
    user to concentrate on building ML models as efficiently as possible. Azure ML
    Studio is also a useful tool for more experienced AI developers who have a fairly
    simple problem at hand and need to get results quickly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure ML Studio consists of two separate services: a Studio Workspace and Studio
    Web Services. Both of these services also include the backend computational resources
    needed for processing, so the user does not have to worry about the maintenance
    of the underlying operating system or hardware. The difference between the two
    services is clear: the Studio Workspace is used to train ML models and experiment
    with different configurations, while Studio Web Services provide a REST API interface
    for scoring examples, using the models published from the Workspace.'
  prefs: []
  type: TYPE_NORMAL
- en: Azure ML Studio is designed for collaborative development. It integrates with
    Azure Active Directory, so users from the same organization can be added to the
    Workspace with a few clicks. All ML models in the ML Studio Workspace are visible
    to all members of the Workspace. Workspace members can also edit models created
    by others, so developers can try to improve each other's results iteratively.
    Therefore, it is a great tool when developers are following the **Team Data Science
    Process** (**TDSP**), for example.
  prefs: []
  type: TYPE_NORMAL
- en: ML models are developed inside *experiments*. An experiment contains all the
    steps required to produce an ML model, beginning with the input dataset. Experiments
    can be used to compare different ML models and parameter configurations. ML Studio
    provides a wide range of modules that can be added to an experiment to perform
    different tasks, such as preprocessing data or evaluating training results. By
    combining these modules, the experiment is built step by step, resulting in a
    training pipeline that can be run to produce a trained ML model. ML Studio also
    includes a wide experiment template collection, with ready-to-run examples from
    many different areas. In the next section, we will show how to deploy these templates
    to an ML Studio Workspace.
  prefs: []
  type: TYPE_NORMAL
- en: The pricing of Workspaces and web services is based on the use of computational
    resources. Workspace resources are consumed when new ML models are trained in
    ML Studio. Workspace billing is also based on the number of users, but using the
    ML Studio UI and building experiments does not incur any extra costs; only the
    experiment runtime is calculated.
  prefs: []
  type: TYPE_NORMAL
- en: When creating a new ML Studio Workspace, a new web service plan resource is
    created automatically. Web service resources are consumed when external applications
    call the ML Studio Web Services API. A web services pricing tier must be chosen
    when creating a web service resource in the Azure portal. The pricing tier determines
    the maximum amount of requests that can be handled in a month. If this limit is
    exceeded, each request is billed on top of the flat monthly price.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Azure ML Studio, you need a Workspace account. There are two types of
    Workspace accounts: *Free Tier* and *Standard* *T*ier. The Free Tier is an independent
    account that is not connected to an Azure subscription. It has more limitations
    in terms of use and does not include a production-scale web API, like the Standard
    Tier does. The Standard Tier requires an Azure subscription and the costs of the
    ML Studio resources are added to the subscription bill. The Workspace and web
    services appear as independent items in the resource group, and they can be managed
    in the Azure portal just like any other Azure resource.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the ML Studio UI, go to the ML Studio Workspace blade in the Azure
    portal and click on Launch Machine Learning Studio. You can also enter the portal
    address in the browser directly: [https://studio.azureml.net/](https://studio.azureml.net/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an Azure AI Gallery template
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an experiment in Azure ML Studio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a model as a web service in ML Studio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an Azure AI Gallery template
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developing models with ML Studio does not have to be done from scratch. Azure
    AI Gallery contains a wide selection of templates for many different scenarios.
    These scenarios include many common use cases for ML, such as credit risk prediction,
    demand estimation, and text sentiment analysis. Templates can be imported to an
    Azure ML Studio Workspace with a few clicks and they contain all the steps needed
    to produce a working ML model. Studying templates is a great way to learn about
    different use cases and the steps required to produce an ML model. Some templates
    are prepared by Microsoft, but users can also submit their own experiments to
    the gallery.
  prefs: []
  type: TYPE_NORMAL
- en: The template gallery can be accessed directly from ...
  prefs: []
  type: TYPE_NORMAL
- en: Building an experiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll show how to build an experiment from scratch using a
    custom dataset. With the GUI, creating new experiments is very fast and results
    can be viewed immediately. Azure ML Studio contains modules for all common ML
    and data-processing tasks, so it is a great tool for testing ideas quickly and
    iteratively. If the built-in modules are not sufficient for the task at hand,
    the script modules can be used for improved extensibility, explained as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Importing and preprocessing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As already discussed, Azure ML Studio is a complete ML tool that takes care
    of every step in the ML model development process. The only input needed is a
    raw dataset in a format understood by ML Studio; if the original data format is
    not recognized, then a file conversion is required, using either an external tool
    or the custom script modules in ML Studio. For raw files, the data formats currently
    recognized by ML Studio are CSV, TSV, ARFF, SvmLight, and R objects. Datasets
    can also be saved in zipped format to save storage space and bandwidth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Datasets can be imported to ML Studio in two ways: by uploading a local file
    from the user''s computer, or using cloud storage in Azure. To import data from
    your local ...'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing and configuring algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Choosing the right models and tuning the parameters for the model are at the
    core of AI application development. In most cases, there are several algorithms
    that are applicable to the task, and it may not be clear from the beginning which
    algorithm will perform best. For example, some algorithms might perform better
    for small datasets, while others excel on big data. Usually, there are also other
    constraints to think about, such as runtime or the amount of computational resources
    available. The best model is the one that achieves a sufficient level of accuracy
    with the minimum amount of computational resources.
  prefs: []
  type: TYPE_NORMAL
- en: The first step when solving an ML problem is to identify which family of algorithms
    should be used. The algorithm family depends mostly on the type of the *predicted* value,
    such as if predicting a number, the possible algorithms are different than when
    predicting a *categorical* value. A categorical value is one where the number
    of possible outcomes is finite. The simplest categorical value is a Boolean variable,
    which can take two values (true/false). The number of possible outcomes can also
    restrict which types of algorithms can be used for the problem, since not all
    algorithms handle very high-dimensional data well. One example of high-dimensional
    categorical data is encountered in text analysis, where each word might represent
    a different category and the number of categories is equal to the size of the
    dictionary. For such high-dimensional data, it is often best to use neural network
    models, which can handle a large number of output values.
  prefs: []
  type: TYPE_NORMAL
- en: Azure ML Studio contains a selection of the most commonly used ML algorithms
    that can be dragged and dropped to an experiment canvas. The algorithms are listed
    in the Initialize model section, under the Machine Learning menu. The algorithms
    are grouped into four categories. The anomaly detection modules are meant for
    detecting outliers in datasets where most of the values are similar to each other,
    but there are some exceptions that we want to identify. These models are widely
    used in predictive fault detection, for example, in the manufacturing and processing
    industries, where machines usually operate normally, but may sometimes produce
    anomalous values, indicating that the machine is about to break. The classification
    modules are used for training supervised algorithms that classify inputs to exclusive
    categories. The clustering modules provide unsupervised algorithms to find similar
    items in a dataset. Regression algorithms predict numerical values (but inputs
    can also be categorical variables). In addition to these ML algorithms, ML Studio
    provides modules for other common ML-related tasks, such as **P****rincipal Component
    Analysis** (**PCA**) and text tokenization.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll show an example of how to train a regression model. The
    input dataset is a record of flight delay information from multiple airports,
    available as a built-in dataset in ML Studio. The dataset includes information
    on the time of the flight, its origin, and its destination airports, and the airline
    that operates the flight. The label column, the value that we want to predict,
    is the departure delay in minutes (column `DepDelay`). A positive value for `DepDelay`
    means that the flight has been delayed, and a negative value means that it has
    departed ahead of schedule. This is a fairly large dataset, containing over 2.7
    million rows and 14 columns. To get more detailed information about the dataset,
    see the full description in the documentation available at [https://docs.microsoft.com/en-us/azure/machine-learning/studio/use-sample-datasets](https://docs.microsoft.com/en-us/azure/machine-learning/studio/use-sample-datasets).
  prefs: []
  type: TYPE_NORMAL
- en: 'The training process consists of the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Import data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preprocess data (choose which columns are used)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split data into training and test datasets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pick an ML algorithm and train it using the training dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the trained model to create predictions for the test dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the predicted values to the actual values in the test dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The input dataset contains mostly numerical data that does not require much
    preprocessing. The `Carrier` column contains categorical values in text format,
    but ML Studio converts these values into numeric values automatically. The only
    preprocessing step is choosing the columns to be used to train the model. In this
    example, the following columns are chosen as the features of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Column** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `Month` | Month (categorical numeric, 1-12) |'
  prefs: []
  type: TYPE_TB
- en: '| `DayOfWeek` | Day of week (categorical numeric, 1-7) |'
  prefs: []
  type: TYPE_TB
- en: '| `OriginAirportID` | Airport—departure (categorical numeric, 70 unique values)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `Carrier` | Airline (categorical string, 16 unique values) |'
  prefs: []
  type: TYPE_TB
- en: '| `CRSDepTime` | Time of day (categorical numeric, 1-2359, 1440 possible values)
    |'
  prefs: []
  type: TYPE_TB
- en: Note that the time of departure is given in numeric format, where the number
    101 corresponds to 01:01, for example. The Select Columns in Dataset module can
    be used to pick these columns and the label column (`DepDelay`) is to be used
    in the training process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before the model is trained, the data must be separated into training and test
    datasets. This is a crucial step in the training process: it is important that
    the accuracy of the model is measured with examples that the model has not seen
    during the training process. The Split Data module is meant for this purpose.
    By setting the Fraction of rows in the first output dataset property of the module
    to `0.75`, for example, the first output port of the module will contain 75% of
    the rows and the second output will contain 25%, selected randomly from the input
    dataset. We will use this splitting to divide the data into the training and test
    datasets, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the data has been processed and divided into training and test datasets,
    the model is trained with the training dataset. The Train Model module in ML Studio
    requires two inputs: an uninitialized ML model and the training dataset. The output
    of the module is the trained ML model that can be used to make predictions. In
    this example, the aim is to predict a numerical variable (the flight delay in
    minutes). As discussed previously, this type of problem requires a regression
    model. For simple testing, it is usually best to start with linear regression.
    This model does not often produce the best results, but it runs fast and gives
    a baseline for accuracy when evaluating more advanced models. Here is an example
    of a full training pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e14730c-4ed6-4ab7-903d-c6384a3368b3.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, the Decision Forest Regression model was trained with 75% of the
    input data. This model can produce accurate results, but the training time can
    be long if the dataset contains many rows. Training this model with a little over
    2 million rows took about 1 hour, while the linear regression model was trained
    in less than 1 minute. Although some algorithms may perform better in certain
    situations, it is usually difficult to predict beforehand which algorithm will
    produce the best results for a given problem. The best approach is to experiment
    with different algorithms and parameters to find the best model. We will show
    how this can be done in an organized manner using the modules in ML Studio, as
    follows.
  prefs: []
  type: TYPE_NORMAL
- en: To get more information about each module, click on the module so that the configuration
    panel appears on the right-hand side of the canvas. Follow the link at the bottom
    of the panel under Quick Help. The module documentation includes detailed information
    about each module and how to configure it.
  prefs: []
  type: TYPE_NORMAL
- en: After the Train Model module has been connected with an ML module and an input
    dataset, its output can be taken to the Score Model module to make predictions.
    To understand how well our model is performing, the test dataset is scored and
    the predictions for the model are compared to the true values (labels). The Score
    Model module will add a new column to the output data, containing the predicted
    values. The predicted values are then plotted against the actual values as a scatter
    plot to see how well they match up against each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although ML Studio does not provide any native visualization modules, the Execute
    R Script module can produce R graphics as output. The `plot` command is suitable
    for simple figures and is supported natively in the R module. The `ggplot2` library
    is also available in the R module. This library is widely used and produces high
    quality pictures. Here is an example of how to plot the `DepDelay` (actual values)
    on the *x* axis and the `Scored Label Mean` (predicted value) on the *y* axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that if the linear regression model was used, the predicted values would
    be in a different column (`Scored Labels`).
  prefs: []
  type: TYPE_NORMAL
- en: 'These are all the steps needed to train the model and analyze the results in
    a single pipeline. The model can now be trained by clicking the Run button in
    the toolbar at the bottom in ML Studio. After the run has finished, the results
    can be viewed by right-clicking the second output (R Device) and choosing Visualize.
    The plotting output can be viewed under the Graphics section, as demonstrated
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38837ea6-5f12-4b49-9df3-b355c609c855.png)'
  prefs: []
  type: TYPE_IMG
- en: In an ideal scenario, each predicted value would be equal to the actual value
    and there would be a straight line from the bottom-left corner to the upper-right
    corner. The preceding screenshot is therefore far from ideal. It seems that the
    model predicts some high values when the actual values are low, and vice versa;
    it is not able to predict high values when it should. We can already see from
    this screenshot that the *variance* of the results is high. The conclusion is
    that the features that were given to the model are not conclusive enough to predict
    delays accurately. The selected features (see the preceding list) do not contain
    sufficient information to explain the variation in the label variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the initial results do not seem convincing, what should the next step
    be? Instead of continuing to experiment with different configurations, it might
    be more productive to take a step back and consider whether there is some additional
    data that gives more information about when delays might occur. For example, weather
    conditions might correlate well with flight delays, so it could be a good idea
    to include weather data in the model. To see an example of this, navigate to Azure
    AI Gallery and search for the `Binary Classification: Flight delay prediction`
    template.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following subsections, we'll examine how different feature variables
    contribute to the variation in the label variable. We'll also show how to use
    ML Studio modules to evaluate different models and explore different parameter
    configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To a beginner, the wide selection of different ML algorithms may feel overwhelming.
    Which algorithm gives quick results, and which is good for large datasets? To
    help answer these and other questions, Microsoft has published an Azure ML algorithm
    cheat sheet: [https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-cheat-sheet](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-cheat-sheet).
    The cheat sheet shows the pros and cons of each algorithm at a quick glance.'
  prefs: []
  type: TYPE_NORMAL
- en: More advanced users will know that the algorithms in ML Studio are just a small
    portion of all of the available models. The algorithm selection can be extended
    with R libraries by using the Create R Model module. This is a code-based alternative
    for developing ML models in ML Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A common problem when developing ML models is deciding which features should
    be used when training a model. For a supervised learning algorithm, the best features
    are those that are highly correlated with the label variable. This means, broadly
    speaking, that changing one of the variables induces a change in the other variable
    as well. An example of highly correlated variables could be the time of day and
    the amount of road traffic: traffic jams usually occur during the rush hour, while
    the amount of traffic during the night is particularly low.'
  prefs: []
  type: TYPE_NORMAL
- en: The general aim of feature selection is to discover the variables that have
    the largest impact on the target variable. If the input dataset contains a large
    amount of columns, it ...
  prefs: []
  type: TYPE_NORMAL
- en: Comparing models and parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the core tasks in developing ML models is choosing the ML algorithm and
    configuring the parameters of the algorithm. ML Studio provides modules for both
    of these tasks, allowing you to compare multiple models, or parameter values in
    a single run.
  prefs: []
  type: TYPE_NORMAL
- en: 'To train multiple models in one experiment, the training and test datasets
    can be reused by directing the datasets to multiple training branches as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1dc845b-3c5f-4b61-9d28-35925b2117b5.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding experiment is similar to the earlier training experiment, except
    that there are two Train Model modules with different algorithms as inputs. The
    results of the Score Model module are also directed to the Evaluate Model module,
    instead of visualizing the raw prediction results, as was done earlier. The evaluation
    module takes two datasets as inputs, each dataset containing the original labels
    and the predicted values from the scoring module.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the evaluation module contains the summary statistics of the
    predicted values (the first input dataset is shown on the first row):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f2c2b8df-2081-4cda-9d8c-19a428d066d0.png)'
  prefs: []
  type: TYPE_IMG
- en: The columns of the evaluation results depend on the nature of the algorithms.
    The accuracy metrics that are used to evaluate regression models are different
    than those used for the evaluation of classification models, for example. As seen
    in the preceding screenshot, the evaluation module calculates several different
    metrics for a regression model. The different accuracy metrics capture different
    aspects of the errors. The Root Mean Squared Error is probably the most widely
    used metric for regression models. This metric indicates the confidence interval
    containing 95% of the examples in the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, different metrics can give contradicting results. In the preceding
    example, the second model has a lower Root Mean Squared Error, while other metrics,
    such as the Mean Absolute Error, are better in the first model. Therefore, it
    is important to choose the accuracy metric carefully when comparing results for
    different models. Different metrics emphasize different aspects of the error distribution,
    so the best metric depends on the problem and the input data. The properties of
    each metric is beyond the scope of this book, and we refer the reader to the ML
    Studio documentation and general statistics literature for details about the accuracy
    metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'As already mentioned, ML algorithms include parameters that affect how the
    model is trained. These parameters are often called **hyperparameters**. While
    the default values of the hyperparameters are chosen to work well in most cases,
    sometimes the accuracy of a model can be improved by choosing different values
    for the parameters. The Tune Model Hyperparameters module enables you to train
    a model multiple times in a single run using different parameter values. This
    module can be used instead of the Train Model module to create a trained model,
    as in the following experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/557405e5-7dfe-4a29-8d7d-3854c6cb26da.png)'
  prefs: []
  type: TYPE_IMG
- en: The inputs to Tune Model Hyperparameters are the same as for Train Model, except
    that the former accepts a validation dataset as a third optional input. Using
    the validation dataset means that the accuracy between different parameter values
    is evaluated with examples that were not used for training the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each algorithm has its own set of parameters and the parameters used for training
    must be specified in the algorithm module. To enable multiple values for the parameters,
    switch the Create trainer mode option of the algorithm module to Parameter Range.
    Note that some algorithms, such as linear regression, do not allow hyperparameter
    tuning. The possible values of the parameters can be given as a comma-separated
    list or by specifying a range using the range builder, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c76f184-025b-4631-a584-acf16fc80471.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Tune Model Hyperparameters module does not necessarily try out all of the
    possible combinations of the parameters. The module supports the following parameter
    sweep modes: entire grid, random grid, and random sweep. If entire grid mode is
    selected, all combinations will be tried. The random grid mode uses only a subset
    of all possible combinations, selected randomly. The total amount of runs in a
    random grid sweep can be controlled by setting the maximum number of runs on random
    sweep to a suitable value. This is particularly useful if there is a large number
    of combinations and it would take a very long time to sweep over the whole parameter
    space. Similarly, the random sweep mode can be used to run a subset of all possible
    combinations. The difference between the random grid and the random sweep modes
    is that the latter chooses the parameter values randomly within the specified
    range, while the former uses only the exact values defined in the algorithm module.'
  prefs: []
  type: TYPE_NORMAL
- en: Before running the example, set the label column similarly, as for Train Model.
    The accuracy metric must also be defined, depending on the nature of the model
    (classification or regression). The accuracy metric determines which measure is
    used when selecting the best model. As already discussed, different metrics can
    disagree about the best model, so it is important to decide which metric is used
    to evaluate the performance of the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the experiment has finished running, the results of the evaluation can
    be viewed in the first output of the Tune Model Hyperparameters module, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/99ff6a2d-8c95-45f8-8345-2042309d77d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each row in the results corresponds to an independent model, trained with different
    parameters. The columns show which parameter values were used in each case and
    the corresponding values of the accuracy metrics. The results are organized in
    decreasing order of accuracy, as defined by the metric chosen (here: Mean Absolute
    Error). The second output of Tune Model Hyperparameters contains the best trained
    model, also defined by the metric. This model can be used for scoring, similar
    to the output of the Train Model module.'
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, Azure ML Studio includes many built-in modules to evaluate the
    accuracy of ML models, and to test different models and configurations. It must,
    however, be borne in mind that even the best models cannot perform well on poor
    data. If the values to be predicted are not correlated with the feature variables,
    the algorithm will not be able to make good predictions. Moreover, the algorithm
    that produces the best accuracy is not always the best model in practice. Particularly
    with large datasets, it is often necessary to consider the runtime of the training
    process. If the complexity of the training process grows uncontrollably as the
    amount of data grows, training the algorithm can become impossible in practice.
    These aspects must also be taken into account when choosing ML algorithms for
    any given problem.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a model as a web service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the biggest strengths of Azure ML Studio is the ease with which you can
    deploy models to the cloud, to be consumed by other applications. Once an ML model
    is trained, as demonstrated in the previous section, it can be exported to ML
    Studio Web Services with just a few clicks. Deployment creates a web API for the
    model, which can be called from any internet-connected application. The model
    takes the features as input data and produces a predicted value as output. By
    deploying models to the ML Studio Web Service, there is no need to worry about
    the underlying server infrastructure. The computing resources and maintenance
    are handled entirely by Azure.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsections show how to deploy an ...
  prefs: []
  type: TYPE_NORMAL
- en: Creating a predictive experiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before a trained model can be exported to the web service, the training experiment
    that created the model must be converted into a predictive experiment. A predictive
    experiment defines the scoring pipeline for creating predictions based on web
    service input. It does not contain any training modules, since the model is already
    trained. Instead, the model is just loaded from the list of trained models and
    imported as input to the Score Model module.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a predictive experiment, open a training experiment that has been
    previously run, or run the training experiment once to create a trained model.
    The experiment does not need to include a Score Model module—this will be added
    to the predictive experiment automatically. Click on Set up Web Service | Create
    Predictive experiment. This leads to a new view that shows the new predictive
    experiment, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f117bdc4-05ce-44cf-858c-91d6f02c2387.png)'
  prefs: []
  type: TYPE_IMG
- en: This example uses the same flight delay prediction experiment that was trained
    earlier. Note that the Split Data module has been removed from the predictive
    experiment and the training modules have now been replaced with the trained model.
    The Split Data module was only used to divide the data into training and test
    datasets, so ML Studio has inferred that it can be removed from the predictive
    experiment along with the training modules.
  prefs: []
  type: TYPE_NORMAL
- en: Run the experiment once before deploying it. The predictive experiment cannot
    be deployed as a web service before it has been run at least once. For instructions
    on how to deploy the model, skip to the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, it might be useful to provide some of the module parameters
    as input from the web service. For example, the data preprocessing steps might
    depend on the input data. For this purpose, most of the module configurations
    can be parameterized so that the configuration values are supplied in the request
    as input. To parameterize a certain module parameter, go back to the training
    experiment and click on the module to be configured. In the configuration panel
    on the right-hand side of the canvas, click on the menu next to the field to be
    configured and select Set as web service parameter, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e801e72b-8904-4b16-b1c3-4a661b0dc417.png)'
  prefs: []
  type: TYPE_IMG
- en: This will add the parameter to the list of Web Services parameters for the module.
    It is also possible to set a default value for the parameter, in case there is
    no value supplied in the request. Not all module parameters can be set as Web
    Service parameters, however. Those parameters that cannot be set do not have the
    context menu next to the field (see, for example, Cleaning mode in the preceding
    screenshot).
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the deployed models might give poor predictions and we may wish to
    revert back to a previous version of the model. The previous runs can always be
    viewed from the Run History, which is found in the bottom panel of the experiment.
    The Run History shows every execution of the experiment, and clicking a version
    of the experiment will open it with the respective configuration and results.
    This version of the experiment will be locked and cannot be edited or deployed
    any more, but it can be saved as a new training experiment and retrained to create
    a new predictive experiment. This is useful if the model has been retrained several
    times and the optimal parameters for the model have been forgotten.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and testing a web service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final step after creating the predictive experiment is to deploy the model
    to the cloud. Open the predictive experiment and make sure that it has been run
    successfully at least once, as discussed previously. From the bottom panel, choose
    Deploy Web Service | Deploy Web Service [New]. This brings up the deployment configuration
    view. Choose a name and the price plan for the web service. The price plan determines
    how many requests the service can handle in a month. The price plan is created
    at the same time as when a new ML Studio Web Service is created in the Azure portal.
    If there is no existing price plan, a new one can also be created by choosing
    Create new... from the menu.
  prefs: []
  type: TYPE_NORMAL
- en: When the configuration ...
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure Machine Learning Studio is a fully managed platform for developing machine
    learning models, enabling the user to concentrate on the essential tasks and problems
    in machine learning development. The graphical user interface is easy to learn
    and its usage requires no programming skills. Even users who have no prior experience
    in programming or machine learning can learn to use it, and the Experiment template
    collection contains many real-world examples of ML models to start with. ML Studio
    is a great way to start learning to develop ML models, and the sample datasets
    in ML Studio make it possible to develop your own models, even if you don't have
    your own data to start with.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning Studio contains modules for all the most common ML-related
    tasks, such as data preprocessing, tuning hyperparameters, and evaluating the
    performance of ML algorithms. If the module collection is not sufficient for the
    task at hand, the R and Python script modules can be used to customize tasks and
    visualize the results, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning Studio is a complete environment for developing ML models,
    including all the steps from data ingestion to serving models in the cloud. Once
    the models have been trained in ML Studio Workspace, they can be converted to
    Predictive Experiments and deployed to the ML Studio Web Services for serving
    with a few clicks. The user does not need to worry about managing the underlying
    infrastructure behind the web services API, as this is managed entirely by the
    service. The web services portal contains comprehensive documentation and examples
    for integrating with the service, making it very easy to begin consuming the ML
    models from external applications. In the next chapter we will see how to use
    Azure in data science.
  prefs: []
  type: TYPE_NORMAL
