["```py\n   // Apply Canny algorithm\n   cv::Mat contours;\n   cv::Canny(image,    // gray-level image\n             contours, // output contours\n             125,      // low threshold\n             350);     // high threshold\n```", "```py\n   // Apply Canny algorithm\n   cv::Mat contours;\n   cv::Canny(image,contours,125,350);\n   // Hough transform for line detection\n   std::vector<cv::Vec2f> lines;\n   cv::HoughLines(test,lines,\n        1,PI/180,  // step size\n        60);       // minimum number of votes\n```", "```py\n   std::vector<cv::Vec2f>::const_iterator it= lines.begin();\n   while (it!=lines.end()) {\n\n      float rho= (*it)[0];   // first element is distance rho\n      float theta= (*it)[1]; // second element is angle theta\n\n      if (theta < PI/4\\. \n           || theta > 3.*PI/4.) { // ~vertical line\n\n         // point of intersection of the line with first row\n         cv::Point pt1(rho/cos(theta),0);        \n         // point of intersection of the line with last row\n         cv::Point pt2((rho-result.rows*sin(theta))/\n                                  cos(theta),result.rows);\n         // draw a white line\n         cv::line( image, pt1, pt2, cv::Scalar(255), 1); \n\n      } else { // ~horizontal line\n\n         // point of intersection of the \n         // line with first column\n         cv::Point pt1(0,rho/sin(theta));        \n         // point of intersection of the line with last column\n         cv::Point pt2(result.cols,\n                 (rho-result.cols*cos(theta))/sin(theta));\n         // draw a white line\n         cv::line(image, pt1, pt2, cv::Scalar(255), 1); \n      }\n\n      ++it;\n   }\n```", "```py\nclass LineFinder {\n\n  private:\n\n     // original image\n     cv::Mat img;\n\n     // vector containing the endpoints \n     // of the detected lines\n     std::vector<cv::Vec4i> lines;\n\n     // accumulator resolution parameters\n     double deltaRho;\n     double deltaTheta;\n\n     // minimum number of votes that a line \n     // must receive before being considered\n     int minVote;\n\n     // min length for a line\n     double minLength;\n\n     // max allowed gap along the line\n     double maxGap;\n\n  public:\n\n     // Default accumulator resolution is 1 pixel by 1 degree\n     // no gap, no minimum length\n     LineFinder() : deltaRho(1), deltaTheta(PI/180), \n                    minVote(10), minLength(0.), maxGap(0.) {}\n```", "```py\n     // Set the resolution of the accumulator\n     void setAccResolution(double dRho, double dTheta) {\n\n        deltaRho= dRho;\n        deltaTheta= dTheta;\n     }\n\n     // Set the minimum number of votes\n     void setMinVote(int minv) {\n\n        minVote= minv;\n     }\n\n     // Set line length and gap\n     void setLineLengthAndGap(double length, double gap) {\n\n        minLength= length;\n        maxGap= gap;\n     }\n```", "```py\n     // Apply probabilistic Hough Transform\n     std::vector<cv::Vec4i> findLines(cv::Mat& binary) {\n\n        lines.clear();\n        cv::HoughLinesP(binary,lines,\n                        deltaRho, deltaTheta, minVote, \n                        minLength, maxGap);\n\n        return lines;\n     }\n```", "```py\n     // Draw the detected lines on an image\n     void drawDetectedLines(cv::Mat &image, \n                cv::Scalar color=cv::Scalar(255,255,255)) {\n\n        // Draw the lines\n        std::vector<cv::Vec4i>::const_iterator it2= \n                                           lines.begin();\n\n        while (it2!=lines.end()) {\n\n           cv::Point pt1((*it2)[0],(*it2)[1]);        \n           cv::Point pt2((*it2)[2],(*it2)[3]);\n\n           cv::line( image, pt1, pt2, color);\n\n           ++it2;   \n        }\n     }\n```", "```py\n   // Create LineFinder instance\n   LineFinder finder;\n\n   // Set probabilistic Hough parameters\n   finder.setLineLengthAndGap(100,20);\n   finder.setMinVote(60);\n\n   // Detect lines and draw them\n   std::vector<cv::Vec4i> lines= finder.findLines(contours);\n   finder.drawDetectedLines(image);\n   cv::namedWindow(\"Detected Lines with HoughP\");\n   cv::imshow(\"Detected Lines with HoughP\",image);\n```", "```py\n   // Create a Hough accumulator\n   // here a uchar image; in practice should be ints\n   cv::Mat acc(200,180,CV_8U,cv::Scalar(0));\n```", "```py\n   // Choose a point\n   int x=50, y=30;\n   // loop over all angles\n   for (int i=0; i<180; i++) {\n\n      double theta= i*PI/180.;\n\n      // find corresponding rho value \n      double rho= x*std::cos(theta)+y*std::sin(theta);\n      // j corresponds to rho from -100 to 100\n      int j= static_cast<int>(rho+100.5);\n\n      std::cout << i << \",\" << j << std::endl;\n\n      // increment accumulator\n      acc.at<uchar>(j,i)++;\n   }\n```", "```py\n   cv::HoughLines(test,lines,1,PI/180,50);\n```", "```py\n   cv::GaussianBlur(image,image,cv::Size(5,5),1.5);\n   std::vector<cv::Vec3f> circles;\n   cv::HoughCircles(image, circles, CV_HOUGH_GRADIENT, \n      2,   // accumulator resolution (size of the image / 2) \n      50,  // minimum distance between two circles\n      200, // Canny high threshold \n      100, // minimum number of votes \n      25, 100); // min and max radius\n```", "```py\n   std::vector<cv::Vec3f>::\n          const_iterator itc= circles.begin();\n\n   while (itc!=circles.end()) {\n\n     cv::circle(image, \n        cv::Point((*itc)[0], (*itc)[1]), // circle centre\n        (*itc)[2],       // circle radius\n        cv::Scalar(255), // color \n        2);              // thickness\n\n     ++itc;   \n   }\n```", "```py\n   int n=0; // we select line 0 \n   // black image\n   cv::Mat oneline(contours.size(),CV_8U,cv::Scalar(0));\n   // white line\n   cv::line(oneline, \n            cv::Point(lines[n][0],lines[n][1]),\n            cv::Point(lines[n][2],lines[n][3]),\n            cv::Scalar(255),\n            3); // line width\n   // contours AND white line\n   cv::bitwise_and(contours,oneline,oneline);\n```", "```py\n   std::vector<cv::Point> points;\n\n   // Iterate over the pixels to obtain all point positions\n   for( int y = 0; y < oneline.rows; y++ ) {    \n      // row y\n\n      uchar* rowPtr = oneline.ptr<uchar>(y);\n\n      for( int x = 0; x < oneline.cols; x++ ) {\n         // column x \n\n         // if on a contour\n         if (rowPtr[x]) {\n\n            points.push_back(cv::Point(x,y));\n         }\n      }\n    }\n```", "```py\n   cv::Vec4f line;\n   cv::fitLine(points,line,\n               CV_DIST_L2, // distance type\n               0,          // not used with L2 distance \n               0.01,0.01); // accuracy\n```", "```py\n   int x0= line[2];        // a point on the line\n   int y0= line[3];\n   int x1= x0+100*line[0]; // add a vector of length 100\n   int y1= y0+100*line[1]; // using the unit vector\n   // draw the line\n   cv::line(image,cv::Point(x0,y0),cv::Point(x1,y1),\n            0,3); // color and thickness\n```", "```py\n   cv::RotatedRect rrect= cv::fitEllipse(cv::Mat(points));\n   cv::ellipse(image,rrect,cv::Scalar(0));\n```", "```py\n   // the vector that will contain the contours\n   std::vector<std::vector<cv::Point>> contours;\n   cv::findContours(image, \n      contours, // a vector of contours \n      CV_RETR_EXTERNAL, // retrieve the external contours\n      CV_CHAIN_APPROX_NONE); // all pixels of each contours\n```", "```py\n   // draw black contours on a white image\n   cv::Mat result(image.size(),CV_8U,cv::Scalar(255));\n   cv::drawContours(result,contours,\n      -1, // draw all contours\n       0, // in black\n       2);// with a thickness of 2\n```", "```py\n   // Eliminate too short or too long contours\n   int cmin= 50;  // minimum contour length\n   int cmax= 1000; // maximum contour length\n   std::vector<std::vector<cv::Point>>::\n              iterator itc= contours.begin();\n   // for all contours\n   while (itc!=contours.end()) {\n\n      // verify contour size\n      if (itc->size() < cmin || itc->size() > cmax)\n         itc= contours.erase(itc);\n      else \n         ++itc;\n   }\n```", "```py\n   cv::findContours(image, \n      contours, // a vector of contours \n      CV_RETR_LIST, // retrieve all contours\n      CV_CHAIN_APPROX_NONE); // all pixels of each contours\n```", "```py\n   std::vector<cv::Vec4i> hierarchy;\n   cv::findContours(image, \n      contours, // a vector of contours\n      hierarchy, // hierarchical representation \n      CV_RETR_TREE, // retrieve all contours in tree format\n      CV_CHAIN_APPROX_NONE); // all pixels of each contours\n```", "```py\n  // testing the bounding box \n  cv::Rect r0= cv::boundingRect(contours[0]);\n  // draw the rectangle\n  cv::rectangle(result,r0, 0, 2);\n```", "```py\n   // testing the enclosing circle \n   float radius;\n   cv::Point2f center;\n   cv::minEnclosingCircle(contours[1],center,radius);\n   // draw the circle\n   cv::circle(result,center,\n              static_cast<int>(radius),cv::Scalar(0),2);\n```", "```py\n   // testing the approximate polygon\n   std::vector<cv::Point> poly;\n   cv::approxPolyDP(contours[2],poly,5,true);\n   // draw the polygon\n   cv::polylines(result, poly, true, 0, 2);\n```", "```py\n   // testing the convex hull\n   std::vector<cv::Point> hull;\n   cv::convexHull(contours[3],hull);\n   // draw the polygon\n   cv::polylines(result, hull, true, 0, 2);\n```", "```py\n   // testing the moments\n   // iterate over all contours\n   itc= contours.begin();\n   while (itc!=contours.end()) {\n\n      // compute all moments\n      cv::Moments mom= cv::moments(cv::Mat(*itc++));\n\n      // draw mass center\n      cv::circle(result,\n         // position of mass center converted to integer\n         cv::Point(mom.m10/mom.m00,mom.m01/mom.m00),\n         2,cv::Scalar(0),2); // draw black dot\n   }\n```", "```py\n  std::vector<cv::Vec4i> defects;\n  cv::convexityDefects(contour, hull, defects);\n```", "```py\n  // create a binary version\n  components= components==255;\n  // open the image (white background)\n  cv::morphologyEx(components,components,\n                    cv::MORPH_OPEN,cv::Mat(),\n                    cv::Point(-1,-1),3);\n```", "```py\n  //invert image (background must be black)\n  cv::Mat componentsInv= 255-components;\n  // Get the contours of the connected components\n  cv::findContours(componentsInv, \n    contours, // a vector of contours \n    CV_RETR_EXTERNAL, // retrieve the external contours\n    CV_CHAIN_APPROX_NONE); \n```", "```py\n  // white image\n  cv::Mat quadri(components.size(),CV_8U,255);\n\n  // for all contours\n  std::vector<std::vector<cv::Point>>::iterator \n                              it= contours.begin();\n  while (it!= contours.end()) {\n    poly.clear();\n    // approximate contour by polygon\n    cv::approxPolyDP(*it,poly,10,true);\n\n    // do we have a quadrilateral?\n    if (poly.size()==4) {\n          // draw it\n      cv::polylines(quadri, poly, true, 0, 2);\n    }\n    ++it;\n  }\n```"]