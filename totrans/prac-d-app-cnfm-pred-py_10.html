<html><head></head><body>
<div id="_idContainer065">
<h1 class="chapter-number" id="_idParaDest-132"><a id="_idTextAnchor130"/><span class="koboSpan" id="kobo.1.1">10</span></h1>
<h1 id="_idParaDest-133"><a id="_idTextAnchor131"/><span class="koboSpan" id="kobo.2.1">Conformal Prediction for Natural Language Processing</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.3.1">Natural language processing</span></strong><span class="koboSpan" id="kobo.4.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.5.1">NLP</span></strong><span class="koboSpan" id="kobo.6.1">) grapples with the complexities of human language, where uncertainty is an inherent challenge. </span><span class="koboSpan" id="kobo.6.2">As NLP models become integral to risk-sensitive and critical applications, ensuring their reliability is paramount. </span><span class="koboSpan" id="kobo.6.3">Conformal prediction emerges as a promising technique, offering a way to quantify the trustworthiness of these models’ predictions, particularly when faced with miscalibrated outputs from deep </span><span class="No-Break"><span class="koboSpan" id="kobo.7.1">learning models.</span></span></p>
<p><span class="koboSpan" id="kobo.8.1">In this chapter, we will navigate the NLP conformal prediction world, understand its significance, and learn how to harness its power for more reliable and </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">confident predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.10.1">In this chapter, we’re going to cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.12.1">Uncertainty quantification </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1">for NLP</span></span></li>
<li><span class="koboSpan" id="kobo.14.1">Why deep learning produces </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">miscalibrated predictions</span></span></li>
<li><span class="koboSpan" id="kobo.16.1">Various approaches to quantify uncertainty in </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">NLP problems</span></span></li>
<li><span class="koboSpan" id="kobo.18.1">Conformal prediction </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">for NLP</span></span></li>
<li><span class="koboSpan" id="kobo.20.1">Building NLP classifiers using </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">conformal prediction</span></span></li>
<li><span class="koboSpan" id="kobo.22.1">Open source tools for conformal prediction </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">in NLP</span></span></li>
</ul>
<h1 id="_idParaDest-134"><a id="_idTextAnchor132"/><span class="koboSpan" id="kobo.24.1">Uncertainty quantification for NLP</span></h1>
<p><span class="koboSpan" id="kobo.25.1">Uncertainty quantification in NLP is an </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.26.1">essential yet often overlooked aspect of model development and deployment. </span><span class="koboSpan" id="kobo.26.2">As NLP models become increasingly integrated into critical applications—from healthcare</span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.27.1"> diagnostics to financial predictions—the need to understand and convey the confidence level of their outputs becomes paramount. </span><span class="koboSpan" id="kobo.27.2">Uncertainty quantification provides a framework for assessing the reliability of predictions, allowing users and developers to gauge the model’s decisiveness and the potential risks of relying on its results. </span><span class="koboSpan" id="kobo.27.3">This section delves into the importance, methodologies, and practical considerations of uncertainty quantification in NLP, highlighting its pivotal role in building robust and trustworthy </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">language</span></span><span class="No-Break"><a id="_idIndexMarker528"/></span><span class="No-Break"><span class="koboSpan" id="kobo.29.1"> models.</span></span></p>
<p><span class="koboSpan" id="kobo.30.1">We will now explore uncertainty in NLP and the benefits and challenges of quantifying uncertainty in </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">NLP applications.</span></span></p>
<h2 id="_idParaDest-135"><a id="_idTextAnchor133"/><span class="koboSpan" id="kobo.32.1">What is uncertainty in NLP?</span></h2>
<p><span class="koboSpan" id="kobo.33.1">NLP, at its core, is about</span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.34.1"> making sense of human language—a medium known for its richness, ambiguity, and diversity. </span><span class="koboSpan" id="kobo.34.2">The inherent variability in language usage, context-driven meanings, and the ever-evolving nature of linguistic constructs make NLP tasks inherently uncertain. </span><span class="koboSpan" id="kobo.34.3">For instance, the word “bank” could refer to a financial institution or the side of a river depending on </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">the context.</span></span></p>
<h2 id="_idParaDest-136"><a id="_idTextAnchor134"/><span class="koboSpan" id="kobo.36.1">Benefits of quantifying uncertainty in NLP</span></h2>
<p><span class="koboSpan" id="kobo.37.1">Quantifying uncertainty in NLP is not </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.38.1">just a theoretical exercise; it has the following </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">tangible benefits:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.40.1">Trustworthiness</span></strong><span class="koboSpan" id="kobo.41.1">: Quantifying uncertainty either bolsters confidence in specific predictions or highlights areas </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">of caution.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.43.1">Performance evaluation</span></strong><span class="koboSpan" id="kobo.44.1">: This assesses the efficacy of various models by examining the uncertainty in </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">their metrics.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.46.1">Enhancement opportunities</span></strong><span class="koboSpan" id="kobo.47.1">: It can recognize areas where a model can be refined, especially in contexts such as </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">active learning.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.49.1">Risk management</span></strong><span class="koboSpan" id="kobo.50.1">: By understanding the degree of uncertainty in predictions, stakeholders can make more informed decisions. </span><span class="koboSpan" id="kobo.50.2">For instance, an NLP model predicting sentiment might be 80% certain that a review is positive. </span><span class="koboSpan" id="kobo.50.3">Knowing this, a business might prioritize addressing reviews where the model’s certainty </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">is lower.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.52.1">Model transparency</span></strong><span class="koboSpan" id="kobo.53.1">: A model that can express its uncertainty is perceived as more transparent and trustworthy. </span><span class="koboSpan" id="kobo.53.2">Users of the model can better understand when to trust the model’s output and when to approach it </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">with caution.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.55.1">Model training</span></strong><span class="koboSpan" id="kobo.56.1">: During the training phase, understanding areas of high uncertainty can guide data</span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.57.1"> collection efforts. </span><span class="koboSpan" id="kobo.57.2">If a model is uncertain about a particular data type, gathering more of that data can lead to more </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">robust training.</span></span></li>
</ul>
<h2 id="_idParaDest-137"><a id="_idTextAnchor135"/><span class="koboSpan" id="kobo.59.1">The challenges of uncertainty in NLP</span></h2>
<p><span class="koboSpan" id="kobo.60.1">Despite its importance, managing </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.61.1">uncertainty in NLP is challenging. </span><span class="koboSpan" id="kobo.61.2">Here are some </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">reasons why:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.63.1">Data sparsity</span></strong><span class="koboSpan" id="kobo.64.1">: Many NLP tasks lack representative data for all possible linguistic variations, leading to models that are uncertain about less common </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">data points</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.66.1">Ambiguity in language</span></strong><span class="koboSpan" id="kobo.67.1">: As mentioned, words can have multiple meanings based on context, leading to </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">inherent uncertainty</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.69.1">Model complexity</span></strong><span class="koboSpan" id="kobo.70.1">: Advanced models such as deep learning networks can sometimes act as black boxes, making it challenging to discern areas </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">of uncertainty</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.72.1">In building robust NLP systems, understanding and quantifying uncertainty becomes paramount. </span><span class="koboSpan" id="kobo.72.2">As we dive deeper into the chapter, we’ll explore techniques, particularly </span><strong class="bold"><span class="koboSpan" id="kobo.73.1">conformal prediction</span></strong><span class="koboSpan" id="kobo.74.1">, that offer a structured approach to tackle these </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">challenges head-on.</span></span></p>
<h1 id="_idParaDest-138"><a id="_idTextAnchor136"/><span class="koboSpan" id="kobo.76.1">Understanding why deep learning produces miscalibrated predictions</span></h1>
<p><span class="koboSpan" id="kobo.77.1">In the rapidly evolving field of NLP, deep learning played a pivotal role in enabling machines to process and generate language in ways that were once the exclusive domain of humans. </span><span class="koboSpan" id="kobo.77.2">The next section introduces the key concepts and milestones in deep learning that has significantly </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">influenced NLP.</span></span></p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor137"/><span class="koboSpan" id="kobo.79.1">Introduction to deep learning in NLP</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.80.1">Deep learning</span></strong><span class="koboSpan" id="kobo.81.1">, a subset of machine </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.82.1">learning, relies on neural networks with many layers (hence “deep”) to analyze various data factors. </span><span class="koboSpan" id="kobo.82.2">In the context of NLP, deep learning has been a game-changer, enabling machines to understand and generate human language with </span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">unprecedented accuracy:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.84.1">Evolution of architectures</span></strong><span class="koboSpan" id="kobo.85.1">: The journey began with simpler architectures such as feedforward neural networks and </span><strong class="bold"><span class="koboSpan" id="kobo.86.1">recurrent neural networks</span></strong><span class="koboSpan" id="kobo.87.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.88.1">RNNs</span></strong><span class="koboSpan" id="kobo.89.1">). </span><span class="koboSpan" id="kobo.89.2">With its ability to</span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.90.1"> remember past information, the latter was particularly influential in sequence-based tasks such as language</span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.91.1"> translation. </span><span class="koboSpan" id="kobo.91.2">Later, more advanced architectures such as </span><strong class="bold"><span class="koboSpan" id="kobo.92.1">long short-term memory</span></strong><span class="koboSpan" id="kobo.93.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.94.1">LSTM</span></strong><span class="koboSpan" id="kobo.95.1">) and the </span><strong class="bold"><span class="koboSpan" id="kobo.96.1">Transformer model</span></strong><span class="koboSpan" id="kobo.97.1"> further elevated </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">performance standards.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.99.1">BERT and transformers</span></strong><span class="koboSpan" id="kobo.100.1">: The introduction of </span><strong class="bold"><span class="koboSpan" id="kobo.101.1">Bidirectional Encoder Representations from Transformers</span></strong><span class="koboSpan" id="kobo.102.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.103.1">BERT</span></strong><span class="koboSpan" id="kobo.104.1">) marked a significant milestone. </span><span class="koboSpan" id="kobo.104.2">BERT achieved state-of</span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.105.1">-the-art results in numerous NLP tasks by analyzing words concerning their entire context (both left and right of a word). </span><span class="koboSpan" id="kobo.105.2">The Transformer architecture, which BERT is based on, introduced attention mechanisms that allow models to focus on specific parts of the input text, much like how humans pay attention to particular words when </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">comprehending language.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.107.1">Language models and LLMs</span></strong><span class="koboSpan" id="kobo.108.1">: </span><strong class="bold"><span class="koboSpan" id="kobo.109.1">Large language models</span></strong><span class="koboSpan" id="kobo.110.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.111.1">LLMs</span></strong><span class="koboSpan" id="kobo.112.1">) such as </span><strong class="bold"><span class="koboSpan" id="kobo.113.1">generative pre-trained transformer</span></strong><span class="koboSpan" id="kobo.114.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.115.1">GPT</span></strong><span class="koboSpan" id="kobo.116.1">) and its iterations, such as ChatGPT, have set new standards</span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.117.1"> in NLP. </span><span class="koboSpan" id="kobo.117.2">With billions of</span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.118.1"> parameters, these models can generate human-like text, answer questions, and even assist in creative writing. </span><span class="koboSpan" id="kobo.118.2">ChatGPT, in particular, has been influential in creating conversational agents capable of more natural and </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">coherent interactions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.120.1">Transfer learning and fine-tuning</span></strong><span class="koboSpan" id="kobo.121.1">: One of the revolutionary aspects of these developments is the idea of transfer learning. </span><span class="koboSpan" id="kobo.121.2">Models such as BERT and GPT are pre-trained on vast corpora and can be fine-tuned on specific tasks with smaller datasets. </span><span class="koboSpan" id="kobo.121.3">This approach has democratized deep learning in NLP, allowing teams with limited resources to achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">competitive results.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.123.1">With these advancements, deep learning models have become the backbone of many modern NLP applications, from</span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.124.1"> chatbots to search engines. </span><span class="koboSpan" id="kobo.124.2">However, as we’ll explore in the subsequent sections, their complexity and sheer scale introduce challenges, especially </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">in calibration.</span></span></p>
<h2 id="_idParaDest-140"><a id="_idTextAnchor138"/><span class="koboSpan" id="kobo.126.1">Challenges with deep learning predictions in NLP</span></h2>
<p><span class="koboSpan" id="kobo.127.1">Deep learning has undeniably </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.128.1">advanced the capabilities of NLP, but it also brings forth several challenges and pitfalls. </span><span class="koboSpan" id="kobo.128.2">As we navigate the landscape of deep learning in NLP, we must be aware of these issues. </span><span class="koboSpan" id="kobo.128.3">Some of the notable challenges include </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.130.1">Model overconfidence</span></strong><span class="koboSpan" id="kobo.131.1">: Deep learning models, given their capacity to fit complex patterns, often become overconfident in their predictions. </span><span class="koboSpan" id="kobo.131.2">For instance, in sentiment analysis, a model might predict a text as positive with 60% confidence when, in reality, the actual confidence should be much lower due to </span><span class="No-Break"><span class="koboSpan" id="kobo.132.1">ambiguous phrasing.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.133.1">Data distribution shift</span></strong><span class="koboSpan" id="kobo.134.1">: NLP models are often trained on specific datasets and may not be exposed to the full linguistic diversity of real-world inputs. </span><span class="koboSpan" id="kobo.134.2">When faced with out-of-distribution data, these models can produce </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">miscalibrated predictions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.136.1">Lack of explicit uncertainty modeling</span></strong><span class="koboSpan" id="kobo.137.1">: Traditional deep learning approaches don’t inherently model uncertainty. </span><span class="koboSpan" id="kobo.137.2">They optimize for accuracy, often at the cost of a reliable </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">uncertainty estimate.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.139.1">Complexity and non-linearity</span></strong><span class="koboSpan" id="kobo.140.1">: The intricate architectures of deep learning models, especially with multiple layers and non-linear activations, can sometimes lead to unpredictable behavior, especially when handling edge cases or rare </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">linguistic constructs.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.142.1">Let’s go through the implications of </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">miscalibration next.</span></span></p>
<h2 id="_idParaDest-141"><a id="_idTextAnchor139"/><span class="koboSpan" id="kobo.144.1">The implications of miscalibration</span></h2>
<p><span class="koboSpan" id="kobo.145.1">Miscalibration in NLP models is more than just a mere academic concern. </span><span class="koboSpan" id="kobo.145.2">In real-world applications, it can lead to misinformed </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.146.1">decisions, misplaced trust, and even potentially harmful outcomes, especially in sensitive areas such as healthcare, finance, and </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">legal systems:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.148.1">Decision-making risks</span></strong><span class="koboSpan" id="kobo.149.1">: Overconfident models can lead stakeholders to make decisions based on misguided confidence, potentially causing miscommunications or </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">flawed strategies</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.151.1">Loss of trust</span></strong><span class="koboSpan" id="kobo.152.1">: Users might lose faith in an NLP system if it frequently expresses high confidence in </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1">incorrect predictions</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.154.1">Resource misallocation</span></strong><span class="koboSpan" id="kobo.155.1">: In automated systems, a miscalibrated model might prioritize tasks inefficiently, wasting computational resources on tasks where human intervention would have been </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">more appropriate</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.157.1">Recognizing these challenges is the first step. </span><span class="koboSpan" id="kobo.157.2">As we progress, we’ll delve into conformal prediction—a technique that presents a viable solution to the miscalibration issues plaguing deep learning models </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">in NLP.</span></span></p>
<h1 id="_idParaDest-142"><a id="_idTextAnchor140"/><span class="koboSpan" id="kobo.159.1">Various approaches to quantify uncertainty in 
NLP problems</span></h1>
<p><span class="koboSpan" id="kobo.160.1">Multiple methods to quantify </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.161.1">uncertainty in NLP problems have been explored to address the challenges of miscalibration and language’s </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">inherent </span></span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">unpredictability.</span></span></p>
<p><span class="koboSpan" id="kobo.164.1">We will now look at Bayesian approaches </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">to UQ.</span></span></p>
<p><span class="koboSpan" id="kobo.166.1">Bayesian approaches to </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">uncertainty quantification</span></span></p>
<p><span class="koboSpan" id="kobo.168.1">Bayesian methods provide a</span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.169.1"> framework for modeling uncertainty. </span><span class="koboSpan" id="kobo.169.2">By treating model parameters as distributions rather than fixed values, Bayesian neural networks offer a measure of uncertainty associated with predictions. </span><span class="koboSpan" id="kobo.169.3">This probabilistic approach ensures that the model not only gives an estimate but also conveys the confidence or spread of </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">that </span></span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">estimate.</span></span></p>
<p><span class="koboSpan" id="kobo.172.1">These are some of the examples of Bayesian approaches </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">to UQ.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.174.1">Variational inference</span></strong><span class="koboSpan" id="kobo.175.1"> is a technique to approximate the posterior distribution of the model parameters, enabling the network to output distributions </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">for predictions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.177.1">Bayesian neural networks</span></strong><span class="koboSpan" id="kobo.178.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.179.1">BNNs</span></strong><span class="koboSpan" id="kobo.180.1">) are neural networks with weights assigned to probability distributions. </span><span class="koboSpan" id="kobo.180.2">By sampling </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.181.1">from these distributions, BNNs can produce a range of outputs, reflecting the uncertainty </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">in predictions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.183.1">Monte Carlo dropout</span></strong><span class="koboSpan" id="kobo.184.1"> is a technique wherein dropout is applied during inference. </span><span class="koboSpan" id="kobo.184.2">We can gain insight into</span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.185.1"> the model’s uncertainty by running the model multiple times and observing the variance </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">in outputs.</span></span></li>
</ul>
<h2 id="_idParaDest-143"><a id="_idTextAnchor141"/><span class="koboSpan" id="kobo.187.1">Bootstrap methods and ensemble techniques</span></h2>
<p><span class="koboSpan" id="kobo.188.1">Bootstrapping involves creating multiple datasets from the original training data through resampling. </span><span class="koboSpan" id="kobo.188.2">By training separate models on these datasets, we can capture model uncertainty. </span><span class="koboSpan" id="kobo.188.3">This variance </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.189.1">across different resamples allows for</span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.190.1"> a more robust evaluation of how changes in the input data can </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">impact predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.192.1">We will now look at some of the examples of bootstrap methods and model ensembles. </span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.193.1">Bagging</span></strong><span class="koboSpan" id="kobo.194.1">: Short for bootstrap aggregating, this involves training multiple models on different bootstrap </span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.195.1">samples. </span><span class="koboSpan" id="kobo.195.2">The variance in predictions across models provides an estimate </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">of uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.197.1">Model ensembles</span></strong><span class="koboSpan" id="kobo.198.1">: Combining predictions from multiple models can also capture uncertainty. </span><span class="koboSpan" id="kobo.198.2">If models trained on the same data but with different architectures disagree on a prediction, it indicates </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">higher uncertainty.</span></span></li>
</ul>
<h2 id="_idParaDest-144"><a id="_idTextAnchor142"/><span class="koboSpan" id="kobo.200.1">Out-of-distribution (OOD) detection</span></h2>
<p><span class="koboSpan" id="kobo.201.1">Identifying inputs that are significantly</span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.202.1"> different from the training data can also help in </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">uncertainty estimation:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.204.1">Likelihood-based methods</span></strong><span class="koboSpan" id="kobo.205.1">: These methods compare the likelihood of new data points to the training data. </span><span class="koboSpan" id="kobo.205.2">Lower likelihood indicates </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">higher uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.207.1">Adversarial training</span></strong><span class="koboSpan" id="kobo.208.1">: By training models to recognize adversarial examples, we can enhance their ability to identify </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">uncertain inputs.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.210.1">Understanding and appropriately</span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.211.1"> employing these techniques is crucial in NLP, given human language’s inherent ambiguities and nuances. </span><span class="koboSpan" id="kobo.211.2">Each approach has its strengths and suitable scenarios, so practitioners must choose wisely based on the specifics of their </span><span class="No-Break"><span class="koboSpan" id="kobo.212.1">NLP task.</span></span></p>
<h1 id="_idParaDest-145"><a id="_idTextAnchor143"/><span class="koboSpan" id="kobo.213.1">Conformal prediction for NLP</span></h1>
<p><span class="koboSpan" id="kobo.214.1">Conformal prediction is a flexible and statistically robust approach to uncertainty quantification. </span><span class="koboSpan" id="kobo.214.2">It is a distribution-free framework that can estimate uncertainty for machine learning models without requiring model retraining or access to limited APIs. </span><span class="koboSpan" id="kobo.214.3">The central idea behind </span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.215.1">conformal prediction is to output a set of predictions containing the correct output with a user-specified probability. </span><span class="koboSpan" id="kobo.215.2">Conformal prediction can help quantify the uncertainty associated with the model’s predictions in </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">language models.</span></span></p>
<p><span class="koboSpan" id="kobo.217.1">Conformal prediction is a framework that delivers valid confidence intervals for predictions, irrespective of the underlying machine learning model. </span><span class="koboSpan" id="kobo.217.2">In the NLP landscape, with its inherent challenges of ambiguity, context sensitivity, and linguistic diversity, conformal prediction offers a structured way to </span><span class="No-Break"><span class="koboSpan" id="kobo.218.1">quantify uncertainty.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.219.1">Validity and efficiency</span></strong><span class="koboSpan" id="kobo.220.1"> are the two fundamental principles of conformal prediction. </span><span class="koboSpan" id="kobo.220.2">Validity ensures that the prediction regions (or sets) are correct with a predefined probability, while efficiency ensures these regions are as tight </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">as possible.</span></span></p>
<h2 id="_idParaDest-146"><a id="_idTextAnchor144"/><span class="koboSpan" id="kobo.222.1">How conformal prediction works in NLP</span></h2>
<p><span class="koboSpan" id="kobo.223.1">The mechanics of conformal prediction</span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.224.1"> are rooted in ordering predictions based on their “strangeness” or non-conformity scores. </span><span class="koboSpan" id="kobo.224.2">The idea is to understand how different a new observation is compared to </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">previous ones:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.226.1">Non-conformity score</span></strong><span class="koboSpan" id="kobo.227.1">: This score measures how different a new prediction is from previous predictions for any NLP task. </span><span class="koboSpan" id="kobo.227.2">For instance, the non-conformity might be based on the distance from the decision boundary in </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">text classification.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.229.1">P-values</span></strong><span class="koboSpan" id="kobo.230.1">: P-values are</span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.231.1"> calculated based on the non-conformity scores, representing the confidence level </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">of predictions.</span></span></li>
</ul>
<h2 id="_idParaDest-147"><a id="_idTextAnchor145"/><span class="koboSpan" id="kobo.233.1">Practical applications of conformal prediction in NLP</span></h2>
<p><span class="koboSpan" id="kobo.234.1">Conformal prediction isn’t just a</span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.235.1"> theoretical construct; its practical applications in NLP </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">are wide-ranging:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.237.1">Sentiment analysis</span></strong><span class="koboSpan" id="kobo.238.1">: When determining the sentiment of a text snippet, conformal prediction can provide a range or set of possible sentiments, each with its </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">confidence level</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.240.1">Named entity recognition</span></strong><span class="koboSpan" id="kobo.241.1">: Conformal prediction can give a confidence score on each tagged entity instead of just tagging entities, helping in tasks where precision </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">is critical</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.243.1">Machine translation</span></strong><span class="koboSpan" id="kobo.244.1">: Beyond translating text, conformal prediction can offer confidence intervals for different translation choices, aiding in tasks where mistranslations can have </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">significant consequences</span></span></li>
</ul>
<h2 id="_idParaDest-148"><a id="_idTextAnchor146"/><span class="koboSpan" id="kobo.246.1">Advantages of using conformal prediction in NLP</span></h2>
<p><span class="koboSpan" id="kobo.247.1">Conformal prediction, a relatively recent development in uncertainty quantification, brings a fresh perspective and many benefits to NLP. </span><span class="koboSpan" id="kobo.247.2">As we venture into an era where the demand for reliable and </span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.248.1">trustworthy models is ever-increasing, methods such as conformal prediction stand out, promising to address some innate challenges in NLP. </span><span class="koboSpan" id="kobo.248.2">Let’s delve into the distinct advantages of integrating conformal prediction in </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">NLP tasks:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.250.1">Model agnostic</span></strong><span class="koboSpan" id="kobo.251.1">: One of the strengths of conformal prediction is its compatibility with any machine</span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.252.1"> learning model. </span><span class="koboSpan" id="kobo.252.2">Conformal prediction can be applied to any statistical, machine, or deep </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">learning model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.254.1">Transparent and interpretable</span></strong><span class="koboSpan" id="kobo.255.1">: Conformal prediction doesn’t operate as a black box. </span><span class="koboSpan" id="kobo.255.2">The non-conformity scores and resulting p-values offer interpretable metrics </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">of uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.257.1">Adaptive</span></strong><span class="koboSpan" id="kobo.258.1">: Conformal prediction is adaptive to the data it’s applied to. </span><span class="koboSpan" id="kobo.258.2">It doesn’t make strong distributional assumptions, making it robust despite diverse </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">linguistic data.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.260.1">The introduction of conformal </span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.261.1">prediction into the NLP toolkit offers a promising avenue for practitioners to handle the inherent uncertainties of human language. </span><span class="koboSpan" id="kobo.261.2">Providing valid and reliable confidence measures helps build more robust and trustworthy </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">NLP systems.</span></span></p>
<p><span class="koboSpan" id="kobo.263.1">An example of applied conformal prediction on an NLP task, such as IMDB Movie reviews that have been pre-labeled with “positive” and “negative” sentiment class labels based on the review content, has been discussed </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">here: </span></span><a href="https://github.com/M-Soundouss/density_based_conformal_prediction/tree/master/imdb"><span class="No-Break"><span class="koboSpan" id="kobo.265.1">https://github.com/M-Soundouss/density_based_conformal_prediction/tree/master/imdb</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.266.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.267.1">Conformal prediction for NLP and LLMs is an emerging and crucial area </span><span class="No-Break"><span class="koboSpan" id="kobo.268.1">of research.</span></span></p>
<p><span class="koboSpan" id="kobo.269.1">A notable contribution to this field is a paper by Kumar et.al., titled </span><em class="italic"><span class="koboSpan" id="kobo.270.1">Conformal Prediction with Large Language Models for Multi-Choice Question </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.271.1">Answering</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.272.1"> (</span></span><a href="https://arxiv.org/abs/2305.18404"><span class="No-Break"><span class="koboSpan" id="kobo.273.1">https://arxiv.org/abs/2305.18404</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.274.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.275.1">This paper dives deep into how conformal prediction can be instrumental in quantifying uncertainty in language models, thereby paving the way for a more trustworthy and reliable deployment of large language models, especially in scenarios where safety </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">is paramount.</span></span></p>
<p><span class="koboSpan" id="kobo.277.1">The paper’s primary focus is on multiple-choice question-answering tasks. </span><span class="koboSpan" id="kobo.277.2">Through a series of experiments, it showcases the efficacy of conformal prediction in deriving uncertainty estimates that are in strong correlation with </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">prediction accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.279.1">Diving into the experimental setup, the authors employed the LLaMA-13B model. </span><span class="koboSpan" id="kobo.279.2">This model, boasting 13 billion parameters and trained on a staggering 1 trillion tokens, generated predictions for MCQA questions sourced from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.280.1">MMLU benchmark</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.281.1">dataset (</span></span><a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu"><span class="No-Break"><span class="koboSpan" id="kobo.282.1">https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.283.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.284.1">The experiments were structured around a calibration set that trained the conformal prediction model and an evaluation set that tested the model’s prowess. </span><span class="koboSpan" id="kobo.284.2">A cross-validation approach was adopted to ensure the experiment’s integrity, ensuring the calibration and evaluation sets were sampled from a </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">consistent distribution.</span></span></p>
<p><span class="koboSpan" id="kobo.286.1">The performance metrics were multifaceted, encompassing accuracy, coverage, and efficiency. </span><span class="koboSpan" id="kobo.286.2">A pivotal observation was that the softmax outputs from the LLaMA-13B model, while reasonably calibrated on average, exhibited tendencies of underconfidence and overconfidence, particularly at the extremities of the probability distribution. </span><span class="koboSpan" id="kobo.286.3">This observation </span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.287.1">was particularly pronounced in subjects such as formal logic and college chemistry, which inherently possess more ambiguity and complexity, making them challenging for LLMs to </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">navigate accurately.</span></span></p>
<p><span class="koboSpan" id="kobo.289.1">One of the standout findings was the strong correlation between the uncertainty estimates provided by conformal prediction and prediction accuracy. </span><span class="koboSpan" id="kobo.289.2">Such a correlation implies that when the model exhibits higher uncertainty about its predictions, it’s more prone to errors. </span><span class="koboSpan" id="kobo.289.3">This insight is invaluable for downstream applications such as selective classification. </span><span class="koboSpan" id="kobo.289.4">By leveraging these uncertainty estimates, it’s feasible to filter out lower-quality predictions, thereby enhancing the overall </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">user experience.</span></span></p>
<p><span class="koboSpan" id="kobo.291.1">The paper underscores the potential of conformal prediction as a beacon for uncertainty quantification in LLMs. </span><span class="koboSpan" id="kobo.291.2">By integrating this approach, LLMs can be more reliable, especially in high-stakes environments, reinforcing their trustworthiness and broadening </span><span class="No-Break"><span class="koboSpan" id="kobo.292.1">their applicability.</span></span></p>
<p><span class="koboSpan" id="kobo.293.1">The second critical paper is </span><em class="italic"><span class="koboSpan" id="kobo.294.1">Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners</span></em><span class="koboSpan" id="kobo.295.1"> (</span><a href="https://robot-help.github.io"><span class="koboSpan" id="kobo.296.1">https://robot-help.github.io</span></a><span class="koboSpan" id="kobo.297.1">), published by a team of researchers from Princeton University </span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">and DeepMind.</span></span></p>
<p><span class="koboSpan" id="kobo.299.1">In robotics and artificial intelligence, the aspiration to equip robots with the capability to discern when uncertain is a pivotal challenge. </span><span class="koboSpan" id="kobo.299.2">The paper addresses this challenge, particularly regarding robots instructed via language. </span><span class="koboSpan" id="kobo.299.3">With its inherent flexibility, language offers a natural interface for humans to convey tasks, contextual information, and intentions. </span><span class="koboSpan" id="kobo.299.4">It also facilitates humans in providing clarifications to robots when they </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">encounter uncertainties.</span></span></p>
<p><span class="koboSpan" id="kobo.301.1">Recent advancements have showcased the potential of LLMs in planning. </span><span class="koboSpan" id="kobo.301.2">These models can interpret and respond to unstructured language instructions, generating temporally extended plans. </span><span class="koboSpan" id="kobo.301.3">The strength of these LLMs lies in their ability to harness the vast knowledge and rich context they have been pre-trained with, leading to enhanced abstract reasoning capabilities. </span><span class="koboSpan" id="kobo.301.4">However, a significant impediment with current LLMs is their propensity to “hallucinate.” </span><span class="koboSpan" id="kobo.301.5">In other words, they tend to generate outputs with high confidence that, while plausible, might be incorrect and not anchored </span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">in reality.</span></span></p>
<p><span class="koboSpan" id="kobo.303.1">Such unwarranted confidence in outputs can be detrimental, especially in LLM-based robotic planning. </span><span class="koboSpan" id="kobo.303.2">This is further exacerbated when natural language instructions, often riddled with inherent or unintentional ambiguities, are provided in real-world settings. </span><span class="koboSpan" id="kobo.303.3">Misinterpreting such instructions can lead to undesirable or, in extreme cases, </span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">unsafe actions.</span></span></p>
<p><span class="koboSpan" id="kobo.305.1">To illustrate, the paper</span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.306.1"> presents an example where a robot tasked with heating food is instructed to place a bowl in the microwave. </span><span class="koboSpan" id="kobo.306.2">In scenarios where multiple bowls are present, such an instruction becomes ambiguous. </span><span class="koboSpan" id="kobo.306.3">Moreover, if one of the bowls is metallic, placing it in the microwave would be hazardous. </span><span class="koboSpan" id="kobo.306.4">Instead of acting on such vague instructions, the ideal robot should recognize its uncertainty and seek clarification. </span><span class="koboSpan" id="kobo.306.5">While previous works in language-based planning have either overlooked the need for such clarifications or relied heavily on extensive prompting, this paper </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">introduces </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.308.1">KNOWNO</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.310.1">KNOWNO is a framework designed to measure and align the uncertainty of LLM-based planners. </span><span class="koboSpan" id="kobo.310.2">It ensures that these planners </span><a id="_idIndexMarker560"/><span class="koboSpan" id="kobo.311.1">know their limitations and seek assistance when required. </span><span class="koboSpan" id="kobo.311.2">The foundation of KNOWNO is built on the theory of conformal prediction, which offers statistical guarantees on task completion while minimizing the need for human intervention in intricate multi-step planning settings. </span><span class="koboSpan" id="kobo.311.3">Experiments across various simulated and real robot setups demonstrate the framework’s efficacy. </span><span class="koboSpan" id="kobo.311.4">These experiments encompass tasks with diverse modes of ambiguity, ranging from spatial uncertainties to numeric ones and from human preferences to </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">Winograd schemas.</span></span></p>
<p><span class="koboSpan" id="kobo.313.1">The paper posits KNOWNO as a promising lightweight approach to model uncertainty. </span><span class="koboSpan" id="kobo.313.2">It can seamlessly complement and scale with the burgeoning capabilities of foundational models. </span><span class="koboSpan" id="kobo.313.3">LLMs can be more reliable by leveraging conformal prediction, especially when precision and safety </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">are paramount.</span></span></p>
<h1 id="_idParaDest-149"><a id="_idTextAnchor147"/><span class="koboSpan" id="kobo.315.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.316.1">In the chapter, we have explored the inherent uncertainty challenges in the NLP domain. </span><span class="koboSpan" id="kobo.316.2">Recognizing the pivotal role of NLP models in today’s critical systems, the chapter emphasizes the importance of ensuring these models’ predictions are trustworthy and reliable. </span><span class="koboSpan" id="kobo.316.3">The chapter introduces conformal prediction as a solution to address the miscalibration seen in deep learning models’ outputs, offering a means to quantify the confidence of predictions robustly. </span><span class="koboSpan" id="kobo.316.4">Throughout this chapter, you gained insights into the intricacies of uncertainty quantification specific to NLP, the reasons why deep learning models often produce miscalibrated predictions, and various methods of quantifying uncertainty in NLP. </span><span class="koboSpan" id="kobo.316.5">Finally, we deeply studied the conformal prediction technique tailored for </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">NLP tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.318.1">At the end of this chapter, you should have a holistic understanding of the challenges of uncertainty in NLP, the merits and mechanics of conformal prediction, and practical knowledge to apply this technique to NLP </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">problems effectively.</span></span></p>
<p><span class="koboSpan" id="kobo.320.1">In the next chapter, we will dive deep into the intriguing world of imbalanced data and show how conformal prediction can address existing challenges in handling </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">such scenarios.</span></span></p>
</div>


<div class="Content" id="_idContainer066">
<h1 id="_idParaDest-150" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor148"/><span class="koboSpan" id="kobo.1.1">Part 4: Advanced Topics</span></h1>
<p><span class="koboSpan" id="kobo.2.1">This part will provide illustrations on how conformal prediction can be used to solve imbalanced data problems, introducing you to various conformal prediction methods that can be used for multi-class </span><span class="No-Break"><span class="koboSpan" id="kobo.3.1">classification problems.</span></span></p>
<p><span class="koboSpan" id="kobo.4.1">This section has the </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1">following chapters:</span></span></p>
<ul>
<li><a href="B19925_11.xhtml#_idTextAnchor149"><em class="italic"><span class="koboSpan" id="kobo.6.1">Chapter 11</span></em></a><span class="koboSpan" id="kobo.7.1">, </span><em class="italic"><span class="koboSpan" id="kobo.8.1">Handling Imbalanced Data</span></em></li>
<li><a href="B19925_12.xhtml#_idTextAnchor159"><em class="italic"><span class="koboSpan" id="kobo.9.1">Chapter 12</span></em></a><span class="koboSpan" id="kobo.10.1">, </span><em class="italic"><span class="koboSpan" id="kobo.11.1">Multi-Class Conformal Prediction</span></em></li>
</ul>
</div>
<div>
<div id="_idContainer067">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer068">
</div>
</div>
</body></html>