- en: <st c="0">5</st>
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2">Working with Outliers</st>
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="23">An outlier</st> <st c="34">is a data point that diverges notably
    from other values within a variable.</st> <st c="110">Outliers may stem from the
    inherent variability of the feature itself, manifesting as extreme values that
    occur infrequently within the distribution (typically found in the tails).</st>
    <st c="291">They can be the result of experimental errors or inaccuracies in data
    collection processes, or they can signal important events.</st> <st c="420">For
    instance, an unusually high expense in a card transaction may indicate fraudulent
    activity, warranting flagging and potentially blocking the card to safeguard customers.</st>
    <st c="594">Similarly, unusually distinct tumor morphologies can suggest malignancy,
    prompting</st> <st c="677">further examination.</st>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: <st c="697">Outliers can exert a disproportionately large impact on a statistical
    analysis.</st> <st c="778">For example, a small number of outliers can reverse
    the statistical significance of a test in either direction (think A/B testing)
    or directly influence the estimation of the parameters of the statistical model
    (think coefficients).</st> <st c="1011">Some machine learning models are well
    known for being susceptible to outliers, such as linear regression.</st> <st c="1117">Other
    models are known for being robust to outliers, such as decision-tree-based models.</st>
    <st c="1206">AdaBoost is said to be sensitive to outliers in the target variable,
    and in principle, distance-based models, such as PCA and KNN, could also be affected
    by the presence</st> <st c="1376">of outliers.</st>
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1388">There isn’t a strict mathematical definition for what qualifies
    as an outlier, and there is also no consensus on how to handle outliers in statistical
    or machine learning models.</st> <st c="1568">If outliers stem from flawed data
    collection, discarding them seems like a safe option.</st> <st c="1656">However,
    in many datasets, pinpointing the exact nature of outliers is challenging.</st>
    <st c="1740">Ultimately, detecting and handling outliers remains a subjective
    exercise, reliant on domain knowledge and an understanding of their potential
    impact</st> <st c="1890">on models.</st>
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1900">In this chapter, we will begin by discussing methods to identify
    potential outliers, or more precisely, observations that significantly deviate
    from the rest.</st> <st c="2060">Then, we’ll proceed under the assumption that
    these observations are not relevant for the analysis, and show how to either remove
    them or reduce their impact on models</st> <st c="2228">through truncation.</st>
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2247">This chapter contains the</st> <st c="2274">following recipes:</st>
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2292">Visualizing outliers with boxplots and the inter-quartile</st>
    <st c="2351">proximity rule</st>
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2365">Finding outliers using the mean and</st> <st c="2402">standard
    deviation</st>
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2420">Using the median absolute deviation to</st> <st c="2460">find outliers</st>
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2473">Removing outliers</st>
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2491">Bringing outliers back within</st> <st c="2522">acceptable limits</st>
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2539">Applying winsorization</st>
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2562">Technical requirements</st>
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2585">In this chapter, we will use the Python</st> `<st c="2626">numpy</st>`<st
    c="2631">,</st> `<st c="2633">pandas</st>`<st c="2639">,</st> `<st c="2641">matplotlib</st>`<st
    c="2651">,</st> `<st c="2653">seaborn</st>`<st c="2660">, and</st> `<st c="2666">feature-engine</st>`
    <st c="2680">libraries.</st>
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2691">Visualizing outliers with boxplots and the inter-quartile proximity
    rule</st>
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2764">A</st> <st c="2767">common way to visualize outliers is by usin</st><st
    c="2810">g boxplots.</st> <st c="2823">Boxplots</st> <st c="2832">provide a standardized
    display of the variable’s distribution based on quartiles.</st> <st c="2914">The
    box contains the observations within the first and third quartiles, known as the</st>
    **<st c="2999">Inter-Quartile Range</st>**<st c="3019">(</st>**<st c="3021">IQR</st>**<st
    c="3024">).</st> <st c="3028">The</st> <st c="3031">first quartile is the value
    below which 25% of the observations lie (equivalent to the 25th percentile), while
    the third quartile is the value below which 75% of the observations lie (equivalent
    to the 75th percentile).</st> <st c="3252">The IQR is calculated</st> <st c="3274">as
    follows:</st>
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>I</mml:mi><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo> </mml:mo><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo> </mml:mo><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:math>](img/21.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: <st c="3320">Boxplots also</st> <st c="3334">display whiskers, which are lines
    that protrude from each end of the box toward the minimum and maximum values and
    up to a limit.</st> <st c="3464">These limits are given by the minimum or maximum
    value of the distribution or, in the presence of extreme values, by the</st> <st
    c="3585">following equations:</st>
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>u</mi><mi>p</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>t</mi><mo>=</mo><mn>3</mn><mi>r</mi><mi>d</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>l</mi><mi>e</mi><mo>+</mo><mi>I</mi><mi>Q</mi><mi>R</mi><mo>×</mo><mn>1.5</mn></mrow></mrow></math>](img/22.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>l</mi><mi>o</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>t</mi><mo>=</mo><mn>1</mn><mi>s</mi><mi>t</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>l</mi><mi>e</mi><mo>−</mo><mi>I</mi><mi>Q</mi><mi>R</mi><mo>×</mo><mn>1.5</mn></mrow></mrow></math>](img/23.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: <st c="3684">According to the</st> **<st c="3701">IQR proximity rule</st>**<st
    c="3719">, we</st> <st c="3723">can consider a value an</st> <st c="3747">outlier
    if it falls beyond the whisker limits determined by the previous equations.</st>
    <st c="3832">In boxplots, outliers are indicated</st> <st c="3868">as dots.</st>
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3876">Note</st>
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3881">If the variable has a normal distribution, about 99% of the observations
    will be located within the interval delimited by the whiskers.</st> <st c="4018">Hence,
    we can treat values beyond the whiskers as outliers.</st> <st c="4078">Boxplots
    are, however, non-parametric, which is why we also use them to visualize outliers
    in</st> <st c="4172">skewed variables.</st>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4189">In this</st> <st c="4198">recipe, we’ll begin by visualizing the
    variable distribution with boxplots, and then we’ll calculate the whisker’s limits
    manually to identify the points beyond which we could consider a value as</st>
    <st c="4394">an o</st><st c="4398">utlier.</st>
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4406">How to do it...</st>
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="4422">We will create boxplots utilizing the</st> `<st c="4461">seaborn</st>`
    <st c="4468">library</st><st c="4476">. Let’s begin by importing the Python libraries
    and loading</st> <st c="4536">the dataset:</st>
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4548">Let’s import the Python libraries and</st> <st c="4587">the dataset:</st>
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: <st c="4707">Modify the default background from</st> `<st c="4743">seaborn</st>`
    <st c="4750">(it makes prettier plots, but that’s subjective,</st> <st c="4800">of
    course):</st>
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: <st c="4837">Load the California house prices dataset</st> <st c="4879">from
    scikit-learn:</st>
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: <st c="4962">Make a boxplot of the</st> `<st c="4985">MedInc</st>` <st c="4991">variable
    to visualize</st> <st c="5014">its distribution:</st>
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: <st c="5132">In the following boxplot, we identify the box containing the observations
    within the IQR, that is, the observations between the first and third quartiles.</st>
    <st c="5288">We also see the whiskers.</st> <st c="5314">On</st> <st c="5316">the
    left, the whisker extends to the minimum value of</st> `<st c="5371">MedInc</st>`<st
    c="5377">; on the right, the whisker goes up to the third quartile plus 1.5 times
    the IQR.</st> <st c="5460">Values beyond the right whisker are represented as
    dots and could</st> <st c="5526">constitute out</st><st c="5540">liers:</st>
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Boxplot of the MedInc variable highlighting potential outliers
    on the right tail of the distribution](img/B22396_05_1.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: <st c="5569">Figure 5.1 – Boxplot of the MedInc variable highlighting potential
    outliers on the right tail of the distribution</st>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5682">Note</st>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5687">As shown in</st> *<st c="5700">Figure 5</st>**<st c="5708">.1</st>*<st
    c="5710">, the boxplot returns asymmetric boundaries denoted by the varying lengths
    of the left and right whiskers.</st> <st c="5817">This makes boxplots a suitable
    method for identifying outliers in highly skewed distributions.</st> <st c="5912">As
    we’ll see in the coming recipes, alternative methods to identify outliers create
    symmetric boundaries around the center of the distribution, which may not be the
    best option for</st> <st c="6093">asymmetric distributions</st><st c="6117">.</st>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6118">Let’s now create a function to</st> <st c="6149">plot a boxplot
    next to</st> <st c="6173">a histogram:</st>
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <st c="6427">Let’s use</st> <st c="6437">the previous</st> <st c="6450">function
    to create the plots for the</st> `<st c="6487">MedInc</st>` <st c="6493">variable:</st>
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: <st c="6538">In the following figure, we can see the relationship between the
    boxplot and the variable’s distribution shown in the histogram.</st> <st c="6668">Note
    how most of</st> `<st c="6685">MedInc</st>`<st c="6691">’s observations are located
    within the IQR box.</st> `<st c="6740">MedInc</st>`<st c="6746">’s potential outliers
    lie on the right tail, corresponding to people with unusually</st> <st c="6831">high-income
    sa</st><st c="6845">laries:</st>
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Boxplot and histogram – two ways of displaying a variable’s
    distribution](img/B22396_05_2.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: <st c="6920">Figure 5.2 – Boxplot and histogram – two ways of displaying a variable’s
    distribution</st>
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7005">Now that</st> <st c="7015">we’ve seen how we can visualize outliers,
    let’s see how to calculate the limits beyond which we find outliers at each side
    of</st> <st c="7141">the distribution.</st>
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7158">Let’s create a function that returns the limits based on the IQR</st>
    <st c="7224">proximity rule:</st>
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: <st c="7452">Note</st>
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7457">Remember that the first and third quartiles are equivalent to the
    25th and 75th percentiles.</st> <st c="7551">That’s why we use pandas’</st> `<st
    c="7577">quantile</st>` <st c="7585">to determine</st> <st c="7599">those values.</st>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7612">With the function from</st> *<st c="7636">step 7</st>*<st c="7642">,
    we’ll calculate the extreme limits</st> <st c="7679">for</st> `<st c="7683">MedInc</st>`<st
    c="7689">:</st>
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: <st c="7749">If we now execute</st> `<st c="7768">lower_limit</st>` <st c="7779">and</st>
    `<st c="7784">upper_limit</st>`<st c="7795">, we will see the values</st> `<st
    c="7820">-0.7063</st>` <st c="7827">and</st> `<st c="7832">8.013</st>`<st c="7837">.
    The lower limit is beyond</st> `<st c="7865">MedInc</st>`<st c="7871">’s minimum
    value, hence in</st> <st c="7899">the boxplot, the whisker only goes up to the
    minimum value.</st> <st c="7959">The upper limit, on the other hand, coincides
    with the right</st> <st c="8020">whisker’s limit.</st>
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="8036">Note</st>
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8041">Common values to multiply the IQR are</st> `<st c="8080">1.5</st>`<st
    c="8083">, which is the default value in boxplots, or</st> `<st c="8128">3</st>`
    <st c="8130">if we want to be</st> <st c="8147">more conservative.</st>
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8165">Let’s display the box plot and histogram for the</st> `<st c="8215">HouseAge</st>`
    <st c="8223">variable:</st>
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: <st c="8270">We can see that this variable does not seem to contain outliers,
    and hence the whiskers in the box plot extend to the minimum and</st> <st c="8401">maximum
    values:</st>
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Boxplot and histogram of the HouseAge variable](img/B22396_05_3.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: <st c="8438">Figure 5.3 – Boxplot and histogram of the HouseAge variable</st>
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8497">Let’s</st> <st c="8503">find the variable’s limits according to
    the IQR</st> <st c="8552">proximity rule:</st>
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: <st c="8627">If we execute</st> `<st c="8642">lower_limit</st>` <st c="8653">and</st>
    `<st c="8658">upper_limit</st>`<st c="8669">, we will see the values</st> `<st
    c="8694">-10.5</st>` <st c="8699">and</st> `<st c="8704">65.5</st>`<st c="8708">,
    which are beyond the edges of the plots, and hence we don’t see</st> <st c="8774">any</st>
    <st c="8778">outliers.</st>
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8787">How it works</st><st c="8800">…</st>
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="8801">In this recipe, we used the</st> `<st c="8829">boxplot</st>` <st
    c="8836">method from Seaborn to create the boxplots and then we calculated the
    limits beyond which a value could be considered an outlier based on the IQR</st>
    <st c="8983">proximity rule.</st>
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8998">In</st> *<st c="9002">Figure 5</st>**<st c="9010">.2</st>*<st c="9012">,
    we saw that the box in the boxplot for</st> `<st c="9053">MedInc</st>` <st c="9059">extended
    from approximately 2 to 5, corresponding to the first and third quantiles (you
    can determine these values precisely by executing</st> `<st c="9198">X[</st>`<st
    c="9200">“</st>`<st c="9202">MedInc</st>`<st c="9208">”</st>`<st c="9210">].quantile(0.25)</st>`
    <st c="9226">and</st> `<st c="9231">X[</st>`<st c="9233">“</st>`<st c="9235">MedInc</st>`<st
    c="9241">”</st>`<st c="9243">].quantile(0.75)</st>`<st c="9259">).</st> <st c="9263">We
    also saw that the whiskers start at</st> `<st c="9302">MedInc</st>`<st c="9308">’s
    minimum on the left and extend up to</st> `<st c="9349">8.013</st>` <st c="9354">on
    the right (we know this value exactly because we calculated it in</st> *<st c="9424">step
    8</st>*<st c="9430">).</st> `<st c="9434">MedInc</st>` <st c="9440">showed values
    greater than</st> `<st c="9468">8.013</st>`<st c="9473">, which were displayed</st>
    <st c="9495">in the boxplot as dots.</st> <st c="9520">Those are the values that
    could be</st> <st c="9555">considered outliers.</st>
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9575">In</st> *<st c="9579">Figure 5</st>**<st c="9587">.3</st>*<st c="9589">,
    we displayed the boxplot for the</st> `<st c="9624">HouseAge</st>` <st c="9632">variable.</st>
    <st c="9643">The box included values ranging from approximately 18 to 35 (you
    can determine the precise values by executing</st> `<st c="9754">X[</st>`<st c="9756">“</st>`<st
    c="9758">HouseAge</st>`<st c="9766">”</st>`<st c="9768">].quantile(0.25)</st>`
    <st c="9784">and</st> `<st c="9789">X[</st>`<st c="9791">“</st>`<st c="9793">HouseAge</st>`<st
    c="9801">”</st>`<st c="9803">].quantile(0.75)</st>`<st c="9819">).</st> <st c="9823">The
    whiskers extended to the minimum and maximum values of the distribution.</st>
    <st c="9900">The limits of the whiskers in the plot did not coincide with those
    based on the IQR proximity rule (which we calculated in</st> *<st c="10023">step
    10</st>*<st c="10030">) because these limits were far beyond the value range observed
    for</st> <st c="10099">this</st> <st c="10103">variable.</st>
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10113">Finding outliers using the mean and standard deviation</st>
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="10168">I</st><st c="10170">n</st> <st c="10172">normally distributed
    variables, around 99.8% of the observations lie within the interval comprising
    the mean plus and minus</st> <st c="10296">thr</st><st c="10299">ee times the
    standard devi</st><st c="10326">ation.</st> <st c="10334">Thus, values beyond
    those limits can be considered outliers; they</st> <st c="10400">are rare.</st>
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10409">Note</st>
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10414">Using the mean and standard deviation to detect outliers has some
    drawbacks.</st> <st c="10492">Firstly, it assumes a normal distribution, including
    outliers.</st> <st c="10555">Secondly, outliers strongly influence the mean and
    standard deviation.</st> <st c="10626">Therefore, a recommended alternative is
    the</st> **<st c="10670">Median Absolute Deviation</st>** <st c="10695">(</st>**<st
    c="10697">MAD</st>**<st c="10700">), which</st> <st c="10709">we’ll discuss in
    the</st> <st c="10731">next recipe.</st>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10743">In this recipe, we will identify outliers as those observations
    that lie outside the interval delimited by the mean plus and minus three times
    the</st> <st c="10891">standa</st><st c="10897">rd deviation.</st>
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10911">How to do it...</st>
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="10927">Let’s begin the</st> <st c="10943">recipe by importing the Python
    libraries and loading</st> <st c="10997">the dataset:</st>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11009">Let’s import the Python libraries</st> <st c="11044">and dataset:</st>
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: <st c="11177">Load the breast cancer dataset</st> <st c="11209">from scikit-learn:</st>
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: <st c="11286">Create</st> <st c="11294">a function to plot a</st> <st c="11315">boxplot
    next to</st> <st c="11331">a histogram:</st>
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: <st c="11584">Note</st>
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11589">We discussed the function from</st> *<st c="11621">step 3</st>*
    <st c="11627">in the previous recipe,</st> *<st c="11652">Visualizing outliers
    with boxplots and the inter-quartile</st>* *<st c="11710">proximity rule</st>*<st
    c="11724">.</st>
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11725">Let’s plot the distribution of the</st> `<st c="11761">mean</st>`
    `<st c="11766">smoothness</st>` <st c="11776">variable:</st>
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: <st c="11830">In the</st> <st c="11837">following boxplot, we see that the variable’s
    values show a distribution like the</st> <st c="11919">normal distribution, and
    it has six outliers – one on the left and five on the</st> <st c="11999">right
    tail:</st>
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Boxplot and histogram of the variable mean smoothness](img/B22396_05_4.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: <st c="12063">Figure 5.4 – Boxplot and histogram of the variable mean smoothness</st>
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12129">Create a function that returns the mean plus and minus</st> `<st
    c="12185">fold</st>` <st c="12189">times the standard deviation, where</st> `<st
    c="12226">fold</st>` <st c="12230">is a parameter to</st> <st c="12249">the function:</st>
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: <st c="12471">Use the</st> <st c="12479">function to identify the extreme limits
    of the</st> `<st c="12527">mean</st>` `<st c="12532">smoothness</st>` <st c="12542">variable:</st>
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: <st c="12618">If we now execute</st> `<st c="12637">lower_limit</st>` <st c="12648">or</st>
    `<st c="12652">upper_limit</st>`<st c="12663">, we will see the values</st> `<st
    c="12688">0.0541</st>` <st c="12694">and</st> `<st c="12699">0.13</st><st c="12703">855</st>`<st
    c="12707">, correspon</st><st c="12718">ding to the limits beyond which we can
    consider a value</st> <st c="12775">an outlier.</st>
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="12786">Note</st>
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12791">The interval between the mean plus and minus three times the standard
    deviation encloses 99.87% of the observations if the variable is normally distributed.</st>
    <st c="12949">For less conservative limits, we could multiply the standard deviation
    by 2 or 2.5, which would produce intervals that enclose 95.4% and 97.6% of the</st>
    <st c="13099">observations, respectively.</st>
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13126">Create</st> <st c="13134">a Boolean vector that flags observations
    with values beyond the limits determined in</st> *<st c="13219">step 6</st>*<st
    c="13225">:</st>
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: <st c="13339">If we now execute</st> `<st c="13358">outliers.sum()</st>`<st
    c="13372">, we will see the value</st> `<st c="13396">5</st>`<st c="13397">, indicating
    that there are five outliers or observations that are smaller or greater than
    the extreme values found with the mean and the standard deviation.</st> <st c="13555">According
    to these limits, we’d identify one outlier less compared to the</st> <st c="13629">IQR
    rule.</st>
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="13638">Let’s add red vertical lines to the histogram from</st> *<st c="13690">step
    3</st>* <st c="13696">to highlight the limits determined</st> <st c="13731">by
    using the mean and the</st> <st c="13758">standard deviation:</st>
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: <st c="14128">And</st> <st c="14133">now let’s make</st> <st c="14148">the plots:</st>
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: <st c="14202">In the following plot, we see that the limits observed by the
    IQR proximity rule in the box plot are less conservative than those identified
    by the mean and the standard deviation.</st> <st c="14384">Hence why we observe
    six potential outliers in the boxplot, but only five based on the mean and standard</st>
    <st c="14489">deviation calculations:</st>
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Comparison of the limits between the whiskers in the boxplot
    and those determined by using the mean and the standard deviation (vertical lines
    in the histogram)](img/B22396_05_5.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: <st c="14560">Figure 5.5 – Comparison of the limits between the whiskers in
    the boxplot and those determined by using the mean and the standard deviation
    (vertical lines in the histogram)</st>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14733">The</st> <st c="14738">boundaries derived from the</st> <st c="14766">mean
    and standard deviation are symmetric.</st> <st c="14809">They extend equidistantly
    from the center of the distribution toward both tails.</st> <st c="14890">As previously
    mentioned, these boundaries are only suitable for normally</st> <st c="14962">distributed
    variables.</st>
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14985">How it works…</st>
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="14999">With pandas’</st> `<st c="15013">mean()</st>` <st c="15019">and</st>
    `<st c="15024">std()</st>`<st c="15029">, we captured the mean and standard deviation
    of the variable.</st> <st c="15092">We determined the limits as the mean plus
    and minus three times the standard deviation.</st> <st c="15180">To highlight
    the outliers, we used NumPy’s</st> `<st c="15223">where()</st>`<st c="15230">.
    The</st> `<st c="15236">where()</st>` <st c="15243">function scanned the rows
    of the vari</st><st c="15281">able, and if the value was</st> <st c="15309">greater
    than the upper limit or smaller than the lower limit, it was assigned</st> `<st
    c="15387">True</st>`<st c="15391">, and alternatively</st> `<st c="15411">False</st>`<st
    c="15416">. Finally, we used pandas’</st> `<st c="15443">sum()</st>` <st c="15448">over
    this Boolean vector to calculate the total number</st> <st c="15504">of outliers.</st>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15516">Finally, we compared the boundaries to determine outliers returned
    by the IQR proximity rule, which we discussed in the previous recipe,</st> *<st
    c="15654">Visualizing outliers with boxplots and the inter-quartile proximity
    rule</st>*<st c="15726">, and the mean and the standard deviation.</st> <st c="15769">We
    observed that the limits of the IQR rule are less conservative.</st> <st c="15836">That
    means that with the IQR rule, we’d flag more outliers in this</st> <st c="15903">particular
    variable.</st>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15923">Using the median absolute deviation to find outliers</st>
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="15976">The mean</st> <st c="15986">and the standard deviation are heavily
    impacted by outliers.</st> <st c="16047">Hence, using these parameters to identify
    outliers can defeat the purpose.</st> <st c="16122">A better way to identify outliers
    is</st> <st c="16159">by using MAD.</st> <st c="16173">MAD is the median of the
    absolute deviation between each observation and the median value of</st> <st c="16266">the
    variable:</st>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>M</mi><mi>A</mi><mi>D</mi><mo>=</mo><mi>b</mi><mo>×</mo><mi>M</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>a</mi><mi>n</mi><mo>(</mo><mfenced
    open="|" close="|"><mrow><mi>x</mi><mi>i</mi><mo>−</mo><mi>M</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>a</mi><mi>n</mi><mfenced
    open="(" close=")"><mi>X</mi></mfenced></mrow></mfenced><mo>)</mo></mrow></mrow></mrow></math>](img/24.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
- en: <st c="16314">In the previous equation,</st> `<st c="16340">xi</st>` <st c="16342">is
    each observation in the</st> `<st c="16370">X</st>` <st c="16371">variable.</st>
    <st c="16382">The beauty of MAD is that it uses the median instead of the mean,
    which is robust to outliers.</st> <st c="16477">The</st> `<st c="16481">b</st>`
    <st c="16482">constant is used to estimate the standard deviation from MAD, and
    if we assume normality, then</st> `<st c="16578">b =</st>` `<st c="16582">1.4826</st>`<st
    c="16588">.</st>
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16589">Note</st>
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16594">If the variable is assumed to have a different distribution,</st>
    `<st c="16656">b</st>` <st c="16657">is then calculated as 1 divided by the 75th
    percentile.</st> <st c="16714">In the case of normality, 1/75th percentile =</st>
    <st c="16760">1.4826.</st>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16767">After computing MAD, we use the median and MAD to establish distribution
    limits, designating values beyond these limits as outliers.</st> <st c="16901">The
    limits are set as the median plus and minus a multiple of MAD, typically ranging
    from 2 to 3.5\.</st> <st c="17001">The multiplication factor we choose reflects
    how stringent we want to be (the higher, the more conservative).</st> <st c="17111">In
    this recipe, we will identify outliers</st> <st c="17153">using MAD.</st>
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17163">How to do it...</st>
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="17179">Let’s begin the recipe by importing the Python libraries and loading</st>
    <st c="17249">the dataset:</st>
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17261">Let’s import the Python libraries</st> <st c="17296">and dataset:</st>
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: <st c="17429">Load the</st> <st c="17439">breast cancer dataset</st> <st c="17461">from
    scikit-learn:</st>
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: <st c="17538">Create a</st> <st c="17548">function that returns the limits based</st>
    <st c="17587">on MAD:</st>
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: <st c="17830">Let’s use the function to capture the extreme limits of the</st>
    `<st c="17891">mean</st>` `<st c="17896">smoothness</st>` <st c="17906">variable:</st>
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: <st c="17981">If we execute</st> `<st c="17996">lower_limit</st>` <st c="18007">or</st>
    `<st c="18011">upper_limit</st>`<st c="18022">, we will see the values</st> `<st
    c="18047">0.0536</st>` <st c="18053">and</st> `<st c="18058">0.13812</st>`<st
    c="18065">, corresponding to the limits beyond which we can consider a value</st>
    <st c="18132">an outlier.</st>
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="18143">Let’s create a Boolean vector that flags observations with values
    beyond</st> <st c="18217">the limits:</st>
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: <st c="18340">If we</st> <st c="18347">now execute</st> `<st c="18359">outliers.sum()</st>`<st
    c="18373">, we will see the value</st> `<st c="18397">5</st>`<st c="18398">, indicating
    that there are five outliers or observations that are smaller or greater than
    the extreme values found</st> <st c="18514">with MAD.</st>
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="18523">Let’s</st> <st c="18530">make a function to plot a boxplot next
    to a histogram of a variable, highlighting in the histogram the limits calculated
    in</st> *<st c="18654">step 4</st>*<st c="18660">:</st>
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: <st c="19013">And now let’s make</st> <st c="19033">the plots:</st>
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: <st c="19087">In the following plot, we see that the limits observed by the
    IQR proximity rule in the box plot are less conservative than those identified
    by using MAD.</st> <st c="19243">MAD returns</st> <st c="19255">symmetric boundaries,
    while the boxplot generates asymmetric boundaries, which are</st> <st c="19338">more
    suitable for highly</st> <st c="19363">skewed distributions:</st>
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Comparison of the limits between the whiskers in the boxplot
    and those determined by using MAD](img/B22396_05_6.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
- en: <st c="19416">Figure 5.6 – Comparison of the limits between the whiskers in
    the boxplot and those determined by using MAD</st>
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19523">Note</st>
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19528">Detecting outliers with MAD requires that the variable has certain
    variability.</st> <st c="19609">If more than 50% of the values in a variable are
    identical, the median coincides with the most frequent value, and MAD=0\.</st>
    <st c="19731">This means that all values different from the median will be flagged
    as outliers.</st> <st c="19813">This constitutes another limitation of using MAD
    in</st> <st c="19865">outlier detection.</st>
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19883">That’s it!</st> <st c="19895">You now know how to identify outliers
    using the median</st> <st c="19950">and MAD.</st>
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19958">How it works…</st>
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="19972">We</st> <st c="19976">determined the median with pandas’</st>
    `<st c="20011">median()</st>` <st c="20019">and the absolute difference with pandas’</st>
    `<st c="20061">abs()</st>`<st c="20066">. Next, we used the NumPy</st> `<st c="20092">where()</st>`
    <st c="20099">function to create a Boolean vector with</st> `<st c="20141">True</st>`
    <st c="20145">if a value was greater than the upper limit or smaller than the
    lower limit, otherwise</st> `<st c="20233">False</st>`<st c="20238">. Finally,
    we used pandas’</st> `<st c="20265">sum()</st>` <st c="20270">over this Boolean
    vector to calculate the total number</st> <st c="20326">of outliers.</st>
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20338">Finally, we</st> <st c="20351">compared the boundaries to determine
    outliers returned by the IQR proximity rule, which we discussed in the</st> *<st
    c="20459">Visualizing outliers with boxplots and the inter-quartile range proximity
    rule</st>* <st c="20537">recipe, and those returned by using MAD.</st> <st c="20579">The
    limits returned by the IQR rule were less conservative.</st> <st c="20639">This
    behavior can be changed by multiplying the IQR by 3 instead of 1.5, which is the
    default value in boxplots.</st> <st c="20752">In addition, we noted that MAD returns
    symmetric boundaries, whereas the boxplot provided asymmetric limits, which could
    be better suited for</st> <st c="20894">asymmetric distributions.</st>
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20919">See also</st>
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="20928">For a thorough discussion of the advantages and limitations of
    the different methods to detect outliers, check out the</st> <st c="21048">following
    resources:</st>
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21068">Rousseeuw PJ, Croux C.</st> *<st c="21092">Alternatives to the
    Median Absolute deviation</st>*<st c="21137">. Journal of the American Statistical
    Association,</st> <st c="21188">1993\.</st> [<st c="21194">http://www.jstor.org/stable/2291267</st>](https://www.jstor.org/stable/2291267)<st
    c="21229">.</st>
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '<st c="21230">Leys C, et.</st> <st c="21243">al.</st> *<st c="21247">Detecting
    outliers: Do not use standard deviation around the mean, use absolute deviation
    around the median</st>*<st c="21354">. Journal of Experimental Social Psychology,</st>
    <st c="21399">2013\.</st> <st c="21405">http://dx.doi.org/10.1016/j.jesp.2013.03.013</st><st
    c="21449">.</st>'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="21450">Thériault R, et.</st> <st c="21468">al.</st> *<st c="21472">Check
    your outliers</st>**<st c="21491">! An introduction to identifying statistical
    outliers in R with easystats</st>*<st c="21564">. Behavior Research Methods,</st>
    <st c="21593">2024\.</st> [<st c="21599">https://doi.</st><st c="21611">org/10.3758/s13428-024-02356-w</st>](https://link.springer.com/article/10.3758/s13428-024-02356-w)<st
    c="21642">.</st>
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="21643">Removing outliers</st>
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '<st c="21661">Recent</st> <st c="21669">studies distinguish three types of
    outliers: error outliers, interesting outliers, and random outliers.</st> <st
    c="21773">Error outliers are likely due to human or methodological errors and
    should be either corrected or removed from the data analysis.</st> <st c="21903">In
    this recipe, we’ll assume outliers are errors (you don’t want to remove interesting
    or random outliers) a</st><st c="22011">nd remove them from</st> <st c="22032">the
    dataset.</st>'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22044">How to do it...</st>
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="22060">We’ll use the IQR proximity rule to find the outliers and then
    remove them from the data using pandas</st> <st c="22163">and Feature-engine:</st>
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22182">Let’s import the Python libraries, functions,</st> <st c="22229">and
    classes:</st>
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: <st c="22454">Load the California housing dataset from scikit-learn and separate
    it into train and</st> <st c="22540">test sets:</st>
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: <st c="22705">Let’s create a function to find the limits beyond which we’ll
    consider a data point an outlier using the IQR</st> <st c="22815">proximity rule:</st>
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: <st c="23043">Note</st>
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23048">In</st> *<st c="23052">step 3</st>*<st c="23058">, we use the
    IQR proximity rule to find the limits beyond which data points will be considered
    outliers, which we discussed in the</st> *<st c="23189">Visualizing outliers with
    boxplots and the inter-quartile proximity rule</st>* <st c="23261">recipe.</st>
    <st c="23270">Alternatively, you can identify outliers with the mean and the standard
    deviation or MAD, as we covered in the</st> *<st c="23381">Finding outliers using
    the mean and standard deviation</st>* <st c="23435">and</st> *<st c="23440">Using
    the median absolute deviation to find</st>* *<st c="23484">outliers</st>* <st
    c="23492">recipes.</st>
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23501">Using the</st> <st c="23511">function from</st> *<st c="23526">step
    3</st>* <st c="23532">, let’s determine the limits of the</st> `<st c="23568">MedInc</st>`
    <st c="23574">variable:</st>
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: <st c="23633">If you execute</st> `<st c="23649">print(lower_limit, upper_limit)</st>`<st
    c="23680">, you’ll see the result of the previous command:</st> `<st c="23729">(-</st>``<st
    c="23731">3.925900000000002, 11.232600000000001)</st>`<st c="23770">.</st>
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="23771">Let’s retain the observations in the train and test sets whose
    values are greater than or equal to (</st>`<st c="23872">ge</st>`<st c="23875">)
    the</st> <st c="23882">lower limit:</st>
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: <st c="24029">Let’s retain the observations whose values are lower than or equal
    to (</st>`<st c="24101">le</st>`<st c="24104">) the</st> <st c="24111">upper limit:</st>
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: <st c="24258">Go</st> <st c="24262">ahead and execute</st> `<st c="24280">X_train.shape</st>`
    <st c="24293">followed by</st> `<st c="24306">train_t.shape</st>` <st c="24319">to
    corroborate that the transformed DataFrame contains fewer observations than the
    original one after removing</st> <st c="24431">the outliers.</st>
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="24444">We can remove outliers across multiple variables simultaneously</st>
    <st c="24509">with</st> `<st c="24514">feature-engine</st>`<st c="24528">.</st>
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="24529">Set up a transformer to identify outliers in three variables by
    using the</st> <st c="24604">IQR rule:</st>
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: <st c="24736">Note</st>
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="24741">OutlierTrimmer</st>` <st c="24756">can identify boundaries using
    the IQR, as we show in this recipe, as well as by using the mean and standard
    deviation, or MAD.</st> <st c="24884">You need to change</st> `<st c="24903">capping_method</st>`
    <st c="24917">to</st> `<st c="24921">gaussian</st>` <st c="24929">or</st> `<st
    c="24933">mad</st>`<st c="24936">, respectively.</st>'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24951">Fit the transformer to the training set so that it learns</st>
    <st c="25010">those limits:</st>
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: <st c="25044">Note</st>
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="25049">By executing</st> `<st c="25063">trimmer.left_tail_caps_</st>`<st
    c="25086">, we can visualize the lower limits for the three variables:</st> `<st
    c="25147">{''MedInc'': -0.6776500000000012, ''HouseAge'': -10.5, ''Population'':
    -626.0}</st>`<st c="25219">. By executing</st> `<st c="25234">trimmer.right_tail_caps_</st>`<st
    c="25258">, we can see the variables’ upper limits:</st> `<st c="25300">{''MedInc'':
    7.984350000000001, ''HouseAge'': 65.5, ''</st>``<st c="25349">Population'': 3134.0}</st>`<st
    c="25370">.</st>'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25371">Finally, let’s remove outliers from the train and</st> <st c="25422">test
    sets:</st>
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: <st c="25509">To finish with the recipe, let’s compare the distribution of a
    variable before and after</st> <st c="25599">removing outliers.</st>
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="25617">Let’s create</st> <st c="25630">a function to display a boxplot
    on top of</st> <st c="25673">a histogram:</st>
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: <st c="25927">Note</st>
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25932">We discussed the code in</st> *<st c="25958">step 10</st>* <st
    c="25965">in the</st> *<st c="25973">Visualizing outliers with boxplots</st>*
    <st c="26007">recipe earlier in</st> <st c="26026">this chapter.</st>
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26039">Let’s plot the distribution of</st> `<st c="26071">MedInc</st>`
    <st c="26077">before removing</st> <st c="26094">the outliers:</st>
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: <st c="26148">In the following plot, we see that</st> `<st c="26184">MedInc</st>`
    <st c="26190">is skewed and observations grea</st><st c="26222">ter than 8 are
    marked</st> <st c="26245">as outliers:</st>
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.7– Boxplot and the histogram of MedInc before removing outliers.](img/B22396_05_7.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
- en: <st c="26277">Figure 5.7– Boxplot and the histogram of MedInc before removing
    outliers.</st>
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26350">Finally, let’s plot</st> <st c="26371">the distribution of</st>
    `<st c="26391">MedInc</st>` <st c="26397">after removing</st> <st c="26413">the
    outliers:</st>
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: <st c="26467">After removing outliers,</st> `<st c="26493">MedInc</st>` <st
    c="26499">seems less skewed and i</st><st c="26523">ts values more</st> <st c="26539">evenly
    distributed:</st>
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Boxplot and the histogram of MedInc after removing outliers](img/B22396_05_8.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: <st c="26577">Figure 5.8 – Boxplot and the histogram of MedInc after removing
    outliers</st>
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26649">Note</st>
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="26654">Using the IQR rule over the transformed variable reveals new
    outliers.</st> <st c="26726">This is not surprising; removing observations at
    the extremes of the distribution alters parameters such as the median and quartile
    values, which in turn determine the length of the whiskers, potentially identifying
    additional observations as outliers.</st> <st c="26979">The tools that we use
    to identify outliers are just that: tools.</st> <st c="27044">To unequivocally
    identify outliers, we need to support these tools with additional</st> <st c="27127">data
    analysis.</st>'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27141">If thinking</st> <st c="27153">of removing error outliers from
    the dataset, make sure to compare and report the results with and without outliers,
    to see the ext</st><st c="27284">ent of their impact on</st> <st c="27308">the
    models.</st>
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27319">How it works...</st>
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="27335">The</st> `<st c="27340">ge()</st>` <st c="27344">and</st> `<st
    c="27349">le()</st>` <st c="27353">methods</st> <st c="27362">from pandas created
    Boolean vectors identifying observations exceeding or falling below thresholds
    set by the IQR proximity rule.</st> <st c="27492">We used these vectors with pandas</st>
    `<st c="27526">loc</st>` <st c="27529">to retain observations within the interval
    defined by</st> <st c="27584">the IQR.</st>
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27592">The</st> `<st c="27597">feature-engine</st>` <st c="27611">library’s</st>
    `<st c="27622">OutlierTrimmer()</st>` <st c="27638">automates the procedure of
    removing outliers for multiple variables.</st> `<st c="27708">OutlierTrimmer()</st>`
    <st c="27724">can identify outliers based on the mean and standard deviation,
    IQR proximity rule, MAD, or quantiles.</st> <st c="27828">We can modify this behavior
    through the</st> `<st c="27868">capping_method</st>` <st c="27882">parameter.</st>
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27893">The methods to identify outliers can be made more or less conservative
    by changing the factor by which we multiply the IQR, the standard deviation, or
    MAD.</st> <st c="28050">With</st> `<st c="28055">OutlierTrimmer()</st>`<st c="28071">,
    we can control the strength of the methods through the</st> `<st c="28128">fold</st>`
    <st c="28132">parameter.</st>
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28143">With</st> `<st c="28149">tails</st>` <st c="28154">set to</st>
    `<st c="28162">"both"</st>`<st c="28168">,</st> `<st c="28170">OutlierTrimmer()</st>`
    <st c="28186">found and removed outliers at both ends of the variables’ distribution.</st>
    <st c="28259">To remove outliers just on one of the tails, we can pass</st> `<st
    c="28316">"left"</st>` <st c="28322">or</st> `<st c="28326">"right"</st>` <st
    c="28333">to the</st> `<st c="28341">tails</st>` <st c="28346">parameter.</st>
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="28357">OutlierTrimmer()</st>` <st c="28374">adopts the scikit-learn
    functionality with the</st> `<st c="28422">fit()</st>` <st c="28427">method, to
    learn parameters, and</st> `<st c="28461">transform()</st>` <st c="28472">to modify
    the dataset.</st> <st c="28496">With</st> `<st c="28501">fit()</st>`<st c="28506">,
    the transformer learned and stored the limits for each variable.</st> <st c="28573">With</st>
    `<st c="28578">transform()</st>`<st c="28589">, it removed the outliers from the
    data, returning</st> `<st c="28640">pandas</st>` <st c="28646">DataFrames.</st>'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28658">See also</st>
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '<st c="28667">This is the study that I mentioned earlier that classifies outliers
    into errors; it is interesting and random: Leys C, et.al.</st> <st c="28794">2019\.</st>
    *<st c="28800">How to Classify, Detect, and Manage Univariate and Multivariate
    Outliers, with Emphasis on Pre-Registration</st>*<st c="28907">. International
    Review of Social</st> <st c="28940">Psycholo</st><st c="28948">gy.</st> [<st c="28953">https://doi.org/10.5334/irsp.289</st>](https://rips-irsp.com/articles/10.5334/irsp.289)<st
    c="28985">.</st>'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28986">Bringing outliers back within acceptable limits</st>
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="29034">Removing</st> <st c="29044">error outliers can be a valid strategy.</st>
    <st c="29084">However, this approach can reduce statistical power, in particular
    when there are outliers across many variables, because we end up removing big
    parts of the dataset.</st> <st c="29251">An alternative way to handle error outliers
    is by bringing outliers back within acceptable limits.</st> <st c="29350">In practice,
    what this means is replacing the value of the outliers with some thresholds identified
    with the IQR proximity rule, the mean and standard deviation, or MAD.</st> <st
    c="29520">In this recipe, we’ll replace outlier va</st><st c="29560">lues using</st>
    `<st c="29572">pandas</st>` <st c="29578">and</st> `<st c="29583">feature-engine</st>`<st
    c="29597">.</st>
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29598">How to do it...</st>
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="29614">We’ll use</st> <st c="29625">the mean and standard deviation to
    find outliers and then replace their values u</st><st c="29705">sing</st> `<st
    c="29711">pandas</st>` <st c="29717">and</st> `<st c="29722">feature-engine</st>`<st
    c="29736">:</st>
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用均值和标准差来查找异常值，然后使用 `<st c="29711">pandas</st>` 和 `<st c="29722">feature-engine</st>`
    替换它们的值：
- en: <st c="29738">Let’s import the required Python libraries</st> <st c="29781">and
    functions:</st>
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的 Python 库和函数：
- en: '[PRE38]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: <st c="29943">Load the breast cancer dataset from scikit-learn and separate
    it into train and</st> <st c="30024">test sets:</st>
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 scikit-learn 加载乳腺癌数据集并将其分为训练集和测试集：
- en: '[PRE39]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: <st c="30183">Let’s create a function to find outliers using the mean and</st>
    <st c="30244">standard deviation:</st>
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个函数来使用均值和标准差查找异常值：
- en: '[PRE40]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: <st c="30472">Note</st>
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: <st c="30477">In</st> *<st c="30481">step 3</st>*<st c="30487">, we use the
    mean and standard deviation to find the limits beyond which data points will be
    considered outliers, as discussed in the</st> *<st c="30621">Finding outliers
    using the mean and standard deviation</st>* <st c="30675">recipe.</st> <st c="30684">Alternatively,
    you can identify outliers with the IQR rule or MAD, as we covered in the</st>
    *<st c="30772">Visualizing outliers with boxplots and the inter-quartile proximity
    rule</st>* <st c="30844">and</st> *<st c="30849">Using the median absolute deviation
    to find</st>* *<st c="30893">outliers</st>* <st c="30902">recipes.</st>
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *<st c="30481">步骤 3</st>* 中，我们使用均值和标准差来查找数据点被认为是异常值的极限，如 *<st c="30621">使用均值和标准差查找异常值</st>*
    菜谱中所述。或者，您可以使用 IQR 规则或 MAD 识别异常值，正如我们在 *<st c="30772">使用箱线图和四分位数间距规则可视化异常值</st>*
    和 *<st c="30849">使用中位数绝对偏差查找异常值</st>* 菜谱中所述。
- en: <st c="30910">Using</st> <st c="30916">the function from</st> *<st c="30935">step
    3</st>*<st c="30941">, let’s determine the limits of the</st> `<st c="30977">mean
    smoothness</st>` <st c="30992">variable, which follows approximately a</st> <st
    c="31033">Gaussian distribution:</st>
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用来自 *<st c="30935">步骤 3</st>* 的函数，让我们确定 `<st c="30977">平均平滑度</st>` 变量的极限，该变量大约遵循高斯分布：
- en: '[PRE41]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: <st c="31137">Let’s make a copy of the</st> <st c="31163">original datasets:</st>
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们复制原始数据集：
- en: '[PRE42]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: <st c="31229">Now, replace outliers with the lower or upper limits from</st>
    *<st c="31288">step 4</st>* <st c="31294">in the</st> <st c="31302">new DataFrames:</st>
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在新数据框中使用 *<st c="31288">步骤 4</st>* 中的下限或上限替换异常值：
- en: '[PRE43]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: <st c="31459">To corroborate that the outliers were replaced with the values
    determined in</st> *<st c="31537">step 4</st>*<st c="31543">, execute</st> `<st
    c="31553">train_t["worst smoothness"].agg(["min", "max"])</st>` <st c="31600">to
    obtain the new maximum and minimum values.</st> <st c="31647">They should coincide
    with the minimum and maximum values of the variable, or the limits returned in</st>
    *<st c="31747">step 4</st>*<st c="31753">.</st>
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了证实异常值已被替换为在 *<st c="31537">步骤 4</st>* 中确定的值，执行 `<st c="31553">train_t["worst
    smoothness"].agg(["min", "max"])</st>` 以获得新的最大和最小值。它们应该与变量的最小和最大值一致，或者与 *<st c="31747">步骤
    4</st>* 中返回的极限一致。
- en: <st c="31754">We can replace outliers in multiple variables simultaneously by</st>
    <st c="31819">utilizing</st> `<st c="31829">feature-engine</st>`<st c="31843">.</st>
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过利用 `<st c="31829">feature-engine</st>` 同时替换多个变量中的异常值。
- en: <st c="31844">Let’s set up a transformer to replace outliers in two variables,
    using limits determined</st> <st c="31934">with the mean and</st> <st c="31952">standard
    deviation:</st>
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置一个转换器来替换两个变量中的异常值，使用由均值和 `<st c="31952">标准差</st>` 确定的极限：
- en: '[PRE44]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: <st c="32091">Note</st>
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`<st c="32096">Winsorizer</st>` <st c="32107">can</st> <st c="32111">identify
    boundaries using the mean and standard deviation, as we show in this recipe, as
    well as the IQR proximity rule and MAD.</st> <st c="32241">You need to change</st>
    `<st c="32260">capping_meth</st><st c="32272">od</st>` <st c="32275">to</st> `<st
    c="32279">iqr</st>` <st c="32282">or</st> `<st c="32286">mad</st>`<st c="32289">,
    respectively.</st>'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32304">Let’s fit the transformer to the data so that it learns</st> <st
    c="32361">those limits:</st>
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '<st c="32394">By executing</st> `<st c="32408">capper.left_tail</st><st c="32424">_caps_</st>`<st
    c="32431">, we can visualize the lower limits for the two variables:</st> `<st
    c="32490">{''worst smoothness'': 0.06364743973736293, ''worst texture'': 7.115307053129349}</st>`<st
    c="32567">. By executing</st> `<st c="32582">capper.right_tail_caps_</st>`<st
    c="32605">, we can see the variables’ upper limits:</st> `<st c="32647">{''worst
    smoothness'': 0.20149734880520967, ''worst</st>` `<st c="32696">texture'': 43.97692158753917}</st>`<st
    c="32724">.</st>'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="32725">Finally, let’s replace the outliers with the limits from</st>
    *<st c="32783">step 8</st>*<st c="32789">:</st>
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: <st c="32861">If we now execute</st> `<st c="32880">train_t[capper.variables_].agg(["min",
    "max"])</st>`<st c="32926">, we’ll see that the maximum and minimum values of
    the transformed DataFrame coincide with either the maximum and minimum values
    of the variables or the identified limits, whatever</st> <st c="33107">comes first:</st>
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: <st c="33196">If you are</st> <st c="33207">planning to cap variables, make
    sure you compare the performance of your models or the results of your ana</st><st
    c="33314">lysis before and after</st> <st c="33338">replacing outliers.</st>
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="33357">How it works...</st>
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="33373">The</st> `<st c="33378">clip()</st>` <st c="33384">function from</st>
    <st c="33398">pandas is used to cap values at lower or upper specified limits.</st>
    <st c="33464">In this recipe, we found those limits using the mean and standard
    deviation, and then clipped the variable so that all observations took values
    within those limits.</st> <st c="33629">The minimum value of the</st> `<st c="33654">worst
    smoothness</st>` <st c="33670">variable was actually greater than the lower limit
    we found in</st> *<st c="33734">step 4</st>*<st c="33740">, so no values were
    replaced at the left of its distribution.</st> <st c="33802">However, there were
    values greater than the upper limit from</st> *<st c="33863">step 4</st>*<st c="33869">,
    and those were replaced with the limit.</st> <st c="33911">This means that the
    minimum value of the transformed variable and the original variable coincide,
    but the maximum values</st> <st c="34032">do not.</st>
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34039">We used</st> `<st c="34048">feature-engine</st>` <st c="34062">to
    replace outliers in multiple variables simultaneously.</st> `<st c="34121">Winsorizer()</st>`
    <st c="34133">can identify outliers based on the mean and standard deviation,
    the IQR proximity rule, MAD, or by using percentiles.</st> <st c="34252">We can
    modify this behavior through the</st> `<st c="34292">capping_method</st>` <st
    c="34306">parameter.</st>
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34317">The methods to identify outliers can be made more or less conservative
    by changing the factor by which we multiply the IQR, the standard deviation, or
    MAD.</st> <st c="34474">With</st> `<st c="34479">Winsorizer()</st>`<st c="34491">,
    we can control the strength of the methods through the</st> `<st c="34548">fold</st>`
    <st c="34552">parameter.</st>
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34563">With</st> `<st c="34569">tails</st>` <st c="34574">set to</st>
    `<st c="34582">"both"</st>`<st c="34588">,</st> `<st c="34590">Winsorizer()</st>`
    <st c="34602">found and replaced outliers at both ends of the variables’ distribution.</st>
    <st c="34676">To replace outliers at either end, we can pass</st> `<st c="34723">"left"</st>`
    <st c="34729">or</st> `<st c="34733">"right"</st>` <st c="34740">to the</st> `<st
    c="34748">tails</st>` <st c="34753">parameter.</st>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="34764">Winsorizer()</st>` <st c="34777">adopts the scikit-learn functionality
    with the</st> `<st c="34825">fit()</st>` <st c="34830">method, to learn parameters,
    and</st> `<st c="34864">transform()</st>` <st c="34875">to modify the dataset.</st>
    <st c="34899">With</st> `<st c="34904">fit()</st>`<st c="34909">, the transformer
    learned and</st> <st c="34939">stored the limits for each variable.</st> <st c="34976">With</st>
    `<st c="34981">transform()</st>`<st c="34992">, it replaced the values of the
    ou</st><st c="35026">tliers, returning</st> <st c="35045">pandas DataFrames.</st>'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35063">See also</st>
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`<st c="35072">feature-engine</st>` <st c="35087">has</st> `<st c="35092">ArbitraryOutlierCapper()</st>`<st
    c="35116">, which caps variables at arbitrary minimum and maximum</st> <st c="35172">values:</st>
    [<st c="35180">https://feature-engine.readthedocs.io/en/latest/api_doc/outliers/ArbitraryOutlierCapper.html</st>](https://feature-engine.readthedocs.io/en/latest/api_doc/outliers/ArbitraryOutlierCapper.html)<st
    c="35272">.</st>'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35273">Applying winsorization</st>
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="35296">Winsorizing, or winsorization, consists</st> <st c="35336">of
    replacing extreme, poorly known</st> <st c="35372">observations, that is, outliers,
    with the magnitude of the next largest (or smallest) observation.</st> <st c="35471">It’s
    similar to the procedure described in the previous recipe,</st> *<st c="35535">Bringing
    outliers back within acceptable limits</st>*<st c="35582">, but not exactly the
    same.</st> <st c="35610">Winsorization involves replacing the</st> *<st c="35647">same
    number of outliers</st>* <st c="35670">at both ends of the distribution, which
    makes Winsorization a symmetric process.</st> <st c="35752">This guarantees that
    the</st> **<st c="35777">Winsorized mean</st>**<st c="35792">, that is, the</st>
    <st c="35806">mean estimated after replacing outliers, remains a robust estimator
    of the central tendency of</st> <st c="35902">the variable.</st>
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: <st c="35915">In practice, to</st> <st c="35931">remove a similar number of
    observations at both tails, we’d use percentiles.</st> <st c="36009">For example,
    the 5th percentile is the value below which 5% of the observations lie and the
    95th percentile is the value beyond which 5% of the observations lie.</st> <st
    c="36171">Using these values as replacements might result in replacing a similar
    number of observations on both tails, but it’s not guaranteed.</st> <st c="36305">If
    the dataset contains repeated values, obtaining reliable percentiles is challenging
    and can lead to an uneven replacement of values at each tail.</st> <st c="36454">If
    this happens, then the winsorized mean is not a good estimator of the central
    tenden</st><st c="36541">cy.</st> <st c="36546">In this recipe, we will</st> <st
    c="36570">apply winsorization.</st>
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36590">How to do it...</st>
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="36606">We will cap all</st> <st c="36623">variables of the breast cancer
    dataset at their 5th and</st> <st c="36679">95th percentiles:</st>
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: <st c="36696">Let’s import the required Python libraries</st> <st c="36740">and
    functions:</st>
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: <st c="36909">Load the breast cancer dataset</st> <st c="36941">from scikit-learn:</st>
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: <st c="37018">Separate</st> <st c="37027">the data into a train and</st> <st
    c="37054">test sets:</st>
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: <st c="37156">Capture the 5th and 95th percentiles of each variable</st> <st
    c="37211">in dictionaries:</st>
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: <st c="37305">Let’s now replace values beyond those percentiles with the respective
    percentiles for all variables</st> <st c="37406">at once:</st>
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: <st c="37502">Let’s display the minimum, maximum, and mean values of one variable</st>
    <st c="37571">before winsorization:</st>
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: <st c="37658">We can see the values in the</st> <st c="37688">following output:</st>
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: <st c="37784">Display the</st> <st c="37796">minimum, maximum, and mean values</st>
    <st c="37831">of the same variable</st> <st c="37852">after winsorization:</st>
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: <st c="37905">In the following output, we can see that the minimum and maximum
    values correspond to the percentiles.</st> <st c="38009">However, the mean is
    quite similar to the original mean of</st> <st c="38068">the variable:</st>
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: <st c="38160">Note</st>
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38165">If you want to use winsorization as part of a scikit-learn pipeline,
    you can use the</st> `<st c="38251">feature-engine</st>` <st c="38265">library’s</st>
    `<st c="38276">Winsorizer()</st>`<st c="38288">, by setting it up</st> <st c="38307">as
    follows:</st>
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '`<st c="38318">capper =</st>` `<st c="38328">Winsorizer(</st>`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '`**<st c="38339">capping_method="quantiles",</st>**`'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '**`**<st c="38367">tail="both",</st>**`'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '**`**<st c="38380">fold=0.05,</st>**`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '**`<st c="38391">)</st>`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38393">After this, proceed with the</st> `<st c="38422">fit()</st>` <st
    c="38427">and</st> `<st c="38432">transform()</st>` <st c="38443">methods as described
    in the</st> *<st c="38472">Bringing outliers back within acceptable</st>* *<st
    c="38513">limits</st>* <st c="38519">recipe.</st>
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38527">It’s</st> <st c="38533">worth</st> <st c="38539">noting that despite
    employing percentiles, the procedure didn’t precisely replace the same number
    of observations on both sides of the distribution.</st> <st c="38688">If you intend
    to winsorize your variables, compare the out</st><st c="38746">comes of your analyses
    before and</st> <st c="38781">after winsorization.</st>
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: <st c="38801">How it works...</st>
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="38817">We used pandas’</st> `<st c="38834">quantiles()</st>` <st c="38845">to
    obtain the 5th and 95th percentiles of all the variables in the dataset, and combined
    it with</st> `<st c="38943">to_dict()</st>` <st c="38952">to retain those percentiles
    in dictionaries, where the keys were the variables and the values were the percentiles.</st>
    <st c="39069">We then passed these dictionaries to pandas’</st> `<st c="39114">clip()</st>`
    <st c="39120">to replace values smaller or larger than those percentiles by the
    percentiles.</st> <st c="39200">By using dictionaries, we capped multiple variables</st>
    <st c="39252">at once.</st>
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39260">See also</st>
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="39269">For more details about how winsorization affects the mean and
    standard deviation in symmetric and asymmetric replacements, check out the</st>
    <st c="39407">original article:</st>
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: <st c="39424">Dixon W.</st> *<st c="39434">Simplified Estimation from Censored
    Normal Samples.</st> <st c="39486">The Annals of Mathematica</st><st c="39511">l
    Statistics</st>*<st c="39524">,</st> <st c="39526">1960\.</st> [<st c="39532">http://www.jstor.org/stable/2237953</st>](https://www.jstor.org/stable/2237953)******
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
