["```py\n    import optuna\n    from tensorflow.keras.models import Sequential \n    from tensorflow.keras.layers import Dense, Dropout\n    def create_model(trial: optuna.trial.Trial, input_size: int):\n    model = Sequential() \n    model.add(Dense(input_size,input_shape=(input_size,),activation='relu'))\n     num_layers = trial.suggest_int('num_layers',low=0,high=3) \n    for layer_i in range(num_layers): \n    n_units = trial.suggest_int(f'n_units_layer_{layer_i}',low=10,high=100,step=5) \n     dropout_rate = trial.suggest_float(f'dropout_rate_layer_{layer_i}',low=0,high=0.5) \n    actv_func = trial.suggest_categorical(f'actv_func _layer_{layer_i}',['relu','tanh','elu']) \n    model.add(Dropout(dropout_rate)) \n     model.add(Dense(n_units,activation=actv_func)) \n    model.add(Dense(1,activation='sigmoid'))\n    return model\n    ```", "```py\n    import tensorflow as tf\n    def create_optimizer(trial: optuna.trial.Trial):\n    opt_kwargs = {}\n    opt_selected = trial.suggest_categorical('optimizer', ['Adam','SGD'])\n    if opt_selected == 'SGD':\n    opt_kwargs['lr'] = trial.suggest_float('sgd_lr',1e-5,1e-1,log=True)\n    opt_kwargs['momentum'] = trial.suggest_float('sgd_momentum',1e-5,1e-1,log=True)\n    else: #'Adam'\n    opt_kwargs['lr'] = trial.suggest_float('adam_lr',1e-5,1e-1,log=True)\n    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n    return optimizer\n    ```", "```py\n    def train(trial, df_train: pd.DataFrame, df_val: pd.DataFrame = None):\n        X_train,y_train = df_train.drop(columns=['y']), df_train['y']\n        if df_val is not None:\n            X_val,y_val = df_val.drop(columns=['y']), df_val['y'] \n       #Apply pre-processing here... \n        #...\n        #Build model & optimizer\n        model = create_model(trial,X_train.shape[1])\n        optimizer = create_optimizer(trial)   \n        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_m])\n        history = model.fit(X_train,y_train,\n                       epochs=trial.suggest_int('epoch',15,50),\n                  batch_size=64,\n                  validation_data=(X_val,y_val) if df_val is not None else None)\n        if df_val is not None:\n            return np.mean(history.history['val_f1_m'])\n        else:\n            return model\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    def objective(trial: optuna.trial.Trial, df_train: pd.DataFrame):\n    #Split into Train and Validation data\n          df_train_hp, df_val = train_test_split(df_train, test_size=0.1, random_state=0)\n          #Train and Validate Model\n          val_f1_score = train(trial, df_train_hp, df_val)  \n          return val_f1_score\n    ```", "```py\nstudy = optuna.create_study(direction='maximize')\n```", "```py\nstudy.optimize(func=lambda trial: objective(trial, df_train),\n```", "```py\n               n_trials=50, n_jobs=-1)\n```", "```py\n    study = optuna.create_study(direction='maximize',\n    sampler=optuna.samplers.TPESampler(seed=0))\n    ```", "```py\n    study.optimize(lambda trial: objective(trial, df_train),\n                   n_trials=50, n_jobs=-1)\n    print(\"Best Trial:\")\n    best_trial = study.best_trial\n    print(\"    Value: \", best_trial.value)\n    print(\"    Hyperparameters: \")\n    for key, value in best_trial.params.items():\n        print(f\"        {key}: {value}\")\n    ```", "```py\n{'num_layers': 2,'n_units_layer_0': 30,'dropout_rate_layer_0': 0.14068484717257745,'actv_func_layer_0': 'relu','n_units_layer_1': 20,'dropout_rate_layer_1': 0.34708586671782293,'actv_func_layer_1': 'relu','optimizer': 'Adam','adam_lr': 0.0018287924415952158,'epoch': 41}\n```", "```py\n    train_and_evaluate_final(df_train, df_test, **best_trial.params)\n    ```", "```py\nstudy = optuna.create_study(direction='maximize', \n```", "```py\nsampler=optuna.samplers.RandomSampler(seed=0))\n```", "```py\n{'num_layers': 0,'optimizer': 'Adam','adam_lr': 0.05075826567070766,'epoch': 50}\n```", "```py\nsearch_space = {'num_layers': [0,1],\n```", "```py\n                'n_units_layer_0': list(range(10,50,5)),\n```", "```py\n                'dropout_rate_layer_0': np.linspace(0,0.5,5),\n```", "```py\n                'actv_func_layer_0': ['relu','elu'],\n```", "```py\n                'optimizer': ['Adam','SGD'],\n```", "```py\n                'sgd_lr': np.linspace(1e-5,1e-1,5),\n```", "```py\n                'sgd_momentum': np.linspace(1e-5,1e-1,5),\n```", "```py\n                'adam_lr': np.linspace(1e-5,1e-1,5),\n```", "```py\n                'epoch': list(range(15,50,5))\n```", "```py\n               }\n```", "```py\nstudy = optuna.create_study(direction='maximize',                  sampler=optuna.samplers.GridSampler(search_space),\n```", "```py\n                           )\n```", "```py\n{'num_layers': 0,'optimizer': 'Adam','adam_lr': 0.05000500000000001,'epoch': 25}\n```", "```py\nclass SimulatedAnnealingSampler(optuna.samplers.BaseSampler):\n```", "```py\n    ...\n```", "```py\n    def sample_relative(self, study, trial, search_space):\n```", "```py\n        if search_space == {}:\n```", "```py\n            # The relative search space is empty (it means this is the first trial of a study).\n```", "```py\n            return {}\n```", "```py\n        prev_trial = self._get_last_complete_trial(study)\n```", "```py\n        if self._rng.uniform(0, 1) <= self._transition_probability(study, prev_trial):\n```", "```py\n            self._current_trial = prev_trial\n```", "```py\n        params = self._sample_neighbor_params(search_space)\n```", "```py\n        #Geometric Cooling Annealing Schedule\n```", "```py\n        self._temperature *= self.cooldown_factor \n```", "```py\n        return params\n```", "```py\n    ...\n```", "```py\nstudy = optuna.create_study(direction='maximize',\n```", "```py\n                  sampler=SimulatedAnnealingSampler(seed=0),\n```", "```py\n                           )\n```", "```py\n{'num_layers': 3,'n_units_layer_0': 30,'dropout_rate_layer_0': 0.28421697443432425,'actv_func_layer_0': 'tanh','n_units_layer_1': 20,'dropout_rate_layer_1': 0.05936385947712203,'actv_func_layer_1': 'tanh','n_units_layer_2': 25,'dropout_rate_layer_2': 0.2179324626328134,'actv_func_layer_2': 'relu','optimizer': 'Adam','adam_lr': 0.006100619734336806,'epoch': 39}\n```", "```py\ndef train(trial, df_train: pd.DataFrame, df_val: pd.DataFrame = None):\n```", "```py\n...\n```", "```py\n    history = model.fit(X_train,y_train,\n```", "```py\n                       epochs=trial.suggest_int('epoch',15,50),\n```", "```py\n                       batch_size=64,\n```", "```py\n                       validation_data=(X_val,y_val) if df_val is not None else None,\n```", "```py\n                       callbacks=[optuna.integration.TFKerasPruningCallback(trial,'val_f1_m')],\n```", "```py\n                   )\n```", "```py\n...\n```", "```py\nstudy = optuna.create_study(direction='maximize',\n```", "```py\n  sampler=optuna.samplers.RandomSampler(seed=0),\n```", "```py\n  pruner=optuna.pruners.SuccessiveHalvingPruner(reduction_factor=3, min_resource=5)\n```", "```py\n                           )\n```", "```py\nstudy.optimize(lambda trial: objective(trial, df_train),\n```", "```py\n               n_trials=100, n_jobs=-1,\n```", "```py\n              )\n```", "```py\n{'num_layers': 3,'n_units_layer_0': 10,'dropout_rate_layer_0': 0.03540368984067649,'actv_func_layer_0': 'elu','n_units_layer_1': 15,'dropout_rate_layer_1': 0.008554081181978979,'actv_func_layer_1': 'elu','n_units_layer_2': 15,'dropout_rate_layer_2': 0.4887044768096681,'actv_func_layer_2': 'relu','optimizer': 'Adam','adam_lr': 0.02763126523504823,'epoch': 28}\n```", "```py\nstudy = optuna.create_study(direction='maximize',\n```", "```py\n  sampler=optuna.samplers.RandomSampler(seed=0),\n```", "```py\n  pruner=optuna.pruners.HyperbandPruner(reduction_factor=3, min_resource=5)\n```", "```py\n                           )\n```", "```py\n{'num_layers': 0,'optimizer': 'Adam','adam_lr': 0.05584201313189952,'epoch': 37}\n```"]