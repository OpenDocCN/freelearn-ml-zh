- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Malware Detection Using Transformers and BERT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Malware refers to malicious software applications that run on computers, smartphones,
    and other devices for nefarious purposes. They execute surreptitiously in the
    background, and often, users are not even aware that their device is infected
    with malware. They can be used to steal sensitive user information (such as passwords
    or banking information) and share it with an adversary, use your device resources
    for cryptocurrency mining or click fraud, or corrupt your data (such as deleting
    photos and emails) and ask for a ransom to recover it. In the 21st century, where
    smartphones are our lifeline, malware can have catastrophic effects. Learning
    how to identify, detect, and remove malware is an important and emerging problem
    in cybersecurity.
  prefs: []
  type: TYPE_NORMAL
- en: Because of its ability to identify and learn patterns in behavior, machine learning
    techniques have been applied to detect malware. This chapter will begin with an
    overview of malware including its life cycle and operating characteristics. We
    will then cover an upcoming and state-of-the-art architecture, known as the **transformer**,
    which is typically used for **natural language processing** (**NLP**) applications.
    Finally, we will combine the two and show how we can build an extremely high-precision
    malware classifier using BERT, which is a model built on top of the transformer
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Basics of malware
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformers and attention
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting malware with BERT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a better understanding of how malware
    works. Most importantly, you will be able to apply transformers and BERT to a
    variety of security-related classification problems based on the concepts we will
    study here.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%203](https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%203).
  prefs: []
  type: TYPE_NORMAL
- en: Basics of malware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we learn about *detecting* malware, let us briefly understand what exactly
    malware is and how it works.
  prefs: []
  type: TYPE_NORMAL
- en: What is malware?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Malware is simply any *mal*icious soft*ware*. It will install itself on your
    device (such as a computer, tablet, or smartphone) and operate in the background,
    often without your knowledge. It is designed to quietly change files on your device,
    and thus steal or corrupt sensitive information. Malware is generally camouflaged
    and pretends to be an otherwise innocent application. For example, a browser extension
    that offers free emojis can actually be malware that is secretly reading your
    passwords and siphoning them off to a third party.
  prefs: []
  type: TYPE_NORMAL
- en: 'Devices can be infected by malware in multiple ways. Here are some of the popular
    vectors attackers exploit to deliver malware to a user device:'
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging the premise of “free” software, such as a cracked version of expensive
    software such as Adobe Photoshop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: USB devices with the malware installed plugged into the user’s computer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phishing emails where attackers pretend to be the employer or IT support and
    ask to download and install a malicious software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Websites that prompt users to install malicious extensions to continue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An example ([https://www.myantispyware.com/2017/02/20/remove-to-continue-the-work-of-your-browser-you-should-install-the-extension-pop-ups/](https://www.myantispyware.com/2017/02/20/remove-to-continue-the-work-of-your-browser-you-should-install-the-extension-pop-ups/))
    of a website prompting users to install an extension is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – A suspicious website prompting malware downloads](img/B19327_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – A suspicious website prompting malware downloads
  prefs: []
  type: TYPE_NORMAL
- en: Malware applications come in multiple forms and flavors, each with a different
    attack strategy. In the next subsection, we will study some popular variants of
    malware.
  prefs: []
  type: TYPE_NORMAL
- en: Types of malware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let us briefly take a look at the various kinds of malware.
  prefs: []
  type: TYPE_NORMAL
- en: Virus
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A virus is a malicious software application that functions in a manner similar
    to its biological counterpart – an actual virus. A virus program is one that replicates
    by creating multiple copies of itself and hogs all system resources. Viruses hide
    in computer files, and once the file is run, they can begin replicating and spreading.
    Viruses can be boot infectors (which target the operating system directly and
    install them as part of the booting process) or file infectors (those which are
    hidden away in executable files, such as free versions of software downloaded
    from shady websites). Some applications also allow third-party extensions to interface
    with them. Examples include macros or extensions. Viruses can also run as part
    of these macros.
  prefs: []
  type: TYPE_NORMAL
- en: Worms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Worms are similar to viruses in operation in terms of their modus operandi,
    which is to replicate and spread. However, worms are standalone applications;
    they are not embedded into files like viruses are. While viruses require users
    to execute the file (such as a `.exe` file or a macro), worms are more dangerous
    because they can execute by themselves. Once they infect a computer, they can
    automatically replicate across the entire network. Worms generally crash the device
    or overload the network by increasing resource usage.
  prefs: []
  type: TYPE_NORMAL
- en: Rootkits
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Rootkits are malware applications that work with the goal of getting the attacker
    complete administrative rights to your system (the term **root** refers to the
    administrator or master user in operating systems, and is a user account that
    can control permissions and other user accounts). A rootkit can allow an adversary
    to have full control of the user’s computer without the user knowing. This means
    that the attacker can read and write to all files, execute malicious applications,
    and lock legitimate users out of the system. The attacker can also execute illegal
    activities, such as launching a DDoS attack, and avoid being caught (as it is
    the user’s machine to which the crime will be traced back). While malicious for
    the most part, some rootkits are also used for good. For example, if a system
    that contains highly sensitive data (such as information pertaining to national
    security) is accessed by an adversary, a rootkit can be used as a **backdoor**
    (a secret or hidden entry point into a system, and one that can be used to bypass
    security mechanisms and gain unauthorized access to a system or data) to access
    it and wipe it off to prevent the information from falling into the wrong hands.
  prefs: []
  type: TYPE_NORMAL
- en: Ransomware
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ransomware are malware applications that block user access to data. Ransomware
    may encrypt the data so that users are powerless to do anything with their devices.
    Attackers ask for a *ransom* to be paid, and threaten that the data will be deleted
    forever or published on the Internet if they do not receive the ransom. There
    is no guarantee that the attacker will actually hold up their end of the bargain
    once the ransom is paid. Ransomware attacks have been on the rise, and the emergence
    of cryptocurrency (such as BTC) has made it possible for attackers to receive
    and spend money pseudo-anonymously.
  prefs: []
  type: TYPE_NORMAL
- en: Keyloggers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A keylogger is an application that records the keyboard activities of a user.
    All information typed is logged as keystrokes and siphoned off to an attacker.
    The attacker can extract information such as usernames, passwords, credit card
    numbers, and secure PINs. As keyloggers do not cause any visible harm (such as
    deleting or locking files), they are hard to detect from a user’s perspective.
    They sit quietly in the background and ship your keystroke information to the
    attacker.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have explored the different kinds of malware, let us turn to how
    malware detectors work.
  prefs: []
  type: TYPE_NORMAL
- en: Malware detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the prevalence of malware grows, so does the need for detecting it. Routine
    system scans and analysis by malware detection algorithms can help users stay
    safe and keep their systems clean.
  prefs: []
  type: TYPE_NORMAL
- en: Malware detection methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Malware detection can be divided broadly into three main categories: signature-based,
    behavioral-based, and heuristic methods. In this section, we will look at what
    these methods are in short and also discuss techniques for analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: Signature-based methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: These methods aim to detect malware by storing a database of known malware examples.
    All applications are checked against this database to identify whether they are
    malicious. The algorithm examines each application and calculates a signature
    using a hash function. In computer security, the hash of a file can be treated
    as its unique identity. It is nearly impossible to have two files with the same
    hash unless they are identical. Therefore, this method works really well in detecting
    known malware. While the simplicity of this technique is unmatched, it is easily
    thwarted; a change of even a single bit in the executable file will cause the
    hash to be completely different, and undetectable by its signature.
  prefs: []
  type: TYPE_NORMAL
- en: Behavioral-based methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'These methods aim to detect malware by looking for evidence of certain malicious
    activity. Signature-based methods detect malware based on what the application
    says, but behavioral methods detect it based on what the application does. It
    can collect a variety of features from the behavior of the application, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: How many GET requests did the app make?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many suspicious URLs did it connect to?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the application have access to file storage?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many distinct IP addresses did the application contact in the past seven
    days?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these features, common-sense rules can be built to flag malicious behavior.
    Past examples of known malware are also studied in detail to identify strategies
    that can be checked for. Behavioral methods are more robust against evasion, as
    an adversary will have to explicitly change the behavior of an app to avoid detection.
  prefs: []
  type: TYPE_NORMAL
- en: Heuristic methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: These are the most powerful methods known to us. Rather than look for a specific
    behavior, they use data mining and machine learning models to learn what malicious
    applications look like. These methods leverage API calls, OpCode Sequences, call
    graphs, and other features from the application and train a classification model.
    Neural networks and Random Forests have been shown to achieve a high-accuracy
    and high-precision classifier for malware. Heuristic methods are even more robust
    than behavioral methods, as changing specific parameters may not necessarily fool
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: Malware analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous section, we discussed malware detection methods. Once a potential
    malware application has been flagged, it needs to be examined to identify its
    behavior, method of spreading, origin, and any potential impact. Researchers often
    dissect malware as it can provide insights into the skills and tactics available
    to an adversary. This process of examining a malware file in detail is known as
    malware analysis. There are two methods for malware analysis: static and dynamic.'
  prefs: []
  type: TYPE_NORMAL
- en: Static analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This method examines the malware file as a whole by collecting information about
    the application without actually running it. The hash of the application is checked
    against known malware samples. The executable file is decompiled and the code
    is analyzed in detail; this provides a deep insight into what the goal of the
    malware was and what the adversary was looking for. Common patterns in the code
    may also indicate the origin or developer of the malware. Any strategies found
    can now be used to develop stronger detection mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dynamic analysis involves studying malware by actually executing it. A protected
    sandbox environment is created, and the malware is allowed to execute in it. This
    allows researchers the opportunity to look at the malware in action. Some behavior
    may not be obvious in the code or may dynamically evolve at runtime. Such behavior
    can be observed when the malware is actually running. Moreover, allowing the application
    to run allows you to collect API call sequences and other behavioral features,
    which can be used for heuristic methods.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that handling malware can be a dangerous task. Inadvertently
    running it may cause the virus or Trojan to take control of your system. There
    are several commercial tools that facilitate malware analysis in a secure way.
    In later sections, we will be using files generated by one such tool.
  prefs: []
  type: TYPE_NORMAL
- en: Transformers and attention
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transformers are an architecture taking the machine learning world by storm,
    especially in the fields of natural language processing. An improvement over classical
    **recurrent neural networks** (**RNN**) for sequence modeling, transformers work
    on the principle of attention. In this section, we will discuss the attention
    mechanism, transformers, and the BERT architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding attention
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now take a look at *attention*, a recent deep learning paradigm that
    has made great advances in the world of natural language processing.
  prefs: []
  type: TYPE_NORMAL
- en: Sequence-to-sequence models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most natural language tasks rely heavily on sequence-to-sequence models. While
    traditional methods are used for classifying a particular data point, sequence-to-sequence
    architectures map sequences in one domain to sequences in another. An excellent
    example of this is language translation. An automatic machine translator will
    take in sequences of tokens (sentences and words) from the source language and
    map them to other sentences in the target language.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sequence-to-sequence model generally has two components: the encoder and
    the decoder. The encoder takes in the source sequences as input and maps them
    to an intermediate vector known as a **context vector**, or embedding. The decoder
    takes in the embedding and maps it to sequences in the target domain. The entire
    model is trained end to end instead of encoders and decoders being trained separately
    as shown in *Figure 3**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Traditional sequence-to-sequence architecture](img/B19327_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – Traditional sequence-to-sequence architecture
  prefs: []
  type: TYPE_NORMAL
- en: The encoder and decoder are typically RNNs, which maintain an internal state
    (hidden state) that has some memory of past inputs. In a traditional sequence-to-sequence
    model, the context vector would simply be a high-dimensional representation of
    the input sentence in a vector space. In *Figure 3**.2*, the words from the French
    sentence are passed one by one to the model (one every time step). The encoder
    contains an RNN that maintains some memory at every time step. After the final
    time step, the hidden state of the RNN becomes the context vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is similar to autoencoders discussed previously, except for one major
    difference: in sequence-to-sequence models, the input and output sequences can
    be of different lengths. This is often the case in language translation. For example,
    the French sentence “Ca va?” translates to “How are you?” in English. Sequence-to-sequence
    models are powerful because they learn the relationships and order between tokens
    and map them to tokens in the target language.'
  prefs: []
  type: TYPE_NORMAL
- en: Attention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key challenge in the standard encoder/decoder architecture is the bottleneck
    created by the context vector. Being a fixed-size vector, there is a limitation
    on how much information can be compressed into it. As a result, it cannot retain
    information from longer sequences and cannot capture information from multiple
    timesteps that the RNN encoder goes through. RNNs have a tendency to forget the
    information they learn. In longer sequences, they will remember the later parts
    of the sequence and start forgetting earlier ones.
  prefs: []
  type: TYPE_NORMAL
- en: The attention mechanism aims to solve the problem of long-term dependencies
    and allow the decoder to access as much information as it needs in order to decode
    the sequence properly. Via attention, the decoder focuses only on the relevant
    parts of the input sequence in order to produce the output sequence. The model
    examines multiple time steps from the encoder and "pays attention" to only the
    ones that it deems to be important.
  prefs: []
  type: TYPE_NORMAL
- en: Concretely speaking, while a traditional sequence-to-sequence model would just
    pass the last hidden state of the RNN to the decoder, an attention model will
    pass all of the hidden states. For example, in an English-French translation model,
    input sentences are English sentences. A hidden state will be created at every
    word position as the RNN encoder steps through the sequence, and all of these
    will be passed to the decoder.
  prefs: []
  type: TYPE_NORMAL
- en: The decoder now has access to the context vector at each time step in the input.
    While decoding, it will try to focus on the parts of the input that are meaningful
    to decoding this time step. It will examine the encoder’s hidden states (remember,
    all of the hidden states have been passed) and score each hidden state. The score
    represents the relevance of that hidden state to the current word being decoded;
    the higher the score, the greater the relevance. The score for each state is normalized
    using a `softmax` function overall scores. Finally, each hidden state is multiplied
    by the `softmax` transformed score. Hidden states with high scores (relevant to
    decoding at this time step) are amplified in value, whereas the ones with low
    scores are diminished. Using the values of these vectors, the decoded output word
    can be produced.
  prefs: []
  type: TYPE_NORMAL
- en: Attention in action
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We discussed that the attention decoder is able to selectively pay attention
    to the relevant words in the source sequence. To demonstrate that the model does
    not mindlessly do a word-by-word translation, we show an example here from the
    paper that first presented the idea of attention ([https://arxiv.org/abs/1409.0473](https://arxiv.org/abs/1409.0473)).
  prefs: []
  type: TYPE_NORMAL
- en: Consider the problem of translating French sentences into English. This is the
    perfect domain in which to demonstrate attention. The French language has a peculiar
    ordering of the parts of speech (adverbs, adjectives, and nouns) that is different
    from English. If a model is doing a word-by-word translation without attention,
    the translated output would be grammatically incorrect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a confusion matrix that demonstrates the attention that the model paid
    to specific tokens in the input to generate specific tokens in the output. The
    brighter the color, the stronger the attention:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Confusion matrix denoting attention](img/B19327_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – Confusion matrix denoting attention
  prefs: []
  type: TYPE_NORMAL
- en: In French, the adjective is generally placed after the noun. So the “European
    Economic Zone” becomes the “Zone économique européenne.” Looking at the confusion
    matrix, note how the model has paid attention to the correct word pairs, irrespective
    of their order. If a model was simply mapping words, the sentence would have been
    translated from the French version to “Area Economic European.” The confusion
    matrix shows that irrespective of the order, the model knew what words to pay
    attention to while decoding certain time steps.
  prefs: []
  type: TYPE_NORMAL
- en: This is the fundamental concept of attention. The actual mechanisms (how the
    hidden states are scored, and how the feature vector is constructed) are out of
    scope here. However, those of you who are interested can refer to the foundational
    paper behind attention for a detailed description of the mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding transformers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous section, we discussed the attention mechanism and how it helps
    sequence-to-sequence applications such as neural machine translation. Now, we
    will look at the transformer: an architecture that leverages attention in multiple
    forms and stages to get the best out of it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The fundamental architecture of the transformer model is reproduced in *Figure
    3**.4* from a 2017 paper ([https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf))
    for convenience:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Transformer architecture](img/B19327_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – Transformer architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'The model has two components: the encoder (depicted by the blocks on the left)
    and the decoder (depicted by the blocks on the right). The goal of the blocks
    on the left is to take in the input sequence and transform it into the context
    vectors that are fed to the decoder. The decoder blocks on the right receive the
    output of the encoder along with the output of the decoder at the previous time
    step to generate the output sequence. Let us now look at the encoder and decoder
    blocks in more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: The encoder
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The encoder consists of two modules: a multi-headed attention module and a
    fully connected feed-forward neural network. The multi-headed attention module
    will apply a technique called self-attention, which allows the model to associate
    each word in the input with other words. For example, consider the sentence, *I
    could not drink the soup because it was too hot*. Here, the word *it* in the latter
    half of the sentence refers to the word *soup* in the first half. Self-attention
    would be able to discover such relationships. As the name suggests, multi-headed
    attention includes multiple blocks (or heads) for attention. The expectation is
    that each head will learn a different relationship. The multi-headed attention
    module calculates the attention weights for the input sequence and generates a
    vector as output that indicates how each word in the sequence should *pay attention*
    to the others.'
  prefs: []
  type: TYPE_NORMAL
- en: The output of the attention module is added back to the input and then passed
    through a normalization layer. Normalization helps control the range of parameters
    and keeps the model stable. The normalized output is passed to the second module,
    which is a feed-forward neural network. This can be any neural network, but generally
    speaking, it consists of multiple fully connected layers with a ReLU activation.
    The addition and normalization process repeats once again, and the final encoder
    output is produced.
  prefs: []
  type: TYPE_NORMAL
- en: The decoder
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The role of the decoder is to take in the encoder’s output and produce an output
    sequence. Note that the general modules remain the same, but the structure differs
    slightly.
  prefs: []
  type: TYPE_NORMAL
- en: The decoder has two attention modules. One of them takes in the embedding of
    the previously produced output and applies the attention mechanism to it. This
    module applies *masked attention*. During the training, we will have pairs of
    input and output sequences that the model will learn from. It is important that
    the decoder learns to produce the next output by looking at only past tokens.
    It should not pay attention to the future tokens (otherwise, the whole point of
    developing a predictive model is moot). The masked attention module zeroes out
    the attention weights for the future tokens.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second attention module takes in two inputs: the normalized output of the
    first module and the output from our encoder. The attention module has three inputs,
    known as the *query*, *key*, and *value* vectors. However, we will not go into
    specifics of these.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, note that the decoder has an additional linear layer and a `softmax`
    layer at the end. The goal of the decoder is to produce sequences (mainly text)
    in the target language. Therefore, the embeddings that are generated must be somehow
    mapped to words. The `softmax` layer outputs a probability distribution over the
    vocabulary of tokens. The one with the maximum probability is chosen to be the
    output word.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding BERT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have seen how the attention mechanism works and how the transformers
    leverage it for effective sequence-to-sequence modeling. As a final step, we will
    learn about BERT, a model that uses transformers and a novel set of training methodologies.
    The effectiveness of BERT and the utility of a pre-trained model in downstream
    tasks will be critical for our malware detection task.
  prefs: []
  type: TYPE_NORMAL
- en: '**BERT** stands for **Bidirectional Encoder Representations from Transformers**.
    Ever since its introduction in 2018, it has made great impacts on the natural
    language processing world. It is a significant discovery that allows researchers
    and scientists to harness the power of large-scale machine learning language models,
    without the need for massive data or extensive computing resources.'
  prefs: []
  type: TYPE_NORMAL
- en: BERT architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Architecturally speaking, BERT leverages transformers to create a structure.
    The BERT base model has 12 transformers stacked on top of each other and 12 self-attention
    heads. The BERT large model has 24 transformer layers and 16 self-attention heads.
    Both these models are *tremendously large* (with 110M and 40M parameters respectively).
  prefs: []
  type: TYPE_NORMAL
- en: Both of these models have been released by Google as open source and are freely
    available for anyone to use.
  prefs: []
  type: TYPE_NORMAL
- en: MLM as a training task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Traditional language models examine text sequences in only one direction: from
    left to right or right to left. This approach works just fine for generating sentences.
    The overarching goal in a language model is, given the words that have occurred
    so far, to predict the next word likely to appear.'
  prefs: []
  type: TYPE_NORMAL
- en: However, BERT takes this a step further. Instead of looking at the sequence
    either left to right or right to left, it looks at the sequence both ways. It
    is trained on a task known as `[MASK]` token. Now, the goal is not to predict
    the next word in the sentence. The model will now learn to predict the masked
    words, given the surrounding words in both directions.
  prefs: []
  type: TYPE_NORMAL
- en: The word embeddings generated by traditional models represent words in a numeric
    space such that words similar in meaning are close to one another in the vector
    space. However, BERT will generate embeddings for a word depending on the context
    of the word. In such embeddings, the vector representation of a word changes with
    the context in which the word is being used.
  prefs: []
  type: TYPE_NORMAL
- en: In traditional word embeddings, a word will have the same embedding irrespective
    of the context. The word *match* will have the same embedding in the sentence
    “They were a perfect match” and “I lit a match last night.” We clearly see that
    although the word is the same, the context matters and changes the meaning. BERT
    recognizes this and conditions the embeddings based on context. The word match
    has different embeddings in these two sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning BERT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned before, the power of BERT lies in fine-tuning. The original BERT
    model has been trained on the masked language model task using the BooksCorpus
    data (containing 800 million words) and the Wikipedia data (containing 2.5 billion
    words). The model learns from large-scale datasets, training that we cannot reproduce
    trivially. For context, the BERT large model required 4 days and 16 cloud TPUs
    for training.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of transfer learning helps us leverage this already-trained model
    for our downstream tasks. The idea behind this is that we take a generic language
    model, and fine-tune it for our specific task. High-level concepts are already
    learned by the model; we simply need to teach it more about a specific task.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do this, we use the pre-trained model and add a single layer (often
    a single-layered neural network) on top of it. The nature of the layer will depend
    on the task we are fine-tuning for. For any task, we simply plug in the task-specific
    inputs and outputs in the correct format into BERT and fine-tune all the parameters
    end to end. As we fine-tune, we will achieve two tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: The parameters of the transformer will be updated iteratively to refine the
    embeddings and generate task-specific contextual embeddings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The newly added layer will be trained (that is, will learn appropriate parameters)
    to classify the new class of embeddings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning BERT is an inexpensive task both in terms of time and resources.
    Classification models can be built using an hour on a TPU, around 4 hours on a
    GPU, and 8-10 hours on a regular CPU. BERT has been used after fine-tuning several
    tasks such as question-answering, sentence completion, and text understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting malware with BERT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen attention, transformers, and BERT. But all of it has been
    very specific to language-related tasks. How is all of what we have learned relevant
    to our task of malware detection, which has nothing to do with language? In this
    section, we will first discuss how we can leverage BERT for malware detection
    and then demonstrate an implementation of the same.
  prefs: []
  type: TYPE_NORMAL
- en: Malware as language
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We saw that BERT shows excellent performance on sentence-related tasks. A sentence
    is merely a sequence of words. Note that we as humans find meaning in a sequence
    because we understand language. Instead of words, the tokens could be anything:
    integers, symbols, or images. So BERT performs well on sequence tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine that instead of words, our tokens were calls made by an application.
    The life cycle of an application could be described as a series of API calls it
    makes. For instance, `<START>` `<REQUEST-URL>` `<DOWNLOAD-FILE>` `<EXECUTE-FILE>`
    `<OPEN-CONTACTS>` `<POST-URL>` `<END>` could represent the behavior of an application.
    Just like a sentence is a sequence of words, an application can be thought of
    as a sequence of API calls.
  prefs: []
  type: TYPE_NORMAL
- en: The relevance of BERT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recall that BERT learned contextual embeddings for a word. If we use BERT with
    malware data (with API calls as words and their sequence as sentences), the model
    will be able to learn embedding representations for each API call and condition
    it on the context. This is useful for malware detection because a single API call
    cannot determine whether an application is malware or not, but the context in
    which it is called might. For example, by itself, the API call for making a request
    to a third-party URL may not be malicious, but coupled with accessing stored passwords
    and contacts, it may indicate malware at work. This is our motivation behind choosing
    BERT as a model for malware detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use BERT on the malware classification task just like a sentence classification
    task. Here we have two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Train a new BERT model from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tune the existing BERT model (pre-trained on language data) on malware
    classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the domains of the pre-trained model are different from malware (that is,
    tokens in malware API sequences will not appear in the Wikipedia or BooksCorpus
    datasets), the first option might seem better. However, recall that the datasets
    for pre-training were massive, and we do not have access to malware data at that
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: Prior research has shown that a BERT model, even when pre-trained in the English
    language, serves as an excellent candidate for malware detection. This is because
    the pre-training results in an optimal set of parameters that results in faster
    convergence of any downstream task such as malware detection. In the following
    sections, this is the approach we will take. We will first preprocess the data,
    read it into a DataFrame, and then fine-tune it on a pre-trained BERT model.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As described previously, malware can be analyzed using both static and dynamic
    methods. Several commercial tools exist for decompiling malware binaries, understanding
    the behavior, and examining their activities. One such tool for malware analysis
    is WildFire ([https://www.paloaltonetworks.com/products/secure-the-network/wildfire](https://www.paloaltonetworks.com/products/secure-the-network/wildfire)),
    developed by Palo Alto Networks. It is a cloud malware protection engine that
    utilizes advanced machine learning models to detect targeted malware attacks in
    real time.
  prefs: []
  type: TYPE_NORMAL
- en: Creating your own datasets for malware detection is challenging. First, using
    tools such as WildFire to generate dynamic analysis files is an expensive task
    (commercial tools are generally patented and require a license) and also outside
    the scope of this book. Second, examples of malware, particularly those seen in
    the wild, are hard to come by. Finally, experimenting with malware executables
    may inadvertently infect your systems. We will, therefore, use a commercially
    available malware dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In 2018, Palo Alto Networks released a research paper ([https://arxiv.org/pdf/1812.07858.pdf](https://arxiv.org/pdf/1812.07858.pdf))
    that discussed common cybersecurity problems, in which malware detection was discussed
    in great detail. Along with the paper, they released a malware dataset that contained
    analysis files for over 180,000 different applications. The dataset is made of
    a sample of malware identified by Palo Alto Networks in a given period. For each
    malware, they provide identifiers and the domains accessed by the file, along
    with the sequence of API calls made by the application.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is freely available for students and researchers and can be obtained
    by contacting Palo Alto Networks as described in the paper. However, the method
    we present is fairly generic and can be applied to any malware dataset that you
    can gain access to.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Palo Alto Networks dataset contains several features for every application,
    including static and dynamic analysis files. However, of particular interest to
    us is the API call sequence. This is because we want to exploit the power of transformers.
    A defining characteristic of transformers is that they excel at handling sequential
    data via attention mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dynamic analysis file will give us the sequence of API calls made by the
    application. Each API call consists of two parts: the `GET` request). The key
    refers to the parameters passed to the API call (such as the actual domain to
    which the application is connected). While examining the parameters will also
    reveal significant information about whether an app is malicious, here we simply
    focus on the action of the API call.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Every application (whether malware or benign) has an associated XML file that
    contains the API call logs. Once they are extracted, we will have access to the
    set of actions taken by the application. An example snippet could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – API call sequence](img/B19327_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – API call sequence
  prefs: []
  type: TYPE_NORMAL
- en: We first extract the sequence for all the applications. Now that we have the
    sequence, it must be converted into tokens suitable for consumption by a machine
    learning model. Once we have all the sequences, we can compute the universe of
    known API calls, and assign a unique integer to each API call. Every application
    can now be represented as a sequence of integers.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the steps discussed so far are not specific to the Palo Alto Networks
    dataset, and this is the reason why we did not introduce any specific functions
    or code to do the preprocessing. You can apply this same technique to construct
    a feature vector from any malware dataset.
  prefs: []
  type: TYPE_NORMAL
- en: For convenience and simplicity, we will provide the preprocessed versions of
    the dataset. Note that the API call sequences are represented by integers, as
    we cannot share the exact API calls publicly. Interested readers can refer to
    the original paper and data if they are curious to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: Building a classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will leverage the BERT model to build our classifier. Much of the code here
    is borrowed from the official notebooks released by Google when they released
    the BERT model in 2019\. Some of the code may seem intimidating; however, do not
    worry. A lot of this is just boilerplate environment setup and function definitions
    that you absolutely do not need to understand in detail. We will go over the code
    and discuss what parts need to be changed when you implement this on your own
    or wish to use this setup for a different problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will import the required libraries. If any of these are not already
    installed (and Python will throw an error saying so), then they can be installed
    using the `pip` utility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will leverage a pre-trained BERT model for building our classifier. TensorFlow
    Hub contains all of these pre-trained models and they are available for use by
    the public. This function reads the model and its vocabulary and generates a tokenizer.
    The tokenizer is responsible for converting the words we see into tokens that
    can be understood by the machine learning model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we actually create the classification model. This function will create
    a BERT module and define the input and output structures. We will then obtain
    the output layer and find the parameters there; these are the ones that would
    be used to run inference. We apply a dropout to this layer and calculate the logits
    (that is, the `softmax` output of the layer). During the training phase, the `softmax`
    output is used to compute the loss relative to the ground truth. In the inferencing
    phase, the output can be used to predict the token depending on which probability
    in the `softmax` output is the highest. Note that the ground truth is in the form
    of categorical tokens (in our case, API calls) and, therefore, needs to be converted
    into a numeric form using one-hot encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The code so far has been mostly boilerplate functions for setting up the parameters.
    Now, we will create a function that actually defines our training and inference
    settings. Recall that the previous function defined the steps to create the model.
    This function will leverage the previous one for training and inference.
  prefs: []
  type: TYPE_NORMAL
- en: First, we read the input features and labels that are crucial to training. These
    will be passed to the function as parameters. If the training phase is going on,
    the function will use the `create_model` function to calculate a loss that will
    be optimized for training. If not, it will simply score the data point on the
    model and return a predicted label and output probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'This function also has a metric calculation function defined. This is crucial
    to analyzing and comparing the performance of our model. TensorFlow has built-in
    functions that calculate common metrics such as precision, recall, false positives,
    false negatives, F1 score, and so on. We leverage these built-in functions and
    return a dictionary, which contains various metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now that all of the functions to initialize the model, compute loss and training,
    and inferencing are good to go, we can use this setup by plugging in our malware
    data. Note that the procedure so far is generically applicable to any fine-tuning
    problem you are trying to solve using BERT; nothing has been hardcoded or is specific
    to malware data. If you want to use the fine-tuning approach to BERT on another
    task (sentiment analysis, hate speech detection, or misinformation detection),
    all of the steps we have completed so far remain valid.
  prefs: []
  type: TYPE_NORMAL
- en: We will now define some parameters used for training. The first set of parameters
    are standard machine learning ones. The batch size defines the number of examples
    that will be used to calculate loss at a time, and the learning rate defines the
    rate at which parameters will be updated in the gradient descent optimization
    algorithm. The number of epochs is set here to `3`, which is a small number. This
    is because we are not training a model from scratch; we are simply using an already
    trained model, and fine-tuning it to operate on our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The next set of parameters exists for optimization and ease in training. It
    defines after how many steps a new version of the model should be saved. Here,
    we have set it to `500`, meaning that after every 500 steps, a new model will
    be saved. This helps us if we run into an unexpected error or crash; the model
    simply reads the latest saved model and picks up training from that point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the last set of parameters defines the positive ratio. This is the
    proportion of malware samples in the training data. Here we set it to 0.001, which
    amounts to 0.1%:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we read the data frame that contains our data. Recall that the `VERDICT`
    column contained a 0/1 label indicating whether that particular data point was
    malware or not. We separate the malware and benign samples, sample the required
    fraction from the positive class, and then combine it with the negative class.
    This way, we have a dataset that contains only the required proportion of malware
    samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We now split our data into training and testing sets. Note that here we have
    a very small proportion of malware in our sampled data. If we split randomly,
    we might end up with all of the malware entirely in the training or testing set.
    To avoid this, we apply stratified sampling. With stratified sampling, the proportion
    of labels remains roughly the same in both the training and testing datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Remember that the data we have is in the form of API call sequences. This has
    to be converted into a form suitable for being consumed by BERT. We do this in
    our next step and transform both the training and test data into the required
    format.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we use the `InputExample` class to wrap our API sequence string and
    labels together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we transform the sequence into features using our tokenizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have our features and labels. We are ready to train the model! We will
    use the model function builder we defined earlier to create the model and pass
    it to the TensorFlow estimator, which will take care of the training for us. We
    specify the output directory in which to save the trained model as well as the
    parameters we defined earlier (summary and checkpoint steps) in a run configuration.
    This also gets passed to the estimator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This will produce a lot of output, most of which you do not need to understand.
    The training time will vary depending on the processor you are using, the GPU
    (if any), and system usage. Without a GPU, the fine-tuning took approximately
    29,000 seconds, which amounts to roughly eight hours.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we want to use this fine-tuned model to make predictions for new data
    and evaluate its performance. We can use the same estimator in inference mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show you an output that prints out the metrics. Note that your
    numbers may differ slightly from the ones you see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Recall that earlier, we defined a model evaluation function. The variable metrics
    will contain the dictionary with the various evaluation metrics. If you print
    it out, you should be able to examine the accuracy, precision, recall, and F-1
    score.
  prefs: []
  type: TYPE_NORMAL
- en: 'This completes our experiment! We have successfully used a BERT model pre-trained
    on a language task and fine-tuned it to classify malicious applications based
    on the API call sequence. Feel free to experiment with the code. Here are some
    things to ponder:'
  prefs: []
  type: TYPE_NORMAL
- en: What happens if you use the BERT large model instead of the BERT base model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does the performance vary with the positive rate fraction?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What happens if you vary the architecture (add more layers)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, we have come to the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided an introduction to malware and a hands-on blueprint for
    how it can be detected using transformers. First, we discussed the concepts of
    malware and the various forms they come in (rootkits, viruses, and worms). We
    then discussed the attention mechanism and transformer architecture, which are
    recent advances that have taken the machine learning world by storm. We also looked
    at BERT, a model that has beat several baselines in tasks such as sentence classification
    and question-answering. We leveraged BERT for malware detection by fine-tuning
    a pre-trained model on API call sequence data.
  prefs: []
  type: TYPE_NORMAL
- en: Malware is a pressing problem that places users of phones and computers at great
    risk. Data scientists and machine learning practitioners who are interested in
    the security space need to have a strong understanding of how malware works and
    the architecture of models that can be used for detection. This chapter provided
    all of the knowledge needed and is a must to master for a SecML professional.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will switch gears and turn to a different problem:
    fake online reviews.'
  prefs: []
  type: TYPE_NORMAL
