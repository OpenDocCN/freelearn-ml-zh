- en: '*Chapter 14*: H2O at Scale in a Larger Platform Context'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第14章*：在更大平台环境下的H2O规模化'
- en: In the previous chapter, we broadened our view of H2O **machine learning** (**ML**)
    technology by introducing H2O AI Cloud, an **end-to-end** ML platform composed
    of multiple model-building engines, an MLOps platform for model deployment, monitoring,
    and management, a Feature Store for reusing and operationalizing model features,
    and a low-code **software development kit** (**SDK**) for building **artificial
    intelligence** (**AI**) applications on top of these components and hosting them
    on an app store for enterprise consumption. The focus of this book has been what
    we have called **H2O at scale**, or the use of H2O Core (H2O-3 and Sparkling Water)
    to build accurate and trusted models on massive datasets, H2O Enterprise Steam
    to manage H2O Core users and their environments, and the H2O MOJO to easily and
    flexibly deploy models to diverse target environments. We learned that these H2O-at-scale
    components are natively a part of the larger H2O AI Cloud platform, though they
    can be deployed separately from it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们通过介绍H2O AI云，一个由多个模型构建引擎、模型部署、监控和管理平台MLOps、用于重用和操作模型特征的特性存储以及构建在上述组件之上并在企业应用商店中托管的人工智能应用的低代码软件开发工具包（SDK）组成的**端到端**机器学习（ML）平台，扩展了我们对H2O
    ML技术的视野。本书的重点是我们所说的**H2O规模化**，即使用H2O Core（H2O-3和Sparkling Water）在大量数据集上构建准确和可信的模型，使用H2O
    Enterprise Steam来管理H2O Core用户及其环境，以及使用H2O MOJO轻松灵活地将模型部署到各种目标环境中。我们了解到，这些H2O规模化的组件是H2O
    AI云平台的原生部分，尽管它们可以独立于它部署。
- en: 'In this chapter, we will explore how H2O at scale achieves greater capabilities
    as a member of the H2O AI Cloud platform. More specifically, we will cover the
    following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨H2O规模化作为H2O AI云平台的一员如何获得更大的能力。更具体地说，我们将涵盖以下主题：
- en: A quick recap of H2O AI Cloud
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速回顾H2O AI云
- en: Exploring a baseline reference solution for H2O at scale
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索H2O规模化的基线参考解决方案
- en: Exploring new possibilities for H2O at scale
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索H2O规模化的新可能性
- en: A Reference H2O Wave app as an enterprise AI integration fabric
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为企业AI集成织物的参考H2O Wave应用
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This link will get you started on developing H2O Wave applications: [https://wave.h2o.ai/docs/installation](https://wave.h2o.ai/docs/installation).
    H2O Wave is open source and can be developed on your local machine. To get full
    familiarity with the H2O AI Cloud platform, you can sign up for a 90-day trial
    of H2O AI Cloud at [https://h2o.ai/freetrial](https://h2o.ai/freetrial).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此链接将帮助您开始开发H2O Wave应用：[https://wave.h2o.ai/docs/installation](https://wave.h2o.ai/docs/installation)。H2O
    Wave是开源的，可以在您的本地机器上开发。为了全面熟悉H2O AI云平台，您可以在[https://h2o.ai/freetrial](https://h2o.ai/freetrial)注册90天的H2O
    AI云试用。
- en: A quick recap of H2O AI Cloud
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速回顾H2O AI云
- en: 'The goal of this chapter is to explore how H2O at scale, the focus of this
    book, picks up new capabilities when used as part of the H2O AI Cloud platform.
    Let''s first have a quick review of H2O AI Cloud by revisiting the following diagram,
    which we encountered in the previous chapter:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是探讨H2O规模化，本书的重点，作为H2O AI云平台的一部分时，如何获得新的功能。让我们首先快速回顾H2O AI云，通过重新审视我们在上一章中遇到的以下图表：
- en: '![ Figure 14.1 – Components of the H2O AI Cloud platform'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![ 图14.1 – H2O AI云平台组件'
- en: '](img/B16721_14_001.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_14_001.jpg)'
- en: Figure 14.1 – Components of the H2O AI Cloud platform
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1 – H2O AI云平台组件
- en: As a quick summary, we see that H2O AI Cloud has four specialized model-building
    engines. H2O Core (H2O-3, H2O Sparkling Water) represents H2O DistributedML for
    horizontally scaling model building on massive datasets. H2O Enterprise Steam,
    in this context, represents a more generalized tool to manage and provision the
    model-building engines.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 简要总结一下，我们看到H2O AI云有四个专门的模型构建引擎。H2O Core（H2O-3，H2O Sparkling Water）代表H2O DistributedML，用于在大量数据集上水平扩展模型构建。在这个背景下，H2O
    Enterprise Steam代表一个更通用的工具，用于管理和提供模型构建引擎。
- en: We see that the H2O MOJO, exported from H2O Core model building, can be deployed
    directly to the H2O MLOps model deployment, monitoring, and management platform
    (though, as seen in [*Chapter 10*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178),
    *H2O Model Deployment Patterns*, the MOJO can be deployed openly to other targets
    as well). Note that the H2O specialized **automated ML** (**AutoML**) engine called
    Driverless AI also produces a MOJO and can be deployed in ways shown in [*Chapter
    10*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178), *H2O Model Deployment Patterns*.
    We also see that the H2O AI Feature Store is available to share and operationalize
    features both in the model-building and model-deployment contexts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，从H2O Core模型构建导出的H2O MOJO可以直接部署到H2O MLOps模型部署、监控和管理平台（尽管，如[*第10章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178)，*H2O模型部署模式*中所示，MOJO也可以公开部署到其他目标）。请注意，H2O的专用**自动化机器学习**（**AutoML**）引擎Driverless
    AI也生成MOJO，并可以按照[*第10章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178)，*H2O模型部署模式*中所示的方式进行部署。我们还看到，H2O
    AI特征存储可用于在模型构建和模型部署环境中共享和操作特征。
- en: Finally, we see that H2O Wave SDK is available to build AI apps over the other
    components of the H2O AI Cloud platform and then publish to an H2O App Store as
    part of the platform.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们看到H2O Wave SDK可用于在H2O AI Cloud平台的其他组件之上构建AI应用，并将其作为平台的一部分发布到H2O App Store。
- en: Let's now start to put these pieces together into various H2O-at-scale solutions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始将这些组件组合成各种H2O-at-scale解决方案。
- en: Exploring a baseline reference solution for H2O at scale
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索H2O在规模上的基线参考解决方案
- en: 'So, let''s now explore how H2O-at-scale components benefit from participating
    in the H2O AI Cloud platform. To do so, let''s first start with a baseline solution
    of H2O at scale outside of H2O AI Cloud. The baseline solution is shown in the
    following diagram. We will use this baseline to compare solutions where H2O at
    scale does integrate with AI Cloud components:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在让我们探索H2O-at-scale组件如何从参与H2O AI Cloud平台中受益。为此，让我们首先从H2O AI Cloud之外的H2O at
    scale的基线解决方案开始。基线解决方案如下所示。我们将使用这个基线来比较H2O at scale与AI Cloud组件集成的解决方案：
- en: '![Figure 14.2 – Baseline solution for H2O at scale'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 14.2 – H2O在规模上的基线解决方案'
- en: '](img/B16721_14_002.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_14_002.jpg](img/B16721_14_002.jpg)'
- en: Figure 14.2 – Baseline solution for H2O at scale
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2 – H2O在规模上的基线解决方案
- en: Important Note
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For this and all solutions in the chapter, it is assumed that the data scientist
    used H2O Enterprise Steam to launch an H2O-3 or H2O Sparkling Water environment.
    See [*Chapter 3*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042), *Fundamental
    Workflow – Data to Deployable Model*, for an overview of this step.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的所有解决方案，假设数据科学家使用H2O Enterprise Steam启动了H2O-3或H2O Sparkling Water环境。请参阅[*第3章*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042)，*基本工作流程
    – 从数据到可部署模型*，以了解这一步骤的概述。
- en: 'A quick walkthrough of its solution flow is summarized as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 其解决方案流程的快速概述如下：
- en: The data scientist imports a large dataset and uses it to build an ML model
    at scale. See the chapters in *Part 2*, *Building State-of-the-Art Models on Large
    Data Volumes Using H2O*, for a deep exploration of this topic.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家导入一个大型数据集，并使用它来构建大规模的ML模型。请参阅*第2部分*，*使用H2O在大型数据量上构建最先进的模型*，以深入了解这一主题。
- en: The operations group deploys the model artifact (called the H2O MOJO) to a scoring
    environment. See [*Chapter 10*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178),
    *H2O Model Deployment Patterns*, to explore a diversity of such target systems
    for H2O model deployment.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运作组将模型工件（称为H2O MOJO）部署到评分环境中。请参阅[*第10章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178)，*H2O模型部署模式*，以探索H2O模型部署的各种目标系统。
- en: The predictions are consumed and acted up by software or tooling within a business
    context. (Here, we are assuming the deployed model is a **supervised learning**
    model, though it could be an unsupervised model that generated outputs that are
    not predictions; for example, cluster membership of an input).
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测被业务环境中的软件或工具消费并采取行动。（在这里，我们假设部署的模型是一个**监督学习**模型，尽管它可能是一个未监督模型，生成了不是预测的输出；例如，输入的聚类成员资格）。
- en: Let's use this baseline solution to start adding H2O AI Cloud components and
    thus see how H2O at scale gains additional capabilities through membership of
    this larger platform.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个基线解决方案来开始添加H2O AI Cloud组件，从而了解H2O在规模上的能力如何通过加入这个更大的平台而获得额外的功能。
- en: Exploring new possibilities for H2O at scale
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索H2O在规模上的新可能性
- en: Now, let's step through different ways we can integrate H2O at scale—the focus
    of this book—with the rest of the H2O AI Cloud platform and thereby achieve greater
    capabilities and value.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐步了解如何将H2O（本书的重点）与其他H2O AI Cloud平台集成，从而实现更大的能力和价值。
- en: Leveraging H2O Driverless AI for prototyping and feature discovery
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用H2O Driverless AI进行原型化和特征发现
- en: H2O's AutoML Driverless AI component is a highly automated model-building tool
    that uses (among other features) a genetic algorithm, AI heuristics, and exhaustive
    automated **feature engineering** to build accurate and explainable models— typically
    in hours—that are then deployed to production systems. Driverless AI, however,
    does not scale to train on the hundreds of GB to TBs sized datasets that H2O-3
    and Sparkling Water handle.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: H2O的AutoML Driverless AI组件是一个高度自动化的模型构建工具，它使用（包括其他功能）遗传算法、AI启发式方法和详尽的自动化**特征工程**来构建准确且可解释的模型——通常在几小时内完成——然后部署到生产系统。然而，Driverless
    AI无法扩展到在H2O-3和Sparkling Water处理的数百GB到TB大小的数据集上进行训练。
- en: It is quite useful, however, for data scientists to feed sampled data from these
    massive datasets to Driverless AI and then use the AutoML tool to (a) quickly
    prototype the model to gain an early understanding and (b) discover auto-engineered
    features that contribute to an accurate model but would otherwise be difficult
    to find from pure manual and domain knowledge means. The resulting knowledge from
    Driverless AI in this workflow is then used as a starting point to build models
    at scale against the original unsampled data using H2O-3 or Sparkling Water.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于数据科学家来说，将这些大规模数据集的采样数据输入到Driverless AI，然后使用AutoML工具（a）快速原型化模型以获得早期理解，以及（b）发现有助于准确模型的自动工程特征，但通过纯手动和领域知识手段难以找到，这非常有用。在此工作流程中，Driverless
    AI产生的知识随后用作起点，使用H2O-3或Sparkling Water在原始未采样的数据上构建大规模模型。
- en: 'This is shown in the following diagram and then summarized:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这在以下图表中显示，然后进行总结：
- en: '![Figure 14.3 – Leveraging H2O Driverless AI for prototyping and feature discovery'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.3 – 利用H2O Driverless AI进行原型化和特征发现]'
- en: '](img/B16721_14_003.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16721_14_003.jpg]'
- en: Figure 14.3 – Leveraging H2O Driverless AI for prototyping and feature discovery
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3 – 利用H2O Driverless AI进行原型化和特征发现
- en: 'The workflow steps to leverage Driverless AI to quickly prototype and discover
    features for model building at scale are provided here:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供了利用Driverless AI快速原型化和发现用于大规模模型构建的特征的工作流程步骤：
- en: Import a large-volume dataset into the distributed in-memory architecture inherent
    in the H2O-at-scale environment. Sample the imported data into a smaller subset
    (typically 10 to 100 GB) using the H2O-3 `split_frame` method (here in Python)
    with an appropriate ratio defined as an input parameter to achieve the desired
    sample size. Write the output to a staging location that Driverless AI can access.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将大量数据集导入到H2O-at-scale环境固有的分布式内存架构中。使用H2O-3的`split_frame`方法（此处为Python）对导入的数据进行采样，形成一个较小的子集（通常为10到100
    GB），并定义一个合适的比例作为输入参数以实现所需的样本大小。将输出写入Driverless AI可以访问的临时存储位置。
- en: Import the sampled dataset to Driverless AI. Use defaults to quickly prototype
    an accurate model. Use different settings to continue prototyping based on your
    domain and data-science experience. Explore explainability techniques on models.
    Explore engineered features with the highest contribution to models. Use **Automated
    Model Documentation** (**AutoDoc**) to understand the models more deeply and translate
    the names of engineered features into their underlying mathematical and logical
    representations.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将采样数据集导入Driverless AI。使用默认设置快速原型化一个准确的模型。根据您的领域和数据科学经验使用不同的设置继续原型化。探索模型的可解释性技术。探索对模型贡献最大的工程特征。使用**自动化模型文档**（**AutoDoc**）深入了解模型，并将工程特征的名称转换为它们背后的数学和逻辑表示。
- en: Use the knowledge from *Step 2* to guide your model building against the full
    massive dataset on H2O-3 or Sparkling Water.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*步骤2*中的知识来指导您在H2O-3或Sparkling Water上对完整的大量数据集进行模型构建。
- en: 'Driverless AI was overviewed in [*Chapter 13*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241),
    *Introducing H2O AI Cloud*. The following screenshot shows an experiment iterating
    toward a final accurate model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第13章*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241)“介绍H2O AI Cloud”中概述了Driverless
    AI。以下截图显示了一个实验迭代以获得最终准确模型：
- en: '![Figure 14.4 – Driverless AI finding an accurate model'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.4 – Driverless AI找到一个准确模型]'
- en: '](img/B16721_14_004.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16721_14_004.jpg]'
- en: Figure 14.4 – Driverless AI finding an accurate model
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4 – 无人驾驶AI找到一个准确的模型
- en: Note the lower-left panel of *Figure 14.4*, which shows the progress of the
    genetic algorithm iterating across models. Each square is a separate ML model
    that has been built. Each of these models uses one of an automated choice of algorithms
    (for example, XGBoost; **Light Gradient Boosting Model** (**LightGBM**); **Generalized
    Linear Model** (**GLM**)) that explores an extremely wide hyperparameter space
    (for example, combinations of learning rates, tree depths, number of trees, to
    name a few).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意图14.4的左下角面板，它显示了遗传算法在模型间迭代的进度。每个方块是一个单独构建的ML模型。这些模型中每一个都使用自动选择的算法之一（例如，XGBoost；**轻梯度提升模型**（**LightGBM**）；**广义线性模型**（**GLM**）），这些算法探索了极其广泛的超参数空间（例如，学习率、树深度、树的数量等组合）。
- en: Importantly, each model built by the genetic algorithm also explores an extremely
    wide space of features engineered from those in the original imported dataset.
    The experiment will stop with a final best model, typically a stacked ensemble
    of preceding top models. Users can run many experiments in short amounts of time
    with the intent of exploring, by changing many high-level and low-level settings
    and evaluating outcomes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，遗传算法构建的每个模型也探索了从原始导入的数据集中工程化出的极其广泛的特征空间。实验将在最终的最佳模型结束时停止，通常是一个先前顶级模型的堆叠集成。用户可以在短时间内运行许多实验，目的是通过改变许多高级和低级设置并评估结果来探索。
- en: Knowledge gained from these rapid explorations, including feature engineering
    that is important to the final model, can be used as a starting point to build
    models at scale with H2O-3 or Sparkling Water.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些快速探索中获得的知识，包括对最终模型重要的特征工程，可以用作使用H2O-3或Sparkling Water构建大规模模型的起点。
- en: Note that for smaller datasets, Driverless AI is quite effective at finding
    highly predictive models in short periods of time. H2O-3 and Sparkling Water,
    however, are needed for scaling to massive datasets or for taking a more controlled
    code-based approach to model building. As shown here, for the code-based approach,
    it is valuable to first prototype a problem with Driverless AI and then use the
    resulting insights and engineered features as a guide to the code-based approach.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于较小的数据集，无人驾驶AI在短时间内发现高度预测性模型非常有效。然而，对于扩展到大量数据集或采用更受控的基于代码的方法来构建模型，则需要H2O-3和Sparkling
    Water。正如这里所示，对于基于代码的方法，首先使用无人驾驶AI原型化一个问题，然后利用产生的洞察力和工程化特征作为基于代码方法的指南，这是很有价值的。
- en: 'Driverless AI (AutoML) versus H2O-3 (DistributedML): When to Use Which?'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 无人驾驶AI（AutoML）与H2O-3（分布式ML）对比：何时使用哪一个？
- en: Driverless AI is a highly automated **user interface** (**UI**)-based (or **application
    programming interface** (**API**)-based) AutoML component of H2O AI Cloud designed
    to quickly find accurate and trusted models for production scoring. Use it when
    you want a highly automated approach (with extensive user controls) to model building
    and when dataset sizes are less than 100 GB (though more resource-heavy server
    instances can work with larger datasets).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 无人驾驶AI是H2O AI云的一个高度自动化的基于**用户界面**（**UI**）或基于**应用程序编程接口**（**API**）的AutoML组件，旨在快速找到准确且值得信赖的模型用于生产评分。当你想要一个高度自动化的方法（具有广泛的用户控制）来构建模型，并且数据集大小小于100
    GB时（尽管更重的服务器实例可以处理更大的数据集）请使用它。
- en: Use H2O-3 or Sparkling Water when your datasets are greater than 100 GB (and
    into TBs) or for a code-based approach to model building when you want more control
    of the model-building process. Note that H2O-3 and Sparkling Water have AutoML
    capabilities, as described in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part 1*, but those in Driverless AI are far more sophisticated,
    extensive, and automated.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的数据集大于100 GB（甚至达到TB级别）或当你想要对模型构建过程有更多控制时，请使用H2O-3或Sparkling Water。请注意，H2O-3和Sparkling
    Water具有AutoML功能，如[*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)中所述，*高级模型构建
    – 第1部分*，但无人驾驶AI中的功能更为复杂、广泛和自动化。
- en: Use Driverless AI to prototype a problem and take the resulting insights and
    discovery of engineered features to guide your model building on H2O-3 or Sparkling
    Water.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用无人驾驶AI原型化一个问题，并将产生的洞察力和工程化特征的发现用于指导你在H2O-3或Sparkling Water上的模型构建。
- en: We have seen our first example of H2O-at-scale model building gaining capabilities
    by interacting with a component in the H2O AI Cloud platform. Let's now look at
    our next example.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了第一个例子，通过与H2O AI云平台的一个组件交互，H2O-at-scale模型构建获得了能力。现在让我们看看下一个例子。
- en: Integrating H2O MLOps for model monitoring, management, and governance
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成 H2O MLOps 以进行模型监控、管理和治理
- en: Models built with H2O-3 and Sparkling Water generate their own ready-to-deploy
    low-latency scoring artifact called the H2O MOJO. As we showed in [*Chapter 10*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178),
    *H2O Model Deployment Patterns*, this scoring artifact can be deployed to a great
    diversity of production systems, ranging from real-time scoring from **REpresentational
    State Transfer** (**REST**) servers and batch scoring from databases to scoring
    from streaming queues (to name a few). We also showed in that chapter that deploying
    to a REST server provides a useful integration pattern for integrating scored
    predictions into common **business intelligence** (**BI**) tools such as Microsoft
    Excel or Tableau.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 H2O-3 和 Sparkling Water 构建的模型会生成自己的低延迟评分工件，称为 H2O MOJO。正如我们在[*第 10 章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178)，“*H2O
    模型部署模式”中所示，这种评分工件可以部署到各种生产系统，从 **REpresentational State Transfer** (**REST**)
    服务器上的实时评分到数据库上的批量评分，以及从流队列中的评分（仅举几例）。我们还展示了在该章节中，将数据部署到 REST 服务器为将评分预测集成到常见的 **商业智能**
    (**BI**) 工具（如 Microsoft Excel 或 Tableau）提供了一个有用的集成模式。
- en: 'The H2O MLOps component of H2O AI Cloud is an excellent choice for deploying
    H2O-3 or Sparkling Water models (or Driverless AI models and non-H2O models—for
    example, scikit-learn models, for that matter). The integration is quite simple,
    as shown in the following diagram:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: H2O AI Cloud 的 H2O MLOps 组件是部署 H2O-3 或 Sparkling Water 模型（或 Driverless AI 模型和非
    H2O 模型，例如 scikit-learn 模型）的一个很好的选择。集成非常简单，如下面的图所示：
- en: '![Figure 14.5 – Deployment of H2O-at-scale models to the H2O MLOps platform'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 14.5 – Deployment of H2O-at-scale models to the H2O MLOps platform'
- en: '](img/B16721_14_005.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_14_005.jpg]'
- en: Figure 14.5 – Deployment of H2O-at-scale models to the H2O MLOps platform
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.5 – 将 H2O-at-scale 模型部署到 H2O MLOps 平台
- en: 'The steps to integrate these models are straightforward, as outlined here:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 集成这些模型的步骤非常简单，如下所述：
- en: Build your model with H2O-3 or Sparkling Water and export the MOJO for deployment.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 H2O-3 或 Sparkling Water 构建您的模型，并导出 MOJO 以进行部署。
- en: From H2O MLOps, deploy the staged MOJO either from the UI or the MLOps API.
    Recall from [*Chapter 13*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241), *Introducing
    H2O AI Cloud,* that there are many deployment options, including real-time versus
    batch, single model versus champion/challenger, or A/B testing.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 H2O MLOps，您可以从 UI 或 MLOps API 中部署预制的 MOJO。回想一下[*第 13 章*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241)，“*介绍
    H2O AI Cloud”，那里有许多部署选项，包括实时与批量、单个模型与冠军/挑战者，或 A/B 测试。
- en: The model is now scorable from a unique REST endpoint. Predictions with optional
    reason codes are ready to be consumed by your system, whether that is a web application,
    a BI tool, and so on.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型现在可以从一个独特的 REST 端点进行评分。带有可选原因代码的预测准备就绪，可供您的系统消费，无论该系统是 Web 应用程序、BI 工具等。
- en: 'For all models during and after this flow, MLOps performs important tasks around
    monitoring, managing, and governing models. The following screenshot, for example,
    shows the data drift monitoring screen for H2O MLOps:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在此流程期间和之后的所有模型中，MLOps 执行与监控、管理和治理模型相关的重要任务。例如，以下截图显示了 H2O MLOps 的数据漂移监控屏幕：
- en: '![Figure 14.6 – Model-monitoring screen for H2O MLOps'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 14.6 – Model-monitoring screen for H2O MLOps'
- en: '](img/B16721_14_006.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_14_006.jpg]'
- en: Figure 14.6 – Model-monitoring screen for H2O MLOps
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.6 – H2O MLOps 的模型监控屏幕
- en: The purpose of monitoring data drift is to detect whether the distribution of
    feature values in live scoring data is diverging from that in the training data
    from which the model was built. The presence of data drift suggests or indicates
    that the model should be retrained with more recent data and then redeployed to
    align with current scoring data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 监控数据漂移的目的是检测实时评分数据中特征值的分布是否与构建模型时所用的训练数据中的分布存在差异。数据漂移的存在表明或暗示模型应该使用更近期的数据进行重新训练，然后重新部署以与当前的评分数据对齐。
- en: 'In the lower-left panel in *Figure 14.6*, data drift for all model features
    is represented in two dimensions: drift on the vertical axis and feature importance
    on the horizontal axis. This view allows partitioning of drift into quadrants
    of drift importance, with high drift and high feature importance being the most
    important drift. Multiple settings are available to define the drift statistic,
    the time frame of measurement, and other aspects of viewing drift. There is also
    a workflow to configure automated alert messaging for drift. These can be used
    either for data scientists to manually decide on whether to retrain a model or
    for fully automated model retraining and deployment through H2O APIs.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图14.6*的左下角面板中，所有模型特征的数据漂移以两个维度表示：垂直轴上的漂移和水平轴上的特征重要性。这种视图允许将漂移分为漂移重要性的四个象限，其中高漂移和高特征重要性是最重要的漂移。有多个设置可以定义漂移统计量、测量的时间框架和其他查看漂移的方面。还有一个工作流程来配置漂移的自动警报消息。这些可以用于数据科学家手动决定是否重新训练模型，或者通过H2O
    API完全自动地重新训练和部署模型。
- en: Drift detection is just one of the capabilities of H2O MLOps. See the H2O documentation
    at [https://docs.h2o.ai/mlops/](https://docs.h2o.ai/mlops/) for a full description
    of H2O MLOps model deployment, monitoring, management, and governance capabilities.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 漂移检测只是H2O MLOps功能之一。有关H2O MLOps模型部署、监控、管理和治理功能的完整描述，请参阅H2O文档[https://docs.h2o.ai/mlops/](https://docs.h2o.ai/mlops/)。
- en: Let's now look at how H2O-3 and Sparkling Water can integrate into H2O AI Feature
    Store.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下H2O-3和Sparkling Water如何集成到H2O AI特征存储中。
- en: Leveraging H2O AI Feature Store for feature operationalization and reuse
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用H2O AI特征存储进行特征操作化和复用
- en: Enterprises often achieve economy of scale by centralizing and sharing environments
    or assets across the organization. H2O AI Feature Store achieves economy of scale
    by centralizing model features and the operationalization of their curation through
    engineering pipelines for reuse across the organization.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 企业通常通过在组织内部集中和共享环境或资产来实现规模经济。H2O AI特征存储通过集中模型特征及其通过工程管道进行操作化的实现，在整个组织内进行复用，从而实现规模经济。
- en: 'Reuse through the Feature Store occurs during both model-building and model-scoring
    contexts. For example, let''s say that a valuable feature across the organization
    is the percentage change in asset price compared to the previous day. Imagine,
    though, that asset price is stored as price per day and asset prices are stored
    in multiple source systems. Feature Store handles retrieval of features from source
    systems and calculation of new values from the original (that is, the feature
    engineering pipeline) and caching the result (the engineered feature) to be shared
    for model training and model scoring. Model building uses an offline mode—that
    is, batched historical data—and uses an online mode for model scoring—that is,
    recent data. This is shown in the following diagram:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过特征存储的复用发生在模型构建和模型评分的上下文中。例如，假设在整个组织中的一个有价值特征是资产价格相对于前一天的百分比变化。然而，想象一下，资产价格以每日价格存储，并且资产价格存储在多个源系统中。特征存储处理从源系统中检索特征，从原始数据（即特征工程管道）计算新值，并将结果（即工程化特征）缓存以供模型训练和模型评分共享。模型构建使用离线模式——即批量历史数据——并使用在线模式进行模型评分——即最近的数据。这在下图中显示：
- en: '![Figure 14.7 – Integration of H2O AI Feature Store with H2O-3 or Sparkling
    Water'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.7 – H2O AI特征存储与H2O-3或Sparkling Water的集成'
- en: '](img/B16721_14_007.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_14_007.jpg)'
- en: Figure 14.7 – Integration of H2O AI Feature Store with H2O-3 or Sparkling Water
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7 – H2O AI特征存储与H2O-3或Sparkling Water的集成
- en: 'Here''s a summary of the workflow in *Figure 14.7*:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是*图14.7*中的工作流程总结：
- en: A data scientist builds a model.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家构建一个模型。
- en: 'During the model-building stage, the data scientist may interact with the feature
    store in two different ways, as outlined here:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型构建阶段，数据科学家可能以两种不同的方式与特征存储进行交互，如下所述：
- en: The data scientist may publish a feature to the Feature Store and include associated
    metadata to assist in search and operationalization by others. An ML engineer
    operationalizes the engineering of the feature from the data source(s) to feed
    the feature values in the feature store. Each feature is configured for how long
    it lives before being updated—for example, update each minute, day, or month.
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家可能将特征发布到特征存储库，并包括相关的元数据以帮助他人进行搜索和操作。机器学习工程师将特征从数据源（源）的操作工程化，以向特征存储库中的特征值提供数据。每个特征都配置了在更新之前存活的时间——例如，每分钟、每天或每月更新一次。
- en: The data scientist may search the Feature Store for features during model building.
    They use the Feature Store API to import the feature and its value into the training
    data loaded by H2O-3 or Sparkling Water (more specifically, into the in-memory
    H2OFrame, which is analogous to a DataFrame).
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型构建期间，数据科学家可以在特征存储库中搜索特征。他们使用特征存储库API将特征及其值导入由H2O-3或Sparkling Water加载的培训数据（更具体地说，导入内存中的H2OFrame，它与DataFrame类似）。
- en: The model is deployed to H2O MLOps, which is configured to consume the feature
    from the feature store. The feature is updated at its configured interval.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型部署到H2O MLOps，该系统配置为从特征存储库中消耗特征。特征在其配置的间隔内更新。
- en: The predictions and—optionally—reason codes are consumed.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消耗预测和（可选）原因代码。
- en: We have ended our workflows with predictions being consumed. Let's now showcase
    how the H2O Wave SDK can be used by data scientists and ML engineers to quickly
    build AI applications with sophisticated visualizations and workflows around model
    predictions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作流程以预测被消耗结束。现在让我们展示H2O Wave SDK如何被数据科学家和机器学习工程师快速构建具有复杂可视化和工作流程的AI应用，这些工作流程围绕模型预测。
- en: Consuming predictions in a business context from a Wave AI app
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从Wave AI应用中在业务环境中消耗预测
- en: ML models ultimately gain value when their outputs are consumed by personas
    or automation executing workflows. These workflows can be based on single predictions
    and underlying reason codes themselves or from insights and intelligence gained
    from them. For example, a customer service representative identifies customers
    who have a high likelihood of leaving the business and proactively reaches out
    to them with improvements or incentives to stay based on the reasons why the model
    made its prediction of likely churn. Alternatively, an analyst explores multiple
    interactive dashboards of churn predictions made in the past 6 months to gain
    insights into the causes of churn and identify where the business can improve
    to prevent churn.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型只有在它们的输出被用于执行工作流程的个人或自动化系统消费时才能获得价值。这些工作流程可以基于单个预测及其背后的原因代码，或者从它们中获得的洞察和智能。例如，客户服务代表识别出有高概率离开业务的客户，并主动与他们联系，提供改进或激励措施以保持业务，基于模型对其可能流失的预测的原因。或者，分析师探索过去6个月内做出的多个流失预测交互式仪表板，以了解流失的原因，并确定业务可以在哪些方面改进以防止流失。
- en: As we learned in [*Chapter 13*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241),
    *Introducing H2O AI Cloud*, H2O Wave is a low-code SDK used by data scientists
    and ML engineers to easily build AI applications and publish them to an App Store
    for enterprise or external use. What do we mean by an AI app? An AI app here is
    a web application that presents one or more stages of the ML life cycle as rich
    visualizations, user interactions, and workflow sequences. The H2O Wave SDK makes
    these easy to build by exposing UI elements (dashboard templates, dialogs, and
    widgets) as attributes-based Python code while abstracting away the complexities
    of building a web application.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[*第13章*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241)中学习的，*介绍H2O AI Cloud*，H2O
    Wave是一个低代码SDK，数据科学家和机器学习工程师使用它来轻松构建AI应用并将它们发布到企业或外部使用的App Store。我们所说的AI应用是什么意思？这里的AI应用是一个展示机器学习生命周期一个或多个阶段的富可视化、用户交互和工作流程序列的Web应用。H2O
    Wave SDK通过将UI元素（仪表板模板、对话框和小部件）作为基于属性的Python代码暴露出来，同时抽象出构建Web应用的复杂性，使得这些应用易于构建。
- en: 'In our example here, Wave apps are being used specifically by business personas
    to consume predictions, as shown in the following diagram. Note that our next
    example will be a Wave app used by data scientists to manage model retraining,
    and not to consume predictions:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，Wave应用被特定地用于由业务角色消耗预测，如下面的图所示。请注意，我们的下一个示例将是一个由数据科学家使用的Wave应用，用于管理模型重新训练，而不是消耗预测：
- en: '![Figure 14.8 – Prediction consumption in Wave AI applications'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.8 – Wave AI应用中的预测消耗'
- en: '](img/B16721_14_008.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_14_008.jpg)'
- en: Figure 14.8 – Prediction consumption in Wave AI applications
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.8 – Wave AI应用中的预测消费
- en: 'The ML workflow in *Figure 14.8* is a familiar one but with a Wave app that
    consumes predictions. Wave''s low-code SDK enables multiple integration protocols
    and thus allows predictions and reason codes to be consumed in real time from
    a REST endpoint or as a batch from a file upload or data warehouse connection,
    for example. As shown in the preceding diagram, from a business context, Wave
    apps that consume predictions can do the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.8*中的ML工作流程是熟悉的，但Wave应用消耗预测。Wave的低代码SDK支持多种集成协议，因此允许从REST端点实时消耗预测和原因代码，或者从文件上传或数据仓库连接批量消耗，例如。如图所示，从业务角度来看，消耗预测的Wave应用可以执行以下操作：'
- en: Visualize predictions from historical and individual prediction views
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从历史和个体预测视图可视化预测
- en: Visualize insights from underlying prediction reason codes, from both global
    (model-level) and individual (single model-scoring) views
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从全局（模型级）和个体（单个模型评分）视图，可视化来自底层预测原因代码的洞察
- en: Perform BI analytics on predictions and insights
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对预测和洞察进行BI分析
- en: Perform workflows for humans in the loop to act on visualizations and analytics
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行人类在循环中的工作流程，以对可视化和分析采取行动
- en: 'Let''s look at a specific example. The screenshot that follows shows one page
    of a Wave app that consumes and displays visualizations from predictions on employee
    churn—in other words, the predicted likelihood that employees will leave the company:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个具体的例子。下面的截图显示了Wave应用消耗并显示员工流失预测可视化的一页——换句话说，就是员工离职的预测可能性：
- en: '![Figure 14.9 – A Wave app visualizing employee churn'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.9 – 一个可视化员工流失的Wave应用'
- en: '](img/B16721_14_009.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.8 – Wave AI应用中的预测消费](img/B16721_14_009.jpg)'
- en: Figure 14.9 – A Wave app visualizing employee churn
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.9 – 一个可视化员工流失的Wave应用
- en: 'This page shows views of the latest batch of employee-churn predictions. The
    upper-left panel shows the probability distribution of these predictions. We can
    see that most employees that were scored by the model have a low probability of
    leaving, though there is a long tail of higher-probability employees. The upper-right
    panel provides insights into why employees depart the company: it shows the Shapley
    values or feature contributions (reason codes) to the prediction. We see that
    overtime, job role, and shift schedule are the top three factors contributing
    to the model''s predictions of churn. The bottom panels show visualizations to
    help understand these predictions better: the left panel displays a geographic
    distribution of churn likelihood, and the right shows a breakdown by job role.
    The thin panel above the map allows user interaction whereby the slider defines
    the probability threshold of classifying an employee as churn or no churn: the
    bottom two panels refresh accordingly as a result.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 本页显示了最新一批员工流失预测的视图。左上角的面板显示了这些预测的概率分布。我们可以看到，大多数被模型评分的员工离职概率较低，尽管有较高概率的员工的长尾。右上角的面板提供了关于员工离职原因的洞察：它显示了Shapley值或特征贡献（原因代码）对预测的影响。我们看到，加班、工作角色和班次安排是导致模型预测流失的前三大因素。底部面板显示了可视化，有助于更好地理解这些预测：左面板显示了流失可能性的地理分布，右面板显示了按工作角色的分解。地图上方的细面板允许用户交互，其中滑块定义了将员工分类为流失或非流失的概率阈值：底部两个面板相应刷新。
- en: The previous screenshot of the Wave app visualized predictions at a batch level—that
    is, of all employees scored over a time period. The application also has a page
    that displays predictions visualized at the individual level. When the user clicks
    on an individual employee (displayed with associated churn probability and other
    employee data), Shapley values are displayed, showing the top features contributing
    to the likelihood of churn for *that individual*. A particular individual may
    show, for example, that monthly income is the larger contribution to the prediction
    and that overtime actually contributes to the individual *not* churning. This
    insight suggests that the employee may leave the company because they are not
    making enough money and are trying to make more. This allows the employee's manager
    to evaluate a salary increase to help guarantee they stay with the organization.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Wave应用的上一张截图展示了批量级别的预测可视化——即在一个时间段内所有员工的评分。该应用还有一个页面，可以显示个体级别的预测可视化。当用户点击某个个体员工（显示相关的流失概率和其他员工数据）时，会显示Shapley值，显示对那个个体流失可能性贡献最大的特征。例如，某个个体可能显示月收入是预测的主要贡献因素，而加班实际上有助于该个体*不*流失。这个洞察表明，员工可能因为收入不足而试图赚更多钱，从而离开公司。这允许员工的经理评估加薪，以确保他们留在组织中。
- en: 'The UI in *Figure 14.9* shows predictions placed in a business context where
    individuals can act upon them. Keep in mind that H2O Wave is quite extensible
    and can incorporate Python packages of your liking, including Python APIs, to
    non-H2O components. Also, remember that the example Wave app shown here is meant
    to be a capability demonstrator: it is not an out-of-the-box point solution to
    manage employee churn but rather an example of how data scientists and ML engineers
    can easily build AI applications using the Wave SDK.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.9*中的UI显示了将预测置于业务背景中的情况，个人可以据此采取行动。请记住，H2O Wave非常易于扩展，可以将其喜欢的Python包（包括Python
    API）纳入非H2O组件。此外，请记住，这里展示的示例Wave应用旨在作为一个能力演示器：它不是一个现成的点解决方案来管理员工流失，而是一个数据科学家和ML工程师如何使用Wave
    SDK轻松构建AI应用的示例。'
- en: H2O Wave SDK Is Very Extensible
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Wave SDK非常易于扩展
- en: The UI in *Figure 14.9* is fairly simple but nevertheless effective in putting
    predictions into a business and analytical context. The H2O Wave SDK is quite
    extensible and thus allows greater layers of sophistication to be included in
    applications built from it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.9*中的UI相对简单，但仍然有效地将预测置于业务和数据分析的背景中。H2O Wave SDK非常易于扩展，因此允许在基于其构建的应用中包含更复杂的层次结构。'
- en: You can, for example, implement HTML **Cascading Style Sheets** (**CSS**) to
    give the **user experience** (**UX**) a more modern or company-specific look.
    Because Wave applications are containerized and isolated from each other, you
    can install any Python package and use it in the application. You can, for example,
    implement **Bokeh** for powerful interactive visualizations or **pandas** for
    data manipulation, or a vendor or home-grown Python API to interact with parts
    of your technology ecosystem.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以实现HTML**层叠样式表**（**CSS**）来给**用户体验**（**UX**）带来更现代或公司特定的外观。由于Wave应用是容器化和相互隔离的，你可以安装任何Python包并在应用中使用它。例如，你可以实现**Bokeh**进行强大的交互式可视化或**pandas**进行数据处理，或者供应商或自建的Python
    API来与你的技术生态系统的一部分进行交互。
- en: Note that the main intent of H2O Wave is for you to build your own AI applications
    with its SDK and to make them purpose-built for your needs. Applications are developed
    locally and can be prototyped quickly with intended users, then finalized, polished,
    and published to H2O App Store for enterprise role-based consumption. H2O will,
    however, provide example applications to you as code accelerators.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，H2O Wave的主要目的是让你使用其SDK构建自己的AI应用，并使其针对你的需求量身定制。应用是在本地开发的，可以快速为预期用户进行原型设计，然后最终完成、润色并发布到H2O
    App Store，供企业基于角色的消费。然而，H2O将提供示例应用给你作为代码加速器。
- en: You can explore live Wave apps by signing up for a 90-day free trial of H2O
    AI Cloud at [https://h2o.ai/freetrial/](https://h2o.ai/freetrial/). You can also
    explore and use the H2O Wave SDK, which is open source, by visiting [https://wave.h2o.ai/](https://wave.h2o.ai/).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过注册H2O AI Cloud的90天免费试用版来探索实时Wave应用，[https://h2o.ai/freetrial/](https://h2o.ai/freetrial/)。你还可以通过访问[https://wave.h2o.ai/](https://wave.h2o.ai/)来探索和使用开源的H2O
    Wave SDK。
- en: We have just explored how Wave apps can be built to consume predictions as part
    of a business analytic and decision-making workflow. Business users need not be
    the only Wave app users. Let's now look at a Wave app used by data scientists
    and built to drive the model-building and model-deployment stages of the ML life
    cycle.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚探讨了如何构建Wave应用程序以作为业务分析和决策工作流程的一部分来消耗预测。业务用户不一定是唯一的Wave应用程序用户。现在让我们看看一个由数据科学家使用并构建的Wave应用程序，用于驱动ML生命周期的模型构建和模型部署阶段。
- en: Integrating an automated retraining pipeline in a Wave AI app
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Wave AI应用程序中集成自动重新训练管道
- en: The H2O Wave SDK includes native APIs to other H2O AI Cloud components. This
    allows data scientists to build Wave apps to accomplish data-science workflows
    (compared to building applications in a business-user context, as shown in the
    previous example).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Wave SDK包括对其他H2O AI Cloud组件的原生API。这使得数据科学家能够构建Wave应用程序以完成数据科学工作流程（与在业务用户环境中构建应用程序相比，如前一个示例所示）。
- en: A common need in data science, for example, is to recognize data drift in deployed
    models and then retrain the model with recent data and redeploy the updated model.
    The following diagram shows how this can be done using a Wave app as both an automation
    orchestrator and UI for tracking the history of retraining and performing analytics
    around the history. This is an application idea and can be defined differently,
    but the general idea should be helpful.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中的一个常见需求，例如，是识别已部署模型中的数据漂移，然后使用最近的数据重新训练模型，并重新部署更新后的模型。以下图表显示了如何使用Wave应用程序作为自动化编排器和跟踪重新训练历史以及围绕历史进行分析的UI来完成此操作。这是一个应用程序想法，可以有不同的定义，但一般想法应该是有帮助的。
- en: 'Here, you can see an overview of the full ML workflow:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以查看整个ML工作流程的概述：
- en: '![Figure 14.10 – A Wave app for automated model retraining'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.10 – 自动模型重新训练的Wave应用程序]'
- en: '](img/B16721_14_010.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_14_010.jpg]'
- en: Figure 14.10 – A Wave app for automated model retraining
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.10 – 自动模型重新训练的Wave应用程序
- en: 'The workflow is summarized as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程总结如下：
- en: The model is built and evaluated in H2O-3 or Sparkling Water (or other H2O model-building
    engines, such as Driverless AI).
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型在H2O-3或Sparkling Water（或其他H2O模型构建引擎，如Driverless AI）中构建和评估。
- en: The model is deployed to H2O MLOps and predictions are consumed. MLOps is configured
    to detect data drift on the model.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模型已部署到H2O MLOps，并消耗了预测结果。MLOps已配置为检测模型上的数据漂移。
- en: At a point in time, drift exceeds configured thresholds for the model, and an
    alert is sent to the model-retraining Wave app that you have built.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在某个时间点，模型的漂移超过了配置的阈值，并向您构建的模型重新训练Wave应用程序发送警报。
- en: The model-retraining Wave app triggers the retraining of the model on the H2O
    model-building engine (in our case, H2O-3 or Sparkling Water). The Wave app deploys
    the retrained model as a challenger in H2O MLOps (using the MLOps API), and after
    a time, the Wave app evaluates the performances of the newly retrained challenger
    versus the existing champion model. The challenger is promoted to replace the
    champion if the former outperforms the latter. The cycle (*steps 3 and 4*) continues
    from this point.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型重新训练Wave应用程序触发在H2O模型构建引擎（在我们的案例中，H2O-3或Sparkling Water）上重新训练模型。Wave应用程序将重新训练的模型作为挑战者部署到H2O
    MLOps（使用MLOps API），经过一段时间后，Wave应用程序评估新重新训练的挑战者与现有冠军模型的性能。如果前者优于后者，挑战者将被提升以取代冠军。从这个点开始，周期（*步骤3和4*）继续进行。
- en: The model-retraining Wave app can provide reporting, visualizations, and analytics
    around model retraining. For example, there could be a table of retraining history
    including time of retraining, drift measurement, current status (for example,
    training in progress, model deployed, and in challenger state or champion state),
    and so on. Visualizations could be provided that provide greater insights into
    the data drift and model-retraining and deployment pipeline. As an alternative,
    automation could be replaced by a human-in-the-loop workflow where steps in the
    pipeline are done manually based on data-scientist evaluations.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 模型重新训练Wave应用程序可以提供关于模型重新训练的报告、可视化和分析。例如，可能有一个包括重新训练时间、漂移测量、当前状态（例如，训练进行中、模型已部署、处于挑战者状态或冠军状态）等的重新训练历史记录表。可以提供提供更多数据漂移和模型重新训练及部署管道洞察力的可视化。作为替代，可以通过人工流程代替自动化，其中管道中的步骤根据数据科学家的评估手动完成。
- en: The goal of H2O Wave as an application-building framework is for you to easily
    build applications according to your own specifications and to integrate into
    the application other components in your ecosystem. So, you likely envision a
    model-retraining application a bit differently than what is shown here. The H2O
    Wave SDK allows you to build the application that you envision.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Wave作为应用构建框架的目标是让您能够轻松地根据自己的规格构建应用，并将您生态系统中的其他组件集成到应用中。因此，您可能对模型重新训练应用的想法与这里展示的不同。H2O
    Wave SDK允许您构建您所设想的应用。
- en: In our example model-retraining application, we integrated multiple H2O components
    into a Wave application workflow with visualizations and analytics. In the next
    section, we will expand integrations to non-H2O components of your ecosystem and
    thereby present a powerful framework to build Wave apps as a single pane of glass
    across your AI ecosystem.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例模型重新训练应用中，我们将多个H2O组件集成到Wave应用工作流程中，包括可视化和分析。在下一节中，我们将扩展集成到您生态系统中的非H2O组件，从而展示一个强大的框架，用于构建作为您AI生态系统单一视窗的Wave应用。
- en: A Reference H2O Wave app as an enterprise AI integration fabric
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作为企业AI集成织物的参考H2O Wave应用
- en: The low-code Wave SDK allows data scientists, ML engineers, and software developers
    to build applications that integrate one or more H2O components participating
    in the ML life cycle into a single application. H2O Wave is thus a powerful integration
    story.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 低代码Wave SDK允许数据科学家、机器学习工程师和软件开发者构建将一个或多个参与机器学习生命周期的H2O组件集成到单个应用中的应用。因此，H2O Wave是一个强大的集成故事。
- en: 'Two Wave design facts need to be revisited, however, because they make this
    integration story even more powerful. First, Wave apps are deployed in containers
    and are thus isolated from other Wave apps. Second, developers can install and
    integrate publicly available or proprietary Python packages and APIs into the
    application. This means that H2O Wave apps can integrate both H2O and non-H2O
    components into a single application. This can effectively be restated as follows:
    H2O apps can be built as single panes of glass across your entire AI-related enterprise
    ecosystem. This is shown in the following diagram:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有两个Wave设计事实需要重新审视，因为它们使这个集成故事更加强大。首先，Wave应用在容器中部署，因此与其他Wave应用隔离。其次，开发者可以将公开可用的或专有Python包和API安装并集成到应用中。这意味着H2O
    Wave应用可以将H2O和非H2O组件集成到单个应用中。这可以重新表述如下：H2O应用可以作为整个AI相关企业生态系统的单一视窗构建。以下图表展示了这一点：
- en: '![Figure 14.11 – H2O Wave AI app as a layer across your enterprise ecosystem'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.11 – H2O Wave AI应用作为企业生态系统的一层]'
- en: '](img/B16721_14_011.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_14_011.jpg]'
- en: Figure 14.11 – H2O Wave AI app as a layer across your enterprise ecosystem
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.11 – H2O Wave AI应用作为企业生态系统的一层
- en: Data scientists, engineers, and software developers can thus build Wave apps
    that combine the end-to-end ML platform of H2O AI Cloud with AI-related and non-AI-related
    components of the enterprise ecosystem and its underlying cloud services. The
    diverse applications are hosted on H2O App Store with role-based access and thus
    made available to diverse enterprise stakeholder consumers. Let's break this down
    further by exploring the following diagram.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家、工程师和软件开发者可以构建Wave应用，将H2O AI Cloud的端到端机器学习平台与企业生态系统及其底层云服务中的AI相关和非AI相关组件结合起来。这些多样化的应用托管在H2O应用商店中，具有基于角色的访问权限，因此可供多样化的企业利益相关者消费者使用。让我们通过以下图表进一步分解这一点。
- en: '![Figure 14.12 – Reference H2O Wave AI app layering across your enterprise
    ecosystem'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.12 – 参考H2O Wave AI应用在企业生态系统中的分层]'
- en: '](img/B16721_14_012.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_14_012.jpg]'
- en: Figure 14.12 – Reference H2O Wave AI app layering across your enterprise ecosystem
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.12 – 参考H2O Wave AI应用在企业生态系统中的分层]'
- en: This is a reference H2O Wave AI app showing its full potential to serve as a
    UI integration layer across your entire AI-related ecosystem. The goal is to show
    the full set of capabilities in this regard, and for you to use your imagination
    to instantiate this generalized reference into specific applications that fit
    your specific AI needs.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个参考的H2O Wave AI应用，展示了其作为UI集成层在整个AI相关生态系统中的全部潜力。目标是展示这方面的全部功能，并激发您的想象力，将这个通用参考实例化到符合您特定AI需求的具体应用中。
- en: 'Let''s review these capabilities, as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照以下方式回顾这些功能：
- en: '**Low-code Python SDK**: Wave''s low-code Python SDK allows data scientists,
    ML engineers, and software developers to develop AI applications in a familiar
    Python style, focusing on populating data in widgets and templates and ignoring
    the complexity of web applications. The SDK can be extended with CSS style sheets
    to accomplish a specific look and feel if desired.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低代码Python SDK**: Wave的低代码Python SDK允许数据科学家、ML工程师和软件开发人员以熟悉的Python风格开发AI应用程序，专注于在控件和模板中填充数据，并忽略Web应用程序的复杂性。如果需要，SDK可以通过CSS样式表进行扩展，以实现特定的外观和感觉。'
- en: '**Data connectors**: The Wave SDK has over 140 connectors to diverse data sources
    and targets, making it easy to integrate Wave applications into your data ecosystem.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据连接器**: Wave SDK拥有超过140个连接器，可以连接到各种数据源和目标，这使得将Wave应用程序集成到您的数据生态系统中变得非常容易。'
- en: '**H2O AI Cloud APIs**: The Wave SDK has APIs for all components in the H2O
    AI Cloud platform: the four model-building engines and their provisioning tool,
    as well as the MLOps and Feature Store components. These integrations provide
    powerful ways to interact with all aspects of the ML life cycle from an application
    perspective. We have taken a quick glimpse of these possibilities in the scoring-consumption
    and model-retraining Wave applications discussed previously.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O AI Cloud API**: Wave SDK为H2O AI Cloud平台的所有组件提供了API：四个模型构建引擎及其配置工具，以及MLOps和特征存储组件。这些集成提供了强大的方式，从应用程序的角度与ML生命周期的各个方面进行交互。我们已经在之前讨论的评分消费和模型重训练Wave应用程序中快速浏览了这些可能性。'
- en: '**Installed Python packages**: The Wave SDK is extensible to any Python package
    you want to install. This allows you, for example, to extend the native Wave UI
    components with more specialized plotting or interactive visualization capabilities,
    or to use familiar packages to manipulate data.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已安装的Python包**: Wave SDK可以扩展到您想要安装的任何Python包。这允许您，例如，使用更专业的绘图或交互式可视化功能扩展本地的Wave
    UI组件，或者使用熟悉的包来操作数据。'
- en: '**Installed Python APIs**: You can also install Python libraries that serve
    as APIs to the rest of your enterprise ecosystem, whether it''s your own components,
    non-H2O vendor components, or applications and native cloud services. This is
    a very powerful way to orchestrate ML workflows driven by APIs connected to H2O
    AI Cloud components with the capabilities across the rest of your enterprise ecosystem.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已安装的Python API**: 您还可以安装作为您企业生态系统其他部分API的Python库，无论是您自己的组件、非H2O供应商组件，还是应用程序和本地云服务。这是一种非常强大的方式，可以通过连接到H2O
    AI Cloud组件的API来编排整个企业生态系统中驱动的ML工作流程。'
- en: The capabilities and integrations just outlined open up a near unlimited number
    of ways for Wave apps to accomplish enterprise-AI analytics and workflows. You
    can, for example, integrate your model deployment and monitoring on H2O MLOps
    to existing multistep governance-process workflows. You can build UI workflows
    where users search data catalogs for authorized data sources, select a data source,
    and then launch and access an H2O model-building environment with the data source
    loaded. These are only two examples to get your mind started. As shown in *Figure
    14.11*, there are many pieces you can tie together in your own specific and creative
    ways to extend ML beyond model building and scoring and to a larger context of
    workflows and multi-stakeholder business value.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如刚刚概述的能力和集成，为Wave应用程序提供了几乎无限的方式来实现企业-AI分析和工作流程。例如，您可以将模型部署和监控集成到现有的多步骤治理流程工作流程中。您可以构建UI工作流程，用户可以在数据目录中搜索授权的数据源，选择数据源，然后启动并访问带有数据源加载的H2O模型构建环境。这些只是两个例子，以激发您的思维。如图14.11所示，您可以根据自己的特定和创造性的方式将许多组件结合起来，以扩展ML的功能，使其超越模型构建和评分，并扩展到工作流程和多方商业价值的更大背景中。
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored how H2O-at-scale technology (H2O-3, H2O Sparkling
    Water, H2O Enterprise Steam, and the H2O MOJO) expands its capabilities by participating
    in the larger H2O AI Cloud end-to-end machine learning ML platform. We saw, for
    example, how H2O-3 and Sparkling Water can gain from initial rapid prototyping
    and automated feature discovery. Likewise, we saw how H2O-3 and Sparkling Water
    models can be deployed easily to the H2O MLOps platform where they gain value
    from its model-scoring, monitoring, and management capabilities. We also saw how
    H2O AI Feature Store can operationalize features for sharing, both in model building
    with H2O-3 or Sparkling Water and model scoring on H2O MLOps.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了H2O-at-scale技术（H2O-3、H2O Sparkling Water、H2O Enterprise Steam和H2O
    MOJO）如何通过参与更大的H2O AI Cloud端到端机器学习ML平台来扩展其功能。例如，我们看到了H2O-3和Sparkling Water如何从初始快速原型设计和自动化特征发现中获益。同样，我们也看到了H2O-3和Sparkling
    Water模型如何轻松部署到H2O MLOps平台，在那里它们从其模型评分、监控和管理能力中获得价值。我们还看到了H2O AI Feature Store如何将特征操作化为共享，无论是在H2O-3或Sparkling
    Water中构建模型，还是在H2O MLOps上进行模型评分。
- en: We started exploring the power of H2O's open source low-code Wave SDK, and how
    data scientists, ML engineers, and software developers can use it to easily create
    visualizations, analytics, and workflows across H2O components and thus the full
    ML life cycle. These applications are published to the App Store component of
    the H2O platform where they are consumed by enterprise stakeholders or external
    partners or customers of the enterprise. One example Wave app that we explored
    was an employee-churn application to consume, understand, and respond to predictions
    on how likely individuals were to leave a company. Another was a model-retraining
    application where data scientists manage and track automated model-retraining
    workloads by leveraging the Wave app's underlying SDK integration with H2O-3 and
    H2O MLOps.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始探索H2O开源低代码Wave SDK的力量，以及数据科学家、机器学习工程师和软件开发人员如何利用它轻松地在H2O组件和整个机器学习生命周期中创建可视化、分析和工作流程。这些应用发布到H2O平台的App
    Store组件中，在那里它们被企业利益相关者、外部合作伙伴或企业的客户所使用。我们探索的一个Wave应用示例是一个员工流失应用，用于消费、理解和响应关于个人离职可能性的预测。另一个是模型重新训练应用，数据科学家通过利用Wave应用底层与H2O-3和H2O
    MLOps的SDK集成来管理和跟踪自动化的模型重新训练工作负载。
- en: Finally, we introduced a reference Wave AI app to build applications that layer
    across H2O and non-H2O parts of the enterprise-AI ecosystem and thus form an enterprise-AI
    integration fabric.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍了一个参考Wave AI应用，用于构建跨越H2O和非H2O企业-AI生态系统的应用，从而形成一个企业-AI集成框架。
- en: We thus finish this book by taking ML at scale with H2O and putting it into
    the context of H2O's larger end to end machine learning ML platform called H2O
    AI Cloud. By marrying its established and proven H2O at scale technology with
    the new and rapidly innovating H2O AI Cloud platform, H2O.ai is continuing to
    prove itself as a bleeding-edge player in defining and creating new ML possibilities
    and value for the enterprise.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们通过使用H2O进行大规模机器学习并将其置于H2O更大的端到端机器学习ML平台H2O AI Cloud的背景下，完成了这本书。通过将成熟的、经过验证的H2O
    at scale技术与新的、快速创新的H2O AI Cloud平台相结合，H2O.ai正在继续证明自己在定义和创造新的机器学习可能性以及为企业创造价值方面是一个前沿的参与者。
