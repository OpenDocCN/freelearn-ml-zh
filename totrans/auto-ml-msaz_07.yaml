- en: '*Chapter 5*: Building an AutoML Classification Solution'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After building your AutoML regression solution with Python in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*,
    Building an AutoML Regression Solution*, you should be feeling confident in your
    coding abilities. In this chapter, you will build a classification solution. Unlike
    regression, **classification** is used to predict the category of the object of
    interest. For example, if you're trying to predict who is likely to become a homeowner
    in the next five years, classification is the right machine learning approach.
  prefs: []
  type: TYPE_NORMAL
- en: '**Binary classification** is when you are trying to predict two classes, such
    as homeowner or not, while **multiclass classification** involves trying to predict
    three or more classes, such as homeowner, renter, or lives with family. You can
    utilize both of these techniques with Azure AutoML, and this chapter will teach
    you how to train both kinds of models using different datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will begin by navigating directly to the Jupyter environment
    as you did in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*, Building
    an AutoML Regression Solution*. Then, you will load in the same Titanic data that
    you used to build a model in [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044)*,
    Training Your First AutoML Model*. Retraining an identical model would be boring,
    so you will enrich the dataset by adding a few derived columns.
  prefs: []
  type: TYPE_NORMAL
- en: Once you accomplish that, you will train, examine, and register your binary
    classification model. Then, you will train a multiclass classification model using
    the popular, publicly available Iris dataset that will predict what type of flower
    an individual plant is based on its dimensions. You will end this chapter by learning
    a few tips and tricks on how to fine-tune classification models. Pay close attention,
    as even seasoned data scientists fail to modify their classification models to
    align with the business problem at hand.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to build all types of classification
    models on your own with ease, regardless of your previous machine learning experience.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepping data for AutoML classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training an AutoML classification model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Registering your trained classification model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training an AutoML multiclass model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning your AutoML classification model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will be building models with Python code in Jupyter notebooks
    through **Azure Machine Learning** (**AML**) **studio**. Furthermore, you will
    be using datasets and Azure resources that you should have created in previous
    chapters. As such, the full list of requirements is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Access to the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web browser, preferably Google Chrome or Microsoft Edge Chromium
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Microsoft Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An **Azure Machine Learning** workspace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `titanic-compute-instance` compute instance created in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023)*,
    Getting Started with Azure Machine Learning*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `compute-cluster` compute cluster created in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023)*,
    Getting Started with Azure Machine Learning*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Titanic Training Data` dataset from [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044)*,
    Training your First AutoML Model*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An understanding of how to navigate to the Jupyter environment from an Azure
    compute instance as demonstrated in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*,
    Building an AutoML Regression Solution*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepping data for AutoML classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classification, or predicting the category of something based on its attributes,
    is one of the key techniques of machine learning. Just like regression, you first
    need to prep your data before training it with AutoML. In this section, you will
    first navigate to your Jupyter notebook, load in your data, and transform it for
    use with AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: Just as you loaded in your `Diabetes Sample` dataset via Jupyter notebooks for
    regression, you will do the same with the `Titanic Training Data` dataset. However,
    this time around you will do much more extensive data transformation before training
    your AutoML model. This is to build upon your learning; classification datasets
    do not necessarily require more transformation than their regression counterparts.
    Identical to the previous chapter, you will begin by opening up a Jupyter notebook
    from your compute instance.
  prefs: []
  type: TYPE_NORMAL
- en: Navigating to your Jupyter environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*, Building
    an AutoML Regression Solution*, you will begin by creating a new Jupyter notebook
    for creating your classification model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First, open AML studio by navigating to [http://ml.azure.com](http://ml.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you are in the studio, click **Compute** on the right-hand side of the
    studio under **Manage**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If your compute instance is currently paused, check the circular checkbox next
    to `titanic-compute-instance` and click the **Start** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, click `Diabetes_Regression_AutoML` notebook that you previously created.
    Each time you create a Jupyter notebook, it will persist on your AMLS workspace
    even if you or other users access Jupyter from a different compute instance. Feel
    free to create as many notebooks as you want in this space, naming them carefully
    so you can easily track different projects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **New** in the upper right-hand corner of your screen to access the drop-down
    menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Python 3.6 – AzureML** from the drop-down menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the new Jupyter notebook that appeared in the top-left corner of your
    screen, `Untitled.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rename `Untitled.ipynb` to `Titanic Classification_AutoML` by clicking `Titanic_Classification_AutoML`
    in the resulting textbox, and clicking **Rename** as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Renaming your Jupyter notebook ](img/B16595_5_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Renaming your Jupyter notebook
  prefs: []
  type: TYPE_NORMAL
- en: With your notebook created, you are now ready to load in your Titanic data.
  prefs: []
  type: TYPE_NORMAL
- en: Loading and transforming your data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All AutoML solutions use roughly the same boilerplate code. If you completed
    [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*, Building an AutoML Regression
    Solution*, begin copying over your code cell by cell. After doing so, simply follow
    the instructions step by step and alter your code when necessary. If you skipped
    directly to this chapter, you will have to code everything from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as before, you will load in your Python libraries and set your workspace,
    datastore, compute cluster, and dataset. You will then transform and register
    your enriched data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load in all of the libraries you will need to run all of your code. Refer to
    [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*, Building an AutoML Regression
    Solution*, for a detailed explanation of all of these packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load in `pandas` and `numpy`. These are popular Python packages that help you
    transform data. `pandas`, in particular, is necessary to view the data in your
    dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your compute cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your `datastore`. For this exercise, we will use the default datastore
    that comes with your AMLS workspace. If you want to use a different datastore,
    you can replace the name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your `dataset`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Step 6* is the first place where you should have altered your code. Each time
    you create a new classification or regression AutoML solution in Azure, use this
    template.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following is the code to view the first 10 rows of data. Make sure that
    it looks correct:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first 10 rows should appear as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Viewing your Titanic dataset ](img/B16595_5_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 5.3 – Viewing your Titanic dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Convert your dataset into a `Age` column. It's very likely that the age of the
    passengers will vary by other columns such as `Sex`. Instead of replacing these
    nulls with the mean value of the entire `Age` column, let's instead replace them
    with mean age by gender.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the mean age of women and men in your `Titanic` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code will show you that the mean age of women is 28 years old and the mean
    age of men is 31 years old. You will use these numbers in the next cell.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Replace null values in the `Age` column with the appropriate number for each
    gender using this conditional Python code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Another common transformation is to bin numerical data. **Binning** numerical
    data means creating multiple categorical columns from a single numeric column,
    for example, splitting an age column into age ranges instead. You should bin numerical
    data when you suspect that the range of numbers matters more than the absolute
    number.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For example, if you suspect whether a person is young or old matters to whether
    they survived the Titanic, but not their exact age, you should bin data into groups.
    AutoML will not automatically bin data for you, but some algorithms, such as decision
    trees, do not require binning to achieve a similar effect.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Bin the `Age` column into four different age groups: Under 15, 15-35, 35-60,
    and over 60:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can try different combinations of ages if you like.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now that you have binned the `Age` column, drop it. This will be your final
    DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reregister your altered data and give the dataset a new name, `Titanic Transformed`.
    This will save your transformed pandas DataFrame to your datastore, creating a
    new file on disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You may get a warning that `register_pandas_dataframe` is an experimental method
    as it is a new feature of the AML SDK. You are safe to ignore this warning.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you're new to Python, some of this code will perplex you, and that's okay.
    You will find great value in learning the `pandas` and `numpy` libraries, as they
    are two of the most popular packages for transforming data. Each time you learn
    a new `pandas` or `numpy` function, save an example to your personal code base
    for later use. Even if you never become a Python expert, however, you will still
    be able to use Azure AutoML to deliver a great model. Yet, Python experts will
    still be able to deliver the best models through careful, nuanced, and savvy data
    transformations.
  prefs: []
  type: TYPE_NORMAL
- en: You are now ready to train another model with your Titanic dataset. Between
    intelligently filling in null values and binning the `Age` column, you may expect
    to produce a superior model to that which you built in [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044)*,
    Training Your First AutoML Model*. Let's see if that's the case.
  prefs: []
  type: TYPE_NORMAL
- en: Training an AutoML classification model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Training an AutoML classification model is very similar to training an AutoML
    regression model, but there are a few key differences. In [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*,
    Building an AutoML Regression Solution*, you began by setting a name for your
    experiment. After that, you set your target column and subsequently set your AutoML
    configurations. Finally, you used AutoML to train a model, performed a data guardrails
    check, and produced results.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the steps in this section are nearly the same. However, pay close attention
    to the data guardrails check and results, as they are substantially different
    when training classification models:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set your `experiment` and give it a name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your `dataset` to your transformed `Titanic` data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your target column, `Survived`. Capitalization matters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable for your `task`: now, `task` is the type of AutoML model
    you are trying to train. For predicting categories, enter `classification`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can always turn a regression problem into a classification, and this is
    often an easier machine learning problem to solve. For example, for the diabetes
    problem, you can create a new column based on the `Y` column. Set a numeric threshold
    and assign a `1` to any patient who exceeds the threshold and a `0` to any patient
    below it. Then, try training a classification model with AutoML.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a variable for your primary metric: **Primary metric** is how your model
    will be scored. Use **accuracy**. This metric divides the number of cases that
    your model accurately predicted the class (survived or not) of by the total number
    of cases. The higher the score, the better your model. Other options for classification
    include **AUC weighted**, **average precision score weighted**, **norm macro recall**,
    and **precision score weighted**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable for `featurization` and set it to `auto`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can set `featurization` to `auto` or `off`. If you set `featurization` to
    `off`, you will have to drop high-cardinality features, impute null values, one-hot
    encode your data, and generate additional features yourself.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With classification, you will also have to balance your classes, meaning that
    you should resample your data to have a close-to-equal number of passengers who
    survived and died on the Titanic. Always set it to `auto` unless you are an expert
    data scientist and are comfortable doing everything yourself:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the number of classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the primary difference when training a classification model. By doing
    this programmatically with the following code, you will never make a mistake as
    you might when manually inputting the number.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: AutoML can handle a large number of classes, but you may run into trouble if
    you have overly imbalanced classes. When you have 20 times the number of your
    largest case as your smallest case, you may want to resample your data or bin
    your target column to reduce the discrepancy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Configure your AutoML run: here, you will pass in your task, primary metric,
    featurization settings, compute target, dataset, target column, and the number
    of classes. All of these you have previously created. You will also pass in how
    long the experiment will run, whether it will stop early if the model performance
    does not improve, the number of cross-validations, and whether your experiment
    will record model explanations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Additionally, you will pass in whether or not you want to use `5` and `20`
    splits:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train your model and watch the results in real time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Most of this code should feel familiar. Kick off your AutoML run, make yourself
    some coffee, come back, and watch your model run. You will then see a data guardrails
    check as seen in *Figure 5.4*. Notice how it has changed for classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, it will check your target column to make sure that classes are balanced.
    Then, it will impute missing values. Here, there are two missing values in the
    `Embarked` column. Since it''s a categorical column, it will be filled with the
    most common value. Lastly, like regression, it looks for categorical columns that
    have **high cardinality** or too many unique values given the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Data guardrails check for classification](img/B16595_5_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Data guardrails check for classification
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as before, after completing the data guardrails check, AutoML will start
    training models with different combinations of feature transformations, algorithms,
    and hyperparameters. Some of the algorithms used will be unique to classification
    such as naïve Bayes, linear SVC, and **logistic regression**, while others such
    as **random forest**, **light GBM**, and **XGBoost** are shared with regression.
    Your output should resemble something similar to *Figure 5.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – AutoML results for classification](img/B16595_5_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – AutoML results for classification
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two striking things about these results: the first model trained
    is the best model and the algorithm you trained in [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044)*,
    Training Your First AutoML Model*, is slightly better. When models are relatively
    simple for machine learning to find patterns, your first model may be your best
    model. Our attempts to outsmart AutoML by filling in nulls ourselves and binning
    the `Age` column failed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite our failure to produce a model, it''s a good exercise to show the inherent
    power of AutoML. Often, leaving the data as is will produce an excellent model.
    Other times, creating new features from your existing features will produce superior
    models. Try experimenting to see if you can get higher-performing results with
    the `Titanic` dataset. See *Figure 5.6* for the visualized results, and notice
    that you can select other metrics from the dropdown in the top-left corner:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – AutoML results visualized for classification ](img/B16595_5_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – AutoML results visualized for classification
  prefs: []
  type: TYPE_NORMAL
- en: Once you have thoroughly experimented with the `Titanic` data and have achieved
    the highest accuracy, you can move on to the next section to register your model.
    Registered models are necessary for later use in scoring new data through machine
    learning pipelines or real-time endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Registering your trained classification model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code to register classification models is identical to the code you used
    in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*, Building an AutoML Regression
    Solution*, to register your regression model. Always register new models, as you
    will use them to score new data using either real-time scoring endpoints or batch
    execution inference pipelines depending on your use case. This will be explained
    in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129)*, Implementing a Batch
    Scoring Solution*, and [*Chapter 11*](B16595_11_ePub.xhtml#_idTextAnchor172)*,
    Implementing a Real-Time Scoring Solution*. Likewise, when registering your models,
    always add tags and descriptions for easier tracking:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, give your model a name, a description, and some tags:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Tags let you easily search for models, so think carefully as you implement them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, register your model to your AMLS workspace, passing in your model name,
    tags, and description. Use the `AutoML_run` instance you trained in the previous
    section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Try registering a different model based on `AutoML_run` using this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`ID.experiment_name = ''Titanic-Transformed-Classification-AutoML''`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`exp = Experiment(workspace=ws, name=experiment_name)`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`AutoML_run = AutoMLRun(experiment = exp, run_id = ''your_run_id'')`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have registered your model and it is ready for use. You have created a classification
    model that can be used to predict who survived and who did not on the ill-fated
    Titanic voyage. It fell a little short of the classification model you built in
    [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044)*, Training Your First AutoML
    Model*, but in doing so, you learned a lot. With your lessons in mind, we can
    move on to tips and tricks that will improve your classification models as you
    train more in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Training an AutoML multiclass model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multiclass classification involves predicting three or more classes instead
    of the standard binary classification. Using custom machine learning, training
    multiclass models is often a messy, complicated affair where you have to carefully
    consider the number of classes you are trying to predict, how unbalanced those
    classes are relative to each other, whether you should combine classes together,
    and how you should present your results. Luckily, AutoML takes care of all these
    considerations for you and makes training a multiclass model as simple as training
    a binary classification model.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you load in data using the publicly available Iris dataset.
    You will then set your AutoML classifications for multiclass classification, train
    and register a model, and examine your results. You will notice that much of the
    code is identical to the last section. By understanding the differences between
    binary and multiclass classification in AutoML, you will gain the confidence to
    tackle any type of classification problem irrespective of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Download the `Iris.csv` file from the GitHub repository, [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load `Iris.csv` into Azure and create a dataset called `Iris Training` following
    the same steps you took in [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044)*,
    Training Your First AutoML Model*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Load in all of the libraries you will need to run all of your code. Notice
    these libraries are identical to the ones you used for binary classification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load in `pandas` and `numpy`. No matter the data you''re working with, you
    will always find these packages useful:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your compute cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your `datastore`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your `dataset`. Notice that this is the first piece of code that differs
    from binary classification, as you''re using an entirely different dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'View the first 10 rows of your data using the following code. Make sure that
    it looks correct. With Iris data, you are trying to predict the `species` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first 10 rows should look similar to *Figure 5.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Iris data](img/B16595_5_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 5.7 – Iris data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the pandas `unique` function on the `species` column to see how many classes
    you need to predict. You should see three classes, *Iris-setosa*, *Iris-versicolor*,
    and *Iris-virginica*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your experiment and give it a name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Try to be descriptive when naming your experiments to easily track them, for
    example, by indicating explicitly that this training run is for multiclass classification.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your target column to `species`. Capitalization matters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Unlike most custom machine learning code, you do not have to convert the three
    different classes to integers. AutoML handles all of this on the backend.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a variable for your task: the task is the type of AutoML model you are
    trying to train. For predicting categories, enter `classification`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`task` should be set to `classification` for both binary and multiclass classification
    problems.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a variable for your primary metric. Use `accuracy`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: All metrics are the same for binary and multiclass classification problems,
    except some are calculated slightly differently by averaging the metric for each
    class instead of simply comparing true positives to true negatives. Accuracy,
    however, is calculated the same regardless of whether the problem is binary or
    multiclass.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a variable for `featurization` and set it to `auto`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can set `featurization` to `auto` or `off`. For multiclass problems, it
    is especially important to set it to `auto` so classes are properly balanced.
    Not doing so will impact model performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the number of classes to `3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: While you can do this programmatically, you can also set it to a number in cases
    where you already know and have confirmed the number of classes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When training multiclass classification problems, sometimes you should hardcode
    in the number of classes. This ensures that your training run will fail if corrupted
    data enters your system and gives you an extra, unexpected class.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Configure your AutoML run. Nothing is different between multiclass and binary
    classification problems when it comes to configuring the run itself. One caveat
    is that multiclass classification problems often benefit from slightly higher
    cross validation settings. This helps ensures that the classes in each training
    split are more uniform. Set it to `10`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train your model and watch the results in real time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once your model is done training, register your model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As your AutoML model is running, it will perform the usual data guardrails check
    followed by. It is the same for binary and multiclass classification, checking
    for class balancing, missing features, and high cardinality. Your Iris data should
    pass all of these checks easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the data guardrails check is complete, AutoML will start training models
    as usual. Compare the models trained on multiclass Iris data versus binary class
    Titanic data. You should notice that most models are the same. Your output should
    resemble *Figure 5.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – AutoML results for multiclass classification ](img/B16595_5_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – AutoML results for multiclass classification
  prefs: []
  type: TYPE_NORMAL
- en: 'There are excellent results. AutoML performs exceptionally well on the Iris
    dataset. There''s also an easy way to graph your performance directly from your
    Jupyter notebook. Scroll down slightly past your model output until you see blue
    links to each of your models as seen in *Figure 5.9*. Click on your highest-performing
    model. For the example, it was the voting ensemble model, but it may be something
    different in your case:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Model links ](img/B16595_5_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Model links
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on this link will expose a large number of visualizations for your
    AutoML classification experiment. In particular, there''s a **precision-recall
    curve**, an **ROC curve**, a **lift curve**, a **gain curve**, a **calibration
    curve**, and a **confusion matrix**. Business users most easily understand the
    confusion matrix, which shows you the number of classes that were accurately classified
    along with the number that were misclassified. As shown in *Figure 5.10*, AutoML
    only misclassified two data points out of 150 total. In both cases, the model
    incorrectly classified an Iris-versicolor as an Iris-virginica:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10 – Confusion matrix for the Iris classification model ](img/B16595_5_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Confusion matrix for the Iris classification model
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have trained both a binary and multiclass classification model
    with AutoML, you can apply these techniques to your own data and business problems.
    If you were training custom machine learning models, you would have to memorize
    many little differences between binary and multiclass classification, but Azure
    AutoML handles all of those complexities for you. You don't even have to change
    your categorical column to integers.
  prefs: []
  type: TYPE_NORMAL
- en: As such, you should feel comfortable using AutoML for any classification problem
    you have. The final section gives you tips and tricks for achieving better model
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning your AutoML classification model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will first review tips and tricks for improving your AutoML
    classification models and then review the algorithms used by AutoML for both binary
    and multiclass classification.
  prefs: []
  type: TYPE_NORMAL
- en: Improving AutoML classification models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Keeping in mind the tips and tricks from [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*,
    Building an AutoML Regression Solution*, here are new ones that are specific to
    classification:'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike regression problems, nearly all classification problems in the real world
    require you to weigh your target column. The reason is that, for most business
    problems, one class is nearly always more important than the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, imagine you are running a business and you are trying to predict
    which customers will stop doing business with you and leave you for a competitor.
    This is a common problem called customer churn or customer turnover. If you misidentify
    a customer as being likely to churn, all you waste is an unnecessary phone call
    or email. However, if your algorithm misses a customer who will churn, you lose
    that customer and their money.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you use the normal accuracy metric in AutoML, that is a poor metric for this
    problem. This is because it's much better to misidentify someone as *likely to
    switch* than it is to misidentify someone as *likely to stay*. The solution to
    this is to use the `weight_column_name` feature in AutoML. This allows you to
    create a column that weights hits and misses differently.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For example, if your algorithm misses a customer who is likely to churn, you
    can penalize that miss 100 times more than if the algorithm says a customer will
    churn when they will not by assigning a weight of 100 to churned customers and
    a weight of 1 to customers who did not churn. This will train a model that excels
    at not missing customers who will turnover, although it will have many false positives
    as well.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Become familiar with all of the different AutoML configuration options for
    classification. You can find them at this link: [https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your target column has a ratio of more than 20 to 1, it is a good idea to
    either collect more data from the smaller class or resample your data to achieve
    the 20 to 1 ratio.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Research the five different primary metrics to understand which metrics fit
    your problem best. Classification requires a much more nuanced understanding of
    the business problem to make a wise metric selection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml)
    to understand what a good classification model looks like. Confusion matrices
    are particularly valuable in determining whether your model is better at predicting
    one class over another. Depending on your business use case, this may or may not
    be a problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go to **Experiments** under **Assets** in AML studio, click your experiment
    name, select **Run ID**, click the **Models** tab, select the highest-performing
    algorithm, and click the **Metrics** tab. This will provide you with all of the
    different metrics and charts necessary to evaluate your algorithm.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explore using the `weight_column_name` configuration option to weigh your data.
    It is important you understand how this works. If some observations are more important
    to get right than others, you should always assign a higher weight to those observations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is particularly important with classification models because, as mentioned
    before, some observations are almost always more important than others. Try assigning
    `0.1` to survivors and `1` to victims using the `Titanic` data and build a model.
    Then, try the opposite.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Overfitting**, where you produce a very good model that doesn''t generalize
    to new datapoints, is as much a problem in classification as it is in regression.
    If this happens to you, try adding more historical data or removing columns from
    your dataset. If your target column has more than 2 classes, try binning it to
    create a simple model less prone to overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be on the lookout for model bias with classification problems. **Bias** can
    occur when your model sacrifices performance in one class for another class. The
    worst bias occurs when the model only predicts a single class, for example, always
    predicting that a Titanic passenger perished. These models can occasionally be
    highly accurate due to class imbalance. With the Titanic data, such a model would
    be 61.6% accurate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When dealing with large datasets, the size of your compute instance doesn't
    matter, but the size of your compute cluster matters a lot. This is because your
    compute instance is only for writing and submitting code, while the AutoML training
    job runs remotely on the compute cluster. It's important that you train your AutoML
    with appropriately sized **virtual machines** (**VMs**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the VMs on your compute cluster should be determined by the size
    of your dataset used for training. Roughly speaking, the RAM of your VM should
    be 20 times as large as the size of the data you are training in uncompressed
    CSV format, or twice as large as the size of the data you are training while in
    a pandas DataFrame. This is because CSV files grow up to 10 times in size when
    converted into a DataFrame. This guarantees a smooth run.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, if your base CSV file is 5 GB in size, then the RAM of each VM
    on your compute cluster should be at least 100 GB. In contrast, if your data is
    5 GB in size after being converted into a pandas DataFrame, then you only require
    VMs with 10 GB of RAM.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`AutoMLConfig` has many options that you should familiarize yourself with.
    One such option is `max_cores_per_iteration`. Set this to `-1` so that each model
    training run fully utilizes all the cores on each VM, giving you a little more
    processing power.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can train AutoML models in parallel through another `AutoMLConfig` option
    called `max_concurrent_iterations`. This determines how many models AutoML trains
    in parallel. Set this to the maximum number of nodes on your compute cluster.
    If you have 8 nodes on your compute cluster and set `max_concurrent_iterations`
    to `8`, then AutoML will train 8 models at a time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a few of the many ways you can fine-tune a classification model
    with AutoML. You can learn more techniques by reading scientific articles on machine
    learning, blog posts, and how-to guides. Of course, nothing beats experience.
  prefs: []
  type: TYPE_NORMAL
- en: Try downloading as many open source classification datasets as you can find,
    load them into Azure, and use them to train and fine-tune AutoML models. With
    experience comes wisdom, and with wisdom comes the ability to solve even the toughest
    business problems with automated machine learning techniques. Learning the details
    about AutoML's classification algorithms is also important for you to develop
    your data science knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding AutoML classification algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many of the algorithms used by AutoML for classification are identical to the
    ones used by AutoML for regression. Like regression, certain algorithms perform
    better in certain situations. Unlike regression, AutoML uses a greater variety
    of algorithms for classification including neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: The **tree**, **gradient boosting**, and **nearest neighbor** algorithms used
    by AutoML for classification are identical to the ones used for regression, and
    you can review them in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056)*,
    Building an AutoML Regression Solution*. The only difference is that the classification
    versions predict probabilities instead of values. **Stochastic gradient descent**
    (**SGD**) is also used by AutoML for classification. Unique to classification
    are logistic regression, naïve Bayes, averaged perceptron classifier, and three
    different algorithms that use **support vector machines** (**SVM**).
  prefs: []
  type: TYPE_NORMAL
- en: '**Logistic regression** uses a logistic function, an s-shaped sigmoid curve,
    to model the probability that your data belongs to a certain class. Despite its
    name, it is unrelated to regression. Like elastic net for regression, logistic
    regression uses **L1** (**lasso**) and **L2** (**ridge**) regularization to create
    simpler models by adjusting the coefficients of your input variables. Logistic
    regression is simple and easy to use, but it doesn''t do well with small datasets
    or when your data has nonlinear relationships.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Naïve Bayes** is another simple classification algorithm. It uses Bayes''
    theorem to calculate the probability of a class given each input feature in a
    row of your data. It then weighs each input feature equally when deciding the
    class. It''s naïve in that it assumes that input features are independent of each
    other. Naïve Bayes performs well even with small data, but its chief assumption
    of independence is almost always violated in real life.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Averaged perceptron classifier** is a simple type of **neural network** that
    uses a system of weights and linear functions to make its predictions. Like logistic
    regression, it''s best suited to datasets with linear relationships between your
    input variable and target column. It''s only used for binary classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support vector algorithms** classify data by drawing dividing among hyperplanes
    of data. Imagine visualizing your data in an n-dimensional space where n is the
    number of your input columns. SVM works by finding the lines that divide your
    data best. They work for both linear and non-linear data, even for high-dimensional
    data. AutoML uses three of these algorithms: **support vector classification**
    (**SVC**), linear SVC, and linear SVM classifier.'
  prefs: []
  type: TYPE_NORMAL
- en: SVC is a standard implementation of support vector machines that works for both
    multiclass and binary classification problems. Linear SVC is an implementation
    that divides data linearly as opposed to SVC, which can divide data using nonlinear
    kernel functions. Linear SVM classifier, on the other hand, is similar to linear
    SVC but can only be used for binary classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'A summary of the 14 algorithms is provided in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11 – AutoML classification algorithms ](img/B16595_5_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – AutoML classification algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Like regression, AutoML performs **model ensembling** at the end of each AutoML
    training run. **Voting ensembles** take the weighted average of predicted class
    probabilities and use that to predict the class of an individual row of input
    data. **Stack ensembles**, in contrast, train a logistic regression model using
    the output of other models. Usually, one of these two ensemble models will be
    your best model.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on these models, please consult the AutoML documentation
    found at [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have added to your repertoire by successfully training a classification
    model using the AML Python SDK. You have loaded in data, heavily transformed it
    using pandas and Numpy, and built a toy AutoML model. You then registered that
    model to your AMLS workspace.
  prefs: []
  type: TYPE_NORMAL
- en: You can now start building classification models with your own data. You can
    easily solve both binary and multiclass classification problems, and you can present
    results to the business in a way they understand with confusion matrices. Many
    of the most common business problems, such as customer churn, are classification
    problems, and with the knowledge you learned in this chapter, you can solve those
    problems and earn trust and respect in your organization.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter, [*Chapter 6*](B16595_06_ePub.xhtml#_idTextAnchor081)*, Building
    an AutoML Forecasting Solution*, will be vastly different from the previous two
    chapters. Forecasting problems have many more settings to use and understand compared
    to classification and regression problems, and they always require you to have
    a deeper understanding of your dataset. Novice data scientists also make many
    mistakes when training such models, and AutoML will enable you to avoid all of
    them.
  prefs: []
  type: TYPE_NORMAL
