- en: '*Chapter 2*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*'
- en: Advanced Clustering Methods
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级聚类方法
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够：
- en: Perform k-modes clustering
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行 k-modes 聚类
- en: Implement DBSCAN clustering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现 DBSCAN 聚类
- en: Perform hierarchical clustering and record clusters in a dendrogram
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行层次聚类并在树状图中记录聚类
- en: Perform divisive and agglomerative clustering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行分裂和聚合聚类
- en: In this chapter, we will have a look at some advanced clustering methods and
    how to record clusters in a dendrogram.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨一些高级聚类方法以及如何在树状图中记录聚类。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: 'So far, we''ve learned about some of the most basic algorithms of unsupervised
    learning: k-means clustering and k-medoids clustering. These are not only important
    for practical use, but are also important for understanding clustering itself.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了无监督学习的一些最基本算法：k-means 聚类和 k-medoids 聚类。这些算法不仅对实际应用很重要，而且对于理解聚类本身也很重要。
- en: In this chapter, we're going to study some other advanced clustering algorithms.
    We aren't calling them advanced because they are difficult to understand, but
    because, before using them, a data scientist should have insights into why he
    or she is using these algorithms instead of the general clustering algorithms
    we studied in the last chapter. k-means is a general-purpose clustering algorithm
    that is sufficient for most cases, but in some special cases, depending on the
    type of data, advanced clustering algorithms can produce better results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究一些其他高级聚类算法。我们不称它们为高级是因为它们难以理解，而是因为在使用它们之前，数据科学家应该了解为什么他们选择这些算法而不是我们在上一章中研究的一般聚类算法。k-means
    是一种通用聚类算法，对于大多数情况都足够用，但在某些特殊情况下，根据数据类型，高级聚类算法可以产生更好的结果。
- en: Introduction to k-modes Clustering
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k-modes 聚类的简介
- en: All the types of clustering that we have studied so far are based on a distance
    metric. But what if we get a dataset in which it's not possible to measure the
    distance between variables in a traditional sense, as in the case of categorical
    variables? In such cases, we use k-modes clustering.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止研究过的所有聚类类型都是基于距离度量的。但如果我们得到一个数据集，其中无法以传统方式测量变量之间的距离，例如分类变量的情况，怎么办？在这种情况下，我们使用
    k-modes 聚类。
- en: k-modes clustering is an extension of k-means clustering, dealing with modes
    instead of means. One of the major applications of k-modes clustering is analyzing
    categorical data such as survey results.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: k-modes 聚类是 k-means 聚类的扩展，处理的是众数而不是均值。k-modes 聚类的主要应用之一是分析调查结果等分类数据。
- en: Steps for k-Modes Clustering
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: k-Modes 聚类的步骤
- en: 'In statistics, mode is defined as the most frequently occurring value. So,
    for k-modes clustering, we''re going to calculate the mode of categorical values
    to choose centers. So, the steps to perform k-modes clustering are as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，众数定义为最频繁出现的值。因此，对于 k-modes 聚类，我们将计算分类值的众数来选择中心。因此，执行 k-modes 聚类的步骤如下：
- en: Choose any k number of random points as cluster centers.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择任意 k 个随机点作为聚类中心。
- en: Find the Hamming distance (discussed in *Chapter 1*, *Introduction to Clustering
    Methods*) of each point from the center.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个点到中心的汉明距离（在第 1 章，聚类方法简介中讨论）。
- en: Assign each point to a cluster whose center it is closest to according to the
    Hamming distance.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据汉明距离将每个点分配到最近的中心所在的聚类。
- en: Choose new cluster centers in each cluster by finding the mode of all data points
    in that cluster.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过找到该聚类中所有数据点的众数来在每个聚类中选择新的聚类中心。
- en: Repeat this from *Step 2* until the cluster centers stop changing.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 *步骤 2* 重复此操作，直到聚类中心不再变化。
- en: You might have noticed that these steps are very similar to those for k-means
    clustering. Only the type of distance metric is changed here. So, if you understand
    k-means clustering, it will be very easy for you to understand k-modes clustering
    as well.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，这些步骤与 k-means 聚类的步骤非常相似。这里只是改变了距离度量的类型。所以，如果您理解了 k-means 聚类，那么理解 k-modes
    聚类也会很容易。
- en: 'Exercise 10: Implementing k-modes Clustering'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 10：实现 k-modes 聚类
- en: Note
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For all the exercises and activities where we are importing external CSV's or
    images, go to **RStudio**-> **Session**-> **Set Working Directory**-> **To Source
    File Location**. You can see in the console that the path is set automatically.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有需要导入外部 CSV 或图像的练习和活动，请转到 **RStudio**-> **会话**-> **设置工作目录**-> **到源文件位置**。您可以在控制台中看到路径已自动设置。
- en: 'The data for this exercise can be downloaded from here: [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv).
    This is a categorical dataset that includes nine variables, some categorical and
    some nominal, describing different breast cancer cases. After saving this data
    in a file called `breast_cancer.csv`, we''ll do the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此练习的数据可以从这里下载：[https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv)。这是一个包含九个变量的分类数据集，其中一些是分类的，一些是名义的，描述了不同的乳腺癌病例。在将数据保存到名为`breast_cancer.csv`的文件中后，我们将执行以下操作：
- en: Note
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This dataset is taken from the UCI Machine Learning Repository. You can find
    the dataset at [https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data).
    This breast cancer domain was obtained from the University Medical Centre, Institute
    of Oncology, Ljubljana, Yugoslavia. Thanks go to M. Zwitter and M. Soklic for
    providing the data. We have downloaded the file and saved it at [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集来自UCI机器学习仓库。您可以在[https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data)找到数据集。这个乳腺癌领域的数据来自南斯拉夫卢布尔雅那大学医学院，肿瘤研究所。感谢M.
    Zwitter和M. Soklic提供数据。我们已经下载了文件，并将其保存在[https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Exercise10/breast_cancer.csv)。
- en: 'Read the dataset and store it in a variable:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取数据集并将其存储到一个变量中：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Store all of the columns from the second column to the end in a new variable:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将从第二列到最后一列的所有列存储到一个新变量中：
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'View the first six rows of the `k_bc_data` variable:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看变量`k_bc_data`的前六行：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output contains the six rows with values for different attributes describing
    the patient, their symptoms, and their treatment:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出包含六个行，其中包含描述患者、症状和治疗的各个属性值：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Import the `klaR` library, which has the `kmodes` function. `klaR` is an R
    library that is used for classification and visualization:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`klaR`库，它包含`kmodes`函数。`klaR`是一个R库，用于分类和可视化：
- en: '[PRE4]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Predict and store the final cluster centers in a variable. In this step, we
    enter the dataset and the number of clusters (that is, `k` and the maximum amount
    of iterations to find the number of clusters):'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测并存储最终的集群中心到一个变量中。在这一步，我们输入数据集和集群数量（即`k`和找到集群数量的最大迭代次数）：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'View the cluster centers:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看集群中心：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.1: Screenshot of the cluster centers](img/C12628_02_01.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1：集群中心的截图](img/C12628_02_01.jpg)'
- en: 'Figure 2.1: Screenshot of the cluster centers'
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.1：集群中心的截图
- en: 'The clustering algorithm has grouped all of the breast cancer cases into two
    clusters, with each cluster containing cases that are similar to each other. In
    the output, there are two main components: the cluster modes and the clustering
    vector. The cluster modes section is telling us the modes or coordinates of the
    centers for cluster 1 and cluster 2\. Below that, the clustering vector contains
    the cluster number of each data point in the index sequence.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类算法将所有乳腺癌病例分为两个集群，每个集群包含彼此相似的病例。在输出中，有两个主要部分：集群模式和聚类向量。集群模式部分告诉我们集群1和集群2的中心或坐标。下面，聚类向量包含索引序列中每个数据点的集群编号。
- en: Note
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You could get different results every time you run the algorithm because of
    the random starting positions of the centers.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于中心的随机起始位置，每次运行算法都可能得到不同的结果。
- en: As it is a multi-dimensional categorical dataset, there's no easy way to visualize
    the results other than printing the data to the R console.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个多维分类数据集，除了将数据打印到R控制台之外，没有简单的方法来可视化结果。
- en: 'Activity 5: Implementing k-modes Clustering on the Mushroom Dataset'
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动5：在蘑菇数据集上实现k-modes聚类
- en: Note
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This dataset is taken from the UCI Machine Learning Repository. You can find
    the dataset at [https://archive.ics.uci.edu/ml/datasets/Mushroom](https://archive.ics.uci.edu/ml/datasets/Mushroom).
    We have downloaded the file, cleaned the data, and saved it at [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集来自 UCI 机器学习仓库。您可以在 [https://archive.ics.uci.edu/ml/datasets/Mushroom](https://archive.ics.uci.edu/ml/datasets/Mushroom)
    找到数据集。我们已经下载了文件，清理了数据，并将其保存在 [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05)。
- en: 'In this activity, we will perform k-modes clustering on the mushroom dataset.
    This dataset lists the attributes of 23 different species of mushrooms. Each species
    is classified as being either edible (e) or poisonous (p). We will see how well
    unsupervised learning can classify poisonous and edible mushrooms by grouping
    the data into two clusters. These steps will help you complete the activity:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将对蘑菇数据集执行 k-modes 聚类。此数据集列出了 23 种不同蘑菇的属性。每种蘑菇被分类为可食用（e）或有毒（p）。我们将看到无监督学习如何通过将数据分组到两个簇中来对有毒和可食用蘑菇进行分类。以下步骤将帮助您完成活动：
- en: Download `mushrooms.csv` from [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05).
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity05)
    下载 `mushrooms.csv`。
- en: Read the `mushroom.csv` file into a variable.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `mushrooms.csv` 文件读入一个变量中。
- en: Import the `klaR` library.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `klaR` 库。
- en: Calculate the clusters according to k-modes clustering.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据k-modes聚类计算簇。
- en: Check the results of clustering by forming a matrix of data labels versus the
    cluster assigned.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过形成数据标签与分配的簇之间的矩阵来检查聚类的结果。
- en: Note
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 212.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第 212 页找到。
- en: 'The output will be a table of true labels and cluster labels, as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是一个真实标签和簇标签的表格，如下所示：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Introduction to Density-Based Clustering (DBSCAN)
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 密度聚类（DBSCAN）简介
- en: '**Density-based clustering** or DBSCAN is one of the most intuitive forms of
    clustering. It is very easy to find naturally occurring clusters and outliers
    in data with this type of clustering. Also, it doesn''t require you to define
    a number of clusters. For example, consider the following figure:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于密度的聚类**或DBSCAN是聚类中最直观的形式之一。使用这种类型的聚类很容易找到数据中的自然簇和异常值。此外，它不需要你定义簇的数量。例如，考虑以下图示：'
- en: '![Figure 2.2: A sample scatter plot](img/C12628_02_02.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2：一个示例散点图](img/C12628_02_02.jpg)'
- en: 'Figure 2.2: A sample scatter plot'
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.2：一个示例散点图
- en: 'There are four natural clusters in this dataset and a few outliers. So, DBSCAN
    will segregate the clusters and outliers, as depicted in the following figure,
    without you having to tell it how many clusters to identify in the dataset:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集中有四个自然簇和一些异常值。因此，DBSCAN将分离簇和异常值，如图所示，而无需您指定数据集中要识别的簇的数量：
- en: '![Figure 2.3: Clusters and outliers classified by DBSCAN](img/C12628_02_03.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3：由 DBSCAN 分类出的簇和异常值](img/C12628_02_03.jpg)'
- en: 'Figure 2.3: Clusters and outliers classified by DBSCAN'
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.3：由 DBSCAN 分类出的簇和异常值
- en: So, DBSCAN can find regions of high density separated by regions of low density
    in a scatter plot.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，DBSCAN可以在散点图中找到由低密度区域分隔的高密度区域。
- en: Steps for DBSCAN
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DBSCAN 步骤
- en: 'As mentioned before, DBSCAN doesn''t require you to choose a number of clusters,
    but you have to choose the other two parameters to perform DBSCAN. The first parameter
    is commonly denoted by ε (epsilon), which denotes the maximum distance between
    two points in the same cluster. Another parameter is the minimum number of points
    in a cluster, which is usually denoted by `minPts`. Now we''ll look at the DBSCAN
    clustering algorithm step by step:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，DBSCAN 不需要您选择簇的数量，但您必须选择其他两个参数来执行 DBSCAN。第一个参数通常用 ε（epsilon）表示，表示同一簇中两点之间的最大距离。另一个参数是簇中的最小点数，通常用
    `minPts` 表示。现在我们将逐步查看 DBSCAN 聚类算法：
- en: Select any point, `R`, in the dataset.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据集中选择任何点，`R`。
- en: Find all the points within distance epsilon from point `R`.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在距离点 `R` 的 epsilon 范围内找到所有点。
- en: If the total number of points within distance epsilon from point `R` is greater
    than `minPts`, then it is a cluster and `R` is the core point.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果从点`R`出发，距离epsilon内的点的总数大于`minPts`，那么它是一个簇，`R`是核心点。
- en: If the total number of points within distance epsilon from point p is less than
    `minPts`, all the points within distance epsilon will be classified as noise.
    We then start the process again from step 2 after selecting a new point, `R`,
    that has neither been classified as noise nor as part of the cluster.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果从点p出发，距离epsilon内的点的总数小于`minPts`，那么距离epsilon内的所有点将被归类为噪声。然后，我们选择一个新的点，`R`，它既没有被归类为噪声，也没有被归类为簇的一部分，从步骤2重新开始这个过程。
- en: Repeat the process for other points in the cluster to find points within distance
    epsilon that are not already in the cluster. Those new points will also be classified
    in the same cluster.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对簇中的其他点重复此过程，以找到距离epsilon内不在簇中的点。这些新点也将被归类到同一个簇中。
- en: Once these steps have been performed for all points in the cluster, repeat the
    same process by selecting a new random point, `R`, that has neither been classified
    in a cluster nor as noise.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当对簇中的所有点执行了这些步骤后，通过选择一个新的随机点，`R`，它既没有被归类到簇中，也没有被归类为噪声，重复相同的过程。
- en: 'So, to illustrate of the preceding algorithm, let''s take an example with epsilon
    as **x** and the minimum number of points in a cluster as 4\. Look at the following
    figure:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了说明前面的算法，让我们以epsilon为**x**和簇中的最小点数为4为例。看看下面的图：
- en: '![Figure 2.4:  Only 2 points lie in the x distance of point R1](img/C12628_02_04.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4：只有2个点位于点R1的x距离内](img/C12628_02_04.jpg)'
- en: 'Figure 2.4: Only 2 points lie within x distance of point R1'
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.4：只有2个点位于点R1的x距离内
- en: 'Only three points lie within **x** distance of point **R1** and our threshold
    for the minimum number of points within **x** radius is four. So, these four points
    will be classified as outliers or noise. But if there were one more point, **R5**,
    somewhere between **R1** and **R4**, all of these four points would belong to
    a cluster as in the following figure:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 只有三个点位于点**R1**的**x**距离范围内，而我们对于**x**半径内最小点数的阈值是四个。因此，这四个点将被归类为异常值或噪声。但如果再有一个点，**R5**，位于**R1**和**R4**之间，所有这四个点将属于一个簇，如下面的图所示：
- en: '![Figure 2.5: All these four points belong to a cluster](img/C12628_02_05.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5：这四个点都属于一个簇](img/C12628_02_05.jpg)'
- en: 'Figure 2.5: All of these four points belong to a cluster'
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.5：这四个点都属于一个簇
- en: 'In the preceding figure, points **R1** and **R5** are core points, as they
    have four points each within **x** distance from them. And points **R4**, **R2**,
    and **R3** are not core points, as illustrated in the following figure:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，点**R1**和**R5**是核心点，因为它们各自有四个点在**x**距离内。而点**R4**、**R2**和**R3**不是核心点，如下面的图所示：
- en: '![Figure 2.6: Core versus non-core points](img/C12628_02_06.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6：核心点与非核心点](img/C12628_02_06.jpg)'
- en: 'Figure 2.6: Core versus non-core points'
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.6：核心点与非核心点
- en: 'Any point outside of any of these circles would be classified as a noise point
    like, **R6** in the following figure:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 任何位于这些圆圈之外的点将被归类为噪声点，如下面的图中的**R6**所示：
- en: '![Figure 2.7: Noise point R6](img/C12628_02_07.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7：噪声点R6](img/C12628_02_07.jpg)'
- en: 'Figure 2.7: Noise point R6'
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.7：噪声点R6
- en: 'Exercise 11: Implementing DBSCAN'
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习11：实现DBSCAN
- en: 'In this exercise, we will have a look at the implementation of DBSCAN using
    the Iris dataset. To perform DBSCAN, we will execute the following steps:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将查看使用Iris数据集实现DBSCAN的过程。为了执行DBSCAN，我们将执行以下步骤：
- en: 'Store the first two columns of the Iris dataset in `iris_data`:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Iris数据集的前两列存储在`iris_data`中：
- en: '[PRE8]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Import the `dbscan` library, which contains the implementation of various DBSCAN
    algorithms:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`dbscan`库，它包含各种DBSCAN算法的实现：
- en: '[PRE9]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Calculate and store clusters in the `clus` variable. In this step, you also
    have to choose the values of epsilon and `minPts`:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算并存储簇在`clus`变量中。在这个步骤中，你还需要选择epsilon和`minPts`的值：
- en: '[PRE10]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can experiment with the values of epsilon. To get the desired output, we
    have set the value as 0.3.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以尝试调整epsilon的值。为了得到期望的输出，我们将其设置为0.3。
- en: 'Import the `factoextra` library for visualizing clusters:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`factoextra`库以可视化簇：
- en: '[PRE11]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Plot the cluster centers. You need to enter the variable in which you stored
    the results of DBSCAN as the first parameter of the `plot` function. As the second
    parameter, you need to enter a dataset. In our case, it''s `iris_data`. The `geom`
    variable in the function is used to define the geometry of the graph. We will
    only use `point`. Now, `ggtheme` is used to select a theme for the plot. `palette`
    is used to select the geometry of the points. The `ellipse` value is set to false
    so that the function does not draw an outline of the clusters.:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制簇中心。您需要将存储DBSCAN结果的变量作为`plot`函数的第一个参数输入。作为第二个参数，您需要输入一个数据集。在我们的例子中，它是`iris_data`。函数中的`geom`变量用于定义图形的几何形状。我们只会使用`point`。现在，`ggtheme`用于选择图形的主题。`palette`用于选择点的几何形状。将`ellipse`值设置为false，这样函数就不会绘制簇的轮廓。
- en: '[PRE12]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is the output:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![Figure 2.8: DBSCAN clusters in different colors](img/C12628_02_08.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8：不同颜色的DBSCAN簇](img/C12628_02_08.jpg)'
- en: 'Figure 2.8: DBSCAN clusters in different colors'
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.8：不同颜色的DBSCAN簇
- en: In Figure 2.8, there are three clusters in orange, blue, and green. The points
    in black are noise or outliers. Points in orange here belong to one species, but
    points in green belong to two different species.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在图2.8中，有三个簇，分别是橙色、蓝色和绿色。黑色点是噪声或异常值。这里的橙色点属于一个物种，而绿色点属于两个不同的物种。
- en: Note
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can make a quick comparison of this scatter plot with Figure 1.18 of *Chapter
    1*, *Introduction to Clustering Methods*.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以快速比较这张散点图与*第一章*，*聚类方法简介*中的图1.18。
- en: 'DBSCAN is different from all the clustering we''ve studied so far and is one
    of the most common and one of the most frequently cited types of clustering methods
    in scientific literature. There are a few advantages that DBSCAN has over other
    clustering methods:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN与我们迄今为止研究过的所有聚类方法都不同，并且在科学文献中是最常见和最常引用的聚类方法之一。DBSCAN相对于其他聚类方法有几个优点：
- en: You don't need to select the number of clusters initially.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您最初不需要选择簇的数量。
- en: It does not produce different results every time you run it, unlike k-means
    or other "k-type" clustering methods, where starting points can have an effect
    on the end results. So, results are reproducible.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它每次运行时不会产生不同的结果，这与k-means或其他“k型”聚类方法不同，其中起始点可能会影响最终结果。因此，结果是可重复的。
- en: It can discover clusters of any shape in data.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以在数据中发现任何形状的簇。
- en: 'But there are also a few disadvantages of DBSCAN:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 但DBSCAN也有一些缺点：
- en: The correct set of parameters, that is, epsilon and `minPts`, are hard to determine
    for the proper clustering of data.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定正确的参数集，即epsilon和`minPts`，对于数据的适当聚类来说很难确定。
- en: DBSCAN cannot differentiate between clusters based on density. If a dataset
    has large variations in density, it may not perform as well.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DBSCAN无法根据密度区分簇。如果一个数据集的密度变化很大，它可能表现不佳。
- en: Uses of DBSCAN
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DBSCAN的应用
- en: 'As DBSCAN is one of the most frequently cited clustering methods, it has many
    practical uses. Some of the practical real-life uses of DBSCAN clustering are
    the following:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最常引用的聚类方法之一，DBSCAN有许多实际应用。DBSCAN聚类的一些实际应用包括以下内容：
- en: DBSCAN can be used in urban planning in many ways. For example, given data about
    crime incidents with locations, DBSCAN can be used to identify crime-ridden areas
    in a city. This data can be used to plan police force deployment or even investigate
    potential gang activity.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DBSCAN可以在城市规划中以多种方式使用。例如，给定关于犯罪事件位置的数据，DBSCAN可以用来识别城市中的犯罪多发区。这些数据可以用来规划警察力量的部署，甚至调查潜在的帮派活动。
- en: DBSCAN can be used to form strategies in games such as cricket and basketball.
    Given the data related to ball pitching on a cricket pitch, you can identify the
    strengths and weaknesses of batsmen and bowlers. Or if we have data on a batsman
    hitting the ball, data gained from DBSCAN can be used to adjust fielding accordingly.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DBSCAN可以用来在板球和篮球等游戏中制定策略。给定板球场地上的投球数据，您可以识别击球手和投球手的优缺点。或者如果我们有关于击球手击球的数据，从DBSCAN中获得的数据可以用来相应地调整防守。
- en: During natural disasters or the spread of viral diseases, the geolocation of
    tweets can be used to identify highly affected areas with DBSCAN.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在自然灾害或病毒疾病的传播期间，可以使用DBSCAN识别受影响严重的地区。
- en: 'Activity 6: Implementing DBSCAN and Visualizing the Results'
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动6：实现DBSCAN并可视化结果
- en: In this activity, we will perform DBSCAN and compare the results with k-means
    clustering. To do this, we are going to use the `multishapes` dataset, which contains
    simulated data that represents different shapes.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将执行DBSCAN并与k-means聚类进行比较。为此，我们将使用包含表示不同形状的模拟数据的`multishapes`数据集。
- en: 'These steps will help you complete the activity:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤将帮助您完成活动：
- en: Generate and store the `multishapes` dataset in the `factoextra` library.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`factoextra`库中生成并存储`multishapes`数据集。
- en: Plot the first two columns of the `multishapes` dataset.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制`multishapes`数据集的前两列。
- en: Perform k-means clustering on the dataset and visualize.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据集上执行k-means聚类并可视化。
- en: Perform DBSCAN on the dataset and visualize the data to compare the results
    with k-means clustering.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据集上执行DBSCAN并可视化数据，以比较与k-means聚类的结果。
- en: Note
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 213.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第213页找到。
- en: 'The plot of DBSCAN clustering will look as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN聚类的绘图将如下所示：
- en: '![Figure 2.9: Expected plot of DBCAN on the multishapes dataset](img/C12628_02_09.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9：多形状数据集上DBCAN的预期绘图](img/C12628_02_09.jpg)'
- en: 'Figure 2.9: Expected plot of DBCAN on the multishapes dataset'
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.9：多形状数据集上DBCAN的预期绘图
- en: Here, all the points in black are anomalies and are not classified in any cluster,
    and the clusters formed in DBSCAN cannot be obtained with any other type of clustering
    method. These clusters have taken several types of shapes and sizes, whereas,
    in k-means, all clusters are of approximately spherical shape.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，所有黑色的点都是异常值，并且没有被归类到任何聚类中，而DBSCAN中形成的聚类无法用其他任何类型的聚类方法获得。这些聚类具有多种形状和大小，而k-means中所有聚类都是近似球形的。
- en: Introduction to Hierarchical Clustering
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 层次聚类简介
- en: The last type of clustering that we're going to study is hierarchical clustering.
    A hierarchy is defined as "a system in which people or things are placed in a
    series of levels with different importance or status." Hierarchical clustering
    merges clusters sequentially. This sequence of merged clusters is called a hierarchy.
    We can see that more clearly with the help of the output of a hierarchical clustering
    algorithm called a **dendrogram**.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要研究的最后一种聚类类型是层次聚类。层次被定义为“一个将人或事物放置在一系列不同重要性或地位的层级系统。”层次聚类是按顺序合并聚类。这个合并聚类的序列被称为层次。我们可以通过一个名为**树状图**的层次聚类算法的输出更清楚地看到这一点。
- en: 'Hierarchical clustering comes in two types:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类有两种类型：
- en: Agglomerative
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: Divisive
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分裂
- en: Since both types of hierarchical clustering are similar, it makes sense to study
    both of them together.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两种类型的层次聚类都很相似，因此一起研究它们是有意义的。
- en: Agglomerative clustering is also known as the bottom-up approach to hierarchical
    clustering. In this method, each data point is assumed to be a single cluster
    at the outset. From there, we start merging the most similar clusters according
    to a similarity or distance metric until all the data points are merged in a single
    cluster.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是层次聚类的自下而上的方法。在这个方法中，每个数据点最初被假定为单个聚类。从那里开始，我们根据相似度或距离度量开始合并最相似的聚类，直到所有数据点合并成一个单一的聚类。
- en: 'In divisive clustering, we do exactly the opposite. It is a top-down approach
    to hierarchical clustering. In this method, all the data points are assumed to
    be in a single cluster initially. From there on, we start splitting the cluster
    into multiple clusters until each data point is a cluster on its own. Differences
    and similarities between the two clustering types will become clear in further
    sections. But first, we should try to understand why we need this other type of
    clustering and the special purpose it serves that other types of clustering don''t
    serve. Hierarchical clustering is used mainly for the following reasons:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在分裂聚类中，我们做的是完全相反的事情。它是层次聚类的自上而下方法。在这个方法中，所有数据点最初被假定为在一个单一的聚类中。从那里开始，我们开始将聚类分割成多个聚类，直到每个数据点都是一个单独的聚类。两种聚类类型之间的差异和相似性将在后续章节中变得清晰。但首先，我们应该尝试理解为什么我们需要这种其他类型的聚类以及它所服务的特殊目的，这是其他类型的聚类所不具备的。层次聚类主要用于以下原因：
- en: Just like DBSCAN, we don't have to choose a number of clusters initially.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像DBSCAN一样，我们最初不需要选择聚类的数量。
- en: The final output of hierarchical clustering, dendrograms, can help us visualize
    the clustering results in a way that means we don't need to re-run the algorithm
    to see a different number of clusters in the results.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次聚类的最终输出，树状图，可以帮助我们以可视化的方式理解聚类结果，这意味着我们不需要重新运行算法来查看结果中不同数量的簇。
- en: Unlike k-means, any type of distance metric can be used in hierarchical clustering.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与k-means不同，层次聚类可以使用任何类型的距离度量。
- en: It can find complex-shaped clusters, unlike other clustering algorithms, such
    as k-means, which only finds approximately spherical clusters.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以找到复杂形状的簇，与像k-means这样的其他聚类算法不同，后者只能找到近似球形的簇。
- en: The combination of all the preceding factors make hierarchical clustering an
    important clustering method in unsupervised learning.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些先前因素的结合使层次聚类成为无监督学习中的一个重要聚类方法。
- en: Types of Similarity Metrics
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相似性度量的类型
- en: 'As described previously, agglomerative hierarchical clustering is a bottom-up
    approach to hierarchical clustering. We merge the most similar clusters one by
    one based on a similarity metric. This similarity metric can be chosen from one
    of several different types:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，层次聚类是一种自下而上的层次聚类方法。我们根据相似性度量逐个合并最相似的簇。这个相似性度量可以从几种不同类型中选择：
- en: '**Single link**: In single-link similarity, we measure the distance or similarity
    between the two most similar points of two clusters:'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单链**：在单链相似度中，我们测量两个簇中两个最相似点之间的距离或相似度：'
- en: '![Figure 2.10: Demonstration of the single-link metric](img/C12628_02_10.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10：单链度量的演示](img/C12628_02_10.jpg)'
- en: 'Figure 2.10: Demonstration of the single-link metric'
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.10：单链度量的演示
- en: '**Complete link**: In this type of metric, we measure the distance or similarity
    between the two most distant points of a cluster:'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全连接**：在这种度量中，我们测量簇中两个最远点之间的距离或相似度：'
- en: '![Figure 2.11: Demonstration of the complete-link metric](img/C12628_02_11.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图2.11：完全连接度量的演示](img/C12628_02_11.jpg)'
- en: 'Figure 2.11: Demonstration of the complete-link metric'
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.11：完全连接度量的演示
- en: '**Group average**: In this metric, we measure the average distance between
    all members of one cluster and any members of a second cluster:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组平均**：在这个度量中，我们测量一个簇中所有成员与第二个簇中任何成员之间的平均距离：'
- en: '![Figure 2.12: Demonstration of the group-average metric](img/C12628_02_12.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图2.12：组平均度量的演示](img/C12628_02_12.jpg)'
- en: 'Figure 2.12: Demonstration of the group-average metric'
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.12：组平均度量的演示
- en: Note
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The distance between members of the same cluster is not measured in these similarity
    metrics.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些相似性度量中，不测量同一簇成员之间的距离。
- en: '**Centroid similarity**: In this type of similarity, the similarity between
    two clusters is defined as the similarity between the centroids of both clusters:'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质心相似度**：在这种相似度中，两个簇之间的相似度定义为两个簇质心之间的相似度：'
- en: '![Figure 2.13: Demonstration of centroid similarity](img/C12628_02_13.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图2.13：质心相似度的演示](img/C12628_02_13.png)'
- en: 'Figure 2.13: Demonstration of centroid similarity'
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.13：质心相似度的演示
- en: Steps to Perform Agglomerative Hierarchical Clustering
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行层次聚类的方法步骤
- en: 'With the knowledge of these similarity metrics, we can now understand the algorithm
    to perform agglomerative hierarchical clustering:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通过了解这些相似性度量，我们现在可以理解执行层次聚类算法的方法：
- en: Initialize each point as a single cluster.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个点初始化为一个单独的簇。
- en: Calculate the similarity metric between every pair of clusters. The similarity
    metric can be any of the four metrics we just read about.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每对簇之间的相似性度量。相似性度量可以是之前提到的四种度量中的任何一种。
- en: Merge the two most similar clusters according to the similarity metric selected
    in step 2.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据第2步中选择的相似性度量，合并两个最相似的簇。
- en: Repeat the process from step 2 until we have only one cluster left.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从第2步开始重复这个过程，直到只剩下一个簇为止。
- en: 'This whole process will produce a graph called a dendrogram. This graph records
    the clusters formed at each step. A simple dendrogram with very few elements would
    look as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程将产生一个称为树状图的图。这个图记录了每个步骤形成的簇。一个简单的、元素非常少的树状图看起来如下：
- en: '![Figure 2.14: A sample dendrogram](img/C12628_02_14.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图2.14：一个示例树状图](img/C12628_02_14.jpg)'
- en: 'Figure 2.14: A sample dendrogram'
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.14：一个示例树状图
- en: In the preceding dendogram, suppose that point A and point B are the closest
    among all points on the similarity measure that we are using. Their closeness
    is used to determine the height of the joining line, which is at **L1** in the
    case of point **A** and point **B**. So, point **A** and point **B** are clustered
    first. After that, at **L2**, point **D** and point **E** are clustered, then,
    at **L3**, points **A**, **B**, and **C** are clustered. At this point, we have
    two clusters that are joined together to form one cluster at **L4**.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的树状图中，假设点 A 和点 B 是我们在使用的相似性度量中所有点上最接近的两个点。它们的接近度被用来确定连接线的长度，在点 **A** 和点 **B**
    的情况下，这个长度是 **L1**。因此，点 **A** 和点 **B** 首先被聚类。之后，在 **L2**，点 **D** 和点 **E** 被聚类，然后，在
    **L3**，点 **A**、**B** 和 **C** 被聚类。此时，我们有两个集群在 **L4** 处连接形成一个集群。
- en: 'Now, to get clusters from this dendrogram, we make horizontal cuts. For example,
    if we make a cut between L4 and L3, we will get two clusters:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了从这个树状图中得到集群，我们进行水平切割。例如，如果我们将在 L4 和 L3 之间进行切割，我们将得到两个集群：
- en: Cluster 1 – A, B, and C
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 1 – A、B 和 C
- en: Cluster 2 – D and E
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 2 – D 和 E
- en: 'The clusters will look as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 集群将看起来如下：
- en: '![Figure 2.15: Clusters represented in the dendrogram](img/C12628_02_15.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.15：树状图中表示的集群](img/C12628_02_15.jpg)'
- en: 'Figure 2.15: Clusters represented in the dendrogram'
  id: totrans-180
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.15：树状图中表示的集群
- en: 'Similarly, if we make a horizontal cut in the dendrogram between L3 and L2,
    we will get three clusters:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，如果我们将在树状图中的 L3 和 L2 之间进行水平切割，我们将得到三个集群：
- en: Cluster 1 – A and B
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 1 – A 和 B
- en: Cluster 2 – C
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 2 – C
- en: Cluster 3 – D and E
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 3 – D 和 E
- en: 'The clusters will look as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 集群将看起来如下：
- en: '![Figure 2.16: Representation of clusters in a dendrogram](img/C12628_02_16.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.16：树状图中集群的表示](img/C12628_02_16.jpg)'
- en: 'Figure 2.16: Representation of clusters in a dendrogram'
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.16：树状图中集群的表示
- en: So, to get a different number of clusters, we didn't need to rerun the process.
    With this method, we can get any number of clusters possible in the data without
    executing the whole process again.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了得到不同数量的集群，我们不需要重新运行整个过程。使用这种方法，我们可以得到数据中可能出现的任何数量的集群，而无需再次执行整个过程。
- en: 'Exercise 12: Agglomerative Clustering with Different Similarity Measures'
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 12：使用不同相似性度量的聚合聚类
- en: 'In this exercise, we''re going to perform agglomerative hierarchical clustering
    with different similarity measures and compare the results:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用不同的相似性度量进行聚合层次聚类，并比较结果：
- en: 'Let''s enter the last three columns of the `iris_flowers` dataset, which are
    petal length, petal width, and species, in the `iris_data` variable, as follows:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将 `iris_flowers` 数据集的最后三列，即花瓣长度、花瓣宽度和物种，输入到 `iris_data` 变量中，如下所示：
- en: '[PRE13]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In this step, we use the `hclust` function to get hierarchical clustering.
    In the `hclust` function, we need to enter the pair-wise distance of all the points
    with each other, for which we use the `dist()` function. The second parameter,
    `method`, is used to define the similarity measure for the hierarchical clustering:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们使用 `hclust` 函数来获取层次聚类。在 `hclust` 函数中，我们需要输入所有点之间的成对距离，这可以通过 `dist()`
    函数实现。第二个参数 `method` 用于定义层次聚类的相似性度量：
- en: '[PRE14]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, let''s plot the results of the hierarchical clustering in a dendrogram,
    as follows:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将层次聚类的结果绘制成树状图，如下所示：
- en: '[PRE15]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.17: Dendrogram derived from the complete similarity metric](img/C12628_02_17.jpg)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.17：由完整相似性度量得到的树状图](img/C12628_02_17.jpg)'
- en: 'Figure 2.17: Dendrogram derived from the complete similarity metric'
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.17：由完整相似性度量得到的树状图
- en: 'To select a number of clusters from the preceding dendrogram, we can use an
    R function called `cutree`. We feed the results of `hclust` along with the number
    of clusters to this function:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从前面的树状图中选择多个集群，我们可以使用一个名为 `cutree` 的 R 函数。我们将 `hclust` 的结果以及集群数量输入到这个函数中：
- en: '[PRE16]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output table is as follows:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出表格如下：
- en: '![](img/C12628_02_18.jpg)'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![img/C12628_02_18.jpg]'
- en: 'Figure 2.18: Table displaying the distribution of clusters'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.18：显示集群分布的表格
- en: The setosa and virginica species get classified accurately with this clustering
    method.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用这种聚类方法，setosa 和 virginica 物种被准确分类。
- en: Use `single` as a similarity metric as follows:.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `single` 作为相似性度量，如下所示：
- en: '[PRE17]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.19: Dendrogram derived from the single similarity metric](img/C12628_02_19.jpg)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.19：由单相似性度量得到的树状图](img/C12628_02_19.jpg)'
- en: 'Figure 2.19: Dendrogram derived from the single similarity metric'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.19：基于单相似度指标生成的树状图
- en: Notice how this dendrogram is different from the dendrogram created with the
    `complete` similarity metric.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意这个树状图与使用`完全`相似度指标创建的树状图的不同之处。
- en: 'Divide this dataset into three clusters:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此数据集划分为三个簇：
- en: '[PRE18]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output is as follows:'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.20: Table displaying the distribution of clusters](img/C12628_02_20.jpg)'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.20：显示簇分布的表格](img/C12628_02_20.jpg)'
- en: 'Figure 2.20: Table displaying the distribution of clusters'
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.20：显示簇分布的表格
- en: Here, our clustering method is successfully able to separate only one class
    from the other two.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们的聚类方法成功地将一个类别从其他两个类别中分离出来。
- en: 'Now let''s perform hierarchical clustering with the `average` similarity metric:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用`平均`相似度指标执行层次聚类：
- en: '[PRE19]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.21: Dendrogram derived from the average similarity metric](img/C12628_02_21.jpg)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.21：基于平均相似度指标生成的树状图](img/C12628_02_21.jpg)'
- en: 'Figure 2.21: Dendrogram derived from the average similarity metric'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.21：基于平均相似度指标生成的树状图
- en: 'Let''s divide the preceding dendrogram into three clusters again and see the
    results:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将前面的树状图再次划分为三个簇，并查看结果：
- en: '[PRE20]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.22: Table displaying the distribution of clusters](img/C12628_02_22.jpg)'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.22：显示簇分布的表格](img/C12628_02_22.jpg)'
- en: 'Figure 2.22: Table displaying the distribution of clusters'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.22：显示簇分布的表格
- en: Here, with the `average` similarity metric, we get almost completely correct
    classification results.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，使用`平均`相似度指标，我们得到了几乎完全正确的分类结果。
- en: 'Now let''s try creating a dendrogram with the last similarity metric, `centroid`:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们尝试使用最后一个相似度指标，`质心`，创建一个树状图：
- en: '[PRE21]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.23: Dendrogram derived from the centroid similarity metric](img/C12628_02_23.jpg)'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.23：基于质心相似度指标生成的树状图](img/C12628_02_23.jpg)'
- en: 'Figure 2.23: Dendrogram derived from the centroid similarity metric'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.23：基于质心相似度指标生成的树状图
- en: 'Now, let''s divide the preceding dendrogram into three clusters and see the
    results:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将前面的树状图划分为三个簇，并查看结果：
- en: '[PRE22]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.24: Table displaying the distribution of clusters](img/C12628_02_24.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![图2.24：显示簇分布的表格](img/C12628_02_24.jpg)'
- en: 'Figure 2.24: Table displaying the distribution of clusters'
  id: totrans-238
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.24：显示簇分布的表格
- en: Although dendrograms of clusters with the `average` and `centroid` similarity
    metrics look different, they have the same number of elements in each cluster
    when we cut the dendrogram at three clusters.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于`平均`和`质心`相似度指标的簇的树状图看起来不同，但当我们把树状图切割成三个簇时，每个簇中的元素数量是相同的。
- en: Divisive Clustering
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 划分聚类
- en: 'Divisive clustering is the opposite of agglomerative clustering. In agglomerative
    clustering, we start with each point as its own cluster, while in divisive clustering,
    we start with the whole dataset as one cluster and from there, we start dividing
    it into more clusters:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 划分聚类与聚合聚类相反。在聚合聚类中，我们以每个点作为其自己的簇开始，而在划分聚类中，我们以整个数据集作为一个簇开始，然后开始将其划分为更多的簇：
- en: '![Figure 2.25: Representation of agglomerative and divisive clustering](img/C12628_02_25.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图2.25：聚合聚类和划分聚类的表示](img/C12628_02_25.jpg)'
- en: 'Figure 2.25: Representation of agglomerative and divisive clustering'
  id: totrans-243
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.25：聚合聚类和划分聚类的表示
- en: 'So, the divisive clustering process can be summarized in one figure as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，划分聚类过程可以总结如下一个图示：
- en: '![Figure 2.26: Representation of the divisive clustering process](img/C12628_02_26.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图2.26：划分聚类过程的表示](img/C12628_02_26.jpg)'
- en: 'Figure 2.26: Representation of the divisive clustering process'
  id: totrans-246
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.26：划分聚类过程的表示
- en: Steps to Perform Divisive Clustering
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行划分聚类的步骤
- en: From step 1 to step 6, the divisive clustering process keeps on dividing points
    into further clusters until each point is a cluster on its own. Figure 2.26 shows
    the first 6 steps of the divisive clustering process, but to correctly run the
    complete process, we will need to execute as many steps as there are points in
    the dataset.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 从步骤1到步骤6，划分聚类过程不断将点划分为更小的簇，直到每个点都是一个单独的簇。图2.26显示了划分聚类过程的前6步，但要正确运行完整过程，我们需要执行与数据集中点数相同数量的步骤。
- en: 'So, for divisive clustering, we will use the DIANA algorithm – DIANA stands
    for Divisive Analysis. For this, we need to carry out the following steps:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于划分聚类，我们将使用 DIANA 算法——DIANA 代表划分分析。为此，我们需要执行以下步骤：
- en: Start with all the points in the dataset in one single cluster.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中所有点都在一个单独的簇中开始。
- en: Choose two of the most dissimilar clusters of all the possible clusters in the
    dataset according to any distance metric you like.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据您喜欢的任何距离度量，从数据集中所有可能的簇中选择两个最不相似的簇。
- en: Repeat step 2 until all the points in the dataset are clustered on their own.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤 2，直到数据集中的所有点都各自聚类。
- en: We're going to use the `cluster` library in R to perform DIANA clustering.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 R 中的 `cluster` 库来执行 DIANA 聚类。
- en: 'Exercise 13: Performing DIANA Clustering'
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 13：执行 DIANA 聚类
- en: 'In this exercise, we will perform DIANA clustering:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将执行 DIANA 聚类：
- en: 'Put the petal length, petal width and species name in the `iris_data` variable:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将花瓣长度、花瓣宽度和物种名称放入 `iris_data` 变量中：
- en: '[PRE23]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Import the `cluster` library:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `cluster` 库：
- en: '[PRE24]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Pass the `iris_data` dataset and the metric by which to measure dissimilarity
    to the `diana()` function:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `iris_data` 数据集和用于度量差异度的度量传递给 `diana()` 函数：
- en: '[PRE25]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Plot the dendrogram with the `pltree()` function. To plot the dendrogram, pass
    the results of the `diana` function and the title of the graph to the `pltree()`
    function:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pltree()` 函数绘制树状图。要绘制树状图，需要将 `diana()` 函数的结果和图表标题传递给 `pltree()` 函数：
- en: '[PRE26]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The dendrogram of the divisive clustering results appears as follows:'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 划分聚类的树状图如下所示：
- en: '![Figure 2.27: Dendrogram of divisive clustering](img/C12628_02_27.jpg)'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.27：划分聚类的树状图](img/C12628_02_27.jpg)'
- en: 'Figure 2.27: Dendrogram of divisive clustering'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.27：划分聚类的树状图
- en: 'If we divide the preceding dendrogram into three clusters, we''ll see that
    this clustering method is also able to identify different species of flowers on
    its own:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们将前面的树状图划分为三个簇，我们会看到这种聚类方法也能够独立地识别不同的花卉种类：
- en: '[PRE27]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE28]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In the preceding output, only one flower is misclassified into another category.
    This is the best performance of all the clustering algorithms we have encountered
    in this book when it comes to classifying flower species without knowing anything
    about them.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，只有一朵花被错误地分类到另一个类别。这是我们在本书中遇到的所有聚类算法在不知道任何关于花卉信息的情况下对花卉物种进行分类的最佳性能。
- en: 'Activity 7: Performing Hierarchical Cluster Analysis on the Seeds Dataset'
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 7：对种子数据集执行层次聚类分析
- en: In this activity, we will perform hierarchical cluster analysis on the seeds
    dataset. We will see what the results of the clustering are when classifying three
    types of seeds.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将对种子数据集执行层次聚类分析。我们将看到当对三种种子进行分类时，聚类的结果是什么。
- en: Note
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This dataset is taken from the UCI Machine Learning Repository. You can find
    the dataset at [http://archive.ics.uci.edu/ml/machine-learning-databases/00236/](http://archive.ics.uci.edu/ml/machine-learning-databases/00236/).
    We have downloaded the file, cleaned it, and saved it at [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集来自 UCI 机器学习仓库。您可以在 [http://archive.ics.uci.edu/ml/machine-learning-databases/00236/](http://archive.ics.uci.edu/ml/machine-learning-databases/00236/)
    找到数据集。我们已经下载了文件，清理了它，并将其保存在 [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt)。
- en: 'These steps will help you complete the activity:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤将帮助您完成活动：
- en: Download the seeds dataset from [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt](
    https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt).
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson02/Activity07/seeds_data.txt)
    下载种子数据集。
- en: Perform agglomerative hierarchical clustering of the dataset and plot the dendrogram.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据集执行层次聚类并绘制树状图。
- en: Make a cut at `k=3` and check the results of the clustering by forming a table
    with original labels.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `k=3` 处进行切割，并通过创建一个包含原始标签的表格来检查聚类的结果。
- en: Perform divisive clustering on the dataset and plot the dendrogram.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据集进行划分聚类并绘制树状图。
- en: Make cut at `k=3` and check the results of the clustering by forming a table
    with original labels.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`k=3`处进行切割，并通过形成一个带有原始标签的表格来检查聚类的结果。
- en: Note
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 215.
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第215页找到。
- en: 'The output of this activity will be a table that shows how the results of the
    clustering have performed at classifying the three types of seeds. It will look
    as follows:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的输出将是一个表格，显示聚类结果在分类三种类型种子方面的表现。它将如下所示：
- en: '![Figure 2.28: Expected table classifying the three types of seeds](img/C12628_02_28.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![图2.28：预期表格，用于分类三种类型的种子](img/C12628_02_28.jpg)'
- en: 'Figure 2.28: Expected table classifying the three types of seeds'
  id: totrans-286
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.28：预期表格，用于分类三种类型的种子
- en: Summary
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Congratulations on completing the second chapter on clustering techniques! With
    this, we've covered all the major clustering techniques, including k-modes, DBSCAN,
    and both types of hierarchical clustering, and we've also looked at what connects
    them. We can apply these techniques to any type of dataset we may encounter. These
    new methods, at times, also produced better results on the same dataset that we
    used in the first chapter. In the next chapter, we're going to study probability
    distributions and their uses in exploratory data analysis.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您完成了关于聚类技术的第二章！至此，我们已经涵盖了所有主要的聚类技术，包括k-modes、DBSCAN以及两种类型的层次聚类，我们还探讨了它们之间的联系。我们可以将这些技术应用到我们可能遇到的任何类型的数据集中。这些新方法有时在第一章中使用的数据集上也产生了更好的结果。在下一章中，我们将研究概率分布及其在探索性数据分析中的应用。
