<html><head></head><body>
		<div id="_idContainer071">
			<h1 id="_idParaDest-67"><em class="italic"><a id="_idTextAnchor068"/>Chapter 5</em>: Building an AutoML Classification Solution</h1>
			<p>After building your AutoML regression solution with Python in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, you should be feeling confident in your coding abilities. In this chapter, you will build a classification solution. Unlike regression, <strong class="bold">classification</strong> is used to predict the category of the object of interest. For example, if you're trying to predict who is likely to become a homeowner in the next five years, classification is the right machine learning approach.</p>
			<p><strong class="bold">Binary classification</strong> is when you are trying to predict two classes, such as homeowner or not, while <strong class="bold">multiclass classification</strong> involves trying to predict three or more classes, such as homeowner, renter, or lives with family. You can utilize both of these techniques with Azure AutoML, and this chapter will teach you how to train both kinds of models using different datasets.</p>
			<p>In this chapter, you will begin by navigating directly to the Jupyter environment as you did in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>. Then, you will load in the same Titanic data that you used to build a model in <a href="B16595_03_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a><em class="italic">, Training Your First AutoML Model</em>. Retraining an identical model would be boring, so you will enrich the dataset by adding a few derived columns.</p>
			<p>Once you accomplish that, you will train, examine, and register your binary classification model. Then, you will train a multiclass classification model using the popular, publicly available Iris dataset that will predict what type of flower an individual plant is based on its dimensions. You will end this chapter by learning a few tips and tricks on how to fine-tune classification models. Pay close attention, as even seasoned data scientists fail to modify their classification models to align with the business problem at hand.</p>
			<p>By the end of this chapter, you will be able to build all types of classification models on your own with ease, regardless of your previous machine learning experience.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Prepping data for AutoML classification</li>
				<li>Training an AutoML classification model</li>
				<li>Registering your trained classification model</li>
				<li>Training an AutoML multiclass model</li>
				<li>Fine-tuning your AutoML classification model</li>
			</ul>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor069"/>Technical requirements</h1>
			<p>For this chapter, you will be building models with Python code in Jupyter notebooks through <strong class="bold">Azure Machine Learning</strong> (<strong class="bold">AML</strong>) <strong class="bold">studio</strong>. Furthermore, you will be using datasets and Azure resources that you should have created in previous chapters. As such, the full list of requirements is as follows:</p>
			<ul>
				<li>Access to the internet</li>
				<li>A web browser, preferably Google Chrome or Microsoft Edge Chromium</li>
				<li>A Microsoft Azure account</li>
				<li>An <strong class="bold">Azure Machine Learning</strong> workspace</li>
				<li>The <strong class="source-inline">titanic-compute-instance</strong> compute instance created in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a><em class="italic">, Getting Started with Azure Machine Learning</em></li>
				<li>The <strong class="source-inline">compute-cluster</strong> compute cluster created in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a><em class="italic">, Getting Started with Azure Machine Learning</em></li>
				<li>The <strong class="source-inline">Titanic Training Data</strong> dataset from <a href="B16595_03_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a><em class="italic">, Training your First AutoML Model</em></li>
				<li>An understanding of how to navigate to the Jupyter environment from an Azure compute instance as demonstrated in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em> </li>
			</ul>
			<h1 id="_idParaDest-69"><a id="_idTextAnchor070"/>Prepping data for AutoML classification</h1>
			<p>Classification, or <a id="_idIndexMarker204"/>predicting the category of <a id="_idIndexMarker205"/>something based on its attributes, is one of the key techniques of machine learning. Just like regression, you first need to prep your data before training it with AutoML. In this section, you will first navigate to your Jupyter notebook, load in your data, and transform it for use with AutoML.</p>
			<p>Just as you loaded in your <strong class="source-inline">Diabetes Sample</strong> dataset via Jupyter notebooks for regression, you will do the same with the <strong class="source-inline">Titanic Training Data</strong> dataset. However, this time around you will do much more extensive data transformation before training your AutoML model. This is to build upon your learning; classification datasets do not necessarily require more transformation than their regression counterparts. Identical to the previous chapter, you will begin by opening up a Jupyter notebook from your compute instance.</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor071"/>Navigating to your Jupyter environment</h2>
			<p>Similar<a id="_idIndexMarker206"/> to <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, you will begin by creating a new Jupyter notebook for creating your classification model as follows:</p>
			<ol>
				<li value="1">First, open AML studio by navigating to <a href="http://ml.azure.com">http://ml.azure.com</a>. </li>
				<li>Once you are in the studio, click <strong class="bold">Compute</strong> on the right-hand side of the studio under <strong class="bold">Manage</strong>.</li>
				<li>If your compute instance is currently paused, check the circular checkbox next to <strong class="source-inline">titanic-compute-instance</strong> and click the <strong class="bold">Start</strong> button.</li>
				<li>Then, click <strong class="bold">Jupyter</strong> under <strong class="bold">Application URL</strong> as seen in the following screenshot:<div id="_idContainer060" class="IMG---Figure"><img src="image/B16595_5_01.jpg" alt="Figure 5.1 – Accessing your Jupyter environment "/></div><p class="figure-caption">Figure 5.1 – Accessing your Jupyter environment</p><p>You should<a id="_idIndexMarker207"/> see the <strong class="source-inline">Diabetes_Regression_AutoML</strong> notebook that you previously created. Each time you create a Jupyter notebook, it will persist on your AMLS workspace even if you or other users access Jupyter from a different compute instance. Feel free to create as many notebooks as you want in this space, naming them carefully so you can easily track different projects.</p></li>
				<li>Click <strong class="bold">New</strong> in the upper right-hand corner of your screen to access the drop-down menu.</li>
				<li>Select <strong class="bold">Python 3.6 – AzureML</strong> from the drop-down menu.</li>
				<li>Click the new Jupyter notebook that appeared in the top-left corner of your screen, <strong class="source-inline">Untitled.ipynb</strong>.</li>
				<li>Rename <strong class="source-inline">Untitled.ipynb</strong> to <strong class="source-inline">Titanic Classification_AutoML</strong> by clicking <strong class="bold">Untitled</strong> in the top-left corner of the screen, typing <strong class="source-inline">Titanic_Classification_AutoML</strong> in the resulting textbox, and clicking <strong class="bold">Rename</strong> as shown <a id="_idIndexMarker208"/>in the following screenshot:</li>
			</ol>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/B16595_5_02.jpg" alt="Figure 5.2 – Renaming your Jupyter notebook "/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.2 – Renaming your Jupyter notebook</p>
			<p>With your notebook created, you are now ready to load in your Titanic data.</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor072"/>Loading and transforming your data</h2>
			<p>All <a id="_idIndexMarker209"/>AutoML <a id="_idIndexMarker210"/>solutions use roughly the same<a id="_idIndexMarker211"/> boilerplate <a id="_idIndexMarker212"/>code. If you completed <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, begin copying over your code cell by cell. After doing so, simply follow the instructions step by step and alter your code when necessary. If you skipped directly to this chapter, you will have to code everything from scratch.</p>
			<p>Just as before, you will load in your Python libraries and set your workspace, datastore, compute cluster, and dataset. You will then transform and register your enriched data as follows:</p>
			<ol>
				<li value="1">Load in all of the libraries you will need to run all of your code. Refer to <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, for a detailed explanation of all of these packages:<p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment</p><p class="source-code">from azureml.core.compute import ComputeTarget</p><p class="source-code">from azureml.train.automl import AutoMLConfig</p><p class="source-code">from azureml.train.automl.run import AutoMLRun</p><p class="source-code">from azureml.widgets import RunDetails</p></li>
				<li>Load in <strong class="source-inline">pandas</strong> and <strong class="source-inline">numpy</strong>. These<a id="_idIndexMarker213"/> are popular Python packages that help you <a id="_idIndexMarker214"/>transform <a id="_idIndexMarker215"/>data. <strong class="source-inline">pandas</strong>, in particular, is<a id="_idIndexMarker216"/> necessary to view the data in your dataset:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p></li>
				<li>Connect your Jupyter notebook to your AMLS workspace:<p class="source-code">ws = Workspace.from_config()</p></li>
				<li>Set your compute cluster:<p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p></li>
				<li>Set your <strong class="source-inline">datastore</strong>. For this exercise, we will use the default datastore that comes with your AMLS workspace. If you want to use a different datastore, you can replace the name:<p class="source-code">datastore = Datastore.get_default(ws)</p><p class="source-code">my_datastore_name = 'workspaceblobstore'</p><p class="source-code">my_datastore = Datastore.get(ws, my_datastore_name)</p></li>
				<li>Set your <strong class="source-inline">dataset</strong>:<p class="source-code">dataset_name = "Titanic Training Data"</p><p class="source-code">dataset = Dataset.get_by_name(ws, dataset_name, version='latest')</p><p class="callout-heading">Note</p><p class="callout"><em class="italic">Step 6</em> is the first <a id="_idIndexMarker217"/>place<a id="_idIndexMarker218"/> where <a id="_idIndexMarker219"/>you should have altered your code. Each time <a id="_idIndexMarker220"/>you create a new classification or regression AutoML solution in Azure, use this template.</p></li>
				<li>The following is the code to view the first 10 rows of data. Make sure that it looks correct:<p class="source-code">dataset.take(10).to_pandas_dataframe()</p><p>The first 10 rows should appear as follows:</p><div id="_idContainer062" class="IMG---Figure"><img src="image/B16595_5_03.jpg" alt="Figure 5.3 – Viewing your Titanic dataset "/></div><p class="figure-caption">Figure 5.3 – Viewing your Titanic dataset</p></li>
				<li>Convert <a id="_idIndexMarker221"/>your<a id="_idIndexMarker222"/> dataset<a id="_idIndexMarker223"/> into<a id="_idIndexMarker224"/> a <strong class="bold">pandas DataFrame</strong>:<p class="source-code">dfRaw = dataset.to_pandas_dataframe()</p><p>AutoML will <a id="_idIndexMarker225"/>automatically fill your null values for you, but it's not particularly savvy in its implementation. It will most often naively fill nulls based on the mean of the column. As a data scientist, you often want to be more careful with how you fill nulls to improve the accuracy of your model. The closer you can approximate the actual missing model, the better it will perform in the real world.</p><p>Notice that the Titanic data has missing values in the <strong class="source-inline">Age</strong> column. It's very likely that the age of the passengers will vary by other columns such as <strong class="source-inline">Sex</strong>. Instead of replacing these nulls with the mean value of the entire <strong class="source-inline">Age</strong> column, let's instead replace them with mean age by gender.</p></li>
				<li>Calculate the mean age of women and men in your <strong class="source-inline">Titanic</strong> dataset:<p class="source-code">dfRaw = dataset.to_pandas_dataframe()</p><p class="source-code">round(dfRaw.groupby(['Sex'])['Age'].mean())</p><p>This code will show you that the mean age of women is 28 years old and the mean age of men is 31 years old. You will use these numbers in the next cell.</p></li>
				<li>Replace null<a id="_idIndexMarker226"/> values in the <strong class="source-inline">Age</strong> column with the<a id="_idIndexMarker227"/> appropriate number for<a id="_idIndexMarker228"/> each<a id="_idIndexMarker229"/> gender using this conditional Python code:<p class="source-code">dfRaw['Age'] = dfRaw.apply(</p><p class="source-code">   lambda row: 31 if np.isnan(row['Age'])\</p><p class="source-code">    and row['Sex']=='male'\</p><p class="source-code">    else (28 if np.isnan(row['Age'])\</p><p class="source-code">          and row['Sex']=='female'\</p><p class="source-code">    else row['Age']),axis=1)</p><p>Another common transformation is to bin numerical data. <strong class="bold">Binning</strong> numerical data means creating multiple categorical columns from a single numeric column, for example, splitting an age column into age ranges instead. You should bin numerical data when you suspect that the range of numbers matters more than the absolute number.</p><p>For example, if you suspect whether a person is young or old matters to whether they survived the Titanic, but not their exact age, you should bin data into groups. AutoML will not automatically bin data for you, but some algorithms, such as decision trees, do not require binning to achieve a similar effect.</p></li>
				<li>Bin the <strong class="source-inline">Age</strong> column into four different age groups: Under 15, 15-35, 35-60, and over 60:<p class="source-code">dfRaw['BinUnder15'] = np.where(dfRaw.Age &lt; 15,1,0)</p><p class="source-code">dfRaw['Bin15to34'] = np.where((dfRaw.Age&gt;14)\</p><p class="source-code">                            &amp; (dfRaw.Age &lt; 35),1,0)</p><p class="source-code">dfRaw['Bin35to60'] = np.where((dfRaw.Age&gt;34)\</p><p class="source-code">                            &amp; (dfRaw.Age &lt; 61),1,0)</p><p class="source-code">dfRaw['BinOver60'] = np.where(dfRaw.Age &gt; 60,1,0)</p><p>You<a id="_idIndexMarker230"/> can try<a id="_idIndexMarker231"/> different combinations of ages if <a id="_idIndexMarker232"/>you<a id="_idIndexMarker233"/> like.</p></li>
				<li>Now that you have binned the <strong class="source-inline">Age</strong> column, drop it. This will be your final DataFrame:<p class="source-code">df = dfRaw.drop(['Age'],axis=1)</p></li>
				<li>Reregister your altered data and give the dataset a new name, <strong class="source-inline">Titanic Transformed</strong>. This will save your transformed pandas DataFrame to your datastore, creating a new file on disk:<p class="source-code">Dataset.Tabular.register_pandas_dataframe(df, datastore,</p><p class="source-code">                            "Titanic Transformed")</p><p>You may get a warning that <strong class="source-inline">register_pandas_dataframe</strong> is an experimental method as it is a new feature of the AML SDK. You are safe to ignore this warning. </p></li>
			</ol>
			<p>If you're new to Python, some of this code will perplex you, and that's okay. You will find great value in learning the <strong class="source-inline">pandas</strong> and <strong class="source-inline">numpy</strong> libraries, as they are two of the most popular packages for transforming data. Each time you learn a new <strong class="source-inline">pandas</strong> or <strong class="source-inline">numpy</strong> function, save an example to your personal code base for later use. Even if you never become a Python expert, however, you will still be able to use Azure AutoML to deliver a great model. Yet, Python experts will still be able to deliver the best models through careful, nuanced, and savvy data transformations. </p>
			<p>You are now ready to train another model with your Titanic dataset. Between intelligently filling in<a id="_idIndexMarker234"/> null values and binning the <strong class="source-inline">Age</strong> column, you <a id="_idIndexMarker235"/>may expect to produce a<a id="_idIndexMarker236"/> superior<a id="_idIndexMarker237"/> model to that which you built in <a href="B16595_03_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a><em class="italic">, Training Your First AutoML Model</em>. Let's see if that's the case.</p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor073"/>Training an AutoML classification model</h1>
			<p>Training an AutoML <a id="_idIndexMarker238"/>classification model is very similar to training an AutoML regression model, but there are a few key differences. In <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, you began by setting a name for your experiment. After that, you set your target column and subsequently set your AutoML configurations. Finally, you used AutoML to train a model, performed a data guardrails check, and produced results. </p>
			<p>All of the steps in this section are nearly the same. However, pay close attention to the data guardrails check and results, as they are substantially different when training classification models:</p>
			<ol>
				<li value="1">Set your <strong class="source-inline">experiment</strong> and give it a name: <p class="source-code">experiment_name = 'Titanic-Transformed-Classification'</p><p class="source-code">exp = Experiment(workspace=ws, name=experiment_name) </p></li>
				<li>Set your <strong class="source-inline">dataset</strong> to your transformed <strong class="source-inline">Titanic</strong> data:<p class="source-code">dataset_name = "Titanic Transformed"</p><p class="source-code">dataset = Dataset.get_by_name(ws, dataset_name, version='latest')</p></li>
				<li>Set your target column, <strong class="source-inline">Survived</strong>. Capitalization matters:<p class="source-code">target_column = 'Survived'</p></li>
				<li>Create a variable for your <strong class="source-inline">task</strong>: now, <strong class="source-inline">task</strong> is the type of AutoML model you are trying to train. For predicting categories, enter <strong class="source-inline">classification</strong>:<p class="source-code">task = 'classification'</p><p class="callout-heading">Important note</p><p class="callout">You can always turn a regression problem into a classification, and this is often an easier machine learning problem to solve. For example, for the diabetes problem, you can create a new column<a id="_idIndexMarker239"/> based on the <strong class="source-inline">Y</strong> column. Set a numeric threshold and assign a <strong class="source-inline">1</strong> to any patient who exceeds the threshold and a <strong class="source-inline">0</strong> to any patient below it. Then, try training a classification model with AutoML. </p></li>
				<li>Create a variable for your primary metric: <strong class="bold">Primary metric</strong> is how your model will be scored. Use <strong class="bold">accuracy</strong>. This metric divides the number of cases that your model accurately predicted the class (survived or not) of by the total number of cases. The higher the score, the better your model. Other options for classification include <strong class="bold">AUC weighted</strong>, <strong class="bold">average precision score weighted</strong>, <strong class="bold">norm macro recall</strong>, and <strong class="bold">precision score weighted</strong>:<p class="source-code">primary_metric = 'accuracy'</p></li>
				<li>Create a variable for <strong class="source-inline">featurization</strong> and set it to <strong class="source-inline">auto</strong>:<p class="source-code">featurization = 'auto'</p><p>You can set <strong class="source-inline">featurization</strong> to <strong class="source-inline">auto</strong> or <strong class="source-inline">off</strong>. If you set <strong class="source-inline">featurization</strong> to <strong class="source-inline">off</strong>, you will have to drop high-cardinality features, impute null values, one-hot encode your data, and generate additional features yourself.</p><p>With classification, you will also have to balance your classes, meaning that you should resample your data to have a close-to-equal number of passengers who survived and died on the Titanic. Always set it to <strong class="source-inline">auto</strong> unless you are an expert data scientist and are comfortable doing everything yourself:</p></li>
				<li>Set the number of classes: <p class="source-code">num_classes = df[target_column].nunique()  </p><p>This is the primary difference when training a classification model. By doing this programmatically with the following code, you will never make a mistake as you might when manually inputting the number.</p><p class="callout-heading">Important note</p><p class="callout">AutoML can handle a large number of classes, but you may run into trouble if you have overly imbalanced <a id="_idIndexMarker240"/>classes. When you have 20 times the number of your largest case as your smallest case, you may want to resample your data or bin your target column to reduce the discrepancy.</p></li>
				<li>Configure your AutoML run: here, you will pass in your task, primary metric, featurization settings, compute target, dataset, target column, and the number of classes. All of these you have previously created. You will also pass in how long the experiment will run, whether it will stop early if the model performance does not improve, the number of cross-validations, and whether your experiment will record model explanations.<p>Additionally, you will pass in <a id="_idIndexMarker241"/>whether or not you want to use <strong class="bold">ensemble models</strong>, models that are combinations of other models. Once again, set your cross-validation setting to between <strong class="source-inline">5</strong> and <strong class="source-inline">20</strong> splits:</p><p class="source-code">config = AutoMLConfig(task=task,</p><p class="source-code">                     primary_metric=primary_metric,</p><p class="source-code">                     num_classes=num_classes,</p><p class="source-code">                     featurization=featurization,</p><p class="source-code">                     compute_target=compute_target,</p><p class="source-code">                     training_data=dataset,</p><p class="source-code">                     label_column_name=target_column,</p><p class="source-code">                     experiment_timeout_minutes=15,</p><p class="source-code">                     enable_early_stopping=True,</p><p class="source-code">                     n_cross_validations=5,</p><p class="source-code">                     model_explainability=True,</p><p class="source-code">                     enable_stack_ensemble=True,</p><p class="source-code">                     enable_voting_ensemble=True)</p></li>
				<li>Train your <a id="_idIndexMarker242"/>model and watch the results in real time:<p class="source-code">AutoML_run = exp.submit(config, show_output = True)</p><p class="source-code">RunDetails(remote_run).show()</p></li>
			</ol>
			<p>Most of this code should feel familiar. Kick off your AutoML run, make yourself some coffee, come back, and watch your model run. You will then see a data guardrails check as seen in <em class="italic">Figure 5.4</em>. Notice how it has changed for classification.</p>
			<p>First, it will check your target column to make sure that classes are balanced. Then, it will impute missing values. Here, there are two missing values in the <strong class="source-inline">Embarked</strong> column. Since it's a categorical column, it will be filled with the most common value. Lastly, like regression, it looks for categorical columns that have <strong class="bold">high cardinality</strong> or too many unique values given the dataset:</p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B16595_5_04.jpg" alt="Figure 5.4 – Data guardrails check for classification"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.4 – Data guardrails check for classification</p>
			<p>Just as before, after <a id="_idIndexMarker243"/>completing the data guardrails check, AutoML will start training models with different combinations of feature<a id="_idIndexMarker244"/> transformations, algorithms, and hyperparameters. Some of the algorithms<a id="_idIndexMarker245"/> used<a id="_idIndexMarker246"/> will be unique to classification such <a id="_idIndexMarker247"/>as naïve Bayes, linear SVC, and <strong class="bold">logistic regression</strong>, while others such as <strong class="bold">random forest</strong>, <strong class="bold">light GBM</strong>, and <strong class="bold">XGBoost</strong> are shared with regression. Your output should resemble something similar to <em class="italic">Figure 5.5</em>:</p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B16595_5_05.jpg" alt="Figure 5.5 – AutoML results for classification"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.5 – AutoML results for classification</p>
			<p>There are two striking<a id="_idIndexMarker248"/> things about these results: the first model trained is the best model and the algorithm you trained in <a href="B16595_03_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a><em class="italic">, Training Your First AutoML Model</em>, is slightly better. When models are relatively simple for machine learning to find patterns, your first model may be your best model. Our attempts to outsmart AutoML by filling in nulls ourselves and binning the <strong class="source-inline">Age</strong> column failed.</p>
			<p>Despite our failure to produce a model, it's a good exercise to show the inherent power of AutoML. Often, leaving the data as is will produce an excellent model. Other times, creating new features from your existing features will produce superior models. Try experimenting to see if you can get higher-performing results with the <strong class="source-inline">Titanic</strong> dataset. See <em class="italic">Figure 5.6</em> for the visualized results, and notice that you can select other metrics from the dropdown in the top-left corner:</p>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B16595_5_06.jpg" alt="Figure 5.6 – AutoML results visualized for classification "/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.6 – AutoML results visualized for classification</p>
			<p>Once you have <a id="_idIndexMarker249"/>thoroughly experimented with the <strong class="source-inline">Titanic</strong> data and have achieved the highest accuracy, you can move on to the next section to register your model. Registered models are necessary for later use in scoring new data through machine learning pipelines or real-time endpoints.</p>
			<h1 id="_idParaDest-73"><a id="_idTextAnchor074"/>Registering your trained classification model</h1>
			<p>The code to register <a id="_idIndexMarker250"/>classification models is identical to the code you used in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, to register your regression model. Always register new models, as you will use them to score new data using either real-time scoring endpoints or batch execution inference pipelines depending on your use case. This will be explained in <a href="B16595_09_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a><em class="italic">, Implementing a Batch Scoring Solution</em>, and <a href="B16595_11_ePub.xhtml#_idTextAnchor172"><em class="italic">Chapter 11</em></a><em class="italic">, Implementing a Real-Time Scoring Solution</em>. Likewise, when registering your models, always add tags and descriptions for easier tracking:</p>
			<ol>
				<li value="1">First, give your model a name, a description, and some tags:<p class="source-code">description = 'Best AutoML Classification Run using Transformed Titanic Data.' </p><p class="source-code">tags = {'project' : "Titanic", "creator" : "your name"} </p><p class="source-code">model_name = 'Titanic-Transformed-Classification-AutoML' </p><p>Tags let you easily search for models, so think carefully as you implement them.</p></li>
				<li>Next, register your model to your AMLS workspace, passing in your model name, tags, and description. Use the <strong class="source-inline">AutoML_run</strong> instance you trained in the previous section:<p class="source-code">AutoML_run.register_model(model_name=model_name, \</p><p class="source-code">description=description, tags=tags)</p></li>
				<li>Try registering a<a id="_idIndexMarker251"/> different model based <a id="_idIndexMarker252"/>on <strong class="bold">normalized macro recall</strong>. Give it a slightly different name, add an additional tag, and use an identical description:<p class="source-code">description = 'Best AutoML Classification Run using \</p><p class="source-code">Transformed Titanic Data.' </p><p class="source-code">tags = {'project' : "Titanic", "creator" : "your name",\</p><p class="source-code"> "metric" : "Norm Macro Recall"} </p><p class="source-code">model_name = 'Titanic-Transformed-Classification-AutoML-NMR' </p><p class="source-code">AutoML_run.register_model(model_name=model_name, \</p><p class="source-code">description=description, tags=tags, metric = 'norm_macro_recall')</p><p class="callout-heading">Important note</p><p class="callout">If time has elapsed since the last time you trained your AutoML model, you can retrieve it by finding <strong class="bold">Run ID</strong> in the <strong class="bold">Experiments</strong> section of the AML studio. Simply click on <strong class="bold">Experiments</strong> under <strong class="bold">Assets</strong>, select the correct experiment name, and copy the <strong class="bold">Run ID</strong> value. Set <strong class="source-inline">AutoML_run</strong> using this:</p><p class="callout"><strong class="source-inline">ID.experiment_name = 'Titanic-Transformed-Classification-AutoML'</strong></p><p class="callout"><strong class="source-inline">exp = Experiment(workspace=ws, name=experiment_name) </strong></p><p class="callout"><strong class="source-inline">AutoML_run = AutoMLRun(experiment = exp, run_id = 'your_run_id') </strong></p></li>
			</ol>
			<p>You have registered your model and it is ready for use. You have created a classification model that can be used to predict who survived and who did not on the ill-fated Titanic voyage. It fell a<a id="_idIndexMarker253"/> little short of the classification model you built in <a href="B16595_03_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a><em class="italic">, Training Your First AutoML Model</em>, but in doing so, you learned a lot. With your lessons in mind, we can move on to tips and tricks that will improve your classification models as you train more in the future.</p>
			<h1 id="_idParaDest-74"><a id="_idTextAnchor075"/>Training an AutoML multiclass model</h1>
			<p>Multiclass classification <a id="_idIndexMarker254"/>involves predicting three or more classes instead of the standard binary classification. Using custom machine learning, training multiclass models is often a messy, complicated affair where you have to carefully consider the number of classes you are trying to predict, how unbalanced those classes are relative to each other, whether you should combine classes together, and how you should present your results. Luckily, AutoML takes care of all these considerations for you and makes training a multiclass model as simple as training a binary classification model.</p>
			<p>In this section, you load in data using the publicly available Iris dataset. You will then set your AutoML classifications for multiclass classification, train and register a model, and examine your results. You will notice that much of the code is identical to the last section. By understanding the differences between binary and multiclass classification in AutoML, you will gain the confidence to tackle any type of classification problem irrespective of complexity.</p>
			<ol>
				<li value="1">Download the <strong class="source-inline">Iris.csv</strong> file from the GitHub repository, <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure</a>.</li>
				<li>Load <strong class="source-inline">Iris.csv</strong> into Azure and create a dataset called <strong class="source-inline">Iris Training</strong> following the same steps you took in <a href="B16595_03_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a><em class="italic">, Training Your First AutoML Model</em>.</li>
				<li>Load in all of the libraries you will need to run all of your code. Notice these libraries are<a id="_idIndexMarker255"/> identical to the ones you used for binary classification:<p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment</p><p class="source-code">from azureml.core.compute import ComputeTarget</p><p class="source-code">from azureml.train.automl import AutoMLConfig</p><p class="source-code">from azureml.train.automl.run import AutoMLRun</p><p class="source-code">from azureml.widgets import RunDetails</p></li>
				<li>Load in <strong class="source-inline">pandas</strong> and <strong class="source-inline">numpy</strong>. No matter the data you're working with, you will always find these packages useful:<p class="source-code">Import pandas as pd</p><p class="source-code">import numpy as np</p></li>
				<li>Connect your Jupyter notebook to your AMLS workspace:<p class="source-code">ws = Workspace.from_config()</p></li>
				<li>Set your compute cluster:<p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p></li>
				<li>Set your <strong class="source-inline">datastore</strong>:<p class="source-code">datastore = Datastore.get_default(ws)</p><p class="source-code">my_datastore_name = 'workspaceblobstore'</p><p class="source-code">my_datastore = Datastore.get(ws, my_datastore_name)</p></li>
				<li>Set your <strong class="source-inline">dataset</strong>. Notice that this is the first piece of code that differs from binary<a id="_idIndexMarker256"/> classification, as you're using an entirely different dataset:<p class="source-code">dataset_name = "Iris Training"</p><p class="source-code">dataset = Dataset.get_by_name(ws, dataset_name, version='latest')</p></li>
				<li>View the first 10 rows of your data using the following code. Make sure that it looks correct. With Iris data, you are trying to predict the <strong class="source-inline">species</strong> column:<p class="source-code">dataset.take(10).to_pandas_dataframe()</p><p>The first 10 rows should look similar to <em class="italic">Figure 5.7</em>:</p><div id="_idContainer066" class="IMG---Figure"><img src="image/B16595_5_07.jpg" alt="Figure 5.7 – Iris data"/></div><p class="figure-caption">Figure 5.7 – Iris data</p></li>
				<li>Use the <a id="_idIndexMarker257"/>pandas <strong class="source-inline">unique</strong> function on the <strong class="source-inline">species</strong> column to see how many classes you need to predict. You should see three classes, <em class="italic">Iris-setosa</em>, <em class="italic">Iris-versicolor</em>, and <em class="italic">Iris-virginica</em>:<p class="source-code">dataset.to_pandas_dataframe().species.unique()</p></li>
				<li>Set your experiment and give it a name:<p class="source-code">experiment_name = 'Iris-Multi-Classification'</p><p class="source-code">exp = Experiment(workspace=ws, name=experiment_name) </p><p>Try to be descriptive when naming your experiments to easily track them, for example, by indicating explicitly that this training run is for multiclass classification.</p></li>
				<li>Set your target column to <strong class="source-inline">species</strong>. Capitalization matters:<p class="source-code">target_column = 'species'</p><p>Unlike most custom machine learning code, you do not have to convert the three different classes to integers. AutoML handles all of this on the backend.</p></li>
				<li>Create a variable for your task: the task is the type of AutoML model you are trying to train. For predicting categories, enter <strong class="source-inline">classification</strong>:<p class="source-code">task = 'classification'</p><p><strong class="source-inline">task</strong> should be set to <strong class="source-inline">classification</strong> for both binary and multiclass classification <a id="_idIndexMarker258"/>problems.</p></li>
				<li>Create a variable for your primary metric. Use <strong class="source-inline">accuracy</strong>:<p class="source-code">primary metric = 'accuracy'</p><p>All metrics are the same for binary and multiclass classification problems, except some are calculated slightly differently by averaging the metric for each class instead of simply comparing true positives to true negatives. Accuracy, however, is calculated the same regardless of whether the problem is binary or multiclass.</p></li>
				<li>Create a variable for <strong class="source-inline">featurization</strong> and set it to <strong class="source-inline">auto</strong>:<p class="source-code">featurization = 'auto'</p><p>You can set <strong class="source-inline">featurization</strong> to <strong class="source-inline">auto</strong> or <strong class="source-inline">off</strong>. For multiclass problems, it is especially important to set it to <strong class="source-inline">auto</strong> so classes are properly balanced. Not doing so will impact model performance.</p></li>
				<li>Set the number of classes to <strong class="source-inline">3</strong>: <p class="source-code">num_classes = 3  </p><p>While you can do this programmatically, you can also set it to a number in cases where you already know and have confirmed the number of classes.</p><p class="callout-heading">Important note</p><p class="callout">When training multiclass classification problems, sometimes you should hardcode in the number of classes. This ensures that your training run will fail if corrupted data enters your system and gives you an extra, unexpected class.</p></li>
				<li>Configure your AutoML run. Nothing is different between multiclass and binary classification problems when it comes to configuring the run itself. One caveat is that multiclass classification problems often benefit from slightly higher cross validation <a id="_idIndexMarker259"/>settings. This helps ensures that the classes in each training split are more uniform. Set it to <strong class="source-inline">10</strong>:<p class="source-code">config = AutoMLConfig(task=task,</p><p class="source-code">                     primary_metric=primary_metric,</p><p class="source-code">                     num_classes=num_classes,</p><p class="source-code">                     featurization=featurization,</p><p class="source-code">                     compute_target=compute_target,</p><p class="source-code">                     training_data=dataset,</p><p class="source-code">                     label_column_name=target_column,</p><p class="source-code">                     experiment_timeout_minutes=15,</p><p class="source-code">                     enable_early_stopping=True,</p><p class="source-code">                     n_cross_validations=10,</p><p class="source-code">                     model_explainability=True,</p><p class="source-code">                     enable_stack_ensemble=True,</p><p class="source-code">                     enable_voting_ensemble=True)</p></li>
				<li>Train your model and watch the results in real time:<p class="source-code">AutoML_run = exp.submit(config, show_output = True)</p><p class="source-code">RunDetails(remote_run).show()</p></li>
				<li>Once your model is done training, register your model:<p class="source-code">description = 'AutoML Multiclass Run using Iris Data.' </p><p class="source-code">tags = {'project' : "Iris", "creator" : "your name"} </p><p class="source-code">model_name = 'Iris-Multi-Classification-AutoML' </p><p class="source-code">AutoML_run.register_model(model_name=model_name,description=\</p><p class="source-code">description,tags=tags)</p></li>
			</ol>
			<p>As your AutoML<a id="_idIndexMarker260"/> model is running, it will perform the usual data guardrails check followed by. It is the same for binary and multiclass classification, checking for class balancing, missing features, and high cardinality. Your Iris data should pass all of these checks easily.</p>
			<p>Once the data guardrails check is complete, AutoML will start training models as usual. Compare the models trained on multiclass Iris data versus binary class Titanic data. You should notice that most models are the same. Your output should resemble <em class="italic">Figure 5.8</em>:</p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B16595_5_08.jpg" alt="Figure 5.8 – AutoML results for multiclass classification "/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.8 – AutoML results for multiclass classification</p>
			<p>There are excellent results. AutoML performs exceptionally well on the Iris dataset. There's also an <a id="_idIndexMarker261"/>easy way to graph your performance directly from your Jupyter notebook. Scroll down slightly past your model output until you see blue links to each of your models as seen in <em class="italic">Figure 5.9</em>. Click on your highest-performing model. For the example, it was the voting ensemble model, but it may be something different in your case:</p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B16595_5_09.jpg" alt="Figure 5.9 – Model links "/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 5.9 – Model links</p>
			<p>Clicking on this link will expose a large number of visualizations for your AutoML classification experiment. In particular, there's a <strong class="bold">precision-recall curve</strong>, an <strong class="bold">ROC curve</strong>, a <strong class="bold">lift curve</strong>, a <strong class="bold">gain curve</strong>, a <strong class="bold">calibration curve</strong>, and a <strong class="bold">confusion matrix</strong>. Business users most easily understand the confusion matrix, which shows you the number of classes that were accurately classified along with the number that were misclassified. As shown in <em class="italic">Figure 5.10</em>, AutoML only misclassified two data points out of 150 total. In both<a id="_idIndexMarker262"/> cases, the model incorrectly classified an Iris-versicolor as an Iris-virginica:</p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B16595_5_10.jpg" alt="Figure 5.10 – Confusion matrix for the Iris classification model "/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.10 – Confusion matrix for the Iris classification model</p>
			<p>Now that you have trained both a binary and multiclass classification model with AutoML, you can apply these techniques to your own data and business problems. If you were training custom machine learning models, you would have to memorize many little differences between binary and multiclass classification, but Azure AutoML handles all of those complexities for you. You don't even have to change your categorical column to integers.</p>
			<p>As such, you should feel comfortable using AutoML for any classification problem you have. The final section gives you tips and tricks for achieving better model performan<a id="_idTextAnchor076"/>ce.</p>
			<h1 id="_idParaDest-75"><a id="_idTextAnchor077"/>Fine-tuning your AutoML classification model</h1>
			<p>In this section, you<a id="_idIndexMarker263"/> will first review tips and tricks for improving your AutoML classification models and then review the algorithms used by AutoML for both binary and multiclass classification.</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor078"/>Improving AutoML classification models</h2>
			<p>Keeping in mind the<a id="_idIndexMarker264"/> tips and tricks from <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, here are new ones that are specific to classification:</p>
			<ul>
				<li>Unlike regression problems, nearly all classification problems in the real world require you to weigh your target column. The reason is that, for most business problems, one class is nearly always more important than the others.<p>For example, imagine you are running a business and you are trying to predict which customers will stop doing business with you and leave you for a competitor. This is a common problem called customer churn or customer turnover. If you misidentify a customer as being likely to churn, all you waste is an unnecessary phone call or email. However, if your algorithm misses a customer who will churn, you lose that customer and their money.</p><p>If you use the normal accuracy metric in AutoML, that is a poor metric for this problem. This is because it's much better to misidentify someone as <em class="italic">likely to switch</em> than it is to misidentify someone as <em class="italic">likely to stay</em>. The solution to this is to use the <strong class="source-inline">weight_column_name</strong> feature in AutoML. This allows you to create a column that weights hits and misses differently.</p><p>For example, if your algorithm misses a customer who is likely to churn, you can penalize that miss 100 times more than if the algorithm says a customer will churn when they will not by assigning a weight of 100 to churned customers and a weight of 1 to customers who did not churn. This will train a model that excels at not missing customers who will turnover, although it will have many false positives as well.</p></li>
				<li>Become familiar with all of the different AutoML configuration options for classification. You can find them at this link: <a href="https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py">https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py</a>.</li>
				<li>If your target column has a ratio of more than 20 to 1, it is a good idea to either collect more data from the smaller class or resample your data to achieve the 20 to 1 ratio.</li>
				<li>Research the five different primary metrics to understand which metrics fit your problem best. Classification requires a much more nuanced understanding of the business problem to make a wise metric selection.</li>
				<li>Use <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml</a> to understand what a good classification model looks like. Confusion<a id="_idIndexMarker265"/> matrices are particularly valuable in determining whether your model is better at predicting one class over another. Depending on your business use case, this may or may not be a problem.</li>
				<li>Go to <strong class="bold">Experiments</strong> under <strong class="bold">Assets</strong> in AML studio, click your experiment name, select <strong class="bold">Run ID</strong>, click the <strong class="bold">Models</strong> tab, select the highest-performing algorithm, and click the <strong class="bold">Metrics</strong> tab. This will provide you with all of the different metrics and charts necessary to evaluate your algorithm.</li>
				<li>Explore using the <strong class="source-inline">weight_column_name</strong> configuration option to weigh your data. It is important you understand how this works. If some observations are more important to get right than others, you should always assign a higher weight to those observations.<p>This is particularly important with classification models because, as mentioned before, some observations are almost always more important than others. Try assigning <strong class="source-inline">0.1</strong> to survivors and <strong class="source-inline">1</strong> to victims using the <strong class="source-inline">Titanic</strong> data and build a model. Then, try the opposite.</p></li>
				<li><strong class="bold">Overfitting</strong>, where you produce a very good model that doesn't generalize to new datapoints, is as much a problem in classification as it is in regression. If this happens to you, try adding more historical data or removing columns from your dataset. If your target column has more than 2 classes, try binning it to create a simple model less prone to overfitting.</li>
				<li>Be on the lookout for model bias with classification problems. <strong class="bold">Bias</strong> can occur when your model sacrifices performance in one class for another class. The worst bias occurs when the model only predicts a single class, for example, always predicting that a Titanic passenger perished. These models can occasionally be highly accurate due to class imbalance. With the Titanic data, such a model would be 61.6% accurate.</li>
				<li>When dealing with large datasets, the size of your compute instance doesn't matter, but the size of<a id="_idIndexMarker266"/> your compute cluster matters a lot. This is because your compute instance is only for writing and submitting code, while the AutoML training job runs remotely on the compute cluster. It's important that you train your AutoML with appropriately sized <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>).</li>
				<li>The size of the VMs on your compute cluster should be determined by the size of your dataset used for training. Roughly speaking, the RAM of your VM should be 20 times as large as the size of the data you are training in uncompressed CSV format, or twice as large as the size of the data you are training while in a pandas DataFrame. This is because CSV files grow up to 10 times in size when converted into a DataFrame. This guarantees a smooth run.<p>For example, if your base CSV file is 5 GB in size, then the RAM of each VM on your compute cluster should be at least 100 GB. In contrast, if your data is 5 GB in size after being converted into a pandas DataFrame, then you only require VMs with 10 GB of RAM.</p></li>
				<li><strong class="source-inline">AutoMLConfig</strong> has many options that you should familiarize yourself with. One such option is <strong class="source-inline">max_cores_per_iteration</strong>. Set this to <strong class="source-inline">-1</strong> so that each model training run fully utilizes all the cores on each VM, giving you a little more processing power.</li>
				<li>You can train AutoML models in parallel through another <strong class="source-inline">AutoMLConfig</strong> option called <strong class="source-inline">max_concurrent_iterations</strong>. This determines how many models AutoML trains in parallel. Set this to the maximum number of nodes on your compute cluster. If you have 8 nodes on your compute cluster and set <strong class="source-inline">max_concurrent_iterations</strong> to <strong class="source-inline">8</strong>, then AutoML will train 8 models at a time.</li>
			</ul>
			<p>These are just a few of the many ways you can fine-tune a classification model with AutoML. You can learn more techniques by reading scientific articles on machine learning, blog posts, and how-to guides. Of course, nothing beats experience.</p>
			<p>Try downloading as many open source classification datasets as you can find, load them into Azure, and use <a id="_idIndexMarker267"/>them to train and fine-tune AutoML models. With experience comes wisdom, and with wisdom comes the ability to solve even the toughest business problems with automated machine learning techniques. Learning the details about AutoML's classification algorithms is also important for you to develop your data science knowledge.</p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor079"/>Understanding AutoML classification algorithms</h2>
			<p>Many of the algorithms <a id="_idIndexMarker268"/>used by AutoML for classification are identical to the ones used by AutoML for regression. Like regression, certain algorithms perform better in certain situations. Unlike regression, AutoML uses <a id="_idIndexMarker269"/>a greater<a id="_idIndexMarker270"/> variety of algorithms for classification<a id="_idIndexMarker271"/> including <a id="_idIndexMarker272"/>neural networks.</p>
			<p>The <strong class="bold">tree</strong>, <strong class="bold">gradient boosting</strong>, and <strong class="bold">nearest neighbor</strong> algorithms used by AutoML for classification are identical to the ones used for regression, and you can review them in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>. The only difference is that the classification versions <a id="_idIndexMarker273"/>predict probabilities instead of values. <strong class="bold">Stochastic gradient descent</strong> (<strong class="bold">SGD</strong>) is also used by AutoML for classification. Unique to classification are logistic regression, naïve Bayes, averaged perceptron classifier, and three different algorithms that use <strong class="bold">support vector machines</strong> (<strong class="bold">SVM</strong>).</p>
			<p><strong class="bold">Logistic regression</strong> uses a <a id="_idIndexMarker274"/>logistic function, an s-shaped sigmoid curve, to model the probability that your data belongs to a certain class. Despite its name, it is unrelated to regression. Like elastic net for regression, logistic regression uses <strong class="bold">L1</strong> (<strong class="bold">lasso</strong>) and <strong class="bold">L2</strong> (<strong class="bold">ridge</strong>) regularization to create simpler models by adjusting the coefficients of your input variables. Logistic regression is simple and easy to use, but it doesn't do well with small datasets or when your data has nonlinear relationships.</p>
			<p><strong class="bold">Naïve Bayes</strong> is another simple classification algorithm. It uses Bayes' theorem to calculate the probability of a class given each input feature in a row of your data. It then weighs each input feature equally when deciding the class. It's naïve in that it assumes that input features are independent of each other. Naïve Bayes performs well even with small data, but its chief assumption of independence is almost always violated in real life.</p>
			<p><strong class="bold">Averaged perceptron classifier</strong> is a simple <a id="_idIndexMarker275"/>type of <strong class="bold">neural network</strong> that uses a system of weights and linear functions to make its predictions. Like logistic regression, it's best suited to datasets with linear relationships between your input variable and target column. It's only used for binary classification.</p>
			<p><strong class="bold">Support vector algorithms</strong> classify data by drawing dividing among hyperplanes of data. Imagine visualizing your data in an n-dimensional space where n is the number of your input columns. SVM works by finding the lines that divide your data best. They work for both linear <a id="_idIndexMarker276"/>and non-linear data, even for high-dimensional data. AutoML uses three of these algorithms: <strong class="bold">support vector classification</strong> (<strong class="bold">SVC</strong>), linear<a id="_idIndexMarker277"/> SVC, and linear SVM classifier.</p>
			<p>SVC is a standard implementation of support vector machines that works for both multiclass and binary classification problems. Linear SVC is an implementation that divides data linearly as opposed to SVC, which can divide data using nonlinear kernel functions. Linear SVM classifier, on the other hand, is similar to linear SVC but can only be used for binary classification.</p>
			<p>A summary of the 14 algorithms is provided in the following table:</p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B16595_5_11.jpg" alt="Figure 5.11 – AutoML classification algorithms "/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.11 – AutoML classification algorithms</p>
			<p>Like regression, AutoML performs <strong class="bold">model ensembling</strong> at the end of each AutoML training run. <strong class="bold">Voting ensembles</strong> take the weighted average of predicted class probabilities and use that to predict the class of an individual row of input data. <strong class="bold">Stack ensembles</strong>, in contrast, train a logistic regression model using the output of other models. Usually, one of these<a id="_idIndexMarker278"/> two ensemble models will be your best model.</p>
			<p>For more information on these models, please consult the AutoML documentation found at <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings</a>.</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor080"/>Summary</h1>
			<p>You have added to your repertoire by successfully training a classification model using the AML Python SDK. You have loaded in data, heavily transformed it using pandas and Numpy, and built a toy AutoML model. You then registered that model to your AMLS workspace.</p>
			<p>You can now start building classification models with your own data. You can easily solve both binary and multiclass classification problems, and you can present results to the business in a way they understand with confusion matrices. Many of the most common business problems, such as customer churn, are classification problems, and with the knowledge you learned in this chapter, you can solve those problems and earn trust and respect in your organization.</p>
			<p>The next chapter, <a href="B16595_06_ePub.xhtml#_idTextAnchor081"><em class="italic">Chapter 6</em></a><em class="italic">, Building an AutoML Forecasting Solution</em>, will be vastly different from the previous two chapters. Forecasting problems have many more settings to use and understand compared to classification and regression problems, and they always require you to have a deeper understanding of your dataset. Novice data scientists also make many mistakes when training such models, and AutoML will enable you to avoid all of them.</p>
		</div>
</body></html>