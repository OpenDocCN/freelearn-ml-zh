["```py\n    !pip install aws-fortuna\n    ```", "```py\n    from sklearn.datasets import fetch_openml\n    ```", "```py\n    bike_sharing = fetch_openml(\"Bike_Sharing_Demand\", version=2, as_frame=True, parser=\"pandas\")\n    ```", "```py\nm = NeuralProphet()\n```", "```py\ntrain_df, test_df = m.split_df(df, freq=\"H\", valid_p=1.0 / 16)\n```", "```py\nconfidence_lv = 0.9\n```", "```py\nquantile_list = [round(((1 - confidence_lv) / 2), 2), round((confidence_lv + (1 - confidence_lv) / 2), 2)]\n```", "```py\nqr_model = NeuralProphet(quantiles=quantile_list)\n```", "```py\nqr_model.set_plotting_backend(\"plotly-static\")\n```", "```py\nmetrics = qr_model.fit(df, freq=\"H\")\n```", "```py\nfuture = qr_model.make_future_dataframe(df, periods=30, n_historic_predictions=100)\n```", "```py\nforecast = qr_model.predict(df=future)\n```", "```py\ntrain_df, cal_df = m.split_df(train_df, freq=\"H\", valid_p=1.0 / 11)\n```", "```py\nn_lags = 3 * 24\n```", "```py\ncp_model1 = NeuralProphet(quantiles=quantile_list)\n```", "```py\ncp_model1.set_plotting_backend(\"plotly-static\")\n```", "```py\ncp_model2 = NeuralProphet(\n```", "```py\n    yearly_seasonality=False,\n```", "```py\n    weekly_seasonality=False,\n```", "```py\n    daily_seasonality=False,\n```", "```py\n    n_lags=n_lags,\n```", "```py\n    ar_layers=[32, 32, 32, 32],\n```", "```py\n    learning_rate=0.003,\n```", "```py\n    quantiles=quantile_list,\n```", "```py\n)\n```", "```py\ncp_model2.set_plotting_backend(\"plotly-static\")\n```", "```py\nset_random_seed(0)\n```", "```py\nmetrics1 = cp_model1.fit(train_df, freq=\"H\")\n```", "```py\nset_random_seed(0)\n```", "```py\nmetrics2 = cp_model2.fit(train_df, freq=\"H\")\n```", "```py\nforecast1 = cp_model1.predict(test_df)[n_lags:]\n```", "```py\nforecast2 = cp_model2.predict(test_df)[n_lags:]\n```", "```py\nMethod = \"\"aïve\"\n```", "```py\nalpha–= 1 - confidence_lv\n```", "```py\nnaïve_forecast1 = cp_model1.conformal_predict(\n```", "```py\n    test_df,\n```", "```py\n    calibration_df=cal_df,\n```", "```py\n    alpha=alpha,\n```", "```py\n    method=method,\n```", "```py\n    plotting_backend=\"plotly-static\",\n```", "```py\n    show_all_PI=naïvee,\n```", "```py\n)\n```", "```py\nnaive_forecast2 = cp_model2.conformal_predict(\n```", "```py\n    test_df,\n```", "```py\n    calibration_df=cal_df,\n```", "```py\n    alpha=alpha,\n```", "```py\n    method=method,\n```", "```py\n    plotting_backend\"\"plotly-static\",\n```", "```py\n    show_all_PI=True,\n```", "```py\n)\n```", "```py\nmethod = \"cqr\"\n```", "```py\ncqr_forecast1 = cp_model1.conformal_predict(\n```", "```py\n    test_df, calibration_df=cal_df, alpha=alpha, method=method, plotting_backend=\"plotly-static\"\n```", "```py\n)\n```", "```py\ncqr_forecast2 = cp_model2.conformal_predict(\n```", "```py\n    test_df, calibration_df=cal_df, alpha=alpha, method=method, plotting_backend=\"plotly-static\"\n```", "```py\n)\n```", "```py\n    !pip install git+https://github.com/Nixtla/statsforecast.git\n    ```", "```py\n    from statsforecast.models import SeasonalExponentialSmoothing, ADIDA, and ARIMA\n    ```", "```py\n    from statsforecast.utils import ConformalIntervals\n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\n    from statsforecast.models import (\n    ```", "```py\n        AutoETS,\n    ```", "```py\n        HistoricAverage,\n    ```", "```py\n        Naive,\n    ```", "```py\n        RandomWalkWithDrift,\n    ```", "```py\n        SeasonalNaive\n    ```", "```py\n    )\n    ```", "```py\n    train = pd.read_csv('https://auto-arima-results.s3.amazonaws.com/M4-Hourly.csv')\n    ```", "```py\n    test = pd.read_csv('https://auto-arima-results.s3.amazonaws.com/M4-Hourly-test.csv'\n    ```", "```py\n    n_series = 8\n    ```", "```py\n    uids = train['unique_id'].unique()[:n_series]\n    ```", "```py\n    train = train.query('unique_id in @uids')test = test.query('unique_id in @uids')\n    StatsForecast.plot(train, test, plot_random = False)\n    ```", "```py\n    models = [\n    ```", "```py\n        AutoETS(season_length=24),\n    ```", "```py\n        HistoricAverage(),\n    ```", "```py\n        Naive(),\n    ```", "```py\n        RandomWalkWithDrift(),\n    ```", "```py\n        SeasonalNaive(season_length=24)\n    ```", "```py\n    ]\n    ```", "```py\n        sf = StatsForecast(\n        ```", "```py\n            df=train,\n        ```", "```py\n            models=models,\n        ```", "```py\n            freq='H',\n        ```", "```py\n            n_jobs=-1\n        ```", "```py\n        )\n        ```", "```py\n        levels = [80, 90, 95, 99] # confidence levels of the prediction intervals\n        ```", "```py\n        forecasts = sf.forecast(h=48, level=levels)\n        ```", "```py\n        forecasts = forecasts.reset_index()\n        ```", "```py\n        forecasts.head()\n        ```", "```py\n    sf.plot(train, test, plot_random = False, models=['SeasonalNaive'], level=levels)\n    ```", "```py\nintervals = ConformalIntervals(h=24, n_windows=2)\n```", "```py\nmodels = [\n```", "```py\n   SeasonalExponentialSmoothing(season_length=24,alpha=0.1, prediction_intervals=intervals),\n```", "```py\n    ADIDA(prediction_intervals=intervals),\n```", "```py\n    ARIMA(order=(24,0,12), season_length=24, prediction_intervals=intervals),\n```", "```py\n]\n```", "```py\nsf = StatsForecast(\n```", "```py\n    df=train,\n```", "```py\n    models=models,\n```", "```py\n    freq='H',\n```", "```py\n)\n```", "```py\nlevels = [80, 90] # confidence levels of the prediction intervals\n```", "```py\nforecasts = sf.forecast(h=24, level=levels)\n```"]