- en: Temporal and Sequential Pattern Discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many of us have visited retail shops such as Reliance and Walmart for our household
    needs. Let's say that we are planning to buy an iPhoneX from Reliance Digital.
    What we would typically do is search for the model by visiting the mobile section
    of the store, and then select the product and head toward the billing counter.
  prefs: []
  type: TYPE_NORMAL
- en: But, in today's world, the goal of the organization is to increase revenue.
    Can this be done by pitching just one product at a time to the customer? The answer
    is a clear **no**. Hence, organizations began mining data relating to frequently
    bought items. They try to find out associations between different items and products
    that can be sold together, which gives assisting in right product placement. Typically,
    it figures out what products are being bought together and organizations can place
    products in a similar manner.
  prefs: []
  type: TYPE_NORMAL
- en: This is what we are going to talk about in this chapter. How do we come up with
    such rules by means of machine learning? We will discuss number of techniques
    here.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Association rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequent pattern growth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Association rules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Association rule mining is a technique that focuses upon observing frequently
    occurring patterns and associations from datasets found in databases such as relational
    and transactional databases. These rules do not say anything about the preferences
    of an individual; rather, they rely chiefly on the items within transactions to
    deduce a certain association. Every transaction is identified by a primary key
    (distinct ID) called, **transaction ID**. All these transactions are studied as
    a group and patterns are mined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Association rules can be thought of as an **if—then** relationship. Just to
    elaborate on that, we have to come up with a rule: **if** an item **A** is being
    bought by the customer, **then** the chances of item **B** being picked by the
    customer too under the same transaction ID (along with item **A**) is found out.
    You needs to understand here that it''s not a causality, rather, it is co-occurrence
    pattern that comes to the fore.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two elements of these rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Antecedent (if)**: This is an item/group of items that are typically found
    in the itemsets or datasets'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consequent (then)**: This comes along as an item with an antecedent/group
    of antecedents'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Have a look at the following rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '*{Bread, milk} ⇒ {Butter}*'
  prefs: []
  type: TYPE_NORMAL
- en: The first part of this rule is called **antecedent** and the second part (after
    the arrow) is **consequent**. It is able to convey that there is a chance of *Butter* being
    picked in a transaction if *Bread* and  *Milk* are picked earlier. However, the
    percentage chance for the consequent to be present in an itemset, given the antecedent,
    is not clear.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at a few metrics that will help us in getting there:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support**: This is a measure of the frequency of the itemset in all the transactions.
    For example, there are two itemsets popping up through the number of transactions
    for a retail outlet such as Walmart: itemset *A = {Milk}*, itemset *B = {laptop}*.
    Given that support is how frequent the itemset is in all the transactions, we
    are asked to find out which itemset has got the higher support. We know that itemset
    *A* will have higher support because *Milk* features in everyday grocery lists
    (and, in turn, the transaction) at a greater probability than *laptop*. Let''s
    add another level of association and study with two new itemsets: itemset *A=
    {milk, cornflakes}*, itemset *B= {milk, USB Drive}*. The purchasing frequency
    of *milk* and *cornflakes* together will be higher than *milk and USB Drive*.
    It will make the support metric higher for *A*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s translate this into mathematics:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Support(A, B) = Transactions comprising A and B/Total number of transactions*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: The total number of transactions is 10,000
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Transactions comprising *A* and *B = 500*
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Then support *(A, B) = 500/10000= 0.05*
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 5% of transactions contain *A* and *B* together
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Confidence**: This indicates how likely item 1 is to be purchased/picked
    when item 2 is already picked. In other words, it measures the likelihood of the
    occurrence of consequent transactions given that the antecedent is already there
    in the transaction. In other words, it is the probability of the occurrence of
    *Butter* in the transaction if *Bread* has already been part of that transaction.
    It is quite clear that it is a conditional probability of the occurrence of the
    consequent while having the antecedent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Confidence(A ⇒ B) = Transactions comprising A and B/Transactions comprising
    A*'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Confidence can be transformed in terms of support*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Confidence(A ⇒ B) = Support(A, B)/Support(A)*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: Transactions with the itemset as *milk = 50*
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Transactions with the itemset as *cereal = 30*
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Transactions comprising *milk* and *cereal = 10*
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Total number of transactions = 100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Confidence(milk ⇒ Cereal) = 10/(50 +10) = 0.167*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It means that there is 16.7% probability of that event taking place.
  prefs: []
  type: TYPE_NORMAL
- en: A drawback of the confidence is it only accounts for how popular item 1 is,
    but not item 2\. If item 2 is equally frequent, there will be a higher chance
    that a transaction containing item 1 will also contain item 2\. Hence, it will
    result in an inflated outcome. To account for the frequency of both constituent
    items, we use a third measure called **lift**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Lift**: This is an indicator of how likely it is that item B will be picked
    in the cart/transaction, given that item *A* is already picked, while keeping
    a tab on the frequency of item *B.* A lift value greater than 1 says that there
    is a great association between item *A* and item *B,* which implies that there
    is a good chance that item *B* will be picked if item *A* is already in the cart.
    A lift value of less than 1 means that the chances are slim that item *B* will
    be picked if item *A* is already present. If the lift value hits zero, it means
    no association can be established here.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Lift(A⇒B) = (Transactions comprising A and B/(Transactions comprising A))/fraction
    of Transaction comprising B*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implies:'
  prefs: []
  type: TYPE_NORMAL
- en: '*= Support(A, B)/(Support(A) * Support(B))*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Lift(milk⇒cereal) = ( 10/(50+10))/0.4*'
  prefs: []
  type: TYPE_NORMAL
- en: '*= 0.416*'
  prefs: []
  type: TYPE_NORMAL
- en: We will see this in a better format here. The probability of having cereal in
    the cart with the knowledge that milk is already in the cart (which is called
    **confidence**) = *10/(50+10) = 0.167.*
  prefs: []
  type: TYPE_NORMAL
- en: The probability of having cereal in the cart without the knowledge that milk
    is in the *cart = (30+10)/100 = 0.4*.
  prefs: []
  type: TYPE_NORMAL
- en: It means that having knowledge that milk is already in the cart reduces the
    chance of picking cereal from *0.4* to *0.167*. It is a lift of *0.167/0.4= 0.416*
    and is less than *1*. Hence, the chances of picking cereal while milk is already
    in the cart are very small.
  prefs: []
  type: TYPE_NORMAL
- en: Apriori algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apriori is a classical algorithm that is used to mine frequent itemsets to derive
    various association rules. It will help set up a retail store in a much better
    way, which will aid revenue generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The anti-monotonicity of the support measure is one of the prime concepts around
    which Apriori revolves. It assumes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: All subsets of a frequent itemset must be frequent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, for any infrequent itemset, all its supersets must be infrequent
    too
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at an example and explain it:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Transaction ID** | **Milk** | **Butter** | **Cereal** | **Bread** | **Book**
    |'
  prefs: []
  type: TYPE_TB
- en: '| t1 | 1 | 1 | 1 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| t2 | 0 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| t3 | 0 | 0 | 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| t4 | 1 | 1 | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| t5 | 1 | 1 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| t6 | 1 | 1 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: We have got the transaction ID and items such as milk, butter, cereal, bread,
    and book. 1 denotes that item is part of the transaction and 0 means that it is
    not.
  prefs: []
  type: TYPE_NORMAL
- en: 'We came up with a frequency table for all the items along, with support (division
    by 6):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| **Items** | **Number of transactions** | **Support** |'
  prefs: []
  type: TYPE_TB
- en: '| Milk | 4 | 67% |'
  prefs: []
  type: TYPE_TB
- en: '| Butter | 5 | 83% |'
  prefs: []
  type: TYPE_TB
- en: '| Cereal | 4 | 67% |'
  prefs: []
  type: TYPE_TB
- en: '| Bread | 4 | 67% |'
  prefs: []
  type: TYPE_TB
- en: '| Book | 3 | 50% |'
  prefs: []
  type: TYPE_TB
- en: 'We will put a threshold of support at 60%, which will filter out the items
    by frequency as these are the ones that can be addressed as frequent itemsets
    in this scenario:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| **Items** | **Number of transactions** |'
  prefs: []
  type: TYPE_TB
- en: '| Milk | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Butter | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| Cereal | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Bread | 4 |'
  prefs: []
  type: TYPE_TB
- en: 'Similarly, we form the number of combinations (two at a time, three at a time,
    and four at a time) with these items and find out frequencies:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| **Items** | **Number of transactions** |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Butter | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Cereal | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Bread | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Butter, Bread | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Butter, Cereal | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Cereal, Bread | 2 |'
  prefs: []
  type: TYPE_TB
- en: Now, again, we have to find out the support for the preceding examples and filter
    them by threshold, which is support at 60%
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the combinations have to be formed with three items at a time (for
    example, Milk, Butter, and Bread) and support needs to be calculated for them.
    And, finally, we will filter them out by threshold. The same process needs to
    be done by doing four items at a time. The step that we have done till now is
    called **frequent itemset generation**.
  prefs: []
  type: TYPE_NORMAL
- en: Finding association rules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to find the association rules, we have to first search for all of
    the rules that have support greater than the threshold support. But the question
    arises: how do we find these? A possible way to find this is by brute force, which
    means to list all the possible association rules and calculate the support and
    confidence for each rule. Later, remove all the rules that fail the confidence
    and support thresholds.'
  prefs: []
  type: TYPE_NORMAL
- en: Given there are *n* items in the set* I*, the total number of possible association
    rules is *3^n - 2^(n+1) + 1*.
  prefs: []
  type: TYPE_NORMAL
- en: If *X* is a frequent itemset with *k* elements, then there are *2^k - 2* association
    rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how to execute association rules in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If we are asking for an item to appear three times in a day for seven days''
    time, the support will be *3 x 7/7051*. *7051* is the total number of transactions.
    We will keep the confidence as 20% in the beginning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the output by running the `results` command from the preceding
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fc03af0b-27fb-4b45-b579-87be6c9ecb77.png)'
  prefs: []
  type: TYPE_IMG
- en: Frequent pattern growth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Frequent pattern growth** (**FP-growth**) is a frequent itemset generation
    technique (similar to Apriori). FP-Growth builds a compact-tree structure and
    uses the tree for frequent itemset mining and generating rules. It is faster than
    Apriori and can throw results with large datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go through the steps of FP-Growth:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting up the transactions**: This step sets up the items by frequency.
    However, the items are set up vertically, not horizontally. That means transforming
    input from transaction to items:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **t_id** | **Items** |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | (B, C, D, A) |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | (B, C, D) |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | (D, A) |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | (A, B) |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | (A, C, B) |'
  prefs: []
  type: TYPE_TB
- en: '**Finding the frequency**: Now we have to find out the frequency of each item
    individually:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **Items** | **Frequency** |'
  prefs: []
  type: TYPE_TB
- en: '| A | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| B | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| C | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| D | 3 |'
  prefs: []
  type: TYPE_TB
- en: 'Let''s set up the minimum threshold or minimum support as 50%:'
  prefs: []
  type: TYPE_NORMAL
- en: Min Support = (5*50/100) = 2.5
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Ceiling of minimum support = 2.5 ~ 3
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prioritize the items by frequency**: Since all the items have a frequency
    greater than or equal to minimum support, all the items will be part of it. Also,
    based on their frequency, priority or rank will be assigned to the items:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **Items** | **Frequency** | **Rank** |'
  prefs: []
  type: TYPE_TB
- en: '| A | 4 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| B | 4 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| C | 3 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| D | 3 | 4 |'
  prefs: []
  type: TYPE_TB
- en: 'The order of the items is: A, B, C, and D (by frequency in descending order)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ordering the items by priority**: Now the order of items will be set according
    to the priority given to various items based on frequency. Currently, the order
    is A, B, C, and D:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **t_id** | **Items** | **Order by priority** |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | (B, C, D, A) | (A, B, C, D) |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | (B, C, D) | (B, C, D) |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | (D, A) | (A, D) |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | (A, B) | (A, B) |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | (A, C, B) | (A, B, C) |'
  prefs: []
  type: TYPE_TB
- en: Frequent pattern tree growth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will study the different frequent pattern tree growth from the following
    rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Row 1**: Every FP-Tree starts with a null node as a root node. Let''s draw
    the first row of the tree order along with their frequency:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/6018c3aa-74dd-46d3-97ba-c8cfb4792d04.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Row 2**: It has got *{B,C,D}*. *A* is missing, so we can not merge it with
    the earlier node. Hence, we will have to create another node, altogether as shown
    here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/64811bcc-9002-4203-a764-0e28f7b0d86b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Row 3**: It has got *{A,D}*. *B* and *C* are missing, but we can tie it with
    the earlier node. *A* encounters a repetition, so frequency will change. It becomes
    *2* now:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/7e0a0970-2717-4b76-ba4a-722a683fa292.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Row 4**: It has got *{A,B}*. We can tie it with the earlier node and will
    traverse on the previous node. *A* and *B* encounters a repetition, so frequency
    will change for it. It becomes 3 and 2 respectively:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/bbb3d66b-ce39-4fff-bcdf-9af564cfb132.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Row 5**: It has got *{A,B,C}*. Again, it can be tied with the earlier node
    and A, B, and C see a repetition, so the frequency will change for them. It becomes
    4, 3, and 2 respectively:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/53cfa7ef-1d4e-48a0-83bc-52cf57af72bc.png)'
  prefs: []
  type: TYPE_IMG
- en: Validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s count the frequency of the final tree that we have got and compare
    the frequency of each item with the table to ensure that we have got the correct
    frequencies in the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A:4**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**B:4**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C:3**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D:3**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now we will go from bottom to top. We will find out the branches where D appears:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/613380ab-1fe4-4529-8db5-b1527163ee34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that there are three branches where D appears:'
  prefs: []
  type: TYPE_NORMAL
- en: 'BC: 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ABC: 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A: 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These branches are termed as conditional pattern base for D. While we do this,
    there are points to be kept in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Even if we traverse from bottom to top, we write the branches in a top-to-bottom
    manner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: D is not part of it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 represents the frequency of occurrence of D in each branch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, the conditional pattern for D results in the conditional frequencies for
    A, B, and C, which are 2, 2, and 2\. All are less than the minimum support (3).
    Hence, there can't be any conditional FP- Tree for it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s do it for C. C is appears in the following branches:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c42a910a-7183-4359-a62e-77209960285c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The branches end up like this:'
  prefs: []
  type: TYPE_NORMAL
- en: B:1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AB:2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It results in A:2 and B:3\. So, B fit with the bill in accordance with the
    minimum support. Now the conditional tree ends up like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ede86a39-0990-469c-96e9-89dac495cb1b.png)'
  prefs: []
  type: TYPE_IMG
- en: Similarly, conditional pattern finding is done for different combinations. Thus,
    it sets up the frequent item dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how it can be done in Python. We will be using a library called `pyfpgrowth`.
    Also, we shall create an itemset in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Importing the library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to perform validation we will import the library and build the transactions
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We build our transactions like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Minimum support is defined now to find the pattern. `find_frequent_patterns()`*,*
    where `transactions` are the list of items bought at each transaction, and `2`
    is the minimum threshold set for support count:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have to define the confidence to get the rules. Rules are generated
    based on the patterns and `0.5` is the minimum threshold set for confidence. Then,
    we store the rules in a dataframe named `rules`. `rules` initially consists of
    an antecedent, a consequent, and the confidence value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af558284-73fa-4c72-a90e-b8fcf6389188.png)'
  prefs: []
  type: TYPE_IMG
- en: This is how we get the rules. FP-growth tends to have the edge over Apriori
    as it is faster and more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have studied association rules. We also discussed the Apriori
    algorithm, which is used for mining frequent itemsets to derive various association
    rules. We also learned about frequent pattern growth (FP-growth), which is similar
    to Apriori and about the frequent itemset generation technique, which is similar
    to the Apriori algorithm. Finally, we saw how FP-growth tends to have an edge
    over Apriori, as it is faster and more efficient, using an example.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will study probabilistic graphical models. We will learn
    in depth about the Bayesian rules and Bayesian networks.
  prefs: []
  type: TYPE_NORMAL
