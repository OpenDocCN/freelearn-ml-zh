- en: Seeing a Heartbeat with a Motion-Amplifying Camera
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用运动放大相机看到心跳
- en: '"Remove everything that has no relevance to the story. If you say in the first
    chapter that there is a rifle hanging on the wall, in the second or third chapter
    it absolutely must go off. If it''s not going to be fired, it shouldn''t be hanging
    there."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “移除所有与故事无关的东西。如果你在第一章中说墙上挂着一支枪，在第二章或第三章它绝对必须开火。如果它不会开火，它就不应该挂在那里。”
- en: – Anton Chekhov
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: – 安东·契诃夫
- en: '"King Julian: I don''t know why the sacrifice didn''t work. The science seemed
    so solid."'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: “朱利安国王：我不知道为什么牺牲没有奏效。科学看起来是如此稳固。”
- en: '– Madagascar: Escape 2 Africa (2008)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: – 《马达加斯加：逃往非洲》（2008）
- en: Despite their strange design and mysterious engineering, Q's gadgets always
    prove useful and reliable. Bond has such faith in the technology that he never
    even asks how to charge the batteries.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们的设计奇特，工程神秘，但Q的小玩意儿总是证明是有用和可靠的。邦德对这项技术如此有信心，以至于他甚至从未询问过如何充电。
- en: 'One of the more inventive ideas in the Bond franchise is that even a lightly
    equipped spy should be able to see and photograph concealed objects, anyplace,
    anytime. Let''s consider a timeline of a few relevant gadgets in the movies, as
    follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在邦德系列电影中，更有创意的想法之一是，即使是一个装备轻的间谍也应该能够随时随地看到并拍摄隐藏的物体。让我们考虑一下电影中一些相关小工具的时间线，如下所示：
- en: '**1967 (*You Only Live Twice*)**: An X-ray desk scans guests for hidden firearms.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1967（《你只能活两次》)**：X光桌扫描客人以寻找隐藏的枪支。'
- en: '**1979 (*Moonraker*)**: A cigarette case contains an X-ray imaging system that
    is used to reveal the tumblers of a safe''s combination lock.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1979（《月亮上的火箭》)**：一个烟盒里含有一个用于揭示保险箱组合锁转轴的X光成像系统。'
- en: '**1989 (*License to Kill*)**: A Polaroid camera takes X-ray photos. Oddly enough,
    its flash is a visible, red laser.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1989（《杀手执照》)**：一台宝丽来相机拍摄X光照片。奇怪的是，它的闪光灯是一个可见的红激光。'
- en: '**1995 (*GoldenEye*)**: A tea tray contains an X-ray scanner that can photograph
    documents beneath the tray.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1995（《黄金眼》)**：一个茶盘里含有一个X光扫描仪，可以拍摄茶盘下的文件。'
- en: '**1999 (*The World is Not Enough*)**: Bond wears a stylish pair of blue-lensed
    glasses that can see through one layer of clothing to reveal concealed weapons.
    According to the *James Bond Encyclopedia* (2007), which is an official guide
    to the movies, the glasses display infrared video after applying special processing
    to them. Despite using infrared, they are commonly called **X-ray specs**, a misnomer.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1999（《世界末日》)**：邦德戴了一副时尚的蓝色镜片的太阳镜，可以穿透一层衣物看到隐藏的武器。根据《詹姆斯·邦德百科全书》（2007年），这是一本官方的电影指南，眼镜在经过特殊处理后可以显示红外视频。尽管使用红外线，但它们通常被称为**X光眼镜**，这是一个误称。'
- en: These gadgets deal with unseen wavelengths of light (or radiation) and are broadly
    comparable to real-world devices such as airport security scanners and night-vision
    goggles. However, it remains difficult to explain how Bond's equipment is so compact
    and how it takes such clear pictures under diverse lighting conditions and through
    diverse materials. Moreover, if Bond's devices are active scanners (meaning they
    emit X-ray radiation or infrared light), they will be clearly visible to other
    spies using similar hardware.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些小玩意儿处理的是未知的可见光波长（或辐射），并且与机场安检仪和夜视镜等现实世界设备广泛可比。然而，解释邦德的设备为何如此紧凑，以及它如何在不同的光照条件下和通过不同的材料拍摄出如此清晰的图片仍然很困难。此外，如果邦德的设备是主动扫描仪（意味着它们会发射X射线辐射或红外光），它们将清楚地被使用类似硬件的其他间谍看到。
- en: To take another approach, what if we avoid unseen wavelengths of light but instead
    focus on unseen frequencies of motion? Many things move in a pattern that is too
    fast or too slow for us to easily notice. Suppose a man is standing in one place.
    If he shifts one leg more than the other, perhaps he is concealing a heavy object,
    such as a gun, on the side that he shifts more. Equally, we might also fail to
    notice deviations from a pattern; suppose the same man has been looking straight
    ahead but suddenly, when he believes no one is looking, his eyes dart to one side.
    Is he watching someone?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 采用另一种方法，如果我们避免未知的可见光波长，而是专注于未知的运动频率呢？许多事物以我们难以轻易察觉的过快或过慢的节奏移动。假设有一个人站在一个地方。如果他的一条腿比另一条腿移动得多，也许他在移动更多的一侧隐藏着一个重物，比如一把枪。同样，我们也可能没有注意到偏离模式的偏差；假设同一个人一直在直视前方，但突然，当他认为没有人注意时，他的目光突然转向一侧。他在看某人吗？
- en: We can make motions of a certain frequency more visible by repeating them, like
    a delayed afterimage or a ghost, with each repetition appearing fainter (or less
    opaque) than the last. The effect is analogous to an echo or a ripple and is achieved
    using an algorithm called **Eulerian video magnification**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过重复某些频率的运动使其更加明显，就像延迟的视觉残留或幽灵一样，每次重复出现的亮度（或不透明度）都比上一次更弱。这种效果类似于回声或涟漪，并且是通过一种称为**欧拉视频放大**的算法实现的。
- en: By applying this technique, we will build a desktop app that allows us to simultaneously
    see the present and selected slices of the past. The idea of experiencing multiple
    images simultaneously is, to me, quite natural because, for the first 26 years
    of my life, I had **strabismus**—commonly called a **lazy eye**—which caused double
    vision. A surgeon corrected my eyesight and gave me depth perception but in memory
    of strabismus, I would like to name this application `Lazy Eyes`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用这项技术，我们将构建一个桌面应用程序，使我们能够同时看到现在的和过去选定的切片。对我来说，同时体验多个图像的想法相当自然，因为在我的前 26 年生活中，我患有**斜视**——通常被称为**懒眼**——这导致了我有双重视力。一位外科医生纠正了我的视力并给了我深度感知，但为了纪念斜视，我想将这个应用程序命名为
    `Lazy Eyes`。
- en: Let's take a closer look, or two or more closer looks, at the fast-paced, moving
    world that we share with other secret agents.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看，或者看两眼或更多，我们与其他秘密特工共享的快节奏、动态的世界。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding what Eulerian video magnification can do
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解欧拉视频放大能做什么
- en: Extracting repeating signals from video using the fast Fourier transform
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用快速傅里叶变换从视频中提取重复的信号
- en: Compositing two images using image pyramids
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图像金字塔合成两个图像
- en: Implementing the Lazy Eyes app
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现 Lazy Eyes 应用程序
- en: Configuring and testing the app for various motions
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置和测试应用程序以支持各种运动
- en: Technical requirements
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter''s project has the following software dependencies:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的项目有以下软件依赖项：
- en: '**A Python environment with the following modules**: OpenCV, NumPy, SciPy,
    PyFFTW, wxPython'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**具有以下模块的 Python 环境**：OpenCV, NumPy, SciPy, PyFFTW, wxPython'
- en: Where not otherwise noted, setup instructions are covered in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml),
    *Preparing for the Mission*. Setup instructions for PyFFTW are covered in the
    current chapter, in the section *Choosing and setting up an FFT library*. Always
    refer to the setup instructions for any version requirements. Basic instructions
    for running Python code are covered in [Appendix C](c44b1aaa-fe12-4054-85fb-37d584f15d3b.xhtml),
    *Running with Snakes (or, First Steps with Python)*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有特别说明，设置说明包含在[第 1 章](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml)，*准备任务*中。PyFFTW
    的设置说明包含在本章的*选择和设置 FFT 库*部分。始终参考设置说明以了解任何版本要求。运行 Python 代码的基本说明包含在[附录 C](c44b1aaa-fe12-4054-85fb-37d584f15d3b.xhtml)，*与
    Python 一起运行（或，Python 的第一步)*中。
- en: The complete project for this chapter can be found in this book's GitHub repository,
    [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition),
    in the `Chapter007` folder.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的完整项目可以在本书的 GitHub 仓库中找到，[https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition)，在
    `Chapter007` 文件夹中。
- en: Planning the Lazy Eyes app
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规划 Lazy Eyes 应用程序
- en: 'Of all our apps, `Lazy Eyes` has the simplest user interface. It just shows
    a live video feed with a special effect that highlights motion. The parameters
    of the effect are quite complex and, moreover, modifying them at runtime would
    have a big effect on performance. Thus, we do not provide a user interface to
    reconfigure the effect, but we do provide many parameters in code to allow a programmer
    to create many variants of the effect and the app. Below the video panel, the
    app displays the current frame rate, measured in **frames per second** (**FPS**).
    The following screenshot illustrates one configuration of the app. This screenshot
    shows me eating cake. Because my hands and face are moving, we see an effect that
    looks like light and dark waves rippling near moving edges (the effect is more
    graceful in a live video than in a screenshot):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们所有的应用中，`Lazy Eyes` 的用户界面最为简单。它只显示带有特殊效果的实时视频流，该效果突出显示运动。该效果参数相当复杂，而且，在运行时修改它们会对性能产生重大影响。因此，我们不提供用户界面来重新配置效果，但我们在代码中提供了许多参数，以便程序员创建效果和应用的多种变体。在视频面板下方，应用显示当前帧率，以每秒帧数（**FPS**）为单位。以下截图展示了应用的一种配置。这张截图显示我正在吃蛋糕。因为我的手和脸在动，所以我们看到一种类似光和暗波在移动边缘附近波动的效果（在实时视频中，这种效果比截图中的效果更加优雅）：
- en: '![](img/14bb7071-cc2e-424e-8fc3-42809889ee68.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/14bb7071-cc2e-424e-8fc3-42809889ee68.png)'
- en: For more screenshots and an in-depth discussion of the parameters, see the *Configuring
    and testing the app for various motions *section later in this chapter.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更多截图和参数的深入讨论，请参阅本章后面的 *配置和测试应用以适应各种运动* 部分。
- en: 'Regardless of how it is configured, the app loops through the following actions:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 不论如何配置，应用都会循环执行以下操作：
- en: Capture an image.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 捕获一张图像。
- en: Copy and downsample the image while applying a blur filter and, optionally,
    an edge-finding filter. We will downsample using so-called **image pyramids**,
    which will be discussed in the *Compositing two images using image pyramids* section
    later in this chapter. The purpose of downsampling is to achieve a higher frame
    rate by reducing the amount of image data that's used in subsequent operations.
    The purpose of applying a blur filter and, optionally, an edge-finding filter
    is to create halos that are useful in amplifying motion.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用模糊滤镜和可选的边缘检测滤镜的同时，复制并下采样图像。我们将使用所谓的**图像金字塔**进行下采样，这将在本章后面的 *使用图像金字塔合成两张图像*
    部分讨论。下采样的目的是通过减少后续操作中使用的图像数据量来提高帧率。应用模糊滤镜和可选的边缘检测滤镜的目的是创建有助于放大运动的光晕。
- en: Store the downsampled copy in a history of frames, with a timestamp. The history
    has a fixed capacity. Once it is full, the oldest frame is overwritten to make
    room for the new one.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将下采样副本存储在带有时间戳的帧历史记录中。历史记录具有固定容量。一旦满载，最旧的帧将被覆盖，为新帧腾出空间。
- en: If the history is not yet full, continue to the next iteration of the loop.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果历史记录尚未满载，则继续循环的下一迭代。
- en: Calculate and display the average frame rate based on the timestamps of the
    frames in the history.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据历史记录中帧的时间戳计算并显示平均帧率。
- en: Decompose the history into a list of frequencies describing fluctuations (motion)
    at each pixel. The decomposition function is called a **fast Fourier transform**
    (**FFT**). We will discuss it in the*Extracting repeating signals from video using
    the fast Fourier transform *section later in this chapter.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将历史记录分解成描述每个像素处波动（运动）的频率列表。这个分解函数被称为**快速傅里叶变换**（**FFT**）。我们将在本章后面的 *使用快速傅里叶变换从视频中提取重复信号*
    部分讨论它。
- en: Set all frequencies to zero except a chosen range of interest. In other words,
    filter out the data on motions that are faster or slower than certain thresholds.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有频率设置为零，除了一个感兴趣的频率范围。换句话说，过滤掉比某些阈值快或慢的运动数据。
- en: Recompose the filtered frequencies into a series of images that are motion maps.
    Areas that are still (with respect to our chosen range of frequencies) become
    dark, and areas that are moving remain bright. The `recomposition` function is
    called an **inverse fast Fourier transform** (**IFFT**), which we will discuss
    later.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将过滤后的频率重新组合成一系列图像，这些图像是运动图。相对于我们选择的频率范围而言，静止区域变暗，而移动区域保持明亮。这个“重新组合”函数被称为**逆快速傅里叶变换**（**IFFT**），我们将在后面的章节中讨论。
- en: Upsample the latest motion map (again, using image pyramids), intensify it,
    and overlay it additively atop the original camera image.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次使用图像金字塔提升最新运动图的分辨率，增强其亮度，并将其以叠加方式覆盖在原始相机图像之上。
- en: Show the resulting composite image.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展示结果合成图像。
- en: That's it—a simple plan that requires rather nuanced implementation and configuration.
    So, with that in mind, let's prepare ourselves by doing a little background research
    first.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样——一个需要相当细腻的实施和配置的简单计划。因此，考虑到这一点，让我们先做一些背景研究来做好准备。
- en: Understanding what Eulerian video magnification can do
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解欧拉视频放大的功能
- en: Eulerian video magnification is inspired by a model in fluid mechanics called
    **Eulerian specification of the flow field**. Let's consider a moving, fluid body,
    such as a river. The Eulerian specification describes the river's velocity at
    a given position and time. The velocity would be fast in the mountains in springtime
    and slow at the river's mouth in winter. The velocity would also be slower at
    a silt-saturated point at the river's bottom, compared to a point where the river's
    surface hits a rock and sprays. An alternative to the Eulerian specification is
    the **Lagrangian specification**, which describes the position of a given particle
    at a given time. For example, a given bit of silt might make its way down from
    the mountains to the river's mouth over a period of many years and then spend
    eons drifting around a tidal basin.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 欧拉视频放大是受到流体力学中一个称为**流场的欧拉规范**的模型的启发。让我们考虑一个移动的流体，比如一条河流。欧拉规范描述了河流在特定位置和时间的速度。在春天山区，速度会很快，而在冬天河流的入海口速度会慢。与河流表面撞击岩石并喷溅的点相比，河流底部淤泥饱和点的速度也会更慢。欧拉规范的另一种选择是**拉格朗日规范**，它描述了特定粒子在特定时间的位置。例如，一块特定的淤泥可能需要许多年才能从山区流到河流的入海口，然后在潮汐盆地漂泊数亿年。
- en: For a more formal description of the Eulerian specification, the Lagrangian
    specification, and their relationship, refer to the following Wikipedia article
    at [http://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field](http://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于欧拉规范、拉格朗日规范及其关系的更正式描述，请参考以下维基百科文章 [http://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field](http://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field)。
- en: The Lagrangian specification is analogous to many computer vision tasks in which
    we model the motion of a particular object or feature over time. However, the
    Eulerian specification is analogous to our current task, in which we model any
    motion occurring in a particular position and a particular window of time. Having
    modeled a motion from an Eulerian perspective, we can visually exaggerate the
    motion by overlaying the model's results for a blend of positions and times.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 拉格朗日规范类似于许多计算机视觉任务，在这些任务中，我们模拟特定对象或特征随时间的变化。然而，欧拉规范类似于我们当前的任务，在这个任务中，我们模拟在特定位置和特定时间窗口内发生的任何运动。从欧拉视角模拟了运动后，我们可以通过叠加模型在不同位置和时间的输出来直观地夸大运动。
- en: 'Let''s set a baseline for our expectations of Eulerian video magnification
    by studying other people''s projects, which include the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过研究其他人的项目，我们可以为欧拉视频放大的预期设定一个基准，这些项目包括以下内容：
- en: 'Michael Rubenstein''s webpage at MIT ([http://people.csail.mit.edu/mrub/vidmag/](http://people.csail.mit.edu/mrub/vidmag/)):
    Gives an abstract of his team''s pioneering work on Eulerian video magnification,
    along with demo videos.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 麻省理工学院迈克尔·鲁宾斯坦的网页（[http://people.csail.mit.edu/mrub/vidmag/](http://people.csail.mit.edu/mrub/vidmag/））：提供了他团队在欧拉视频放大方面的开创性工作的摘要，以及演示视频。
- en: 'Bryce Drennan''s eulerian-magnification library ([https://github.com/brycedrennan/eulerian-magnification](https://github.com/brycedrennan/eulerian-magnification)):
    Implements the algorithm using NumPy, SciPy, and OpenCV. This implementation is
    good inspiration for us, but is designed for processing prerecorded videos and
    is not sufficiently optimized for real-time input.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布赖斯·德雷南的欧拉放大库（[https://github.com/brycedrennan/eulerian-magnification](https://github.com/brycedrennan/eulerian-magnification)）：使用NumPy、SciPy和OpenCV实现算法。这个实现对我们来说是一个很好的灵感来源，但它是为处理预录制的视频而设计的，并且没有足够优化以适应实时输入。
- en: Now, let's move on and understand the functions that are the building blocks
    of these projects and ours.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续前进，了解构成这些项目和我们的项目的基石——函数。
- en: Extracting repeating signals from video using the fast Fourier transform
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用快速傅里叶变换从视频中提取重复信号
- en: An audio signal is typically visualized as a bar chart or wave. The bar or wave
    is high when the sound is loud and low when it is soft. We recognize that a repetitive
    sound, such as a metronome's beat, makes repetitive peaks and valleys in the visualization.
    When audio has multiple channels (such as a stereo or surround-sound recording),
    each channel can be considered a separate signal and can be visualized as a separate
    bar chart or wave.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 音频信号通常被可视化为一个条形图或波形。条形或波形在声音响亮时高，在声音柔和时低。我们认识到重复的声音，如节拍器的节拍，会在可视化中产生重复的峰值和谷值。当音频有多个通道（如立体声或环绕声录音）时，每个通道都可以被视为一个独立的信号，可以单独可视化为一个条形图或波形。
- en: Similarly, in a video, every channel of every pixel can be considered a separate
    signal, rising and falling (becoming brighter and dimmer) over time. Imagine that
    we use a stationary camera to capture a video of a metronome. In this case, certain
    pixel values will rise and fall at a regular interval as they capture the passage
    of the metronome's needle. If the camera has an attached microphone, its signal
    values will rise and fall at the same interval. Based on either the audio or the
    video, we can then measure the metronome's frequency—its **beats per minute**
    (**bpm**) or its beats per second (Hertz or Hz). Conversely, if we change the
    metronome's bpm setting, the effect on both the audio and the video will be predictable.
    From this thought experiment, we can learn that a signal—be it audio, video, or
    any other kind—can be expressed as a function of time and, *equivalently*, a function
    of frequency.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在视频中，每个像素的每个通道都可以被视为一个独立的信号，随时间上升和下降（变得更亮或更暗）。想象一下，我们使用一个静止的相机来捕捉节拍器的视频。在这种情况下，某些像素值将以固定的间隔上升和下降，因为它们捕捉节拍器针的移动。如果相机连接了一个麦克风，其信号值将以相同的间隔上升和下降。基于音频或视频，我们然后可以测量节拍器的频率——其**每分钟节拍数**（**bpm**）或其每秒节拍数（赫兹或Hz）。相反，如果我们改变节拍器的bpm设置，对音频和视频的影响将是可预测的。从这个思想实验中，我们可以了解到一个信号——无论是音频、视频还是任何其他类型的信号——都可以表示为时间的函数，*等价地*，也可以表示为频率的函数。
- en: 'Consider the following pair of graphs. They express the same signal, first
    as a function of time and then as a function of frequency. Within the time domain,
    we see one wide peak and valley (in other words, a tapering effect) spanning many
    narrow peaks and valleys. Within the frequency domain, we can see a low-frequency
    peak and a high-frequency peak, as shown in the following diagram:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下一对图表。它们以时间函数和频率函数的形式表达相同的信号。在时域内，我们看到一个宽的峰值和谷值（换句话说，一个渐变效果），跨越许多狭窄的峰值和谷值。在频域内，我们可以看到低频峰值和高频峰值，如下面的图所示：
- en: '![](img/320f1e75-511e-4178-84d5-d1367685ee8d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图像](img/320f1e75-511e-4178-84d5-d1367685ee8d.png)'
- en: The transformation from the time domain to the frequency domain is called the
    **Fourier transform** (**FT**). Conversely, the transformation from the frequency
    domain to the time domain is called the **inverse Fourier transform**. Within
    the digital world, signals are discrete, not continuous, so we use the terms **discrete
    Fourier transform** (**DFT**) and **inverse discrete Fourier transform** (**IDFT**).
    There is a variety of efficient algorithms for computing the DFT or IDFT, and
    such an algorithm might be described as a FFT or IFFT.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从时域到频域的转换称为**傅里叶变换**（**FT**）。相反，从频域到时域的转换称为**逆傅里叶变换**。在数字世界中，信号是离散的，而不是连续的，所以我们使用**离散傅里叶变换**（**DFT**）和**逆离散傅里叶变换**（**IDFT**）这些术语。计算DFT或IDFT有多种高效的算法，这样的算法可能被描述为FFT或IFFT。
- en: For algorithmic descriptions, refer to the following Wikipedia article at [http://en.wikipedia.org/wiki/Fast_Fourier_transform](http://en.wikipedia.org/wiki/Fast_Fourier_transform).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法描述，请参考以下维基百科文章：[快速傅里叶变换](http://en.wikipedia.org/wiki/Fast_Fourier_transform)。
- en: The result of the FT (including its discrete variants) is a function that maps
    a frequency to an amplitude and phase. The **amplitude** represents the magnitude
    of the frequency's contribution to the signal. The **phase** represents a temporal
    shift; it determines whether the frequency's contribution starts on a high or
    a low. Typically, the amplitude and phase are encoded in a complex number, `a+bi`,
    where `amplitude=sqrt(a^2+b^2)` and `phase=atan2(a, b)`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: FT（包括其离散变体）的结果是一个将频率映射到幅度和相位的函数。**幅度**表示频率对信号的贡献的大小。**相位**表示时间上的位移；它决定了频率的贡献是开始于高还是低。通常，幅度和相位被编码在一个复数中，`a+bi`，其中`幅度=sqrt(a^2+b^2)`和`相位=atan2(a,
    b)`。
- en: 'For an explanation of complex numbers, see the following Wikipedia article:
    [http://en.wikipedia.org/wiki/Complex_number](http://en.wikipedia.org/wiki/Complex_number).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 关于复数的解释，请参阅以下维基百科文章：[http://en.wikipedia.org/wiki/Complex_number](http://en.wikipedia.org/wiki/Complex_number)。
- en: The FFT and IFFT are fundamental to a field of computer science called **digital
    signal processing**. Many signal processing applications, including `Lazy Eyes`,
    involve taking the signal's FFT, modifying or removing certain frequencies in
    the FFT result, and then reconstructing the filtered signal in the time domain
    using the IFFT. For example, this approach allows us to amplify certain frequencies
    while leaving others unchanged.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: FFT和IFFT是计算机科学领域**数字信号处理**的基础。许多信号处理应用，包括`Lazy Eyes`，涉及获取信号的FFT，修改或移除FFT结果中的某些频率，然后使用IFFT在时域中重建经过过滤的信号。例如，这种方法允许我们放大某些频率，同时保持其他频率不变。
- en: Now, where do we find this functionality?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们到哪里去找这个功能？
- en: Choosing and setting up an FFT library
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择和设置FFT库
- en: 'Several Python libraries provide FFT and IFFT implementations that can process
    NumPy arrays (and thus OpenCV images). The five major contenders are as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 几个Python库提供了FFT和IFFT的实现，可以处理NumPy数组（因此也可以处理OpenCV图像）。以下五大主要竞争者如下：
- en: '*NumPy*, which provides FFT and IFFT implementations in a module called `numpy.fft`
    ([http://docs.scipy.org/doc/numpy/reference/routines.fft.html](http://docs.scipy.org/doc/numpy/reference/routines.fft.html)).
    The module also offers other signal processing functions for working with the
    output of the FFT.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*NumPy*，在名为`numpy.fft`的模块中提供了FFT和IFFT的实现（[http://docs.scipy.org/doc/numpy/reference/routines.fft.html](http://docs.scipy.org/doc/numpy/reference/routines.fft.html)）。该模块还提供了其他信号处理函数，用于处理FFT的输出。'
- en: '*SciPy*, which provides FFT and IFFT implementations in a module called `scipy.fftpack`
    ([http://docs.scipy.org/doc/scipy/reference/fftpack.html](http://docs.scipy.org/doc/scipy/reference/fftpack.html)).
    This SciPy module is closely based on the `numpy.fft` module, but adds some optional
    arguments and dynamic optimizations based on the input format. The SciPy module
    also adds more signal processing functions for working with the output of the
    FFT.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SciPy*，在名为`scipy.fftpack`的模块中提供了FFT和IFFT的实现（[http://docs.scipy.org/doc/scipy/reference/fftpack.html](http://docs.scipy.org/doc/scipy/reference/fftpack.html)）。这个SciPy模块与`numpy.fft`模块紧密相关，但增加了一些可选参数和基于输入格式的动态优化。SciPy模块还增加了更多信号处理函数，用于处理FFT的输出。'
- en: '*OpenCV* itself has implementations of FFT (`cv2.dft`) and IFT (`cv2.idft`).
    The following official tutorial provides examples and a comparison to NumPy''s
    FFT implementation: [https://docs.opencv.org/master/d8/d01/tutorial_discrete_fourier_transform.html](https://docs.opencv.org/master/d8/d01/tutorial_discrete_fourier_transform.html).
    Note that OpenCV''s FFT and IFT interfaces are not directly interoperable with
    the `numpy.fft` and `scipy.fftpack` modules, which offer a broader range of signal
    processing functionality. (They format the data very differently.)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenCV*本身实现了FFT（`cv2.dft`）和IFFT（`cv2.idft`）。以下官方教程提供了示例，并与NumPy的FFT实现进行了比较：[https://docs.opencv.org/master/d8/d01/tutorial_discrete_fourier_transform.html](https://docs.opencv.org/master/d8/d01/tutorial_discrete_fourier_transform.html)。请注意，OpenCV的FFT和IFFT接口不能直接与`numpy.fft`和`scipy.fftpack`模块互操作，后者提供了更广泛的信号处理功能。（它们的数据格式非常不同。）'
- en: '*PyFFTW* ([https://hgomersall.github.io/pyFFTW/](https://hgomersall.github.io/pyFFTW/)),
    which is a Python wrapper around a C library called the **Fastest Fourier Transform
    in the West** (**FFTW**) ([http://www.fftw.org/](http://www.fftw.org/)). FFTW
    provides multiple implementations of FFT and IFFT. At runtime, it dynamically
    selects implementations that are well-optimized for given input formats, output
    formats, and system capabilities. Optionally, it takes advantage of multithreading
    (and its threads may run on multiple CPU cores, as the implementation releases
    Python''s **Global Interpreter Lock** (**GIL**)). PyFFTW provides optional interfaces
    matching NumPy''s and SciPy''s FFT and IFFT functions. These interfaces have a
    low overhead cost (thanks to good caching options that are provided by PyFFTW)
    and they help to ensure that PyFFTW is interoperable with a broad range of signal
    processing functionality, as implemented in `numpy.fft` and `scipy.fftpack`.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyFFTW* ([https://hgomersall.github.io/pyFFTW/](https://hgomersall.github.io/pyFFTW/))，这是一个围绕名为
    **Fastest Fourier Transform in the West** (**FFTW**) 的C库的Python包装器 ([http://www.fftw.org/](http://www.fftw.org/))。FFTW提供了FFT和IFFT的多个实现。在运行时，它动态选择针对给定输入格式、输出格式和系统能力进行了优化的实现。可选地，它利用多线程（其线程可能运行在多个CPU核心上，因为实现释放了Python的
    **Global Interpreter Lock** (**GIL**)）。PyFFTW提供了与NumPy和SciPy的FFT和IFFT函数相匹配的可选接口。这些接口具有低开销成本（归功于PyFFTW提供的良好缓存选项），并且有助于确保PyFFTW与
    `numpy.fft` 和 `scipy.fftpack` 中实现的广泛信号处理功能兼容。'
- en: '*Reinka* ([http://reikna.publicfields.net/en/latest/](http://reikna.publicfields.net/en/latest/)),
    which is a Python library for GPU-accelerated computations, uses either PyCUDA
    ([http://mathema.tician.de/software/pycuda/](http://mathema.tician.de/software/pycuda/))
    or PyOpenCL ([http://mathema.tician.de/software/pyopencl/](http://mathema.tician.de/software/pyopencl/))
    as a backend. Reinka provides FFT and IFFT implementations in a module called
    `reikna.fft`. Reinka internally uses PyCUDA or PyOpenCL arrays (not NumPy arrays)
    and provides interfaces for conversion from NumPy arrays to these GPU arrays and
    back. The converted NumPy output is compatible with other signal processing functionality,
    as implemented in `numpy.fft` and `scipy.fftpack`. However, this compatibility
    comes at a high overhead cost due to the need to lock, read, and convert the contents
    of GPU memory.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Reinka* ([http://reikna.publicfields.net/en/latest/](http://reikna.publicfields.net/en/latest/))，这是一个用于GPU加速计算的Python库，它使用PyCUDA
    ([http://mathema.tician.de/software/pycuda/](http://mathema.tician.de/software/pycuda/))
    或 PyOpenCL ([http://mathema.tician.de/software/pyopencl/](http://mathema.tician.de/software/pyopencl/))
    作为后端。Reinka提供了一个名为 `reikna.fft` 的模块，其中实现了FFT和IFFT。Reinka内部使用PyCUDA或PyOpenCL数组（而不是NumPy数组），并提供从NumPy数组到这些GPU数组的转换接口以及反向转换。转换后的NumPy输出与
    `numpy.fft` 和 `scipy.fftpack` 中实现的其它信号处理功能兼容。然而，这种兼容性需要以高昂的开销为代价，因为需要锁定、读取和转换GPU内存的内容。'
- en: NumPy, SciPy, OpenCV, and PyFFTW are open source libraries under the BSD license.
    Reinka is an open-source library under the MIT license.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy、SciPy、OpenCV和PyFFTW都是在BSD许可下的开源库。Reinka是在MIT许可下的开源库。
- en: I recommend PyFFTW because of its optimizations and its interoperability (at
    a low overhead cost), and all the other functionality that interests us in NumPy,
    SciPy, and OpenCV. For a tour of PyFFTW's features, including its NumPy- and SciPy-compatible
    interfaces, see the official tutorial at [https://hgomersall.github.io/pyFFTW/sphinx/tutorial.html](https://hgomersall.github.io/pyFFTW/sphinx/tutorial.html).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我推荐PyFFTW，因为它进行了优化，具有低开销的互操作性，以及NumPy、SciPy和OpenCV中所有其他吸引我们的功能。要了解PyFFTW的功能，包括其与NumPy和SciPy兼容的接口，请参阅官方教程[https://hgomersall.github.io/pyFFTW/sphinx/tutorial.html](https://hgomersall.github.io/pyFFTW/sphinx/tutorial.html)。
- en: 'Depending on our platform, we can set up PyFFTW in one of the following ways:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的平台，我们可以以下列方式之一设置 PyFFTW：
- en: 'On Mac, the third-party MacPorts package manager offers PyFFTW packages for
    some versions of Python, currently including Python 3.6 but not Python 3.7\. To
    install PyFFTW with MacPorts, open a Terminal and run something like the following
    command (but substitute your Python version if it differs from `py36`):'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Mac上，第三方MacPorts包管理器为某些Python版本提供了PyFFTW包，目前包括Python 3.6，但不包括Python 3.7。要使用MacPorts安装PyFFTW，请打开终端并运行以下类似命令（但如果你使用的Python版本与
    `py36` 不同，请替换你的Python版本）：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Alternatively, on any system, use Python''s package manager, pip, to install
    PyFFTW. Open a command prompt and run something like the following command (depending
    on your system, you might need to replace `pip` with `pip3` in order to install
    PyFFTW for Python 3):'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者，在任意系统上，使用Python的包管理器pip来安装PyFFTW。打开命令提示符并运行以下类似命令（根据您的系统，您可能需要将`pip`替换为`pip3`以安装Python
    3的PyFFTW）：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Some versions of pip''s `pyFFTW` package have installation bugs that affect
    some systems. If `pip` fails to install the `pyFFTW` package, try again, but manually
    specify version 10.4 of the package by running the following command:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: pip的`pyFFTW`包的一些版本存在安装错误，这会影响某些系统。如果`pip`无法安装`pyFFTW`包，请重试，但手动指定包的10.4版本，运行以下命令：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that some old versions of the library are called `PyFFTW3`. We do not want
    `PyFFTW3`. On Ubuntu 18.04 and its derivatives, the `python-fftw` package in the
    system's standard apt repository is an old `PyFFTW3` version.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一些旧版本的库被称为`PyFFTW3`。我们不希望使用`PyFFTW3`。在Ubuntu 18.04及其衍生版本中，系统标准apt仓库中的`python-fftw`包是旧的`PyFFTW3`版本。
- en: We have our FFT and IFFT needs covered by the Fastest Fourier Transform in the
    West (and if we were cowboys instead of secret agents, we could say, *Cover me!*).
    For additional signal processing functionality, we will use SciPy, which can be
    set up in the way we described in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml),
    *Preparing for the Mission*, in the *Setting up a development machine* section.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过西方最快的傅里叶变换（FFT和IFFT）来满足我们的需求（如果我们是牛仔而不是秘密特工，我们可以说，*掩护我!*）。对于额外的信号处理功能，我们将使用SciPy，它可以通过我们在[第1章](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml)中描述的方式设置，即在*设置开发机器*部分。
- en: Signal processing is not the only new material that we must learn about for
    Lazy Eyes, so let's look at other functionality that is provided by OpenCV.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Lazy Eyes，我们不仅要学习信号处理的新材料，还要了解OpenCV提供的其他功能。
- en: Compositing two images using image pyramids
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用图像金字塔合成两个图像
- en: Running an FFT on a full-resolution video feed would be slow. The resulting
    frequencies may also reflect localized phenomena at each captured pixel, so that
    the motion map (the result of filtering the frequencies and then applying the
    IFFT) might appear noisy and overly sharp. To address these problems, we need
    a cheap, blurry downsampling technique. However, we also want the option to enhance
    edges, which are important to our perception of motion.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在全分辨率视频流上运行FFT会很慢。结果频率可能还会反映每个捕获像素的局部现象，因此运动图（过滤频率后应用IFFT的结果）可能会出现噪声和过于尖锐。为了解决这些问题，我们需要一种便宜、模糊的下采样技术。然而，我们还想有增强边缘的选项，这对我们感知运动很重要。
- en: Our need for a blurry downsampling technique is fulfilled by a **Gaussian image
    pyramid**. A **Gaussian filter** blurs an image by making each output pixel a
    weighted average of multiple input pixels in the neighborhood. An image pyramid
    is a series in which each image is a fraction of the width and height of the previous
    image. Often, the fraction is one half. The halving of image dimensions is achieved
    by *decimation*, meaning that every other pixel is simply omitted. A Gaussian
    image pyramid is constructed by applying a Gaussian filter before each decimation
    operation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对模糊下采样技术的需求通过**高斯图像金字塔**得到满足。**高斯滤波器**通过将每个输出像素设置为邻域内多个输入像素的加权平均值来模糊图像。图像金字塔是一系列图像，其中每个图像是前一个图像宽度和高度的一部分。通常，这个比例是二分之一。通过*降采样*实现图像尺寸的二分之一，这意味着简单地省略了每个像素。高斯图像金字塔是通过在每个降采样操作之前应用高斯滤波器来构建的。
- en: Our need to enhance edges in downsampled images is fulfilled by a **Laplacian
    image pyramid**, which is constructed in the following manner. Suppose we have
    already constructed a Gaussian image pyramid. We take the image at level `i+1`
    in the Gaussian pyramid, upsample it by duplicating pixels, and apply a Gaussian
    filter to it again. We then subtract the result from the image at level `i` in
    the Gaussian pyramid to produce the corresponding image at level `i` of the Laplacian
    pyramid. Thus, the Laplacian image is the difference between a blurry, downsampled
    image and an even blurrier image that was downsampled, downsampled again, and
    upsampled.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在降采样图像中增强边缘的需求通过一个**拉普拉斯图像金字塔**得到满足，其构建方式如下。假设我们已构建了一个高斯图像金字塔。我们从高斯金字塔中取出`i+1`层的图像，通过复制像素进行上采样，并再次应用高斯滤波器。然后我们从高斯金字塔中`i`层的图像中减去这个结果，以产生拉普拉斯金字塔中`i`层的对应图像。因此，拉普拉斯图像是模糊的降采样图像与一个更模糊的图像之间的差异，这个图像经过降采样、再次降采样并上采样。
- en: You might wonder how such an algorithm is a form of edge-finding. Consider that
    edges are areas of local contrast, while non-edges are areas of local uniformity.
    If we blur a uniform area, it is still uniform—there is zero difference. If we
    blur a contrasting area, however, it becomes more uniform—there is a non-zero
    difference. Thus, the difference can be used to find edges.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道这样的算法是如何成为边缘检测的一种形式的。考虑一下，边缘是局部对比度的区域，而非边缘是局部均匀性的区域。如果我们模糊一个均匀的区域，它仍然是均匀的——没有差异。然而，如果我们模糊一个对比度区域，它就会变得更加均匀——存在非零差异。因此，差异可以用来找到边缘。
- en: 'The Gaussian and Laplacian image pyramids are described in detail in the following
    journal article: E. H. Adelson, C. H. Anderson, J. R. Bergen, P. J. Burt, and
    J. M. Ogden. "Pyramid methods in image processing". RCA Engineer, Vol. 29, No.
    6, November/Dececember 1984. It can be downloaded from [http://persci.mit.edu/pub_pdfs/RCA84.pdf](http://persci.mit.edu/pub_pdfs/RCA84.pdf).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯和拉普拉斯图像金字塔在以下期刊文章中有详细描述：E. H. Adelson, C. H. Anderson, J. R. Bergen, P. J.
    Burt, and J. M. Ogden. "图像处理中的金字塔方法"。RCA Engineer, Vol. 29, No. 6, November/December
    1984。可以从[http://persci.mit.edu/pub_pdfs/RCA84.pdf](http://persci.mit.edu/pub_pdfs/RCA84.pdf)下载。
- en: Besides using image pyramids to downsample the FFT's input, we can also use
    them to upsample the most recent frame of the IFFT's output. This upsampling step
    is necessary for creating an overlay that matches the size of the original camera
    image so that we can composite the two. Like in the construction of the Laplacian
    pyramid, upsampling consists of duplicating pixels and applying a Gaussian filter.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用图像金字塔来降采样FFT的输入外，我们还可以使用它们来上采样IFFT输出的最新帧。这一上采样步骤对于创建与原始相机图像大小匹配的叠加层是必要的，这样我们就可以合成两个图像。就像在构建拉普拉斯金字塔时一样，上采样包括复制像素和应用高斯滤波器。
- en: OpenCV implements the relevant downsizing and upsizing functions as `cv2.pyrDown`
    and `cv2.pyrUp`. These functions are useful in compositing two images in general
    (whether or not signal processing is involved), because they allows us to soften
    differences while preserving edges. The OpenCV documentation includes a good tutorial
    on this topic at [https://docs.opencv.org/master/dc/dff/tutorial_py_pyramids.html](https://docs.opencv.org/master/dc/dff/tutorial_py_pyramids.html).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV实现了相关的降采样和上采样函数，分别是`cv2.pyrDown`和`cv2.pyrUp`。这些函数在合成两个图像时非常有用（无论是否涉及信号处理），因为它们允许我们在保留边缘的同时软化差异。OpenCV文档中包含了一个关于这个主题的优秀教程，链接为[https://docs.opencv.org/master/dc/dff/tutorial_py_pyramids.html](https://docs.opencv.org/master/dc/dff/tutorial_py_pyramids.html)。
- en: Now that we are armed with the necessary knowledge, it's time to implement `Lazy
    Eyes`!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了必要的知识，是时候实现Lazy Eyes了！
- en: Implementing the Lazy Eyes app
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现Lazy Eyes应用程序
- en: 'Let''s create a new folder for Lazy Eyes and, in this folder, create copies
    of or links to the `ResizeUtils.py` and `WxUtils.py` files from any of our previous
    Python projects, such as `The Living Headlights` from [Chapter 5](b4619968-1f90-45f0-8a77-3505624bc0c0.xhtml),
    *Equipping Your Car with a Rearview Camera and Hazard Detection*. Alongside the
    copies or links, let''s create a new file, `LazyEyes.py`. Edit it and enter the
    following `import` statements:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为Lazy Eyes创建一个新的文件夹，并在该文件夹中创建从我们之前的Python项目（例如第5章中的`The Living Headlights`）中的`ResizeUtils.py`和`WxUtils.py`文件的副本或链接，例如`Equipping
    Your Car with a Rearview Camera and Hazard Detection`。在副本或链接旁边，让我们创建一个新的文件，`LazyEyes.py`。编辑它并输入以下`import`语句：
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Besides the modules that we have used in the previous projects, we are now using
    the standard library's `collections` module for efficient collections, as well
    as the `timeit` module for precise timing. For the first time, we are also using
    the signal processing functionality from PyFFTW and SciPy.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们在以前的项目中使用过的模块外，我们现在还使用标准库的 `collections` 模块来高效地收集数据，以及 `timeit` 模块来进行精确的时间测量。第一次，我们还使用了
    PyFFTW 和 SciPy 的信号处理功能。
- en: 'Like our other Python applications, `Lazy Eyes` is implemented as a class that
    extends `wx.Frame`. The following code block contains the declarations of the
    class and its initializer:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们的其他 Python 应用程序一样，`Lazy Eyes` 是作为一个扩展 `wx.Frame` 的类实现的。以下代码块包含了类的声明及其初始化器：
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The initializer''s arguments affect the app''s frame rate and the manner in
    which motion is amplified. These effects are discussed in detail in the section
    *Configuring and testing the app for various motions *later in this chapter. The
    following is just a brief description of the arguments:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化器的参数会影响应用程序的帧率和运动放大的方式。这些效果将在本章后面的 *配置和测试应用程序以适应各种运动* 部分详细讨论。以下只是对参数的简要描述：
- en: '`maxHistoryLength` is the number of frames (including the current frame and
    preceding frames) that are analyzed for motion.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxHistoryLength` 是分析运动所用的帧数（包括当前帧和前面的帧）。'
- en: '`minHz` and `maxHz`, respectively, define the slowest and fastest motions that
    are amplified.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minHz` 和 `maxHz` 分别定义了被放大的最慢和最快的运动。'
- en: '`amplification` is the scale of the visual effect. A higher value means motion
    is highlighted more brightly.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`amplification` 是视觉效果的比例。值越高，运动越明亮地被突出显示。'
- en: '`numPyramidLevels` is the number of pyramid levels by which frames are downsampled
    before signal processing is done. Each level corresponds to downsampling by a
    factor of `2`. Our implementation assumes `numPyramidLevels>0`.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numPyramidLevels` 是在信号处理之前对帧进行下采样的金字塔层数。每一层对应于以 `2` 为因子的下采样。我们的实现假设 `numPyramidLevels>0`。'
- en: If `useLaplacianPyramid` is `True`, frames are downsampled using a Laplacian
    pyramid before signal processing is done. The implication is that only edge motion
    is highlighted. Alternatively, if `useLaplacianPyramid` is `False`, a Gaussian
    pyramid is used, and motion in all areas is highlighted.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `useLaplacianPyramid` 为 `True`，则在信号处理之前使用拉普拉斯金字塔对帧进行下采样。这意味着只有边缘运动被突出显示。如果
    `useLaplacianPyramid` 为 `False`，则使用高斯金字塔，并且所有区域的运动都被突出显示。
- en: If `useGrayOverlay` is `True`, frames are converted to grayscale before signal
    processing is done. The implication is that motion is only highlighted in areas
    of grayscale contrast. Alternatively, if `useGrayOverlay` is `False`, motion is
    highlighted in areas that have contrast in any color channel.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `useGrayOverlay` 为 `True`，则在信号处理之前将帧转换为灰度。这意味着只有在灰度对比度区域才会突出显示运动。如果 `useGrayOverlay`
    为 `False`，则在任何颜色通道有对比度的区域突出显示运动。
- en: '`numFFTThreads` and `numIFFTThreads`, are the numbers of threads that are used
    in FFT and IFFT computations, respectively.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numFFTThreads` 和 `numIFFTThreads` 分别是用于 FFT 和 IFFT 计算的线程数。'
- en: '`cameraDeviceID` and `imageSize` are our usual capture parameters.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cameraDeviceID` 和 `imageSize` 是我们常用的捕获参数。'
- en: 'The initializer''s implementation begins in the same way as our other Python
    apps. It sets flags to indicate that the app is running and should be mirrored
    by default. It creates the capture object and configures its resolution to match
    the requested width and height, if possible. Failing that, the device''s fallback
    capture resolution is used. The initializer also declares variables to store images,
    and creates a lock to manage thread-safe access to the images. The relevant code
    is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化器的实现方式与我们的其他 Python 应用程序相同。它设置标志以指示应用程序正在运行并且默认应该被镜像。它创建捕获对象并配置其分辨率以匹配请求的宽度和高度，如果可能的话。如果失败，则使用设备的备用捕获分辨率。初始化器还声明了用于存储图像的变量，并创建了一个锁来管理对图像的线程安全访问。相关代码如下：
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we need to determine the shape of the history of frames. We already know
    that it has at least three dimensions—a number of frames, and a width and height
    for each frame. The width and height are downsampled from the capture width and
    height based on the number of pyramid levels. If we are concerned with color motion,
    and not just grayscale motion, the history also has a fourth dimension that consists
    of three color channels. The following code calculates the history''s shape:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要确定帧历史记录的形状。我们已经知道它至少有三个维度——帧的数量，以及每帧的宽度和高度。宽度和高度基于金字塔层级数从捕获宽度和高度下采样。如果我们关心颜色运动，而不仅仅是灰度运动，历史记录还有一个第四维，由三个颜色通道组成。以下代码计算历史记录的形状：
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note the use of `>>`, the right bitshift operator, in the preceding code; it's
    used to divide the dimensions by a power of two. The power is equal to the number
    of pyramid levels.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意前述代码中`>>`的使用，这是右移位运算符，用于将维度除以2的幂。这个幂等于金字塔层级数。
- en: 'We now need to store the specified maximum history length. For the frames in
    the history, we will create a NumPy array of the shape we just determined. For
    timestamps of the frames, we will create a **double-ended queue** (**deque**),
    a type of collection that allows us to cheaply add or remove elements from either
    end, as shown in the following code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要存储指定的最大历史长度。对于历史记录中的帧，我们将创建一个形状与我们刚刚确定的NumPy数组。对于帧的时间戳，我们将创建一个**双端队列**（**deque**），这是一种允许我们以低成本从两端添加或删除元素的集合类型，如下所示：
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We will store the remaining arguments because we will need to pass them to
    the pyramid functions and signal processing functions for each frame later, as
    follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将存储剩余的参数，因为我们将在稍后为每个帧将它们传递给金字塔函数和信号处理函数，如下所示：
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To ensure meaningful error messages and early termination in the case of invalid
    arguments, we could add code such as the following for each argument:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保有意义的错误消息和在无效参数的情况下提前终止，我们可以在每个参数上添加如下代码：
- en: '`assert numPyramidLevels > 0, \`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`assert numPyramidLevels > 0, \`'
- en: '`        ''numPyramidLevels must be positive.''`'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`        ''numPyramidLevels must be positive.''`'
- en: For brevity, such assertions are omitted from our code samples.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁，我们在代码示例中省略了此类断言。
- en: 'We now need to call the following two functions to tell PyFFTW to cache its
    data structures (notably, its NumPy arrays) for a period of at least 1.0 seconds
    from their last use. (The default is 0.1 seconds.) Caching is a critical optimization
    for the PyFFTW interfaces that we are using, so we will choose a period that is
    more than long enough to keep the cache alive from frame to frame, as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要调用以下两个函数来告诉PyFFTW缓存其数据结构（特别是其NumPy数组）至少1.0秒（默认为0.1秒）的时间。对于PyFFTW接口，这是一个关键的优化，因此我们将选择一个足够长的时间段，以确保从一帧到另一帧缓存保持活跃，如下所示：
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As shown in the following code, the initializer''s implementation ends with
    code to set up a window, event bindings, a video panel, a layout, and a background
    thread, which are all familiar tasks from our previous Python projects:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下代码所示，初始化器的实现以设置窗口、事件绑定、视频面板、布局和后台线程的代码结束，这些都是我们之前Python项目中的熟悉任务：
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We must now modify our usual `_onCloseWindow` callback to disable PyFFTW''s
    cache. Disabling the cache ensures that resources are freed and that PyFFTW''s
    threads terminate normally. The callback''s implementation is shown in the following
    code:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须修改我们常用的`_onCloseWindow`回调以禁用PyFFTW的缓存。禁用缓存确保资源被释放，PyFFTW的线程正常终止。回调的实现如下所示：
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The escape key is bound to our usual `_onQuitCommand` callback, which just
    closes the app, as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 逃逸键绑定到我们常用的`_onQuitCommand`回调，它只是关闭应用程序，如下所示：
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The video panel''s erase and paint events are bound to our usual callbacks,
    `_onVideoPanelEraseBackground` and `_onVideoPanelPaint`, as shown in the following
    code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 视频面板的擦除和绘制事件绑定到我们常用的回调，`_onVideoPanelEraseBackground`和`_onVideoPanelPaint`，如下所示：
- en: '[PRE13]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The loop running on our background thread is similar to the one used in other
    Python apps. For each frame, it calls a helper function, `_applyEulerianVideoMagnification`.
    The loop''s implementation is as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的后台线程上运行的循环与在其他Python应用程序中使用的循环类似。对于每一帧，它调用一个辅助函数`_applyEulerianVideoMagnification`。循环的实现如下：
- en: '[PRE14]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `_applyEulerianVideoMagnification` helper function is quite long, so we
    will consider its implementation in several chunks. First, we need to create a
    timestamp for the frame and copy the frame to a format that is more suitable for
    processing. Specifically, we will use a floating point with either one gray channel
    or three color channels, depending on the configuration, as shown in the following
    code:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`_applyEulerianVideoMagnification`辅助函数相当长，所以我们将将其实现分成几个部分。首先，我们需要为帧创建一个时间戳并将帧复制到一个更适合处理的格式。具体来说，我们将使用一个浮点数，它有一个灰度通道或三个颜色通道，具体取决于配置，如下面的代码所示：'
- en: '[PRE15]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Using this copy, we will calculate the appropriate level in the Gaussian or
    Laplacian pyramid, as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个副本，我们将计算高斯或拉普拉斯金字塔的适当级别，如下所示：
- en: '[PRE16]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: For the purposes of the history and signal processing functions, we will refer
    to this pyramid level as *the image *or *the frame*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于历史和信号处理函数的目的，我们将把这个金字塔级别称为*图像*或*帧*。
- en: 'Next, we need to check the number of history frames that have been filled so
    far. If the history has more than one unfilled frame (meaning the history still
    won''t be full after adding the frame), we will append and timestamp the new image,
    before returning it early, so that no signal processing is done until a later
    frame. This can be seen in the following code:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要检查到目前为止已填充的历史帧数。如果历史中有多于一个未填充的帧（这意味着在添加帧后历史仍然不会满），我们将在返回之前追加并标记新的图像，这样就不会在后续帧上进行信号处理。这可以在下面的代码中看到：
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If the history is just one frame short of being full (meaning the history will
    be full after adding this frame), we will append the new image and timestamp,
    as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果历史只差一帧就满了（这意味着在添加这一帧后历史将满），我们将追加新的图像和时间戳，如下所示：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If the history is already full, we will drop the oldest image and timestamp
    and append the new image and timestamp, as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果历史已经满了，我们将删除最旧的图像和时间戳，并追加新的图像和时间戳，如下所示：
- en: '[PRE19]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The history of image data is a NumPy array and, as such, we are using the terms
    *append *and *drop *loosely. NumPy arrays are immutable, meaning that they cannot
    grow or shrink. Moreover, we are not recreating this array because it is large,
    and reallocating each frame would be expensive. Instead, we are just overwriting
    data within the array by moving old data leftward and copying new data in.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数据的历史是一个NumPy数组，因此我们在这里松散地使用“追加”和“删除”这两个术语。NumPy数组是不可变的，这意味着它们不能增长或缩小。此外，我们并不是因为数组很大而重新创建这个数组，因为为每一帧重新分配内存会非常昂贵。相反，我们只是通过将旧数据向左移动并复制新数据到数组中来覆盖数组内的数据。
- en: 'Based on the timestamps, we will calculate the average time per frame in the
    history, and we will display the frame rate, as seen in the following code:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 根据时间戳，我们将计算历史中每帧的平均时间，并将显示帧率，如下面的代码所示：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We will then proceed with a combination of signal processing functions, collectively
    called a **temporal bandpass filter**. This filter blocks (zeros out) some frequencies
    and allows others to pass and remain unchanged. Our first step in implementing
    this filter is to run the `pyfftw.interfaces.scipy_fftpack.fft` function using
    the history and number of threads as arguments. Also, with the `axis=0` argument,
    we will specify that the history''s first axis is the time axis, as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将进行一系列信号处理函数的组合，统称为**时域带通滤波器**。这个滤波器阻止（置零）一些频率，允许其他频率通过并保持不变。在实现此滤波器的第一步中，我们将使用历史和线程数作为参数运行`pyfftw.interfaces.scipy_fftpack.fft`函数。此外，使用`axis=0`参数，我们将指定历史的第一轴是时间轴，如下所示：
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We will pass the FFT result and the time per frame to the `scipy.fftpack.fftfreq`
    function. This function will then return an array of midpoint frequencies (in
    Hz, in our case) corresponding to the indices in the FFT result. (This array answers
    the question, *Which frequency is the midpoint of the bin of frequencies represented
    by index* `i` *in the FFT?*) We will find the indices whose midpoint frequencies
    lie closest to our initializer''s `minHz` and `maxHz` parameters (a minimum of
    absolute value difference). Then, we will modify the FFT result by setting the
    data to zero in all ranges that do not represent frequencies of interest, as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将FFT结果和每帧时间传递给`scipy.fftpack.fftfreq`函数。然后，该函数将返回一个对应于FFT结果中索引的中点频率数组（在我们的情况下是Hz）。（这个数组回答了问题：“哪个频率是索引`i`表示的频率桶的中点？”）然后，我们将找到中点频率最接近初始化器的`minHz`和`maxHz`参数（绝对值差异最小）的索引。然后，我们将通过将所有不表示感兴趣频率范围的数据设置为零来修改FFT结果，如下所示：
- en: '[PRE22]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The FFT result is symmetrical—`fftResult[i]` and `fftResult[-i-1]` pertain to
    the same bin of frequencies. Thus, we modify the FFT result symmetrically.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: FFT结果是对称的——`fftResult[i]`和`fftResult[-i-1]`属于相同的频率桶。因此，我们对称地修改FFT结果。
- en: Remember, the Fourier transform maps a frequency to a complex number that encodes
    an amplitude and phase. Thus, while the indices of the FFT result correspond to
    frequencies, the values contained at those indices are complex numbers. Zero as
    a complex number is written in Python as `0+0j` or `0j`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，傅里叶变换将一个频率映射到一个复数，该复数编码了振幅和相位。因此，虽然FFT结果的索引对应于频率，但那些索引处的值是复数。Python中将零作为复数写作`0+0j`或`0j`。
- en: 'Having filtered out the frequencies that do not interest us, we will now finish
    applying the temporal bandpass filter by passing the data to the `pyfftw.interfaces.scipy_fftpack.ifft`
    function, as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在过滤掉我们不感兴趣的频率后，我们现在将应用时间带通滤波器的最后一步，通过将数据传递给`pyfftw.interfaces.scipy_fftpack.ifft`函数，如下所示：
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'From the IFFT result, we will take the most recent frame. It should somewhat
    resemble the current camera frame, but should be black in areas that do not exhibit
    recent motion that matches our parameters. We will multiply this filtered frame
    so that the non-black areas become bright. Then, we will upsample it (using a
    pyramid technique) and add the result to the current camera frame so that areas
    of motion are lit up. The relevant code, which concludes the `_applyEulerianVideoMagnification`
    method, is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 从IFFT结果中，我们将取最新的帧。它应该在一定程度上类似于当前相机帧，但在不显示与我们的参数匹配的最近运动区域应该是黑色的。我们将乘以这个过滤帧，使非黑色区域变亮。然后，我们将使用金字塔技术对其进行上采样，并将结果添加到当前相机帧中，以便在运动区域点亮。完成`_applyEulerianVideoMagnification`方法的代码如下：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This concludes the implementation of the `LazyEyes` class. Our module''s `main`
    function just instantiates and runs the app, as seen in the following code:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了`LazyEyes`类的实现。我们的模块的`main`函数只是实例化和运行应用程序，如下面的代码所示：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: That's all! Now, it's time to run the app and stay still while it builds up
    its history of frames. Until the history is full, the video feed will not show
    any special effects. At the history's default length of 360 frames, it fills in
    about 50 seconds on a machine. Once it is full, you should start to see ripples
    moving through the video feed in areas of recent motion—or perhaps even everywhere
    if the camera moves or the lighting or exposure changes. The ripples should then
    gradually settle and disappear in areas of the scene that become still, with new
    ripples appearing in new areas of motion. Feel free to experiment on your own.
    Now, let's discuss a few recipes for configuring and testing the parameters of
    the `LazyEyes` class.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 那就结束了！现在，是时候运行应用程序，并在它建立其帧历史记录时保持静止。直到历史记录填满，视频流将不会显示任何特殊效果。在历史记录的默认长度为360帧时，它在机器上大约填充了50秒。一旦填满，你应该开始看到视频流中最近运动区域出现波纹——或者如果相机移动或光线或曝光发生变化，可能甚至无处不在。然后，波纹应该逐渐在场景中静止的区域消失，在新运动区域出现新的波纹。请随意自行实验。现在，让我们讨论一些配置和测试`LazyEyes`类参数的配方。
- en: Configuring and testing the app for various motions
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置和测试应用程序以处理各种运动
- en: 'Currently, our `main` function initializes the `LazyEyes` object with the default
    parameters. If we were to fill in the same parameter values explicitly, we would
    have the following statement:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们的`main`函数使用默认参数初始化`LazyEyes`对象。如果我们显式地填充相同的参数值，我们将有如下语句：
- en: '[PRE26]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This recipe calls for a capture resolution of *640 x 480* and a signal processing
    resolution of *160 x 120* (as we are downsampling by `2` pyramid levels, or a
    factor of `4`). We are amplifying the motion only at frequencies of 0.833 Hz to
    1.0 Hz, only at edges (as we are using the Laplacian pyramid), only in grayscale,
    and only over a history of 360 frames (about 20 to 40 seconds, depending on the
    frame rate). Motion is exaggerated by a factor of `32`. These settings are suitable
    for many subtle upper-body movements such as a person's head swaying side to side,
    shoulders heaving with breathing, nostrils flaring, eyebrows rising and falling,
    and eye scanning to and fro. For performance, FFT and IFFT are each using `4`
    threads.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方需要捕获分辨率为*640 x 480*和信号处理分辨率为*160 x 120*（因为我们通过`2`个金字塔级别进行下采样，或`4`的因子）。我们只在0.833
    Hz到1.0 Hz的频率上放大运动，只在边缘（因为我们使用拉普拉斯金字塔），只在灰度上，并且只在360帧的历史记录中（大约20到40秒，取决于帧率）。运动被放大了`32`倍。这些设置适用于许多微妙的上半身运动，例如一个人的头部左右摇摆，肩膀随着呼吸起伏，鼻孔扩张，眉毛上下移动，以及眼睛的来回扫描。为了性能，FFT和IFFT各自使用`4`个线程。
- en: 'How the app looks when it runs with its default parameters is shown in the
    following screenshot. Moments before taking the screenshot, I smiled before returning
    to my normal expression. Note that my eyebrows and mustache are visible in multiple
    positions, including their current low positions and their previous high positions.
    For the sake of capturing the motion amplification effect in a still image, this
    gesture is quite exaggerated. However, in a moving video, we can see the amplification
    of more subtle movements, too:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序使用默认参数运行时的外观在以下截图中显示。在截图之前，我微笑了一下，然后恢复了正常表情。请注意，我的眉毛和胡须在多个位置可见，包括它们当前的低位置和之前的高位置。为了在静态图像中捕捉运动放大效果，这个手势被夸张了。然而，在移动视频中，我们也可以看到更微妙运动的放大：
- en: '![](img/d8fdda93-ce9d-45d0-aac9-526c0806f5ff.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d8fdda93-ce9d-45d0-aac9-526c0806f5ff.png)'
- en: 'The following screenshot illustrates an example where my eyebrows appear taller
    after being raised and then lowered:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了这样一个例子，我的眉毛在抬起后又放下后显得更高：
- en: '![](img/0c2fde30-5d3f-43cc-af6c-1547965bb234.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0c2fde30-5d3f-43cc-af6c-1547965bb234.png)'
- en: 'The parameters interact with each other in complex ways. Consider the following
    relationships:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 参数以复杂的方式相互作用。考虑以下关系：
- en: Frame rate is greatly affected by the size of the input data for the FFT and
    IFFT functions. The size of the input data is determined by `maxHistoryLength`
    (a shorter length provides less input and thus a faster frame rate), `numPyramidLevels`
    (more levels implies less input), `useGrayOverlay` (`True` implies less input),
    and `imageSize` (a smaller size is less input).
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帧率受到FFT和IFFT函数输入数据大小的极大影响。输入数据的大小由`maxHistoryLength`（较短的长度提供较少的输入，因此帧率更快）、`numPyramidLevels`（更多级别意味着较少的输入）、`useGrayOverlay`（`True`意味着较少的输入）和`imageSize`（较小的尺寸意味着较少的输入）决定。
- en: Frame rate is also greatly affected by the level of multithreading of the FFT
    and IFFT functions, as determined by `numFFTThreads` and `numIFFTThreads` (a greater
    number of threads is faster up to some point).
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帧率也受到FFT和IFFT函数多线程级别的极大影响，由`numFFTThreads`和`numIFFTThreads`确定（线程数量越多，速度越快，但达到某个点后速度会减慢）。
- en: Frame rate is slightly affected by `useLaplacianPyramid` (`False` implies a
    faster frame rate), as the Laplacian algorithm requires extra steps beyond the
    Gaussian.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帧率稍微受到`useLaplacianPyramid`（`False`意味着帧率更快）的影响，因为拉普拉斯算法需要比高斯算法更多的步骤。
- en: Frame rate determines the amount of time that `maxHistoryLength` represents.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帧率决定了`maxHistoryLength`代表的时间量。
- en: Frame rate and `maxHistoryLength` determine how many repetitions of motion (if
    any) can be captured in the `minHz` to `maxHz` range. The number of captured repetitions,
    together with `amplification`, determines how greatly a motion or a deviation
    from the motion will be amplified.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帧率和`maxHistoryLength`决定了在`minHz`到`maxHz`范围内可以捕获多少次运动（如果有）。捕获的重复次数，加上`amplification`，决定了运动或运动偏差将被放大多少。
- en: The inclusion or exclusion of noise is affected by `minHz` and `maxHz` (depending
    on which frequencies of noise are characteristic of the camera), `numPyramidLevels`
    (more levels implies a less noisy image), `useLaplacianPyramid` (`True` is less
    noisy), `useGrayOverlay` (`True` is less noisy), and `imageSize` (a smaller size
    implies a less noisy image).
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 噪声的包含或排除受`minHz`和`maxHz`（取决于哪些频率的噪声是摄像机的特征）的影响，`numPyramidLevels`（更多级别意味着图像噪声更少），`useLaplacianPyramid`（`True`意味着噪声更少），`useGrayOverlay`（`True`意味着噪声更少），以及`imageSize`（较小的尺寸意味着图像噪声更少）。
- en: The inclusion or exclusion of motion is affected by `numPyramidLevels` (fewer
    means the amplification is more inclusive of small motions), `useLaplacianPyramid`
    (`False` is more inclusive of motion in non-edge areas), `useGrayOverlay` (`False`
    is more inclusive of motion in areas of color contrast), `minHz` (a lower value
    is more inclusive of slow motion), `maxHz` (a higher value is more inclusive of
    fast motion), and `imageSize` (a bigger size is more inclusive of small motions).
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动的包含或排除受`numPyramidLevels`（较少意味着对小运动的放大更全面）的影响，`useLaplacianPyramid`（`False`意味着非边缘区域中的运动更全面），`useGrayOverlay`（`False`意味着在颜色对比区域中的运动更全面），`minHz`（较低的值意味着对慢动作更全面），`maxHz`（较高的值意味着对快动作更全面），以及`imageSize`（较大的尺寸意味着对小运动更全面）。
- en: Subjectively, the visual effect is always more impressive when the frame rate
    is high, noise is excluded, and small motions are included. Again subjectively,
    other conditions for including or excluding motion (edge versus non-edge, grayscale
    contrast versus color contrast, or fast versus slow) are application-dependent.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主观上，当帧率高、噪声被排除、小运动被包含时，视觉效果总是更令人印象深刻。再次主观上，其他包含或排除运动的条件（边缘与非边缘、灰度对比与颜色对比、或快与慢）都是应用相关的。
- en: Now, let's try our hand at reconfiguring `Lazy Eyes`, starting with the `numFFTThreads`
    and `numIFFTThreads` parameters. We want to determine the numbers of threads that
    maximize Lazy Eyes' frame rate on a given machine. The more CPU cores there are,
    the more threads one can gainfully use. However, experimentation is the best guide
    for picking a number.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试重新配置`Lazy Eyes`，从`numFFTThreads`和`numIFFTThreads`参数开始。我们想要确定在特定机器上最大化Lazy
    Eyes帧率的线程数量。CPU核心越多，可以有效地使用的线程就越多。然而，实验是选择数字的最佳指南。
- en: Run `LazyEyes.py`. Once the history fills up, the history's average FPS will
    be displayed in the lower left corner of the window. Wait until this average FPS
    value stabilizes. It might take a minute for the average to adjust to the effect
    of the FFT and IFFT functions. Take note of the FPS value, close the app, adjust
    the thread count parameters, and test again. Repeat these steps until you feel
    that you have enough data to pick a good number of threads to use on the relevant
    hardware.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`LazyEyes.py`。一旦历史记录填满，窗口左下角将显示历史记录的平均FPS。等待这个平均FPS值稳定。平均FPS可能需要一分钟才能调整到FFT和IFFT函数的影响。注意FPS值，关闭应用程序，调整线程计数参数，并再次测试。重复这些步骤，直到您觉得有足够的数据来选择在相关硬件上使用的线程数量。
- en: By activating additional CPU cores, multithreading can cause your system's temperature
    to rise. As you experiment, monitor your machine's temperature, fans, and CPU
    usage statistics. If you become concerned, reduce the number of FFT and IFFT threads.
    Having a sub-optimal frame rate is better than overheating your machine.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通过激活额外的CPU核心，多线程可能会导致您的系统温度升高。在实验过程中，请监控机器的温度、风扇和CPU使用统计信息。如果您感到担忧，请减少FFT和IFFT线程的数量。拥有一个次优的帧率比让机器过热要好。
- en: Now, experiment with other parameters to see how they affect FPS; the `numPyramidLevels`,
    `useGrayOverlay`, and `imageSize` parameters should all have a considerable effect.
    At a threshold of approximately 12 FPS, a series of frames starts to look like
    continuous motion instead of *a slide show*. The higher the frame rate, the smoother
    the motion will appear. Traditionally, hand-drawn animated movies run at 12 drawings
    per second for most scenes, and 24 drawings per second for fast action.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，尝试调整其他参数以观察它们对FPS的影响；`numPyramidLevels`、`useGrayOverlay`和`imageSize`参数都应该有相当大的影响。在约12
    FPS的阈值下，一系列帧开始看起来像连续运动而不是*幻灯片*。帧率越高，运动看起来越平滑。传统上，手绘动画电影在大多数场景中以每秒12幅画面的速度运行，在快速动作中以每秒24幅画面的速度运行。
- en: Besides the software parameters, external factors can also greatly affect the
    frame rate. Examples include the camera parameters, the lens parameters, and the
    scene's brightness.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 除了软件参数外，外部因素也会极大地影响帧率。例如，包括相机参数、镜头参数和场景的亮度。
- en: 'Let''s try another recipe. Whereas our default recipe accentuates motion at
    edges that have high grayscale contrast, this next recipe accentuates motion in
    all areas (edge or non-edge) that have either high color or grayscale contrast.
    By considering three color channels instead of one grayscale channel, we are tripling
    the amount of data that is processed by the FFT and IFFT. To offset this change,
    we need to cut each dimension of the capture resolution to half of its default
    value, thus reducing the amount of data to *1/2 * 1/2 = 1/4* times the default
    amount. As a net change, the FFT and IFFT process *3 * 1/4 = 3/4* times the default
    amount of data, a small decrease. The following initialization statement shows
    our new recipe''s parameters:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试另一个食谱。与我们的默认食谱强调具有高灰度对比度的边缘运动不同，这个下一个食谱强调所有区域（边缘或非边缘）的运动，无论是高颜色还是灰度对比度。通过考虑三个颜色通道而不是一个灰度通道，我们将FFT和IFFT处理的数据量增加了三倍。为了抵消这种变化，我们需要将捕获分辨率的每个维度减半到其默认值的一半，从而将数据量减少到默认量的1/2
    * 1/2 = 1/4倍。作为一个净变化，FFT和IFFT处理的数据量减少了3/4倍，这是一个小的减少。以下初始化语句显示了我们的新食谱的参数：
- en: '[PRE27]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note that we are still using the default values for most parameters. If you
    found non-default values that work well for `numFFTThreads` and `numIFFTThreads`
    on your machine, enter them as well.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们仍在使用大多数参数的默认值。如果您在您的机器上找到了对`numFFTThreads`和`numIFFTThreads`有效的非默认值，请也输入它们。
- en: 'The following screenshots show the effects of our new recipe. Let''s look at
    a non-extreme example first. I was typing on my laptop when this was taken. Note
    the halos around my arms, which move a lot when I type, and a slight distortion
    and discoloration of my left cheek (your left in this mirrored image). My left
    cheek twitches a little when I think. Apparently, it is a tic already known to
    my friends and family, but rediscovered by me with the help of computer vision:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了我们的新食谱的效果。我们先来看一个非极端的例子。这张截图是在我打字时拍摄的。注意我手臂周围的晕影，当我打字时手臂移动很多，以及我左脸颊（在这面镜像图中是您的左边）的轻微扭曲和变色。当我思考时，我的左脸颊会轻微抽搐。显然，这是我朋友和家人已经知道的习惯性动作，但我在计算机视觉的帮助下重新发现了它：
- en: '![](img/2a624d19-c9ea-4e30-bb24-4641e5378363.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a624d19-c9ea-4e30-bb24-4641e5378363.png)'
- en: If you are viewing the color version of this image in the e-book, you should
    see that the halos around my arms take a green hue from the shirt and a red hue
    from the sofa. Similarly, the halos on my cheek take a magenta hue from my skin
    and a brown hue from my hair.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在查看电子书中的此图像的彩色版本，您应该会看到我手臂周围的晕影从衬衫中吸收了绿色调，从沙发上吸收了红色调。同样，我脸颊上的晕影从我的皮肤中吸收了洋红色调，从我的头发中吸收了棕色调。
- en: 'Now, let''s consider a more fanciful example. If we were Jedi instead of secret
    agents, we might wave a steel ruler in the air and pretend it was a lightsaber.
    While testing the theory that Lazy Eyes could make the ruler *look like a real
    lightsaber*, I took the following screenshot. This screenshot shows two pairs
    of light and dark lines in two places where I was waving the lightsaber ruler.
    One of the pairs of lines passes through each of my shoulders. The Light Side
    (the light line) and the Dark Side (the dark line) show opposite ends of the ruler''s
    path as it moved. The lines are especially clear in the color version in the e-book:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑一个更富有想象力的例子。如果我们是绝地武士而不是秘密特工，我们可能会在空中挥舞一把钢尺，假装它是光剑。在测试“懒眼”能否让钢尺看起来像真正的光剑的理论时，我拍了以下这张截图。这张截图显示了我在挥舞光剑尺时两个地方的两对明暗线条。其中一对线条穿过我的每个肩膀。光明面（亮线）和黑暗面（暗线）显示了钢尺移动时的相反端点。在电子书的彩色版本中，线条特别清晰：
- en: '![](img/bd02af24-f872-40ae-b53f-79cd91a93532.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd02af24-f872-40ae-b53f-79cd91a93532.png)'
- en: 'Finally, the moment for which we have all been waiting—a recipe for amplifying
    a heartbeat! If you have a heart rate monitor, start by measuring your heart rate.
    Mine is approximately 87 **beats per minute** (**bpm**) as I type these words
    and listen to inspiring ballads by Canadian folk singer Stan Rogers. To convert
    bpm to Hz, divide the bpm value by 60 (the number of seconds per minute), which
    gives (87 / 60) Hz = 1.45 Hz in my case. The most visible effect of a heartbeat
    is that a person''s skin changes color, becoming more red or purple when blood
    is pumped through an area. Thus, let''s modify our second recipe, which is able
    to amplify color motions in non-edge areas. Choosing a frequency range centered
    on 1.45 Hz, we have the following initializer:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们一直等待的时刻——放大心跳的菜谱！如果你有心率监测器，请先测量你的心率。当我写这些话并听加拿大民谣歌手Stan Rogers的鼓舞人心的民谣时，我的心率大约是87
    **每分钟跳动**（**bpm**）。要将bpm转换为Hz，将bpm值除以60（每分钟的秒数），在我的情况下，(87 / 60) Hz = 1.45 Hz。心跳最明显的影响是，当血液通过一个区域时，一个人的皮肤会改变颜色，变得更红或更紫。因此，让我们修改我们的第二个菜谱，它能够放大非边缘区域的颜色运动。选择以1.45
    Hz为中心的频率范围，我们有以下初始化器：
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Customize `minHz` and `maxHz` based on your own heart rate. Remember to also
    specify `numFFTThreads` and `numIFFTThreads` if non-default values work best for
    you on your machine.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你自己的心率自定义`minHz`和`maxHz`。记住，如果你的机器上非默认值效果最好，也要指定`numFFTThreads`和`numIFFTThreads`。
- en: 'Even when amplified, a heartbeat is difficult to show in still images; it is
    much clearer in the live video when running the app. However, take a look at the
    following pair of screenshots. My skin in the left-hand screenshot is more yellow
    (and lighter), whereas in the right-hand screenshot it is more purple (and darker).
    For comparison, note that there is no change in the cream-colored curtains in
    the background:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 即使放大，心跳在静态图像中也很难显示；在运行应用程序的实时视频中，它要清晰得多。然而，看看以下这对截图。在左边的截图中，我的皮肤更黄（更亮），而在右边的截图中，它更紫（更暗）。为了比较，请注意，背景中奶油色的窗帘没有任何变化：
- en: '![](img/471e21b7-e4d8-41a7-bbee-6a29e4e94f42.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/471e21b7-e4d8-41a7-bbee-6a29e4e94f42.png)'
- en: Three recipes are a good start, and they're certainly enough to fill a cooking
    TV show. So, why not go and observe some other motions in your environment, try
    to estimate their frequencies, and then configure `Lazy Eyes` to amplify them.
    How do they look with grayscale amplification versus color amplification? Edge
    (Laplacian) versus area (Gaussian)? What about when different history lengths,
    pyramid levels, and amplification multipliers are used?
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 三个菜谱是一个良好的开始，它们当然足够填满一个烹饪电视节目。那么，为什么不出去观察一下你周围的其他动作，尝试估计它们的频率，然后配置`Lazy Eyes`来放大它们呢？它们在灰度放大与颜色放大之间看起来如何？边缘（拉普拉斯）与面积（高斯）之间呢？当使用不同的历史长度、金字塔级别和放大倍数时又会怎样？
- en: Check this book's GitHub repository, [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition),
    for additional recipes, and feel free to share your own by mailing me at [josephhowse@nummist.com](mailto:josephhowse@nummist.com).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 检查这本书的GitHub仓库[https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition)，以获取更多菜谱，并且请随时通过邮件[mailto:josephhowse@nummist.com](mailto:josephhowse@nummist.com)与我分享你的想法。
- en: Summary
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has introduced the relationship between computer vision and digital
    signal processing. We have considered a video feed as a collection of many signals—one
    for each channel value of each pixel—and we have learned that repetitive motions
    create wave patterns in some of these signals. We have used the fast Fourier transform
    and its inverse to create an alternative video stream that only sees certain frequencies
    of motion. Finally, we have superimposed this filtered video atop the original
    to amplify the selected frequencies of motion. There, we summarized Eulerian video
    magnification in 100 words!
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了计算机视觉与数字信号处理之间的关系。我们将视频流视为许多信号的集合——每个像素的每个通道值对应一个信号——并且我们了解到重复的动作在这些信号中产生了波形模式。我们使用了快速傅里叶变换及其逆变换来创建一个只看到某些运动频率的替代视频流。最后，我们将这个过滤后的视频叠加在原始视频上，以放大所选运动频率。在那里，我们用100个字总结了欧拉视频放大！
- en: Our implementation adapts Eulerian video magnification to real-time by running
    the FFT repeatedly on a sliding window of recently captured frames, rather than
    running it once on an entire prerecorded video. We have considered optimizations
    such as limiting our signal processing to grayscale, recycling large data structures
    rather than recreating them, and using several threads.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现通过在最近捕获的帧的滑动窗口上反复运行FFT，而不是在整个预录制的视频上运行一次，将欧拉视频放大应用于实时。我们已经考虑了优化，例如将我们的信号处理限制为灰度，回收大型数据结构而不是重新创建它们，以及使用多个线程。
- en: Seeing things in different light
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从不同的角度看待事物
- en: Although we began this chapter by presenting Eulerian video magnification as
    a useful technique for visible light, it is also applicable to other kinds of
    light or radiation. For example, a person's blood beneath the skin (in veins and
    bruises) is more visible when imaged in **ultraviolet** (**UV**) or in **near
    infrared** (**NIR**) than in visible light. This is because blood is darker in
    UV light than in visible light, and skin is more transparent in NIR light than
    in visible light. Thus, a UV or NIR video might be an even better input when trying
    to magnify a person's pulse.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们是以将欧拉视频放大作为可见光的有用技术来介绍这一章，但它也适用于其他类型的灯光或辐射。例如，当皮肤下的血液（在静脉和瘀伤中）在**紫外光**（UV）或**近红外光**（NIR）中成像时比在可见光中更明显。这是因为血液在紫外光中的颜色比在可见光中更深，而皮肤在近红外光中的透明度比在可见光中更高。因此，当尝试放大一个人的脉搏时，UV或NIR视频可能是一个更好的输入。
- en: We will experiment with invisible light in the next chapter, [Chapter 8](5d2f960a-10ed-4efe-a195-47843cdf608b.xhtml),
    *Stopping Time and Seeing like a Bee*. Q's gadgets will inspire us once again!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中实验不可见光，[第8章](5d2f960a-10ed-4efe-a195-47843cdf608b.xhtml)，*停止时间，像蜜蜂一样看世界*。Q的装置将再次激发我们！
