<html><head></head><body>
<div id="sbo-rt-content"><div class="Basic-Text-Frame" id="_idContainer043">
<h1 class="chapterNumber">2</h1>
<h1 class="chapterTitle" id="_idParaDest-32">The Machine Learning Development Process</h1>
<p class="normal">In this chapter, we will define how the work for any successful <strong class="keyWord">machine learning</strong> (<strong class="keyWord">ML</strong>) software engineering project can be divided up. Basically, we will answer the question of how you <em class="italic">actually organize the doing</em> of a successful ML project. We will not only discuss the process and workflow but we will also set up the tools you will need for each stage of the process and highlight some important best practices with real ML code examples.</p>
<p class="normal">In this edition, there will be more<a id="_idIndexMarker069"/> details on an important data science and ML project management methodology: <strong class="keyWord">Cross-Industry Standard Process for Data Mining</strong> (<strong class="keyWord">CRISP-DM</strong>). This will include a discussion of how this methodology compares to traditional Agile and Waterfall methodologies and will provide some tips and tricks for applying it to your ML projects. There are also<a id="_idIndexMarker070"/> far more detailed examples to help you get up and running with <strong class="keyWord">continuous integration/continuous deployment</strong> (<strong class="keyWord">CI/CD</strong>) using GitHub Actions, including how to run ML-focused processes such as automated<a id="_idIndexMarker071"/> model validation. The advice on getting up and running in an <strong class="keyWord">Interactive Development Environment</strong> (<strong class="keyWord">IDE</strong>) has also been made more tool-agnostic, to allow for those using any appropriate IDE. As before, the chapter will focus heavily on a “four-step”<strong class="keyWord"> </strong>methodology I propose that encompasses a <em class="italic">discover, play, develop, deploy</em> workflow for your ML projects. This project workflow will be compared with the CRISP-DM methodology, which is very popular in data science circles. We will also discuss the appropriate development tooling and its configuration and integration for a successful project. We will also cover version control strategies and their basic implementation, and setting up CI/CD for your ML project. Then, we will introduce some potential execution environments as the target destinations for your ML solutions. By the end of this chapter, you will be set up for success in your Python ML engineering project. This is the foundation on which we will build everything in subsequent chapters.</p>
<p class="normal">As usual, we will conclude the chapter by summarizing the main points and highlighting what this means as we work through the rest of the book.</p>
<p class="normal">Finally, it is also important to note that although we will frame the discussion here in terms of ML challenges, most of what you will learn in this chapter can also be applied to other Python software engineering projects. My hope is that the investment in building out these foundational concepts in detail will be something you can leverage again and again in all of your work.</p>
<p class="normal">We will explore all of this in the following sections and subsections:</p>
<ul>
<li class="bulletList">Setting up our tools</li>
<li class="bulletList">Concept to solution in four steps:<ul>
<li class="bulletList">Discover</li>
<li class="bulletList">Play</li>
<li class="bulletList">Develop</li>
<li class="bulletList">Deploy</li>
</ul>
</li>
</ul>
<p class="normal">There is plenty of exciting stuff to get through and lots to learn – so let’s get started!</p>
<h1 class="heading-1" id="_idParaDest-33">Technical requirements</h1>
<p class="normal">As in <em class="chapterRef">Chapter 1</em>, <em class="italic">Introduction to ML Engineering</em> if you want to run the examples provided here, you can create a Conda environment using the environment YAML file provided in the <code class="inlineCode">Chapter02</code> folder of the book’s GitHub repository:</p>
<pre class="programlisting con"><code class="hljs-con">conda env create –f mlewp-chapter02.yml
</code></pre>
<p class="normal">On top of this, many of the examples in this chapter will require the use of the following software and packages. These will also stand you in good stead for following the examples in the rest of the book:</p>
<ul>
<li class="bulletList">Anaconda</li>
<li class="bulletList">PyCharm Community Edition, VS Code, or another Python-compatible IDE</li>
<li class="bulletList">Git</li>
</ul>
<p class="normal">You will also need the following:</p>
<ul>
<li class="bulletList">An Atlassian Jira account. We will discuss this more later in the chapter, but you can sign up for one for free at <a href="https://www.atlassian.com/software/jira/free"><span class="url">https://www.atlassian.com/software/jira/free</span></a>.</li>
<li class="bulletList">An AWS account. This will also be covered in the chapter, but you can sign up for an account at <a href="https://aws.amazon.com/"><span class="url">https://aws.amazon.com/</span></a>. You will need to add payment details to sign up for AWS, but everything we do in this book will only require the free tier solutions.</li>
</ul>
<p class="normal">The technical steps in this chapter were all tested on both a Linux machine running Ubuntu 22.04 LTS with a user profile that had admin rights and on a Macbook Pro M2 with the setup described in <em class="chapterRef">Chapter 1</em>, <em class="italic">Introduction to ML Engineering.</em> If you are running the steps on a different system, then you may have to consult the documentation for that specific tool if the steps do not work as planned. Even if this is the case, most of the steps will be the same, or very similar, for most systems. You can also check out all of the code for this chapter in the book’s repository at <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter02"><span class="url">https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter02</span></a>. The repo will also contain further resources for getting the code examples up and running.</p>
<h1 class="heading-1" id="_idParaDest-34">Setting up our tools</h1>
<p class="normal">To prepare for the work<a id="_idIndexMarker072"/> in the rest of this chapter, and indeed the rest of the book, it will be helpful to set up some tools. At a high level, we need the following:</p>
<ul>
<li class="bulletList">Somewhere to code</li>
<li class="bulletList">Something to track our code changes</li>
<li class="bulletList">Something to help manage our tasks</li>
<li class="bulletList">Somewhere to provision infrastructure and deploy our solution</li>
</ul>
<p class="normal">Let’s look at how to approach each of these in turn:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Somewhere to code</strong>: First, although the weapon of choice for coding by data scientists is of course Jupyter Notebook, once you begin to make the move toward ML engineering, it will be important to have an IDE to hand. An IDE is basically an application that comes with a series of built-in tools and capabilities to help you to develop the best software that you can. <strong class="keyWord">PyCharm</strong> is an excellent example for Python developers and comes with a wide variety<a id="_idIndexMarker073"/> of plugins, add-ons, and integrations useful to ML engineers. You can download the Community Edition from JetBrains at <a href="https://www.jetbrains.com/pycharm/"><span class="url">https://www.jetbrains.com/pycharm/</span></a>. Another popular development tool is the lightweight but powerful source code editor VS Code. Once you have successfully installed PyCharm, you can create a new project or open an existing one from the <strong class="keyWord">Welcome to PyCharm</strong> window, as shown in <em class="italic">Figure 2.1</em>:
    <figure class="mediaobject"><img alt="Figure 2.1 – Opening or creating your PyCharm project " height="590" src="../Images/B19525_02_01.png" width="760"/></figure>
<p class="packt_figref">Figure 2.1: Opening or creating your PyCharm project.</p></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord">Something to track code changes</strong>: Next on the list is a code version control system. In this book, we will use <strong class="keyWord">GitHub</strong> but there are a variety<a id="_idIndexMarker074"/> of solutions, all freely available, that are based<a id="_idIndexMarker075"/> on the same underlying open-source <strong class="keyWord">Git</strong> technology. Later sections will discuss how to use these as part of your development workflow, but first, if you do not have a version control system set up, you can navigate to <a href="http://github.com"><span class="url">github.com</span></a> and create a free account. Follow the instructions on the site to create your first repository, and you will be shown a screen that looks something like <em class="italic">Figure 2.2</em>. To make your life easier later, you should select <strong class="screenText">Add a README file</strong> and <strong class="screenText">Add .gitignore</strong> (then select <strong class="screenText">Python</strong>). The README file provides an initial Markdown file for you to get started with and somewhere to describe your project. The <code class="inlineCode">.gitignore</code> file tells your Git distribution to ignore certain types of files that in general are not important for version<a id="_idIndexMarker076"/> control. It is up to you whether you want the repository to be public or private and what license you wish to use. The repository<a id="_idIndexMarker077"/> for this book uses the <strong class="keyWord">MIT license</strong>:
    <figure class="mediaobject"><img alt="Figure 2.2 – Setting up your GitHub repository " height="633" src="../Images/B19525_02_02.png" width="690"/></figure>
<p class="packt_figref">Figure 2.2: Setting up your GitHub repository.</p>
<p class="normal">Once you have set up your IDE and version control system, you need to make them talk to each other by using the Git plugins provided with PyCharm. This is as simple as navigating to <strong class="screenText">VCS</strong> | <strong class="screenText">Enable Version Control Integration</strong> and selecting <strong class="screenText">Git</strong>. You can edit the version control settings by navigating to<strong class="screenText"> File</strong> | <strong class="screenText">Settings</strong> | <strong class="screenText">Version</strong> <strong class="screenText">Control</strong>; see <em class="italic">Figure 2.3</em>:</p>
<figure class="mediaobject"><img alt="Figure 2.3 – Configuring version control with PyCharm " height="542" src="../Images/B19525_02_03.png" width="623"/></figure>
<p class="packt_figref">Figure 2.3: Configuring version control with PyCharm.</p></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord">Something to help manage our tasks</strong>: You are now ready to write Python and track your code changes, but are you ready to manage or participate in a complex project<a id="_idIndexMarker078"/> with other team members? For this, it is often useful to have a solution where you can track tasks, issues, bugs, user stories, and other documentation and items of work. It also helps if this has good integration points with the other tools you will use. In this book, we will use <strong class="keyWord">Jira</strong> as an example<a id="_idIndexMarker079"/> of this. If you navigate to <a href="https://www.atlassian.com/software/jira"><span class="url">https://www.atlassian.com/software/jira</span></a>, you can create a free cloud Jira account and then follow the interactive tutorial within the solution to set up your first<a id="_idIndexMarker080"/> board and create some tasks. <em class="italic">Figure 2.4</em> shows the task board for this book project, called <strong class="keyWord">Machine Learning Engineering in Python</strong> (<strong class="keyWord">MEIP</strong>):
    <figure class="mediaobject"><img alt="" height="492" role="presentation" src="../Images/B19525_02_04.png" width="761"/></figure>
<p class="packt_figref">Figure 2.4: The task board for this book in Jira.</p></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord">Somewhere to provision infrastructure and deploy our solution</strong>: Everything that you have just installed and set up is tooling that will really help take your workflow and software development practices to the next level. The last piece of the puzzle is having the tools, technologies, and infrastructure available for deploying the end solution. The management of computing infrastructure for applications was (and often still is) the provision of dedicated infrastructure teams, but with the advent of public clouds, there has been real democratization of this capability for people working across the spectrum of software roles. In particular, modern ML engineering is very dependent on the successful<a id="_idIndexMarker081"/> implementation<a id="_idIndexMarker082"/> of cloud technologies, usually through the main<a id="_idIndexMarker083"/> public cloud providers such as <strong class="keyWord">Amazon Web Services</strong> (<strong class="keyWord">AWS</strong>), <strong class="keyWord">Microsoft Azure</strong>, or <strong class="keyWord">Google Cloud Platform</strong> (<strong class="keyWord">GCP</strong>). This book will utilize tools found in the AWS ecosystem, but all of the tools and techniques you will find here have equivalents in the other clouds.</li>
</ul>
<p class="normal">The flip side of the democratization<a id="_idIndexMarker084"/> of capabilities that the cloud brings is that teams who own the deployment of their solutions have to gain new skills and understanding. I am a strong believer in the principle that “<em class="italic">you build it, you own it, you run it</em>” as far as possible, but this means that as an ML engineer, you will have to be comfortable with a host of potential new tools and principles, as well as <em class="italic">owning</em> the performance of your deployed solution. <em class="italic">With great power comes great responsibility</em> and all that. In <em class="chapterRef">Chapter 5</em>, <em class="italic">Deployment Patterns and Tools</em>, we will dive into this topic<a id="_idIndexMarker085"/> in detail.</p>
<p class="normal">Let’s talk through setting this up.</p>
<h2 class="heading-2" id="_idParaDest-35">Setting up an AWS account</h2>
<p class="normal">As previously stated, you don’t have<a id="_idIndexMarker086"/> to use AWS, but that’s what we’re going to use throughout this book. Once it’s set up here, you can use it for everything we’ll do:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">To set up an AWS account, navigate to <a href="http://aws.amazon.com"><span class="url">aws.amazon.com</span></a> and select <strong class="screenText">Create Account</strong>. You will have to add some payment details but everything we mention in this book can be explored through the <em class="italic">free tier</em> of AWS, where you do not incur a cost below a certain threshold of consumption.</li>
<li class="numberedList">Once you have created your account, you can navigate to the AWS Management Console, where you can see all the services that are available to you (see <em class="italic">Figure 2.5</em>):</li>
</ol>
<figure class="mediaobject"><img alt="Figure 2.5 – The AWS Management Console " height="364" src="../Images/B19525_02_05.png" width="755"/></figure>
<p class="packt_figref">Figure 2.5: The AWS Management Console.</p>
<p class="normal">With our AWS account ready to go, let’s look at the four steps that cover the whole process.</p>
<h1 class="heading-1" id="_idParaDest-36">Concept to solution in four steps</h1>
<p class="normal">All ML projects are unique<a id="_idIndexMarker087"/> in some way: the organization, the data, the people, and the tools and techniques employed will never be exactly the same for any two projects. This is good, as it signifies progress as well as the natural variety that makes this such a fun space to work in.</p>
<p class="normal">That said, no matter the details, broadly speaking, all successful ML projects actually have a good deal in common. They require the translation of a business problem into a technical problem, a lot of research and understanding, proofs of concept, analyses, iterations, the consolidation of work, the construction of the final product, and its deployment to an appropriate environment. That is ML engineering in a nutshell!</p>
<p class="normal">Developing this a bit further, you can start to bucket these activities into rough categories or stages, the results of each being necessary inputs for later stages. This is shown in <em class="italic">Figure 2.6</em>:</p>
<figure class="mediaobject"><img alt="Figure 2.6 – The stages that any ML project goes through as part of the ML development process " height="314" src="../Images/B19525_02_06.png" width="557"/></figure>
<p class="packt_figref">Figure 2.6: The stages that any ML project goes through as part of the ML development process.</p>
<p class="normal">Each category of work has a slightly different flavor, but taken together, they provide the backbone of any good ML project. The next few sections will develop the details of each of these categories and begin to show you how they can be used to build your ML engineering solutions. As we will discuss later, it is also not necessary for you to tackle your entire project in four steps like this; you can actually work through each of these steps for a specific feature or part of your overall project. This will be covered in the <em class="italic">Selecting a software development methodology</em> section.</p>
<p class="normal">Let’s make this a bit more real. The main focus<a id="_idIndexMarker088"/> and outputs of every stage can be summarized as shown in <em class="italic">Table 2.1</em>:</p>
<table class="table-container" id="table001-1">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Stage</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Outputs</strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Discover</p>
</td>
<td class="table-cell">
<p class="normal">Clarity on the business question.</p>
<p class="normal">Clear arguments for ML over another approach.</p>
<p class="normal">Definition of the KPIs and metrics you want to optimize.</p>
<p class="normal">A sketch of the route to value.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Play</p>
</td>
<td class="table-cell">
<p class="normal">Detailed understanding of the data.</p>
<p class="normal">Working proof of concept.</p>
<p class="normal">Agreement on the model/algorithm/logic that will solve the problem.</p>
<p class="normal">Evidence that a solution is doable within realistic resource scenarios.</p>
<p class="normal">Evidence that good ROI can be achieved.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Develop</p>
</td>
<td class="table-cell">
<p class="normal">A working solution that can be hosted on appropriate and available infrastructure.</p>
<p class="normal">Thorough test results and performance metrics (for algorithms and software).</p>
<p class="normal">An agreed retraining and model deployment strategy.</p>
<p class="normal">Unit tests, integration tests, and regression tests.</p>
<p class="normal">Solution packaging and pipelines.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Deploy</p>
</td>
<td class="table-cell">
<p class="normal">A working and tested deployment process.</p>
<p class="normal">Provisioned infrastructure with appropriate security and performance characteristics.</p>
<p class="normal">Mode retraining and management processes.</p>
<p class="normal">An end-to-end working solution!</p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 2.1: The outputs of the different stages of the ML development process.</p>
<div class="note">
<p class="normal">IMPORTANT NOTE</p>
<p class="normal">You may think that an ML engineer only really needs to consider the latter two stages, <em class="italic">develop</em>, and <em class="italic">deploy</em>, and that earlier stages are owned by the data scientist or even a business analyst. We will indeed focus mainly on these stages throughout this book and this division of labor can work very well. It is, however, crucially important that if you are going to build an ML solution, you understand all of the motivations and development steps that have gone before – you wouldn’t build a new type of rocket without understanding where you want to go first, would you?</p>
</div>
<h2 class="heading-2" id="_idParaDest-37">Comparing this to CRISP-DM</h2>
<p class="normal">The high-level categorization of project steps that we will outline in the rest of this chapter has many similarities to, and some<a id="_idIndexMarker089"/> differences from, an important methodology known as CRISP-DM. This methodology was published in 1999 and has since gathered a large following as a way to understand how to build any data project. In CRISP-DM, there are six different phases of activity, covering similar ground to that outlined in the four steps described in the previous section:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><strong class="keyWord">Business understanding</strong>: This is all about getting to know the business problem and domain area. This becomes part of the <em class="italic">Discover</em> phase in the four-step model.</li>
<li class="numberedList"><strong class="keyWord">Data understanding</strong>: Extending the knowledge of the business domain to include the state of the data, its location, and how it is relevant to the problem. Also included in the <em class="italic">Discover</em> phase.</li>
<li class="numberedList"><strong class="keyWord">Data preparation</strong>: Starting to take the data and transform it for downstream use. This will often have to be iterative. Captured in the <em class="italic">Play</em> stage.</li>
<li class="numberedList"><strong class="keyWord">Modeling</strong>: Taking the prepared data and then developing analytics on top of it; this could now include ML of various levels of sophistication. This is an activity that occurs both in the <em class="italic">Play</em> and <em class="italic">Develop</em> phases of the four-step methodology.</li>
<li class="numberedList"><strong class="keyWord">Evaluation</strong>: This stage is concerned with confirming whether the solution will meet the business requirements and performing a holistic review of the work that has gone before. This helps confirm if anything was overlooked or could be improved upon. This is very much part of the <em class="italic">Develop</em> and <em class="italic">Deploy</em> phases; in the methodology we will describe in this chapter, these tasks are very much more baked in across the project.</li>
<li class="numberedList"><strong class="keyWord">Deployment</strong>: In CRISP-DM, this was originally focused on deploying simple analytics solutions like dashboards or scheduled ETL pipelines that would run the decided-upon analytics models. 
    <p class="numberedList">In the world of model ML engineering, this stage can represent, well, anything talked about in this book! CRISP-DM suggests sub-stages around planning and then reviewing the deployment.</p></li>
</ol>
<p class="normal">As you can see<a id="_idIndexMarker090"/> from the list, many steps in CRISP-DM cover similar topics to those outlined in the four steps I propose. CRISP-DM is extremely popular across the data science community and so its merits are definitely appreciated by a huge number of data professionals across the world. Given this, you might be wondering, “Why bother developing something else then?” Let me convince you of why this is a good idea.</p>
<p class="normal">The CRISP-DM methodology is just another way to group the important activities of any data project in order<a id="_idIndexMarker091"/> to give them some structure. As you<a id="_idIndexMarker092"/> can perhaps see from the brief description of the stages I gave above and if you do further research, CRISP-DM has some potential drawbacks <a id="_idIndexMarker093"/>for use in a modern ML engineering project:</p>
<ul>
<li class="bulletList">The process outlined in CRISP-DM is relatively rigid and quite linear. This can be beneficial for providing structure but might inhibit moving fast in a project.</li>
<li class="bulletList">The methodology is very big on documentation. Most steps detail writing some kind of report, review, or summary. Writing and maintaining good documentation is absolutely critical in a project but there can be a danger of doing too much.</li>
<li class="bulletList">CRISP-DM was written in a world before “big data” and large-scale ML. It is unclear to me whether its details still apply in such a different world, where classic extract-transform-load patterns are only one of so many.</li>
<li class="bulletList">CRISP-DM definitely comes from the data world and then tries to move toward the idea of a deployable solution in the last stage. This is laudable, but in my opinion, this is not enough. ML engineering is a different discipline in the sense that it is far closer to classic software engineering than not. This is a point that this book will argue time and again. It is therefore important to have a methodology where the concepts of deployment and development are aligned with software and modern ML techniques all the way through.</li>
</ul>
<p class="normal">The <em class="italic">four-step</em> methodology<a id="_idIndexMarker094"/> attempts to alleviate some of these challenges and does so in a way that constantly makes reference to software engineering and ML skills and techniques. This does not mean that you should never use CRISP-DM in your projects; it might just be the perfect thing! As with many of the concepts introduced in this book, the important thing is to have many tools in your toolkit so that you can select the one most appropriate for the job at hand.</p>
<p class="normal">Given this, let’s now go through the four steps in detail.</p>
<h2 class="heading-2" id="_idParaDest-38">Discover</h2>
<p class="normal">Before you start working<a id="_idIndexMarker095"/> to build any solution, it is vitally important that<a id="_idIndexMarker096"/> you understand the problem you are trying to solve. This activity is often termed <strong class="keyWord">discovery</strong> in business analysis and is crucial if your ML project is going to be a success.</p>
<p class="normal">The key things to do during the discovery phase are the following:</p>
<ul>
<li class="bulletList"><em class="italic">Speak to the customer! And then speak to them again</em>: You must understand the end user requirements in detail if you are to design and build the right system.</li>
<li class="bulletList"><em class="italic">Document everything</em>: You will be judged on how well you deliver against the requirements, so make sure that all of the key points from your discussion are documented and signed off by members of your team and the customer or their appropriate representative.</li>
<li class="bulletList"><em class="italic">Define the metrics that matter</em>: It is very easy at the beginning of a project to get carried away and to feel like you can solve any and every problem with the amazing new tool you are going to build. Fight this tendency as aggressively as you can, as it can easily cause major headaches later on. Instead, steer your conversations toward defining a single or very small number of metrics that define what success will look like.</li>
<li class="bulletList"><em class="italic">Start finding out where the data lives!</em>: If you can start working out what kind of systems you will have to access to get the data you need, this saves you time later and can help you find any major issues before they derail your project.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-39">Using user stories</h3>
<p class="normal">Once you have spoken<a id="_idIndexMarker097"/> to the customer (a few times), you can<a id="_idIndexMarker098"/> start to define some <strong class="keyWord">user stories</strong>. User stories are concise and consistently formatted expressions of what the user or customer wants to see and the acceptance criteria for that feature or unit of work. For example, we may want to define a user story based on the taxi ride example from <em class="chapterRef">Chapter 1</em>, <em class="italic">Introduction to ML Engineering</em>: “As a user of our internal web service, I want to see anomalous taxi rides and be able to investigate them further.”</p>
<p class="normal">Let’s begin!</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">To add this in Jira, select the <strong class="screenText">Create</strong> button.</li>
<li class="numberedList">Next, select <strong class="screenText">Story</strong>.</li>
<li class="numberedList">Then, fill in the details as you deem appropriate.</li>
</ol>
<p class="normal">You have now added a user story<a id="_idIndexMarker099"/> to your work management tool! This allows you to do things such as create new tasks and link them to this user story or update its status as your project progresses:</p>
<figure class="mediaobject"><img alt="Figure 2.8 – An example user story in Jira " height="526" src="../Images/B19525_02_07.png" width="821"/></figure>
<p class="packt_figref">Figure 2.7: An example user story in Jira.</p>
<p class="normal">The data sources you use are particularly crucial to understand. As you know, <em class="italic">garbage in, garbage out</em>, or even worse, <em class="italic">no data, no go</em>! The particular questions you have to answer about the data are mainly centered around <strong class="keyWord">access</strong>, <strong class="keyWord">technology</strong>, <strong class="keyWord">quality</strong>, and <strong class="keyWord">relevance</strong>.</p>
<p class="normal">For access and technology, you are trying to pre-empt how much work the data engineers have to do to start their pipeline of work and how much this will hold up the rest of the project. It is therefore crucial that you get this one right.</p>
<p class="normal">A good example would be if you find out quite quickly that the main bulk of data you will need lives in a legacy internal financial system with no real modern APIs and no access request mechanism for non-finance team members. If its main backend is on-premises and you need to migrate locked-down financial data to the cloud, but this makes your business nervous, then you know you have a lot of work to do before you type a line of code. If the data already lives in an enterprise data lake that your team has access to, then you are obviously in a better position. Any challenge is surmountable if the value proposition is strong enough, but finding all this out early will save you time, energy, and money later on.</p>
<p class="normal">Relevance is a bit harder to find out before you kick off, but you can begin to get an idea. For example, if you want to perform the inventory forecast we discussed in <em class="chapterRef">Chapter 1</em>, <em class="italic">Introduction to ML Engineering</em>, do you need to pull in customer account information? If you want to create the classifier of <em class="italic">premium</em> or <em class="italic">non-premium</em> customers as marketing targets, also mentioned in <em class="chapterRef">Chapter 1</em>, <em class="italic">Introduction to ML Engineering</em>, do you need to have data on social media feeds? The question as to what is relevant will often be less clear-cut than for these examples but an important thing to remember is that you can always come back to it if you really missed something important. You are trying to capture the most important design decisions early, so common sense and lots of stakeholder and subject-matter expert engagement will go a long way.</p>
<p class="normal">Data quality is something that you can try to anticipate a little before moving forward in your project with some questions to current users or consumers of the data or those involved in its entry processes. To get a more quantitative understanding though, you will often just need<a id="_idIndexMarker100"/> to get your data scientists working with the data in a hands-on manner.</p>
<p class="normal">In the next section, we will look at how we develop proof-of-concept ML solutions in the most research-intensive phase, <em class="italic">Play</em>.</p>
<h2 class="heading-2" id="_idParaDest-40">Play</h2>
<p class="normal">In the <strong class="keyWord">play</strong> stage<a id="_idIndexMarker101"/> of the project, your aim is to work out whether solving<a id="_idIndexMarker102"/> the task even at the proof-of-concept level is feasible. To do this, you might employ the usual data science bread-and-butter techniques of exploratory data analysis and explanatory modeling we mentioned in the last chapter before moving on to creating an ML model that does what you need.</p>
<p class="normal">In this part of the process, you are not overly concerned with details of implementation, but with exploring the realms of possibility and gaining an in-depth understanding of the data and the problem, which goes beyond initial discovery work. Since the goal here is not to create <em class="italic">production-ready</em> code or to build reusable tools, you should not worry about whether or not the code you are writing is of the highest quality, or using sophisticated patterns. For example, it will not be uncommon to see code that looks something like the following examples (taken, in fact, from the repo for this book):</p>
<figure class="mediaobject"><img alt="Figure 2.9 – Some example prototype code that will be created during the play stage " height="535" src="../Images/B19525_02_08.png" width="821"/></figure>
<p class="packt_figref">Figure 2.8: Some example prototype code that will be created during the play stage.</p>
<p class="normal">Even a quick glance at these screenshots tells you a few things:</p>
<ul>
<li class="bulletList">The code is in a Jupyter notebook, which is run by a user interactively in a web browser.</li>
<li class="bulletList">The code sporadically calls methods to simply check or explore elements of the data (for example, <code class="inlineCode">df.head()</code> and <code class="inlineCode">df.dtypes</code>).</li>
<li class="bulletList">There is ad hoc code for plotting (and it’s not very intuitive!).</li>
<li class="bulletList">There is a variable called <code class="inlineCode">tmp</code>, which is not very descriptive.</li>
</ul>
<p class="normal">All of this is absolutely fine<a id="_idIndexMarker103"/> in this more exploratory phase, but one of the aims of this book is to help you understand what is required to take code like this and make it into something suitable for your production ML pipelines. The next section starts us along this path.</p>
<h2 class="heading-2" id="_idParaDest-41">Develop</h2>
<p class="normal">As we have mentioned<a id="_idIndexMarker104"/> a few times already, one of the aims<a id="_idIndexMarker105"/> of this book is to get you thinking about the fact that you are building software products that just happen to have ML in them. This means a steep learning curve for some of us who have come from more mathematical and algorithmic backgrounds. This may seem intimidating but do not despair! The good news is that we can reuse a lot of the best practices and techniques honed through the software engineering community over several decades. There is nothing new under the sun.</p>
<p class="normal">This section explores several of those methodologies, processes, and considerations that can be employed in the development phase of our ML engineering projects.</p>
<h3 class="heading-3" id="_idParaDest-42">Selecting a software development methodology</h3>
<p class="normal">One of the first things<a id="_idIndexMarker106"/> we could and should shamelessly<a id="_idIndexMarker107"/> replicate as ML engineers is the software development methodologies that are utilized<a id="_idIndexMarker108"/> in projects across the globe. One category of these, often referred to as <strong class="keyWord">Waterfall</strong>, covers project workflows that fit quite naturally with the idea of building something complex (think a building or a car). In Waterfall methodologies, there are distinct and sequential phases of work, each with a clear set of outputs that are needed before moving on to the next phase. For example, a typical Waterfall project may have phases that broadly cover requirements-gathering, analysis, design, development, testing, and deployment (sound familiar?). The key thing is that in a Waterfall-flavored project, when you are in the <em class="italic">requirements-gathering</em> phase, you should <em class="italic">only</em> be working on gathering requirements, when in the testing phase, you should <em class="italic">only</em> be working on testing, and so on. We will discuss the pros and cons of this for ML in the next few paragraphs after introducing another set of methodologies.</p>
<p class="normal">The other set of methodologies, termed <strong class="keyWord">Agile</strong>, began its life after the introduction of the <strong class="keyWord">Agile Manifesto </strong>in 2001 (<a href="https://agilemanifesto.org/"><span class="url">https://agilemanifesto.org/</span></a>). At the heart of Agile development<a id="_idIndexMarker109"/> are the ideas of flexibility, iteration, incremental updates, failing<a id="_idIndexMarker110"/> fast, and adapting to changing requirements. If you are from a research or scientific background, this concept of flexibility and adaptability based on results and new findings may sound familiar.</p>
<p class="normal">What may not be so familiar to you if you have this type of scientific or academic background is that you can still embrace these concepts within a relatively strict framework that is centered around delivery outcomes. Agile software development methodologies are all about finding the balance between experimentation and delivery. This is often done by introducing the concepts of <strong class="keyWord">ceremonies</strong> (such as <strong class="keyWord">Scrums</strong> and <strong class="keyWord">Sprint</strong> <strong class="keyWord">Retrospectives</strong>) and <strong class="keyWord">roles</strong> (such as <strong class="keyWord">Scrum Master</strong> and <strong class="keyWord">Product Owner</strong>).</p>
<p class="normal">Further to this, within Agile development, there are two variants that are extremely popular: <strong class="keyWord">Scrum</strong> and <strong class="keyWord">Kanban</strong>. Scrum projects<a id="_idIndexMarker111"/> are centered around short units of work called <strong class="keyWord">Sprints</strong> where the idea<a id="_idIndexMarker112"/> is to make additions <a id="_idIndexMarker113"/>to the product from ideation through to deployment in that small timeframe. In Kanban, the main idea is to achieve a steady <strong class="keyWord">flow</strong> of tasks from an organized backlog into work in progress through to completed work.</p>
<p class="normal">All of these<a id="_idIndexMarker114"/> methodologies (and many more besides) have their merits and their detractions. You do not have to be married to any of them; you can chop and change between them. For example, in an ML project, it may make sense to do some <em class="italic">post-deployment</em> work that has a focus on maintaining an already existing service (sometimes termed a <em class="italic">business-as-usual</em> activity) such as further model improvements or software optimizations in a Kanban framework. It may make sense to do the main delivery of your core body of work in Sprints with very clear outcomes. But you can chop and change and see what fits best for your use cases, your team, and your organization.</p>
<p class="normal">But what makes applying these types of workflows to ML projects different? What do we need to think about in this world of ML that we didn’t before? Well, some of the key points are the following:</p>
<ul>
<li class="bulletList"><em class="italic">You don’t know what you don’t know</em>: You cannot know whether you will be able to solve the problem until you have seen the data. Traditional software engineering is not as critically dependent on the data that will flow through the system as ML engineering is. We can know how to solve a problem in principle, but if the appropriate data does not exist in sufficient quantity or is of poor quality, then we can’t solve the problem in practice.</li>
<li class="bulletList"><em class="italic">Your system is alive</em>: If you build a classic website, with its backend database, shiny frontend, amazing load-balancing, and other features, then realistically, if the resource is there, it can just run forever. Nothing fundamental changes about the website and how it runs over time. Clicks still get translated into actions and page navigation still happens the same way. Now, consider putting some ML-generated advertising content based on typical user profiles in there. What is a <em class="italic">typical user profile</em> and does that change with time? With more traffic and more users, do behaviors that we never saw before become <em class="italic">the new normal?</em> Your system is learning all the time and that leads to the problems of <em class="italic">model drift</em> and <em class="italic">distributional shift</em>, as well as more complex update and rollback scenarios.</li>
<li class="bulletList"><em class="italic">Nothing is certain</em>: When building a system that uses rule-based logic, you know what<a id="_idIndexMarker115"/> you are going<a id="_idIndexMarker116"/> to get each and every time. <em class="italic">If X</em>, <em class="italic">then Y</em> means just that, always. With ML models, it is often much harder to know what the answer is when you ask the question, which is in fact why these algorithms are so powerful. </li>
</ul>
<p class="normal">But it does mean that you can have unpredictable behavior, either for the reasons discussed previously or simply because the algorithm has learned something that is not obvious about the data to a human observer, or, because ML algorithms can be based on probabilistic and statistical concepts, results come attached to some uncertainty or <em class="italic">fuzziness</em>. A classic example is when you apply logistic regression and receive the probability of the data point belonging to one of the classes. It’s a probability so you cannot say with certainty that it is the case; just how likely it is! This is particularly important to consider when the outputs of your ML system will be leveraged by users or other systems to make decisions.</p>
<p class="normal">Given these issues, in the next section, we’ll try and understand what development methodologies can help us when we build our ML solutions. In <em class="italic">Table 2.2</em>, we can see some advantages and disadvantages<a id="_idIndexMarker117"/> of each of these Agile<a id="_idIndexMarker118"/> methodologies for different stages<a id="_idIndexMarker119"/> and types of ML engineering<a id="_idIndexMarker120"/> projects:</p>
<table class="table-container" id="table002">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Methodology</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Pros</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Cons</strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Agile</p>
</td>
<td class="table-cell">
<p class="normal">Flexibility is expected.</p>
<p class="normal">Faster dev to deploy cycles.</p>
</td>
<td class="table-cell">
<p class="normal">If not well managed, can easily have scope drift.</p>
<p class="normal">Kanban or Sprints may not work well for some projects.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Waterfall</p>
</td>
<td class="table-cell">
<p class="normal">Clearer path to deployment.</p>
<p class="normal">Clear staging and ownership of tasks.</p>
</td>
<td class="table-cell">
<p class="normal">Lack of flexibility.</p>
<p class="normal">Higher admin overheads.</p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 2.2: Agile versus Waterfall for ML development.</p>
<p class="normal">Let’s move on to the next section!</p>
<h3 class="heading-3" id="_idParaDest-43">Package management (conda and pip)</h3>
<p class="normal">If I told you to write<a id="_idIndexMarker121"/> a program that did anything in data science<a id="_idIndexMarker122"/> or ML without using any libraries or packages and just pure Python, you would probably find this quite difficult to achieve in any reasonable amount of time, and incredibly boring! This is a good thing. One of the really powerful features of developing software in Python is that you can leverage an extensive ecosystem of tools and capabilities relatively easily. The flip side of this is that it would be very easy for managing the dependencies of your code base to become a very complicated and hard-to-replicate task. This is where package and environment managers such as <code class="inlineCode">pip</code> and <code class="inlineCode">conda</code> come in.</p>
<p class="normal"><code class="inlineCode">pip</code> is the standard package manager in Python and the one recommended for use by the Python Package Authority. </p>
<p class="normal">It retrieves and installs Python packages from <code class="inlineCode">PyPI</code>, the <code class="inlineCode">Python Package Index</code>. <code class="inlineCode">pip</code> is super easy to use and is often the suggested way to install packages in tutorials and books.</p>
<p class="normal"><code class="inlineCode">conda</code> is the <em class="italic">package and environment</em> manager that comes with the Anaconda and Miniconda Python distributions. A key strength of <code class="inlineCode">conda</code> is that although it comes from the Python ecosystem, and it has excellent capabilities there, it is actually a more general package manager. As such, if your project requires dependencies outside Python (the NumPy and SciPy libraries being good examples), then although <code class="inlineCode">pip</code> can install these, it can’t track all the non-Python dependencies, nor manage their versions. With <code class="inlineCode">conda</code>, this is solved.</p>
<p class="normal">You can also use <code class="inlineCode">pip</code> within <code class="inlineCode">conda</code> environments, so<a id="_idIndexMarker123"/> you can get the best of both worlds or use whatever you need for your project. The typical workflow that I use is to use <code class="inlineCode">conda</code> to manage the environments I create and then use that to install any packages I think may require non-Python dependencies that perhaps are not captured well within <code class="inlineCode">pip</code>, and then I can use <code class="inlineCode">pip</code> most of the time within the created <code class="inlineCode">conda</code> environment. Given this, throughout the book, you may see <code class="inlineCode">pip</code> or <code class="inlineCode">conda</code> installation commands used interchangeably. This is perfectly fine.</p>
<p class="normal">To get started with Conda, if you haven’t already, you<a id="_idIndexMarker124"/> can download the <strong class="keyWord">Individual</strong> distribution installer from the Anaconda website (<a href="https://www.anaconda.com/products/individual"><span class="url">https://www.anaconda.com/products/individual</span></a>). Anaconda comes with some Python packages already installed, but if you want to start from a completely empty environment, you can download Miniconda from the same website instead (they have the exact same functionality; you just start from a different base).</p>
<p class="normal">The Anaconda<a id="_idIndexMarker125"/> documentation is very helpful for getting you<a id="_idIndexMarker126"/> up to speed with the appropriate commands, but here is a quick tour of some of the key ones.</p>
<p class="normal">First, if we want to create a <code class="inlineCode">conda</code> environment called <code class="inlineCode">mleng</code> with Python version 3.8 installed, we simply execute the following in our terminal:</p>
<pre class="programlisting con"><code class="hljs-con">conda env --name mleng python=3.10
</code></pre>
<p class="normal">We can then activate the <code class="inlineCode">conda</code> environment by running the following:</p>
<pre class="programlisting con"><code class="hljs-con">source activate mleng
</code></pre>
<p class="normal">This means that any new <code class="inlineCode">conda</code> or <code class="inlineCode">pip</code> commands will install packages in this environment and not system-wide.</p>
<p class="normal">We often want to share the details of our environment with others working on the same project, so it can be useful to export all the package configurations to a <code class="inlineCode">.yml</code> file:</p>
<pre class="programlisting con"><code class="hljs-con">conda export env &gt; environment.yml
</code></pre>
<p class="normal">The GitHub repository for this book contains a file called <code class="inlineCode">mleng-environment.yml</code> for you to create your own instance of the <code class="inlineCode">mleng</code> environment. The following command creates an environment with this configuration using this file:</p>
<pre class="programlisting con"><code class="hljs-con">conda env create --file environment.yml
</code></pre>
<p class="normal">This pattern of creating a <code class="inlineCode">con</code><code class="inlineCode">da</code> environment from an environment file is a nice way to get your environments set up for running the examples in each of the chapters in the book. So, the <em class="italic">Technical requirements</em> section in each chapter will point to the name of the correct environment YAML file contained in the book’s repository. </p>
<p class="normal">These commands, coupled with your classic <code class="inlineCode">conda</code> or <code class="inlineCode">pip install</code> command, will set you up for your project quite nicely!</p>
<pre class="programlisting con"><code class="hljs-con">conda install &lt;package-name&gt;
</code></pre>
<p class="normal">Or</p>
<pre class="programlisting con"><code class="hljs-con">pip install &lt;package-name&gt;
</code></pre>
<p class="normal">I think it’s always a good practice to have many options for doing something, and in general, this is good engineering practice. So given that, now that we have covered the classic Python environment and package managers in <code class="inlineCode">conda</code> and <code class="inlineCode">pip</code>, we will cover one more package manager. This is a tool that I like for its ease of use and versatility. I think it provides a nice extension<a id="_idIndexMarker127"/> of the capabilities of <code class="inlineCode">conda</code> and <code class="inlineCode">pip</code> and <a id="_idIndexMarker128"/>can be used to complement<a id="_idIndexMarker129"/> them nicely. This tool<a id="_idIndexMarker130"/> is called Poetry and it is what we turn to now. </p>
<h3 class="heading-3" id="_idParaDest-44">Poetry</h3>
<p class="normal">Poetry is another package<a id="_idIndexMarker131"/> manager that has become very popular<a id="_idIndexMarker132"/> in recent years. It allows you to manage your project’s dependencies and package information into a single configuration file in a similar way to the environment YAML file we discussed in the section on Conda. Poetry’s strength lies in its far superior ability to help you manage complex dependencies and ensure “deterministic” builds, meaning that you don’t have to worry about the dependency of a package updating in the background and breaking your solution. It does this via the use of “lock files” as a core feature, as well as in-depth dependency checking. This means that reproducibility can often be easier in Poetry. It is important to call out that Poetry is focused on Python package management specifically, while Conda can also install and manage other packages, for example, C++ libraries. One way to think of Poetry is that it is like an upgrade of the <code class="inlineCode">pip</code> Python installation package, but one that also has some environment management capability. The next steps will explain how to set up and use Poetry for a very basic use case. </p>
<p class="normal">We will build on this with some later examples in the book. First, follow these steps:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"> First, as usual, we will install Poetry:
        <pre class="programlisting con"><code class="hljs-con">pip install poetry
</code></pre>
</li>
<li class="numberedList">After Poetry<a id="_idIndexMarker133"/> is installed, you can create a new project<a id="_idIndexMarker134"/> using the <code class="inlineCode">poetry new</code> command, followed by the name of your project:
        <pre class="programlisting con"><code class="hljs-con">poetry new mleng-with-python
</code></pre>
</li>
<li class="numberedList">This will create a new directory named <code class="inlineCode">mleng-with-python</code> with the necessary files and directories for a Python project. To manage your project’s dependencies, you can add them to the <code class="inlineCode">pyproject.toml</code> file in the root directory of your project. This file contains all of the configuration information for your project, including its dependencies and package metadata.
    <p class="normal">For example, if you are building a ML project and want to use the <code class="inlineCode">scikit-learn</code> library, you would add the following to your <code class="inlineCode">pyproject.toml</code> file:</p>
<pre class="programlisting code"><code class="hljs-code">[tool.poetry.dependencies]
scikit-learn = "*"
</code></pre></li>
</ol>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="4">You can then install the dependencies for your project by running the following command. This will install the <code class="inlineCode">scikit-learn</code> library and any other dependencies specified in your <code class="inlineCode">pyproject.toml</code> file:
        <pre class="programlisting con"><code class="hljs-con">poetry install
</code></pre>
</li>
<li class="numberedList">To use a dependency in your project, you can simply import it in your Python code like so:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
</code></pre>
</li>
</ol>
<p class="normal">As you can see, getting started with Poetry is very easy. We will return to using Poetry throughout the book in order to give you examples that complement the knowledge of Conda that we will develop. <em class="chapterRef">Chapter 4</em>, <em class="italic">Packaging Up</em>, will discuss this in detail and will show you how<a id="_idIndexMarker135"/> to get the most out of Poetry.</p>
<h3 class="heading-3" id="_idParaDest-45">Code version control</h3>
<p class="normal">If you are going to write<a id="_idIndexMarker136"/> code for real systems, you are almost<a id="_idIndexMarker137"/> certainly going to do it as part of a team. You are also going to make your life easier if you can have a clean audit trail of changes, edits, and updates so that you can see how the solution has developed. Finally, you are going to want to cleanly and safely separate out the stable versions of the solution that you are building and that can be deployed versus more transient developmental versions. All of this, thankfully, is taken care of by source code version control <a id="_idIndexMarker138"/>systems, the most popular of which is <strong class="keyWord">Git</strong>.</p>
<p class="normal">We will not go into how Git works under the hood here (there are whole books on the topic!) but we will focus on understanding the key practical elements of using it:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">You already have a GitHub account from earlier in the chapter, so the first thing to do is to create a repository with Python as the language and initialize <code class="inlineCode">README.md</code> and <code class="inlineCode">.gitignore</code> files. The next thing to do is to get a local copy of this repository by running the following command in Bash, Git Bash, or another terminal:
        <pre class="programlisting con"><code class="hljs-con">git clone &lt;repo-name&gt;
</code></pre>
</li>
<li class="numberedList">Now that you have done this, go into the <code class="inlineCode">README.md</code> file and make some edits (anything will do). Then, run the following commands to tell Git to <em class="italic">monitor</em> this file and to save your changes locally with a message briefly explaining what these are:
        <pre class="programlisting con"><code class="hljs-con">git add README.md
git commit -m "I've made a nice change …"
</code></pre>
<p class="normal">This now means that your local Git instance has stored what you’ve changed and is ready to share that with the remote repo.</p></li>
</ol>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="3">You can then incorporate these changes into the <code class="inlineCode">main</code> branch by doing the following:
        <pre class="programlisting con"><code class="hljs-con">git push origin main
</code></pre>
<p class="normal">If you now go back to the GitHub site, you will see that the changes have taken place in your remote repository and that the comments you added have accompanied the change.</p> </li>
</ol>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="4">Other people in your team can then get the updated changes by running the following:
        <pre class="programlisting con"><code class="hljs-con">git pull origin main
</code></pre>
</li>
</ol>
<p class="normal">These steps are the absolute<a id="_idIndexMarker139"/> basics of Git and there is a ton more you can learn<a id="_idIndexMarker140"/> online. What we will do now, though, is start setting up our repo and workflow in a way that is relevant to ML engineering.</p>
<h3 class="heading-3" id="_idParaDest-46">Git strategies</h3>
<p class="normal">The presence<a id="_idIndexMarker141"/> of a strategy for using version control systems can often<a id="_idIndexMarker142"/> be a key differentiator between the data science and ML engineering aspects of a project. It can sometimes be overkill to define a strict Git strategy for exploratory and basic modeling stages (<em class="italic">Discover</em> and <em class="italic">Play</em>) but if you want to engineer something for deployment (and you are reading this book, so this is likely where your head is at), then it is fundamentally important.</p>
<p class="normal">Great, but what do we mean by a Git strategy?</p>
<p class="normal">Well, let’s imagine that we just try to develop our solution without a shared direction on how to organize the versioning and code.</p>
<p class="normal">ML engineer <em class="italic">A</em> wants to start building some of the data science code into a Spark ML pipeline (more on this later) so creates a branch from <code class="inlineCode">main</code> called <code class="inlineCode">pipeline1spark</code>:</p>
<pre class="programlisting con"><code class="hljs-con">git checkout -b pipeline1spark
</code></pre>
<p class="normal">They then get to work on the branch and writes some nice code in a new file called <code class="inlineCode">pipeline.py</code>:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.</span>
tokenizer = Tokenizer(inputCol=<span class="hljs-string">"text"</span>, outputCol=<span class="hljs-string">"words"</span>)
hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(),
                      outputCol=<span class="hljs-string">"features"</span>)
lr = LogisticRegression(maxIter=<span class="hljs-number">10</span>, regParam=<span class="hljs-number">0.001</span>)
pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])
</code></pre>
<p class="normal">Great, they’ve made some excellent progress in translating some previous <code class="inlineCode">sklearn</code> code into Spark, which was deemed more appropriate for the use case. They then keep working in this branch because it has all of their additions, and they think it’s better to do everything in one place. When they want to push the branch to the remote repository, they run the following commands:</p>
<pre class="programlisting con"><code class="hljs-con">git push origin pipeline1spark
</code></pre>
<p class="normal">ML engineer <em class="italic">B</em> comes along, and they want<a id="_idIndexMarker143"/> to use ML engineer <em class="italic">A</em>’s pipeline code and build some extra steps<a id="_idIndexMarker144"/> around it. They know engineer <em class="italic">A</em>’s code has a branch with this work, so they know enough about Git to create another branch with <em class="italic">A</em>’s code in it, which <em class="italic">B</em> calls <code class="inlineCode">pipeline</code>:</p>
<pre class="programlisting con"><code class="hljs-con">git pull origin pipeline1spark
git checkout pipeline1spark
git checkout -b pipeline
</code></pre>
<p class="normal">They then add some code to read the parameters for the model from a variable:</p>
<pre class="programlisting code"><code class="hljs-code">lr = LogisticRegression(maxIter=model_config[<span class="hljs-string">"maxIter"</span>], 
                        regParam=model_config[<span class="hljs-string">"regParam"</span>])
</code></pre>
<p class="normal">Cool, engineer <em class="italic">B</em> has made an update that is starting to abstract away some of the parameters. They then push their new branch to the remote repository:</p>
<pre class="programlisting con"><code class="hljs-con">git push origin pipeline
</code></pre>
<p class="normal">Finally, ML engineer <em class="italic">C</em> joins the team and wants to get started on the code. Opening up Git and looking at the branches, they see there are three:</p>
<pre class="programlisting code"><code class="hljs-code">main
pipeline1spark
pipeline
</code></pre>
<p class="normal">So, which one should be taken as the most up to date? If they want to make new edits, where should they branch from? It isn’t clear, but more dangerous than that is if they are tasked with pushing deployment code to the execution environment, they may think that <code class="inlineCode">main</code> has all the relevant changes. On a far busier project that’s been going on for a while, they may even branch off from <code class="inlineCode">main</code> and duplicate some of <em class="italic">B</em> and <em class="italic">C</em>’s work! In a small project, you would waste time going on this wild goose chase; in a large project with many different lines of work, you would have very little chance of maintaining a good workflow:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Branch pipeline1spark - Commit 1 (Engineer A)</span>
lr = LogisticRegression(maxIter=<span class="hljs-number">10</span>, regParam=<span class="hljs-number">0.001</span>)
pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])
<span class="hljs-comment"># Branch pipeline - Commit 2 (Engineer B)</span>
lr = LogisticRegression(maxIter=model_config[<span class="hljs-string">"maxIter"</span>], 
                        regParam=model_config[<span class="hljs-string">"</span><span class="hljs-string">regParam"</span>])
pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])
</code></pre>
<p class="normal">If these commits<a id="_idIndexMarker145"/> both get pushed<a id="_idIndexMarker146"/> to the <code class="inlineCode">main</code> branch at the same time, then we will get what is called a <strong class="keyWord">merge conflict</strong>, and in each case, the engineer will have to choose which piece of code to keep, the current or new example. This would look something like this if engineer <em class="italic">A</em> pushed their changes to <code class="inlineCode">main</code> first:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
lr = LogisticRegression(maxIter=<span class="hljs-number">10</span>, regParam=<span class="hljs-number">0.001</span>)
pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])
=======
lr = LogisticRegression(maxIter=model_config[<span class="hljs-string">"maxIter"</span>], 
                        regParam=model_config[<span class="hljs-string">"regParam"</span>])
pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])
&gt;&gt;&gt;&gt;&gt;&gt;&gt; pipeline
</code></pre>
<p class="normal">The delimiters in the code<a id="_idIndexMarker147"/> show that there has been a merge conflict and that it is up to the developer to select which of the two versions of the code they want to keep.</p>
<div class="note">
<p class="normal">IMPORTANT NOTE</p>
<p class="normal">Although, in this simple case, we could potentially trust the engineers to select the <em class="italic">better</em> code, allowing situations like this to occur very frequently is a huge risk to your project. This not only wastes a huge amount of precious development time but it could also mean that you actually end up with worse code!</p>
</div>
<p class="normal">The way to avoid confusion and extra work like this is to have a very clear strategy for the use of the version control system in place, such as the one we will now explore.</p>
<h4 class="heading-4">The Gitflow workflow</h4>
<p class="normal">The biggest problem <a id="_idIndexMarker148"/>with the previous example was that all of our hypothetical engineers were actually working on the same piece of code in different places. To stop situations like this, you have to create a process that your team can all follow – in other words, a version control strategy or workflow.</p>
<p class="normal">One of the most popular of these strategies is the <strong class="keyWord">Gitflow workflow</strong>. This builds on the basic idea of having branches that are dedicated to features and extends it to incorporate the concept of releases and hotfixes, which are particularly relevant to projects with a continuous deployment element.</p>
<p class="normal">The main idea is we have several types of branches, each with clear and specific reasons for existing:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Main</strong> contains your official releases and should only contain the stable version of your code.</li>
<li class="bulletList"><strong class="keyWord">Dev</strong> acts as the main point for branching from and merging to for most work in the repository; it contains the ongoing development of the code base and acts as a staging area before <code class="inlineCode">main</code>.</li>
<li class="bulletList"><strong class="keyWord">Feature</strong> branches should not be merged straight into the <code class="inlineCode">main</code> branch; everything should branch off from <code class="inlineCode">dev</code> and then be merged back into <code class="inlineCode">dev</code>.</li>
<li class="bulletList"><strong class="keyWord">Release</strong> branches are created from <code class="inlineCode">dev</code> to kick off a build or release process before being merged into <code class="inlineCode">main</code> and <code class="inlineCode">dev</code> and then deleted.</li>
<li class="bulletList"><strong class="keyWord">Hotfix</strong> branches are for removing bugs in deployed or production software. You can branch this from <code class="inlineCode">main</code> before merging into <code class="inlineCode">main</code> and <code class="inlineCode">dev</code> when done.</li>
</ul>
<p class="normal">This can all be summarized diagrammatically as in <em class="italic">Figure 2.9</em>, which shows how the different branches contribute to the evolution of your code base in the Gitflow workflow:</p>
<figure class="mediaobject"><img alt="Figure 2.11 – The Gitflow Workflow " height="867" src="../Images/B19525_02_09.png" width="675"/></figure>
<p class="packt_figref">Figure 2.9: The Gitflow workflow.</p>
<p class="normal">This diagram is taken from <a href="https://lucamezzalira.com/2014/03/10/git-flow-vs-github-flow/"><span class="url">https://lucamezzalira.com/2014/03/10/git-flow-vs-github-flow/</span></a>. More details can be found at <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow"><span class="url">https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow</span></a>.</p>
<p class="normal">If your ML project can follow<a id="_idIndexMarker149"/> this sort of strategy (and you don’t need to be completely strict about this if you want to adapt it), you will likely see a drastic improvement in productivity, code quality, and even documentation:</p>
<figure class="mediaobject"><img alt="Figure 2.12 – Example code changes upon a pull request in GitHub " height="595" src="../Images/B19525_02_10.png" width="821"/></figure>
<figure class="mediaobject">Figure 2.10: Example code changes upon a pull request in GitHub.</figure>
<p class="normal">One important aspect we haven’t discussed yet is the concept of code reviews. These are triggered<a id="_idIndexMarker150"/> in this process by what is known as a <strong class="keyWord">pull request</strong>, where you make known your intention to merge into another branch and allow another team member to review your code before this executes. This is the natural way to introduce code review to your workflow. You do this whenever you want to merge your changes and update them into dev or main branches. The proposed changes can then be made visible to the rest of the team, where they can be debated and iterated on with further commits before completing the merge. </p>
<p class="normal">This enforces code review to improve quality, as well as creating an audit trail and safeguards for updates. <em class="italic">Figure 2.10</em> shows an example of how changes<a id="_idIndexMarker151"/> to code are made visible for debate during a pull request in GitHub.</p>
<p class="normal">Now that we have discussed some of the best practices for applying version control to your code, let’s explore how to version control the models you produce during your ML project.</p>
<h3 class="heading-3" id="_idParaDest-47">Model version control</h3>
<p class="normal">In any ML engineering <a id="_idIndexMarker152"/>project, it is not only code changes<a id="_idIndexMarker153"/> that you have to track clearly but also changes in your models. You want to track changes not only in the modeling approach but also in performance when new or different data is fed into your chosen algorithms. One of the best tools for tracking these kinds of changes<a id="_idIndexMarker154"/> and providing version control of ML models is <strong class="keyWord">MLflow</strong>, an open-source platform from <strong class="keyWord">Databricks</strong> under the stewardship of the Linux<a id="_idIndexMarker155"/> Foundation. </p>
<p class="normal">To install MLflow, run the following command in your chosen Python environment:</p>
<pre class="programlisting con"><code class="hljs-con">pip install mlflow
</code></pre>
<p class="normal">The main aim of MLflow is to provide a platform via which you can log model experiments, artifacts, and performance metrics. It does this through some very simple APIs provided by the Python <code class="inlineCode">mlflow</code> library, interfaced to selected storage solutions through a series of centrally developed and community plugins. It also comes with functionality<a id="_idIndexMarker156"/> for querying, analyzing, and importing/exporting data via a <strong class="keyWord">Graphical User Interface</strong> (<strong class="keyWord">GUI</strong>), which will look something like <em class="italic">Figure 2.11</em>:</p>
<figure class="mediaobject"><img alt="Figure 2.13 – The MLflow Tracking Server UI with some forecasting runs " height="333" src="../Images/B19525_02_11.png" width="821"/></figure>
<p class="packt_figref">Figure 2.11: The MLflow tracking server UI with some forecasting runs.</p>
<p class="normal">The library is extremely<a id="_idIndexMarker157"/> easy to use. In the following example, we will take the sales<a id="_idIndexMarker158"/> forecasting example from <em class="chapterRef">Chapter 1</em>, <em class="italic">Introduction to ML Engineering</em>, and add some basic MLflow functionality for tracking performance metrics and saving the trained Prophet model:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">First, we make the relevant imports, including MLflow’s <code class="inlineCode">pyfunc</code> module, which acts as a general interface for saving and loading models that can be written as Python functions. This facilitates working with libraries and tools not natively supported in MLflow (such as the <code class="inlineCode">fbprophet</code> library):
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> fbprophet <span class="hljs-keyword">import</span> Prophet
<span class="hljs-keyword">from</span> fbprophet.diagnostics <span class="hljs-keyword">import</span> cross_validation
<span class="hljs-keyword">from</span> fbprophet.diagnostics <span class="hljs-keyword">import</span> performance_metrics
<span class="hljs-keyword">import</span> mlflow
<span class="hljs-keyword">import</span> mlflow.pyfunc
</code></pre>
</li>
<li class="numberedList">To create a more seamless integration with the forecasting models from <code class="inlineCode">fbprophet</code>, we define a small wrapper class that inherits from the <code class="inlineCode">mlflow.pyfunc.PythonModel</code> object:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span> <span class="hljs-title">FbProphetWrapper</span>(mlflow.pyfunc.PythonModel):
    <span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, model</span>):
        self.model = model
        <span class="hljs-built_in">super</span>().__init__()
    <span class="hljs-keyword">def</span> <span class="hljs-title">load_context</span>(<span class="hljs-params">self, context</span>):
        <span class="hljs-keyword">from</span> fbprophet <span class="hljs-keyword">import</span> Prophet
        <span class="hljs-keyword">return</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title">predict</span>(<span class="hljs-params">self, context, model_input</span>):
        future = self.model.make_future_dataframe(
            periods=model_input[<span class="hljs-string">"periods"</span>][<span class="hljs-number">0</span>])
        <span class="hljs-keyword">return</span> self.model.predict(future)
</code></pre>
<p class="normal">We now wrap the functionality for training and prediction into a single helper function called <code class="inlineCode">train_predict()</code> to make running multiple times simpler. We will not define all of the details inside this function here but let’s run through<a id="_idIndexMarker159"/> the main pieces of MLflow functionality<a id="_idIndexMarker160"/> contained within it.</p></li>
</ol>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="3">First, we need to let MLflow know that we are now starting a training run we wish to track:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">with</span> mlflow.start_run():
    <span class="hljs-comment"># Experiment code and mlflow logging goes in here</span>
</code></pre>
</li>
<li class="numberedList">Inside this loop, we then define and train the model, using parameters defined elsewhere in the code:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># create Prophet model</span>
model = Prophet(
    yearly_seasonality=seasonality_params[<span class="hljs-string">'yearly'</span>],
    weekly_seasonality=seasonality_params[<span class="hljs-string">'</span><span class="hljs-string">weekly'</span>],
    daily_seasonality=seasonality_params[<span class="hljs-string">'daily'</span>]
)
<span class="hljs-comment"># train and predict</span>
model.fit(df_train)
</code></pre>
</li>
<li class="numberedList">We then perform some cross-validation to calculate some metrics we would like to log:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Evaluate Metrics</span>
df_cv = cross_validation(model, initial=<span class="hljs-string">"730 days"</span>, 
                         period=<span class="hljs-string">"180 days"</span>, horizon=<span class="hljs-string">"365 days"</span>)
df_p = performance_metrics(df_cv)
</code></pre>
</li>
<li class="numberedList">We can log these metrics, for example, the <strong class="keyWord">Root Mean Squared Error</strong> (<strong class="keyWord">RMSE</strong>) here, to our MLflow server:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Log parameter, metrics, and model to MLflow</span>
mlflow.log_metric(<span class="hljs-string">"rmse"</span>, df_p.loc[<span class="hljs-number">0</span>, <span class="hljs-string">"rmse"</span>])
</code></pre>
</li>
<li class="numberedList">Then finally, we<a id="_idIndexMarker161"/> can use our model wrapper class to log<a id="_idIndexMarker162"/> the model and print some information about the run:
        <pre class="programlisting code"><code class="hljs-code">mlflow.pyfunc.log_model(<span class="hljs-string">"model"</span>, python_model=FbProphetWrapper(model))
<span class="hljs-built_in">print</span>(
    <span class="hljs-string">"Logged model with URI: runs:/{run_id}/model"</span>.<span class="hljs-built_in">format</span>(
        run_id=mlflow.active_run().info.run_id
    )
)
</code></pre>
</li>
<li class="numberedList">With only a few extra lines, we have started to perform version control on our models and track the statistics of different runs!</li>
</ol>
<p class="normal">There are many different ways to save the ML model you have built to MLflow (and in general), which is particularly important when tracking model versions. Some of the main options are as follows:</p>
<ul>
<li class="bulletList"><strong class="keyWord">pickle</strong>: <code class="inlineCode">pickle</code> is a Python library<a id="_idIndexMarker163"/> for object serialization that is often used for the export of ML models that are written in <code class="inlineCode">scikit-learn</code> or pipelines in the wider <code class="inlineCode">scipy</code> ecosystem (<a href="https://docs.python.org/3/library/pickle.xhtml#module-pickle"><span class="url">https://docs.python.org/3/library/pickle.xhtml#module-pickle</span></a>). Although it is extremely easy to use and often very fast, you must be careful when exporting your models to <code class="inlineCode">pickle</code> files because of the following:<ul>
<li class="bulletList"><strong class="keyWord">Versioning</strong>: When you pickle<a id="_idIndexMarker164"/> an object, you have to unpickle it in other programs using the <em class="italic">same version of pickle</em> for stability reasons. This adds more complexity to managing your project.</li>
<li class="bulletList"><strong class="keyWord">Security</strong>: The documentation<a id="_idIndexMarker165"/> for <code class="inlineCode">pickle</code> states clearly that it is <em class="italic">not secure</em> and that it is very easy to construct malicious pickles, which will execute dangerous code upon unpickling. This is a very important consideration, especially as you move toward production.</li>
</ul>
<p class="normal">In general, as long as the lineage of the <code class="inlineCode">pickle</code> files you use is known and the source is trusted, they are OK to use and a very simple and fast way to share your models!</p> </li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord">joblib</strong>: <code class="inlineCode">joblib</code> is a general-purpose<a id="_idIndexMarker166"/> pipelining library in Python that is very powerful but lightweight. It has a lot of really useful capabilities centered around caching, parallelizing, and compression that make it a very versatile tool for saving and reading in your ML pipelines. It is also particularly fast for storing large <code class="inlineCode">NumPy</code> arrays, so is useful for data storage. We will use <code class="inlineCode">joblib</code> more in later chapters. It is important to note that <code class="inlineCode">joblib</code> suffers from the same security issues as <code class="inlineCode">pickle</code>, so knowing the lineage of your <code class="inlineCode">joblib</code> files is incredibly important.</li>
<li class="bulletList"><strong class="keyWord">JSON</strong>: If <code class="inlineCode">pickle</code> and <code class="inlineCode">joblib</code> aren’t appropriate, you <a id="_idIndexMarker167"/>can serialize your model and its parameters in JSON format. This is good because JSON is a standardized text serialization format that is commonly used across a variety of solutions and platforms. The caveat to using JSON serialization of your models is that you often have to manually define the JSON structure with the relevant<a id="_idIndexMarker168"/> parameters you want to store. So, it can<a id="_idIndexMarker169"/> create a lot of extra work. Several ML libraries in Python have their own export to JSON functionality, for example, the deep learning package Keras, but they can all result in quite different formats.</li>
<li class="bulletList"><strong class="keyWord">MLeap</strong>: MLeap is a serialization<a id="_idIndexMarker170"/> format and execution engine based on the <strong class="keyWord">Java Virtual Machine</strong> (<strong class="keyWord">JVM</strong>). It has integrations with Scala, PySpark, and Scikit-Learn but you will often<a id="_idIndexMarker171"/> see it used in examples and tutorials for saving Spark pipelines, especially for models built with Spark ML. This focus means it is not the most flexible of formats but is very useful if you are working in the <strong class="keyWord">Spark ecosystem</strong>.</li>
<li class="bulletList"><strong class="keyWord">ONNX</strong>: The <strong class="keyWord">Open Neural Network Exchange</strong> (<strong class="keyWord">ONNX</strong>) format is aimed at being completely cross-platform<a id="_idIndexMarker172"/> and allowing the exchange of models between the main ML frameworks and ecosystems. The main downside of ONNX is that (as you can guess from the name) it is mainly aimed at neural network-based models, with the exception of its <code class="inlineCode">scikit-learn</code> API. It is an excellent option if you are building a neural network though.</li>
</ul>
<p class="normal">In <em class="chapterRef">Chapter 3</em>, <em class="italic">From Model to Model Factory</em>, we will export our models to MLflow using some of these formats, but they are all compatible with MLflow and so you should feel comfortable using them as part of your ML engineering workflow.</p>
<p class="normal">The final section of this chapter will introduce some important concepts for planning how you wish to deploy<a id="_idIndexMarker173"/> your solution, prefacing more detailed discussions later in the book.</p>
<h2 class="heading-2" id="_idParaDest-48">Deploy</h2>
<p class="normal">The final stage<a id="_idIndexMarker174"/> of the ML development process is the one that really<a id="_idIndexMarker175"/> matters: how do you get the amazing solution you have built out into the real world and solve your original problem? The answer has multiple parts, some of which will occupy us more thoroughly later in this book but will be outlined in this section. If we are to successfully deploy our solution, first of all, we need to know our deployment options: what infrastructure is available and is appropriate for the task? We then need to get the solution from our development environment onto this production infrastructure so that, subject to appropriate orchestration and controls, it can execute the tasks we need it to and surface the results where it has to. This is where the concepts of <strong class="keyWord">DevOps</strong> and <strong class="keyWord">MLOps</strong> come into play.</p>
<p class="normal">Let’s elaborate on these two core concepts, laying the groundwork for later chapters and exploring how to begin deploying our work.</p>
<h3 class="heading-3" id="_idParaDest-49">Knowing your deployment options</h3>
<p class="normal">In <em class="chapterRef">Chapter 5</em>, <em class="italic">Deployment Patterns and Tools</em>, we will cover in detail what you need to get your ML engineering<a id="_idIndexMarker176"/> project from the <strong class="keyWord">develop</strong> to <strong class="keyWord">deploy</strong> stage, but to pre-empt that and provide a taster of what is to come, let’s explore the different types of deployment options we have at our disposal:</p>
<ul>
<li class="bulletList"><strong class="keyWord">On-premises deployment</strong>: The first option we have is to ignore the public cloud altogether<a id="_idIndexMarker177"/> and deploy our solutions in-house on owned infrastructure. This option is particularly popular and necessary for a lot of large institutions with a lot of legacy software and strong regulatory constraints on data location and processing. The basic steps for deploying on-premises are the same as deploying on the cloud but often require a lot more involvement from other teams with particular specialties. For example, if you are in the cloud, you often do not need to spend a lot of time configuring networking or implementing load balancers, whereas on-premises solutions will require these.
    <p class="normal">The big advantage of on-premises deployment is security and peace of mind that none of your data is going to traverse your company firewall. The big downsides are that it requires a larger investment upfront for hardware and that you have to expend a lot of effort to successfully configure and manage that hardware effectively. We will not be discussing on-premises deployment in detail in this book, but all of the concepts we will employ around software development, packaging, environment management, and training and prediction<a id="_idIndexMarker178"/> systems still apply.</p></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord">Infrastructure-as-a-Service</strong> (<strong class="keyWord">IaaS</strong>): If you are going to use the cloud, one of the lowest levels of abstraction<a id="_idIndexMarker179"/> you have access to for deployment is IaaS solutions. These are typically based on the concept of virtualization, such that servers with a variety of specifications can be spun up at the user’s will. These solutions often abstract away the need for maintenance and operations as part of the service. Most importantly, they allow extreme scalability of your infrastructure as you need it. Have to run 100 more servers next week? No problem, just scale up your IaaS request and there it is. Although IaaS solutions are a big step up from fully managed on-premises infrastructure, there are still several things you need to think about and configure. The balance in cloud computing is always over how easy you want things to be versus what level of control you want to have. IaaS<a id="_idIndexMarker180"/> maximizes control but minimizes (relative) ease compared<a id="_idIndexMarker181"/> to some other solutions. In <strong class="keyWord">AWS</strong>, <strong class="keyWord">Simple Storage Service</strong> (<strong class="keyWord">S3</strong>) and <strong class="keyWord">Elastic Compute Cloud</strong> (<strong class="keyWord">EC2</strong>) are good examples of IaaS offerings.</li>
<li class="bulletList"><strong class="keyWord">Platform-as-a-Service</strong> (<strong class="keyWord">PaaS</strong>): PaaS solutions are the next level up in terms of abstraction<a id="_idIndexMarker182"/> and usually provide you with a lot of capabilities<a id="_idIndexMarker183"/> without needing to know exactly what is going on under the hood. This means you can focus solely on the development tasks that the platform is geared up to support, without worrying <a id="_idIndexMarker184"/>about underlying infrastructure at all. One good example is <strong class="keyWord">AWS</strong> <strong class="keyWord">Lambda</strong> functions, which are serverless functions that can scale almost without limit. </li>
</ul>
<p class="normal">All you are required to do is enter the main piece of code you want to execute inside the function. Another good example is <strong class="keyWord">Databricks</strong>, which provides a very intuitive UI on top of the <strong class="keyWord">Spark cluster</strong> infrastructure, with the ability to provision, configure, and<a id="_idIndexMarker185"/> scale up these clusters<a id="_idIndexMarker186"/> almost seamlessly.</p>
<p class="normal">Being aware of these different options and their capabilities can help you design your ML solution and ensure that you focus your team’s engineering effort where it is most needed and will be most valuable. If your ML engineer is working on configuring routers, for example, you have definitely gone wrong somewhere.</p>
<p class="normal">But once you have selected the components you’ll use and provisioned the infrastructure, how<a id="_idIndexMarker187"/> do you integrate these together and manage your deployment and update cycles? This is what we will explore now.</p>
<h3 class="heading-3" id="_idParaDest-50">Understanding DevOps and MLOps</h3>
<p class="normal">A very powerful idea in modern<a id="_idIndexMarker188"/> software development is that your team should be able to continuously<a id="_idIndexMarker189"/> update your code base as needed, while testing, integrating, building, packaging, and deploying your solution should be as automated as possible. This then means these processes can happen on an almost continual basis without big pre-planned <strong class="keyWord">buckets</strong> of time being assigned<a id="_idIndexMarker190"/> to update cycles. This is the main idea behind <strong class="keyWord">CI/CD</strong>. CI/CD is a core part of <strong class="keyWord">DevOps</strong> and its ML-focused cousin <strong class="keyWord">MLOps</strong>, which both aim<a id="_idIndexMarker191"/> to bring together software development and post-deployment<a id="_idIndexMarker192"/> operations. Several of the concepts and solutions we will develop in this book will be built up so that they naturally fit within an MLOps framework.</p>
<p class="normal">The CI part is mainly focused on the stable incorporation of ongoing changes to the code base while ensuring functionality remains stable. The CD part is all about taking the resultant stable version of the solution and pushing it to the appropriate infrastructure. </p>
<p class="normal"><em class="italic">Figure 2.12</em> shows a high-level view of this process:</p>
<figure class="mediaobject"><img alt="Figure 2.14 – A high-level view of CI/CD processes " height="250" src="../Images/B19525_02_12.png" width="675"/></figure>
<p class="packt_figref">Figure 2.12: A high-level view of CI/CD processes.</p>
<p class="normal">In order to make CI/CD a reality, you need to incorporate tools that help automate tasks that you would traditionally perform manually in your development and deployment process. For example, if you can automate the running of tests upon merging of code, or the pushing of your code artifacts/models to the appropriate environment, then you are well on your way to CI/CD.</p>
<p class="normal">We can break this out further and think of the different types of tasks that fall into the DevOps or MLOps lifecycles for a solution. Development tasks will typically cover all of the activities that take you from a blank screen on your computer to a working piece of software. This means that development<a id="_idIndexMarker193"/> is where you spend most of your time in a DevOps or MLOps project. This covers<a id="_idIndexMarker194"/> everything from writing the code<a id="_idIndexMarker195"/> to formatting it correctly and testing it. </p>
<p class="normal"><em class="italic">Table 2.3</em> splits out these typical tasks<a id="_idIndexMarker196"/> and provides some details on how they build on each other, as well as typical tools you could use in your Python stack for enabling them.</p>
<table class="table-container" id="table003">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Lifecycle Stage</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Activity</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Details</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Tools</strong></p>
</td>
</tr>
<tr>
<td class="table-cell" rowspan="7">
<p class="normal">Dev</p>
</td>
<td class="table-cell" rowspan="4">
<p class="normal">Testing</p>
</td>
<td class="table-cell">
<p class="normal">Unit tests: tests aimed at testing the functionality smallest pieces of code.</p>
</td>
<td class="table-cell">
<p class="normal">pytest or unittest</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Integration tests: ensure that interfaces within the code and to other solutions work.</p>
</td>
<td class="table-cell">
<p class="normal">Selenium</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Acceptance tests: business focused tests.</p>
</td>
<td class="table-cell">
<p class="normal">Behave</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">UI tests: ensuring any frontends behave as expected.</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Linting</p>
</td>
<td class="table-cell">
<p class="normal">Raise minor stylistic errors and bugs.</p>
</td>
<td class="table-cell">
<p class="normal">flake8 or bandit</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Formatting</p>
</td>
<td class="table-cell">
<p class="normal">Enforce well-formatted code automatically.</p>
</td>
<td class="table-cell">
<p class="normal">black or sort</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Building</p>
</td>
<td class="table-cell">
<p class="normal">The final stage of bringing the solution together.</p>
</td>
<td class="table-cell">
<p class="normal">Docker, twine, or pip</p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 2.3: Details of the development activities carried out in any DevOps or MLOps project.</p>
<p class="normal">Next, we can think about the ML activities within MLOps, which this book will be very concerned with. This covers all of the tasks that a classic Python software engineer would not have to worry about, but that are crucially important to get right for ML engineers like us. This includes the development of capabilities to automatically train the ML models, to run the predictions or inferences the model should generate, and to bring that together inside code pipelines. It also covers the staging and management of the versions of your models, which heavily complements the idea of versioning your application code, as we do using tools like Git. Finally, an ML engineer also has to consider that they have to build out specific monitoring capabilities for the operational mode of their solution, which is not covered in traditional DevOps workflows. For an ML solution, you may have to consider monitoring things like precision, recall, the f1-score, population stability, entropy, and data drift in order to know if the model component of your solution is behaving within a tolerable range. This is very different from classic software<a id="_idIndexMarker197"/> engineering as it requires<a id="_idIndexMarker198"/> a knowledge of how ML models work, how they can go wrong, and a real <a id="_idIndexMarker199"/>appreciation of the importance of data quality to all of this. This is why ML engineering<a id="_idIndexMarker200"/> is such an exciting place to be! See <em class="italic">Table 2.4</em> for some more details on these types of activities.</p>
<table class="table-container" id="table004">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Lifecycle Stage</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Activity</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Details</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Tools</strong></p>
</td>
</tr>
<tr>
<td class="table-cell" rowspan="5">
<p class="normal">ML</p>
</td>
<td class="table-cell">
<p class="normal">Training</p>
</td>
<td class="table-cell">
<p class="normal">Train the model .</p>
</td>
<td class="table-cell">
<p class="normal">Any ML package.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Predicting</p>
</td>
<td class="table-cell">
<p class="normal">Run the predictions or inference steps.</p>
</td>
<td class="table-cell">
<p class="normal">Any ML package.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Building</p>
</td>
<td class="table-cell">
<p class="normal">Creating the pipelines and application logic in which the model is embedded.</p>
</td>
<td class="table-cell">
<p class="normal">sklearn pipelines, Spark ML pipelines, ZenML.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Staging</p>
</td>
<td class="table-cell">
<p class="normal">Tag and release the appropriate version of your models and pipelines.</p>
</td>
<td class="table-cell">
<p class="normal">MLflow or Comet.ml.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Monitoring</p>
</td>
<td class="table-cell">
<p class="normal">Track the solution performance and raise alerts when necessary.</p>
</td>
<td class="table-cell">
<p class="normal">Seldon, Neptune.ai, Evidently.ai, or Arthur.ai.</p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 2.4: Details on the ML-centered activities carried out during an MLOps project.</p>
<p class="normal">Finally, in either DevOps or MLOps, there is the Ops piece, which refers to Operations. This is all about how the solution will actually run, how it will alert you if there is an issue, and if it can recover successfully. Naturally then, operations will cover activities relating to the final packaging, build, and release of your solution. It also has to cover another type of monitoring, which is different from the performance monitoring of ML models. This monitoring has more of a focus on infrastructure utilization, stability, and scalability, on solution latency, and on the general running <a id="_idIndexMarker201"/>of the wider solution. This part of the DevOps and MLOps lifecycle <a id="_idIndexMarker202"/>is quite mature in terms<a id="_idIndexMarker203"/> of tooling, so there are many options available. Some information<a id="_idIndexMarker204"/> to get you started is presented in <em class="italic">Table 2.5</em>.</p>
<table class="table-container" id="table005">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Lifecycle Stage</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Activity</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Details</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Tools</strong></p>
</td>
</tr>
<tr>
<td class="table-cell" rowspan="3">
<p class="normal">Ops</p>
</td>
<td class="table-cell">
<p class="normal">Releasing</p>
</td>
<td class="table-cell">
<p class="normal">Taking the software you have built and storing it somewhere central for reuse.</p>
</td>
<td class="table-cell">
<p class="normal">Twine, pip, GitHub, or BitBucket.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Deploying</p>
</td>
<td class="table-cell">
<p class="normal">Pushing the software you have built to the appropriate target location and environment.</p>
</td>
<td class="table-cell">
<p class="normal">Docker, GitHub Actions, Jenkins, TravisCI, or CircleCI.</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Monitoring</p>
</td>
<td class="table-cell">
<p class="normal">Tracking the performance and utilization of the underlying infrastructure and general software performance, alerting where necessary.</p>
</td>
<td class="table-cell">
<p class="normal">DataDog, Dynatrace, or Prometheus.</p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 2.5: Details of the activities carried out in order to make a solution operational in a DevOps or MLOps project.</p>
<p class="normal">Now that we have elucidated the core concepts needed across the MLOps lifecycle, in the next section, we will discuss how to implement CI/CD practices so that we can start making this a reality in our ML engineering projects. We will also extend this to cover automated testing of the performance<a id="_idIndexMarker205"/> of your ML models and pipelines, and to perform<a id="_idIndexMarker206"/> automated retraining<a id="_idIndexMarker207"/> of your ML<a id="_idIndexMarker208"/> models.</p>
<h3 class="heading-3" id="_idParaDest-51">Building our first CI/CD example with GitHub Actions</h3>
<p class="normal">We will use GitHub Actions<a id="_idIndexMarker209"/> as our CI/CD tool in this book, but<a id="_idIndexMarker210"/> there are several other tools<a id="_idIndexMarker211"/> available that do the same job. GitHub Actions is available to anyone with a GitHub account, has a very useful set of documentation, <a href="https://docs.github.com/en/actions"><span class="url">https://docs.github.com/en/actions</span></a>, and is extremely easy to start using, as we will show now.</p>
<p class="normal">When using GitHub Actions, you have to create a <code class="inlineCode">.yml</code> file that tells GitHub when to perform the required actions and, of course, what actions to perform. This <code class="inlineCode">.yml</code> file should be put in a folder called <code class="inlineCode">.github/workflows</code> in the root directory of your repository. You will have to create this if it doesn’t already exist. We will do this in a new branch called <code class="inlineCode">feature/actions</code>. Create this branch by running:</p>
<pre class="programlisting con"><code class="hljs-con">git checkout –b feature/actions
</code></pre>
<p class="normal">Then, create a <code class="inlineCode">.yml</code> file called <code class="inlineCode">github-actions-basic.yml</code>. In the following steps, we will build up this example <code class="inlineCode">.yml</code> file for a Python<a id="_idIndexMarker212"/> project where we automatically install dependencies, run a <strong class="keyWord">linter</strong> (a solution to check for bugs, syntax errors, and other issues), and then run some unit tests. This example comes from the GitHub Starter Workflows repository (<a href="https://github.com/actions/starter-workflows/blob/main/ci/python-package-conda.yml"><span class="url">https://github.com/actions/starter-workflows/blob/main/ci/python-package-conda.yml</span></a>). Open up <code class="inlineCode">github-actions-basic.yml</code> and then execute the following:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">First, you define the name of the GitHub Actions workflow and what Git event will trigger it:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">name:</span> <span class="hljs-string">Python</span> <span class="hljs-string">package</span>
<span class="hljs-attr">on:</span> [<span class="hljs-string">push</span>]
</code></pre>
</li>
<li class="numberedList">You then list the jobs you want to execute as part of the workflow, as well as their configuration. For example, here we have one job called <code class="inlineCode">build</code>, which we want to run on the latest Ubuntu distribution, and we want to attempt the build using several different versions of Python:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">jobs:</span>
  <span class="hljs-attr">build:</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">strategy:</span>
      <span class="hljs-attr">matrix:</span>
        <span class="hljs-attr">python-version:</span> [<span class="hljs-number">3.9</span>, <span class="hljs-number">3.10</span>]
</code></pre>
</li>
<li class="numberedList">You then define the steps<a id="_idIndexMarker213"/> that execute as part of the<a id="_idIndexMarker214"/> job. Each step is separated by a hyphen and is executed as a separate command. It is important to note that the <code class="inlineCode">uses</code> keyword grabs standard GitHub Actions; for example, in the first step, the workflow uses the <strong class="keyWord">v2</strong> version of the <code class="inlineCode">checkout</code> action, and the second step sets up the Python versions we want to run in the workflow:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">steps:</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Set</span> <span class="hljs-string">up</span> <span class="hljs-string">Python</span> <span class="hljs-string">${{</span> <span class="hljs-string">matrix.python-version</span> <span class="hljs-string">}}</span>
<span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-python@v4</span>
<span class="hljs-attr">with:</span>
<span class="hljs-attr">  python-version:</span> <span class="hljs-string">${{</span> <span class="hljs-string">matrix.python-version</span> <span class="hljs-string">}}</span>
</code></pre>
</li>
<li class="numberedList">The next step installs<a id="_idIndexMarker215"/> the relevant dependencies<a id="_idIndexMarker216"/> for the solution<a id="_idIndexMarker217"/> using <code class="inlineCode">pip</code> and a <code class="inlineCode">requirements.txt</code> file (but you can use <code class="inlineCode">conda</code> of course!):
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Install</span> <span class="hljs-string">dependencies</span>
<span class="hljs-attr">run:</span> <span class="hljs-string">|</span>
<span class="hljs-string">  python</span> <span class="hljs-string">-m</span> <span class="hljs-string">pip</span> <span class="hljs-string">install</span> <span class="hljs-string">--upgrade</span> <span class="hljs-string">pip</span>
<span class="hljs-string">  pip</span> <span class="hljs-string">install</span> <span class="hljs-string">flake8</span> <span class="hljs-string">pytest</span>
<span class="hljs-string">  if</span> [ <span class="hljs-string">-f</span> <span class="hljs-string">requirements.txt</span> ]<span class="hljs-string">;</span> <span class="hljs-string">then</span> <span class="hljs-string">pip</span> <span class="hljs-string">install</span> <span class="hljs-string">-r</span> <span class="hljs-string">requirements.txt;</span> <span class="hljs-string">fi</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Lint</span> <span class="hljs-string">with</span> <span class="hljs-string">flake8</span>
</code></pre>
</li>
<li class="numberedList">We then run some linting:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Lint</span> <span class="hljs-string">with</span> <span class="hljs-string">flake8</span>
<span class="hljs-attr">run:</span> <span class="hljs-string">|</span>
<span class="hljs-comment">  # stop the build if there are Python syntax errors or undefined </span>
<span class="hljs-comment">  names</span>
<span class="hljs-string">  flake8</span> <span class="hljs-string">.</span> <span class="hljs-string">--count</span> <span class="hljs-string">--select=E9,F63,F7,F82</span> <span class="hljs-string">--show-source</span> <span class="hljs-string">--statistics</span>
<span class="hljs-comment">  # exit-zero treats all errors as warnings. The GitHub editor is </span>
<span class="hljs-comment">  127 chars wide</span>
<span class="hljs-string">  flake8</span> <span class="hljs-string">.</span> <span class="hljs-string">--count</span> <span class="hljs-string">--exit-zero</span> <span class="hljs-string">--max-complexity=10</span> <span class="hljs-string">--max-line-</span>
<span class="hljs-string">  length=127</span> <span class="hljs-string">--statistics</span>
</code></pre>
</li>
<li class="numberedList">Finally, we run our tests using our favorite Python testing library. For this step, we do not want to run through the entire repository, as it is quite complex, so for this example, we use the <code class="inlineCode">working-directory</code> keyword to only run <code class="inlineCode">pytest</code> in that directory. 
    <p class="numberedList">Since it contains a simple test function in <code class="inlineCode">test_basic.py</code>, this will automatically pass:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Test</span> <span class="hljs-string">with</span> <span class="hljs-string">pytest</span>
<span class="hljs-attr">run:</span> <span class="hljs-string">pytest</span>
<span class="hljs-attr">working-directory:</span> <span class="hljs-string">Chapter02</span>
</code></pre></li>
</ol>
<p class="normal">We have now built up the GitHub Actions<a id="_idIndexMarker218"/> workflow; the next stage is to show it running. This is taken care of automatically by GitHub, all you have to do is push to the remote repository. So, add the edited <code class="inlineCode">.yml</code> file, commit it, and then push it:</p>
<pre class="programlisting con"><code class="hljs-con">git add .github/workflows/github-actions-basic.yml
git commit –m "Basic CI run with dummy test"
git push origin feature/actions
</code></pre>
<p class="normal">After you have run these commands in the terminal, you can navigate to the GitHub UI and then click on <strong class="screenText">Actions</strong> in the top menu bar. You will then be presented with a view of all action runs for the repository like that in <em class="italic">Figure 2.13.</em></p>
<figure class="mediaobject"><img alt="" height="152" role="presentation" src="../Images/B19525_02_13.png" width="825"/></figure>
<p class="packt_figref">Figure 2.13: The GitHub Actions run as viewed from the GitHub UI.</p>
<p class="normal">If you then click on the run, you will be presented with details of all jobs that ran within the <strong class="screenText">Actions</strong> run, as shown in <em class="italic">Figure 2.14</em>.</p>
<figure class="mediaobject"><img alt="" height="326" role="presentation" src="../Images/B19525_02_14.png" width="742"/></figure>
<p class="packt_figref">Figure 2.14: GitHub Actions run details from the GitHub UI.</p>
<p class="normal">Finally, you can<a id="_idIndexMarker219"/> go into each job <a id="_idIndexMarker220"/>and see the<a id="_idIndexMarker221"/> steps that were executed, as shown in <em class="italic">Figure 2.15</em>. Clicking on these will also show the outputs from each of the steps. This is extremely useful for analyzing any failures in the run.</p>
<figure class="mediaobject"><img alt="" height="550" role="presentation" src="../Images/B19525_02_15.png" width="825"/></figure>
<p class="packt_figref">Figure 2.15: The GitHub Actions run steps as shown on the GitHub UI.</p>
<p class="normal">What we have shown so far is an example of CI. For this to be extended to cover CD, we need to include steps that push the produced solution to its target host destination. Examples are building a Python package and publishing it to <code class="inlineCode">pip</code>, or creating a pipeline and pushing it to another system<a id="_idIndexMarker222"/> for it to be picked up and run. This latter example will be covered with an <strong class="keyWord">Airflow DAG</strong> in <em class="chapterRef">Chapter 5</em>, <em class="italic">Deployment Patterns and Tools</em>. And that, in a nutshell, is how you start building your CI/CD pipelines. As mentioned, later in the book, we will build workflows specific to our ML solutions.</p>
<p class="normal">Now we will look<a id="_idIndexMarker223"/> at how we take CI/CD concepts<a id="_idIndexMarker224"/> to the next level for ML engineering<a id="_idIndexMarker225"/> and build some tests for our model performance, which can then also be triggered as part of continuous processes.</p>
<h3 class="heading-3" id="_idParaDest-52">Continuous model performance testing</h3>
<p class="normal">As ML engineers, we not only <a id="_idIndexMarker226"/>care about the core functional behavior<a id="_idIndexMarker227"/> of the code we are writing; we also have to care about the models that we are building, This is an easy thing to forget, as traditional software projects do not have to consider this component. </p>
<p class="normal">The process I will now walk you through shows how you can take some base reference data and start to build up some different flavors of tests to give confidence that your model will perform as expected when you deploy it.</p>
<p class="normal">We have already introduced how to test automatically with Pytest and GitHub Actions, the good news is that we can just extend this concept to include the testing of some model performance metrics. To do this, you need a few things in place:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Within the action or tests, you need to retrieve the reference data for performing the model validation. This can be done by pulling from a remote data store like an object store or a database, as long as you provide the appropriate credentials. I would suggest storing these as secrets in Github. Here, we will use a dataset generated in place using the <code class="inlineCode">sklearn</code> library as a simple example.</li>
<li class="numberedList">You need to retrieve the model or models you wish to test from some location as well. This could be a full-fledged model registry or some other storage mechanism. The same points around access and secrets management as in <em class="italic">point 1 </em>apply. Here we will pull a model from the <code class="inlineCode">Hugging Face Hub</code> (more on Hugging Face in <em class="chapterRef">Chapter 3</em>), but this could equally have been an MLflow Tracking instance or some other tool.</li>
<li class="numberedList">You need to define the tests you want to run and that you are confident will achieve the desired outcome. You do not want to write tests that are far too sensitive and trigger failed builds for spurious reasons, and you also want to try and define tests that are useful for capturing the types of failures you would want to flag. </li>
</ol>
<p class="normal">For <em class="italic">point 1</em>, here we grab<a id="_idIndexMarker228"/> some data from the <code class="inlineCode">sklearn</code> library and make it available to the tests through a <code class="inlineCode">pytest fixture</code>:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">test_dataset</span>() -&gt; <span class="hljs-type">Union</span>[np.array, np.array]:
    <span class="hljs-comment"># Load the dataset</span>
    X, y = load_wine(return_X_y=<span class="hljs-literal">True</span>)
    <span class="hljs-comment"># create an array of True for 2 and False otherwise</span>
    y = y == <span class="hljs-number">2</span>
    <span class="hljs-comment"># Train and test split</span>
    X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                        random_state=<span class="hljs-number">42</span>)
    <span class="hljs-keyword">return</span> X_test, y_test
</code></pre>
<p class="normal">For <em class="italic">point 2</em>, I will use the <code class="inlineCode">Hugging Face Hub</code> package to retrieve the stored model. As mentioned in the bullets above, you will need to adapt this to whatever model storage mechanism you are accessing. The repository in this case is public so there is no need to store any secrets; if you did need to do this, please use the GitHub Secrets store.</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">model</span>() -&gt; sklearn.ensemble._forest.RandomForestClassifier:
    REPO_ID = <span class="hljs-string">"</span><span class="hljs-string">electricweegie/mlewp-sklearn-wine"</span>
    FILENAME = <span class="hljs-string">"rfc.joblib"</span>
    model = joblib.load(hf_hub_download(REPO_ID, FILENAME))
    <span class="hljs-keyword">return</span> model
</code></pre>
<p class="normal">Now, we just need to write the tests. Let’s start simple with a test that confirms that the predictions of the model produce the correct object types:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">test_model_inference_types</span>(<span class="hljs-params">model, test_dataset</span>):
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(model.predict(test_dataset[<span class="hljs-number">0</span>]), np.ndarray)
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(test_dataset[<span class="hljs-number">0</span>], np.ndarray)
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(test_dataset[<span class="hljs-number">1</span>], np.ndarray)
</code></pre>
<p class="normal">We can then write a test to assert some specific conditions on the performance of the model on the test dataset is met:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">test_model_performance</span>(<span class="hljs-params">model, test_dataset</span>):
    metrics = classification_report(y_true=test_dataset[<span class="hljs-number">1</span>], 
                                    y_pred=model.predict(test_dataset[<span class="hljs-number">0</span>]),
                                    output_dict=<span class="hljs-literal">True</span>)
    <span class="hljs-keyword">assert</span> metrics[<span class="hljs-string">'False'</span>][<span class="hljs-string">'f1-score'</span>] &gt; <span class="hljs-number">0.95</span>
    <span class="hljs-keyword">assert</span> metrics[<span class="hljs-string">'False'</span>][<span class="hljs-string">'precision'</span>] &gt; <span class="hljs-number">0.9</span>
    <span class="hljs-keyword">assert</span> metrics[<span class="hljs-string">'True'</span>][<span class="hljs-string">'f1-score'</span>] &gt; <span class="hljs-number">0.8</span>
    <span class="hljs-keyword">assert</span> metrics[<span class="hljs-string">'True'</span>][<span class="hljs-string">'precision'</span>] &gt; <span class="hljs-number">0.8</span>
</code></pre>
<p class="normal">The previous test can be thought of as something like a data-driven unit test and will make sure that if you change something<a id="_idIndexMarker229"/> in the model (perhaps you change some feature engineering step<a id="_idIndexMarker230"/> in the pipeline or you change a hyperparameter), you will not breach the desired performance criteria. Once these tests have been successfully added to the repo, on the next push, the GitHub action will be triggered and you will see that the model performance test runs successfully. </p>
<p class="normal">This means we are performing some continuous model validation as part of our CI/CD process!</p>
<figure class="mediaobject"><img alt="" height="210" role="presentation" src="../Images/B19525_02_16.png" width="824"/></figure>
<p class="packt_figref">Figure 2.16: Successfully executing model validation tests as part of a CI/CD process using GitHub Actions.</p>
<p class="normal">More sophisticated tests<a id="_idIndexMarker231"/> can be built upon this simple concept, and you<a id="_idIndexMarker232"/> can adapt the environment and packages used to suit your needs.</p>
<h3 class="heading-3" id="_idParaDest-53">Continuous model training</h3>
<p class="normal">An important extension<a id="_idIndexMarker233"/> of the “continuous” concept in ML engineering<a id="_idIndexMarker234"/> is to perform continuous training. The previous section showed how to trigger some ML processes for testing purposes when pushing code; now, we will discuss how to extend this for the case where you want to trigger retraining of the model based on a code change. Later in this book, we will learn a lot about training and retraining ML models based on a variety of different triggers like data or model drift in <em class="chapterRef">Chapter 3</em>, <em class="italic">From Model to Model Factory</em>, and about how to deploy ML models in general in <em class="chapterRef">Chapter 5</em>, <em class="italic">Deployment Patterns and Tools</em>. Given this, we will not cover the details of deploying to different targets here but instead show you how to build continuous training steps into your CI/CD pipelines.</p>
<p class="normal">This is actually simpler than you probably think. As you have hopefully noticed by now, CI/CD is really all about automating a series of steps, which are triggered upon particular events occurring during the development process. Each of these steps can be very simple or more complex, but fundamentally it is always just other programs we are executing in the specified order upon activating the trigger event.</p>
<p class="normal">In this case, since we are concerned with continuous training, we should ask ourselves, when would we want to retrain during code development? Remember that we are ignoring the most obvious cases of retraining on a schedule or upon a drift in model performance or data quality, as these are touched on in later chapters. If we only consider that the code is changing for now, the natural answer is to train only when there is a substantial change to the code. </p>
<p class="normal">For example, if a trigger was fired every time we committed our code to version control, this would likely result in a lot of costly compute cycles being used for not much gain, as the ML model will likely not perform very differently in each case. We could<a id="_idIndexMarker235"/> instead limit the triggering of retraining<a id="_idIndexMarker236"/> to only occur when a pull request is merged into the main branch. In a project, this is an event that signifies a new software feature or functionality has been added and has now been incorporated into the core of the solution. </p>
<p class="normal">As a reminder, when building CI/CD in GitHub Actions, you create or edit <code class="inlineCode">YAML</code> files contained in the <code class="inlineCode">.github</code> folder of your Git repository. If we want to trigger a training process upon a pull request, then we can add something like:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">name:</span> <span class="hljs-string">Continous</span> <span class="hljs-string">Training</span> <span class="hljs-string">Example</span>
<span class="hljs-attr">on:</span> [<span class="hljs-string">pull_request</span>]
</code></pre>
<p class="normal">And then we need to define the steps for pushing the appropriate training script to the target system and running it. First, this would likely require some fetching of access tokens. Let’s assume this is for AWS and that you have loaded your appropriate AWS credentials as GitHub Secrets; for more information, see <em class="chapterRef">Chapter 5</em>, <em class="italic">Deployment Patterns and Tools</em>. We would then be able to retrieve these in the first step of a <code class="inlineCode">deploy-trainer</code> job:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">jobs:</span>
  <span class="hljs-string">deploy-trainer</span> 
    <span class="hljs-attr">runs-on:</span> [<span class="hljs-string">ubuntu-latest</span>]
    <span class="hljs-attr">steps:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name: Checkout       uses:</span> <span class="hljs-string">actions/checkout@v3</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Configure</span> <span class="hljs-string">AWS</span> <span class="hljs-string">Credentials</span>
      <span class="hljs-attr">uses:</span> <span class="hljs-string">aws-actions/configure-aws-credentials@v2</span>
      <span class="hljs-attr">with:</span>
        <span class="hljs-attr">aws-access-key-id:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_ACCESS_KEY_ID</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">aws-secret-access-key:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_SECRET_ACCESS_KEY</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">aws-region:</span> <span class="hljs-string">us-east-2</span>
        <span class="hljs-attr">role-to-assume:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_ROLE_TO_ASSUME</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">role-external-id:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_ROLE_EXTERNAL_ID</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">role-duration-seconds:</span> <span class="hljs-number">1200</span>
        <span class="hljs-attr">role-session-name:</span> <span class="hljs-string">TrainingSession</span>     
</code></pre>
<p class="normal">You may then want to copy your repository files to a target <strong class="keyWord">S3</strong> destination; perhaps they contain modules that the main training script needs to run. You could then do something like this:</p>
<pre class="programlisting code"><code class="hljs-code">    <span class="hljs-bullet">-</span> <span class="hljs-attr">name: Copy files to target destination</span>
<span class="hljs-attr">    run:</span> <span class="hljs-string">aws</span> <span class="hljs-string">s3</span> <span class="hljs-string">sync</span> <span class="hljs-string">.</span> <span class="hljs-string">s3://&lt;S3-BUCKET-NAME&gt;</span>
</code></pre>
<p class="normal">And finally, you would want<a id="_idIndexMarker237"/> to run some sort of process that uses these files<a id="_idIndexMarker238"/> to perform the training. There are so many ways to do this that I have left the specifics out for this example. Many ways for deploying ML processes will be covered in <em class="chapterRef">Chapter 5</em>, <em class="italic">Deployment Patterns and Tools</em>:</p>
<pre class="programlisting code"><code class="hljs-code">    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">training</span> <span class="hljs-string">job</span>
       <span class="hljs-attr">run:</span> <span class="hljs-string">|</span>
        <span class="hljs-comment"># Your bespoke run commands go in here using the tools of your choice!</span>
</code></pre>
<p class="normal">And with that, you have all the key pieces you need to run continuous ML model training to complement the other section on continuous model performance testing. This is how you bring the DevOps concept of CI/CD to the world of MLOps!</p>
<h1 class="heading-1" id="_idParaDest-54">Summary</h1>
<p class="normal">This chapter was all about building a solid foundation for future work. We discussed the development steps common to all ML engineering projects, which we called “<em class="italic">Discover, Play, Develop, Deploy</em>,” and contrasted this way of thinking against traditional methodologies like CRISP-DM. In particular, we outlined the aim of each of these steps and their desired outputs.</p>
<p class="normal">This was followed by a high-level discussion of tooling and a walkthrough of the main setup steps. We set up the tools for developing our code, keeping track of the changes to that code, managing our ML engineering project, and finally, deploying our solutions.</p>
<p class="normal">In the rest of the chapter, we went through the details for each of the four steps we outlined previously, with a particular focus on the <em class="italic">Develop</em> and <em class="italic">Deploy</em> stages. Our discussion covered everything from the pros and cons of Waterfall and Agile development methodologies to environment management and then software development best practices. We explored how to package your ML solution and what deployment infrastructure is available for you to use, and outlined the basics of setting up your DevOps and MLOps workflows. We finished up the chapter by discussing, in some detail, how to apply testing to our ML code, including how to automate this testing as part of CI/CD pipelines. This was then extended into the concepts of continuous model performance testing and continuous model training.</p>
<p class="normal">In the next chapter, we will turn our attention to how to build out the software for performing the automated training and retraining of your models using a lot of the techniques we have discussed here.</p>
<h1 class="heading-1" id="_idParaDest-55">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussion with the author and other readers:</p>
<p class="normal"><a href="https://packt.link/mle"><span class="url">https://packt.link/mle</span></a></p>
<p class="normal"><img alt="" height="177" role="presentation" src="../Images/QR_Code102810325355484.png" width="177"/></p>
</div>
</div></body></html>