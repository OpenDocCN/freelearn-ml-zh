- en: Chapter 2. Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Discriminant function analysis - geological measurements on brines from wells
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multinomial logistic regression - understanding program choices made by students
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tobit regression - measuring students' academic aptitude
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poisson regression - understanding species present in Galapagos Islands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Discriminant analysis** is used to distinguish distinct sets of observations
    and allocate new observations to previously defined groups. For example, if a
    study was to be carried out in order to investigate the variables that discriminate
    between fruits eaten by (1) primates, (2) birds, or (3) squirrels, the researcher
    could collect data on numerous fruit characteristics of those species eaten by
    each of the animal groups. Most fruits will naturally fall into one of the three
    categories. Discriminant analysis could then be used to determine which variables
    are the best predictors of whether a fruit will be eaten by birds, primates, or
    squirrels. Discriminant analysis is commonly used in biological species classification,
    in medical classification of tumors, in facial recognition technologies, and in
    the credit card and insurance industries for determining risk. The main goals
    of discriminant analysis are discrimination and classification. The assumptions
    regarding discriminant analysis are multivariate normality, equality of variance-covariance
    within group and low multicollinearity of the variables.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multinomial logistic regression** is used to predict categorical placement
    in or the probability of category membership on a dependent variable, based on
    multiple independent variables. It is used when the dependent variable has more
    than two nominal or unordered categories, in which dummy coding of independent
    variables is quite common. The independent variables can be either dichotomous
    (binary) or continuous (interval or ratio in scale). Multinomial logistic regression
    uses maximum likelihood estimation to evaluate the probability of categorical
    membership. It uses maximum likelihood estimation rather than the least squares
    estimation used in traditional multiple regression. The general form of the distribution
    is assumed. The starting values of the estimated parameters are used and the likelihood
    that the sample came from a population with those parameters is computed. The
    values of the estimated parameters are adjusted iteratively until the maximum
    likelihood value for the estimated parameters is obtained.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tobit regression** is used to describe the relationship between non-negative
    dependent variables and independent variables. It is also known as a censored
    regression model, designed to estimate linear relationships between variables
    when there is either left or right censoring in the dependent variable. Censoring
    takes place when cases with a value at or above some threshold, all take on the
    value of that threshold, so that the true value might be equal to the threshold,
    but it might also be higher. The Tobit model has been used in a large number of
    applications where the dependent variable is observed to be zero for some individuals
    in the sample (automobile expenditures, medical expenditures, hours worked, wages,
    and so on). This model is for metric dependent variables and then it is limited
    in the sense that we observe it only if it is above or below some cut off level.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: The wages may be limited from below by the minimum wage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The donation amount given to charity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Top coding income
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time used and leisure activity of individuals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Poisson regression** deals with situations in which the dependent variable
    is a count. Poisson regression is similar to regular multiple regression except
    that the dependent (Y) variable is an observed count that follows the Poisson
    distribution. Thus, the possible values of Y are the nonnegative integers: 0,
    1, 2, 3, and so on. It is assumed that large counts are rare. Hence, Poisson regression
    is similar to logistic regression, which also has a discrete response variable.
    However, the response is not limited to specific values as it is in logistic regression.'
  prefs: []
  type: TYPE_NORMAL
- en: Discriminant function analysis - geological measurements on brines from wells
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us assume that a study of ancient artifacts that have been collected from
    mines needs to be carried out. Rock samples have been collected from the mines.
    On the collected rock samples geochemical measurements have been carried out.
    A similar study has been carried out on the collected artifacts. In order to separate
    the samples into the mine from which they were excavated, DFA can be used as a
    function. The function can then be applied to the artifacts to predict which mine
    was the source of each artifact.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to perform discriminant function analysis we shall be using a dataset
    collected from mines.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 - collecting and describing data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The dataset on data analysis in geology titled `BRINE` shall be used. This
    can be obtained from [http://www.kgs.ku.edu/Mathgeo/Books/Stat/ASCII/BRINE.TXT](http://www.kgs.ku.edu/Mathgeo/Books/Stat/ASCII/BRINE.TXT)
    . The dataset is in a standard form, with rows corresponding to samples and columns
    corresponding to variables. Each sample is assigned to a stratigraphic unit, listed
    in the last column. There are 19 cases and eight variables in the dataset. The
    eight numeric measurements include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`No`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`HCO3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SO4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MG`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Group`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's get into the details.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 - exploring data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step is to load the following package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Version info: Code for this page was tested in R version 3.2.3 (2015-12-10)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s explore the data and understand the relationships among the variables.
    We''ll begin by importing the txt data file named `brine.txt`. We will be saving
    the data to the `brine` data frame, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we shall print the `brine` data frame. The `head()` function returns the
    `brine` data frame. The `brine` data frame is passed as an input parameter. Use
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: DFA assumes multivariate normality. The data must be checked to verify the normality
    before performing the analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to verify the appropriateness of the transformation, plotting of the
    data is carried out. The `pairs` `()` function is used to plot the data. It produces
    a matrix of scatterplots. The cross-plots should only compare the measurement
    variables in columns 1-6, the last (7th column) is the name of the group. Consider
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot is as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 2 - exploring data](img/image_02_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Step 3 - transforming data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is visible that the data has a comet-shaped distribution pattern. This indicates
    that log transformation of the data is required, which is common for geochemical
    data. It is good practice to first make a copy of the entire dataset, and then
    apply the log transformation only to the geochemical measurements. Since the data
    includes zeros as well; `log+1` transformation should be carried out instead of
    `log` transformation on the dataset. The `brine` data frame is copied to the `brine.log`
    data frame. The log transformation on the data frame is carried out. As stated
    earlier, log transformation is carried out. Look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After the data transformation, in order to re-evaluate the normality condition
    using the `pairs()` function data frame, `brine.log` is replotted. The distribution
    appears to be more normal. The skewness has been reduced compared to the earlier
    plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot is as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 3 - transforming data](img/image_02_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Step 4 - training the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The next step is about training the model. This is carried out by discriminant
    function analysis. The `lda()` function is called to perform discriminant function
    analysis as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The format of this call is much like a linear regression or ANOVA, in that
    we specify a formula. Here, the `GROUP` variable should be treated as the dependent
    variable, with the geochemical measurements as the independent variables. In this
    case, no interactions between the variables are being modeled, so the variables
    are added with `+` instead of `*`. Because `attach()` was not called, the name
    of the data frame must be supplied to the data parameter. After running the DFA,
    the first step is to view the results, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The first part of the output displays the formula that was fitted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second section is the prior probabilities of the groups, which reflects
    the proportion of each group within the dataset. In other words, if you had no
    measurements and the number of measured samples represented the actual relative
    abundances of the groups, the prior probabilities would describe the probability
    that any unknown sample would belong to each of the groups.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third section shows the group means, which is a table of the average value
    of each of the variables for each of your groups. Scanning this table can help
    you to see if the groups are distinctive in terms of one or more of the variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fourth section reports the coefficients of the discriminant function (a,
    b, and c). Because there are three groups, there are 3-1 linear discriminants
    (if you had only two groups, you would need only 1 [2-1] linear discriminants).
    For each linear discriminant (`LD1` and `LD2`), there is one coefficient corresponding,
    in order, to each of the variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the fifth section shows the proportion of the trace, which gives the
    variance explained by each discriminant function. Here, first the discriminant
    explains 75% of the variance, with the remainder explained by the second discriminant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 5 - classifying the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `predict()` function, also part of the `MASS` package, uses the `lda()`
    results to assign the samples to the groups. In other words, since `lda()` derived
    a linear function that should classify the groups, `predict()` allows you to apply
    this function to the same data to see how successful the classification function
    is. Following the statistical convention that x-hat is the prediction of x, (hat
    is added to the object name to make it clear that these are the predictions).
    Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us print `brine.log.hat` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output starts with the assigned classifications of each of our samples.
    Next, it lists the posterior probabilities of each sample to each group, with
    the probabilities in each row (that is, for each sample) summing to 1.0\. These
    posterior probabilities measure the strength of each classification. If one of
    these probabilities for a sample is much greater than all the others, that sample
    is assigned to one group with a high degree of certainty. If two or more of the
    probabilities are nearly equal, the assignment is much less certain. If there
    are many groups, the following command is a quick way to find the maximum probability
    for each sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Since most of the probabilities in the dataset are large (>0.9), this indicates
    that most of the samples in the set have been assigned to one group.
  prefs: []
  type: TYPE_NORMAL
- en: 'If most of these probabilities are large, the overall classification is successful.
    The last part of the `predict()` output lists the scores of each sample for each
    discriminant function axis. These scores can be plotted to show graphically how
    the groups are distributed in the discriminant function, just as scores from a
    principal components analysis could be plotted, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The three groups occupy distinctly different and non-overlapping regions. There
    is just one case of group 1 being close to group 2, so one can clearly state that
    the discrimination has been successful.
  prefs: []
  type: TYPE_NORMAL
- en: 'The plot is as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 5 - classifying the data](img/image_02_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'A second type of plot shows the data plot along a particular discriminant function
    axis as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![Step 5 - classifying the data](img/image_02_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Again, note the good separation of the groups along discriminant function 1,
    and particularly so for group 2.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 - evaluating the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The effectiveness of DFA in classifying the groups must be evaluated, and this
    is done by comparing the assignments made by `predict()` to the actual group assignments.
    The `table()` function is most useful for this. By convention, it is called with
    the actual assignments as the first argument and the fitted assignments as the
    second argument, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Printing the value of tab.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The rows in the output correspond to the groups specified in the original data
    and the columns correspond to the classification made by the DFA. In a perfect
    classification, large values would lie along the diagonal, with zeroes off the
    diagonal, which would indicate that all samples that belong to group 1 were discriminated
    by the DFA as belonging to group 1, and so on. The form of this table can give
    you considerable insight into which groups are reliably discriminated. It can
    also show which groups are likely to be confused and which types of misclassification
    are more common than others. The following command will calculate the overall
    predictive accuracy, that is, the proportion of cases that lie along the diagonal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here the predictive accuracy is almost 95%, quite a success. This approach measures
    what is called the resubstitution error, how well the samples are classified when
    all the samples are used to develop the discriminant function.
  prefs: []
  type: TYPE_NORMAL
- en: 'A second approach for evaluating a DFA is leave-one-out cross-validation (also
    called jackknifed validation), which excludes one observation. This approach of
    evaluating DFA uses the data that has been left out, that is, excluding one observation.
    We are now left with n - 1 observation. This cross-validation technique is done
    automatically for each sample in the dataset. To do this, add `CV=TRUE` (think
    Cross-validation) to the `lda()` call as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The success of the discrimination can be measured similarly, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the value of tab as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In this dataset, the jackknifed validation is considerably less accurate (only
    79% accurate), reflecting that the resubstitution error always overestimates the
    performance of a DFA. Such a discrepancy is particularly common with small datasets
    such as this, and discriminant function analysis is often much more successful
    with large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Multinomial logistic regression - understanding program choices made by students
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's assume that high school students are to be enrolled on a program. The
    students are given the opportunity to choose programs of their choice. The choices
    of the students are based on three options. These choices are general program,
    vocational program, and academic program. The choice of each student is based
    on each student's writing score and social economic status.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to complete this recipe we shall be using a student's dataset. The
    first step is collecting the data.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 - collecting data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The student''s dataset titled `hsbdemo` is being utilized. The dataset is available
    at: [http://voia.yolasite.com/resources/hsbdemo.csv](http://voia.yolasite.com/resources/hsbdemo.csv)
    in an MS Excel format. There are 201 data rows and 13 variables in the dataset.
    The eight numeric measurements are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`id`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`read`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`write`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`math`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`science`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`socst`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`awards`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cid`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The non-numeric measurements are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gender`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ses`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`schtyp`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prog`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`honors`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's get into the details.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 - exploring data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step is loading the packages. The `library ()` returns an error if
    the package does not exist. Use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Version info: Code for this page was tested in R version 3.2.3 (2015-12-10).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exploring the data throws some light on the relationships of the data. The
    CSV file titled `hsbdemo.csv` needs to be imported in the R environment. The imported
    data is saved in the data frame titled `ml` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Exploring the descriptive statistics of the variables that are of interest
    is to be carried out using the `with()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us obtain the mean and the standard deviation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The mean is the highest for academic and the standard deviation is the highest
    for general.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 - training the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to estimate multinomial logistic regression, the `multinom()` function
    is used. The `multinom()` function does not require the reshaping of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to choose a reference group for the outcome. We can choose
    the level of our outcome that we wish to use as our baseline. This is specified
    in the `relevel ()` function. Then, we run our model using the `multinom()` function.
    Since no p-value calculations are carried out for the regression coefficients,
    p-value tests are carried out using Wald tests (z-tests). The formula mentioned
    in the `multinom()` function is of the form response ~ predictors. The data frame
    `ml` is the data frame to interpret the variables occurring in the formula, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the test summary of coefficients is divided by the test summary of standard
    errors, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Display the value of `z` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Step 4 - testing the results of the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A two-tailed z test is carried out as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Display the value of p as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Step 5 - model improvement performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Relative risk is defined as the ratio between choosing one outcome category
    and choosing the baseline category. The relative risk is the exponential of the
    right-hand side of the linear equation. The exponential regression coefficients
    are relative risk ratios for a unit change in the predictor variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Extract the coefficients from the model and perform an exponential on it as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The relative risk ratio for a one-unit increase in the variable write is `.9437`
    for being in a general program versus an academic program. The relative risk ratio
    switching from `ses = 1` to `3` is `.3126` for being in a general program versus
    an academic program. Use the probabilities that have been predicted to get an
    insight into the model. The `fitted()` function is used to calculate predicted
    probabilities for each of our outcome levels as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Examine the changes in probability associated with one of the two variables, `ses`
    and `write`. Create small datasets varying one variable while holding the other
    one constant. First, hold the write variable at its mean and then examine the
    predicted probability for each level of the `ses` variable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking at the average predicted probabilities for different values of the
    continuous predictor variable, using predicted probabilities as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Store the predicted probabilities for each value of `ses` and write as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the mean probabilities within each level of `ses` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes, a couple of plots can convey a good deal of information. Using the
    predictions we generated for the `pp.write` object previously, we can plot the
    predicted probabilities against the writing score by the level of `ses` for different
    levels of the outcome variable. The `melt()` function takes data in wide format
    and stacks a set of columns into a single column of data. The `lpp` data frame
    is used to specify the data frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the values for `head` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we plot predicted probabilities across write values for each level of
    `ses` facetted by program type as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '![Step 5 - model improvement performance](img/image_02_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tobit regression - measuring the students' academic aptitude
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us measure the academic aptitude of a student on a scale of 200-800\. This
    measurement is based on the model using reading and math scores. The nature of
    the program in which the student has been enrolled is also to be taken into consideration.
    There are three types of programs: academic, general, and vocational. The problem
    is that some students may answer all the questions on the academic aptitude test
    correctly and score 800 even though it is likely that these students are not truly
    equal in aptitude. This may be true for all the students who may answer all the
    questions incorrectly and score 200.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to complete this recipe we shall be using a student's dataset. The
    first step is collecting the data.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 - collecting data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To develop the Tobit regression model we shall use the student dataset titled
    tobit, which is available at [http://www.ats.ucla.edu/stat/data/tobit.csv](http://www.ats.ucla.edu/stat/data/tobit.csv)
    in an MS Excel format. There are 201 data rows and five variables in the dataset.
    The four numeric measurements are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`id`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`read`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`math`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`apt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The non-numeric measurement is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`prog`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's get into the details.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 - exploring data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step is to load the following packages. The `require()` function
    is designed for use inside other functions; it returns `FALSE` and gives a warning
    (rather than an error as `library ()` does by default) if the package does not
    exist. Use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Version info: Code for this page was tested in R version 3.2.3 (2015-12-10)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Explore the data and understand the relationships among the variables. Begin
    by importing the CSV data file named `gala.txt`. This will save the data to the
    `dat` data frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'In this dataset, the lowest value of `apt` is 352\. This indicates that no
    student has received the lowest score of 200\. Even though censoring from below
    was possible, it is not required in this dataset. Use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Step 3 - plotting data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Write is a function that gives the density of a normal distribution for a given
    mean and standard deviation, which has been scaled on the count metric. In order
    to generate the histogram formulate count as *density * sample size * bin* width
    use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we shall set up the base plot as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we shall prepare a histogram, colored by proportion in different programs
    with a normal distribution overlaid as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The histogram plotted is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 3 - plotting data](img/image_02_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Looking at the preceding histogram, we can see the censoring in the values of
    `apt`, that is, there are far more cases with scores between 750 to 800 than one
    would expect compared to the rest of the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In the following alternative histogram, the excess of cases where `apt`=800
    have been highlighted. In the following histogram, the breaks option produces
    a histogram where each unique value of `apt` has its own bar (by setting breaks
    equal to a vector containing values from the minimum of `apt` to the maximum of
    apt). Because `apt` is continuous, most values of `apt` are unique in the dataset,
    although close to the center of the distribution there are a few values of apt
    that have two or three cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The spike on the far right of the histogram is the bar for cases where `apt`=800,
    the height of this bar, relative to all the others, clearly shows the excess number
    of cases with this value. Use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '![Step 3 - plotting data](img/image_02_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Step 4 - exploring relationships
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following command enables use to explore the bivariate relationships in
    the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Now plot the matrix as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '![Step 4 - exploring relationships](img/image_02_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the first row of the scatterplot matrix, the scatterplots display a relationship
    between read and apt. The relationship between math and apt is also established.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 - training the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Run the Tobit model, using the `vglm` function of the VGAM package using this
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The preceding output informs us about the options specified.
  prefs: []
  type: TYPE_NORMAL
- en: The table labeled coefficients gives the coefficients their standard errors
    and the z-statistic. No p-values are included in the summary table.
  prefs: []
  type: TYPE_NORMAL
- en: 'The interpretation of the Tobit regression coefficients is similar to that
    of OLS regression coefficients. The linear coefficients effect is on the uncensored
    latent variable:'
  prefs: []
  type: TYPE_NORMAL
- en: For a one-unit increase in read, there is a `2.6981` point increase in the predicted
    value of `apt`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A one-unit increase in `math` is associated with a `5.9146` unit increase in
    the predicted value of `apt`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The terms for `prog` have a slightly different interpretation. The predicted
    value of apt is `-46.1419` points lower for students in a vocational program than
    for students in an academic program.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coefficient labeled `(Intercept):1` is the intercept or constant for the
    model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coefficient labeled `(Intercept):2` is an ancillary statistic. Exponential
    of this value, is analogous to the square root of the residual variance in OLS
    regression. The value of `65.6773` can be compared to the standard deviation of
    academic aptitude, which was `99.21`, a substantial reduction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final log likelihood, `-1041.0629`, is shown toward the bottom of the output;
    it can be used in comparisons of nested models.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 - testing the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Calculate the p - values for each of the coefficients in the model. Calculate
    the p - value for each of the coefficients using z - values and then display them
    in a tabular manner. The coefficients for `read`, `math`, and `prog` = 3 (vocational)
    are statistically significant as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'We can test the significance of the program type overall by fitting a model
    without a program in it and using a likelihood ratio test as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The statistical significance of the prog variable is indicated by the p - value
    equal to `0.0032`. We calculate the upper and lower 95% confidence intervals for
    the coefficients as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: By plotting residuals to one, we can assess the absolute as well as relative
    (Pearson) values and assumptions such as normality and homogeneity of variance.
    This shall help in examining the model and the data fit.
  prefs: []
  type: TYPE_NORMAL
- en: 'We may also wish to examine how well our model fits the data. One way to start
    is with plots of the residuals to assess their absolute as well as relative (Pearson)
    values and assumptions such as normality and homogeneity of variance. Use the
    following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot is as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 6 - testing the model](img/image_02_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Establish the correlation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Variance accounted for is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: The correlation between the predicted and observed values of `apt` is `0.7825`.
    If we square this value, we get the multiple squared correlation, this indicates
    that the predicted values share 61.23% of their variance with `apt`.
  prefs: []
  type: TYPE_NORMAL
- en: Poisson regression - understanding species present in Galapagos Islands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Galapagos Islands are situated in the Pacific Ocean about 1000 km from the
    Ecuadorian coast. The archipelago consists of 13 islands, five of which are inhabited.
    The islands are rich in flora and fauna. Scientists are still perplexed by the
    fact that such a diverse set of species can flourish in such a small and remote
    group of islands.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to complete this recipe we shall be using species dataset. The first
    step is collecting the data.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 - collecting and describing the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will utilize the number of species dataset titled `gala` that is available
    at [https://github.com/burakbayramli/kod/blob/master/books/Practical_Regression_Anove_Using_R_Faraway/gala.txt](https://github.com/burakbayramli/kod/blob/master/books/Practical_Regression_Anove_Using_R_Faraway/gala.txt)
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset includes 30 cases and seven variables in the dataset. The seven
    numeric measurements include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Species`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Endemics`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Area`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Elevation`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Nearest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Scruz`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Adjcacent`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's get into the details.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 - exploring the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Exploring the data will throw some light on the relationships. Begin by importing
    the txt data file named `gala.txt`. We will be saving the data to the gala data
    frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'The `regpois()` gives the Poisson regression on the variables that are expected
    to be important from an ecological point of view as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Next provide the summary of the data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The `summary` function will provide deviance residuals, coefficients, `signif`
    codes, null deviance, residual deviance, AIC, and number of Fisher scoring iterations.The
    results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: (Dispersion parameter for Poisson family taken to be 1)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Number of Fisher Scoring iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 2 - exploring the data](img/image_02_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Step 3 - plotting data and testing empirical data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`ppois()` is the distribution function of a Poisson where the parameter is
    `lambda=regpois$fit` and it is computed in `gala$Species` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'The values should be close to uniform in nature. Check the uniformity by plotting
    the values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot result is shown in the screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 3 - plotting data and testing empirical data](img/image_02_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The plot clearly shows that they are not in uniform.
  prefs: []
  type: TYPE_NORMAL
- en: Now carry out the Kolmogorov-Smirnov test on whether empirical data fits a given
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The Kolmogorov-Smirnov test is a test for goodness of fit and it usually involves
    examining a random sample from some unknown distribution in order to test the
    null hypothesis that the unknown distribution function is in fact a known, specified
    function. We usually use the Kolmogorov-Smirnov test to check the normality assumption
    in the analysis of variance.
  prefs: []
  type: TYPE_NORMAL
- en: The Kolmogorov-Smirnov test is constructed as a statistical hypothesis test.
    We determine a null hypothesis, ![Step 3 - plotting data and testing empirical
    data](img/image_02_012.jpg), that the two samples we are testing come from the
    same distribution. Then we search for evidence that this hypothesis should be
    rejected and express this in terms of a probability. If the likelihood of the
    samples being from different distributions exceeds a confidence level we demand
    that the original hypothesis is rejected in favor of the hypothesis, ![Step 3
    - plotting data and testing empirical data](img/image_02_013.jpg), that the two
    samples are from different distributions.
  prefs: []
  type: TYPE_NORMAL
- en: To do this we devise a single number calculated from the samples, that is, a
    statistic. The trick is to find a statistic that has a range of values that do
    not depend on things we do not know, such as the actual underlying distributions
    in this case.
  prefs: []
  type: TYPE_NORMAL
- en: The test statistic in the Kolmogorov-Smirnov test is very easy; it is just the
    maximum vertical distance between the empirical cumulative distribution functions
    of the two samples. The empirical cumulative distribution of a sample is the proportion
    of the sample values that are less than or equal to a given value.
  prefs: []
  type: TYPE_NORMAL
- en: 'One sample Kolmogorov-Smirnov test is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, we can safely conclude that the model is not adequate.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 - rectifying discretization of the Poisson model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now make a correction since Poisson  is discrete. The change is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'A correction of the procedure is carried out, taking into account discrete
    distribution as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us check the uniformity by plotting the values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot result is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 4 - rectifying discretization of the Poisson model](img/image_02_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The correction does not make much of a difference. The plot clearly shows that
    they are not in uniform.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let us carry out the Kolmogorov-Smirnov test again to verify whether empirical
    data fits a given distribution as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: Step 5 - training and evaluating the model using the link function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We shall see how generalized linear models fit using the `glm( )` function
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us print the results of `regpois2` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: Step 6 - revaluating using the Poisson model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A correction of the procedure is carried out, taking into account discrete
    distribution as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the uniformity by plotting the values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot result is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 6 - revaluating using the Poisson model](img/image_02_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Carry out the Kolmogorov-Smirnov test again to verify whether empirical data
    fits a given distribution as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'A one sample Kolmogorov-Smirnov test is carried out as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: The result still does not pass the test.
  prefs: []
  type: TYPE_NORMAL
- en: Step 7 - revaluating using the linear model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Applying usual the linear model: `lm()` function is used to fit linear models.
    It can be used to carry out regression, single stratum analysis of variance, and
    analysis of covariance (although `[aov](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/aov.html)`
    may provide a more convenient interface for these). The `reg` data frame is used
    to store the results returned from the `lm()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us now view the results of the `reg` data frame using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let us plot the reg data frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'The **Residuals vs Fitted** plot is shown in the folllowing figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The Normal Q-Q linear model plot is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The **Scale-Location** linear model plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now let us apply a transformation by using the following square root function.
    The `reg2` data frame is used to store the results returned from the `lm` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us now view the results of the `reg` data frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let us plot the `reg2` data frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'The **Residual vs Fitted** plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The **Normal Q-Q** linear model plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The Poisson regression  **Scale-Location** linear model plot is shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The **Scale-Location** linear model plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let us carry out the Shapiro  test. Given a sample X1, . . . , Xn of n real-valued
    observations, the Shapiro-Wilk test (Shapiro and Wilk, 1965) is a test of the
    composite hypothesis that the data is **i.i.d**. (**independent and identically
    distributed**) and normal, that is, N(µ, σ2) for some unknown real µ and some
    σ > 0\. Use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: Now let us apply a transformation by using the log function as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `reg3` data frame is used to store the results returned from the `lm()`
    function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us now view the results of the `reg3` data frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let us plot the `reg3` data frame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: 'The **Residuals vs Fitted** plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The Normal Q-Q linear model plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_024.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The **Scale-Location** linear model plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 7 - revaluating using the linear model](img/image_02_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let us carry out a Shapiro test as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
