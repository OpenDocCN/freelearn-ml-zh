<html><head></head><body>
			<h1 id="_idParaDest-72" class="chapter-number"><a id="_idTextAnchor072"/>6</h1>
			<h1 id="_idParaDest-73"><a id="_idTextAnchor073"/>Stabilizing the Machine Learning System</h1>
			<p>In the last two chapters, we went over the different concepts in machine learning and how we can create a comprehensive machine learning system pipeline that can work and adapt to <span class="No-Break">our needs.</span></p>
			<p>While our pipeline can address our expectations, it is important for us to be able to maintain our system in the face of external factors to which it may be hard for the system <span class="No-Break">to self-adjust.</span></p>
			<p>In this chapter, we will discuss the phenomenon of dataset shifts and how we can optimize our machine learning system to help address these issues while maintaining its functional goal without having to rebuild our system <span class="No-Break">from scratch.</span></p>
			<p>We will be going over the <span class="No-Break">following concepts:</span></p>
			<ul>
				<li>Machine learning parameterization and <span class="No-Break">dataset shifts</span></li>
				<li>The causes of <span class="No-Break">dataset shifts</span></li>
				<li>Identifying <span class="No-Break">dataset shifts</span></li>
				<li>Handling and stabilizing <span class="No-Break">dataset shifts</span></li>
			</ul>
			<h1 id="_idParaDest-74"><a id="_idTextAnchor074"/>Machine learning parameterization and dataset shifts</h1>
			<p>Maintaining our <a id="_idIndexMarker361"/>machine learning models is an integral part of creating a <a id="_idIndexMarker362"/>robust model. As time progresses, our data begins to morph and shift based on our environment, and while most models can detect and self-repair, sometimes, human intervention will be required to guide them back <span class="No-Break">on track.</span></p>
			<p>In this section, we will briefly go over two main concepts that will help us understand the impact on <span class="No-Break">our model:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Parameterization</strong></span></li>
				<li><span class="No-Break"><strong class="bold">Dataset shifts</strong></span></li>
			</ul>
			<p>Our machine <a id="_idIndexMarker363"/>learning model is represented by certain <a id="_idIndexMarker364"/>specifications that help define the learning process of our model. These include <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Parameters</strong></span></li>
				<li><span class="No-Break"><strong class="bold">Hyperparameters</strong></span></li>
			</ul>
			<p>We will first <a id="_idIndexMarker365"/>look at parameters. These specifications are internal within the model. During the training process, these parameters are updated and learned while the model is trying to learn the mapping between the input features and the <span class="No-Break">target values.</span></p>
			<p>Most of the time, these parameters are set to an initial value of either zeros or random values. As the training process happens, the values are continuously updated by an optimization method, such as gradient descent. At the end of the training process, the final weights of the values are what constitute the model itself. These weights can even be used for other models, especially those with <span class="No-Break">similar applications.</span></p>
			<p>Some examples <a id="_idIndexMarker366"/>of parameters include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Node weights and bias values for artificial <span class="No-Break">neural networks</span></li>
				<li>Coefficients of linear and logistic <span class="No-Break">regression models</span></li>
				<li>Cluster centroids for <span class="No-Break">clustering models</span></li>
			</ul>
			<p>While parameters play a core role in determining the performance of a model, they are mostly out of our control since the model itself is what updates the weights. This leads us <span class="No-Break">to hyperparameters.</span></p>
			<p>Hyperparameters are <a id="_idIndexMarker367"/>parameters that control the learning process of our machine learning model, which, in turn, affects the output weights that our model learns. These values are set from the beginning and stay fixed throughout the <span class="No-Break">learning process.</span></p>
			<p>We, as users, determine which values to set in the beginning for our model to use during the training process. As a result, it takes time and experience to figure out which values produce the best results. There is effort involved in testing and training multiple variations of hyperparameters to see which performs <span class="No-Break">the best.</span></p>
			<p>There are many <a id="_idIndexMarker368"/>hyperparameters and each model has its own unique set of hyperparameters that the user can modify. These hyperparameters can include <span class="No-Break">the following:</span></p>
			<ul>
				<li>The split ratio between the training and <span class="No-Break">testing datasets</span></li>
				<li>The learning rate used in <span class="No-Break">optimization algorithms</span></li>
				<li>The choice of <span class="No-Break">optimization algorithm</span></li>
				<li>The <span class="No-Break">batch size</span></li>
				<li>The number of epochs <span class="No-Break">or iterations</span></li>
				<li>The number of <span class="No-Break">hidden layers</span></li>
				<li>The number of nodes in each <span class="No-Break">hidden layer</span></li>
				<li>The choice of cost or <span class="No-Break">loss function</span></li>
				<li>The choice of <span class="No-Break">activation function</span></li>
				<li>The number of <img src="image/Formula_06_001.png" alt=""/> <span class="No-Break">clusters</span></li>
			</ul>
			<p>Since there can be many hyperparameters to adjust and many different combinations to try, it can be very time-consuming to test these changes one by one. As discussed in the last chapter, it can be useful to have a section in our pipeline that automates this process by running multiple models with different combinations of hyperparameters to speed up the testing process and find the most optimal combination <span class="No-Break">of hyperparameters.</span></p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B18934_06_1.jpg" alt="Figure 6.1: Hyperparameter and parameter tuning"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1: Hyperparameter and parameter tuning</p>
			<p>There may be cases where adjusting our parameters and hyperparameters is not enough for us to prevent our model <span class="No-Break">from degrading.</span></p>
			<p>For example, let’s say we <a id="_idIndexMarker369"/>create a machine learning model with a model accuracy of 85%. This model continues to perform well for some time. We then begin to see our model accuracy deteriorate until it becomes unusable, as the model is unable to properly predict the new test data <span class="No-Break">we collect.</span></p>
			<p>As we analyze our model, we can begin to see that our training data does not reflect the testing data we have recently collected. Here, we can see that there is a shift between the data distribution for our training and <span class="No-Break">test datasets.</span></p>
			<p>Before we work on resolving dataset shifts, we must first understand the background of dataset shifts, how they occur, and how we can adjust our machine learning system to help prevent dataset shifts from impacting <span class="No-Break">our model.</span></p>
			<p>Machine learning systems are built under the assumption that the data distribution between the training and test sets is similar. Since the real world is ever-changing, new data distributions emerge and there may be a significant difference between the training and <span class="No-Break">test sets.</span></p>
			<p>The major difference <a id="_idIndexMarker370"/>in data distribution between the training and test sets is considered a dataset shift. This drastic difference will eventually degrade the model, as the model is biased to the training set and is unable to adapt to the <span class="No-Break">test set:</span></p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B18934_06_2.jpg" alt="Figure 6.2: Outcome of a machine learning model due to a dataset shift"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2: Outcome of a machine learning model due to a dataset shift</p>
			<p>Some examples of this occurring include a shift in consumer habits, a socioeconomic shift, or a global influence, such as a pandemic. These events can heavily impact the data we collect and observe, which, in turn, can sway our <span class="No-Break">model’s performance.</span></p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">First, try adjusting the hyperparameters of your machine learning model and see whether the newly learned parameters can improve your model significantly. If you still encounter major issues, it may be best to analyze the data and see whether a dataset shift <span class="No-Break">has occurred.</span></p>
			<h1 id="_idParaDest-75"><a id="_idTextAnchor075"/>The causes of dataset shifts</h1>
			<p>Now that we have learned what dataset shifts are, we can start to investigate the different <a id="_idIndexMarker371"/>causes of dataset shifts. While there are many different reasons dataset shifts can occur, we can split them into <span class="No-Break">two categories:</span></p>
			<ul>
				<li><strong class="bold">Sample </strong><span class="No-Break"><strong class="bold">selection bias</strong></span></li>
				<li><span class="No-Break"><strong class="bold">Non-stationary environments</strong></span></li>
			</ul>
			<p>Sample selection bias is self-explanatory in that there is a bias or issue when it comes to labeling or collecting the training data used for the model. Collecting biased data will result in a non-uniform sample selection for the training set. That bias, in essence, will fail to represent the actual <span class="No-Break">sample distribution.</span></p>
			<p>Non-stationary environments are another cause for dataset shifts – we will go into further detail about the different types later in the chapter. Let’s assume that we have a model with a set of input features, <img src="image/Formula_06_002.png" alt=""/>, a target or output variable <img src="image/Formula_06_003.png" alt=""/>. From there, we can also define the prior probability as <img src="image/Formula_06_004.png" alt=""/>, the conditional probability as <img src="image/Formula_06_005.png" alt=""/>, and the joint distribution as <img src="image/Formula_06_006.png" alt=""/>. This dataset shift is caused by temporal or spatial changes, defined as <img src="image/Formula_06_007.png" alt=""/>, which reflect very much how the real <span class="No-Break">world operates.</span></p>
			<p>This causal effect can lead to different types <span class="No-Break">of shifts:</span></p>
			<ul>
				<li>For <img src="image/Formula_06_008.png" alt=""/> problems, non-stationary environments can make changes to either <img src="image/Formula_06_009.png" alt=""/> or <img src="image/Formula_06_010.png" alt=""/>, giving us a covariate or <span class="No-Break">concept shift</span></li>
				<li>For <img src="image/Formula_06_011.png" alt=""/> problems, a change in <img src="image/Formula_06_012.png" alt=""/> or <img src="image/Formula_06_013.png" alt=""/> can give us a prior probability or <span class="No-Break">concept shift</span></li>
			</ul>
			<p>In the next section, we will look into the different types of shifts and how we can <span class="No-Break">identify them.</span></p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor076"/>Identifying dataset shifts</h1>
			<p>After looking into the different causes of dataset shifts, we can begin to classify certain shifts into <a id="_idIndexMarker372"/>different groups that can help us easily identify the type of dataset shift we are <span class="No-Break">dealing with.</span></p>
			<p>Among the different dataset shifts we can encounter, we can classify data shifts into <span class="No-Break">these categories:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Covariate shifts</strong></span></li>
				<li><strong class="bold">Prior </strong><span class="No-Break"><strong class="bold">probability shifts</strong></span></li>
				<li><span class="No-Break"><strong class="bold">Concept shifts</strong></span></li>
			</ul>
			<p>We will first <a id="_idIndexMarker373"/>look at covariate shifts. This is the most common <a id="_idIndexMarker374"/>dataset shift, as a covariate shift occurs when there is a change in the distribution of one or more of the input features of the training or test data. Despite the change, the target value remains <span class="No-Break">the same.</span></p>
			<p>In mathematical terms, this dataset shift occurs only in X &gt; Y problems. Whenever the input distribution, <img src="image/Formula_06_014.png" alt=""/>, changes between the training and testing datasets, <img src="image/Formula_06_015.png" alt=""/>, but the conditional probability of the training and testing dataset stays the same, <img src="image/Formula_06_016.png" alt=""/>, this will cause a <span class="No-Break">covariate shift.</span></p>
			<p>For example, we can create a model that predicts the salary of the employees of a certain city. Let’s say that the majority of the employees in your training set consist of younger individuals. After time passes, the employees get older. If you were to try to predict the salary of the older employees, you would begin to see a significant error. This is due to the model being heavily biased toward the training set, which consisted of mostly younger employees and is unable to find the relationship among the <span class="No-Break">older employees.</span></p>
			<div>
				<div id="_idContainer135" class="IMG---Figure">
					<img src="image/B18934_06_3.jpg" alt="Figure 6.3: Covariate dataset shifts"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3: Covariate dataset shifts</p>
			<p>Next, we will be <a id="_idIndexMarker375"/>looking into prior probability shifts, also known <a id="_idIndexMarker376"/>as label shifts. This is the opposite of a covariate shift, as this shift occurs when the output distribution changes for a given output but the <a id="_idIndexMarker377"/>input distribution remains <span class="No-Break">the same.</span></p>
			<p>In mathematical terms, this occurs only in Y -&gt; X problems. When the prior probability changes, <img src="image/Formula_06_017.png" alt=""/>, but the conditional probability remains the same, <img src="image/Formula_06_018.png" alt=""/>, a prior probability <span class="No-Break">shift occurs:</span></p>
			<div>
				<div id="_idContainer138" class="IMG---Figure">
					<img src="image/B18934_06_4.jpg" alt="Figure 6.4: Prior probability shifts"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4: Prior probability shifts</p>
			<p>Finally, we will discuss concept shifts, also known as concept drifts. This shift occurs when the <a id="_idIndexMarker378"/>distribution of the training data remains the <a id="_idIndexMarker379"/>same but the conditional distribution for the output given the training <span class="No-Break">data changes.</span></p>
			<p>In mathematical terms, this can occur both in X -&gt; Y or Y -&gt; <span class="No-Break">X problems:</span></p>
			<ul>
				<li>For X -&gt; Y problems, this occurs when the prior probability of the input variables remains the same in the training and testing datasets, (<img src="image/Formula_06_019.png" alt=""/>, but the conditional probability <span class="No-Break">changes, <img src="image/Formula_06_020.png" alt=""/>.</span></li>
				<li>For Y -&gt; X problems, this occurs when the prior probability of the target variables remains the same in the training and testing datasets, <img src="image/Formula_06_021.png" alt=""/>, but the conditional probability <span class="No-Break">changes, <img src="image/Formula_06_022.png" alt=""/></span><span class="No-Break">.</span></li>
			</ul>
			<p>As an example, a user’s purchasing behavior is affected due to the economy, but neither our training nor our test data contains any information regarding the economy’s performance. As a result, our model’s performance <span class="No-Break">will degrade.</span></p>
			<div>
				<div id="_idContainer143" class="IMG---Figure">
					<img src="image/B18934_06_5.jpg" alt="Figure 6.5: Concept shifts"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.5: Concept shifts</p>
			<p>This can be <a id="_idIndexMarker380"/>a tricky dataset shift since the distribution shift is not related <a id="_idIndexMarker381"/>to the data that we train on, but rather external information that our model may not have. Most of the time, these dataset shifts are cyclical <span class="No-Break">and/or seasonal.</span></p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Visualizing your data and calculating the different probabilities with regard to your data is the best way to help determine and identify which dataset shift you are dealing with. From there, you can decide how you will address your <span class="No-Break">dataset shift.</span></p>
			<p>When it comes to identifying most dataset shifts, there is a process that we can follow to help us. It includes the <span class="No-Break">following steps:</span></p>
			<ul>
				<li>Preprocessing <span class="No-Break">the data</span></li>
				<li>Creating random samples of your training and test sets on <span class="No-Break">their own</span></li>
				<li>Combining the random samples into <span class="No-Break">one dataset</span></li>
				<li>Create a model using one feature at a time while using the origin as the <span class="No-Break">output value</span></li>
				<li>Predicting <a id="_idIndexMarker382"/>on the test set and calculating the <strong class="bold">Area Under Curve – Receiver Operating Characteristics </strong><span class="No-Break"><strong class="bold">Curve </strong></span><span class="No-Break">(</span><span class="No-Break"><strong class="bold">AUC-ROC</strong></span><span class="No-Break">)</span></li>
				<li>If the <a id="_idIndexMarker383"/>AUC-ROC is greater than a certain threshold, for example, 80%, we can classify the data as having experienced a <span class="No-Break">dataset shift</span></li>
			</ul>
			<div>
				<div id="_idContainer144" class="IMG---Figure">
					<img src="image/B18934_06_6.jpg" alt="Figure 6.6: An example of an AUC-ROC graph (a value close to 1 indicates a strong model)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.6: An example of an AUC-ROC graph (a value close to 1 indicates a strong model)</p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor077"/>Handling and stabilizing dataset shifts</h1>
			<p>Now that we have established the methods for identifying the different types of dataset shifts, we can <a id="_idIndexMarker384"/>discuss the different ways of addressing these shifts <a id="_idIndexMarker385"/>and stabilizing our machine <span class="No-Break">learning models.</span></p>
			<p>While there are many ways to address dataset shifts, we will be looking at the three main methods. They consist of <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Feature dropping</strong></span></li>
				<li><span class="No-Break"><strong class="bold">Adversarial search</strong></span></li>
				<li><strong class="bold">Density </strong><span class="No-Break"><strong class="bold">ratio estimation</strong></span></li>
			</ul>
			<p>We will first <a id="_idIndexMarker386"/>look at feature dropping. This is the simplest form of adjusting dataset shifts. As we determine which features are classified as drifting, we can simply drop them from the machine learning model. We can also define a simple rule where any features with a drift value greater than a certain threshold, for example, 80%, can <span class="No-Break">be dropped:</span></p>
			<div>
				<div id="_idContainer145" class="IMG---Figure">
					<img src="image/B18934_06_7.jpg" alt="Figure 6.7: Feature Dropping Process"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.7: Feature Dropping Process</p>
			<p>While this is a simple change, this is something that needs to be considered carefully. If this feature is considered important when training your machine learning model, then it is worth reconsidering whether this feature needs to be dropped. Also, if the majority of your features pass the threshold for being dropped, you may want to revisit your data as a whole and consider a different approach when addressing your <span class="No-Break">dataset shift.</span></p>
			<p>Next, we will look at adversarial search. This is a technique that requires training a binary classifier to predict whether the sample data is within the training or test datasets. We can then evaluate the performance of the classifier to determine whether there has been a dataset shift. If the performance of our classifier is close to that of a random guess (~50%), we can confidently determine that our training and test dataset distribution <a id="_idIndexMarker387"/>is consistent. On the other hand, if our classifier <a id="_idIndexMarker388"/>performs better than a random guess, then that will indicate an inconsistency between the distribution of the training and <span class="No-Break">test datasets.</span></p>
			<p>The adversarial search can be split into <span class="No-Break">three parts:</span></p>
			<ol>
				<li>From the original dataset, we will remove the target value column and replace it with a new column that indicates the source of data (train = 0 and test = <span class="No-Break">1).</span></li>
				<li>We will create and train the new classifier with the new dataset. The output of the classifier is the probability that the sample data is part of the <span class="No-Break">test dataset.</span></li>
				<li>Finally, we can observe the results and measure the performance of our classifier. If our classifier performance is close to 50%, then this indicates that the model is unable to differentiate whether the data is coming from the training or test set. This can tell us that the data distribution between the training and test datasets is consistent. On the flip side, if our performance is close to 100%, then the model is confident enough to find the difference between the training and test datasets, which then indicates a major difference between the distribution of the training and <span class="No-Break">test datasets.</span></li>
			</ol>
			<div>
				<div id="_idContainer146" class="IMG---Figure">
					<img src="image/B18934_06_8.jpg" alt="Figure 6.8: Adversarial search process"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.8: Adversarial search process</p>
			<p>Using adversarial <a id="_idIndexMarker389"/>search, we can establish three methods <a id="_idIndexMarker390"/>to address the dataset shifts <span class="No-Break">we encounter:</span></p>
			<ul>
				<li>Using the results, we can use them as sample weights for the training process. The weights correspond to the nature of how the data is distributed. The data that is similar in the actual distribution will be assigned a larger weight while that with inconsistent distribution will be given a lower weight. This will help the model emphasize the data that actually represents the real distribution it is trying <span class="No-Break">to learn.</span></li>
				<li>We can use only the top-ranked adversarial validation results. Rather than mitigating the weights of inconsistent samples in the testing dataset, we can remove <span class="No-Break">them altogether.</span></li>
				<li>All data is used for training except for the top-ranked adversarial validation results. This method can address the issues that can arise from the second method by using all the data rather than dropping features. Rather than discarding unimportant data, we can incorporate some of the data in the training data for each fold when using K-fold cross-validation during training. This helps maintain consistency while using all <span class="No-Break">the data.</span></li>
			</ul>
			<p>The final <a id="_idIndexMarker391"/>method used to address dataset shifts is called <a id="_idIndexMarker392"/>the density ratio estimation method. This method is still under research and not a commonly used method to address <span class="No-Break">dataset shifts.</span></p>
			<p>With this approach, we would first estimate the training and test dataset densities separately. Once we have done this, we will then estimate the importance of the dataset by taking the ratio of the estimated densities of the training and test datasets. Using this density ratio, we can use it as the weight for each data entry in our <span class="No-Break">training dataset.</span></p>
			<p>The reason this method is not preferred and is still under research is that it is computationally expensive, especially for higher dimensional datasets. Even then, the improvements it can bring to addressing dataset shifts are negligible and not worth the effort of pursuing <span class="No-Break">this method.</span></p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Feature dropping is the easiest and simplest way to address dataset shifts. Consider using this approach before using the adversarial search approach, as that option, while effective, can be a little involved and may require more effort and resources to help mitigate the effect of <span class="No-Break">dataset shifts.</span></p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor078"/>Summary</h1>
			<p>In this chapter, we went over the general concepts of dataset shifts and how they can negatively impact our machine <span class="No-Break">learning model.</span></p>
			<p>From there, we delved in deeper into what causes these dataset shifts to occur and what different characteristics dataset shifts can exhibit. Using these characteristics, we can better identify the type of dataset shift – whether it was a covariate shift, prior probability shift, or <span class="No-Break">concept shift.</span></p>
			<p>Once we were able to analyze our data and identify the type of dataset shift, we looked at different methods to help us handle and stabilize these dataset shifts so that we could maintain our machine learning model. We went over some techniques, such as feature searching, adversarial search, and density ratio estimation, that can assist us when dealing with <span class="No-Break">dataset shifts.</span></p>
			<p>Using these processes and methods, we can prevent our model from suffering from common dataset shifts that occur in the real world and continuously maintain our machine <span class="No-Break">learning model.</span></p>
			<p>Now that we have a firm understanding of machine learning and how to maintain a robust model, we can start looking into how we can incorporate our machine learning models into our <strong class="bold">Microservices </strong><span class="No-Break"><strong class="bold">Architecture</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">MSA</strong></span><span class="No-Break">).</span></p>
</body></html>