<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Setting Up a Docker Container</h1>
                </header>
            
            <article>
                
<p><span>Docker is a convenient platform that can package an application and its dependencies in a replicable virtual environment that can run on different operating systems. In particular, it is well integrated with any <strong>Linux system</strong></span>. </p>
<p>The <span>replicable</span> virtual environment is described in a <strong>Dockerfile</strong><strong> </strong>that contains instructions that should be executed in order to achieve the desired virtual environment. These instructions mainly include the installation procedure, which is pretty much similar to the installation procedure with a Linux shell. Once the environment has been created, you can be sure that your app will have the same behavior on any other machine.</p>
<p>In Docker terminology, the resulting virtual environment is called a <strong>Docker image</strong>. You can create an instance of the virtual environment, which is called a <strong>Docker container</strong>. After the container is created, you can execute your code inside the container.</p>
<div class="packt_tip">Please follow the installation instructions on the official website in order to get Docker up and running on the operating system of your choice: <a href="https://docs.docker.com/install/">https://docs.docker.com/install/</a></div>
<p><span>For your convenience, we are including Dockerfiles, which will make it very easy to replicate the environment that we have used to run the code in this book, regardless of what operating system you have on your computer. First, we describe a Dockerfile that uses only the CPU without GPU acceleration. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining a Dockerfile</h1>
                </header>
            
            <article>
                
<p>Instructions in the Dockerfile start from a base image, and then desired installations and modifications are done on top of that image.</p>
<div class="packt_infobox"><span>At the time of writing, TensorFlow does not support </span><strong>Python 3.8</strong><span>. If you plan to run </span><a href="0e410c47-1679-4125-9614-54ec0adfa160.xhtml">Chapter 7</a><span>, </span><em>Learning to Recognize Traffic Signs</em><span>, or </span><a href="8baf5d4c-f1e9-4b76-b957-e19682cb9e68.xhtml">Chapter 9</a><span>, </span><em>Learning to Classify and Localize Objects</em><span>, where TensorFlow is used, you can start with </span><strong>Python 3.7</strong><span> and then install TensorFlow with </span><kbd>pip</kbd><span>, or you can pick </span><kbd>tensorflow/tensorflow:latest-py3</kbd><span> as the base image.</span></div>
<p>Let's go over the steps to create our environment:</p>
<ol>
<li>We start from a base image, which is the basic Python image that is based on <strong>Debian</strong>:</li>
</ol>
<pre style="padding-left: 60px">FROM python:3.8</pre>
<ol start="2">
<li>We install useful packages that will particularly be used during the <span>installation process of </span>OpenCV and other dependencies:</li>
</ol>
<pre style="padding-left: 60px">RUN apt-get update &amp;&amp; apt-get install -y \<br/>        build-essential \<br/>        cmake \<br/>        git \<br/>        wget \<br/>        unzip \<br/>        yasm \<br/>        pkg-config \<br/>        libswscale-dev \<br/>        libtbb2 \<br/>        libtbb-dev \<br/>        libjpeg-dev \<br/>        libpng-dev \<br/>        libtiff-dev \<br/>        libavformat-dev \<br/>        libpq-dev \<br/>        libgtk2.0-dev \<br/>        libtbb2 libtbb-dev \<br/>        libjpeg-dev \<br/>        libpng-dev \<br/>        libtiff-dev \<br/>        libv4l-dev \<br/>        libdc1394-22-dev \<br/>        qt4-default \<br/>        libatk-adaptor \<br/>        libcanberra-gtk-module \<br/>        x11-apps \<br/>        libgtk-3-dev \<br/>    &amp;&amp; rm -rf /var/lib/apt/lists/*</pre>
<ol start="3">
<li>We download <strong>OpenCV 4.2</strong> together with the contributor packages, which are required for non-free algorithms such as <span><strong>scale-invariant feature transform</strong> </span>(<strong>SIFT</strong>) and <span><strong>speeded-up robust features</strong> </span>(<strong>SURF</strong>):</li>
</ol>
<pre style="padding-left: 60px">WORKDIR /<br/>RUN wget --output-document cv.zip https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip \<br/>    &amp;&amp; unzip cv.zip \<br/>    &amp;&amp; wget --output-document contrib.zip https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip \<br/>    &amp;&amp; unzip contrib.zip \<br/>    &amp;&amp; mkdir /opencv-${OPENCV_VERSION}/cmake_binary</pre>
<ol start="4">
<li>We install a version of NumPy that works with <strong>OpenCV 4.2</strong>:</li>
</ol>
<pre style="padding-left: 60px">RUN pip install --upgrade pip &amp;&amp; pip install --no-cache-dir numpy==1.18.1</pre>
<ol start="5">
<li>We compile OpenCV using appropriate flags:</li>
</ol>
<pre style="padding-left: 60px">RUN cd /opencv-${OPENCV_VERSION}/cmake_binary \<br/>    &amp;&amp; cmake -DBUILD_TIFF=ON \<br/>        -DBUILD_opencv_java=OFF \<br/>        -DWITH_CUDA=OFF \<br/>        -DWITH_OPENGL=ON \<br/>        -DWITH_OPENCL=ON \<br/>        -DWITH_IPP=ON \<br/>        -DWITH_TBB=ON \<br/>        -DWITH_EIGEN=ON \<br/>        -DWITH_V4L=ON \<br/>        -DBUILD_TESTS=OFF \<br/>        -DBUILD_PERF_TESTS=OFF \<br/>        -DCMAKE_BUILD_TYPE=RELEASE \<br/>        -D OPENCV_EXTRA_MODULES_PATH=/opencv_contrib-${OPENCV_VERSION}/modules \<br/>        -D OPENCV_ENABLE_NONFREE=ON \<br/>        -DCMAKE_INSTALL_PREFIX=$(python3.8 -c "import sys; print(sys.prefix)") \<br/>        -DPYTHON_EXECUTABLE=$(which python3.8) \<br/>        -DPYTHON_INCLUDE_DIR=$(python3.8 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())") \<br/>        -DPYTHON_PACKAGES_PATH=$(python3.8 -c "from distutils.sysconfig import get_python_lib; print(get_python_lib())") \<br/>        .. \<br/>    &amp;&amp; make install \<br/>    &amp;&amp; rm /cv.zip /contrib.zip \<br/>    &amp;&amp; rm -r /opencv-${OPENCV_VERSION} /opencv_contrib-${OPENCV_VERSION}</pre>
<ol start="6">
<li>We link the OpenCV Python binary to the appropriate location so that the interpreter can find it:</li>
</ol>
<pre style="padding-left: 60px">RUN ln -s \<br/>  /usr/local/python/cv2/python-3.8/cv2.cpython-38m-x86_64-linux-gnu.so \<br/>  /usr/local/lib/python3.8/site-packages/cv2.so</pre>
<p style="padding-left: 60px" class="mce-root">This linking might be redundant or result in an error if you have used a base image that differs from <kbd>python:3.8</kbd>.</p>
<ol start="7">
<li>We install other Python packages that are used in the book:</li>
</ol>
<pre style="padding-left: 60px">RUN pip install --upgrade pip &amp;&amp; pip install --no-cache-dir pathlib2 wxPython==4.0.5<br/><br/>RUN pip install --upgrade pip &amp;&amp; pip install --no-cache-dir scipy==1.4.1 matplotlib==3.1.2 requests==2.22.0 ipython numba==0.48.0 jupyterlab==1.2.6 rawpy==0.14.0</pre>
<p>So, now that we have composed the Dockerfile, we can build the corresponding Docker image as follows:</p>
<pre><strong><span>$ docker build -f dockerfiles/Dockerfile  -t cv  dockerfiles</span></strong></pre>
<p>We have named the image <kbd>cv</kbd> and we have passed a Dockerfile located at <kbd>dockerfiles/Dockerfile</kbd> to build the image. Of course, you can place your Dockerfile in any other location. The last argument is required in Docker and it specifies a context that might be used; for example, if the Dockerfile contains directives to copy files from a relative path. In our case, we do not have such directives, and it can be, in general, any valid path.</p>
<p>Once the image is built, we can start the <kbd>docker</kbd> container as follows:</p>
<pre><strong>$ docker run --device /dev/video0 --env DISPLAY=$DISPLAY  -v="/tmp/.X11-unix:/tmp/.X11-unix:rw"  -v `pwd`:/book -it book</strong></pre>
<p>Here, we have passed the <kbd>DISPLAY</kbd> environment variable, mounted <kbd>/tmp/.X11-unix</kbd>, and specified the <kbd>/dev/video0</kbd> <span>device </span>in order to allow the container to use the desktop environment and connect to the camera, where the container is used in most of the chapters of the book.</p>
<div class="packt_infobox">If the Docker container fails to connect to the <em>X</em> server of your system, you might need to run <strong><kbd>$ xhost +local:docker</kbd> </strong>on your system in order to allow the connection.</div>
<p>So, now that we are up and running with the composed Docker image, let's examine how to support GPU acceleration with Docker.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with a GPU</h1>
                </header>
            
            <article>
                
<p class="mce-root">The environment that we create with Docker has limited access to the devices of your machine. In particular, you have seen that we have specified the camera device when running a Docker container and have mounted <kbd>/tmp/.X11-unix</kbd> in order to allow the Docker container to connect to the running desktop environment.</p>
<p class="mce-root">When we have custom devices such as GPUs, the integration process becomes more complicated, because the Docker container needs appropriate ways to talk to the device. Fortunately, for <strong>NVIDIA GPUs</strong>, this problem is solved with the help of <strong>NVIDIA Container Toolkit </strong>(<a href="https://github.com/NVIDIA/nvidia-docker">https://github.com/NVIDIA/nvidia-docker</a>).</p>
<p class="mce-root">Following installation of the toolkit, you can build and run GPU-accelerated Docker containers. Nvidia provides a base image so that you can build your image on top of it without bothering about appropriate access to the GPU. The requirement is that you should have an appropriate Nvidia driver installed on your system with an Nvidia GPU.</p>
<p class="mce-root">In our case, we mainly use GPUs for accelerating TensorFlow. TensorFlow itself provides an image that can be used to run TensorFlow with GPU acceleration. Therefore, to have a GPU-accelerated container, we can simply pick the Docker image of TensorFlow and make all other installations on top of it, as follows:</p>
<pre>FROM tensorflow/tensorflow:2.1.0-gpu-py3</pre>
<p>This declaration will pick TensorFlow version <kbd>2.1.0</kbd> with GPU acceleration and Python 3 support. Note that this version of the TensorFlow image uses <strong>Python 3.6</strong>. Nevertheless, you can use the remaining part of the Dockerfile for the CPU that we described in <a href="a4f1f102-9f62-4644-bcde-f478cd28621a.xhtml">Appendix A</a>, <em>Profiling and Accelerating Your Apps</em>, and you will be up and running with a container that can run the code in this book.</p>
<p class="mce-root">Once you are done with creating the image, the only modification that you have to do when starting a container is to pass one additional argument: <kbd>--runtime=nvidia</kbd>.</p>


            </article>

            
        </section>
    </body></html>