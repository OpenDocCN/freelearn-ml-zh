<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer105">
			<h1 id="_idParaDest-121" class="chapter-number"><a id="_idTextAnchor121"/>9</h1>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor122"/>Model Optimizations – Hyperparameter Tuning and NAS</h1>
			<p>We have now become quite familiar with some of the Vertex AI offerings related to managing data, training no-code and low-code models, and launching large-scale custom model training jobs (with metadata tracking and monitoring capabilities). As ML practitioners, we know that it is highly unlikely that the first model we train would be the best model for a given use case and dataset. Thus, in order to find the best model (which is the most accurate and least biased), we often use different model optimization techniques. <strong class="bold">Hyperparameter Tuning</strong> (<strong class="bold">HPT</strong>) and <strong class="bold">Neural Architecture Search</strong> (<strong class="bold">NAS</strong>) are two such model optimization techniques. In this chapter, we will learn how to configure and launch model optimization experiments using Vertex AI on <span class="No-Break">Google Cloud.</span></p>
			<p>In this chapter, we will first learn about the importance of model optimization techniques such as HPT and then learn how to quickly set up and launch HPT jobs within Google Vertex AI. We will also understand how NAS works and how it is different from HPT. The topics covered in this chapter are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>What is HPT and why is <span class="No-Break">it important?</span></li>
				<li>Setting up HPT jobs on <span class="No-Break">Vertex AI</span></li>
				<li>What is NAS and how is it different <span class="No-Break">from HPT?</span></li>
				<li>NAS on Vertex <span class="No-Break">AI overview</span></li>
			</ul>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor123"/>Technical requirements</h1>
			<p>The code examples shown in this chapter can be found in the following GitHub <span class="No-Break">repo: </span><a href="https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter09"><span class="No-Break">https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter09</span></a></p>
			<h1 id="_idParaDest-124"><a id="_idTextAnchor124"/>What is HPT and why is it important?</h1>
			<p>Hyperparameter tuning, or HPT for short, is a popular model optimization technique that is very commonly used across ML projects. In this section, we will learn about hyperparameters, the importance<a id="_idIndexMarker551"/> of tuning them, and different methods of finding the best hyperparameters for a machine <span class="No-Break">learning algorithm.</span></p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor125"/>What are hyperparameters?</h2>
			<p>When we train an ML system, we basically have three kinds of data – input data, model parameters, and model hyperparameters. Input data refers to our training or test data that is associated with the problem <a id="_idIndexMarker552"/>we are solving. Model parameters are the variables that we modify during the model training process and we try to adjust them to fit the training data. Model hyperparameters, on the other hand, are variables that govern the training process itself. These hyperparameters are fixed before we start to train our model. For example, learning rate, optimizer, batch size, number of hidden layers in a neural network, and the max depth in a tree-based algorithm are some examples of <span class="No-Break">model hyperparameters.</span></p>
			<h2 id="_idParaDest-126"><a id="_idTextAnchor126"/>Why HPT?</h2>
			<p>How well your machine learning model will perform largely depends upon the hyperparameters you <a id="_idIndexMarker553"/>choose before training. The values of hyperparameters can make all the difference to performance metrics (such as accuracy), training time, bias, fairness, and so on for your model. Hyperparameter tuning or HPT is a model optimization technique that chooses a set of optimal hyperparameters for a learning algorithm. The same ML algorithm can require totally different values of hyperparameters to generalize for different data patterns. There is an objective function associated with every HPT job that it tries to optimize (minimize or maximize) and it returns the values of hyperparameters that achieve that optimal value. This objective function can be similar to the model training objective (e.g., loss function) or it can be a completely <span class="No-Break">new metric.</span></p>
			<p>We run model optimization operations such as HPT or NAS when we are at a stage where our final model (i.e., XGBoost) is fixed and we have a fixed test set for which we want to optimize the hyperparameters of our chosen model. A typical HPT job runs multiple trials with different sets of hyperparameters and returns the hyperparameters that lead to the best trial. The best trial here represents the trial that optimizes the objective function associated with the <a id="_idIndexMarker554"/><span class="No-Break">HPT job.</span></p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor127"/>Search algorithms</h2>
			<p>While running HPT, we have to decide what kind of search algorithm we want to run over our hyperparameter space. There are multiple<a id="_idIndexMarker555"/> different kinds of search algorithms that we can choose from based on our needs. A few commonly used approaches are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break">Grid search</span></li>
				<li><span class="No-Break">Random search</span></li>
				<li><span class="No-Break">Bayesian optimization</span></li>
			</ul>
			<p>Let’s discuss <span class="No-Break">these approaches!</span></p>
			<h3>Grid search</h3>
			<p>The traditional way of performing HPT has been grid search, which is basically an exhaustive search over a <a id="_idIndexMarker556"/>manually specified search space. A grid search must be provided with a performance metric that it tries to calculate over all possible sets of hyperparameter<a id="_idIndexMarker557"/> combinations, measured over a hold-out validation set (or cross-validation on a training set). As it runs all possible combinations of provided hyperparameter ranges, it is important to set those ranges carefully and with discrete values. As grid search runs all the trials independently, it can be parallelized for <span class="No-Break">faster outcomes.</span></p>
			<h3>Random search</h3>
			<p>Instead of trying all combinations<a id="_idIndexMarker558"/> sequentially and exhaustively like grid search, random <a id="_idIndexMarker559"/>search selects hyperparameters randomly from the provided search space during each trial. As it chooses hyperparameter values randomly, it also generalizes to continuous spaces along with discrete spaces, as discussed above. Random search again is highly parallelizable as all the trials are independent. Despite its simplicity, random search is one of the most important baselines to test new optimization or search <span class="No-Break">techniques against.</span></p>
			<h3>Bayesian optimization</h3>
			<p>Unlike grid search and random search, the Bayesian optimization method builds a probabilistic model of the function that maps<a id="_idIndexMarker560"/> hyperparameter values to the HPT objective function. Thus, at each new trial, it learns better about the direction it should take to find the optimal <a id="_idIndexMarker561"/>hyperparameters for the given objective function on a fixed validation set. It tries to balance exploration and exploitation and has been shown to obtain better results than the preceding techniques in fewer trials. But as it learns from the ongoing trials, it often runs the trials iteratively (thus it’s <span class="No-Break">less parallelizable).</span></p>
			<p>Now that we have a good understanding of HPT, let’s understand how to set up and launch HPT jobs on <span class="No-Break">Vertex AI.</span></p>
			<h1 id="_idParaDest-128"><a id="_idTextAnchor128"/>Setting up HPT jobs on Vertex AI</h1>
			<p>In this section, we will learn how to <a id="_idIndexMarker562"/>set up HPT jobs with Vertex AI. We will use the <a id="_idIndexMarker563"/>same neural network model experiment from <a href="B17792_07.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Training Fully Custom ML Models with Vertex AI</em>, and optimize its hyperparameters to get the best <span class="No-Break">model settings.</span></p>
			<p>The first step is to create a new Jupyter Notebook in Vertex AI Workbench and import <span class="No-Break">useful libraries:</span></p>
			<pre class="source-code">
import numpy as np
import glob
import matplotlib.pyplot as plt
import os
import google.cloud.aiplatform as aiplatform
from google.cloud.aiplatform import hyperparameter_tuning as hpt
from datetime import datetime
TIMESTAMP = datetime.now().strftime("%Y%m%d%H%M%S")
%matplotlib inline</pre>			<p>Next, we set up <span class="No-Break">project configurations:</span></p>
			<pre class="source-code">
PROJECT_ID='************'
REGION='us-west2'
SERVICE_ACCOUNT='417xxxxxxxxx7-compute@developer.gserviceaccount.com'
BUCKET_URI='gs://my-training-artifacts'</pre>			<p>Then, we initialize the Vertex <span class="No-Break">AI SDK:</span></p>
			<pre class="source-code">
aiplatform.init(project=PROJECT_ID, location=REGION, \
    staging_bucket=BUCKET_URI)</pre>			<p>The next step is to <a id="_idIndexMarker564"/>containerize the full training application code. We will put our full training code into a Python file, <strong class="source-inline">task.py</strong>, here. The <strong class="source-inline">task.py</strong> file should have an <a id="_idIndexMarker565"/>entire flow, including <span class="No-Break">the following:</span></p>
			<ul>
				<li>Loading and preparing the <span class="No-Break">training data</span></li>
				<li>Defining the <span class="No-Break">model architecture</span></li>
				<li>Training the model (running a trial with given hyperparameters <span class="No-Break">as args)</span></li>
				<li>Saving the <span class="No-Break">model (optional)</span></li>
				<li>Passing the training trial output to the <span class="No-Break"><strong class="source-inline">hypertune()</strong></span><span class="No-Break"> method</span></li>
			</ul>
			<p>The training script should have a list of hyperparameters that it wants to tune, defined <span class="No-Break">as arguments:</span></p>
			<pre class="source-code">
def get_args():
    '''Parses args. Must include all hyperparameters you want to tune.'''
    parser = argparse.ArgumentParser()
    parser.add_argument(
      '--epochs',
      required=True,
      type=int,
      help='training epochs')
    parser.add_argument(
      '--steps_per_epoch',
      required=True,
      type=int,
      help='steps_per_epoch')</pre>			<p>Similarly, we have <a id="_idIndexMarker566"/>other important hyperparameters, such as<a id="_idIndexMarker567"/> learning rate, batch size, loss function, and <span class="No-Break">so on:</span></p>
			<pre class="source-code">
    parser.add_argument(
      '--learning_rate',
      required=True,
      type=float,
      help='learning rate')
    parser.add_argument(
      '--batch_size',
      required=True,
      type=int,
      help='training batch size')
    parser.add_argument(
      '--loss',
      required=True,
      type=str,
      help='loss function')
    args = parser.parse_args()
    return args</pre>			<p>The script should have a<a id="_idIndexMarker568"/> function that loads and prepares the training and<a id="_idIndexMarker569"/> <span class="No-Break">validation datasets:</span></p>
			<pre class="source-code">
def make_datasets_unbatched():
    # Load train, validation and test sets
    dest = 'gs://data-bucket-417812395597/'
    train_x = np.load(BytesIO(
        file_io.read_file_to_string(dest+'train_x', \
            binary_mode=True)
    ))
    train_y = np.load(BytesIO(
        file_io.read_file_to_string(dest+'train_y', \
            binary_mode=True)
    ))</pre>			<p>Similarly, the validation and test data parts <span class="No-Break">are loaded:</span></p>
			<pre class="source-code">
    val_x = np.load(BytesIO(
        file_io.read_file_to_string(dest+'val_x', \
            binary_mode=True)
    ))
    val_y = np.load(BytesIO(
        file_io.read_file_to_string(dest+'val_y', \
            binary_mode=True)
    ))
    test_x = np.load(BytesIO(
        file_io.read_file_to_string(dest+'test_x', \
            binary_mode=True)
    ))
    test_y = np.load(BytesIO(
        file_io.read_file_to_string(dest+'test_y', \
            binary_mode=True)
    ))
    return train_x, train_y, val_x, val_y, test_x, test_y</pre>			<p>The preceding function loads the <a id="_idIndexMarker570"/>already prepared dataset from GCS. We can refer to <a href="B17792_07.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Training Fully Custom ML Models with Vertex AI</em>, to fully understand the data <span class="No-Break">preparation part.</span></p>
			<p>Next, we define the<a id="_idIndexMarker571"/> <strong class="bold">TensorFlow</strong> (<strong class="bold">TF</strong>) <span class="No-Break">model architecture:</span></p>
			<pre class="source-code">
def tf_model():
    black_n_white_input = tensorflow.keras.layers.Input(shape=(80, 80, 1))
    enc = black_n_white_input</pre>			<p>We then define the encoder part of <span class="No-Break">the model:</span></p>
			<pre class="source-code">
    #Encoder part
    enc = tensorflow.keras.layers.Conv2D(
        32, kernel_size=3, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)
    enc = tensorflow.keras.layers.Conv2D(
        64, kernel_size=3, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)</pre>			<p>Similarly, we will define two more<a id="_idIndexMarker572"/> encoder layers with an increasing number of filters, a kernel size of 3, and a stride <a id="_idIndexMarker573"/>of 2 so that we can compress the image into <span class="No-Break">important features:</span></p>
			<pre class="source-code">
    enc = tensorflow.keras.layers.Conv2D(
        128, kernel_size=3, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)
    enc = tensorflow.keras.layers.Conv2D(
        256, kernel_size=1, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.Dropout(0.5)(enc)</pre>			<p>Define the decoder part of the TF <a id="_idIndexMarker574"/>model within the <span class="No-Break">same function:</span></p>
			<pre class="source-code">
    #Decoder part
    dec = enc
    dec = tensorflow.keras.layers.Conv2DTranspose(
        256, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)
    dec = tensorflow.keras.layers.Conv2DTranspose(
        128, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)</pre>			<p>As we can see, the decoder design is <a id="_idIndexMarker575"/>almost opposite to the encoder part. Here, we re-create the image from compressed features by using multiple layers of transpose convolutions and reducing the channels gradually to 3 to generate the final color <span class="No-Break">image output:</span></p>
			<pre class="source-code">
    dec = tensorflow.keras.layers.Conv2DTranspose(
        64, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)
    dec = tensorflow.keras.layers.Conv2DTranspose(
        32, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)
    dec = tensorflow.keras.layers.Conv2D(
        3, kernel_size=3, padding='same'
    )(dec)</pre>			<p>Add a <strong class="source-inline">tanh</strong> activation function <a id="_idIndexMarker576"/>to get the final colored<a id="_idIndexMarker577"/> <span class="No-Break">output image:</span></p>
			<pre class="source-code">
    color_image = tensorflow.keras.layers.Activation('tanh')(dec)
    return black_n_white_input, color_image</pre>			<p>Also, add a function to build and compile the <span class="No-Break">TF model:</span></p>
			<pre class="source-code">
# Build the and compile TF model
def build_and_compile_tf_model(loss_fn, learning_rate):
    black_n_white_input, color_image = tf_model()
    model = tensorflow.keras.models.Model(
        inputs=black_n_white_input,
        outputs=color_image
    )
    _optimizer = tensorflow.keras.optimizers.Adam(
        learning_rate=learning_rate,
        beta_1=0.5
    )
    model.compile(
        loss=loss_fn,
        optimizer=_optimizer
    )
    return model</pre>			<p>Finally, add a <strong class="source-inline">main</strong> function that trains the <a id="_idIndexMarker578"/>model and provides the hyperparameter <a id="_idIndexMarker579"/>tuning metric value to the <strong class="source-inline">hypertune()</strong> function. In our case, we will be optimizing the loss over the validation dataset. See the <span class="No-Break">following snippet:</span></p>
			<pre class="source-code">
def main():
    args = get_args()</pre>			<p>Set up the configurations and load <span class="No-Break">the data:</span></p>
			<pre class="source-code">
    NUM_WORKERS = strategy.num_replicas_in_sync
    # Global batch size should be scaled as per the number     # of workers used in training.    GLOBAL_BATCH_SIZE = args.batch_size * NUM_WORKERS
    MODEL_DIR = os.getenv("AIP_MODEL_DIR")
    train_x, train_y, val_x, val_y, _, _ = \
        make_datasets_unbatched()</pre>			<p>Now, let’s build the TF model <a id="_idIndexMarker580"/>and fit it on the <span class="No-Break">training </span><span class="No-Break"><a id="_idIndexMarker581"/></span><span class="No-Break">data:</span></p>
			<pre class="source-code">
    with strategy.scope():
        # Creation of dataset, and model building/compiling need to be within
        # `strategy.scope()`.
        model = build_and_compile_tf_model(args.loss, \
            args.learning_rate)
    history = model.fit(
        train_x,
        train_y,
        batch_size=GLOBAL_BATCH_SIZE,
        epochs=args.epochs,
        steps_per_epoch=args.steps_per_epoch,
        validation_data=(val_x, val_y),
    )
    model.save(MODEL_DIR)</pre>			<p>Use <strong class="source-inline">hypertune</strong> to define and report hyperparameter tuning metrics to the <span class="No-Break">HPT algorithm:</span></p>
			<pre class="source-code">
    # DEFINE HPT METRIC
    hp_metric = history.history['val_loss'][-1]
    hpt = hypertune.HyperTune()
    hpt.report_hyperparameter_tuning_metric(
      hyperparameter_metric_tag='val_loss',
      metric_value=hp_metric,
      global_step=args.epochs)</pre>			<p>If we put this all into a single <a id="_idIndexMarker582"/>Python file, our <strong class="source-inline">task.py</strong> file should look something like <span class="No-Break">the following:</span></p>
			<pre class="source-code">
%%writefile task.py
# Single, Mirror and Multi-Machine Distributed Training</pre>			<p>Load all the <a id="_idIndexMarker583"/>dependencies for <span class="No-Break">our task:</span></p>
			<pre class="source-code">
import tensorflow as tf
import tensorflow
from tensorflow.python.client import device_lib
import argparse
import os
import sys
from io import BytesIO
import numpy as np
from tensorflow.python.lib.io import file_io
import hypertune</pre>			<p>Parse arguments where we define the hyperparameters used <span class="No-Break">for tuning:</span></p>
			<pre class="source-code">
def get_args():
    '''Parses args. Must include all hyperparameters you want to tune.'''
    parser = argparse.ArgumentParser()
    parser.add_argument(
      '--epochs',
      required=True,
      type=int,
      help='training epochs')
    parser.add_argument(
      '--steps_per_epoch',
      required=True,
      type=int,
      help='steps_per_epoch')</pre>			<p>Define a few more <a id="_idIndexMarker584"/>hyperparameter-related arguments for tuning the<a id="_idIndexMarker585"/> learning rate, batch size, and <span class="No-Break">loss functions:</span></p>
			<pre class="source-code">
    parser.add_argument(
      '--learning_rate',
      required=True,
      type=float,
      help='learning rate')
    parser.add_argument(
      '--batch_size',
      required=True,
      type=int,
      help='training batch size')
    parser.add_argument(
      '--loss',
      required=True,
      type=str,
      help='loss function')
    args = parser.parse_args()
    return args</pre>			<p>Set up configurations <a id="_idIndexMarker586"/>for <span class="No-Break">training</span><span class="No-Break"><a id="_idIndexMarker587"/></span><span class="No-Break"> purposes:</span></p>
			<pre class="source-code">
print('Python Version = {}'.format(sys.version))
print('TensorFlow Version = {}'.format(tf.__version__))
print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', \
    'Not found')))
print('DEVICES', device_lib.list_local_devices())</pre>			<p>Define configuration settings for training distribution strategies based on the requirements – it can be a single, mirror, or <span class="No-Break">multi-worker strategy:</span></p>
			<pre class="source-code">
DISTRIBUTE='single'
if DISTRIBUTE == 'single':
    if tf.test.is_gpu_available():
        strategy = tf.distribute.OneDeviceStrategy(device="/gpu:0")
    else:
        strategy = tf.distribute.OneDeviceStrategy(device="/cpu:0")
# Single Machine, multiple compute device
elif DISTRIBUTE == 'mirror':
    strategy = tf.distribute.MirroredStrategy()
# Multiple Machine, multiple compute device
elif DISTRIBUTE == 'multi':
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()print('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))</pre>			<p>Load and prepare the training, validation, and<a id="_idIndexMarker588"/> test partitions of data <a id="_idIndexMarker589"/>from the <span class="No-Break">GCS bucket:</span></p>
			<pre class="source-code">
# Preparing dataset
BUFFER_SIZE = 10000
def make_datasets_unbatched():
    # Load train, validation and test sets
    dest = 'gs://data-bucket-417812395597/'
    train_x = np.load(BytesIO(
        file_io.read_file_to_string(dest+'train_x', \
            binary_mode=True)
    ))
    train_y = np.load(BytesIO(
        file_io.read_file_to_string(dest+'train_y', \
            binary_mode=True)
    ))</pre>			<p>Similarly, load the validation and <span class="No-Break">test partitions:</span></p>
			<pre class="source-code">
    val_x = np.load(BytesIO(
        file_io.read_file_to_string(dest+'val_x', \
            binary_mode=True)
    ))
    val_y = np.load(BytesIO(
        file_io.read_file_to_string(dest+'val_y', \
            binary_mode=True)
    ))
    test_x = np.load(BytesIO(
        file_io.read_file_to_string(dest+'test_x', \
            binary_mode=True)
    ))
    test_y = np.load(BytesIO(
        file_io.read_file_to_string(dest+'test_y', \
            binary_mode=True)
    ))
    return train_x, train_y, val_x, val_y, test_x, test_y</pre>			<p>Define the TF model <a id="_idIndexMarker590"/>architecture for converting a black-and-white image to<a id="_idIndexMarker591"/> a <span class="No-Break">color image:</span></p>
			<pre class="source-code">
def tf_model():
    black_n_white_input = tensorflow.keras.layers.Input(shape=(80, 80, 1))
    enc = black_n_white_input</pre>			<p>Define the encoder<a id="_idIndexMarker592"/> part of <span class="No-Break">the model:</span></p>
			<pre class="source-code">
    #Encoder part
    enc = tensorflow.keras.layers.Conv2D(
        32, kernel_size=3, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)
    enc = tensorflow.keras.layers.Conv2D(
        64, kernel_size=3, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)</pre>			<p>Similarly, we will define two <a id="_idIndexMarker593"/>more encoder layers with an increasing number of filters, a kernel size of 3, and a stride of 2 so that we can compress the image into <span class="No-Break">important features:</span></p>
			<pre class="source-code">
    enc = tensorflow.keras.layers.Conv2D(
        128, kernel_size=3, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)
    enc = tensorflow.keras.layers.Conv2D(
        256, kernel_size=1, strides=2, padding='same'
    )(enc)
    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)
    enc = tensorflow.keras.layers.Dropout(0.5)(enc)</pre>			<p>Define<a id="_idIndexMarker594"/> the decoder <a id="_idIndexMarker595"/>part of <span class="No-Break">the model:</span></p>
			<pre class="source-code">
     #Decoder part
    dec = enc
    dec = tensorflow.keras.layers.Conv2DTranspose(
        256, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)
    dec = tensorflow.keras.layers.Conv2DTranspose(
        128, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)</pre>			<p>As we can see, the decoder <a id="_idIndexMarker596"/>design is almost opposite to the encoder part. Here, we re-create the image from compressed features by using multiple layers of transpose convolutions and reduce the channels gradually to 3 to generate the final<a id="_idIndexMarker597"/> color <span class="No-Break">image output:</span></p>
			<pre class="source-code">
    dec = tensorflow.keras.layers.Conv2DTranspose(
        64, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)
    dec = tensorflow.keras.layers.Conv2DTranspose(
        32, kernel_size=3, strides=2, padding='same'
    )(dec)
    dec = tensorflow.keras.layers.Activation('relu')(dec)
    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)
    dec = tensorflow.keras.layers.Conv2D(
        3, kernel_size=3, padding='same'
    )(dec)</pre>			<p>Finally, generate the color<a id="_idIndexMarker598"/> image output by using the <strong class="source-inline">tanh</strong> <span class="No-Break">activation function:</span></p>
			<pre class="source-code">
    color_image = tensorflow.keras.layers.Activation('tanh')(dec)
    return black_n_white_input, color_image</pre>			<p>The following function will build and compile the TF model <span class="No-Break">for us:</span></p>
			<pre class="source-code">
`# Build the and compile TF model
def build_and_compile_tf_model(loss_fn, learning_rate):
    black_n_white_input, color_image = tf_model()
    model = tensorflow.keras.models.Model(
        inputs=black_n_white_input,
        outputs=color_image
    )
    _optimizer = tensorflow.keras.optimizers.Adam(
        learning_rate=learning_rate,
        beta_1=0.5
    )
    model.compile(
        loss=loss_fn,
        optimizer=_optimizer
    )
    return model</pre>			<p>Now, let’s define the main function <a id="_idIndexMarker599"/>to start executing our training and tuning task. Here, the <strong class="source-inline">num_replicas_in_sync</strong> parameter defines how <a id="_idIndexMarker600"/>many training tasks are running in parallel on different workers in a multi-worker <span class="No-Break">training strategy:</span></p>
			<pre class="source-code">
def main():
    args = get_args()
    NUM_WORKERS = strategy.num_replicas_in_sync
    # Here the batch size scales up by number of workers since
    # `tf.data.Dataset.batch` expects the global batch size.
    GLOBAL_BATCH_SIZE = args.batch_size * NUM_WORKERS
    MODEL_DIR = os.getenv("AIP_MODEL_DIR")</pre>			<p>Load the training and validation <a id="_idIndexMarker601"/>data to start training our <span class="No-Break">TF </span><span class="No-Break"><a id="_idIndexMarker602"/></span><span class="No-Break">model:</span></p>
			<pre class="source-code">
    train_x, train_y, val_x, val_y, _, _ = \
        make_datasets_unbatched()
    with strategy.scope():
        # Creation of dataset, and model building/compiling need to be within
        # `strategy.scope()`.
        model = build_and_compile_tf_model(args.loss, \
            args.learning_rate)
    history = model.fit(
        train_x,
        train_y,
        batch_size=GLOBAL_BATCH_SIZE,
        epochs=args.epochs,
        steps_per_epoch=args.steps_per_epoch,
        validation_data=(val_x, val_y),
    )
    model.save(MODEL_DIR)</pre>			<p>Finally, define<a id="_idIndexMarker603"/> the HPT <a id="_idIndexMarker604"/>metric with the help of the <span class="No-Break"><strong class="source-inline">hypertune</strong></span><span class="No-Break"> package:</span></p>
			<pre class="source-code">
    # DEFINE HPT METRIC
    hp_metric = history.history['val_loss'][-1]
    hpt = hypertune.HyperTune()
    hpt.report_hyperparameter_tuning_metric(
      hyperparameter_metric_tag='val_loss',
      metric_value=hp_metric,
      global_step=args.epochs)
if __name__ == "__main__":
    main()</pre>			<p>Next, we create a staging bucket in GCS that will be used for storing artifacts such as trial outcomes from our <span class="No-Break">HPT job:</span></p>
			<pre class="source-code">
BUCKET_URI = "gs://hpt-staging"  # @param {type:"string"}
if BUCKET_URI == "" or BUCKET_URI is None or BUCKET_URI == "gs://[your-bucket-name]":
    BUCKET_URI = "gs://" + PROJECT_ID + "aip-" + TIMESTAMP
! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}
GCS_OUTPUT_BUCKET = BUCKET_URI + "/output/"</pre>			<p>The next step is to containerize the entire training code defined in the <strong class="source-inline">task.py</strong> file. The hyperparameter tuning<a id="_idIndexMarker605"/> job will use this container to launch different trials with different hyperparameters <span class="No-Break">as arguments:</span></p>
			<pre class="source-code">
%%writefile Dockerfile
FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-8
WORKDIR /
# Installs hypertune library
RUN pip install cloudml-hypertune
# Copies the trainer code to the Docker image.
COPY task.py .
# Sets up the entry point to invoke the trainer.
ENTRYPOINT ["python", "-m", "task"]</pre>			<p>Our <a id="_idIndexMarker606"/>Dockerfile is ready – let’s build <a id="_idIndexMarker607"/>and push the Docker image to <strong class="bold">Google Container </strong><span class="No-Break"><strong class="bold">Registry</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GCR</strong></span><span class="No-Break">):</span></p>
			<pre class="source-code">
PROJECT_NAME="*******-project"
IMAGE_URI = (
    f"gcr.io/{PROJECT_NAME}/example-tf-hptune:latest"
)
! docker build ./ -t $IMAGE_URI
! docker push $IMAGE_URI</pre>			<p>Now we have a container image ready with all the training code that we need. Let’s configure the <span class="No-Break">HPT job.</span></p>
			<p>First, we define the type of machine we want our trials to run on. The machine specification will depend upon the size of the model and training dataset. As this is a small experiment, we will <a id="_idIndexMarker608"/>use the <strong class="source-inline">n1-standard-8</strong> machine to <span class="No-Break">run it:</span></p>
			<pre class="source-code">
# The spec of the worker pools including machine type and Docker image
# Be sure to replace PROJECT_ID in the `image_uri` with your project.
worker_pool_specs = [
    {
        "machine_spec": {
            "machine_type": "n1-standard-8",
            "accelerator_type": None,
            "accelerator_count": 0,
        },
        "replica_count": 1,
        "container_spec": {
            "image_uri": f"gcr.io/{PROJECT_NAME}/example-tf-hptune:latest"
        },
    }
]</pre>			<p>Note that, within the worker<a id="_idIndexMarker609"/> pool spec, we have also passed the path to the training image that <span class="No-Break">we created.</span></p>
			<p>Next, we will define the parameter space that our job will use to find the <span class="No-Break">best hyperparameters:</span></p>
			<pre class="source-code">
# Dictionary representing parameters to optimize.
# The dictionary key is the parameter_id, which is passed into your training
# job as a command line argument,
# And the dictionary value is the parameter specification of the metric.
parameter_spec = {
    "learning_rate": hpt.DoubleParameterSpec(min=0.0001, \
        max=0.001, scale="log"),
    "epochs": hpt.DiscreteParameterSpec(values=[10, 20, \
        30], scale=None),
    "steps_per_epoch": hpt.IntegerParameterSpec(min=100, \
        max=300, scale="linear"),
    "batch_size": hpt.DiscreteParameterSpec(values=[16,32,\
        64], scale=None),
    "loss": hpt.CategoricalParameterSpec(["mse"]), # we can add other loss values
}</pre>			<p>The parameter space should be<a id="_idIndexMarker610"/> carefully defined based on best practices and prior knowledge so that the HPT job doesn’t have to perform unnecessary<a id="_idIndexMarker611"/> trials over unimportant <span class="No-Break">hyperparameter ranges.</span></p>
			<p>Next, we need to define the metric specifications. In our case, as we are trying to optimize the validation loss value, we would like to minimize it. In the case of accuracy, we should have maximized <span class="No-Break">our metric:</span></p>
			<pre class="source-code">
metric_spec = {"val_loss": "minimize"}</pre>			<p>Vertex AI HPT jobs use the Bayesian optimization approach by default to find the best hyperparameters for our settings. We also have the option to use other optimization approaches. As Bayesian optimization works best for most cases, we will be using it in <span class="No-Break">our experiment.</span></p>
			<p>Next, we define the custom job that will run our hyperparameter <span class="No-Break">tuning trials:</span></p>
			<pre class="source-code">
my_custom_job = aiplatform.CustomJob(
    display_name="example-tf-hpt-job",
    worker_pool_specs=worker_pool_specs,
    staging_bucket=GCS_OUTPUT_BUCKET,
)</pre>			<p>Finally, we define the HPT job that<a id="_idIndexMarker612"/> will launch the trials using the preceding <a id="_idIndexMarker613"/><span class="No-Break">custom job:</span></p>
			<pre class="source-code">
hp_job = aiplatform.HyperparameterTuningJob(
    display_name="example-tf-hpt-job",
    custom_job=my_custom_job,
    metric_spec=metric_spec,
    parameter_spec=parameter_spec,
    max_trial_count=5,
    parallel_trial_count=3,
)</pre>			<p>Note that the <strong class="source-inline">max_trial_count</strong> and <strong class="source-inline">parallel_trial_count</strong> parameters are <span class="No-Break">important here:</span></p>
			<ul>
				<li><strong class="source-inline">max_trial_count</strong>: You need to put an upper bound on the number of trials the service will run. More trials generally lead to better results, but there will be a point of diminishing returns, after which additional trials have little or no effect on the metric you’re trying to optimize. It is best practice to start with a smaller number of trials and get a sense of how impactful your chosen hyperparameters are before <span class="No-Break">scaling up.</span></li>
				<li><strong class="source-inline">parallel_trial_count</strong>: If you use parallel trials, the service provisions multiple training processing clusters. Increasing the number of parallel trials reduces the amount of time the hyperparameter tuning job takes to run; however, it can reduce the effectiveness of the job overall. This is because the default tuning strategy uses the results of previous trials to inform the assignment of values in subsequent trials. If we keep the parallel trial count equal to the number of maximum trials, then all trials will start running in parallel, and we will end up running a “random parameter search” here as there will not be any <a id="_idIndexMarker614"/>scope of learning from the performance of <span class="No-Break">previous trials.</span></li>
			</ul>
			<p>Now that we are all set, we can launch the <span class="No-Break">HPT job:</span></p>
			<pre class="source-code">
hp_job.run()</pre>			<p>As soon as we launch the job, it provides us with a link to the Cloud console UI, where we can monitor the progress of our HPT trials and jobs. The Cloud console UI looks something similar to what’s <a id="_idIndexMarker615"/>shown in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/B17792_09_1.jpg" alt="Figure 9.1 – HPT job monitoring within the Cloud console UI" width="771" height="752"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – HPT job monitoring within the Cloud console UI</p>
			<p>Now that we have successfully understood and launched an HPT job on Vertex AI, let’s jump to the next section and understand the NAS model <span class="No-Break">optimization technique.</span></p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor129"/>What is NAS and how is it different from HPT?</h1>
			<p><strong class="bold">Artificial Neural Networks</strong> or <strong class="bold">ANNs</strong> are widely used today for solving complex ML problems. Most of the time, these <a id="_idIndexMarker616"/>network architectures are hand-designed by ML experts, which may not be optimal every time. <strong class="bold">Neural Architecture Search</strong> or <strong class="bold">NAS</strong> is a technique that automates the process of designing neural network architectures that usually outperform <span class="No-Break">hand-designed networks.</span></p>
			<p>Although both HPT and <a id="_idIndexMarker617"/>NAS are used as model optimization techniques, there are certain differences in how they both work. HPT assumes a given architecture and focuses on optimizing the hyperparameters that lead to the best model. HPT optimizes hyperparameters such as learning rate, optimizer, batch size, activation function, and so on. NAS, on the other hand, focuses on optimizing architecture-specific parameters (in a way, it automates the process of designing a neural network architecture). NAS optimizes parameters such as the number of layers, number of units, types of connections between layers, and so on. Using NAS, we can search for optimal neural architectures in terms of accuracy, latency, memory, a combination of these, or a <span class="No-Break">custom metric.</span></p>
			<p>NAS usually works with a<a id="_idIndexMarker618"/> relatively larger search space than HPT and controls different aspects of network architectures. However, the underlying problem addressed is the same as HPT optimization. There are many NAS-based optimization approaches, but on a high level, any NAS approach has three main<a id="_idIndexMarker619"/> components, <span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break">Search space</span></li>
				<li><span class="No-Break">Optimization method</span></li>
				<li><span class="No-Break">Evaluation method</span></li>
			</ul>
			<p>Let’s learn more about each of <span class="No-Break">these components.</span></p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor130"/>Search space</h2>
			<p>This component controls the <a id="_idIndexMarker620"/>set of possible neural architectures to consider. The search space is often problem-specific, as a vision-related problem would have the possibility of having <strong class="bold">Convolutional Neural Network</strong> (<strong class="bold">CNN</strong>) layers as <a id="_idIndexMarker621"/>well. However, the process of identifying the best architecture is automated by NAS. Carefully designing these search spaces still depends upon <span class="No-Break">human expertise.</span></p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor131"/>Optimization method</h2>
			<p>This component <a id="_idIndexMarker622"/>decides how to navigate the search space to find the best possible architecture for a given application. Many different optimization methods have been applied to NAS, such as <strong class="bold">reinforcement learning</strong> (<strong class="bold">RL</strong>), Bayesian <a id="_idIndexMarker623"/>optimization, gradient-based optimization, evolutionary search, and so on. Each of these methods has its own way of evaluating the architectures, but the high-level goal is to focus on the area of the search space that provides better performance. This aspect of NAS is quite similar to HPT <span class="No-Break">optimization methods.</span></p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor132"/>Evaluation method</h2>
			<p>The evaluation method is a component that is used for assessing the quality of architectures designed by the chosen optimization method. One simple way to evaluate neural architecture is to fully train it, but this <a id="_idIndexMarker624"/>method is quite computationally expensive. Alternatively, to make NAS more efficient, partial training and evaluation methods have been developed. In order to provide cheaper heuristic measures of neural network quality, some evaluation methods have been developed. These evaluation methods are quite specific to NAS and exploit the basic structure of a neural network to estimate the quality of a network. Some examples of these methods include weight-sharing, hypernetworks, network morphism, and so on. These NAS-specific evaluation methods are practically way cheaper than <span class="No-Break">full training.</span></p>
			<p>We now have a good understanding of the NAS optimization method and how it works. Next, let’s explore the Vertex AI offering and its features for launching NAS on <span class="No-Break">Google Cloud.</span></p>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor133"/>NAS on Vertex AI overview</h1>
			<p>Vertex AI NAS is <a id="_idIndexMarker625"/>an optimization technique that can be leveraged to find the best neural network architecture for a given ML use case. NAS-based optimization searches for the best network in terms of accuracy <a id="_idIndexMarker626"/>but can also be augmented with other constraints such as latency, memory, or a custom metric as per the requirements. In general, the search space of possible neural networks can be quite large and NAS may support a search space as large as 10^20. In the past few<a id="_idIndexMarker627"/> years, NAS has been able to successfully generate some state-of-the-art computer vision network architectures, including NASNet, MNasNet, EfficientNet, SpineNet, NAS-FPN, and <span class="No-Break">so on.</span></p>
			<p>It may seem complex, but NAS features are quite flexible and easy to use. A beginner can leverage prebuilt modules for search spaces, trainer scripts, and Jupyter notebooks to start exploring Vertex AI NAS on a custom dataset. If you are an expert, you could potentially develop custom trainer scripts, custom search spaces, custom evaluation methods, and even develop applications for non-vision-based <span class="No-Break">use cases.</span></p>
			<p>Vertex AI can be leveraged to explore the full set of NAS features for our customized architectures and use cases. Here is what Vertex AI provides us with to help in implementing NAS <span class="No-Break">more conveniently:</span></p>
			<ul>
				<li>Vertex AI provides a NAS-specific language that can be leveraged to define a custom search space to try out the desired set of possible neural network architectures and integrate this space with our custom <span class="No-Break">trainer scripts.</span></li>
				<li>Pre-built state-of-the-art search spaces and a trainer that are ready to use and can run on <span class="No-Break">a GPU.</span></li>
				<li>A pre-defined NAS controller that samples our custom-defined search space to find the best neural <span class="No-Break">network architecture.</span></li>
				<li>A set of prebuilt libraries and Docker images that can be leveraged to calculate latency, FLOPS (Floating-point operations per second), or memory usage on a custom <span class="No-Break">hardware setting.</span></li>
				<li>Google Cloud provides tutorials to explain the usage of NAS. It also provides examples and guidance for setting up NAS for PyTorch-based <span class="No-Break">applications efficiently.</span></li>
				<li>Pre-built tools to design <span class="No-Break">proxy tasks.</span></li>
				<li>There is library<a id="_idIndexMarker628"/> support that can be leveraged to report custom-defined metrics and perform analysis <span class="No-Break">on them.</span></li>
				<li>The Google Cloud console is very helpful in monitoring and managing NAS jobs. We also get some easy-to-use example notebooks to kick-start <span class="No-Break">the search.</span></li>
				<li>Management of CPU/GPU resource usage on the basis of per project or per job, with the help of a <span class="No-Break">prebuilt library.</span></li>
				<li>A NAS client to<a id="_idIndexMarker629"/> build Docker images, launch NAS jobs, and resume an old NAS search job that <span class="No-Break">is Python-based.</span></li>
				<li>Customer support is Google Cloud <span class="No-Break">console UI-based.</span></li>
			</ul>
			<p>These features can help us in setting up a custom NAS job without putting in too much effort. Now let’s discuss some of the best practices while working <span class="No-Break">with NAS.</span></p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor134"/>NAS best practices</h2>
			<p>The important thing to note<a id="_idIndexMarker630"/> here is that NAS is not an optimization method that we should apply to all our ML problems. There are certain things to keep in mind before deciding to run a NAS job for our use case. Some of these best practices are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>NAS is not meant for tuning the hyperparameters of a model. It only performs an architecture search and it is not advised to compare the results of these two methods. In some setups, HPT can be followed <span class="No-Break">by NAS.</span></li>
				<li>NAS is not recommended for smaller or highly <span class="No-Break">imbalanced datasets.</span></li>
				<li>NAS is expensive, so unless we can spend a few thousand dollars without extremely high expectations, it’s not meant <span class="No-Break">for us.</span></li>
				<li>You should first try other traditional and conventional machine learning methods and techniques such as hyperparameter tuning. You should use neural architecture <a id="_idIndexMarker631"/>search only if you don’t see further gains with <span class="No-Break">traditional methods.</span></li>
			</ul>
			<p>Setting up NAS jobs on Vertex AI is not very complex, thanks to the prebuilt assets and publicly released code examples. With these prebuilt features, examples, and best practices, we should be able to set up a custom NAS job that can help us find an optimal architecture to meet our <span class="No-Break">project goals.</span></p>
			<h1 id="_idParaDest-135"><a id="_idTextAnchor135"/>Summary</h1>
			<p>In this chapter, we discussed the importance of applying model optimization techniques to get the best performance for our application. We learned about two model optimization methods – HPT and NAS, with their similarities and differences. We also learned how to set up and launch large-scale HPT jobs on Vertex AI with code examples. Additionally, we discussed some best practices to get the best out of both HPT <span class="No-Break">and NAS.</span></p>
			<p>After reading this chapter, you should have a fair understanding of the term “model optimization” and its importance while developing ML applications. Additionally, you should now be confident about quickly setting up small to large-scale hyperparameter tuning experiments with the help of Vertex AI tooling on Google Cloud. You should also have a fair understanding of NAS, its differences from HPT, and the best practices for setting up a <span class="No-Break">NAS job.</span></p>
			<p>Now that we understand the importance and common methods of model optimization techniques, we are in good shape to develop high-quality models. Next, let’s learn about how to deploy these models so that they can be consumed by <span class="No-Break">downstream applications.</span></p>
		</div>
	</div>
</div>
</body></html>