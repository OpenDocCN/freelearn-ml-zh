# *第6章*：特征工程和标注

在上一章中，我们学习了如何清理我们的数据并进行基本统计分析。在本章中，我们将深入探讨在开始我们的机器学习训练之前必须执行的两种更多类型的操作。这两个步骤是所有步骤中最重要的，除了高效地清理数据集之外，而且要擅长它们，你需要有大量的经验。本章将为你提供一个基础来构建。

在第一部分，我们将学习特征工程。我们将了解这个过程，如何从我们的数据集中选择预测特征，以及将我们的数据集中的特征转换为可用于我们的机器学习算法的方法。

在第二部分，我们将探讨数据标注。大多数机器学习算法属于监督学习类别，这意味着它们需要标注的训练数据。我们将探讨一些需要标签的典型场景，并学习Azure机器学习如何帮助完成这项繁琐的任务。

在本章中，我们将涵盖以下主题：

+   理解和应用特征工程

+   处理数据标注

# 技术要求

在本章中，我们将使用以下Python库和版本来对不同的数据集进行特征工程。

+   `azureml-sdk 1.34.0`

+   `azureml-widgets 1.34.0`

+   `azureml-dataprep 2.20.0`

+   `pandas 1.3.2`

+   `numpy 1.19.5`

+   `scikit-learn 0.24.2`

+   `seaborn 0.11.2`

+   `plotly 5.3.1`

+   `umap_learn 0.5.1`

+   `statsmodels 0.13.0`

+   `missingno 0.5.0`

与前几章类似，你可以使用本地Python解释器或Azure机器学习中的笔记本环境执行此代码。

本章中所有的代码示例都可以在本书的GitHub仓库中找到：[https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06)。

# 理解和应用特征工程

**特征工程**是一个通用术语，描述了将我们数据集中的现有特征进行转换、创建缺失特征，并最终从我们的数据集中选择最具有预测性的特征以使用给定的机器学习算法开始机器学习训练过程的过程。这些不能仅仅被视为我们必须应用于我们的数据的某些数学函数。这是一种艺术形式，做得好可以区分一个平庸和高度表现的预测模型。如果你想知道你应该在哪里投入时间，特征工程是你可以对最终机器学习模型的质量产生最大影响的步骤。为了产生这种影响并提高效率，我们必须考虑以下因素：

+   **机器学习算法要求**：特征是否需要特定的格式或范围？我如何最好地避免模型过拟合和欠拟合？

+   **领域知识**：给定的特征是否足够用于我们的模型？我们能否创建包含更多预测信息的附加特征或派生特征？

在本节中，我们将定义不同的特征工程技术类别，然后探讨一些应用于不同类型数据集的最显著方法。

重要提示

请记住，特定特征工程方法的有用性取决于所使用的特征类型（分类、连续、文本、图像、音频）以及所选的机器学习算法。

## 特征工程技术分类

广义而言，特征工程方法可以归纳为以下类别：

+   **特征创建**：从给定的特征集或额外的信息源中创建新的特征。

+   **特征转换**：转换单个特征，使其对所使用的机器学习算法有用且稳定。

+   **特征提取**：从原始数据中创建派生特征。

+   **特征选择**：选择最突出和最具预测性的特征。

让我们看看这些类别及其包含的内容。

### 特征创建

特征工程的第一步是找到模型中应包含的所有特征。要擅长这一点，你必须对相关领域有深入了解，或者知道该领域的**领域专家**（SME）。最后，我们想要确保我们考虑了任何具有预测性且在合理时间内可以获取的数据点。

反过来，我们必须理解所有可以帮助我们在数据集中创建新特征的方法，无论是来自额外来源还是初始数据集。通常，这些方法可以按以下方式分类：

+   **添加缺失的预测特征**：我们添加外部缺失信息，以实现更具有预测性的模型。

+   **结合可用特征**：我们通过结合数据集中已有的特征来创建新的特征。

为什么我们必须更改数据集中已经存在的特征？

原因在于，我们理解的许多特征与标签之间的联系可能对所使用的机器学习算法来说并不明显。因此，考虑哪些特征或可用特征的表示我们认为对于使机器学习算法更容易把握内在联系是很有帮助的。

让我们看看一些例子，以便更好地理解这一点。

想象一下，你有一个用于预测房价的数据集，就像我们在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)“执行数据分析与可视化”中考察的那样。此外，想象一下我们拥有的特征是房屋或公寓的**长度**和**宽度**。在这种情况下，将这两个特征结合起来创建一个名为**面积**的新特征可能是有用的。此外，如果缺少**建筑类型**（房屋、公寓、联排别墅等），我们可能需要从其他来源添加这个信息，因为我们知道类型会影响房产的价格。

重要提示

如果你从现有特征中创建新特征，通常明智的做法是只保留新创建的特征，从数据集中删除那些初始特征。

现在，想象一下一个人在其一生中花费的金额。年轻时，这可能会非常少。随着年龄的增长，他们可能会有抵押贷款和子女，最终，当他们的子女搬出家时，他们的支出可能会下降，他们接近退休。由于这会在**年龄**和**生活成本**之间形成某种抛物线关系，因此，对于机器学习算法来说，可能不容易掌握这一点。因此，一个可能的选择是将**生活成本**特征的值平方，以强调更高的成本，并降低较低的成本的重要性。

在前两个例子中，我们使用了我们的领域知识来创建新的特征。但如果我们没有这种知识怎么办？

有一种方法可以通过所谓的**多项式扩展**在数学上创建新特征。这个想法是通过将一个特征的值提升到一定的幂，并乘以一个或多个其他特征来创建新特征。在这里，我们定义**度**为单个特征可以提升到的最大幂，我们定义**顺序**为我们允许相互乘积的特征的数量。以下图表显示了左侧阶数为2，顺序为2的所有可能组合，以及右侧阶数为3，顺序为3的所有可能组合：

![图6.1 – 多项式扩展的可能组合（左侧为阶数=2，顺序=2；右侧为阶数=2，顺序=3）](img/B17928_06_01.jpg)

图6.1 – 多项式扩展的可能组合（左侧为阶数=2，顺序=2；右侧为阶数=3，顺序=3）

你应该只考虑最大阶数为3，因为，如图所示，即使阶数为2，这个操作也已经产生了太多的组合。然而，这个自动过程可能比原始的特征产生更好的预测特征。

要尝试这种方法，你可以使用`sklearn`库中的`PolynomialFeatures`类（[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)）。

在考虑了所有这些方法之后，我们可以在我们的数据集中创建新的特征，这些特征可能更容易被我们的机器学习算法处理，并且包含更精确、更具预测性的信息。

接下来，让我们看看一些让我们可以通过转换其值或其表示来改变单个特征的方法。

### 特征转换

**特征转换**是关于操纵特征以改变其值或创建相同特征的新表示。以下列表涵盖了我们可以对单个特征执行的转换类型：

+   **离散化**：将特征值划分为不同的组或区间以降低复杂性。这可以在数值或分类特征上完成。

+   **拆分**：将特征拆分为多个元素。这通常是在日期时间和字符串值上进行的。

+   **分类编码**：通过创建新的数值特征并遵循特定方法来数值化分类特征。

+   **缩放**：将连续特征转换为一个适合特定值范围的值。

+   **标准化**：将连续特征转换为一个具有均值为0和标准差为1的正态分布。

+   **归一化**：将多个连续特征的向量（行）分别转换为一个所谓的单位范数（单位大小）。

+   `square`、`square root`、`exp`、`log`等。

在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)，“执行数据分析与可视化”中，我们使用了`log`函数来计算所有房价值的对数。我们这样做是为了减少少数异常值对我们机器学习训练的影响。因此，转换特征的主要原因是使特征适应给定机器学习算法的可能数学要求。通常，你可能会遇到以下机器学习算法的要求：

+   **数值格式**：算法要求所有特征都是数值的。

+   **相同尺度**：算法要求所有预测特征都在相同的尺度上，甚至可能具有均值为0和标准差为1。

+   **数学理论**：域本身可能需要根据数学理论进行某些转换。例如，对于涉及经济理论的预测，价格特征几乎总是需要用自然对数进行转换。

+   `[-1,1]`.

+   **复杂性**：大多数算法都需要非常精确的特征。因此，降低特征可能取值的复杂性通常是有价值的。

例如，离散化特征。其中一种方法称为**分箱**，它将数值连续值转换为少量离散值。我们将在[*第七章*](B17928_07_ePub.xhtml#_idTextAnchor112)，“使用NLP的高级特征提取”中看到这一方法的应用。

另一个例子是将日期时间特征分割。想象一下，我们想要预测一天中特定时间某条道路上的交通量。假设我们得到了一个表示我们记录的**日期和时间**以及在那个点追踪的**汽车数量**的特征。为了做出更好的预测，一个想法是创建三个新的特征，表示是否是**工作日**、**周末**或**假日**。与工作日上午7点相比，星期天上午7点的交通量会更少。

让我们学习如何执行这种转换。以下截图显示了我们的初始小型数据库和添加`星期几`的第一个转换：

![图6.2 – 包含新工作日特征的数据库](img/B17928_06_02.jpg)

图6.2 – 包含新工作日特征的数据库

在下一步中，我们必须通过添加一个名为`daytype`的新分类特征来丰富数据，该特征表示一天是工作日、周末还是假日：

![图6.3 – 数据库丰富化](img/B17928_06_03.jpg)

图6.3 – 数据库丰富化

理论上，我们已经完成了。但我们的机器学习算法可能在这里有不同的看法。我们的机器学习模型可能会为我们的分类数据创建一个不存在的自然顺序，或者它简单地无法处理分类数据。在这种情况下，明智的做法是将我们的分类数据用数值进行**编码**。一种这样的方法称为**独热编码**，它通过为每个现有类别创建一个具有两个有效值（0或1）的新特征，将分类特征转换为多个数值特征。以下截图显示了我们对示例的这种编码：

![图6.4 – 对新特征进行独热编码](img/B17928_06_04.jpg)

图6.4 – 对新特征进行独热编码

在这里，我们创建了三个新的特征，分别命名为`holiday`、`weekday`和`weekend`，每个特征代表我们的初始类别。如果一个样本具有这个初始类别，那么该特征的值设置为`1`；否则，设置为`0`。

在这个例子中，我们做了什么？我们通过分割特征，添加外部知识通过特征创建，并在创建的特征上执行分类编码，将一个非常不直观的日期时间特征转换成具有更多预测力的特征。

现在我们已经很好地掌握了特征转换，让我们看看什么是特征提取的范畴。

### 特征提取

通过**特征提取**，我们将所有不通过简单手段操纵特征但能从高维数据集中提取有用信息的方法分组在一起。这通常是通过使用复杂的数学算法或机器学习算法来完成的。

当底层数据集过于复杂而难以处理时，通常需要提取，同时保持其预测价值，将其转化为简化的形式。 

以下是一些不同场景下的典型提取类型：

+   **高维降维**：基于n维数据集创建代表性特征。

+   **特征检测**：在图像数据集中的每张图像中找到感兴趣点。

+   **词嵌入**：为文本数据集中的单词创建数值编码。

+   **信号处理**：从音频数据集中提取声音波的特征。

我们在[*第5章*](B17928_05_ePub.xhtml#_idTextAnchor085)“执行数据分析和可视化”中讨论了高维降维方法，当时我们探讨了可视化高维数据集。在**主成分分析**（PCA）这样的过程中，数据集通过创建主成分向量被投影到二维或三维空间。我们不仅可以使用这种方法进行可视化，还可以使用这些计算向量作为派生和更简单的特征，这些特征代表我们的数据集。

重要提示

高维降维技术可用于特征提取，但请注意，我们失去了对特征的内禀理解。我们最终得到的不是称为郊区或房间的特征，而是称为主成分1和主成分2的特征。

观察其他场景，似乎提取通常发生在我们处理由文本、图像或音频数据组成的复杂数据集时。在这些所有情况下，当我们从原始数据中提取信息时，都有特定的方法需要考虑。

在图像数据集的情况下，我们可能对关键区域或感兴趣点感兴趣，包括寻找边缘和对象。在[*第10章*](B17928_10_ePub.xhtml#_idTextAnchor165)“在Azure上训练深度神经网络”中，你会看到这样的图像提取步骤是由**深度神经网络**自动完成的，从而消除了在许多情况下对图像进行手动特征提取的需要。

在文本数据的情况下，我们可以使用诸如**词袋模型**和**TF-IDF**之类的提取方法，这两种方法都有助于创建文本的数值表示，捕捉意义和语义关系。我们将在[*第7章*](B17928_07_ePub.xhtml#_idTextAnchor112)“使用NLP的高级特征提取”中深入探讨这些方法。

在音频数据的情况下，我们可以使用信号处理从源数据中提取信息和新的特征。在这种情况下，也存在两个领域——时域和频域——我们可以从中提取信息。从时域来看，我们通常会提取诸如**幅度包络**这样的内容，它是每帧信号的峰值幅度，**均方根能量**，它暗示了信号的响度，以及**过零率**，即波穿越水平时间轴的次数。如果你必须处理来自这个领域的数据，请让自己熟悉这样的处理技术。

重要提示

许多特征提取和特征转换技术已经嵌入到常见的机器学习框架和算法中，无需您手动触摸特征。通过理解算法本身做什么以及您在预处理时需要手动做什么，来获得良好的理解。

到目前为止，我们已经学习了如何创建新特征、转换特征以及从我们的数据集中提取特征。现在，让我们看看一些可以帮助我们从特征集中选择最具预测性的特征的方法。

### 特征选择

通过**特征选择**，我们定义了所有帮助我们理解特征对目标有价值性和预测性的方法，以便我们可以选择有用的特征变量子集进行训练。减少复杂性的原因有两个。一方面，我们希望简单性使模型**可解释**；另一方面，我们希望避免模型**过拟合**。当输入信息过多时，我们最终会得到一个模型，在大多数情况下，这个模型会完美地拟合我们的训练数据，但除了这些之外，它在未见过的数据上的表现会很差。

通常，有三种不同类型的特征选择方法，如下所示：

+   **基于过滤的方法**：这些方法定义了一个派生指标，即不是目标错误率，来衡量特征子集的质量。

+   **基于包装的方法**：这些方法使用贪婪搜索算法在不同的特征子集组合上运行预测模型。

+   **嵌入式方法**：这些是已经嵌入到我们最终机器学习模型中的特定选择方法。

基于过滤的方法在计算资源方面可以非常高效，但仅与一个更简单的过滤方法进行评估。通常，这些方法中使用统计指标，如相关性、互信息和熵作为度量标准。

另一方面，基于包装的方法计算密集。同时，它们可以找到性能极佳的特征集，因为用于特征选择的错误函数或指标与实际模型训练中使用的相同。这种方法的不利之处在于，如果没有独立的指标，选定的子集仅对所选的机器学习训练算法有用。通常，这是通过执行以下过程之一来完成的：

+   **逐步前进特征选择**：根据每个特征的训练结果逐个添加特征，直到模型不再提高其性能。

+   **逐步后退特征选择**：使用完整特征集评估模型。然后，这些特征被逐一移除，直到达到预定义的特征数量。这种移除是循环进行的。

+   **穷举特征选择**：评估所有特征子集，这是最昂贵的方法。

最后，当选择步骤是模型学习算法本身的一部分时，选择方法被称为嵌入式方法。嵌入式方法通常通过学习算法利用其选择过程，同时进行选择和训练，从而结合过滤器和包装方法的特性。嵌入式方法的典型例子是集成模型、**Lasso**和**Ridge**。

你可能现在已经意识到了，我们在[*第5章*](B17928_05_ePub.xhtml#_idTextAnchor085)，*执行数据分析与可视化*中使用了这样的方法。我们用于生成相关矩阵的**皮尔逊相关系数**是一个派生指标，因此它属于基于过滤器的选择方法。此外，我们还使用了一个**集成决策树模型**来计算数据集的特征重要性。这有助于我们清楚地了解哪些特征可能比其他特征对目标有更大的影响。这种集成方法利用了**随机森林**方法。随机森林不仅实现了所谓的**袋装**技术，随机选择样本子集进行训练，而且还随机选择特征，而不是使用所有特征来生长每一棵树。因此，对于特征选择，随机森林属于嵌入式类别。

我们将在[*第9章*](B17928_09_ePub.xhtml#_idTextAnchor152)，*使用Azure机器学习构建ML模型*中更详细地查看基于树的集成分类器，以及袋装和提升。

除了所有这些特征选择的数学方法之外，有时，更手动的方法可能更优越。例如，当我们从[*第5章*](B17928_05_ePub.xhtml#_idTextAnchor085)，*执行数据分析与可视化*中的**墨尔本住房数据集**中删除邮政编码时，我们这样做是因为我们理解邮政编码和郊区包含相同的信息，这使得它们是冗余的。我们这样做是因为我们具有领域知识，并了解邮政编码和郊区之间的关系。请注意，这种额外的知识减轻了模型自己学习这些联系的压力。

重要提示

对于特征工程，对数据或领域了解的更多外部知识，可以使许多预处理步骤变得更加简单，或者完全避免。

我们将在本书中反复阐述这一概念，因为它需要融入你做的每一件事，以便你更高效、更擅长处理数据。

我们现在对可以执行的一般特征工程类型有了总体了解。在下一节中，我们将概述最显著的方法，并深入探讨其中的一些方法。

## 发现特征转换和提取方法

现在我们已经很好地掌握了我们可以应用于特征的特征工程动作类型，让我们来看看一些最突出的特征工程技术和它们的名称。以下表格提供了我们所学不同类别中大多数已知方法的良好概述：

![图6.5 – 不同特征工程方法的概述](img/B17928_06_05.jpg)

图6.5 – 不同特征工程方法的概述

请记住，这个列表远非详尽无遗，正如我们之前提到的，其中一些方法已经作为特定机器学习算法的一部分得到实现。

在接下来的章节中，我们将探讨其中的一些。您可以自由下载GitHub仓库中该章节的`01_feateng_examples.ipynb`文件，其中包含即将到来的示例的代码。如果您想了解更多关于我们将要介绍的一些特征提取方法，我们将在接下来的章节中回到它们。对于我们将不介绍的方法，请自由研究它们。

### 缩放、标准化和归一化

由于所有缩放和归一化方法彼此之间非常相似，我们在这里将详细讨论它们。

让我们从所谓的**StandardScaler**开始。这种缩放将我们的特征值转换，使得结果值分布的均值（µ）为0，标准差（s）为1。应用于每个值的公式看起来如下：

![](img/Formula_06_01.png)

在这里，µ是给定分布的均值，s是给定分布的标准差。有了这个，我们可以将每个值，![](img/Formula_06_02.png)，转换成一个新的缩放值，![](img/Formula_06_03.png)。

下图展示了该缩放器如何改变多个分布的形状：

![图6.6 – StandardScaler分布（左：缩放前，右：缩放后）](img/B17928_06_06.jpg)

图6.6 – StandardScaler分布（左：缩放前，右：缩放后）

只有当底层分布是*正态分布*时，才应使用此缩放器，因为这符合要求。

接下来，我们将探讨**MinMaxScaler**。这种缩放方法与标准化非常相似，只是我们不是在处理值分布的均值或标准差；相反，我们将值缩放到[0,1]或[-1,1]（如果存在负值）的范围内。以这种方式缩放特征通常会提高机器学习算法的性能，因为它们通常更擅长处理小规模值。

从数学上讲，这种缩放定义为以下：

![](img/Formula_06_04.png)

在这里，![](img/Formula_06_05.png)定义了初始分布的最小值，而![](img/Formula_06_06.png)定义了初始分布的最大值。

如果最小值和最大值定义良好，MinMaxScaler是一个不错的选择 – 想想RGB图片中的颜色强度。此外，我们可以改变公式以影响结果的值范围。

重要提示

StandardScaler和MinMaxScaler都对分布中的异常值非常敏感，这反过来又可能扭曲某些机器学习算法。

许多机器学习算法更关注大值，因此它们存在异常值的问题。为了解决这个问题，定义了一个名为**RobustScaler**的缩放器。这个缩放器使用**四分位距**（**IQR**）而不是标准差作为离散度的度量，并使用分布的**中位数**而不是平均值作为集中趋势的度量。四分位距表示分布中间的50%，这意味着它是第75百分位数和第25百分位数之间的差值。

因此，数学缩放函数看起来是这样的：

![](img/Formula_06_07.png)

在这里，![](img/Formula_06_08.png)表示分布的中位数，![](img/Formula_06_09.png)表示第一四分位数开始的位置，![](img/Formula_06_10.png)表示第三四分位数开始的位置。

为什么这个缩放器对异常值更有效？

在前面的公式中，最大的异常值仍然会落在预定义的区间内，因为最大的异常值会是![](img/Formula_06_11.png)。因此，异常值离数据点群越远，中心值缩向0的程度就越大。另一方面，使用RobustScaler，中间50%的所有数据点都会缩放到单位距离，而高于或低于这个值的数据点会被缩放到主要区间之外适当的值，同时保持分布中间值之间的相对距离不变。

简而言之，中位数和四分位距受异常值的影响不大，因此这个缩放器受异常值的影响也不大。

让我们看看这些缩放器在一个样本分布上的表现。为此，我们将取`Price`列的`Price`列和应用我们讨论的每种缩放方法得到的分布：

![图6.7 – 使用多种缩放方法缩放的分布](img/B17928_06_07.jpg)

图6.7 – 使用多种缩放方法缩放的分布

如我们所见，**StandardScaler**创建了一个均值为0、标准差为1的分布，**MinMaxScaler**将值缩放到0到1之间，而**RobustScaler**将均值设置为0。查看*图6.8*和*图6.9*中的箱线图，我们可以看到它们分布的差异。请注意*y*轴的刻度：

![图6.8 – StandardScaler和RobustScaler的箱线图](img/B17928_06_08.jpg)

图6.8 – StandardScaler和RobustScaler的箱线图

将下面的箱线图与*图6.8*进行比较，我们可以看到它们分布的差异：

![图6.9 – MinMaxScaler的箱线图](img/B17928_06_09.jpg)

图6.9 – MinMaxScaler的箱线图

现在我们已经对如何缩放一个特征有了些了解，让我们来谈谈归一化。

**归一化**是将特征值向量（行）缩放到**单位模长**的过程，通常是为了简化如**余弦相似度**这样的数学过程。

让我们先了解一个可以从中受益的归一化步骤。余弦相似度描述了两个不同向量之间的相似程度。在一个n维空间中，它们是否指向同一方向，是否相互垂直，或者是否面向相反方向？

例如，这样的计算可以帮助我们理解文本文档之间的相似性，通过取词频向量或类似信息并比较它们来实现。

因此，为了理解文档相似性，我们必须使用以下公式计算向量之间的余弦值：

![公式_06_12.png](img/Formula_06_12.png)

如您所见，为了进行这个计算，我们必须计算每个向量的模——例如，![公式_06_13.png](img/Formula_06_13.png)。这个模定义为以下内容：

![公式_06_14.png](img/Formula_06_14.png)

这个单独的向量模长计算相当昂贵。现在，假设我们有一个包含数十万个文档的数据集。我们每次都必须为数据集中每个向量的组合（样本）计算这个值。如果所有这些向量模长都等于1，不是会更容易吗？这将极大地简化余弦的计算。

因此，我们的想法是通过适当缩放所有样本，将数据集中的所有样本归一化到单位模长，如下所示：

![公式_06_15.png](img/Formula_06_15.png)

在这个方程中，![公式_06_16.png](img/Formula_06_16.png)表示我们的初始向量，![公式_06_17.png](img/Formula_06_17.png)表示初始向量的模，![公式_06_18.png](img/Formula_06_18.png)表示我们缩放到单位模长的缩放向量。

这种归一化称为**L2范数**，是三种典型归一化方法之一。让我们看看在这个以及其他所有度量中如何计算向量的模：

+   **L1范数**：这个计算将向量的模定义为向量各分量绝对值的和。

+   **L2范数**：这个计算的是传统的向量模长（如上所述）。

+   **最大范数**：这个计算的是向量的元素绝对值的模。

L1范数和最大范数不能用于余弦相似度，因为它们没有计算数学上定义的向量模。所以，让我们看看这两个是如何计算的。

L1范数在数学上定义为以下内容：

![公式_06_19.png](img/Formula_06_19.png)

L1范数常用于在拟合机器学习算法时正则化数据集中的值。它保持系数较小，这使得模型训练过程更简单。

最大范数在数学上定义为以下内容：

![公式_06_20.png](img/Formula_06_20.png)

最大范数也用于正则化，通常在**神经网络**中用于保持神经元之间连接的权重低，这也有助于执行更少的极端反向传播运行以稳定机器学习算法的学习。

到目前为止，你应该已经很好地掌握了缩放和归一化的有用性。接下来，我们将探讨一些可以将分类值转换为数值表示的方法。

### 分类编码

当我们将特征转换作为一个概念来考虑时，我们查看了一个应用了**独热编码**的例子。这种方法为初始分类特征中的每个可用类别创建具有两个可能值（0，1）的新特征。这可能很有帮助，但高基数分类特征会极大地膨胀特征空间。因此，在使用这种方法时，我们必须弄清楚每个类别是否具有预测性。

在我们之前的例子中，我们不是使用一周中每天（周一至周六）的类别，而是选择了只有三个类别，即工作日、周末和假日。在这种情况下，独热编码非常有帮助。

除了这种方法之外，还有其他方法可以编码分类特征。其中最基本的方法是**标签编码**。在标签编码中，我们将每个类别替换为一个数值标签（0，..，*n*），从而使其成为一个数值特征。通过这种方式，我们没有向这个特征添加任何额外的信息。

接下来的想法是将整个数据集的一些内在信息添加到我们必须编码的值中，并使其融入其中。这个想法的一些选项如下：

+   **计数编码**：将每个类别替换为整个数据集中该类别观察值的绝对数量。

+   **频率编码**：将每个类别替换为整个数据集中该类别观察值的相对数量（百分比）。

+   **目标编码**：将每个类别替换为从整个数据集中该类别的每个条目计算出的目标平均值。

为了理解这些方法，让我们假设我们有一个包含25个人的最爱零食项作为特征之一，以及他们购买公司生产的新零食产品的可能性的数据集。以下表格显示了原始值和我们所讨论的所有三种编码：

![图6.10 – 计数、频率和目标编码示例](img/B17928_06_10.jpg)

图6.10 – 计数、频率和目标编码示例

使用这些方法，我们可以将额外的信息融入特征中，使机器学习算法更容易理解关系。

最后，让我们谈谈`Rare`，因此将它们归为一类。这有助于降低整体复杂性，特别是如果`Rare`类别仍然只是整体类别分布的一小部分时，更应该这样做。你可以将这比作在选举图中将小党派归入*其他*标签，而主要展示大党派。

到目前为止，你应该对不同的编码技术有了很好的理解。在下一节中，我们将讨论我们如何在真实数据集上尝试这些技术。

## 在表格数据集上测试特征工程技术

在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)《执行数据分析与可视化》中，我们对**墨尔本住房数据集**进行了一些清理和统计分析。在上一节查看了一系列可能的特征工程方法之后，你可能已经意识到我们在处理数据集时使用了其中的一些方法。

作为练习，思考我们之前停在了哪里，并考虑到特征工程选项，我们现在可以做什么来创建新的有用特征，转换给定的特征，并最终在我们的数据集中选择最突出和最具预测性的特征。

为了获得灵感，请查看GitHub仓库中本章的`02_fe_melbhousing.ipynb`文件。

在本章的最后部分，我们将放下特征空间，专注于我们的机器学习训练的目标或标签——更准确地说，是那些缺少标签的情况。

# 处理数据标注

在本节中，我们将探讨在为机器学习训练预处理数据集时最耗时且最重要的任务之一：**数据标注**。正如我们在[*第一章*](B17928_01_ePub.xhtml#_idTextAnchor015)《理解端到端机器学习流程》中学习到的那样，对于大多数场景，将标签附加到我们的样本上至关重要。正如我们在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)《执行数据分析与可视化》中查看高维降维和其他机器学习技术时讨论的，在大多数情况下，我们希望使用监督模型，这意味着我们需要标签。

在接下来的几节中，我们将讨论哪些场景需要我们进行手动标注，以及Azure机器学习如何帮助我们尽可能高效地完成这项单调的任务。

## 分析需要标签的场景

我们将首先查看我们迄今为止讨论过的数据集类型，以及我们需要在哪些场景下进行手动标注。

### 数值数据和分类数据

正如我们在处理**墨尔本住房数据集**时所见，对于表格数据集，我们可能经常有一个可以用作标签的列。在我们的案例中，我们可以用作标签的是价格列，因为我们的机器学习目标是根据特定的特征输入预测房价。

即使这个列缺失了，我们也可以纳入其他数据集，例如显示墨尔本不同郊区的房屋平均价格的那些数据集，来为我们的数据集样本中的每一个计算一个合理的价值。

因此，与其他我们将讨论的任何场景相比，主要优势在于，在由具有明确意义（不是图像的像素值）的数值和分类特征组成的数据集中，我们可以使用逻辑和数学函数来创建数值标签，或者我们可以自动将样本分类到分类标签。这意味着我们不必手动查看每个样本来定义其标签。

### 自然语言处理

让我们先看看文本数据。你可能认为分类条目在某种程度上也是文本，但通常，分类数据也可以用数学值交换，而不会损失太多。

另一方面，文本数据表示单词块，例如这本书中的那些，因此它们要复杂得多。看看以下两个句子或话语：

*我想预订2020年12月23日从迪拜到巴黎的机票。*

*房间没有打扫，暖气也不工作。*

我们将如何标记这些话语？这非常取决于我们的训练目标。也许我们只想将这些话语分组，例如订单、问候或陈述。在这种情况下，每个话语都会收到一个标签。另一方面，我们可能想要深入挖掘句子中单词的意义。对于我们的第一个话语，我们可能想要理解订单的意义，通过展示可能的航班选项来提供答案。对于第二个话语，我们可能想要理解情感，因为它是对酒店房间质量的陈述。

因此，我们需要在话语本身开始标记单个单词或短语，同时寻找其语义意义。

我们将在[*第7章*](B17928_07_ePub.xhtml#_idTextAnchor112)中回到这个话题，*使用NLP的高级特征提取*。

### 计算机视觉

当我们谈论图像的机器学习建模时，我们通常试图理解和学习以下之一：

+   **图像分类**：将图像分类到一类或多类。典型用例包括图像搜索、图书馆管理和对人的情感分析。

+   **目标检测**：在图像中定位特定对象。典型用例包括行人检测、交通流量分析和对象计数。

+   **图像分割**：将图像的每个像素分配到特定的区域。典型用例包括自动驾驶汽车的精确环境分析和 X 射线或 MRI 图像中的像素级异常检测。

以下图示展示了这三种类型的示例：

![图 6.11 – 不同的图像处理方法](img/B17928_06_11.jpg)

图 6.11 – 不同的图像处理方法

对于这些方法，随着我们向下查看列表，标注的过程变得更加复杂。对于分类，我们只需在图像上放置一个或多个标签。对于目标检测，我们在图像上开始绘制所谓的边界框或多边形。最后，图像分割变得非常复杂，因为我们必须为图像的每个像素分配标签。为此，需要高度专业的工具。

如我们很快将看到的，我们可以使用 Azure Machine Learning Studio 中的数据标注工具来进行分类、目标检测，并在一定程度上进行图像标注任务的分割。

### 音频标注

最后，让我们来谈谈音频数据的标注。当涉及到音频数据的机器学习建模时，以下场景是可能的：

+   **语音转文本**：运行实时转录、语音助手、发音评估和类似解决方案。

+   **语音翻译**：将语音翻译为触发应用程序或设备中的操作。

+   **说话人识别**：通过声音特征验证和识别说话人。

因此，标注音频数据意味着我们必须从音频文件中提取片段，并相应地标注这些片段。以下图示展示了这个过程的简单示例：

![图 6.12 – 音频标注过程](img/B17928_06_12.jpg)

图 6.12 – 音频标注过程

如您所想，这个标注任务也不是非常直接，需要专门的工具。

我们已经看到了很多标注至关重要的场景。现在，让我们尝试自己标注一些图像。

## 使用 Azure Machine Learning 标注服务进行图像分类的数据标注

在本节中，我们将使用 Azure Machine Learning Studio 中的数据标注服务来标注一些资产。正如我们在[*第 3 章*](B17928_03_ePub.xhtml#_idTextAnchor054)，“准备 Azure Machine Learning 工作区”中学习的，导航到 Azure Machine Learning Studio 并在菜单底部点击**数据标注**，如图下截图所示：

![图 6.13 – Azure Machine Learning Studio](img/B17928_06_13.jpg)

图 6.13 – Azure Machine Learning Studio

在下一个屏幕上，点击**添加项目**，这将带您到以下视图：

![图 6.14 – 标注项目创建向导](img/B17928_06_14.jpg)

图 6.14 – 标注项目创建向导

在我们开始练习之前，让我们看看我们可以使用这个服务执行哪些类型的标注任务。如图中所示，我们可以使用图像和文本数据作为数据源。在屏幕上的**图像**和**文本**选项之间切换，我们有以下选择：

+   **图像分类多类别**：给每张图像附加一个标签。

+   **图像分类多标签**：给每张图像附加多个标签。

+   **目标检测（边界框）**：在图像上的一个对象周围绘制一个或多个框。

+   **实例分割（多边形）**：在图像上的一个对象周围绘制复杂的多边形。

+   **文本分类多类别**：给一段文本附加一个标签。

+   **文本分类多标签**：给一段文本附加一个或多个标签。

如我们所见，在图像数据方面有很多有用的选项。我们可以通过使用**边界框**或**多边形**来突出显示和标记图像中的非常具体的部分。使用多边形，您在技术上能够进行完整的**图像分割**，但使用这个工具将每个像素分配到类别中相当困难。

然而，对于文本数据，有一些限制。我们没有选择在一段文本中标注特定单词或短语，正如我们在上一节中讨论的那样。在撰写本文时，唯一的选择是对文本块进行单标签或多标签。

因此，我们将使用图像。为了不让第一次使用这个工具变得过于复杂，我们将从给图像数据集中的图像附加单个标签开始。在接下来的步骤中，我们将创建一个图像数据集和一个相应的标注项目：

1.  在通过向导之前，让我们寻找一个合适的图像数据集来使用。我们将使用**STL-10数据集**([https://cs.stanford.edu/~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/))。这个数据集包含大量的小型96x96图像，可以分成10个类别（**飞机**、**鸟**、**汽车**、**猫**、**鹿**、**狗**、**马**、**猴子**、**船**和**卡车**）。这10个类别将成为我们的标签。由于原始页面只提供给我们二进制格式的图像，我们需要找到不同的来源。在**Kaggle**上，您经常可以找到这些类型的数据集以不同的格式准备。

1.  访问[https://www.kaggle.com/jessicali9530/stl10](https://www.kaggle.com/jessicali9530/stl10)并下载`test_images`，这是一个包含8,000个`png`格式文件的集合。通常，我们会使用`unlabeled_images`集合，但由于有10万个，我们暂时将其保留。

1.  如果您还没有这样做，请将本章的文件下载到您的设备上，并在`chapter06`文件夹下创建一个名为`images`的新文件夹。

1.  将所有 8,000 张图片提取到`images`文件夹中。之后，打开`03_reg_unlabeled_data.ipynb`文件。在这个文件中，你会发现我们迄今为止用来连接到我们的工作空间和数据存储的代码。请将`datastore_name`替换为你 ML 工作空间中给出的名称。第一个单元格的最后一段代码如下：

    [PRE0]

`upload_directory`方法将一次性上传`images`文件夹中的所有文件到你在目标中定义的数据存储位置，并创建一个名为`file_ds`的文件数据集对象。一旦上传完成，我们可以使用以下代码注册我们的新数据集：

[PRE1]

如果你导航到 Azure Machine Learning Studio 中的**数据集**选项卡，你会看到我们新注册的数据集。在**探索**选项卡下，你会看到图像的子集，包括图像元数据和图像预览。

1.  现在我们已经注册了我们的数据集，我们可以设置我们的标注项目。回到向导，如图 6.14 所示，将项目名称输入为`STL10_Labeling`，并选择**多类图像分类**作为类型。点击**下一步**。

1.  在下一屏，Microsoft 将提供从**Azure Marketplace**雇佣劳动力来完成你的标注工作的选项。这将是一个有用的工具，因为你很快就会了解到这项任务有多么繁琐。现在，我们不需要额外的帮助。点击**下一步**。

1.  现在，我们可以选择要工作的数据集。选择我们新创建的数据集，命名为`STL10_unlabeled`，然后点击**下一步**。

1.  我们将看到一个名为**增量刷新**的选项。此功能如果底层数据集中添加了新图像，则每天更新一次项目。我们目前不打算这样做，所以保持原样并点击**下一步**。

1.  下一屏要求我们定义我们的标签。标签为`飞机`、`鸟`、`汽车`、`猫`、`鹿`、`狗`、`马`、`猴子`、`船`和`卡车`。然后，点击**下一步**。

1.  倒数第二屏允许我们输入**标注说明**。如果我们不是单独在这个项目上工作，或者我们已经订购了劳动力来完成这项工作，这些说明将很有用。在这里，我们可以给他们下指令。对我们来说，因为我们单独工作，这就不必要了。所以，点击**下一步**。

1.  最后，我们有选择使用**ML 辅助标注**的选项。如果我们不激活此选项，我们就必须自己标注所有 8,000 张图片，而不需要帮助。请注意，激活此选项需要运行 GPU 计算集群，每次辅助 ML 模型重新训练时都会运行几分钟。我们将选择**使用默认**选项，这将为我们创建一个合适的集群。点击**创建项目**。这将带我们回到概览页。当集群创建完成后，点击项目的名称以获取概览页面。

你将看到一个类似于以下仪表板的界面：

![图 6.15 – 标注项目的仪表板](img/B17928_06_15.jpg)

图 6.15 – 标注项目的仪表板

仪表板分为以下视图：

+   **进度**：这显示了正在标注的资产数量。在我们的案例中，我们正在处理8,000张图像。它还显示了每个资产的状态（**完成**、**跳过**、**需要审查**和**不完整**）。

+   **标签类别分布**：此视图将显示一个条形图，显示哪些标签被使用以及分类图像的次数。

+   **标注员性能**：此视图显示每个标注员处理了多少资产。在我们的案例中，只会显示我们的名字。

+   **任务队列**：此视图显示管道中的任务。目前，我们需要在下一个训练阶段或下一次检查之前手动标注150张图像。

+   **机器学习辅助标注实验**：此视图显示了辅助机器学习模型的运行或已运行的训练实验。

如果你切换到**数据**标签页，你会看到一些图像预览，你可以查看已经标注的图像。当你在一个团队中工作时，这很有帮助，因为一些人正在标注图像，而另一些人正在审查他们的标注工作。

最后，如果你查看`DefLabelNC6`。

以下截图显示了此集群的概览页面：

![图6.16 – 标注集群仪表板](img/B17928_06_16.jpg)

图6.16 – 标注集群仪表板

如你所见，用于节点的机器具有6个核心，56 GB的RAM和一个Tesla K80 GPU。在Azure上创建任何类型的计算实例时，请始终检查定价页面（[https://azure.microsoft.com/en-us/pricing/details/virtual-machines/ml-server-ubuntu/](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/ml-server-ubuntu/))。如该页面所示，我们使用的节点称为**NC6**，每小时大约花费3美元。集群节点显示集群是**空闲**的，因此没有费用。稍后，你可以检查**运行**标签页以了解训练运行的持续时间，从而了解定价影响。目前，一个合理的估计是，我们将在我们的标注项目中需要2到4小时的机器学习辅助支持。

因此，在我们开始标注图像之前，让我们了解机器学习辅助标注能做什么。当你切换回我们的标注项目仪表板时，你会在**任务队列**下看到三个选项，如下所示：

+   **手动**：这表示在任何时候都必须处理的资产，没有任何支持。

+   **集群**：这表示在已经标注的资产上使用了聚类模型。当你处理这些资产时，它们将以模型认为属于同一类的图像组的形式显示给你。

+   **预标注**：这表示在已经标注的资产上训练了分类模型的资产。在这种情况下，它为未标注的资产预测了标签。当你处理这些图像时，你会看到建议的标签并需要检查模型是否正确。

现在，让我们开始标记。当您点击**标记数据**时，您将看到以下视图：

![图 6.17 – 标记任务视图](img/B17928_06_17.jpg)

图 6.17 – 标记任务视图

从这个视图，您可以看到中间的资产。通过顶部的控件，您可以**放大**并更改图像的**亮度**和**对比度**属性。如果您对这些选项不确定，您可以暂时选择**跳过**。在右侧，您可以选择适当的标签。如果您对您的选择满意，您可以点击**提交**。

对几幅图像进行标记，以便掌握情况。之后，查看右上角的控件。在这里，我们可以更改同时显示给我们多少资产（1、4、6 或 9）。我建议同时显示 6 个资产。此外，为了标记图片，您可以多选它们，并使用键盘上的数字 1 到 9（如前一张截图所示）来更快地进行标记。

现在，为了看到机器学习辅助标记的触发，您需要手动标记大约 400 到 600 张图像。您可以决定这是否是您时间的良好利用，但这是一个很好的练习，因为它让您了解了这项任务的繁琐程度。

最终，训练将被触发，如下面的截图所示：

![图 6.18 – 触发的标记训练运行](img/B17928_06_18.jpg)

图 6.18 – 触发的标记训练运行

在第一次标记训练触发之前，我不得不手动标记 616 个资产。正如我们所见，该工具显示了在标记过程中遇到的标签类别的分布。与其他任何训练一样，这创建了一个带有运行的实验。您可以在 ML 工作区的“实验”下找到这些，如下面的截图所示：

![图 6.19 – 使用机器学习辅助标记的实验运行](img/B17928_06_19.jpg)

图 6.19 – 使用机器学习辅助标记的实验运行

在这一点上，只需继续标记资产。最终，您将看到由页面顶部的**聚类任务**定义的聚类图像（参见*图 6.20*）：

![图 6.20 – 显示聚类图像的数据标记](img/B17928_06_20.jpg)

图 6.20 – 显示聚类图像的数据标记

或者，您将看到预先标记的图像，这些图像由页面顶部的**预标记任务**定义（参见*图 6.21*）：

![图 6.21 – 显示预标记图像的数据标记](img/B17928_06_21.jpg)

图 6.21 – 显示预标记图像的数据标记

通过以上内容，您已经了解了如何利用机器学习建模来标记您的资产，以及 Azure 机器学习工作室如何使这一过程更加简便。正如您现在应该理解的那样，这是一项耗时的工作，但如果您希望在未来的机器学习训练中取得更好的结果，这项工作必须完成。

# 摘要

在本章中，我们探讨了如何通过特征工程来准备我们的特征，以及如何通过标记来准备我们的标签。

在第一部分，我们了解到特征工程包括创建新的和缺失的特征、转换现有特征、从高维数据集中提取特征，以及使用方法来选择对机器学习训练最有预测性的特征。

在第二部分，我们了解到标记是必不可少的且繁琐的。因此，像Azure Machine Learning数据标记这样的工具可以是一种祝福，可以减轻这项耗时的工作。

本章的关键要点是，创建、转换和选择预测性特征对机器学习模型的质量影响最大。在机器学习管道中的其他任何步骤都不会对其结果产生更大的影响。

要完成高质量的特征工程，你必须对领域有深入了解（或者你必须认识一个有这种知识的人），并且清楚地掌握所选机器学习算法的内部工作方式。这包括理解数学理论、算法期望作为输入的数据结构，以及当你拟合模型时自动应用的特征工程方法。

在下一章中，我们将看到特征工程的实际应用。我们将探讨如何对文本数据进行特征提取，以用于自然语言处理。
