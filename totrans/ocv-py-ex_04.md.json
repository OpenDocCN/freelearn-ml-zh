["```py\nimport cv2\nimport numpy as np\n\nface_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')\n\ncap = cv2.VideoCapture(0)\nscaling_factor = 0.5\n\nwhile True:\n    ret, frame = cap.read()\n    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n    for (x,y,w,h) in face_rects:\n        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n\n    cv2.imshow('Face Detector', frame)\n\n    c = cv2.waitKey(1)\n    if c == 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nface_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')\n\nface_mask = cv2.imread('mask_hannibal.png')\nh_mask, w_mask = face_mask.shape[:2]\n\nif face_cascade.empty():\n    raise IOError('Unable to load the face cascade classifier xml file')\n\ncap = cv2.VideoCapture(0)\nscaling_factor = 0.5\n\nwhile True:\n    ret, frame = cap.read()\n    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n    for (x,y,w,h) in face_rects:\n        if h > 0 and w > 0:\n            # Adjust the height and weight parameters depending on the sizes and the locations. You need to play around with these to make sure you get it right.\n            h, w = int(1.4*h), int(1.0*w)\n            y -= 0.1*h\n\n            # Extract the region of interest from the image\n            frame_roi = frame[y:y+h, x:x+w]\n            face_mask_small = cv2.resize(face_mask, (w, h), interpolation=cv2.INTER_AREA)\n\n            # Convert color image to grayscale and threshold it\n            gray_mask = cv2.cvtColor(face_mask_small, cv2.COLOR_BGR2GRAY)\n            ret, mask = cv2.threshold(gray_mask, 180, 255, cv2.THRESH_BINARY_INV)\n\n            # Create an inverse mask\n            mask_inv = cv2.bitwise_not(mask)\n\n            # Use the mask to extract the face mask region of interest\n            masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask)\n\n            # Use the inverse mask to get the remaining part of the image\n            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n\n            # add the two images to get the final output\n            frame[y:y+h, x:x+w] = cv2.add(masked_face, masked_frame)\n\n    cv2.imshow('Face Detector', frame)\n\n    c = cv2.waitKey(1)\n    if c == 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nframe_roi = frame[y:y+h, x:x+w]\n```", "```py\nimport cv2\nimport numpy as np\n\nface_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')\neye_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_eye.xml')\nif face_cascade.empty():\n  raise IOError('Unable to load the face cascade classifier xml file')\n\nif eye_cascade.empty():\n  raise IOError('Unable to load the eye cascade classifier xml file')\n\ncap = cv2.VideoCapture(0)\nds_factor = 0.5\n\nwhile True:\n    ret, frame = cap.read()\n    frame = cv2.resize(frame, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_AREA)\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n    for (x,y,w,h) in faces:\n        roi_gray = gray[y:y+h, x:x+w]\n        roi_color = frame[y:y+h, x:x+w]\n        eyes = eye_cascade.detectMultiScale(roi_gray)\n        for (x_eye,y_eye,w_eye,h_eye) in eyes:\n            center = (int(x_eye + 0.5*w_eye), int(y_eye + 0.5*h_eye))\n            radius = int(0.3 * (w_eye + h_eye))\n            color = (0, 255, 0)\n            thickness = 3\n            cv2.circle(roi_color, center, radius, color, thickness)\n\n    cv2.imshow('Eye Detector', frame)\n\n    c = cv2.waitKey(1)\n    if c == 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nface_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')\neye_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_eye.xml')\n\nif face_cascade.empty():\n  raise IOError('Unable to load the face cascade classifier xml file')\n\nif eye_cascade.empty():\n  raise IOError('Unable to load the eye cascade classifier xml file')\n\nimg = cv2.imread('input.jpg')\nsunglasses_img = cv2.imread('sunglasses.jpg')\n\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\ncenters = []\nfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\n\nfor (x,y,w,h) in faces:\n    roi_gray = gray[y:y+h, x:x+w]\n    roi_color = img[y:y+h, x:x+w]\n    eyes = eye_cascade.detectMultiScale(roi_gray)\n    for (x_eye,y_eye,w_eye,h_eye) in eyes:\n        centers.append((x + int(x_eye + 0.5*w_eye), y + int(y_eye + 0.5*h_eye)))\n\nif len(centers) > 0:\n    # Overlay sunglasses; the factor 2.12 is customizable depending on the size of the face\n    sunglasses_width = 2.12 * abs(centers[1][0] - centers[0][0])\n    overlay_img = np.ones(img.shape, np.uint8) * 255\n    h, w = sunglasses_img.shape[:2]\n    scaling_factor = sunglasses_width / w\n    overlay_sunglasses = cv2.resize(sunglasses_img, None, fx=scaling_factor,\n            fy=scaling_factor, interpolation=cv2.INTER_AREA)\n\n    x = centers[0][0] if centers[0][0] < centers[1][0] else centers[1][0]\n\n    # customizable X and Y locations; depends on the size of the face\n    x -= 0.26*overlay_sunglasses.shape[1]\n    y += 0.85*overlay_sunglasses.shape[0]\n\n    h, w = overlay_sunglasses.shape[:2]\n    overlay_img[y:y+h, x:x+w] = overlay_sunglasses\n\n    # Create mask\n    gray_sunglasses = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n    ret, mask = cv2.threshold(gray_sunglasses, 110, 255, cv2.THRESH_BINARY)\n    mask_inv = cv2.bitwise_not(mask)\n    temp = cv2.bitwise_and(img, img, mask=mask)\n    temp2 = cv2.bitwise_and(overlay_img, overlay_img, mask=mask_inv)\n    final_img = cv2.add(temp, temp2)\n\n    cv2.imshow('Eye Detector', img)\n    cv2.imshow('Sunglasses', final_img)\n    cv2.waitKey()\n    cv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nleft_ear_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_mcs_leftear.xml')\nright_ear_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_mcs_rightear.xml')\n\nif left_ear_cascade.empty():\n  raise IOError('Unable to load the left ear cascade classifier xml file')\n\nif right_ear_cascade.empty():\n  raise IOError('Unable to load the right ear cascade classifier xml file')\n\nimg = cv2.imread('input.jpg')\n\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nleft_ear = left_ear_cascade.detectMultiScale(gray, 1.3, 5)\nright_ear = right_ear_cascade.detectMultiScale(gray, 1.3, 5)\n\nfor (x,y,w,h) in left_ear:\n    cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 3)\n\nfor (x,y,w,h) in right_ear:\n    cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 3)\n\ncv2.imshow('Ear Detector', img)\ncv2.waitKey()\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nmouth_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_mcs_mouth.xml')\n\nif mouth_cascade.empty():\n  raise IOError('Unable to load the mouth cascade classifier xml file')\n\ncap = cv2.VideoCapture(0)\nds_factor = 0.5\n\nwhile True:\n    ret, frame = cap.read()\n    frame = cv2.resize(frame, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_AREA)\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    mouth_rects = mouth_cascade.detectMultiScale(gray, 1.7, 11)\n    for (x,y,w,h) in mouth_rects:\n        y = int(y - 0.15*h)\n        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n        break\n\n    cv2.imshow('Mouth Detector', frame)\n\n    c = cv2.waitKey(1)\n    if c == 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nmouth_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_mcs_mouth.xml')\n\nmoustache_mask = cv2.imread('../images/moustache.png')\nh_mask, w_mask = moustache_mask.shape[:2]\n\nif mouth_cascade.empty():\n  raise IOError('Unable to load the mouth cascade classifier xml file')\n\ncap = cv2.VideoCapture(0)\nscaling_factor = 0.5\n\nwhile True:\n    ret, frame = cap.read()\n    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    mouth_rects = mouth_cascade.detectMultiScale(gray, 1.3, 5)\n    if len(mouth_rects) > 0:\n        (x,y,w,h) = mouth_rects[0]\n        h, w = int(0.6*h), int(1.2*w)\n        x -= 0.05*w\n        y -= 0.55*h\n        frame_roi = frame[y:y+h, x:x+w]\n        moustache_mask_small = cv2.resize(moustache_mask, (w, h), interpolation=cv2.INTER_AREA)\n\n        gray_mask = cv2.cvtColor(moustache_mask_small, cv2.COLOR_BGR2GRAY)\n        ret, mask = cv2.threshold(gray_mask, 50, 255, cv2.THRESH_BINARY_INV)\n        mask_inv = cv2.bitwise_not(mask)\n        masked_mouth = cv2.bitwise_and(moustache_mask_small, moustache_mask_small, mask=mask)\n        masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n        frame[y:y+h, x:x+w] = cv2.add(masked_mouth, masked_frame)\n\n    cv2.imshow('Moustache', frame)\n\n    c = cv2.waitKey(1)\n    if c == 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nnose_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_mcs_nose.xml')\n\nif nose_cascade.empty():\n  raise IOError('Unable to load the nose cascade classifier xml file')\n\ncap = cv2.VideoCapture(0)\nds_factor = 0.5\n\nwhile True:\n    ret, frame = cap.read()\n    frame = cv2.resize(frame, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_AREA)\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    nose_rects = nose_cascade.detectMultiScale(gray, 1.3, 5)\n    for (x,y,w,h) in nose_rects:\n        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n        break\n\n    cv2.imshow('Nose Detector', frame)\n\n    c = cv2.waitKey(1)\n    if c == 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nimport math\n\nimport cv2\nimport numpy as np\n\nimg = cv2.imread('input.jpg')\nscaling_factor = 0.7\n\nimg = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\ncv2.imshow('Input', img)\ngray = cv2.cvtColor(~img, cv2.COLOR_BGR2GRAY)\n\nret, thresh_gray = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\ncontours, hierarchy = cv2.findContours(thresh_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n\nfor contour in contours:\n    area = cv2.contourArea(contour)\n    rect = cv2.boundingRect(contour)\n    x, y, width, height = rect\n    radius = 0.25 * (width + height)\n\n    area_condition = (100 <= area <= 200)\n    symmetry_condition = (abs(1 - float(width)/float(height)) <= 0.2)\n    fill_condition = (abs(1 - (area / (math.pi * math.pow(radius, 2.0)))) <= 0.3)\n\n    if area_condition and symmetry_condition and fill_condition:\n        cv2.circle(img, (int(x + radius), int(y + radius)), int(1.3*radius), (0,180,0), -1)\n\ncv2.imshow('Pupil Detector', img)\n\nc = cv2.waitKey()\ncv2.destroyAllWindows()\n```", "```py\ngray = cv2.cvtColor(~img, cv2.COLOR_BGR2GRAY)\n```"]