<html><head></head><body>
		<div id="_idContainer098">
			<h1 id="_idParaDest-88"><em class="italic"><a id="_idTextAnchor088"/>Chapter 6</em>: Classifying Trees with Multiclass Logistic Regression</h1>
			<p>Multiclass logistic regression is the <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) algorithm used to classify events, entities, and behaviors into a fixed number of categories. It can be used across different industries and business scenarios when it's necessary to predict the classification of an entity into multiple groups. A typical classification use case is represented by the desire to segment the customer base of a company according to their profitability and preferences in order to target the right customers with the most effective marketing campaigns.</p>
			<p>This kind of technique is an extension of the binary logistic regression that allows us to overcome the limits of two possible labels and opens the applicability to other contexts where we can find multiple categories to identify.</p>
			<p>In this chapter, we'll see all the stages necessary to implement, evaluate, and test a multiclass logistic regression model leveraging BigQuery ML.</p>
			<p>In this chapter, we'll go through the following topics:</p>
			<ul>
				<li>Introducing the business scenario</li>
				<li>Discovering multiclass logistic regression</li>
				<li>Exploring and understanding the dataset</li>
				<li>Training the multiclass logistic regression model</li>
				<li>Evaluating the multiclass logistic regression model</li>
				<li>Using the multiclass logistic regression model</li>
				<li>Drawing business conclusions</li>
			</ul>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor089"/>Technical requirements</h1>
			<p>This chapter requires you to access a web browser and to have the possibility to leverage the following:</p>
			<ul>
				<li>A GCP account to access the Google Cloud Console</li>
				<li>A GCP project to host the BigQuery datasets</li>
			</ul>
			<p>Now that we're ready with the technical requirements, let's dive into the analysis and development of our BigQuery ML logistic regression model.</p>
			<p>Check out the following video to see the Code in Action: <a href="https://bit.ly/3h4w7xG">https://bit.ly/3h4w7xG</a></p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor090"/>Introducing the business scenario</h1>
			<p>For this business<a id="_idIndexMarker323"/> scenario, we can imagine being a ML expert in New York City. Among all the activities that the city should perform, a census of the trees and verifying their condition is one of the most time-consuming.</p>
			<p>The trees are spread across different areas of New York City and the process of collecting information about each tree is performed manually by volunteers or New York City employees. After the collection of the information, the data is stored in a database and made publicly available through a BigQuery public dataset for further analyses (<a href="https://console.cloud.google.com/marketplace/details/city-of-new-york/nyc-tree-census">https://console.cloud.google.com/marketplace/details/city-of-new-york/nyc-tree-census</a>).</p>
			<p>In the following figure, we can see a picture from Central Park, one of the areas with more trees in New York City:</p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B16722_06_001.jpg" alt="Figure 6.1 – Trees in Central Park, New York City&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1 – Trees in Central Park, New York City</p>
			<p>In order to support<a id="_idIndexMarker324"/> and accelerate the job of the people in charge of classifying the trees and assessing their condition, one of your managers may ask you to build a ML model.</p>
			<p>The goal of the ML model would be to automatically classify the trees into different species according to their characteristics, such as their position, size, and health status.</p>
			<p>For this use case, we can focus our attention only on the five species of trees most present in the city.</p>
			<p>Now that we've briefly explained and understood the business scenario, let's take a look at the ML technique that we can use to classify objects or events into multiple classes.</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor091"/>Discovering multiclass logistic regression</h1>
			<p>In this section, we'll<a id="_idIndexMarker325"/> learn the basics of multiclass logistic regression and when this technique can be applied.</p>
			<p><strong class="bold">Multiclass logistic regression</strong> is a classification technique that can be used to categorize events, objects, customers, or other entities into multiple classes. Different from binary logistic regression, this ML algorithm can be used to classify output values into more than two discrete classes.</p>
			<p>In order to predict one of the multiple labels, this ML algorithm calculates the probability of each outcome and selects the label with the highest probability.</p>
			<p>Being a regression algorithm, the prediction of the label is based on a set of independent variables called features that are used to predict the dependent variable, called a label.</p>
			<p>This ML technique can be used to answer business questions, such as the following:</p>
			<ul>
				<li>Is the comment of my customer <em class="italic">neutral</em>, <em class="italic">positive</em>, or <em class="italic">negative</em>?</li>
				<li>Does my customer belong to the <em class="italic">Gold</em>, <em class="italic">Silver</em>, or <em class="italic">Bronze</em> level?</li>
				<li>Is the probability of churn for a specific customer <em class="italic">high</em>, <em class="italic">medium</em>, or <em class="italic">low</em>?</li>
				<li>Does the image recognition algorithm identify a <em class="italic">cat</em>, a <em class="italic">dog</em>, a <em class="italic">mouse</em>, or a <em class="italic">cow</em>?</li>
			</ul>
			<p>In our business scenario, since there are a limited number of species of trees and we'll focus only on five species, we can leverage multiclass logistic regression. Specifically, we're interested in classifying a tree into one of the five species according to its characteristics in terms of size, position, and health status.</p>
			<p>Training a multiclass logistic regression model means trying to find the values of the coefficients that can be used in the equation between the input variables, called features, and the output variable, called a label.</p>
			<p>After the <a id="_idIndexMarker326"/>training, we'll leverage a <strong class="bold">Confusion Matrix</strong> to evaluate the performances of our multiclass logistic regression model. In multiclass logistic <a id="_idIndexMarker327"/>regression, multiple rows and multiple columns compose the confusion matrix.</p>
			<p>To evaluate the <a id="_idIndexMarker328"/>performances of our ML model, we'll again use the <strong class="bold">Area Under the Curve</strong> (<strong class="bold">AUC</strong>) <strong class="bold">Receiver Operating Characteristic</strong> (<strong class="bold">ROC</strong>).</p>
			<p>Now that we've learned the basics of multiclass logistic regression, it's time to take a look at the<a id="_idIndexMarker329"/> dataset that we'll use to build our ML model.</p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor092"/>Exploring and understanding the dataset</h1>
			<p>As we've <a id="_idIndexMarker330"/>already done in the previous use cases, before diving into the<a id="_idIndexMarker331"/> development of the ML model, it's necessary to analyze the data that can be used to solve our use case.</p>
			<p>We'll start with the analysis of the table structure to have a clear understanding of the data that can be used for our business scenario. </p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor093"/>Understanding the data</h2>
			<p>In this section, we'll look <a id="_idIndexMarker332"/>take a look at the data to understand its structure and how it can be used to build our ML model.</p>
			<p>To start exploring the data, we need to do the following:</p>
			<ol>
				<li value="1">Log in to the Google Cloud Console and access the <strong class="bold">BigQuery</strong> user interface from the navigation menu.</li>
				<li>Create a new dataset under the project that we created in <a href="B16722_02_Final_ASB_ePub.xhtml#_idTextAnchor039"><em class="italic">Chapter 2</em></a>, <em class="italic">Setting Up Your GCP and BigQuery Environment</em>. For this use case, we'll create the dataset <strong class="source-inline">06_nyc_trees</strong> with the default options.</li>
				<li>Open the GCP project <strong class="bold">bigquery-public-data</strong>, which hosts all the BigQuery public datasets, and browse the datasets until we find <strong class="source-inline">new_york_trees</strong>.</li>
				<li>As we can see in the following screenshot, the BigQuery public dataset contains multiple tables to host the data collected every 10 years: <div id="_idContainer090" class="IMG---Figure"><img src="image/B16722_06_002.jpg" alt="Figure 6.2 – The New York City Trees Public dataset contains the census &#13;&#10;of the trees collected every 10 years&#13;&#10;"/></div><p class="figure-caption">Figure 6.2 – The New York City Trees Public dataset contains the census of the trees collected every 10 years</p></li>
				<li>We'll use<a id="_idIndexMarker333"/> the most recent one: <strong class="source-inline">tree_census_2015</strong>. This table contains all the information about the trees planted in New York City and registered in 2015.</li>
				<li>Let's click on the table name <strong class="source-inline">tree_census_2015</strong> in the BigQuery navigation menu to access the schema of the table:<div id="_idContainer091" class="IMG---Figure"><img src="image/B16722_06_003.jpg" alt="Figure 6.3 – The structure of the tree_census_2015 table lists all the fields &#13;&#10;that can be used as labels and features&#13;&#10;"/></div><p class="figure-caption">Figure 6.3 – The structure of the tree_census_2015 table lists all the fields that can be used as labels and features</p></li>
				<li>Each field is<a id="_idIndexMarker334"/> well described in the <strong class="bold">Description </strong>column.<p>The table contains the <strong class="bold">spc_latin</strong> column represented by a <strong class="bold">STRING</strong> that indicates the scientific name of the species of each tree. This field will be the label of our ML model.</p><p>In order to classify each tree, we can leverage the information present in other fields. Some columns describe the size of the tree. For example, <strong class="bold">tree_dbh</strong> measures the diameter of the tree and <strong class="bold">stump_diam</strong> represents the diameter of the stump. We can also leverage information about the <strong class="bold">health</strong> of the tree. We can imagine that some species are more robust than others and more suited to the New York City weather.</p><p>Other fields are more related to the position of the tree in the city and to the context where it lives. In order to train our ML model, we can use the zip area where the tree resides: <strong class="bold">zip_city</strong>. Some other examples are the <strong class="bold">boroname </strong>column, which contains the name of the borough where the tree was planted, and <strong class="bold">nta_name</strong>, which represents the neighborhood the tree falls into.</p><p>We can also assume that some species are more intrusive than others – the <strong class="bold">sidewalk</strong> field indicates whether a sidewalk adjacent to the tree was damaged, cracked, or lifted by the roots of the tree.</p><p>From a schema perspective, this table includes a lot of useful information that can be used to develop our classification model. Let's proceed with our analysis, diving more into the data.</p></li>
			</ol>
			<p>In this section, we've<a id="_idIndexMarker335"/> analyzed the metadata of the <strong class="bold">tree_census_2015 </strong>table, now it's time to look at the actual data and start querying it.</p>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor094"/>Checking the data quality</h2>
			<p>As we've already<a id="_idIndexMarker336"/> understood from the previous use cases, the quality of data is fundamental to build effective ML models. In this section, we'll apply some data quality checks in order to identify the right records to use:</p>
			<ol>
				<li value="1">First of all, we'll check if the table <strong class="source-inline">tree_census_2015</strong> contains records with <strong class="source-inline">spc_latin</strong> equals to NULL. This is fundamental because the field <strong class="source-inline">spc_latin</strong> will be used as label of our machine learning model:<p class="source-code">SELECT  COUNT(*) total</p><p class="source-code">FROM    `bigquery-public-data.new_york_trees.tree_census_2015`</p><p class="source-code">WHERE</p><p class="source-code">         spc_latin is NULL;</p><p>The code block will COUNT all the records in the table `<strong class="source-inline">bigquery-public-data.new_york_trees.tree_census_2015</strong>` where the field <strong class="source-inline">spc_latin</strong> is empty.</p><p>In the following screenshot, you can see the results of the query where we got a value higher than thirty one thousand:</p><div id="_idContainer092" class="IMG---Figure"><img src="image/B16722_06_004.jpg" alt="Figure 6.4 – The result of the query shows that some rows contain empty labels&#13;&#10;"/></div><p class="figure-caption">Figure 6.4 – The result of the query shows that some rows contain empty labels</p><p>For this reason, <a id="_idIndexMarker337"/>in the next queries we'll exclude the records where the field <strong class="source-inline">spc_latin</strong> is empty.</p></li>
				<li>Focusing only on the rows where the field <strong class="source-inline">spc_latin</strong> is <strong class="source-inline">NOT NULL</strong>, we can check the presence of empty values on all the other fields that are potential features of our ML model:<p class="source-code">SELECT  COUNT(*)</p><p class="source-code">FROM    `bigquery-public-data.new_york_trees.tree_census_2015`</p><p class="source-code">WHERE</p><p class="source-code">         spc_latin is NOT NULL</p><p class="source-code">         AND (</p><p class="source-code">            zip_city is NULL OR</p><p class="source-code">            tree_dbh is NULL OR</p><p class="source-code">            boroname is NULL OR</p><p class="source-code">            nta_name is NULL OR</p><p class="source-code">            nta_name is NULL OR</p><p class="source-code">            health is NULL OR</p><p class="source-code">            sidewalk is NULL) ;</p><p>Also, in this case, the result of the query is not zero. In fact, we can easily identify three records that present <strong class="source-inline">NULL</strong> values in the <strong class="source-inline">health</strong> and <strong class="source-inline">sidewalk</strong> fields.</p><p>We'll filter these records in the following stages of the ML model life cycle.</p></li>
			</ol>
			<p>Now that we've applied some quality checks to our dataset and we've understood which records<a id="_idIndexMarker338"/> should be filtered, let's focus on segmenting our dataset to focus the creation of our BigQuery ML model only on the five most frequent species of trees.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor095"/>Segmenting the dataset</h2>
			<p>In this <a id="_idIndexMarker339"/>section, we'll prepare the tables that we'll use to train, evaluate, and test our ML model.</p>
			<p>For our purposes, we'll extract the five most frequent species that appear in the dataset. After that, we'll create the BigQuery tables that will be used to train, evaluate, and test our ML model:</p>
			<ol>
				<li value="1">First of all, we'll identify only the five most frequent species in the <strong class="source-inline">tree_census_2015</strong> table with the following query:<p class="source-code">SELECT   spc_latin,</p><p class="source-code">         COUNT(*) total</p><p class="source-code">FROM    `bigquery-public-data.new_york_trees.tree_census_2015`</p><p class="source-code">WHERE</p><p class="source-code">         spc_latin is NOT NULL</p><p class="source-code">         AND zip_city is NOT NULL</p><p class="source-code">         AND tree_dbh is NOT NULL</p><p class="source-code">         AND boroname is NOT NULL</p><p class="source-code">         AND nta_name is NOT NULL</p><p class="source-code">         AND health is NOT NULL</p><p class="source-code">         AND sidewalk is NOT NULL</p><p class="source-code">GROUP BY</p><p class="source-code">         spc_latin</p><p class="source-code">ORDER BY</p><p class="source-code">         total desc</p><p class="source-code">LIMIT 5;</p><p>The SQL<a id="_idIndexMarker340"/> statement counts the number of occurrences of each species in the <strong class="source-inline">tree_census_2015</strong> table using the <strong class="source-inline">GROUP BY spc_latin</strong> clause and the <strong class="source-inline">COUNT(*)</strong> operator.</p><p>The query orders the records in descending mode according to the value of the field <strong class="source-inline">total</strong> field, which contains the result of the <strong class="source-inline">COUNT</strong>. Finally, the result set of the query is limited to the first five records of the result set with the <strong class="source-inline">LIMIT 5</strong> clause at the end of the query.</p><p>The SQL statement is based on the BigQuery public table <strong class="source-inline">tree_census_2015</strong> properly filtered with the data quality checks that we identified in the previous, <em class="italic">Checking the data quality </em>section.</p><p>In the following screenshot, we can see the results of the query and the most common species of tree in our dataset:</p><div id="_idContainer093" class="IMG---Figure"><img src="image/B16722_06_005.jpg" alt="Figure 6.5 – The result of the query shows the most common trees in New York City&#13;&#10;"/></div><p class="figure-caption">Figure 6.5 – The result of the query shows the most common trees in New York City</p><p>From the <a id="_idIndexMarker341"/>query result, we can easily read the Latin name of the trees ordered from the most to the least common.</p></li>
				<li>Since we'll use this subset of five species in the next SQL queries, we can add a <strong class="source-inline">CREATE TABLE</strong> statement at the beginning of our <strong class="source-inline">SELECT</strong> statement in order to materialize the results in the <strong class="source-inline">top5_species</strong> table:<p class="source-code">CREATE OR REPLACE TABLE `06_nyc_trees.top5_species` AS</p><p class="source-code">      SELECT   spc_latin,</p><p class="source-code">         COUNT(*) total</p><p class="source-code">      FROM    `bigquery-public-data.new_york_trees.tree_census_2015`</p><p class="source-code">      WHERE</p><p class="source-code">               spc_latin is NOT NULL</p><p class="source-code">               AND zip_city is NOT NULL</p><p class="source-code">               AND tree_dbh is NOT NULL</p><p class="source-code">               AND boroname is NOT NULL</p><p class="source-code">               AND nta_name is NOT NULL</p><p class="source-code">               AND health is NOT NULL</p><p class="source-code">               AND sidewalk is NOT NULL</p><p class="source-code">      GROUP BY</p><p class="source-code">               spc_latin</p><p class="source-code">      ORDER BY</p><p class="source-code">               total desc</p><p class="source-code">      LIMIT 5;</p><p>By executing<a id="_idIndexMarker342"/> the query, we'll get the creation of a new table that contains only two fields and five records. <strong class="source-inline">spc_latin</strong> represents the species of the tree, while <strong class="source-inline">total</strong> counts the number of occurrences of each species in the original dataset.</p></li>
				<li>Now, we can leverage the <strong class="source-inline">top5_species</strong> table to filter only the species on which we're focusing and create the training table:<p class="source-code">CREATE OR REPLACE TABLE `06_nyc_trees.training_table` AS </p><p class="source-code">SELECT  *</p><p class="source-code">FROM    `bigquery-public-data.new_york_trees.tree_census_2015`</p><p class="source-code">WHERE</p><p class="source-code">         zip_city is NOT NULL</p><p class="source-code">         AND tree_dbh is NOT NULL</p><p class="source-code">         AND boroname is NOT NULL</p><p class="source-code">         AND nta_name is NOT NULL</p><p class="source-code">         AND health is NOT NULL</p><p class="source-code">         AND sidewalk is NOT NULL</p><p class="source-code">         AND spc_latin in </p><p class="source-code">         (SELECT spc_latin from  `06_nyc_trees.top5_species`)</p><p class="source-code">         AND MOD(tree_id,11)&lt;=8;</p><p>The query creates a table with all the columns available in the original dataset through the <strong class="source-inline">SELECT *</strong> statement. It applies all the filters necessary to get not empty values for the <strong class="source-inline">spc_latin</strong> label and all the other potential features.</p><p>With the usage of the <strong class="source-inline">IN</strong> clause, <strong class="source-inline">training_table</strong> will contain only the records related to the most five frequent species in the dataset.</p><p>The last line <a id="_idIndexMarker343"/>of the query, with the clause <strong class="source-inline">MOD(tree_id,11)&lt;=8</strong>, allows us to only pick up 80% of the records from the entire set of records. <strong class="source-inline">MOD</strong> stands for modulo and returns the remainder of the division of <strong class="source-inline">tree_id</strong> by 11.</p></li>
				<li>With a similar approach, we can create the table that will be used for the evaluation of our ML model:<p class="source-code">CREATE OR REPLACE TABLE `06_nyc_trees.evaluation_table` AS </p><p class="source-code">SELECT  *</p><p class="source-code">FROM    `bigquery-public-data.new_york_trees.tree_census_2015`</p><p class="source-code">WHERE</p><p class="source-code">         zip_city is NOT NULL</p><p class="source-code">         AND tree_dbh is NOT NULL</p><p class="source-code">         AND boroname is NOT NULL</p><p class="source-code">         AND nta_name is NOT NULL</p><p class="source-code">         AND health is NOT NULL</p><p class="source-code">         AND sidewalk is NOT NULL</p><p class="source-code">         AND spc_latin in </p><p class="source-code">         (SELECT spc_latin from `06_nyc_trees.top5_species`) </p><p class="source-code">         AND MOD(tree_id,11)=9;</p><p>For the <strong class="source-inline">evaluation_table</strong>, we will pick up only 10% of the records with the filter <strong class="source-inline">MOD(tree_id,11)=9</strong>.</p></li>
				<li>Finally, we'll execute the following SQL statement in order to create the table that will be <a id="_idIndexMarker344"/>used to apply our multiclass classification model:<p class="source-code">CREATE OR REPLACE TABLE `06_nyc_trees.classification_table` AS </p><p class="source-code">SELECT  *</p><p class="source-code">FROM    `bigquery-public-data.new_york_trees.tree_census_2015`</p><p class="source-code">WHERE</p><p class="source-code">         zip_city is NOT NULL</p><p class="source-code">         AND tree_dbh is NOT NULL</p><p class="source-code">         AND boroname is NOT NULL</p><p class="source-code">         AND nta_name is NOT NULL</p><p class="source-code">         AND health is NOT NULL</p><p class="source-code">         AND sidewalk is NOT NULL</p><p class="source-code">         AND spc_latin in </p><p class="source-code">         (SELECT spc_latin from `06_nyc_trees.top5_species`) </p><p class="source-code">         AND MOD(tree_id,11)=10;</p><p><strong class="source-inline">classification_table</strong> is very similar to the previous segments of the dataset, but thanks to the <strong class="source-inline">MOD</strong> function will contain the remaining 10% percent of the dataset.</p></li>
			</ol>
			<p>In this section, we've analyzed the <strong class="source-inline">new_york_trees</strong> dataset, which contains information about the trees in New York City. We applied some data quality checks to exclude empty values. Then, we segmented the data, focusing on the five most common species that appear in the table. Now that we've completed the preparatory steps, it's time to move <a id="_idIndexMarker345"/>on and start the training of our BigQuery ML model.</p>
			<h1 id="_idParaDest-96"><a id="_idTextAnchor096"/>Training the multiclass logistic regression model</h1>
			<p>Now that we've clearly<a id="_idIndexMarker346"/> understood the structure of the data and we've segmented it into multiple tables to support the different stages of the ML model life cycle, let's focus on the training of our multiclass logistic regression model. We'll execute the SQL queries to create our multiclass logistic regression models: </p>
			<ol>
				<li value="1">Let's start creating the first version of our ML model:<p class="source-code">CREATE OR REPLACE MODEL `06_nyc_trees.classification_model_version_1`</p><p class="source-code">OPTIONS</p><p class="source-code">  ( model_type='LOGISTIC_REG',</p><p class="source-code">    auto_class_weights=TRUE</p><p class="source-code">  ) AS</p><p class="source-code">SELECT</p><p class="source-code">  zip_city,</p><p class="source-code">  tree_dbh,</p><p class="source-code">  spc_latin as label</p><p class="source-code">FROM</p><p class="source-code">  `06_nyc_trees.training_table` ;</p><p>The query used to create the <strong class="source-inline">classification_model_version_1</strong> model is based only on two features: the zip area and the diameter of the tree.</p><p>The SQL statement starts with the keywords <strong class="source-inline">CREATE OR REPLACE MODEL</strong>, which are used to run the training, followed by the <strong class="source-inline">OPTIONS</strong> clause. Among the options, we can specify the model type equals <strong class="source-inline">LOGISTIC_REG</strong> and <strong class="source-inline">auto_class_weights=TRUE</strong>. This option can be particularly useful when we're in front of unbalanced training datasets with some labels that appear more frequently than others. In our case, the occurrences of the most common species are more than double the occurrences of the fifth one. For this reason, we've applied <a id="_idIndexMarker347"/>this kind of adjustment.</p><p class="callout-heading">Important note</p><p class="callout">The BigQuery ML syntax does not distinguish between binary logistic regression and multiclass logistic regression. In both cases, the BigQuery ML model type is <strong class="source-inline">LOGISTIC_REG</strong>. The difference is caused by the number of distinct values that appear in the column label of the training dataset. If the label presents only two values, BigQuery ML will train a binary logistic regression. If the label contains more than two distinct values, the model will be trained as a multiclass logistic regression.</p></li>
				<li>After the execution of the training, we can access the information of our first ML model by clicking on <strong class="bold">classification_model_version_1</strong> from the navigation menu and selecting the <strong class="bold">Evaluation</strong> tab.<p>The following screenshot presents the key performance indicators of our first attempt:</p><div id="_idContainer094" class="IMG---Figure"><img src="image/B16722_06_006.jpg" alt="Figure 6.6 – The Evaluation tab shows the performance metrics related &#13;&#10;to the selected BigQuery ML model&#13;&#10;"/></div><p class="figure-caption">Figure 6.6 – The Evaluation tab shows the performance metrics related to the selected BigQuery ML model</p><p>To have an<a id="_idIndexMarker348"/> idea of the effectiveness of our ML model, we can look at the <strong class="bold">ROC AUC</strong> value of <strong class="bold">0.7383</strong>.</p><p>By scrolling down with the mouse in the <strong class="bold">Evaluation</strong> tab, we can take a look at the confusion matrix of our multiclass logistic regression model.</p><p>In the following figure, the confusion matrix shows the percentage of predicted and actual labels on the training dataset:</p><div id="_idContainer095" class="IMG---Figure"><img src="image/B16722_06_007.jpg" alt="Figure 6.7 – The Evaluation tab shows the confusion matrix related to the selected BigQuery ML model&#13;&#10;"/></div><p class="figure-caption">Figure 6.7 – The Evaluation tab shows the confusion matrix related to the selected BigQuery ML model</p><p>Looking at<a id="_idIndexMarker349"/> the confusion matrix, we can visually notice that our ML model works quite well for some species but performs very poorly for others. For example, when the actual label is <strong class="bold">Quercus palustris</strong>, in 40% of the cases the ML model suggests a different species: <strong class="bold">Platanus x acerifolia</strong>.</p></li>
				<li>Let's try to improve our model by adding new features with the following BigQuery ML SQL statement:<p class="source-code">CREATE OR REPLACE MODEL `06_nyc_trees.classification_model_version_2`</p><p class="source-code">OPTIONS</p><p class="source-code">  ( model_type='LOGISTIC_REG',</p><p class="source-code">    auto_class_weights=TRUE</p><p class="source-code">  ) AS</p><p class="source-code">SELECT</p><p class="source-code">  zip_city,</p><p class="source-code">  tree_dbh,</p><p class="source-code">  boroname,</p><p class="source-code">  nta_name,</p><p class="source-code">  spc_latin as label</p><p class="source-code">FROM</p><p class="source-code">  `06_nyc_trees.training_table` ;</p><p>In comparison<a id="_idIndexMarker350"/> with the first attempt, we've included additional features in the training of our model. In fact, we've added the name of the borough contained in the <strong class="source-inline">boroname</strong> field and <strong class="source-inline">nta_name</strong> to the list of features.</p><p>After the execution of the SQL statement, let's access the <strong class="bold">Evaluation</strong> tab of the new model to see if we're improving its performance. Taking a look at the <strong class="bold">ROC AUC</strong> value of <strong class="bold">0.7667</strong>, we can see a slight increase in the performance of our model.</p></li>
				<li>As a last attempt, we'll enrich our ML model with additional features. The new fields are related to the health of the tree and to the size of the roots:<p class="source-code">CREATE OR REPLACE MODEL `06_nyc_trees.classification_model_version_3`</p><p class="source-code">OPTIONS</p><p class="source-code">  ( model_type='LOGISTIC_REG',</p><p class="source-code">    auto_class_weights=TRUE</p><p class="source-code">  ) AS</p><p class="source-code">SELECT</p><p class="source-code">  zip_city,</p><p class="source-code">  tree_dbh,</p><p class="source-code">  boroname,</p><p class="source-code">  nta_name,</p><p class="source-code">  health,</p><p class="source-code">  sidewalk,</p><p class="source-code">  spc_latin as label</p><p class="source-code">FROM</p><p class="source-code">  `06_nyc_trees.training_table`;</p><p>Compared to <a id="_idIndexMarker351"/>the previous ML model, in <strong class="source-inline">classification_model_version_3</strong> we've included the fields <strong class="source-inline">health</strong>, which describes the health status of our tree, and <strong class="source-inline">sidewalk</strong>, used to specify whether the roots of the tree are damaging the adjacent pavements.</p></li>
				<li>Looking at the performance of our last ML model in the <strong class="bold">Evaluation</strong> tab of the BigQuery user interface, we can notice that we've achieved another increase in terms of <strong class="bold">ROC AUC</strong> value: <strong class="source-inline">0.7696</strong>.<p class="callout-heading">Tip</p><p class="callout">Although the usage of more features can increase the ROC AUC value of a BigQuery ML classification model, we need to take into consideration the balance between the performance improvement and the resources spent to achieve it. In real-life scenarios, especially when the volumes are really high, we need to select only the features that can have the highest impact on the performance of our BigQuery ML model.</p></li>
			</ol>
			<p>In this section, we've created different ML models trying to use different features in our dataset. In the next sections, we'll use the model with the highest ROC AUC value: <strong class="source-inline">classification_model_version_3</strong>.</p>
			<p>Next, let's<a id="_idIndexMarker352"/> evaluate the performance of our ML model leveraging the evaluation dataset.</p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor097"/>Evaluating the multiclass logistic regression model</h1>
			<p>In this section, we'll <a id="_idIndexMarker353"/>execute queries to check the performance of the multiclass logistic regression model.</p>
			<p>For the evaluation phase of our BigQuery ML model, we'll use the <strong class="source-inline">ML.EVALUATE</strong> function and the <strong class="source-inline">evaluation_table</strong> table, expressly created to host the evaluation records.</p>
			<p>As we can see, the evaluation is performed on the same fields that were used during the training phase of the model but are extracted from the <strong class="source-inline">evaluation_table</strong> table that was created completely disjoint from the training dataset.</p>
			<p>The external <strong class="source-inline">SELECT</strong> statement extracts the <strong class="source-inline">roc_auc</strong> value returned by the <strong class="source-inline">ML.EVALUATE</strong> function. It also provides a meaningful description of the quality of the model that starts from <strong class="source-inline">'POOR'</strong> and goes up to the <strong class="source-inline">'EXCELLENT'</strong> grade, passing through some intermediate stages such as <strong class="source-inline">'NEEDS IMPROVEMENTS'</strong> and <strong class="source-inline">'GOOD'</strong>.</p>
			<p>Let's execute the following query to extract the key performance indicator of our ML model:</p>
			<p class="source-code">SELECT</p>
			<p class="source-code">  roc_auc,</p>
			<p class="source-code">  CASE</p>
			<p class="source-code">    WHEN roc_auc &gt; .9 THEN 'EXCELLENT'</p>
			<p class="source-code">    WHEN roc_auc &gt; .8 THEN 'VERY GOOD'</p>
			<p class="source-code">    WHEN roc_auc &gt; .7 THEN 'GOOD'</p>
			<p class="source-code">    WHEN roc_auc &gt; .6 THEN 'FINE'</p>
			<p class="source-code">    WHEN roc_auc &gt; .5 THEN 'NEEDS IMPROVEMENTS'</p>
			<p class="source-code">  ELSE</p>
			<p class="source-code">  'POOR'</p>
			<p class="source-code">END</p>
			<p class="source-code">  AS model_quality</p>
			<p class="source-code">FROM </p>
			<p class="source-code">  ML.EVALUATE(MODEL `06_nyc_trees.classification_model_version_3`,</p>
			<p class="source-code">    (</p>
			<p class="source-code">    SELECT</p>
			<p class="source-code">       zip_city,</p>
			<p class="source-code">       tree_dbh,</p>
			<p class="source-code">       boroname,</p>
			<p class="source-code">       nta_name,</p>
			<p class="source-code">       health,</p>
			<p class="source-code">       sidewalk,</p>
			<p class="source-code">       spc_latin as label</p>
			<p class="source-code">     FROM `06_nyc_trees.evaluation_table`));</p>
			<p>From the<a id="_idIndexMarker354"/> following screenshot, we can see the results of the query – the <strong class="bold">roc_auc</strong> value achieved more than 0.77. The result of our BigQuery ML model can be considered <strong class="bold">GOOD</strong>:</p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/B16722_06_008.jpg" alt="Figure 6.8 – The query extracts the ROC AUC value of the BigQuery ML model &#13;&#10;and a short description of the model quality&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.8 – The query extracts the ROC AUC value of the BigQuery ML model and a short description of the model quality</p>
			<p>Now that we've verified that the ML model maintains its performance on the disjoint evaluation <a id="_idIndexMarker355"/>dataset too, we can start using it to classify the trees in our <strong class="source-inline">classification_table</strong> table.</p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor098"/>Using the multiclass logistic regression model</h1>
			<p>In this<a id="_idIndexMarker356"/> section, we'll test our ML model and analyze the results.</p>
			<p>To use our BigQuery ML model, we'll use the <strong class="source-inline">ML.PREDICT</strong> function and the <strong class="source-inline">classification_table</strong> table, which hosts the records, to test our model, as seen in the following code block:</p>
			<p class="source-code">SELECT</p>
			<p class="source-code">  tree_id,</p>
			<p class="source-code">  actual_label,</p>
			<p class="source-code">  predicted_label_probs,</p>
			<p class="source-code">  predicted_label</p>
			<p class="source-code">FROM</p>
			<p class="source-code">  ML.PREDICT (MODEL `06_nyc_trees.classification_model_version_3`,</p>
			<p class="source-code">    (</p>
			<p class="source-code">    SELECT</p>
			<p class="source-code">       tree_id,</p>
			<p class="source-code">       zip_city,</p>
			<p class="source-code">       tree_dbh,</p>
			<p class="source-code">       boroname,</p>
			<p class="source-code">       nta_name,</p>
			<p class="source-code">       health,</p>
			<p class="source-code">       sidewalk,</p>
			<p class="source-code">       spc_latin as actual_label</p>
			<p class="source-code">    FROM</p>
			<p class="source-code">      `06_nyc_trees.classification_table`</p>
			<p class="source-code">     ));</p>
			<p>The query statement is composed of the <strong class="source-inline">SELECT</strong> keyword, which extracts the <strong class="source-inline">tree_id</strong>, the actual value of the species in the field, <strong class="source-inline">actual_label</strong>, and the predicted fields <strong class="source-inline">predicted_label_probs</strong> and <strong class="source-inline">predicted_label</strong>. </p>
			<p>The <strong class="source-inline">ML.PREDICT</strong> function is applied to the <strong class="source-inline">SELECT</strong> statement, which extracts the features and the actual species from the <strong class="source-inline">classification_table</strong>. The <strong class="source-inline">actual_label</strong> field<a id="_idIndexMarker357"/> will be used only as a benchmark for our predictions and not during the prediction phase.</p>
			<p>In the following screenshot, we can see the structure of a record gotten from the execution of the previous query:</p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B16722_06_009.jpg" alt="Figure 6.9 – A record of the output dataset generated by the classification model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.9 – A record of the output dataset generated by the classification model</p>
			<p>In this case, <strong class="bold">tree_id</strong> is equal to <strong class="bold">857</strong>, the tree is a <strong class="bold">Quercus palustris</strong>, and is correctly classified by the BigQuery ML model because <strong class="bold">predicted_label</strong> is exactly the same. <strong class="bold">predicted_label_probs</strong> indicates confidence of 45% for the highest classification label. All the other possible species are characterized by lower probabilities.</p>
			<p>Now that we've <a id="_idIndexMarker358"/>applied our model, let's formulate some final considerations about our classification use case.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor099"/>Drawing business conclusions</h1>
			<p>Using the<a id="_idIndexMarker359"/> results that we got from the previous section, <em class="italic">Using the multiclass logistic regression model</em>, we'll draw some conclusions about the effectiveness of our ML model.</p>
			<p>Enriching the previous query with a parent <strong class="source-inline">SELECT COUNT</strong> statement, we can count how many predictions are right compared to the total number of records.</p>
			<p>Let's execute the following query to calculate how often our BigQuery ML model is able to correctly classify the trees in the <strong class="source-inline">classification_table</strong> table:</p>
			<p class="source-code">SELECT COUNT(*)</p>
			<p class="source-code">FROM (</p>
			<p class="source-code">      SELECT</p>
			<p class="source-code">        tree_id,</p>
			<p class="source-code">        actual_label,</p>
			<p class="source-code">        predicted_label_probs,</p>
			<p class="source-code">        predicted_label</p>
			<p class="source-code">      FROM</p>
			<p class="source-code">        ML.PREDICT (MODEL `06_nyc_trees.classification_model_version_3`,</p>
			<p class="source-code">          (</p>
			<p class="source-code">          SELECT</p>
			<p class="source-code">             tree_id,</p>
			<p class="source-code">             zip_city,</p>
			<p class="source-code">             tree_dbh,</p>
			<p class="source-code">             boroname,</p>
			<p class="source-code">             nta_name,</p>
			<p class="source-code">             health,</p>
			<p class="source-code">             sidewalk,</p>
			<p class="source-code">             spc_latin as actual_label</p>
			<p class="source-code">          FROM</p>
			<p class="source-code">            `06_nyc_trees.classification_table`</p>
			<p class="source-code">           )</p>
			<p class="source-code">        )</p>
			<p class="source-code">)</p>
			<p class="source-code">WHERE</p>
			<p class="source-code">      actual_label = predicted_label;</p>
			<p>The result of <a id="_idIndexMarker360"/>the <strong class="source-inline">SELECT COUNT</strong> query returns a value of 13,323 predictions with a correctly predicted label.</p>
			<p>Considering that the total size of the <strong class="source-inline">classification_table</strong> table is 27,182, we can declare that in 49% of cases, our ML model is able to predict the right species of tree based on its characteristics and its position.</p>
			<p>This could seem like a bad result, but we need to consider that multiclass logistic regression is more complex than a binary one because there are multiple options that could deceive the results of our model.</p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor100"/>Summary</h1>
			<p>In this chapter, we've built our first multiclass classification model. After a brief introduction to the use case, we discovered what multiclass logistic regression is and how it can be used to classify events, behaviors, and objects according to their features into more than two categories.</p>
			<p>Before diving into the development of the ML model, we analyzed the schema of the dataset related to the trees in New York City and applied some data quality checks necessary to build an effective ML model.</p>
			<p>During the training stage, we trained three different ML models using different features to gradually improve the performance of the BigQuery ML model.</p>
			<p>Then, we chose the third ML model and we evaluated it against the evaluation dataset. In this phase, we noticed that the ML model was able to maintain its performance on new records also and was ready to pass to the next phase.</p>
			<p>In the last step, we used our ML model to classify the trees in New York City into five different categories and leveraged their characteristics, such as size, health status, and position in the city.</p>
			<p>We also calculated that our classification model is able to classify the right species of tree in 49% of cases.</p>
			<p>In the next chapter, we'll introduce unsupervised ML and the K-Means clustering technique.</p>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor101"/>Further resources</h1>
			<ul>
				<li><strong class="bold">NYC Trees Census Public Dataset</strong>: <a href="https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tree-census">https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tree-census</a></li>
				<li><strong class="bold">BigQuery ML Create Model</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create</a></li>
				<li><strong class="bold">BigQuery ML Evaluate Model</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate</a></li>
				<li><strong class="bold">BigQuery ML Predict</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict</a></li>
				<li><strong class="bold">BigQuery ML Multiclass Logistic Example</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction">https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction</a></li>
			</ul>
		</div>
	</body></html>