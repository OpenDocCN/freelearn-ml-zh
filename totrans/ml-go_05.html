<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Classification</h1>
                </header>
            
            <article>
                
<p class="mce-root">When many people think about machine learning or artificial intelligence, they probably first think about machine learning to solve classification problems. These are problems where we want to train a model to predict one of a finite number of distinct categories. For example, we may want to predict if a financial transaction is fraudulent or not fraudulent, or we may want to predict whether an image contains a hot dog, airplane, cat, and so on, or none of those things.</p>
<p>The categories that we try to predict could number from two to many hundreds or thousands. In addition, we could be making our predictions based on only a few attributes or many attributes. All of the scenarios arising from these combinations lead to a host of models with a corresponding host of assumptions, advantages, and disadvantages.</p>
<p>We will cover some of these models in this chapter and later in the book, but there are many that we will skip for brevity. However, as with any of the problems that we tackle in this book, simplicity and integrity should be a major concern as we choose a type of model for our use cases. There are highly sophisticated and complicated models that solve certain problems very well, but these models are not necessary for many use cases. Applying simple and interpretable classification models should continue to be one of our goals.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding classification model jargon</h1>
                </header>
            
            <article>
                
<p>As with regression, classification problems come with their own set of jargon. There is some overlap with terms used in regression, but there are also some new terms specific to classification:</p>
<ul>
<li><strong>Categories</strong>, <strong>labels</strong>, or <strong>classes</strong>: These terms are used interchangeably to represent the various distinct choices for our prediction. For example, we could have a fraud class and a not fraud class, or we could have sitting, standing, running, and walking categories.</li>
<li><strong>Binary classification</strong>: This type of classification is one with only two categories or classes, such as yes/no or fraud/not fraud.</li>
<li><strong>Multi-class classification</strong>: This type of classification is one with more than two classes, such as a classification trying to assign one of hot dog, airplane, cat, and so on, to an image.</li>
<li><strong>Labeled data</strong> or <strong>annotated data</strong>: Real-world observations or records that have been paired with their corresponding class. For example, if we are predicting fraud via transaction time, this data would include a bunch of measured transaction times along with a corresponding label indicating whether they were fraudulent or not.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logistic regression</h1>
                </header>
            
            <article>
                
<p>The first classification model that we are going to explore is called <strong>logistic regression</strong>. As you can tell from the name, this method is based on a regression, which we discussed in more detail in the previous chapter. However, this particular regression uses a function that is particularly well suited to classification problems.</p>
<p>This is also a simple and interpretable model, which makes it a great first choice when solving classification problems. There are a variety of existing Go packages that implement logistic regression for you, including <kbd>github.com/xlvector/hector</kbd>, <kbd>github.com/cdipaolo/goml</kbd>, and <kbd>github.com/sjwhitworth/golearn</kbd>. However, in our example, we will implement logistic regression from scratch, so that you can both form a full understanding of what goes into training a model and understand the simplicity of logistic regression. Further, in some cases, you may want to utilize a from-scratch implementation as illustrated in the following section to avoid extra dependencies in your code base.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of logistic regression</h1>
                </header>
            
            <article>
                
<p>Let's say that we have two classes, <em>A</em> and <em>B,</em> that we are trying to predict. Let's also suppose that we are trying to predict <em>A</em> or <em>B</em> based on a variable <em>x</em>. Classes <em>A</em> and <em>B</em> might look something like this when plotted against <em>x</em>:</p>
<div class="CDPAlignCenter CDPAlign"><img height="201" width="269" class="image-border" src="assets/e025a17c-35a1-48f6-b99f-6acac1b654c5.png"/></div>
<p>Although we could draw a line modeling this behavior, this is clearly not linear behavior and does not fit the assumptions of linear regression. The shape of the data is more of a step from one class to another class as a function of <em>x</em>. What we really need is some function that goes to and stays at <em>A</em> for low values of <em>x,</em> and goes to and stays at <em>B</em> for higher values of <em>x.</em></p>
<p>Well, we are in luck! There is such a function. The function is called the <strong>logistic function</strong>, and it gives logistic regression its name. It has the following form:</p>
<div style="padding-left: 120px" class="mce-root CDPAlignLeft CDPAlign"><img height="36" width="102" src="assets/00e1e244-3cb7-445a-aff7-af8b3d72f391.jpg"/></div>
<p class="mce-root">Implemented in Go, this looks as follows:</p>
<pre>// logistic implements the logistic function, which
// is used in logistic regression.
func logistic(x float64) float64 {
        return 1 / (1 + math.Exp(-x))
}</pre>
<p class="mce-root">Let's plot the logistic function with <kbd>gonum.org/v1/plot</kbd> to see what it looks like:</p>
<pre>// Create a new plot.
p, err := plot.New()
if err != nil {
    log.Fatal(err)
}
p.Title.Text = "Logistic Function"
p.X.Label.Text = "x"
p.Y.Label.Text = "f(x)"

// Create the plotter function.
logisticPlotter := plotter.NewFunction(func(x float64) float64 { return logistic(x) })
logisticPlotter.Color = color.RGBA{B: 255, A: 255}

// Add the plotter function to the plot.
p.Add(logisticPlotter)

// Set the axis ranges.  Unlike other data sets,
// functions don't set the axis ranges automatically
// since functions don't necessarily have a
// finite range of x and y values.
p.X.Min = -10
p.X.Max = 10
p.Y.Min = -0.1
p.Y.Max = 1.1

// Save the plot to a PNG file.
if err := p.Save(4*vg.Inch, 4*vg.Inch, "logistic.png"); err != nil {
    log.Fatal(err)
}</pre>
<p>Compiling and running this plotting code creates the following graph:</p>
<div class="CDPAlignCenter CDPAlign"><img height="261" width="261" class="image-border" src="assets/aaac3a8d-b90c-421d-83d9-0505f845a417.png"/></div>
<p>As you can see, this function has the step-like behavior that we are looking for to model the steps between classes <em>A</em> and <em>B</em> (imagining that <em>A</em> corresponds to <em>0.0</em> and <em>B</em> corresponds to <em>1.0</em>).</p>
<p>Not only that, the logistic function has some really convenient properties that we can take advantage of while doing classification. To see this, let's take a step back and consider how we might model <em>p</em>, the probability of one of the classes <em>A</em> or <em>B</em>, occurring. One way to do this would be to model the <em>log</em> of the <strong>odds</strong> <strong>ratio</strong>, <em>log(</em> <em>p / (1 - p) )</em> linearly, where the odds ratio tells us how the presence or absence of class <em>A</em> has an effect on the presence or absence of class <em>B</em>. The reason for using this strange <em>log</em> (referred to as <strong>logit</strong>) will make sense shortly, but for now, let's just assume that we want to model this linearly as follows:</p>
<div style="padding-left: 150px" class="mce-root"><img height="72" width="196" src="assets/12a20c36-d29d-4179-9462-60aae6534f4a.jpg"/></div>
<p>Now, if we take the exponential of this odds ratio, we get the following:</p>
<div style="padding-left: 180px" class="mce-root"><img height="62" width="116" src="assets/8832e141-9447-4913-a625-f96e1ea61cd0.jpg"/></div>
<p>This is what we get when we simplify the preceding equation:</p>
<div style="padding-left: 180px" class="mce-root"><img height="63" width="136" src="assets/08fee5a9-69d0-458a-8c82-14fd462b2640.jpg"/></div>
<p>If you look at the right-hand side of this equation, you will see that our logistic function has popped up. This equation then gives some formal underpinning to our assumption that the logistic function would be good for modeling the separation between two classes: <em>A</em> and <em>B</em>. If, for instance, we take <em>p</em> to be the probability of observing <em>B</em> and we fit the logistic function to our data, we could get a model that predicts the probability of <em>B</em> as a function of <em>x</em> (and thus one minus the probability of predicting <em>A</em>). This is pictured in the following plot, in which we have formalized our original plot of <em>A</em> and <em>B</em> and overlaid the logistic function that models probability:</p>
<div class="CDPAlignCenter CDPAlign"><img height="213" width="284" class="image-border" src="assets/ed4153cb-34b8-4084-8435-3bbb0606c82a.png"/></div>
<p>Thus, creating a logistic regression model involves finding the logistic function that maximizes the number of observations that we can predict with the logistic function.</p>
<div class="packt_infobox">Note that one advantage of logistic regression is that it remains simple and interpretable. However, the coefficients <em>m</em> and <em>b</em> in the model do not have the same interpretation as in linear regression. The coefficient <em>m</em> (or coefficients <em>m<sub>1</sub></em>, <em>m<sub>2</sub></em>, and so on, if we have multiple independent variables) has an exponential relationship with the odds ratio. Thus, if you have a coefficient <em>m</em> of <em>0.5</em>, this is related to the odds ratio via <em>exp(0.5 x)</em>. If we had two coefficients <em>exp(0.5 x<sub>1</sub> + 1.0 x<sub>2</sub>)</em>, we could conclude that the odds of the modeled class for <em>x<sub>1</sub></em> is <em>exp(0.5) = <span>1.65</span></em> when <span>compared to <em>exp(1.0) = 2.72</em> for <em>x<sub>2</sub></em>. In other words, we cannot directly compare the coefficients. We need to keep them in the context of the exponential.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logistic regression assumptions and pitfalls</h1>
                </header>
            
            <article>
                
<p>Remember the long list of assumptions that applied to linear regression? Well, logistic regression is not limited by those same assumptions. However, there are still some important assumptions that we make when using logistic regression:</p>
<ul>
<li><strong>Linear relationship with the log odds</strong>: As we discussed earlier, underlying logistic regression is an assumption that we can model the log of the odds ratio with a line.</li>
<li><strong>Encoding of dependent variable</strong>: When we set up our model earlier, we assumed that we were trying to predict the probability of <em>B</em>, where a probability of 1.0 corresponded to a positive <em>B</em> example. Thus, we need to prepare our data with this type of encoding. This will be demonstrated in the following example.</li>
<li><strong>Independence of observations</strong>: Each of the examples of <em>x</em> in our data must be independent. That is, we have to avoid things like including the same example several times.</li>
</ul>
<p>Also, some common pitfalls of logistic regression to keep in mind are as follows:</p>
<ul>
<li>Logistic regression can be more sensitive to outliers than other classification techniques. Keep this in mind and try to profile your data accordingly.</li>
<li>As logistic regression relies on an exponential function that never truly goes to <em>0.0</em> or <em>1.0</em> (except at +/- infinity), you may have very small degradations in your evaluation metric.</li>
</ul>
<p>All being said, logistic regression is a fairly robust method that remains interpretable. It is a flexible model that should be at the top of your list when considering how you might solve classification problems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logistic regression example</h1>
                </header>
            
            <article>
                
<p>The dataset that we are going to use to illustrate logistic regression is data corresponding to loans issues by LendingClub. LendingClub publishes this data quarterly and it can be found in its original form at <a href="https://www.lendingclub.com/info/download-data.action">https://www.lendingclub.com/info/download-data.action</a>. We will work with a trimmed down and simplified version of this data (available in the code bundles that come with this book) including only two columns, <kbd>FICO.Range</kbd> (indicating a loan applicants credit score as given by Fair, Isaac and Company, or FICO) and <kbd>Interest.Rate</kbd> (indicating the interest rate of a loan granted to the loan applicant). The data looks like this:</p>
<pre><strong>$ head loan_data.csv 
FICO.Range,Interest.Rate
735-739,8.90%
715-719,12.12%
690-694,21.98%
695-699,9.99%
695-699,11.71%
670-674,15.31%
720-724,7.90%
705-709,17.14%
685-689,14.33%</strong></pre>
<p>Our goal for this exercise will be to create a logistic regression model that will tell us, for a given credit score, if we can get a loan at or below a certain interest rate. For example, let's say that we are interested in getting an interest rate below 12%. Our model would tell us that we could (yes, or class one) or could not (no, class two) get a loan, given a certain credit score.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cleaning and profiling the data</h1>
                </header>
            
            <article>
                
<p>Looking at the preceding sample of the loan data, we can see that it is not exactly in the form that we need for our classification. Specifically, we need to do the following:</p>
<ol>
<li>Remove non-numerical characters from the interest rate and FICO score columns.</li>
<li>Encode our interest rate into two classes for a given interest rate threshold. We will use <em>1.0</em> to represent our first class (yes, we can get the loan with that interest rate) and <em>0.0</em> to represent our second class (no, we cannot get the loan with that interest rate).</li>
<li>Select a single value for the FICO credit score. We are given a range of credit scores, but we need a single value. The average, minimum, or maximum score are natural choices and, in our example, we will use the minimum value (to be conservative).</li>
<li>In this case, we are going to <strong>standardize</strong> our FICO scores (by subtracting the minimum score value from each score and then dividing by the score range). This will spread out our score values between <em>0.0</em> and <em>1.0</em>. We need to have a justification for this as it is making our data less readable. However, there is a good justification. We will be training our logistic regression using a gradient descent method that can perform better with normalized data. In fact, when running the same example with non-normalized data, there are convergence issues.</li>
</ol>
<p class="mce-root">Let's write a Go program that will clean our data for a given interest rate (12% for our example). We will read in the data from a given file, parse the values using <kbd>encoding/csv</kbd>, and put the cleaned data in an output file called <kbd>clean_loan_data.csv</kbd>. During the cleaning of the data we will make use of the following minimum and maximum values, that we define as constants:</p>
<pre>const (<br/>    scoreMax = 830.0<br/>    scoreMin = 640.0<br/>)</pre>
<p class="mce-root">Then, the actual cleaning functionality is shown in the following code:</p>
<pre>// Open the loan dataset file.<br/>f, err := os.Open("loan_data.csv")<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer f.Close()<br/><br/>// Create a new CSV reader reading from the opened file.<br/>reader := csv.NewReader(f)<br/>reader.FieldsPerRecord = 2<br/><br/>// Read in all of the CSV records
rawCSVData, err := reader.ReadAll()
if err != nil {
    log.Fatal(err)
}

// Create the output file.
f, err = os.Create("clean_loan_data.csv")
if err != nil {
    log.Fatal(err)
}
defer f.Close()

// Create a CSV writer.
w := csv.NewWriter(f)
<br/>// Sequentially move the rows writing out the parsed values.
for idx, record := range rawCSVData {

    // Skip the header row.
    if idx == 0 {<br/> <br/><br/>        // Write the header to the output file.
        if err := w.Write(record); err != nil {
            log.Fatal(err)
        }
        continue
    }

    // Initialize a slice to hold our parsed values.
    outRecord := make([]string, 2)

    // Parse and standardize the FICO score.<br/>    score, err := strconv.ParseFloat(strings.Split(record[0], "-")[0], 64)<br/>    if err != nil {<br/>        log.Fatal(err)<br/>    }<br/><br/>    outRecord[0] = strconv.FormatFloat((score-scoreMin)/(scoreMax-scoreMin), 'f', 4, 64)

    // Parse the Interest rate class.
    rate, err := strconv.ParseFloat(strings.TrimSuffix(record[1], "%"), 64)
    if err != nil {
        log.Fatal(err)
    }

    if rate &lt;= 12.0 {
        outRecord[1] = "1.0"

        // Write the record to the output file.
        if err := w.Write(outRecord); err != nil {
            log.Fatal(err)
        }
        continue
    }

    outRecord[1] = "0.0"

    // Write the record to the output file.
    if err := w.Write(outRecord); err != nil {
        log.Fatal(err)
    }
}<br/><br/>// Write any buffered data to the underlying writer (standard output).<br/>w.Flush()<br/><br/>if err := w.Error(); err != nil {<br/>    log.Fatal(err)<br/>}</pre>
<p class="mce-root">Compiling this and running it confirms our desired output:</p>
<pre><strong>$ go build
$ ./example3 
$ head clean_loan_data.csv 
FICO_score,class</strong><br/><strong>0.5000,1.0</strong><br/><strong>0.3947,0.0</strong><br/><strong>0.2632,0.0</strong><br/><strong>0.2895,1.0</strong><br/><strong>0.2895,1.0</strong><br/><strong>0.1579,0.0</strong><br/><strong>0.4211,1.0</strong><br/><strong>0.3421,0.0</strong><br/><strong>0.2368,0.0</strong></pre>
<p class="mce-root">Great! We have our data in the desired format. Now, let's gain a little more intuition about our data by creating histograms for the FICO score and interest rate data and calculating summary statistics. We will utilize <kbd>github.com/kniren/gota/dataframe</kbd> to calculate summary statistics and <kbd>gonum.org/v1/plot</kbd> to generate histograms:</p>
<pre>// Open the CSV file.
loanDataFile, err := os.Open("clean_loan_data.csv")
if err != nil {
    log.Fatal(err)
}
defer loanDataFile.Close()

// Create a dataframe from the CSV file.
loanDF := dataframe.ReadCSV(loanDataFile)

// Use the Describe method to calculate summary statistics
// for all of the columns in one shot.
loanSummary := loanDF.Describe()

// Output the summary statistics to stdout.
fmt.Println(loanSummary)

// Create a histogram for each of the columns in the dataset.
for _, colName := range loanDF.Names() {

    // Create a plotter.Values value and fill it with the
    // values from the respective column of the dataframe.
    plotVals := make(plotter.Values, loanDF.Nrow())
    for i, floatVal := range loanDF.Col(colName).Float() {
        plotVals[i] = floatVal
    }

    // Make a plot and set its title.
    p, err := plot.New()
    if err != nil {
        log.Fatal(err)
    }
    p.Title.Text = fmt.Sprintf("Histogram of a %s", colName)

    // Create a histogram of our values.
    h, err := plotter.NewHist(plotVals, 16)
    if err != nil {
        log.Fatal(err)
    }

    // Normalize the histogram.
    h.Normalize(1)

    // Add the histogram to the plot.
    p.Add(h)

    // Save the plot to a PNG file.
    if err := p.Save(4*vg.Inch, 4*vg.Inch, colName+"_hist.png"); err != nil {
        log.Fatal(err)
    }
}</pre>
<p>Running this results in the following output:</p>
<pre><strong>$ go build
$ ./myprogram
[7x3] DataFrame</strong><br/><br/><strong>    column FICO_score class </strong><br/><strong> 0: mean 0.346782 0.396800</strong><br/><strong> 1: stddev 0.184383 0.489332</strong><br/><strong> 2: min 0.000000 0.000000</strong><br/><strong> 3: 25% 0.210500 0.000000</strong><br/><strong> 4: 50% 0.315800 0.000000</strong><br/><strong> 5: 75% 0.447400 1.000000</strong><br/><strong> 6: max 1.000000 1.000000</strong><br/><strong>    &lt;string&gt; &lt;float&gt; &lt;float&gt;     

$ ls *.png
class_hist.png FICO_score_hist.png</strong></pre>
<p>We can see that the average credit score is pretty high at <em>706.1</em> and there is a pretty good balance between the classes one and zero, as indicated by a mean near <em>0.5</em>. However, there appears to be more class zero examples (which corresponds to not receiving a loan with an interest rate of 12% or lower). Also, the <kbd>*.png</kbd> histogram graphs look as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img height="247" width="492" class="image-border" src="assets/5ef325e8-a76e-45db-a77f-2b727bbd76cb.png"/></div>
<p>This confirms our suspicions about the balance between the classes and shows us that the FICO scores are skewed a bit to lower values.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our training and test sets</h1>
                </header>
            
            <article>
                
<p>Similar to our examples in the previous chapter, we need to split our data into a training and test set. We will once again use <kbd>github.com/kniren/gota/dataframe</kbd> to do this:</p>
<pre>// Open the clean loan dataset file.<br/>f, err := os.Open("clean_loan_data.csv")        <br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer f.Close()<br/>        <br/>// Create a dataframe from the CSV file.
// The types of the columns will be inferred.
loanDF := dataframe.ReadCSV(f)

// Calculate the number of elements in each set.
trainingNum := (4 * loanDF.Nrow()) / 5
testNum := loanDF.Nrow() / 5
if trainingNum+testNum &lt; loanDF.Nrow() {
    trainingNum++
}

// Create the subset indices.
trainingIdx := make([]int, trainingNum)
testIdx := make([]int, testNum)

// Enumerate the training indices.
for i := 0; i &lt; trainingNum; i++ {
    trainingIdx[i] = i
}

// Enumerate the test indices.
for i := 0; i &lt; testNum; i++ {
    testIdx[i] = trainingNum + i
}

// Create the subset dataframes.
trainingDF := loanDF.Subset(trainingIdx)
testDF := loanDF.Subset(testIdx)

// Create a map that will be used in writing the data
// to files.
setMap := map[int]dataframe.DataFrame{
    0: trainingDF,
    1: testDF,
}

// Create the respective files.
for idx, setName := range []string{"training.csv", "test.csv"} {

    // Save the filtered dataset file.
    f, err := os.Create(setName)
    if err != nil {
        log.Fatal(err)
    }

    // Create a buffered writer.
    w := bufio.NewWriter(f)

    // Write the dataframe out as a CSV.
    if err := setMap[idx].WriteCSV(w); err != nil {
        log.Fatal(err)
    }
}</pre>
<p>Compiling and running this results in two files with our training and test examples:</p>
<pre><strong>$ go build
$ ./myprogram 
$ wc -l *.csv
 2046 clean_loan_data.csv
  410 test.csv
 1638 training.csv
 4094 total</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training and testing the logistic regression model</h1>
                </header>
            
            <article>
                
<p>Now, let's create a function that trains a logistic regression model. This function needs to perform the following:</p>
<ol>
<li>Accept our FICO score data as an independent variable.</li>
<li>Add an intercept to our model.</li>
<li>Initialize and optimize the coefficients (or weights) of the logistic regression model.</li>
<li>Return the optimized weights which define our trained model.</li>
</ol>
<p>To optimize the coefficient/weights, we will use a technique called <strong>stochastic gradient descent</strong>. This technique will be covered in greater detail in the Appendix, <em>Algorithms/Techniques Related to Machine Learning.</em> For now, suffice it to say that we are trying to make predictions with some non-optimized weights, calculating an error for those weights, and then updating them iteratively to maximize the likelihood of making a correct prediction.</p>
<p>An implementation of this optimization is as follows. The function takes the following as input:</p>
<ul>
<li><kbd>features</kbd>: A pointer to a gonum <kbd>mat64.Dense</kbd> matrix. This matrix includes a column for any independent variable that we are using (FICO score, in our case) along with columns of 1.0s representing an intercept.</li>
<li><kbd>labels</kbd>: A slice of floats including all of the class labels corresponding to our <kbd>features</kbd>.</li>
<li><kbd>numSteps</kbd>: A maximum number of iterations for the optimization.</li>
<li><kbd>learningRate</kbd>: An adjustable parameter that helps with the convergence of the optimization.</li>
</ul>
<p>The function then outputs the optimized weights for the logistic regression model:</p>
<pre>// logisticRegression fits a logistic regression model<br/>// for the given data.<br/>func logisticRegression(features *mat64.Dense, labels []float64, numSteps int, learningRate float64) []float64 {<br/><br/>        // Initialize random weights.<br/>        _, numWeights := features.Dims()<br/>        weights := make([]float64, numWeights)<br/><br/>        s := rand.NewSource(time.Now().UnixNano())<br/>        r := rand.New(s)<br/><br/>        for idx, _ := range weights {<br/>                weights[idx] = r.Float64()<br/>        }<br/><br/>        // Iteratively optimize the weights.<br/>        for i := 0; i &lt; numSteps; i++ {<br/><br/>        // Initialize a variable to accumulate error for this iteration.<br/>        var sumError float64<br/><br/>        // Make predictions for each label and accumulate error.<br/>        for idx, label := range labels {<br/><br/>            // Get the features corresponding to this label.<br/>            featureRow := mat64.Row(nil, idx, features)<br/><br/>            // Calculate the error for this iteration's weights.<br/>            pred := logistic(featureRow[0]*weights[0]<br/>            featureRow[1]*weights[1])<br/>            predError := label - pred<br/>            sumError += math.Pow(predError, 2)<br/><br/>            // Update the feature weights.<br/>            for j := 0; j &lt; len(featureRow); j++ {<br/>                weights[j] += learningRate * predError * pred * (1 - pred) * featureRow[j]<br/>            }<br/>        }<br/>    }<br/><br/>    return weights<br/>}</pre>
<p>As you can see, this function is relatively compact and simple. This will keep our code readable and allow people on our team to quickly understand what is happening in our model without hiding things in a black box.</p>
<div class="packt_infobox">Despite the popularity of R and Python in machine learning, you can see that machine learning algorithms can be implemented quickly and compactly in Go. Moreover, these implementations immediately achieve a level of integrity that far surpasses naive implementations in other languages.</div>
<p>To train our logistic regression model on our training dataset, we will parse our training file with <kbd>encoding/csv</kbd> and then supply the necessary parameters to our <kbd>logisticRegression</kbd> function. This process is as follows, along with some code to output our trained logistic formula to <kbd>stdout</kbd>:</p>
<pre>// Open the training dataset file.<br/>f, err := os.Open("training.csv")<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer f.Close()<br/><br/>// Create a new CSV reader reading from the opened file.<br/>reader := csv.NewReader(f)<br/>reader.FieldsPerRecord = 2<br/><br/>// Read in all of the CSV records<br/>rawCSVData, err := reader.ReadAll()<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/><br/>// featureData and labels will hold all the float values that<br/>// will eventually be used in our training.<br/>featureData := make([]float64, 2*len(rawCSVData))<br/>labels := make([]float64, len(rawCSVData))<br/><br/>// featureIndex will track the current index of the features<br/>// matrix values.<br/>var featureIndex int<br/><br/>// Sequentially move the rows into the slices of floats.<br/>for idx, record := range rawCSVData {<br/><br/>    // Skip the header row.<br/>    if idx == 0 {<br/>        continue<br/>    }<br/><br/>    // Add the FICO score feature.<br/>    featureVal, err := strconv.ParseFloat(record[0], 64)<br/>    if err != nil {<br/>        log.Fatal(err)<br/>    }<br/><br/>    featureData[featureIndex] = featureVal<br/><br/>    // Add an intercept.<br/>    featureData[featureIndex+1] = 1.0<br/><br/>    // Increment our feature row.<br/>    featureIndex += 2<br/><br/>    // Add the class label.<br/>    labelVal, err := strconv.ParseFloat(record[1], 64)<br/>    if err != nil {<br/>        log.Fatal(err)<br/>    }<br/><br/>    labels[idx] = labelVal<br/>}        <br/><br/>// Form a matrix from the features.
features := mat64.NewDense(len(rawCSVData), 2, featureData)

// Train the logistic regression model.
weights := logisticRegression(features, labels, 100, 0.3)

// Output the Logistic Regression model formula to stdout.
formula := "p = 1 / ( 1 + exp(- m1 * FICO.score - m2) )"
fmt.Printf("\n%s\n\nm1 = %0.2f\nm2 = %0.2f\n\n", formula, weights[0], weights[1])</pre>
<p>Compiling and running this training functionality results in the following trained logistic regression formula:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><br/><strong>p = 1 / ( 1 + exp(- m1 * FICO.score - m2) )</strong><br/><br/><strong>m1 = 13.65</strong><br/><strong>m2 = -4.89</strong><br/><br/></pre>
<p>We can then utilize this formula directly to make predictions. Remember, however, that this model makes a prediction for the probability of getting the loan (at the interest rate of 12%). As such, we need to utilize a threshold for the probability in making predictions. For example, we can say that any <em>p</em> of <em>0.5+</em> will be deemed positive (class one, or getting the loan) and any lower <em>p</em> values will be deemed negative. This type of prediction is implemented in the following function:</p>
<pre>// predict makes a prediction based on our
// trained logistic regression model.
func predict(score float64) float64 {

    // Calculate the predicted probability.
    p := 1 / (1 + math.Exp(-13.65*score+4.89))

    // Output the corresponding class.
    if p &gt;= 0.5 {
        return 1.0
    }

    return 0.0
}</pre>
<p class="mce-root">Using this <kbd>predict</kbd> function, we can evaluate our trained logistic regression model using one of the evaluation metrics introduced earlier in the book. In this case, let's use accuracy, as shown in the following code:</p>
<pre>// Open the test examples.<br/>f, err := os.Open("test.csv")<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer f.Close()<br/><br/>// Create a new CSV reader reading from the opened file.<br/>reader := csv.NewReader(f)<br/><br/>// observed and predicted will hold the parsed observed and predicted values<br/>// form the labeled data file.<br/>var observed []float64<br/>var predicted []float64<br/><br/>// line will track row numbers for logging.<br/>line := 1<br/><br/>// Read in the records looking for unexpected types in the columns.<br/>for {<br/><br/>    // Read in a row. Check if we are at the end of the file.<br/>    record, err := reader.Read()<br/>    if err == io.EOF {<br/>        break<br/>    }<br/><br/>    // Skip the header.<br/>    if line == 1 {<br/>        line++<br/>        continue<br/>    }<br/>                <br/>    // Read in the observed value.
    observedVal, err := strconv.ParseFloat(record[1], 64)
    if err != nil {
        log.Printf("Parsing line %d failed, unexpected type\n", line)
        continue
    }

    // Make the corresponding prediction.
    score, err := strconv.ParseFloat(record[0], 64)
    if err != nil {
        log.Printf("Parsing line %d failed, unexpected type\n", line)
        continue
    }

    predictedVal := predict(score)

    // Append the record to our slice, if it has the expected type.
    observed = append(observed, observedVal)
    predicted = append(predicted, predictedVal)
    line++
}

// This variable will hold our count of true positive and
// true negative values.
var truePosNeg int

// Accumulate the true positive/negative count.
for idx, oVal := range observed {
    if oVal == predicted[idx] {
        truePosNeg++
    }
}

// Calculate the accuracy (subset accuracy).
accuracy := float64(truePosNeg) / float64(len(observed))

// Output the Accuracy value to standard out.
fmt.Printf("\nAccuracy = %0.2f\n\n", accuracy)<br/><br/></pre>
<p>Running this test on our data results in the following accuracy:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><br/><strong>Accuracy = 0.83</strong></pre>
<p>Nice! 83% accuracy is not that bad for a machine learning model that we implemented in about 30 lines of Go. With this simple model, we were able to predict whether, given a certain credit score, loan applicants would be accepted for a loan with less than or equal to 12% interest. Not only that, we did it with real-world messy data from a real company.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">k-nearest neighbors</h1>
                </header>
            
            <article>
                
<p>Moving on from logistic regression, let's try our first non-regression model, <strong>k-nearest neighbors</strong> (<strong>kNN</strong>). kNN is also a simple classification model, and it's one of the easiest model algorithms to grasp. It follows on from the basic premise that if I want to classify a record, I should consider other similar records.</p>
<p>kNN is implemented in multiple existing Go packages including <kbd><span>github.com/sjwhitworth/golearn</span></kbd>, <kbd>github.com/rikonor/go-ann</kbd>, <kbd>github.com/akreal/knn</kbd>, and <kbd>github.com/cdipaolo/goml</kbd>. We will be using the <kbd><span>github.com/sjwhitworth/golearn</span></kbd> implementation, which will serve as a great introduction to using <kbd><span>github.com/sjwhitworth/golearn</span></kbd> <span>in general.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of kNN</h1>
                </header>
            
            <article>
                
<p>As mentioned, kNN operates on the principle that we should classify records according to similar records. There are some details to be dealt with in defining similar. However, kNN does not have the complexity of parameters and options that come with many models.</p>
<p>Imagine again that we have two classes <em>A</em> and <em>B</em>. This time, however, suppose that we are wanting to classify based on two features, <em>x<sub>1</sub></em> and <em>x<sub>2</sub></em>. Visually, this looks something like the following:</p>
<div class="CDPAlignCenter CDPAlign"><img height="210" width="280" class="image-border" src="assets/76976c71-4716-4ed4-8567-a855e8195ca8.png"/></div>
<p>Now, suppose we have a new point of data with an unknown class. This new point of data will sit somewhere in this space. kNN says that, to classify this new point, we should perform the following:</p>
<ol>
<li>Find the <em>k</em> nearest point to the new point according to some measure of nearness (straight distance in this space of <em>x<sub>1</sub></em> <span>and</span> <em>x<sub>2</sub></em>, for example).</li>
<li>Determine how many of those <em>k</em> nearest neighbors are of class <em>A</em> and how many are of class <em>B.</em></li>
<li>Classify the new point as the dominant class among the <em>k</em> nearest neighbors.</li>
</ol>
<p>For example, if we choose <em>k</em> to be four, this would look something as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img height="187" width="315" class="image-border" src="assets/1a6bf21d-8fa5-46a6-aa44-dcd480c6e8e6.png"/></div>
<p>Our mystery point has three <em>A</em> nearest neighbors and only one <em>B</em> nearest neighbor. Thus, we would classify the new mystery point as a class <em>A</em> point.</p>
<p>There are many measures of similarity that you can use to determine the <em>k</em> nearest neighbors. The most common of these is the Euclidean distance<em>,</em> which is just the straight line distance from one point to the next in the space made up of your features (<em>x<sub>1</sub></em> <span>and</span> <em>x<sub>2</sub></em> <span>in our example</span>). Others include <strong>Manhattan distance</strong>, <strong>Minkowski</strong> <strong>distance</strong>, <strong>cosine similarity</strong>, and <strong>Jaccard Similarity</strong>.</p>
<div class="packt_tip">As with evaluation metrics, there are a whole host of ways that distance or similarity can be measured. When using kNN, you should look into the advantages and disadvantages of these measures and choose one that fits your use case and data. When in doubt, however, you can try starting with the Euclidean distance.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">kNN assumptions and pitfalls</h1>
                </header>
            
            <article>
                
<p>Due to its simplicity, kNN does not have too many assumptions. However, there are some common pitfalls that you should be aware of as you apply kNN:</p>
<ul>
<li>kNN is evaluated lazily. By this, we mean that the distances or similarities are calculated when we need to make a prediction. There is not really anything to train or fit prior to making a prediction. This has some advantages, but the calculation and search over points can be slow when you have many data points.</li>
<li>The choice of <em>k</em> is up to you, but you should put some formalism around choosing <em>k</em> and provide justification for the <em>k</em> that you choose. A common technique to choose <em>k</em> is just to search over a range of <em>k</em> values. You could, for example, start with <em>k = 2</em>. Then, you could start increasing <em>k</em>, and for each <em>k</em>, evaluate on a test set.</li>
<li>kNN does not take into consideration which features are more important than other features. Moreover, if the scale of certainty of your features is much larger than other features, this could unnaturally weight the importance of those larger features.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">kNN example</h1>
                </header>
            
            <article>
                
<p>For this, and the remaining examples in this chapter, we are going to solve a classic classification problem using a dataset about <strong>iris flowers</strong>. The dataset looks like this:</p>
<pre><strong>$ head iris.csv 
sepal_length,sepal_width,petal_length,petal_width,species
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
5.0,3.6,1.4,0.2,Iris-setosa
5.4,3.9,1.7,0.4,Iris-setosa
4.6,3.4,1.4,0.3,Iris-setosa
5.0,3.4,1.5,0.2,Iris-setosa
4.4,2.9,1.4,0.2,Iris-setosa</strong></pre>
<p>The first four columns are various measurements of iris flowers and the last column is a corresponding species label. The goal of this example will be to create a kNN classifier that is able to predict the species of an iris flower from a set of measurements. There are three species of flowers, or three classes, making this a multi-class classification (in contrast to the binary classification that we did with logistic regression).</p>
<div class="packt_tip"><span>You may remember that we already profiled the iris dataset in detail in <a href="5e7af3cb-ce60-4699-b2d3-7eeff8978a9e.xhtml" target="_blank">Chapter 2</a>,</span> <em>Matrices, Probability, and Statistics.</em> <span>We will not reprofile the data here.</span> However, it is still important that we have intuition about our data as we develop the kNN model. Make sure you flip back to <a href="5e7af3cb-ce60-4699-b2d3-7eeff8978a9e.xhtml" target="_blank">Chapter 2</a>, <em>Matrices, Probability, and Statistics</em>, to remind yourself about the distributions of variables in this dataset.</div>
<p>We will be using <span><kbd>github.com/sjwhitworth/golearn</kbd> in this example. <kbd>github.com/sjwhitworth/golearn</kbd> implements a variety of machine learning models, including kNN and some others that we will explore shortly. <kbd>github.com/sjwhitworth/golearn</kbd> also implements cross-validation. We will take advantage of cross-validation here to perform training, testing, and validation, which is convenient and lets us avoid performing a manual split between training and test sets.</span></p>
<p>To use any of <span><kbd>github.com/sjwhitworth/golearn</kbd>'s models, we must first convert the data into a <kbd>github.com/sjwhitworth/golearn</kbd> internal format called <strong>instances</strong>. For the iris data, we can do this as follows:</span></p>
<pre>// Read in the iris data set into golearn "instances".
irisData, err := base.ParseCSVToInstances("iris.csv", true)
if err != nil {
    log.Fatal(err)
}</pre>
<p>Then, initializing our kNN model and performing the cross-validation is quick and simple:</p>
<pre>// Initialize a new KNN classifier.  We will use a simple
// Euclidean distance measure and k=2.
knn := knn.NewKnnClassifier("euclidean", "linear", 2)

// Use cross-fold validation to successively train and evaluate the model
// on 5 folds of the data set.
cv, err := evaluation.GenerateCrossFoldValidationConfusionMatrices(irisData, knn, 5)
if err != nil {
    log.Fatal(err)
}</pre>
<p>Finally, we can get the average accuracy across the five folds of the cross-validation and output that accuracy to <kbd>stdout</kbd>:</p>
<pre>// Get the mean, variance and standard deviation of the accuracy for the
// cross validation.
mean, variance := evaluation.GetCrossValidatedMetric(cv, evaluation.GetAccuracy)
stdev := math.Sqrt(variance)

// Output the cross metrics to standard out.
fmt.Printf("\nAccuracy\n%.2f (+/- %.2f)\n\n", mean, stdev*2)</pre>
<p>Compiling and running all of this together gives the following output:</p>
<pre><strong>$ go build
$ ./myprogram 
Optimisations are switched off
Optimisations are switched off
Optimisations are switched off
Optimisations are switched off
Optimisations are switched off
KNN: 95.00 % done
Accuracy
0.95 (+/- 0.05)</strong></pre>
<p>After some benign logging from the package during the cross-validation, we can see that kNN (<em>k = 2</em>) was able to predict iris flower species with 95% accuracy!</p>
<p>The next step here would be to try this model out with a variety of different <em>k</em> values. Actually, it would be a good exercise to plot the accuracy versus <em>k</em> values to see which <em>k</em> value gives you the best performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision trees and random forests</h1>
                </header>
            
            <article>
                
<p>Tree-based models are very different from the previous types of models that we have discussed, but they are widely utilized and very powerful. You can think about a <strong>decision tree</strong> model like a series of <kbd>if-then</kbd> statements applied to your data. When you train this type of model, you are constructing a series of control flow statements that eventually allow you to classify records.</p>
<p>Decision trees are implemented in <kbd>github.com/sjwhitworth/golearn</kbd> and <kbd>github.com/xlvector/hector</kbd>, among others, and random forests are implemented in <span><kbd>github.com/sjwhitworth/golearn</kbd>,</span> <kbd><span>github.com/xlvector/hector</span></kbd><span>, and <kbd>github.com/ryanbressler/CloudForest</kbd>, among others. We will utilize <kbd>github.com/sjwhitworth/golearn</kbd> again in our examples shown in the following section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of decision trees and random forests</h1>
                </header>
            
            <article>
                
<p>Again, consider our classes <em>A</em> and <em>B</em>. In this case, suppose that we have one feature, <em>x<sub>1</sub>,</em> that ranges from <em>0.0</em> to <em>1.0</em>, and we have another feature, <em>x<sub>2</sub></em> that is categorical and can take on one of two values, <em>a<sub>1</sub></em> and <em>a<sub>2</sub></em> (this could be something like male/female or red/blue). A decision tree to classify a new data point might look something like the following:</p>
<div class="CDPAlignCenter CDPAlign"><img height="156" width="434" class="image-border" src="assets/3c0fa849-b74d-4d02-a1c4-b8a767b82300.png"/></div>
<p>There are a variety of ways to choose how decision trees are constructed, split, and so on. One of the most common ways to determine how decision trees are constructed is using a quantity called <strong>entropy</strong>. This entropy-based approach is discussed in more detail in the <em>Appendix</em>, but, basically, we construct the tree and splits based on which features give us the most information about the problem we are solving. The more important features are prioritized higher on the tree.</p>
<p>This prioritization of important features and a natural looking structure makes decision trees very interpretable. This makes decision trees important for applications in which you might have to explain your inferences (for compliance reasons, for example).</p>
<p>However, a single decision tree can be unstable with respect to changes in your training data. In other words, the structure of the tree may change significantly with even small changes in your training data. This can be challenging to manage both operationally and cognitively, and this is one of the reasons why the <strong>random forest</strong> model was created.</p>
<p>A random forest is a collection of decision trees that work together to make a prediction. Random forests are more stable when compared to single decision trees, and they are more robust against overfitting. In fact, this idea of combining models in an <strong>ensemble</strong> is prevalent throughout machine learning both to improve the performance of simple classifiers (such as decision trees) and to help prevent overfitting.</p>
<p>To construct a random forest, we choose <em>N</em> random subsets of features and construct <em>N</em> separate decision trees based on these subsets. When making a prediction, we can then have each of these <em>N</em> decision trees make a prediction. To obtain a final prediction, we can take the majority vote of these <em>N</em> predictions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision tree and random forest assumptions and pitfalls</h1>
                </header>
            
            <article>
                
<p>Tree-based approaches are non-statistical approaches without many of the assumptions that come along with things like regression. However, there are some pitfalls to keep in mind:</p>
<ul>
<li>Single decision tree models can easily overfit to your data, especially if you do not limit the depth of the trees. Most implementations allow you to limit this depth via a parameter (or <strong>prune</strong> your decision trees). A pruning parameter will often allow you to remove sections of the tree that have little influence on the predictions, and, thus, reduce the overall complexity of the model.</li>
<li>When we start talking about ensemble models, such as random forest, we are getting into models that are somewhat opaque. It's very hard to gain intuition about an ensemble of models and you have to treat it like a black box to some degree. Less interpretable models like these should be applied only when necessary.</li>
<li>Although decision trees themselves are very computationally efficient, random forests can be very computationally inefficient depending on how many features you have and how many trees are in your random forest.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision tree example</h1>
                </header>
            
            <article>
                
<p>We will again utilize the iris dataset for this example. You have already learned how to handle this dataset in <kbd>github.com/sjwhitworth/golearn</kbd><span>, and we can follow a similar pattern again. We will again use cross-validation. However, this time we will fit a decision tree model:</span></p>
<pre>// Read in the iris data set into golearn "instances".
irisData, err := base.ParseCSVToInstances("iris.csv", true)
if err != nil {
    log.Fatal(err)
}

// This is to seed the random processes involved in building the
// decision tree.
rand.Seed(44111342)

// We will use the ID3 algorithm to build our decision tree.  Also, we
// will start with a parameter of 0.6 that controls the train-prune split.
tree := trees.NewID3DecisionTree(0.6)

// Use cross-fold validation to successively train and evaluate the model
// on 5 folds of the data set.
cv, err := evaluation.GenerateCrossFoldValidationConfusionMatrices(irisData, tree, 5)
if err != nil {
    log.Fatal(err)
}

// Get the mean, variance and standard deviation of the accuracy for the
// cross validation.
mean, variance := evaluation.GetCrossValidatedMetric(cv, evaluation.GetAccuracy)
stdev := math.Sqrt(variance)

// Output the cross metrics to standard out.
fmt.Printf("\nAccuracy\n%.2f (+/- %.2f)\n\n", mean, stdev*2)</pre>
<p>Compiling and running this decision tree model gives the following:</p>
<pre><strong>$ go build
$ ./myprogram 

Accuracy
0.94 (+/- 0.06)</strong></pre>
<p>94% accuracy this time. Slightly worse than our kNN model, but still very respectable.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forest example</h1>
                </header>
            
            <article>
                
<p><kbd>github.com/sjwhitworth/golearn</kbd> <span>also implements random forests. To utilize random forest in solving the iris problem, we simply swap our decision tree model for the random forests. We will need to tell the package how many trees we want to build and with how many randomly chosen features per tree.</span></p>
<p>A sane default for the number of features per tree is the square root of the number of total features, which in our case would be two. We will see that this choice for our small dataset does not produce good results because we need all of the features to make a good prediction here. However, we will illustrate random forest with the sane default to see how it works:</p>
<pre>// Assemble a random forest with 10 trees and 2 features per tree,
// which is a sane default (number of features per tree is normally set
// to sqrt(number of features)).
rf := ensemble.NewRandomForest(10, 2)

// Use cross-fold validation to successively train and evaluate the model
// on 5 folds of the data set.
cv, err := evaluation.GenerateCrossFoldValidationConfusionMatrices(irisData, rf, 5)
if err != nil {
    log.Fatal(err)
}</pre>
<p>Running this gives an accuracy that is worse than the single decision tree. If we change the number of features per tree back up to four, we will recreate the accuracy of the single decision tree. This means that every tree is being trained with the same information as the single decision tree, and thus produces the same results.</p>
<p>Random forest is likely to overkill here and cannot be justified with any performance gains, so it would be best to stick with the single decision tree. This single decision tree is also more interpretable and more efficient.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Naive bayes</h1>
                </header>
            
            <article>
                
<p>The final model that we will cover here for classification is called <strong>Naive bayes</strong>. In <a href="5e7af3cb-ce60-4699-b2d3-7eeff8978a9e.xhtml" target="_blank">Chapter 2</a>, <em>Matrices, Probability, and Statistics,</em> we discussed the Bayes rule, which forms the basis of this technique. Naive Bayes is a probability-based method like logistic regression, but its basic ideas and assumptions are different.</p>
<p>Naive Bayes is also implemented in <kbd>github.com/sjwhitworth/golearn</kbd><span>, which will allow us to easily try it out. However, there are a variety of other Go implementations including <kbd>github.com/jbrukh/bayesian</kbd>, <kbd>github.com/lytics/multibayes</kbd>, and <kbd>github.com/cdipaolo/goml</kbd>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of naive bayes and its big assumption</h1>
                </header>
            
            <article>
                
<p>Naive bayes operates under one large assumption. This assumption says that the probability of the classes and the presence or absence of a certain feature in our dataset is independent of the presence or absence of other features in our dataset. This allows us to write a very simple formula for the probability of a certain class, given the presence or absence of certain features.</p>
<p>Let's take an example to make this more concrete. Again, let's say that we are trying to predict two classes of emails, <em>A</em> and <em>B</em> (spam and not spam, for example), based on words in the emails. Naive bayes would assume that the presence/absence of a certain word is independent of other words. If we make this assumption, the probability that a certain class contains certain words is proportional to all of the individual conditional probabilities multiplied together. Using this, the Bayes rule, some chain rules, and our independent assumptions, we can write the conditional probability of a certain class as follows:</p>
<div style="padding-left: 60px" class="mce-root CDPAlignLeft CDPAlign"><img height="35" width="467" src="assets/a6a0ccd5-a99e-4a30-aecd-12ca929d01bd.jpg"/></div>
<p>Everything on the right-hand side we can calculate by counting the occurrences of the features and labels in our training set, which is what is done when training the model. Predictions can then be made by stringing together chains of these probabilities.</p>
<div class="packt_tip">Actually, in practice, a little trick is used to avoid having to string together a bunch of numbers that are close to zero. We can take the log of the probabilities, add these, and then take the exponential of the expression. This process is generally better in practice.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Naive bayes example</h1>
                </header>
            
            <article>
                
<p><span>Circling back to our loan dataset for a final time, we are going to use</span> <kbd>github.com/sjwhitworth/golearn</kbd> <span>to solve the same loan acceptance problem with Naive bayes. We will utilize the same training and test sets that we used in the logistic regression example. However, we need to convert the labels in the datasets to a binary classifier format used in <kbd>github.com/sjwhitworth/golearn</kbd>. We can write a simple function to perform this conversion:</span></p>
<pre>// convertToBinary utilizes built in golearn functionality to
// convert our labels to a binary label format.
func convertToBinary(src base.FixedDataGrid) base.FixedDataGrid {
    b := filters.NewBinaryConvertFilter()
    attrs := base.NonClassAttributes(src)
    for _, a := range attrs {
        b.AddAttribute(a)
    }
    b.Train()
    ret := base.NewLazilyFilteredInstances(src, b)
    return ret
}</pre>
<p><span>Once we have that, we can train and test our naive bayes model, as shown in the following code:</span></p>
<pre>// Read in the loan training data set into golearn "instances".
trainingData, err := base.ParseCSVToInstances("training.csv", true)
if err != nil {
    log.Fatal(err)
}

// Initialize a new Naive Bayes classifier.
nb := naive.NewBernoulliNBClassifier()

// Fit the Naive Bayes classifier.
nb.Fit(convertToBinary(trainingData))

// Read in the loan test data set into golearn "instances".<br/>// This time we will utilize a template of the previous set<br/>// of instances to validate the format of the test set.<br/>testData, err := base.ParseCSVToTemplatedInstances("test.csv", true, trainingData)
if err != nil {
    log.Fatal(err)
}

// Make our predictions.
predictions := nb.Predict(convertToBinary(testData))

// Generate a Confusion Matrix.
cm, err := evaluation.GetConfusionMatrix(testData, predictions)
if err != nil {
    log.Fatal(err)
}

// Retrieve the accuracy.
accuracy := evaluation.GetAccuracy(cm)
fmt.Printf("\nAccuracy: %0.2f\n\n", accuracy)</pre>
<p>Compiling and running this gives the following accuracy:</p>
<pre><strong>$ go build
$ ./myprogram 

Accuracy: 0.63</strong></pre>
<p>This is not quite as good as our from-scratch logistic regression. However, there is still some predictive power here. A good exercise would be to add some of the other features from the LendingClub dataset to this model, especially some of the categorical variables. This would likely improve the naive bayes result.</p>
<p> </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">References</h1>
                </header>
            
            <article>
                
<p>General classification:</p>
<ul>
<li><kbd><span>github.com/sjwhitworth/golearn</span></kbd> docs: <a href="https://godoc.org/github.com/sjwhitworth/golearn">https://godoc.org/github.com/sjwhitworth/golearn</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We have covered a variety of classification models including logistic regression, k-nearest neighbors, decision trees, random forest, and naive bayes. In fact, we even implemented logistic regression from scratch. All of these models have their different strengths and weaknesses, which we have discussed. However, they should provide you with a good set of tools to start doing classification with Go.</p>
<p>In the next chapter, we will discuss yet another type of machine learning called <strong>clustering</strong>. This is the first unsupervised technique that we will discuss, and we will try a few different approaches.</p>


            </article>

            
        </section>
    </body></html>