["```py\n((B[i] == 255) ? B[i] : \n    min(255, ((A[i] << 8) / (255 - B[i]))))\n```", "```py\ndef dodge_naive(image, mask):\n    # determine the shape of the input image\n    width, height = image.shape[:2]\n\n    # prepare output argument with same size as image\n    blend = np.zeros((width, height), np.uint8)\n\n    for c in range(width):\n        for r in range(height):\n\n            # shift image pixel value by 8 bits\n            # divide by the inverse of the mask\n            result = (image[c, r] << 8) / (255 - mask[c, r])\n\n            # make sure resulting value stays within bounds\n            blend[c, r] = min(255, result)\n    return blend\n```", "```py\nimport cv2 \n\ndef dodge(image, mask): \n    return cv2.divide(image, 255 - mask, scale=256) \n```", "```py\nimg_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) \n```", "```py\n    inv_gray = 255 - gray_image\n    blurred_image = cv2.GaussianBlur(inv_gray, (21, 21), 0, 0)\n```", "```py\n    gray_sketch = cv2.divide(gray_image, 255 - blurred_image, \n    scale=256)\n```", "```py\ndef convert_to_pencil_sketch(rgb_image):\n    gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n    blurred_image = cv2.GaussianBlur(gray_image, (21, 21), 0, 0)\n    gray_sketch = cv2.divide(gray_image, blurred_image, scale=256)\n    return cv2.cvtColor(gray_sketch, cv2.COLOR_GRAY2RGB)\n```", "```py\n    if canvas is not None:\n        gray_sketch = cv2.multiply(gray_sketch, canvas, scale=1 / 256)\n```", "```py\ndef pencil_sketch_on_canvas(rgb_image, canvas=None):\n    gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n    blurred_image = cv2.GaussianBlur(gray_image, (21, 21), 0, 0)\n    gray_sketch = cv2.divide(gray_image, blurred_image, scale=256)\n    if canvas is not None:\n        gray_sketch = cv2.multiply(gray_sketch, canvas, scale=1 / 256)\n    return cv2.cvtColor(gray_sketch, cv2.COLOR_GRAY2RGB)\n```", "```py\nfrom scipy.interpolate import UnivariateSpline \n\ndef spline_to_lookup_table(spline_breaks: list, break_values: list):\n    spl = UnivariateSpline(spline_breaks, break_values)\n    return spl(range(256)\n```", "```py\nimport cv2 \nimport numpy as np \n\nx = [0, 128, 255] \ny = [0, 192, 255] \nmyLUT = spline_to_lookup_table(x, y) \nimg_curved = cv2.LUT(img_gray, myLUT).astype(np.uint8) \n```", "```py\nINCREASE_LOOKUP_TABLE = spline_to_lookup_table([0, 64, 128, 192, 256],\n                                               [0, 70, 140, 210, 256])\nDECREASE_LOOKUP_TABLE = spline_to_lookup_table([0, 64, 128, 192, 256],\n                                               [0, 30, 80, 120, 192])\n```", "```py\n    c_r, c_g, c_b = cv2.split(rgb_image)\n```", "```py\n    if green_filter is not None:\n        c_g = cv2.LUT(c_g, green_filter).astype(np.uint8)\n```", "```py\ndef apply_rgb_filters(rgb_image, *,\n                      red_filter=None, green_filter=None, blue_filter=None):\n    c_r, c_g, c_b = cv2.split(rgb_image)\n    if red_filter is not None:\n        c_r = cv2.LUT(c_r, red_filter).astype(np.uint8)\n    if green_filter is not None:\n        c_g = cv2.LUT(c_g, green_filter).astype(np.uint8)\n    if blue_filter is not None:\n        c_b = cv2.LUT(c_b, blue_filter).astype(np.uint8)\n    return cv2.merge((c_r, c_g, c_b))\n```", "```py\n        interim_img = apply_rgb_filters(rgb_image,\n                                        red_filter=INCREASE_LOOKUP_TABLE,\n                                        blue_filter=DECREASE_LOOKUP_TABLE)\n```", "```py\ndef apply_hue_filter(rgb_image, hue_filter):\n    c_h, c_s, c_v = cv2.split(cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV))\n    c_s = cv2.LUT(c_s, hue_filter).astype(np.uint8)\n    return cv2.cvtColor(cv2.merge((c_h, c_s, c_v)), cv2.COLOR_HSV2RGB)\n```", "```py\n    def _render_cool(rgb_image: np.ndarray) -> np.ndarray:\n        interim_img = apply_rgb_filters(rgb_image,\n                                        red_filter=DECREASE_LOOKUP_TABLE,\n                                        blue_filter=INCREASE_LOOKUP_TABLE)\n        return apply_hue_filter(interim_img, DECREASE_LOOKUP_TABLE)\n```", "```py\n    img_small = cv2.resize(img_rgb, (0, 0), fx=0.5, fy=0.5) \n```", "```py\n    downsampled_img = cv2.pyrDown(rgb_image)\n```", "```py\n    for _ in range(num_bilaterals):\n        filterd_small_img = cv2.bilateralFilter(downsampled_img, 9, 9, 7)\n```", "```py\n    downsampled_img = rgb_image\n    for _ in range(num_pyr_downs):\n        downsampled_img = cv2.pyrDown(downsampled_img)\n```", "```py\n    for _ in range(num_bilaterals):\n        filterd_small_img = cv2.bilateralFilter(downsampled_img, 9, 9, 7)\n```", "```py\n    filtered_normal_img = filterd_small_img\n    for _ in range(num_pyr_downs):\n        filtered_normal_img = cv2.pyrUp(filtered_normal_img)\n```", "```py\n    # convert to grayscale and apply median blur\n    img_gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n    img_blur = cv2.medianBlur(img_gray, 7)\n```", "```py\n    gray_edges = cv2.adaptiveThreshold(img_blur, 255,\n                                       cv2.ADAPTIVE_THRESH_MEAN_C,\n                                       cv2.THRESH_BINARY, 9, 2)\n```", "```py\ndef cartoonize(rgb_image, *,\n               num_pyr_downs=2, num_bilaterals=7):\n    # STEP 1 -- Apply a bilateral filter to reduce the color palette of\n    # the image.\n    downsampled_img = rgb_image\n    for _ in range(num_pyr_downs):\n        downsampled_img = cv2.pyrDown(downsampled_img)\n\n    for _ in range(num_bilaterals):\n        filterd_small_img = cv2.bilateralFilter(downsampled_img, 9, 9, 7)\n\n    filtered_normal_img = filterd_small_img\n    for _ in range(num_pyr_downs):\n        filtered_normal_img = cv2.pyrUp(filtered_normal_img)\n\n    # make sure resulting image has the same dims as original\n    if filtered_normal_img.shape != rgb_image.shape:\n        filtered_normal_img = cv2.resize(\n            filtered_normal_img, rgb_image.shape[:2])\n\n    # STEP 2 -- Convert the original color image into grayscale.\n    img_gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n    # STEP 3 -- Apply amedian blur to reduce image noise.\n    img_blur = cv2.medianBlur(img_gray, 7)\n\n    # STEP 4 -- Use adaptive thresholding to detect and emphasize the edges\n    # in an edge mask.\n    gray_edges = cv2.adaptiveThreshold(img_blur, 255,\n                                       cv2.ADAPTIVE_THRESH_MEAN_C,\n                                       cv2.THRESH_BINARY, 9, 2)\n    # STEP 5 -- Combine the color image from step 1 with the edge mask\n    # from step 4.\n    rgb_edges = cv2.cvtColor(gray_edges, cv2.COLOR_GRAY2RGB)\n    return cv2.bitwise_and(filtered_normal_img, rgb_edges)\n```", "```py\nimport wx\nimport cv2\nimport numpy as np\n```", "```py\nfrom wx_gui import BaseLayout\nfrom tools import apply_hue_filter\nfrom tools import apply_rgb_filters\nfrom tools import load_img_resized\nfrom tools import spline_to_lookup_table\nfrom tools import cartoonize\nfrom tools import pencil_sketch_on_canvas\n```", "```py\ndef main(): \n    capture = cv2.VideoCapture(0) \n```", "```py\n    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n```", "```py\n    # start graphical user interface\n    app = wx.App()\n    layout = FilterLayout(capture, title='Fun with Filters')\n    layout.Center()\n    layout.Show()\n    app.MainLoop()\n```", "```py\nimport numpy as np\nimport wx\nimport cv2\n```", "```py\nclass BaseLayout(wx.Frame):\n```", "```py\nclass BaseLayout(wx.Frame):\n    ...\n    ...\n    ...\n    def process_frame(self, frame_rgb: np.ndarray) -> np.ndarray:\n        \"\"\"Process the frame of the camera (or other capture device)\n\n        :param frame_rgb: Image to process in rgb format, of shape (H, W, 3)\n        :return: Processed image in rgb format, of shape (H, W, 3)\n        \"\"\"\n        raise NotImplementedError()\n```", "```py\n    def __init__(self,\n                 capture: cv2.VideoCapture,\n                 title: str = None,\n                 parent=None,\n                 window_id: int = -1,  # default value\n                 fps: int = 10):\n        self.capture = capture\n        _, frame = self._acquire_frame()\n        self.imgHeight, self.imgWidth = frame.shape[:2]\n```", "```py\n        super().__init__(parent, window_id, title,\n                         size=(self.imgWidth, self.imgHeight + 20))\n        self.fps = fps\n        self.bmp = wx.Bitmap.FromBuffer(self.imgWidth, self.imgHeight, frame)\n```", "```py\n        self.video_pnl = wx.Panel(self, size=(self.imgWidth, self.imgHeight))\n        self.video_pnl.SetBackgroundColour(wx.BLACK)\n```", "```py\n        # display the button layout beneath the video stream\n        self.panels_vertical = wx.BoxSizer(wx.VERTICAL)\n        self.panels_vertical.Add(self.video_pnl, 1, flag=wx.EXPAND | wx.TOP,\n                                 border=1)\n```", "```py\n        self.augment_layout()\n```", "```py\n        self.SetMinSize((self.imgWidth, self.imgHeight))\n        self.SetSizer(self.panels_vertical)\n        self.Centre()\n```", "```py\n        self.timer = wx.Timer(self)\n        self.timer.Start(1000\\. / self.fps)\n```", "```py\n        self.Bind(wx.EVT_TIMER, self._on_next_frame)\n```", "```py\n        self.video_pnl.Bind(wx.EVT_PAINT, self._on_paint)\n```", "```py\n    def _on_next_frame(self, event):\n        \"\"\"\n        Capture a new frame from the capture device,\n        send an RGB version to `self.process_frame`, refresh.\n        \"\"\"\n        success, frame = self._acquire_frame()\n        if success:\n            # process current frame\n            frame = self.process_frame(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n            ...\n```", "```py\n            ...\n            # update buffer and paint (EVT_PAINT triggered by Refresh)\n            self.bmp.CopyFromBuffer(frame)\n            self.Refresh(eraseBackground=False)\n```", "```py\n    def _on_paint(self, event):\n        \"\"\" Draw the camera frame stored in `self.bmp` onto `self.video_pnl`.\n        \"\"\"\n        wx.BufferedPaintDC(self.video_pnl).DrawBitmap(self.bmp, 0, 0)\n```", "```py\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        color_canvas = load_img_resized('pencilsketch_bg.jpg',\n                                        (self.imgWidth, self.imgHeight))\n        self.canvas = cv2.cvtColor(color_canvas, cv2.COLOR_RGB2GRAY)\n```", "```py\n    def augment_layout(self):\n        \"\"\" Add a row of radio buttons below the camera feed. \"\"\"\n\n        # create a horizontal layout with all filter modes as radio buttons\n        pnl = wx.Panel(self, -1)\n        self.mode_warm = wx.RadioButton(pnl, -1, 'Warming Filter', (10, 10),\n                                        style=wx.RB_GROUP)\n        self.mode_cool = wx.RadioButton(pnl, -1, 'Cooling Filter', (10, 10))\n        self.mode_sketch = wx.RadioButton(pnl, -1, 'Pencil Sketch', (10, 10))\n        self.mode_cartoon = wx.RadioButton(pnl, -1, 'Cartoon', (10, 10))\n        hbox = wx.BoxSizer(wx.HORIZONTAL)\n        hbox.Add(self.mode_warm, 1)\n        hbox.Add(self.mode_cool, 1)\n        hbox.Add(self.mode_sketch, 1)\n        hbox.Add(self.mode_cartoon, 1)\n        pnl.SetSizer(hbox)\n\n        # add panel with radio buttons to existing panels in a vertical\n        # arrangement\n        self.panels_vertical.Add(pnl, flag=wx.EXPAND | wx.BOTTOM | wx.TOP,\n                                 border=1\n```", "```py\n    def process_frame(self, frame_rgb: np.ndarray) -> np.ndarray:\n        \"\"\"Process the frame of the camera (or other capture device)\n\n        Choose a filter effect based on the which of the radio buttons\n        was clicked.\n\n        :param frame_rgb: Image to process in rgb format, of shape (H, W, 3)\n        :return: Processed image in rgb format, of shape (H, W, 3)\n        \"\"\"\n        if self.mode_warm.GetValue():\n            return self._render_warm(frame_rgb)\n        elif self.mode_cool.GetValue():\n            return self._render_cool(frame_rgb)\n        elif self.mode_sketch.GetValue():\n            return pencil_sketch_on_canvas(frame_rgb, canvas=self.canvas)\n        elif self.mode_cartoon.GetValue():\n            return cartoonize(frame_rgb)\n        else:\n            raise NotImplementedError()\n```"]