["```py\npip install tensorflow\n```", "```py\nimport tensorflow as tf \na = tf.placeholder(tf.int32, name='a') # input \nb = tf.placeholder(tf.int32, name='b') # input \ntimes = tf.Variable(name=\"times\", dtype=tf.int32, initial_value=2) \nc = tf.pow(tf.add(a, b), times, name=\"c\") \nsaver = tf.train.Saver()\n\ninit_op = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init_op) tf.train.write_graph(sess.graph_def, '.', 'tfdroid.pbtxt')\n\nsess.run(tf.assign(name=\"times\", value=2, ref=times)) # save the graph \n# save a checkpoint file, which will store the above assignment saver.save(sess, './tfdroid.ckpt')\n```", "```py\npython (filename)\n```", "```py\nimport sys import tensorflow as tf from tensorflow.python.tools \nimport freeze_graph from tensorflow.python.tools \nimport optimize_for_inference_lib MODEL_NAME = 'tfdroid'\n# Freeze the graph\n\ninput_graph_path = MODEL_NAME+'.pbtxt' checkpoint_path = './'+MODEL_NAME+'.ckpt' input_saver_def_path = \"\" input_binary = False output_node_names = \"c\" restore_op_name = \"save/restore_all\" filename_tensor_name = \"save/Const:0\" output_frozen_graph_name = 'frozen_'+MODEL_NAME+'.pb' output_optimized_graph_name = 'optimized_'+MODEL_NAME+'.pb' clear_devices = True freeze_graph.freeze_graph(input_graph_path, input_saver_def_path, input_binary, checkpoint_path, output_node_names, restore_op_name, filename_tensor_name, output_frozen_graph_name, clear_devices, \"\")\n```", "```py\n# Optimize for inference \ninput_graph_def = tf.GraphDef() with tf.gfile.Open(output_frozen_graph_name, \"r\") as f: data = f.read() input_graph_def.ParseFromString(data) \noutput_graph_def = optimize_for_inference_lib.optimize_for_inference( input_graph_def, [\"a\", \"b\"], \n# an array of the input node(s) [\"c\"], \n# an array of output nodes tf.int32.as_datatype_enum)\n\n# Save the optimized graph f = tf.gfile.FastGFile(output_optimized_graph_name, \"w\") f.write(output_graph_def.SerializeToString()) tf.train.write_graph(output_graph_def, './', output_optimized_graph_name)\n```", "```py\nlibs\n|____arm64-v8a\n| |____libtensorflow_inference.so\n|____armeabi-v7a\n| |____libtensorflow_inference.so\n|____libandroid_tensorflow_inference_java.jar\n|____x86\n| |____libtensorflow_inference.so\n|____x86_64\n| |____libtensorflow_inference.so\n```", "```py\nsourceSets { main { jniLibs.srcDirs = ['libs'] } }\n```", "```py\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<RelativeLayout \n\nandroid:id=\"@+id/activity_main\"\nandroid:layout_width=\"match_parent\"\nandroid:layout_height=\"match_parent\"\nandroid:paddingBottom=\"@dimen/activity_vertical_margin\"\nandroid:paddingLeft=\"@dimen/activity_horizontal_margin\"\nandroid:paddingRight=\"@dimen/activity_horizontal_margin\"\nandroid:paddingTop=\"@dimen/activity_vertical_margin\"\ntools:context=\"com.example.vavinash.tensorflowsample.MainActivity\">\n\n<EditText\nandroid:id=\"@+id/editNum1\"\nandroid:layout_width=\"100dp\"\nandroid:layout_height=\"wrap_content\"\nandroid:layout_alignParentTop=\"true\"\nandroid:layout_marginEnd=\"13dp\"\nandroid:layout_marginTop=\"129dp\"\nandroid:layout_toStartOf=\"@+id/button\"\nandroid:ems=\"10\"\nandroid:hint=\"a\"\nandroid:inputType=\"textPersonName\"\nandroid:textAlignment=\"center\" />\n\n<EditText\nandroid:id=\"@+id/editNum2\"\nandroid:layout_width=\"100dp\"\nandroid:layout_height=\"wrap_content\"\nandroid:layout_alignBaseline=\"@+id/editNum1\"\nandroid:layout_alignBottom=\"@+id/editNum1\"\nandroid:layout_toEndOf=\"@+id/button\"\nandroid:ems=\"10\"\nandroid:hint=\"b\"\nandroid:inputType=\"textPersonName\"\nandroid:textAlignment=\"center\" />\n\n<Button\nandroid:text=\"Run\"\nandroid:layout_width=\"wrap_content\"\nandroid:layout_height=\"wrap_content\"\nandroid:id=\"@+id/button\"\nandroid:layout_below=\"@+id/editNum2\"\nandroid:layout_centerHorizontal=\"true\"\nandroid:layout_marginTop=\"50dp\" />\n\n<TextView\nandroid:layout_width=\"wrap_content\"\nandroid:layout_height=\"wrap_content\"\nandroid:text=\"Output\"\nandroid:id=\"@+id/txtViewResult\"\nandroid:layout_marginTop=\"85dp\"\nandroid:textAlignment=\"center\"\nandroid:layout_alignTop=\"@+id/button\"\nandroid:layout_centerHorizontal=\"true\" />\n</RelativeLayout>\n```", "```py\npackage com.example.vavinash.tensorflowsample;\nimport android.support.v7.app.AppCompatActivity;\nimport android.os.Bundle;\nimport android.widget.EditText;\nimport android.widget.TextView;\nimport android.widget.Button;\nimport android.view.View;\nimport org.tensorflow.contrib.android.TensorFlowInferenceInterface;public class MainActivity extends AppCompatActivity {\n    //change with the file name of your own model generated in python tensorflow.\n    private static final String MODEL_FILE = \"file:///android_asset/tfdroid.pb\";\n\n    //here we are using this interface to perform the inference with our generated model. It internally     uses c++ libraries and JNI.\n    private TensorFlowInferenceInterface inferenceInterface;\n    static {\n        System.loadLibrary(\"tensorflow_inference\");\n    }\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        inferenceInterface = new TensorFlowInferenceInterface();\n        //instantiatind and setting our model file as input.\n        inferenceInterface.initializeTensorFlow(getAssets(), MODEL_FILE);\n        final Button button = (Button) findViewById(R.id.button);\n        button.setOnClickListener(new View.OnClickListener() {\n            public void onClick(View v) {\n                final EditText editNum1 = (EditText) findViewById(R.id.editNum1);\n                final EditText editNum2 = (EditText) findViewById(R.id.editNum2);\n                float num1 = Float.parseFloat(editNum1.getText().toString());\n                float num2 = Float.parseFloat(editNum2.getText().toString());\n                int[] i = {1};\n                int[] a = {((int) num1)};\n                int[] b = {((int) num2)};\n                //Setting input for variable a and b in our model.\n                inferenceInterface.fillNodeInt(\"a\",i,a);\n                inferenceInterface.fillNodeInt(\"b\",i,b);\n                //performing the inference and getting the output in variable c\n                inferenceInterface.runInference(new String[] {\"c\"});\n                //reading received output\n                int[] c = {0};\n                inferenceInterface.readNodeInt(\"c\", c);\n                //projecting to user.\n                final TextView textViewR = (TextView) findViewById(R.id.txtViewResult);\n                textViewR.setText(Integer.toString(c[0]));\n            }\n        });\n    }\n}\n```", "```py\nSystem.loadLibrary(\"tensorflow_inference\");\n```"]