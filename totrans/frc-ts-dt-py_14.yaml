- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Productionalizing Prophet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have made it through all of the chapters in this book, congratulations!
    You are well prepared to take on any forecasting assignments Prophet can handle.
    This final chapter will cover a few additional features that can be helpful in
    a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you’ll learn how to save a trained model for reuse later and
    you’ll learn how you can speed up model fitting when new data becomes available.
    To close out the chapter, you’ll discover a new series of interactive plots that
    can be used in a web dashboard to share your work with a wider audience. The topics
    covered in this chapter will be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Saving a model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating a fitted model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making interactive plots with Plotly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data files and code for the examples in this chapter can be found at [https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition](https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition).
  prefs: []
  type: TYPE_NORMAL
- en: Saving a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 11*](B19630_11.xhtml#_idTextAnchor728), *Managing Uncertainty Intervals*,
    you forecast the number of crimes per day in the city of Baltimore, using **Markov
    chain Monte Carlo** (**MCMC**) sampling. This was a long computation, and you
    were only using daily data. Had you used the Divvy hourly data instead, a dataset
    more than 10 times larger, the computation would have been even longer. And these
    two datasets are certainly smaller than many you’ll encounter in the real world.
    If Prophet provided no way to save your work, every time you trained a model,
    you would have to leave the model in your computer’s memory for as long as you
    wanted to use it.
  prefs: []
  type: TYPE_NORMAL
- en: Maybe you’re familiar with the `pickle` module in Python—this works great to
    save your trained models in `sklearn`, for example. However, Prophet uses Stan
    in the backend to build its models and these Stan objects don’t pickle well. Fortunately,
    Prophet includes some functions to serialize your model in JSON and re-open it
    later. So, once your model is trained, you can put it away for the day and bring
    it back later whenever you want to predict a future date.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use the Baltimore crime data again to see how to save your model. We’ll
    need to import pandas in order to read the `.csv` file; Prophet, of course, to
    build our model; and we’ll also need to import `json` to save and reopen the file.
    The functions to convert a model object into JSON and back again are imported
    from Prophet’s `serialize` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we’ll run through the now-familiar process of opening our data and training
    a model. We’re also discarding the outliers from the data, as we did in [*Chapter
    11*](B19630_11.xhtml#_idTextAnchor728), *Managing* *Uncertainty Intervals*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We’ve now got our trained model. Previously, you would have needed to keep your
    Python kernel running and the model in memory for as long as you wanted to access
    it. At the end of the day, you would want to save it, shut down your machine,
    and go home for the night, but you would lose all that work.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, you’ll use the `with` statement to create a context
    manager so that you can open a JSON file, and Python will automatically close
    it when you’re done. The `''w''` and `''r''` arguments used in the following statements
    merely stand for *write* and *read*. This code block uses Prophet’s `model_to_json`
    function to convert the `model` object into a JSON file, and then it saves it
    to your hard drive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the file is saved, you can safely shut down Python. To convert the
    JSON file back into a `model` object, simply use the `json_to_model` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'With the model reloaded, you can use it just as you would any fitted model;
    for example, you can plot a forecast:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'With no `future` created, this is just the fitted model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – Baltimore crime forecast](img/Fig_14.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.1 – Baltimore crime forecast
  prefs: []
  type: TYPE_NORMAL
- en: Saving and re-opening your work can certainly be helpful, but the real value
    is when you keep a model around and every day update it with new data, as we’ll
    do next.
  prefs: []
  type: TYPE_NORMAL
- en: Updating a fitted model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forecasting is unique among predictive models in that the value of the data
    is its recency and each passing moment creates a new set of valuable data to use.
    A common situation with a forecast model is the need to refit it as more data
    comes in. The city of Baltimore, for example, may use the crime model to predict
    how many crimes they might expect to happen tomorrow, so as to better place their
    officers in advance. Once tomorrow arrives, they can record the actual data, retrain
    their model, and predict for the next day.
  prefs: []
  type: TYPE_NORMAL
- en: Prophet is unable to handle online data, which means it cannot add a single
    new data observation and quickly update the model. Prophet must be trained offline—the
    new observation will be added to the existing data and the model will be completely
    retrained. But it doesn’t have to be completely retrained from scratch and the
    following technique will save a lot of time when retraining.
  prefs: []
  type: TYPE_NORMAL
- en: Prophet is essentially an optimization problem. Deep in the code are some settings
    to pick a set of initial parameters that Prophet believes will be close to the
    actual parameters needed to model the forecast curve. It then creates its curve,
    measures the error with existing data points, updates the parameters to reduce
    the error, and repeats.
  prefs: []
  type: TYPE_NORMAL
- en: Many hundreds or thousands of iterations may occur as Prophet attempts to get
    closer and closer to the best set of parameters. You can greatly speed up this
    optimization problem by taking the already-optimized parameters from yesterday’s
    model and using them as better initializations for today’s model. The assumption
    is that today’s data point will not dramatically change the overall model, which
    is generally a very good assumption. Let’s see how this technique works.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll begin by creating a DataFrame of the Baltimore crime data with the final
    observation removed. This is *yesterday’s* data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we’ll fit `model1` on this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The city of Baltimore could use this model to make a prediction about the next
    day’s activity, for example. Now, let’s say that the next day has arrived; we
    record the day’s crime level and want to update our model with `df`, *today’s*
    data, which has that final data point included. Let’s first do it from scratch
    and use the IPython `timeit` magic function to see how long it takes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'On my current machine, as I write this, the process took about 865 milliseconds
    according to the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s do it again, but instead of starting from scratch, we’ll give Prophet
    a *warm start* by passing it the parameters from yesterday’s model for initialization.
    We first need to define a class to format those parameters correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This class simply opens up the `model.params` dictionary and saves the relevant
    values in a new dictionary formatted as the Stan backend requires. We now use
    this class to extract the parameters from `model1` and pass this initialization
    to the `fit` method, again timing the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'When I run that command, I see more than a 4x improvement in training speed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 0.195 seconds compared to 0.865 seconds is a dramatic improvement. The amount
    of time saved depends on many factors and will often vary even when you repeat
    the experiment again.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one caveat with this method though: if the locations of changepoints
    change, the updated model may actually take *longer* to fit than just fitting
    from scratch. For these reasons, this method works best when adding a very small
    amount of new data relative to the existing data, as we did here by adding one
    day to several years of data.'
  prefs: []
  type: TYPE_NORMAL
- en: With MAP estimation, as we just did in the previous example, each iteration
    is an optimization problem. This means that better initialization will speed things
    up considerably. With MCMC sampling, however, each iteration must fully run through
    each link in the Markov chain (refer back to [*Chapter 11*](B19630_11.xhtml#_idTextAnchor728),
    *Managing Uncertainty Intervals*, for a review of the difference between MAP estimation
    and MCMC sampling).
  prefs: []
  type: TYPE_NORMAL
- en: What this means is that warm-starting will speed up MAP estimation considerably
    but will not speed up MCMC sampling. Warm-starting will, however, increase the
    quality of each Markov chain iteration. So, if you do a warm start with MCMC sampling,
    you can probably get away with fewer `mcmc_samples` without a significant reduction
    in result quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'This reduction in `mcmc_samples` creates an opportunity to speed up MCMC sampling
    on any new model. The idea is to train an initial model with MAP estimation, and
    then use that model to warm start a model with MCMC sampling, but using fewer
    `mcmc_samples` than you would otherwise choose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we created an initial `model1` using MAP estimation
    and all data. We then used the parameters from `model1` to warm start `model2`,
    which uses MCMC sampling, but only `mcmc_samples=200`, instead of the value of
    `300` we chose in [*Chapter 11*](B19630_11.xhtml#_idTextAnchor728), *Managing
    Uncertainty Intervals*. This will result in an MCMC-sampled model with roughly
    the same performance as earlier but trained in two-thirds of the time.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, warm starting with MAP estimation (that is, when `mcmc_samples=0`)
    will speed up your model training. Warm starting will not speed up a model when
    `mcmc_samples` is greater than 0 though, but in this case, you can quickly train
    a model with MAP estimation and then warm start your model with `mcmc_samples`
    set to a reduced value, without losing much quality. Now, let’s learn how to use
    Prophet to make interactive plots.
  prefs: []
  type: TYPE_NORMAL
- en: Making interactive plots with Plotly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final section, we’ll use the Plotly library to build some interactive
    plots. **Plotly** is a completely separate visualization package from the **Matplotlib**
    package, which we’ve been using throughout this book. A plot made with Plotly
    is richly interactive, allowing tooltips on mouse hover, zooming in and out of
    a plot, and all sorts of other interactivities.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re familiar with Tableau or Power BI, Plotly brings similar interactivity
    to Python. Additionally, the Plotly team also built **Dash**, a library for creating
    web-based dashboards. A full tutorial for creating such a dashboard is beyond
    the scope of this book, but I encourage you to learn about this valuable tool
    if you would like to share your Prophet forecasts with a wide audience.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prophet does not automatically install Plotly as a dependency, so before we
    begin, you will need to install it on your machine. It is a simple process and
    can be accomplished through either `conda` or `pip`. Here is the `conda` installation
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have not installed Anaconda or Miniconda though, you will have to use
    `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If you tend to work in Jupyter Notebook or JupyterLab, you will also want to
    install some support packages. This can be done through `conda`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If you do not have `conda`, you may also use `pip` instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have trouble with any of these commands, the best resource is Plotly’s
    own documentation: [https://plotly.com/python/getting-started/](https://plotly.com/python/getting-started/).'
  prefs: []
  type: TYPE_NORMAL
- en: You have already learned about many of the plotting functions in Prophet’s `plot`
    package throughout the examples in this book. There are four functions that we
    haven’t touched on yet; these take many of the same keywords as the Matplotlib
    counterparts you have learned already but output a Plotly chart instead.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This book will contain static images of Plotly plots, but if you run the example
    code in a Jupyter notebook, you’ll be able to manipulate the image in a richly
    interactive environment.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate these tools, let’s use the Divvy data again, and use temperature
    as an extra regressor. We won’t be using Matplotlib at all in this section, so
    no need to import it. We’ve already got pandas and Prophet imported from the previous
    sections, but we’ll need to make a few more imports here.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you recall from [*Chapter 9*](B19630_09.xhtml#_idTextAnchor599), *Including
    Additional Regressors*, we artificially reduced our training data by 2 weeks so
    that we could forecast 2 weeks ahead while using weather conditions as additional
    regressors. We’ll do that again here, so we need to import `timedelta` to help
    out. Most importantly though, we’ll import `plotly.offline` and initialize notebook
    mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s read in our data and put it into a DataFrame. We’ll only use one
    additional regressor in this example, `temperature`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we just build our model as before. We create a regressor for temperature,
    then fit the model on the data while excluding the final 2 weeks. We next make
    a future forecast of 2 weeks, using those unfitted 2 weeks of `temperature` data
    in the `future` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, this should all be a review (except for importing and initializing
    Plotly). But now, we’ll import those final four functions from the `plot` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Let’s run through these one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Plotly forecast plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First up is `plot_plotly`. To use this function, you simply pass in the model
    and the forecast. I’m also including the `trend=True` argument to include the
    trend line in the plot. You could also add `changepoints=True`, and it would completely
    mimic the `add_changepoints_to_plot` Matplotlib function. The `py.iplot(fig)`
    line is analogous to Matplotlib’s `plt.show()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This screenshot also displays the tooltip shown on hovering over the point
    for **May** **10, 2015**:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure \uFEFF\uFEFF14.2 – Plotly plot](img/Fig_14.2.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – Plotly plot
  prefs: []
  type: TYPE_NORMAL
- en: Plotly components plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next up, we’ll look at the Plotly components plot. This is much the same as
    the Matplotlib version, but it also includes interactivity. I’m also including
    the `figsize` argument to reduce the size of this one a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This plot shows the same subplots as `plot_components`:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 14.3 – P\uFEFF\uFEFFlotly components plot](img/Fig_14.3.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 – Plotly components plot
  prefs: []
  type: TYPE_NORMAL
- en: Plotly single component plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I wanted to use this Divvy data so that we could use the extra temperature
    regressor. We could have plotted any of the subplots in *Figure 14**.3* using
    this next function, but all of them can be handled with other functions, except
    for extra regressors. Plotting those alone requires the use of the `plot_forecast_components_plotly`
    function. Here, we pass in the `''``temp''` component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As with the other plots in this section, a static image does not do them justice.
    Plotly was intended to be used in an interactive environment; these plots beg
    to be placed on a dashboard, not printed in a book. Here, I’m showing a hover
    tooltip again:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 14.4 –\uFEFF\uFEFF Plotly temperature plot](img/Fig_14.4.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 14.4 – Plotly temperature plot
  prefs: []
  type: TYPE_NORMAL
- en: Plotly seasonality plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the final Plotly function, we’ll plot the yearly seasonality using the `plot_seasonality_plotly`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The Plotly toolbar has been left out of the components plot to save space but
    is included in all the others; you can see it at the upper right of *Figures 14.2*,
    *14.4*, and *14.5*. In the following seasonality plot, I’ve used the **Toggle
    Spike Lines** and **Compare Data** buttons from this toolbar to add further information
    to the hover tooltip, seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 14.5 – Plotly seasonality \uFEFFplot](img/Fig_14.5.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Plotly seasonality plot
  prefs: []
  type: TYPE_NORMAL
- en: I strongly encourage you to explore these plots in a Jupyter notebook, and if
    you find them useful, consider putting them together in a dashboard using Dash.
    There are plenty of tutorials available online.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This last chapter in the book was the most optional of all of them, but for
    those of you who often work in a production environment, these tools will be invaluable.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned how to save a model to your hard drive using JSON
    serialization, so you can share it or open it up later without requiring the model
    to be retrained. You also learned how to update a model that has already been
    fitted, another procedure designed to save you time. Finally, you examined a new
    plot format, an impressive tool to make your plots interactive in a browser, and
    hopefully, you saw the potential of packaging this information into a dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Together, what you learned in this chapter will help you to update your model
    as time progresses and new data comes in, and share that model via live, web-based
    interactive dashboards.
  prefs: []
  type: TYPE_NORMAL
