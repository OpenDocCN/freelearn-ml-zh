["```py\n    mat_A <- matrix(rbinom(n = 40, size = 100, prob = 0.4),nrow = 10, ncol=4)\n    mat_B <- matrix(rbinom(n = 20, size = 100, prob = 0.4),nrow = 4, ncol=5)\n    ```", "```py\n    list_of_matrices <- list(mat_A = mat_A, mat_B =mat_B)\n    ```", "```py\n    A <- list_of_matrices[[\"mat_A\"]][4,2]\n    B <- list_of_matrices[[\"mat_B\"]][2,1]\n    ```", "```py\n    list_of_matrices[[\"mat_A\"]][2,1] - (A*B)\n    ```", "```py\n    ## [1] -1554\n    ```", "```py\n    library(dplyr)\n    library(tidyr)\n    Warning: package 'tidyr' was built under R version 3.2.5\n    ```", "```py\n    df <- tbl_df(df_bank_detail)\n    ```", "```py\n    df_wide <- df %>%\n      select(age, balance, duration, pdays) %>% \n      summarise_all(funs(min = min, \n                          q25 = quantile(., 0.25), \n                          median = median, \n                          q75 = quantile(., 0.75), \n                          max = max,\n                          mean = mean, \n                          sd = sd))\n    ```", "```py\n    dim(df_wide)\n    ## [1]  1 28\n    ```", "```py\n    df_stats_tidy <- df_wide %>% gather(stat, val) %>%\n      separate(stat, into = c(\"var\", \"stat\"), sep = \"_\") %>%\n      spread(stat, val) %>%\n      select(var,min, q25, median, q75, max, mean, sd) # reorder columns\n    print(df_stats_tidy)\n    ```", "```py\n    ## # A tibble: 4 x 8\n    ##        var   min   q25 median   q75    max       mean         sd\n    ## *    <chr> <dbl> <dbl>  <dbl> <dbl>  <dbl>      <dbl>      <dbl>\n    ## 1      age    18    33     39    48     95   40.93621   10.61876\n    ## 2  balance -8019    72    448  1428 102127 1362.27206 3044.76583\n    ## 3 duration     0   103    180   319   4918  258.16308  257.52781\n    ## 4    pdays    -1    -1     -1    -1    871   40.19783  100.12875\n    ```", "```py\n    library(ggplot2)\n    library(cowplot)\n    ```", "```py\n    df <- read.csv(\"bank-additional-full.csv\",sep=';')\n    ```", "```py\n    plot_grid_numeric <- function(df,list_of_variables,ncols=2){\n      plt_matrix<-list()\n      i<-1\n      for(column in list_of_variables){\n        plt_matrix[[i]]<-ggplot(data=df,aes_string(x=column)) + \n          geom_density(fill=\"red\",alpha =0.5)  +\n          ggtitle(paste(\"Density Plot for variable:\",column)) + theme_bw()\n        i<-i+1\n      }\n      plot_grid(plotlist=plt_matrix,ncol=2)\n    }\n    ```", "```py\n    plot_grid_numeric(df,c(\"campaign\",\"pdays\",\"previous\",\"emp.var.rate\"),2)\n    ```", "```py\n    plot_grid_numeric <- function(df,list_of_variables,ncols=2){\n      plt_matrix<-list()\n      i<-1\n      for(column in list_of_variables){\n        plt_matrix[[i]]<-ggplot(data=df,aes_string(y=column)) + \n          geom_boxplot(outlier.colour=\"black\") +\n          ggtitle(paste(\"Boxplot for variable:\",column)) + theme_bw()\n        i<-i+1\n      }\n      plot_grid(plotlist=plt_matrix,ncol=2)\n    }\n    plot_grid_numeric(df,c(\"campaign\",\"pdays\",\"previous\",\"emp.var.rate\"),2)\n    ```", "```py\n    library(ggplot2)\n    ```", "```py\n    ggplot(data = PM25, aes(x = PRES, y = pm2.5, color = hour)) +   geom_point()\n    ```", "```py\n    geom_smooth(method='auto',formula=y~x, colour = \"blue\", size =1)\n    ```", "```py\n    facet_wrap(~ month, nrow = 4)\n    ```", "```py\n    ggplot(data = PM25, aes(x = PRES, y = pm2.5, color = hour)) +      geom_point() +      geom_smooth(method='auto',formula=y~x, colour = \"blue\", size =1) +      facet_wrap(~ month, nrow = 4)\n    ```", "```py\n    library(dplyr)\n    library(lubridate)\n    library(tidyr)\n    library(ggplot2)\n    library(grid)\n    library(zoo)\n    ```", "```py\n    PM25$datetime <- with(PM25, ymd_h(sprintf('%04d%02d%02d%02d', year, month, day,hour)))\n    ```", "```py\n    PM25_subset <- na.omit(PM25[,c(\"datetime\",\"pm2.5\")])\n    ```", "```py\n    PM25_three_hour_pm25_avg <- rollapply(zoo(PM25_subset$pm2.5,PM25_subset$datetime), 3, mean)\n    ```", "```py\n    PM25_three_hour_pm25_avg <- as.data.frame(PM25_three_hour_pm25_avg)\n    PM25_three_hour_pm25_avg$timestamp <- row.names(PM25_three_hour_pm25_avg)\n    row.names(PM25_three_hour_pm25_avg) <- NULL\n    colnames(PM25_three_hour_pm25_avg) <- c(\"avg_pm25\",\"timestamp\")\n    PM25_three_hour_pm25_avg$pollution_level <- ifelse(PM25_three_hour_pm25_avg$avg_pm25 <= 35, 0,1)\n    PM25_three_hour_pm25_avg$timestamp <- as.POSIXct(PM25_three_hour_pm25_avg$timestamp, format= \"%Y-%m-%d %H:%M:%S\",tz=\"GMT\")\n    ```", "```py\n    PM25_for_class <- merge(PM25_three_hour_pm25_avg, PM25[,c(\"datetime\",\"TEMP\",\"DEWP\",\"PRES\",\"Iws\",\"cbwd\",\"Is\",\"Ir\")], by.x = \"timestamp\",by.y = \"datetime\")\n    ```", "```py\n    PM25_logit_model <- glm(pollution_level ~ DEWP + TEMP + Iws, data = PM25_for_class,family=binomial(link='logit'))\n    ```", "```py\n    summary(PM25_logit_model)\n    ```", "```py\n    Call:\n    glm(formula = pollution_level ~ DEWP + TEMP + Iws, family = binomial(link = \"logit\"), \n        data = PM25_for_class)\n    Deviance Residuals: \n        Min       1Q   Median       3Q      Max  \n    -2.4699  -0.5212   0.4569   0.6508   3.5824  \n    Coefficients:\n                  Estimate Std. Error z value Pr(>|z|)    \n    (Intercept)  2.5240276  0.0273353   92.34   <2e-16 ***\n    DEWP         0.1231959  0.0016856   73.09   <2e-16 ***\n    TEMP        -0.1028211  0.0018447  -55.74   <2e-16 ***\n    Iws         -0.0127037  0.0003535  -35.94   <2e-16 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    (Dispersion parameter for binomial family taken to be 1)\n        Null deviance: 49475  on 41754  degrees of freedom\n    Residual deviance: 37821  on 41751  degrees of freedom\n    AIC: 37829\n    Number of Fisher Scoring iterations: 5\n    ```", "```py\n    multiple_PM25_linear_model$coefficients\n    ```", "```py\n    (Intercept)        DEWP        TEMP         Iws \n    161.1512066   4.3841960  -5.1335111  -0.2743375\n    ```", "```py\n    multiple_PM25_linear_model$residuals\n    ```", "```py\n    25            26            27            28 \n      17.95294914   32.81291348   21.38677872   26.34105878 \n               29            30            31            32 \n    ```", "```py\n    multiple_PM25_linear_model$fitted.values\n    ```", "```py\n    25         26         27         28         29 \n    111.047051 115.187087 137.613221 154.658941 154.414781 \n            30         31         32         33         34 \n    ```", "```py\n    summary(multiple_PM25_linear_model)$r.squared\n    ```", "```py\n    [1] 0.2159579\n    ```", "```py\n    summary(multiple_PM25_linear_model)$fstatistic\n    ```", "```py\n        value     numdf     dendf \n     3833.506     3.000 41753.000 \n    ```", "```py\n    summary(multiple_PM25_linear_model)$coefficients[,4]\n    ```", "```py\n      (Intercept)          DEWP          TEMP           Iws \n     0.000000e+00  0.000000e+00  0.000000e+00 4.279601e-224\n    ```", "```py\n    df_copy <- df_new\n    ```", "```py\n    df_copy$MaxTemp2 <- df_copy$MaxTemp ^2\n    df_copy$MaxTemp3 <- df_copy$MaxTemp ^3\n    df_copy$MaxTemp_root <- sqrt(df_copy$MaxTemp)\n    df_copy$Rainfall2 <- df_copy$Rainfall ^2\n    df_copy$Rainfall3 <- df_copy$Rainfall ^3\n    df_copy$Rainfall_root <- sqrt(df_copy$Rainfall)\n    df_copy$Humidity3pm2 <- df_copy$Humidity3pm ^2\n    df_copy$Humidity3pm3 <- df_copy$Humidity3pm ^3\n    df_copy$Humidity3pm_root <- sqrt(df_copy$Humidity3pm)\n    ```", "```py\n    #Setting seed for reproducibility\n    set.seed(2019)\n    #Creating a list of indexes for the training dataset (70%)\n    train_index <- sample(seq_len(nrow(df_copy)),floor(0.7 * nrow(df_copy)))\n    #Split the data into test and train\n    train_new <- df_copy[train_index,]\n    test_new <- df_copy[-train_index,]\n    ```", "```py\n    model <- glm(RainTomorrow~., data=train_new ,family=binomial(link='logit'))\n    ```", "```py\n    print(\"Training data results -\")\n    pred_train <-factor(ifelse(predict(model,newdata=train_new,\n    type = \"response\") > 0.5,\"Yes\",\"No\"))\n    #Create the Confusion Matrix\n    train_metrics <- confusionMatrix(pred_train, train_new$RainTomorrow,positive=\"Yes\")\n    print(train_metrics)\n    ```", "```py\n    \"Training data results -\"\n    Confusion Matrix and Statistics\n              Reference\n    Prediction    No   Yes\n           No  58330  8650\n           Yes  3161  8906\n\n                   Accuracy : 0.8506          \n                     95% CI : (0.8481, 0.8531)\n        No Information Rate : 0.7779          \n        P-Value [Acc > NIR] : < 2.2e-16       \n\n                      Kappa : 0.5132          \n     Mcnemar's Test P-Value : < 2.2e-16       \n\n                Sensitivity : 0.5073          \n                Specificity : 0.9486          \n             Pos Pred Value : 0.7380          \n             Neg Pred Value : 0.8709          \n                 Prevalence : 0.2221          \n             Detection Rate : 0.1127          \n       Detection Prevalence : 0.1527          \n          Balanced Accuracy : 0.7279          \n\n           'Positive' Class : Yes \n    ```", "```py\n    print(\"Test data results -\")\n    pred_test <-factor(ifelse(predict(model,newdata=test_new,\n    type = \"response\") > 0.5,\"Yes\",\"No\"))\n    #Create the Confusion Matrix\n    test_metrics <- confusionMatrix(pred_test, test_new$RainTomorrow,positive=\"Yes\")\n    print(test_metrics)\n    ```", "```py\n    \"Test data results -\"\n    Confusion Matrix and Statistics\n              Reference\n    Prediction    No   Yes\n           No  25057  3640\n           Yes  1358  3823\n\n                   Accuracy : 0.8525          \n                     95% CI : (0.8486, 0.8562)\n        No Information Rate : 0.7797          \n        P-Value [Acc > NIR] : < 2.2e-16       \n\n                      Kappa : 0.5176          \n     Mcnemar's Test P-Value : < 2.2e-16       \n\n                Sensitivity : 0.5123          \n                Specificity : 0.9486          \n             Pos Pred Value : 0.7379          \n             Neg Pred Value : 0.8732          \n                 Prevalence : 0.2203          \n             Detection Rate : 0.1128          \n       Detection Prevalence : 0.1529          \n          Balanced Accuracy : 0.7304          \n\n           'Positive' Class : Yes             \n    ```", "```py\n    library(rpart)\n    ```", "```py\n    control = rpart.control(\n        minsplit = 15, \n        cp = 0.001)\n    ```", "```py\n    tree_model <- rpart(RainTomorrow~.,data=train, control = control)\n    ```", "```py\n    plotcp(tree_model)\n    ```", "```py\n    print(\"Training data results -\")\n    pred_train <- predict(tree_model,newdata = train,type = \"class\")\n    confusionMatrix(pred_train, train$RainTomorrow,positive=\"Yes\")\n    ```", "```py\n    \"Training data results -\"\n    Confusion Matrix and Statistics\n              Reference\n    Prediction    No   Yes\n           No  58494  9032\n           Yes  2997  8524\n\n                   Accuracy : 0.8478          \n                     95% CI : (0.8453, 0.8503)\n        No Information Rate : 0.7779          \n        P-Value [Acc > NIR] : < 2.2e-16       \n\n                      Kappa : 0.4979          \n     Mcnemar's Test P-Value : < 2.2e-16       \n\n                Sensitivity : 0.4855          \n                Specificity : 0.9513          \n             Pos Pred Value : 0.7399          \n             Neg Pred Value : 0.8662          \n                 Prevalence : 0.2221          \n             Detection Rate : 0.1078          \n       Detection Prevalence : 0.1457          \n          Balanced Accuracy : 0.7184          \n\n           'Positive' Class : Yes             \n    ```", "```py\n    print(\"Test data results -\")\n    pred_test <- predict(tree_model,newdata = test,type = \"class\")\n    confusionMatrix(pred_test, test$RainTomorrow,positive=\"Yes\")\n    ```", "```py\n    \"Test data results -\"\n    Confusion Matrix and Statistics\n              Reference\n    Prediction    No   Yes\n           No  25068  3926\n           Yes  1347  3537\n\n                   Accuracy : 0.8444          \n                     95% CI : (0.8404, 0.8482)\n        No Information Rate : 0.7797          \n        P-Value [Acc > NIR] : < 2.2e-16       \n\n                      Kappa : 0.4828          \n     Mcnemar's Test P-Value : < 2.2e-16       \n\n                Sensitivity : 0.4739          \n                Specificity : 0.9490          \n             Pos Pred Value : 0.7242          \n             Neg Pred Value : 0.8646          \n                 Prevalence : 0.2203          \n             Detection Rate : 0.1044          \n       Detection Prevalence : 0.1442          \n          Balanced Accuracy : 0.7115          \n\n           'Positive' Class : Yes \n    ```", "```py\n    library(randomForest)\n    ```", "```py\n    rf_model <- randomForest(RainTomorrow ~ . , data = train, ntree = 500,                                             importance = TRUE, \n                                                maxnodes=60)\n    ```", "```py\n    print(\"Training data results -\")\n    pred_train <- predict(rf_model,newdata = train,type = \"class\")\n    confusionMatrix(pred_train, train$RainTomorrow,positive=\"Yes\")\n    ```", "```py\n    \"Training data results -\"\n    Confusion Matrix and Statistics\n              Reference\n    Prediction    No   Yes\n           No  59638 10169\n           Yes  1853  7387\n\n                   Accuracy : 0.8479          \n                     95% CI : (0.8454, 0.8504)\n        No Information Rate : 0.7779          \n        P-Value [Acc > NIR] : < 2.2e-16       \n\n                      Kappa : 0.4702          \n     Mcnemar's Test P-Value : < 2.2e-16       \n\n                Sensitivity : 0.42077         \n                Specificity : 0.96987         \n             Pos Pred Value : 0.79946         \n             Neg Pred Value : 0.85433         \n                 Prevalence : 0.22210         \n             Detection Rate : 0.09345         \n       Detection Prevalence : 0.11689         \n          Balanced Accuracy : 0.69532         \n\n           'Positive' Class : Yes \n    ```", "```py\n    print(\"Test data results -\")\n    pred_test <- predict(rf_model,newdata = test,type = \"class\")\n    confusionMatrix(pred_test, test$RainTomorrow,positive=\"Yes\")\n    ```", "```py\n    \"Test data results -\"\n    Confusion Matrix and Statistics\n              Reference\n    Prediction    No   Yes\n           No  25604  4398\n           Yes   811  3065\n\n                   Accuracy : 0.8462          \n                     95% CI : (0.8424, 0.8501)\n        No Information Rate : 0.7797          \n        P-Value [Acc > NIR] : < 2.2e-16       \n\n                      Kappa : 0.4592          \n     Mcnemar's Test P-Value : < 2.2e-16       \n\n                Sensitivity : 0.41069         \n                Specificity : 0.96930         \n             Pos Pred Value : 0.79076         \n             Neg Pred Value : 0.85341         \n                 Prevalence : 0.22029         \n             Detection Rate : 0.09047         \n       Detection Prevalence : 0.11441         \n          Balanced Accuracy : 0.69000         \n\n           'Positive' Class : Yes  \n    ```", "```py\n    PM25 <- read.csv(\"PRSA_data_2010.1.1-2014.12.31.csv\")\n    ```", "```py\n    library(caret)\n    cbwd_one_hot <- dummyVars(\" ~ cbwd\", data = PM25) \n    ```", "```py\n    cbwd_one_hot <- data.frame(predict(cbwd_one_hot, newdata = PM25))\n    ```", "```py\n    PM25$cbwd <- NULL\n    ```", "```py\n    PM25 <- cbind(PM25, cbwd_one_hot)\n    ```", "```py\n    head(PM25)\n    ```", "```py\n    ##   No year month day hour pm2.5 DEWP TEMP PRES   Iws Is Ir cbwd.cv cbwd.NE\n    ## 1  1 2010     1   1    0    NA  -21  -11 1021  1.79  0  0       0       0\n    ## 2  2 2010     1   1    1    NA  -21  -12 1020  4.92  0  0       0       0\n    ## 3  3 2010     1   1    2    NA  -21  -11 1019  6.71  0  0       0       0\n    ## 4  4 2010     1   1    3    NA  -21  -14 1019  9.84  0  0       0       0\n    ## 5  5 2010     1   1    4    NA  -20  -12 1018 12.97  0  0       0       0\n    ## 6  6 2010     1   1    5    NA  -19  -10 1017 16.10  0  0       0       0\n    ##   cbwd.NW cbwd.SE\n    ## 1       1       0\n    ## 2       1       0\n    ## 3       1       0\n    ## 4       1       0\n    ## 5       1       0\n    ## 6       1       0\n    ```", "```py\n    library(mlbench)\n    library(dplyr)\n    library(caret)\n    ```", "```py\n    data(PimaIndiansDiabetes)\n    df<-PimaIndiansDiabetes\n    ```", "```py\n    set.seed(2019)\n    ```", "```py\n    train_control = trainControl(method = \"repeatedcv\",                                number=5,                               repeats = 10,   savePredictions = TRUE,verboseIter = TRUE)\n    ```", "```py\n    parameter_values = expand.grid(mtry=c(3,4,5))\n    ```", "```py\n    model_rf_kfold<- train(diabetes~., data=df, trControl=train_control,                    method=\"rf\",  metric= \"Accuracy\", tuneGrid = parameter_values)\n    ```", "```py\n    print(paste(\"Average Accuracy :\",mean(model_rf_kfold$resample$Accuracy)))\n    print(paste(\"Std. Dev Accuracy :\",sd(model_rf_kfold$resample$Accuracy)))\n    ```", "```py\n    plot(model_rf_kfold)\n    ```", "```py\n    library(mlbench)\n    ```", "```py\n    data(BostonHousing)\n    df<-BostonHousing\n    ```", "```py\n    train <- df[1:400,]\n    test <- df[401:dim(df)[1],]\n    ```", "```py\n    model <- lm(medv~crim+zn+indus+chas+\n     nox+rm+age+dis+rad+tax,data=train)\n    ```", "```py\n    #' @get /predict_data\n    function(crim,zn,indus,chas,nox,rm,age,dis,rad,tax){\n    ```", "```py\n      crim <- as.numeric(crim)\n      zn <- as.numeric(zn)\n      indus <- as.numeric(indus)\n      chas <- as.factor(chas)\n      nox <- as.numeric(nox)\n      rm <- as.numeric(rm)\n      age <- as.numeric(age)\n      dis <- as.numeric(dis)\n      rad <- as.numeric(rad)\n      tax <- as.numeric(tax)\n    ```", "```py\n      sample <- data.frame(crim  = crim,  zn  = zn,  indus  = indus,  \n                           chas  = chas,  nox  = nox,  rm  = rm,  \n                           age  = age,  dis  = dis,  rad  = rad,  \n                           tax  = tax )\n    ```", "```py\n      y_pred<-predict(model,newdata=sample)\n\n      list(Answer=y_pred)\n    }\n    ```", "```py\n    library(mlbench)\n    data(BostonHousing)\n    df<-BostonHousing\n    train <- df[1:400,]\n    test <- df[401:dim(df)[1],]\n    model <- lm(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax,data=train)\n    #' @get /predict_data\n    function(crim,zn,indus,chas,nox,rm,age,dis,rad,tax){\n\n      crim <- as.numeric(crim)\n      zn <- as.numeric(zn)\n      indus <- as.numeric(indus)\n      chas <- as.factor(chas)\n      nox <- as.numeric(nox)\n      rm <- as.numeric(rm)\n      age <- as.numeric(age)\n      dis <- as.numeric(dis)\n      rad <- as.numeric(rad)\n      tax <- as.numeric(tax)\n\n      sample <- data.frame(crim  = crim,  zn  = zn,  indus  = indus,  \n                           chas  = chas,  nox  = nox,  rm  = rm,  \n                           age  = age,  dis  = dis,  rad  = rad,  \n                           tax  = tax )\n\n      y_pred<-predict(model,newdata=sample)\n\n      list(Answer=y_pred)\n    }\n    ```", "```py\n    library(plumber)\n    ```", "```py\n    r <- plumb(model.r)\n    ```", "```py\n    http://127.0.0.1:8080/\n    ```", "```py\n    {\"Answer\":[22.5813]}\n    ```", "```py\n    multilabel.lrn3 = makeLearner(\"multilabel.rFerns\")\n    multilabel.lrn4 = makeLearner(\"multilabel.randomForestSRC\")\n    multilabel.lrn3\n    ```", "```py\n    ## Learner multilabel.rFerns from package rFerns\n    ## Type: multilabel\n    ## Name: Random ferns; Short name: rFerns\n    ## Class: multilabel.rFerns\n    ## Properties: numerics,factors,ordered\n    ## Predict-Type: response\n    ## Hyperparameters:\n    ```", "```py\n    lrn = makeLearner(\"classif.C50\", predict.type = \"prob\")\n    multilabel.lrn1 = makeMultilabelBinaryRelevanceWrapper(lrn)\n    multilabel.lrn2 = makeMultilabelNestedStackingWrapper(lrn)\n    ```", "```py\n    lrn\n    ```", "```py\n    ## Learner classif.C50 from package C50\n    ## Type: classif\n    ## Name: C50; Short name: C50\n    ## Class: classif.C50\n    ## Properties: twoclass,multiclass,numerics,factors,prob,missings,weights\n    ## Predict-Type: prob\n    ## Hyperparameters:\n    ```", "```py\n    multilabel.lrn1\n    ```", "```py\n    ## Learner multilabel.binaryRelevance.classif.C50 from package C50\n    ## Type: multilabel\n    ## Name: ; Short name: \n    ## Class: MultilabelBinaryRelevanceWrapper\n    ## Properties: numerics,factors,missings,weights,prob,twoclass,multiclass\n    ## Predict-Type: prob\n    ## Hyperparameters:\n    ```", "```py\n    df_nrow <- nrow(df_scene)\n    df_all_index <- c(1:df_nrow)\n    train_index <- sample(1:df_nrow, 0.7*df_nrow)\n    test_index <- setdiff(df_all_index,train_index)\n    scene_classi_mod = train(multilabel.lrn1, scene.task, subset = train_index)\n    ```", "```py\n    scene_classi_mod\n    ```", "```py\n    ## Model for learner.id=multilabel.binaryRelevance.classif.C50; learner.class=MultilabelBinaryRelevanceWrapper\n    ## Trained on: task.id = multi; obs = 1684; features = 294\n    ## Hyperparameters:\n    ```", "```py\n    pred = predict(scene_classi_mod, task = scene.task, subset = test_index)\n    names(as.data.frame(pred))\n    ```", "```py\n    ##  [1] \"id\"                   \"truth.Beach\"          \"truth.Sunset\"        \n    ##  [4] \"truth.FallFoliage\"    \"truth.Field\"          \"truth.Mountain\"      \n    ##  [7] \"truth.Urban\"          \"prob.Beach\"           \"prob.Sunset\"         \n    ## [10] \"prob.FallFoliage\"     \"prob.Field\"           \"prob.Mountain\"       \n    ## [13] \"prob.Urban\"           \"response.Beach\"       \"response.Sunset\"     \n    ## [16] \"response.FallFoliage\" \"response.Field\"       \"response.Mountain\"   \n    ## [19] \"response.Urban\"\n    ```", "```py\n    MEASURES = list(multilabel.hamloss, multilabel.f1, multilabel.subset01, multilabel.acc, multilabel.tpr, multilabel.ppv)\n    performance(pred, measures = MEASURES)\n    ```", "```py\n    ##  multilabel.hamloss       multilabel.f1 multilabel.subset01 \n    ##           0.1258645           0.5734901           0.5532503 \n    ##      multilabel.acc      multilabel.tpr      multilabel.ppv \n    ##           0.5412633           0.6207930           0.7249104\n    ```", "```py\n    listMeasures(\"multilabel\")\n    ```", "```py\n    ##  [1] \"featperc\"            \"multilabel.tpr\"      \"multilabel.hamloss\" \n    ##  [4] \"multilabel.subset01\" \"timeboth\"            \"timetrain\"          \n    ##  [7] \"timepredict\"         \"multilabel.ppv\"      \"multilabel.f1\"      \n    ## [10] \"multilabel.acc\"\n    ```", "```py\n    rdesc = makeResampleDesc(method = \"CV\", stratify = FALSE, iters = 3)\n    r = resample(learner = multilabel.lrn1, task = scene.task, resampling = rdesc,measures = list(multilabel.hamloss), show.info = FALSE)\n    r\n    ```", "```py\n    ## Resample Result\n    ## Task: multi\n    ## Learner: multilabel.binaryRelevance.classif.C50\n    ## Aggr perf: multilabel.hamloss.test.mean=0.1335695\n    ## Runtime: 72.353\n    ```", "```py\n    getMultilabelBinaryPerformances(r$pred, measures = list(acc, mmce, auc))\n    ```", "```py\n    ##             acc.test.mean mmce.test.mean auc.test.mean\n    ## Beach           0.8608226     0.13917740     0.8372448\n    ## Sunset          0.9401745     0.05982551     0.9420085\n    ## FallFoliage     0.9081845     0.09181554     0.9008202\n    ## Field           0.8998754     0.10012464     0.9134458\n    ## Mountain        0.7710843     0.22891566     0.7622767\n    ## Urban           0.8184462     0.18155380     0.7837401\n    ```"]