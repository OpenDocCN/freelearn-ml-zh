<html><head></head><body><div><h1 class="header-title">Representing Data and Engineering Features</h1>
                
            
            
                
<p>In the last chapter, we built our very first supervised learning models and applied them to some classic datasets, such as the <strong>Iris</strong> and the <strong>Boston</strong> datasets. However, in the real world, data rarely comes in a neat <kbd>&lt;n_samples x n_features&gt;</kbd> <strong>feature matrix</strong> that is part of a pre-packaged database. Instead, it is our responsibility to find a way to represent the data in a meaningful way. The process of finding the best way to represent our data is known as <strong>feature engineering</strong>, and it is one of the main tasks of data scientists and machine learning practitioners trying to solve real-world problems.</p>
<p>I know you would rather jump right to the end and build the deepest neural network mankind has ever seen. ...</p></div>



  
<div><h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>You can refer to the code for this chapter from the following link: <a href="https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter04">https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter04</a>.</p>
<p>Here is a summary of the software and hardware requirements:</p>
<ul>
<li>You will need OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).</li>
<li>You will need Python version 3.6 (any Python version 3.x will be fine).</li>
<li>You will need Anaconda Python 3 for installing Python and the required modules.</li>
<li>You can use any operating system—macOS, Windows, and Linux-based OSes, along with this book. We recommend you have at least 4 GB RAM in your system.</li>
<li>You don't need to have a GPU to run the code provided along with this book.</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Understanding feature engineering</h1>
                
            
            
                
<p>Believe it or not, how well a machine learning system can learn is mainly determined by the quality of the training data. Although every learning algorithm has its strengths and weaknesses, differences in performance often come down to the way the data is prepared or represented. Feature engineering can hence be understood as a tool for <strong>data representation</strong>. Machine learning algorithms try to learn a solution to a problem from sample data, and feature engineering asks: what is the best representation of the sample data to use for learning a solution to the problem?</p>
<p>Remember, a couple of chapters ago, we talked about the whole machine learning pipeline. There, we already mentioned feature extraction, but we ...</p></div>



  
<div><h1 class="header-title">Preprocessing data</h1>
                
            
            
                
<p>The more disciplined we are in handling our data, the better results we are likely to achieve in the end. The first step in this procedure is known as <strong>data preprocessing</strong>, and it comes in (at least) three different flavors:</p>
<ul>
<li><strong>Data formatting</strong>: The data may not be in a format that is suitable for us to work with; for example, the data might be provided in a proprietary file format, which our favorite machine learning algorithm does not understand.</li>
</ul>
<ul>
<li><strong>Data cleaning</strong>: The data may contain invalid or missing entries, which need to be cleaned up or removed.</li>
</ul>
<ul>
<li><strong>Data sampling</strong>: The data may be far too large for our specific purpose, forcing us to sample the data intelligently.</li>
</ul>
<p>Once the data has been preprocessed, we are ready for the actual feature engineering: to transform the preprocessed data to fit our specific machine learning algorithm. This step usually involves one or more of three possible procedures:</p>
<ul>
<li><strong>Scaling</strong>: Certain machine learning algorithms often require the data to be within a common range, such as to have zero mean and unit variance. Scaling is the process of bringing all features (which might have different physical units) into a common range of values.</li>
<li><strong>Decomposition</strong>: Datasets often have many more features than we could possibly process. Feature decomposition is the process of compressing data into a smaller number of highly informative data components.</li>
<li><strong>Aggregation</strong>: Sometimes, it is possible to group multiple features into a single, more meaningful one. For example, a database might contain the date and time for each user who logged into a web-based system. Depending on the task, this data might be better represented by simply counting the number of logins per user.</li>
</ul>
<p>Let's look at some of these processes in more detail.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Standardizing features</h1>
                
            
            
                
<p><strong>Standardization</strong> refers to the process of scaling the data to have zero mean and unit variance. This is a common requirement for a wide range of machine learning algorithms, which might behave badly if individual features do not fulfill this requirement. We could manually standardize our data by subtracting from every data point the mean value (<em>μ</em>) of all of the data and dividing that by the variance (<em>σ</em>) of the data; that is, for every feature <em>x</em>, we would compute <em>(x - μ) / σ</em>.</p>
<p>Alternatively, scikit-learn offers a straightforward implementation of this process in its <kbd>preprocessing</kbd> module.</p>
<p>Let's consider a 3 x 3 data matrix, <kbd>X</kbd>, standing for three data points (rows) with three arbitrarily chosen feature values each (columns): ...</p></div>



  
<div><h1 class="header-title">Normalizing features</h1>
                
            
            
                
<p>Similar to standardization, normalization is the process of scaling individual samples to have a unit norm. I'm sure you know that the norm stands for the length of a vector and can be defined in different ways. We discussed two of them in the previous chapter: the L1 norm (or Manhattan distance), and the L2 norm (or Euclidean distance).</p>
<p>In scikit-learn, our data matrix, <kbd>X</kbd>, can be normalized using the <kbd>normalize</kbd> function, and the <kbd>l1</kbd> norm is specified by the <kbd>norm</kbd> keyword:</p>
<pre>In [5]: X_normalized_l1 = preprocessing.normalize(X, norm='l1')<br/>...     X_normalized_l1<br/>Out[5]: array([[ 0.2, -0.4, 0.4],<br/>               [ 1. , 0. , 0. ],<br/>               [ 0. , 0.5, -0.5]])</pre>
<p>Similarly, the L2 norm can be computed by specifying <kbd>norm='l2'</kbd>:</p>
<pre>In [6]: X_normalized_l2 = preprocessing.normalize(X, norm='l2')<br/>...     X_normalized_l2<br/>Out[6]: array([[ 0.33333333, -0.66666667, 0.66666667],<br/>               [ 1. , 0. , 0. ],<br/>               [ 0. , 0.70710678, -0.70710678]])</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Scaling features to a range</h1>
                
            
            
                
<p>An alternative to scaling features to zero mean and unit variance is to get features to lie between a given minimum and maximum value. Often, these values are zero and one, so that the maximum absolute value of each feature is scaled to unit size. In scikit-learn, this can be achieved using <kbd>MinMaxScaler</kbd>:</p>
<pre>In [7]: min_max_scaler = preprocessing.MinMaxScaler()...     X_min_max = min_max_scaler.fit_transform(X)...     X_min_maxOut[7]: array([[ 0.33333333, 0. , 1. ],               [ 1. , 0.66666667, 0.33333333],               [ 0. , 1. , 0. ]])</pre>
<p>By default, the data will be scaled to fall within 0 and 1. We can specify different ranges by passing a keyword argument, <kbd>feature_range</kbd>, to the <kbd>MinMaxScaler</kbd> constructor:</p>
<pre>In [8]: min_max_scaler = preprocessing.MinMaxScaler(feature_range ...</pre></div>



  
<div><h1 class="header-title">Binarizing features</h1>
                
            
            
                
<p>Finally, we might find ourselves not caring too much about the exact feature values of the data. Instead, we might just want to know whether a feature is present or absent. Binarizing the data can be achieved by thresholding the feature values. Let's quickly remind ourselves of our feature matrix, <kbd>X</kbd>:</p>
<pre>In [9]: X<br/>Out[9]: array([[ 1., -2., 2.],<br/>               [ 3., 0., 0.],<br/>               [ 0., 1., -1.]])</pre>
<p>Let's assume that these numbers represent the thousands of dollars in our bank accounts. If there are more than 0.5 thousand dollars in the account, we consider the person rich, which we represent with a 1. Otherwise, we put a 0. This is akin to thresholding the data with <kbd>threshold=0.5</kbd>:</p>
<pre>In [10]: binarizer = preprocessing.Binarizer(threshold=0.5)<br/>...      X_binarized = binarizer.transform(X)<br/>...      X_binarized<br/>Out[10]: array([[ 1., 0., 1.],<br/>                [ 1., 0., 0.],<br/>                [ 0., 1., 0.]])</pre>
<p>The result is a matrix made up entirely of ones and zeros.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Handling the missing data</h1>
                
            
            
                
<p>Another common requirement in feature engineering is the handling of missing data. For example, we might have a dataset that looks like this:</p>
<pre>In [11]: from numpy import nan...      X = np.array([[ nan, 0,   3 ],...                    [ 2,   9,  -8 ],...                    [ 1,   nan, 1 ],...                    [ 5,   2,   4 ],...                    [ 7,   6,  -3 ]])</pre>
<p>Most machine learning algorithms cannot handle the <strong>Not a Number</strong> (<strong>NAN</strong>) values (<kbd>nan</kbd> in Python). Instead, we first have to replace all of the <kbd>nan</kbd> values with some appropriate fill values. This is known as the <strong>imputation</strong> of missing values.</p>
<p>Three different strategies to impute missing values are offered by scikit-learn:</p>
<ul>
<li><kbd>mean</kbd>: Replaces all of the <kbd>nan</kbd> values with a mean value along a specified axis of the matrix (default: <em>axis = 0</em>)</li>
<li><kbd>median</kbd>: Replaces all ...</li></ul></div>



  
<div><h1 class="header-title">Understanding dimensionality reduction</h1>
                
            
            
                
<p>Datasets often have many more features than we could possibly process. For example, let's say our job was to predict a country's poverty rate. We would probably start by matching a country's name with its poverty rate, but that would not help us to predict the poverty rate of a new country. So, we start thinking about the possible causes of poverty. But how many possible causes of poverty are there? Factors might include a country's economy, lack of education, high divorce rate, overpopulation, and so on. If each one of these causes was a feature used to help to predict the poverty rate, we would end up with a countless number of features. If you're a mathematician, you might think of these features as axes in a high-dimensional space, and every country's poverty rate is then a single point in this high-dimensional space.</p>
<p>If you're not a mathematician, it might help to start small. Let's say, we first look at only two features: a country's <strong>Gross Domestic Product</strong> (<strong>GDP</strong>) and the number of citizens. We interpret the GDP as the <em>x axis</em>, and the number of citizens as the <em>y axis</em>, in a 2D space. Then, we look at the first country. It has a small GDP and an average number of citizens. We draw a point in the <em>x-y</em> plane that represents this country. We add a second, third, and fourth country. The fourth country just happens to have both a high GDP and a large number of citizens. Hence, our four data points might be spread across the <em>x-y</em> plane much like in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-823 image-border" src="img/ecfc1cd0-8e6f-4658-8f61-ac5429753231.png" style="width:30.75em;height:12.92em;" width="1594" height="670"/></p>
<p>However, what happens if we start adding a third feature, such as the country's divorce rate, to our analysis? This would add a third axis to our plot (<em>z axis</em>). Suddenly, we find that the data no longer spreads very nicely across the <em>x-y-z</em> cube, as most of the cube remains empty. While in two dimensions, it seemed like we had most of the <em>x-y</em> square covered, in three dimensions, we would need many more data points to fill the void between the data points 1 to 3 and the lonely data point 4 in the upper-right corner.</p>
<p>This problem is also known as the <strong>curse of dimensionality</strong>: the number of data points needed to fill the available space grows exponentially with the number of dimensions (or plot axes). If a classifier is not fed with data points that span the entire feature space (such as shown in the preceding cube example), the classifier will not know what to do once a new data point is presented that lies far away from all of the previously encountered data points.</p>
<p>The curse of dimensionality means that, after a certain number of features (or dimensions), the performance of the classifier will start degrading. Let's try to understand this. More features essentially mean that more variations in the dataset can be accounted for. But taking into account more than the required features will cause the classifier to even take into account any outliers or to overfit the dataset. Hence, the performance of the classifier will start degrading rather than improving:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-824 image-border" src="img/b1c75237-aa2d-4f6f-b2d4-f91c27700030.png" style="width:24.75em;height:14.42em;" width="1079" height="630"/></p>
<p>But, how do we find this seemingly optimal number of dimensions for our dataset?</p>
<p>This is where dimensionality reduction comes in to play. These are a family of techniques that allow us to find a compact representation of our high-dimensional data, without losing too much information.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Implementing Principal Component Analysis (PCA) in OpenCV</h1>
                
            
            
                
<p>One of the most common dimensionality reduction techniques is called <strong>PCA</strong>.</p>
<p>Similar to the 2D and 3D examples shown earlier, we can think of an image as a point in a high-dimensional space. If we flatten a 2D grayscale image of height <em>m</em> and width <em>n</em> by stacking all of the columns, we get a (feature) vector of length <em>m x n x 1</em>. The value of the <em>i</em><sup>th</sup> element in this vector is the grayscale value of the <em>i</em><sup>th</sup> pixel in the image. Now, imagine we would like to represent every possible 2D grayscale image with these exact dimensions. How many images would that give?</p>
<p>Since grayscale pixels usually take values between 0 and 255, there are a total of 256 raised to the power of <em>m x</em> <em>n</em> images. Chances ...</p></div>



  
<div><h1 class="header-title">Implementing independent component analysis (ICA)</h1>
                
            
            
                
<p>Other useful dimensionality reduction techniques that are closely related to PCA are provided by scikit-learn, but not OpenCV. We mention them here for the sake of completeness. ICA performs the same mathematical steps as PCA, but it chooses the components of the decomposition to be as independent as possible from each other, rather than per predictor as in PCA.</p>
<p class="mce-root"/>
<p>In scikit-learn, ICA is available from the <kbd>decomposition</kbd> module:</p>
<pre>In [9]:  from sklearn import decomposition<br/>In [10]: ica = decomposition.FastICA(tol=0.005)</pre>
<p>Why do we use <kbd>tol=0.005</kbd>? Because we want the FastICA to converge to some particular value. There are two methods to do that—increase the number of iterations (the default value is <kbd>200</kbd>) or decrease the tolerance (the default value is <kbd>0.0001</kbd>). I tried to increase the iterations but, unfortunately, it didn't work, so I went ahead with the other option. Can you figure out why it didn't converge? </p>
<p>As seen before, the data transformation happens in the <kbd>fit_transform</kbd> function:</p>
<pre>In [11]: X2 = ica.fit_transform(X)</pre>
<p>In our case, plotting the rotated data leads to a similar result to that achieved with PCA earlier, as can be verified in the diagram that follows this code block.</p>
<pre>In [12]: plt.figure(figsize=(10, 6))<br/>...      plt.plot(X2[:, 0], X2[:, 1], 'o')<br/>...      plt.xlabel('first independent component')<br/>...      plt.ylabel('second independent component')<br/>...      plt.axis([-0.2, 0.2, -0.2, 0.2])<br/>Out[12]: [-0.2, 0.2, -0.2, 0.2]</pre>
<p>This can be seen in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-828 image-border" src="img/1113f231-b274-4a4e-8f27-c47cf82851e9.png" style="width:35.25em;height:21.00em;" width="642" height="382"/></p>


            

            
        
    </div>



  
<div><h1 class="header-title">Implementing non-negative matrix factorization (NMF)</h1>
                
            
            
                
<p>Another useful dimensionality reduction technique is called <strong>NMF</strong>. It again implements the same basic mathematical operations as PCA and ICA, but it has the additional constraint that it <strong>only operates on non-negative data</strong>. In other words, we cannot have negative values in our feature matrix if we want to use NMF; the resulting components of the decomposition will all have non-negative values as well.</p>
<p>In scikit-learn, NMF works exactly like ICA:</p>
<pre>In [13]: nmf = decomposition.NMF()In [14]: X2 = nmf.fit_transform(X)In [15]: plt.plot(X2[:, 0], X2[:, 1], 'o')...      plt.xlabel('first non-negative component')...      plt.ylabel('second non-negative component')...      plt.axis([-5, 20, -5, 10])Out[15]: [-5, 20, ...</pre></div>



  
<div><h1 class="header-title">Visualizing the dimensionality reduction using t-Distributed Stochastic Neighbor Embedding (t-SNE)</h1>
                
            
            
                
<p>t-SNE is a technique for dimensionality reduction that is best suited to the visualization of high-dimensional data. </p>
<p>In this section, we will see an example of how to visualize high-dimensional datasets using t-SNE. Let's use the digits dataset in this case, which has handwritten images of digits from 0 to 9. It's a publicly available dataset, commonly referred to as the MNIST dataset. We will see how we can visualize the dimensionality reduction on this dataset using t-SNE:</p>
<ol>
<li>First, let's load the dataset:</li>
</ol>
<pre style="padding-left: 60px">In [1]: import numpy as np<br/>In [2]: from sklearn.datasets import load_digits<br/>In [3]: digits = load_digits()<br/>In [4]: X, y = digits.data/255.0, digits.target<br/>In [5]: print(X.shape, y.shape)<br/>Out[5]: (1797, 64) (1797,)</pre>
<ol start="2">
<li>You should first apply a dimensional reduction technique such as PCA to reduce the high number of dimensions to a lower number and then use a technique such as t-SNE to visualize the data. But, in this case, let's use all of the dimensions and use t-SNE directly:</li>
</ol>
<pre style="padding-left: 60px">In [6]: from sklearn.manifold import TSNE<br/>In [7]: tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)<br/>In [8]: tsne_results = tsne.fit_transform(df.loc[:,features].values)<br/>Out[8]: [t-SNE] Computing 121 nearest neighbors...<br/>... [t-SNE] Indexed 1797 samples in 0.009s...<br/>... [t-SNE] Computed neighbors for 1797 samples in 0.395s...<br/>... [t-SNE] Computed conditional probabilities for sample 1000 / 1797<br/>... [t-SNE] Computed conditional probabilities for sample 1797 / 1797<br/>... [t-SNE] Mean sigma: 0.048776<br/>... [t-SNE] KL divergence after 250 iterations with early exaggeration: 61.094833<br/>... [t-SNE] KL divergence after 300 iterations: 0.926492</pre>
<ol start="3">
<li>Finally, let's visualize the two dimensions that we have extracted using t-SNE with the help of a scatterplot:</li>
</ol>
<pre style="padding-left: 60px">In [9]: import matplotlib.pyplot as plt<br/>In [10]: plt.scatter(tsne_results[:,0],tsne_results[:,1],c=y/10.0)<br/>...      plt.xlabel('x-tsne')<br/>...      plt.ylabel('y-tsne')<br/>...      plt.title('t-SNE')<br/>In [11]: plt.show()</pre>
<p>And we get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-857 image-border" src="img/61cf6482-31a5-407e-a21e-f5a514efb2ee.png" style="width:27.83em;height:21.67em;" width="595" height="463"/></p>
<p>Now, let's discuss how we can represent categorical variables in the next section.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Representing categorical variables</h1>
                
            
            
                
<p>One of the most common data types we might encounter while building a machine learning system is <strong>categorical features</strong> (also known as <strong>discrete features</strong>), such as the color of a fruit or the name of a company. The challenge with categorical features is that they don't change in a continuous way, which makes it hard to represent them with numbers.</p>
<p>For example, a banana is either green or yellow, but not both. A product belongs either in the clothing department or in the books department, but rarely in both, and so on.</p>
<p>How would you go about representing such features?</p>
<p>For example, let's assume we are trying to encode a dataset consisting of a list of forefathers of machine learning and artificial intelligence: ...</p></div>



  
<div><h1 class="header-title">Representing text features</h1>
                
            
            
                
<p>Similar to categorical features, scikit-learn offers an easy way to encode another common feature type—text features. When working with text features, it is often convenient to encode individual words or phrases as numerical values.</p>
<p>Let's consider a dataset that contains a small corpus of text phrases:</p>
<pre>In [1]: sample = [<br/>...        'feature engineering',<br/>...        'feature selection',<br/>...        'feature extraction'<br/>...     ]</pre>
<p>One of the simplest methods of encoding such data is by word count; for each phrase, we simply count the occurrences of each word within it. In scikit-learn, this is easily done using <kbd>CountVectorizer</kbd>, which functions akin to <kbd>DictVectorizer</kbd>:</p>
<pre>In [2]: from sklearn.feature_extraction.text import CountVectorizer<br/>...     vec = CountVectorizer()<br/>...     X = vec.fit_transform(sample)<br/>...     X<br/>Out[2]: &lt;3x4 sparse matrix of type '&lt;class 'numpy.int64'&gt;'<br/>                with 6 stored elements in Compressed Sparse Row format&gt;</pre>
<p>By default, this will store our feature matrix, <kbd>X</kbd>, as a sparse matrix. If we want to manually inspect it, we need to convert it into a regular array:</p>
<pre>In [3]: X.toarray()<br/>Out[3]: array([[1, 0, 1, 0],<br/>               [0, 0, 1, 1],<br/>               [0, 1, 1, 0]], dtype=int64)</pre>
<p>To understand what these numbers mean, we have to look at the feature names:</p>
<pre>In [4]: vec.get_feature_names()<br/>Out[4]: ['engineering', 'extraction', 'feature', 'selection']</pre>
<p>Now, it becomes clear what the integers in <kbd>X</kbd> mean. If we look at the phrase that is represented in the top row of <kbd>X</kbd>, we see that it contains one occurrence of the word, <kbd>engineering</kbd>, and one occurrence of the word, <kbd>feature</kbd>. On the other hand, it does not contain the words <kbd>extraction</kbd> or <kbd>selection</kbd>. Does this make sense? A quick glance at our original data <kbd>sample</kbd> reveals that the phrase was indeed <kbd>feature engineering</kbd>.</p>
<p>Looking only at the <kbd>X</kbd> array (no cheating!), can you guess what the last phrase in <kbd>sample</kbd> was?</p>
<p>One possible shortcoming of this approach is that we might put too much weight on words that appear very frequently. One approach to fixing this is known as <strong>Term Frequency-Inverse Document Frequency</strong> (<strong>TF-IDF</strong>). What TF-IDF does might be easier to understand than its name, which is basically to weigh the word counts by a measure of how often they appear in the entire dataset.</p>
<p>The syntax for TF-IDF is pretty much similar to the previous command:</p>
<pre>In [5]: from sklearn.feature_extraction.text import TfidfVectorizer<br/>...     vec = TfidfVectorizer()<br/>...     X = vec.fit_transform(sample)<br/>...     X.toarray()<br/>Out[5]: array([[ 0.861037 , 0. , 0.50854232, 0. ],<br/>               [ 0. , 0. , 0.50854232, 0.861037 ],<br/>               [ 0. , 0.861037 , 0.50854232, 0. ]])</pre>
<p>We note that the numbers are now smaller than before, with the third column taking the biggest hit. This makes sense, as the third column corresponds to the most frequent word across all three phrases, <kbd>feature</kbd>:</p>
<pre>In [6]: vec.get_feature_names()<br/>Out[6]: ['engineering', 'extraction', 'feature', 'selection']</pre>
<p>If you're interested in the math behind TF-IDF, you can start with this paper: <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.1424&amp;rep=rep1&amp;type=pdf" target="_blank">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.1424&amp;rep=rep1&amp;type=pdf</a>. For more information about its specific implementation in scikit-learn, have a look at the API documentation at <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting">http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting</a><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.1424&amp;rep=rep1&amp;type=pdf">.</a></p>
<p>Representing text features will become important in <a href="08148129-87ac-4042-944d-8e0a2bbbe0c5.xhtml" target="_blank">Chapter 7</a>, <em>Implementing a Spam Filter with Bayesian Learning</em>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Representing images</h1>
                
            
            
                
<p>One of the most common and important data types for computer vision is, of course, images. The most straightforward way to represent images is probably by using the grayscale value of each pixel in the image. Usually, grayscale values are not very indicative of the data they describe. For example, if we saw a single pixel with a grayscale value of 128, could we tell what object this pixel belonged to? Probably not. Therefore, grayscale values are not very effective image features.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Using color spaces</h1>
                
            
            
                
<p>Alternatively, we might find that colors contain some information that raw grayscale values cannot capture. Most often, images come in the conventional RGB color space, where every pixel in the image gets an intensity value for its apparent <strong>Redness</strong> (<strong>R</strong>), <strong>Greenness</strong> (<strong>G</strong>), and <strong>Blueness</strong> (<strong>B</strong>). However, OpenCV offers a whole range of other color spaces, such as <strong>Hue Saturation Value</strong> (<strong>HSV</strong>), <strong>Hue Saturation Lightness</strong> (<strong>HSL</strong>), and the Lab color space. Let's have a quick look at them.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Encoding images in the RGB space</h1>
                
            
            
                
<p>I am sure that you are already familiar with the RGB color space, which uses additive mixing of different shades of red, green, and blue to produce different composite colors. The RGB color space is useful in everyday life because it covers a large part of the color space that the human eye can see. This is why color television sets or color computer monitors only need to care about producing mixtures of red, green, and blue light.</p>
<p>In OpenCV, RGB images are supported straight out of the box. All you need to know, or need to be reminded of, is that color images are actually stored as BGR images in OpenCV; that is, the order of color channels is blue-green-red instead of red-green-blue. The reasons for this ...</p></div>



  
<div><h1 class="header-title">Encoding images in the HSV and HLS space</h1>
                
            
            
                
<p>However, ever since the RGB color space was created, people have realized that it is actually quite a poor representation of human vision. Therefore, researchers have developed many alternative representations. One of them is called <strong>HSV</strong> (short for <strong>Hue, Saturation, and Value</strong>) and the other one is called <strong>HLS</strong> (<strong>Hue, Lightness, and Saturation</strong>). You might have seen these color spaces in color pickers and common image editing software. In these color spaces, the hue of the color is captured by a single hue channel, the colorfulness is captured by a saturation channel, and the lightness or brightness is captured by a lightness or value channel.</p>
<p>In OpenCV, an RGB image can easily be converted into the HSV color space using <kbd>cv2.cvtColor</kbd>:</p>
<pre>In [5]: img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)</pre>
<p>The same is true for the HLS color space. In fact, OpenCV provides a whole range of additional color spaces, which are available via <kbd>cv2.cvtColor</kbd>. All we need to do is to replace the color flag with one of the following:</p>
<ul>
<li>HLS using <kbd>cv2.COLOR_BGR2HLS</kbd></li>
<li>LAB (lightness, green-red, and blue-yellow) using <kbd>cv2.COLOR_BGR2LAB</kbd></li>
<li>YUV (overall luminance, blue luminance, and red luminance) using <kbd>cv2.COLOR_BGR2YUV</kbd></li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Detecting corners in images</h1>
                
            
            
                
<p>One of the most straightforward traditional features to find in an image are probably corners (locations where several edges meet). OpenCV provides at least two different algorithms to find corners in an image:</p>
<ul>
<li><strong>Harris Dorner Detection</strong>: Knowing that edges are areas with high-intensity changes in all directions, Harris and Stephens came up with a fast way of finding such locations. This algorithm is implemented as <kbd>cv2.cornerHarris</kbd> in OpenCV.</li>
<li><strong>Shi-Tomasi Corner Detection</strong>: Shi and Tomasi have their own idea of what constitute good features to track, and they usually do better than Harris corner detection by finding the <em>N</em> strongest corners. This algorithm is implemented as <kbd>cv2.goodFeaturesToTrack</kbd> in OpenCV.</li>
</ul>
<p>Harris ...</p></div>



  
<div><h1 class="header-title">Using the star detector and BRIEF descriptor</h1>
                
            
            
                
<p>However, corner detection is not sufficient when the scale of an image changes. Multiple papers have been published describing different algorithms for feature detection and description. We will look at a combination of the <strong>Speeded Up Robust Features</strong> (<strong>SURF</strong>) detector (for more information, see <a href="https://en.wikipedia.org/wiki/Speeded_up_robust_features" target="_blank">https://en.wikipedia.org/wiki/Speeded_up_robust_features</a>) and the <strong>Binary Robust Independent Elementary Features</strong> (<strong>BRIEF</strong>) descriptor. The feature detector identifies the keypoints in the image and the feature descriptor calculates the actual feature value for all of the keypoints.</p>
<p>The details of these algorithms are beyond the scope of this book. Advanced users can refer to the papers describing these algorithms in detail.</p>
<p>For more details, you can refer to the following links:</p>
<ul>
<li>For SURF: <a href="https://www.vision.ee.ethz.ch/~surf/eccv06.pdf" target="_blank">https://www.vision.ee.ethz.ch/~surf/eccv06.pdf</a></li>
<li>For BRIEF: <a href="https://www.cs.ubc.ca/~lowe/525/papers/calonder_eccv10.pdf" target="_blank">https://www.cs.ubc.ca/~lowe/525/papers/calonder_eccv10.pdf</a></li>
</ul>
<p>The entire process starts with reading the image, converting it into grayscale, using the star feature detector to find the interesting points, and finally, using the BRIEF descriptor to calculate the feature value.</p>
<ol>
<li>Let's first read the image and convert it to grayscale:</li>
</ol>
<pre>In [23]: img = cv2.imread('data/rubic-cube.png')<br/>In [24]: gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<strong><br/></strong></pre>
<ol start="2">
<li>Now, we will create the feature detector and descriptor:</li>
</ol>
<div><pre style="padding-left: 60px">In [25]: star = cv2.xfeatures2d.StarDetector_create()<br/>In [26]: brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()</pre></div>
<ol start="3">
<li>Next, it's time to use the star detector to get the keypoints and pass them to the BRIEF descriptor:</li>
</ol>
<pre style="padding-left: 60px">In [27]: keyPoints = star.detect(gray, None)<br/>In [28]: keyPoints, descriptors = brief.compute(img, keyPoints)</pre>
<p style="padding-left: 60px">There's a catch here. At the time of writing this book, the OpenCV version 4.0 didn't have the resolved version of the <kbd>cv2.drawKeypoints</kbd> function. So, I have written a similar function that we can use to draw the keypoints. You don't need to worry about the steps involved in the function—it's just for your reference. If you have installed the OpenCV version specified in this book (OpenCV 4.1.0 or OpenCV 4.1.1), you can use the <kbd>cv2.drawKeypoints</kbd> function directly:</p>
<pre style="padding-left: 60px">In [29]: def drawKeypoint (img, keypoint, color):<br/>...          draw_shift_bits = 4<br/>...          draw_multiplier = 1 &lt;&lt; draw_shift_bits<br/>    <br/>...          center = (int(round(keypoint.pt[0])),int(round(keypoint.pt[1])))<br/>    <br/>...          radius = int(round(keypoint.size/2.0))<br/>    <br/>...          # draw the circles around keypoints with the keypoints size<br/>...          cv2.circle(img, center, radius, color, 1, cv2.LINE_AA)<br/>    <br/>...          # draw orientation of the keypoint, if it is applicable<br/>...          if keypoint.angle != -1:<br/>        <br/>...              srcAngleRad = keypoint.angle * np.pi/180.0<br/>        <br/>...              orient = (int(round(np.cos(srcAngleRad)*radius)), \<br/>                 int(round(np.sin(srcAngleRad)*radius)))<br/>        <br/>...              cv2.line(img, center, (center[0]+orient[0],\<br/>                               center[1]+orient[1]),\<br/>                 color, 1, cv2.LINE_AA)<br/>...          else:<br/>...              # draw center with R=1<br/>...              radius = 1 * draw_multiplier<br/>...              cv2.circle(img, center, radius,\<br/>                  color, 1, cv2.LINE_AA)<br/>    <br/>...          return img<br/>In [30]: from random import randint<br/>...      def drawKeypoints(image, keypoints):<br/>...          for keypoint in keypoints:<br/>...              color = (randint(0,256),randint(0,256),randint(0,256))<br/>...              image = drawKeypoint(image, keypoint, color)<br/>...          return image</pre>
<ol start="4">
<li>Let's now use this function to draw the detected keypoints:</li>
</ol>
<pre style="padding-left: 60px">In [31]: result = drawKeypoints(img, keyPoints)<br/>In [32]: print("Number of keypoints = {}".format(len(keyPoints)))<br/>Out[32]: Number of keypoints = 453<br/>In [33]: plt.figure(figsize=(18,9))<br/>...      plt.imshow(result)</pre>
<p>And we get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1069 image-border" src="img/ebc26310-d118-45b6-bb17-4c12686d3188.png" style="width:24.58em;height:23.42em;" width="564" height="536"/></p>
<p>It's pretty awesome, right? </p>
<p>As easy and fast as BRIEF is, it doesn't work well with the rotation of an image. You can try it out by rotating the image (more information at <a href="https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/" target="_blank">https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/</a>) and then running BRIEF. Let's see how ORB helps us to resolve this.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Using Oriented FAST and Rotated BRIEF (ORB)</h1>
                
            
            
                
<p>Personally speaking, I am a huge fan of ORB. It's free and a good alternative to SIFT and SURF, which are both protected by patent laws. ORB actually works better than SURF. It's also interesting to note that Gary Bradski was one of the authors of the paper entitled <em>ORB: An Efficient Alternative to SIFT and SURF</em>. Can you figure out why that's interesting? Google Gary Bradski and OpenCV and you will get your answer.</p>

<p>The entire process will more or less stay the same, so let's quickly go through the code:</p>
<pre>In [34]: img = cv2.imread('data/rubic-cube.png')...      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)In [35]: orb = cv2.ORB_create()In [36]: keyPoints = orb.detect(gray,None)In [37]: keyPoints, descriptors ...</pre></div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we went deep down the rabbit hole and looked at several common feature engineering techniques, focusing on both feature selection and feature extraction. We successfully formatted, cleaned, and transformed data so that it could be understood by common machine learning algorithms. We learned about the curse of dimensionality and dabbled a bit in dimensionality reduction by implementing PCA in OpenCV. Finally, we took a short tour of common feature extraction techniques that OpenCV provides for image data.</p>
<p>With these skills under our belt, we are now ready to take on any data, be it numerical, categorical, text, or image data. We know exactly what to do when we encounter missing data, and we know how to transfer our data to make it fit our preferred machine learning algorithm.</p>
<p>In the next chapter, we will take the next step and talk about a specific use case, which is how to use our newly acquired knowledge to make medical diagnoses using decision trees.</p>


            

            
        
    </div>



  </body></html>