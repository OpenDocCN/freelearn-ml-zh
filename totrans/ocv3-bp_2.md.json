["```py\n$ killall PTPCamera\n\n```", "```py\n$ gvfs-mount -l\n\n```", "```py\nDrive(0): APPLE SSD SM1024F\n  Type: GProxyDrive (GProxyVolumeMonitorUDisks2)\n  Volume(0): Recovery HD\n    Type: GProxyVolume (GProxyVolumeMonitorUDisks2)\n  Volume(1): Macintosh HD\n    Type: GProxyVolume (GProxyVolumeMonitorUDisks2)\nDrive(1): APPLE SD Card Reader\n  Type: GProxyDrive (GProxyVolumeMonitorUDisks2)\nVolume(0): NIKON DSC D80\n  Type: GProxyVolume (GProxyVolumeMonitorGPhoto2)\n  Mount(0): NIKON DSC D80 -> gphoto2://[usb:001,007]/\n    Type: GProxyShadowMount (GProxyVolumeMonitorGPhoto2)\nMount(1): NIKON DSC D80 -> gphoto2://[usb:001,007]/\n  Type: GDaemonMount\n```", "```py\n$ gvfs-mount –u gphoto2://[usb:001,007]/\n\n```", "```py\n#!/usr/bin/env bash\n\nif [ \"$(uname)\" == \"Darwin\" ]; then\n  killall PTPCamera\nelse\n  mounted_cameras=`gvfs-mount -l | grep -Po 'gphoto2://.*/' | uniq`\n  for mounted_camera in $mounted_cameras; do\n    gvfs-mount -u $mounted_camera\n  done\nfi\n```", "```py\n$ chmod +x unmount_cameras.sh\n\n```", "```py\n$ ./unmount_cameras.sh\n\n```", "```py\n$ sudo port install gphoto2\n\n```", "```py\n$ sudo apt-get install gphoto2\n\n```", "```py\n$ sudo yum install gphoto2\n\n```", "```py\n$ ./unmount_cameras.sh\n$ gphoto2 --capture-image\n\n```", "```py\n$ ./unmount_cameras.sh\n$ gphoto2 --get-all-files\n```", "```py\n$ man gphoto2\n```", "```py\n$ gphoto2 --set-config exposurecompensation=1000 --capture-image\n\n```", "```py\n$ gphoto2 --set-config shutterspeed=1s flashmode=2 --capture-image\n\n```", "```py\n$ gphoto2 --list-all-config\n\n```", "```py\n#!/usr/bin/env bash\n\nev_step=1000\nframes=3\nwhile getopts s:f: flag; do\n  case $flag in\n    s)\n      ev_step=\"$OPTARG\"\n      ;;\n    f)\n      frames=\"$OPTARG\"\n      ;;\n    ?)\n      exit\n      ;;\n  esac\ndone\n\nmin_ev=$((-ev_step * (frames - 1) / 2))\nfor ((i=0; i<frames; i++)); do\n  ev=$((min_ev + i * ev_step))\n  gphoto2 --set-config exposurecompensation=$ev \\\n    --capture-image\ndone\ngphoto2 --set-config exposurecompensation=0\n```", "```py\n$ chmod +x capture_exposure_bracket.sh\n\n```", "```py\n$ ./unmount_cameras.sh\n$ ./capture_exposure_bracket.sh –s 1500 –f 5\n\n```", "```py\nimport os\nimport subprocess\n```", "```py\nclass CameraCommander(object):\n\n  def __init__(self, logPath=os.devnull):\n    self._logFile = open(logPath, 'w')\n    self._capProc = None\n    self.unmount_cameras()\n```", "```py\n  def __del__(self):\n    self._logFile.close()\n```", "```py\n  def _open_proc(self, command):\n    return subprocess.Popen(\n      command, shell=True, stdout=self._logFile,\n      stderr=self._logFile)\n```", "```py\n  def unmount_cameras(self):\n    proc = self._open_proc('./unmount_cameras.sh')\n    proc.wait()\n```", "```py\n  def capture_image(self):\n    self.stop_capture()\n    self._capProc = self._open_proc(\n      'gphoto2 --capture-image')\n```", "```py\n  def capture_time_lapse(self, interval, frames=0):\n    self.stop_capture()\n    if frames <= 0:\n      # Capture an indefinite number of images.\n      command = 'gphoto2 --capture-image -I %d' % interval\n    else:\n      command = 'gphoto2 --capture-image -I %d -F %d' %\\\n        (interval, frames)\n    self._capProc = self._open_proc(command)\n```", "```py\n  def capture_exposure_bracket(self, ev_step=1.0, frames=3):\n    self.stop_capture()\n    self._capProc = self._open_proc(\n      './capture_exposure_bracket.sh -s %d -f %d' %\\\n        (int(ev_step * 1000), frames))\n```", "```py\n  def stop_capture(self):\n    if self._capProc is not None:\n      if self._capProc.poll() is None:\n        # The process is currently running but might finish\n        # before the next function call.\n        try:\n          self._capProc.terminate()\n        except:\n          # The process already finished.\n          pass\n      self._capProc = None\n```", "```py\n  def wait_capture(self):\n    if self._capProc is not None:\n      self._capProc.wait()\n      self._capProc = None\n```", "```py\n  @property\n  def capturing(self):\n    if self._capProc is None:\n      return False\n    elif self._capProc.poll() is None:\n      return True\n    else:\n      self._capProc = None\n      return False\n```", "```py\n#!/usr/bin/env python\n\nimport CameraCommander\n\ndef main():\n\n  cc = CameraCommander.CameraCommander('test_camera_commands.log')\n\n  cc.capture_image()\n  print('Capturing image...')\n  cc.wait_capture()\n  print('Done')\n\n  cc.capture_time_lapse(3, 2)\n  print('Capturing 2 images at time interval of 3 seconds...')\n  cc.wait_capture()\n  print('Done')\n\n  cc.capture_exposure_bracket(1.0, 3)\n  print('Capturing 3 images at exposure interval of 1.0 EV...')\n  cc.wait_capture()\n  print('Done')\n\nif __name__ == '__main__':\n  main()\n```", "```py\n$ chmod +x test_camera_commands.py\n$ ./test_camera_commands.py\n\n```", "```py\n$ sudo apt-get install libgphoto2-dev\n\n```", "```py\n#!/usr/bin/env python\n\nimport argparse\nimport time\n\nimport numpy\nimport cv2\n\nimport CameraCommander\n```", "```py\ndef main():\n\n  parser = argparse.ArgumentParser(\n    description='This script detects motion using an '\n                'attached webcam. When it detects '\n                'motion, it captures photos on an '\n                'attached gPhoto2-compatible photo '\n                'camera.')\n\n  parser.add_argument(\n    '--debug', type=bool, default=False,\n    help='print debugging information')\n\n  parser.add_argument(\n    '--cam-index', type=int, default=-1,\n    help='device index for detection camera '\n         '(default=0)')\n  parser.add_argument(\n    '--width', type=int, default=320,\n    help='capture width for detection camera '\n         '(default=320)')\n  parser.add_argument(\n    '--height', type=int, default=240,\n    help='capture height for detection camera '\n         '(default=240)')\n  parser.add_argument(\n    '--detection-interval', type=float, default=0.25,\n    help='interval between detection frames, in seconds '\n         '(default=0.25)')\n\n  parser.add_argument(\n    '--learning-rate', type=float, default=0.008,\n    help='learning rate for background subtractor, which '\n         'is used in motion detection (default=0.008)')\n  parser.add_argument(\n    '--min-motion', type=float, default=0.15,\n    help='proportion of frame that must be classified as '\n         'foreground to trigger motion event '\n         '(default=0.15, valid_range=[0.0, 1.0])')\n\n  parser.add_argument(\n    '--photo-count', type=int, default=1,\n    help='number of photo frames per motion event '\n         '(default=1)')\n  parser.add_argument(\n    '--photo-interval', type=float, default=3.0,\n    help='interval between photo frames, in seconds '\n         '(default=3.0)')\n  parser.add_argument(\n    '--photo-ev-step', type=float, default=None,\n    help='exposure step between photo frames, in EV. If '\n         'this is specified, --photo-interval is ignored '\n         'and --photo-count refers to the length of an '\n         'exposure bracketing sequence, not a time-lapse '\n         'sequence.')\n```", "```py\n$ ./set_motion_trap.py -h\n```", "```py\n  args = parser.parse_args()\n\n  debug = args.debug\n\n  cam_index = args.cam_index\n  w, h = args.width, args.height\n  detection_interval = args.detection_interval\n\n  learning_rate = args.learning_rate\n  min_motion = args.min_motion\n\n  photo_count = args.photo_count\n  photo_interval = args.photo_interval\n  photo_ev_step = args.photo_ev_step\n```", "```py\n  cap = cv2.VideoCapture(cam_index)\n  cap.set(cv2.CAP_PROP_FRAME_WIDTH, w)\n  cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)\n\n  bgr = None\n  gray = None\n  fg_mask = None\n\n  bg_sub = cv2.createBackgroundSubtractorMOG2()\n\n  cc = CameraCommander.CameraCommander()\n```", "```py\n  while True:\n    time.sleep(detection_interval)\n```", "```py\n    success, bgr = cap.read(bgr)\n    if success:\n      gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY, gray)\n      gray = cv2.equalizeHist(gray, gray)\n```", "```py\n      fg_mask = bg_sub.apply(gray, fg_mask, learning_rate)\n```", "```py\n      h, w = fg_mask.shape\n      motion = numpy.sum(numpy.where(fg_mask == 255, 1, 0))\n      motion /= float(h * w)\n```", "```py\n      if debug:\n        print('motion=%f' % motion)\n```", "```py\n      if motion >= min_motion and not cc.capturing:\n        if photo_ev_step is not None:\n          cc.capture_exposure_bracket(photo_ev_step, photo_count)\n        else:\n          cc.capture_time_lapse(photo_interval, photo_count)\n```", "```py\nif __name__ == '__main__':\n  main()\n```", "```py\n$ chmod +x set_motion_trap.py\n$ ./set_motion_trap.py --debug True\n```", "```py\nimages = [myImage]  # One or more input images\nchannels =  [0, 1, 2]  # The channel indices\nmask = None  # The image region, or None for everything\nhistSize = [256, 256, 256]  # The channel depths\nranges = [0, 255, 0, 255, 0, 255]  # The color bin boundaries\nhist = cv2.calcHist(images, channels, mask, histSize, ranges)\n```", "```py\nnormalizedHist = cv2.normalize(hist, norm_type=cv2.NORM_L1)\n```", "```py\nmethod = cv2.HISTCMP_INTERSECT  # A method of comparison\nsimilarity = cv2.compareHist(\n  normalizedHist, otherNormalizedHist, method)\n```", "```py\nfrom __future__ import print_function\n```", "```py\ndef main():\n\n  parser = argparse.ArgumentParser(\n    description='This script detects colors using an '\n                'attached webcam. When it detects colors '\n                'that match the histogram of a reference '\n                'image, it captures photos on an '\n                'attached gPhoto2-compatible photo '\n                'camera.')\n\n  # ...\n\n  parser.add_argument(\n    '--reference-image', type=str, required=True,\n    help='path to reference image, whose colors will be '\n         'detected in scene')\n  parser.add_argument(\n    '--min-similarity', type=float, default=0.02,\n    help='similarity score that histogram comparator '\n         'must find in order to trigger similarity event '\n         '(default=0.02, valid_range=[0.0, 1.0])')\n\n  # ...\n```", "```py\n  args = parser.parse_args()\n\n  # ...\n\n  reference_image = cv2.imread(args.reference_image,\n                               cv2.IMREAD_COLOR)\n  if reference_image is None:\n    print('Failed to read reference image: %s' %\n          args.reference_image, file=sys.stderr)\n    return\n\n  min_similarity = args.min_similarity\n\n  # ...\n```", "```py\n  # ...\n\n  channels = range(3)\n  hist_size = [256] * 3\n  ranges = [0, 255] * 3\n\n  def create_normalized_hist(image, hist=None):\n    hist = cv2.calcHist(\n      [image], channels, None, hist_size, ranges, hist)\n    return cv2.normalize(hist, hist, norm_type=cv2.NORM_L1)\n\n  reference_hist = create_normalized_hist(reference_image)\n  query_hist = None\n\n  # ...\n```", "```py\n  while True:\n    time.sleep(detection_interval)\n    success, bgr = cap.read(bgr)\n    if success:\n      query_hist = create_normalized_hist(\n        bgr, query_hist)\n      similarity = cv2.compareHist(\n        reference_hist, query_hist, cv2.HISTCMP_INTERSECT)\n      if debug:\n        print('similarity=%f' % similarity)\n      if similarity >= min_similarity and not cc.capturing:\n        if photo_ev_step is not None:\n          cc.capture_exposure_bracket(photo_ev_step, photo_count)\n        else:\n          cc.capture_time_lapse(photo_interval, photo_count)\n```", "```py\nif __name__ == '__main__':\n  main()\n```", "```py\n$ ./set_color_trap.py --reference-image media/OrangeCoat.jpg --min-similarity 0.13 --width 640 --height 480 --debug True\n\n```", "```py\ndef main():\n\n  parser = argparse.ArgumentParser(\n    description='This script detects objects using an '\n                'attached webcam. When it detects '\n                'objects that match a given cascade '\n                'file, it captures photos on an attached '\n                'gPhoto2-compatible photo camera.')\n\n  # ...\n\n  parser.add_argument(\n    '--cascade-file', type=str, required=True,\n    help='path to cascade file that classifier will use '\n         'to detect objects in scene')\n  parser.add_argument(\n    '--scale-factor', type=float, default=1.05,\n    help='relative difference in scale between '\n         'iterations of multi-scale classification '\n         '(default=1.05)')\n  parser.add_argument(\n    '--min-neighbors', type=int, default=8,\n    help='minimum number of overlapping objects that '\n         'classifier must detect in order to trigger '\n         'classification event (default=8)')\n  parser.add_argument(\n    '--min-object-width', type=int, default=40,\n    help='minimum width of each detected object'\n         '(default=40)')\n  parser.add_argument(\n    '--min-object-height', type=int, default=40,\n    help='minimum height of each detected object'\n         '(default=40)')\n\n  # ...\n```", "```py\n  args = parser.parse_args()\n\n  # ...\n\n  classifier = cv2.CascadeClassifier(args.cascade_file)\n  if classifier.empty():\n    print('Failed to read cascade file: %s' %\n          args.cascade_file, file=sys.stderr)\n    return\n\n  scale_factor = args.scale_factor\n  min_neighbors = args.min_neighbors\n  min_size = (args.min_object_width, args.min_object_height)\n\n  # ...\n```", "```py\n  while True:\n    time.sleep(detection_interval)\n    success, bgr = cap.read(bgr)\n    if success:\n      gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY, gray)\n      gray = cv2.equalizeHist(gray, gray)\n      objects = classifier.detectMultiScale(\n        gray, scaleFactor=scale_factor,\n        minNeighbors=min_neighbors, minSize=min_size)\n      num_objects = len(objects)\n      if debug:\n        print('num_objects=%d' % num_objects)\n      if num_objects > 0 and not cc.capturing:\n        if photo_ev_step is not None:\n          cc.capture_exposure_bracket(photo_ev_step, photo_count)\n        else:\n          cc.capture_time_lapse(photo_interval, photo_count)\n```", "```py\nif __name__ == '__main__':\n  main()\n```", "```py\n$ ./set_classifier_trap.py --cascade-file cascades/haarcascade_frontalcatface_extended.xml --min-neighbors 16 --scale-factor 1.2 --width 640 --height 480 --debug True\n\n```", "```py\n$ gphoto2 --get-all-files\n\n```", "```py\n#!/usr/bin/env python\n\nimport cv2\n\ndef main():\n\n  ldr_images = [\n    cv2.imread('media/PlasmaWink_0.jpg'),\n    cv2.imread('media/PlasmaWink_1.jpg')]\n\n  hdr_processor = cv2.createMergeMertens()\n  hdr_image = hdr_processor.process(ldr_images) * 255\n  cv2.imwrite('media/PlasmaWink_HDR.jpg', hdr_image)\n\nif __name__ == '__main__':\n  main()\n```", "```py\n#!/usr/bin/env python\n\nimport cv2\n\ndef main():\n\n  num_input_files = 56\n  input_filename_pattern = 'media/JosephineChair_%02d.jpg'\n  output_filename = 'media/JosephineChair_TimeLapse.avi'\n  fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n  fps = 60.0\n  writer = None\n\n  for i in range(num_input_files):\n    input_filename = input_filename_pattern % i\n    image = cv2.imread(input_filename)\n    if writer is None:\n      is_color = (len(image.shape) > 2)\n      h, w = image.shape[:2]\n      writer = cv2.VideoWriter(\n        output_filename, fourcc, fps, (w, h), is_color)\n    writer.write(image)\n\nif __name__ == '__main__':\n    main()\n```"]