["```py\n    Run = Run.get_context()\n    exp = run.experiment\n    # train your model\n    clf, test_acc = train_sklearn_mnist()\n    ```", "```py\n    Def get_metrics(exp, metric):\n      for run in Run.list(exp, status='Completed'):\n        yield run.get_metrics().get(metric)\n    m_name = 'Test accuracy'\n    best_acc = max(get_metrics(exp, m_name), default=0)\n    ```", "```py\n    Import joblib\n    # serialize the model and write it to disk\n    joblib.dump(clf, 'outputs/model.pkl')\n    if test_acc > best_acc:\n      model = run.register_model(\n        model_name='sklearn_mnist',\n        model_path='outputs/model.pkl')\n      print(model.name, model.id, model.version, sep='\\t')\n    ```", "```py\n    import joblib\n    from azureml.core.model import Model\n    model_path = Model.get_model_path('sklearn_mnist')\n    model = joblib.load(model_path)\n    ```", "```py\n    From azureml.core.resource_configuration import \\\n      ResourceConfiguration\n    resource_config = ResourceConfiguration(\n      cpu=1, memory_in_gb=2.0, gpu=0)\n    ```", "```py\n    From azureml.core import Model\n    model = run.register_model(\n      model_name='sklearn_mnist',\n      model_path='outputs/model.pkl',\n      model_framework=Model.Framework.SCIKITLEARN,\n      model_framework_version='0.24.2',\n      resource_configuration= resource_config)\n    ```", "```py\n    Service_name = 'my-sklearn-service'\n    service = Model.deploy(ws, service_name, [model])\n    ```", "```py\n    service.wait_for_deployment(show_output=True)\n    print(service.state)\n    print(\"Scoring URL: \" + service.scoring_uri)\n    ```", "```py\n    From azureml.core import Environment\n    from azureml.core.conda_dependencies import \\\n      CondaDependencies\n    def get_env(name=\"my-env\", packages=None):\n      packages = packages or []\n      packages += ['azureml-defaults']\n      conda_deps = CondaDependencies.create(\n        pip_packages=packages)\n      env = Environment(name=name)\n      env.python.conda_dependencies = conda_deps\n      return env\n    ```", "```py\n    myenv = get_env(name=\"PythonEnv\",\n                    packages=[\"numpy\",\n                              \"scikit-learn\", \n                              \"tensorflow\"])\n    ```", "```py\n    myenv.register(ws, name=\"PythonEnv\")\n    ```", "```py\n    myenv = Environment.get(ws, name=\"PythonEnv\")\n    ```", "```py\n    from azureml.core.model import InferenceConfig\n    inference_config = InferenceConfig(\n      entry_script=\"score.py\",\n      environment=myenv)\n    ```", "```py\n    from azureml.core import Image\n    build = myenv.build(ws)\n    build.wait_for_completion(show_output=True)\n    ```", "```py\n    model_path = Model.get_model('sklearn_mnist')\n    package = Model.package(ws, [model], inference_config)\n    package.wait_for_creation(show_output=True)\n    ```", "```py\nFrom azureml.core.webservice import LocalWebservice\ndeployment_config = LocalWebservice.deploy_configuration(\n  port=8890)\nservice = Model.deploy(ws,\n  name=service_name,\n  models=[model],\n  inference_config=inference_config,\n  deployment_config=deployment_config)\nservice.wait_for_deployment(show_output=True)\nprint(service.state)\n```", "```py\nclf = train(name=\"sentiment-analysis\")\nclf.save_pretrained(\"outputs/sentiment-analysis\")\nmodel = Model.register(ws,\n  model_name='sentiment-analysis',\n  model_path='outputs/sentiment-analysis')\n```", "```py\ndef init():\n  print(\"Initializing service\")\ndef run(data):\n  print(\"Received a new request with data: \", data)\n```", "```py\nfrom transformers import AutoModel\nfrom azureml.core import Model\ndef init():\n  global model\n  model_path = os.getenv(\"AZUREML_MODEL_DIR\")\n  model = AutoModel.from_pretrained(model_path,\n                                    from_tf=True)\n```", "```py\nimport json\ndef run(request):\n    try:\n        data = json.loads(request)\n        text = data['query']\n        sentiment = model(text)\n        result = {'sentiment': sentiment}\n        return result\n    except Exception as e:\n        return str(e)\n```", "```py\n    from azureml.core.webservice import AciWebservice\n    deploy_config = AciWebservice.deploy_configuration(\n      cpu_cores=1,\n      memory_gb=1)\n    ```", "```py\n    from azureml.core.model import InferenceConfig\n    env = get_env(name=\"sentiment-analysis\",\n                  package=[\"tensorflow\", \"transformers\"])\n    inference_config = InferenceConfig(\n      environment=env,\n      source_directory=\"code\",\n      entry_script=\"scoring_file.py\",\n    )\n    ```", "```py\n    service_name = \"sentiment-analysis\"\n    service = Model.deploy(ws,\n      name=service_name,\n      models=[model],\n      inference_config=inference_config,\n      deployment_config=deploy_config)\n    service.wait_for_deployment(show_output=True)\n    print(service.state)\n    ```", "```py\n    import requests\n    import json\n    from azureml.core import Webservice\n    service = Webservice(ws, name=\"sentiment-analysis\")\n    scoring_uri = service.scoring_uri\n    # If the service is authenticated\n    key, _ = service.get_keys()\n    # Set the appropriate headers\n    headers = {\"Content-Type\": \"application/json\"}\n    headers[\"Authorization\"] = f\"Bearer {key}\"\n    data = {\"query\": \"AzureML is quite good.\"}\n    resp = requests.post(scoring_uri,\n                         data=json.dumps(data),\n                         headers=headers)\n    print(resp.text)\n    ```", "```py\n    from azureml.core.compute import AksCompute, \\\n      ComputeTarget\n    # Configure AKS cluster with NVIDIA Tesla P40 GPU\n    prov_config = AksCompute.provisioning_configuration(\n      vm_size=\"Standard_ND6s\")\n    aks_name = 'aks-ml-prod'\n    # Create the cluster\n    aks_target = ComputeTarget.create(ws,\n      name=aks_name,\n      provisioning_configuration=prov_config)\n    # Wait for the create process to complete\n    aks_target.wait_for_completion(show_output=True)\n    ```", "```py\n    resource_group = 'my-rg'\n    cluster_name = 'aks-ml-prod'\n    attach_config = AksCompute.attach_configuration(\n      resource_group = resource_group,\n      cluster_name=cluster_name)\n    aks_target = ComputeTarget.attach(ws,\n      cluster_name,\n      attach_config)\n    ```", "```py\n    deploy_config = AksWebservice.deploy_configuration(\n      cpu_cores=1,\n      memory_gb=1,\n      gpu_cores=1)\n    service = Model.deploy(ws,\n      service_name,\n      [model],\n      inference_config,\n      deploy_config,\n      aks_target)\n    service.wait_for_deployment(show_output=True)\n    print(service.state)\n    print(service.get_logs())\n    ```", "```py\nimport numpy as np\ninput_sample = np.array([[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]])\noutput_sample = np.array([3726.995])\n@input_schema('data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\ndef run(data):\n  # data is a np.array\n  pass\n```", "```py\nimport numpy as np\nimport pandas as pd\ninput_sample = pd.DataFrame(data=[\n  {'query\": \"AzureML is quite good.\"}])\noutput_sample = np.array([np.array([\"POSITIVE\", 0.95])])\n@input_schema('data', PandasParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\ndef run(data):\n  # data is a pd.DataFrame\n  pass\n```", "```py\n    from azureml.core.webservice import AksEndpoint\n    endpoint_config = AksEndpoint.deploy_configuration(\n      version_name=\"version-1\",\n      tag'={'modelVersion':'1'}, \n      namespace=\"nlp\", \n      traffic_percentile=100)\n    ```", "```py\n    endpoint_name\"= \"sentiment-analysis\"\n    endpoint = Model.deploy(ws,\n      endpoint_name,\n      [model],\n      inference_config,\n      endpoint_config,\n      aks_target)\n    endpoint.wait_for_deployment(show_output=True)\n    print(endpoint.state)\n    ```", "```py\n    endpoint.update_version(\n      version_name=\"version-1\",\n      traffic_percentile=50,\n      is_default=True,\n      is_control_version_type=True)\n    ```", "```py\n    endpoint.create_version(\n      version_name=\"version-2\",\n      inference_config=inference_config,\n      models=[test_model],\n      tags={'modelVersion':'2'},\n      description=\"my second version\",\n      traffic_percentile=50)\n    ```", "```py\n    endpoint.wait_for_deployment(show_output=True)\n    print(endpoint.state)\n    ```", "```py\n    from azureml.pipeline.core.graph import \\\n      PipelineParameter\n    batch_size_param = PipelineParameter(\n      name=\"param_batch_size\",\n      default_value=20)\n    ```", "```py\n    from azureml.pipeline.steps import PythonScriptStep\n    batch_score_step = PythonScriptStep(\n      name=\"batch_scoring\",\n      script_name=\"batch_scoring.py\",\n      arguments=[\n       \"--dataset_path\", input_images,\n       \"--model_name\", \"inception\",\n       \"--label_dir\", label_dir,\n       \"--output_dir\", output_dir,\n       \"--batch_size\", batch_size_param],\n      compute_target=compute_target,\n      inputs=[input_images, label_dir],\n      outputs=[output_dir],\n      runconfig=amlcompute_run_config)\n    ```", "```py\n    from azureml.core import Experiment\n    from azureml.pipeline.core import Pipeline\n    pipeline = Pipeline(ws, steps=[batch_score_step])\n    exp = Experiment(ws, 'batch_scoring')\n    pipeline_run = exp.submit(pipeline,\n      pipeline_params={\"param_batch_size\": 20})\n    ```", "```py\n    pipeline_run.wait_for_completion(show_output=True)\n    step_run = list(pipeline_run.get_children())[0]\n    step_run.download_file(\"./outputs/result-labels.txt\")\n    ```", "```py\n    import pandas as pd\n    df = pd.read_csv(\n      \"./outputs/result-labels.txt\",\n      delimiter=\":\",\n      header=None)\n    df.columns = [\"Filename\", \"Prediction\"]\n    df.head()\n    ```", "```py\n    published_pipeline = pipeline_run.publish_pipeline(\n      name=\"Inception_v3_scoring\",\n      description=\"Batch scoring using Inception v3\",\n      version=\"1.0\")\n    published_id = published_pipeline.id\n    rest_endpoint = published_pipeline.endpoint\n    ```", "```py\n    from azureml.core.authentication import \\\n      AzureCliAuthentication\n    cli_auth = AzureCliAuthentication()\n    aad_token = cli_auth.get_authentication_header()\n    ```", "```py\n    import requests\n    # Specify batch size when running the pipeline\n    response = requests.post(\n      rest_endpoint,\n      headers=aad_token,\n      json={\n       \"ExperimentName\": \"batch_scoring\",\n       \"ParameterAssignments\": {\n         \"param_batch_size\": 50\n        }\n      })\n    run_id = response.json()[\"Id\"]\n    ```", "```py\n    import json\n    test_data = json.dump'({'data': [\n        [1,2,3,4,5,6,7,8,9,10]\n    ]})\n    ```", "```py\n    profile = Model.profile(ws,\n      service_name,\n      [model],\n      inference_config,\n      test_data)\n    profile.wait_for_profiling(True)\n    print(profile.get_results())\n    ```", "```py\n    {'cpu': 1.0, 'memoryInGB': 0.5}\n    ```", "```py\nfrom applicationinsights import TelemetryClient\nimport nvidia_smi\nnvidia_smi.nvmlInit()\n# Get handle for card id 0\ndev_handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\nres = nvidia_smi.nvmlDeviceGetUtilizationRates(dev_handle)\n# Submit GPU metrics to AppInsights\ntc = TelemetryClient(\"<insert appinsights key\")\ntc.track_metric(\"gpu\", res.gpu)\ntc.track_metric(\"gpu-gpu-mem\", res.memory)\n```", "```py\nfrom azureml.core.webservice import Webservice\naks_service= Webservice(ws, \"aks-deployment\")\naks_service.update(enable_app_insights=True)\n```", "```py\n    from azureml.core import Workspace, Dataset\n    from datetime import datetime\n    ws = Workspace.from_config()\n    ds_target = Dataset.get_by_name(ws, 'housing-data')\n    ds_baseline = ds_target.time_before(\n      datetime(2022, 1, 1))\n    ```", "```py\n    from azureml.datadrift import AlertConfiguration\n    alert_config = AlertConfiguration(\n      email_addresses=['<insert email address>'])\n    ```", "```py\n    from azureml.datadrift import DataDriftDetector\n    monitor = DataDriftDetector.create_from_datasets(ws,\n      \"data-drift-monitor\",\n      ds_baseline,\n      ds_target,\n      compute_target=compute_target,\n      frequency='Month',\n      feature_list=['a', 'b', 'c'],\n      alert_config=alert_config,\n      drift_threshold=0.25,\n      latency=24)\n    ```", "```py\n    monitor.enable_schedule() \n    ```"]