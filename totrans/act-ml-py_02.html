<html><head></head><body>
<div id="book-content" class="calibre2">
<div id="sbo-rt-content" class="calibre3"><div id="_idContainer012" class="calibre4">
			<h1 id="_idParaDest-15" class="calibre8"><a id="_idTextAnchor015" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>1</h1>
			<h1 id="_idParaDest-16" class="calibre8"><a id="_idTextAnchor016" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Introducing Active Machine Learning</h1>
			<p class="calibre6">Machine learning models require large, labeled datasets, which can be expensive and time-consuming to obtain. <strong class="bold">Active machine learning</strong> (<strong class="bold">active ML</strong>) minimizes the labeling effort needed by intelligently choosing which data points a human should label. In this book, you will gain the necessary knowledge to understand active learning, including its mechanisms and applications. With these fundamentals, the subsequent chapters will equip you with concrete skills to implement active learning techniques on <span>your own.</span></p>
			<p class="calibre6">By the end of this book, you will have practical experience with state-of-the-art strategies to minimize labeling costs and maximize model performance. You will be able to apply active learning to enhance the efficiency and adaptability of your models across different application areas, such as vision <span>and language.</span></p>
			<p class="calibre6">To begin with, this chapter provides an introduction to active ML and explains how it can improve model accuracy using fewer labeled examples. By the end of the chapter, you will have covered <span>the following:</span></p>
			<ul class="calibre16">
				<li class="calibre20">Understanding active machine <span>learning systems</span></li>
				<li class="calibre20">Exploring query <span>strategy scenarios</span></li>
				<li class="calibre20">Comparing active and <span>passive learning</span></li>
			</ul>
			<h1 id="_idParaDest-17" class="calibre8"><a id="_idTextAnchor017" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Understanding active machine learning systems</h1>
			<p class="calibre6"><strong class="bold">Active machine learning</strong> (<strong class="bold">active ML</strong>) is a powerful approach that seeks<a id="_idIndexMarker000" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to create predictive models with remarkable accuracy, all while minimizing the number of labeled training examples required. This is achieved by employing a clever strategy that involves selectively choosing the most informative data points to be labeled by a knowledgeable oracle, such as a human annotator. By doing so, active learning enables models to extract the necessary knowledge they need from a relatively small amount <span>of data.</span></p>
			<p class="calibre6">Now, let’s explore some definitions and the fundamental concepts that form the foundation of <span>active ML.</span></p>
			<h2 id="_idParaDest-18" class="calibre9"><a id="_idTextAnchor018" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Definition</h2>
			<p class="calibre6"><strong class="bold">Active learning</strong> can be defined as a dynamic<a id="_idIndexMarker001" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> and iterative approach to machine learning, where the algorithm intelligently engages with an <strong class="bold">oracle</strong> to label new data points. An oracle is a source that<a id="_idIndexMarker002" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> provides labels for data points queried by the active learner. The oracle acts as a teacher, guiding the model by providing labels for its most informative queries. Typically, oracles are human annotators or experts who can manually assign labels to new data points. However, oracles can also be simulation engines, crowdsourcing services, or other systems capable <span>of labeling.</span></p>
			<p class="calibre6">The key objective of active ML is to select and prioritize the most informative data points for the model. The aim is to achieve higher accuracy levels while minimizing the need for extensive training labels, in comparison to traditional supervised learning methods, which rely on large datasets of pre-labeled examples to train models in predicting outcomes. On the other hand, unsupervised learning methods work with unlabeled data, seeking patterns or structures without explicit instruction on the outcomes. Active learning bridges these approaches by focusing on a semi-supervised learning strategy. This process allows the model to actively learn and adapt over time, continuously improving its predictive capabilities by leveraging the most relevant and significant data points. By actively engaging with the data and carefully choosing which samples to label, active ML optimizes the entire learning process. It allows the algorithm to focus on the most relevant and informative instances, thereby reducing the need for extensive labeling efforts. As a result, active ML not only saves time and resources but also enables machine learning models to achieve higher accuracy and better generalization. Active ML opens the door for more advanced and intelligent machine learning systems by effectively prioritizing <span>data labeling.</span></p>
			<h2 id="_idParaDest-19" class="calibre9"><a id="_idTextAnchor019" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Potential range of applications</h2>
			<p class="calibre6">Active learning is a highly<a id="_idIndexMarker003" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> versatile technique that can significantly enhance efficiency and model performance across a wide range of applications. It does so by directing human labeling efforts to areas where they can have the <span>most impact.</span></p>
			<p class="calibre6">This approach has proven<a id="_idIndexMarker004" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to be particularly effective in <strong class="bold">computer vision applications</strong>, such as image classification, object detection, and image segmentation. By selectively acquiring labels for ambiguous images that traditional sampling methods often miss, active learning can reduce costs and improve accuracy. It does this by identifying the most informative edge cases to query, allowing for accurate results with fewer labeled samples. For example, if we consider a self-driving car object-detection model that needs to identify various objects such as people, trees, and other cars, we can utilize active learning to prioritize the classes that it may struggle <span>to learn.</span></p>
			<p class="calibre6">In <strong class="bold">natural language tasks</strong>, such as document classification<a id="_idIndexMarker005" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> and translation, active learners play a crucial role in filling gaps in linguistic coverage. By querying sentences that cover rare vocabulary and structures, active learning improves adaptation and improves overall performance. The labeling process is focused only on the most useful examples, minimizing the need for extensive <span>labeling efforts.</span></p>
			<p class="calibre6"><strong class="bold">Anomaly detection</strong> is another domain where active<a id="_idIndexMarker006" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> learning proves to be highly effective. By targeting rare outliers and anomalies, which are critical for identifying issues such as fraud, active learning improves the detection of these important but uncommon examples. By focusing human reviews on unusual cases, active learning enhances the overall accuracy of anomaly <span>detection systems.</span></p>
			<p class="calibre6"><strong class="bold">Recommendation systems</strong> heavily rely on user feedback, and active<a id="_idIndexMarker007" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> learning provides a framework for acquiring this feedback intelligently. By querying users on their preferences for certain content, active learning gathers focused signals that can be used to fine-tune recommendations. For example, streaming services can use active learning techniques to improve the accuracy and relevance of their <span>video suggestions.</span></p>
			<p class="calibre6">In the field of <strong class="bold">medical diagnosis</strong>, active learning techniques<a id="_idIndexMarker008" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> play a vital role in minimizing physician time spent on common diagnoses. By identifying challenging cases that require expert input, active learning ensures that effort is focused on ambiguous examples that can significantly improve diagnostic <span>model performance.</span></p>
			<p class="calibre6">Active learning provides both the algorithms and mechanisms necessary to efficiently focus human effort on useful areas across various applications. By selectively acquiring labels, it overcomes the inherent costs and challenges associated with supervised machine learning, making it an invaluable tool in the field of artificial intelligence. Across science, engineering, and technology, the ability to intelligently guide data collection and labeling can accelerate progress with minimal <span>human effort.</span></p>
			<p class="calibre6">Now, let’s move ahead to discuss the key components of an active learning system and how they apply to all the applications we have <span>just mentioned.</span></p>
			<h2 id="_idParaDest-20" class="calibre9"><a id="_idTextAnchor020" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Key components of active machine learning systems</h2>
			<p class="calibre6">Active ML systems comprise<a id="_idIndexMarker009" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> four <span>key elements:</span></p>
			<ul class="calibre16">
				<li class="calibre20"><strong class="bold">Unlabeled dataset</strong>: This pool of unlabeled data<a id="_idIndexMarker010" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> points is what the active learner can query from. It may contain tens, hundreds, or even millions <span>of examples.</span></li>
				<li class="calibre20"><strong class="bold">Query strategy</strong>: This is the core mechanism<a id="_idIndexMarker011" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> of active learning. It guides how the system selects which data points to query labels for. Different criteria can be used, which we will <span>explore later.</span></li>
				<li class="calibre20"><strong class="bold">Machine learning model</strong>: The underlying predictive<a id="_idIndexMarker012" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> model being trained, such as a neural network, random forest, <span>or SVM.</span></li>
				<li class="calibre20"><strong class="bold">Oracle</strong>: The source that provides<a id="_idIndexMarker013" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> labels. This is typically a human annotator who can manually label queried <span>data points.</span></li>
			</ul>
			<p class="calibre6">How do the key components just mentioned interact with each other? <span><em class="italic">Figure 1</em></span><em class="italic">.1</em> depicts the interaction between various components of an active <span>ML loop:</span></p>
			<div class="calibre18">
				<div id="_idContainer007" class="img---figure">
					<img src="image/B21789_01_01.jpg" alt="Figure 1.1 – Active ML loop" class="calibre21"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 1.1 – Active ML loop</p>
			<p class="calibre6">Models engage in an<a id="_idIndexMarker014" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> iterative loop, such as <span>the following:</span></p>
			<ol class="calibre16">
				<li class="calibre17">The query strategy identifies the most useful data points <span>to label.</span></li>
				<li class="calibre17">These are labeled by the oracle (<span>human annotator).</span></li>
				<li class="calibre17">The newly labeled data is used to train the machine <span>learning model.</span></li>
				<li class="calibre17">The updated model is then used to inform the next round of querying <span>and labeling.</span></li>
			</ol>
			<p class="calibre6">This loop allows active learning models to intelligently explore datasets, acquiring new training labels that maximize <span>information gain.</span></p>
			<p class="calibre6">In the next section, we will dig deeper into the query strategy step by first examining the various scenarios that one can <span>choose from.</span></p>
			<h1 id="_idParaDest-21" class="calibre8"><a id="_idTextAnchor021" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Exploring query strategies scenarios</h1>
			<p class="calibre6">Active learning can be implemented<a id="_idIndexMarker015" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> in different ways, depending on the nature of the unlabeled data and how the queries are performed. There are three main scenarios to consider when implementing <span>active learning:</span></p>
			<ul class="calibre16">
				<li class="calibre20">Membership <span>query synthesis</span></li>
				<li class="calibre20">Stream-based <span>selective sampling</span></li>
				<li class="calibre20"><span>Pool-based sampling</span></li>
			</ul>
			<p class="calibre6">These scenarios offer different ways to optimize and improve the active learning process. Understanding these scenarios can help you make informed decisions and choose the most suitable approach for your specific needs. In this section, we will explore each of <span>these scenarios.</span></p>
			<h2 id="_idParaDest-22" class="calibre9"><a id="_idTextAnchor022" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Membership query synthesis</h2>
			<p class="calibre6">In <strong class="bold">membership query synthesis</strong>, the active learner has the ability<a id="_idIndexMarker016" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to create its own<a id="_idIndexMarker017" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> unlabeled data points in order to improve its training. This is done by generating new data points from scratch and then requesting the oracle for labels, as depicted in <span><em class="italic">Figure 1</em></span><em class="italic">.2</em>. By incorporating these newly labeled data points into its training set, the model becomes more robust <span>and accurate:</span></p>
			<div class="calibre18">
				<div id="_idContainer008" class="img---figure">
					<img src="image/B21789_01_02.jpg" alt="Figure 1.2 – Membership query synthesis workflow" class="calibre22"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 1.2 – Membership query synthesis workflow</p>
			<p class="calibre6">Let’s consider an image classifier as an example. With the power of synthesis, the active learner can create new images by combining various shapes, textures, and colors in different compositions. This allows the model to explore a wide range of possibilities and learn to recognize patterns and features that may not have been present in the original <span>labeled data.</span></p>
			<p class="calibre6">Similarly, a text classifier can <a id="_idIndexMarker018" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>also benefit from membership<a id="_idIndexMarker019" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> query synthesis. By generating new sentences and paragraphs with specific words or structures, the model can expand its understanding of different language patterns and improve its ability to classify <span>text accurately.</span></p>
			<p class="calibre6">There are several advantages<a id="_idIndexMarker020" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> of membership <span>query synthesis:</span></p>
			<ul class="calibre16">
				<li class="calibre20">The model has complete control over the data points it queries, allowing it to focus on corner cases and unusual examples that normal sampling might overlook. This helps to reduce overfitting and improve the model’s generalization by increasing the diversity of <span>the data.</span></li>
				<li class="calibre20">By synthesizing data, the model can actively explore its weaknesses rather than rely on what is in the <span>training data</span></li>
				<li class="calibre20">This is useful for problems where data synthesis is straightforward, such as simple tabular data <span>and sequences.</span></li>
			</ul>
			<p class="calibre6">However, there are also several disadvantages<a id="_idIndexMarker021" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to using <span>this scenario:</span></p>
			<ul class="calibre16">
				<li class="calibre20">It requires the ability to synthesize new useful data points accurately. This can be extremely difficult for complex real-world data such as images, audio, <span>and video.</span></li>
				<li class="calibre20">Data synthesis does not work well for high-dimensional, nuanced data. The generated points are often <span>not natural.</span></li>
				<li class="calibre20">It is less practical for real-world applications today compared to pool-based sampling. Advances in generative modeling can <span>improve synthesis.</span></li>
				<li class="calibre20">It is computationally expensive to repeatedly generate full data points from scratch, especially for <span>multimedia data.</span></li>
				<li class="calibre20">Over-generating synthetic examples can lead to overfitting, wherein the model becomes overly fixated on classifying the synthetic instances rather than the actual data. As a result, the model’s accuracy<a id="_idIndexMarker022" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> may suffer when confronted with unfamiliar and <span>unseen data.</span></li>
			</ul>
			<p class="calibre6">Overall, membership query synthesis<a id="_idIndexMarker023" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> is mostly studied in theory and rarely applied in practice today. However, advances in generative modeling may increase its viability for real applications in <span>the future.</span></p>
			<h2 id="_idParaDest-23" class="calibre9"><a id="_idTextAnchor023" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Stream-based selective sampling</h2>
			<p class="calibre6">In <strong class="bold">stream-based selective sampling</strong>, the process of receiving unlabeled<a id="_idIndexMarker024" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> data points occurs<a id="_idIndexMarker025" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> continuously and dynamically rather than in a static and predetermined batch. <span><em class="italic">Figure 1</em></span><em class="italic">.3</em> shows how the active learner is presented with a constant flow of data points, one <span>after another:</span></p>
			<div class="calibre18">
				<div id="_idContainer009" class="img---figure">
					<img src="image/B21789_01_03.jpg" alt="Figure 1.3 – Stream-based selective sampling workflow" class="calibre23"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 1.3 – Stream-based selective sampling workflow</p>
			<p class="calibre6">The active learner is faced with the task of making instantaneous decisions about whether or not to request a label for each individual point. This real-time decision-making process adds an element<a id="_idIndexMarker026" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> of flexibility and adaptability<a id="_idIndexMarker027" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to the learning algorithm. This allows it to adjust its sampling strategy on the fly based on the evolving characteristics of the incoming data stream. By actively selecting which data points to query for labels, the active learner can optimize the learning process and make the most efficient use of limited <span>labeling resources.</span></p>
			<p class="calibre6">Stream-based selective sampling finds its applications in data, including user activity, live sensor data, and the data in news feeds, social media, and many <span>more sources.</span></p>
			<p class="calibre6">There is a massive amount of data being generated by user activity in the form of clicks, searches, and posts. By selectively labeling a fraction of user actions on websites and apps to train models (e.g., predicting churn and engagement), stream-based selective sampling avoids storing massive logs of all <span>user actions.</span></p>
			<p class="calibre6">On the other hand, live sensor data from devices or machinery requires continual monitoring. To minimize this oversight, the querying of labels is performed on only the most critical sensor events from <span>autonomous systems.</span></p>
			<p class="calibre6">In the case of news feeds, social media streams, and content recommendation systems, stream-based selective sampling helps in acquiring user feedback for recommending a small fraction of content items. This focused user input improves suggestions without overwhelming <span>the users.</span></p>
			<p class="calibre6">In these cases, data arrives<a id="_idIndexMarker028" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> constantly in real time. The active<a id="_idIndexMarker029" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> learning model evaluates each new data point and selectively queries the oracle for labels on the most useful examples. The less useful points are discarded rather <span>than stored.</span></p>
			<p class="calibre6">The main advantages of stream-based selective sampling<a id="_idIndexMarker030" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> are <span>the following:</span></p>
			<ul class="calibre16">
				<li class="calibre20">It is well-suited for real-time applications with constant live <span>data streams</span></li>
				<li class="calibre20">It is storage efficient as the full data stream isn’t saved, only the <span>queried points</span></li>
				<li class="calibre20">It is scalable because it involves efficiently managing high volumes of incoming data without the need for storing all <span>of it</span></li>
			</ul>
			<p class="calibre6">However, it comes with<a id="_idIndexMarker031" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> a few drawbacks, too, listed <span>as follows:</span></p>
			<ul class="calibre16">
				<li class="calibre20">The model must evaluate and make query decisions on the fly as the stream arrives. There is no opportunity for <span>deep analysis.</span></li>
				<li class="calibre20">Discarded points cannot be revisited or <span>re-queried later.</span></li>
				<li class="calibre20">Changes in data distribution over time are harder to adapt to without retraining <span>from scratch.</span></li>
				<li class="calibre20">If the model only labels specific data types, it can introduce bias. This can result in a model that is optimized for those particular data types but may not perform well when faced with <span>new data.</span></li>
				<li class="calibre20">The effectiveness of the approach may vary depending on the streaming platform and its limitations, which can<a id="_idIndexMarker032" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> restrict <span>its usefulness.</span></li>
			</ul>
			<p class="calibre6">Overall, stream-based selective sampling<a id="_idIndexMarker033" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> is an efficient approach when low storage and real-time response are critical. It works well when the stream distribution is relatively stable. If the stream changes over time, pool-based sampling may be more effective since earlier points can <span>be re-analyzed.</span></p>
			<h2 id="_idParaDest-24" class="calibre9"><a id="_idTextAnchor024" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Pool-based sampling</h2>
			<p class="calibre6">In the context of <strong class="bold">pool-based sampling</strong>, the active learner is given access<a id="_idIndexMarker034" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> to a large collection<a id="_idIndexMarker035" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> of unlabeled data points that remain static over time. The data points in that scenario are usually acquired from an existing unlabeled dataset or a labeled dataset where the labels are temporarily hidden. They can also be collected by scraping <span>public sources.</span></p>
			<p class="calibre6">Active learning selects data points from a static data pool and sends them to the oracle for labeling. Unlike the stream-based sampling scenario, none of the data points <span>are discarded.</span></p>
			<p class="calibre6"><span><em class="italic">Figure 1</em></span><em class="italic">.4</em> depicts a pool-based <span>sampling workflow:</span></p>
			<div class="calibre18">
				<div id="_idContainer010" class="img---figure">
					<img src="image/B21789_01_04.jpg" alt="Figure 1.4 – Pool-based sampling workflow" class="calibre24"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 1.4 – Pool-based sampling workflow</p>
			<p class="calibre6">The static pool serves as a dataset from which the learner can repeatedly draw samples, with the aim of acquiring the most informative labeled examples. By tapping into this pool, the learner can explore and extract valuable insights that contribute to the learning process. Through multiple iterations of sampling, the learner gains a deeper understanding and improves their ability to make <span>informed decisions.</span></p>
			<p class="calibre6">The pool is designed to provide<a id="_idIndexMarker036" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> users with the utmost<a id="_idIndexMarker037" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> flexibility, enabling them to query any point within the pool at any given time. This feature allows for seamless access to data points, ensuring convenience and versatility in the querying process. The size of the pool is determined based on computational constraints, with common sizes ranging from 10,000 to 1,000,000 data points. The choice of pool size depends on various factors, such as the computational resources available and the specific requirements of the model <span>being used.</span></p>
			<p class="calibre6">It is important to emphasize that throughout the iterative process, the pool remains fixed. The model continuously queries and selects the most valuable points from the pool, optimizing its performance and refining its results. This dynamic interplay between the pool and the model is essential in achieving optimal efficiency and accuracy in <span>data analysis.</span></p>
			<p class="calibre6">By maintaining a fixed pool size while iteratively querying for valuable points, the model ensures that it can adapt and evolve based on the changing needs of the analysis. This iterative approach allows the model to continuously refine its understanding and improve its predictions, leading to more insightful and <span>accurate results.</span></p>
			<p class="calibre6">For example, potential pool datasets could include <span>the following:</span></p>
			<ul class="calibre16">
				<li class="calibre20">A database table with many <span>unlabeled rows</span></li>
				<li class="calibre20">A collection of images, audio clips, <span>or documents</span></li>
				<li class="calibre20">An existing ML dataset with the labels <span>temporarily removed</span></li>
			</ul>
			<p class="calibre6">Pool-based sampling offers<a id="_idIndexMarker038" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> several advantages, such as <span>the following:</span></p>
			<ul class="calibre16">
				<li class="calibre20">Maximum flexibility in sampling. Any point can be queried <span>multiple times</span></li>
				<li class="calibre20">The sampling strategy can be adjusted and improved over <span>multiple iterations</span></li>
				<li class="calibre20">The ability to re-query points and fine-tune over time as the <span>model changes</span></li>
			</ul>
			<p class="calibre6">There are a few challenges<a id="_idIndexMarker039" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> <span>as well:</span></p>
			<ul class="calibre16">
				<li class="calibre20">It requires sufficient storage for the full unlabeled <span>pool dataset</span></li>
				<li class="calibre20">It is computationally intensive to search large, high-dimensional data pools for <span>optimal queries</span></li>
				<li class="calibre20">The pool does not adapt over time in the way that a live data <span>stream does.</span></li>
				<li class="calibre20">The model’s accuracy depends on the selection method used to identify the most informative sample, which can reduce the <span>model’s accuracy</span></li>
			</ul>
			<p class="calibre6">Overall, pool-based sampling<a id="_idIndexMarker040" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> provides the most practical active learning solution for many real-world applications. With sufficient storage and computation, it offers total flexibility in iterative querying. Stream-based sampling can complement in cases where real-time performance <span>is critical.</span></p>
			<p class="calibre6">Having explored the three different types of active ML scenarios, we can now assess how they differ from traditional passive <span>learning methods.</span></p>
			<h1 id="_idParaDest-25" class="calibre8"><a id="_idTextAnchor025" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Comparing active and passive learning</h1>
			<p class="calibre6">In traditional passive machine<a id="_idIndexMarker041" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> learning, models are trained on fixed<a id="_idIndexMarker042" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> and pre-existing labeled datasets, which are carefully assembled to include both data points and their respective ground truth labels. The model then goes through the dataset once, without any iteration or interaction, and learns the patterns and relationships between the features and labels. This is the passive learning approach. It’s important to note that the model only trains on the finite data it is provided and cannot actively seek out new information or modify its training based on new inputs. Moreover, the labeled datasets required for a passive learning approach come at <span>a cost.</span></p>
			<p class="calibre6">There are several reasons why labeling<a id="_idIndexMarker043" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> is expensive in traditional <span>machine learning:</span></p>
			<ul class="calibre16">
				<li class="calibre20"><strong class="bold">Manual labeling requires experts</strong>: Accurately labeling data often demands the expertise of domain specialists such as doctors or ecologists. However, their time is limited and valuable, making their <span>involvement expensive.</span></li>
				<li class="calibre20"><strong class="bold">Time-consuming process</strong>: Manually labeling data such as images, audio clips, or text is a slow and tedious task that does not scale well. It can take minutes to hours to accurately label a single data point. While several annotation platforms integrate features and tools to make the labeling process smoother and faster, it still <span>remains slow.</span></li>
				<li class="calibre20"><strong class="bold">Annotation errors</strong>: Some labels may be of lower quality due to overworked, rushed, or non-expert labelers. These incorrect and noisy labels can have a negative impact on the performance of models. To prevent this, additional oversight and one or more reviewing steps are <span>often necessary.</span></li>
				<li class="calibre20"><strong class="bold">Accumulating labeling costs</strong>: When the cost per hour of labeling is multiplied by the number of examples needed, the overall expenses for data annotation can quickly become prohibitive, especially if several reviewing steps are needed. Modern deep learning models often require a large number of labeled examples, which can be <span>very expensive.</span></li>
				<li class="calibre20"><strong class="bold">Expanding model capabilities</strong>: As new cases emerge, there is a constant need to acquire new labeled data. Continuously<a id="_idIndexMarker044" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> labeling evolving data poses <span>a challenge.</span></li>
			</ul>
			<p class="calibre6">All these reasons make passive labeling an expensive bottleneck. Minimizing these costs is crucial for developing scalable and accurate <span>AI systems.</span></p>
			<p class="calibre6">Active learning, on the other hand, takes an interactive and iterative approach. Instead of receiving a predefined labeled dataset, an active learning model dynamically chooses which data points it wants to be labeled. It analyzes a pool of unlabeled data and intelligently selects the most useful points to query an oracle for labels. The newly labeled data is then incorporated into its <span>training set.</span></p>
			<p class="calibre6">This introduces a feedback<a id="_idIndexMarker045" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> loop between data sampling, human labeling, and model<a id="_idIndexMarker046" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> training. The model guides its own learning by acquiring new training data specifically tailored to improve its weaknesses. Human effort is focused only on the most informative examples through <span>selective sampling:</span></p>
			<div class="calibre18">
				<div id="_idContainer011" class="img---figure">
					<img src="image/B21789_01_05.jpg" alt="Figure 1.5 – Passive learning and active learning – a comparison" class="calibre25"/>
				</div>
			</div>
			<p class="calibre6" lang="en-US" xml:lang="en-US">Figure 1.5 – Passive learning and active learning – a comparison</p>
			<p class="calibre6">One key advantage of active learning is that it reduces the total amount of labeled data required. Passive learners often need vast amounts of labeled examples to achieve desired performance, which can be costly and time-consuming to collect and prepare. Active learning minimizes this upfront labeling effort by acquiring only the examples that provide the maximum <span>information value.</span></p>
			<p class="calibre6">Furthermore, active learning systems can adapt and adjust over multiple iterations of querying. The model can change its sampling strategy based on previous rounds, re-query certain examples, or increase focus on areas where it is weakest. In contrast, passive learning involves a static dataset without room <span>for adjustment.</span></p>
			<p class="calibre6">Overall, active learning provides<a id="_idIndexMarker047" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> critical benefits of reduced labeling costs<a id="_idIndexMarker048" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/> and flexible, adaptive training. By steering its own data collection, Active ML achieves higher predictive performance with significantly less reliance on vast <span>labeled datasets.</span></p>
			<h1 id="_idParaDest-26" class="calibre8"><a id="_idTextAnchor026" class="pcalibre pcalibre1 calibre5 pcalibre4 pcalibre2 pcalibre3"/>Summary</h1>
			<p class="calibre6">In this introductory chapter, we covered the fundamentals of active ML and how it contrasts with passive <span>learning approaches.</span></p>
			<p class="calibre6">You learned what active learning is and its goal of maximizing predictive performance with fewer labeled training examples. We discussed the core components of an active learning system: the unlabeled data pool, query strategy, machine learning model, and the <span>oracle labeler.</span></p>
			<p class="calibre6">You now understand the difference between membership query synthesis, stream-based sampling, and pool-based sampling scenarios. We compared active and passive learning, highlighting the benefits of an interactive, iterative approach in <span>active learning.</span></p>
			<p class="calibre6">Importantly, you now know that active learning can produce models with equal or greater accuracy while requiring far less labeled training data. This is critical for reducing the costs of modeling, as labeling is often the most <span>expensive component.</span></p>
			<p class="calibre6">The skills you gained in this introduction will equip you to determine when active learning is appropriate for a problem. You can now correctly select the right components when implementing an active <span>learning system.</span></p>
			<p class="calibre6">Now that we have covered the fundamentals of active learning, query scenarios, and applications, the next step is to dive into specific query strategies. In the next chapter, we will explore frameworks for designing effective queries to identify the most valuable data points <span>to label.</span></p>
		</div>
	</div>
</div>
</body></html>