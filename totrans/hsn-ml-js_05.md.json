["```py\n{\n  \"name\": \"Ch5-knn\",\n  \"version\": \"1.0.0\",\n  \"description\": \"ML in JS Example for Chapter 5 - k-nearest-neighbor\",\n  \"main\": \"src/index.js\",\n  \"author\": \"Burak Kanber\",\n  \"license\": \"MIT\",\n  \"scripts\": {\n    \"build-web\": \"browserify src/index.js -o dist/index.js -t [ babelify --presets [ env ] ]\",\n    \"build-cli\": \"browserify src/index.js --node -o dist/index.js -t [ babelify --presets [ env ] ]\",\n    \"start\": \"yarn build-cli && node dist/index.js\"\n  },\n  \"dependencies\": {\n    \"babel-core\": \"^6.26.0\",\n    \"babel-plugin-transform-object-rest-spread\": \"^6.26.0\",\n    \"babel-preset-env\": \"^1.6.1\",\n    \"babelify\": \"^8.0.0\",\n    \"browserify\": \"^15.1.0\",\n    \"jimp\": \"^0.2.28\"\n  }\n}\n```", "```py\n/**\n * Calculate the distance between two points.\n * Points must be given as arrays or objects with equivalent keys.\n * @param {Array.<number>} a\n * @param {Array.<number>} b\n * @return {number}\n */\nconst distance = (a, b) => Math.sqrt(\n    a.map((aPoint, i) => b[i] - aPoint)\n        .reduce((sumOfSquares, diff) => sumOfSquares + (diff*diff), 0)\n);\n```", "```py\nclass KNN {\n\n    constructor(k = 1, data, labels) {\n        this.k = k;\n        this.data = data;\n        this.labels = labels;\n    }\n\n}\n\nexport default KNN;\n```", "```py\ngenerateDistanceMap(point) {\n\n    const map = [];\n    let maxDistanceInMap;\n\n    for (let index = 0, len = this.data.length; index < len; index++) {\n\n        const otherPoint = this.data[index];\n        const otherPointLabel = this.labels[index];\n        const thisDistance = distance(point, otherPoint);\n\n        /**\n         * Keep at most k items in the map. \n         * Much more efficient for large sets, because this \n         * avoids storing and then sorting a million-item map.\n         * This adds many more sort operations, but hopefully k is small.\n         */\n        if (!maxDistanceInMap || thisDistance < maxDistanceInMap) {\n\n            // Only add an item if it's closer than the farthest of the candidates\n            map.push({\n                index,\n                distance: thisDistance,\n                label: otherPointLabel\n            });\n\n            // Sort the map so the closest is first\n            map.sort((a, b) => a.distance < b.distance ? -1 : 1);\n\n            // If the map became too long, drop the farthest item\n            if (map.length > this.k) {\n                map.pop();\n            }\n\n            // Update this value for the next comparison\n            maxDistanceInMap = map[map.length - 1].distance;\n\n        }\n    }\n\n    return map;\n}\n```", "```py\npredict(point) {\n\n    const map = this.generateDistanceMap(point);\n    const votes = map.slice(0, this.k);\n    const voteCounts = votes\n        // Reduces into an object like {label: voteCount}\n        .reduce((obj, vote) => Object.assign({}, obj, {[vote.label]: (obj[vote.label] || 0) + 1}), {})\n    ;\n    const sortedVotes = Object.keys(voteCounts)\n        .map(label => ({label, count: voteCounts[label]}))\n        .sort((a, b) => a.count > b.count ? -1 : 1)\n    ;\n\n    return {\n        label: sortedVotes[0].label,\n        voteCounts,\n        votes\n    };\n\n}\n```", "```py\nimport KNN from './knn.js';\nimport {weight_height} from './data.js';\n```", "```py\nconsole.log(\"Testing height and weight with k=5\");\nconsole.log(\"==========================\");\n\n const solver1 = new KNN(5, weight_height.data, weight_height.labels);\n\n console.log(\"Testing a 'definitely male' point:\");\n console.log(solver1.predict([200, 75]));\n console.log(\"\\nTesting a 'probably male' point:\");\n console.log(solver1.predict([170, 70]));\n console.log(\"\\nTesting a 'totally uncertain' point:\");\n console.log(solver1.predict([140, 64]));\n console.log(\"\\nTesting a 'probably female' point:\");\n console.log(solver1.predict([130, 63]));\n console.log(\"\\nTesting a 'definitely female' point:\");\n console.log(solver1.predict([120, 60]));\n```", "```py\nTesting height and weight with k=5\n======================================================================\n\n Testing a 'definitely male' point:\n { label: 'Male',\n voteCounts: { Male: 5 },\n votes:\n [ { index: 372, distance: 0, label: 'Male' },\n { index: 256, distance: 1, label: 'Male' },\n { index: 291, distance: 1, label: 'Male' },\n { index: 236, distance: 2.8284271247461903, label: 'Male' },\n { index: 310, distance: 3, label: 'Male' } ] }\n\n Testing a 'probably male' point:\n { label: 'Male',\n voteCounts: { Male: 5 },\n votes:\n [ { index: 463, distance: 0, label: 'Male' },\n { index: 311, distance: 0, label: 'Male' },\n { index: 247, distance: 1, label: 'Male' },\n { index: 437, distance: 1, label: 'Male' },\n { index: 435, distance: 1, label: 'Male' } ] }\n\n Testing a 'totally uncertain' point:\n { label: 'Male',\n voteCounts: { Male: 3, Female: 2 },\n votes:\n [ { index: 329, distance: 0, label: 'Male' },\n { index: 465, distance: 0, label: 'Male' },\n { index: 386, distance: 0, label: 'Male' },\n { index: 126, distance: 0, label: 'Female' },\n { index: 174, distance: 1, label: 'Female' } ] }\n\n Testing a 'probably female' point:\n { label: 'Female',\n voteCounts: { Female: 4, Male: 1 },\n votes:\n [ { index: 186, distance: 0, label: 'Female' },\n { index: 90, distance: 0, label: 'Female' },\n { index: 330, distance: 0, label: 'Male' },\n { index: 51, distance: 1, label: 'Female' },\n { index: 96, distance: 1, label: 'Female' } ] }\n\n Testing a 'definitely female' point:\n { label: 'Female',\n voteCounts: { Female: 5 },\n votes:\n [ { index: 200, distance: 0, label: 'Female' },\n { index: 150, distance: 0, label: 'Female' },\n { index: 198, distance: 1, label: 'Female' },\n { index: 147, distance: 1, label: 'Female' },\n { index: 157, distance: 1, label: 'Female' } ] }\n```", "```py\nexport const colors_16 = {\n data: [\n [0, 0, 0], // black\n [128, 128, 128], // gray\n [128, 0, 0], //maroon\n [255, 0, 0], // red\n [0, 128, 0], // green\n [0, 255, 0], // lime\n [128, 128, 0], // olive\n [255, 255, 0], // yellow\n [0, 0, 128], // navy\n [0, 0, 255], // blue\n [128, 0, 128], // purple\n [255, 0, 255], // fuchsia\n [0, 128, 128], // teal\n [0, 255, 255], // aqua\n [192, 192, 192], // silver\n [255, 255, 255], // white\n ],\n\n labels: [\n 'Black',\n 'Gray',\n 'Maroon',\n 'Red',\n 'Green',\n 'Lime',\n 'Olive',\n 'Yellow',\n 'Navy',\n 'Blue',\n 'Purple',\n 'Fuchsia',\n 'Teal',\n 'Aqua',\n 'Silver',\n 'White',\n ]\n };\n```", "```py\nimport KNN from './knn.js';\nimport {colors_16} from './data.js';\nimport jimp from 'jimp'\n```", "```py\nconst decolorize = filename => {\n\n  return jimp.read(filename)\n    .then(image => {\n\n      // Create a KNN instance with our color scheme as training data\n      // We use k=1 to find the single closest color\n      // k > 1 wouldn't work, because we only have 1 label per training point\n      const mapper = new KNN(1, colors_16.data, colors_16.labels);\n      const {width, height} = image.bitmap;\n\n      // For every pixel in the image...\n      for (let x = 0; x < width; x++) {\n      for (let y = 0; y < height; y++) {\n\n      // Do some work to get the RGB value as an array: [R,G,B]\n      const originalColorHex = image.getPixelColor(x, y);\n      const originalColorRgb = jimp.intToRGBA(originalColorHex);\n      const pixelPoint = [originalColorRgb.r, originalColorRgb.g, originalColorRgb.b];\n\n      // Ask the KNN instance what the closest color from the scheme is\n      const closestColor = mapper.predict(pixelPoint);\n\n      // Then get that color in hex format, and set the pixel to the new color\n      const newColor = colors_16.data[colors_16.labels.indexOf(closestColor.label)];\n      const newColorHex = jimp.rgbaToInt(newColor[0], newColor[1], newColor[2], 255);\n      image.setPixelColor(newColorHex, x, y);\n\n    }\n  }\n\n  const ext = image.getExtension();\n  image.write(filename.replace('.'+ext, '') + '_16.' + ext);\n\n  })\n  .catch(err => {\n    console.log(\"Error reading image:\");\n    console.log(err);\n  })\n};\n\nexport default decolorize\n```", "```py\n['landscape.jpeg', 'lily.jpeg', 'waterlilies.jpeg'].forEach(filename => {\n  console.log(\"Decolorizing \" + filename + '...');\n  decolorize('./files/' + filename)\n    .then(() => console.log(filename + \" decolorized\"));\n});\n```", "```py\n Decolorizing images\n =======================================================\n Decolorizing landscape.jpeg...\n Decolorizing lily.jpeg...\n Decolorizing waterlilies.jpeg...\n lily.jpeg decolorized\n waterlilies.jpeg decolorized\n landscape.jpeg decolorized\n```", "```py\n{\n \"name\": \"Ch5-Bayes\",\n \"version\": \"1.0.0\",\n \"description\": \"ML in JS Example for Chapter 5 - Bayes\",\n \"main\": \"src/index.js\",\n \"author\": \"Burak Kanber\",\n \"license\": \"MIT\",\n \"scripts\": {\n \"build-web\": \"browserify src/index.js -o dist/index.js -t [ babelify --presets [ env ] ]\",\n \"build-cli\": \"browserify src/index.js --node -o dist/index.js -t [ babelify --presets [ env ] ]\",\n \"start\": \"yarn build-cli && node dist/index.js\"\n },\n \"dependencies\": {\n \"babel-core\": \"^6.26.0\",\n \"babel-plugin-transform-object-rest-spread\": \"^6.26.0\",\n \"babel-preset-env\": \"^1.6.1\",\n \"babelify\": \"^8.0.0\",\n \"browserify\": \"^15.1.0\"\n }\n }\n```", "```py\nexport const simpleTokenizer = string => string\n .toLowerCase()\n .replace(/[^\\w\\d]/g, ' ')\n .split(' ')\n .filter(word => word.length > 3)\n .filter((word, index, arr) => arr.indexOf(word, index+1) === -1);\n```", "```py\nclass BayesClassifier {\n\n constructor(tokenizer = null) {\n this.database = {\n labels: {},\n tokens: {}\n };\n\n this.tokenizer = (tokenizer !== null) ? tokenizer : simpleTokenizer;\n }\n }\n\n export default BayesClassifier;\n```", "```py\n/**\n * Trains a given document for a label.\n * @param label\n * @param text\n */\ntrain(label, text) {\n  this.incrementLabelDocumentCount(label);\n  this.tokenizer(text).forEach(token => this.incrementTokenCount(token, label));\n}\n\n /**\n * Increments the count of documents in a given category/label\n * @param label\n */\nincrementLabelDocumentCount(label) {\n  this.database.labels[label] = this.getLabelDocumentCount(label) + 1;\n}\n\n /**\n * Returns the number of documents seen for a given category/label.\n * If null is passed as the label, return the total number of training documents seen.\n * @param label\n */\ngetLabelDocumentCount(label = null) {\n  if (label) {\n    return this.database.labels[label] || 0;\n  } else {\n    return Object.values(this.database.labels)\n      .reduce((sum, count) => sum + count, 0);\n  }\n}\n\n /**\n * Increment the count of a token observed with a given label.\n * @param token\n * @param label\n */\nincrementTokenCount(token, label) {\n  if (typeof this.database.tokens[token] === 'undefined') {\n    this.database.tokens[token] = {};\n  }\n\n  this.database.tokens[token][label] = this.getTokenCount(token, label) + 1;\n}\n\n /**\n * Get the number of times a token was seen with a given category/label.\n * If no label is given, returns the total number of times the token was seen\n * across all training examples.\n * @param token\n * @param label\n * @returns {*}\n */\ngetTokenCount(token, label = null) {\n  if (label) {\n    return (this.database.tokens[token] || {})[label] || 0;\n  } else {\n    return Object.values(this.database.tokens[token] || {})\n      .reduce((sum, count) => sum + count, 0);\n  }\n}\n```", "```py\n/**\n * Given a document, predict its category or label.\n * @param text\n * @returns {{label: string, probability: number, probabilities: array}}\n */\npredict(text) {\n  const probabilities = this.calculateAllLabelProbabilities(text);\n  const best = probabilities[0];\n\n  return {\n    label: best.label,\n    probability: best.probability,\n    probabilities\n  };\n\n}\n```", "```py\n/**\n * Given a document, determine its probability for all labels/categories encountered in the training set.\n * The first element in the return array (element 0) is the label/category with the best match.\n * @param text\n * @returns {Array.<Object>}\n */\ncalculateAllLabelProbabilities(text) {\n  const tokens = this.tokenizer(text);\n  return this.getAllLabels()\n    .map(label => ({\n      label,\n      probability: this.calculateLabelProbability(label, tokens)\n    }))\n    .sort((a, b) => a.probability > b.probability ? -1 : 1);\n}\n```", "```py\n/**\n * Get all labels encountered during training.\n * @returns {Array}\n */\ngetAllLabels() {\n  return Object.keys(this.database.labels);\n}\n```", "```py\n/**\n * Given a token stream (ie a tokenized document), calculate the probability that\n * this document has a given label.\n * @param label\n * @param tokens\n * @returns {number}\n */\ncalculateLabelProbability(label, tokens) {\n\n  // We assume that the a-priori probability of all labels are equal.\n  // You could alternatively calculate the probability based on label frequencies.\n  const probLabel = 1 / this.getAllLabels().length;\n\n  // How significant each token must be in order to be considered;\n  // Their score must be greater than epsilon from the default token score\n  // This basically filters out uninteresting tokens from consideration.\n  // Responsible for 78% => 87.8% accuracy bump (e=.17) overall.\n  const epsilon = 0.15;\n\n  // For each token, we have to calculate a \"token score\", which is the probability of this document\n  // belonging to a category given the token appears in it.\n  const tokenScores = tokens\n    .map(token => this.calculateTokenScore(token, label))\n    .filter(score => Math.abs(probLabel - score) > epsilon);\n\n // To avoid floating point underflow when working with really small numbers,\n // we add combine the token probabilities in log space instead.\n // This is only used because of floating point math and should not affect the algorithm overall.\n  const logSum = tokenScores.reduce((sum, score) => sum + (Math.log(1-score) - Math.log(score)), 0);\n  const probability = 1 / (1 + Math.exp(logSum));\n\n  return probability;\n}\n```", "```py\nconst multiplyArray = arr => arr.reduce((product, current) => current * product, 1);\nconst tokenScores = []; // array of scores, defined elsewhere\nconst inverseTokenScores = tokenScores.map(score => 1 - score);\nconst combinedProbability = multiplyArray(tokenScores) / (multiplyArray(tokenScores) + multiplyArray(inverseTokenScores));\n```", "```py\np = (p1 * p2 * p3 * ... pN) / ( (p1 * p2 * p3 * ... pN) + (1-p1 * 1-p2 * 1-p3 * ... 1-pN) )\n```", "```py\n /**\n * Given a token and a label, calculate the probability that\n * the document has the label given that the token is in the document.\n * We do this by calculating the much easier to find Bayesian equivalent:\n * the probability that the token appears, given the label (the word frequency in that category).\n * This method also adjusts for rare tokens.\n * @param token\n * @param label\n * @returns {number}\n */\ncalculateTokenScore(token, label) {\n  const rareTokenWeight = 3;\n\n  const totalDocumentCount = this.getLabelDocumentCount();\n  const labelDocumentCount = this.getLabelDocumentCount(label);\n  const notLabelDocumentCount = totalDocumentCount - labelDocumentCount;\n\n  // Assuming equal probabilities gave us 1% accuracy bump over using the frequencies of each label\n  const probLabel = 1 / this.getAllLabels().length;\n  const probNotLabel = 1 - probLabel;\n\n  const tokenLabelCount = this.getTokenCount(token, label);\n  const tokenTotalCount = this.getTokenCount(token);\n  const tokenNotLabelCount = tokenTotalCount - tokenLabelCount;\n\n  const probTokenGivenLabel = tokenLabelCount / labelDocumentCount;\n  const probTokenGivenNotLabel = tokenNotLabelCount / notLabelDocumentCount;\n  const probTokenLabelSupport = probTokenGivenLabel * probLabel;\n  const probTokenNotLabelSupport = probTokenGivenNotLabel * probNotLabel;\n\n  const rawWordScore =\n    (probTokenLabelSupport)\n    /\n    (probTokenLabelSupport + probTokenNotLabelSupport);\n\n  // Adjust for rare tokens -- essentially weighted average\n  // We're going to shorthand some variables to make reading easier.\n  // s is the \"strength\" or the \"weight\"\n  // n is the number of times we've seen the token total\n  const s = rareTokenWeight;\n  const n = tokenTotalCount;\n  const adjustedTokenScore =\n    ( (s * probLabel) + (n * (rawWordScore || probLabel)) )\n    /\n    ( s + n );\n\n  return adjustedTokenScore;\n}\n```", "```py\nimport readline from 'readline';\nimport fs from 'fs';\nimport BayesClassifier, {simpleTokenizer} from \"./bayes\";\n\nconst classifier = new BayesClassifier(simpleTokenizer);\n```", "```py\nconst trainer = (filename, label, classifier) => {\n\n  return new Promise((resolve) => {\n    console.log(\"Training \" + label + \" examples...\");\n    readline.createInterface({\n      input: fs.createReadStream(filename)\n    })\n      .on('line', line => classifier.train(label, line))\n      .on('close', () => {\n        console.log(\"Finished training \" + label + \" examples.\");\n        resolve();\n      });\n  });\n}\n```", "```py\nconst tester = (filename, label, classifier) => {\n\n  return new Promise((resolve) => {\n    let total = 0;\n    let correct = 0;\n    console.log(\"Testing \" + label + \" examples...\");\n    readline.createInterface({ input: fs.createReadStream(filename) })\n      .on('line', line => {\n        const prediction = classifier.predict(line);\n        total++;\n        if (prediction.label === label) {\n          correct++;\n        }\n      })\n      .on('close', () => {\n        console.log(\"Finished testing \" + label + \" examples.\");\n        const results = {total, correct};\n        console.log(results);\n        resolve(results);\n      });\n  }); \n}\n```", "```py\nPromise.all([\n  trainer('./data/train_positive.txt', 'positive', classifier),\n  trainer('./data/train_negative.txt', 'negative', classifier)\n])\n  .then(() => {\n    console.log(\"Finished training. Now testing.\");\n\n    Promise.all([\n      tester('./data/test_negative.txt', 'negative', classifier),\n      tester('./data/test_positive.txt', 'positive', classifier)\n    ])\n      .then(results => results.reduce(\n        (obj, item) => ({total: obj.total + item.total, correct: obj.correct + item.correct}), {total: 0, correct: 0}\n      ))\n      .then(results => {\n        const pct = (100 * results.correct / results.total).toFixed(2) + '%';\n        console.log(results);\n        console.log(\"Test results: \" + pct);\n      });\n })\n```", "```py\nTraining positive examples...\nTraining negative examples...\nFinished training positive examples.\nFinished training negative examples.\nFinished training. Now testing.\nTesting negative examples...\nTesting positive examples...\nFinished testing positive examples.\n{ total: 4999, correct: 4402 }\nFinished testing negative examples.\n{ total: 5022, correct: 4738 }\n{ total: 10021, correct: 9140 }\nTest results: 91.21%\n```", "```py\nPromise.all([\n  trainer('./data/train_positive.txt', 'positive', classifier),\n  trainer('./data/train_negative.txt', 'negative', classifier)\n])\n  .then(() => {\n\n    const tests = [\n      \"i really hated this awful movie, it was so bad I didn't even know what to do with myself\",\n      \"this was the best movie i've ever seen. it was so exciting, i was on the edge of my seat every minute\",\n      \"i am indifferent about this\"\n    ];\n\n    tests.forEach(test => {\n      console.log(\"Testing: \" + test);\n      const result = classifier.predict(test);\n      console.log(result);\n    });\n  });\n```", "```py\nTraining positive examples...\nTraining negative examples...\nFinished training positive examples.\nFinished training negative examples.\n\nTesting: i really hated this awful movie, it was so bad I didn't even know what to do with myself\n{ label: 'negative',\n probability: 0.9727173302897202,\n probabilities:\n [ { label: 'negative', probability: 0.9727173302897202 },\n { label: 'positive', probability: 0.027282669710279664 } ] }\n\nTesting: this was the best movie i've ever seen. it was so exciting, i was on the edge of my seat every minute\n{ label: 'positive',\n probability: 0.8636681390743286,\n probabilities:\n [ { label: 'positive', probability: 0.8636681390743286 },\n { label: 'negative', probability: 0.13633186092567148 } ] }\n\nTesting: i am indifferent about this\n{ label: 'negative',\n probability: 0.5,\n probabilities:\n [ { label: 'negative', probability: 0.5 },\n { label: 'positive', probability: 0.5 } ] }\n```", "```py\n{\n \"name\": \"Ch5-SVM\",\n \"version\": \"1.0.0\",\n \"description\": \"ML in JS Example for Chapter 5 - Support Vector Machine\",\n \"main\": \"src/index.js\",\n \"author\": \"Burak Kanber\",\n \"license\": \"MIT\",\n \"scripts\": {\n \"build-web\": \"browserify src/index.js -o dist/index.js -t [ babelify --presets [ env ] ]\",\n \"build-cli\": \"browserify src/index.js --node -o dist/index.js -t [ babelify --presets [ env ] ]\",\n \"start\": \"yarn build-cli && node dist/index.js\"\n },\n \"dependencies\": {\n \"babel-core\": \"^6.26.0\",\n \"babel-plugin-transform-object-rest-spread\": \"^6.26.0\",\n \"babel-preset-env\": \"^1.6.1\",\n \"babelify\": \"^8.0.0\",\n \"browserify\": \"^15.1.0\",\n \"libsvm-js\": \"^0.1.3\",\n \"ml-cross-validation\": \"^1.2.0\",\n \"ml-dataset-iris\": \"^1.0.0\",\n \"ml-random-forest\": \"^1.0.2\"\n }\n }\n```", "```py\nimport SVM from 'libsvm-js/asm';\nimport IrisDataset from 'ml-dataset-iris';\n```", "```py\nconst data = IrisDataset.getNumbers();\nconst labels = IrisDataset.getClasses().map(\n  (elem) => IrisDataset.getDistinctClasses().indexOf(elem)\n);\n```", "```py\nconst loss = (expected, actual) => {\n  let incorrect = 0,\n  len = expected.length;\n  for (let i in expected) {\n    if (expected[i] !== actual[i]) {\n      incorrect++;\n    }\n  }\n  return incorrect / len;\n};\n```", "```py\nconsole.log(\"Support Vector Machine\");\nconsole.log(\"======================\");\n\nconst svm = new SVM({\n  kernel: SVM.KERNEL_TYPES.RBF,\n  type: SVM.SVM_TYPES.C_SVC,\n  gamma: 0.25,\n  cost: 1,\n  quiet: true\n});\n\nsvm.train(data, labels);\n\nconst svmPredictions = svm.predict(data);\nconst svmCvPredictions = svm.crossValidation(data, labels, 5);\n\nconsole.log(\"Loss for predictions: \" + Math.round(loss(labels, svmPredictions) * 100) + \"%\");\nconsole.log(\"Loss for crossvalidated predictions: \" + Math.round(loss(labels, svmCvPredictions) * 100) + \"%\");\n```", "```py\n Support Vector Machine\n =============================================\n Loss for predictions: 1%\n Loss for crossvalidated predictions: 3%\n```", "```py\n Support Vector Machine\n =============================================\n Loss for predictions: 0%\n Loss for crossvalidated predictions: 25%\n```", "```py\nimport {RandomForestClassifier} from 'ml-random-forest';\nimport crossValidation from 'ml-cross-validation';\n```", "```py\nconsole.log(\"======================\");\nconsole.log(\"Random Forest\");\nconsole.log(\"======================\");\n\nconst rfOptions = {\n  maxFeatures: 3,\n  replacement: true,\n  nEstimators: 100,\n  useSampleBagging: true\n};\n\nconst rf = new RandomForestClassifier(rfOptions);\nrf.train(data, labels);\nconst rfPredictions = rf.predict(data);\n\nconst confusionMatrix = crossValidation.kFold(RandomForestClassifier, data, labels, rfOptions, 10);\nconst accuracy = confusionMatrix.getAccuracy();\n\nconsole.log(\"Predictions:\");\nconsole.log(rfPredictions.join(\",\"));\nconsole.log(\"\\nLoss for predictions: \" + Math.round(loss(labels, rfPredictions) * 100) + \"%\");\nconsole.log(\"Loss for crossvalidated predictions: \" + Math.round( (1 - accuracy) * 100) + \"%\\n\");\nconsole.log(confusionMatrix);\n```", "```py\nRandom Forest\n======================================================================\nPredictions:\n0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0, 0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,2,0,2,0,2,0,0,2,2,2,1,2,1,2,2,1, 2,2,2,2,2,2,2,2,2,0,1,1,2,2,0,2,2,2,1,1,1,2,2,0,1,0,0,2,0,0,2,2,2,2,2,\n2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\n2,2,2,2,2,2,2,2,2,2\n\nLoss for predictions: 31%\nLoss for crossvalidated predictions: 33%\n\nConfusionMatrix {\n labels: [ 0, 1, 2 ],\n matrix: [ [ 43, 6, 1 ], [ 8, 11, 31 ], [ 1, 2, 47 ] ] }\n```", "```py\nConfusionMatrix {\n labels: [ 0, 1, 2 ],\n matrix: [ [ 43, 6, 1 ], [ 8, 11, 31 ], [ 1, 2, 47 ] ] }\n```", "```py\n0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,2,0,2,0,2,0,0,2,2,2,1,2,1,2,2,1,2,2,2,2,2,2,2,2,2,0,1,1,2,2,0,2,2,2,1,1,1,2,2,0,1,0,0,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2\n```"]