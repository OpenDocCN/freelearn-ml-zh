<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer674">
    <h1 class="chapterNumber">15</h1>
    <h1 class="chapterTitle" id="_idParaDest-335">Making Use of Big Data</h1>
    <p class="normal">Although today’s most exciting machine learning research is found in the realm of big data—computer vision, natural language processing, autonomous vehicles, and so on—most business applications are much smaller scale, using what might be termed, at best, “<em class="italic">medium</em>” data. As noted in <em class="chapterRef">Chapter 12</em>, <em class="italic">Advanced Data Preparation</em>, true big data work requires access to datasets and computing facilities generally found only at very large tech companies or research universities. Even then, the actual job of using these resources is often primarily a feat of data engineering, which simplifies the data greatly before its use in conventional business applications.</p>
    <p class="normal">The good news is that the headline-making research conducted at big data companies eventually trickles down and can be applied in simpler forms to more traditional machine learning tasks. This chapter covers a variety of approaches for making use of such big data methods in R. You will learn:</p>
    <ul>
      <li class="bulletList">How to borrow from the deep learning models developed at big data companies and apply them to conventional modeling tasks</li>
      <li class="bulletList">Strategies for reducing the complexity of large and unstructured big data formats like text and images so that they can be used for prediction</li>
      <li class="bulletList">Cutting-edge packages and approaches for accessing and modeling big datasets that may be too large to fit into memory</li>
    </ul>
    <p class="normal">Despite R’s reputation for being ill equipped for big data projects, the efforts of the R community have gradually transformed it into a tool capable of tackling a surprising number of advanced tasks. The goal of this chapter is to demonstrate R’s ability to remain relevant in the era of deep learning and big data. Even though R is unlikely to be found at the heart of the biggest big data projects, and despite facing increasing competition from Python and cloud-based tools, R’s strengths keep it on the desktops of many practicing data scientists.</p>
    <h1 class="heading-1" id="_idParaDest-336">Practical applications of deep learning</h1>
    <p class="normal">Deep learning <a id="_idIndexMarker1707"/>has received a great deal of attention lately due to its successes in tackling machine learning tasks that have been notoriously difficult to solve with conventional methods. Using sophisticated neural networks to teach computers to think more like a human has allowed machines to catch up with or even surpass human performance on many tasks that humans once held a seemingly insurmountable lead. Perhaps more importantly, even if humans still perform better at certain tasks, the upsides of machine learning—workers that never tire, never get bored, and require no salary—turn even imperfect automatons into useful tools for many tasks.</p>
    <p class="normal">Unfortunately, for those of us working outside of large technology companies and research organizations, it is not always easy to take advantage of deep learning methods. Training a deep learning model generally requires not only state-of-the-art computing hardware but also large volumes of training data. In fact, as mentioned in <em class="chapterRef">Chapter 12</em>, <em class="italic">Advanced Data Preparation</em>, most practical machine learning applications in the business setting are in the so-called small or medium data regimes, and here deep learning methods might perform no better and possibly even worse than conventional machine learning approaches like regression and decision trees. Thus, many organizations that are investing heavily in deep learning are doing so as a result of hype rather than true need.</p>
    <p class="normal">Even though some of the buzz around deep learning is surely based on its novelty as well as excitement from business leaders with visions of artificial intelligence replacing costly human workers, there are in fact practical applications of the technique that can be used in combination with, rather than as a replacement for, conventional machine learning methods. The purpose of this chapter is therefore not to provide a start-to-finish tutorial for building deep neural networks, but rather to show how deep learning’s successes can be incorporated into conventional machine learning projects including those outside the big data regime.</p>
    <div class="note">
      <p class="normal">Packt Publishing offers numerous resources on deep learning, such as <em class="italic">Hands-On Deep Learning with R: A practical guide to designing, building, and improving neural network models using R</em> (2020) by M. Pawlus and R. Devine, <em class="italic">Advanced Deep Learning with R</em> (2019) by B. Rai, and <em class="italic">Deep Learning with R Cookbook</em> (2020) by S. Gupta, R. A. Ansari, and D. Sarkar.</p>
    </div>
    <h2 class="heading-2" id="_idParaDest-337">Beginning with deep learning</h2>
    <p class="normal">In recent years, with<a id="_idIndexMarker1708"/> a new cohort of data science practitioners having been trained in the age of deep learning, a form of “generation gap” has developed in the machine learning community. Prior to the development of deep learning, the field was staffed primarily by those who were trained in statistics or computer science. Especially in the earliest years, machine learning practitioners carried with them the metaphorical baggage of their prior domain, and the software and algorithms they used fell into camps along party lines. Statisticians typically preferred regression-based techniques and software like R, whereas computer scientists favored iterative and heuristic-based algorithms like decision trees written in languages like Python and Java. Deep learning has blurred the line between these camps, and the next generation of data scientists may seem somewhat foreign to the prior generations as if they speak a different language.</p>
    <p class="normal">The rift seems to have come out of nowhere, despite being able to see its origins clearly with the benefit of hindsight. As the famous author Ernest Hemingway once wrote, it happened “gradually, then suddenly.” Just as machine learning itself was only possible as the result of the simultaneous evolution of computing power, statistical methods, and available data, it makes sense that the next big evolutionary leap would arise out of a series of smaller evolutions in each of the same three components. Recalling the similar image presented in <em class="chapterRef">Chapter 1</em>, <em class="italic">Introducing Machine Learning</em>, a revised cycle of advancement diagram depicting today’s state-of-the-art machine learning cycle illustrates the environment in which deep learning was developed:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_01.png"/></figure>
    <p class="packt_figref">Figure 15.1: A combination of factors in the cycle of advancement led to the development of deep learning</p>
    <p class="normal">It is no<a id="_idIndexMarker1709"/> surprise that deep learning arose out of the big data era, while also being provided the requisite computing hardware—<strong class="keyWord">graphics processing units</strong> (<strong class="keyWord">GPUs</strong>) and<a id="_idIndexMarker1710"/> cloud-based parallel processing tools, which will be covered later in this chapter—necessary to process datasets that are both very long and very wide. What is less obvious, and therefore easy to take for granted, is the academic and research environment that was also necessary for this evolution. Without a strong data science community comprising researchers whose expertise spans both statistics and computer science, in addition to applied data scientists motivated to solve practical business problems on large and complex real-world datasets, it is unlikely that deep learning would have arisen as it has. Stated differently, the fact that data science now exists as a focused academic discipline has undoubtedly accelerated the cycle of advancement. To borrow an analogy from science fiction, the system is much like a robot that becomes self-aware and learns much more quickly now that it has learned how to learn!</p>
    <p class="normal">The rapid development of deep learning has contributed to the previously mentioned generation gap, but it is not the only factor. As you will soon learn, deep learning not only offers impressive performance on big data tasks, but it can also perform much like conventional learning methods on smaller tasks. This has led some to focus almost exclusively on the technique, much like earlier generations of machine learning practitioners focused exclusively on regression or decision trees. The fact that deep learning also utilizes specialized software tools and mathematical terminology to perform these tasks means that its practitioners are, in some cases, literally speaking another language to describe the same series of steps. As has been said many times before, “there is no free lunch” in the field of machine learning, so as you continue your machine learning<a id="_idIndexMarker1711"/> journey, it is best to see it as one of many useful tools—and not the <em class="italic">only</em> tool for the job.</p>
    <div class="packt_tip">
      <p class="normal">The terminology used by deep learning practitioners, even for simpler methods like linear regression, includes phrases like “cost function,” “gradient descent,” and “optimization.” This is a good reminder that although deep learning can approximate regression and other machine learning methods, the means by which it finds the solution is completely different.</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-338">Choosing appropriate tasks for deep learning</h3>
    <p class="normal">As <a id="_idIndexMarker1712"/>mentioned in <em class="chapterRef">Chapter 7</em>, <em class="italic">Black-Box Methods – Neural Networks and Support Vector Machines</em>, neural networks with at least one hidden layer can act as universal function approximators. Elaborating on this principle, one might say that given enough training data, a cleverly designed neural network can learn to mimic the output of any other function. </p>
    <p class="normal">This implies that the conventional learning methods covered throughout this book can likewise be approximated by well-designed neural networks. In fact, it is quite trivial to design a neural network that almost exactly matches linear or logistic regression, and with a bit more work it is possible to approximate techniques like k-nearest neighbors and naive Bayes. Given enough data, a neural network can get closer and closer to the performance of even the best tree-based algorithms like random forests or gradient boosting machines.</p>
    <p class="normal">Why not apply deep learning to every problem, then? Indeed, a neural network’s ability to mimic all other learning approaches appears to be a violation of the “no free lunch” theorem, which, put simply, suggests that there is no machine learning algorithm that can perform best across all potential modeling tasks. There are a couple of key reasons why the theorem remains safe despite deep learning’s magic. First, the ability of a neural network to approximate a function is related to how much training data it has. In the small data regime, conventional techniques can perform better, especially when combined with careful feature engineering. Second, to reduce the amount of data the neural network needs for training, the network must have a topology that facilitates its ability to learn the underlying function. Of course, if the person building the model knows what topology to use, then it may be preferable to use the simpler conventional model in the first place.</p>
    <p class="normal">People using deep learning for conventional learning tasks are likely to prefer the black box approach, which works in the big data regime. Big data, however, is not merely the presence of many rows of data, but also many features. Most conventional learning tasks, including those with many millions of rows of data, are in the medium data regime, where conventional learning algorithms still perform well. In this case, whether the neural network performs better will ultimately come down to the balance of overfitting and underfitting—a balance that is sometimes challenging to find with a neural network, as the method tends to somewhat easily overfit the training data.</p>
    <p class="normal">Perhaps for this <a id="_idIndexMarker1713"/>reason, deep learning is not well suited for racking up wins in machine learning competitions. If you ask a Kaggle Grandmaster, they are likely to tell you that neural networks don’t work on standard, real-life problems, and on traditional supervised learning tasks, gradient boosting wins. One can also see proof of this by browsing the leaderboards and noting the absence of deep learning. Perhaps a clever team will use neural networks for feature engineering and blend the deep learning model with other models in an ensemble to boost their performance, but even this is rare. Deep learning’s strengths are elsewhere. As a rule of thumb, tree-based ensemble methods win on structured, tabular data, while neural networks win on unstructured data, like image, sound, and text.</p>
    <p class="normal">Reading recent news about research breakthroughs and technology startup companies, one is likely to encounter deep learning applications that utilize the method’s unique ability to solve unconventional tasks. In general, these unconventional learning tasks fall into one of three categories: computer vision, natural language processing, or tasks involving unusual data formats like repeated measurements over time or having an exceptionally large number of interrelated predictors. A selection of specific successes for each category is listed in the following table:</p>
    <table class="table-container" id="table001-10">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Challenging machine learning tasks</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Deep learning successes</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Computer vision tasks involving classifying images found in still pictures or video data</p>
          </td>
          <td class="table-cell">
            <ul>
              <li class="bulletList">Identifying faces in security camera footage</li>
              <li class="bulletList">Categorizing plants or animals for ecological monitoring</li>
              <li class="bulletList">Diagnosing medical images such as X-rays, MRI, or CT scans</li>
              <li class="bulletList">Measuring the activity of athletes on the sporting field</li>
              <li class="bulletList">Autonomous driving</li>
            </ul>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Natural language applications requiring an understanding of the meaning of words in context</p>
          </td>
          <td class="table-cell">
            <ul>
              <li class="bulletList">Processing social media posts to filter out fake news or hate speech</li>
              <li class="bulletList">Monitoring Twitter or customer support emails for consumer sentiment or other marketing insights</li>
              <li class="bulletList">Examining electronic health records for patients at risk of adverse outcomes or for eligibility for new treatments</li>
            </ul>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">Predictive analysis involving many repeated measurements or very large numbers of predictors</p>
          </td>
          <td class="table-cell">
            <ul>
              <li class="bulletList">Predicting the price of goods or equities in open markets</li>
              <li class="bulletList">Estimating energy, resource, or healthcare utilization</li>
              <li class="bulletList">Forecasting survival or other medical outcomes using insurance billing codes</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">Even though some people certainly do use deep learning for conventional learning problems, this <a id="_idIndexMarker1714"/>chapter focuses only on tasks that cannot be solved via conventional modeling techniques. Deep learning is highly adept at tapping into the unstructured data types that characterize the big data era, such as images and text, which are extremely difficult to model with traditional approaches. </p>
    <p class="normal">Unlocking these capabilities requires the use of specialized software and specialized data structures, which you will learn about in the next section.</p>
    <h3 class="heading-3" id="_idParaDest-339">The TensorFlow and Keras deep learning frameworks</h3>
    <p class="normal">Perhaps <a id="_idIndexMarker1715"/>no software tool has contributed as much to the rapid growth in deep learning as <strong class="keyWord">TensorFlow</strong> (<a href="https://www.tensorflow.org"><span class="url">https://www.tensorflow.org</span></a>), an open-source mathematical library <a id="_idIndexMarker1716"/>developed at <a id="_idIndexMarker1717"/>Google for advanced machine learning. TensorFlow provides a computing interface using directed graphs that “flow” data structures through a sequence of mathematical operations.</p>
    <div class="note">
      <p class="normal">Packt Publishing offers many books on TensorFlow. To search the current offerings, visit <a href="https://subscription.packtpub.com/search?query=tensorflow"><span class="url">https://subscription.packtpub.com/search?query=tensorflow</span></a>.</p>
    </div>
    <p class="normal">The fundamental TensorFlow data structure is unsurprisingly known<a id="_idIndexMarker1718"/> as a <strong class="keyWord">tensor</strong>, which is an array of zero or more dimensions. Building upon the simplest 0-D and 1-D tensors, which represent a single value and a sequence of values, respectively, adding additional dimensions allows <a id="_idIndexMarker1719"/>more complex data structures to be represented. Note that because we typically analyze sets of structures, the first dimension is generally reserved to allow multiple objects to be stacked; the first dimension then refers to the batch or sample number for each structure. For example:</p>
    <ul>
      <li class="bulletList">A set of 1-D tensors, collecting feature values for a set of people, is a 2-D tensor analogous to a data frame in R: <code class="inlineCode">[person_id, feature_values]</code> </li>
      <li class="bulletList">For measurements repeated over time, 2-D tensors can be stacked as a 3-D tensor: <code class="inlineCode">[person_id, time_sequence, feature values]</code></li>
      <li class="bulletList">2-D images are represented by a 4-D tensor, with the fourth dimension storing the color values for each pixel in the 2-D grid: <code class="inlineCode">[image_id, row, column, color_values]</code></li>
      <li class="bulletList">Video or animated images are represented in 5-D with an additional time dimension: <code class="inlineCode">[image_id, time_sequence, row, column, color_values]</code></li>
    </ul>
    <p class="normal">Most tensors are rectangular matrices completely filled with numeric data, but more complex structures like ragged tensors and sparse tensors are available for use with text data.</p>
    <div class="note">
      <p class="normal">For an in-depth look at TensorFlow’s tensor objects, the documentation is available at <a href="https://www.tensorflow.org/guide/tensor"><span class="url">https://www.tensorflow.org/guide/tensor</span></a>.</p>
    </div>
    <p class="normal">TensorFlow’s graph, which<a id="_idIndexMarker1720"/> can be more specifically<a id="_idIndexMarker1721"/> termed a <strong class="keyWord">dataflow graph</strong>, uses nodes connected by directional arrows known as edges to represent dependencies between data structures, mathematical operations on these data structures, and the output. The nodes represent mathematical operations and the edges represent tensors flowing between operations. The graph aids in the parallelization of the work, since it is clear what steps must be completed in sequence versus those that may be completed simultaneously.</p>
    <p class="normal">A dataflow graph can be visualized if desired, which produces something like the idealized graph depicted in <em class="italic">Figure 15.2</em>. Although this is a highly simplified representation and real-world TensorFlow graphs tend to be much more complex, the diagram here shows that after completing the first operation, the second and fourth operations can begin in parallel:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_02.png"/></figure>
    <p class="packt_figref">Figure 15.2: A simplified representation of a TensorFlow graph</p>
    <p class="normal">As tensors flow through <a id="_idIndexMarker1722"/>the graph, they are transformed by the series of operations represented by the nodes. The steps are defined by the person building the diagram, with each step moving closer to the end goal of accomplishing some sort of mathematical task. Some steps in the flow graph may apply simple mathematical transformations like normalization, smoothing, or bucketing to the data; others may attempt to train a model by iterating repeatedly while monitoring a <strong class="keyWord">loss function</strong>, which <a id="_idIndexMarker1723"/>measures the fit of the model’s predictions to the true values.</p>
    <p class="normal">R interfaces to TensorFlow have been developed by the team at RStudio. The <code class="inlineCode">tensorflow</code> package provides access to the core API, while the <code class="inlineCode">tfestimators</code> package provides access to higher-level machine learning functionality. Note that TensorFlow’s directed graph approach can be used to implement many different machine learning models, including some of those discussed in this book. However, to do so requires a thorough understanding of the matrix mathematics that defines each model, and thus is outside the scope of this text. For more information about these packages and RStudio’s ability to interface with TensorFlow, visit <a href="https://tensorflow.rstudio.com"><span class="url">https://tensorflow.rstudio.com</span></a>.</p>
    <p class="normal">Because TensorFlow <a id="_idIndexMarker1724"/>relies so heavily on complex mathematical operations that must be programmed carefully by <a id="_idIndexMarker1725"/>hand, the <strong class="keyWord">Keras</strong> library (<a href="https://keras.io"><span class="url">https://keras.io</span></a>) was<a id="_idIndexMarker1726"/> developed to provide a higher-level interface to TensorFlow and allow deep neural networks to be built more easily. Keras was developed in Python and is typically paired with TensorFlow as the back-end computing engine. Using Keras, it is possible to do deep learning in just a few lines of code—even for challenging applications such as image classification, as you will discover in the example later in this chapter.</p>
    <div class="note">
      <p class="normal">Packt Publishing offers numerous books and videos to learn Keras. To search current offerings, visit <a href="https://subscription.packtpub.com/search?query=keras"><span class="url">https://subscription.packtpub.com/search?query=keras</span></a>.</p>
    </div>
    <p class="normal">The <code class="inlineCode">keras</code> package, developed by<a id="_idIndexMarker1727"/> RStudio founder J. J. Allaire, allows R to interface with Keras. Although<a id="_idIndexMarker1728"/> there is very little code required to use the package, developing useful deep learning models from scratch requires extensive knowledge of neural networks as well as familiarity with TensorFlow and the Keras API. For these reasons, a tutorial is outside the scope of this book. Instead, refer to the RStudio TensorFlow documentation or the book <em class="italic">Deep Learning with R</em> (2018), which was co-authored by Francois Chollet and J. J. Allaire—the creators of Keras and the <code class="inlineCode">keras</code> package, respectively. Given their credentials, there is no better place to begin learning about this tool.</p>
    <div class="note">
      <p class="normal">Although the combination of Keras and TensorFlow is arguably the most popular deep learning toolkit, it is not the only tool for the <a id="_idIndexMarker1729"/>task. The <strong class="keyWord">PyTorch</strong> framework developed at Facebook has rapidly gained popularity, especially in the academic research community, as an easy-to-use alternative. For more information, see <a href="https://pytorch.org"><span class="url">https://pytorch.org</span></a>.</p>
    </div>
    <p class="normal">TensorFlow’s innovative idea to represent complex mathematical functions using a simple graph abstraction, combined with the Keras framework to make it easier to specify the network topology, has enabled the construction of deeper and more complex neural networks, such as those described in the next section. Keras even makes it easy to adapt pre-built neural networks to new tasks with no more than a few lines of code.</p>
    <h2 class="heading-2" id="_idParaDest-340">Understanding convolutional neural networks</h2>
    <p class="normal">Neural networks<a id="_idIndexMarker1730"/> have been studied for over 60 years, and even though deep learning has only recently become widespread, the concept of a deep neural network has been known for decades. As first introduced in <em class="chapterRef">Chapter 7</em>, <em class="italic">Black-Box Methods – Neural Networks and Support Vector Machines</em>, a <strong class="keyWord">deep neural network</strong> (<strong class="keyWord">DNN</strong>) is <a id="_idIndexMarker1731"/>simply a neural network with more than one hidden layer. </p>
    <p class="normal">This understates what deep learning is in practice, as typical DNNs are substantially more complex than the types of neural networks we’ve built previously. It’s not enough to add a few extra nodes in a new hidden layer and call it “deep learning.” Instead, typical DNNs use extremely complex but purposefully designed topologies to facilitate learning on big data, and in doing so are capable of human-like performance on challenging learning tasks.</p>
    <p class="normal">A turning point for <a id="_idIndexMarker1732"/>deep learning came in 2012, when a team <a id="_idIndexMarker1733"/>called SuperVision used deep learning to win the ImageNet Large Scale Visual Recognition Challenge. This annual competition tests the ability to classify a subset of 10 million hand-labeled images across 10,000 categories of objects. In the early years of the competition, humans vastly outperformed computers, but the performance of the SuperVision model closed the gap significantly. Today, computers are nearly as good as humans at visual classification, and, in some specific cases, are even better. Humans tend to be better at identifying small, thin, or distorted items, while computers have a greater ability to distinguish among specific types of items such as dog breeds. Before long, it is likely that computers will outperform humans on both types of visual tasks.</p>
    <p class="normal">An innovative network topology designed specifically for image recognition is responsible for the surge in performance. A <strong class="keyWord">convolutional neural network</strong> (<strong class="keyWord">CNN</strong>) is a deep feed-forward network used for visual tasks that independently learns the important distinguishing image features rather than requiring such feature engineering beforehand. For example, to classify road signs like “stop” or “yield,” a traditional learning algorithm would require pre-engineered features like the shape and color of the sign. In contrast, a CNN requires only the raw data for each of the image pixels, and the network will learn how to distinguish important features like shape and color on its own.</p>
    <p class="normal">Learning features like these is made possible due to the huge increase in dimensionality when using raw image data. A traditional learning algorithm would use one row per image, in a form like (<em class="italic">stop sign</em>, <em class="italic">red, octagon</em>), while a CNN uses data in the form (<em class="italic">stop sign</em>, <em class="italic">x</em>, <em class="italic">y</em>, <em class="italic">color</em>), where <em class="italic">x</em> and <em class="italic">y</em> are pixel coordinates and <em class="italic">color</em> is the color data for the given pixel. This may seem like an increase of only one dimension but note that even a very small image is made of many (<em class="italic">x</em>, <em class="italic">y</em>) combinations and color is often specified as a combination of RGB (<em class="italic">red</em>, <em class="italic">green</em>, <em class="italic">blue</em>) values. This means that a more accurate representation of a single row of training data would be:</p>
    <p class="center">(<em class="italic">stop sign</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">r</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">g</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">b</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub><em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">r</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub><em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">g</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub><em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">b</em>, …,<em class="italic"> x</em><sub class="subscript-italic" style="font-style: italic;">n</sub><em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">n</sub><em class="italic">r</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub><em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub><em class="italic">g</em>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub><em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">n</sub><em class="italic">b</em>)</p>
    <p class="normal">Each of the predictors refers to the level of red, green, or blue at the specified combination of (<em class="italic">x</em>, <em class="italic">y</em>), and <em class="italic">r</em>, <em class="italic">g</em>, or <em class="italic">b</em> values. Thus, the dimensionality increases greatly, and the dataset becomes much wider as the image becomes larger. </p>
    <p class="normal">A small 100x100 pixel image would have <em class="italic">100x100x3 = 30,000</em> predictors. Even this is small compared to the SuperVision team, which used over 60 million parameters when it won the visual recognition challenge in 2012!</p>
    <p class="normal"><em class="chapterRef">Chapter 12</em>, <em class="italic">Advanced Data Preparation</em>, noted that if a model is overparameterized, it reaches an<a id="_idIndexMarker1734"/> interpolation threshold at which there are enough parameters to memorize and perfectly classify all the training samples. The ImageNet Challenge dataset, which contained 10 million images, is much smaller than the 60 million parameters the winning team used. Intuitively, this makes sense; assuming there are no completely identical pictures in the database, at least one of the pixels will vary for every image. Thus, an algorithm could simply memorize every image to achieve the perfect classification of the training data. The problem is that the model will be evaluated on a dataset of unseen data, and thus the severe overfitting to the training data will lead to a massive generalization error.</p>
    <p class="normal">The topology <a id="_idIndexMarker1735"/>of a CNN prevents this from happening. We won’t be diving too deeply into the black box of the CNN, but we will understand it as a series of layers in the following categories:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Convolutional layers</strong> are placed early in the network and usually comprise the most<a id="_idIndexMarker1736"/> computationally intensive step in the network because they are the only layers to process the raw image data directly; we can understand convolution as passing the raw data through a filter creating a set of tiles that represent small, overlapping portions of the full area</li>
      <li class="bulletList"><strong class="keyWord">Pooling layers</strong>, also<a id="_idIndexMarker1737"/> known<a id="_idIndexMarker1738"/> as <strong class="keyWord">downsampling</strong> or <strong class="keyWord">subsampling</strong> layers, gather the output <a id="_idIndexMarker1739"/>signals from a cluster of neurons in one layer, and summarize them into a single neuron for the next layer, usually by taking the maximum or average value among those being summarized</li>
      <li class="bulletList"><strong class="keyWord">Fully connected layers</strong> are <a id="_idIndexMarker1740"/>much like the layers in a traditional multilayer perceptron, and are used near the end of the CNN to build the model that makes predictions</li>
    </ul>
    <p class="normal">The convolutional and pooling layers in the network serve the interrelated purposes of identifying important features of the images to be learned, as well as reducing the dimensionality of the dataset before hitting the fully connected layers that make predictions. In other words, the early stages of the network perform feature engineering, while the later stages use the constructed features to make predictions.</p>
    <div class="note">
      <p class="normal">To better understand the layers in a CNN, see <em class="italic">An Interactive Node-Link Visualization of Convolutional Neural Networks</em> by Adam W. Harley at <a href="https://adamharley.com/nn_vis/"><span class="url">https://adamharley.com/nn_vis/</span></a>. The interactive tool has you draw a number from zero to nine, which is then classified using a neural network. The 2D and 3D convolutional network visualizations clearly show how the digit you drew passes through the convolutional, downsampling, and fully connected layers before reaching the output layer where the prediction is made. Neural networks for general image classification work much the same way, but using a substantially larger and more complex network.</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-341">Transfer learning and fine tuning</h3>
    <p class="normal">Building a CNN from scratch requires a tremendous amount of data, expertise, and <a id="_idIndexMarker1741"/>computing power. Thankfully, many large organizations that have access to data and computing resources have built image, text, and audio classification models, and have shared them with the data science community. Through a process of <strong class="keyWord">transfer learning</strong>, a deep learning model can be adapted from one context to another. Not only is it possible to apply the saved model to similar types of problems as it was trained on, but it may also be useful for problems outside the original domain. For instance, a neural network that was trained to recognize an endangered species of elephants in satellite photos may also be useful for identifying the position of tanks in infrared drone images taken above a war zone.</p>
    <p class="normal">If the knowledge doesn’t transfer directly to the new task, it is possible to hone a pre-trained neural network using additional training in a process<a id="_idIndexMarker1742"/> known as <strong class="keyWord">fine tuning</strong>. Taking a model that was trained generally, such as a general image classification model that can identify 10,000 classes of objects, and fine tuning it to be good at identifying a single type of object not only reduces the amount of training data and computing power needed but also may offer improved generalization over a model trained on a single class of images.</p>
    <p class="normal">Keras can be used for both transfer learning and fine tuning by downloading neural networks with pre-trained weights. A list of available pre-trained models is available at <a href="https://keras.io/api/applications/"><span class="url">https://keras.io/api/applications/</span></a> and an example of fine tuning an image processing model to better predict cats and dogs can be found at <a href="https://tensorflow.rstudio.com/guides/keras/transfer_learning"><span class="url">https://tensorflow.rstudio.com/guides/keras/transfer_learning</span></a>. In the next section, we will apply a pre-trained image model to real-world images.</p>
    <h3 class="heading-3" id="_idParaDest-342">Example – classifying images using a pre-trained CNN in R</h3>
    <p class="normal">R may not <a id="_idIndexMarker1743"/>be the right tool for the heaviest deep learning jobs, but with the right set of packages, we can apply pre-trained CNNs to perform tasks, such as image recognition, that conventional machine learning algorithms have trouble solving. The predictions generated by the R code can then be used directly for image recognition tasks like filtering obscene profile pictures, determining whether an image depicts a cat or a dog, or even identifying stop signs inside a simple autonomous vehicle. Perhaps more commonly, the predictions could be used as predictors in an ensemble that includes conventional machine learning models using tabular-structured data in addition to the deep learning neural network that consumes the unstructured image data. You may recall that <em class="chapterRef">Chapter 14</em>, <em class="italic">Building Better Learners</em>, described a potential stacked ensemble that combined image, text, and traditional machine learning models in this way to predict elements of a Twitter user’s future behavior. The following pictures illustrate hypothetical Twitter profile pictures, which we will classify using a deep neural network shortly:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_03.png"/></figure>
    <p class="packt_figref">Figure 15.3: A pre-trained neural network can be used in R to identify the subject of images like these</p>
    <p class="normal">First, before using a pre-trained model, it is important to consider the dataset that was used to train the neural network. Most publicly available image networks were trained on huge image databases comprising a variety of everyday objects and animals, such as cars, dogs, houses, various tools, and so on. This is appropriate if the desired task is to distinguish among everyday objects, but more specific tasks may require more specific training datasets. For instance, a facial recognition tool or an algorithm identifying stop signs would be more effectively trained on datasets of faces and road signs, respectively. With transfer learning, it is possible to fine-tune a deep neural network trained on a variety of images to be better at a more specific task—it could become very good at identifying pictures of cats, for example—but it is hard to imagine a network trained on faces or road signs ever becoming very good at identifying cats, even with additional tuning!</p>
    <p class="normal">For this <a id="_idIndexMarker1744"/>exercise, we will classify our small set of images using a CNN called <strong class="keyWord">ResNet-50</strong>, which is a 50-layer deep network that has been trained on a large and comprehensive variety of labeled images. This model, which was introduced by a group of researchers in 2015 as a state-of-the-art, competition-winning computer vision algorithm, has since been surpassed by more sophisticated approaches, but continues to be extremely popular and effective due to its ease of use and integration with tools like R and Keras. </p>
    <div class="note">
      <p class="normal">For more information <a id="_idIndexMarker1745"/>about ResNet-50, see <em class="italic">Deep Residual Learning for Image Recognition, He, K., Zhang, X., Ren, S., and Sun, J., 2015, </em><a href="https://arxiv.org/abs/1512.03385v1"><span class="url">https://arxiv.org/abs/1512.03385v1</span></a>.</p>
    </div>
    <p class="normal">The <strong class="keyWord">ImageNet database</strong> (<a href="https://www.image-net.org"><span class="url">https://www.image-net.org</span></a>) that <a id="_idIndexMarker1746"/>was<a id="_idIndexMarker1747"/> used to train the ResNet-50 model is the same database used for the ImageNet Visual Recognition Challenge and has contributed greatly to computer vision since its introduction in 2010. Composed of over 14 million hand-labeled images and consuming many gigabytes of storage (or even terabytes in the case of the full, academic version), it is fortunate that there is no need to download this resource and train the model from scratch. Instead, we simply download the neural network weights for the ResNet-50 model that researchers trained on the full database, saving us a tremendous amount of computational expense.</p>
    <p class="normal">To begin the process, we’ll need to add the <code class="inlineCode">tensorflow</code> and <code class="inlineCode">keras</code> packages to R as well as the various dependencies. Most of these steps must only be performed once. The <code class="inlineCode">devtools</code> package adds tools to develop R packages and use packages that are in active development, so we’ll begin by installing and loading this as usual:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> install.packages<span class="hljs-punctuation">(</span><span class="hljs-string">"devtools"</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>devtools<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Next, we’ll use the <code class="inlineCode">devtools</code> package to obtain the latest version of the <code class="inlineCode">tensorflow</code> package from GitHub. Typically, we install packages from CRAN, but for packages in active development, it can be better to install directly from the latest source code. The command to install the <code class="inlineCode">tensorflow</code> package from its GitHub path is:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> devtools<span class="hljs-operator">::</span>install_github<span class="hljs-punctuation">(</span><span class="hljs-string">"rstudio/tensorflow"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">This points R to the RStudio GitHub account, which stores the source code for the package. To read the documentation and see the code for yourself on the web, visit <a href="https://github.com/rstudio/tensorflow"><span class="url">https://github.com/rstudio/tensorflow</span></a> in a web browser.</p>
    <p class="normal">After installing the <code class="inlineCode">tensorflow</code> package, there are several dependencies that are required to<a id="_idIndexMarker1748"/> begin using TensorFlow in R. In particular, the <code class="inlineCode">tensorflow</code> package is merely an interface between R and TensorFlow, so we must first install TensorFlow itself. Perhaps ironically, Python and several of its packages are <a id="_idIndexMarker1749"/>required for this. Thus, the<a id="_idIndexMarker1750"/> R <code class="inlineCode">reticulate</code> package (<a href="https://rstudio.github.io/reticulate/"><span class="url">https://rstudio.github.io/reticulate/</span></a>) is used to manage the interface between R and Python. As confusing as this seems, the complete installation process is driven by a single command from the <code class="inlineCode">tensorflow</code> package as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>tensorflow<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> install_tensorflow<span class="hljs-punctuation">()</span>
</code></pre>
    <p class="normal">While the command is running, you should see R working to install a large collection of Python tools and packages. If all goes well, you can proceed to install the Keras package from GitHub:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> devtools<span class="hljs-operator">::</span>install_github<span class="hljs-punctuation">(</span><span class="hljs-string">"rstudio/keras"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">In the case of a problem, keep in mind that although the code for this example was tested on multiple platforms and R versions, it is quite possible for something to go wrong among the many dependencies required to have R interface with Python and TensorFlow. Don’t be afraid to search the web for a particular error message or check the Packt Publishing GitHub repository for the updated R code for this chapter.</p>
    <p class="normal">With the necessary packages installed, Keras can help load the ResNet-50 model with the weights trained on the ImageNet database:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>keras<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> model <span class="hljs-operator">&lt;-</span> application_resnet50<span class="hljs-punctuation">(</span>weights <span class="hljs-operator">=</span> <span class="hljs-string">'imagenet'</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Our 50-layer deep image classification model trained on millions of everyday images is now ready to start making predictions; however, the ease at which we loaded the model conceals the work to come.</p>
    <p class="normal">The greater challenge with using a pre-trained model is transforming our unstructured image data, which we hope to classify, into the same structured format that it saw during training. ResNet-50 used square images of 224-by-224 pixels with each pixel reflecting a color composed of three channels, red, green, and blue, each having 255 levels of brightness. All images we hope to classify must be transformed from their original formats, such as PNG, GIF, or JPEG, into a 3-D tensor using this representation. We’ll see this in practice using the previously depicted <code class="inlineCode">cat.jpg</code>, <code class="inlineCode">ice_cream.jpg</code>, and <code class="inlineCode">pizza.jpg</code> files found in the R code folder for this chapter, but the process will work similarly for any image.</p>
    <p class="normal">The <code class="inlineCode">image_load()</code> function in the <code class="inlineCode">keras</code> package will get the process started. Simply provide <a id="_idIndexMarker1751"/>the file name and desired target dimensions as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> img <span class="hljs-operator">&lt;-</span> image_load<span class="hljs-punctuation">(</span><span class="hljs-string">"ice_cream.jpg"</span><span class="hljs-punctuation">,</span> target_size <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">224</span><span class="hljs-punctuation">,</span><span class="hljs-number">224</span><span class="hljs-punctuation">))</span>
</code></pre>
    <p class="normal">This creates an image object, but we need one more command to convert it into a 3-D tensor:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> x <span class="hljs-operator">&lt;-</span> image_to_array<span class="hljs-punctuation">(</span>img<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">To prove it to ourselves, we can examine the dimensions and structure of the object as follows. As expected, the object is a numeric matrix with <em class="italic">224 </em>x<em class="italic"> 224 </em>x<em class="italic"> 3</em> as the dimensions: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> <span class="hljs-built_in">dim</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] 224 224   3
</code></pre>
    <p class="normal">The first few values in the matrix are all 255, which isn’t very meaningful:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> str<span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con"> num [1:224, 1:224, 1:3] 255 255 255 255 255 255 255 255 255 255 ...
</code></pre>
    <p class="normal">Let’s do some investigation to better understand these data structures. Because of R’s row, column matrix format, the matrix coordinates are (<em class="italic">y</em>, <em class="italic">x</em>), with (<em class="italic">1</em>, <em class="italic">1</em>) representing the top-left pixel in the image and (<em class="italic">1</em>, <em class="italic">224</em>) the top-right pixel. To illustrate this, let’s obtain each of the three color channels for a couple of pixels in the ice cream image:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> x<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">224</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">3</span><span class="hljs-punctuation">]</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] 253 253 255
</code></pre>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> x<span class="hljs-punctuation">[</span><span class="hljs-number">40</span><span class="hljs-punctuation">,</span> <span class="hljs-number">145</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">3</span><span class="hljs-punctuation">]</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] 149  23  34
</code></pre>
    <p class="normal">The <a id="_idIndexMarker1752"/>pixel at (<em class="italic">1</em>, <em class="italic">224</em>) has (<em class="italic">r</em>, <em class="italic">g</em>, <em class="italic">b</em>) colors of (<em class="italic">253</em>, <em class="italic">253</em>, <em class="italic">255</em>), which corresponds to nearly the brightest possible white, while the pixel at (<em class="italic">40</em>, <em class="italic">145</em>) has color values (<em class="italic">149</em>, <em class="italic">23</em>, <em class="italic">34</em>) translating to a dark red—a piece of strawberry in the ice cream. These coordinates are illustrated in the following figure:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_04.png"/></figure>
    <p class="packt_figref">Figure 15.4: The picture of ice cream has been reduced from a matrix of 1,000x1,000 pixels to 224x224; each pixel in the image has three color channels</p>
    <p class="normal">One additional complication is that the ResNet-50 model expects a four-dimensional tensor, with the fourth dimension representing the batch. With only one image to classify, we have no need for this parameter, so we’ll simply assign it a constant value of 1 to create a matrix of <em class="italic">1x224x224x3</em>. The command <code class="inlineCode">c(1, dim(x))</code> defines the new matrix in this format, and then the <code class="inlineCode">array_reshape()</code> function fills this matrix with the contents of <code class="inlineCode">x</code> using the Python-style row-by-row ordering used by TensorFlow rather than the R-style column-by-column filling. The full command is as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> x <span class="hljs-operator">&lt;-</span> array_reshape<span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">dim</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)))</span>
</code></pre>
    <p class="normal">To confirm that <code class="inlineCode">x</code> has the correct dimensions, we can use the <code class="inlineCode">dim()</code> command:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> <span class="hljs-built_in">dim</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1]   1 224 224   3
</code></pre>
    <p class="normal">Finally, we run the <code class="inlineCode">imagenet_preprocess_input()</code> function to normalize the color values to match the ImageNet database:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> x <span class="hljs-operator">&lt;-</span> imagenet_preprocess_input<span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The<a id="_idIndexMarker1753"/> primary function of this transformation is to zero-center each color with respect to the database, essentially treating each color value as being greater than or less than the average of ImageNet images on that color. For example, the red pixel in the ice cream at (<code class="inlineCode">40</code>, <code class="inlineCode">145</code>) had color values of 149, 23, and 34 before; now, it has very different values:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> x<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">40</span><span class="hljs-punctuation">,</span> <span class="hljs-number">145</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">3</span><span class="hljs-punctuation">]</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] -69.939 -93.779  25.320
</code></pre>
    <p class="normal">Negative values indicate a color level less than the ImageNet average for that color, and positive values indicate higher. The preprocessing step also inverts the red-green-blue format to blue-green-red, so only the red channel is above the average ImageNet level, which is not terribly surprising, as a strawberry is quite red!</p>
    <p class="normal">Now, let’s see what the ResNet-50 network thinks is depicted in the image. We’ll first use the <code class="inlineCode">predict()</code> function on the model object and the image matrix, and then use the <code class="inlineCode">keras</code> function <code class="inlineCode">imagenet_decode_predictions()</code> to convert the network’s predicted probabilities to text-based labels that categorize each of the ImageNet images. Because there are 1,000 categories of images in the ImageNet database, the <code class="inlineCode">preds</code> object contains 1,000 predicted probabilities—one for each possibility. The decoding function allows us to limit the output to the top <em class="italic">N</em> most probable possibilities—ten, in this case:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> p_resnet50 <span class="hljs-operator">&lt;-</span> predict<span class="hljs-punctuation">(</span>m_resnet50<span class="hljs-punctuation">,</span> x<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> c_resnet50 <span class="hljs-operator">&lt;-</span> imagenet_decode_predictions<span class="hljs-punctuation">(</span>p_resnet50<span class="hljs-punctuation">,</span> top <span class="hljs-operator">=</span> <span class="hljs-number">10</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The <code class="inlineCode">c_resnet50</code> object is a list which contains the top ten predictions for our lone image. To see the predictions, we simply type the name of the list to discover that the network correctly identified the image as ice cream with about 99.6 percent probability:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> c_resnet50
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[[1]]
   class_name class_description         score
1   n07614500         ice_cream 0.99612110853
2   n07836838   chocolate_sauce 0.00257453066
3   n07613480            trifle 0.00017260048
4   n07932039            eggnog 0.00011857488
5   n07930864               cup 0.00011558698
6   n07745940        strawberry 0.00010969469
7   n15075141     toilet_tissue 0.00006556125
8   n03314780       face_powder 0.00005355201
9   n03482405            hamper 0.00004582879
10  n04423845           thimble 0.00004054611
</code></pre>
    <p class="normal">Although<a id="_idIndexMarker1754"/> none of the other potential classifications had a predicted probability much greater than zero, some of the other top predictions make a bit of sense; it is not difficult to see why they were considered as possibilities. Eggnog is in the correct category of foods, while an ice cream cone might look a bit like a cup, or a thimble. </p>
    <p class="normal">The model even listed strawberry as the sixth most likely option, which is the correct flavor of ice cream.</p>
    <p class="normal">As an exercise, we’ll do the same process with the other two images. The following sequence of steps uses the <code class="inlineCode">lapply()</code> function to apply the image processing steps to the pair of images, each time creating a new list to supply to the subsequent function. The last step supplies the list containing two prepared image arrays to the <code class="inlineCode">lapply()</code> function, which applies the <code class="inlineCode">predict()</code> command to each image:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> img_list <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">list</span><span class="hljs-punctuation">(</span><span class="hljs-string">"cat.jpg"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"pizza.jpg"</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> img_data <span class="hljs-operator">&lt;-</span> lapply<span class="hljs-punctuation">(</span>img_list<span class="hljs-punctuation">,</span> image_load<span class="hljs-punctuation">,</span> target_size <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">224</span><span class="hljs-punctuation">,</span><span class="hljs-number">224</span><span class="hljs-punctuation">))</span>
<span class="hljs-operator">&gt;</span> img_arrs <span class="hljs-operator">&lt;-</span> lapply<span class="hljs-punctuation">(</span>img_data<span class="hljs-punctuation">,</span> image_to_array<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> img_resh <span class="hljs-operator">&lt;-</span> lapply<span class="hljs-punctuation">(</span>img_arrs<span class="hljs-punctuation">,</span> array_reshape<span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">224</span><span class="hljs-punctuation">,</span> <span class="hljs-number">224</span><span class="hljs-punctuation">,</span> <span class="hljs-number">3</span><span class="hljs-punctuation">))</span>
<span class="hljs-operator">&gt;</span> img_prep <span class="hljs-operator">&lt;-</span> lapply<span class="hljs-punctuation">(</span>img_resh<span class="hljs-punctuation">,</span> imagenet_preprocess_input<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> img_prob <span class="hljs-operator">&lt;-</span> lapply<span class="hljs-punctuation">(</span>img_prep<span class="hljs-punctuation">,</span> predict<span class="hljs-punctuation">,</span> object <span class="hljs-operator">=</span> m_resnet50<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Finally, the <code class="inlineCode">sapply()</code> function is used to apply the decoding function to each of the two sets of predictions, while simplifying the result. The <code class="inlineCode">lapply()</code> function would also work here, but because <code class="inlineCode">imagenet_decode_predictions()</code> returns a list, the result is a sub-list of length one within a list; <code class="inlineCode">sapply()</code> recognizes that this is redundant and unnecessary, and will eliminate the additional level of hierarchy:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> img_classes <span class="hljs-operator">&lt;-</span> sapply<span class="hljs-punctuation">(</span>img_prob<span class="hljs-punctuation">,</span> imagenet_decode_predictions<span class="hljs-punctuation">,</span>
                        top <span class="hljs-operator">=</span> <span class="hljs-number">3</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Typing the name of the resulting object shows the top three predictions for each of the two images:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> img_classes
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[[1]]
  class_name class_description      score
1  n02123045             tabby 0.63457680
2  n02124075      Egyptian_cat 0.08966244
3  n02123159         tiger_cat 0.06287414
[[2]]
  class_name class_description        score
1  n07873807             pizza 0.9890466332
2  n07684084       French_loaf 0.0083064679
3  n07747607            orange 0.0002433858
</code></pre>
    <p class="normal">The <a id="_idIndexMarker1755"/>ResNet-50 algorithm didn’t merely classify the images correctly; it also correctly identified the cat picture as a tabby. This demonstrates the ability of neural networks to surpass human specificity for certain tasks; many or most people might have simply labeled the image as a cat, whereas the computer can determine the specific type of cat. On the other hand, humans remain better at identifying objects in less-than-optimal conditions. For example, a cat obscured by darkness or camouflaged in the weeds would present a greater challenge to a computer than to a human in most cases. Even so, the computer’s ability to work tirelessly gives it a huge advantage for automating artificial intelligence tasks. As stated previously, applied to a large dataset such as Twitter profile images, the predictions from this type of computer vision model could be used in an ensemble model predicting countless different user behaviors.</p>
    <h1 class="heading-1" id="_idParaDest-343">Unsupervised learning and big data</h1>
    <p class="normal">The previous<a id="_idIndexMarker1756"/> section illustrated how a deep neural network could be used to classify a limitless supply of input images as an instance of everyday creatures or objects. From another perspective, one might also understand this as a machine learning task that takes the highly dimensional input of image pixel data and reduces it to a lower-dimensional set of image labels. It is important to note, however, that the deep learning neural network is a supervised learning technique, which means that the machine can only learn what the humans tell it to learn—in other words, it can only learn from something that has been previously labeled.</p>
    <p class="normal">The purpose of this section is to present useful applications of<a id="_idIndexMarker1757"/> unsupervised learning techniques in the context of big data. These applications are in many ways similar to the techniques covered in <em class="chapterRef">Chapter 9</em>, <em class="italic">Finding Groups of Data – Clustering with k-means</em>. However, where previous unsupervised learning techniques leaned heavily on humans to interpret the results, in the context of big data, the machine can go a step further than before and provide a deeper, richer understanding of the data and the implications of the connections the algorithm discovers.</p>
    <p class="normal">To put this in <a id="_idIndexMarker1758"/>practical terms, imagine a deep neural network that can learn to identify a cat without ever having been told what a cat is. Of course, without being given the label beforehand, the computer may not explicitly label it a “cat” <em class="italic">per se</em>, but it may understand that a cat has certain consistent relationships to other things that appear in pictures along with the cat: people, litter boxes, mice, balls of yarn—but rarely or never dogs! Such associations help form a conceptualization of cat as something that relates closely to people, litter boxes, and yarn, but is perhaps in opposition to another thing with four legs and a tail. Given enough pictures, it is possible the neural network could eventually associate its impression of cats with the English-language word “cat” by identifying cats near bags of cat food or in the internet’s countless cat-based memes!</p>
    <p class="normal">Developing such a sophisticated model of cats would take more data and computing power than most machine learning practitioners have access to, but it is certainly possible to develop simpler models or to borrow from big data companies that do have access to such resources. These techniques provide yet another way to incorporate unstructured data sources into more conventional learning tasks, as the machine can reduce the complexity of big data into something much more digestible.</p>
    <h2 class="heading-2" id="_idParaDest-344">Representing highly dimensional concepts as embeddings</h2>
    <p class="normal">The things we <a id="_idIndexMarker1759"/>encounter in everyday life can be described by a limitless number of attributes. Moreover, not only are there countless data points that can be used to describe each object, but the nature of human subjectivity makes it unlikely that any two people would describe an object in the same way. For example, if you ask a few people to describe typical horror films, one might say they imagine slasher films with blood and gore, another might think of zombie or vampire movies, and another one might think of spooky ghost stories and haunted houses. These descriptions could be represented using the following statements:</p>
    <ul>
      <li class="bulletList"><em class="italic">horror</em> = <em class="italic">killer</em> + <em class="italic">blood</em> + <em class="italic">gore</em></li>
      <li class="bulletList"><em class="italic">horror</em> = <em class="italic">creepy</em> + <em class="italic">zombies</em> + <em class="italic">vampires</em></li>
      <li class="bulletList"><em class="italic">horror</em> = <em class="italic">spooky</em> + <em class="italic">ghosts</em> + <em class="italic">haunted</em></li>
    </ul>
    <p class="normal">If we were<a id="_idIndexMarker1760"/> to program these definitions into a computer, it could substitute any of the representations of horror for one another and thus use a wider general concept of “horror” rather than the more specific features like “gore,” “creepy,” or “spooky” to make predictions. For instance, a learning algorithm could discover that a social media user that writes any of these horror-related terms is more likely to click on an advertisement for the new <em class="italic">Scream</em> movie.</p>
    <p class="normal">Unfortunately, if a user posts “I just love a good scary movie!” or “The Halloween season is my favorite time of year!” then the algorithm will be unable to relate the text to the prior conceptualizations of horror, and thus will be unable to realize that a horror movie advertisement should be displayed. This is likewise true for any of the hundreds of horror-related keywords that the computer had not previously seen verbatim, including many that will seem obvious to a human observer, like witches, demons, graveyards, spiders, skeletons, and so on. What is needed is a way to generalize the concept of horror to the almost limitless number of ways that it can be described.</p>
    <p class="normal">An <strong class="keyWord">embedding</strong> is a <a id="_idIndexMarker1761"/>mathematical concept referring to the ability to represent a higher-dimensional vector using fewer dimensions; in machine learning, the embedding is purposefully constructed such that dimensions that are correlated in the high-dimensional space are positioned more closely in the lower-dimensional space. </p>
    <p class="normal">If the embedding is constructed well, the low-dimensional space will retain the semantics, or meaning, of the higher dimensions while being a more compact representation that can be used for classification tasks. The core challenge of creating an embedding is the unsupervised learning task of modeling the semantic meaning embedded in highly dimensional unstructured or semi-structured datasets.</p>
    <p class="normal">Humans are quite adept at constructing low-dimensional representations of concepts, as we do this intuitively whenever we assign labels to objects or phenomena that are similar in broad strokes but may vary in the details. We do this when we label movies as comedy, science fiction, or horror; when we talk about categories of music like hip-hop, pop, or rock and roll; or when we create taxonomies of foods, animals, or illnesses. In <em class="chapterRef">Chapter 9</em>, <em class="italic">Finding Groups of Data – Clustering with k-means</em>, we saw how the machine learning process of clustering can mimic this human process of labeling by grouping diverse but similar items through a process of “unsupervised classification.” However, even though this approach reduces the dimensionality of a dataset, it requires a structured dataset with the same specific features for each example before it can associate like-with-like. For something unstructured like a textual description of a movie, the features are too numerous and sparse to allow clustering.</p>
    <p class="normal">Instead, what<a id="_idIndexMarker1762"/> if we wanted to mimic the human ability to learn via association? Specifically, a human can watch a series of movies and associate like-with-like without having specific measurable features for each movie; we can classify one set of movies as horror films without needing to see the identical clichéd storyline or to count the number of screams each film elicited. The trick is that a human doesn’t need a concrete definition of “horror” because we intuit it as a concept relative to the others in a set. Just like a cat suddenly jumping into frame can be used as slapstick humor in a comedy movie or paired with suspenseful music to provoke a jump scare, the semantic meaning of horror is always determined by its context.</p>
    <p class="normal">In much the same way, learning algorithms can construct embeddings via context. Each of the thousands of movies that Hollywood has produced can be understood relative to others, and without studying exactly what features the movies <em class="italic">Halloween</em> and <em class="italic">Night of the Living Dead</em> have in common, an algorithm can observe that they appear in similar contexts and are somewhat substitutable for one another across contexts. This notion of substitutability is the basis for most embedding algorithms, and has indeed been used to construct embeddings for use in movie recommendation algorithms and other domains. In the next section, we’ll see how a popular language embedding algorithm uses substitutability to discover the semantic meanings of words.</p>
    <h3 class="heading-3" id="_idParaDest-345">Understanding word embeddings</h3>
    <p class="normal">If there are<a id="_idIndexMarker1763"/> roughly a million words in the English language, the feature space for a language-based model would be roughly a million dimensions wide even before phrases and word order are considered! This clearly would be far too large and sparse for most conventional learning algorithms to find a meaningful signal. A bag-of-words approach, as described in <em class="chapterRef">Chapter 4</em>, <em class="italic">Probabilistic Learning – Classification Using Naive Bayes</em>, might work with enough computing power, but it would also require a tremendous amount of training data to associate words with the desired outcome. What if, instead, we could use a language embedding that has been pre-trained on big data?</p>
    <p class="normal">To illustrate the upside of this alternative approach, let’s imagine the machine learning task of deciding whether to display an advertisement for a lunchtime café to users posting on a social media website. Consider the following posts made by hypothetical users:</p>
    <ul>
      <li class="bulletList">I ate bacon and eggs in the morning for the most important meal of the day!</li>
      <li class="bulletList">I am going to grab a quick sandwich this afternoon before hitting the gym.</li>
      <li class="bulletList">Can anyone provide restaurant recommendations for my date tonight?</li>
    </ul>
    <p class="normal">For a naive <a id="_idIndexMarker1764"/>Bayes approach, we would first need many of these types of sentences, but because the algorithm is a supervised learner, we would also need a target feature that indicates whether or not the user writing the sentence is interested in purchasing lunch from the café. We could then train the model to recognize which words are predictive of buying lunch. </p>
    <p class="normal">In comparison, a human reading these sentences can easily form a reasonable guess as to which of the three users is most likely to be interested in buying lunch today. The human’s guess is not based on being trained to predict lunch buying behavior specifically, but rather is based on an understanding of the embedded meaning in each of the sentences’ words. In other words, because a human understands the meaning of the users’ words, it becomes unnecessary to guess their behavior as we can instead just listen to what they are telling us they plan to do.</p>
    <div class="packt_tip">
      <p class="normal">The most effective language models do more than merely look at the meaning of words; they also look at the meaning of words in relation to others. The use of grammar and phrasing can completely change the implications of a sentence. For example, the sentence “I skipped breakfast today, so I can stuff myself at lunch” is very different from “I stuffed myself at breakfast, so I need to skip lunch today” despite containing almost exactly the same words!</p>
    </div>
    <p class="normal">Ignoring for now how this might be constructed, suppose we have a very simple language embedding that captures the meaning of all English-language words in two dimensions: a “lunch” dimension that measures how related a term is to lunch, and a “food” dimension that indicates whether the term is related to food. In this model, the semantic meaning that was once delivered by unique and specific terms like “soup” and “salad” is instead represented by the position of these concepts in the 2-D space, as illustrated for a selection of words in <em class="italic">Figure 15.5</em>:</p>
    <figure class="mediaobject"><img alt="A picture containing text, receipt, screenshot  Description automatically generated" src="../Images/B17290_15_05.png"/></figure>
    <p class="packt_figref">Figure 15.5: A very simple embedding reduces the highly dimensional meaning of various words into two dimensions that a machine can use to understand the subjective concepts of “food” and “lunch”</p>
    <p class="normal">The embedding<a id="_idIndexMarker1765"/> itself is a mapping of a word to coordinates in a lower-dimensional space. Thus, a lookup function can provide the values for a specific word. For instance, using the 2-D word embedding above, we can obtain coordinates for a selection of terms that may have appeared in social media posts:</p>
    <ul>
      <li class="bulletList"><em class="italic">f(sandwich)</em> = <em class="italic">(0.97, 0.54)</em></li>
      <li class="bulletList"><em class="italic">f(bacon)</em> = <em class="italic">(-0.88, 0.75)</em></li>
      <li class="bulletList"><em class="italic">f(apple)</em> = <em class="italic">(0.63, 0.25)</em></li>
      <li class="bulletList"><em class="italic">f(orange)</em> = <em class="italic">(-0.38, 0.13)</em></li>
    </ul>
    <p class="normal">Terms with higher values of the first dimension are more specifically related to lunch (and lunch alone) while lower values indicate terms that are specifically not related to lunch. For example, the word “sandwich” has a high lunch value while “bacon” has a low lunch value, due to their close association with lunch and breakfast, respectively. In much the same way, terms with higher or lower values of the second dimension are more or less likely to be foods. The words “orange” and “apple” can both be foods, but the former can also represent a color while the latter can represent a computer, so they are near the middle of the food dimension. In contrast, the words “bacon” and “sandwich” are higher in this dimension but are lower than “burrito” or “spaghetti” due to their meanings outside of the culinary context; someone can “bring home the bacon” (that is, they can earn money) or an item can be “sandwiched” between other items.</p>
    <p class="normal">An interesting <a id="_idIndexMarker1766"/>and useful property of this type of embedding is that words can be related to one another via simple mathematics and nearest-neighbor-style distance calculations. In the 2-D plot, we can observe this property by examining the terms that are mirror images across the horizontal or vertical axis or those that are close neighbors. This leads to observations such as:</p>
    <ul>
      <li class="bulletList">An apple is a more lunch-related version of an orange</li>
      <li class="bulletList">Beef is like chicken, but not as associated with lunch</li>
      <li class="bulletList">Pitas and tacos are somewhat similar, as are kebabs and sandwiches</li>
      <li class="bulletList">Soup and salad are closely related and are the lunch versions of eggs and pasta</li>
      <li class="bulletList">Heavy and light are opposites with respect to lunch, as are afternoon and evening</li>
      <li class="bulletList">The term “brown bag” is lunch-ish like “apple” but less food-ish</li>
    </ul>
    <p class="normal">Although this is a simple, contrived example, the word embeddings developed using big data have similar mathematical properties—albeit with a much higher number of dimensions. As you will soon see, these additional dimensions allow additional aspects of word meaning to be modeled, and enrich the embedding far beyond the “lunch” and “food” dimensions illustrated so far.</p>
    <h3 class="heading-3" id="_idParaDest-346">Example – using word2vec for understanding text in R</h3>
    <p class="normal">The previous sections<a id="_idIndexMarker1767"/> introduced the idea of embedding as a means of encoding a highly dimensional concept in a lower-dimensional space. We’ve also learned that, conceptually, the process involves training a computer to learn about the substitutability of various terms by applying a human-like process of learning by association. But so far, we haven’t explored the algorithm that performs this feat. There are several such methods, which have been developed by big data companies or research universities and shared with the public.</p>
    <p class="normal">Perhaps one of the most widely used word embedding techniques<a id="_idIndexMarker1768"/> is <strong class="keyWord">word2vec</strong>, which was published in 2013 by a team of researchers at Google and, as the name suggests, literally transforms words to vectors. According to the authors, it is not a single algorithm so much as it is a collection of methods that can be used for natural language processing tasks. Although there have been many new methods published in the time since word2vec was published, it remains popular and is well studied even today. Understanding the full scope of word2vec is outside the scope of this chapter, but understanding some of its key components will provide a foundation upon which many other natural language processing techniques can be understood.</p>
    <div class="note">
      <p class="normal">For a deep dive into the word2vec approach, see <em class="italic">Efficient Estimation of Word Representations in Vector Space by Mikolov, T., Chen, K., Corrado, G., and Dean, J., 2013</em> at <a href="https://arxiv.org/abs/1301.3781"><span class="url">https://arxiv.org/abs/1301.3781</span></a>. Another early but widely used approach for word embeddings is called <a id="_idIndexMarker1769"/>the <strong class="keyWord">GloVe algorithm</strong>, which <a id="_idIndexMarker1770"/>was published in 2014 by a team at Stanford University and uses a similar set of methods. For more information on GloVe, see <a href="https://nlp.stanford.edu/projects/glove/"><span class="url">https://nlp.stanford.edu/projects/glove/</span></a>.</p>
    </div>
    <p class="normal">Consider <a id="_idIndexMarker1771"/>a computer attempting to learn from reading a large corpus of text such as a web page or textbook. To begin learning which words are associated and are substitutable for one another, the computer will need a formal definition of “context” to limit the scope to something more reasonable than the entire text, particularly if the text is large. To this end, the word2vec technique defines a <strong class="keyWord">window size</strong> parameter<a id="_idIndexMarker1772"/> that dictates how many words of context will be used when attempting to understand a single word. A smaller window size guarantees a tight association between words in context, but because related words can appear much later in the sentence, making the window too small may lead to missing important relationships among words and ideas. Balance is required, because making the window too large can pull in unrelated ideas much earlier or later in the text. Typically, the window is set to approximately the length of a sentence, or about five to ten words, with useless stop words like “and,” “but,” and “the” excluded.</p>
    <p class="normal">Given contexts comprising approximately sentence-length sets of words, the word2vec process proceeds with one of two methodologies. The <strong class="keyWord">continuous bag-of-words </strong>(<strong class="keyWord">CBOW</strong>) methodology<a id="_idIndexMarker1773"/> trains a model to predict each word from its <a id="_idIndexMarker1774"/>context; the <strong class="keyWord">skip-gram</strong> approach does the inverse and attempts to guess the surrounding contextual words when provided with a single input word. Although the underlying process is nearly identical for both approaches, there are mathematical nuances that lead to different results depending on which one is used. </p>
    <p class="normal">Because we are merely understanding the methods conceptually, it suffices to say that the CBOW methodology tends to create embeddings favoring words that are nearly identical replacements or true synonyms for one another, such as “apple” and “apples” or “burger” and “hamburger,” while the skip-gram method favors terms that are conceptually similar, like “apple” and “fruit” or “burger” and “fries.”</p>
    <p class="normal">For both CBOW and skip-gram, the process of developing the embedding is similar and can be understood as follows. Beginning from a sentence like “an apple is a fruit I eat for lunch,” a model is constructed that attempts to relate a word like “apple” to its context, like “fruit,” “eat,” and “lunch.” By iterating over huge volumes of such sentences—like “a banana is a fruit people eat for breakfast” or “an orange is both a fruit and a color” and so on—the values of the embedding can be determined, such that the <a id="_idIndexMarker1775"/>embedding minimizes the prediction error between the word and its context. Words that appear consistently in similar contexts will thus have similar values for the embedding and can therefore be treated as similar, interchangeable concepts:</p>
    <figure class="mediaobject"><img alt="Diagram  Description automatically generated" src="../Images/B17290_15_06.png"/> </figure>
    <p class="packt_figref">Figure 15.6: The word2vec process creates an embedding that relates each term to its context</p>
    <p class="normal">Technically speaking, the word2vec approach is not considered “deep learning” even though it is in many ways analogous to deep learning. As depicted in the figure that follows, the embedding itself can be imagined as a hidden layer in a neural network, here represented with four nodes. In the CBOW approach, the input layer is a one-hot encoding of the input term, with one node for each possible word in the vocabulary, but only a single node with a value of 1 and the remaining nodes set to 0 values. The output layer also has one node per term in the vocabulary but can have multiple “1” values—each representing a word appearing in the context of the input term. </p>
    <p class="normal">Note that for the skip-gram approach, this arrangement would be reversed:</p>
    <figure class="mediaobject"><img alt="Diagram, schematic  Description automatically generated" src="../Images/B17290_15_07.png"/></figure>
    <p class="packt_figref">Figure 15.7: Developing an embedding involves training a model in a process analogous to deep learning</p>
    <p class="normal">Varying the <a id="_idIndexMarker1776"/>number of nodes in the hidden layer affects the complexity of the network as well as the depth of the model’s semantic understanding of each term. A greater number of nodes leads to a richer understanding of each term in its context but becomes much more computationally expensive to train and requires much more training data. Each additional node adds an additional dimension from which each term can be distinguished. Too few nodes and the model will have insufficient dimensionality to capture the many nuances of how each term can be used—the word “orange” as a color versus “orange” as a food, for instance—but using too many dimensions may increase the risk of the model being distracted by noise, or worse, being useless for the embedding’s initial intended purpose of dimensionality reduction! As you will soon see firsthand, even though the embeddings presented so far used just a few dimensions for simplicity and illustrative purposes, actual word embeddings used in practice typically have hundreds of dimensions and require huge amounts of training data and computational power to train.</p>
    <p class="normal">In R, installing the <code class="inlineCode">word2vec</code> package by Jan Wijffels will provide a wrapper for the C++ implementation of the word2vec algorithm. If desired, the package can train a word embedding if given a corpus of text data, but it is often preferable to use pre-trained embeddings that can be downloaded from the web. Here, we’ll use an embedding that was trained using a Google News archive consisting of 100 billion written words. </p>
    <p class="normal">The resulting embedding contains 300-dimensional vectors for 3 million words and simple phrases, and is available for download at the Google word2vec project page as follows: <a href="https://code.google.com/archive/p/word2vec/"><span class="url">https://code.google.com/archive/p/word2vec/</span></a>. To follow along with the example, look for the link to the <code class="inlineCode">GoogleNews-vectors-negative300.bin.gz</code> file, then download, unzip, and save the file to your R project folder before proceeding.</p>
    <div class="packt_tip">
      <p class="normal">As a word of warning, the Google News embedding is quite large at about 1.5 GB compressed (3.4 GB after unzipping) and unfortunately cannot be distributed with the code for this chapter. Furthermore, the file can be somewhat hard to find on the project website. Try a find command (<em class="keystroke">Ctrl</em> + <em class="keystroke">F</em> or <em class="keystroke">Command</em> + <em class="keystroke">F</em>) in your web browser to search the page for the file name if needed. Depending on your platform, you may need an additional program to unzip files with the Gzip compression algorithm (<code class="inlineCode">.gz</code> file extension). </p>
    </div>
    <p class="normal">As shown in the<a id="_idIndexMarker1777"/> code that follows, to read the Google News embedding into R, we’ll load the <code class="inlineCode">word2vec</code> package and use the <code class="inlineCode">read.word2vec()</code> function. Ensure you have downloaded and installed the <code class="inlineCode">word2vec</code> package and Google News embedding before attempting this step:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>word2vec<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> m_w2v <span class="hljs-operator">&lt;-</span> read.word2vec<span class="hljs-punctuation">(</span>file <span class="hljs-operator">=</span> <span class="hljs-string">"GoogleNews-vectors-negative300.bin"</span><span class="hljs-punctuation">,</span>
                         normalize <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">If the embedding loaded correctly, the <code class="inlineCode">str()</code> command will show details about this pre-trained model:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> str<span class="hljs-punctuation">(</span>m_w2v<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">List of 4
 $ model     :&lt;externalptr&gt; 
 $ model_path: chr "GoogleNews-vectors-negative300.bin"
 $ dim       : int 300
 $ vocabulary: num 3e+06
 - attr(*, "class")= chr "word2vec"
</code></pre>
    <p class="normal">As expected, the embedding has 300 dimensions for each of the 3 million terms. We can obtain these dimensions for a term (or terms) using <code class="inlineCode">predict()</code> as a lookup function on the model object. The <code class="inlineCode">type = "embedding"</code> parameter requests the embedding vector for the term, as opposed to the most similar terms, which will be demonstrated shortly. </p>
    <p class="normal">Here, we’ll request the word vectors for a few terms related to breakfast, lunch, and dinner:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> foods <span class="hljs-operator">&lt;-</span> predict<span class="hljs-punctuation">(</span>m_w2v<span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">"cereal"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"bacon"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"eggs"</span><span class="hljs-punctuation">,</span>
                     <span class="hljs-string">"sandwich"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"salad"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"steak"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"spaghetti"</span><span class="hljs-punctuation">),</span>
                      type <span class="hljs-operator">=</span> <span class="hljs-string">"embedding"</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> meals <span class="hljs-operator">&lt;-</span> predict<span class="hljs-punctuation">(</span>m_w2v<span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">"breakfast"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"lunch"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"dinner"</span><span class="hljs-punctuation">),</span>
                     type <span class="hljs-operator">=</span> <span class="hljs-string">"embedding"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The previous commands created matrices named <code class="inlineCode">foods</code> and <code class="inlineCode">meals</code>, with rows reflecting the terms and<a id="_idIndexMarker1778"/> columns representing the 300 dimensions of the embedding. We can examine the first few values of a single word vector for <em class="italic">cereal</em> as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> head<span class="hljs-punctuation">(</span>foods<span class="hljs-punctuation">[</span><span class="hljs-string">"cereal"</span><span class="hljs-punctuation">,</span> <span class="hljs-punctuation">])</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] -1.1961552  0.7056815 -0.4154012  3.3832674  0.1438890 -0.2777683
</code></pre>
    <p class="normal">Alternatively, we can examine the first few columns for all foods:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> foods<span class="hljs-punctuation">[,</span> <span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">5</span><span class="hljs-punctuation">]</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">                [,1]       [,2]       [,3]     [,4]       [,5]
cereal    -1.1961552  0.7056815 -0.4154012 3.383267  0.1438890
bacon     -0.4791541 -0.8049789  0.5749849 2.278036  1.2266345
eggs      -1.0626601  0.3271616  0.3689792 1.456238 -0.3345411
sandwich  -0.7829969 -0.3914984  0.7379323 2.996794 -0.2267311
salad     -0.6817439  0.9336928  0.6224619 2.647933  0.6866841
steak     -1.5433296  0.4492917  0.2944511 2.030697 -0.5102126
spaghetti -0.2083995 -0.6843739 -0.4476731 3.828377 -1.3121454
</code></pre>
    <p class="normal">Although we have no idea what each of the five dimensions represents (nor any of the remaining 295 dimensions not shown), we would expect similar, more substitutable foods and concepts to be closer neighbors in the 300-dimensional space. We can take advantage of this to measure the relatedness of the foods to the three main meals of the day using the <code class="inlineCode">word2vec_similarity()</code> function as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> word2vec_similarity<span class="hljs-punctuation">(</span>foods<span class="hljs-punctuation">,</span> meals<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">          breakfast     lunch    dinner
cereal    0.6042315 0.5326227 0.3473523
bacon     0.6586656 0.5594635 0.5982034
eggs      0.4939182 0.4477274 0.4690089
sandwich  0.6928092 0.7046211 0.5999536
salad     0.6797127 0.6867730 0.6821324
steak     0.6580227 0.6383550 0.7106042
spaghetti 0.6301417 0.6122567 0.6742931
</code></pre>
    <p class="normal">In this output, higher<a id="_idIndexMarker1779"/> values indicate greater similarity between the foods and each of the three mealtimes, according to the 300-dimension word embedding. Unsurprisingly, breakfast foods like cereal, bacon, and eggs are closer to the word <em class="italic">breakfast</em> than they are to <em class="italic">lunch</em> or <em class="italic">dinner</em>. Sandwiches and salads are closest to lunch, while steak and spaghetti are closest to dinner.</p>
    <div class="packt_tip">
      <p class="normal">Although it was not used in the previous example, it is a popular convention to use the <strong class="keyWord">cosine similarity</strong> measure, which<a id="_idIndexMarker1780"/> considers only the direction of the compared vectors, rather than the default Euclidean distance-like measure, which considers both direction and magnitude. The cosine similarity can be obtained by specifying <code class="inlineCode">type = "cosine"</code> when calling the <code class="inlineCode">word2vec_similarity()</code> function. Here, it is not likely to substantially affect the results because the Google News vectors were normalized when they were loaded into R.</p>
    </div>
    <p class="normal">For a more practical application of word2vec concepts, let’s revisit the hypothetical social media posts presented earlier and attempt to determine whether to present the users with a breakfast, lunch, or dinner advertisement. We’ll start by creating a <code class="inlineCode">user_posts</code> character vector, which stores the raw text of each of the posts:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> user_posts <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span>
    <span class="hljs-string">"I eat bacon and eggs in the morning for the most important meal of the day!"</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"I am going to grab a quick sandwich this afternoon before hitting the gym."</span><span class="hljs-punctuation">,</span>
    <span class="hljs-string">"Can anyone provide restaurant recommendations for my date tonight?"</span>
  <span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Importantly, there is a substantial hurdle we must pass before applying word2vec to each of the user posts; specifically, each post is a sentence composed of multiple terms, and word2vec is only designed to return vectors for single words. Unfortunately, there is no perfect solution to this problem, and choosing the correct solution may depend on the desired use case. For instance, if the application is intended merely to identify people that post about a particular subject, it may suffice to iterate over each word in the post and determine whether any of the words meet a similarity threshold.</p>
    <p class="normal">More complex alternative solutions exist for solving the problem of applying word2vec to longer strings of text. A common but somewhat crude solution involves simply averaging the word2vec vectors across all words in the sentence, but this often results in poor results for much the same reason that mixing too many colors of paint results in an ugly shade of brown. As sentences grow longer, averaging across all words creates a muddy mess due to the fact that some words will inevitably have vectors in opposite directions and the resulting average is meaningless. Moreover, as sentences grow in complexity, it is more likely that word order and grammar will affect the meaning of the words in the sentence.</p>
    <p class="normal">An approach <a id="_idIndexMarker1781"/>called doc2vec attempts to address this by adapting the training of word2vec to longer blocks of text, called documents, which need not be full documents but may be paragraphs or sentences. The premise of doc2vec is to create an embedding for each document based on the words appearing in the document. Document vectors can then be compared to determine the overall similarity between two documents. In our case, the goal would be to compare whether two documents (that is, sentences) are conveying similar ideas—for instance, is a user’s post like other sentences that were about breakfast, lunch, or dinner?</p>
    <p class="normal">Unfortunately, we do not have access to a doc2vec model to use this more sophisticated approach, but we can apply the <code class="inlineCode">word2vec</code> package’s <code class="inlineCode">doc2vec()</code> function to create a document vector for each user post and treat the document vector as if it were a single word. As stated previously, for longer sentences this may create a muddied vector, but because social media posts are often short and to the point, this issue may be mitigated.</p>
    <p class="normal">We’ll begin by loading the <code class="inlineCode">tm</code> package, which was introduced in <em class="chapterRef">Chapter 4</em>, <em class="italic">Probabilistic Learning – Classification Using Naive Bayes</em>, as a collection of tools for processing text data. The package provides a <code class="inlineCode">stopwords()</code> function, which can be combined with its <code class="inlineCode">removeWords()</code> function to remove unhelpful terms from social media posts. Then, the <code class="inlineCode">txt_clean_word2vec()</code> function is used to prepare the posts for use with <code class="inlineCode">doc2vec</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>tm<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> user_posts_clean <span class="hljs-operator">&lt;-</span> removeWords<span class="hljs-punctuation">(</span>user_posts<span class="hljs-punctuation">,</span> stopwords<span class="hljs-punctuation">())</span>
<span class="hljs-operator">&gt;</span> user_posts_clean <span class="hljs-operator">&lt;-</span> txt_clean_word2vec<span class="hljs-punctuation">(</span>user_posts_clean<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">To see the result of this processing, let’s look at the first cleaned user post:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> user_posts_clean<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-comment"># look at the first cleaned user post</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] "i eat bacon eggs morning important meal day"
</code></pre>
    <p class="normal">As expected, the text has been standardized and all unhelpful words have been removed. We can then supply the posts to the <code class="inlineCode">doc2vec()</code> function, along with the pre-trained Google News word2vec model as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> post_vectors <span class="hljs-operator">&lt;-</span> doc2vec<span class="hljs-punctuation">(</span>m_w2v<span class="hljs-punctuation">,</span> user_posts_clean<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The result of <a id="_idIndexMarker1782"/>this operation is a matrix with three rows (one for each document) and 300 columns (one for each dimension in the embedding). The <code class="inlineCode">str()</code> command shows the first few values of this matrix:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> str<span class="hljs-punctuation">(</span>post_vectors<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">num [1:3, 1:300] -1.541 0.48 -0.825 -0.198 0.955 ...
</code></pre>
    <p class="normal">We’ll need to compare these pseudo-document vectors to the word vectors for breakfast, lunch, and dinner. These vectors were created previously using the <code class="inlineCode">predict()</code> function and the word2vec model, but the code is repeated here for clarity:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> meals <span class="hljs-operator">&lt;-</span> predict<span class="hljs-punctuation">(</span>m_w2v<span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">"breakfast"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"lunch"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"dinner"</span><span class="hljs-punctuation">),</span>
                   type <span class="hljs-operator">=</span> <span class="hljs-string">"embedding"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Finally, we can compute the similarity between the two. Each row represents a user’s post, and the column values indicate the similarity between that post’s document vector and the corresponding term:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> word2vec_similarity<span class="hljs-punctuation">(</span>post_vectors<span class="hljs-punctuation">,</span> meals<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">     breakfast     lunch    dinner
[1,] 0.7811638 0.7695733 0.7151590
[2,] 0.6262028 0.6700359 0.5391957
[3,] 0.5475215 0.5308735 0.5646606
</code></pre>
    <p class="normal">Unsurprisingly, the user post about bacon and eggs is most similar to the word breakfast, while the post with sandwiches is most similar to lunch, and the evening date is most related to dinner. We could use the maximum similarity per row to determine whether to display a breakfast, lunch, or dinner advertisement to each user.</p>
    <p class="normal">Document vectors can also be used directly as predictors in supervised machine learning tasks. For example, <em class="chapterRef">Chapter 14</em>, <em class="italic">Building Better Learners</em>, described a theoretical model for predicting a Twitter user’s gender or future purchasing behavior based on the user’s basic profile data, profile picture, and social media post text. </p>
    <p class="normal">The chapter proposed ensembling a traditional machine learning model with a deep learning model for the image data and a naive Bayes text model for the user posts. Alternatively, it is possible to use document vectors as is by treating the 300 dimensions as 300 individual predictors that the supervised learning algorithm can use to determine which are relevant to predicting the user’s gender:</p>
    <figure class="mediaobject"><img alt="A picture containing text, device, gauge  Description automatically generated" src="../Images/B17290_15_08.png"/></figure>
    <p class="packt_figref">Figure 15.8: The values for a document vector resulting from unstructured text data can be used in a predictive model side by side with the more conventional predictors</p>
    <p class="normal">This strategy of <a id="_idIndexMarker1783"/>creating a document vector for an unstructured block of text and using the resultant embedding values as predictors for supervised learning is quite generalizable as a means of enhancing the performance of a conventional machine learning approach. Many datasets include unstructured text fields that go unused in conventional models due to their complexity or the inability to train a language model. However, a relatively simple transformation made possible by a pre-trained word embedding allows the text data to be used in the model alongside the other predictors. Thus, there is little excuse not to incorporate this approach and provide the learning algorithm with an infusion of big data the next time you encounter this type of machine learning task.</p>
    <h2 class="heading-2" id="_idParaDest-347">Visualizing highly dimensional data</h2>
    <p class="normal">Data exploration <a id="_idIndexMarker1784"/>is one of the five key steps involved in any machine learning project, and thus is not immune to the so-called curse of dimensionality—the tendency of a project to become increasingly challenging as the number of features increases. Visualization techniques that work on simpler datasets may become useless as the number of dimensions grows unmanageable; for example, a scatterplot matrix may help identify relationships for a dozen or so features, but as the number grows bigger to dozens or hundreds of features, then what was once a helpful visualization may quickly turn into information overload. </p>
    <p class="normal">Likewise, we can interpret a 2-D or even a three-dimensional plot without too much difficulty, but if we hope to understand the relationship among four or more dimensions, an entirely different approach is needed.</p>
    <p class="normal">Though <a id="_idIndexMarker1785"/>physics suggests there are ten or eleven dimensions of the universe, we only experience four, and only interact directly with three of them. Perhaps for this reason, our brains are attuned to understanding visuals in at most three dimensions; moreover, because most of our intellectual work is on 2-D surfaces like blackboards, whiteboards, paper, or computer screens, we are accustomed to seeing data represented in at most two dimensions. One day, as virtual or augmented reality computer interfaces become more prevalent, we may see an explosion of innovation in three-dimensional visualizations, but until that day comes, there is a need for tools that can aid the display of highly dimensional relationships in no more than two dimensions.</p>
    <p class="normal">Reducing the dimensionality of a highly dimensional visualization to just two dimensions may seem like an impossibility, but the premise guiding the process is surprisingly straightforward: points that are closely positioned in the highly dimensional space need to be positioned closely in the 2-D space. If you are thinking that this idea sounds somewhat familiar, you would not be wrong; this is the same concept that guides embeddings, as described earlier in this chapter. The key difference is that while an embedding technique like word2vec reduces highly dimensional data down to a few hundred dimensions, embeddings for visualization must reduce the dimensionality even further to only two dimensions.</p>
    <h3 class="heading-3" id="_idParaDest-348">The limitations of using PCA for big data visualization</h3>
    <p class="normal"><strong class="keyWord">Principal component analysis</strong> (<strong class="keyWord">PCA</strong>), which <a id="_idIndexMarker1786"/>was introduced in <em class="chapterRef">Chapter 13</em>, <em class="italic">Challenging Data – Too Much, Too Little, Too Complex</em>, is one approach capable of reducing a highly dimensional <a id="_idIndexMarker1787"/>dataset to two dimensions. You may recall that PCA works by expressing the covariance of multiple correlated attributes as a single vector. In this way, from the larger set of features, a smaller number of new features, called components, can be synthesized. If the number of components is set to two, a high-dimensional dataset can then be visualized in a simple scatterplot.</p>
    <p class="normal">We’ll apply this visualization technique to the 36-dimension social media profile dataset first introduced in <em class="chapterRef">Chapter 9</em>, <em class="italic">Finding Groups of Data – Clustering with k-means</em>. The first few steps are straightforward; we use the tidyverse to read the data and select the 36 columns of<a id="_idIndexMarker1788"/> interest, set the random seed to <code class="inlineCode">123456</code> to ensure your results match the book, then use the <code class="inlineCode">prcomp_irlba()</code> function from the <code class="inlineCode">irlba</code> package to find the two principal components of the dataset:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>tidyverse<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> sns_terms <span class="hljs-operator">&lt;-</span> read_csv<span class="hljs-punctuation">(</span><span class="hljs-string">"snsdata.csv"</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt; </span>select<span class="hljs-punctuation">(</span>basketball<span class="hljs-operator">:</span>drugs<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>irlba<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> set.seed<span class="hljs-punctuation">(</span><span class="hljs-number">123456</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> sns_pca <span class="hljs-operator">&lt;-</span> sns_terms <span class="hljs-operator">|&gt;</span>
    prcomp_irlba<span class="hljs-punctuation">(</span>n <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> center <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> scale <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The <code class="inlineCode">sns_pca$x</code> object contains a transformed version of the original dataset in which the 36 original dimensions have been reduced to 2. Because this is stored as a matrix, we’ll first convert it to a data frame before piping it into a <code class="inlineCode">ggplot()</code> function to create a scatterplot:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>ggplot2<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> as.data.frame<span class="hljs-punctuation">(</span>sns_pca<span class="hljs-operator">$</span>x<span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>PC1<span class="hljs-punctuation">,</span> PC2<span class="hljs-punctuation">))</span> <span class="hljs-operator">+</span> geom_point<span class="hljs-punctuation">(</span>size <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> shape <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The resulting visualization appears as follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_09.png"/></figure>
    <p class="packt_figref">Figure 15.9: Principal component analysis (PCA) can be used to create 2-D visualizations of highly dimensional datasets, but the results are not always especially helpful</p>
    <p class="normal">Unfortunately, this<a id="_idIndexMarker1789"/> scatterplot reveals a limitation of using PCA for data exploration, which is that the two principal components often create little visual separation among the points in 2-D space. Based on our prior work in <em class="chapterRef">Chapter 9</em>, <em class="italic">Finding Groups of Data – Clustering with k-means</em>, we know that there are clusters of social media users that use similar keywords on their social media profiles. These clusters ought to be visible as distinct groupings in the scatterplot, but instead, we see one large group of points and a scattering of apparent outliers around the perimeter. The disappointing result here is not specific to the dataset used here and is typical of PCA when used in this way. Thankfully, there is another algorithm that is better suited to data exploration, which will be introduced in the next section.</p>
    <h3 class="heading-3" id="_idParaDest-349">Understanding the t-SNE algorithm</h3>
    <p class="normal">The <a id="_idIndexMarker1790"/>underlying math of the PCA technique <a id="_idIndexMarker1791"/>utilizes covariance matrices to perform a linear dimensionality reduction, and the resulting principal components are intended to capture the overall variance of the dataset. The effect is like a compression algorithm that reduces the dimensionality of a dataset by eliminating redundant information. While this is obviously an important and useful attribute for a dimensionality reduction technique, it is less helpful for data visualization. As we observed in the previous section, this<a id="_idIndexMarker1792"/> tendency of PCA to “compress” the dimensions may obscure important relationships in the data—the exact type of relationships we hope to discover when performing big data exploration.</p>
    <p class="normal">A <a id="_idIndexMarker1793"/>technique called <strong class="keyWord">t-Distributed Stochastic Neighbor Embedding</strong>, or <strong class="keyWord">t-SNE</strong> for short, is designed precisely as a tool for the visualization of high-dimensional datasets and thus addresses the previously mentioned shortcomings of PCA. The t-SNE approach was published in 2008 by Laurens van der Maaten, and it has quickly become a de facto standard for big data visualization for high-dimensional real-world datasets. Van der Maaten and others have published and presented numerous case studies contrasting PCA and t-SNE, and illustrating the strengths of the latter. However, because the math that drives t-SNE is highly complex, we will focus on understanding it conceptually and comparing it to other related methods covered previously.</p>
    <div class="note">
      <p class="normal">For a deep dive into the mechanics of the t-SNE algorithm, see the original publication, <em class="italic">Visualizing Data using t-SNE, van der Maaten, L. and Hinton, G., Journal of Machine Learning Research 9, 2008, pp. 2579-2606</em>.</p>
    </div>
    <p class="normal">Just like with any technique for visualizing highly dimensional datasets, the goal of t-Distributed Stochastic Neighbor Embedding is to ensure that points or “neighbors” that are close in the high-dimensional space are positioned closely in the low-dimensional (2-D or 3-D) space. </p>
    <p class="normal">The word <em class="italic">embedding</em> in the t-SNE name highlights the close connection between this and the more general task of constructing an embedding, as described in prior sections. However, as will be apparent shortly, t-SNE uses an approach unlike the deep learning analogue that is used for creating a word embedding. For starters, the word <em class="italic">stochastic</em> in the t-SNE name describes the non-deterministic nature of the algorithm, which implies that there is a relatively large degree of randomness in the output. But there are also more fundamental differences.</p>
    <p class="normal">To begin to understand the t-SNE algorithm, imagine if the task were merely to reduce from three dimensions to two. In this case, if the data points were somehow depicted as small balls suspended in the air in three-dimensional space, and the same number of data points were placed randomly as flat discs on the ground in 2-D space, then a human could perform the dimensionality reduction by observing each ball in 3-D space, identifying its set of neighbors, and then carefully moving the discs in 2-D space to place neighbors closer together. Of course, this is more challenging than it sounds, because moving discs closer together and further apart in the flat space may inadvertently create or eliminate groupings relative to the 3-D space. For instance, moving point<a id="_idIndexMarker1794"/> A to be closer to its neighbor point B may also move A closer to point C, when A and C should be distant according to the higher-dimensional space. For this reason, it would be important to iterate, observing each 3-D point’s neighborhood and shifting its 2-D neighbors until the overall 2-D representation is relatively stable.</p>
    <p class="normal">The <a id="_idIndexMarker1795"/>same basic process can be performed algorithmically in a much larger number of dimensions using a series of mathematical steps. First, the similarity of each point in high-dimensional space is computed—traditionally, using the familiar metric of Euclidian distance as with k-means and k-nearest neighbors in earlier chapters. This similarity metric is used to define a conditional probability distribution stating that similar points are proportionally more probable to be neighbors in the high-dimensional space. Likewise, a similar distance metric and conditional probability distribution is defined for the low-dimensional space. With these two metrics defined, the algorithm must then optimize the entire system such that the overall error for the high- and low-dimensional probability distributions is minimized. Keep in mind that the two are inseparably linked by the fact they rely on the same set of examples; the coordinates are known for the high-dimensional space, so it is essentially solving for a way to transform the high-dimensional coordinates into a low-dimensional space while preserving the similarity as much as possible.</p>
    <p class="normal">Given that the t-SNE algorithm is so different than PCA, it is no surprise that there are many differences<a id="_idIndexMarker1796"/> in how they perform. An<a id="_idIndexMarker1797"/> overall comparison of the two approaches is presented in the following table:</p>
    <table class="table-container" id="table002-7">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">PCA</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">t-SNE</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <ul>
              <li class="bulletList">Tends to compress the visualization</li>
              <li class="bulletList">Global (overall) variance is depicted</li>
              <li class="bulletList">Deterministic algorithm will produce the same result each run</li>
              <li class="bulletList">Does not have hyperparameters to be set</li>
              <li class="bulletList">Relatively fast (for datasets that can fit in memory)</li>
              <li class="bulletList">Involves linear transformations</li>
              <li class="bulletList">Useful as a general dimensionality reduction technique by creating additional principal components</li>
            </ul>
          </td>
          <td class="table-cell">
            <ul>
              <li class="bulletList">Tends to cluster the visualization</li>
              <li class="bulletList">Local variance is more apparent</li>
              <li class="bulletList">Stochastic algorithm introduces randomness into the result</li>
              <li class="bulletList">Result can be sensitive to hyperparameters</li>
              <li class="bulletList">Relatively slow (but faster approximations exist)</li>
              <li class="bulletList">Involves non-linear transformations</li>
              <li class="bulletList">Typically used only as a data visualization technique (two or three dimensions)</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">As a rule<a id="_idIndexMarker1798"/> of thumb, t-SNE is generally the more appropriate tool for big data visualization, but it is worth noting a few differences that can be weaknesses or present challenges in certain circumstances. First, we have observed that PCA can do a poor job at depicting natural clusters in the data, but t-SNE is so<a id="_idIndexMarker1799"/> apt at presenting clusters that it can occasionally even form clusters in a dataset without these types of natural divisions. This fault is compounded by the fact that t-SNE is a non-deterministic algorithm that is often quite sensitive to the values of its hyperparameters; setting these parameters poorly is more likely to create false clusters or obscure real ones. Lastly, the t-SNE algorithm involves iterating repeatedly over a relatively slow process, but stopping too early often produces a poor result or creates a false sense of the dataset’s structure; unfortunately, it is also possible that too many iterations will lead to the same problems! </p>
    <p class="normal">These challenges are not listed here to imply that t-SNE is more work than it is worth, but rather to encourage treating the output with a degree of skepticism until it has been thoroughly explored. This may mean testing various hyperparameter combinations, or it may involve a qualitative examination of the visualization, such as investigating the identified clusters by hand in order to determine what features the neighborhood has in common. We’ll see some of these potential pitfalls in practice in the next section, which applies t-SNE to a familiar real-world dataset.</p>
    <h3 class="heading-3" id="_idParaDest-350">Example – visualizing data’s natural clusters with t-SNE</h3>
    <p class="normal">To illustrate the <a id="_idIndexMarker1800"/>ability of t-SNE to depict a dataset’s natural clusters, we’ll apply the method to the same 36-dimensional social media profile dataset used previously with PCA. Beginning as before, we’ll read the raw data into R using the tidyverse, but because t-SNE is somewhat computationally expensive, we use the <code class="inlineCode">slice_sample()</code> command to limit the dataset to a random sample of 5,000 users. This is not strictly necessary but will speed up the execution time and make the visualization less dense and thus easier to read. Don’t forget to use the <code class="inlineCode">set.seed(123)</code> command to ensure your results match those that follow:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>tidyverse<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> set.seed<span class="hljs-punctuation">(</span><span class="hljs-number">123</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> sns_sample <span class="hljs-operator">&lt;-</span> read_csv<span class="hljs-punctuation">(</span><span class="hljs-string">"snsdata.csv"</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    slice_sample<span class="hljs-punctuation">(</span>n <span class="hljs-operator">=</span> <span class="hljs-number">5000</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Even with a<a id="_idIndexMarker1801"/> relatively small sample, the standard t-SNE implementation can still be rather slow. Instead, we will use a faster version called <a id="_idIndexMarker1802"/>the <strong class="keyWord">Barnes-Hut implementation</strong>. The Barnes-Hut algorithm was originally developed to simulate the so-called “<em class="italic">n</em>-body” problem—the complex system of gravitational relationships that arises among a set of <em class="italic">n</em> celestial bodies. Because every object exerts a force on every other object, exactly computing the net force for each body requires <em class="italic">n</em> <em class="italic">× n = n</em><sup class="superscript-italic" style="font-style: italic;">2</sup> calculations. This becomes computationally infeasible at an astronomical scale due to the scope of the universe and the virtually limitless numbers of objects within. Barnes-Hut simplifies this problem using a heuristic that treats more distant objects as a group identified by its center of mass, and only performs the exact calculations for objects closer than a threshold represented by the Greek letter <em class="italic">theta</em>. Larger values of theta drastically reduce the number of calculations needed to perform the simulation, while setting theta to zero performs the exact calculation.</p>
    <p class="normal">Because the role of t-SNE can be imagined as an <em class="italic">n</em>-body problem of positioning points in space, with each point’s force of attraction to other points in the 2-D space based on how similar it is to the same points in the high-dimensional space, the Barnes-Hut simplification can be applied to simplify the computation of the system’s gravity-like forces. This provides a t-SNE implementation that is much faster and scales much better on large datasets.</p>
    <p class="normal">The <code class="inlineCode">Rtsne</code> package, which you should install if you have not done so already, provides a wrapper for the C++ implementation of Barnes-Hut t-SNE. It also includes other optimizations for use with very large-dimensional datasets. One of these optimizations includes an initial PCA step, which by default reduces the dataset to its first 50 principal components. </p>
    <p class="normal">Admittedly, it may seem odd to use PCA as part of the t-SNE process, but the two have complementary strengths and weaknesses. While t-SNE tends to struggle with the curse of dimensionality, PCA is strong at dimensionality reduction; likewise, while PCA tends to obscure local variance, t-SNE highlights the data’s natural structures. Using PCA to reduce the dimensionality and following this with the t-SNE process applies both techniques’ strengths. In our case, with a dataset having only 36 dimensions, the PCA step does not meaningfully affect the result.</p>
    <p class="normal">We’ll begin by <a id="_idIndexMarker1803"/>running a t-SNE process with the default parameters. After setting the random seed, the 5,000-row sample is piped into a <code class="inlineCode">select()</code> command to choose only the 36 columns that measure the counts of various terms used on each user’s profile. This is then piped into the <code class="inlineCode">Rtsne()</code> function with <code class="inlineCode">check_duplicates = FALSE</code> to prevent an error message that occurs when the dataset has duplicate rows. Duplicate rows are found in the social media dataset chiefly because there are many users who have counts of zero for all 36 terms. There is no reason that the t-SNE method cannot handle these duplicates, but including them may lead to unexpected or unsightly results in the visualization when the algorithm attempts to arrange such a tightly clustered set of points. For social media users, seeing this cluster will be helpful, so we will override the <code class="inlineCode">Rtsne()</code> function’s default as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>Rtsne<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> set.seed<span class="hljs-punctuation">(</span><span class="hljs-number">123</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> sns_tsne <span class="hljs-operator">&lt;-</span> sns_sample <span class="hljs-operator">|&gt;</span>
    select<span class="hljs-punctuation">(</span>basketball<span class="hljs-operator">:</span>drugs<span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    Rtsne<span class="hljs-punctuation">(</span>check_duplicates <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span>
</code></pre>
    <div class="packt_tip">
      <p class="normal">Piping a dataset into the <code class="inlineCode">distinct()</code> function will eliminate duplicate rows and can be used prior to the <code class="inlineCode">Rtsne()</code> command.</p>
    </div>
    <p class="normal">The 2-D representation of the 36-dimensional dataset is stored as a matrix named <code class="inlineCode">Y</code> in the <code class="inlineCode">sns_tsne</code> list object created by the <code class="inlineCode">Rtsne()</code> function. This has 5,000 rows representing the social media users, and two columns representing the (<em class="italic">x</em>, <em class="italic">y</em>) coordinates of each user. After converting the matrix to a data frame, we can pipe these values into a <code class="inlineCode">ggplot()</code> function to visualize the t-SNE result as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>ggplot2<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> data.frame<span class="hljs-punctuation">(</span>sns_tsne<span class="hljs-operator">$</span>Y<span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>X1<span class="hljs-punctuation">,</span> X2<span class="hljs-punctuation">))</span> <span class="hljs-operator">+</span> geom_point<span class="hljs-punctuation">(</span>size <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> shape <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Displayed side by side with the earlier PCA visualization, it’s remarkable to see the vast improvement in visual clarity that the t-SNE technique provides. Distinct clusters of users can be observed, reflecting these users’ similarities in the 36-dimensional space:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_10.png"/></figure>
    <p class="packt_figref">Figure 15.10: Compared to PCA, the t-SNE technique tends to create more useful visualizations that depict the data’s natural clusters</p>
    <p class="normal">Of course, it is<a id="_idIndexMarker1804"/> somewhat unusual for a t-SNE visualization to work as nicely as this one did on the first try. If your results are disappointing, it is possible that merely setting a different random seed will generate better-looking results due to t-SNE’s use of randomization. Additionally, the <code class="inlineCode">perplexity</code> and <code class="inlineCode">max_iter</code> parameters of the <code class="inlineCode">Rtsne()</code> function can be adjusted to affect the size and density of the resulting plot. The perplexity governs the number of nearest neighbors to consider during the adjustment from high-to-low dimensions, and changing the maximum number of iterations (<code class="inlineCode">max_iter</code>) up or down may lead the algorithm to arrive at a completely different solution.</p>
    <p class="normal">Unfortunately, there are very few rules of thumb for tuning these parameters, and thus it often requires some trial and error to get things just right. The creator of t-SNE, Laurens van der Maaten, offers a few words of wisdom:</p>
    <blockquote class="packt_quote">
      <p class="quote">…one could say that a larger / denser dataset requires a larger perplexity. Typical values for the perplexity range between 5 and 50… [seeing a “ball” with uniformly distributed points] usually indicates you set your perplexity way too high. [If you continue to see bad results after tuning] maybe there is not very much nice structure in your data in the first place.</p>
      <p class="cite">Source: <a href="https://lvdmaaten.github.io/tsne/"><span class="url">https://lvdmaaten.github.io/tsne/</span></a></p>
    </blockquote>
    <p class="normal">Be warned that the <code class="inlineCode">Rtsne()</code> function parameters like <code class="inlineCode">perplexity</code> and <code class="inlineCode">max_iter</code> can drastically affect the amount of time it takes for the t-SNE algorithm to converge. If you’re not careful, you may need to force the process to quit rather than wait endlessly. Setting <code class="inlineCode">verbose = TRUE</code> in the <code class="inlineCode">Rtsne()</code> function call may provide insight into how the work has progressed.</p>
    <div class="note">
      <p class="normal">For an outstanding treatment of t-SNE’s parameters and hyperparameters with interactive visualizations that show the impact of adjustments to each, see <em class="italic">How to Use t-SNE Effectively, Wattenberg, M., Viégas, F., and Johnson, I., 2016</em>, <code class="inlineCode">https://distill.pub/2016/misread-tsne/</code>.</p>
    </div>
    <p class="normal">Because t-SNE is<a id="_idIndexMarker1805"/> an unsupervised method, aside from the remarkably large and round cluster in the top right of the visualization—which we can reasonably assume is composed of identical users with no social media keywords in their profile—we have no idea what the other clusters represent. This being said, it is possible to probe the data to investigate the clusters by labeling points with different colors or shapes based on their underlying values.</p>
    <p class="normal">For example, we can confirm the hypothesis about the top-right cluster by creating a categorical measure of how many keywords were used on each user’s page. The following tidyverse code begins by using <code class="inlineCode">bind_cols()</code> to append the t-SNE coordinates onto the original dataset. Next, it uses the <code class="inlineCode">rowwise()</code> function to change the behavior of <code class="inlineCode">dplyr</code> so that the commands work on rows rather than columns. Thus, we can use the <code class="inlineCode">sum()</code> function to count the number of terms each user had on their profile, using <code class="inlineCode">c_across()</code> to select the columns with word counts. After using <code class="inlineCode">ungroup()</code> to remove the rowwise behavior, this count is transformed into a two-outcome categorical variable using the <code class="inlineCode">if_else()</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> sns_sample_tsne <span class="hljs-operator">&lt;-</span> sns_sample <span class="hljs-operator">|&gt;</span>
    bind_cols<span class="hljs-punctuation">(</span>data.frame<span class="hljs-punctuation">(</span>sns_tsne<span class="hljs-operator">$</span>Y<span class="hljs-punctuation">))</span> <span class="hljs-operator">|&gt;</span> <span class="hljs-comment"># add the t-SNE data</span>
    rowwise<span class="hljs-punctuation">()</span> <span class="hljs-operator">|&gt;</span>
    mutate<span class="hljs-punctuation">(</span>n_terms <span class="hljs-operator">=</span> <span class="hljs-built_in">sum</span><span class="hljs-punctuation">(</span>c_across<span class="hljs-punctuation">(</span>basketball<span class="hljs-operator">:</span>drugs<span class="hljs-punctuation">)))</span> <span class="hljs-operator">|&gt;</span>
    ungroup<span class="hljs-punctuation">()</span> <span class="hljs-operator">|&gt;</span>
    mutate<span class="hljs-punctuation">(</span>`Terms Used` <span class="hljs-operator">=</span> if_else<span class="hljs-punctuation">(</span>n_terms <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"1+"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"0"</span><span class="hljs-punctuation">))</span>
</code></pre>
    <p class="normal">Using the result of this series of steps, we’ll again plot the t-SNE data, but change the shape and color of the points according to the number of terms used:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> sns_sample_tsne <span class="hljs-operator">|&gt;</span>
    ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>X1<span class="hljs-punctuation">,</span> X2<span class="hljs-punctuation">,</span> shape <span class="hljs-operator">=</span> `Terms Used`<span class="hljs-punctuation">,</span> color <span class="hljs-operator">=</span> `Terms Used`<span class="hljs-punctuation">))</span> <span class="hljs-operator">+</span>
    geom_point<span class="hljs-punctuation">(</span>size <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span>
    scale_shape<span class="hljs-punctuation">(</span>solid <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The resulting <a id="_idIndexMarker1806"/>figure confirms our assumption, as the users with zero terms used in their social media profile (denoted by circles) comprise the dense cluster in the top right of the figure, while the users with one or more terms used (denoted by triangles) are scattered elsewhere in the plot:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_11.png"/></figure>
    <p class="packt_figref">Figure 15.11: Adding color or changing the point style can help understand the clusters depicted in the t-SNE visualization</p>
    <p class="normal">The t-SNE technique is more than just a tool to make pretty pictures, although it does tend to also do that well! For one, it may be helpful for determining the value of <em class="italic">k</em> to be used for k-means clustering. The t-SNE technique can also be used after clustering has been performed, with the points colored according to their cluster assignments to illustrate the clusters for presentation purposes. Stakeholders are more likely to trust a model with results that can be seen in a PowerPoint presentation. Similarly, t-SNE can be used to qualitatively gauge the performance of an embedding such as word2vec; if the embedding is meaningful, plotting the 300-dimensional vectors in 2-D space will reveal clusters of words with related meanings. With so many useful applications of t-SNE, it is no wonder that it has quickly become a popular tool in the data science toolkit.</p>
    <div class="note">
      <p class="normal">For a fun application using both word2vec and t-SNE in which computers learned the meaning of emoji, see <em class="italic">emoji2vec: Learning Emoji Representations from their Description, Eisner, B., Rocktäschel, T., Augenstein, I., Bošnjak, M., and Riedel, S., 2016, in Proceedings of the 4th International Workshop on Natural Language Processing for Social Media at EMNLP 2016</em>.</p>
    </div>
    <p class="normal">While <a id="_idIndexMarker1807"/>tools like word2vec and t-SNE provide means for understanding big data, they are of no use if R is unable to handle the workload. The remainder of this chapter will equip you with additional tools for loading, processing, and modeling such large data sources.</p>
    <h1 class="heading-1" id="_idParaDest-351">Adapting R to handle large datasets</h1>
    <p class="normal">Although<a id="_idIndexMarker1808"/> the phrase “big data” means more than just the number of rows or the amount of memory a dataset consumes, sometimes working with a large volume of data can be a challenge in itself. Large datasets can cause computers to freeze or slow to a crawl when system memory runs out, or models cannot be built in a reasonable amount of time. Many real-world datasets are very large even if they are not truly “big,” and thus you are likely to encounter some of these issues on future projects. In doing so, you may find that the task of turning data into action is more difficult than it first appeared.</p>
    <p class="normal">Thankfully, there are packages that make it easier to work with large datasets even while remaining in the R environment. We’ll begin by looking at the functionality that allows R to connect to databases and work with datasets that may exceed available system memory, as well as packages allowing R to work in parallel, and some that utilize modern machine learning frameworks in the cloud.</p>
    <h2 class="heading-2" id="_idParaDest-352">Querying data in SQL databases</h2>
    <p class="normal">Large datasets <a id="_idIndexMarker1809"/>are often stored<a id="_idIndexMarker1810"/> in a <strong class="keyWord">database management system</strong> (<strong class="keyWord">DBMS</strong>) such as <a id="_idIndexMarker1811"/>Oracle, MySQL, PostgreSQL, Microsoft SQL, or SQLite. These systems allow the datasets to be accessed using<a id="_idIndexMarker1812"/> the <strong class="keyWord">Structured Query Language</strong> (<strong class="keyWord">SQL</strong>), a programming language designed to pull data from databases.</p>
    <h3 class="heading-3" id="_idParaDest-353">The tidy approach to managing database connections</h3>
    <p class="normal">RStudio<a id="_idIndexMarker1813"/> version 1.1, which was released in 2017, introduced a graphical approach for connecting to databases. The <strong class="screenText">Connections</strong> tab in the top-right portion of the interface provides the ability to interact with database connections found on your system. Upon clicking the <strong class="screenText">New Connection</strong> button within this interface tab, you will see a window with the available connection options. The following screenshot depicts some of the possible connection types, but your own system is likely to have a different selection than those shown here:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_12.png"/></figure>
    <p class="packt_figref">Figure 15.12: The “New Connection” button in RStudio v1.1 or greater opens an interface that will assist you with connecting to any predefined data sources</p>
    <p class="normal">The creation of these connections is typically performed by a database administrator and is specific to the type of database as well as the operating system. For instance, on Microsoft Windows, you may need to install the appropriate database drivers as well as use the ODBC Data Source Administrator application; on macOS and Unix/Linux, you may need to install the drivers and edit an <code class="inlineCode">odbc.ini</code> file. Complete documentation about the potential connection types and installation instructions is available at <a href="https://solutions.posit.co/connections/db/"><span class="url">https://solutions.posit.co/connections/db/</span></a>.</p>
    <p class="normal">Behind the scenes, the graphical interface uses a variety of R packages to manage the connections to these data sources. At the core of this functionality is the <code class="inlineCode">DBI</code> package, which provides a tidyverse-compliant front-end interface to the database. The <code class="inlineCode">DBI</code> package also manages the back-end database driver, which must be provided by another R package. Such packages let R connect to Oracle (<code class="inlineCode">ROracle</code>), MySQL (<code class="inlineCode">RMySQL</code>), PostgreSQL (<code class="inlineCode">RPostgreSQL</code>), and SQLite (<code class="inlineCode">RSQLite</code>), among many others.</p>
    <p class="normal">To illustrate <a id="_idIndexMarker1814"/>this functionality, we’ll use the <code class="inlineCode">DBI</code> and <code class="inlineCode">RSQLite</code> packages to connect to a SQLite database containing the credit dataset used previously. SQLite is a simple database that doesn’t require running a server. It simply connects to a database file on a machine, which here is named <code class="inlineCode">credit.sqlite3</code>. Before starting, be sure you’ve installed both required packages and saved the database file into your R working directory. After doing this, you can connect to the database using the following command:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> con <span class="hljs-operator">&lt;-</span> dbConnect<span class="hljs-punctuation">(</span>RSQLite<span class="hljs-operator">::</span>SQLite<span class="hljs-punctuation">(),</span> <span class="hljs-string">"credit.sqlite3"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">To prove the connection has succeeded, we can list the database tables to confirm the credit table exists as expected:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> dbListTables<span class="hljs-punctuation">(</span>con<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] "credit"
</code></pre>
    <p class="normal">From here, we can send SQL query commands to the database and return records as R data frames. For instance, to return the loan applicants with an age of 45 years or greater, we would query the database as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> res <span class="hljs-operator">&lt;-</span> dbSendQuery<span class="hljs-punctuation">(</span>con<span class="hljs-punctuation">,</span> <span class="hljs-string">"SELECT * FROM credit WHERE age &gt;= 45"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The entire result set can be fetched as a data frame using the following command:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> credit_age45 <span class="hljs-operator">&lt;-</span> dbFetch<span class="hljs-punctuation">(</span>res<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">To confirm that it worked, we’ll examine the summary statistics, which confirm that the ages begin at 45 years:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> summary<span class="hljs-punctuation">(</span>credit_age45<span class="hljs-operator">$</span>age<span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  45.00   48.00   52.00   53.98   60.00   75.00
</code></pre>
    <p class="normal">When our work is done, it is advisable to clear the query result set and close the database connection to free these resources:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> dbClearResult<span class="hljs-punctuation">(</span>res<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> dbDisconnect<span class="hljs-punctuation">(</span>con<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">In addition<a id="_idIndexMarker1815"/> to SQLite and the database-specific R packages, the <code class="inlineCode">odbc</code> package allows R to connect to many different types of databases<a id="_idIndexMarker1816"/> using a single protocol known as the <strong class="keyWord">Open Database Connectivity</strong> (<strong class="keyWord">ODBC</strong>) standard. The ODBC standard can be used regardless of operating system or DBMS.</p>
    <p class="normal">If you have previously connected to an ODBC database, you may have referred to it via its <strong class="keyWord">data source name</strong> (<strong class="keyWord">DSN</strong>). You <a id="_idIndexMarker1817"/>can use the DSN to create a database connection with a single line of R code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> con <span class="hljs-operator">&lt;-</span> dbConnect<span class="hljs-punctuation">(</span>odbc<span class="hljs-operator">:</span>odbc<span class="hljs-punctuation">(),</span> <span class="hljs-string">"my_data_source_name"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">If you have a more complicated setup, or want to specify the connection properties manually, you can specify a full connection string as arguments to the DBI package <code class="inlineCode">dbConnect()</code> function as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>DBI<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> con <span class="hljs-operator">&lt;-</span> dbConnect<span class="hljs-punctuation">(</span>odbc<span class="hljs-operator">::</span>odbc<span class="hljs-punctuation">(),</span>
                   database <span class="hljs-operator">=</span> <span class="hljs-string">"my_database"</span><span class="hljs-punctuation">,</span>
                   uid <span class="hljs-operator">=</span> <span class="hljs-string">"my_username"</span><span class="hljs-punctuation">,</span>
                   pwd <span class="hljs-operator">=</span> <span class="hljs-string">"my_password"</span><span class="hljs-punctuation">,</span>
                   host <span class="hljs-operator">=</span> <span class="hljs-string">"my.server.address"</span><span class="hljs-punctuation">,</span>
                   port <span class="hljs-operator">=</span> <span class="hljs-number">1234</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">With the connection established, queries can be sent to the ODBC database and tables can be returned as data frames using the same functions that were used for the SQLite example previously.</p>
    <div class="packt_tip">
      <p class="normal">Due to security and firewall settings, the instructions for configuring an ODBC network connection are highly specific to each situation. If you are having trouble setting up the connection, check with your database administrator. The Posit team (formerly known as RStudio) also provides helpful information at <a href="https://solutions.posit.co/connections/db/best-practices/drivers/"><span class="url">https://solutions.posit.co/connections/db/best-practices/drivers/</span></a>.</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-354">Using a database backend for dplyr with dbplyr</h3>
    <p class="normal">Using<a id="_idIndexMarker1818"/> the tidyverse’s <code class="inlineCode">dplyr</code> functions with an external database is no more difficult than using it with a traditional data frame. The <code class="inlineCode">dbplyr</code> package (short for “database plyr”) allows any <a id="_idIndexMarker1819"/>database supported by the <code class="inlineCode">DBI</code> package to be used transparently as a backend for <code class="inlineCode">dplyr</code>. The connection allows tibble objects to be pulled from the database. Generally, one does not need to do more than merely install the <code class="inlineCode">dbplyr</code> package, and <code class="inlineCode">dplyr</code> can then take advantage of its functionality.</p>
    <p class="normal">For example, let’s connect to the SQLite <code class="inlineCode">credit.sqlite3</code> database used previously, then save its <code class="inlineCode">credit</code> table as a tibble object using the <code class="inlineCode">tbl()</code> function as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>DBI<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>dplyr<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> con <span class="hljs-operator">&lt;-</span> dbConnect<span class="hljs-punctuation">(</span>RSQLite<span class="hljs-operator">::</span>SQLite<span class="hljs-punctuation">(),</span> <span class="hljs-string">"credit.sqlite3"</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> credit_tbl <span class="hljs-operator">&lt;-</span> con <span class="hljs-operator">|&gt;</span> tbl<span class="hljs-punctuation">(</span><span class="hljs-string">"credit"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Because <code class="inlineCode">dplyr</code> has been routed through a database, the <code class="inlineCode">credit_tbl</code> object here is not stored as a local R object, but rather is a table within a database. In spite of this, <code class="inlineCode">credit_tbl</code> will act exactly like an ordinary tibble and will gain all the other benefits of the <code class="inlineCode">dplyr</code> package, with the exception that the computational work will occur within the database rather than in R. This means that if the SQLite database were replaced with a database residing across a network on a more traditional SQL server, work could be offloaded to machines with more computational power rather than being performed on your local machine.</p>
    <p class="normal">For example, to query the database and display the age summary statistics for credit applicants that are at least 45 years old, we can pipe the tibble through the following sequence of functions:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>dplyr<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> credit_tbl <span class="hljs-operator">|&gt;</span>
    filter<span class="hljs-punctuation">(</span>age <span class="hljs-operator">&gt;=</span> <span class="hljs-number">45</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    select<span class="hljs-punctuation">(</span>age<span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    collect<span class="hljs-punctuation">()</span> <span class="hljs-operator">|&gt;</span>
    summary<span class="hljs-punctuation">()</span>
</code></pre>
    <p class="normal">The result is as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">      age       
 Min.   :45.00  
 1st Qu.:48.00  
 Median :52.00  
 Mean   :53.98  
 3rd Qu.:60.00  
 Max.   :75.00
</code></pre>
    <p class="normal">Note<a id="_idIndexMarker1820"/> that the <code class="inlineCode">dbplyr</code> functions are “lazy,” which means that no work is done in the database until it is necessary. Thus, the <code class="inlineCode">collect()</code> function forces <code class="inlineCode">dplyr</code> to retrieve the results from the “server” (in this case, a SQLite instance, but more typically a powerful database server) so that the summary statistics may be calculated. If the <code class="inlineCode">collect()</code> statement is omitted, the code will fail as the <code class="inlineCode">summary()</code> function cannot work directly with the database connection object.</p>
    <p class="normal">Given a database connection, most <code class="inlineCode">dplyr</code> commands will be translated seamlessly into SQL on the backend. To see how this works, we can ask <code class="inlineCode">dbplyr</code> to show the SQL code that is generated for a series of <code class="inlineCode">dplyr</code> steps. Let’s build a slightly more complex sequence of commands to show the average loan amount after filtering for ages 45 and older, and grouping by loan default status:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> credit_tbl <span class="hljs-operator">|&gt;</span>
    filter<span class="hljs-punctuation">(</span>age <span class="hljs-operator">&gt;=</span> <span class="hljs-number">45</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    group_by<span class="hljs-punctuation">(</span>default<span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    summarize<span class="hljs-punctuation">(</span>mean_amount <span class="hljs-operator">=</span> avg<span class="hljs-punctuation">(</span>amount<span class="hljs-punctuation">))</span>
</code></pre>
    <p class="normal">The output shows that those that defaulted tended to request larger loan amounts on average:</p>
    <pre class="programlisting con"><code class="hljs-con"># Source:   SQL [2 x 2]
# Database: sqlite 3.41.2 [/MLwR/Chapter 15/credit.sqlite3]
  default mean_amount
  &lt;chr&gt;         &lt;dbl&gt;
1 no            2709.
2 yes           4956.
</code></pre>
    <p class="normal">Note that this looks different from a normal <code class="inlineCode">dplyr</code> output and includes information about the database used, since the work was performed in the database rather than R. To see the SQL code that was generated to perform this analysis, simply pipe the steps into the <code class="inlineCode">show_query()</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> credit_tbl <span class="hljs-operator">|&gt;</span>
    filter<span class="hljs-punctuation">(</span>age <span class="hljs-operator">&gt;=</span> <span class="hljs-number">45</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    group_by<span class="hljs-punctuation">(</span>default<span class="hljs-punctuation">)</span> <span class="hljs-operator">|&gt;</span>
    summarize<span class="hljs-punctuation">(</span>mean_amount <span class="hljs-operator">=</span> avg<span class="hljs-punctuation">(</span>amount<span class="hljs-punctuation">))</span> <span class="hljs-operator">|&gt;</span>
    show_query<span class="hljs-punctuation">()</span>
</code></pre>
    <p class="normal">The output shows the SQL query that was run on the SQLite database:</p>
    <pre class="programlisting con"><code class="hljs-con">&lt;SQL&gt;
SELECT `default`, avg(`amount`) AS `mean_amount`
FROM `credit`
WHERE (`age` &gt;= 45.0)
GROUP BY `default`
</code></pre>
    <p class="normal">Using<a id="_idIndexMarker1821"/> the <code class="inlineCode">dbplyr</code> functionality, the same R code that is used on smaller data frames can also be used to prepare larger datasets stored in SQL databases—the heavy lifting is done on the remote server, rather than your local laptop or desktop machine. In this way, learning the tidyverse suite of packages ensures your code will apply to any type of project from small to massive. Of course, there are even more ways to enable R to work with large datasets, as you will see in the sections that follow.</p>
    <h2 class="heading-2" id="_idParaDest-355">Doing work faster with parallel processing</h2>
    <p class="normal">In the early <a id="_idIndexMarker1822"/>days of computing, computer processors always <a id="_idIndexMarker1823"/>executed instructions in <strong class="keyWord">serial</strong>, which meant that they were limited to performing a single <a id="_idIndexMarker1824"/>task at a time. In serial computing, the next instruction cannot be started until the previous instruction is complete:</p>
    <figure class="mediaobject"><img alt="Diagram  Description automatically generated" src="../Images/B17290_15_13.png"/></figure>
    <p class="packt_figref">Figure 15.13: In serial computing, tasks cannot begin until prior tasks have been completed</p>
    <p class="normal">Although it was widely known that many tasks could be completed more efficiently by completing steps simultaneously, the technology simply did not exist. This was addressed by the development of <strong class="keyWord">parallel computing</strong> methods, which use a set of two or more processors or computers to perform tasks simultaneously:</p>
    <figure class="mediaobject"><img alt="Diagram  Description automatically generated" src="../Images/B17290_15_14.png"/></figure>
    <p class="packt_figref">Figure 15.14: Parallel computing allows several tasks to occur simultaneously, which can speed up processing, but the results must be combined at the end</p>
    <p class="normal">Many modern computers <a id="_idIndexMarker1825"/>are designed for parallel computing. Even in the case that they have a single processor, they often have two or more cores that work in parallel. A core is essentially a processor within a processor, which allows computations to occur even if the other cores are busy with another task.</p>
    <p class="normal">Networks of multiple computers<a id="_idIndexMarker1826"/> called <strong class="keyWord">clusters</strong> can also be used for parallel computing. A large cluster may include a variety of hardware and be separated over large distances. In this case, the cluster is known<a id="_idIndexMarker1827"/> as a <strong class="keyWord">grid</strong>. Taken to an extreme, a cluster or grid of hundreds or thousands of computers running commodity hardware could be a very powerful system. Cloud computing systems like Amazon Web Services (AWS) and <a id="_idIndexMarker1828"/>Microsoft Azure make it easier than ever to use clusters for data science projects.</p>
    <p class="normal">The catch, however, is that not every problem can be parallelized. Certain problems are more conducive to parallel execution than others. One might expect that adding 100 processors would<a id="_idIndexMarker1829"/> result in 100 times the work being accomplished in the same amount of time (that is, the overall execution time would be 1/100), but this is typically not the case. The reason is that it takes effort to manage the workers. Work must be divided into equal, non-overlapping tasks, and each of the workers’ results must be combined into one final answer.</p>
    <p class="normal">So-called <strong class="keyWord">embarrassingly parallel</strong> problems are <a id="_idIndexMarker1830"/>the ideal. These tasks are easy to reduce into non-overlapping blocks of work, and the results are easy to recombine. An example of an embarrassingly parallel machine learning task would be 10-fold cross-validation; once the 10 samples are divided, each of the 10 blocks of work is independent, meaning that they do not affect the others. As you will soon see, this task can be sped up quite dramatically using parallel computing.</p>
    <h3 class="heading-3" id="_idParaDest-356">Measuring R’s execution time</h3>
    <p class="normal">Efforts to<a id="_idIndexMarker1831"/> speed up R will be wasted if it is not possible to systematically measure how much time was saved. Although a stopwatch is one option, an easier solution is to wrap the offending code in a <code class="inlineCode">system.time()</code> function.</p>
    <p class="normal">For example, on the author’s laptop, the <code class="inlineCode">system.time()</code> function notes that it takes about 0.026 seconds to generate a million random numbers:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">1000000</span><span class="hljs-punctuation">))</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">   user  system elapsed 
  0.025   0.001   0.026 
</code></pre>
    <p class="normal">The same function can be used to evaluate improvement in performance, obtained with the methods that were just described or any R function.</p>
    <div class="note">
      <p class="normal">For what it’s worth, when the first edition of this book was published, generating a million random numbers took 0.130 seconds; the same took about 0.093 seconds for the second edition and 0.067 seconds for the third edition. Here, it takes only 0.026 seconds. Although I’ve used a slightly more powerful computer each time, this reduction of about 80 percent of the processing time over the course of about ten years illustrates just how quickly computer hardware and software are improving!</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-357">Enabling parallel processing in R</h3>
    <p class="normal">The <code class="inlineCode">parallel</code> package, included with R version 2.14.0 and later, has lowered the entry barrier to deploying<a id="_idIndexMarker1832"/> parallel algorithms by providing a standard framework for setting up worker processes that can complete tasks simultaneously. It does this by including components of the <code class="inlineCode">multicore</code> and <code class="inlineCode">snow</code> packages, which each take a different approach to multitasking.</p>
    <p class="normal">If your computer is reasonably recent, you are likely to be able to use parallel processing. To determine the number of cores your machine has, use the <code class="inlineCode">detectCores()</code> function as follows. Note that your output will differ depending on your hardware specifications:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>parallel<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> detectCores<span class="hljs-punctuation">()</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] 10
</code></pre>
    <p class="normal">The <code class="inlineCode">multicore</code> package was developed by Simon Urbanek and allows parallel processing on a single machine that has multiple processors or processor cores. It utilizes the multitasking <a id="_idIndexMarker1833"/>capabilities of a computer’s operating system to <strong class="keyWord">fork</strong>, or create a copy of, additional R sessions that share the same memory, and is perhaps the simplest way to get started with parallel processing in R.</p>
    <div class="packt_tip">
      <p class="normal">Note that because the Microsoft Windows operating system does not support forking, the <code class="inlineCode">multicore</code> example works only on macOS or Linux machines. For a Windows-ready solution, skip ahead to the next section on <code class="inlineCode">foreach</code> and <code class="inlineCode">doParallel</code>.</p>
    </div>
    <p class="normal">An easy way to get started with the <code class="inlineCode">multicore</code> functionality is to use the <code class="inlineCode">mclapply()</code> function, which is a multicore version of <code class="inlineCode">lapply()</code>. For instance, the following blocks of code illustrate how the task of generating 10 million random numbers can be divided across 1, 2, 4, and 8 cores. The <code class="inlineCode">unlist()</code> function is used to combine the parallel results (a list) into a single vector after each core has completed its chunk of work:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>l1 <span class="hljs-operator">&lt;-</span> unlist<span class="hljs-punctuation">(</span>mclapply<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">10</span><span class="hljs-punctuation">,</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span> <span class="hljs-punctuation">{</span>
    rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">10000000</span><span class="hljs-punctuation">)},</span> mc.cores <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">)))</span>
   user  system elapsed 
  <span class="hljs-number">2.840</span>   <span class="hljs-number">0.183</span>   <span class="hljs-number">3.027</span> 
<span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>l2 <span class="hljs-operator">&lt;-</span> unlist<span class="hljs-punctuation">(</span>mclapply<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">10</span><span class="hljs-punctuation">,</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span> <span class="hljs-punctuation">{</span>
    rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">10000000</span><span class="hljs-punctuation">)},</span> mc.cores <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">)))</span>
   user  system elapsed 
  <span class="hljs-number">2.876</span>   <span class="hljs-number">0.840</span>   <span class="hljs-number">2.361</span> 
<span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>l4 <span class="hljs-operator">&lt;-</span> unlist<span class="hljs-punctuation">(</span>mclapply<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">10</span><span class="hljs-punctuation">,</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span> <span class="hljs-punctuation">{</span>
    rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">10000000</span><span class="hljs-punctuation">)</span> <span class="hljs-punctuation">},</span> mc.cores <span class="hljs-operator">=</span> <span class="hljs-number">4</span><span class="hljs-punctuation">)))</span>
   user  system elapsed 
  <span class="hljs-number">2.901</span>   <span class="hljs-number">0.824</span>   <span class="hljs-number">1.459</span> 
<span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>l8 <span class="hljs-operator">&lt;-</span> unlist<span class="hljs-punctuation">(</span>mclapply<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">10</span><span class="hljs-punctuation">,</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span> <span class="hljs-punctuation">{</span>
    rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">10000000</span><span class="hljs-punctuation">)</span> <span class="hljs-punctuation">},</span> mc.cores <span class="hljs-operator">=</span> <span class="hljs-number">8</span><span class="hljs-punctuation">)))</span>
   user  system elapsed 
  <span class="hljs-number">2.975</span>   <span class="hljs-number">1.146</span>   <span class="hljs-number">1.481</span>
</code></pre>
    <p class="normal">Notice how as the number of cores increases, the elapsed time decreases, though the benefit tapers off and may even be detrimental once too many cores have been added. Though this is a simple example, it can be adapted easily to many other tasks.</p>
    <p class="normal">The <code class="inlineCode">snow</code> package (Simple Network of Workstations) by Luke Tierney, A. J. Rossini, Na Li, and H. Sevcikova allows parallel computing on multicore or multiprocessor machines as well as on a <a id="_idIndexMarker1834"/>network of multiple machines. It is slightly more difficult to use but offers much more power and flexibility. The <code class="inlineCode">snow</code> functionality is included in the <code class="inlineCode">parallel</code> package, so to set up a cluster on a single machine, use the <code class="inlineCode">makeCluster()</code> function with the number of cores to be used:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> cl1 <span class="hljs-operator">&lt;-</span> makeCluster<span class="hljs-punctuation">(</span><span class="hljs-number">4</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Because <code class="inlineCode">snow</code> communicates via network traffic, depending on your operating system, you may receive a message to approve access through your firewall.</p>
    <p class="normal">To confirm the cluster is operational, we can ask each node to report back its hostname. The <code class="inlineCode">clusterCall()</code> function executes a function on each machine in the cluster. In this case, we’ll define a function that simply calls the <code class="inlineCode">Sys.info()</code> function and returns the <code class="inlineCode">nodename</code> parameter:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> clusterCall<span class="hljs-punctuation">(</span>cl1<span class="hljs-punctuation">,</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">()</span> <span class="hljs-punctuation">{</span> Sys.info<span class="hljs-punctuation">()[</span><span class="hljs-string">"nodename"</span><span class="hljs-punctuation">]</span> <span class="hljs-punctuation">}</span> <span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[[1]]
                  nodename
"Bretts-Macbook-Pro.local"
[[2]]
nodename
"Bretts-Macbook-Pro.local"
[[3]]
nodename
"Bretts-Macbook-Pro.local"
[[4]]
nodename
"Bretts-Macbook-Pro.local"
</code></pre>
    <p class="normal">Unsurprisingly, since all four nodes are running on a single machine, they report back the same hostname. To have the four nodes run a different command, supply them with a unique parameter via the <code class="inlineCode">clusterApply()</code> function. Here, we’ll supply each node with a different letter. Each node will then perform a simple function on its letter in parallel:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> clusterApply<span class="hljs-punctuation">(</span>cl1<span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">'A'</span><span class="hljs-punctuation">,</span> <span class="hljs-string">'B'</span><span class="hljs-punctuation">,</span> <span class="hljs-string">'C'</span><span class="hljs-punctuation">,</span> <span class="hljs-string">'D'</span><span class="hljs-punctuation">),</span>
               <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span> <span class="hljs-punctuation">{</span> paste<span class="hljs-punctuation">(</span><span class="hljs-string">"Cluster"</span><span class="hljs-punctuation">,</span> x<span class="hljs-punctuation">,</span> <span class="hljs-string">"ready!"</span><span class="hljs-punctuation">)</span> <span class="hljs-punctuation">})</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[[1]]
[1] "Cluster A ready!"
[[2]]
[1] "Cluster B ready!"
[[3]]
[1] "Cluster C ready!"
[[4]]
[1] "Cluster D ready!"
</code></pre>
    <p class="normal">When we’re done <a id="_idIndexMarker1835"/>with the cluster, it’s important to terminate the processes it spawned. This will free up the resources each node is using:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> stopCluster<span class="hljs-punctuation">(</span>cl1<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Using these simple commands, it is possible to speed up many machine learning tasks. For the largest big data problems, much more complex <code class="inlineCode">snow</code> configurations are possible. For instance, you may attempt to <a id="_idIndexMarker1836"/>configure a <strong class="keyWord">Beowulf cluster</strong>—a network of many consumer-grade machines. In academic and industry research settings with dedicated computing clusters, <code class="inlineCode">snow</code> can use <a id="_idIndexMarker1837"/>the <code class="inlineCode">Rmpi</code> package to access these high-performance <strong class="keyWord">message-passing interface</strong> (<strong class="keyWord">MPI</strong>) servers. Working with such clusters requires knowledge of network configurations and computing hardware outside the scope of this book.</p>
    <div class="note">
      <p class="normal">For a much more detailed introduction to <code class="inlineCode">snow</code>, including some information on how to configure parallel computing on several computers over a network, see the following lecture by Luke Tierney: <a href="http://homepage.stat.uiowa.edu/~luke/classes/295-hpc/notes/snow.pdf"><span class="url">http://homepage.stat.uiowa.edu/~luke/classes/295-hpc/notes/snow.pdf</span></a>.</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-358">Taking advantage of parallel with foreach and doParallel</h3>
    <p class="normal">The <code class="inlineCode">foreach</code> package by <a id="_idIndexMarker1838"/>Rich Calaway <a id="_idIndexMarker1839"/>and Steve Weston provides perhaps the easiest way to get started with parallel computing, especially if you are running R on the Windows operating system, as some of the other packages are platform specific.</p>
    <p class="normal">The core of the package is a <code class="inlineCode">foreach</code> looping construct. If you have worked with other programming languages, this may be familiar. Essentially, it allows looping over a set of items, without explicitly counting the number of items; in other words, <em class="italic">for each</em> item in the set, <em class="italic">do</em> something.</p>
    <p class="normal">If you’re thinking that R already provides a set of apply functions to loop over sets of items (for example, <code class="inlineCode">apply()</code>, <code class="inlineCode">lapply()</code>, <code class="inlineCode">sapply()</code>, and so on), you are correct. However, the <code class="inlineCode">foreach</code> loop has an additional benefit: iterations of the loop can be completed in parallel using a very simple syntax. Let’s see how this works.</p>
    <p class="normal">Recall the command we’ve been using to generate millions of random numbers. To make this more challenging, let’s increase the count to a hundred million, which causes the process to take about 2.5 seconds:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>l1 <span class="hljs-operator">&lt;-</span> rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">100000000</span><span class="hljs-punctuation">))</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">   user  system elapsed 
  2.466   0.080   2.546
</code></pre>
    <p class="normal">After the <code class="inlineCode">foreach</code> package has been installed, the same task can be expressed with a loop that combines four sets of 25,000,000 randomly generated numbers. The <code class="inlineCode">.combine</code> parameter is an optional setting that tells <code class="inlineCode">foreach</code> which function it should use to combine the final set of results from each loop iteration. In this case, since each iteration generates a set of random numbers, we simply use the <code class="inlineCode">c()</code> concatenate function to create a single, combined vector:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>l4 <span class="hljs-operator">&lt;-</span> foreach<span class="hljs-punctuation">(</span>i <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">4</span><span class="hljs-punctuation">,</span> .combine <span class="hljs-operator">=</span> <span class="hljs-string">'c'</span><span class="hljs-punctuation">)</span>
              <span class="hljs-operator">%do%</span> rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">25000000</span><span class="hljs-punctuation">))</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">   user  system elapsed 
  2.603   0.106   2.709
</code></pre>
    <p class="normal">If you noticed that this function didn’t result in a speed improvement, good catch! In fact, the process was slower. The reason is that by default, the <code class="inlineCode">foreach</code> package runs each loop iteration in serial, and the function adds a small amount of computational overhead to the process. The sister <a id="_idIndexMarker1840"/>package <code class="inlineCode">doParallel</code> provides a parallel backend for <code class="inlineCode">foreach</code> that utilizes the <code class="inlineCode">parallel</code> package included with R, described earlier in this chapter.</p>
    <p class="normal">Before <a id="_idIndexMarker1841"/>parallelizing this work, it is wise to confirm the number of cores available on your system as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> detectCores<span class="hljs-punctuation">()</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] 10
</code></pre>
    <p class="normal">Your results will differ depending on your system capabilities.</p>
    <p class="normal">Next, after installing and loading the <code class="inlineCode">doParallel</code> package, simply register the desired number of cores and swap the <code class="inlineCode">%do%</code> command with the <code class="inlineCode">%dopar%</code> operator. Here, we only need at most four cores, as there are only four groups of random numbers to combine:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>doParallel<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> registerDoParallel<span class="hljs-punctuation">(</span>cores <span class="hljs-operator">=</span> <span class="hljs-number">4</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>l4p <span class="hljs-operator">&lt;-</span> foreach<span class="hljs-punctuation">(</span>i <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">4</span><span class="hljs-punctuation">,</span> .combine <span class="hljs-operator">=</span> <span class="hljs-string">'c'</span><span class="hljs-punctuation">)</span>
              <span class="hljs-operator">%dopar%</span> rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">25000000</span><span class="hljs-punctuation">))</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">   user  system elapsed 
  2.868   1.041   1.571
</code></pre>
    <p class="normal">As shown in the output, this results in a performance increase, cutting the execution time by about 40 percent.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">Warning</strong>: if the <code class="inlineCode">cores</code> parameter is set to a number greater than the available cores on your system, or if the combined work exceeds the free memory on your computer, R may crash! In this case, the vector of random numbers is nearly a gigabyte of data, so systems with low RAM may be especially prone to crashing here.</p>
    </div>
    <p class="normal">To close the <code class="inlineCode">doParallel</code> cluster, simply type:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> stopImplicitCluster<span class="hljs-punctuation">()</span>
</code></pre>
    <p class="normal">Though the cluster will be closed automatically at the conclusion of the R session, it is better form to do so explicitly.</p>
    <h3 class="heading-3" id="_idParaDest-359">Training and evaluating models in parallel with caret</h3>
    <p class="normal">The <code class="inlineCode">caret</code> package<a id="_idIndexMarker1842"/> by Max Kuhn (covered previously in <em class="chapterRef">Chapter 10</em>, <em class="italic">Evaluating Model Performance</em>, and <em class="chapterRef">Chapter 14</em>, <em class="italic">Building Better Learners</em>) will transparently utilize a parallel backend if one <a id="_idIndexMarker1843"/>has been registered with R using the <code class="inlineCode">foreach</code> package described previously.</p>
    <p class="normal">Let’s look at a simple<a id="_idIndexMarker1844"/> example in which we attempt to train a random forest model on the credit dataset. Without parallelization, the model takes about 65 seconds to train:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>caret<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> credit <span class="hljs-operator">&lt;-</span> read.csv<span class="hljs-punctuation">(</span><span class="hljs-string">"credit.csv"</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>train<span class="hljs-punctuation">(</span>default <span class="hljs-operator">~</span> .<span class="hljs-punctuation">,</span> data <span class="hljs-operator">=</span> credit<span class="hljs-punctuation">,</span> method <span class="hljs-operator">=</span> <span class="hljs-string">"rf"</span><span class="hljs-punctuation">,</span>
                    trControl <span class="hljs-operator">=</span> trainControl<span class="hljs-punctuation">(</span>allowParallel <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)))</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">   user  system elapsed 
 64.009   0.870  64.855
</code></pre>
    <p class="normal">On the other hand, if we use the <code class="inlineCode">doParallel</code> package to register eight cores to be used in parallel (be sure to lower this number if you have fewer than eight cores available), the model takes about 10 seconds to build—less than one-sixth of the time—and we didn’t need to change the remaining <code class="inlineCode">caret</code> code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>doParallel<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> registerDoParallel<span class="hljs-punctuation">(</span>cores <span class="hljs-operator">=</span> <span class="hljs-number">8</span><span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> system.time<span class="hljs-punctuation">(</span>train<span class="hljs-punctuation">(</span>default <span class="hljs-operator">~</span> .<span class="hljs-punctuation">,</span> data <span class="hljs-operator">=</span> credit<span class="hljs-punctuation">,</span> method <span class="hljs-operator">=</span> <span class="hljs-string">"rf"</span><span class="hljs-punctuation">))</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">   user  system elapsed 
 68.396   1.692  10.569
</code></pre>
    <p class="normal">Many of the tasks involved in training and evaluating models, such as creating random samples and repeatedly testing predictions for 10-fold cross-validation, are embarrassingly parallel and ripe for performance improvements. With this in mind, it is wise to always register multiple cores before beginning a <code class="inlineCode">caret</code> project.</p>
    <div class="note">
      <p class="normal">Configuration<a id="_idIndexMarker1845"/> instructions and a case study of the performance improvements for enabling parallel processing in <code class="inlineCode">caret</code> are available on the project’s website: <a href="https://topepo.github.io/caret/parallel-processing.html"><span class="url">https://topepo.github.io/caret/parallel-processing.html</span></a>.</p>
    </div>
    <h2 class="heading-2" id="_idParaDest-360">Utilizing specialized hardware and algorithms</h2>
    <p class="normal">Base R has a <a id="_idIndexMarker1846"/>reputation for being slow and memory inefficient, a reputation that is at least somewhat earned. These faults are largely unnoticed on a modern PC for datasets of many thousands of records, but datasets with <a id="_idIndexMarker1847"/>millions of records or more can exceed the limits of what is currently possible with consumer-grade hardware. The problem is worsened if the dataset contains many features or if complex learning algorithms are being used.</p>
    <div class="note">
      <p class="normal">CRAN has a high-performance computing task view that lists packages pushing the boundaries of what is possible in R at <a href="http://cran.r-project.org/web/views/HighPerformanceComputing.html"><span class="url">http://cran.r-project.org/web/views/HighPerformanceComputing.html</span></a>.</p>
    </div>
    <p class="normal">Packages that extend R past the capabilities of the base package are being developed rapidly. These packages allow R to work faster, perhaps by spreading the work over additional computers or processors, by utilizing specialized computer hardware, or by providing machine learning optimized to big data problems.</p>
    <h3 class="heading-3" id="_idParaDest-361">Parallel computing with MapReduce concepts via Apache Spark</h3>
    <p class="normal">The <strong class="keyWord">MapReduce</strong> programming <a id="_idIndexMarker1848"/>model <a id="_idIndexMarker1849"/>was developed at Google to process its data on a large cluster of networked computers. MapReduce conceptualizes parallel programming as a two-step process:</p>
    <ul>
      <li class="bulletList">A <strong class="keyWord">map</strong> step, in <a id="_idIndexMarker1850"/>which a problem is divided into smaller tasks that are distributed across the computers in the cluster</li>
      <li class="bulletList">A <strong class="keyWord">reduce</strong> step, in <a id="_idIndexMarker1851"/>which the results of the small chunks of work are collected and synthesized into a solution to the original problem</li>
    </ul>
    <p class="normal">A popular open-source alternative to the proprietary MapReduce framework is <strong class="keyWord">Apache Hadoop</strong>. The<a id="_idIndexMarker1852"/> Hadoop software comprises the MapReduce concept plus a distributed filesystem capable of storing large amounts of data across a cluster of computers. Hadoop requires somewhat specialized programming skills to take advantage of its capabilities and to perform even basic machine learning tasks. Additionally, although Hadoop is excellent at working with extremely large amounts of data, it may not always be the fastest option because it keeps all data on disk rather than utilizing available memory.</p>
    <p class="normal"><strong class="keyWord">Apache Spark</strong> is a <a id="_idIndexMarker1853"/>cluster-computing framework for big data, offering solutions to these issues with Hadoop. Spark takes advantage of the cluster’s available memory to process data approximately 100x faster than Hadoop. Additionally, it provides easy-to-use libraries for many common data processing, analysis, and modeling tasks. These include the SparkSQL data query language, the MLlib machine learning library, GraphX for graph and network analysis, and the Spark Streaming library for processing real-time data streams. For these reasons, Spark is perhaps the current standard for open-source big data processing.</p>
    <div class="note">
      <p class="normal">Packt Publishing has published many books on Spark. To search their current offerings, visit <a href="https://subscription.packtpub.com/search?query=spark"><span class="url">https://subscription.packtpub.com/search?query=spark</span></a>.</p>
    </div>
    <p class="normal">Apache Spark is<a id="_idIndexMarker1854"/> often run remotely on a cloud-hosted cluster of virtual machines, but its benefits can also be seen running on your own hardware. In either case, the <code class="inlineCode">sparklyr</code> package connects to the cluster and provides a <code class="inlineCode">dplyr</code> interface for analyzing the data using Spark. </p>
    <p class="normal">More detailed instructions for using Spark with R can be found at <a href="https://spark.rstudio.com"><span class="url">https://spark.rstudio.com</span></a>, but the basic instructions for getting up and running are straightforward.</p>
    <p class="normal">To illustrate the fundamentals, let’s build a random forest model on the credit dataset to predict loan defaults. To begin, you’ll need to install and load the <code class="inlineCode">sparklyr</code> package. Then, the first time you use Spark, you’ll need to run the <code class="inlineCode">spark_install()</code> function, which downloads Spark onto your computer. Note that this is a sizeable download at about 220 megabytes, as it includes the full Spark environment:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>sparklyr<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> spark_install<span class="hljs-punctuation">()</span>
</code></pre>
    <p class="normal">Additionally, Spark itself requires a Java installation, which can be downloaded from <code class="inlineCode">http://www.java.com</code> if you do not already have it. Once Spark and Java have been installed, you can instantiate a Spark cluster on your local machine using the following command:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> spark_cluster <span class="hljs-operator">&lt;-</span> spark_connect<span class="hljs-punctuation">(</span>master <span class="hljs-operator">=</span> <span class="hljs-string">"local"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Next, we’ll load the loan dataset from the <code class="inlineCode">credit.csv</code> file on our local machine into the Spark instance, then use the Spark function <code class="inlineCode">sdf_random_split()</code> to randomly assign 75 and 25 percent of the data to the training and test sets, respectively. The <code class="inlineCode">seed</code> parameter is the random seed to ensure the results are identical each time this code is run:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> splits <span class="hljs-operator">&lt;-</span> sdf_random_split<span class="hljs-punctuation">(</span>credit_spark<span class="hljs-punctuation">,</span>
                           train <span class="hljs-operator">=</span> <span class="hljs-number">0.75</span><span class="hljs-punctuation">,</span> test <span class="hljs-operator">=</span> <span class="hljs-number">0.25</span><span class="hljs-punctuation">,</span>
                           seed <span class="hljs-operator">=</span> <span class="hljs-number">123</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Lastly, we’ll pipe the training data into the random forest model function, make predictions, and use the classification evaluator to compute the AUC on the test set:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> credit_rf <span class="hljs-operator">&lt;-</span> splits<span class="hljs-operator">$</span>train <span class="hljs-operator">|&gt;</span>
    ml_random_forest<span class="hljs-punctuation">(</span>default <span class="hljs-operator">~</span> .<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> pred <span class="hljs-operator">&lt;-</span> ml_predict<span class="hljs-punctuation">(</span>credit_rf<span class="hljs-punctuation">,</span> splits<span class="hljs-operator">$</span>test<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> ml_binary_classification_evaluator<span class="hljs-punctuation">(</span>pred<span class="hljs-punctuation">,</span>
    metric_name <span class="hljs-operator">=</span> <span class="hljs-string">"areaUnderROC"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">[1] 0.7824574
</code></pre>
    <p class="normal">We’ll then disconnect from the cluster:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> spark_disconnect<span class="hljs-punctuation">(</span>spark_cluster<span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">With just a few<a id="_idIndexMarker1855"/> lines of R code, we’ve built a random forest model using Spark that could expand to model millions of records. If even more computing power is needed, the code can be run in the cloud using a massively parallel Spark cluster simply by pointing the <code class="inlineCode">spark_connect()</code> function to the correct hostname. The code can also be easily adapted to other modeling approaches using one of the <a id="_idIndexMarker1856"/>supervised learning functions in the Spark Machine Learning Library (MLlib) listed at <a href="https://spark.rstudio.com/mlib/"><span class="url">https://spark.rstudio.com/mlib/</span></a>.</p>
    <div class="note">
      <p class="normal">Perhaps the easiest way to get started using Spark is with Databricks, a cloud platform developed by the creators of Spark that makes it easy to manage and scale clusters via a web-based interface. The free “Community Edition” provides a small cluster for you to try tutorials or even experiment with your own data. Check it out at <a href="https://databricks.com"><span class="url">https://databricks.com</span></a>.</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-362">Learning via distributed and scalable algorithms with H2O</h3>
    <p class="normal">The <strong class="keyWord">H2O project</strong> (<a href="https://h2o.ai"><span class="url">https://h2o.ai</span></a>) is a <a id="_idIndexMarker1857"/>big data framework <a id="_idIndexMarker1858"/>that provides fast in-memory implementations of machine learning algorithms, which can also operate in a cluster-computing environment. It includes functions for many of the methods covered in this book, including Naive Bayes, regression, deep neural networks, k-means clustering, ensemble methods, and random forests, among many others.</p>
    <p class="normal">H2O uses<a id="_idIndexMarker1859"/> heuristics to find approximate solutions to machine learning problems by iterating repeatedly over smaller chunks of the data. This gives the user the control to determine exactly how much of a massive dataset the learner should use. For some problems, a quick solution may be acceptable, but for others, the complete set may be required, which will require additional training time.</p>
    <p class="normal">H2O is usually substantially faster and performs better on very massive datasets relative to Spark’s machine learning functions, which are already much faster than base R. However, because Apache Spark is a commonly used cluster-computing and big data preparation environment, H2O can be run on Apache Spark using<a id="_idIndexMarker1860"/> the <strong class="keyWord">Sparkling Water</strong> software. With Sparkling Water, data scientists have the best of both worlds—the benefits of Spark for data preparation, and the benefits of H2O for machine learning.</p>
    <p class="normal">The <code class="inlineCode">h2o</code> package provides functionality for accessing an H2O instance from within the R environment. A full tutorial on H2O is outside the scope of this book, and documentation is available at <code class="inlineCode">http://docs.h2o.ai</code>, but the basics are straightforward. </p>
    <p class="normal">To get started, be sure you have Java installed on your computer (<a href="http://www.java.com"><span class="url">http://www.java.com</span></a>) and install the <code class="inlineCode">h2o</code> package in R. Then, initialize a local H2O instance using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> library<span class="hljs-punctuation">(</span>h2o<span class="hljs-punctuation">)</span>
<span class="hljs-operator">&gt;</span> h2o_instance <span class="hljs-operator">&lt;-</span> h2o.init<span class="hljs-punctuation">()</span>
</code></pre>
    <p class="normal">This starts an H2O server on your computer, which can be viewed via H2O Flow at <code class="inlineCode">http://localhost:54321</code>. The H2O Flow web application allows you to administer and send commands to the H2O server, or even build and evaluate models using a simple, browser-based interface:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B17290_15_15.png"/></figure>
    <p class="packt_figref">Figure 15.15: H2O Flow is a web application for interacting with the H2O instance</p>
    <p class="normal">Although <a id="_idIndexMarker1861"/>you could complete an analysis within this interface, let’s go back to R and use H2O on the loan default data that we examined previously. First, we need to upload the <code class="inlineCode">credit.csv</code> dataset to this instance using the following command:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> credit.hex <span class="hljs-operator">&lt;-</span> h2o.uploadFile<span class="hljs-punctuation">(</span><span class="hljs-string">"credit.csv"</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">Note that the <code class="inlineCode">.hex</code> extension is used to refer to an H2O data frame.</p>
    <p class="normal">Next, we’ll apply H2O’s random forest implementation to this dataset using the following command:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-operator">&gt;</span> h2o.randomForest<span class="hljs-punctuation">(</span>y <span class="hljs-operator">=</span> <span class="hljs-string">"default"</span><span class="hljs-punctuation">,</span>
                   training_frame <span class="hljs-operator">=</span> credit.hex<span class="hljs-punctuation">,</span>
                   ntrees <span class="hljs-operator">=</span> <span class="hljs-number">500</span><span class="hljs-punctuation">,</span>
                   seed <span class="hljs-operator">=</span> <span class="hljs-number">123</span><span class="hljs-punctuation">)</span>
</code></pre>
    <p class="normal">The output of this command includes information on the out-of-bag estimates of model performance:</p>
    <pre class="programlisting con"><code class="hljs-con">** Reported on training data. **
** Metrics reported on Out-Of-Bag training samples **
MSE:  0.1637001
RMSE:  0.4045987
LogLoss:  0.4956604
Mean Per-Class Error:  0.2835714
AUC:  0.7844833
AUCPR:  0.6195022
Gini:  0.5689667
R^2:  0.2204758
</code></pre>
    <p class="normal">Although the <a id="_idIndexMarker1862"/>credit dataset used here is not very large, the H2O code used here would scale to datasets of almost any size. Additionally, the code would be virtually unchanged if it were to be run in the cloud—simply point the <code class="inlineCode">h2o.init()</code> function to the remote host.</p>
    <h3 class="heading-3" id="_idParaDest-363">GPU computing</h3>
    <p class="normal">An<a id="_idIndexMarker1863"/> alternative to parallel processing uses a computer’s <strong class="keyWord">graphics processing unit</strong> (<strong class="keyWord">GPU</strong>) to <a id="_idIndexMarker1864"/>increase the speed of mathematical calculations. A GPU is a specialized processor that is optimized for rapidly displaying images on a computer screen. Because a computer often needs to display complex 3D graphics (particularly for video games), many GPUs use hardware designed for parallel processing and extremely efficient matrix and vector calculations. </p>
    <p class="normal">A side benefit is that they can be used to efficiently solve certain types of mathematical problems. As depicted in the following illustration, where a typical laptop or desktop computer processor may have on the order of 16 cores, a typical GPU may have thousands or even tens of thousands:</p>
    <figure class="mediaobject"><img alt="A picture containing shoji, building  Description automatically generated" src="../Images/B17290_15_16.png"/></figure>
    <p class="packt_figref">Figure 15.16: A graphics processing unit (GPU) has many times more cores than the typical central processing unit (CPU)</p>
    <p class="normal">The downside of GPU computing is that it requires specific hardware that is not included with many computers. In most cases, a GPU from the manufacturer NVIDIA is required, as it provides a proprietary <a id="_idIndexMarker1865"/>framework called <strong class="keyWord">Complete Unified Device Architecture</strong> (<strong class="keyWord">CUDA</strong>) that makes the GPU programmable using common languages such as C++.</p>
    <div class="note">
      <p class="normal">For more information on NVIDIA’s role in GPU computing, go to <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/machine-learning/"><span class="url">https://www.nvidia.com/en-us/deep-learning-ai/solutions/machine-learning/</span></a>.</p>
    </div>
    <p class="normal">The <code class="inlineCode">gputools</code> package <a id="_idIndexMarker1866"/>by Josh Buckner, Mark Seligman, and Justin Wilson implements several R functions, such as matrix operations, clustering, and regression modeling using <a id="_idIndexMarker1867"/>the NVIDIA CUDA toolkit. The package requires a CUDA 1.3 or higher GPU and the installation of the NVIDIA CUDA toolkit. This package was once the standard approach for GPU computing in R, but appears to have gone without an update since 2017 and has since been removed from the CRAN repository.</p>
    <p class="normal">Instead, it appears that GPU work has transitioned to the TensorFlow mathematical library. The RStudio team provides information about using a local or cloud GPU on the following pages:</p>
    <ul>
      <li class="bulletList"><a href="https://tensorflow.rstudio.com/install/local_gpu"><span class="url">https://tensorflow.rstudio.com/install/local_gpu</span></a></li>
      <li class="bulletList"><a href="https://tensorflow.rstudio.com/install/cloud_server_gpu"><span class="url">https://tensorflow.rstudio.com/install/cloud_server_gpu</span></a></li>
    </ul>
    <p class="normal">At the time of publication, a typical GPU used for deep learning is priced at several hundred US dollars for entry-level models and around $1,000-$3,000 for moderately priced units with greater performance. High-end units may cost many thousands of dollars. </p>
    <p class="normal">Rather than spending this much up front, many people rent server time by the hour on cloud providers like AWS and Microsoft Azure, where it costs approximately $1 per hour for a minimal GPU instance—just don’t forget to shut it down when your work completes, as it can get expensive quite quickly!</p>
    <h1 class="heading-1" id="_idParaDest-364">Summary</h1>
    <p class="normal">It is certainly an exciting time to be studying machine learning. Ongoing work on the relatively uncharted frontiers of parallel and distributed computing offers great potential for tapping the knowledge found in the deluge of big data. And the burgeoning data science community is facilitated by the free and open-source R programming language, which provides a very low barrier to entry—you simply need to be willing to learn.</p>
    <p class="normal">The topics you have learned, in both this chapter as well as previous chapters, provide the foundation for understanding more advanced machine learning methods. It is now your responsibility to keep learning and adding tools to your arsenal. Along the way, be sure to keep in mind the no free lunch theorem—no learning algorithm rules them all, and they all have varying strengths and weaknesses. For this reason, there will always be a human element to machine learning, adding subject-specific knowledge and the ability to match the appropriate algorithm to the task at hand.</p>
    <p class="normal">In the coming years, it will be interesting to see how the human side changes as the line between machine learning and human learning blurs. Services such as Amazon’s Mechanical Turk provide crowd-sourced intelligence, offering a cluster of human minds ready to perform simple tasks at a moment’s notice. Perhaps one day, just as we have used computers to perform tasks that human beings cannot do easily, computers will employ human beings to do the reverse. What interesting food for thought!</p>
    <h1 class="heading-1" id="_idParaDest-365">Join our book’s Discord space</h1>
    <p class="normal">Join our Discord community to meet like-minded people and learn alongside more than 4000 people at:</p>
    <p class="normal"><a href="https://packt.link/r"><span class="url">https://packt.link/r</span></a></p>
    <p class="normal"><img alt="" src="../Images/r.jpg"/></p>
  </div>
</body></html>