- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Describe Azure Machine Learning Capabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we’ve talked a lot about foundational concepts for machine learning,
    including scenarios, models, algorithms, and training data. You’ve seen a few
    simple examples of machine learning. You may have even dusted off your college
    statistics course knowledge to work through those examples yourself.
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Machine Learning** (sometimes stylized as **Azure ML** or **AzureML**)
    is the group of Microsoft Azure services that puts all of those concepts to work.
    Azure ML is comprised of a suite of tools that are used to manage the entire machine
    learning life cycle. Azure ML is used by a variety of engineers, data scientists,
    and other professionals to train, build, and deploy models and machine learning-integrated
    workflows.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The objectives and skills we’ll cover in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: What is Azure ML?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe capabilities of **automated machine** **learning** (**AutoML**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe data and compute services for data science and machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe model management and deployment capabilities in Azure ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a machine learning model in Azure ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you should be able to describe the features, capabilities,
    and supporting services for Azure ML.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: What is Azure ML?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into the particulars of machine learning on the Azure platform,
    let’s step back a minute and talk about some of the features, capabilities, and
    goals of Azure ML.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure ML enhances the capabilities and efficiency of machine learning workloads
    through a comprehensive range of tools and features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Centralized data management**: Azure ML offers a unified repository for storing
    and managing datasets, facilitating easy access and reuse across various machine
    learning projects. This centralized storage supports efficient data handling for
    both model training and evaluation, streamlining the data preparation process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalable compute resources**: Azure ML provides on-demand compute resources
    tailored for machine learning tasks. Users can leverage these resources to run
    extensive machine learning jobs, including model training and batch inferencing,
    without the need for upfront hardware investments. This flexibility allows for
    cost-effective scaling according to the complexity and size of the tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated machine learning** (**AutoML**): AutoML simplifies the process
    of applying machine learning by automatically testing multiple training jobs with
    various algorithms and hyperparameters. This feature helps users quickly identify
    the most effective model for their specific dataset, significantly reducing the
    time and expertise required for model selection and tuning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Orchestrated pipelines and visual tools**: Azure ML includes intuitive visual
    tools that allow users to create and manage orchestrated workflows, known as **pipelines**.
    These pipelines automate and streamline the end-to-end machine learning processes,
    from data preprocessing and model training to deployment and inferencing, ensuring
    reproducibility and efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Framework integration**: The platform integrates seamlessly with popular
    machine learning frameworks and tools such as **MLflow**, **TensorFlow**, **PyTorch**,
    and **scikit-learn**. This compatibility enables data scientists and developers
    to manage the life cycle of their machine learning models, from training and evaluation
    to deployment and monitoring, within a familiar environment using familiar tooling,
    all while leveraging existing code and libraries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Responsible AI practices**: Azure ML is committed to responsible AI by providing
    built-in tools and features for monitoring and evaluating AI ethics considerations.
    This includes visualizing model performance, understanding model predictions through
    explainability features, and assessing model fairness to ensure that AI systems
    are transparent, fair, and accountable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tooling and capabilities**: Azure ML provides several tools that make machine
    learning accessible to those with all levels of experience. Data scientists and
    engineers can take advantage of code-first approaches through Python, while those
    with less experience with coding and development can use the web-based **Azure
    Machine Learning Studio** to manage machine learning assets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, these features make Azure ML a comprehensive and user-friendly platform
    that addresses the needs of both novice and experienced machine learning practitioners,
    promoting efficient development, deployment, and maintenance of machine learning
    models at scale.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll begin focusing on the specific features of AutoML
    in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Describe capabilities of AutoML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AutoML is a service that automates the process of applying machine learning
    to solve problems. It significantly reduces the complexity and time needed to
    produce a model by automating various steps of the machine learning process, including
    data **preprocessing**, feature selection, algorithm selection, and hyperparameter
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: With AutoML, users can quickly create high-quality machine learning models while
    maintaining full control and transparency. The service is designed to accommodate
    both novices and experts in machine learning. For beginners, it simplifies the
    process by abstracting away many of the complexities involved in building and
    tuning machine learning models. For experts, it provides a fast way to experiment
    with different models and parameters, saving time that can be used to focus on
    other aspects of their projects.
  prefs: []
  type: TYPE_NORMAL
- en: What’s preprocessing?
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing is the idea of preparing the data before actually using it in
    machine learning models. This can involve several normalization processes and
    content preparation, such as converting text into tokens (chunks) for natural
    language processing, or using some of the techniques you learned in the previous
    chapter surrounding feature selection and dimensionality reduction.
  prefs: []
  type: TYPE_NORMAL
- en: The process with AutoML involves providing a dataset and specifying the target
    metric or outcome you are interested in. The service then automatically preprocesses
    the data, selects appropriate machine learning algorithms, and tunes their hyperparameters
    to find the best possible model based on the provided data and settings. Throughout
    this process, AutoML keeps track of all the **experiments**, providing detailed
    reports and metrics that allow users to understand how different models perform
    and why certain models are chosen.
  prefs: []
  type: TYPE_NORMAL
- en: What’s an experiment?
  prefs: []
  type: TYPE_NORMAL
- en: 'Experiments in Azure ML and AutoML refer to the process of running one or more
    trials to train and validate machine learning models. An experiment is a type
    of container object, grouping all the assets related to a particular model. They’re
    used to systematically test, track, and compare the results of different runs
    to determine the most effective configurations. An experiment typically contains
    the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Algorithms and models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameters and settings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics and outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking and comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, AutoML integrates with other Azure services, enabling models
    to be deployed seamlessly in production environments, model performance monitoring,
    and the ability to retain models with new data. This integration supports a comprehensive
    machine learning life cycle, from data preparation to model deployment and management.
    *Figure 5**.1* depicts a high-level overview of the AutoML process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Overview of the AutoML process](img/B22207_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Overview of the AutoML process
  prefs: []
  type: TYPE_NORMAL
- en: AutoML also allows you to create a Responsible AI dashboard so that you can
    track your adherence to Microsoft’s principles of responsible AI (which you learned
    about in [*Chapter 2*](B22207_02.xhtml#_idTextAnchor027), *Identify the Guiding
    Principles for* *Responsible AI*).
  prefs: []
  type: TYPE_NORMAL
- en: AutoML use cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AutoML is useful in a variety of scenarios and can help even novices in data
    science create and manage models and data pipelines. The goal of AutoML is to
    simplify the entire machine learning experience, helping data scientists and engineers
    focus more on the outcomes instead of the tooling. This section describes, at
    a high level, the types of models and use cases where AutoML is applicable.
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Classification is a supervised learning approach that’s used in machine learning
    where models are trained on labeled data and then apply the learned patterns to
    new, unseen data. Azure ML supports classification tasks and offers specialized
    features such as deep neural network text **featurizers** to enhance model performance.
    The objective of classification models is to accurately predict the category or
    class of new data instances, based on the knowledge gained from the training dataset.
    Typical applications of classification models include fraud detection, handwriting
    recognition, and object detection.
  prefs: []
  type: TYPE_NORMAL
- en: What’s a featurizer?
  prefs: []
  type: TYPE_NORMAL
- en: A featurizer is a component or technique that’s used to transform raw data into
    something the machine learning model can work with. Featurizers extract the features
    (hence the name) from the content, representing it in a way that it’s compatible
    with the training process. Featurizers can also perform dimensionality reduction
    to help simplify or reduce the complexity of the model, speeding up the performance
    and efficiency of the model. Featurizers can also help normalize data or perform
    exception handling for missing data elements.
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Regression, like classification, is a type of supervised learning task that’s
    supported by Azure ML and tailored specifically for predicting numerical outcomes.
    Unlike classification, which predicts categorical outcomes, regression models
    forecast continuous numerical values based on independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: Regression aims to determine the relationship between these variables, such
    as predicting an automobile’s price from features like gas mileage and safety
    ratings. Azure ML provides specialized featurization for regression problems and
    supports a range of algorithms for these tasks through AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: Time series forecasting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AutoML in Azure ML can be leveraged to generate high-quality time series forecasts
    for various business needs, such as predicting revenue, inventory levels, sales,
    or customer demand. This process treats time series forecasting as a multivariate
    regression problem, where past values are used alongside other predictors to enhance
    forecasting accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional methods, this approach can incorporate multiple contextual
    variables to understand their interrelationships. AutoML learns a comprehensive
    model that can apply to all items and prediction horizons in the dataset, making
    it possible to generalize predictions to new, unseen series with the benefit of
    a larger data pool for model training.
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure ML provides support for computer vision tasks, enabling the creation of
    models for image classification and object detection. This allows seamless integration
    with Azure’s data labeling features, the use of labeled data for model generation,
    and optimization of model performance through algorithm selection and hyperparameter
    tuning. Users can download or deploy these models as web services, and scale operations
    effectively using Azure ML’s **machine learning operations** (**MLOps**) and ML
    Pipelines capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Natural language processing (NLP)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Support for NLP in Azure ML provides a comprehensive and user-friendly framework
    for developing, training, and deploying models tailored for text data. This includes
    tasks such as text classification and named entity recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Azure ML supports the entire life cycle of NLP model training, from data preparation
    to model deployment. It utilizes state-of-the-art deep neural network approaches,
    including the latest pre-trained models, such as **Bidirectional Encoder Representations
    from Transformers** (**BERT**), which are renowned for their effectiveness in
    understanding the nuances of human language.
  prefs: []
  type: TYPE_NORMAL
- en: Training, validation, and test scenarios
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AutoML in Azure allows you to provide training data for machine learning model
    training and lets you specify the type of model validation to be used. It performs
    model validation as part of the training process, tuning the model’s hyperparameters
    with validation data to best fit the training data.
  prefs: []
  type: TYPE_NORMAL
- en: However, using the same validation data for each iteration introduces a risk
    of model evaluation bias as the model may *overfit* the validation data. To mitigate
    this, AutoML enables the use of separate test data to evaluate the final model
    it recommends at the experiment’s conclusion. Providing test data in your AutoML
    experiment configuration ensures that the recommended model is tested objectively,
    helping to confirm the absence of bias in the final model and its ability to generalize
    well with previously unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature engineering involves creating new features (or variables) from existing
    data based on domain knowledge to improve a machine learning algorithm’s performance.
    In Azure ML, this includes applying scaling and normalization techniques, collectively
    known as **featurization**.
  prefs: []
  type: TYPE_NORMAL
- en: In AutoML experiments, featurization processes such as feature normalization,
    handling missing data, and converting text into numeric values are automated but
    can be tailored to fit specific data needs. This not only aids in enhancing model
    learning but also helps in addressing issues such as overfitting and data imbalance.
    The featurization steps that are incorporated during model training are automatically
    applied to new input data during predictions, ensuring consistency and accuracy
    in results.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What about scenarios where more than one model might help predict more accurately?
  prefs: []
  type: TYPE_NORMAL
- en: AutoML incorporates **ensemble** models by default to enhance predictive performance
    and machine learning outcomes. Ensemble learning combines several models to form
    a single prediction, contrasting with approaches that rely on individual models.
    In AutoML, the final stages of a job often include ensemble iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process utilizes two main methods for ensemble learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Voting**: This method uses the weighted average of predicted probabilities
    (in classification tasks) or target values (in regression tasks) from different
    models to make predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stacking**: This approach involves combining various models and using a meta-model
    to make predictions based on the outputs from the initial models. For classification,
    LogisticRegression serves as the default meta-model, while ElasticNet is used
    for regression and forecasting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mix-and-match, but not that way
  prefs: []
  type: TYPE_NORMAL
- en: In AutoML, ensemble models are specific to either classification or regression
    tasks but are not mixed within the same ensemble. This means that an ensemble
    for a classification task will combine multiple classification models, whereas
    an ensemble for a regression task will combine multiple regression models.
  prefs: []
  type: TYPE_NORMAL
- en: The ensemble methods that are used, such as voting for classification and stacking
    for both classification and regression, are tailored to handle models of the same
    type (all classifiers or all regressors). The logic behind this approach is that
    combining models of the same type ensures that the predictions being averaged
    (in the case of voting) or used as input for a meta-model (in the case of stacking)
    are compatible and meaningful when aggregated.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason an ensemble model would not mix and match between different types
    of models is due to the differing types of output (categorical versus continuous),
    which serve different purposes. The metrics and outputs of the classifier and
    regressor models are different, resulting in compatible datasets to be able to
    do a comparison. To paraphrase, they’re apples and oranges.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML employs the **Caruana ensemble selection algorithm**, initiating the
    ensemble with up to five of the top-performing models, provided they are all within
    a 5% performance threshold of the leading model to ensure quality. With each iteration,
    a new model is tested within the existing ensemble, and if it improves the collective
    performance, it is included in the ensemble, enhancing the overall predictive
    strength.
  prefs: []
  type: TYPE_NORMAL
- en: What is the Caruana ensemble selection algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: The Caruana ensemble selection algorithm refers to a method developed by Rich
    Caruana and his colleagues for creating ensemble machine learning models. This
    method is particularly known for its application in ensemble learning to improve
    the predictive performance of models by combining the strengths of various individual
    models. For more information on the Carauna ensemble selection algorithm, see
    [http://www.niculescu-mizil.org/papers/shotgun.icml04.revised.rev2.pdf](http://www.niculescu-mizil.org/papers/shotgun.icml04.revised.rev2.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s shift gears and look at the services that support machine learning in
    Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Describe data and compute services for data science and machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with machine learning in Azure, it’s important to be familiar with
    the types of resources, connections, and elements that you can work with. Let’s
    look at each of the main types of services and resources associated with machine
    learning workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Compute
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Azure ML, **compute** refers to the computing resources or power that are
    allocated for running machine learning jobs (such as training models or running
    experiments) or hosting service endpoints. This can range from **serverless computing**
    (such as functions that require a minimal amount of compute resources to execute
    a command) to fully deployed server clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Azure ML supports various types of compute resources to cater to different needs
    and scenarios. Let’s take a look.
  prefs: []
  type: TYPE_NORMAL
- en: Compute cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a scalable, managed compute infrastructure that allows users to easily
    set up a cluster of virtual machines equipped with CPU or GPU processing capabilities.
    Compute clusters are ideal for running large-scale machine learning experiments
    and training jobs in the cloud. They provide flexibility in choosing the size
    and number of nodes, enabling users to scale resources according to the workload’s
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless compute
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For scenarios where managing a compute cluster may be unnecessary or too resource-intensive,
    Azure ML offers serverless compute options. These options allow users to execute
    machine learning tasks without having to worry about the underlying infrastructure
    since Azure ML manages the compute life cycle, scaling, and provisioning automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Compute instance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a managed cloud-based development environment that’s fully equipped
    with popular data science and machine learning tools and frameworks. Compute instances
    serve as personal, customizable virtual machines that can be used for developing,
    training, and testing machine learning models. They are similar to traditional
    virtual machines but are optimized for machine learning and data science workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For deploying and managing machine learning models in production environments,
    Azure ML supports integration with **Azure Kubernetes Service** (**AKS**). Users
    can deploy their trained models to AKS clusters directly from the Azure ML workspace.
    This setup is ideal for high-scale, production-grade machine learning model deployments,
    providing advanced management features and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: Attached compute
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure ML also offers the flexibility to attach external compute resources to
    the Azure ML workspace. This means users can leverage their existing infrastructure
    – such as on-premises data centers or other cloud environments – for training
    and **inference** purposes. Attached compute resources can be used seamlessly
    within Azure ML workflows, providing a bridge between Azure ML services and external
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: By offering a range of compute options, Azure ML ensures that users can select
    the most appropriate computing resources for their specific machine learning tasks,
    whether it’s for model development, training, or deployment, thereby optimizing
    performance and cost-efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data is one of the most critical factors in developing machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Azure ML, managing and utilizing data efficiently is a crucial aspect of
    configuring and managing machine learning workloads. Azure ML accommodates a wide
    variety of data types and sources, making it versatile for various data science
    and machine learning projects. You can work with the following data types and
    sources in Azure ML:'
  prefs: []
  type: TYPE_NORMAL
- en: '`uri_folder` and `uri_file` types facilitate easy access to data by allowing
    Azure ML workloads to mount or download content directly onto the compute nodes
    executing the job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mltable` format supports a rich set of operations, including filtering, transformation,
    and aggregation, making it a powerful tool for preprocessing and feature engineering
    in machine learning pipelines.*   **Primitives**: These are basic data types that
    form the building blocks for more complex data structures. Azure ML supports several
    primitive types, including the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**string**: Text data, which is useful for labels, categories, and any form
    of text analysis or manipulation.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**boolean**: A true or false value, often used for binary classification tasks
    or flagging records and frequently represented by a 0 (false) and 1 (true)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**number**: Numeric data, which can be integers or floating-point numbers,
    which is crucial for most analytical and statistical operations in machine learning'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For most data handling scenarios within Azure ML, URIs (`uri_folder` and `uri_file`)
    are commonly used to pinpoint the exact location of data within storage solutions.
    This approach simplifies the process of integrating data into machine learning
    workflows as you can easily map data locations to the filesystem of compute resources.
    Whether the data needs to be mounted as a drive or downloaded directly onto the
    compute node, Azure ML provides flexible options to ensure that your data is readily
    accessible for processing, training, and inference tasks.
  prefs: []
  type: TYPE_NORMAL
- en: By supporting a diverse range of data types and sources, Azure ML ensures that
    users can efficiently manage and utilize their data, regardless of its format
    or storage location, facilitating seamless integration into machine learning workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Datastore
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the term data refers to content (both its values and format), datastore
    refers to the locations of that data.
  prefs: []
  type: TYPE_NORMAL
- en: In Azure ML, datastores play a vital role in managing and accessing data efficiently.
    A datastore in Azure ML is essentially a secure mechanism for storing connection
    information to your data storage services hosted on Azure. This setup ensures
    that sensitive data such as connection strings or access keys are not hard-coded
    into your scripts, enhancing security and simplifying data access management.
  prefs: []
  type: TYPE_NORMAL
- en: When working with Azure ML, you can **register** (or connect) a new datastore
    or manage existing ones to streamline the connection to various Azure storage
    services. This registration process encapsulates the authentication details, allowing
    your machine learning scripts and workflows to access data seamlessly without
    repeatedly providing security credentials.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Credentials can also be stored in Azure Key Vault.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Azure ML’s **command-line interface** (**CLI**) v2 and **software development
    kit** (**SDK**) v2 extend support to various types of cloud-based storage services,
    enabling broad compatibility with different data storage needs. The following
    services are supported:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Blob Storage container**: Ideal for storing large amounts of unstructured
    data, such as images, text files, or binary data, which can be used in machine
    learning experiments and model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Files Share**: Offers shared storage for legacy applications using
    the standard **server message block** (**SMB**) protocol. This is suitable for
    scenarios where files need to be accessed and shared across multiple virtual machines
    or services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Data Lake Storage** (**ADLS**): Designed for big data analytics, it
    provides a scalable and secure storage solution for large datasets. ADLS is optimized
    for performance in analytical scenarios and supports fine-grained security control.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Data Lake Storage Gen2**: This service combines the features of Azure
    Blob Storage and ADLS, offering a highly scalable and cost-effective storage solution
    that supports both analytics and hierarchical filesystem capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By leveraging these datastores, Azure ML users can efficiently manage their
    data’s life cycle, from ingestion and storage to training and model deployment,
    ensuring that the right data is accessible at the right time for machine learning
    workflows. This integration simplifies the process of connecting to different
    Azure storage services, enabling data scientists and ML practitioners to focus
    more on developing and refining their models rather than managing data connections.
  prefs: []
  type: TYPE_NORMAL
- en: Environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Azure ML, environments are a fundamental concept as they act as containers
    for the software dependencies, libraries, and runtime context needed to run machine
    learning models and scripts. These environments ensure that your machine learning
    workflows are reproducible, scalable, and portable across different compute targets,
    from local development machines to cloud-based compute resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two core types of environments: **curated** and **custom**. Curated
    environments are defined, managed, and updated by Microsoft and include popular
    machine learning frameworks and tooling. Custom environments, on the other hand,
    are built by the user. To create an environment, you would typically use the following
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: A Docker image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Docker image with conda YAML package management for customization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Docker build context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Users might choose a custom environment if they have specific package dependencies
    or specific versions of libraries or if there are certain regulatory requirements
    that they need to comply with.
  prefs: []
  type: TYPE_NORMAL
- en: Azure ML environments can be versioned and managed centrally, allowing data
    scientists and developers to share, replicate, and deploy machine learning models
    consistently. Once defined, an environment can be reused across multiple experiments,
    pipelines, and deployments, minimizing the “it works on my machine” problem by
    ensuring that the runtime context is the same regardless of where the code is
    executed.
  prefs: []
  type: TYPE_NORMAL
- en: Environments can be created and managed through the Azure Machine Learning Studio
    UI, CLI, or SDK, providing flexibility in how you define and manipulate your machine
    learning contexts. Additionally, Azure ML provides a repository of pre-built environments
    for common machine learning tasks and frameworks, allowing you to quickly start
    your projects without having to manually configure every aspect of the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Models, in the context of Azure ML operations, are the output of the machine
    learning training process. Models are binary files that represent a machine learning
    model and its associated metadata.
  prefs: []
  type: TYPE_NORMAL
- en: Workspaces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Azure ML, a workspace acts as the primary organizational resource or container,
    serving as a centralized hub for all machine learning activities and artifacts.
    It is designed to streamline the process of developing, training, and deploying
    machine learning models by providing a unified environment where data scientists
    and developers can manage their projects, experiments, and resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'The workspace encompasses a wide range of elements that are essential for machine
    learning workflows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Job history**: This element maintains comprehensive records of all machine
    learning jobs that are executed within the workspace, capturing details such as
    execution logs, performance metrics, outputs, and even snapshots of the scripts
    used. This historical data facilitates an analysis and comparison of different
    runs over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource management**: The workspace organizes and provides easy access to
    various Azure resources that are utilized in machine learning projects, such as
    datastores for data storage and compute resources for processing and model training.
    This centralized management simplifies the task of configuring and scaling resources
    according to project needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asset storage**: Beyond just managing resources, the workspace stores all
    the machine learning assets that are created during the model development life
    cycle. This includes trained models ready for deployment, custom environments
    specifying the runtime context and dependencies, reusable components for building
    pipelines, and data assets such as datasets and data transformations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collaboration and versioning**: By serving as a shared environment, the workspace
    enables team collaboration, allowing multiple users to work on projects, share
    assets, and contribute to experiments. It supports versioning of assets such as
    models and environments, ensuring that teams can manage changes and maintain consistency
    across different stages of the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration with Azure services**: Workspaces are deeply integrated with
    other Azure services, enabling seamless deployment of models as web services,
    implementation of MLOps practices with Azure Pipelines, and monitoring of deployed
    models with Azure Application Insights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure ML workspaces are accessible through the Azure portal, SDK, and CLI, offering
    flexibility in how users interact with their machine learning resources and assets.
    By encapsulating all aspects of machine learning projects within a single workspace,
    Azure ML significantly reduces the complexity of managing machine learning life
    cycles and enables data scientists to focus more on model development and less
    on infrastructure management.
  prefs: []
  type: TYPE_NORMAL
- en: Subscription
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The subscription is a financial component that establishes the relationship
    between the Azure customer (you) and Microsoft.
  prefs: []
  type: TYPE_NORMAL
- en: Storage account
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A storage account is a resource that gives you access to a variety of storage
    objects, such as blobs, files, queues, and tables. A storage account has a unique
    namespace and can be accessed over HTTP or HTTPS.
  prefs: []
  type: TYPE_NORMAL
- en: Key Vault
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Azure Key Vault** is a secure store for authentication data (such as usernames
    and passwords, commonly referred to as **secrets**). Training jobs might require
    a secret to access the data, compute, or other services.'
  prefs: []
  type: TYPE_NORMAL
- en: Application Insights
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Application Insights can be used to provide logging and monitoring for your
    model. This integration allows you to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitor your machine learning models**: Once your machine learning model
    is deployed as a web service, Application Insights can be used to monitor its
    performance, availability, and usage. This includes tracking how often the model
    is called, response times, success rates, and any failures or exceptions that
    occur.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log custom events and metrics**: You can log custom events, traces, and metrics
    from your machine learning models to Application Insights. This can include detailed
    information about the data being processed, predictions being made, and any other
    metrics relevant to your model’s performance and usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analyze and visualize telemetry data**: Application Insights provides tools
    for analyzing and visualizing the telemetry data that’s been collected from your
    machine learning services. This can help you understand how your models are being
    used, identify trends or anomalies in their performance, and troubleshoot issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set up alerts**: You can configure alerts in Application Insights based on
    metrics or events related to your machine learning service. This can help you
    respond quickly to potential issues, such as a drop in prediction accuracy or
    an increase in response times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diagnose issues with Live Metrics Stream**: Application Insights’ Live Metrics
    Stream provides real-time visibility into the performance and health of your machine
    learning services, allowing you to diagnose issues as they happen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container Registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Azure Container Registry** is a managed, private Docker registry service
    based on the open source Docker Registry 2.0\. It is used to store and manage
    container images that are used in Azure ML for various purposes, such as training
    and deploying models.'
  prefs: []
  type: TYPE_NORMAL
- en: With that, let’s start examining some of the overall model management and deployment
    features in Azure ML.
  prefs: []
  type: TYPE_NORMAL
- en: Describe model management and deployment capabilities in Azure ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you’ve already seen throughout this chapter, Azure ML has a lot of capabilities
    –ranging from developing to deploying both simple and complex machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we’ll look at three different (yet connected) areas of model
    management in Azure ML:'
  prefs: []
  type: TYPE_NORMAL
- en: Model management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model deployment capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at each of them.
  prefs: []
  type: TYPE_NORMAL
- en: Model management and deployment capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure ML offers robust model deployment capabilities, allowing data scientists
    and developers to operationalize their machine learning models efficiently and
    at scale. These capabilities span various deployment targets, including cloud,
    on-premises, and edge environments, and provide the flexibility to meet a wide
    range of operational requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Over the next few pages, we’ll look at the key deployment capabilities of Azure
    ML.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment targets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Depending on the size of your models and how comfortable you are with different
    types of infrastructure, you can deploy Azure ML models to a variety of targets,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Kubernetes Service** (**AKS**): Ideal for high-scale production deployments,
    AKS provides a managed Kubernetes environment that supports advanced scenarios
    such as autoscaling, A/B testing, and high availability. If your deployment involves
    complex workflows or requires integration with other microservices or backend
    systems, AKS provides the necessary infrastructure and tools for managing such
    deployments. Choose AKS when you need to deploy large-scale, production-grade
    machine learning models that require auto-scaling and high availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Container Instances** (**ACI**): Best suited for low-scale CPU-based
    workloads and development/testing scenarios, ACI offers a cost-effective and simple
    deployment option without the need for Kubernetes expertise. Choose ACI for quick
    prototyping, testing, and development of machine learning models without the overhead
    of managing a Kubernetes cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Machine Learning Compute Instances**: This is useful for batch-scoring
    scenarios or when you need to run predictions on a schedule or on-demand without
    a web service. Choose Azure Machine Learning Compute Instances for development,
    experimentation, and interactive exploration of datasets and models using Jupyter
    Notebooks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Edge devices**: For scenarios requiring low-latency predictions or where
    data privacy is a concern, models can be deployed to edge devices using Azure
    IoT Edge. This allows for local model inference, reducing the need to send data
    back to the cloud for processing. Choose an edge device deployment in scenarios
    where real-time inference is required, or where network connectivity is limited
    or unreliable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model packaging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure ML packages models as **Docker containers**, which can be deployed anywhere
    that Docker containers are supported. A container holds all of the code and support
    tooling necessary to support the model. This approach ensures consistency across
    different environments and simplifies the deployment process, such as moving from
    development to production.
  prefs: []
  type: TYPE_NORMAL
- en: Model management and versioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure ML provides a central repository for storing and managing trained models.
    You can version models, track their metadata, and manage their life cycle from
    training to retirement.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and diagnostics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once deployed, Azure ML offers tools for monitoring the health and performance
    of your models in production. This includes data drift monitoring, application
    insights integration for telemetry, and logging capabilities to help diagnose
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: Security and compliance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure ML deployments can be secured using standard Azure security controls,
    including network isolation with virtual networks, encryption in transit and at
    rest, and authentication and authorization controls. Compliance with industry
    standards and regulations is also supported through **Azure** **Policy** (**AzPolicy**).
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs: []
  type: TYPE_NORMAL
- en: For more information on using AzPolicy with Azure ML, go to [https://learn.microsoft.com/en-us/azure/machine-learning/security-controls-policy](https://learn.microsoft.com/en-us/azure/machine-learning/security-controls-policy).
  prefs: []
  type: TYPE_NORMAL
- en: Scalability and performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Depending on the deployment target, Azure ML supports autoscaling to automatically
    adjust resources based on the load, ensuring that your deployments can handle
    varying levels of demand efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Integration with MLOps practices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The deployment capabilities are designed to integrate seamlessly with **machine
    learning operations** (**MLOps**) practices, supporting **continuous integration
    and delivery** (**CI/CD**) pipelines for machine learning models. This allows
    for automated model training, validation, deployment, and monitoring within a
    robust DevOps framework.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging these deployment capabilities, organizations can streamline the
    process of bringing machine learning models into production, ensuring they are
    scalable, secure, and maintainable over time.
  prefs: []
  type: TYPE_NORMAL
- en: MLOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**MLOps** is a set of operational principles, based on DevOps, that include
    the concepts of CI/CD and are designed to operationalize the life cycle of machine
    learning tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Azure MLOps represents a comprehensive approach to integrating machine learning
    models into production environments seamlessly and efficiently. As machine learning
    technologies advance, creating models that deliver precise forecasts has become
    more accessible. However, transitioning these models from development to production
    poses unique challenges that require a structured approach, combining people,
    processes, and technology to operationalize machine learning within an enterprise
    effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a situation where you have developed a machine learning model that
    surpasses all expectations in terms of accuracy and has garnered the admiration
    of your organization’s stakeholders. The next step is deploying this model into
    a live environment, which might present unforeseen complexities. Before deployment,
    the organization must establish a framework involving the necessary governance,
    personnel, workflows, and tooling to leverage the machine learning model effectively
    in production settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the landscape evolves, there might be occasions where an updated model outperforms
    the existing one in production. Introducing a new model into a live environment
    raises critical considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring the transition to the new model does not disrupt ongoing business operations
    that depend on the current system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In light of regulatory demands, there may be a need to justify the predictions
    made by the new model or to reproduce the model entirely should it generate unexpected
    or biased outcomes due to new data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the dynamic nature of data, it’s essential to periodically retrain the
    model to sustain its accuracy. This necessitates designating an individual or
    team responsible for data management, monitoring model performance, retraining
    efforts, and addressing any model failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While some aspects of MLOps align with traditional DevOps practices – such
    as implementing unit and integration tests and utilizing version control – other
    elements are uniquely tailored to machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Facilitating continuous experimentation and benchmarking against existing models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring for shifts in incoming data to identify data drift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating model retraining processes and establishing rollback mechanisms for
    rapid recovery from setbacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing and maintaining scalable data pipelines for both training models
    and executing predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The essence of MLOps is to bridge the divide between the developmental phase
    and operational deployment, thereby accelerating the delivery of value to end
    users. This transition demands a reevaluation of conventional development and
    deployment strategies to better align with the agile nature of machine learning
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring models as part of MLOps helps detect **drift** (the change in data
    over time that causes deviations in the model). Drift is overcome through the
    process of **adaptation** – periodically retraining the model based on updated
    data.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to recognize that MLOps requirements can vary significantly between
    organizations. The architecture that’s designed for MLOps in a large, global corporation
    is likely to differ considerably from the setup in a smaller, emerging company.
    Organizations typically start with modest initiatives and expand their MLOps capabilities
    as their experience, portfolio of models, and operational maturity increase.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you’ll put some of the things you’ve used into practice
    by creating a machine learning model of your own.
  prefs: []
  type: TYPE_NORMAL
- en: Build a machine learning model in Azure ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 3*](B22207_03.xhtml#_idTextAnchor042), *Identify Common Machine
    Learning Techniques*, you learned about some of the core ideas behind how machine
    learning works (including model names, sample algorithms, and the basics of validation).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’re going to have a break from the theory and create a machine
    learning model in Azure ML!
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs: []
  type: TYPE_NORMAL
- en: To complete this exercise, you will need an Azure subscription (either trial
    or paid) so that you can configure and access Azure resources. You can sign up
    for Azure credit at [https://azure.microsoft.com/en-us/pricing/offers/ms-azr-0044p/](https://azure.microsoft.com/en-us/pricing/offers/ms-azr-0044p/).
  prefs: []
  type: TYPE_NORMAL
- en: Creating a machine learning workspace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you have enabled Azure services in your environment, follow these steps
    to configure the services and set up a model:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the Azure portal ([https://portal.azure.com](https://portal.azure.com))
    and sign in.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Azure services**, click **Create** **a resource**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Filter using the text `machine learning`, select **Create** under **Azure Machine
    Learning**, and then select **Azure Machine Learning**, as shown in *Figure 5**.2*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Creating an Azure ML resource](img/B22207_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Creating an Azure ML resource
  prefs: []
  type: TYPE_NORMAL
- en: On the **Create a machine learning workspace** page, select a **Subscription**
    option. Also, select an existing **Resource group** (or **Create** a new one).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under **Workspace details**, enter a **Name** value for the workspace and select
    a **Region** option. You can leave the rest of the settings as-is. See *Figure
    5**.3*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Creating a machine learning workspace](img/B22207_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Creating a machine learning workspace
  prefs: []
  type: TYPE_NORMAL
- en: Click **Review + create** and then click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Go to resource** (or open a new browser tab and navigate to [https://ml.azure.com](https://ml.azure.com)
    to launch Azure Machine Learning Studio), then select the new workspace name you
    deployed).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you’ve created a workspace, it’s time to start working with AutoML!
  prefs: []
  type: TYPE_NORMAL
- en: Using AutoML to train a model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you’ll start working inside Azure Machine Learning Studio to
    train a model.
  prefs: []
  type: TYPE_NORMAL
- en: Sample datasets
  prefs: []
  type: TYPE_NORMAL
- en: You can find sample datasets suitable for Azure ML all over the internet. Kaggle
    ([https://www.kaggle.com](https://www.kaggle.com)) contains nearly 300,000 datasets
    and is constantly being updated. Other popular sources for data include OpenML
    ([https://openml.orgv](https://openml.orgv)), Carnegie Mellon University ([https://guides.library.cmu.edu/machine-learning/datasets](https://guides.library.cmu.edu/machine-learning/datasets)),
    and the UCI Machine Learning Repository ([https://archive.ics.uci.edu/](https://archive.ics.uci.edu/)).
    Many datasets include information on what type of models or scenarios they are
    suitable for (such as binary classification or regression), so when choosing a
    dataset, you’ll need to configure the parameters for your AutoML job accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we’ll be using a dataset that predicts engine health based
    on several metrics captured from sensor readings, though you can use any dataset.
    You can download the dataset for this chapter from this book’s GitHub repository:
    [https://github.com/PacktPublishing/Microsoft-Azure-AI-Fundamentals-AI-900-Exam-Guide](https://github.com/PacktPublishing/Microsoft-Azure-AI-Fundamentals-AI-900-Exam-Guide).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft also provides a sample dataset, available at [https://aka.ms/bike-rentals](https://aka.ms/bike-rentals),
    that can be used for this regression task.
  prefs: []
  type: TYPE_NORMAL
- en: 'From Azure Machine Learning Studio, under **Authoring**, select **Automated
    ML**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Selecting Automated ML](img/B22207_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Selecting Automated ML
  prefs: []
  type: TYPE_NORMAL
- en: Click **New Automated** **ML job**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the **Basic settings** page, enter **Job name** and **New experiment name**
    values (or accept the defaults). Click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Configuring the Basic settings page](img/B22207_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Configuring the Basic settings page
  prefs: []
  type: TYPE_NORMAL
- en: If you are using the engine health dataset, set **Select task type** to **Classification**.
    If you are using the Microsoft-provided bike rental dataset, choose **Regression**
    as the task type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under **Select data**, click **Create**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Configuring the task’s type and data](img/B22207_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – Configuring the task’s type and data
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Data type** page, enter **Name** and **Type** values. In this case,
    the source data is going to be a CSV file, so you can select **Tabular** for **Type**
    and click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Configuring the data asset](img/B22207_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – Configuring the data asset
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Data source** page, select a source location. If you have downloaded
    a dataset to your local computer, you can select **From local files**. If you
    have an HTTP-enabled endpoint where your tabular data is stored, select **From
    web files**. After selecting the source for your dataset, click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you selected **From web files** for the data source location, enter the URL
    where the data is stored.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you selected **From local files**, select **Azure Blob Storage** for **Datastore
    type** and click **Next**. See *Figure 5**.8*:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Selecting a data store location](img/B22207_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Selecting a data store location
  prefs: []
  type: TYPE_NORMAL
- en: If you selected **From local files** for the data source, click **Upload files
    or folder** and browse to the location where your source data is located. Click
    **Next** when you’re finished.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the data has been imported, you’ll have a chance to review it. Azure ML
    will automatically detect the format of the data, so you’ll want to ensure it’s
    correct. Click **Next** to continue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Viewing the imported data](img/B22207_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Viewing the imported data
  prefs: []
  type: TYPE_NORMAL
- en: On the **Schema** page, click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the **Review** page, click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the dataset has been created, select the dataset and click **Next** to
    submit the AutoML job. See *Figure 5**.10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.10 – Selecting the dataset](img/B22207_05_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Selecting the dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Task settings** page, select a **Target column** value. This is the
    label that you are going to predict. For this example, select **Engine Condition**.
    If you are using the Microsoft-provided bike rental dataset, choose **Rentals**,
    as that is the value you are trying to predict:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Configuring a target column](img/B22207_05_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Configuring a target column
  prefs: []
  type: TYPE_NORMAL
- en: 'Select **View additional configuration settings**. On the **Additional configuration**
    flyout, configure the following settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you’re using the engine health dataset, under **Primary metric**, select
    **AUCWeighted**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If you’re using the bike rental dataset, under **Primary metric**, select **NormalizedRootMeanSquaredError**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Clear the **Use all supported models** checkbox and choose models that might
    best support your data type (you can leave the default selected, but it will take
    longer to go through each of the models). If your data source has recommended
    model types, select those:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the engine health model, select **LogisticRegresion**, **DecisionTree**,
    **RandomForest**, **KNN**, and **LightGBM**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the Microsoft-provided bike rental model, select **RandomForest** and **LightGBM**:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Configuring additional job parameters](img/B22207_05_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Configuring additional job parameters
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs: []
  type: TYPE_NORMAL
- en: For more information on which primary metric choices may work best for your
    model, check out [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python#supported-algorithms](
    https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python#supported-algorithms).
  prefs: []
  type: TYPE_NORMAL
- en: Click **Save**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under **Limits**, configure the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Max** **trials**: 3'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Max concurrent** **trials**: 3'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Max** **nodes**: 3'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Metric score** **threshold**: 0.085'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Experiment timeout**: 45 minutes'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Iteration timeout**: 30 minutes'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Enable early** **termination**: Selected'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Under **Validate and test**, configure the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Validation type**: Train-validation split'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Percentage validation of** **data**: 10'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Test** **data**: None'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the **Compute** page, configure the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Select compute** **type**: Serverless'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Virtual machine** **type**: CPU'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Virtual machine** **tier**: Dedicated'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Virtual machine size**: Standard_DS3_v2 is recommended, though you can use
    any'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Number of** **instances**: 1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Configuring compute settings](img/B22207_05_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Configuring compute settings
  prefs: []
  type: TYPE_NORMAL
- en: On the **Review** page, click **Submit** **training job**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The job will be submitted and started automatically. After the job has been
    submitted, you can refresh the **Jobs** page to see its current status, as shown
    in *Figure 5**.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – AutoML job status](img/B22207_05_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – AutoML job status
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing and selecting the best model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once model training has been completed, scroll down on the **Overview** tab
    to view the **Best model summary** area. See *Figure 5**.15*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Reviewing the training information](img/B22207_05_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – Reviewing the training information
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the value for **Algorithm name** and then select the **Metrics** tab
    to review the details of the model’s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Reviewing the model metrics](img/B22207_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.16 – Reviewing the model metrics
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and testing the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the model trained and the best algorithm selected, you can deploy it.
    To do so, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Inside Azure Machine Learning Studio, navigate to the **Model** tab for the
    best model trained.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click **Deploy** and select **Web service**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Deploying a model](img/B22207_05_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.17 – Deploying a model
  prefs: []
  type: TYPE_NORMAL
- en: On the **Deploy a model** flyout, enter **Name** and **Description** values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Compute** type, select **Azure** **Container Instance**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll to the bottom of the flyout and click **Deploy**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model will deploy as a web service. It may take 5-10 minutes, depending
    on the size of the dataset and model type.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the deployed model service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once the model has been deployed, you can manually submit test data to see
    what its predictions might be. To submit a test, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Inside the workspace you have configured, select **Endpoints**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Real-time endpoints**, select the endpoint that you provisioned as a
    web service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Test** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Form editor** radio button to enter data values in the web form
    or select the **JSON editor** radio button to update test values in a pre-configured
    JSON array. Depending on your dataset and model type, you may only see the JSON
    editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill out test inputs for each of the displayed features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Engine health model**: Specify values for **Engine RPM**, **Lub oil pressure**,
    **Fuel pressure**, **Coolant pressure**, **Lub oil temp**, and **Coolant temp**.
    Click **Test** and review the values under **Test result**. **Results** that display
    *int 1* mean that the engine is likely healthy, while **Results** that display
    *int 0* indicate the engine is likely unhealthy:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Testing the classification model](img/B22207_05_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.18 – Testing the classification model
  prefs: []
  type: TYPE_NORMAL
- en: '**Bike rentals model**: Specify numeric values for **day**, **mnth**, **year**,
    **season**, **holiday**, **weekday**, **working day**, **weathersit**, **temp**,
    **atemp**, **hum**, and **windspeed**. Click **Test** and review the values under
    **Test result**. **Results** should show an integer that predicts the number of
    predicted bike rentals.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Congratulations! You’ve trained machine learning models to help predict outcomes
    based on training data! You can continue exploring other models and datasets to
    see what insights you can uncover.
  prefs: []
  type: TYPE_NORMAL
- en: Teardown
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you’re done exploring Azure ML and AutoML, you can delete the configured
    resources in Azure to avoid incurring unwanted Azure service charges. To do so,
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In Azure Machine Learning Studio, on the **Endpoints** tab, select any endpoints
    that you have published.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Delete** and then confirm the deletion.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Home**, and then click **Workspaces**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the Azure portal ([https://portal.azure.com](https://portal.azure.com))
    and search for `Resource groups`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the resource group you specified when you created the Azure ML workspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Delete resource group**, enter the name of the resource group to confirm
    that you want to delete it, and then click **Delete**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With that, of your resources will be deprovisioned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the features and capabilities of Azure ML
    and AutoML. You learned about the data and compute services and components that
    are used to support Azure ML, such as compute clusters, models, workspaces, and
    storage accounts.
  prefs: []
  type: TYPE_NORMAL
- en: You also learned about the model management and deployment capabilities of Azure
    ML, as well as the concepts surrounding MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you learned how to deploy Azure ML models, train them with sample data,
    and then test against them.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you’ll begin exploring computer vision solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Exam Readiness Drill – Chapter Review Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from a solid understanding of key concepts, being able to think quickly
    under time pressure is a skill that will help you ace your certification exam.
    That is why working on these skills early on in your learning journey is key.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter review questions are designed to improve your test-taking skills progressively
    with each chapter you learn and review your understanding of key concepts in the
    chapter at the same time. You’ll find these at the end of each chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before you proceed
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a Packt Library subscription or you haven't purchased this
    book from the Packt store, you will need to unlock the online resources to access
    the exam readiness drills. Unlocking is free and needs to be done only once. To
    learn how to do that, head over to the chapter titled [*Chapter 12*](B22207_12.xhtml#_idTextAnchor228)*,
    Accessing the* *Online Resources*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To open the Chapter Review Questions for this chapter, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click the link – [https://packt.link/AI-900_CH05](https://packt.link/AI-900_CH05).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, you can scan the following QR code (*Figure 5**.19*):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.19 – QR code that opens Chapter Review Questions for logged-in users](img/B22207_05_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.19 – QR code that opens Chapter Review Questions for logged-in users
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you log in, you’ll see a page similar to the one shown in *Figure 5**.20*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Chapter Review Questions for Chapter 5](img/B22207_05_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.20 – Chapter Review Questions for Chapter 5
  prefs: []
  type: TYPE_NORMAL
- en: Once ready, start the following practice drills, re-attempting the quiz multiple
    times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exam Readiness Drill
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the first three attempts, don’t worry about the time limit.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first time, aim for at least **40%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix your learning gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The second time, aim for at least **60%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix any remaining learning
    gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The third time, aim for at least **75%**. Once you score 75% or more, you start
    working on your timing.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You may take more than **three** attempts to reach 75%. That’s okay. Just review
    the relevant sections in the chapter till you get there.
  prefs: []
  type: TYPE_NORMAL
- en: Working On Timing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your aim is to keep the score the same while trying to answer these questions
    as quickly as possible. Here’s an example of how your next attempts should look
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Attempt** | **Score** | **Time Taken** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 5 | 77% | 21 mins 30 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 6 | 78% | 18 mins 34 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 7 | 76% | 14 mins 44 seconds |'
  prefs: []
  type: TYPE_TB
- en: Table 5.1 – Sample timing practice drills on the online platform
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The time limits shown in the above table are just examples. Set your own time
    limits with each attempt based on the time limit of the quiz on the website.
  prefs: []
  type: TYPE_NORMAL
- en: With each new attempt, your score should stay above **75%** while your “time
    taken” to complete should “decrease”. Repeat as many attempts as you want till
    you feel confident dealing with the time pressure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 3: Describe Features of Computer Vision Workloads on Azure'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you’ll begin exploring **computer vision**—the concepts and technologies
    that allow computers to look at images and identify objects and text.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part includes the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B22207_06.xhtml#_idTextAnchor112), *Identify Common Types of
    Computer Vision Solutions*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B22207_07.xhtml#_idTextAnchor129), *Identify Azure Tools and
    Services for Computer Vision Tasks*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
