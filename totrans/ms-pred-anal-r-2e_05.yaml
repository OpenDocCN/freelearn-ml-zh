- en: Chapter 5. Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've looked at two of the most well-known methods used for predictive
    modeling. Linear regression is probably the most typical starting point for problems
    where the goal is to predict a numerical quantity. The model is based on a linear
    combination of input features. Logistic regression uses a nonlinear transformation
    of this linear feature combination in order to restrict the range of the output
    in the interval [0,1]. In so doing, it predicts the probability that the output
    belongs to one of two classes. Thus, it is a very well-known technique for classification.
  prefs: []
  type: TYPE_NORMAL
- en: Both methods share the disadvantage that they are not robust when dealing with
    many input features. In addition, logistic regression is typically used for binary
    classification problems. In this chapter, we will introduce the concept of **neural
    networks**, a nonlinear approach to solving both regression and classification
    problems. They are significantly more robust when dealing with a higher dimensional
    input feature space, and for classification, they possess a natural way to handle
    more than two output classes.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are a biologically inspired model, the origins of which date
    back to the 1940s. Interest in neural networks has fluctuated greatly over the
    years as the first models proved to be quite limited compared to the expectations
    at the time. Additionally, training a large neural network requires substantial
    computational resources. Recently, there has been a huge surge in interest in
    neural networks as distributed on-demand computing resources are now widespread
    and an important area of machine learning, known as **deep learning**, is already
    showing great promise. For this reason, it is a great time to be learning about
    this type of model.
  prefs: []
  type: TYPE_NORMAL
- en: The biological neuron
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Neural network models draw their analogy from the organization of neurons in
    the human brain, and for this reason they are also often referred to as **artificial
    neural networks** (**ANNs**) to distinguish them from their biological counterparts.
    The key parallel is that a single biological neuron acts as a simple computational
    unit, but when a large number of these are combined together, the result is an
    extremely powerful and massively distributed processing machine capable of complex
    learning, known more commonly as the human brain. To get an idea of how neurons
    are connected in the brain, the following image shows a simplified picture of
    a human neural cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The biological neuron](img/00079.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In a nutshell, we can think of a human neuron as a computational unit that takes
    in a series of parallel electrical signal inputs known as **synaptic neurotransmitters**
    coming in from the **dendrites**. The dendrites transmit signal chemicals to the
    **soma** or body of the neuron in response to the received synaptic neurotransmitters.
    This conversion of an external input signal to a local signal can be thought of
    as a process in which the dendrites apply a **weight** (which can be negative
    or positive depending on whether the chemicals produced are **inhibitors** or
    **activators,** respectively) to their inputs.
  prefs: []
  type: TYPE_NORMAL
- en: The soma of the neuron, which houses the **nucleus** or central processor, mixes
    these input signals in a process that can be thought of as summing up all the
    signals. Consequently, the original dendrite inputs are basically transformed
    into a single linear weighted sum. This sum is sent to the **axon** of the neuron,
    which is the transmitter of the neuron. The weighted sum of electrical inputs
    creates an electric potential in the neuron, and this potential is processed in
    the axon by means of an **activation function**, which determines whether the
    neuron will fire.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, the activation function is modeled as a switch that requires a minimum
    electrical potential, known as the **bias**, to be reached before it is turned
    on. Thus, the activation function essentially determines whether the neuron will
    output an electrical signal or not, and if so, the signal is transported through
    the axon and propagated to other neurons through the **axon terminals**. These,
    in turn, connect to the dendrites of neighboring neurons and the electrical signal
    output becomes an input to subsequent neural processing.
  prefs: []
  type: TYPE_NORMAL
- en: This description is, of course, a simplification of what happens in our neurons,
    but the goal here is to explain what aspects of the biological process have been
    used to inspire the computational model of a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: The artificial neuron
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using our biological analogy, we can construct a model of a computational neuron,
    and this model is known as the **McCulloch-Pitts model** of a neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The artificial neuron](img/00080.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Warren McCulloch* and *Walter Pitts* proposed this model of a neural network
    as a computing machine in a paper titled *A logical calculus of the ideas immanent
    in nervous activity*, published by the *Bulletin of Mathematical Biophysics* in
    1943.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This computational neuron is the simplest example of a neural network. We can
    construct the output function, *y*, of our neural network directly from following
    our diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The artificial neuron](img/00081.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The function `g()` in our neural network is the activation function. Here,
    the specific activation function that is chosen is the **step function**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The artificial neuron](img/00082.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'When the linear weighted sum of inputs exceeds zero, the step function outputs
    1, and when it does not, the function outputs -1\. It is customary to create a
    dummy input feature *x[0]* which is always taken to be 1, in order to merge the
    bias or threshold *w[0]* into the main sum as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The artificial neuron](img/00083.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Using our experience with logistic regression, it should be very easy to conclude
    that we could construct a simple classifier using this setup for the binary classification
    problem. The only difference is that in logistic regression, we would choose the
    logistic function as the activation function. In fact, in 1957, *Frank Rosenblatt*
    proposed a supervised learning algorithm for training the *McCulloch-Pitts* model
    of neurons to perform binary classification, and this algorithm along with the
    learning model produced is known as the **Rosenblatt perceptron**.
  prefs: []
  type: TYPE_NORMAL
- en: We've thus far presented linear and logistic regression as models that can solve
    supervised learning problems and showed the criteria that are used to train them
    without actually going into the optimization details of the training algorithms
    involved. This was done intentionally to allow us to focus our attention on understanding
    the models themselves, and how to apply them in R.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have built up some experience with classification and regression,
    this chapter is going to be different, in that we will look at some of the details
    of how predictive models are trained, as this too is an important process that
    adds to our overall understanding of a model. In addition, neural networks differ
    substantially from previous models we have seen so far, in that training a neural
    network is often more time consuming and involves adjusting a number of parameters,
    many of which arise from the optimization procedure itself. Thus, it helps to
    understand the role these parameters play during training and how they can affect
    the final model.
  prefs: []
  type: TYPE_NORMAL
- en: Before we present a training algorithm for the perceptron, we'll first have
    to learn one of the most fundamental techniques used in solving optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the models we''ve seen so far, such as linear regression, we''ve talked
    about a criterion or objective function that the model must minimize while it
    is being trained. This criterion is also sometimes known as the **cost function**.
    For example, the least squares cost function for a model can be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stochastic gradient descent](img/00084.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We''ve added a constant term of ½ in front of this for reasons that will become
    apparent shortly. We know from basic differentiation that when we are minimizing
    a function, multiplying the function by a constant factor does not alter the value
    of the minimum value of the function. In linear regression, just as with our perceptron
    model, our model''s predicted ![Stochastic gradient descent](img/00085.jpeg)are
    just the sum of a linear weighted combination of the input features. If we assume
    that our data is fixed and that the weights are variable and must be chosen so
    as to minimize our criterion, we can treat the cost function as being a function
    of the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stochastic gradient descent](img/00086.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We have used the letter *w* to represent the model weights here for the more
    general case, though in linear regression we''ve seen that it is customary to
    use the Greek letter *β* instead. As our model variables are the weights, we can
    consider that our function is a function of a weight vector ![Stochastic gradient
    descent](img/00087.jpeg). To find the minimum of this function, we just need to
    take the partial derivative of our cost function with respect to this weight vector.
    For a specific weight *w[k]*, this partial derivative is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stochastic gradient descent](img/00088.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that the coefficient of one half has usefully cancelled out the *2* from
    the derivative. We now have three different subscripts, so it is a good idea to
    take a step back and try to understand this equation. The innermost sum is still
    computing, which is the model''s predicted output. Let''s replace this in the
    equation to simplify things a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stochastic gradient descent](img/00089.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Now we should be in a better position to understand this equation. It says that
    the partial derivative of the cost function that we are trying to minimize for
    a specific weight, *w[k]*, in our model is just the difference between the predicted
    output of the model and the actual labeled output, multiplied by *x[ik]* (for
    the *i^(th)* observation, the value of the input feature that corresponds to our
    weight *w[k]*), and averaged over all the *n* observations in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you are not familiar with partial differentiation, but are familiar with
    differentiation, you already know everything you need to in order to understand
    this equation. We use partial differentiation to explicitly identify the variable
    that we will be differentiating with respect to an equation that has more than
    one variable. When we do this, we treat all other variables as constants and the
    differentiation is carried out normally.
  prefs: []
  type: TYPE_NORMAL
- en: To find the optimal weights, we need to solve this equation for every weight
    in our weight vector. Note that through the predicted output term, all the weights
    in the model appear in the partial derivative of every individual weight. Put
    differently, this produces a complete system of linear equations that is often
    very large, so solving this directly is often prohibitively expensive, computationally
    speaking.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, many model implementations use iterative optimization procedures that
    are designed to gradually approach the correct solution. One such method is **gradient
    descent**. For a particular value of the weight vector, gradient descent finds
    the direction in which the gradient of the cost function is steepest, and adjusts
    the weights in that direction by a small amount, which is determined by a parameter
    known as the **learning rate**. Thus, the updated equation is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stochastic gradient descent](img/00090.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the previous equation, the learning rate is denoted by the Greek letter *η*.
    Setting the learning rate to an appropriate value is a very important aspect of
    optimizing with gradient descent. If we choose a value that is too small, the
    algorithm will update the weights by a very small amount each time, and thus it
    will take too long to finish. If we use a value that is too large, we may cause
    the weights to change too drastically, oscillating between values, and so again
    the learning algorithm will either take too long to converge or oscillate continuously.
  prefs: []
  type: TYPE_NORMAL
- en: There are various sophisticated methods to estimate an appropriate learning
    rate, the details of which we won't discuss here. Instead, we'll try to find an
    appropriate learning rate through trial and error, and this often works just fine
    in practice. One way to keep track of whether our chosen learning rate is decent
    is to plot the cost function we are trying to minimize versus time (represented
    by the number of iterations made through the dataset). We should be seeing a decreasing
    (or at least non-increasing) change in the cost function over time if we have
    chosen a good value for the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: A variant of the gradient descent method is **stochastic gradient descent**,
    which does a similar computation, but takes the observations one at a time instead
    of all together. The key idea is that, on average, the gradient of the cost function
    computed for a particular observation will equal that of the gradient computed
    across all observations. This is, of course, an approximation, but it does mean
    that we can process individual observations one at a time, which is very useful,
    especially if we want to perform online learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stochastic gradient descent updates a particular weight, *w[k]*, when processing
    the *i^(th)* observation in the dataset according to the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stochastic gradient descent](img/00091.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An excellent resource for some of the tricks that are useful when training a
    model with stochastic gradient descent is a book chapter by *Leo Bottou*, titled
    *Stochastic Gradient Descent Tricks*. A version of this can be found online at
    [http://research.microsoft.com/pubs/192769/tricks-2012.pdf](http://research.microsoft.com/pubs/192769/tricks-2012.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent and local minima
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Gradient descent methods rely on the idea that the cost function that is being
    minimized is a **convex function**. We''ll skip the mathematical details of this
    and just say that a convex function is a function that has, at most, a single
    global minimum. Let''s look at an example of a non-convex cost function in terms
    of a single weight *w*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gradient descent and local minima](img/00092.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The global minimum of this function is the first trough on the left for a value
    of *w*, close to 4.5\. If our initial guess for the weight *w* is 1, the gradient
    of the cost function points towards the global minimum, and we will progressively
    approach it until we reach it. If our initial guess of the weight is 12, then
    the gradient of the cost function will point downwards towards the trough near
    the value 10.5\. Once we reach the second trough, the gradient of the cost function
    will be 0 and consequently, we will not be able to make any progress towards our
    global minimum because we have landed in a local minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting and avoiding local minima can be very tricky, especially if there
    are many of them. One way to do this is to repeat the optimization with different
    starting points and then pick the weights that produce the lowest value of the
    cost function across the different times the optimization is run. This procedure
    works well if the number of local minima is small and they are not too close together.
    Thankfully, the squared error cost function that we saw in the previous section
    is a convex function and so gradient descent methods are guaranteed to find the
    global minimum, but it is good to be aware that there are other examples of cost
    functions that we will encounter that are non-convex.
  prefs: []
  type: TYPE_NORMAL
- en: The perceptron algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Without further ado, we'll present our first training algorithm for classification
    with neural networks. This is a variation of the perceptron learning algorithm
    and is known as the **pocket perceptron algorithm**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Inputs:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`x`: A two-dimensional matrix, where the rows are the observations and the
    columns are the input features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y`: A vector with the class label (-1 or 1) for all the observations in *x*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate`: A number that controls the learning rate of the algorithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_iterations`: The maximum number of cycles through our data that our algorithm
    is allowed to perform while learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outputs:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`w`: The learned weights of the perceptron.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`converged`: Whether the algorithm converged (true or false).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`iterations`: The actual number of iterations through the data performed during
    learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Method:**'
  prefs: []
  type: TYPE_NORMAL
- en: Randomly initialize the weights *w*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select an observation in *x*, and call it *xi*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the predicted class,![The perceptron algorithm](img/00093.jpeg), using
    the current values of the weights *w* and the equation for the output of the perceptron.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the predicted class,![The perceptron algorithm](img/00093.jpeg) is not the
    same as the actual class, `yi`, then update the weights vector using stochastic
    gradient descent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 2–4 for all the observations in our dataset and count the number
    of errors made.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the number of errors is zero, we have converged and the algorithm terminates.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the number of errors made in the current iteration was less than the lowest
    numbers of errors ever made, store the weights vector as the best weights vector
    seen so far.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we have reached the maximum number of iterations, stop and return the value
    of the best weights vector. Otherwise, begin a new iteration over the dataset
    at step 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We''ll see the R code for this directly and discuss the steps in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first function we define is the step function, which we know will produce
    either the value `-1` or the value `1` corresponding to the two classes in our
    dataset. We then define our main function, which we call `pocket_perceptron()`.
    The job of this function is to learn the weights for our perceptron so that our
    model classifies our training data correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we have not introduced any regularization in our algorithm to keep
    things simple, and so we will likely end up with a model that will overfit our
    data, as we are shooting for 100 percent training accuracy. Proceeding with our
    algorithm description, we begin our function by initializing the weights vector
    to small randomly generated numbers. In practice, it is a good idea to make sure
    that weights are not set to `0` and are not symmetric, and this method is a good
    way to avoid this.
  prefs: []
  type: TYPE_NORMAL
- en: We will also set our starting best guess of the weights to be our initial vector
    and our starting best error rate to be the total number of observations, which
    is the worst possible error rate on a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The main `while` loop of the function controls the number of iterations over
    which our algorithm will run. We will only begin a new iteration when we have
    not converged and when we have not hit our maximum number of iterations. Inside
    the `while` loop, we use a `for` loop to iterate over the observations in our
    dataset and classify these using the current version of our weight vector.
  prefs: []
  type: TYPE_NORMAL
- en: Every time we make a mistake in classification, we update our error rate, note
    that we have not converged in this iteration, and update our weight vector according
    to the stochastic gradient descent update rule for least squares that we saw in
    the previous section. Although the cost function for the perceptron is not differentiable
    because of the step function used to threshold the output, it turns out that we
    can, in fact, still use the same update rule for the weights.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of a complete iteration through our dataset, also known as an **epoch**,
    we check whether we need to update our best weights vector and update the number
    of iterations. We update our best weights vector only if the performance in the
    current iteration on the training data was the best performance we have seen thus
    far across all completed iterations. When the algorithm terminates, we return
    the best weights we found, whether or not we converged, and the total number of
    completed iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The definitive textbook on neural networks, and one that explains perceptron
    learning in more detail, including proof of why the algorithm works, is *Neural
    Networks and Learning Machines 3rd Edition*, *Simon Haykin*, *Prentice Hall.*
  prefs: []
  type: TYPE_NORMAL
- en: 'We can put our model to the test by generating some artificial data. We''ll
    do this by sampling values from two uniform distributions in order to create two
    input features: *x[1]* and *x[2]*. We''ll then separate these data points into
    two different classes according to a linear decision boundary that we''ve chosen
    randomly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The perceptron algorithm](img/00094.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we have the data and the computed class labels, we can run our perceptron
    algorithm on it. The following code generates the test data and builds our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that after 32 iterations, our perceptron algorithm has converged.
    If we divide our weights vector by `2` (this does not alter our decision boundary),
    we can see more clearly that we have a decision boundary that is very close to
    the one that was used when classifying the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The following plot shows that the model's decision boundary is virtually indistinguishable
    from the population line. For our artificially generated dataset, this is because
    the two classes are so close together. If the classes were further apart, we would
    more likely see a noticeable difference between the population decision boundary
    and the model's decision boundary.
  prefs: []
  type: TYPE_NORMAL
- en: This is because the space of possible lines (or planes when we are dealing with
    more than two features) that can separate the data would be larger.
  prefs: []
  type: TYPE_NORMAL
- en: '![The perceptron algorithm](img/00095.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Linear separation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data that we generated had a particular property that ensured that the perceptron
    algorithm would converge--it was **linearly separable**. When two classes are
    linearly separable in terms of a set of features, it means that it is possible
    to find a linear combination of these features as a decision boundary that will
    allow us to classify the two classes with 100 percent accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: If we consider plotting the data points belonging to the two classes in the
    *p*-dimensional feature space, then linear separation means that there is a plane
    (or line for two dimensions, as we saw in our example) that can be drawn to separate
    the two classes. There is a theorem, known as the **perceptron convergence theorem**,
    which states that for linearly separable classes, the perceptron learning algorithm
    will always converge to a solution that correctly classifies all the data given
    enough time.
  prefs: []
  type: TYPE_NORMAL
- en: The logistic neuron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The perceptron is also known as a **binary threshold neuron**. We can create
    different types of neurons by changing the activation function. For example, if
    we remove the threshold function completely, we end up with a **linear neuron**,
    which essentially performs the same task as linear regression. By changing the
    activation function to a logistic function, we can create a **logistic neuron**.
  prefs: []
  type: TYPE_NORMAL
- en: 'A logistic neuron performs the same task as logistic regression, by taking
    a linear combination of inputs and applying the logistic function to predict a
    value in the interval [0,1]. Stochastic gradient descent can be applied in order
    to learn the weights of linear neurons as well as logistic neurons. Hence, it
    can also be applied to learn the weights for logistic and linear regression. The
    general form of the stochastic gradient descent weight update rule is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The logistic neuron](img/00096.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the derivative is computing the gradient of the cost function at the
    particular observation. We saw the simple form for linear regression and the linear
    neuron in the previous section. If we perform differentiation on the cost function
    for logistic regression, we will discover that the update rule for stochastic
    gradient descent for the logistic neuron appears to be exactly the same as with
    the linear neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The logistic neuron](img/00097.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The subtle difference here is that the form of ![The logistic neuron](img/00093.jpeg)
    is completely different as it now includes the weights inside the logistic function,
    whereas this was not the case in linear regression. Logistic neurons are very
    important because they are the most common type of neuron used when building networks
    of many neurons connected together. As we'll see in the next section, we generally
    build neural networks in layers. The layer containing the neurons that produce
    our outputs is known as the **output layer**. The **input layer** is comprised
    of our data features that are the inputs to network.
  prefs: []
  type: TYPE_NORMAL
- en: Layers in between the input and output layers are known as **hidden layers**.
    Logistic neurons are the most common hidden layer neuron. Additionally, we use
    logistic neurons as output layer neurons when our task is classification, and
    linear neurons when our task is regression.
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer perceptron networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multilayer neural networks are models that chain many neurons in order to create
    a neural architecture. Individually, neurons are very basic units, but when organized
    together, we can create a model significantly more powerful than the individual
    neurons.
  prefs: []
  type: TYPE_NORMAL
- en: 'As touched upon in the previous section, we build neural networks in layers
    and we distinguish between different kinds of neural networks primarily on the
    basis of the connections that exist between these layers and the types of neurons
    used. The following diagram shows the general structure of a **multilayer perceptron**
    (**MLP**) neural network, shown here for two hidden layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Multilayer perceptron networks](img/00098.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The first characteristic of the MLP network is that the information flows in
    a single direction from input layer to output layer. Thus, it is known as a **feedforward
    neural network**. This is in contrast to other neural network types, in which
    there are cycles that allow information to flow back to earlier neurons in the
    network as a feedback signal. These networks are known as **feedback neural networks**
    or **recurrent neural** networks. Recurrent neural networks are generally very
    difficult to train and often do not scale well with the number of inputs. Nonetheless,
    they do find a number of applications, in particular with problems involving a
    time component such as forecasting and signal processing.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to the MLP architecture shown in the diagram, we note that the first
    group of neurons on the left are known as the input neurons and form the input
    layer. We always have as many input neurons as there are input features. The input
    neurons are said to produce the values of our input features as outputs. For this
    reason, we often don't refer to them as input neurons, but rather as input sources
    or input nodes. At the far right of the diagram, we have the output layer with
    the output neurons. We usually have as many output neurons as outputs that we
    are modeling. Thus, our neural network can naturally learn to predict more than
    one thing at a time. One exception to this rule is that when we are modeling a
    multiclass classification problem, we usually have one binary output neuron for
    every class. In this case, all the output neurons are a dummy encoding of a single
    multiclass factor output.
  prefs: []
  type: TYPE_NORMAL
- en: Between the input and output layers, we have the hidden layers. Neurons are
    organized into layers depending on how many neurons are between them and an input
    neuron. For example, neurons in the first hidden layer are directly connected
    to at least one neuron in the input layer, whereas neurons in the second hidden
    layer are directly connected to one or more neurons in the first hidden layer.
    Our diagram is an example of a 4-4 architecture, which means that there are two
    hidden layers with four neurons each. Even though they are not neurons themselves,
    the diagram explicitly shows the bias units for all the neurons. We saw in our
    equation for the output of a single neuron that we can treat the bias unit as
    a dummy input feature with a value of 1 that has a weight on it that corresponds
    to the bias or threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Not all the neurons in the architecture are assumed to have the same activation
    function. In general, we pick the activation function for the neurons in the hidden
    layers separately from that of the output layer. The activation function for the
    output layer we've already seen is chosen based on what type of output we would
    like, which in turn depends on whether we are performing regression or classification.
  prefs: []
  type: TYPE_NORMAL
- en: The activation function for the hidden layer neurons is generally nonlinear,
    because chaining together linear neurons can be algebraically simplified to a
    single linear neuron with different weights and so this does not add any power
    to the network. The most common activation function is the logistic function,
    but others such as the hyperbolic tangent function are also used.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the neural network can be calculated by successively computing
    the outputs of the neurons of each layer. The output of the units of the first
    hidden layer can be computed using the equations for the output of a neuron that
    we have seen thus far. These outputs become inputs to the neurons of the second
    hidden layer and thus, are effectively the new features with respect to that layer.
  prefs: []
  type: TYPE_NORMAL
- en: One of the strengths of neural networks is this power to learn new features
    through the learning of weights in the hidden layers. This process repeats for
    every layer in the neural network until the final layer, where we obtain the output
    of the neural network as a whole. This process of propagating the signals from
    the input to the output layer is known as **forward propagation**.
  prefs: []
  type: TYPE_NORMAL
- en: Training multilayer perceptron networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multilayer perceptron networks are more complicated to train than a single perceptron.
    The famous algorithm used to train them--which has been around since the 1980s--is
    known as the **backpropagation algorithm**. We'll give a sketch of how this algorithm
    works here, but the reader interested in neural networks is strongly encouraged
    to read up on this algorithm in more depth.
  prefs: []
  type: TYPE_NORMAL
- en: There are two very important insights to understand this algorithm. The first
    is that for every observation, it proceeds in two steps. The forward propagation
    step begins at the input layer and ends at the output layer, and computes the
    predicted output of the network for this observation. This is relatively straightforward
    to do using the equation for the output of each neuron, which is just the application
    of its activation function on the linear weighted sum of its inputs.
  prefs: []
  type: TYPE_NORMAL
- en: The backward propagation step is designed to modify the weights of the network
    when the predicted output does not match the desired output. This step begins
    at the output layer, computing the error on the output nodes and the necessary
    updates to the weights of the output neurons. Then, it moves backwards through
    the network, updating the weights of each hidden layer in reverse until it reaches
    the first hidden layer, which is processed last. Thus, there is a forward pass
    through the network, followed by a backward pass.
  prefs: []
  type: TYPE_NORMAL
- en: The second important insight to understand is that updating the weights of the
    neurons in the hidden layer is substantially trickier than updating the weights
    in the output layer. To see this, consider that when we want to update the weights
    of neurons in the output layer, we know precisely what the desired output for
    that neuron should be for a given input.
  prefs: []
  type: TYPE_NORMAL
- en: This is because the desired outputs of the output neurons are the outputs of
    the network itself, which are available to us in our training data. By contrast,
    at first glance, we don't actually know what the right output of a neuron in a
    hidden layer should be for a particular input. Additionally, this output is distributed
    to all the neurons of the next layer in the network and hence impacts all of their
    outputs as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key insight here is that we propagate the error made in the output neurons
    back to the neurons in the hidden layers. We do this by finding the gradient of
    the cost function to adjust the weights of the neurons in the direction of the
    greatest error reduction and apply the chain rule of differentiation to express
    this gradient in terms of the output of the individual neuron we are interested
    in. This process results in a general formula for updating the weights of any
    neuron in the network, known as the **delta update rule**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training multilayer perceptron networks](img/00099.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Let's understand this equation by assuming that we are currently processing
    the weights for all the neurons in layer l. This equation tells us how to update
    the weight between the *j^(th)* neuron in layer l and the *i^(th)* neuron in the
    layer before it (layer l-1). The (*n*) superscripts all denote the fact that we
    are currently updating the weight as a result of processing the *n^(th)* observation
    in our dataset. We will drop these from now on, and assume they are implied.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, the delta rule tells us that to obtain the new value of the
    neuron weight; we must add a product of three terms to the old value. The first
    of these terms is the learning rate *η*. The second is known as the local gradient,
    *δ[j]*, and is the product of the error, *e[j]*, of neuron *j* and the gradient
    of its activation function, *g()*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training multilayer perceptron networks](img/00100.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we denote the output of neuron *j* before applying its activation function
    by *z[j]*, so that the following relation holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training multilayer perceptron networks](img/00101.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'It turns out that the local gradient is also the gradient of the cost function
    of the network computed with respect to *z[j]*. Finally, the third term in the
    delta update rule is the input to neuron *j* from neuron *i*, which is just the
    output of neuron *i*, *y[i]*. The only term that differs between output layer
    neurons and hidden layer neurons is the local gradient term. We''ll see an illustrative
    example for neural networks that perform classification using logistic neurons
    throughout. When neuron *j* is an output neuron, the local gradient is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training multilayer perceptron networks](img/00102.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The first term in brackets is just the known error of the output neuron, this
    being the difference between the target output, *t[j]*, and the actual output,
    *y[j]*. The other two terms arise from the differentiation of the logistic activation
    function. When neuron *j* is a hidden layer neuron, the gradient of the logistic
    activation function is the same, but the error term is computed as the weighted
    sum of the local gradients of the *k* neurons in the next layer that receive input
    from neuron *j*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training multilayer perceptron networks](img/00103.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The back propagation algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The backward propagation of errors, or simply backpropagation, is another somewhat
    common method for training artificial neural networks and it is used in combination
    with an optimization method (such as gradient descent, which is described later
    in this chapter).
  prefs: []
  type: TYPE_NORMAL
- en: The goal of backpropagation is to *optimize the weights* so that the neural
    network model can learn how to correctly map arbitrary inputs to outputs. In other
    words, when using back propagation, the initial system output is continually compared
    to the desired output, and the system is adjusted until the difference between
    the two is minimized.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the energy efficiency of buildings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will investigate how neural networks can be used to solve
    a real-world regression problem. Once again, we turn to the UCI Machine Learning
    Repository for our dataset. We've chosen to try out the *energy efficiency dataset*
    available at [http://archive.ics.uci.edu/ml/datasets/Energy+efficiency](http://archive.ics.uci.edu/ml/datasets/Energy+efficiency).
    The prediction task is to use various building characteristics, such as surface
    area and roof area, in order to predict the energy efficiency of a building, which
    is expressed in the form of two different metrics--heating load and cooling load.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a good example for us to try out as we can demonstrate how neural networks
    can be used to predict two different outputs with a single network. The full attribute
    description of the dataset is given in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Column name | Type | Definition |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `relCompactness` | Numerical | Relative compactness |'
  prefs: []
  type: TYPE_TB
- en: '| `surfArea` | Numerical | Surface area |'
  prefs: []
  type: TYPE_TB
- en: '| `wallArea` | Numerical | Wall area |'
  prefs: []
  type: TYPE_TB
- en: '| `roofArea` | Numerical | Roof area |'
  prefs: []
  type: TYPE_TB
- en: '| `height` | Numerical | Overall height |'
  prefs: []
  type: TYPE_TB
- en: '| `orientation` | Numerical | Building orientation (factor) |'
  prefs: []
  type: TYPE_TB
- en: '| `glazArea` | Numerical | Glazing area |'
  prefs: []
  type: TYPE_TB
- en: '| `glazAreaDist` | Numerical | Glazing area distribution (factor) |'
  prefs: []
  type: TYPE_TB
- en: '| `heatLoad` | Numerical | Heating load (first output) |'
  prefs: []
  type: TYPE_TB
- en: '| `coolLoad` | Numerical | Cooling load (second output) |'
  prefs: []
  type: TYPE_TB
- en: The data was generated using a simulator called *Ecotect*. Each observation
    in the dataset corresponds to a simulated building. All the buildings have the
    same volume, but other attributes that impact their energy efficiency, such as
    their glazing area, are modified.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This dataset is described in the paper *Accurate quantitative estimation of
    energy performance of residential buildings using statistical machine learning
    tools*, *Athanasios Tsanas* and *Angeliki Xifara*, published in *Energy and Buildings*,
    Vol. 49, in 2012.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data on the website comes in Microsoft Excel format. To load this into
    R, we can use the R package `xlsx`, which can read and understand Microsoft Excel
    files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The import adds a number of empty observations at the end of the data frame,
    so the last line removes these. Now, by referring to the paper in which the dataset
    was presented, we discover that two of our attributes are actually factors. In
    order for our neural network to work with these, we will need to convert them
    into dummy variables. To do this, we will use the `dummyVars()` function from
    the `caret` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `dummyVars()` function takes in a formula and a data frame. From these,
    it identifies the input features and performs dummy encoding on those that are
    factors in order to produce new binary columns. There are as many columns created
    for a factor as there are levels in that factor. Just as with the `preProcess()`
    function that we''ve been using, we actually obtain the columns themselves after
    using the `predict()` function. Next, we''ll do an 80-20 split between the training
    and test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: One of the most important preprocessing steps to perform when training neural
    networks is to scale input features and outputs. One good reason to perform input
    scaling is in order to avoid **saturation,** which occurs when the optimization
    procedure reaches a point where the gradient of the error function is very small
    in absolute value. This is usually the result of very large or very small inputs
    to the nonlinear neuron activation functions. Saturation causes the optimization
    procedure to terminate, thinking we have converged.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the particular neural network implementation, for regression tasks
    it may also make sense to scale the outputs as some implementations of linear
    neurons are designed to produce an output in the interval [-1,1]. Scaling can
    also help convergence. Consequently, we will use `caret` to scale all our data
    dimensions to the unit interval, noting that this has no effect on the binary
    columns produced earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Several different packages implement neural networks in R, each with their
    various merits and strengths. For this reason, it helps to be familiar with more
    than one package and in this chapter we will investigate three of these, the first
    being `neuralnet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `neuralnet()` function trains a neural network based on the information
    provided in its arguments. The first argument we provide is a formula and the
    format is similar to the formulae that we've seen with the `lm()` and `glm()`
    functions in previous chapters. One interesting difference here is that we have
    specified two outputs, `heatLoad` and `coolLoad`. Another difference is that currently
    we are unable to use the dot (`.`) notation to imply that all the remaining columns
    in our data frame can be used as features, so we need to specify them explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Note that with the formula, we have effectively defined the input and output
    layers of the neural network and so what remains to be specified is the structure
    of the hidden layers. This is specified with the `hidden` parameter, which either
    takes in a scalar for a single layer, or a vector of scalars that specify the
    number of hidden units in each layer, starting from the layer just after the input
    layer, and ending with the layer just before the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example we saw earlier, we''ve used a single layer with 10 nodes. We
    can actually visualize our neural network as the package provides us with the
    ability to plot the model directly (the numbered circles are dummy bias neurons):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predicting the energy efficiency of buildings](img/00104.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The call to `neuralnet()` also allows us to specify what type of activation
    function we would like to use for our neurons through the parameter string `act.fct`.
    By default, this is set to the logistic activation function and so we have not
    changed this. Another very important parameter is `linear.output`, which can be
    either `TRUE` or `FALSE`. This specifies whether we should apply the activation
    function to the neurons in the output layer. The default value of `TRUE` that
    we used means that we do not apply the activation function and so we can observe
    a linear output. For regression type problems, this is what is appropriate. This
    is because; if we were to apply a logistic activation function our output would
    be bounded in the interval [0,1]. Finally, we can specify a differentiable error
    function through the `err.fct` parameter to use as part of our optimization strategy.
    As we are doing regression, we use the default value of `sse`, which corresponds
    to the sum of squared error.
  prefs: []
  type: TYPE_NORMAL
- en: 'As there is a random component in neural network training, namely the initialization
    of the weights, we may want to specify that we should retrain the same model a
    number of times in order for us to pick the best possible model that we get (using
    criteria such as the SSE to rank these). This can be done by specifying an integer
    value for the `rep` parameter. Let''s rewrite our original call to explicitly
    show the default values we are using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The model's output provides us with some information about the performance of
    the neural network and what is shown depends on its configuration. As we have
    specified the SSE as our error metric, the error shown is the SSE that was obtained.
    The threshold figure is just the value of the partial derivative of the error
    function when the model stopped training. Essentially, instead of terminating
    when the gradient is 0 exactly, we specify a very small value below which the
    error gradient needs to fall before the algorithm terminates. The default value
    for this is 0.01 and it can be changed by supplying a number for the threshold
    parameter in the `neuralnet()` function. Reducing this value will generally result
    in longer training times. The model output also shows us the number of training
    steps that were performed. Finally, if we had used the `rep` parameter to repeat
    this process multiple times, we would see a row for each model trained. Our output
    shows us that we trained only one model.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the neural network contains a random component in the form of the initialization
    of weight vectors, reproducing our code will likely not give the exact same results.
    If, when running the examples, R outputs a message that the model has not converged,
    try running the code again.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating multilayer perceptrons for regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The package `neuralnet` provides us with a neat way to use our model to perform
    predictions through the `compute()` function. Essentially, it provides us with
    not only the predicted output for a data frame of observations, but also shows
    us the output values of all the neurons in the model''s architecture. To evaluate
    the performance of the model, we are interested in the outputs of the neural network
    on our test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can access the predicted outputs of the neural network using the `net.result`
    attribute of the `test_predictions` object as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As this is a regression problem, we would like to be able to use the MSE in
    order to evaluate the performance of our model on both target outputs. In order
    to do that, we need to transform our predicted outputs back onto their original
    scale for a fair assessment to be made. The scaling constants we used on our data
    are stored in the `ranges` attribute of the `eneff_train_out_pp` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The first row contains the minimum values of the original data, and the second
    row contains the maximum values. We''ll now write a function that will take in
    a scaled vector and another vector that contains the original minimum and maximum
    values, and will return the original unscaled vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll use this to obtain the unscaled predicted outputs for our test
    set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also define a simple function to compute the MSE and use it to check
    the performance on our two tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'These values are very low, indicating that we have very good prediction accuracy.
    We can also investigate correlation, which is scale independent, and we could
    have used it on the unscaled outputs as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: These values are extremely high, indicating that we have near-perfect performance,
    something very rare to see with real-world data. If the accuracy were not this
    high, we would experiment by making the architecture more complicated. We could,
    for example, build a model with an additional layer by setting `hidden=c(10,5)`
    so that we would have an additional layer of five neurons before the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting glass type revisited
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](part0026_split_000.html#OPEK2-c6198d576bbb4f42b630392bd61137d7
    "Chapter 3. Linear Regression"), *Linear Regression*, we analyzed the glass identification
    dataset, whose task is to identify the type of glass comprising a glass fragment
    found at a crime scene. The output of this dataset is a factor with several class
    levels corresponding to different types of glass. Our previous approach was to
    build a one-versus-all model using multinomial logistic regression. The results
    were not very promising, and one of the main points of concern was a poor model
    fit on the training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will revisit this dataset and see whether a neural network
    model can do better. At the same time, we will demonstrate how neural networks
    can handle classification problems as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Our output is a multiclass factor and so we will want to dummy-encode this into
    binary columns. With the `neuralnet` package, we would normally need to do this
    manually as a preprocessing step before we can build our model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will look at a second package that contains functions for
    building neural networks, `nnet`. This is actually the same package that we used
    for multinomial logistic regression. One of the benefits of this package is that
    for multiclass classification, the `nnet()` function that trains the neural network
    will automatically detect outputs that are factors and perform the dummy encoding
    for us. With that in mind, we will prepare a training and test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, just as with our previous dataset, we will normalize our input data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to train our model. Whereas the `neuralnet` package is able
    to model multiple hidden layers, the `nnet` package is designed to model neural
    networks with a single hidden layer. As a result, we still specify a formula as
    before, but this time, instead of a `hidden` parameter that can be either a scalar
    or a vector of integers, we specify a `size` parameter that is an integer representing
    the number of nodes in the single hidden layer of our model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, the default neural network model in the `nnet` package is for classification,
    as the output layer uses a logistic activation function. It is really important
    when working with different packages for training the same type of model, such
    as multilayer perceptrons, to check the default values for the various model parameters,
    as these will be different from package to package. One other difference between
    the two packages that we will mention here is that `nnet` currently does not offer
    any plotting capabilities. Without further ado, we will now train our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'From the output, we can see that the model has not converged, stopping after
    the default value of 100 iterations. To converge, we can either rerun this code
    a number of times or we can increase the number of allowed iterations to 1,000
    using the `maxit` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s first investigate the accuracy of our model on the training data in
    order to assess the quality of fit. To compute predictions, we use the `predict()`
    function and specify the type parameter to be `class`. This lets the `predict()`
    function know that we want the class with highest probability to be selected.
    If we want to see the probabilities of each class, we can specify the value `response`
    for the `type` parameter. Finally, remember that we must pass in a data frame
    without the outputs to the `predict()` function, and thus the need to subset the
    training data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Our first attempt shows us that we are getting the same quality of fit as with
    our multinomial logistic regression model. To improve upon this, we''ll increase
    the complexity of the model by adding more neurons in our hidden layer. We will
    also increase our `maxit` parameter to `10,000` as the model is more complex and
    might need more iterations to converge:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, we have now achieved 100 percent training accuracy. Now that
    we have a decent model fit, we can investigate our performance on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Even though our model fits the training data perfectly, we see that the accuracy
    on the test set is only 60 percent. Even factoring in that the dataset is very
    small, this discrepancy is a classic signal that our model is overfitting on the
    training data. When we looked at linear and logistic regression, we saw that there
    are shrinkage methods, such as the lasso, which are designed to combat overfitting
    by restricting the size of the coefficients in the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'An analogous technique known as **weight decay** exists for neural networks.
    With this approach, the product of a decay constant and the sum of the squares
    of all the network weights is added to the cost function. This limits any weights
    from taking overly large values and thus performs regularization on the network.
    Whereas there is currently no option for regularization with `neuralnet()`, `nnet()`
    uses the `decay` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: With this model, the fit on our training data is still very high, and substantially
    higher than we achieved with multinomial logistic regression. On the test set,
    the performance is still worse than on the training set, but much better than
    we had before.
  prefs: []
  type: TYPE_NORMAL
- en: We won't spend any more time on the glass identification data. Instead, we will
    reflect on a few lessons learned before moving on. The first of these is that
    achieving good performance with a neural network, and sometimes even just reaching
    convergence, might be tricky. Training the model involves a random initialization
    of network weights and the final result is often quite sensitive to these starting
    conditions. We can convince ourselves of this fact by training the different model
    configurations we have seen so far a number of times and noticing that certain
    configurations on some runs might not converge, and the performance on our training
    and test set does tend to differ from one run to the next.
  prefs: []
  type: TYPE_NORMAL
- en: Another insight is that training a neural network involves tuning a diverse
    range of parameters, from the number and arrangement of hidden neurons to the
    value of the `decay` parameter. Others that we did not experiment with include
    the choice of nonlinear activation function to use with the hidden layer neurons,
    the criteria for convergence, and the particular cost function we use to fit our
    model. For example, instead of using least squares, we could use a criterion known
    as **entropy**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before settling on a final choice of model, therefore, it pays to try out as
    many different combinations of these as possible. A good place to experiment with
    different parameter combinations is the `train()` function of the `caret` package.
    It provides a unified interface for both neural network packages we have seen
    and, in conjunction with `expand.grid()`, allows the simultaneous training and
    evaluation of several different neural network configurations. We''ll provide
    just a vignette here, and the interested reader can use this to continue their
    investigation further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Predicting handwritten digits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our final application for neural networks will be the handwritten digit prediction
    task. In this task, the goal is to build a model that will be presented with an
    image of a numerical digit (0–9) and the model must predict which digit is being
    shown. We will use the *MNIST* database of handwritten digits from [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  prefs: []
  type: TYPE_NORMAL
- en: 'From this page, we have downloaded and unzipped the two training files, `train-images-idx3-ubyte.gz`
    and `train-images-idx3-ubyte.gz`. The former contains the data from the images
    and the latter contains the corresponding digit labels. The advantage of using
    this website is that the data has already been preprocessed by centering each
    digit in the image and scaling the digits to a uniform size. To load the data,
    we''ve used information from the website about the IDX format to write two functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then load our two data files by issuing the following two commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Each image is represented by a 28-pixel by 28-pixel matrix of grayscale values
    in the range 0 to 255, where 0 is white and 255 is black. Thus, our observations
    each have 282 = 784 feature values. Each image is stored as a vector by rasterizing
    the matrix from right to left and top to bottom. There are 60,000 images in the
    training data, and our `mnist_train` object stores these as a matrix of 60,000
    rows by 78 columns so that each row corresponds to a single image. To get an idea
    of what our data looks like, we can visualize the first seven images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predicting handwritten digits](img/00105.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: To analyze this dataset, we will introduce our third and final R package for
    training neural network models, `RSNNS`. This package is actually an R wrapper
    around the **Stuttgart Neural Network Simulator** (**SNNS**), a popular software
    package containing standard implementations of neural networks in C created at
    the University of Stuttgart.
  prefs: []
  type: TYPE_NORMAL
- en: 'The package authors have added a convenient interface for the many functions
    in the original software. One of the benefits of using this package is that it
    provides several of its own functions for data processing, such as splitting the
    data into a training and test set. Another is that it implements many different
    types of neural networks, not just MLPs. We will begin by normalizing our data
    to the unit interval by dividing by `255` and then indicating that our output
    is a factor with each level corresponding to a digit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Although the MNIST website already contains separate files with test data,
    we have chosen to split the training data file as the models already take quite
    a while to run. The reader is encouraged to repeat the analysis that follows with
    the supplied test files as well. To prepare the data for splitting, we will randomly
    shuffle our images in the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Next, we must dummy-encode our output factor as this is not done automatically
    for us. The `decodeClassLabels()` function from the `RSNNS` package is a convenient
    way to do this. Additionally, we will split our shuffled data into an 80–20 training
    and test set split using `splitForTrainingAndTest()`. This will store the features
    and labels for the training and test sets separately, which will be useful for
    us shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can also normalize our data using the `normTrainingAndTestSet()`
    function. To specify unit interval normalization, we must set the `type` parameter
    to `0_1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: For comparison, we will train two MLP networks using the `mlp()` function. By
    default, this is configured for classification and uses the logistic function
    as the activation function for hidden layer neurons. The first model will have
    a single hidden layer with 100 neurons; the second model will use 300.
  prefs: []
  type: TYPE_NORMAL
- en: The first argument to the `mlp()` function is the matrix of input features and
    the second is the vector of labels. The `size` parameter plays the same role as
    the `hidden` parameter in the `neuralnet` package. That is to say, we can specify
    a single integer for a single hidden layer, or a vector of integers specifying
    the number of hidden neurons per layer when we want more than one hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can use the `inputsTest` and `targetsTest` parameters to specify the
    features and labels of our test set beforehand, so that we can be ready to observe
    the performance on our test set in one call. The models we will train will take
    several hours to run. If we want to know how long each model took to run, we can
    save the current time using `proc.time()` before training a model and comparing
    it against the time when the model completes. Putting all this together, here
    is how we trained our two MLP models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the models take quite a long time to run (the values are in
    seconds). For reference, these were trained on a 2.5 GHz Intel Core i7 Apple MacBook
    Pro with 16 GB of memory. The model predictions on our test set are saved in the
    `fittedTestValues` attribute (and for our training set, they are stored in the
    `fitted.values` attribute). We will focus on test set accuracy. First, we must
    decode the dummy-encoded network outputs by selecting the binary column with the
    maximum value. We must also do this for the target outputs. Note that the first
    column corresponds to the digit `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can check the accuracy of our two models, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The accuracy is very high for both models, with the second model slightly outperforming
    the first. We can use the `confusionMatrix()` function to see the errors made
    in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As expected, we see quite a bit of symmetry in this matrix because certain pairs
    of digits are often harder to distinguish than others. For example, the most common
    pair of digits that the model confuses is the pair (3,5). The test data available
    on the website contains some examples of digits that are harder to distinguish
    from others.
  prefs: []
  type: TYPE_NORMAL
- en: By default, the `mlp()` function allows for a maximum of 100 iterations, via
    its `maxint` parameter. Often, we don't know the number of iterations we should
    run for a particular model; a good way to determine this is to plot the training
    and testing error rates versus iteration number. With the RSNNS package, we can
    do this with the `plotIterativeError()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following graphs show that for our two models, both errors plateau after
    30 iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predicting handwritten digits](img/00106.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Receiver operating characteristic curves
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [Chapter 3](part0026_split_000.html#OPEK2-c6198d576bbb4f42b630392bd61137d7
    "Chapter 3. Linear Regression"), *Logistic Regression*, we studied the precision-recall
    graph as an example of an important graph showing the trade-off between two important
    performance metrics of a binary classifier--precision and recall. In this chapter,
    we will present another related and commonly used graph to show binary classification
    performance, the **receiver operating characteristic** (**ROC**) curve.
  prefs: []
  type: TYPE_NORMAL
- en: This curve is a plot of the true positive rate on the *y* axis and the false
    positive rate on the *x* axis. The true positive rate, as we know, is just the
    recall or, equivalently, the sensitivity of a binary classifier. The false positive
    rate is just 1 minus the specificity. A random binary classifier will have a true
    positive rate equal to the false positive rate and thus, on the ROC curve, the
    line *y = x* is the line showing the performance of a random classifier. Any curve
    lying above this line will perform better than a random classifier.
  prefs: []
  type: TYPE_NORMAL
- en: A perfect classifier will exhibit a curve from the origin to the point (0,1),
    which corresponds to a 100 percent true positive rate and a 0 percent false positive
    rate. We often talk about the **ROC Area Under the Curve** (**ROC AUC**) as a
    performance metric. The area under the random classifier is just 0.5 as we are
    computing the area under the line *y = x* on a unit square. By convention, the
    area under a perfect classifier is 1 as the curve passes through the point (0,1).
    In practice, we obtain values between these two. For our MNIST digit classifier,
    we have a multiclass problem, but we can use the `plotROC()` function of the RSNNS
    package to study the performance of our classifier on individual digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot shows the ROC curve for digit 1, which is almost perfect:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Receiver operating characteristic curves](img/00107.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Radial basis function networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A radial basis function network-based upon the concept of function approximation
    - is a kind of artificial neural network that uses *radial basis functions* to
    define a node's output (given a set of inputs). The output of the network consists
    of a *linear combination* of radial basis functions of the inputs and neuron parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Radial basis function** (**RBF**) networks (also referred to as RBFNN for
    Radial Basis Function Neural Networks) will have three separate layers: an **input**
    layer, a **hidden** layer, and a linear **output** layer. The input layer will
    be a set of several nodes that transfer transition the input values to the second
    (or hidden) layer where activation patterns are applied. These patterns will be
    selected radial basis functions that best fit the application or objective. This
    transformation occurs in a non-linear fashion. The third layer (or output layer)
    provides the response of the network to the activation or RFB functions applied
    to the inputs. In an RFB network, the transformation from the hidden layer to
    the output layer is nonlinear.'
  prefs: []
  type: TYPE_NORMAL
- en: A radial basis function network is a neural network usually approached by viewing
    the design as a curve-fitting (guesstimate) problem in a high dimensional space.
    Learning is equivalent to finding a multidimensional function that provides a
    best fit to the training data, with the criterion for best fit being measured
    in some statistical sense.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, RBF networks seem to have the advantages of a more easily understood
    design, generalization ability, and a record of good tolerance to "noise" within
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: The properties of RBF networks make it a very good choice for designing control
    systems that are required to be very flexible in that they must continually evaluate
    the various *paths to completion* and determine the most efficient. The study
    most famous in using RBF networks is in solving the traveling salesman problem
    (finding the shortest closed path between a group of cities).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw neural networks as a nonlinear method capable of solving
    both regression and classification problems. Motivated by the biological analogy
    to human neurons, we first introduced the simplest neural network, the perceptron.
    This is able to solve binary classification problems only when the two classes
    are linearly separable, something that we very rarely rely upon in practice.
  prefs: []
  type: TYPE_NORMAL
- en: By changing the function that transforms the linear weighted combination of
    inputs, namely the activation function, we discovered how to create different
    types of individual neurons. A linear activation function creates a neuron that
    performs linear regression, whereas the logistic activation function creates a
    neuron that performs logistic regression. By organizing and connecting neurons
    into layers, we can create multilayer neural networks that are powerful models
    for solving nonlinear problems.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind having hidden layers of neurons is that each hidden layer learns
    a new set of features from its inputs. As the most common type of multilayer neural
    network, we introduced the multilayer perceptron and saw that it can naturally
    learn multiple outputs with the same network. In addition, we experimented on
    real-world datasets for both regression and classification tasks, including a
    multiclass classification problem that we saw is also handled naturally. R has
    a number of packages for implementing neural networks, including `neuralnet`,
    `nnet`, and `RSNNS`, and we experimented with each of these in turn. Each has
    its respective advantages and disadvantages and there isn't a clear winner for
    every circumstance.
  prefs: []
  type: TYPE_NORMAL
- en: An important benefit of working with neural networks is that they can be very
    powerful in solving highly complex nonlinear problems of regression and classification
    alike without making any significant assumptions about the relationships between
    the input features. On the other hand, neural networks can often be quite tricky
    to train. Scaling input features is important. It is also important to be aware
    of the various parameters affecting the convergence of the model, such as the
    learning rate and the error gradient tolerance. Another crucial decision to make
    is the number and distribution of hidden layer neurons. As the complexity of the
    network, the number of input features, or the size of the training data increases,
    the training time often becomes quite long compared to other supervised learning
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: We also saw in our regression example that because of the flexibility and power
    of neural networks, they can be prone to overfitting the data, thus overestimating
    the model's accuracy. Regularization approaches, such as weight decay, exist to
    mitigate this problem to a certain extent. Finally, one clear disadvantage that
    deserves mention is that the neural weights have no direct interpretation, unlike
    regression coefficients, and even though the neural network topology may learn
    features, these are difficult to explain or interpret.
  prefs: []
  type: TYPE_NORMAL
- en: Our next chapter continues our foray into the world of supervised learning and
    presents support vector machines, our third nonlinear modeling tool, which is
    primarily used for dealing with classification problems.
  prefs: []
  type: TYPE_NORMAL
