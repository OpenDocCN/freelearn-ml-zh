<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer277">
<h1 class="chapter-number" id="_idParaDest-161"><a id="_idTextAnchor172"/><a id="_idTextAnchor173"/>8</h1>
<h1 id="_idParaDest-162"><a id="_idTextAnchor174"/>Model Monitoring and Management Solutions</h1>
<p>In <a href="B18638_06.xhtml#_idTextAnchor132"><em class="italic">Chapter 6</em></a>, <em class="italic">SageMaker Training and Debugging Solutions</em>, and <a href="B18638_07.xhtml#_idTextAnchor151"><em class="italic">Chapter 7</em></a>,<em class="italic"> SageMaker Deployment Solutions</em>, we focused on training and deploying <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models using <strong class="bold">SageMaker</strong>. If you were able to complete the hands-on solutions presented in those chapters, you should be able to perform similar types of experiments and deployments using other algorithms and datasets. These two chapters are good starting points, especially when getting started with the managed service. At some point, however, you will have to use its other capabilities to manage, troubleshoot, and monitor different types of resources in production ML environments.</p>
<p>One of the clear advantages of using SageMaker is that a lot of the commonly performed tasks of data scientists and ML practitioners have already been automated as part of this fully managed service. This means that we generally do not need to build a custom solution, especially if SageMaker already has that capability or feature. Examples of these capabilities include <strong class="bold">SageMaker Debugger</strong>, <strong class="bold">SageMaker Feature Store</strong>, <strong class="bold">SageMaker Training Compiler</strong>, <strong class="bold">SageMaker Inference Recommender</strong>, <strong class="bold">SageMaker Clarify</strong>, <strong class="bold">SageMaker Processing</strong>, and more! If we need to use one or more of these capabilities, all we need to do is use <strong class="bold">boto3</strong>, along with the <strong class="bold">SageMaker Python SDK</strong>, to run a few lines of code to obtain the desired functionality and results in just a matter of hours (or even minutes!). </p>
<p>In this chapter, we will focus on using the built-in <strong class="bold">model registry</strong> of SageMaker, which we will use to register and manage trained ML models. We will also show a quick demonstration of how to deploy models from the model registry into an ML inference endpoint. In addition to the model registry, we will work with <strong class="bold">SageMaker Model Monitor</strong>, which is another built-in capability that we will use to capture and analyze the data that passes through an ML inference endpoint. </p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Registering models to SageMaker Model Registry</li>
<li>Deploying models from SageMaker Model Registry</li>
<li>Enabling data capture and simulating predictions</li>
<li>Scheduled monitoring with SageMaker Model Monitor</li>
<li>Analyzing the captured data</li>
<li>Deleting an endpoint with a monitoring schedule</li>
<li>Cleaning up</li>
</ul>
<p>Once you have completed the hands-on solutions in this chapter, you will have an easier time understanding, using, and configuring the other built-in features of SageMaker. With this in mind, let’s begin!</p>
<h1 id="_idParaDest-163"><a id="_idTextAnchor175"/>Technical prerequisites</h1>
<p>Before we start, we must have the following ready:</p>
<ul>
<li>A web browser (preferably Chrome or Firefox)</li>
<li>Access to the AWS account and <strong class="bold">SageMaker Studio</strong> domain that was used in the first chapter of this book</li>
</ul>
<p>The Jupyter notebooks, source code, and other files used for each chapter are available in this book’s GitHub repository: <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS</a>.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">It is recommended to use an IAM user with limited permissions instead of the root account when running the examples in this book. We will discuss this, along with other security best practices, in detail in <a href="B18638_09.xhtml#_idTextAnchor187"><em class="italic">Chapter 9</em></a>, <em class="italic">Security, Governance, and Compliance Strategies</em>. If you are just starting to use AWS, you may proceed with using the root account in the meantime.</p>
<h1 id="_idParaDest-164"><a id="_idTextAnchor176"/>Registering models to SageMaker Model Registry</h1>
<p>In <a href="B18638_06.xhtml#_idTextAnchor132"><em class="italic">Chapter 6</em></a>, <em class="italic">SageMaker Training and Debugging Solutions</em>, we<a id="_idIndexMarker905"/> used<a id="_idIndexMarker906"/> the <strong class="source-inline">deploy()</strong> method of the <strong class="source-inline">Estimator</strong> instance to immediately deploy our ML model to an inference endpoint right after using the <strong class="source-inline">fit()</strong> method to train the model. When performing ML experiments and deployments in production, a model may have to be analyzed and evaluated first before proceeding with the deployment step. The individual or team performing the analysis would review the input configuration parameters, the training data, and the algorithm used to train the model, along with other relevant information available. Once the data science team has to work with multiple models, managing and organizing all of these would be much easier <a id="_idIndexMarker907"/>using a <strong class="bold">model registry</strong>. </p>
<p>What’s a model registry? A model registry is simply a repository that focuses on helping data scientists and ML practitioners manage, organize, and catalog ML models. After the training step, the data science team may store the trained ML model in the model registry and tag its status as <em class="italic">For Review</em> or <em class="italic">Pending Approval</em>. This will allow the reviewing team to easily locate the models for review, along with the history and information <a id="_idIndexMarker908"/>linked<a id="_idIndexMarker909"/> to these models:</p>
<div>
<div class="IMG---Figure" id="_idContainer259">
<img alt="Figure 8.1 – Working with a model registry " height="588" src="image/B18638_08_001.jpg" width="958"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Working with a model registry</p>
<p>Once the reviewing team has finished the review process and has approved a model for deployment, the status of the model can now be changed to <em class="italic">Approved</em>, similar to what is shown in the preceding diagram. Once the status of the ML model has been changed to <em class="italic">Approved</em>, it can be deployed manually or even automatically using an <strong class="bold">MLOps pipeline</strong>. In <a id="_idIndexMarker910"/>addition to these, other automated actions such as automated reports and notifications can be triggered. </p>
<p class="callout-heading">Note</p>
<p class="callout">For more information on MLOps pipelines, feel free to check out <a href="B18638_10.xhtml#_idTextAnchor215"><em class="italic">Chapter 10</em></a>, <em class="italic">Machine Learning Pipelines with Kubeflow on Amazon EKS</em>, and <a href="B18638_11.xhtml#_idTextAnchor231"><em class="italic">Chapter 11</em></a>, <em class="italic">Machine Learning Pipelines with SageMaker Pipelines</em>.</p>
<p>Now that you have a better idea of how data science teams can make their lives easier using a model registry, you may already be planning on coding a model registry from scratch! Hold it right there – SageMaker already provides one for us! In the succeeding pages of <a id="_idIndexMarker911"/>this<a id="_idIndexMarker912"/> chapter, we will use<a id="_idIndexMarker913"/> the <strong class="bold">boto3</strong> library<a id="_idIndexMarker914"/><a id="_idIndexMarker915"/> and the <strong class="bold">SageMaker Python SDK</strong> to utilize the model registry available in SageMaker.</p>
<h2 id="_idParaDest-165"><a id="_idTextAnchor177"/>Creating a new notebook in SageMaker Studio</h2>
<p>We will start the<a id="_idIndexMarker916"/> hands-on portion of this section <a id="_idIndexMarker917"/>by opening SageMaker Studio and creating a new Jupyter Notebook inside a new directory.</p>
<p class="callout-heading">Note</p>
<p class="callout">Make sure that you have completed the hands-on solutions in the <em class="italic">Getting Started with SageMaker and SageMaker Studio</em> section of <em class="italic">Chapter 1</em>, <em class="italic">Introduction to ML Engineering on AWS</em> before proceeding. Note that the hands-on section in this chapter is <em class="italic">NOT</em> a continuation of what we completed in <a href="B18638_06.xhtml#_idTextAnchor132"><em class="italic">Chapter 6</em></a>, <em class="italic">SageMaker Training and Debugging Solutions</em>, and <a href="B18638_07.xhtml#_idTextAnchor151"><em class="italic">Chapter 7</em></a>, <em class="italic">SageMaker Deployment Solutions</em>.</p>
<p>Follow these steps to launch SageMaker Studio and then create a new Notebook that will be used to run the Python scripts in this chapter:</p>
<ol>
<li>Navigate to <strong class="bold">SageMaker Studio</strong> by typing <strong class="source-inline">sagemaker studio</strong> in the search bar of the AWS Management Console and selecting <strong class="bold">SageMaker Studio</strong> from the list of results under <strong class="bold">Features</strong>.</li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">This chapter assumes that we are using the <strong class="bold">Oregon</strong> (<strong class="source-inline">us-west-2</strong>) region when using services to manage and create different types of resources. You may use a different region but make sure to make any adjustments needed in case certain resources need to be transferred to your region of choice.</p>
<ol>
<li value="2">Next, click <strong class="bold">Studio</strong> under <strong class="bold">SageMaker Domain</strong> in the sidebar.</li>
<li>Click <strong class="bold">Launch app</strong>, as highlighted in the following screenshot. Select <strong class="bold">Studio</strong> from the list <a id="_idIndexMarker918"/>of <a id="_idIndexMarker919"/>drop-down options:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer260">
<img alt="Figure 8.2 – Opening SageMaker Studio " height="447" src="image/B18638_08_002.jpg" width="1018"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2 – Opening SageMaker Studio</p>
<p class="list-inset">This will redirect you to SageMaker Studio. Wait a few seconds for the interface to load.</p>
<ol>
<li value="4">Right-click on the empty space in the <strong class="bold">File Browser</strong> sidebar pane to open a context menu similar to the following: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer261">
<img alt="Figure 8.3 – Creating a new folder " height="366" src="image/B18638_08_003.jpg" width="860"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Creating a new folder</p>
<p class="list-inset">Select <strong class="bold">New Folder</strong> to create a new folder inside the current directory. Name the folder <strong class="source-inline">CH08</strong>.</p>
<ol>
<li value="5">Navigate to the <strong class="bold">CH08</strong> directory by double-clicking the corresponding folder name in the sidebar.</li>
<li>Create a<a id="_idIndexMarker920"/> new <a id="_idIndexMarker921"/>Notebook by clicking the <strong class="bold">File</strong> menu and choosing <strong class="bold">Notebook</strong> from the list of options under the <strong class="bold">New</strong> submenu:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer262">
<img alt="Figure 8.4 – Creating a new Notebook " height="283" src="image/B18638_08_004.jpg" width="830"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4 – Creating a new Notebook</p>
<p class="list-inset">In the preceding screenshot, we can see other options as well, including creating a new <strong class="bold">Console</strong>, <strong class="bold">Data Wrangler Flow</strong>, <strong class="bold">Terminal</strong>, <strong class="bold">Text File</strong>, and more. Note that in this chapter, we will only work with <strong class="source-inline">.ipynb</strong> Notebook files, which will be used to run the different blocks of code.</p>
<ol>
<li value="7">In the <strong class="bold">Set up notebook environment</strong> window, specify the following configuration values:<ul><li><strong class="bold">Image</strong>: <strong class="source-inline">Data Science</strong> (option found under <strong class="bold">SageMaker image</strong>)</li>
<li><strong class="bold">Kernel</strong>: <strong class="source-inline">Python 3</strong></li>
<li><strong class="bold">Start-up script</strong>: <strong class="source-inline">No script</strong> </li>
</ul></li>
<li>Click the <strong class="bold">Select</strong> button afterward. </li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Wait for the kernel to start. This step may take around 3 to 5 minutes while an ML instance is being provisioned to run the Jupyter notebook cells.</p>
<ol>
<li value="9">Right-click<a id="_idIndexMarker922"/> on the tab’s name, as <a id="_idIndexMarker923"/>highlighted in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer263">
<img alt="Figure 8.5 – Renaming a notebook " height="278" src="image/B18638_08_005.jpg" width="1079"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Renaming a notebook</p>
<p class="list-inset">Select <strong class="bold">Rename Notebook…</strong> from the list of options in the context menu.</p>
<ol>
<li value="10">In the <strong class="bold">Rename File</strong> popup, specify <strong class="source-inline">01 - Registering Models to the SageMaker Model Registry.ipynb</strong> under <strong class="bold">New Name</strong>. Click the <strong class="bold">Rename</strong> button afterward.</li>
</ol>
<p>Now that our<a id="_idIndexMarker924"/> notebook <a id="_idIndexMarker925"/>is ready, we can proceed with registering pre-trained models to SageMaker Model Registry!</p>
<h2 id="_idParaDest-166"><a id="_idTextAnchor178"/>Registering models to SageMaker Model Registry using the boto3 library</h2>
<p>In this <a id="_idIndexMarker926"/>section, we <a id="_idIndexMarker927"/>will be <a id="_idIndexMarker928"/>working with two pre-trained models stored inside <strong class="source-inline">.tar.gz</strong> files. We will store and register these models in <strong class="bold">SageMaker Model Registry</strong>. To give more context, the model artifacts stored in the <strong class="source-inline">.tar.gz</strong> files were generated by performing two separate ML training jobs<a id="_idIndexMarker929"/> using the <strong class="bold">K-Nearest Neighbor</strong> and <strong class="bold">Linear Learner</strong> built-in algorithms <a id="_idIndexMarker930"/>of SageMaker. These models accept <em class="italic">x</em> and <em class="italic">y</em> values as input and return a predicted <em class="italic">label</em> value as output. What do these <em class="italic">x</em> and <em class="italic">y</em> values represent? Let’s take a look:</p>
<div>
<div class="IMG---Figure" id="_idContainer264">
<img alt="Figure 8.6 – Predicting the preferred vaccination site " height="639" src="image/B18638_08_006.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.6 – Predicting the preferred vaccination site</p>
<p>As shown in the preceding screenshot, these <em class="italic">x</em> and <em class="italic">y</em> values correspond to transformed and scaled coordinate values where certain members of the population reside using a specified point in the map as a reference. During the first vaccination run, several of these members selected their preferred vaccination site. These vaccination sites are tagged with the appropriate <em class="italic">label</em> value – <em class="italic">0</em>, <em class="italic">1</em>, and <em class="italic">2</em>. Using previous vaccination site data as our training data, we were able to generate two models that can automatically predict the preferred vaccination site for unvaccinated members, given a set of coordinate values – that is, <em class="italic">x</em> and <em class="italic">y</em>.</p>
<p>Follow these steps to download the artifacts of the two pre-trained models mentioned and register these in SageMaker Model Registry in the <strong class="source-inline">01 - Registering Models to the SageMaker Model Registry.ipynb</strong> Notebook we prepared in the previous section:</p>
<ol>
<li value="1">We <a id="_idIndexMarker931"/>will<a id="_idIndexMarker932"/> start<a id="_idIndexMarker933"/> by downloading the pre-trained model artifacts to the <strong class="source-inline">tmp</strong> directory using the <strong class="source-inline">wget</strong> command:<pre class="source-code">%%bash</pre><pre class="source-code">mkdir -p <strong class="bold">tmp</strong></pre><pre class="source-code"><strong class="bold">wget</strong> -O tmp/<strong class="bold">knn.model.tar.gz</strong> https://bit.ly/3yZ6qHE</pre><pre class="source-code"><strong class="bold">wget</strong> -O tmp/<strong class="bold">ll.model.tar.gz</strong> https://bit.ly/3ahj1fd</pre></li>
</ol>
<p class="list-inset">Here, we downloaded two <strong class="source-inline">.tar.gz</strong> files: </p>
<ul>
<li><strong class="source-inline">knn.model.tar.gz</strong>: This contains the model artifacts for the pre-trained <strong class="bold">K-Nearest Neighbor</strong> model</li>
<li><strong class="source-inline">ll.model.tar.gz</strong>: This contains the model artifacts for the pre-trained <strong class="bold">Linear Learner</strong> model</li>
</ul>
<ol>
<li value="2">Specify a unique S3 bucket name and prefix. Make sure that you replace the value of <strong class="source-inline">&lt;INSERT S3 BUCKET HERE&gt;</strong> with a unique S3 bucket name before running the following block of code:<pre class="source-code">s3_bucket = "<strong class="bold">&lt;INSERT S3 BUCKET HERE&gt;</strong>"</pre><pre class="source-code">prefix = "chapter08"</pre></li>
</ol>
<p class="list-inset">Make sure that you specify a bucket name for an S3 bucket that does <em class="italic">NOT</em> exist yet. If you want to reuse one of the buckets you created in the previous chapters, you may do so, but make sure to use an S3 bucket in the same region where <strong class="bold">SageMaker Studio</strong> is set up and configured.</p>
<ol>
<li value="3">Let’s create the S3 bucket where we will upload the <strong class="source-inline">ll.model.tar.gz</strong> and <strong class="source-inline">knn.model.tar.gz</strong> files we downloaded earlier:<pre class="source-code">!<strong class="bold">aws s3 mb</strong> s3://{s3_bucket}</pre></li>
</ol>
<p class="list-inset">You can skip this step if you are planning to reuse one of the existing S3<a id="_idIndexMarker934"/> buckets you<a id="_idIndexMarker935"/> created<a id="_idIndexMarker936"/> in<a id="_idIndexMarker937"/> the previous chapters.</p>
<ol>
<li value="4">Now that our S3 bucket is ready, let’s prepare the S3 paths so that they point to where we will upload the pre-trained model artifacts:<pre class="source-code"><strong class="bold">ll_model_data</strong> = \</pre><pre class="source-code">f's3://{s3_bucket}/{prefix}/models/<strong class="bold">ll.model.tar.gz</strong>'</pre><pre class="source-code"><strong class="bold">knn_model_data</strong> = \</pre><pre class="source-code">f's3://{s3_bucket}/{prefix}/models/<strong class="bold">knn.model.tar.gz</strong>'</pre></li>
</ol>
<p class="list-inset">Note that at this point, the <strong class="source-inline">ll.model.tar.gz</strong> and <strong class="source-inline">knn.model.tar.gz</strong> files do not exist yet in the specified S3 paths stored in the <strong class="source-inline">ll_model_data</strong> and <strong class="source-inline">knn_model_data</strong> variables. Here, we are simply preparing the S3 location paths (string) where the <strong class="source-inline">.tar.gz</strong> files will be uploaded.</p>
<ol>
<li value="5">Now, let’s <a id="_idIndexMarker938"/>use the <strong class="source-inline">aws s3 cp</strong> command to copy and upload the <strong class="source-inline">.tar.gz</strong> files to their corresponding S3 locations:<pre class="source-code">!<strong class="bold">aws s3 cp</strong> tmp/<strong class="bold">ll.model.tar.gz</strong> {ll_model_data}</pre><pre class="source-code">!<strong class="bold">aws s3 cp</strong> tmp/<strong class="bold">knn.model.tar.gz</strong> {knn_model_data}</pre></li>
</ol>
<p class="list-inset">This will upload the <strong class="source-inline">ll.model.tar.gz</strong> and <strong class="source-inline">knn.model.tar.gz</strong> files from the <strong class="source-inline">tmp</strong> directory to the S3 bucket.</p>
<ol>
<li value="6">With the pre-trained model artifacts already in S3, let’s proceed with getting the ECR container image URI of the ML algorithms used to train these models. We’ll use the <strong class="source-inline">retrieve()</strong> function to get the image URIs for the <strong class="bold">Linear Learner</strong> and <strong class="bold">K-Nearest Neighbor</strong> algorithms: <pre class="source-code">from sagemaker.image_uris import retrieve</pre><pre class="source-code">ll_image_uri = <strong class="bold">retrieve</strong>(</pre><pre class="source-code">    "<strong class="bold">linear-learner</strong>", </pre><pre class="source-code">    region="us-west-2", </pre><pre class="source-code">    version="1"</pre><pre class="source-code">)</pre><pre class="source-code">knn_image_uri = <strong class="bold">retrieve</strong>(</pre><pre class="source-code">    "<strong class="bold">knn</strong>", </pre><pre class="source-code">    region="us-west-2", </pre><pre class="source-code">    version="1"</pre><pre class="source-code">)</pre></li>
<li>Initialize<a id="_idIndexMarker939"/> the <strong class="source-inline">boto3</strong> client<a id="_idIndexMarker940"/> for<a id="_idIndexMarker941"/> SageMaker. We will use this client to call several SageMaker APIs, which will help us create model packages and model package groups in the succeeding set of steps:<pre class="source-code">import boto3</pre><pre class="source-code">client = boto3.client(service_name="<strong class="bold">sagemaker</strong>")</pre></li>
<li>Next, define the <strong class="source-inline">generate_random_string()</strong> function:<pre class="source-code">import string </pre><pre class="source-code">import random</pre><pre class="source-code">def <strong class="bold">generate_random_string()</strong>:</pre><pre class="source-code">    return ''.join(</pre><pre class="source-code">        random.sample(</pre><pre class="source-code">        string.ascii_uppercase,12)</pre><pre class="source-code">    )</pre></li>
</ol>
<p class="list-inset"><em class="italic">What’s this for?</em> We will use the <strong class="source-inline">generate_random_string()</strong> function when creating new resources (in the succeeding set of steps). This will help us generate a random identifier or label for each of the resources we will create.</p>
<ol>
<li value="9">With the <strong class="source-inline">generate_random_string()</strong> function ready, let’s generate a random <strong class="source-inline">group_id</strong> value. This will be used to generate a <em class="italic">package group name</em> (<strong class="source-inline">package_group_name</strong>) and a <em class="italic">package group description</em> (<strong class="source-inline">package_group_desc</strong>). Then, we <a id="_idIndexMarker942"/>will <a id="_idIndexMarker943"/>create <a id="_idIndexMarker944"/>the <em class="italic">model package group</em> using the <strong class="source-inline">create_model_package_group()</strong> method of the boto3 client:<pre class="source-code">group_id = <strong class="bold">generate_random_string()</strong></pre><pre class="source-code"><strong class="bold">package_group_name</strong> = f"group-{<strong class="bold">group_id</strong>}"</pre><pre class="source-code"><strong class="bold">package_group_desc</strong> = f"Model package group {<strong class="bold">group_id</strong>}"</pre><pre class="source-code">response = client.<strong class="bold">create_model_package_group</strong>(</pre><pre class="source-code">    ModelPackageGroupName=<strong class="bold">package_group_name</strong>,</pre><pre class="source-code">    ModelPackageGroupDescription=<strong class="bold">package_group_desc</strong></pre><pre class="source-code">)</pre><pre class="source-code">package_group_arn = response['ModelPackageGroupArn']</pre><pre class="source-code">package_group_arn</pre></li>
<li>Next, let’s define the <strong class="source-inline">prepare_inference_specs()</strong> function, which we will use to configure and set up our model package in the next step:<pre class="source-code">def <strong class="bold">prepare_inference_specs</strong>(image_uri, model_data):</pre><pre class="source-code">    return {</pre><pre class="source-code">        "Containers": [</pre><pre class="source-code">            {</pre><pre class="source-code">                "Image": image_uri,</pre><pre class="source-code">                "ModelDataUrl": model_data</pre><pre class="source-code">            }</pre><pre class="source-code">        ],</pre><pre class="source-code">        "SupportedContentTypes": [ </pre><pre class="source-code">            "text/csv" </pre><pre class="source-code">        ],</pre><pre class="source-code">        "SupportedResponseMIMETypes": [ </pre><pre class="source-code">            "application/json" </pre><pre class="source-code">        ],</pre><pre class="source-code">    }</pre></li>
</ol>
<p class="list-inset">Here, we created a function that prepares and returns the necessary nested configuration <a id="_idIndexMarker945"/>structure<a id="_idIndexMarker946"/> using<a id="_idIndexMarker947"/> the <em class="italic">ECR container image URI</em> and the <em class="italic">model artifact S3 path</em> as input parameters.</p>
<ol>
<li value="11">Next, let’s define a custom function called <strong class="source-inline">create_model_package()</strong>. This function accepts <a id="_idIndexMarker948"/>several input parameter values, such as the following: <ul><li>The <strong class="bold">Amazon Resource Name</strong> (<strong class="bold">ARN</strong>) <em class="italic">of the model package group</em> </li>
<li>The <em class="italic">inference specification configuration</em></li>
<li>(Optional) The <strong class="source-inline">boto3</strong> client for SageMaker:<pre class="source-code">def <strong class="bold">create_model_package</strong>(</pre><pre class="source-code">        package_group_arn, </pre><pre class="source-code">        inference_specs, </pre><pre class="source-code">        client=client):</pre><pre class="source-code">    input_dict = {</pre><pre class="source-code">        "ModelPackageGroupName" : package_group_arn,</pre><pre class="source-code">        "ModelPackageDescription" : "Description",</pre><pre class="source-code">        "ModelApprovalStatus" : "Approved",</pre><pre class="source-code">        "InferenceSpecification" : inference_specs</pre><pre class="source-code">    }</pre><pre class="source-code">    </pre><pre class="source-code">    response = client.<strong class="bold">create_model_package</strong>(</pre><pre class="source-code">        **input_dict</pre><pre class="source-code">    )</pre><pre class="source-code">    return response["ModelPackageArn"]</pre></li>
</ul></li>
</ol>
<p class="list-inset">Here, we <a id="_idIndexMarker949"/>automatically <a id="_idIndexMarker950"/>set<a id="_idIndexMarker951"/> the <strong class="source-inline">ModelApprovalStatus</strong> value to <strong class="source-inline">Approved</strong> upon creating the model package. Note that we have the option to set the value to <strong class="source-inline">PendingManualApproval</strong> first before transitioning it to <strong class="source-inline">Approved</strong>. However, we will simplify things a bit and directly set the value to <strong class="source-inline">Approved</strong>.</p>
<p class="callout-heading">Note</p>
<p class="callout">The approval status of the model can be used to tag and identify which models are ready to be deployed to a production endpoint. Ideally, ML models are evaluated and manually approved first before being deployed. If the model passes the evaluation step, we can set the approval status to <strong class="source-inline">Approved</strong>. Otherwise, we set the status to <strong class="source-inline">Rejected</strong>.</p>
<ol>
<li value="12">Use the <strong class="source-inline">prepare_inference_specs()</strong> function to prepare the prerequisite inference specification configuration for both the <strong class="bold">K-Nearest Neighbor</strong> and <strong class="bold">Linear Learner</strong> model packages:<pre class="source-code">knn_inference_specs = <strong class="bold">prepare_inference_specs</strong>(</pre><pre class="source-code">    image_uri=knn_image_uri,</pre><pre class="source-code">    model_data=knn_model_data</pre><pre class="source-code">)</pre><pre class="source-code">ll_inference_specs = <strong class="bold">prepare_inference_specs</strong>(</pre><pre class="source-code">    image_uri=ll_image_uri,</pre><pre class="source-code">    model_data=ll_model_data</pre><pre class="source-code">)</pre></li>
<li>With<a id="_idIndexMarker952"/> the<a id="_idIndexMarker953"/> inference <a id="_idIndexMarker954"/>specification configurations ready, let’s use <strong class="source-inline">create_model_package()</strong> to create the model packages:<pre class="source-code">knn_package_arn = <strong class="bold">create_model_package</strong>(</pre><pre class="source-code">    package_group_arn=package_group_arn,</pre><pre class="source-code">    inference_specs=knn_inference_specs</pre><pre class="source-code">)</pre><pre class="source-code">ll_package_arn = <strong class="bold">create_model_package</strong>(</pre><pre class="source-code">    package_group_arn=package_group_arn,</pre><pre class="source-code">    inference_specs=ll_inference_specs</pre><pre class="source-code">)</pre></li>
<li>Finally, let’s use the <strong class="source-inline">%store</strong> magic from IPython to store the variable values for <strong class="source-inline">knn_package_arn</strong>, <strong class="source-inline">ll_package_arn</strong>, <strong class="source-inline">s3_bucket</strong>, and <strong class="source-inline">prefix</strong>:<pre class="source-code">%store <strong class="bold">knn_package_arn</strong></pre><pre class="source-code">%store <strong class="bold">ll_package_arn</strong></pre><pre class="source-code">%store <strong class="bold">s3_bucket</strong></pre><pre class="source-code">%store <strong class="bold">prefix</strong></pre></li>
</ol>
<p class="list-inset">We will use these stored variable values in the succeeding sections of this chapter.</p>
<p>At this point, two<a id="_idIndexMarker955"/> model <a id="_idIndexMarker956"/>packages<a id="_idIndexMarker957"/> have been created and are ready for use.</p>
<p class="callout-heading">Note</p>
<p class="callout">You may use <strong class="source-inline">client.list_model_package_groups()</strong> and <strong class="source-inline">client.list_model_packages(ModelPackageGroupName='&lt;INSERT GROUP NAME&gt;')</strong> to check the list of registered model package groups and model packages. We will leave this to you as an exercise!</p>
<h1 id="_idParaDest-167"><a id="_idTextAnchor179"/>Deploying models from SageMaker Model Registry</h1>
<p>There are many <a id="_idIndexMarker958"/>possible next steps available <a id="_idIndexMarker959"/>after an ML model has been registered to a model registry. In this section, we will focus on deploying the first registered ML model (pre-trained <strong class="bold">K-Nearest Neighbor</strong> model) manually<a id="_idIndexMarker960"/> to a new inference endpoint. After the first registered ML model has been deployed, we will proceed with deploying the second registered model (pre-trained <strong class="bold">Linear Learner</strong> model) in the <a id="_idIndexMarker961"/>same endpoint where the first ML model has been deployed, similar to what’s shown in the following diagram:</p>
<div>
<div class="IMG---Figure" id="_idContainer265">
<img alt="Figure 8.7 – Deploying models from the model registry   " height="683" src="image/B18638_08_007.jpg" width="1473"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.7 – Deploying models from the model registry</p>
<p>Here, we can<a id="_idIndexMarker962"/> see <a id="_idIndexMarker963"/>that we can directly replace the deployed ML model inside a running ML inference endpoint without creating a new separate inference endpoint. This means that we do not need to worry about changing the “target infrastructure server” in our setup since the model replacement operation is happening behind the scenes. At the same time, SageMaker has already automated this process for us, so all we need to do is call the right APIs to initiate this process.</p>
<p>Here, we will continue where we left off in the <em class="italic">Registering models to SageMaker Model Registry</em> section and deploy the two registered models to an ML inference endpoint. That said, we will perform the following set of steps:</p>
<ol>
<li value="1">Create a new Notebook by clicking the <strong class="bold">File</strong> menu and choosing <strong class="bold">Notebook</strong> from the list of options under the <strong class="bold">New</strong> submenu.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Note that we will be creating the new notebook inside the <strong class="source-inline">CH08</strong> directory beside the <strong class="source-inline">01 - Registering Models to the SageMaker Model Registry.ipynb</strong> notebook file we worked with in the previous section.</p>
<ol>
<li value="2">In the <strong class="bold">Set up notebook environment</strong> window, specify the following configuration values:<ul><li><strong class="bold">Image</strong>: <strong class="source-inline">Data Science</strong> (option found under <strong class="bold">SageMaker image</strong>)</li>
<li><strong class="bold">Kernel</strong>: <strong class="source-inline">Python 3</strong></li>
<li><strong class="bold">Start-up script</strong>: <strong class="source-inline">No script</strong> </li>
</ul></li>
</ol>
<p class="list-inset">Click the <strong class="bold">Select</strong> button afterward. </p>
<ol>
<li value="3">Right-click on the tab name of the new Notebook and select <strong class="bold">Rename Notebook…</strong> from the list of options in the context menu. In the <strong class="bold">Rename File</strong> popup, specify <strong class="source-inline">02 - Deploying Models from the SageMaker Model Registry.ipynb</strong> under <strong class="bold">New Name</strong>. Click the <strong class="bold">Rename</strong> button.</li>
<li>Now that we <a id="_idIndexMarker964"/>have<a id="_idIndexMarker965"/> the new notebook ready, let’s continue by loading the values of the stored variables for <strong class="source-inline">knn_package_arn</strong> and <strong class="source-inline">ll_package_arn</strong> using the <strong class="source-inline">%store</strong> magic from IPython:<pre class="source-code">%store -r <strong class="bold">knn_package_arn</strong></pre><pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre></li>
<li>Let’s initialize a <strong class="source-inline">ModelPackage</strong> instance using the following block of code: <pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker import ModelPackage</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">model = <strong class="bold">ModelPackage</strong>(</pre><pre class="source-code">    role=role,</pre><pre class="source-code">    model_package_arn=<strong class="bold">knn_package_arn</strong>,</pre><pre class="source-code">    sagemaker_session=session</pre><pre class="source-code">)</pre><pre class="source-code">model.predictor_cls = Predictor</pre></li>
</ol>
<p class="list-inset">Here, we passed the <em class="italic">IAM execution role</em>, <em class="italic">K-Nearest Neighbor model package ARN</em>, and the <strong class="bold">SageMaker Python SDK</strong> <strong class="source-inline">Session</strong> instance when initializing the <strong class="source-inline">ModelPackage</strong> instance.</p>
<ol>
<li value="6">Now that <a id="_idIndexMarker966"/>we <a id="_idIndexMarker967"/>have initialized the <strong class="source-inline">ModelPackage</strong> instance, we will call its <strong class="source-inline">deploy()</strong> method to deploy the pre-trained model to a real-time inference endpoint:<pre class="source-code">from sagemaker.serializers import JSONSerializer</pre><pre class="source-code">from sagemaker.deserializers import JSONDeserializer</pre><pre class="source-code">predictor = model.<strong class="bold">deploy</strong>(</pre><pre class="source-code">    instance_type='ml.m5.xlarge', </pre><pre class="source-code">    initial_instance_count=1,</pre><pre class="source-code">    serializer=JSONSerializer(),</pre><pre class="source-code">    deserializer=JSONDeserializer()</pre><pre class="source-code">)</pre></li>
</ol>
<p class="list-inset">Since we set the <strong class="source-inline">predictor_class</strong> attribute in the previous step to <strong class="source-inline">Predictor</strong>, the <strong class="source-inline">deploy()</strong> method will return a <strong class="source-inline">Predictor</strong> instance instead of <strong class="source-inline">None</strong>.</p>
<p class="callout-heading">Note</p>
<p class="callout">Model deployment should take around 5 to 10 minutes to complete. Feel free to grab a cup of coffee or tea!</p>
<ol>
<li value="7">Once our ML inference endpoint is ready, we will perform a sample prediction using the <strong class="source-inline">predict()</strong> method of the <strong class="source-inline">Predictor</strong> instance to test our setup:<pre class="source-code">payload = {</pre><pre class="source-code">    'instances': [</pre><pre class="source-code">        {</pre><pre class="source-code">          "features": [ <strong class="bold">1.5</strong>, <strong class="bold">2</strong> ]</pre><pre class="source-code">        },</pre><pre class="source-code">    ]</pre><pre class="source-code">}</pre><pre class="source-code">predictor.<strong class="bold">predict</strong>(data=payload)</pre></li>
</ol>
<p class="list-inset">This <a id="_idIndexMarker968"/>should<a id="_idIndexMarker969"/> yield an output value equal or similar to <strong class="source-inline">{'predictions': [{'predicted_label': 2.0}]}</strong>.</p>
<ol>
<li value="8">Next, let’s define the <strong class="source-inline">process_prediction_result()</strong> function:<pre class="source-code">def <strong class="bold">process_prediction_result</strong>(raw_result):</pre><pre class="source-code">    first = raw_result['predictions'][0]</pre><pre class="source-code">    return first['predicted_label']</pre></li>
</ol>
<p class="list-inset">This will extract the <strong class="source-inline">label</strong> value from the nested structure returned by the <strong class="source-inline">predict()</strong> method of the <strong class="source-inline">Predictor</strong> instance. Of course, the code in the function assumes that we will only be passing one payload at a time when calling the <strong class="source-inline">predict()</strong> method.</p>
<ol>
<li value="9">Let’s define a custom <strong class="source-inline">predict()</strong> function that accepts the input <strong class="source-inline">x</strong> and <strong class="source-inline">y</strong> values, along with an optional <strong class="source-inline">Predictor</strong> instance parameter value:<pre class="source-code">def <strong class="bold">predict</strong>(x, y, predictor=predictor):</pre><pre class="source-code">    payload = {</pre><pre class="source-code">        'instances': [</pre><pre class="source-code">            {</pre><pre class="source-code">              "features": [ x, y ]</pre><pre class="source-code">            },</pre><pre class="source-code">        ]</pre><pre class="source-code">    }</pre><pre class="source-code">    </pre><pre class="source-code">    raw_result = predictor.predict(</pre><pre class="source-code">        data=payload</pre><pre class="source-code">    )</pre><pre class="source-code">    </pre><pre class="source-code">    return process_prediction_result(raw_result)</pre></li>
<li>Let’s test<a id="_idIndexMarker970"/> our<a id="_idIndexMarker971"/> custom <strong class="source-inline">predict()</strong> function using a set of sample values for <strong class="source-inline">x</strong> and <strong class="source-inline">y</strong>:<pre class="source-code">predict(x=3, y=4)</pre></li>
</ol>
<p class="list-inset">This should return the predicted <strong class="source-inline">label</strong> value equal to or similar to <strong class="source-inline">1.0</strong>. <em class="italic">How do we interpret this result?</em> The customer who lives in a location represented with the specified input <strong class="source-inline">x</strong> and <strong class="source-inline">y</strong> values would probably go to the vaccination site tagged with the label <strong class="source-inline">1</strong> (that is, the second vaccination site).</p>
<p class="callout-heading">Note</p>
<p class="callout">Feel free to modify the <strong class="source-inline">process_prediction_result()</strong> function to convert the type of the resulting predicted <strong class="source-inline">label</strong> value into an <em class="italic">integer</em> instead of a <em class="italic">float</em>.</p>
<ol>
<li value="11">Next, let’s define the <strong class="source-inline">test_different_values()</strong> function:<pre class="source-code">from time import sleep</pre><pre class="source-code">def <strong class="bold">test_different_values</strong>(predictor=predictor):</pre><pre class="source-code">    for <strong class="bold">x</strong> in range(-3, 3+1):</pre><pre class="source-code">        for <strong class="bold">y</strong> in range(-3, 3+1):</pre><pre class="source-code">            label = <strong class="bold">predict</strong>(</pre><pre class="source-code">                        x=<strong class="bold">x</strong>, </pre><pre class="source-code">                        y=<strong class="bold">y</strong>, </pre><pre class="source-code">                        predictor=predictor</pre><pre class="source-code">                    )</pre><pre class="source-code">            print(f"x={x}, y={y}, label={label}")</pre><pre class="source-code">            sleep(0.2)</pre></li>
</ol>
<p class="list-inset">Here, we just call our custom <strong class="source-inline">predict()</strong> function multiple times (with a 200-millisecond delay between each prediction request) using different combinations of values for <em class="italic">x</em> and <em class="italic">y</em>. </p>
<ol>
<li value="12">Before<a id="_idIndexMarker972"/> proceeding, let’s check if<a id="_idIndexMarker973"/> our <strong class="source-inline">test_different_values()</strong> function is working as expected:<pre class="source-code"><strong class="bold">test_different_values()</strong></pre></li>
</ol>
<p class="list-inset">This should show us the predicted <strong class="source-inline">label</strong> values given the different combinations of <em class="italic">x</em> and <em class="italic">y</em>.</p>
<ol>
<li value="13">Next, let’s define a custom <strong class="source-inline">create_model()</strong> function that makes use of the <strong class="source-inline">create_model()</strong> method of the boto3 client to work with the SageMaker API:<pre class="source-code">import boto3</pre><pre class="source-code">client = <strong class="bold">boto3.client(service_name="sagemaker")</strong></pre><pre class="source-code">def <strong class="bold">create_model</strong>(model_package_arn, </pre><pre class="source-code">                 model_name, </pre><pre class="source-code">                 role=role, </pre><pre class="source-code">                 client=client):</pre><pre class="source-code">    container_list = [</pre><pre class="source-code">        {'ModelPackageName': model_package_arn}</pre><pre class="source-code">    ]</pre><pre class="source-code">    response = client.<strong class="bold">create_model</strong>(</pre><pre class="source-code">        ModelName = model_name,</pre><pre class="source-code">        ExecutionRoleArn = role,</pre><pre class="source-code">        Containers = container_list</pre><pre class="source-code">    )</pre><pre class="source-code">    </pre><pre class="source-code">    return response["ModelArn"]</pre></li>
<li>Let’s define the <strong class="source-inline">generate_random_string()</strong> function, which we will use to generate a random model name. After that, we will call the custom <strong class="source-inline">create_model()</strong> function <a id="_idIndexMarker974"/>we<a id="_idIndexMarker975"/> defined in the previous step, passing the model package ARN of our <strong class="bold">Linear Learner</strong> model along with the generated model name:<pre class="source-code">import string </pre><pre class="source-code">import random</pre><pre class="source-code">def <strong class="bold">generate_random_string</strong>():</pre><pre class="source-code">    return ''.join(</pre><pre class="source-code">        random.sample(</pre><pre class="source-code">        string.ascii_uppercase,12)</pre><pre class="source-code">    )</pre><pre class="source-code">model_name = f"ll-{<strong class="bold">generate_random_string()</strong>}"</pre><pre class="source-code">model_arn = <strong class="bold">create_model</strong>(</pre><pre class="source-code">    model_package_arn=<strong class="bold">ll_package_arn</strong>,</pre><pre class="source-code">    model_name=<strong class="bold">model_name</strong></pre><pre class="source-code">)</pre></li>
<li>Next, let’s define the <strong class="source-inline">create_endpoint_config()</strong> function:<pre class="source-code">def <strong class="bold">create_endpoint_config</strong>(</pre><pre class="source-code">        model_name, </pre><pre class="source-code">        config_name, </pre><pre class="source-code">        client=client):</pre><pre class="source-code">    response = client.<strong class="bold">create_endpoint_config</strong>(</pre><pre class="source-code">        EndpointConfigName = config_name,</pre><pre class="source-code">        ProductionVariants=[{</pre><pre class="source-code">            'InstanceType': "ml.m5.xlarge",</pre><pre class="source-code">            'InitialInstanceCount': 1,</pre><pre class="source-code">            'InitialVariantWeight': 1,</pre><pre class="source-code">            'ModelName': model_name,</pre><pre class="source-code">            'VariantName': 'AllTraffic'</pre><pre class="source-code">        }]</pre><pre class="source-code">    )</pre><pre class="source-code">    return response["EndpointConfigArn"]</pre></li>
</ol>
<p class="list-inset">This function<a id="_idIndexMarker976"/> simply<a id="_idIndexMarker977"/> makes use of the <strong class="source-inline">create_endpoint_config()</strong> method of the boto3 client for SageMaker to prepare the desired endpoint configuration.</p>
<ol>
<li value="16">Using the <strong class="source-inline">create_endpoint_config()</strong> function we defined in the previous step, let’s create a SageMaker ML inference endpoint configuration:<pre class="source-code">config_name = f"config-{generate_random_string()}"</pre><pre class="source-code">config_arn = <strong class="bold">create_endpoint_config</strong>(</pre><pre class="source-code">    model_name=model_name,</pre><pre class="source-code">    config_name=config_name</pre><pre class="source-code">)</pre></li>
<li>Now, let’s update the endpoint configuration using the <strong class="source-inline">update_endpoint()</strong> method:<pre class="source-code">response = client.<strong class="bold">update_endpoint</strong>(</pre><pre class="source-code">    EndpointName=predictor.endpoint_name,</pre><pre class="source-code">    EndpointConfigName=config_name</pre><pre class="source-code">)</pre></li>
</ol>
<p class="list-inset">Here, we used the endpoint configuration we created in the previous step.</p>
<p class="callout-heading">Important Note</p>
<p class="callout"><em class="italic">What’s going to happen here?</em> Once we call the <strong class="source-inline">update_endpoint()</strong> method, SageMaker will perform the needed steps behind the scenes to update the endpoint and replace the old, deployed model (<strong class="bold">K-Nearest Neighbor</strong>) with the new model (<strong class="bold">Linear Learner</strong>) specified in the latest endpoint configuration. Note that this is just one of the possible solutions we can implement using the <strong class="bold">SageMaker Python SDK</strong> and the <strong class="bold">boto3</strong> library. Other possible <a id="_idIndexMarker978"/>deployment solutions <a id="_idIndexMarker979"/>include <strong class="bold">multi-model endpoints</strong>, <strong class="bold">A/B testing</strong> endpoint setups, endpoints<a id="_idIndexMarker980"/> using an <strong class="bold">inference pipeline model</strong>, and more! We won’t dive deep into these other variations and solutions, so feel free to check the deployment recipes found in the book <em class="italic">Machine Learning with Amazon SageMaker Cookbook</em>.</p>
<ol>
<li value="18">Before<a id="_idIndexMarker981"/> proceeding with the <a id="_idIndexMarker982"/>next set of steps, let’s wait 5 minutes using the following block of code: <pre class="source-code">print('Wait for update operation to complete')</pre><pre class="source-code"><strong class="bold">sleep</strong>(60*5)</pre></li>
</ol>
<p class="list-inset">Here, we used the <strong class="source-inline">sleep()</strong> function, which accepts an input value equal to the number of seconds we want our code to wait or sleep.</p>
<p class="callout-heading">Note</p>
<p class="callout">We use the <strong class="source-inline">sleep()</strong> function to wait for 5 minutes to ensure that the update endpoint operation has been completed already (assuming that it takes approximately 5 minutes or less to complete).</p>
<ol>
<li value="19">Initialize a <strong class="source-inline">Predictor</strong> object and attach it to the existing ML inference endpoint we prepared earlier in this section:<pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre><pre class="source-code">    endpoint_name=predictor.endpoint_name,</pre><pre class="source-code">    sagemaker_session=session,</pre><pre class="source-code">    serializer=<strong class="bold">JSONSerializer()</strong>,</pre><pre class="source-code">    deserializer=<strong class="bold">JSONDeserializer()</strong></pre><pre class="source-code">)</pre></li>
<li>Let’s test<a id="_idIndexMarker983"/> our <a id="_idIndexMarker984"/>setup by making a prediction using a sample payload:<pre class="source-code">payload = {</pre><pre class="source-code">    'instances': [</pre><pre class="source-code">        {</pre><pre class="source-code">          "features": [ <strong class="bold">1.5</strong>, <strong class="bold">2</strong> ]</pre><pre class="source-code">        },</pre><pre class="source-code">    ]</pre><pre class="source-code">}</pre><pre class="source-code"><strong class="bold">predictor.predict(data=payload)</strong></pre></li>
</ol>
<p class="list-inset">This should yield an output value with a structure similar to<strong class="source-inline"> {'predictions': [{'score': [0.04544410854578018, 0.3947080075740814, 0.5598478317260742], 'predicted_label': 2}]}</strong>.</p>
<p class="list-inset"><em class="italic">How do we interpret this result?</em> The customer who lives in a location represented with the specified input <strong class="source-inline">x</strong> and <strong class="source-inline">y</strong> values (that is, <em class="italic">x</em> = <strong class="source-inline">1.5</strong> and <em class="italic">y</em> = <strong class="source-inline">2</strong>) has the following probabilities: </p>
<ul>
<li><strong class="source-inline">4.5%</strong> probability of going to the first vaccination site (label = 0)</li>
<li><strong class="source-inline">39.5%</strong> probability of going to the second vaccination site (label = 1)</li>
<li><strong class="source-inline">56%</strong> probability of going to the third vaccination site (label = 2)</li>
</ul>
<p class="list-inset">Given that the third vaccination site has the highest probability value, the model sets the <strong class="source-inline">predicted_label</strong> value to <strong class="source-inline">2</strong> (given that counting starts at 0).</p>
<p class="callout-heading">Note</p>
<p class="callout">Note that the deployed <strong class="bold">Linear Learner</strong> model returned the <em class="italic">probability scores for each class</em>, along with the <em class="italic">predicted label</em>, while the <strong class="bold">k-nearest neighbor</strong> model that we deployed at the start of this section only returned the <em class="italic">predicted label</em>. We need to be careful when replacing a deployed model with a model from a different instance family (which may require using a different algorithm container image for inference) since the new model may involve a different set of input and output structures and values.</p>
<ol>
<li value="21">Similar<a id="_idIndexMarker985"/> to<a id="_idIndexMarker986"/> what we performed earlier on the ML inference endpoint hosting our <strong class="bold">K-Nearest Neighbor</strong> model, we will perform multiple sample predictions using different values of <em class="italic">x</em> and <em class="italic">y</em>:<pre class="source-code"><strong class="bold">test_different_values</strong>(predictor=predictor)</pre></li>
<li>Use the <strong class="source-inline">%store</strong> magic to store the variable value for <strong class="source-inline">endpoint_name</strong>:<pre class="source-code">endpoint_name = predictor.endpoint_name</pre><pre class="source-code">%store <strong class="bold">endpoint_name</strong></pre></li>
</ol>
<p>If you are wondering why we haven’t deleted the ML inference endpoint yet… we will reuse this endpoint <a id="_idIndexMarker987"/>and use it to demonstrate <a id="_idIndexMarker988"/>how to use the model monitoring capabilities and features of SageMaker in the very next section!</p>
<h1 id="_idParaDest-168"><a id="_idTextAnchor180"/>Enabling data capture and simulating predictions</h1>
<p>After an ML <a id="_idIndexMarker989"/>model <a id="_idIndexMarker990"/>has been deployed to an inference endpoint, its quality needs to be monitored and checked so that we can easily perform corrective actions whenever quality issues or deviations are detected. This is similar to web application development, where even if the quality assurance team has already spent days (or weeks) testing the final build of the application, there can still be other issues that would only be detected once the web application is running already:</p>
<div>
<div class="IMG---Figure" id="_idContainer266">
<img alt="Figure 8.8 – Capturing the request and response data of the ML inference endpoint " height="628" src="image/B18638_08_008.jpg" width="1208"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.8 – Capturing the request and response data of the ML inference endpoint</p>
<p>As shown in the preceding diagram, model monitoring starts by capturing the request and response data, which passes through a running ML inference endpoint. This collected data is processed and analyzed in a later step using a separate automated task or job that can generate reports and flag issues or anomalies. If we deployed our ML model in a custom-built web application endpoint, we may need to build this data capturing and model monitoring setup ourselves. However, if we are using SageMaker, there is no need for us to code anything from scratch since we can just utilize the built-in model monitoring capabilities, which just need to be enabled and configured.</p>
<p class="callout-heading">Note</p>
<p class="callout">In our “preferred vaccination site prediction” example, the captured data (ideally) includes both the input (the <em class="italic">x</em> and <em class="italic">y</em> values) and output values (predicted <em class="italic">label</em> value).</p>
<p>Follow these steps to enable data capture in a running ML inference endpoint and simulate inference requests using randomly generated payload values:</p>
<ol>
<li value="1">Create a new Notebook by clicking the <strong class="bold">File</strong> menu and choosing <strong class="bold">Notebook</strong> from the <a id="_idIndexMarker991"/>list <a id="_idIndexMarker992"/>of options under the <strong class="bold">New</strong> submenu.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Note that we will be creating the new notebook inside the <strong class="source-inline">CH08</strong> directory beside the <strong class="source-inline">01 - Registering Models to the SageMaker Model Registry.ipynb</strong> and <strong class="source-inline">02 - Deploying Models from the SageMaker Model Registry.ipynb</strong> notebook files we worked with in the previous sections in this chapter.</p>
<ol>
<li value="2">In the <strong class="bold">Set up notebook environment</strong> window, specify the following configuration values:<ul><li><strong class="bold">Image</strong>: <strong class="source-inline">Data Science</strong> (option found under <strong class="bold">SageMaker image</strong>)</li>
<li><strong class="bold">Kernel</strong>: <strong class="source-inline">Python 3</strong></li>
<li><strong class="bold">Start-up script</strong>: <strong class="source-inline">No script</strong> </li>
</ul></li>
</ol>
<p class="list-inset">Click the <strong class="bold">Select</strong> button afterward. </p>
<ol>
<li value="3">Right-click on the tab name of the new Notebook and select <strong class="bold">Rename Notebook…</strong> from the list of options in the context menu. In the <strong class="bold">Rename File</strong> popup, specify <strong class="source-inline">03 - Enabling Data Capture and Simulating Predictions.ipynb</strong> under <strong class="bold">New Name</strong>. Click the <strong class="bold">Rename</strong> button.</li>
<li>Now that we have our new notebook ready, let’s use the <strong class="source-inline">%store</strong> magic from IPython to load the values of the stored variables for <strong class="source-inline">s3_bucket</strong>, <strong class="source-inline">prefix</strong>, <strong class="source-inline">ll_package_arn</strong>, and <strong class="source-inline">endpoint_name</strong>:<pre class="source-code">%store -r <strong class="bold">s3_bucket</strong></pre><pre class="source-code">%store -r <strong class="bold">prefix</strong></pre><pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre><pre class="source-code">%store -r <strong class="bold">endpoint_name</strong></pre></li>
<li>Initialize a <strong class="source-inline">Predictor</strong> object and attach it to the ML inference endpoint we prepared<a id="_idIndexMarker993"/> in <a id="_idIndexMarker994"/>the <em class="italic">Deploying models from SageMaker Model Registry</em> section of this chapter:<pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">from sagemaker.serializers import CSVSerializer</pre><pre class="source-code">from sagemaker.deserializers import CSVDeserializer</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre><pre class="source-code">    endpoint_name=endpoint_name,</pre><pre class="source-code">    sagemaker_session=session,</pre><pre class="source-code">    role=role,</pre><pre class="source-code">    serializer=<strong class="bold">CSVSerializer</strong>(),</pre><pre class="source-code">    deserializer=<strong class="bold">CSVDeserializer</strong>()</pre><pre class="source-code">)</pre></li>
<li>Next, let’s prepare and initialize the <strong class="source-inline">DataCaptureConfig</strong> instance using the following block of code:<pre class="source-code">from sagemaker.model_monitor import DataCaptureConfig</pre><pre class="source-code">base = f"s3://{s3_bucket}/{prefix}"</pre><pre class="source-code">capture_upload_path = f"{base}/data-capture"</pre><pre class="source-code"><strong class="bold">capture_config_dict</strong> = {</pre><pre class="source-code">    'enable_capture': True,</pre><pre class="source-code">    'sampling_percentage': 100,</pre><pre class="source-code">    'destination_s3_uri': capture_upload_path,</pre><pre class="source-code">    'kms_key_id': None,</pre><pre class="source-code">    'capture_options': ["REQUEST", "RESPONSE"],</pre><pre class="source-code">    'csv_content_types': ["text/csv"],</pre><pre class="source-code">    'json_content_types': ["application/json"]</pre><pre class="source-code">}</pre><pre class="source-code">data_capture_config = <strong class="bold">DataCaptureConfig</strong>(</pre><pre class="source-code">    **<strong class="bold">capture_config_dict</strong></pre><pre class="source-code">)</pre></li>
</ol>
<p class="list-inset">Here, we<a id="_idIndexMarker995"/> specified <a id="_idIndexMarker996"/>a <strong class="source-inline">sampling_percentage</strong> value of <strong class="source-inline">100</strong>, which means that all of the data will be captured. We also specified, through the <strong class="source-inline">capture_options</strong> configuration value, that we are planning to capture both the request and response data that passes through the ML inference endpoint.</p>
<ol>
<li value="7">Now that our configuration is ready, let’s call the <strong class="source-inline">update_data_capture_config()</strong> method of the <strong class="source-inline">Predictor</strong> instance:<pre class="source-code">%%time</pre><pre class="source-code">predictor.<strong class="bold">update_data_capture_config</strong>(</pre><pre class="source-code">    data_capture_config=data_capture_config</pre><pre class="source-code">)</pre></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">This should take around 5 to 15 minutes to complete. Feel free to grab a cup of coffee or tea!</p>
<ol>
<li value="8">Use the <strong class="source-inline">%store</strong> magic<a id="_idIndexMarker997"/> to <a id="_idIndexMarker998"/>store the variable value for <strong class="source-inline">capture_upload_path</strong>:<pre class="source-code">%store <strong class="bold">capture_upload_path</strong></pre></li>
<li>Define the <strong class="source-inline">generate_random_payload()</strong> function:<pre class="source-code">import random</pre><pre class="source-code">def <strong class="bold">generate_random_payload</strong>():</pre><pre class="source-code">    x = random.randint(-5,5)</pre><pre class="source-code">    y = random.randint(-5,5)</pre><pre class="source-code">    </pre><pre class="source-code">    return f"{x},{y}"</pre></li>
<li>Define the <strong class="source-inline">perform_good_input()</strong> and <strong class="source-inline">perform_bad_input()</strong> functions:<pre class="source-code">def <strong class="bold">perform_good_input</strong>(predictor):</pre><pre class="source-code">    print("&gt; PERFORM REQUEST WITH GOOD INPUT")</pre><pre class="source-code">    payload = generate_random_payload()</pre><pre class="source-code">    result = predictor.predict(data=payload)</pre><pre class="source-code">    print(result)</pre><pre class="source-code">def <strong class="bold">perform_bad_input</strong>(predictor):</pre><pre class="source-code">    print("&gt; PERFORM REQUEST WITH BAD INPUT")</pre><pre class="source-code">    payload = generate_random_payload() + ".50"</pre><pre class="source-code">    result = predictor.predict(data=payload)</pre><pre class="source-code">    print(result)</pre></li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">At this point, you might be wondering why we are considering floating-point values for the <em class="italic">y</em> input payload as <em class="italic">bad input</em>. Note that this is just for demonstration purposes since we are planning to<a id="_idIndexMarker999"/> configure <strong class="bold">SageMaker Model Monitor</strong> to tag floating-point input values for <em class="italic">x</em> and <em class="italic">y</em> as invalid values while configuring the constraints in the <em class="italic">Scheduled Monitoring with SageMaker Model Monitor</em> section.</p>
<ol>
<li value="11">Use the <strong class="source-inline">perform_good_input()</strong> function to run a sample inference request containing “valid values:”<pre class="source-code"><strong class="bold">perform_good_input</strong>(predictor)</pre></li>
<li>Use the <strong class="source-inline">perform_bad_input()</strong> function to run a sample inference<a id="_idIndexMarker1000"/> request containing “invalid <a id="_idIndexMarker1001"/>values:”<pre class="source-code"><strong class="bold">perform_bad_input</strong>(predictor)</pre></li>
<li>Define the <strong class="source-inline">generate_sample_requests()</strong> function, which will alternate between calling the <strong class="source-inline">perform_good_input()</strong> and <strong class="source-inline">perform_bad_input()</strong> functions:<pre class="source-code">from time import sleep</pre><pre class="source-code">def <strong class="bold">generate_sample_requests</strong>(predictor):</pre><pre class="source-code">    for i in range(0, 2 * 240):</pre><pre class="source-code">        print(f"ITERATION # {i}")</pre><pre class="source-code">        perform_good_input(predictor)</pre><pre class="source-code">        perform_bad_input(predictor)</pre><pre class="source-code">        </pre><pre class="source-code">        print("&gt; SLEEPING FOR 30 SECONDS")</pre><pre class="source-code">        sleep(30)</pre></li>
<li>With everything ready, let’s continuously send sample requests to our ML inference endpoint using the <strong class="source-inline">generate_sample_requests()</strong> function: <pre class="source-code"><strong class="bold">generate_sample_requests</strong>(predictor)</pre></li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">Note that the last step in this section will continuously send sample inference requests every 30 seconds and loop 480 times. We will leave this running and proceed with the next section. We should only stop the execution of the <strong class="source-inline">generate_sample_requests()</strong> function after completing the <em class="italic">Scheduled monitoring with SageMaker Model Monitor</em> section of this chapter.</p>
<p>At this point, you <a id="_idIndexMarker1002"/>might<a id="_idIndexMarker1003"/> be wondering where the data is stored and how this data would be used for analysis. In the next few sections, we will answer these questions and provide more details on how model monitoring works in SageMaker.</p>
<h1 id="_idParaDest-169"><a id="_idTextAnchor181"/>Scheduled monitoring with SageMaker Model Monitor</h1>
<p>If you have<a id="_idIndexMarker1004"/> been working in the data science and ML industry for quite some time, you probably know that an ML model’s performance after deployment is not guaranteed. Deployed models in production must be monitored in real time (or near-real time) so that we can potentially replace the deployed model and fix any issues once <a id="_idIndexMarker1005"/>any <strong class="bold">drift</strong> or deviation from the expected set of values is detected:</p>
<div>
<div class="IMG---Figure" id="_idContainer267">
<img alt="Figure 8.9 – Analyzing captured data and detecting violations using Model Monitor    " height="637" src="image/B18638_08_009.jpg" width="1330"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.9 – Analyzing captured data and detecting violations using Model Monitor </p>
<p>In the preceding diagram, we can see that we can process and analyze the captured data through a monitoring (processing) job. This job is expected to generate an automated report that can be used to analyze the deployed model and the data. At the same time, any <a id="_idIndexMarker1006"/>detected violations are flagged and reported as part of the report.</p>
<p class="callout-heading">Note</p>
<p class="callout">Let’s say that we have trained an ML model that predicts a professional’s <em class="italic">salary</em> given the professional’s <em class="italic">age</em>, <em class="italic">number of years of work experience</em>, <em class="italic">role</em>, and <em class="italic">number of children</em>. Once the ML model has been deployed to an inference endpoint, a variety of applications would then send request data to the ML inference endpoint to get the predicted salary value. <em class="italic">What if one of the applications starts sending erroneous values?</em> For example, the value specified for the <em class="italic">number of children</em> in the input payload is negative. Given that it is impossible to have a negative number for this field, a monitoring job should flag this violation <a id="_idIndexMarker1007"/>as a <strong class="bold">data quality issue</strong>. </p>
<p>In this section, we will configure <strong class="bold">SageMaker Model Monitor</strong> to analyze the captured data using a scheduled hourly processing job. Once the processing job results are ready, we will see that the monitoring job has flagged a violation caused by sending “bad input” as part of the payload to the ML inference endpoint in the previous section. Model Monitor <a id="_idIndexMarker1008"/>can be configured to detect <a id="_idIndexMarker1009"/>violations <a id="_idIndexMarker1010"/>concerning <strong class="bold">data quality</strong>, <strong class="bold">model quality</strong>, <strong class="bold">bias drift</strong>, and <strong class="bold">feature attribution drift</strong>. In <a id="_idIndexMarker1011"/>the hands-on solutions in this section, we will only focus on detecting violations concerning data quality. However, detecting the other types of drifts and violations should follow a similar set of steps, which will be presented in a bit.</p>
<p>Follow these steps to configure <strong class="bold">SageMaker Model Monitor</strong> to run a monitoring job every hour and analyze the captured data that passed through the ML inference endpoint: </p>
<ol>
<li value="1">Create a new Notebook by clicking the <strong class="bold">File</strong> menu and choosing <strong class="bold">Notebook</strong> from the list of options under the <strong class="bold">New</strong> submenu.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Note that we will be creating the new notebook inside the <strong class="source-inline">CH08</strong> directory beside the other notebook files we created in the previous sections of this chapter.</p>
<ol>
<li value="2">In <a id="_idIndexMarker1012"/>the <strong class="bold">Set up notebook environment</strong> window, specify the following configuration values:<ul><li><strong class="bold">Image</strong>: <strong class="source-inline">Data Science</strong> (option found under <strong class="bold">SageMaker image</strong>)</li>
<li><strong class="bold">Kernel</strong>: <strong class="source-inline">Python 3</strong></li>
<li><strong class="bold">Start-up script</strong>: <strong class="source-inline">No script</strong> </li>
</ul></li>
</ol>
<p class="list-inset">Click the <strong class="bold">Select</strong> button afterward. </p>
<ol>
<li value="3">Right-click on the tab name of the new Notebook and select <strong class="bold">Rename Notebook…</strong> from the list of options in the context menu. In the <strong class="bold">Rename File</strong> popup, specify <strong class="source-inline">04 - Scheduled Monitoring with SageMaker Model Monitor.ipynb</strong> under <strong class="bold">New Name</strong>. Click the <strong class="bold">Rename</strong> button afterward.</li>
<li>Now that we have our new notebook ready, let’s use the <strong class="source-inline">%store</strong> magic from IPython to load the values of the stored variables for <strong class="source-inline">s3_bucket</strong>, <strong class="source-inline">prefix</strong>, <strong class="source-inline">ll_package_arn</strong>, <strong class="source-inline">endpoint_name</strong>, and <strong class="source-inline">ll_package_arn</strong>:<pre class="source-code">%store -r <strong class="bold">s3_bucket</strong></pre><pre class="source-code">%store -r <strong class="bold">prefix</strong></pre><pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre><pre class="source-code">%store -r <strong class="bold">endpoint_name</strong></pre><pre class="source-code">%store -r <strong class="bold">ll_package_arn</strong></pre></li>
<li>Initialize a <strong class="source-inline">Predictor</strong> object and attach it to the ML inference endpoint we deployed in <a id="_idIndexMarker1013"/>the <em class="italic">Deploying models from SageMaker Model Registry</em> section:<pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre><pre class="source-code">    endpoint_name=endpoint_name,</pre><pre class="source-code">    sagemaker_session=session,</pre><pre class="source-code">    role=role</pre><pre class="source-code">)</pre></li>
<li>Download the <strong class="source-inline">baseline.csv</strong> file using the <strong class="source-inline">wget</strong> command:<pre class="source-code">%%bash</pre><pre class="source-code"><strong class="bold">mkdir</strong> -p tmp</pre><pre class="source-code"><strong class="bold">wget</strong> -O tmp/<strong class="bold">baseline.csv</strong> <a href="https://bit.ly/3td5vjx">https://bit.ly/3td5vjx</a></pre></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">What’s the <strong class="source-inline">baseline.csv</strong> file for? This CSV file will later serve as the <strong class="bold">baseline dataset</strong> that <a id="_idIndexMarker1014"/>will be used by <strong class="bold">SageMaker Model Monitor</strong> as a “reference” to check for drifts and issues with the captured data.</p>
<ol>
<li value="7">Let’s also prepare the S3 path location where we will store the baseline analysis output files:<pre class="source-code">base = f's3://{s3_bucket}/{prefix}'</pre><pre class="source-code">baseline_source_uri = f'{base}/<strong class="bold">baseline.csv</strong>'</pre><pre class="source-code">baseline_output_uri = f"{base}/baseline-output"</pre></li>
<li>Use the <strong class="source-inline">aws s3 cp</strong> command to upload the <strong class="source-inline">baseline.csv</strong> file from the <strong class="source-inline">tmp</strong> directory to the S3 target location stored in <strong class="source-inline">baseline_source_uri</strong>:<pre class="source-code">!aws s3 cp tmp/baseline.csv {baseline_source_uri}</pre></li>
<li>Initialize and<a id="_idIndexMarker1015"/> configure the <strong class="source-inline">DefaultModelMonitor</strong> instance using the following block of code:<pre class="source-code">from sagemaker.model_monitor import DefaultModelMonitor</pre><pre class="source-code"><strong class="bold">monitor_dict</strong> = {</pre><pre class="source-code">    'role': role,</pre><pre class="source-code">    'instance_count': 1,</pre><pre class="source-code">    'instance_type': 'ml.m5.large',</pre><pre class="source-code">    'volume_size_in_gb': 10,</pre><pre class="source-code">    'max_runtime_in_seconds': 1800,</pre><pre class="source-code">}</pre><pre class="source-code">default_monitor = <strong class="bold">DefaultModelMonitor</strong>(</pre><pre class="source-code">    **<strong class="bold">monitor_dict</strong></pre><pre class="source-code">)</pre></li>
</ol>
<p class="list-inset">Here, we configured <strong class="bold">SageMaker Model Monitor</strong> to use an <strong class="source-inline">ml.m5.large</strong> instance when processing the captured data.</p>
<p class="callout-heading">Note</p>
<p class="callout">To monitor the deployed ML model and the data passing through the inference endpoint, <strong class="bold">SageMaker Model Monitor</strong> runs <strong class="bold">SageMaker Processing</strong> jobs automatically on a <a id="_idIndexMarker1016"/>scheduled basis (depending on the schedule configuration). Running a SageMaker Processing job involves launching ML instances (with the specified instance size and instance count) where processing scripts (and containers) would run inside. Once a processing job has finished, the ML instance (or instances) used is deleted automatically. That said, the values specified in <strong class="source-inline">monitor_dict</strong> correspond to the configuration of the SageMaker Processing jobs for monitoring the ML model and the data.</p>
<ol>
<li value="10">Let’s run the <a id="_idIndexMarker1017"/>baselining job using the following block of code:<pre class="source-code">%%time</pre><pre class="source-code">from sagemaker.model_monitor import dataset_format</pre><pre class="source-code">dataset_format = dataset_format.DatasetFormat.csv(</pre><pre class="source-code">    header=True</pre><pre class="source-code">)</pre><pre class="source-code"><strong class="bold">baseline_dict</strong> = {</pre><pre class="source-code">    'baseline_dataset': baseline_source_uri,</pre><pre class="source-code">    'dataset_format': dataset_format,</pre><pre class="source-code">    'output_s3_uri': baseline_output_uri,</pre><pre class="source-code">    'wait': True</pre><pre class="source-code">}</pre><pre class="source-code">default_monitor.<strong class="bold">suggest_baseline</strong>(</pre><pre class="source-code">    **<strong class="bold">baseline_dict</strong></pre><pre class="source-code">)</pre></li>
</ol>
<p class="list-inset">Here, we used the <strong class="source-inline">baseline.csv</strong> file as a reference for the expected properties of the data that will pass through the ML inference endpoint. Let’s say that one of the columns in the <strong class="source-inline">baseline.csv</strong> file only contains positive integers. Using this CSV file as the baseline, we would be able to configure <strong class="bold">SageMaker Model Monitor</strong> to flag negative or floating-point input values (for the said column or feature) as “bad input.”</p>
<p class="callout-heading">Note</p>
<p class="callout">Of course, detecting the violations and issues is only half the story. Fixing the issue would be the other half. </p>
<ol>
<li value="11">Define a custom <strong class="source-inline">flatten()</strong> function, which will help us inspect and view a dictionary <a id="_idIndexMarker1018"/>object in a DataFrame:<pre class="source-code">import pandas as pd</pre><pre class="source-code">def <strong class="bold">flatten</strong>(input_dict):</pre><pre class="source-code">    df = pd.json_normalize(input_dict)</pre><pre class="source-code">    return df.head()</pre></li>
<li>Let’s the check statistics report generated by the baselining job:<pre class="source-code">baseline_job = default_monitor.<strong class="bold">latest_baselining_job</strong></pre><pre class="source-code">stats = baseline_job.<strong class="bold">baseline_statistics()</strong></pre><pre class="source-code">schema_dict = stats.body_dict["features"]</pre><pre class="source-code">flatten(<strong class="bold">schema_dict</strong>)</pre></li>
</ol>
<p class="list-inset">This should yield a DataFrame similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer268">
<img alt="Figure 8.10 – DataFrame containing the baseline statistics " height="197" src="image/B18638_08_010.jpg" width="1220"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.10 – DataFrame containing the baseline statistics</p>
<p class="list-inset">Here, we can see the <strong class="source-inline">inferred_type</strong> values for each of the columns of the <strong class="source-inline">baseline.csv</strong> file, along with the other statistics values.</p>
<ol>
<li value="13">Next, let’s review the suggested constraints prepared by the baselining job:<pre class="source-code">constraints = baseline_job.<strong class="bold">suggested_constraints()</strong></pre><pre class="source-code">constraints_dict = constraints.body_dict["features"]</pre><pre class="source-code">flatten(<strong class="bold">constraints_dict</strong>)</pre></li>
</ol>
<p class="list-inset">This should give us a DataFrame of values similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer269">
<img alt="Figure 8.11 – DataFrame with the suggested constraints of each of the features " height="139" src="image/B18638_08_011.jpg" width="736"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.11 – DataFrame with the suggested constraints of each of the features</p>
<p class="list-inset">Here, we can<a id="_idIndexMarker1019"/> see the constraints recommended by the baselining job after analyzing the baseline dataset used.</p>
<p class="callout-heading">Note</p>
<p class="callout">These (suggested) constraints will be used later by the <strong class="bold">SageMaker Processing</strong> jobs to check the quality of the captured data. The processing jobs will then detect and report violations if the “properties” of the baseline do not match the “properties” of the captured data. For example, if column <strong class="source-inline">a</strong> in the baseline dataset has a constraint where it should contain integer values only, then the processing jobs will flag if the captured data contains records, where the column <strong class="source-inline">a</strong> value is a floating-point number.</p>
<ol>
<li value="14">Next, we will modify the constraints for columns <strong class="source-inline">a</strong> and <strong class="source-inline">b</strong> (containing the input <em class="italic">x</em> and <em class="italic">y</em> values) and assume that the valid values for these are of the integer type instead of float or decimal:<pre class="source-code">constraints.body_dict['features'][1]['inferred_type'] = '<strong class="bold">Integral</strong>'</pre><pre class="source-code">constraints.body_dict['features'][2]['inferred_type'] = '<strong class="bold">Integral</strong>'</pre><pre class="source-code">constraints.<strong class="bold">save()</strong></pre></li>
</ol>
<p class="list-inset">Once the hourly processing job analyzes the captured data, <strong class="bold">SageMaker Model Monitor</strong> will flag <a id="_idIndexMarker1020"/>the payloads containing floating-point <em class="italic">y</em> values as “bad input.” </p>
<p class="callout-heading">Important Note</p>
<p class="callout">What happens if we change the <strong class="source-inline">inferred_type</strong> values for columns <strong class="source-inline">a</strong> and <strong class="source-inline">b</strong> (containing the <em class="italic">x</em> and <em class="italic">y</em> values, respectively) of the suggested constraints to <strong class="source-inline">'Fractional'</strong> instead of <strong class="source-inline">'Integral'</strong>? Since the payload values generated by the <strong class="source-inline">generate_sample_requests()</strong> function in the <em class="italic">Enabling data capture and simulating predictions</em> section involve a combination of integer and floating-point values, <strong class="bold">SageMaker Model Monitor</strong> will tag all input request payloads as “good input” and it will not report any detected violations.</p>
<ol>
<li value="15">Let’s define the <strong class="source-inline">generate_label()</strong> function, which will help us generate a random string label for the monitoring schedule name in a later step:<pre class="source-code">from sagemaker.model_monitor import (</pre><pre class="source-code">    CronExpressionGenerator</pre><pre class="source-code">)</pre><pre class="source-code">from string import ascii_uppercase</pre><pre class="source-code">import random</pre><pre class="source-code">def <strong class="bold">generate_label</strong>():</pre><pre class="source-code">    chars = random.choices(ascii_uppercase, k=5)</pre><pre class="source-code">    output = 'monitor-' + ''.join(chars)</pre><pre class="source-code">    return output</pre></li>
<li>Let’s load the baseline statistics and suggested constraints using the <strong class="source-inline">baseline_statistics()</strong> and <strong class="source-inline">suggested_constraints()</strong> methods, respectively:<pre class="source-code">s3_report_path = f'{base}/report'</pre><pre class="source-code">baseline_statistics = default_monitor.<strong class="bold">baseline_statistics()</strong></pre><pre class="source-code">constraints = default_monitor.<strong class="bold">suggested_constraints()</strong></pre></li>
<li>Let’s prepare the <strong class="bold">cron expression</strong> that<a id="_idIndexMarker1021"/><a id="_idIndexMarker1022"/> we will use to configure the monitoring<a id="_idIndexMarker1023"/> job to run once every hour in a later step: <pre class="source-code">cron_expression = <strong class="bold">CronExpressionGenerator.hourly()</strong></pre></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">For more details on other <a id="_idIndexMarker1024"/>supported <strong class="bold">cron expressions</strong>, feel free to check out <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml">https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml</a>.</p>
<ol>
<li value="18">With the prerequisites ready, let’s create the monitoring schedule using the <strong class="source-inline">create_monitoring_schedule()</strong> method of the <strong class="source-inline">DefaultModelMonitor</strong> instance:<pre class="source-code"><strong class="bold">schedule_dict</strong> = {</pre><pre class="source-code">    'monitor_schedule_name': generate_label(),</pre><pre class="source-code">    'endpoint_input': predictor.endpoint,</pre><pre class="source-code">    'output_s3_uri': s3_report_path,</pre><pre class="source-code">    'statistics': baseline_statistics,</pre><pre class="source-code">    'constraints': constraints,</pre><pre class="source-code">    'schedule_cron_expression': cron_expression,</pre><pre class="source-code">    'enable_cloudwatch_metrics': True</pre><pre class="source-code">}</pre><pre class="source-code">default_monitor.<strong class="bold">create_monitoring_schedule</strong>(</pre><pre class="source-code">    **<strong class="bold">schedule_dict</strong></pre><pre class="source-code">)</pre></li>
</ol>
<p class="list-inset">After running this block of code, <strong class="bold">SageMaker Model Monitor</strong> creates a <strong class="source-inline">schedule</strong> that runs a <strong class="bold">SageMaker Processing</strong> job (once every hour) that processes <a id="_idIndexMarker1025"/>and monitors the data that’s been captured.</p>
<p class="callout-heading">Note</p>
<p class="callout">If you encounter deprecation warnings or issues when using <strong class="source-inline">predictor.endpoint</strong>, you may replace it with <strong class="source-inline">predictor.endpoint_name</strong> instead. For more information on deprecations (along with breaking and non-breaking changes) when using version 2.x of the <strong class="bold">SageMaker Python SDK</strong>, feel free to check out <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml">https://sagemaker.readthedocs.io/en/stable/v2.xhtml</a>.</p>
<ol>
<li value="19">Let’s quickly inspect the monitor’s schedule properties:<pre class="source-code">flatten(default_monitor.<strong class="bold">describe_schedule()</strong>)</pre></li>
</ol>
<p class="list-inset">This should yield a DataFrame similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer270">
<img alt="Figure 8.12 – DataFrame describing the properties of the monitoring schedule " height="154" src="image/B18638_08_012.jpg" width="899"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.12 – DataFrame describing the properties of the monitoring schedule</p>
<p class="list-inset">Here, we can see that the <strong class="source-inline">MonitoringScheduleStatus</strong> value is still <strong class="source-inline">Pending</strong>.</p>
<ol>
<li value="20">Use the <strong class="source-inline">sleep()</strong> function to wait for 5 minutes before executing the next cell:<pre class="source-code">from time import sleep</pre><pre class="source-code"><strong class="bold">sleep</strong>(300)</pre></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Here, we wait for a few minutes while the monitoring schedule is being created (assuming it is created in 5 minutes).</p>
<ol>
<li value="21">Test and load the initial set of values for the monitor’s constraint violations and statistics<a id="_idIndexMarker1026"/> using the <strong class="source-inline">latest_monitoring_constraint_violations() </strong>and <strong class="source-inline">latest_monitoring_statistics()</strong> methods of the <strong class="source-inline">DefaultModelMonitor</strong> instance:<pre class="source-code">dm = default_monitor</pre><pre class="source-code">monitoring_violations = \</pre><pre class="source-code">dm.<strong class="bold">latest_monitoring_constraint_violations()</strong></pre><pre class="source-code">monitoring_statistics = \</pre><pre class="source-code">dm.<strong class="bold">latest_monitoring_statistics()</strong></pre></li>
<li>Define the <strong class="source-inline">get_violations()</strong> and <strong class="source-inline">load_and_load_violations()</strong> functions:<pre class="source-code">%%time</pre><pre class="source-code">from time import sleep</pre><pre class="source-code">def <strong class="bold">get_violations()</strong>:</pre><pre class="source-code">    return \</pre><pre class="source-code">    dm.<strong class="bold">latest_monitoring_constraint_violations()</strong></pre><pre class="source-code">def <strong class="bold">loop_and_load_violations</strong>():</pre><pre class="source-code">    for i in range(0, 2 * 120):</pre><pre class="source-code">        print(f"ITERATION # {i}")</pre><pre class="source-code">        print("&gt; SLEEPING FOR 60 SECONDS")</pre><pre class="source-code">        sleep(60)</pre><pre class="source-code">        </pre><pre class="source-code">        try:</pre><pre class="source-code">            v = get_violations()</pre><pre class="source-code">            violations = v</pre><pre class="source-code">            </pre><pre class="source-code">            if violations:</pre><pre class="source-code">                return violations</pre><pre class="source-code">        except:</pre><pre class="source-code">            pass</pre><pre class="source-code">    </pre><pre class="source-code">    print("&gt; DONE!")</pre><pre class="source-code">    return None              </pre></li>
<li>Invoke <a id="_idIndexMarker1027"/>the <strong class="source-inline">load_and_load_violations()</strong> function we defined in the previous step:<pre class="source-code"><strong class="bold">loop_and_load_violations()</strong></pre></li>
</ol>
<p class="list-inset">This should yield a set of logs similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer271">
<img alt="Figure 8.13 – Logs generated while running the loop_and_load_violations() function " height="414" src="image/B18638_08_013.jpg" width="981"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.13 – Logs generated while running the loop_and_load_violations() function</p>
<p class="list-inset">Here, we simply iterated and waited for the scheduled Model Monitor processing job to yield the generated analysis report containing the detected violations, along<a id="_idIndexMarker1028"/> with the other statistical values computed from the captured data.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">This step may take an hour or more to complete. Feel free to grab a (larger) cup of coffee or tea! While waiting for this step to complete, you may continue with the hands-on solutions of the next section of this chapter, <em class="italic">Analyzing the captured data</em>. </p>
<ol>
<li value="24">Once the <strong class="source-inline">loop_and_load_violations()</strong> function has finished running, you can proceed with loading and inspecting the detected violations using the <strong class="source-inline">latest_monitoring_constraint_violations()</strong> method of the <strong class="source-inline">DefaultModelMonitor</strong> instance:<pre class="source-code">violations = dm.<strong class="bold">latest_monitoring_constraint_violations()</strong></pre><pre class="source-code">violations.__dict__</pre></li>
</ol>
<p class="list-inset">This should give us a nested dictionary of values, similar to what we have in the following code:</p>
<pre class="list-inset1 source-code">{'body_dict': {'violations': [
  {'feature_name': 'b',
    'constraint_check_type': 'data_type_check',
    'description': '<strong class="bold">Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 50.0% of data is Integral.</strong>'}]
  },
 'file_s3_uri': 's3://&lt;BUCKET&gt;/chapter08/report/1-2022-05-23-14-39-16-279/monitor-YTADH/2022/05/23/16/constraint_violations.json',
 'kms_key': None,
 'session': None
}</pre>
<p class="list-inset">Here, we can see that we have several detected violations for feature <strong class="source-inline">b</strong> (corresponding to the <em class="italic">y</em> input values). To have a better idea of what these detected violations are, we can check the available description – <strong class="source-inline">Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 50.0% of data is Integral</strong>.</p>
<ol>
<li value="25">Load and <a id="_idIndexMarker1029"/>inspect the statistics data using the <strong class="source-inline">latest_monitoring_statistics()</strong> method of the <strong class="source-inline">DefaultModelMonitor</strong> instance:<pre class="source-code">monitoring_statistics = dm.<strong class="bold">latest_monitoring_statistics()</strong></pre><pre class="source-code">monitoring_statistics.__dict__</pre></li>
</ol>
<p class="list-inset">This should give us a nested structure of values similar to the following:</p>
<pre class="list-inset1 source-code">{'body_dict': {'version': 0.0,
  'dataset': {'item_count': 190},
  'features': [{'name': 'label',
    'inferred_type': 'Integral',
    'numerical_statistics': {'common': {'num_present': 190, 'num_missing': 0},
     'mean': 1.2052631578947368,
     'sum': 229.0,
     'std_dev': 0.7362591679068381,
     'min': 0.0,
     'max': 2.0,
      ... (and more) ...</pre>
<p><em class="italic">Wasn’t that easy?</em> Imagine trying to build this yourself! It would have taken you a few days to code and build this yourself from scratch. </p>
<p>At this point, you should have a better idea of how to configure and use <strong class="bold">SageMaker Model Monitor</strong> to detect violations and potential issues in the model and data. Before cleaning up the resources we created and used in this chapter, we will look at another approach regarding <a id="_idIndexMarker1030"/>how to analyze and process the data captured and collected by Model Monitor in the S3 bucket.</p>
<h1 id="_idParaDest-170"><a id="_idTextAnchor182"/>Analyzing the captured data</h1>
<p>Of course, there are <a id="_idIndexMarker1031"/>other ways to process the data that’s been captured and stored inside the S3 bucket. Instead of using the built-in model monitoring capabilities and features discussed in the previous section, we can also download the collected ML inference endpoint data from the S3 bucket and analyze it directly in a notebook. </p>
<p class="callout-heading">Note</p>
<p class="callout">It is still recommended to utilize the built-in model monitoring capabilities and features of SageMaker. However, knowing this approach would help us troubleshoot any issues we may encounter while using and running the automated solutions available in SageMaker.</p>
<p>Follow these steps to use a variety of Python libraries to process, clean, and analyze the collected ML inference data in S3:</p>
<ol>
<li value="1">Create a new Notebook by clicking the <strong class="bold">File</strong> menu and choosing <strong class="bold">Notebook</strong> from the list of options under the <strong class="bold">New</strong> submenu.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Note that we will be creating the new notebook inside the <strong class="source-inline">CH08</strong> directory beside the other notebook files we created in the previous sections of this chapter.</p>
<ol>
<li value="2">In the <strong class="bold">Set up notebook environment</strong> window, specify the following configuration values:<ul><li><strong class="bold">Image</strong>: <strong class="source-inline">Data Science</strong> (option found under <strong class="bold">SageMaker image</strong>)</li>
<li><strong class="bold">Kernel</strong>: <strong class="source-inline">Python 3</strong></li>
<li><strong class="bold">Start-up script</strong>: <strong class="source-inline">No script</strong> </li>
</ul></li>
</ol>
<p class="list-inset">Click the <strong class="bold">Select</strong> button afterward. </p>
<ol>
<li value="3">Right-click on the<a id="_idIndexMarker1032"/> tab name of the new Notebook and select <strong class="bold">Rename Notebook…</strong> from the list of options in the context menu. In the <strong class="bold">Rename File</strong> popup, specify <strong class="source-inline">05 - Analyzing the Captured Data.ipynb</strong> under <strong class="bold">New Name</strong>. Click the <strong class="bold">Rename</strong> button.</li>
<li>Now that we have created our new notebook, let’s use the <strong class="source-inline">%store</strong> magic from <strong class="bold">IPython</strong> to load the values of the stored variables for <strong class="source-inline">s3_bucket</strong> and <strong class="source-inline">capture_upload_path</strong>:<pre class="source-code">%store -r <strong class="bold">s3_bucket</strong></pre><pre class="source-code">%store -r <strong class="bold">capture_upload_path</strong></pre></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Wait! Where did <strong class="source-inline">capture_upload_path</strong> come from? In the <em class="italic">Enabling data capture and simulating predictions</em> section, we initialized <strong class="source-inline">capture_upload_path</strong> and set its value to the S3 path where the captured data (of <strong class="bold">SageMaker Model Monitor</strong>) will be stored.</p>
<ol>
<li value="5">Get the S3 path of each of the generated <strong class="source-inline">jsonl</strong> files containing the input and output data of the inference requests:<pre class="source-code">results = !<strong class="bold">aws s3 ls</strong> {capture_upload_path} --recursive</pre><pre class="source-code">processed = []</pre><pre class="source-code">for result in results:</pre><pre class="source-code">    partial = result.split()[-1]</pre><pre class="source-code">    path = f"s3://{s3_bucket}/{partial}"</pre><pre class="source-code">    processed.append(path)</pre><pre class="source-code">    </pre><pre class="source-code">processed</pre></li>
<li>Create the <strong class="source-inline">captured</strong> directory<a id="_idIndexMarker1033"/> using the <strong class="source-inline">mkdir</strong> command:<pre class="source-code">!mkdir -p <strong class="bold">captured</strong></pre></li>
<li>Next, use the <strong class="source-inline">aws s3 cp</strong> command to copy each of the generated <strong class="source-inline">jsonl</strong> files to the <strong class="source-inline">captured</strong> directory we just created in the previous step:<pre class="source-code">for index, path in enumerate(processed):</pre><pre class="source-code">    print(index, path)</pre><pre class="source-code">    !<strong class="bold">aws s3 cp</strong> {path} captured/{index}.jsonl</pre></li>
<li>Define the <strong class="source-inline">load_json_file()</strong> function:<pre class="source-code">import json</pre><pre class="source-code">def <strong class="bold">load_json_file</strong>(path):</pre><pre class="source-code">    output = []</pre><pre class="source-code">    </pre><pre class="source-code">    with open(path) as f:</pre><pre class="source-code">        output = [json.loads(line) for line in f]</pre><pre class="source-code">        </pre><pre class="source-code">    return output</pre></li>
<li>Extract the JSON values from each of the downloaded <strong class="source-inline">jsonl</strong> files inside the <strong class="source-inline">captured</strong> directory:<pre class="source-code">all_json = []</pre><pre class="source-code">for index, _ in enumerate(processed):</pre><pre class="source-code">    print(f"INDEX: {index}")</pre><pre class="source-code">    new_records = <strong class="bold">load_json_file</strong>(</pre><pre class="source-code">        f"captured/{index}.jsonl"</pre><pre class="source-code">    )</pre><pre class="source-code">    all_json = all_json + new_records</pre><pre class="source-code">    </pre><pre class="source-code">    </pre><pre class="source-code"><strong class="bold">all_json</strong></pre></li>
<li>Use <strong class="source-inline">pip</strong> to install the <strong class="source-inline">flatten-dict</strong> library:<pre class="source-code">!pip3 install <strong class="bold">flatten-dict</strong></pre></li>
</ol>
<p class="list-inset">As we will see in<a id="_idIndexMarker1034"/> the succeeding set of steps, the <strong class="source-inline">flatten-dict</strong> package is useful in “flattening” any nested dictionary structure.</p>
<ol>
<li value="11">Test the <strong class="source-inline">flatten()</strong> function from the <strong class="source-inline">flatten-dict</strong> library on the first entry stored in the <strong class="source-inline">all_json</strong> list:<pre class="source-code">from flatten_dict import flatten</pre><pre class="source-code">first = <strong class="bold">flatten</strong>(all_json[0], reducer='dot')</pre><pre class="source-code">first</pre></li>
</ol>
<p class="list-inset">This should give us a flattened structure similar to the following:</p>
<pre class="list-inset1 source-code">{'captureData.endpointInput.observedContentType': 'text/csv',
 'captureData.endpointInput.mode': 'INPUT',
 'captureData.endpointInput.data': '0,0',
 'captureData.endpointInput.encoding': 'CSV',
 'captureData.endpointOutput.observedContentType': 'text/csv; charset=utf-8',
 'captureData.endpointOutput.mode': 'OUTPUT',
 'captureData.endpointOutput.data': '2\n',
 'captureData.endpointOutput.encoding': 'CSV',
 'eventMetadata.eventId': 'b73b5e15-06ad-48af-b53e-6b8800e98678',
 'eventMetadata.inferenceTime': '2022-05-23T18:43:42Z',
 'eventVersion': '0'}</pre>
<p class="callout-heading">Note</p>
<p class="callout">We will use <strong class="source-inline">flatten()</strong> shortly to convert the nested JSON values stored in <strong class="source-inline">all_json</strong> into “flattened” JSON values. This list of “flattened” JSON values will then be converted into a <strong class="bold">pandas</strong> <strong class="bold">DataFrame</strong> (which we will process and analyze in later steps).</p>
<ol>
<li value="12">Flatten each of the<a id="_idIndexMarker1035"/> JSON values stored in the <strong class="source-inline">all_json</strong> list using the following block of code: <pre class="source-code">flattened_json = []</pre><pre class="source-code">for entry in all_json:</pre><pre class="source-code">    result = <strong class="bold">flatten</strong>(entry, reducer='dot')</pre><pre class="source-code">    flattened_json.append(result)</pre><pre class="source-code">    </pre><pre class="source-code">flattened_json</pre></li>
<li>Next, load the flattened structure into a pandas DataFrame:<pre class="source-code">import pandas as pd</pre><pre class="source-code">df = pd.<strong class="bold">DataFrame</strong>(flattened_json)</pre><pre class="source-code">df</pre></li>
</ol>
<p class="list-inset">This should yield a DataFrame similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer272">
<img alt="Figure 8.14 – DataFrame containing the collected monitoring data  " height="346" src="image/B18638_08_014.jpg" width="1083"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.14 – DataFrame containing the collected monitoring data </p>
<p class="list-inset">Here, we can see the collected endpoint data flattened inside a DataFrame. </p>
<ol>
<li value="14">Now, let’s clean <a id="_idIndexMarker1036"/>things up a bit by extracting the <em class="italic">x</em> and <em class="italic">y</em> values from the DataFrame column, <strong class="source-inline">captureData.endpointInput.data</strong>, which contains the input request data:<pre class="source-code">df[['<strong class="bold">x</strong>', '<strong class="bold">y</strong>']] = df['captureData.endpointInput.data'].str.split(',', 1, expand=True)</pre></li>
<li>After that, let’s extract the <strong class="source-inline">label</strong> value from the DataFrame column, <strong class="source-inline">captureData.endpointOutput.data</strong>, which contains the output response data. Store the <strong class="source-inline">label</strong> values inside a new column called <strong class="source-inline">predicted_label</strong>:<pre class="source-code">df['<strong class="bold">predicted_label</strong>'] = df['captureData.endpointOutput.data'].str.strip()</pre></li>
<li>Let’s prepare the <strong class="source-inline">clean_df</strong> DataFrame, which only contains three columns from the original <strong class="source-inline">DataFrame</strong> – <strong class="source-inline">predicted_label</strong>, <strong class="source-inline">x</strong>, and <strong class="source-inline">y</strong>: <pre class="source-code">clean_df = df[['<strong class="bold">predicted_label</strong>', '<strong class="bold">x</strong>', '<strong class="bold">y</strong>']]</pre><pre class="source-code">clean_df.<strong class="bold">head()</strong></pre></li>
</ol>
<p class="list-inset">This should give us a DataFrame similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer273">
<img alt="Figure 8.15 – DataFrame containing the values for predicted_label, x, and y " height="285" src="image/B18638_08_015.jpg" width="956"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.15 – DataFrame containing the values for predicted_label, x, and y</p>
<p class="list-inset">Here, we can see that some values of the <strong class="source-inline">y</strong> column are integers, while some values are in floating-point format. </p>
<ol>
<li value="17">Next, let’s<a id="_idIndexMarker1037"/> typecast the values stored in the <strong class="source-inline">clean_df</strong> DataFrame using the <strong class="source-inline">astype</strong> method:<pre class="source-code">clean_df = clean_df.<strong class="bold">astype</strong>({</pre><pre class="source-code">    'predicted_label': 'int',</pre><pre class="source-code">    'x': 'float',</pre><pre class="source-code">    'y': 'float',</pre><pre class="source-code">})</pre><pre class="source-code">clean_df.head()</pre></li>
</ol>
<p class="list-inset">This should give us a DataFrame similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer274">
<img alt="Figure 8.16 – Values for x and y cast into floating-point values " height="295" src="image/B18638_08_016.jpg" width="898"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.16 – Values for x and y cast into floating-point values</p>
<p class="list-inset">Now, everything is in floating-point format under the <strong class="source-inline">x</strong> and <strong class="source-inline">y</strong> columns. </p>
<p>At this point, we can run different types of analysis, such as computing different types of statistics manually, similar to what is performed automatically by <strong class="bold">SageMaker Model Monitor</strong>. We can also use this approach to troubleshoot data encoding issues encountered by the <a id="_idIndexMarker1038"/>Model Monitor processing job when analyzing the collected data, similar to what we have at <a href="https://github.com/aws/sagemaker-python-sdk/issues/1896">https://github.com/aws/sagemaker-python-sdk/issues/1896</a>.</p>
<h1 id="_idParaDest-171"><a id="_idTextAnchor183"/>Deleting an endpoint with a monitoring schedule</h1>
<p>Now that <a id="_idIndexMarker1039"/>we are done using our <a id="_idIndexMarker1040"/>ML inference endpoint, let’s delete it, along with the attached monitors and monitoring schedules.</p>
<p>Follow these steps to list all the attached monitors of our ML inference endpoint and delete any attached monitoring schedules, along with the endpoint:</p>
<ol>
<li value="1">Create a new Notebook by clicking the <strong class="bold">File</strong> menu and choosing <strong class="bold">Notebook</strong> from the list of options under the <strong class="bold">New</strong> submenu.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Note that we will be creating the new notebook inside the <strong class="source-inline">CH08</strong> directory beside the other notebook files we created in the previous sections of this chapter.</p>
<ol>
<li value="2">In the <strong class="bold">Set up notebook environment</strong> window, specify the following configuration values:<ul><li><strong class="bold">Image</strong>: <strong class="source-inline">Data Science</strong> (option found under <strong class="bold">SageMaker image</strong>)</li>
<li><strong class="bold">Kernel</strong>: <strong class="source-inline">Python 3</strong></li>
<li><strong class="bold">Start-up script</strong>: <strong class="source-inline">No script</strong> </li>
</ul></li>
</ol>
<p class="list-inset">Click the <strong class="bold">Select</strong> button afterward. </p>
<ol>
<li value="3">Right-click on the tab name of the new Notebook and select <strong class="bold">Rename Notebook…</strong> from the list of options in the context menu. In the <strong class="bold">Rename File</strong> popup, specify <strong class="source-inline">06 - Deleting an Endpoint with a Monitoring Schedule.ipynb</strong> under <strong class="bold">New Name</strong>. Click the <strong class="bold">Rename</strong> button.</li>
<li>Now that<a id="_idIndexMarker1041"/> we<a id="_idIndexMarker1042"/> have our new notebook ready, let’s use the <strong class="source-inline">%store</strong> magic from IPython to load the stored variable value for <strong class="source-inline">endpoint_name</strong>:<pre class="source-code">%store -r <strong class="bold">endpoint_name</strong></pre></li>
<li>Initialize the <strong class="source-inline">Predictor</strong> instance and attach it to an existing ML inference endpoint using the following block of code:<pre class="source-code">import sagemaker</pre><pre class="source-code">from sagemaker import get_execution_role</pre><pre class="source-code">from sagemaker.predictor import Predictor</pre><pre class="source-code">session = sagemaker.Session()</pre><pre class="source-code">role = get_execution_role()</pre><pre class="source-code">predictor = <strong class="bold">Predictor</strong>(</pre><pre class="source-code">    endpoint_name=<strong class="bold">endpoint_name</strong>,</pre><pre class="source-code">    sagemaker_session=session,</pre><pre class="source-code">    role=role</pre><pre class="source-code">)</pre></li>
<li>Let’s quickly list any attached monitors before deleting them in the next step:<pre class="source-code">monitors = predictor.<strong class="bold">list_monitors()</strong></pre><pre class="source-code">for monitor in monitors:</pre><pre class="source-code">    print(monitor.<strong class="bold">__dict__</strong>)</pre></li>
</ol>
<p class="list-inset">Here, we used the <strong class="source-inline">__dict__</strong> attribute to inspect the properties of the monitor instances.</p>
<ol>
<li value="7">Let’s use the <strong class="source-inline">delete_monitoring_schedule()</strong> method to delete each of the monitors:<pre class="source-code">for monitor in monitors:</pre><pre class="source-code">    monitor.<strong class="bold">delete_monitoring_schedule()</strong></pre></li>
</ol>
<p class="list-inset">This should yield an output similar to <strong class="source-inline">Deleting Monitoring Schedule with name: monitor-HWFEL</strong>.</p>
<ol>
<li value="8">Finally, let’s delete the inference endpoint using the <strong class="source-inline">delete_endpoint()</strong> method:<pre class="source-code">predictor.<strong class="bold">delete_endpoint()</strong></pre></li>
</ol>
<p>Make sure<a id="_idIndexMarker1043"/> that <a id="_idIndexMarker1044"/>you also stop the execution of any running cells in the notebooks that were used in this chapter.</p>
<h1 id="_idParaDest-172"><a id="_idTextAnchor184"/>Cleaning up</h1>
<p>Now that we<a id="_idIndexMarker1045"/> have finished working on the hands-on solutions of this chapter, it is time we clean up and turn off any resources we will no longer use. Follow these steps to locate and turn off any remaining running instances in <strong class="bold">SageMaker Studio</strong>:</p>
<ol>
<li value="1">Click the <strong class="bold">Running Instances and Kernels</strong> icon in the sidebar, as highlighted in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer275">
<img alt="Figure 8.17 – Turning off the running instance " height="303" src="image/B18638_08_017.jpg" width="1010"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.17 – Turning off the running instance</p>
<p class="list-inset">Clicking the <strong class="bold">Running Instances and Kernels</strong> icon should open and show the running instances, apps, and terminals in SageMaker Studio.</p>
<ol>
<li value="2">Turn off all running instances under <strong class="bold">RUNNING INSTANCES</strong> by clicking the <strong class="bold">Shutdown</strong> button for each of the instances, as highlighted in the preceding screenshot. Clicking the <strong class="bold">Shutdown</strong> button will open a popup window verifying the instance<a id="_idIndexMarker1046"/> shutdown operation. Click the <strong class="bold">Shut down all</strong> button to proceed.</li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">Make sure that you close the open notebook tabs in the <strong class="bold">Editor</strong> pane. In some cases, SageMaker will automatically turn on an instance when it detects that there are open notebook tabs.</p>
<ol>
<li value="3">Make sure that you check and delete all running inference endpoints under <strong class="bold">SageMaker resources</strong> as well (if any):</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer276">
<img alt="Figure 8.18 – Checking the list of running inference endpoints " height="601" src="image/B18638_08_018.jpg" width="990"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.18 – Checking the list of running inference endpoints</p>
<p class="list-inset">To check if there are running inference endpoints, click the <strong class="bold">SageMaker resources</strong> icon, as highlighted in the preceding screenshot, and then select <strong class="bold">Endpoints</strong> from the list of options in the drop-down menu.</p>
<ol>
<li value="4">Finally, open the <strong class="bold">File</strong> menu and select <strong class="bold">Shut down</strong> from the list of options available. This should ensure that all running instances inside SageMaker Studio have been turned off as well.</li>
</ol>
<p>Note that this cleanup <a id="_idIndexMarker1047"/>operation needs to be performed after using <strong class="bold">SageMaker Studio</strong>. These resources are not turned off automatically by SageMaker, even during periods of inactivity.</p>
<h1 id="_idParaDest-173"><a id="_idTextAnchor185"/>Summary</h1>
<p>In this chapter, we utilized the model registry available in SageMaker to register, organize, and manage our ML models. After deploying ML models stored in the registry, we used <strong class="bold">SageMaker Model Monitor</strong> to capture data and run processing jobs that analyze the collected data and flag any detected issues or deviations.</p>
<p>In the next chapter, we will focus on securing ML environments and systems using a variety of strategies and solutions. If you are serious about designing and building secure ML systems and environments, then the next chapter is for you!</p>
<h1 id="_idParaDest-174"><a id="_idTextAnchor186"/>Further reading</h1>
<p>For more information on the topics that were covered in this chapter, feel free to check out the following resources:</p>
<ul>
<li><em class="italic">SageMaker Model Registry – Viewing the Deployment History</em> (<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy-history.xhtml">https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy-history.xhtml</a>)</li>
<li><em class="italic">SageMaker Model Monitor – Monitor models for data and model quality, bias, and explainability</em> (<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.xhtml">https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.xhtml</a>)</li>
<li><em class="italic">SageMaker Python SDK — Amazon SageMaker Model Monitor</em> (<a href="https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.xhtml">https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.xhtml</a>)</li>
</ul>
</div>
<div>
<div id="_idContainer278">
</div>
</div>
</div>
</body></html>