- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Identify Azure Tools and Services for Computer Vision Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B22207_06.xhtml#_idTextAnchor112), *Identify Common Types of
    Computer Vision Solutions*, you learned how to identify common types of computer
    vision solutions capabilities surrounding image classification, object detection,
    **optical character recognition** (**OCR**), facial detection, and facial analysis.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will explore the use of the **Azure AI Vision Studio tool**
    and the **Azure AI Vision** service, which allows you to analyze images, read
    text, and provide spatial analysis. You will then explore the **Azure AI Face**
    service, which allows you to detect and recognize faces and attributes in images.
    Finally, you will discover the **Azure AI Video Indexer** service, which is a
    video and audio analytics service that allows insights to be extracted using machine
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: This content requires some understanding of machine learning principles; if
    you have skipped straight to this chapter and are new to machine learning or just
    want to refresh on some existing knowledge, then please refer to *Part 2 – Fundamental
    Principles of Machine Learning on Azure*, as a machine learning primer before
    you continue with this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The Azure AI services of **Vision**, **Face**, and **Video Indexer** provide
    *pre-built* and *customizable* machine learning models that can be used by developers
    to enhance their applications. This allows you to add AI services with fewer skills,
    cost, and complexity and provides faster time to value and faster time to market,
    providing a competitive edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objectives and skills we’ll cover in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Describe capabilities of the Azure AI Vision service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe capabilities of the Azure AI Face service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe capabilities of the Azure AI Video Indexer service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you should be aware of the capabilities of the aforementioned
    Azure AI services.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started with the **Azure AI services** mentioned in this chapter, you
    will need an **Azure subscription** with sufficient access to create and delete
    resources. You can create a free Azure account for evaluation by going to [https://azure.microsoft.com/free/](https://azure.microsoft.com/free/).
  prefs: []
  type: TYPE_NORMAL
- en: 'This free Azure account provides the following:'
  prefs: []
  type: TYPE_NORMAL
- en: $200 credit to explore Azure for 30 days
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 12 months of free popular services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 55+ other services that are always free
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have an Azure subscription in place, you need either the **Owner**
    or **Contributor** role at the *resource group* or *resource* level.
  prefs: []
  type: TYPE_NORMAL
- en: 'To evaluate computer vision, you can create a “single service resource” or
    a “multi-service resource”; each can be explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure AI Vision**: This is an example of a specific *single service resource*.
    This resource can be used with the “free tier” of the Azure AI services you may
    wish to evaluate; it uses an *endpoint* and a *key* that are unique for *each
    single* Azure AI service. So, if you use multiple Azure AI services, then you
    will have multiple endpoints and keys (one endpoint and key for each service).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure AI Services**: This is a general *multi-service resource*. This resource
    provides billing consolidation for *all used service resources* through the use
    of a *single key* and *endpoint*. So, if you use multiple Azure AI services, then
    you will have just one endpoint and just one key that can access all the services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding workspaces or compute resources isn’t required; only an Azure
    AI resource needs to be created within your Azure subscription.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about service resources at [https://learn.microsoft.com/en-us/azure/ai-services/multi-service-resource](https://learn.microsoft.com/en-us/azure/ai-services/multi-service-resource).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve looked at the technical requirements for working with the Azure
    AI services that will be covered in this chapter, let’s discover the first of
    the Azure AI services: Azure AI Vision.'
  prefs: []
  type: TYPE_NORMAL
- en: Describe capabilities of the Azure AI Vision service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Azure AI Vision** service is a *cloud-based Microsoft-hosted AI* service
    that provides machine learning algorithms that allow you to analyze the visual
    features and characteristics of an image, moderate image content, and extract
    text from images.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Azure AI Vision service provides the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Analysis**: This capability can be used to return information on image
    characteristics and visual features. It includes the following model capabilities:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add captions and dense captions to images
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign labels to images with tags
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect objects in images, such as people
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect multiple instances of products
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect brands
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect color schemes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect sensitive information in images, such as adult content (including “racy”
    or “gory” content)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Create custom image classification and object detection models that can be trained
    on your collection of images
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect damaged/non-conforming products using custom models
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You can learn more at [https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-image-analysis](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-image-analysis).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**OCR**: This capability, sometimes also referred to as text recognition or
    text extraction, is based on machine learning and allows printed or handwritten
    text to be extracted from the likes of **documents**, such as forms, invoices,
    expense receipts, and **images**, which could include vehicle number plates, street
    signs, product brand labels, names on movie posters, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can learn more at [https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-ocr](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-ocr).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Face**: This capability provides machine learning for detecting human faces
    in an image; it can provide recognition and analysis to extract attributes such
    as age, glasses, facial hair, and pose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can learn more at [https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-identity](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-identity).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The Foundation model that’s used for the tasks of computer vision is the **Microsoft
    Florence model**. It is “pre-trained” on vast amounts of captioned internet images
    to build models that can be used for image analysis tasks, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image classification**: Identify an image category and add labels to the
    image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object detection**: Identify an object’s location in an image, photo, or
    video'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Captioning**: Generate human-readable descriptions for everything that appears
    in images, such as a photo'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tagging**: Generate a list of tags that can be associated with an image for
    its detected attributes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The capabilities for the models of the **Azure AI Vision** service can analyze
    an image, at which point one more **label** can be applied based on its understanding
    of the contents.
  prefs: []
  type: TYPE_NORMAL
- en: '**Labels** are identified as belonging to an image; the image can be associated
    with one or more labels. You can think of this as adding **attributes** to the
    image. The service’s capabilities mean it can also be used with documents as well
    as photographs.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure AI Vision Studio**, shown in *Figure 7**.1*, is a public web-based
    portal that can be used to perform image analysis tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – The Azure AI Vision Studio portal](img/B22207_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – The Azure AI Vision Studio portal
  prefs: []
  type: TYPE_NORMAL
- en: You can get started with **Azure AI Vision Studio** at [https://portal.vision.cognitive.azure.com/](https://portal.vision.cognitive.azure.com/).
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.2* shows an example of **image analysis** when using the **Azure
    AI Vision** service. It can generate a human-readable sentence as a description
    of the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Image captioning information provided via Azure AI Vision Studio](img/B22207_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Image captioning information provided via Azure AI Vision Studio
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.2* shows an example of image analysis using the **Azure AI Vision**
    service. It can **caption** an image and generate a human-readable **sentence**
    that acts as the **description** of the image; the caption reads “a car with a
    red seat and a fence in the background.”'
  prefs: []
  type: TYPE_NORMAL
- en: The **Azure AI Vision** service models’ capabilities can analyze an image; a
    **label** can be applied based on its understanding of the contents.
  prefs: []
  type: TYPE_NORMAL
- en: '**Categorization** is a “parent/child hierarchy structure;” there are *86 categories*,
    with all the names in English. *Figure 7**.3* shows an example of this category’s
    taxonomy and structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Category topology example](img/B22207_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Category topology example
  prefs: []
  type: TYPE_NORMAL
- en: The full “text format” topology shown in *Figure 7**.3* can be found at [https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/category-taxonomy](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/category-taxonomy).
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about how images are categorized at [https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-categorizing-images](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-categorizing-images).
  prefs: []
  type: TYPE_NORMAL
- en: In this subsection, you discovered image classification when using the Azure
    AI Vision service. In the next subsection, you’ll learn about object detection.
  prefs: []
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Where **image classification** provides us with categorization and can tell
    us of singular information – that is, there is a “person,” “car,” “cat,” and so
    on in the image – **object detection** provides individual **location information**
    for objects in the image, in addition to the “categorization” and “caption labels”
    provided by the classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiple objects** can also be identified in an image. For each object that’s
    found in the image, the detected attributes will be returned by the API. The individual
    location of the object in the image is found by providing the coordinates of a
    **bounding box** (*in pixels*) returned by the **Image Analysis API**. This information
    can be used to provide a relationship between objects in the image.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure AI Vision Studio**, shown in *Figure 7**.4*, is a public web-based
    portal that can be used to perform object detection tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – TheAzure AI Vision Studio portal](img/B22207_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – TheAzure AI Vision Studio portal
  prefs: []
  type: TYPE_NORMAL
- en: You can get started with **Azure AI Vision Studio** at [https://portal.vision.cognitive.azure.com/](https://portal.vision.cognitive.azure.com/).
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.5* shows an example of using object detection in an image via **Azure
    AI** **Vision Studio**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – Object detection information provided via Azure AI Vision Studio](img/B22207_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – Object detection information provided via Azure AI Vision Studio
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.5* shows an example of **image analysis** when using the **Azure
    AI Vision** service to generate detections regarding **car** and **Tire**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The object’s location is provided within a **bounding box** as a **pixel value**
    within the image; **Tag** information will also be retrieved from the image. The
    **JavaScript Object Notation** (**JSON**) information that’s returned by the API
    is as follows for the image shown in *Figure 7**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It should be noted that this service does not use a **regression** or **clustering**
    model but an **Image** **Analysis** model.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can learn more at the following URLs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-object-detection-40](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-object-detection-40)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-describe-images-40](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-describe-images-40)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This section identified the capabilities of object detection solutions using
    the Azure AI Vision service. In the next section, you will learn how to identify
    the capabilities of OCR solutions using Azure AI Vision.
  prefs: []
  type: TYPE_NORMAL
- en: OCR solutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Azure AI Vision service** can be used as a solution for **OCR**.
  prefs: []
  type: TYPE_NORMAL
- en: Through the capabilities of OCR, this service enables you to “extract” text
    information from photographs, scanned documents, or any other visual content.
    The **Read API** can recognize printed and handwritten text across languages.
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure AI Vision Studio**, shown in *Figure 7**.6*, is a public web-based
    portal that can be used to perform OCR tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – The Azure AI Vision Studio portal](img/B22207_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – The Azure AI Vision Studio portal
  prefs: []
  type: TYPE_NORMAL
- en: You can get started with **Azure AI Vision Studio** at [https://portal.vision.cognitive.azure.com/](https://portal.vision.cognitive.azure.com/).
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.7* shows an example of using **OCR** via **Azure AI Vision Studio**
    to extract the “printed text” located in the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – Extracting text from an image by using the OCR capability via
    Azure AI Vision Studio](img/B22207_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – Extracting text from an image by using the OCR capability via Azure
    AI Vision Studio
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more at [https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-ocr](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-ocr).
  prefs: []
  type: TYPE_NORMAL
- en: This section looked at identifying the capabilities of OCR solutions using the
    Azure AI Vision service. In the next section, you will learn how to identify the
    capabilities of face detection via the Azure AI Face service.
  prefs: []
  type: TYPE_NORMAL
- en: Describe the capabilities of the Azure AI Face service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Azure AI Face** service is a part of **Microsoft Azure’s** **AI** services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Face** service provides capabilities for detecting and recognizing human
    faces in images, as well as extracting various facial attributes. Some key features
    and functionalities of the Microsoft Azure AI Face service are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Face Detection**: Identify and locate human faces within an image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Face Recognition**: Associate detected faces with previously known faces
    in a dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Face Verification**: Confirm whether two faces in an image are of the same
    person or not'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Facial Landmarks Detection**: Identify key facial features such as eyes,
    nose, and mouth'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Face Similarity Matching**: Determine the similarity between faces for potential
    use in applications such as face-based authentication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developers can integrate the **Azure AI Face** service into their applications
    using a **REST API**.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you were introduced to the Azure AI Face service. In the next
    section, you will understand what you’ll need to start using it.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To get started with Face, you will need to create resources within an Azure
    subscription, as covered in the *Technical requirements* section. One of the following
    is required:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Face Azure resource**: This resource will be used to create a *dedicated*
    endpoint and key for this *specific* Azure AI service. You will be billed for
    the consumption of this AI service independently of any other Azure AI service.
    This is best suited if you’re not using any other Azure AI services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure AI services Azure resource**: This resource will be used to create
    a *shared* endpoint and key that will be used for all Azure AI services you wish
    to use. You will have an aggregated bill for the consumption of all AI services
    you use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure AI Vision Studio**, shown in *Figure 7**.8*, is a public web-based
    portal that can be used to perform these tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8 – The Azure AI Vision Studio portal](img/B22207_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – The Azure AI Vision Studio portal
  prefs: []
  type: TYPE_NORMAL
- en: You can get started with **Azure AI Vision Studio** at [https://portal.vision.cognitive.azure.com/](https://portal.vision.cognitive.azure.com/).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned what’s required to get started with the Azure AI
    Face service. We will look at the Azure AI Face service’s capabilities in the
    following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Facial detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This capability can take an image and identify human faces within it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Azure AI Face** service provides an API for facial detection and recognition
    within images. It can detect attributes and return the pixel coordinates to locate
    the face(s) in the image. *Figure 7**.9* illustrates this capability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Detecting faces using Azure AI Vision Studio](img/B22207_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – Detecting faces using Azure AI Vision Studio
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.9* shows an example of **face detection** using the **Azure AI
    Face** service to extract the human faces located in the image.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of the `mask`, under `faceAttributes`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Please note that the full JSON response that was returned was not included;
    this snippet has only been included for illustrative purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine learning algorithms that are *pre-built* with the **Azure AI Face**
    service can identify the following face-related attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accessories**: This refers to whether the face is wearing accessories, such
    as headwear, glasses, or a mask; a confidence score will also be returned'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blur**: This refers to whether there is a lack of focus on the image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exposure**: This refers to whether faces in the image are overexposed or
    underexposed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Occlusion**: This refers to whether the face may be blocked by an object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Noise**: This refers to visual noise, where an image has reduced clarity
    through tiny dots, and grainy appearance, such as for photos with darker settings
    where a high ISO has been used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pose**: This refers to the face’s orientation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the *Responsible AI* section to learn more about how to retire attribute
    detection such as emotion, age, and facial hair.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following should be considered for better detection results for the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Format**: BMP, GIF (*first frame*), JPEG, PNG'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**File size**: 6 MB maximum'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Face size**: 36 x 36 minimum and 4,096 x 4,096 maximum size range to be able
    to be detected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rotation**: Images must be rotated correctly; for some images, such as those
    in JPEG format, this may be done automatically through their **Exchangeable Image
    File Format** (**EXIF**) metadata'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Additionally**: The accuracy will be reduced when the images have extreme
    face angles, lighting, and object blocking (occlusion)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to the *video input*, the following settings should be considered
    for clearer video frame results:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Shutter angle**: A lower shutter angle should be used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shutter speed**: Reduce the amount of motion between frames'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Smoothing**: This should be turned off'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each face that’s detected in an image by the Face service, you can request
    a **Face ID** via the **Face Detect API**. This is a *unique* *identifier* string.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following API operations can be performed using the Face service:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identify**: This is a one-to-many operation to find the match closest to
    a queried person from a known person database/security repository (**Person group**).
    This takes **Face IDs** from a **Detected Face** object and returns a list of
    **Person objects** with a **confidence prediction** value that the detected face
    may belong to – that is, is this the person being claimed?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each **Person group** (security repository/database of person objects) can have
    a maximum number of Person objects of 1 million; a maximum of 248 faces can be
    registered for each Person object in the Person group.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Verify**: This a one-to-one operation that validates if the Face ID for the
    detected face in the image matches the Person object from the security repository/database
    – that is, are these two faces the same person?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Find Similar**: This is a face search operation that can take a Face ID and
    find other candidates’ face images in a face list that are matched as similar;
    it can answer the questions of whether all the faces belong together, or whether
    this person looks like other people. The working modes are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**matchPerson**: This uses the **Verify API** to return filtered similar faces.
    This means the results that are returned can only be images of the target face.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**matchFace**: This returns a list of candidates’ faces similar to the Face
    ID, but they may not be the face of that person; the filter of **same-person**
    is ignored. This means the results will not necessarily contain the target face
    in the returned images.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Group**: This is an operation that’s based on similarity; unknown faces of
    similar candidates are divided into smaller groups. This means the likelihood
    is that all returned faces are of the same person, but that person can have different
    groups where a factor such as a facial expression can be used to differentiate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Azure AI Face service** can analyze two faces and determine whether they
    belong to the same person; if the face that’s identified is verified against an
    identity data store, then some action could be taken based on this verification.
  prefs: []
  type: TYPE_NORMAL
- en: These actions form the basis of security protocols through **Authentication**
    (**AuthN**) and **Authorization** (**AuthZ**) – that is, verifying “who you say
    you are” and “what you have access to,”
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more at [https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-identity](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-identity).
  prefs: []
  type: TYPE_NORMAL
- en: You can try out face detection at [https://portal.vision.cognitive.azure.com/gallery/face](https://portal.vision.cognitive.azure.com/gallery/face).
  prefs: []
  type: TYPE_NORMAL
- en: Responsible AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the previous capabilities are available to all to use, to support Microsoft’s
    **Responsible AI Standard**, there are additional **Face Service** capabilities
    for face matching and identifying named individuals available to “Managed Microsoft”
    customers through a limited access policy.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more at [https://aka.ms/facerecognition](https://aka.ms/facerecognition).
  prefs: []
  type: TYPE_NORMAL
- en: You should be aware that the capabilities of facial recognition, such as emotion,
    smile, gender, age, makeup, facial hair, and hair, and others, which can infer
    emotional states and identity attributes, have been retired by Microsoft so that
    they’re not misused as this may lead to a denial of service attack, discrimination,
    and stereotyping.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more at [https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/](https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following guiding principles of responsible AI are adhered to:'
  prefs: []
  type: TYPE_NORMAL
- en: Accountability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inclusiveness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reliability and safety
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fairness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transparency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy and security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, you learned about Microsoft’s positioning on responsible AI.
    Next, we will look at the Azure AI Video Indexer service.
  prefs: []
  type: TYPE_NORMAL
- en: Describe capabilities of the Azure AI Video Indexer service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The computer vision capabilities of Azure ML can be used as a solution for analyzing
    and extracting insights and metadata from video and audio media files, as well
    as detecting and identifying faces in video.
  prefs: []
  type: TYPE_NORMAL
- en: 'The use cases for the **Azure AI Video Indexer** service are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Accessibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content creation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content moderation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monetization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Azure AI Video Indexer** service uses machine learning algorithms and
    can be used to perform these tasks. It is built on the **Azure AI services** of
    **Azure AI Vision**, **Face**, **Speech**, and **Translator**. There are 30+ models
    available that retrieve video and audio content insights.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Azure AI Video Indexer service** can retrieve insights from video files
    using the following models:'
  prefs: []
  type: TYPE_NORMAL
- en: Account-based face identification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Black frame detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Celebrity identification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Editorial shot type detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Face detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keyframe extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labels identification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matched person
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OCR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observed people tracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rolling credits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scene segmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shot detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slate detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Textual logo detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thumbnail extraction for faces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual content moderation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **Azure AI Video Indexer** service can retrieve insights from audio files
    using the following models:'
  prefs: []
  type: TYPE_NORMAL
- en: Audio effects detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic language detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Audio transcription
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Closed captioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-language speech identification and transcription
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Noise reduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speaker enumeration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speaker statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text-based emotion detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Textual content moderation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two-channel processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following multi-channel (*audio and video*) models are available:'
  prefs: []
  type: TYPE_NORMAL
- en: Artifacts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keywords extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Named entities extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Topic inference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Azure AI Video Indexer service can be tried out at https://www.videoindexer.ai/.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more at https://learn.microsoft.com/en-us/azure/azure-video-indexer/.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided complete coverage of the *Describe features of computer
    vision workloads on Azure* AI-900 Azure Fundamentals skills area.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you were introduced to the Azure AI Vision Studio tool and
    discovered the capabilities of the Azure AI Vision service regarding image classification,
    object detection, and OCR. You then learned about the Azure Face service, which
    can be used for facial detection, facial analysis, and recognition. Finally, we
    covered the Azure AI Video Indexer service, which can extract insights from video
    and audio files, as well as Microsoft’s positioning on responsible AI.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to describe the various features of
    **natural language processing** (**NLP**) workloads on Azure. NLP supports many
    of the popular commercial AI services available today.
  prefs: []
  type: TYPE_NORMAL
- en: Exam Readiness Drill – Chapter Review Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from a solid understanding of key concepts, being able to think quickly
    under time pressure is a skill that will help you ace your certification exam.
    That is why working on these skills early on in your learning journey is key.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter review questions are designed to improve your test-taking skills progressively
    with each chapter you learn and review your understanding of key concepts in the
    chapter at the same time. You’ll find these at the end of each chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before you proceed
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a Packt Library subscription or you haven't purchased this
    book from the Packt store, you will need to unlock the online resources to access
    the exam readiness drills. Unlocking is free and needs to be done only once. To
    learn how to do that, head over to the chapter titled [*Chapter 12*](B22207_12.xhtml#_idTextAnchor228)*,
    Accessing the* *Online Resources*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To open the Chapter Review Questions for this chapter, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click the link – [https://packt.link/AI-900_CH07](https://packt.link/AI-900_CH07).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, you can scan the following QR code (*Figure 7**.10*):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.10 – QR code that opens Chapter Review Questions for logged-in users](img/B22207_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – QR code that opens Chapter Review Questions for logged-in users
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you log in, you’ll see a page similar to the one shown in *Figure 7**.11*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.11 – Chapter Review Questions for Chapter 7](img/B22207_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 – Chapter Review Questions for Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: Once ready, start the following practice drills, re-attempting the quiz multiple
    times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exam Readiness Drill
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the first three attempts, don’t worry about the time limit.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first time, aim for at least **40%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix your learning gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The second time, aim for at least **60%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix any remaining learning
    gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The third time, aim for at least **75%**. Once you score 75% or more, you start
    working on your timing.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You may take more than **three** attempts to reach 75%. That’s okay. Just review
    the relevant sections in the chapter till you get there.
  prefs: []
  type: TYPE_NORMAL
- en: Working On Timing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your aim is to keep the score the same while trying to answer these questions
    as quickly as possible. Here’s an example of how your next attempts should look
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Attempt** | **Score** | **Time Taken** |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 5 | 77% | 21 mins 30 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 6 | 78% | 18 mins 34 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 7 | 76% | 14 mins 44 seconds |'
  prefs: []
  type: TYPE_TB
- en: Table 7.1 – Sample timing practice drills on the online platform
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The time limits shown in the above table are just examples. Set your own time
    limits with each attempt based on the time limit of the quiz on the website.
  prefs: []
  type: TYPE_NORMAL
- en: With each new attempt, your score should stay above **75%** while your “time
    taken” to complete should “decrease”. Repeat as many attempts as you want till
    you feel confident dealing with the time pressure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 4: Describe Features of Natural Language Processing (NLP) Workloads on
    Azure'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Natural language processing** (**NLP**) is the technology that allows computers
    to identify and understand the relevant parts of human language, including text
    recognition, text analysis, text-to-speech, and speech synthesis. In this part,
    you’ll learn about the NLP capabilities in Azure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This part includes the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B22207_08.xhtml#_idTextAnchor148), *Identify Features of Common
    NLP Workload Scenarios*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B22207_09.xhtml#_idTextAnchor169), *Identify Azure Tools and
    Services for NLP Workloads*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
