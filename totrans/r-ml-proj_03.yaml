- en: Implementing a Jokes Recommendation Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I am sure this is something you have experienced as well: while shopping for
    a cellphone on Amazon, you are also shown some product recommendations of mobile
    accessories, such as screen guards and phone cases. Not very surprisingly, most
    of us end up buying one or more of these recommendations! The primary purpose
    of a recommendation engine in an e-commerce site is to lure buyers into purchasing
    more from vendors. Of course, this is no different from a salesperson trying to
    up-sell or cross-sell to customers in a physical store.'
  prefs: []
  type: TYPE_NORMAL
- en: You may recollect the Customers Who Bought This Item Also Bought This heading
    on Amazon (or any e-commerce site) where recommendations are shown. The aim of
    these recommendations is to get you to buy not just one product but a product
    combo, therefore pushing the sales revenues in an upward direction. Recommendations
    on Amazon are so successful that McKinsey estimated that a whopping 35% of the
    overall sales made on Amazon is due to their recommendations!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the theory and implementation of a recommendation
    engine to suggest jokes to users. To do this, we use the Jester''s jokes dataset
    that is available in the `recommenderlab` library of R. We will cover the following
    major topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Fundamental aspects of recommendation engines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the Jokes recommendation problem and the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation system using an item-based collaborative filtering technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation system using a user-based collaborative filtering technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation system using an association-rule mining technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content-based recommendation engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid recommendation system for Jokes recommendation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fundamental aspects of recommendation engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While the basic intent of showing recommendations is to push sales, they actually
    serve just beyond the better sales concept. Highly personalized content is something
    recommendation engines are able to deliver. This essentially means that recommendation
    engines on a retail platform such as Amazon are able to offer the right content
    to the right customer at the right time through the right channel. It makes sense
    to provide personalized content; after all, there is no point in showing an irrelevant
    product to a customer. Also, with the lower attention spans of customers, businesses
    want to be able to maximize their selling opportunities by showing the right products
    and encouraging them to buy the right products. At a very high level, personalized
    content recommendation is achieved in AI in several ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mapping similar products that were bought together**:Let''s take an example
    of an online shopper who searched for school bags on a shopping website. Very
    likely, the shopper would be interested in buying additional school-related items
    when buying a school bag. Therefore, displaying school bags along with notebooks,
    pencils, pens, and pencil cases ensures a higher probability of additional sales.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommendations based on customer demographics**:Showing high-end phones
    and stylish phone accessories as recommended products to conservative middle class
    customers, who generally look for steal deals, may not fetch a big upswing in
    sales of the recommended products. Instead, such customers might find these irrelevant
    recommendations to be annoying, therefore impacting their loyalty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommendations based on similarities between customers**:Product recommendations
    to a customer are based on the products purchased or liked by other, similar customers.
    For example, recommending a newly-arrived cosmetic product to young women living
    in urban locations. The recommendation in this case is not just because of the
    attributes of the customer but because other customers of a similar type have
    bought this product. As the item grows in popularity among similar individuals,
    the product is chosen as the one to be recommended.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommendations based on product similarities**:If you search for a laptop
    backpack of a particular brand, along with the results of the searched item, you
    are also shown other brand laptop backpacks as recommendations. This recommendation
    is purely based on the similarity between the products.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommendations based on the historical purchase profile of customers**:If
    a customer has always purchased a particular brand of jeans, they are shown recommendations
    of newer varieties of jeans of the particular brand they tend to purchase. These
    recommendations are purely based on the historical purchases of the customer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid recommendations**:It is possible that one or more recommendation approaches
    can be combined to arrive at the best recommendations for a customer. For example,
    a recommendation list can be arrived by using customer preferences inferred from
    the historical data as well as from the demographics information of the customer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repurchase campaigns, newsletter recommendations, rebinding the sales from abandoned
    carts, customized discounts and offers, and smoothened browsing experience of
    e-commerce sites are some of the applications of recommendation systems in the
    online retail industry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to several prevalent use cases, it might appear that recommender systems
    are used in only in the e-commerce industry. However, this is not true. The following
    are some of the use cases of recommender systems in non e-commerce domains:'
  prefs: []
  type: TYPE_NORMAL
- en: In the pharmaceutical industry, recommender systems are applied to identify
    drugs patients with certain characteristics that they will respond better to
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stocks recommendation are done based on the stock picks of a successful group
    of people
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YouTube and online media use a recommendation engine to serve content that is
    similar to the content currently being watched by the user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tourism recommendations are based on tourist spots that the user or similar
    users have visited
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying skills and personality traits of future employees in various roles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the culinary sciences, dishes that go pair together can be explored through
    the application of recommender systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list can grow to an enormous size, given that use cases for recommendation
    systems exist in almost every domain.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of the concept of recommendation systems
    and the value it offers to business, we can now move to our next section, where
    we attempt to understand the Jester's Jokes recommendation dataset and the problems
    that could be solved by building a recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation engine categories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prior to implementing our first recommender system, let''s explore the types
    of recommender systems in detail. The following diagram shows the broad categories
    of recommender systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1fadf08c-415c-415c-81d3-ef14bdba4077.png)'
  prefs: []
  type: TYPE_IMG
- en: Recommender system categories
  prefs: []
  type: TYPE_NORMAL
- en: Each of the techniques shown in the diagram may be used to build a recommender
    system model that is capable of suggesting jokes to the users. Let's briefly explore
    the various recommendation engine categories.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cognitive filtering, or content-based filtering, recommends items by comparing
    product attributes and customer profile attributes. The attributes of each product
    is represented as a set of tags or terms—typically the words that occur in a product
    description document. The customer profile is represented with the same terms
    and built by analyzing the content of products that have been seen or rated by
    the customer.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Social filtering, or collaborative filtering, filters information by using the
    recommendations of other people. The principle behind collaborative filtering
    is that the customers who have appreciated the same items in the past have a high
    probability of displaying similar interests in the future as well.
  prefs: []
  type: TYPE_NORMAL
- en: We generally ask for reviews and recommendation from friends prior to watching
    a movie. A recommendation from a friend is more accepted than recommendations
    from others as we share some interests with our friends. This is the same principle
    on which collaborative filtering works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Collaborative filtering can be further classified into memory-based and model-based
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory-based**: In this method, user rating information is used to compute
    the likeness between users or items. This computed likeness is then used to come
    up with recommendations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model based**: Data mining methods are applied to recognize patterns in the
    data, and the learned patterns are then used to generate recommendations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this class of recommendation systems, we combine more than one type of recommendation
    system to come up with final recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started, you will have to download the supporting files from the GitHub
    link.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Jokes recommendation problem and the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Dr. Ken Goldberg and his colleagues, Theresa Roeder, Dhruv Gupta, and Chris
    Perkins, introduced a dataset to the world through their paper *Eigentaste: A
    Constant Time Collaborative Filtering Algorithm*, which is pretty popular in the
    recommender-systems domain. The dataset is named the Jester''s jokes dataset.
    To create it, a number of users are presented with several jokes and they are
    asked to rate them. The ratings provided by the users for the various jokes formed
    the dataset. The data in this dataset is collected between April 1999 and May
    2003\. The following are the attributes of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Over 11,000,000 ratings of 150 jokes from 79,681 users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each row is a user (Row 1 = User #1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each column is a joke (Column 1 = Joke #1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ratings are given as real values from -10.00 to +10.00; -10 being the lowest
    possible rating and 10 being the highest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 99 corresponds to a null rating
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `recommenderlab` package in R provides a subset of this original dataset
    provided by Dr. Ken Goldberg's group. We will make use of this subset for our
    projects covered in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The `Jester5k` dataset provided in the `recommenderlab` library contains a 5,000
    x 100 rating matrix (5,000 users and 100 jokes) with ratings between -10.00 and
    +10.00\. All selected users have rated 36 or more jokes. The dataset is in the
    `realRatingMatrix` format. This is a special matrix format that the `recommenderlab`
    expects the data to be in, to apply the various functions that are packaged in
    the library.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are already aware, **exploratory data analysis** (**EDA**) is the first
    step for any data science project. Going by this principle, let''s begin by reading
    the data, and then proceed with the EDA step on the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The data structure output is pretty self explanatory and we see it provides
    empirical evidence for the details we have discussed already. Let''s continue
    our EDA further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We will print the summary of the dataset using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now plot the histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e25c8393-971a-4c48-8978-0889a87024b8.png)'
  prefs: []
  type: TYPE_IMG
- en: From the output, we see a somewhat normal distribution. It can also be seen
    that the positive ratings outnumber the negative ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Jester5K` dataset also provides a character vector called `JesterJokes`.
    The vector is of length 100\. These are the actual 100 jokes among others that
    were shown to the users to get the ratings. We could examine the jokes with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on the 5,000 user ratings we have, we could perform additional EDA to
    identify the joke that is rated as best by the users. This can be done through
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We could perform additional EDA to visualize the univariate and multivariate
    analysis. This exploration will help us understand each of the variables in detail
    as well as the relationship between them. While we do not delve deep into each
    of these aspects, here are some thoughts that can be explored:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the users who always provide high ratings to most jokes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correlation between the ratings provided to jokes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identification of users that are very critical
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the most popular jokes or least popular jokes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying the jokes with the fewest ratings and identifying the associations
    between them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting the DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to use functions from an R library called `recommenderlab` to build
    recommendation engine projects in this chapter. Irrespective of the category of
    recommendation system we implement, there are some prerequisites that the dataset
    needs to satisfy to be able to apply the `recommenderlab` functions. The prebuilt
    `recommenderlab` functions for collaborative filtering expects `realRatingMatrix`
    to be supplied as input. In our case, the `Jester5k` dataset is already in this
    format, therefore, we could directly use this matrix to apply the `recommenderlab`
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In case, we were to have our data as a R DataFrame and if we intend to convert
    into `realRatingMatrix`, the following steps may be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert the DataFrame into an R matrix as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the resultant matrix into `realRatingMatrix` with the help of the `as()`
    function as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we assume that the name of the DataFrame is `df`, the code will convert
    it into a `realRatingMatrix` that can be used as input to the `recommenderlab`
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Dividing the DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another prerequisite is to divide the dataset into train and test subsets.
    These subsets will be used in later sections to implement our recommendation systems
    and to measure the performance. The `evaluationScheme()` function from the `recommenderlab`
    library can be used to split the dataset into training and testing subsets. A
    number of user-specified parameters can be passed to this function. In the following
    code, `realRatingMatrix` is split according to an 80/20 training/testing split,
    with up to 20 items recommended for each user. Furthermore, we specify that any
    rating greater than `0` is to be considered a positive rating, in conformance
    with the predefined `[-10, 10]` rating scale. The `Jester5k` dataset can be divided
    into the train and test datasets with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: From the output of the `evaluationScheme()` function, we can observe that the
    function yielded a single R object containing both the training and test subsets.
    This object will be used to define and evaluate a variety of recommender models.
  prefs: []
  type: TYPE_NORMAL
- en: Building a recommendation system with an item-based collaborative filtering
    technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `recommenderlab` package of R offers the **item-based collaborative filtering**
    (**ITCF**) option to build a recommendation system. This is a very straightforward
    approach that just needs us to call the function and supply it with the necessary
    parameters. The parameters, in general, will have a lot of influence on the performance
    of the model; therefore, testing each parameter combination is the key to obtaining
    the best model for recommendations. The following are the parameters that can
    be passed to the `Recommender` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data normalization**: Normalizing the ratings matrix is a key step in preparing
    the data for the recommendation engine. The process of normalization processes
    the ratings in the matrix by removing the rating bias. The possible values for
    this parameter are `NULL`, `Center`, and `Z-Score`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distance**: This represents the type of similarity metric to be used within
    the model. The possible values for this parameter are Cosine similarity, Euclidean
    distance, and Pearson''s correlation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With these parameter combinations, we could build and test 3 x 3 ITCF models. The
    basic intuition behind ITCF is that if a person likes item A, there is a good
    probability that they like item B as well, as long as items A and B are similar.
    It may be understood that the term *similar* does not indicate similarity between
    the items based on the item''s attributes, but, a similarity in user preferences,
    for example, a group of people that liked items A also liked item B. The following
    diagram shows the working principle of ITCF:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c3012d9-a348-4945-b0e0-b9ac887cc18f.png)'
  prefs: []
  type: TYPE_IMG
- en: Example showing the working of item based collaborative filtering
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore the diagram in a little more detail. In ITCF, the watermelon and
    grapes will form the similar-items neighborhood, which means that irrespective
    of users, different items that are equivalent will form a neighborhood. So when
    user X likes watermelon, the other item from the same neighborhood, which is grapes,
    will be recommended by the recommender system based on item-based collaborative
    filter.
  prefs: []
  type: TYPE_NORMAL
- en: 'ITCF involves the following three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computing the item-based similarities through a distance measure**: This
    involves computing the distance between the items. The distance may be computed
    with one of the many distance measures, such as Cosine similarity, Euclidean distance,
    Manhattan distance, or Jaccard index. The output of this step is to obtain a similarity
    matrix where each cell corresponds to the similarity of the item specified on
    the row of the cell and the item specified on the column of the cell.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Predicting the targeted item rating for a specific user**: The rating is
    arrived at by computing the weighted sum of ratings made to the item very similar
    to the target item.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Recommending the top N items**: Once all the items are predicted, we recommend
    the top *N* items.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let''s build each one of the ITCF models and measure the performance against
    the test dataset. The following code trains the ITCF models with several parameter
    combinations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have the ITCF models, so let''s get to computing the performance on
    the test data with each of the models we have created. The objective is to identify
    the best-performing ITCF model for this dataset. The following code gets the performance
    measurements with all the nine models on the test dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We see the output that the ITCF recommendation application on data with the
    Euclidean distance yielded the best performance measurement.
  prefs: []
  type: TYPE_NORMAL
- en: Building a recommendation system with a user-based collaborative filtering technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Jokes recommendation system we built earlier, with item-based filtering,
    uses the powerful `recommenderlab` library available in R. In this implementation
    of the **user-based collaborative filtering** (**UBCF**) approach, we make use
    of the same library.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the working principle of UBCF:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d22941f0-29d2-4c0e-8a79-5f065e5f527e.png)'
  prefs: []
  type: TYPE_IMG
- en: Example depicting working principle of user based collaborative filter
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand the concept better, let''s discuss the preceding diagram in detail.
    Let''s assume that there are three users: X,Y, and Z. In UBCF, users X and Z are
    very similar as both of them like strawberries and watermelons. User X also likes
    grapes and oranges. So a user-based collaborative filter recommends grapes and
    oranges to user Z. The idea is that similar people tend to like similar things.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The primary difference between a user-based collaborative filter and an item-based
    collaborative filter is demonstrated by the following recommendation captions
    often seen in online retail sites:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ITCF**: Customers who bought this item also bought'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UBCF**: Customers similar to you bought'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A user-based collaborative filter is built upon the following three key steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the **k-nearest neighbors** (**KNN**) to the user *x*, using a similarity
    function, *w*, to measure the distance between each pair of users:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0052a429-61c2-4996-afe6-b51671d3ac79.png)'
  prefs: []
  type: TYPE_IMG
- en: Predict the rating that user *x* will provide to all items the KNN has rated,
    but *x* has not.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The *N* recommended items to user *x* is the top *N* items that have the best
    predicted ratings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In short, a user-item matrix is constructed during the UBCF process and based
    on similar users, the ratings of the unseen items of a user are predicted. The
    items that get the highest ratings among the predictions form the final list of
    recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of this project is very similar to ITCF as we are using
    the same library. The only change required in the code is to change the IBCF method
    to use UBCF. The following code block is the full code of the project implementation
    with UBCF:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Based on the UBCF output, we observe that the `Z-score` normalized data with
    Pearson's correlation as the distance has yielded the best performance measurement.
    Furthermore, if we want, the UBCF and ITCF results may be compared (testing needs
    to be done on the same test dataset) to arrive at a conclusion of accepting the best
    model among the 18 models that are built for the final recommendation engine deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The key point to observe in the code is the `UBCF` value that is passed to the `method`
    parameter. In the previous project, we built an item-based collaborative filter;
    all that is needed is for us to replace the value passed to the `method` parameter
    with IBCF.
  prefs: []
  type: TYPE_NORMAL
- en: Building a recommendation system based on an association-rule mining technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Association-rule mining, or market-basket analysis, is a very popular data mining
    technique used in the retail industry to identify the products that need to be
    kept together so as to encourage cross sales. An interesting aspect behind this
    algorithm is that historical invoices are mined to identify the products that
    are bought together.
  prefs: []
  type: TYPE_NORMAL
- en: There are several off-the-shelf algorithms available to perform market-basket
    analysis. Some of them are Apriori, **equivalence class transformation** (**ECLAT**),
    and **frequent pattern growth** (**FP-growth**). We will learn to solve our problem
    of recommending jokes to users through applying the Apriori algorithm on the Jester
    jokes dataset. We will now learn the theoretical aspects that underpin the Apriori
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The Apriori algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The building blocks of the algorithm are the items that are found in any given
    transaction. Each transaction could have one or more items in it. The items that
    form a transaction are called an itemset. An example of a transaction is an invoice.
  prefs: []
  type: TYPE_NORMAL
- en: Given the transactions dataset, the objective is to find the items in data that
    are associated with each other. Association is measured as frequency of the occurrence
    of the items in the same context. For example, purchasing one product when another
    product is purchased represents an association rule. The association rule detects
    the common usage of items.
  prefs: []
  type: TYPE_NORMAL
- en: More formally, we can define association-rule mining as, given a set of items
    I = {I1,I2,..Im} and database of transactions D = {t1,t,2..tn}, where ti= { Ii1,Ii2..Iim}
    where Iik is element of, an association is an implication of X->Y where X,Y subset
    of I are set of items and X intersection Y is φ. In short, associations express
    an implication from X-> Y, where X and Y are itemsets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm can be better understood by an example. So, let''s consider the
    following table, which shows a representative list of sample transactions in a
    supermarket:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Transaction** | **Items** |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Milk, curd, chocolate |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Bread, butter |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Coke, jam |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Bread, milk, butter, Coke |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Bread, milk, butter, jam |'
  prefs: []
  type: TYPE_TB
- en: Sample transactions in a super market
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to explore some fundamental concepts that will help us understand
    how the Apriori algorithm works:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Item**: An item is any individual product that is part of each of the transactions.
    For example, milk, Coke, and butter are all termed as items.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Itemset**: Collection of one or more items. For example, *{butter, milk,
    coke}, {butter, milk}*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support count**: Frequency of occurrence of an itemset. For example, support
    count or *σ {butter, bread, milk} = 2*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support**: A fraction of transactions that contain an itemset. For example, *s
    = {butter, bread, milk} = 2/5*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequent itemset**: An itemset whose support is greater than the minimum
    threshold.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support for an itemset in a context**: Fraction of contexts that contain
    both *X* and *Y*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/d64f7390-23d7-409f-94cf-887150e51c11.png)'
  prefs: []
  type: TYPE_IMG
- en: So, *s* for *{milk, butter} -> {bread} will be s = σ {milk, butter, bread}/N
    = 2/5 = 0.4*
  prefs: []
  type: TYPE_NORMAL
- en: '**Confidence**: Measures the strength of the rule, whereas support measures
    how often it should occur in the database. It computes how often items in *Y*
    occur in containing *X* through the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/d00a906f-97da-40fc-8a56-293d0461bcc9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For example: For {bread} -> {butter}'
  prefs: []
  type: TYPE_NORMAL
- en: '*c or α = σ {butter, bread} / σ {bread} = 3/3 = 1*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider another example confidence for *{curd} -> {bread}*:'
  prefs: []
  type: TYPE_NORMAL
- en: '*c or α = σ {curd,bread} / σ {bread} = 0/3 = 0*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Apriori algorithm intends to generate all possible combinations of the
    itemsets from the list of the items and then prunes the itemsets that have met
    the predefined support and confidence parameter values that were passed to the
    algorithm. So, it may be understood that the Apriori algorithm is a two-step algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating itemsets from the items
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluating and pruning the itemsets based on predefined support and confidence
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's discuss step 1 in detail. Assume there are *n* items in the collection.
    The number of itemsets one could create is 2^*n*, and all these need to be evaluated
    in the second step in order to come up with the final results. Even considering
    just 100 different items, the number of itemsets generated is 1.27e+30! The huge
    number of itemsets poses a severe computational challenge.
  prefs: []
  type: TYPE_NORMAL
- en: The Apriori algorithm overcomes this challenge by preempting the itemsets that
    are generally rare or less important. The Apriori principle states that *if an
    itemset is frequent, all of its subsets must also be frequent*. This means that
    if an item does not meet the predefined support threshold, then such item does
    not participate in the creation of itemsets. The Apriori algorithm thus comes
    up with restricted number of itemsets that are viable to be evaluated without
    encountering a computational challenge.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step of the algorithm is iterative in nature. In the first iteration,
    it considers all itemsets of length 1, that is, each itemset contains only one
    item in it. Then each item is evaluated to eliminate the itemsets that are found
    to not meet the preset support threshold. The output of the first iteration is
    all itemsets of length 1 that meet the required support. This becomes the input
    for iteration 2, and now itemsets of length 2 are formed using only the final
    itemsets that are output in first iteration. Each of the itemsets formed during
    step 2 is checked again for the support threshold; if it is not met, such itemsets
    are eliminated. The iterations continue until no new itemsets can be created.
    The process of itemsets is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6eead20b-c634-450e-be63-eba894c02b86.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration showing the itemsets creation in Apriori algorithm
  prefs: []
  type: TYPE_NORMAL
- en: Once we have all itemsets post all the step 1 iterations of the algorithm, step
    2 kicks in. Each of the itemsets generated is tested to check whether it meets
    the predefined confidence value. If it does not meet the threshold, such itemsets
    are eliminated from the final output.
  prefs: []
  type: TYPE_NORMAL
- en: 'At a stage where all iterations are complete and the final rules are the output
    from Apriori, we make use of a metric called lift to consume the relevant rules
    from the final output. Lift defines how much more likely one item or itemset is
    purchased relative to its typical rate of purchase, given that we know another
    item or itemset has been purchased. For each itemset, we get the lift measurement
    using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d40eaf00-9435-4131-9272-b62dc512c54b.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's delve a little deeper into understanding the lift metric. Assume that
    in a supermarket, milk and bread are bought together by chance. In such a case,
    a large number of transactions are expected to cover the milk and bread purchased.
    A lift (milk -> bread) of more than 1 implies that these items are found together
    more often than these items are purchased together by chance. We generally would
    look for lift values greater than 1 when evaluating the rules for their usefulness
    in business. A lift value higher than 1 indicates that the itemset generated is
    very strong, and therefore worth considering for implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s implement the recommendation system using the Apriori algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We can see from the output that the `Jester5k` data in the `recommenderlab`
    library is in the `realRatingsMatrix` format. We are also aware that the cells
    in this matrix contain the ratings provided by the users for various jokes and
    we are aware that the ratings range between -10 to +10.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying the Apriori algorithm on the `Jester5k` dataset give us an opportunity
    to understand the association between the jokes. However, prior to applying the
    Apriori algorithm, we will need to transform the dataset to binary values where
    1 represents a positive rating and 0 represents a negative rating or no rating.
    The `recommenderlab` library comes up with the `binarize()` function, which can
    perform the required operation for us. The following code binarizes the ratings
    matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We can observe from the output that `realRatingsMatrix` is successfully converted
    into `binaryRatingMatrix`. The Apriori algorithm that mines the associations expects
    a matrix to be passed as input rather than `binaryRatingMatrix`. We can very easily
    convert the `Jester5k_bin` object to the matrix format with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/94f50034-68a7-44df-9c4e-653e4d103700.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We see from the output that all the cells of the matrix are represented as
    `TRUE` and `FALSE`, but Apriori expects the cells to be numeric. Let''s now convert
    the cells into `1` and `0` for `TRUE` and `FALSE`, respectively, with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5f7b4675-5f57-4d77-82bb-3768722b41c0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we are all set to apply the Apriori algorithm on the dataset. There are
    two parameters, `support` and `confidence`, that we need to pass to the algorithm.
    The algorithm mines the dataset based on these two parameter values. We pass `0.5`
    as the value for support and `0.8` as the value for confidence. The following
    line of code extracts the joke associations that exist in our Jester jokes dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The `rules` object that was created from the execution of the Apriori algorithm
    now has all the joke associations that were extracted and mined from the dataset.
    As we can see from the output, there are `78` jokes associations that were extracted
    in total. We can examine the rules with the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The output shown is just five rules out of the overall 78 rules that are in
    the list. The way to read each rule is that the joke shown on the left column
    (`lhs`) leads to the joke on the right column (`rhs`); that is, a user that liked
    the joke on `lhs` of the rule generally tends to like the joke shown on `rhs`.
    For example, in the first rule, if a user has liked joke `j48`, it is likely that
    they will also like `j50`, therefore it is worth recommending joke `j50` to the
    user that has only read joke `j48`.
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are several rules generated by the Apriori algorithm, the strength
    of each rule is specified by a metric, called `lift`. This is a metric that describes
    the worthiness of a rule in a business context. Note that for a rule to be considered
    general, it has to have a lift that is less than or equal to `1`. A lift value
    greater than 1 signifies a better rule for implementing in business. The aim of
    the following lines of code is to get such strong rules to the top of the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/83ceb235-42e8-4278-8191-79cbceabdc2e.png)'
  prefs: []
  type: TYPE_IMG
- en: It may be observed that the output shown is only a subset of the rules output.
    The first rule indicates that `j35` is a joke that can be recommended to a user
    that has already read jokes `j29` and `j50`.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, we could just write a script to search all the jokes that a user has
    already read and match it with the left side of the rule; if a match is found,
    the corresponding right side of the rule can be recommended as the joke for the
    user.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based recommendation engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A recommendation engine that is solely based on the explicit or implicit feedback
    received from customers is termed as **content-based recommendation system**.
    Explicit feedback is the customer's expression of the interest through filling
    in a survey about preferences or rating jokes of interest or opting for newsletters
    related to the joke or adding the joke on the watchlist, and so on. Implicit feedback
    is more of a mellowed-out approach where a customer visits a page, clicks on a
    joke link, or just spends time reading a joke review on an e-commerce page. Based
    on the feedback received, similar jokes are recommended to the customers. It may
    be noted that content-based recommendations do not take into consideration the
    preferences and feedback of other customers in the system; instead, it is purely
    based on the personalized feedback from the specific customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the recommendation process, the system identifies the products that are
    already positively rated by the customer with the products that the customer has
    not rated and looks for equivalents. Products that are similar to the positively-rated
    ones are recommended to the customers. In this model, the customer''s preferences
    and behavior play a major role in incrementally fine-tuning the recommendations—that
    is, with each recommendation and based on whether the customer responded to the
    recommendation, the system learns incrementally to recommend differently. The
    following diagram is an illustration of how a content-based recommendation system
    works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62443519-42f8-4de0-9d16-df39c9b9205d.png)'
  prefs: []
  type: TYPE_IMG
- en: Working of a content based recommendation system
  prefs: []
  type: TYPE_NORMAL
- en: In our Jester jokes dataset, we have ratings given by users for various jokes
    as well as the content of the jokes themselves. Remember that the `JesterJokes`
    character vector incorporates the text present in the jokes themselves. Similarities
    between the texts present in the jokes can be used as one method to recommend
    jokes to users. The assumption is that if a person liked the content in a joke,
    and if there is another joke whose content is very similar, recommending the latter
    joke is probably going to be liked by the user.
  prefs: []
  type: TYPE_NORMAL
- en: Additional metadata related to jokes is not given in the Jester jokes dataset,
    however such metadata may be created from the content of the jokes. For example,
    the length of the joke, number of nouns, number of funny terms present in the
    joke, and central theme in the joke. Processing the text is not purely a recommendation
    area but it involves using NLP techniques as well. As we will be covering NLP
    in a different chapter, we will not cover it here.
  prefs: []
  type: TYPE_NORMAL
- en: Differentiating between ITCF and content-based recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It might appear that item-based collaborative and content-based recommendations
    are the same. In reality, they are not the same. Let's touch upon the differences.
  prefs: []
  type: TYPE_NORMAL
- en: ITCF is totally based on user-item rankings. When we compute the similarity
    between items, we do not include the item attributes and just compute the similarity
    of items based on all customers' ratings. So the similarity between items is computed
    based on the ratings instead of the metadata of item itself.
  prefs: []
  type: TYPE_NORMAL
- en: In content-based recommendations, we make use of the content of both the user
    and the item. Generally, we construct a user profile and item profile using the
    content of a shared attribute space. For example, for a movie, we represent it
    with the actors in it and the genre (using binary coding, for example). For a
    user profile, we can do the same thing based on the user, such as some actors/genres.
    Then the similarity of user and item can be computed using cosine similarity,
    for example. This cosine measure leads to the recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering identifies products that are similar based on the tags
    assigned to each product. Each product is assigned weights on the basis of term
    frequency and inverse document frequency of each tag. After this, the user's probability
    of liking a product is calculated in order to arrive at the final recommendation
    list.
  prefs: []
  type: TYPE_NORMAL
- en: While content-based recommendation systems are highly efficient and personalized,
    there is an inherent problem with this model. Let's understand the over-specialization
    problem of content-based recommendations with an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assume there are the following five movie genres:'
  prefs: []
  type: TYPE_NORMAL
- en: Comedy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thriller
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Science fiction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Action
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Romance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is this customer, Jake, who generally watches thriller and science fiction
    movies. Based on this preference, the content-based recommendation engine will
    only recommend movies related to these genres and it is never going to recommend
    movies from other categories. This problem arises as content-based recommendation
    engine solely relies on the user's past behavior and preferences to determine
    the recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike content-recommendation systems, in ITCF recommendations, similar products
    build neighborhoods based on positive preferences of customers. Therefore, the
    system generates recommendations with products in the neighborhood that a customer
    might prefer. ITCF does this by making use of the correlation between the items
    based on the ratings given them by different users, while collaborative filtering
    relies on past preferences or rating correlation between users and it is able
    to generate recommendations for similar products even from customer's interest
    domain. This technique can lead to bad predictions if the product is unpopular
    and very few users have given feedback about it.
  prefs: []
  type: TYPE_NORMAL
- en: Building a hybrid recommendation system for Jokes recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We see that both content-based filtering and collaborative filtering have their
    strengths and weaknesses. To overcome the issues, organizations build recommender
    systems that combine two or more technique and they are termed hybrid recommendation
    models. An example of this is a combination of content-based, IBCF, UBCF, and
    model-based recommender engine. This takes into account all the possible aspects
    that contribute to making the most relevant recommendation to the user. The following
    diagram shows an example approach followed in hybrid recommendation engines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de76d7c8-e602-45d1-a149-fba5f673ac84.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample approach to hybrid recommendation engine
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to note that there is no standard approach to achieving a hybrid recommendation
    engine. In order to combine recommendations, here are some suggested strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Voting**: Apply voting among the recommendation output obtained from individual
    recommender systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rules-based selection**: We could devise rules that suggest weighting the
    output recommendations obtained from individual recommender systems. In this case,
    the output from recommender systems that got higher weights will be dominant and
    have more influence on the final recommendation outcome.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combination**: Recommendations from all the recommender engines are presented
    together. A final list of recommendations is just the union of all recommendation
    output obtained from individual recommender systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Attribute integration**: Taking metadata from all recommender system to infuse
    it as input to another recommender.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Again, what works for a problem may not work for another, therefore these strategies
    need to be tested individually prior to coming up with final recommendation strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `recommenderlab` library offers the `HybridRecommender` function which allows
    users to train multiple recommender engines on the same set of data in one go
    and combine the predictions. The function has a weights parameter that offers
    a way to specify the weight of each of the models that will be used to combine
    individual predictions to arrive at the final recommendation predictions on unseen
    data. Implementing a hybrid recommendation-engine-based project is super straightforward
    and not too different from the code we learned in item-based collaborative filtering
    or user-based collaborative filtering projects. Anyway, let''s write the code
    and build a hybrid recommendation engine for the `Jester5k` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code is what trains a hybrid recommender. This is where it differs
    from the `ITCF` or `UBCF` recommenders we''ve built. We can observe from the code
    that we have used four different recommender methods that will constitute the
    hybrid recommender. Let''s discuss each of these methods:'
  prefs: []
  type: TYPE_NORMAL
- en: The popular recommendation method simply recommends the popular jokes (determined
    by the number of ratings received) to users.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second recommender method we have used is item-based collaborative filtering
    method with non-normalized data but with distance being computed between items
    through cosine similarity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-based collaborative filtering on `Z-score` normalized data with Euclidean
    distance being computed between users in the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A random recommendation method that provides a random recommendation to the
    users.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By no means, we finalize that the combination of these four recommender methods
    is the best hybrid for this problem. The intention of this project is to demonstrate
    the implementation of the hybrid recommender. The choice of the methods involved
    is purely arbitrary. In reality, we may need to try multiple combinations to identify
    the best hybrid. The hybrid classifier is built using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Observe the weights assignment in the hybrid model. We see that the popular
    and random recommenders are assigned 20% weight each, whereas the `ITCF` and `UBCF`
    methods involved in the preceding hybrid are assigned 30% weight each. It is not
    mandatory to set the weights while building a hybrid recommender, in which case,
    equal weights are assigned to each of the methods involved in the hybrid recommender.
    Now that our model is ready, let''s make predictions and evaluate the performance
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used the `recommenderlab` library extensively to build the
    various types of joke-recommendation engines based on the Jester jokes dataset.
    We also learned about the theoretical concepts behind the methods.
  prefs: []
  type: TYPE_NORMAL
- en: Recommender systems is an individual ML area on its own. This subject is so
    vast that it cannot be covered in just one chapter. Several types of recommendation
    systems exists and they may be applied to datasets in specific scenarios. Matrix
    factorization, singular-value decomposition approximation, most popular items,
    and SlopeOne are some techniques that may be employed to build recommendation
    systems. These techniques are outside the scope of this chapter as these are rarely
    used in business situations to build recommendation systems, and the aim of the
    chapter is provide exposure to more popular techniques. Further learning on recommendation
    engines could be in the direction of exploring and studying these rarely-used
    techniques and applying them to real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is focused on NLP techniques. We are going to implement a sentiment-analysis
    engine on Amazon product reviews using several popular techniques. We'll explore
    semantic and syntactic approaches to analyzing text and then apply them on the
    Amazon review corpus. I am all geared up to turn this page and move on to the
    next chapter. How about you?!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While the `recommenderlab` library is super popular in the R community, this
    is not the only choice for building a recommendation system. Here are some other
    popular libraries you may rely on to implement recommendation engines:'
  prefs: []
  type: TYPE_NORMAL
- en: '`rrecsys`: There are several popular recommendation systems, such as Global/Item/User-Average
    baselines, Item-Based KNN, FunkSVD, BPR, and weighted ALS for rapid prototyping.
    Refer to [https://cran.r-project.org/web/packages/rrecsys/index.htmlImplementations](https://cran.r-project.org/web/packages/rrecsys/index.htmlImplementations) for
    more information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recosystem`: The R wrapper of the `libmf` library ([http://www.csie.ntu.edu.tw/~cjlin/libmf/](http://www.csie.ntu.edu.tw/~cjlin/libmf/))
    for recommender system using matrix factorization. It is typically used to approximate
    an incomplete matrix using the product of two matrices in a latent space. Other
    common names for this task include collaborative filtering, matrix completion,
    and matrix recovery. High-performance multicore parallel computing is supported
    in this package.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rectools`: An advanced package for recommender systems to incorporate user
    and item covariate information, including item category preferences with parallel
    computation, novel variations on statistical latent factor model, focus group
    finder, NMF, ANOVA, and cosine models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
